<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-20T01:42:30Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>assafelovic/gpt-researcher</title>
    <updated>2023-08-20T01:42:30Z</updated>
    <id>tag:github.com,2023-08-20:/assafelovic/gpt-researcher</id>
    <link href="https://github.com/assafelovic/gpt-researcher" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GPT based autonomous agent that does online comprehensive research on any given topic&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üîé GPT Researcher&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://tavily.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Official%20Website-tavily.com-blue?style=flat&amp;amp;logo=world&amp;amp;logoColor=white&#34; alt=&#34;Official Website&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.com/invite/2pFkc83fRq&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/2pFkc83fRq?style=flat&#34; alt=&#34;Discord Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/assafelovic/gpt-researcher&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/assafelovic/gpt-researcher?style=social&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/assaf_elovic&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/assaf_elovic?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GPT Researcher is an autonomous agent designed for comprehensive online research on a variety of tasks.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The agent can produce detailed, factual and unbiased research reports, with customization options for focusing on relevant resources, outlines, and lessons. Inspired by &lt;a href=&#34;https://github.com/Significant-Gravitas/Auto-GPT&#34;&gt;AutoGPT&lt;/a&gt; and the recent &lt;a href=&#34;https://arxiv.org/abs/2305.04091&#34;&gt;Plan-and-Solve&lt;/a&gt; paper, GPT Researcher addresses issues of speed and determinism, offering a more stable performance and increased speed through parallelized agent work, as opposed to synchronous operations.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Our mission is to empower individuals and organizations with accurate, unbiased, and factual information by leveraging the power of AI.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Why GPT Researcher?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To form objective conclusions for manual research tasks can take time, sometimes weeks to find the right resources and information.&lt;/li&gt; &#xA; &lt;li&gt;Current LLMs are trained on past and outdated information, with heavy risks of hallucinations, making them almost irrelevant for research tasks.&lt;/li&gt; &#xA; &lt;li&gt;Solutions that enable web search (such as ChatGPT + Web Plugin), only consider limited resources that in some cases result in superficial conclusions or biased answers.&lt;/li&gt; &#xA; &lt;li&gt;Using only a selection of resources can create bias in determining the right conclusions for research questions or tasks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;The main idea is to run &#34;planner&#34; and &#34;execution&#34; agents, whereas the planner generates questions to research, and the execution agents seek the most related information based on each generated research question. Finally, the planner filters and aggregates all related information and creates a research report. The agents leverage both gpt3.5-turbo-16k and gpt-4 to complete a research task.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img align=&#34;center&#34; height=&#34;500&#34; src=&#34;https://cowriter-images.s3.amazonaws.com/arch.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;More specifically:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate a set of research questions that together form an objective opinion on any given task.&lt;/li&gt; &#xA; &lt;li&gt;For each research question, trigger a crawler agent that scrapes online resources for information relevant to the given task.&lt;/li&gt; &#xA; &lt;li&gt;For each scraped resources, summarize based on relevant information and keep track of its sources.&lt;/li&gt; &#xA; &lt;li&gt;Finally, filter and aggregate all summarized sources and generate a final research report.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/assafelovic/gpt-researcher/assets/13554167/a00c89a6-a295-4dd0-b58d-098a31c40fda&#34;&gt;https://github.com/assafelovic/gpt-researcher/assets/13554167/a00c89a6-a295-4dd0-b58d-098a31c40fda&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Tutorials&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.loom.com/share/04ebffb6ed2a4520a27c3e3addcdde20?sid=da1848e8-b1f1-42d1-93c3-5b0b9c3b24ea&#34;&gt;How to Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.loom.com/share/6a3385db4e8747a1913dd85a7834846f?sid=a740fd5b-2aa3-457e-8fb7-86976f59f9b8&#34;&gt;Live Demo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìù Generate research, outlines, resources and lessons reports&lt;/li&gt; &#xA; &lt;li&gt;üåê Aggregates over 20 web sources per research to form objective and factual conclusions&lt;/li&gt; &#xA; &lt;li&gt;üñ•Ô∏è Includes an easy-to-use web interface (HTML/CSS/JS)&lt;/li&gt; &#xA; &lt;li&gt;üîç Scrapes web sources with javascript support&lt;/li&gt; &#xA; &lt;li&gt;üìÇ Keeps track and context of visited and used web sources&lt;/li&gt; &#xA; &lt;li&gt;üìÑ Export research reports to PDF and more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 0&lt;/strong&gt; - Install Python 3.11 or later. &lt;a href=&#34;https://www.tutorialsteacher.com/python/install-python&#34;&gt;See here&lt;/a&gt; for a step-by-step guide.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; - Download the project&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/assafelovic/gpt-researcher.git&#xA;$ cd gpt-researcher&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; - Install dependencies&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; - Create .env file with your OpenAI Key or simply export it&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ export OPENAI_API_KEY={Your API Key here}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;By default, we use OpenAI, but you can use any other LLM model (including open sources)&lt;/strong&gt; supported by &lt;a href=&#34;https://python.langchain.com/docs/guides/adapters/openai&#34;&gt;Langchain Adapter&lt;/a&gt;, simply change the llm model and provider in config/config.py. Follow &lt;a href=&#34;https://python.langchain.com/docs/integrations/llms/&#34;&gt;this guide&lt;/a&gt; to learn how to integrate LLMs with Langchain.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;We highly recommend using GPT models for optimal performance.&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 4&lt;/strong&gt; - Run the agent with FastAPI&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ uvicorn main:app --reload&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 5&lt;/strong&gt; - Go to &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt; on any browser and enjoy researching!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;update:&lt;/strong&gt; if you are having issues with weasyprint, please visit their website and follow the installation instructions: &lt;a href=&#34;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&#34;&gt;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Try it with Docker&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; - Install Docker&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Follow instructions at &lt;a href=&#34;https://docs.docker.com/engine/install/&#34;&gt;https://docs.docker.com/engine/install/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; - Create .env file with your OpenAI Key or simply export it&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ export OPENAI_API_KEY={Your API Key here}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; - Run the application&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 4&lt;/strong&gt; - Go to &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt; on any browser and enjoy researching!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;update:&lt;/strong&gt; if you are having issues with weasyprint, please visit their website and follow the installation instructions: &lt;a href=&#34;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&#34;&gt;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üöÄ Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We highly welcome contributions! Please check out &lt;a href=&#34;https://raw.githubusercontent.com/assafelovic/gpt-researcher/master/CONTRIBUTING.md&#34;&gt;contributing&lt;/a&gt; if you&#39;re interested.&lt;/p&gt; &#xA;&lt;p&gt;Please check out our &lt;a href=&#34;https://trello.com/b/3O7KBePw/gpt-researcher-roadmap&#34;&gt;roadmap&lt;/a&gt; page and reach out to us via our &lt;a href=&#34;https://discord.gg/2pFkc83fRq&#34;&gt;Discord community&lt;/a&gt; if you&#39;re interested in joining our mission.&lt;/p&gt; &#xA;&lt;h2&gt;üîß Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re constantly working to provide a more stable version. In the meantime, see here for known issues:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;model: gpt-4 does not exist&lt;/strong&gt; This relates to not having permission to use gpt-4 yet. Based on OpenAI, it will be &lt;a href=&#34;https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4&#34;&gt;widely available for all by end of July&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;cannot load library &#39;gobject-2.0-0&#39;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The issue relates to the library WeasyPrint (which is used to generate PDFs from the research report). Please follow this guide to resolve it: &lt;a href=&#34;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&#34;&gt;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Error processing the url&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;We&#39;re using &lt;a href=&#34;https://www.selenium.dev&#34;&gt;Selenium&lt;/a&gt; for site scraping. Some sites fail to be scraped. In these cases, restart and try running again.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Chrome version issues&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Many users have an issue with their chromedriver because the latest chrome browser version doesn&#39;t have a compatible chrome driver yet.&lt;/p&gt; &#xA;&lt;p&gt;To downgrade your Chrome web browser using &lt;a href=&#34;https://www.slimjet.com/chrome/google-chrome-old-version.php&#34;&gt;slimjet&lt;/a&gt;, follow these steps. First, visit the website and scroll down to find the list of available older Chrome versions. Choose the version you wish to install making sure it&#39;s compatible with your operating system. Once you&#39;ve selected the desired version, click on the corresponding link to download the installer. Before proceeding with the installation, it&#39;s crucial to uninstall your current version of Chrome to avoid conflicts.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s important to check if the version you downgrade to, has a chromedriver available in the official &lt;a href=&#34;https://chromedriver.chromium.org/downloads&#34;&gt;chrome driver website&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;If none of the above work, you can &lt;a href=&#34;https://app.tavily.com&#34;&gt;try out our hosted beta&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üõ° Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This project, GPT Researcher, is an experimental application and is provided &#34;as-is&#34; without any warranty, express or implied. We are sharing codes for academic purposes under the MIT license. Nothing herein is academic advice, and NOT a recommendation to use in academic or research papers.&lt;/p&gt; &#xA;&lt;p&gt;Our view on unbiased research claims:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The whole point of our scraping system is to reduce incorrect fact. How? The more sites we scrape the less chances of incorrect data. We are scraping 20 per research, the chances that they are all wrong is extremely low.&lt;/li&gt; &#xA; &lt;li&gt;We do not aim to eliminate biases; we aim to reduce it as much as possible. &lt;strong&gt;We are here as a community to figure out the most effective human/llm interactions.&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;In research, people also tend towards biases as most have already opinions on the topics they research about. This tool scrapes many opinions and will evenly explain diverse views that a biased person would never have read.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note that the use of the GPT-4 language model can be expensive due to its token usage.&lt;/strong&gt; By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>huggingface/candle</title>
    <updated>2023-08-20T01:42:30Z</updated>
    <id>tag:github.com,2023-08-20:/huggingface/candle</id>
    <link href="https://github.com/huggingface/candle" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Minimalist ML framework for Rust&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;candle&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.com/channels/879548962464493619/1136218819447238726&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/hugging-face-879548962464493619&#34; alt=&#34;discord server&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://crates.io/crates/candle-core&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/v/candle-core.svg?sanitize=true&#34; alt=&#34;Latest version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.rs/candle-core&#34;&gt;&lt;img src=&#34;https://docs.rs/candle-core/badge.svg?sanitize=true&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/crates/l/candle-core.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Candle is a minimalist ML framework for Rust with a focus on performance (including GPU support) and ease of use. Try our online demos: &lt;a href=&#34;https://huggingface.co/spaces/lmz/candle-whisper&#34;&gt;whisper&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/spaces/lmz/candle-llama2&#34;&gt;llama2&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let a = Tensor::randn(0f32, 1., (2, 3), &amp;amp;Device::Cpu)?;&#xA;let b = Tensor::randn(0f32, 1., (3, 4), &amp;amp;Device::Cpu)?;&#xA;&#xA;let c = a.matmul(&amp;amp;b)?;&#xA;println!(&#34;{c}&#34;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Check out our examples&lt;/h2&gt; &#xA;&lt;p&gt;Check out our &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/&#34;&gt;examples&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/whisper/&#34;&gt;Whisper&lt;/a&gt;: speech recognition model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/llama/&#34;&gt;Llama and Llama-v2&lt;/a&gt;: general LLM.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/falcon/&#34;&gt;Falcon&lt;/a&gt;: general LLM.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/bert/&#34;&gt;Bert&lt;/a&gt;: useful for sentence embeddings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/bigcode/&#34;&gt;StarCoder&lt;/a&gt;: LLM specialized to code generation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/stable-diffusion/&#34;&gt;Stable Diffusion&lt;/a&gt;: text to image generative model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/dinov2/&#34;&gt;DINOv2&lt;/a&gt;: computer vision model trained using self-supervision (can be used for imagenet classification, depth evaluation, segmentation).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Run them using the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cargo run --example whisper --release&#xA;cargo run --example llama --release&#xA;cargo run --example falcon --release&#xA;cargo run --example bert --release&#xA;cargo run --example bigcode --release&#xA;cargo run --example stable-diffusion --release -- --prompt &#34;a rusty robot holding a fire torch&#34;&#xA;cargo run --example dinov2 --release -- --image path/to/myinput.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In order to use &lt;strong&gt;CUDA&lt;/strong&gt; add &lt;code&gt;--features cuda&lt;/code&gt; to the example command line. If you have cuDNN installed, use &lt;code&gt;--features cudnn&lt;/code&gt; for even more speedups.&lt;/p&gt; &#xA;&lt;p&gt;There are also some wasm examples for whisper and &lt;a href=&#34;https://github.com/karpathy/llama2.c&#34;&gt;llama2.c&lt;/a&gt;. You can either build them with &lt;code&gt;trunk&lt;/code&gt; or try them online: &lt;a href=&#34;https://huggingface.co/spaces/lmz/candle-whisper&#34;&gt;whisper&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/spaces/lmz/candle-llama2&#34;&gt;llama2&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For llama2, run the following command to retrieve the weight files and start a test server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd candle-wasm-examples/llama2-c&#xA;wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/model.bin&#xA;wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/tokenizer.json&#xA;trunk serve --release --public-url /candle-llama2/ --port 8081&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then head over to &lt;a href=&#34;http://localhost:8081/candle-llama2&#34;&gt;http://localhost:8081/candle-llama2&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!-- ANCHOR: features ---&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Simple syntax, looks and feels like PyTorch. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Model training.&lt;/li&gt; &#xA;   &lt;li&gt;Embed user-defined ops/kernels, such as &lt;a href=&#34;https://github.com/huggingface/candle/raw/89ba005962495f2bfbda286e185e9c3c7f5300a3/candle-flash-attn/src/lib.rs#L152&#34;&gt;flash-attention v2&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Backends. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Optimized CPU backend with optional MKL support for x86 and Accelerate for macs.&lt;/li&gt; &#xA;   &lt;li&gt;CUDA backend for efficiently running on GPUs, multiple GPU distribution via NCCL.&lt;/li&gt; &#xA;   &lt;li&gt;WASM support, run your models in a browser.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Included models. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;LLMs: Llama v1 and v2, Falcon, StarCoder.&lt;/li&gt; &#xA;   &lt;li&gt;Whisper (multi-lingual support).&lt;/li&gt; &#xA;   &lt;li&gt;Stable Diffusion.&lt;/li&gt; &#xA;   &lt;li&gt;Computer Vision: DINOv2.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Serverless (on CPU), small and fast deployments.&lt;/li&gt; &#xA; &lt;li&gt;Quantization support using the llama.cpp quantized types.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- ANCHOR_END: features ---&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;!-- ANCHOR: cheatsheet ---&gt; &#xA;&lt;p&gt;Cheatsheet:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Using PyTorch&lt;/th&gt; &#xA;   &lt;th&gt;Using Candle&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Creation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;torch.Tensor([[1, 2], [3, 4]])&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;Tensor::new(&amp;amp;[[1f32, 2.], [3., 4.]], &amp;amp;Device::Cpu)?&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Creation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;torch.zeros((2, 2))&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;Tensor::zeros((2, 2), DType::F32, &amp;amp;Device::Cpu)?&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Indexing&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;tensor[:, :4]&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;tensor.i((.., ..4))?&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Operations&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;tensor.view((2, 2))&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;tensor.reshape((2, 2))?&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Operations&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;a.matmul(b)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;a.matmul(&amp;amp;b)?&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Arithmetic&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;a + b&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&amp;amp;a + &amp;amp;b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Device&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;tensor.to(device=&#34;cuda&#34;)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;tensor.to_device(&amp;amp;Device::Cuda(0))?&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dtype&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;tensor.to(dtype=torch.float16)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;tensor.to_dtype(&amp;amp;DType::F16)?&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Saving&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;torch.save({&#34;A&#34;: A}, &#34;model.bin&#34;)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;candle::safetensors::save(&amp;amp;HashMap::from([(&#34;A&#34;, A)]), &#34;model.safetensors&#34;)?&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Loading&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;weights = torch.load(&#34;model.bin&#34;)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;candle::safetensors::load(&#34;model.safetensors&#34;, &amp;amp;device)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- ANCHOR_END: cheatsheet ---&gt; &#xA;&lt;h2&gt;Structure&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-core&#34;&gt;candle-core&lt;/a&gt;: Core ops, devices, and &lt;code&gt;Tensor&lt;/code&gt; struct definition&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-nn/&#34;&gt;candle-nn&lt;/a&gt;: Tools to build real models&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/&#34;&gt;candle-examples&lt;/a&gt;: Examples of using the library in realistic settings&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-kernels/&#34;&gt;candle-kernels&lt;/a&gt;: CUDA custom kernels&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-datasets/&#34;&gt;candle-datasets&lt;/a&gt;: Datasets and data loaders.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-transformers&#34;&gt;candle-transformers&lt;/a&gt;: transformers-related utilities.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/candle/main/candle-flash-attn&#34;&gt;candle-flash-attn&lt;/a&gt;: Flash attention v2 layer.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;Why should I use Candle?&lt;/h3&gt; &#xA;&lt;p&gt;Candle&#39;s core goal is to &lt;em&gt;make serverless inference possible&lt;/em&gt;. Full machine learning frameworks like PyTorch are very large, which makes creating instances on a cluster slow. Candle allows deployment of lightweight binaries.&lt;/p&gt; &#xA;&lt;p&gt;Secondly, Candle lets you &lt;em&gt;remove Python&lt;/em&gt; from production workloads. Python overhead can seriously hurt performance, and the &lt;a href=&#34;https://www.backblaze.com/blog/the-python-gil-past-present-and-future/&#34;&gt;GIL&lt;/a&gt; is a notorious source of headaches.&lt;/p&gt; &#xA;&lt;p&gt;Finally, Rust is cool! A lot of the HF ecosystem already has Rust crates, like &lt;a href=&#34;https://github.com/huggingface/safetensors&#34;&gt;safetensors&lt;/a&gt; and &lt;a href=&#34;https://github.com/huggingface/tokenizers&#34;&gt;tokenizers&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Other ML frameworks&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/coreylowman/dfdx&#34;&gt;dfdx&lt;/a&gt; is a formidable crate, with shapes being included in types. This prevents a lot of headaches by getting the compiler to complain about shape mismatches right off the bat. However, we found that some features still require nightly, and writing code can be a bit daunting for non rust experts.&lt;/p&gt; &lt;p&gt;We&#39;re leveraging and contributing to other core crates for the runtime so hopefully both crates can benefit from each other.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/burn-rs/burn&#34;&gt;burn&lt;/a&gt; is a general crate that can leverage multiple backends so you can choose the best engine for your workload.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/LaurentMazare/tch-rs.git&#34;&gt;tch-rs&lt;/a&gt; Bindings to the torch library in Rust. Extremely versatile, but they bring in the entire torch library into the runtime. The main contributor of &lt;code&gt;tch-rs&lt;/code&gt; is also involved in the development of &lt;code&gt;candle&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Common Errors&lt;/h3&gt; &#xA;&lt;h4&gt;Missing symbols when compiling with the mkl feature.&lt;/h4&gt; &#xA;&lt;p&gt;If you get some missing symbols when compiling binaries/tests using the mkl or accelerate features, e.g. for mkl you get:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  = note: /usr/bin/ld: (....o): in function `blas::sgemm&#39;:&#xA;          .../blas-0.22.0/src/lib.rs:1944: undefined reference to `sgemm_&#39; collect2: error: ld returned 1 exit status&#xA;&#xA;  = note: some `extern` functions couldn&#39;t be found; some native libraries may need to be installed or have their path specified&#xA;  = note: use the `-l` flag to specify native libraries to link&#xA;  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or for accelerate:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Undefined symbols for architecture arm64:&#xA;            &#34;_dgemm_&#34;, referenced from:&#xA;                candle_core::accelerate::dgemm::h1b71a038552bcabe in libcandle_core...&#xA;            &#34;_sgemm_&#34;, referenced from:&#xA;                candle_core::accelerate::sgemm::h2cf21c592cba3c47 in libcandle_core...&#xA;          ld: symbol(s) not found for architecture arm64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is likely due to a missing linker flag that was needed to enable the mkl library. You can try adding the following for mkl at the top of your binary:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;extern crate intel_mkl_src;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or for accelerate:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;extern crate accelerate_src;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Cannot run llama example : access to source requires login credentials&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;Error: request error: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer.json: status code 401&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is likely because you&#39;re not permissioned for the llama-v2 model. To fix this, you have to register on the huggingface-hub, accept the &lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-hf&#34;&gt;llama-v2 model conditions&lt;/a&gt;, and set up your authentication token. See issue &lt;a href=&#34;https://github.com/huggingface/candle/issues/350&#34;&gt;#350&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h4&gt;Tracking down errors&lt;/h4&gt; &#xA;&lt;p&gt;You can set &lt;code&gt;RUST_BACKTRACE=1&lt;/code&gt; to be provided with backtraces when a candle error is generated.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>songquanpeng/one-api</title>
    <updated>2023-08-20T01:42:30Z</updated>
    <id>tag:github.com,2023-08-20:/songquanpeng/one-api</id>
    <link href="https://github.com/songquanpeng/one-api" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenAI Êé•Âè£ÁÆ°ÁêÜ &amp; ÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅ Azure„ÄÅAnthropic Claude„ÄÅGoogle PaLM 2„ÄÅÊô∫Ë∞± ChatGLM„ÄÅÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®Ä„ÄÅËÆØÈ£ûÊòüÁÅ´ËÆ§Áü•‰ª•ÂèäÈòøÈáåÈÄö‰πâÂçÉÈóÆÔºåÂèØÁî®‰∫é‰∫åÊ¨°ÂàÜÂèëÁÆ°ÁêÜ keyÔºå‰ªÖÂçïÂèØÊâßË°åÊñá‰ª∂ÔºåÂ∑≤ÊâìÂåÖÂ•Ω Docker ÈïúÂÉèÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÂºÄÁÆ±Âç≥Áî®. OpenAI key management &amp; redistribution system, using a single API for all LLMs, and features an English UI.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;right&#34;&gt; &lt;strong&gt;‰∏≠Êñá&lt;/strong&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/songquanpeng/one-api/main/README.en.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/songquanpeng/one-api/main/README.ja.md&#34;&gt;Êó•Êú¨Ë™û&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/songquanpeng/one-api&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/songquanpeng/one-api/main/web/public/logo.png&#34; width=&#34;150&#34; height=&#34;150&#34; alt=&#34;one-api logo&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;One API&lt;/h1&gt; &#xA; &lt;p&gt;&lt;em&gt;‚ú® ÈÄöËøáÊ†áÂáÜÁöÑ OpenAI API Ê†ºÂºèËÆøÈóÆÊâÄÊúâÁöÑÂ§ßÊ®°ÂûãÔºåÂºÄÁÆ±Âç≥Áî® ‚ú®&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/songquanpeng/one-api/main/LICENSE&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/songquanpeng/one-api?color=brightgreen&#34; alt=&#34;license&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/songquanpeng/one-api/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/songquanpeng/one-api?color=brightgreen&amp;amp;include_prereleases&#34; alt=&#34;release&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/justsong/one-api&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/justsong/one-api?color=brightgreen&#34; alt=&#34;docker pull&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/songquanpeng/one-api/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/downloads/songquanpeng/one-api/total?color=brightgreen&amp;amp;include_prereleases&#34; alt=&#34;release&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/songquanpeng/one-api&#34;&gt; &lt;img src=&#34;https://goreportcard.com/badge/github.com/songquanpeng/one-api&#34; alt=&#34;GoReportCard&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/songquanpeng/one-api#ÈÉ®ÁΩ≤&#34;&gt;ÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/songquanpeng/one-api#‰ΩøÁî®ÊñπÊ≥ï&#34;&gt;‰ΩøÁî®ÊñπÊ≥ï&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/songquanpeng/one-api/issues&#34;&gt;ÊÑèËßÅÂèçÈ¶à&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/songquanpeng/one-api#Êà™ÂõæÂ±ïÁ§∫&#34;&gt;Êà™ÂõæÂ±ïÁ§∫&lt;/a&gt; ¬∑ &lt;a href=&#34;https://openai.justsong.cn/&#34;&gt;Âú®Á∫øÊºîÁ§∫&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/songquanpeng/one-api#Â∏∏ËßÅÈóÆÈ¢ò&#34;&gt;Â∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/songquanpeng/one-api#Áõ∏ÂÖ≥È°πÁõÆ&#34;&gt;Áõ∏ÂÖ≥È°πÁõÆ&lt;/a&gt; ¬∑ &lt;a href=&#34;https://iamazing.cn/page/reward&#34;&gt;ËµûËµèÊîØÊåÅ&lt;/a&gt; &lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; Êú¨È°πÁõÆ‰∏∫ÂºÄÊ∫êÈ°πÁõÆÔºå‰ΩøÁî®ËÄÖÂøÖÈ°ªÂú®ÈÅµÂæ™ OpenAI ÁöÑ&lt;a href=&#34;https://openai.com/policies/terms-of-use&#34;&gt;‰ΩøÁî®Êù°Ê¨æ&lt;/a&gt;‰ª•Âèä&lt;strong&gt;Ê≥ïÂæãÊ≥ïËßÑ&lt;/strong&gt;ÁöÑÊÉÖÂÜµ‰∏ã‰ΩøÁî®Ôºå‰∏çÂæóÁî®‰∫éÈùûÊ≥ïÁî®ÈÄî„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;Ê†πÊçÆ&lt;a href=&#34;http://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm&#34;&gt;„ÄäÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°ÁÆ°ÁêÜÊöÇË°åÂäûÊ≥ï„Äã&lt;/a&gt;ÁöÑË¶ÅÊ±ÇÔºåËØ∑ÂãøÂØπ‰∏≠ÂõΩÂú∞Âå∫ÂÖ¨‰ºóÊèê‰æõ‰∏ÄÂàáÊú™ÁªèÂ§áÊ°àÁöÑÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°„ÄÇ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt; ‰ΩøÁî® Docker ÊãâÂèñÁöÑÊúÄÊñ∞ÈïúÂÉèÂèØËÉΩÊòØ &lt;code&gt;alpha&lt;/code&gt; ÁâàÊú¨ÔºåÂ¶ÇÊûúËøΩÊ±ÇÁ®≥ÂÆöÊÄßËØ∑ÊâãÂä®ÊåáÂÆöÁâàÊú¨„ÄÇ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;ÂäüËÉΩ&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ÊîØÊåÅÂ§öÁßçÂ§ßÊ®°ÂûãÔºö &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://platform.openai.com/docs/guides/gpt/chat-completions-api&#34;&gt;OpenAI ChatGPT Á≥ªÂàóÊ®°Âûã&lt;/a&gt;ÔºàÊîØÊåÅ &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/ai-services/openai/reference&#34;&gt;Azure OpenAI API&lt;/a&gt;Ôºâ&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://anthropic.com&#34;&gt;Anthropic Claude Á≥ªÂàóÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://developers.generativeai.google&#34;&gt;Google PaLM2 Á≥ªÂàóÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html&#34;&gt;ÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®ÄÁ≥ªÂàóÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://help.aliyun.com/document_detail/2400395.html&#34;&gt;ÈòøÈáåÈÄö‰πâÂçÉÈóÆÁ≥ªÂàóÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.xfyun.cn/doc/spark/Web.html&#34;&gt;ËÆØÈ£ûÊòüÁÅ´ËÆ§Áü•Â§ßÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://bigmodel.cn&#34;&gt;Êô∫Ë∞± ChatGLM Á≥ªÂàóÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÈÖçÁΩÆÈïúÂÉè‰ª•Âèä‰ºóÂ§öÁ¨¨‰∏âÊñπ‰ª£ÁêÜÊúçÂä°Ôºö &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://openai-sb.com&#34;&gt;OpenAI-SB&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://api2d.com/r/197971&#34;&gt;API2D&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://aigptx.top?aff=uFpUl2Kf&#34;&gt;OhMyGPT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://aiproxy.io/?i=OneAPI&#34;&gt;AI Proxy&lt;/a&gt; ÔºàÈÇÄËØ∑Á†ÅÔºö&lt;code&gt;OneAPI&lt;/code&gt;Ôºâ&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://console.closeai-asia.com/r/2412&#34;&gt;CloseAI&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Ëá™ÂÆö‰πâÊ∏†ÈÅìÔºö‰æãÂ¶ÇÂêÑÁßçÊú™Êî∂ÂΩïÁöÑÁ¨¨‰∏âÊñπ‰ª£ÁêÜÊúçÂä°&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÈÄöËøá&lt;strong&gt;Ë¥üËΩΩÂùáË°°&lt;/strong&gt;ÁöÑÊñπÂºèËÆøÈóÆÂ§ö‰∏™Ê∏†ÈÅì„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ &lt;strong&gt;stream Ê®°Âºè&lt;/strong&gt;ÔºåÂèØ‰ª•ÈÄöËøáÊµÅÂºè‰º†ËæìÂÆûÁé∞ÊâìÂ≠óÊú∫ÊïàÊûú„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ&lt;strong&gt;Â§öÊú∫ÈÉ®ÁΩ≤&lt;/strong&gt;Ôºå&lt;a href=&#34;https://raw.githubusercontent.com/songquanpeng/one-api/main/#%E5%A4%9A%E6%9C%BA%E9%83%A8%E7%BD%B2&#34;&gt;ËØ¶ËßÅÊ≠§Â§Ñ&lt;/a&gt;„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ&lt;strong&gt;‰ª§ÁâåÁÆ°ÁêÜ&lt;/strong&gt;ÔºåËÆæÁΩÆ‰ª§ÁâåÁöÑËøáÊúüÊó∂Èó¥ÂíåÈ¢ùÂ∫¶„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ&lt;strong&gt;ÂÖëÊç¢Á†ÅÁÆ°ÁêÜ&lt;/strong&gt;ÔºåÊîØÊåÅÊâπÈáèÁîüÊàêÂíåÂØºÂá∫ÂÖëÊç¢Á†ÅÔºåÂèØ‰ΩøÁî®ÂÖëÊç¢Á†Å‰∏∫Ë¥¶Êà∑ËøõË°åÂÖÖÂÄº„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ&lt;strong&gt;ÈÄöÈÅìÁÆ°ÁêÜ&lt;/strong&gt;ÔºåÊâπÈáèÂàõÂª∫ÈÄöÈÅì„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ&lt;strong&gt;Áî®Êà∑ÂàÜÁªÑ&lt;/strong&gt;‰ª•Âèä&lt;strong&gt;Ê∏†ÈÅìÂàÜÁªÑ&lt;/strong&gt;ÔºåÊîØÊåÅ‰∏∫‰∏çÂêåÂàÜÁªÑËÆæÁΩÆ‰∏çÂêåÁöÑÂÄçÁéá„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÊ∏†ÈÅì&lt;strong&gt;ËÆæÁΩÆÊ®°ÂûãÂàóË°®&lt;/strong&gt;„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ&lt;strong&gt;Êü•ÁúãÈ¢ùÂ∫¶ÊòéÁªÜ&lt;/strong&gt;„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ&lt;strong&gt;Áî®Êà∑ÈÇÄËØ∑Â•ñÂä±&lt;/strong&gt;„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ‰ª•ÁæéÂÖÉ‰∏∫Âçï‰ΩçÊòæÁ§∫È¢ùÂ∫¶„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÂèëÂ∏ÉÂÖ¨ÂëäÔºåËÆæÁΩÆÂÖÖÂÄºÈìæÊé•ÔºåËÆæÁΩÆÊñ∞Áî®Êà∑ÂàùÂßãÈ¢ùÂ∫¶„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÊ®°ÂûãÊò†Â∞ÑÔºåÈáçÂÆöÂêëÁî®Êà∑ÁöÑËØ∑Ê±ÇÊ®°Âûã„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÂ§±Ë¥•Ëá™Âä®ÈáçËØï„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÁªòÂõæÊé•Âè£„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ‰∏∞ÂØåÁöÑ&lt;strong&gt;Ëá™ÂÆö‰πâ&lt;/strong&gt;ËÆæÁΩÆÔºå &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;ÊîØÊåÅËá™ÂÆö‰πâÁ≥ªÁªüÂêçÁß∞Ôºålogo ‰ª•ÂèäÈ°µËÑö„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;ÊîØÊåÅËá™ÂÆö‰πâÈ¶ñÈ°µÂíåÂÖ≥‰∫éÈ°µÈù¢ÔºåÂèØ‰ª•ÈÄâÊã©‰ΩøÁî® HTML &amp;amp; Markdown ‰ª£Á†ÅËøõË°åËá™ÂÆö‰πâÔºåÊàñËÄÖ‰ΩøÁî®‰∏Ä‰∏™ÂçïÁã¨ÁöÑÁΩëÈ°µÈÄöËøá iframe ÂµåÂÖ•„ÄÇ&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÈÄöËøáÁ≥ªÁªüËÆøÈóÆ‰ª§ÁâåËÆøÈóÆÁÆ°ÁêÜ API„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ Cloudflare Turnstile Áî®Êà∑Ê†°È™å„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÁî®Êà∑ÁÆ°ÁêÜÔºåÊîØÊåÅ&lt;strong&gt;Â§öÁßçÁî®Êà∑ÁôªÂΩïÊ≥®ÂÜåÊñπÂºè&lt;/strong&gt;Ôºö &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ÈÇÆÁÆ±ÁôªÂΩïÊ≥®ÂÜåÔºàÊîØÊåÅÊ≥®ÂÜåÈÇÆÁÆ±ÁôΩÂêçÂçïÔºâ‰ª•ÂèäÈÄöËøáÈÇÆÁÆ±ËøõË°åÂØÜÁ†ÅÈáçÁΩÆ„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/settings/applications/new&#34;&gt;GitHub ÂºÄÊîæÊéàÊùÉ&lt;/a&gt;„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÊéàÊùÉÔºàÈúÄË¶ÅÈ¢ùÂ§ñÈÉ®ÁΩ≤ &lt;a href=&#34;https://github.com/songquanpeng/wechat-server&#34;&gt;WeChat Server&lt;/a&gt;Ôºâ„ÄÇ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;ÈÉ®ÁΩ≤&lt;/h2&gt; &#xA;&lt;h3&gt;Âü∫‰∫é Docker ËøõË°åÈÉ®ÁΩ≤&lt;/h3&gt; &#xA;&lt;p&gt;ÈÉ®ÁΩ≤ÂëΩ‰ª§Ôºö&lt;code&gt;docker run --name one-api -d --restart always -p 3000:3000 -e TZ=Asia/Shanghai -v /home/ubuntu/data/one-api:/data justsong/one-api&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;ÂÖ∂‰∏≠Ôºå&lt;code&gt;-p 3000:3000&lt;/code&gt; ‰∏≠ÁöÑÁ¨¨‰∏Ä‰∏™ &lt;code&gt;3000&lt;/code&gt; ÊòØÂÆø‰∏ªÊú∫ÁöÑÁ´ØÂè£ÔºåÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅËøõË°å‰øÆÊîπ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Êï∞ÊçÆÂ∞Ü‰ºö‰øùÂ≠òÂú®ÂÆø‰∏ªÊú∫ÁöÑ &lt;code&gt;/home/ubuntu/data/one-api&lt;/code&gt; ÁõÆÂΩïÔºåËØ∑Á°Æ‰øùËØ•ÁõÆÂΩïÂ≠òÂú®‰∏îÂÖ∑ÊúâÂÜôÂÖ•ÊùÉÈôêÔºåÊàñËÄÖÊõ¥Êîπ‰∏∫ÂêàÈÄÇÁöÑÁõÆÂΩï„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰∏äÈù¢ÁöÑÈïúÂÉèÊó†Ê≥ïÊãâÂèñÔºåÂèØ‰ª•Â∞ùËØï‰ΩøÁî® GitHub ÁöÑ Docker ÈïúÂÉèÔºåÂ∞Ü‰∏äÈù¢ÁöÑ &lt;code&gt;justsong/one-api&lt;/code&gt; ÊõøÊç¢‰∏∫ &lt;code&gt;ghcr.io/songquanpeng/one-api&lt;/code&gt; Âç≥ÂèØ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†ÁöÑÂπ∂ÂèëÈáèËæÉÂ§ßÔºå&lt;strong&gt;Âä°ÂøÖ&lt;/strong&gt;ËÆæÁΩÆ &lt;code&gt;SQL_DSN&lt;/code&gt;ÔºåËØ¶ËßÅ‰∏ãÈù¢&lt;a href=&#34;https://raw.githubusercontent.com/songquanpeng/one-api/main/#%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F&#34;&gt;ÁéØÂ¢ÉÂèòÈáè&lt;/a&gt;‰∏ÄËäÇ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Êõ¥Êñ∞ÂëΩ‰ª§Ôºö&lt;code&gt;docker run --rm -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower -cR&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Nginx ÁöÑÂèÇËÄÉÈÖçÁΩÆÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;server{&#xA;   server_name openai.justsong.cn;  # ËØ∑Ê†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰øÆÊîπ‰Ω†ÁöÑÂüüÂêç&#xA;   &#xA;   location / {&#xA;          client_max_body_size  64m;&#xA;          proxy_http_version 1.1;&#xA;          proxy_pass http://localhost:3000;  # ËØ∑Ê†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰øÆÊîπ‰Ω†ÁöÑÁ´ØÂè£&#xA;          proxy_set_header Host $host;&#xA;          proxy_set_header X-Forwarded-For $remote_addr;&#xA;          proxy_cache_bypass $http_upgrade;&#xA;          proxy_set_header Accept-Encoding gzip;&#xA;          proxy_read_timeout 300s;  # GPT-4 ÈúÄË¶ÅËæÉÈïøÁöÑË∂ÖÊó∂Êó∂Èó¥ÔºåËØ∑Ëá™Ë°åË∞ÉÊï¥&#xA;   }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;‰πãÂêé‰ΩøÁî® Let&#39;s Encrypt ÁöÑ certbot ÈÖçÁΩÆ HTTPSÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Ubuntu ÂÆâË£Ö certbotÔºö&#xA;sudo snap install --classic certbot&#xA;sudo ln -s /snap/bin/certbot /usr/bin/certbot&#xA;# ÁîüÊàêËØÅ‰π¶ &amp;amp; ‰øÆÊîπ Nginx ÈÖçÁΩÆ&#xA;sudo certbot --nginx&#xA;# Ê†πÊçÆÊåáÁ§∫ËøõË°åÊìç‰Ωú&#xA;# ÈáçÂêØ Nginx&#xA;sudo service nginx restart&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÂàùÂßãË¥¶Âè∑Áî®Êà∑Âêç‰∏∫ &lt;code&gt;root&lt;/code&gt;ÔºåÂØÜÁ†Å‰∏∫ &lt;code&gt;123456&lt;/code&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;ÊâãÂä®ÈÉ®ÁΩ≤&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;‰ªé &lt;a href=&#34;https://github.com/songquanpeng/one-api/releases/latest&#34;&gt;GitHub Releases&lt;/a&gt; ‰∏ãËΩΩÂèØÊâßË°åÊñá‰ª∂ÊàñËÄÖ‰ªéÊ∫êÁ†ÅÁºñËØëÔºö &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/songquanpeng/one-api.git&#xA;&#xA;# ÊûÑÂª∫ÂâçÁ´Ø&#xA;cd one-api/web&#xA;npm install&#xA;npm run build&#xA;&#xA;# ÊûÑÂª∫ÂêéÁ´Ø&#xA;cd ..&#xA;go mod download&#xA;go build -ldflags &#34;-s -w&#34; -o one-api&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;ËøêË°åÔºö &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;chmod u+x one-api&#xA;./one-api --port 3000 --log-dir ./logs&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;ËÆøÈóÆ &lt;a href=&#34;http://localhost:3000/&#34;&gt;http://localhost:3000/&lt;/a&gt; Âπ∂ÁôªÂΩï„ÄÇÂàùÂßãË¥¶Âè∑Áî®Êà∑Âêç‰∏∫ &lt;code&gt;root&lt;/code&gt;ÔºåÂØÜÁ†Å‰∏∫ &lt;code&gt;123456&lt;/code&gt;„ÄÇ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Êõ¥Âä†ËØ¶ÁªÜÁöÑÈÉ®ÁΩ≤ÊïôÁ®ã&lt;a href=&#34;https://iamazing.cn/page/how-to-deploy-a-website&#34;&gt;ÂèÇËßÅÊ≠§Â§Ñ&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Â§öÊú∫ÈÉ®ÁΩ≤&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ÊâÄÊúâÊúçÂä°Âô® &lt;code&gt;SESSION_SECRET&lt;/code&gt; ËÆæÁΩÆ‰∏ÄÊ†∑ÁöÑÂÄº„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÂøÖÈ°ªËÆæÁΩÆ &lt;code&gt;SQL_DSN&lt;/code&gt;Ôºå‰ΩøÁî® MySQL Êï∞ÊçÆÂ∫ìËÄåÈùû SQLiteÔºåÊâÄÊúâÊúçÂä°Âô®ËøûÊé•Âêå‰∏Ä‰∏™Êï∞ÊçÆÂ∫ì„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊâÄÊúâ‰ªéÊúçÂä°Âô®ÂøÖÈ°ªËÆæÁΩÆ &lt;code&gt;NODE_TYPE&lt;/code&gt; ‰∏∫ &lt;code&gt;slave&lt;/code&gt;Ôºå‰∏çËÆæÁΩÆÂàôÈªòËÆ§‰∏∫‰∏ªÊúçÂä°Âô®„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ËÆæÁΩÆ &lt;code&gt;SYNC_FREQUENCY&lt;/code&gt; ÂêéÊúçÂä°Âô®Â∞ÜÂÆöÊúü‰ªéÊï∞ÊçÆÂ∫ìÂêåÊ≠•ÈÖçÁΩÆÔºåÂú®‰ΩøÁî®ËøúÁ®ãÊï∞ÊçÆÂ∫ìÁöÑÊÉÖÂÜµ‰∏ãÔºåÊé®ËçêËÆæÁΩÆËØ•È°πÂπ∂ÂêØÁî® RedisÔºåÊó†ËÆ∫‰∏ª‰ªé„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;‰ªéÊúçÂä°Âô®ÂèØ‰ª•ÈÄâÊã©ËÆæÁΩÆ &lt;code&gt;FRONTEND_BASE_URL&lt;/code&gt;Ôºå‰ª•ÈáçÂÆöÂêëÈ°µÈù¢ËØ∑Ê±ÇÂà∞‰∏ªÊúçÂä°Âô®„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;‰ªéÊúçÂä°Âô®‰∏ä&lt;strong&gt;ÂàÜÂà´&lt;/strong&gt;Ë£ÖÂ•Ω RedisÔºåËÆæÁΩÆÂ•Ω &lt;code&gt;REDIS_CONN_STRING&lt;/code&gt;ÔºåËøôÊ†∑ÂèØ‰ª•ÂÅöÂà∞Âú®ÁºìÂ≠òÊú™ËøáÊúüÁöÑÊÉÖÂÜµ‰∏ãÊï∞ÊçÆÂ∫ìÈõ∂ËÆøÈóÆÔºåÂèØ‰ª•ÂáèÂ∞ëÂª∂Ëøü„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;Â¶ÇÊûú‰∏ªÊúçÂä°Âô®ËÆøÈóÆÊï∞ÊçÆÂ∫ìÂª∂Ëøü‰πüÊØîËæÉÈ´òÔºåÂàô‰πüÈúÄË¶ÅÂêØÁî® RedisÔºåÂπ∂ËÆæÁΩÆ &lt;code&gt;SYNC_FREQUENCY&lt;/code&gt;Ôºå‰ª•ÂÆöÊúü‰ªéÊï∞ÊçÆÂ∫ìÂêåÊ≠•ÈÖçÁΩÆ„ÄÇ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;ÁéØÂ¢ÉÂèòÈáèÁöÑÂÖ∑‰Ωì‰ΩøÁî®ÊñπÊ≥ïËØ¶ËßÅ&lt;a href=&#34;https://raw.githubusercontent.com/songquanpeng/one-api/main/#%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F&#34;&gt;Ê≠§Â§Ñ&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;ÂÆùÂ°îÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/h3&gt; &#xA;&lt;p&gt;ËØ¶ËßÅ &lt;a href=&#34;https://github.com/songquanpeng/one-api/issues/175&#34;&gt;#175&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Â¶ÇÊûúÈÉ®ÁΩ≤ÂêéËÆøÈóÆÂá∫Áé∞Á©∫ÁôΩÈ°µÈù¢ÔºåËØ¶ËßÅ &lt;a href=&#34;https://github.com/songquanpeng/one-api/issues/97&#34;&gt;#97&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;ÈÉ®ÁΩ≤Á¨¨‰∏âÊñπÊúçÂä°ÈÖçÂêà One API ‰ΩøÁî®&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Ê¨¢Ëøé PR Ê∑ªÂä†Êõ¥Â§öÁ§∫‰æã„ÄÇ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;ChatGPT Next Web&lt;/h4&gt; &#xA;&lt;p&gt;È°πÁõÆ‰∏ªÈ°µÔºö&lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web&#34;&gt;https://github.com/Yidadaa/ChatGPT-Next-Web&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --name chat-next-web -d -p 3001:3000 yidadaa/chatgpt-next-web&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ê≥®ÊÑè‰øÆÊîπÁ´ØÂè£Âè∑Ôºå‰πãÂêéÂú®È°µÈù¢‰∏äËÆæÁΩÆÊé•Âè£Âú∞ÂùÄÔºà‰æãÂ¶ÇÔºö&lt;a href=&#34;https://openai.justsong.cn/&#34;&gt;https://openai.justsong.cn/&lt;/a&gt; ÔºâÂíå API Key Âç≥ÂèØ„ÄÇ&lt;/p&gt; &#xA;&lt;h4&gt;ChatGPT Web&lt;/h4&gt; &#xA;&lt;p&gt;È°πÁõÆ‰∏ªÈ°µÔºö&lt;a href=&#34;https://github.com/Chanzhaoyu/chatgpt-web&#34;&gt;https://github.com/Chanzhaoyu/chatgpt-web&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --name chatgpt-web -d -p 3002:3002 -e OPENAI_API_BASE_URL=https://openai.justsong.cn -e OPENAI_API_KEY=sk-xxx chenzhaoyu94/chatgpt-web&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ê≥®ÊÑè‰øÆÊîπÁ´ØÂè£Âè∑„ÄÅ&lt;code&gt;OPENAI_API_BASE_URL&lt;/code&gt; Âíå &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;ÈÉ®ÁΩ≤Âà∞Á¨¨‰∏âÊñπÂπ≥Âè∞&lt;/h3&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;ÈÉ®ÁΩ≤Âà∞ Sealos &lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;div&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Sealos ÁöÑÊúçÂä°Âô®Âú®ÂõΩÂ§ñÔºå‰∏çÈúÄË¶ÅÈ¢ùÂ§ñÂ§ÑÁêÜÁΩëÁªúÈóÆÈ¢òÔºåÊîØÊåÅÈ´òÂπ∂Âèë &amp;amp; Âä®ÊÄÅ‰º∏Áº©„ÄÇ&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &#xA;  &lt;p&gt;ÁÇπÂáª‰ª•‰∏ãÊåâÈíÆ‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºàÈÉ®ÁΩ≤ÂêéËÆøÈóÆÂá∫Áé∞ 404 ËØ∑Á≠âÂæÖ 3~5 ÂàÜÈíüÔºâÔºö&lt;/p&gt; &#xA;  &lt;p&gt;&lt;a href=&#34;https://cloud.sealos.io/?openapp=system-fastdeploy?templateName=one-api&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg?sanitize=true&#34; alt=&#34;Deploy-on-Sealos.svg&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;ÈÉ®ÁΩ≤Âà∞ Zeabur&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;div&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Zeabur ÁöÑÊúçÂä°Âô®Âú®ÂõΩÂ§ñÔºåËá™Âä®Ëß£ÂÜ≥‰∫ÜÁΩëÁªúÁöÑÈóÆÈ¢òÔºåÂêåÊó∂ÂÖçË¥πÁöÑÈ¢ùÂ∫¶‰πüË∂≥Â§ü‰∏™‰∫∫‰ΩøÁî®„ÄÇ&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;È¶ñÂÖà fork ‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;ËøõÂÖ• &lt;a href=&#34;https://zeabur.com?referralCode=songquanpeng&#34;&gt;Zeabur&lt;/a&gt;ÔºåÁôªÂΩïÔºåËøõÂÖ•ÊéßÂà∂Âè∞„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Êñ∞Âª∫‰∏Ä‰∏™ ProjectÔºåÂú® Service -&amp;gt; Add Service ÈÄâÊã© MarketplaceÔºåÈÄâÊã© MySQLÔºåÂπ∂ËÆ∞‰∏ãËøûÊé•ÂèÇÊï∞ÔºàÁî®Êà∑Âêç„ÄÅÂØÜÁ†Å„ÄÅÂú∞ÂùÄ„ÄÅÁ´ØÂè£Ôºâ„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Â§çÂà∂ÈìæÊé•ÂèÇÊï∞ÔºåËøêË°å &lt;code&gt;create database `one-api` &lt;/code&gt; ÂàõÂª∫Êï∞ÊçÆÂ∫ì„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;ÁÑ∂ÂêéÂú® Service -&amp;gt; Add ServiceÔºåÈÄâÊã© GitÔºàÁ¨¨‰∏ÄÊ¨°‰ΩøÁî®ÈúÄË¶ÅÂÖàÊéàÊùÉÔºâÔºåÈÄâÊã©‰Ω† fork ÁöÑ‰ªìÂ∫ì„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Deploy ‰ºöËá™Âä®ÂºÄÂßãÔºåÂÖàÂèñÊ∂à„ÄÇËøõÂÖ•‰∏ãÊñπ VariableÔºåÊ∑ªÂä†‰∏Ä‰∏™ &lt;code&gt;PORT&lt;/code&gt;ÔºåÂÄº‰∏∫ &lt;code&gt;3000&lt;/code&gt;ÔºåÂÜçÊ∑ªÂä†‰∏Ä‰∏™ &lt;code&gt;SQL_DSN&lt;/code&gt;ÔºåÂÄº‰∏∫ &lt;code&gt;&amp;lt;username&amp;gt;:&amp;lt;password&amp;gt;@tcp(&amp;lt;addr&amp;gt;:&amp;lt;port&amp;gt;)/one-api&lt;/code&gt; ÔºåÁÑ∂Âêé‰øùÂ≠ò„ÄÇ Ê≥®ÊÑèÂ¶ÇÊûú‰∏çÂ°´ÂÜô &lt;code&gt;SQL_DSN&lt;/code&gt;ÔºåÊï∞ÊçÆÂ∞ÜÊó†Ê≥ïÊåÅ‰πÖÂåñÔºåÈáçÊñ∞ÈÉ®ÁΩ≤ÂêéÊï∞ÊçÆ‰ºö‰∏¢Â§±„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;ÈÄâÊã© Redeploy„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;ËøõÂÖ•‰∏ãÊñπ DomainsÔºåÈÄâÊã©‰∏Ä‰∏™ÂêàÈÄÇÁöÑÂüüÂêçÂâçÁºÄÔºåÂ¶Ç &#34;my-one-api&#34;ÔºåÊúÄÁªàÂüüÂêç‰∏∫ &#34;my-one-api.zeabur.app&#34;Ôºå‰πüÂèØ‰ª• CNAME Ëá™Â∑±ÁöÑÂüüÂêç„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Á≠âÂæÖÈÉ®ÁΩ≤ÂÆåÊàêÔºåÁÇπÂáªÁîüÊàêÁöÑÂüüÂêçËøõÂÖ• One API„ÄÇ&lt;/li&gt; &#xA;  &lt;/ol&gt; &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;ÈÖçÁΩÆ&lt;/h2&gt; &#xA;&lt;p&gt;Á≥ªÁªüÊú¨Ë∫´ÂºÄÁÆ±Âç≥Áî®„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;‰Ω†ÂèØ‰ª•ÈÄöËøáËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÊàñËÄÖÂëΩ‰ª§Ë°åÂèÇÊï∞ËøõË°åÈÖçÁΩÆ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Á≠âÂà∞Á≥ªÁªüÂêØÂä®ÂêéÔºå‰ΩøÁî® &lt;code&gt;root&lt;/code&gt; Áî®Êà∑ÁôªÂΩïÁ≥ªÁªüÂπ∂ÂÅöËøõ‰∏ÄÊ≠•ÁöÑÈÖçÁΩÆ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;ÔºöÂ¶ÇÊûú‰Ω†‰∏çÁü•ÈÅìÊüê‰∏™ÈÖçÁΩÆÈ°πÁöÑÂê´‰πâÔºåÂèØ‰ª•‰∏¥Êó∂Âà†ÊéâÂÄº‰ª•ÁúãÂà∞Ëøõ‰∏ÄÊ≠•ÁöÑÊèêÁ§∫ÊñáÂ≠ó„ÄÇ&lt;/p&gt; &#xA;&lt;h2&gt;‰ΩøÁî®ÊñπÊ≥ï&lt;/h2&gt; &#xA;&lt;p&gt;Âú®&lt;code&gt;Ê∏†ÈÅì&lt;/code&gt;È°µÈù¢‰∏≠Ê∑ªÂä†‰Ω†ÁöÑ API KeyÔºå‰πãÂêéÂú®&lt;code&gt;‰ª§Áâå&lt;/code&gt;È°µÈù¢‰∏≠Êñ∞Â¢ûËÆøÈóÆ‰ª§Áâå„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;‰πãÂêéÂ∞±ÂèØ‰ª•‰ΩøÁî®‰Ω†ÁöÑ‰ª§ÁâåËÆøÈóÆ One API ‰∫ÜÔºå‰ΩøÁî®ÊñπÂºè‰∏é &lt;a href=&#34;https://platform.openai.com/docs/api-reference/introduction&#34;&gt;OpenAI API&lt;/a&gt; ‰∏ÄËá¥„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;‰Ω†ÈúÄË¶ÅÂú®ÂêÑÁßçÁî®Âà∞ OpenAI API ÁöÑÂú∞ÊñπËÆæÁΩÆ API Base ‰∏∫‰Ω†ÁöÑ One API ÁöÑÈÉ®ÁΩ≤Âú∞ÂùÄÔºå‰æãÂ¶ÇÔºö&lt;code&gt;https://openai.justsong.cn&lt;/code&gt;ÔºåAPI Key Âàô‰∏∫‰Ω†Âú® One API ‰∏≠ÁîüÊàêÁöÑ‰ª§Áâå„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Ê≥®ÊÑèÔºåÂÖ∑‰ΩìÁöÑ API Base ÁöÑÊ†ºÂºèÂèñÂÜ≥‰∫é‰Ω†ÊâÄ‰ΩøÁî®ÁöÑÂÆ¢Êà∑Á´Ø„ÄÇ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR&#xA;    A(Áî®Êà∑)&#xA;    A ---&amp;gt;|ËØ∑Ê±Ç| B(One API)&#xA;    B --&amp;gt;|‰∏≠ÁªßËØ∑Ê±Ç| C(OpenAI)&#xA;    B --&amp;gt;|‰∏≠ÁªßËØ∑Ê±Ç| D(Azure)&#xA;    B --&amp;gt;|‰∏≠ÁªßËØ∑Ê±Ç| E(ÂÖ∂‰ªñ‰∏ãÊ∏∏Ê∏†ÈÅì)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÂèØ‰ª•ÈÄöËøáÂú®‰ª§ÁâåÂêéÈù¢Ê∑ªÂä†Ê∏†ÈÅì ID ÁöÑÊñπÂºèÊåáÂÆö‰ΩøÁî®Âì™‰∏Ä‰∏™Ê∏†ÈÅìÂ§ÑÁêÜÊú¨Ê¨°ËØ∑Ê±ÇÔºå‰æãÂ¶ÇÔºö&lt;code&gt;Authorization: Bearer ONE_API_KEY-CHANNEL_ID&lt;/code&gt;„ÄÇ Ê≥®ÊÑèÔºåÈúÄË¶ÅÊòØÁÆ°ÁêÜÂëòÁî®Êà∑ÂàõÂª∫ÁöÑ‰ª§ÁâåÊâçËÉΩÊåáÂÆöÊ∏†ÈÅì ID„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;‰∏çÂä†ÁöÑËØùÂ∞Ü‰ºö‰ΩøÁî®Ë¥üËΩΩÂùáË°°ÁöÑÊñπÂºè‰ΩøÁî®Â§ö‰∏™Ê∏†ÈÅì„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;ÁéØÂ¢ÉÂèòÈáè&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_CONN_STRING&lt;/code&gt;ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰ΩøÁî® Redis ‰Ωú‰∏∫ËØ∑Ê±ÇÈ¢ëÁéáÈôêÂà∂ÁöÑÂ≠òÂÇ®ÔºåËÄåÈùû‰ΩøÁî®ÂÜÖÂ≠òÂ≠òÂÇ®„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;REDIS_CONN_STRING=redis://default:redispw@localhost:49153&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SESSION_SECRET&lt;/code&gt;ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰ΩøÁî®Âõ∫ÂÆöÁöÑ‰ºöËØùÂØÜÈí•ÔºåËøôÊ†∑Á≥ªÁªüÈáçÊñ∞ÂêØÂä®ÂêéÂ∑≤ÁôªÂΩïÁî®Êà∑ÁöÑ cookie Â∞Ü‰æùÊóßÊúâÊïà„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;SESSION_SECRET=random_string&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SQL_DSN&lt;/code&gt;ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰ΩøÁî®ÊåáÂÆöÊï∞ÊçÆÂ∫ìËÄåÈùû SQLiteÔºåËØ∑‰ΩøÁî® MySQL Êàñ PostgreSQL„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;MySQLÔºö&lt;code&gt;SQL_DSN=root:123456@tcp(localhost:3306)/oneapi&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;PostgreSQLÔºö&lt;code&gt;SQL_DSN=postgres://postgres:123456@localhost:5432/oneapi&lt;/code&gt;ÔºàÈÄÇÈÖç‰∏≠ÔºåÊ¨¢ËøéÂèçÈ¶àÔºâ&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Ê≥®ÊÑèÈúÄË¶ÅÊèêÂâçÂª∫Á´ãÊï∞ÊçÆÂ∫ì &lt;code&gt;oneapi&lt;/code&gt;ÔºåÊó†ÈúÄÊâãÂä®Âª∫Ë°®ÔºåÁ®ãÂ∫èÂ∞ÜËá™Âä®Âª∫Ë°®„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Â¶ÇÊûú‰ΩøÁî®Êú¨Âú∞Êï∞ÊçÆÂ∫ìÔºöÈÉ®ÁΩ≤ÂëΩ‰ª§ÂèØÊ∑ªÂä† &lt;code&gt;--network=&#34;host&#34;&lt;/code&gt; ‰ª•‰ΩøÂæóÂÆπÂô®ÂÜÖÁöÑÁ®ãÂ∫èÂèØ‰ª•ËÆøÈóÆÂà∞ÂÆø‰∏ªÊú∫‰∏äÁöÑ MySQL„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Â¶ÇÊûú‰ΩøÁî®‰∫ëÊï∞ÊçÆÂ∫ìÔºöÂ¶ÇÊûú‰∫ëÊúçÂä°Âô®ÈúÄË¶ÅÈ™åËØÅË∫´‰ªΩÔºåÈúÄË¶ÅÂú®ËøûÊé•ÂèÇÊï∞‰∏≠Ê∑ªÂä† &lt;code&gt;?tls=skip-verify&lt;/code&gt;„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;ËØ∑Ê†πÊçÆ‰Ω†ÁöÑÊï∞ÊçÆÂ∫ìÈÖçÁΩÆ‰øÆÊîπ‰∏ãÂàóÂèÇÊï∞ÔºàÊàñËÄÖ‰øùÊåÅÈªòËÆ§ÂÄºÔºâÔºö &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;code&gt;SQL_MAX_IDLE_CONNS&lt;/code&gt;ÔºöÊúÄÂ§ßÁ©∫Èó≤ËøûÊé•Êï∞ÔºåÈªòËÆ§‰∏∫ &lt;code&gt;100&lt;/code&gt;„ÄÇ&lt;/li&gt; &#xA;     &lt;li&gt;&lt;code&gt;SQL_MAX_OPEN_CONNS&lt;/code&gt;ÔºöÊúÄÂ§ßÊâìÂºÄËøûÊé•Êï∞ÔºåÈªòËÆ§‰∏∫ &lt;code&gt;1000&lt;/code&gt;„ÄÇ &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;Â¶ÇÊûúÊä•Èîô &lt;code&gt;Error 1040: Too many connections&lt;/code&gt;ÔºåËØ∑ÈÄÇÂΩìÂáèÂ∞èËØ•ÂÄº„ÄÇ&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;code&gt;SQL_CONN_MAX_LIFETIME&lt;/code&gt;ÔºöËøûÊé•ÁöÑÊúÄÂ§ßÁîüÂëΩÂë®ÊúüÔºåÈªòËÆ§‰∏∫ &lt;code&gt;60&lt;/code&gt;ÔºåÂçï‰ΩçÂàÜÈíü„ÄÇ&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;FRONTEND_BASE_URL&lt;/code&gt;ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÈáçÂÆöÂêëÈ°µÈù¢ËØ∑Ê±ÇÂà∞ÊåáÂÆöÁöÑÂú∞ÂùÄÔºå‰ªÖÈôê‰ªéÊúçÂä°Âô®ËÆæÁΩÆ„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;FRONTEND_BASE_URL=https://openai.justsong.cn&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SYNC_FREQUENCY&lt;/code&gt;ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÂÆöÊúü‰∏éÊï∞ÊçÆÂ∫ìÂêåÊ≠•ÈÖçÁΩÆÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÊú™ËÆæÁΩÆÂàô‰∏çËøõË°åÂêåÊ≠•„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;SYNC_FREQUENCY=60&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;NODE_TYPE&lt;/code&gt;ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÊåáÂÆöËäÇÁÇπÁ±ªÂûãÔºåÂèØÈÄâÂÄº‰∏∫ &lt;code&gt;master&lt;/code&gt; Âíå &lt;code&gt;slave&lt;/code&gt;ÔºåÊú™ËÆæÁΩÆÂàôÈªòËÆ§‰∏∫ &lt;code&gt;master&lt;/code&gt;„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;NODE_TYPE=slave&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CHANNEL_UPDATE_FREQUENCY&lt;/code&gt;ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÂÆöÊúüÊõ¥Êñ∞Ê∏†ÈÅì‰ΩôÈ¢ùÔºåÂçï‰Ωç‰∏∫ÂàÜÈíüÔºåÊú™ËÆæÁΩÆÂàô‰∏çËøõË°åÊõ¥Êñ∞„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;CHANNEL_UPDATE_FREQUENCY=1440&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CHANNEL_TEST_FREQUENCY&lt;/code&gt;ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÂÆöÊúüÊ£ÄÊü•Ê∏†ÈÅìÔºåÂçï‰Ωç‰∏∫ÂàÜÈíüÔºåÊú™ËÆæÁΩÆÂàô‰∏çËøõË°åÊ£ÄÊü•„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;CHANNEL_TEST_FREQUENCY=1440&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;POLLING_INTERVAL&lt;/code&gt;ÔºöÊâπÈáèÊõ¥Êñ∞Ê∏†ÈÅì‰ΩôÈ¢ù‰ª•ÂèäÊµãËØïÂèØÁî®ÊÄßÊó∂ÁöÑËØ∑Ê±ÇÈó¥ÈöîÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÈªòËÆ§Êó†Èó¥Èöî„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;POLLING_INTERVAL=5&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;ÂëΩ‰ª§Ë°åÂèÇÊï∞&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;--port &amp;lt;port_number&amp;gt;&lt;/code&gt;: ÊåáÂÆöÊúçÂä°Âô®ÁõëÂê¨ÁöÑÁ´ØÂè£Âè∑ÔºåÈªòËÆ§‰∏∫ &lt;code&gt;3000&lt;/code&gt;„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;--port 3000&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--log-dir &amp;lt;log_dir&amp;gt;&lt;/code&gt;: ÊåáÂÆöÊó•ÂøóÊñá‰ª∂Â§πÔºåÂ¶ÇÊûúÊ≤°ÊúâËÆæÁΩÆÔºåÊó•ÂøóÂ∞Ü‰∏ç‰ºöË¢´‰øùÂ≠ò„ÄÇ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰æãÂ≠êÔºö&lt;code&gt;--log-dir ./logs&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--version&lt;/code&gt;: ÊâìÂç∞Á≥ªÁªüÁâàÊú¨Âè∑Âπ∂ÈÄÄÂá∫„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--help&lt;/code&gt;: Êü•ÁúãÂëΩ‰ª§ÁöÑ‰ΩøÁî®Â∏ÆÂä©ÂíåÂèÇÊï∞ËØ¥Êòé„ÄÇ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;ÊºîÁ§∫&lt;/h2&gt; &#xA;&lt;h3&gt;Âú®Á∫øÊºîÁ§∫&lt;/h3&gt; &#xA;&lt;p&gt;Ê≥®ÊÑèÔºåËØ•ÊºîÁ§∫Á´ô‰∏çÊèê‰æõÂØπÂ§ñÊúçÂä°Ôºö &lt;a href=&#34;https://openai.justsong.cn&#34;&gt;https://openai.justsong.cn&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Êà™ÂõæÂ±ïÁ§∫&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/39998050/233837954-ae6683aa-5c4f-429f-a949-6645a83c9490.png&#34; alt=&#34;channel&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/39998050/233837971-dab488b7-6d96-43af-b640-a168e8d1c9bf.png&#34; alt=&#34;token&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Â∏∏ËßÅÈóÆÈ¢ò&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;È¢ùÂ∫¶ÊòØ‰ªÄ‰πàÔºüÊÄé‰πàËÆ°ÁÆóÁöÑÔºüOne API ÁöÑÈ¢ùÂ∫¶ËÆ°ÁÆóÊúâÈóÆÈ¢òÔºü &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;È¢ùÂ∫¶ = ÂàÜÁªÑÂÄçÁéá * Ê®°ÂûãÂÄçÁéá * ÔºàÊèêÁ§∫ token Êï∞ + Ë°•ÂÖ® token Êï∞ * Ë°•ÂÖ®ÂÄçÁéáÔºâ&lt;/li&gt; &#xA;   &lt;li&gt;ÂÖ∂‰∏≠Ë°•ÂÖ®ÂÄçÁéáÂØπ‰∫é GPT3.5 Âõ∫ÂÆö‰∏∫ 1.33ÔºåGPT4 ‰∏∫ 2Ôºå‰∏éÂÆòÊñπ‰øùÊåÅ‰∏ÄËá¥„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Â¶ÇÊûúÊòØÈùûÊµÅÊ®°ÂºèÔºåÂÆòÊñπÊé•Âè£‰ºöËøîÂõûÊ∂àËÄóÁöÑÊÄª tokenÔºå‰ΩÜÊòØ‰Ω†Ë¶ÅÊ≥®ÊÑèÊèêÁ§∫ÂíåË°•ÂÖ®ÁöÑÊ∂àËÄóÂÄçÁéá‰∏ç‰∏ÄÊ†∑„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Ê≥®ÊÑèÔºåOne API ÁöÑÈªòËÆ§ÂÄçÁéáÂ∞±ÊòØÂÆòÊñπÂÄçÁéáÔºåÊòØÂ∑≤ÁªèË∞ÉÊï¥ËøáÁöÑ„ÄÇ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Ë¥¶Êà∑È¢ùÂ∫¶Ë∂≥Â§ü‰∏∫‰ªÄ‰πàÊèêÁ§∫È¢ùÂ∫¶‰∏çË∂≥Ôºü &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ËØ∑Ê£ÄÊü•‰Ω†ÁöÑ‰ª§ÁâåÈ¢ùÂ∫¶ÊòØÂê¶Ë∂≥Â§üÔºåËøô‰∏™ÂíåË¥¶Êà∑È¢ùÂ∫¶ÊòØÂàÜÂºÄÁöÑ„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;‰ª§ÁâåÈ¢ùÂ∫¶‰ªÖ‰æõÁî®Êà∑ËÆæÁΩÆÊúÄÂ§ß‰ΩøÁî®ÈáèÔºåÁî®Êà∑ÂèØËá™Áî±ËÆæÁΩÆ„ÄÇ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ÊèêÁ§∫Êó†ÂèØÁî®Ê∏†ÈÅìÔºü &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ËØ∑Ê£ÄÊü•ÁöÑÁî®Êà∑ÂàÜÁªÑÂíåÊ∏†ÈÅìÂàÜÁªÑËÆæÁΩÆ„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;‰ª•ÂèäÊ∏†ÈÅìÁöÑÊ®°ÂûãËÆæÁΩÆ„ÄÇ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Ê∏†ÈÅìÊµãËØïÊä•ÈîôÔºö&lt;code&gt;invalid character &#39;&amp;lt;&#39; looking for beginning of value&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ËøôÊòØÂõ†‰∏∫ËøîÂõûÂÄº‰∏çÊòØÂêàÊ≥ïÁöÑ JSONÔºåËÄåÊòØ‰∏Ä‰∏™ HTML È°µÈù¢„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Â§ßÊ¶ÇÁéáÊòØ‰Ω†ÁöÑÈÉ®ÁΩ≤Á´ôÁöÑ IP Êàñ‰ª£ÁêÜÁöÑËäÇÁÇπË¢´ CloudFlare Â∞ÅÁ¶Å‰∫Ü„ÄÇ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ChatGPT Next Web Êä•ÈîôÔºö&lt;code&gt;Failed to fetch&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ÈÉ®ÁΩ≤ÁöÑÊó∂ÂÄô‰∏çË¶ÅËÆæÁΩÆ &lt;code&gt;BASE_URL&lt;/code&gt;„ÄÇ&lt;/li&gt; &#xA;   &lt;li&gt;Ê£ÄÊü•‰Ω†ÁöÑÊé•Âè£Âú∞ÂùÄÂíå API Key ÊúâÊ≤°ÊúâÂ°´ÂØπ„ÄÇ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Êä•ÈîôÔºö&lt;code&gt;ÂΩìÂâçÂàÜÁªÑË¥üËΩΩÂ∑≤È•±ÂíåÔºåËØ∑Á®çÂêéÂÜçËØï&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;‰∏äÊ∏∏ÈÄöÈÅì 429 ‰∫Ü„ÄÇ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Áõ∏ÂÖ≥È°πÁõÆ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/labring/FastGPT&#34;&gt;FastGPT&lt;/a&gt;: Âü∫‰∫é LLM Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÁü•ËØÜÂ∫ìÈóÆÁ≠îÁ≥ªÁªü&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web&#34;&gt;ChatGPT Next Web&lt;/a&gt;: ‰∏ÄÈîÆÊã•Êúâ‰Ω†Ëá™Â∑±ÁöÑË∑®Âπ≥Âè∞ ChatGPT Â∫îÁî®&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Ê≥®ÊÑè&lt;/h2&gt; &#xA;&lt;p&gt;Êú¨È°πÁõÆ‰ΩøÁî® MIT ÂçèËÆÆËøõË°åÂºÄÊ∫êÔºå&lt;strong&gt;Âú®Ê≠§Âü∫Á°Ä‰∏ä&lt;/strong&gt;ÔºåÂøÖÈ°ªÂú®È°µÈù¢Â∫ïÈÉ®‰øùÁïôÁΩ≤Âêç‰ª•ÂèäÊåáÂêëÊú¨È°πÁõÆÁöÑÈìæÊé•„ÄÇÂ¶ÇÊûú‰∏çÊÉ≥‰øùÁïôÁΩ≤ÂêçÔºåÂøÖÈ°ªÈ¶ñÂÖàËé∑ÂæóÊéàÊùÉ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ÂêåÊ†∑ÈÄÇÁî®‰∫éÂü∫‰∫éÊú¨È°πÁõÆÁöÑ‰∫åÂºÄÈ°πÁõÆ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;‰æùÊçÆ MIT ÂçèËÆÆÔºå‰ΩøÁî®ËÄÖÈúÄËá™Ë°åÊâøÊãÖ‰ΩøÁî®Êú¨È°πÁõÆÁöÑÈ£éÈô©‰∏éË¥£‰ªªÔºåÊú¨ÂºÄÊ∫êÈ°πÁõÆÂºÄÂèëËÄÖ‰∏éÊ≠§Êó†ÂÖ≥„ÄÇ&lt;/p&gt;</summary>
  </entry>
</feed>