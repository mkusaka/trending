<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-15T01:41:17Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>arc53/DocsGPT</title>
    <updated>2023-10-15T01:41:17Z</updated>
    <id>tag:github.com,2023-10-15:/arc53/DocsGPT</id>
    <link href="https://github.com/arc53/DocsGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GPT-powered chat for documentation, chat with your documents&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; DocsGPT ü¶ñ &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;strong&gt;Open-Source Documentation Assistant&lt;/strong&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;strong&gt;&lt;a href=&#34;https://docsgpt.arc53.com/&#34;&gt;DocsGPT&lt;/a&gt;&lt;/strong&gt; is a cutting-edge open-source solution that streamlines the process of finding information in project documentation. With its integration of the powerful &lt;strong&gt;GPT&lt;/strong&gt; models, developers can easily ask questions about a project and receive accurate answers. &lt;/p&gt;&#xA;&lt;p&gt;Say goodbye to time-consuming manual searches, and let &lt;strong&gt;&lt;a href=&#34;https://docsgpt.arc53.com/&#34;&gt;DocsGPT&lt;/a&gt;&lt;/strong&gt; help you quickly find the information you need. Try it out and see how it revolutionizes your project documentation experience. Contribute to its development and be a part of the future of AI-powered assistance.&lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/arc53/DocsGPT&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/arc53/docsgpt?style=social&#34; alt=&#34;example1&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/arc53/DocsGPT&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/arc53/docsgpt?style=social&#34; alt=&#34;example2&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/arc53/DocsGPT/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/arc53/docsgpt&#34; alt=&#34;example3&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/n5BX8dh8rU&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1070046503302877216&#34; alt=&#34;example3&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Production Support / Help for companies:&lt;/h3&gt; &#xA;&lt;p&gt;We&#39;re eager to provide personalized assistance when deploying your DocsGPT to a live environment.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cal.com/arc53/docsgpt-demo-b2b&#34;&gt;Book Demo üëã&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;mailto:contact@arc53.com?subject=DocsGPT%20support%2Fsolutions&#34;&gt;Send Email ‚úâÔ∏è&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/arc53/DocsGPT/raw/main/HACKTOBERFEST.md&#34;&gt;üéâ Join the Hacktoberfest with DocsGPT and Earn a Free T-shirt! üéâ&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://d3dg1063dc54p9.cloudfront.net/videos/demov3.gif&#34; alt=&#34;video-example-of-docs-gpt&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;You can find our roadmap &lt;a href=&#34;https://github.com/orgs/arc53/projects/2&#34;&gt;here&lt;/a&gt;. Please don&#39;t hesitate to contribute or create issues, it helps us improve DocsGPT!&lt;/p&gt; &#xA;&lt;h2&gt;Our Open-Source models optimized for DocsGPT:&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Base Model&lt;/th&gt; &#xA;   &lt;th&gt;Requirements (or similar)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/Arc53/docsgpt-7b-falcon&#34;&gt;Docsgpt-7b-falcon&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Falcon-7b&lt;/td&gt; &#xA;   &lt;td&gt;1xA10G gpu&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/Arc53/docsgpt-14b&#34;&gt;Docsgpt-14b&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;llama-2-14b&lt;/td&gt; &#xA;   &lt;td&gt;2xA10 gpu&#39;s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/Arc53/docsgpt-40b-falcon&#34;&gt;Docsgpt-40b-falcon&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;falcon-40b&lt;/td&gt; &#xA;   &lt;td&gt;8xA10G gpu&#39;s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;If you don&#39;t have enough resources to run it, you can use bitsnbytes to quantize.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/17906039/220427472-2644cff4-7666-46a5-819f-fc4a521f63c7.png&#34; alt=&#34;Group 9&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Useful links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;üîçüî• &lt;a href=&#34;https://docsgpt.arc53.com/&#34;&gt;Live preview&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üí¨üéâ&lt;a href=&#34;https://discord.gg/n5BX8dh8rU&#34;&gt;Join our Discord&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üìöüòé &lt;a href=&#34;https://docs.docsgpt.co.uk/&#34;&gt;Guides&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üë©‚Äçüíªüë®‚Äçüíª &lt;a href=&#34;https://github.com/arc53/DocsGPT/raw/main/CONTRIBUTING.md&#34;&gt;Interested in contributing?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üóÇÔ∏èüöÄ &lt;a href=&#34;https://docs.docsgpt.co.uk/Guides/How-to-train-on-other-documentation&#34;&gt;How to use any other documentation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üè†üîê &lt;a href=&#34;https://docs.docsgpt.co.uk/Guides/How-to-use-different-LLM&#34;&gt;How to host it locally (so all data will stay on-premises)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Project structure&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Application - Flask app (main application).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Extensions - Chrome extension.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Scripts - Script that creates similarity search index for other libraries.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Frontend - Frontend uses Vite and React.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;QuickStart&lt;/h2&gt; &#xA;&lt;p&gt;Note: Make sure you have Docker installed&lt;/p&gt; &#xA;&lt;p&gt;On Mac OS or Linux, write:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./setup.sh&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;It will install all the dependencies and allow you to download the local model or use OpenAI.&lt;/p&gt; &#xA;&lt;p&gt;Otherwise, refer to this Guide:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download and open this repository with &lt;code&gt;git clone https://github.com/arc53/DocsGPT.git&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in your root directory and set the env variable &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; with your &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI API key&lt;/a&gt; and &lt;code&gt;VITE_API_STREAMING&lt;/code&gt; to true or false, depending on if you want streaming answers or not. It should look like this inside:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;API_KEY=Yourkey&#xA;VITE_API_STREAMING=true&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;See optional environment variables in the &lt;a href=&#34;https://github.com/arc53/DocsGPT/raw/main/.env-template&#34;&gt;/.env-template&lt;/a&gt; and &lt;a href=&#34;https://github.com/arc53/DocsGPT/raw/main/application/.env_sample&#34;&gt;/application/.env_sample&lt;/a&gt; files.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;a href=&#34;https://github.com/arc53/DocsGPT/raw/main/run-with-docker-compose.sh&#34;&gt;./run-with-docker-compose.sh&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to &lt;a href=&#34;http://localhost:5173/&#34;&gt;http://localhost:5173/&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;To stop, just run &lt;code&gt;Ctrl + C&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Development environments&lt;/h2&gt; &#xA;&lt;h3&gt;Spin up mongo and redis&lt;/h3&gt; &#xA;&lt;p&gt;For development, only two containers are used from &lt;a href=&#34;https://github.com/arc53/DocsGPT/raw/main/docker-compose.yaml&#34;&gt;docker-compose.yaml&lt;/a&gt; (by deleting all services except for Redis and Mongo). See file &lt;a href=&#34;https://raw.githubusercontent.com/arc53/DocsGPT/main/docker-compose-dev.yaml&#34;&gt;docker-compose-dev.yaml&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker compose -f docker-compose-dev.yaml build&#xA;docker compose -f docker-compose-dev.yaml up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run the backend&lt;/h3&gt; &#xA;&lt;p&gt;Make sure you have Python 3.10 or 3.11 installed.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Export required environment variables or prepare a &lt;code&gt;.env&lt;/code&gt; file in the &lt;code&gt;/application&lt;/code&gt; folder: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Copy &lt;a href=&#34;https://github.com/arc53/DocsGPT/raw/main/application/.env_sample&#34;&gt;.env_sample&lt;/a&gt; and create &lt;code&gt;.env&lt;/code&gt; with your OpenAI API token for the &lt;code&gt;API_KEY&lt;/code&gt; and &lt;code&gt;EMBEDDINGS_KEY&lt;/code&gt; fields.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;(check out &lt;a href=&#34;https://raw.githubusercontent.com/arc53/DocsGPT/main/application/core/settings.py&#34;&gt;&lt;code&gt;application/core/settings.py&lt;/code&gt;&lt;/a&gt; if you want to see more config options.)&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;(optional) Create a Python virtual environment: You can follow the &lt;a href=&#34;https://docs.python.org/3/tutorial/venv.html&#34;&gt;Python official documentation&lt;/a&gt; for virtual environments.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;a) On Mac OS and Linux&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;python -m venv venv&#xA;. venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;b) On Windows&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;python -m venv venv&#xA; venv/Scripts/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Change to the &lt;code&gt;application/&lt;/code&gt; subdir by the command &lt;code&gt;cd application/&lt;/code&gt; and install dependencies for the backend:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Run the app using &lt;code&gt;flask run --host=0.0.0.0 --port=7091&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Start worker with &lt;code&gt;celery -A application.app.celery worker -l INFO&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Start frontend&lt;/h3&gt; &#xA;&lt;p&gt;Make sure you have Node version 16 or higher.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Navigate to the &lt;a href=&#34;https://github.com/arc53/DocsGPT/tree/main/frontend&#34;&gt;/frontend&lt;/a&gt; folder.&lt;/li&gt; &#xA; &lt;li&gt;Install required packages &lt;code&gt;husky&lt;/code&gt; and &lt;code&gt;vite&lt;/code&gt; (ignore if installed).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;npm install husky -g&#xA;npm install vite -g&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install dependencies by running &lt;code&gt;npm install --include=dev&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run the app using &lt;code&gt;npm run dev&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/arc53/DocsGPT/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; file for information about how to get involved. We welcome issues, questions, and pull requests.&lt;/p&gt; &#xA;&lt;h2&gt;Code Of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;We as members, contributors, and leaders, pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/arc53/DocsGPT/main/CODE_OF_CONDUCT.md&#34;&gt;CODE_OF_CONDUCT.md&lt;/a&gt; file for more information about contributing.&lt;/p&gt; &#xA;&lt;h2&gt;Many Thanks To Our Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://raw.githubusercontent.com/arc53/DocsGPT/main/%5Bhttps://github.com/arc53/DocsGPT/graphs/contributors%5D(https://docsgpt.arc53.com/)&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=arc53/DocsGPT&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The source code license is &lt;a href=&#34;https://opensource.org/license/mit/&#34;&gt;MIT&lt;/a&gt;, as described in the &lt;a href=&#34;https://raw.githubusercontent.com/arc53/DocsGPT/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;Built with &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;ü¶úÔ∏èüîó LangChain&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>usebruno/bruno</title>
    <updated>2023-10-15T01:41:17Z</updated>
    <id>tag:github.com,2023-10-15:/usebruno/bruno</id>
    <link href="https://github.com/usebruno/bruno" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Opensource IDE For Exploring and Testing Api&#39;s (lightweight alternative to postman/insomnia)&lt;/p&gt;&lt;hr&gt;&lt;br&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/usebruno/bruno/main/assets/images/logo-transparent.png&#34; width=&#34;80&#34;&gt; &#xA;&lt;h3&gt;Bruno - Opensource IDE for exploring and testing APIs.&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://badge.fury.io/gh/usebruno%bruno&#34;&gt;&lt;img src=&#34;https://badge.fury.io/gh/usebruno%2Fbruno.svg?sanitize=true&#34; alt=&#34;GitHub version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/usebruno/bruno/workflows/unit-tests.yml&#34;&gt;&lt;img src=&#34;https://github.com/usebruno/bruno/actions/workflows/unit-tests.yml/badge.svg?branch=main&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/usebruno/bruno/pulse&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/m/usebruno/bruno&#34; alt=&#34;Commit Activity&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/use_bruno&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/use_bruno?style=social&amp;amp;logo=x&#34; alt=&#34;X&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.usebruno.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Website-Visit-blue&#34; alt=&#34;Website&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.usebruno.com/downloads&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Download-Latest-brightgreen&#34; alt=&#34;Download&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;English&lt;/strong&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/usebruno/bruno/main/readme_ru.md&#34;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Bruno is a new and innovative API client, aimed at revolutionizing the status quo represented by Postman and similar tools out there.&lt;/p&gt; &#xA;&lt;p&gt;Bruno stores your collections directly in a folder on your filesystem. We use a plain text markup language, Bru, to save information about API requests.&lt;/p&gt; &#xA;&lt;p&gt;You can use git or any version control of your choice to collaborate over your API collections.&lt;/p&gt; &#xA;&lt;p&gt;Bruno is offline-only. There are no plans to add cloud-sync to Bruno, ever. We value your data privacy and believe it should stay on your device. Read our long-term vision &lt;a href=&#34;https://github.com/usebruno/bruno/discussions/269&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/usebruno/bruno/main/assets/images/landing-2.png&#34; alt=&#34;bruno&#34;&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Run across multiple platforms üñ•Ô∏è&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/usebruno/bruno/main/assets/images/run-anywhere.png&#34; alt=&#34;bruno&#34;&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Collaborate via Git üë©‚Äçüíªüßë‚Äçüíª&lt;/h3&gt; &#xA;&lt;p&gt;Or any version control system of your choice&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/usebruno/bruno/main/assets/images/version-control.png&#34; alt=&#34;bruno&#34;&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Important Links üìå&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/usebruno/bruno/discussions/269&#34;&gt;Our Long Term Vision&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/usebruno/bruno/discussions/384&#34;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.usebruno.com&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.usebruno.com&#34;&gt;Website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.usebruno.com/downloads&#34;&gt;Download&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Showcase üé•&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/usebruno/bruno/discussions/343&#34;&gt;Testimonials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/usebruno/bruno/discussions/386&#34;&gt;Knowledge Hub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/usebruno/bruno/discussions/385&#34;&gt;Scriptmania&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Support ‚ù§Ô∏è&lt;/h3&gt; &#xA;&lt;p&gt;Woof! If you like project, hit that ‚≠ê button !!&lt;/p&gt; &#xA;&lt;h3&gt;Share Testimonials üì£&lt;/h3&gt; &#xA;&lt;p&gt;If Bruno has helped you at work and your teams, please don&#39;t forget to share your &lt;a href=&#34;https://github.com/usebruno/bruno/discussions/343&#34;&gt;testimonials on our github discussion&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Contribute üë©‚Äçüíªüßë‚Äçüíª&lt;/h3&gt; &#xA;&lt;p&gt;I am happy that you are looking to improve bruno. Please checkout the &lt;a href=&#34;https://raw.githubusercontent.com/usebruno/bruno/main/contributing.md&#34;&gt;contributing guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Even if you are not able to make contributions via code, please don&#39;t hesitate to file bugs and feature requests that needs to be implemented to solve your use case.&lt;/p&gt; &#xA;&lt;h3&gt;Authors&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/usebruno/bruno/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=usebruno/bruno&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Stay in touch üåê&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/use_bruno&#34;&gt;Twitter&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://www.usebruno.com&#34;&gt;Website&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://discord.com/invite/KgcZUncpjq&#34;&gt;Discord&lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/company/usebruno&#34;&gt;LinkedIn&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;License üìÑ&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/usebruno/bruno/main/license.md&#34;&gt;MIT&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>openai/openai-python</title>
    <updated>2023-10-15T01:41:17Z</updated>
    <id>tag:github.com,2023-10-15:/openai/openai-python</id>
    <link href="https://github.com/openai/openai-python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The official Python library for the OpenAI API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenAI Python Library&lt;/h1&gt; &#xA;&lt;p&gt;The OpenAI Python library provides convenient access to the OpenAI API from applications written in the Python language. It includes a pre-defined set of classes for API resources that initialize themselves dynamically from API responses which makes it compatible with a wide range of versions of the OpenAI API.&lt;/p&gt; &#xA;&lt;p&gt;You can find usage examples for the OpenAI Python library in our &lt;a href=&#34;https://platform.openai.com/docs/api-reference?lang=python&#34;&gt;API reference&lt;/a&gt; and the &lt;a href=&#34;https://github.com/openai/openai-cookbook/&#34;&gt;OpenAI Cookbook&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Beta Release&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;br&gt; We&#39;re preparing to release version 1.0 of the OpenAI Python library.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;This new version will be a major release and will include breaking changes. We&#39;re releasing this beta version to give you a chance to try out the new features and provide feedback before the official release. You can install the beta version with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install --pre openai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And follow along with the &lt;a href=&#34;https://github.com/openai/openai-python/discussions/631&#34;&gt;beta release notes&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To start, ensure you have Python 3.7.1 or newer. If you just want to use the package, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install --upgrade openai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After you have installed the package, import it at the top of a file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install this package from source to make modifications to it, run the following command from the root of the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Optional dependencies&lt;/h3&gt; &#xA;&lt;p&gt;Install dependencies for &lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-python/main/openai/embeddings_utils.py&#34;&gt;&lt;code&gt;openai.embeddings_utils&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install openai[embeddings]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install support for &lt;a href=&#34;https://wandb.me/openai-docs&#34;&gt;Weights &amp;amp; Biases&lt;/a&gt; which can be used for fine-tuning:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install openai[wandb]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Data libraries like &lt;code&gt;numpy&lt;/code&gt; and &lt;code&gt;pandas&lt;/code&gt; are not installed by default due to their size. They‚Äôre needed for some functionality of this library, but generally not for talking to the API. If you encounter a &lt;code&gt;MissingDependencyError&lt;/code&gt;, install them with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install openai[datalib]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;The library needs to be configured with your OpenAI account&#39;s private API key which is available on our &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;developer platform&lt;/a&gt;. Either set it as the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; environment variable before using the library:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export OPENAI_API_KEY=&#39;sk-...&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or set &lt;code&gt;openai.api_key&lt;/code&gt; to its value:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;openai.api_key = &#34;sk-...&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Examples of how to use this library to accomplish various tasks can be found in the &lt;a href=&#34;https://github.com/openai/openai-cookbook/&#34;&gt;OpenAI Cookbook&lt;/a&gt;. It contains code examples for: classification using fine-tuning, clustering, code search, customizing embeddings, question answering from a corpus of documents. recommendations, visualization of embeddings, and more.&lt;/p&gt; &#xA;&lt;p&gt;Most endpoints support a &lt;code&gt;request_timeout&lt;/code&gt; param. This param takes a &lt;code&gt;Union[float, Tuple[float, float]]&lt;/code&gt; and will raise an &lt;code&gt;openai.error.Timeout&lt;/code&gt; error if the request exceeds that time in seconds (See: &lt;a href=&#34;https://requests.readthedocs.io/en/latest/user/quickstart/#timeouts&#34;&gt;https://requests.readthedocs.io/en/latest/user/quickstart/#timeouts&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;Chat completions&lt;/h3&gt; &#xA;&lt;p&gt;Chat models such as &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; and &lt;code&gt;gpt-4&lt;/code&gt; can be called using the &lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat/create&#34;&gt;chat completions endpoint&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;completion = openai.ChatCompletion.create(model=&#34;gpt-3.5-turbo&#34;, messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Hello world&#34;}])&#xA;print(completion.choices[0].message.content)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can learn more in our &lt;a href=&#34;https://platform.openai.com/docs/guides/gpt/chat-completions-api&#34;&gt;chat completions guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Completions&lt;/h3&gt; &#xA;&lt;p&gt;Text models such as &lt;code&gt;babbage-002&lt;/code&gt; or &lt;code&gt;davinci-002&lt;/code&gt; (and our &lt;a href=&#34;https://platform.openai.com/docs/deprecations/deprecation-history&#34;&gt;legacy completions models&lt;/a&gt;) can be called using the completions endpoint.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;completion = openai.Completion.create(model=&#34;davinci-002&#34;, prompt=&#34;Hello world&#34;)&#xA;print(completion.choices[0].text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can learn more in our &lt;a href=&#34;https://platform.openai.com/docs/guides/gpt/completions-api&#34;&gt;completions guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Embeddings&lt;/h3&gt; &#xA;&lt;p&gt;Embeddings are designed to measure the similarity or relevance between text strings. To get an embedding for a text string, you can use following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;text_string = &#34;sample text&#34;&#xA;&#xA;model_id = &#34;text-embedding-ada-002&#34;&#xA;&#xA;embedding = openai.Embedding.create(input=text_string, model=model_id)[&#39;data&#39;][0][&#39;embedding&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can learn more in our &lt;a href=&#34;https://platform.openai.com/docs/guides/embeddings/embeddings&#34;&gt;embeddings guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Fine-tuning&lt;/h3&gt; &#xA;&lt;p&gt;Fine-tuning a model on training data can both improve the results (by giving the model more examples to learn from) and lower the cost/latency of API calls by reducing the need to include training examples in prompts.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create a fine-tuning job with an already uploaded file&#xA;openai.FineTuningJob.create(training_file=&#34;file-abc123&#34;, model=&#34;gpt-3.5-turbo&#34;)&#xA;&#xA;# List 10 fine-tuning jobs&#xA;openai.FineTuningJob.list(limit=10)&#xA;&#xA;# Retrieve the state of a fine-tune&#xA;openai.FineTuningJob.retrieve(&#34;ft-abc123&#34;)&#xA;&#xA;# Cancel a job&#xA;openai.FineTuningJob.cancel(&#34;ft-abc123&#34;)&#xA;&#xA;# List up to 10 events from a fine-tuning job&#xA;openai.FineTuningJob.list_events(id=&#34;ft-abc123&#34;, limit=10)&#xA;&#xA;# Delete a fine-tuned model (must be an owner of the org the model was created in)&#xA;openai.Model.delete(&#34;ft:gpt-3.5-turbo:acemeco:suffix:abc123&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can learn more in our &lt;a href=&#34;https://platform.openai.com/docs/guides/fine-tuning&#34;&gt;fine-tuning guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To log the training results from fine-tuning to Weights &amp;amp; Biases use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;openai wandb sync&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information, read the &lt;a href=&#34;https://docs.wandb.ai/guides/integrations/openai&#34;&gt;wandb documentation&lt;/a&gt; on Weights &amp;amp; Biases.&lt;/p&gt; &#xA;&lt;h3&gt;Moderation&lt;/h3&gt; &#xA;&lt;p&gt;OpenAI provides a free Moderation endpoint that can be used to check whether content complies with the OpenAI &lt;a href=&#34;https://platform.openai.com/docs/usage-policies&#34;&gt;content policy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;moderation_resp = openai.Moderation.create(input=&#34;Here is some perfectly innocuous text that follows all OpenAI content policies.&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can learn more in our &lt;a href=&#34;https://platform.openai.com/docs/guides/moderation&#34;&gt;moderation guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Image generation (DALL¬∑E)&lt;/h3&gt; &#xA;&lt;p&gt;DALL¬∑E is a generative image model that can create new images based on a prompt.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;image_resp = openai.Image.create(prompt=&#34;two dogs playing chess, oil painting&#34;, n=4, size=&#34;512x512&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can learn more in our &lt;a href=&#34;https://platform.openai.com/docs/guides/images&#34;&gt;image generation guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Audio (Whisper)&lt;/h3&gt; &#xA;&lt;p&gt;The speech to text API provides two endpoints, transcriptions and translations, based on our state-of-the-art &lt;a href=&#34;https://github.com/openai/whisper&#34;&gt;open source large-v2 Whisper model&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f = open(&#34;path/to/file.mp3&#34;, &#34;rb&#34;)&#xA;transcript = openai.Audio.transcribe(&#34;whisper-1&#34;, f)&#xA;&#xA;transcript = openai.Audio.translate(&#34;whisper-1&#34;, f)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can learn more in our &lt;a href=&#34;https://platform.openai.com/docs/guides/speech-to-text&#34;&gt;speech to text guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Async API&lt;/h3&gt; &#xA;&lt;p&gt;Async support is available in the API by prepending &lt;code&gt;a&lt;/code&gt; to a network-bound method:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;async def create_chat_completion():&#xA;    chat_completion_resp = await openai.ChatCompletion.acreate(model=&#34;gpt-3.5-turbo&#34;, messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Hello world&#34;}])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To make async requests more efficient, you can pass in your own &lt;code&gt;aiohttp.ClientSession&lt;/code&gt;, but you must manually close the client session at the end of your program/event loop:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from aiohttp import ClientSession&#xA;openai.aiosession.set(ClientSession())&#xA;&#xA;# At the end of your program, close the http session&#xA;await openai.aiosession.get().close()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Command-line interface&lt;/h3&gt; &#xA;&lt;p&gt;This library additionally provides an &lt;code&gt;openai&lt;/code&gt; command-line utility which makes it easy to interact with the API from your terminal. Run &lt;code&gt;openai api -h&lt;/code&gt; for usage.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# list models&#xA;openai api models.list&#xA;&#xA;# create a chat completion (gpt-3.5-turbo, gpt-4, etc.)&#xA;openai api chat_completions.create -m gpt-3.5-turbo -g user &#34;Hello world&#34;&#xA;&#xA;# create a completion (text-davinci-003, text-davinci-002, ada, babbage, curie, davinci, etc.)&#xA;openai api completions.create -m ada -p &#34;Hello world&#34;&#xA;&#xA;# generate images via DALL¬∑E API&#xA;openai api image.create -p &#34;two dogs playing chess, cartoon&#34; -n 1&#xA;&#xA;# using openai through a proxy&#xA;openai --proxy=http://proxy.com api models.list&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Microsoft Azure Endpoints&lt;/h3&gt; &#xA;&lt;p&gt;In order to use the library with Microsoft Azure endpoints, you need to set the &lt;code&gt;api_type&lt;/code&gt;, &lt;code&gt;api_base&lt;/code&gt; and &lt;code&gt;api_version&lt;/code&gt; in addition to the &lt;code&gt;api_key&lt;/code&gt;. The &lt;code&gt;api_type&lt;/code&gt; must be set to &#39;azure&#39; and the others correspond to the properties of your endpoint. In addition, the deployment name must be passed as the &lt;code&gt;deployment_id&lt;/code&gt; parameter.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;openai.api_type = &#34;azure&#34;&#xA;openai.api_key = &#34;...&#34;&#xA;openai.api_base = &#34;https://example-endpoint.openai.azure.com&#34;&#xA;openai.api_version = &#34;2023-05-15&#34;&#xA;&#xA;# create a chat completion&#xA;chat_completion = openai.ChatCompletion.create(deployment_id=&#34;deployment-name&#34;, model=&#34;gpt-3.5-turbo&#34;, messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Hello world&#34;}])&#xA;&#xA;# print the completion&#xA;print(chat_completion.choices[0].message.content)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please note that for the moment, the Microsoft Azure endpoints can only be used for completion, embedding, and fine-tuning operations. For a detailed example of how to use fine-tuning and other operations using Azure endpoints, please check out the following Jupyter notebooks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook/tree/main/examples/azure/completions.ipynb&#34;&gt;Using Azure completions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook/tree/main/examples/azure/chat.ipynb&#34;&gt;Using Azure chat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook/raw/main/examples/azure/embeddings.ipynb&#34;&gt;Using Azure embeddings&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Microsoft Azure Active Directory Authentication&lt;/h3&gt; &#xA;&lt;p&gt;In order to use Microsoft Active Directory to authenticate to your Azure endpoint, you need to set the &lt;code&gt;api_type&lt;/code&gt; to &#34;azure_ad&#34; and pass the acquired credential token to &lt;code&gt;api_key&lt;/code&gt;. The rest of the parameters need to be set as specified in the previous section.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from azure.identity import DefaultAzureCredential&#xA;import openai&#xA;&#xA;# Request credential&#xA;default_credential = DefaultAzureCredential()&#xA;token = default_credential.get_token(&#34;https://cognitiveservices.azure.com/.default&#34;)&#xA;&#xA;# Setup parameters&#xA;openai.api_type = &#34;azure_ad&#34;&#xA;openai.api_key = token.token&#xA;openai.api_base = &#34;https://example-endpoint.openai.azure.com/&#34;&#xA;openai.api_version = &#34;2023-05-15&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credit&lt;/h2&gt; &#xA;&lt;p&gt;This library is forked from the &lt;a href=&#34;https://github.com/stripe/stripe-python&#34;&gt;Stripe Python Library&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>