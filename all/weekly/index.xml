<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-09-15T01:41:17Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>afadil/wealthfolio</title>
    <updated>2024-09-15T01:41:17Z</updated>
    <id>tag:github.com,2024-09-15:/afadil/wealthfolio</id>
    <link href="https://github.com/afadil/wealthfolio" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Beautiful Private and Secure Desktop Investment Tracking Application&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/afadil/wealthfolio&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/afadil/wealthfolio/main/public/logo.svg?sanitize=true&#34; alt=&#34;Logo&#34; width=&#34;80&#34; height=&#34;80&#34;&gt; &lt;/a&gt; &#xA; &lt;h3 align=&#34;center&#34;&gt;Wealthfolio&lt;/h3&gt; &#xA; &lt;p align=&#34;center&#34;&gt; A Beautiful and Boring Desktop Investment Tracker &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://wealthfolio.app&#34;&gt;Website&lt;/a&gt; · &lt;a href=&#34;https://discord.gg/WDMCY6aPWK&#34;&gt;Discord&lt;/a&gt; · &lt;a href=&#34;https://x.com/intent/follow?screen_name=WealthfolioApp&#34;&gt;Twitter&lt;/a&gt; · &lt;a href=&#34;https://github.com/afadil/wealthfolio/releases&#34;&gt;Releases&lt;/a&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/afadil&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/afadil/wealthfolio/main/public/button-buy-me-a-coffee.png&#34; width=&#34;150&#34; alt=&#34;Buy me a coffee button&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Wealthfolio App&lt;/strong&gt; is a Beautiful and Boring Investment Tracker, with Local Data Storage. No Subscriptions, No Cloud.&lt;/p&gt; &#xA;&lt;p&gt;Visit the app website at &lt;a href=&#34;https://wealthfolio.app/&#34;&gt;Wealthfolio App&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/afadil/wealthfolio/main/public/screenshot.png&#34; alt=&#34;Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/afadil/wealthfolio/main/ROADMAP.md&#34;&gt;ROADMAP.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;Ensure you have the following installed on your machine:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nodejs.org/&#34;&gt;Node.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pnpm.io/&#34;&gt;pnpm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.rust-lang.org/&#34;&gt;Rust&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tauri.app/&#34;&gt;Tauri&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/afadil/wealthfolio.git&#xA;cd wealthfolio&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install dependencies using pnpm&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pnpm install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Running the Application&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Development Mode&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Build and run the desktop application using Tauri:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pnpm tauri dev&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Build for Production&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Build the application for production:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pnpm tauri build&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Technologies Used&lt;/h2&gt; &#xA;&lt;h3&gt;Frontend&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;React&lt;/strong&gt;: JavaScript library for building user interfaces.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;React Router&lt;/strong&gt;: Declarative routing for React.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tailwind CSS&lt;/strong&gt;: Utility-first CSS framework for styling.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Radix UI/Shadcn&lt;/strong&gt;: Accessible UI components.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Recharts&lt;/strong&gt;: Charting library built with React.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Backend / APIs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;React Query&lt;/strong&gt;: Data-fetching library for React.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Zod&lt;/strong&gt;: TypeScript-first schema declaration and validation library.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Development Tools&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vite&lt;/strong&gt;: Next-generation frontend tooling.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;: Typed superset of JavaScript.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ESLint&lt;/strong&gt;: Pluggable linting utility for JavaScript and JSX.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Prettier&lt;/strong&gt;: Code formatter.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tauri&lt;/strong&gt;: Framework for building tiny, secure, and fast desktop applications.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Folder Structure&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;wealthfolio/&#xA;├── src/                 # Main source code for the React application&#xA;├── src-core/            # Core backend functionality&#xA;├── src-tauri/           # Tauri-specific code for desktop app functionality&#xA;├── public/              # Public assets&#xA;├── LICENSE              # License file&#xA;├── README.md            # Project documentation&#xA;├── ROADMAP.md           # Future plans and roadmap&#xA;├── components.json      # Component configuration&#xA;├── package.json         # Node.js dependencies and scripts&#xA;├── pnpm-lock.yaml       # Lock file for pnpm&#xA;├── postcss.config.js    # PostCSS configuration&#xA;├── tailwind.config.js   # Tailwind CSS configuration&#xA;├── tsconfig.json        # TypeScript configuration&#xA;└── vite.config.ts       # Vite build tool configuration&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome! Please follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork the repository.&lt;/li&gt; &#xA; &lt;li&gt;Create a new branch (&lt;code&gt;git checkout -b feature-branch&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Make your changes.&lt;/li&gt; &#xA; &lt;li&gt;Commit your changes (&lt;code&gt;git commit -m &#39;Add some feature&#39;&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Push to the branch (&lt;code&gt;git push origin feature-branch&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Open a pull request.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the LGPL-3.0 license. See the &lt;code&gt;LICENSE&lt;/code&gt; file for details.&lt;/p&gt; &#xA;&lt;h2&gt;🌟 Star History&lt;/h2&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://star-history.com/#afadil/wealthfolio&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=afadil/wealthfolio&amp;amp;type=Timeline&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Enjoy managing your wealth with &lt;strong&gt;Wealthfolio&lt;/strong&gt;! 🚀&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OpenBMB/MiniCPM</title>
    <updated>2024-09-15T01:41:17Z</updated>
    <id>tag:github.com,2024-09-15:/OpenBMB/MiniCPM</id>
    <link href="https://github.com/OpenBMB/MiniCPM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;MiniCPM3-4B: An edge-side LLM that surpasses GPT-3.5-Turbo.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/minicpm_logo.png&#34; width=&#34;500em&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;p&gt; &lt;b&gt;中文&lt;/b&gt; | &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/README-en.md&#34;&gt;English&lt;/a&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://openbmb.vercel.app/?category=Chinese+Blog&#34; target=&#34;_blank&#34;&gt;MiniCPM 技术博客&lt;/a&gt; | &lt;a href=&#34;https://modelbest.feishu.cn/wiki/D2tFw8Pcsi5CIzkaHNacLK64npg&#34; target=&#34;_blank&#34;&gt;MiniCPM 知识库&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2404.06395&#34; target=&#34;_blank&#34;&gt;MiniCPM 论文&lt;/a&gt; | &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM-V/&#34; target=&#34;_blank&#34;&gt;MiniCPM-V 仓库&lt;/a&gt; | 加入我们的 &lt;a href=&#34;https://discord.gg/3cGQn9b3YM&#34; target=&#34;_blank&#34;&gt;discord&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/assets/wechat.jpg&#34; target=&#34;_blank&#34;&gt;微信群&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;更新日志🔥&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2024.09.05] 发布 &lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM3-4B&#34;&gt;&lt;strong&gt;MiniCPM3-4B&lt;/strong&gt;&lt;/a&gt;！该模型的表现超越 Phi-3.5-mini-instruct 和 GPT-3.5-Turbo-0125，并且能够比肩 Llama3.1-8B-Instruct、Qwen2-7B-Instruct、GLM-4-9B-Chat 等多个 7B-9B 参数量的模型。&lt;/li&gt; &#xA; &lt;li&gt;[2024.07.09] MiniCPM-2B 已经支持使用 &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#sglang-%E6%8E%A8%E7%90%86&#34;&gt;SGLang&lt;/a&gt; 推理！&lt;/li&gt; &#xA; &lt;li&gt;[2024.07.05] 发布 &lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-S-1B-sft&#34;&gt;MiniCPM-S-1B&lt;/a&gt;！该模型在保持下游任务性能无损的前提下，FFN 层实现了 87.89% 的平均稀疏度，将 FFN FLOPs 降低了 84%。&lt;/li&gt; &#xA; &lt;li&gt;[2024.04.11] 发布 &lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-128k&#34;&gt;MiniCPM-2B-128k&lt;/a&gt;、&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-MoE-8x2B&#34;&gt;MiniCPM-MoE-8x2B&lt;/a&gt; 和 &lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16&#34;&gt;MiniCPM-1B&lt;/a&gt;！点击&lt;a href=&#34;https://openbmb.vercel.app/?category=Chinese+Blog&#34;&gt;这里&lt;/a&gt;查看技术博客。&lt;/li&gt; &#xA; &lt;li&gt;[2024.03.16] MiniCPM-2B 的 30 余个中间检查点开放了！&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-history&#34;&gt;HuggingFace链接&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2024.02.01] 发布 &lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16&#34;&gt;&lt;strong&gt;MiniCPM-2B&lt;/strong&gt;&lt;/a&gt;！该模型在公开评测集上与 Mistral-7B 表现相近（中文、数学、代码能力更优），整体性能超越 Llama2-13B、MPT-30B、Falcon-40B 等模型。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;目录&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD&#34;&gt;模型下载&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#minicpm-30&#34;&gt;MiniCPM 3.0&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C&#34;&gt;评测结果&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E7%BB%BC%E5%90%88%E8%AF%84%E6%B5%8B&#34;&gt;综合评测&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%E8%83%BD%E5%8A%9B&#34;&gt;工具调用能力&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E9%95%BF%E6%96%87%E6%9C%AC%E8%83%BD%E5%8A%9B&#34;&gt;长文本能力&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86&#34;&gt;模型推理&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#huggingface&#34;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#vllm&#34;&gt;vLLM&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#llamacpp&#34;&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;模型微调&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#llama-factory&#34;&gt;LLaMA-Factory&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E8%BF%9B%E9%98%B6%E5%8A%9F%E8%83%BD&#34;&gt;进阶功能&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8&#34;&gt;工具调用&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#%E4%BB%A3%E7%A0%81%E8%A7%A3%E9%87%8A%E5%99%A8&#34;&gt;代码解释器&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#minicpm-20&#34;&gt;MiniCPM 2.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#minicpm-10&#34;&gt;MiniCPM 1.0&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;模型下载&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;HuggingFace&lt;/th&gt; &#xA;   &lt;th&gt;ModelScope&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM3-4B&#34;&gt;MiniCPM3-4B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.modelscope.cn/models/OpenBMB/MiniCPM3-4B&#34;&gt;MiniCPM3-4B&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16&#34;&gt;MiniCPM-2B-sft&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/miniCPM-bf16&#34;&gt;MiniCPM-2B-sft&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-dpo-bf16&#34;&gt;MiniCPM-2B-dpo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-2B-dpo-bf16/summary&#34;&gt;MiniCPM-2B-dpo&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-128k&#34;&gt;MiniCPM-2B-128k&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/openbmb/MiniCPM-2B-128k/summary&#34;&gt;MiniCPM-2B-128k&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-MoE-8x2B&#34;&gt;MiniCPM-MoE-8x2B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-MoE-8x2B&#34;&gt;MiniCPM-MoE-8x2B&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16&#34;&gt;MiniCPM-1B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-1B-sft-bf16&#34;&gt;MiniCPM-1B&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-S-1B-sft&#34;&gt;MiniCPM-S-1B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-S-1B-sft&#34;&gt;MiniCPM-S-1B&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;注: 更多模型版本见&lt;a href=&#34;https://huggingface.co/collections/openbmb/minicpm-2b-65d48bf958302b9fd25b698f&#34;&gt;这里&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;h2&gt;MiniCPM 3.0&lt;/h2&gt; &#xA;&lt;p&gt;MiniCPM 3.0 是一个 4B 参数量的语言模型，相比 MiniCPM1.0/2.0，功能更加全面，综合能力大幅提升，多数评测集上的效果比肩甚至超越众多 7B-9B 模型。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;支持工具调用🛠️（Function Calling）和代码解释器💻（Code Interpreter）&lt;/strong&gt;：&lt;a href=&#34;https://gorilla.cs.berkeley.edu/leaderboard.html&#34;&gt;Berkeley Function Calling Leaderboard (BFCL)&lt;/a&gt; 上取得 9B 规模以下 SOTA，超越 GLM-4-9B-Chat、Qwen2-7B-Instruct。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;超强的推理能力🧮&lt;/strong&gt;：数学能力方面，&lt;a href=&#34;https://open-compass.github.io/MathBench/&#34;&gt;MathBench&lt;/a&gt; 上的效果超越 GPT-3.5-Turbo 以及多个 7B-9B 模型。在非常具有挑战性的 &lt;a href=&#34;https://livecodebench.github.io/&#34;&gt;LiveCodeBench&lt;/a&gt; 上，效果超越 Llama3.1-8B-Instruct。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;出色的中英文指令遵循能力🤖&lt;/strong&gt;：英文指令遵循 &lt;a href=&#34;https://huggingface.co/datasets/google/IFEval&#34;&gt;IFEval&lt;/a&gt;、中文指令遵循 &lt;a href=&#34;https://huggingface.co/datasets/YuxinJiang/FollowBench&#34;&gt;FollowBench-zh&lt;/a&gt; 效果超越 GLM-4-9B-Chat、Qwen2-7B-Instruct。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;长文本能力&lt;/strong&gt;：原生支持 32k 上下文长度，32k 长度内大海捞针全绿。提出 &lt;strong&gt;LLM x MapReduce&lt;/strong&gt; ，理论可处理的上下文长度达到 +∞。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;RAG能力&lt;/strong&gt;：我们发布了 &lt;a href=&#34;https://huggingface.co/collections/openbmb/minicpm-rag-suite-66d976b4204cd0a4f8beaabb&#34;&gt;MiniCPM RAG 套件&lt;/a&gt;。基于 MiniCPM 系列模型的 &lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-Embedding&#34;&gt;MiniCPM-Embedding&lt;/a&gt;、&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-Reranker&#34;&gt;MiniCPM-Reranker&lt;/a&gt; 在中文、中英跨语言检索测试中取得 SOTA 表现；针对 RAG 场景的 &lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM3-RAG-LoRA&#34;&gt;MiniCPM3-RAG-LoRA&lt;/a&gt; 在开放域问答等多项任务上超越 Llama3-8B、Baichuan2-13B 等模型。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;评测结果&lt;/h3&gt; &#xA;&lt;h4&gt;综合评测&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;评测集&lt;/td&gt; &#xA;   &lt;td&gt;Qwen2-7B-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;GLM-4-9B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;Gemma2-9B-it&lt;/td&gt; &#xA;   &lt;td&gt;Llama3.1-8B-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;GPT-3.5-Turbo-0125&lt;/td&gt; &#xA;   &lt;td&gt;Phi-3.5-mini-Instruct(3.8B)&lt;/td&gt; &#xA;   &lt;td&gt;MiniCPM3-4B &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td colspan=&#34;15&#34; align=&#34;left&#34;&gt;&lt;strong&gt;英文能力&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MMLU&lt;/td&gt; &#xA;   &lt;td&gt;70.5&lt;/td&gt; &#xA;   &lt;td&gt;72.4&lt;/td&gt; &#xA;   &lt;td&gt;72.6&lt;/td&gt; &#xA;   &lt;td&gt;69.4&lt;/td&gt; &#xA;   &lt;td&gt;69.2&lt;/td&gt; &#xA;   &lt;td&gt;68.4&lt;/td&gt; &#xA;   &lt;td&gt;67.2 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BBH&lt;/td&gt; &#xA;   &lt;td&gt;64.9&lt;/td&gt; &#xA;   &lt;td&gt;76.3&lt;/td&gt; &#xA;   &lt;td&gt;65.2&lt;/td&gt; &#xA;   &lt;td&gt;67.8&lt;/td&gt; &#xA;   &lt;td&gt;70.3&lt;/td&gt; &#xA;   &lt;td&gt;68.6&lt;/td&gt; &#xA;   &lt;td&gt;70.2 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MT-Bench&lt;/td&gt; &#xA;   &lt;td&gt;8.41&lt;/td&gt; &#xA;   &lt;td&gt;8.35&lt;/td&gt; &#xA;   &lt;td&gt;7.88&lt;/td&gt; &#xA;   &lt;td&gt;8.28&lt;/td&gt; &#xA;   &lt;td&gt;8.17&lt;/td&gt; &#xA;   &lt;td&gt;8.60&lt;/td&gt; &#xA;   &lt;td&gt;8.41 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;IFEVAL (Prompt Strict-Acc.)&lt;/td&gt; &#xA;   &lt;td&gt;51.0&lt;/td&gt; &#xA;   &lt;td&gt;64.5&lt;/td&gt; &#xA;   &lt;td&gt;71.9&lt;/td&gt; &#xA;   &lt;td&gt;71.5&lt;/td&gt; &#xA;   &lt;td&gt;58.8&lt;/td&gt; &#xA;   &lt;td&gt;49.4&lt;/td&gt; &#xA;   &lt;td&gt;68.4 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td colspan=&#34;15&#34; align=&#34;left&#34;&gt;&lt;strong&gt;中文能力&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CMMLU&lt;/td&gt; &#xA;   &lt;td&gt;80.9&lt;/td&gt; &#xA;   &lt;td&gt;71.5&lt;/td&gt; &#xA;   &lt;td&gt;59.5&lt;/td&gt; &#xA;   &lt;td&gt;55.8&lt;/td&gt; &#xA;   &lt;td&gt;54.5&lt;/td&gt; &#xA;   &lt;td&gt;46.9&lt;/td&gt; &#xA;   &lt;td&gt;73.3 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CEVAL&lt;/td&gt; &#xA;   &lt;td&gt;77.2&lt;/td&gt; &#xA;   &lt;td&gt;75.6&lt;/td&gt; &#xA;   &lt;td&gt;56.7&lt;/td&gt; &#xA;   &lt;td&gt;55.2&lt;/td&gt; &#xA;   &lt;td&gt;52.8&lt;/td&gt; &#xA;   &lt;td&gt;46.1&lt;/td&gt; &#xA;   &lt;td&gt;73.6 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AlignBench v1.1&lt;/td&gt; &#xA;   &lt;td&gt;7.10&lt;/td&gt; &#xA;   &lt;td&gt;6.61&lt;/td&gt; &#xA;   &lt;td&gt;7.10&lt;/td&gt; &#xA;   &lt;td&gt;5.68&lt;/td&gt; &#xA;   &lt;td&gt;5.82&lt;/td&gt; &#xA;   &lt;td&gt;5.73&lt;/td&gt; &#xA;   &lt;td&gt;6.74 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FollowBench-zh (SSR)&lt;/td&gt; &#xA;   &lt;td&gt;63.0&lt;/td&gt; &#xA;   &lt;td&gt;56.4&lt;/td&gt; &#xA;   &lt;td&gt;57.0&lt;/td&gt; &#xA;   &lt;td&gt;50.6&lt;/td&gt; &#xA;   &lt;td&gt;64.6&lt;/td&gt; &#xA;   &lt;td&gt;58.1&lt;/td&gt; &#xA;   &lt;td&gt;66.8 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td colspan=&#34;15&#34; align=&#34;left&#34;&gt;&lt;strong&gt;数学能力&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MATH&lt;/td&gt; &#xA;   &lt;td&gt;49.6&lt;/td&gt; &#xA;   &lt;td&gt;50.6&lt;/td&gt; &#xA;   &lt;td&gt;46.0&lt;/td&gt; &#xA;   &lt;td&gt;51.9&lt;/td&gt; &#xA;   &lt;td&gt;41.8&lt;/td&gt; &#xA;   &lt;td&gt;46.4&lt;/td&gt; &#xA;   &lt;td&gt;46.6 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GSM8K&lt;/td&gt; &#xA;   &lt;td&gt;82.3&lt;/td&gt; &#xA;   &lt;td&gt;79.6&lt;/td&gt; &#xA;   &lt;td&gt;79.7&lt;/td&gt; &#xA;   &lt;td&gt;84.5&lt;/td&gt; &#xA;   &lt;td&gt;76.4&lt;/td&gt; &#xA;   &lt;td&gt;82.7&lt;/td&gt; &#xA;   &lt;td&gt;81.1 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MathBench&lt;/td&gt; &#xA;   &lt;td&gt;63.4&lt;/td&gt; &#xA;   &lt;td&gt;59.4&lt;/td&gt; &#xA;   &lt;td&gt;45.8&lt;/td&gt; &#xA;   &lt;td&gt;54.3&lt;/td&gt; &#xA;   &lt;td&gt;48.9&lt;/td&gt; &#xA;   &lt;td&gt;54.9&lt;/td&gt; &#xA;   &lt;td&gt;65.6 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td colspan=&#34;15&#34; align=&#34;left&#34;&gt;&lt;strong&gt;代码能力&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HumanEval+&lt;/td&gt; &#xA;   &lt;td&gt;70.1&lt;/td&gt; &#xA;   &lt;td&gt;67.1&lt;/td&gt; &#xA;   &lt;td&gt;61.6&lt;/td&gt; &#xA;   &lt;td&gt;62.8&lt;/td&gt; &#xA;   &lt;td&gt;66.5&lt;/td&gt; &#xA;   &lt;td&gt;68.9&lt;/td&gt; &#xA;   &lt;td&gt;68.3 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MBPP+&lt;/td&gt; &#xA;   &lt;td&gt;57.1&lt;/td&gt; &#xA;   &lt;td&gt;62.2&lt;/td&gt; &#xA;   &lt;td&gt;64.3&lt;/td&gt; &#xA;   &lt;td&gt;55.3&lt;/td&gt; &#xA;   &lt;td&gt;71.4&lt;/td&gt; &#xA;   &lt;td&gt;55.8&lt;/td&gt; &#xA;   &lt;td&gt;63.2 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LiveCodeBench v3&lt;/td&gt; &#xA;   &lt;td&gt;22.2&lt;/td&gt; &#xA;   &lt;td&gt;20.2&lt;/td&gt; &#xA;   &lt;td&gt;19.2&lt;/td&gt; &#xA;   &lt;td&gt;20.4&lt;/td&gt; &#xA;   &lt;td&gt;24.0&lt;/td&gt; &#xA;   &lt;td&gt;19.6&lt;/td&gt; &#xA;   &lt;td&gt;22.6 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td colspan=&#34;15&#34; align=&#34;left&#34;&gt;&lt;strong&gt;工具调用能力&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BFCL v2&lt;/td&gt; &#xA;   &lt;td&gt;71.6&lt;/td&gt; &#xA;   &lt;td&gt;70.1&lt;/td&gt; &#xA;   &lt;td&gt;19.2&lt;/td&gt; &#xA;   &lt;td&gt;73.3&lt;/td&gt; &#xA;   &lt;td&gt;75.4&lt;/td&gt; &#xA;   &lt;td&gt;48.4&lt;/td&gt; &#xA;   &lt;td&gt;76.0 &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td colspan=&#34;15&#34; align=&#34;left&#34;&gt;&lt;strong&gt;综合能力&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;平均分&lt;/td&gt; &#xA;   &lt;td&gt;65.3&lt;/td&gt; &#xA;   &lt;td&gt;65.0&lt;/td&gt; &#xA;   &lt;td&gt;57.9&lt;/td&gt; &#xA;   &lt;td&gt;60.8&lt;/td&gt; &#xA;   &lt;td&gt;61.0&lt;/td&gt; &#xA;   &lt;td&gt;57.2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;66.3&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h4&gt;工具调用能力&lt;/h4&gt; &#xA;&lt;p&gt;我们在 &lt;a href=&#34;https://gorilla.cs.berkeley.edu/leaderboard.html&#34;&gt;Berkeley Function Calling Leaderboard (BFCL)&lt;/a&gt; 上测试了模型的工具调用能力，MiniCPM3-4B 在该榜单上的表现超越了多个 7B-9B 参数量的模型，优于 GPT-3.5-Turbo-0125。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;模型&lt;/td&gt; &#xA;   &lt;td&gt;总体准确率&lt;/td&gt; &#xA;   &lt;td&gt;AST Summary&lt;/td&gt; &#xA;   &lt;td&gt;Exec Summary&lt;/td&gt; &#xA;   &lt;td&gt;Irrelevance Detection&lt;/td&gt; &#xA;   &lt;td&gt;Relevance Detection &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniCPM3-4B&lt;/td&gt; &#xA;   &lt;td&gt;76.03%&lt;/td&gt; &#xA;   &lt;td&gt;68.55%&lt;/td&gt; &#xA;   &lt;td&gt;85.54%&lt;/td&gt; &#xA;   &lt;td&gt;53.71%&lt;/td&gt; &#xA;   &lt;td&gt;90.24% &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama3.1-8B-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;73.28%&lt;/td&gt; &#xA;   &lt;td&gt;64.61%&lt;/td&gt; &#xA;   &lt;td&gt;86.48%&lt;/td&gt; &#xA;   &lt;td&gt;43.12%&lt;/td&gt; &#xA;   &lt;td&gt;85.37% &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen2-7B-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;71.61%&lt;/td&gt; &#xA;   &lt;td&gt;65.71%&lt;/td&gt; &#xA;   &lt;td&gt;79.57%&lt;/td&gt; &#xA;   &lt;td&gt;44.70%&lt;/td&gt; &#xA;   &lt;td&gt;90.24% &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GLM-4-9B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;70.08%&lt;/td&gt; &#xA;   &lt;td&gt;60.69%&lt;/td&gt; &#xA;   &lt;td&gt;80.02%&lt;/td&gt; &#xA;   &lt;td&gt;55.02%&lt;/td&gt; &#xA;   &lt;td&gt;82.93% &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi-3.5-mini-instruct&lt;/td&gt; &#xA;   &lt;td&gt;48.44%&lt;/td&gt; &#xA;   &lt;td&gt;38.89%&lt;/td&gt; &#xA;   &lt;td&gt;54.04%&lt;/td&gt; &#xA;   &lt;td&gt;46.78%&lt;/td&gt; &#xA;   &lt;td&gt;65.85% &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemma2-9B-it&lt;/td&gt; &#xA;   &lt;td&gt;19.18%&lt;/td&gt; &#xA;   &lt;td&gt;5.41%&lt;/td&gt; &#xA;   &lt;td&gt;18.50%&lt;/td&gt; &#xA;   &lt;td&gt;88.88%&lt;/td&gt; &#xA;   &lt;td&gt;7.32%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h4&gt;长文本能力&lt;/h4&gt; &#xA;&lt;p&gt;在 32k 的上下文长度进行&lt;a href=&#34;https://github.com/gkamradt/LLMTest_NeedleInAHaystack&#34;&gt;大海捞针&lt;/a&gt;测试，结果如下图：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/eval_needle.jpeg&#34; alt=&#34;needle&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;模型推理&lt;/h3&gt; &#xA;&lt;h4&gt;Huggingface&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;import torch&#xA;torch.manual_seed(0)&#xA;&#xA;path = &#39;openbmb/MiniCPM3-4B&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(path)&#xA;model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map=&#39;cuda&#39;, trust_remote_code=True)&#xA;&#xA;responds, history = model.chat(tokenizer, &#34;请写一篇关于人工智能的文章，详细介绍人工智能的未来发展和隐患。&#34;, temperature=0.7, top_p=0.7)&#xA;print(responds)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;vLLM&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装 vllm &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install git+https://github.com/OpenBMB/vllm.git@minicpm3&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;推理 &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer&#xA;from vllm import LLM, SamplingParams&#xA;&#xA;model_name = &#34;openbmb/MiniCPM3-4B&#34;&#xA;prompt = [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;请写一篇关于人工智能的文章，详细介绍人工智能的未来发展和隐患。&#34;}]&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)&#xA;input_text = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)&#xA;&#xA;llm = LLM(model=model_name,&#xA;    trust_remote_code=True,&#xA;    tensor_parallel_size=1&#xA;)&#xA;sampling_params = SamplingParams(top_p=0.7, temperature=0.7, max_tokens=1024)&#xA;&#xA;outputs = llm.generate(prompts=input_text, sampling_params=sampling_params)&#xA;&#xA;print(outputs[0].outputs[0].text)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;llama.cpp&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装 llama.cpp &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;  git clone https://github.com/OpenBMB/llama.cpp.git&#xA;  cd llama.cpp&#xA;  git checkout minicpm3    &#xA;  make &#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;创建模型目录 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;  cd llama.cpp/models&#xA;  mkdir Minicpm3&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;下载 MiniCPM3 模型所有文件到 &lt;code&gt;llama.cpp/models/Minicpm3&lt;/code&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;  cd llama.cpp/models/Minicpm3&#xA;  git clone https://huggingface.co/openbmb/MiniCPM3-4B&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;将模型转换为 gguf 格式，并且量化： &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python3 -m pip install -r requirements.txt&#xA;# 将pytorch模型转化为fp16的gguf&#xA;python3 convert_hf_to_gguf.py models/Minicpm3/MiniCPM3-4B --outfile ./models/Minicpm3/CPM-4B-F16.gguf&#xA;# 完成以上步骤，llama.cpp/models/Minicpm3目录下有一个CPM-4B-F16.gguf的模型文件&#xA;./llama-quantize ./models/Minicpm3/CPM-4B-F16.gguf ./models/Minicpm3/ggml-model-Q4_K_M.gguf Q4_K_M&#xA;# 使用本行代码执行成功后，./models/Minicpm3下将存在ggml-model-Q4_K_M.gguf的4bit量化文件&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;推理 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;./llama-cli -c 1024 -m ./models/Minicpm/ggml-model-Q4_K_M.gguf -n 1024 --top-p 0.7 --temp 0.7 --prompt &#34;&amp;lt;|im_start|&amp;gt;user\n请写一篇关于人工智能的文章，详细介绍人工智能的未来发展和隐患。&amp;lt;|im_end|&amp;gt;\n&amp;lt;|im_start|&amp;gt;assistant\n&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;模型微调&lt;/h3&gt; &#xA;&lt;h4&gt;LLaMA-Factory&lt;/h4&gt; &#xA;&lt;p&gt;目前模型微调支持 &lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory&#34;&gt;LLaMA-Factory&lt;/a&gt;，使用方法参考 &lt;a href=&#34;https://modelbest.feishu.cn/docx/Z7USdW4lloZzkZxQ14icJ3senjb?from=from_copylink&#34;&gt;LLaMA-Factory 微调&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;h3&gt;进阶功能&lt;/h3&gt; &#xA;&lt;p&gt;对于以下进阶功能，我们推荐使用 &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#vllm&#34;&gt;vLLM&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;h4&gt;工具调用&lt;/h4&gt; &#xA;&lt;p&gt;我们提供了使用 MiniCPM3 调用工具的示例代码：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd demo/minicpm3/function_call&#xA;python function_call.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;如果你想启动一个能够调用工具的推理服务，使用以下代码：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd demo/minicpm3/function_call&#xA;pip install -r requirements.txt&#xA;python openai_api_server.py \&#xA;    --model openbmb/MiniCPM3-4B \&#xA;    --served-model-name MiniCPM3-4B \&#xA;    --chat-template chatml.jinja \&#xA;    --dtype auto \&#xA;    --api-key token-abc123 \&#xA;    --tensor-parallel-size 1 \&#xA;    --trust-remote-code&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;下面是一个调用搜索工具回答问题的演示：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/function_call.gif&#34; alt=&#34;function_call&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;代码解释器&lt;/h4&gt; &#xA;&lt;p&gt;我们提供了一个 MiniCPM3 使用代码解释器的示例代码：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd demo/minicpm3/code_interpreter&#xA;pip install -r requirements.txt&#xA;python code_interpreter.py openbmb/MiniCPM3-4B&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;下面是一个使用代码解释器生成二维码的演示：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/code_interpreter.gif&#34; alt=&#34;code_interpreter&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;MiniCPM 2.0&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;查看 MiniCPM 2.0 的详细信息&lt;/summary&gt; &#xA; &lt;p&gt;MiniCPM 2.0 系列模型对 MiniCPM 进行了多个维度的升级，包括以下模型版本：&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;MiniCPM-2B-128k：将 MiniCPM-2B 的上下文长度从 4k 扩展至 128k，在 InfiniteBench 测试集上优于 ChatGLM3-6B-128k、Yi-6B-200k 等更大参数量的模型。&lt;/li&gt; &#xA;  &lt;li&gt;MiniCPM-MoE-8x2B：基于 MiniCPM-2B 进行 MoE 扩展，综合表现相比于 MiniCPM-2B 平均提高 4.5 个百分点。&lt;/li&gt; &#xA;  &lt;li&gt;MiniCPM-1B：相比于 MiniCPM-2B 成本下降 60%，综合表现仍然优于 LLaMA2-13B。&lt;/li&gt; &#xA;  &lt;li&gt;MiniCPM-S-1B：在保持下游任务性能无损的前提下，FFN 层实现了 87.89% 的平均稀疏度，将 FFN FLOPs 降低了 84%。结合 PowerInfer 推理框架，解码速度提升约 2.8 倍。&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h3&gt;评测结果&lt;/h3&gt; &#xA; &lt;h4&gt;MiniCPM-2B-128k 模型评测&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;avg&lt;/th&gt; &#xA;    &lt;th&gt;avg w/o code&amp;amp;math&lt;/th&gt; &#xA;    &lt;th&gt;passkey&lt;/th&gt; &#xA;    &lt;th&gt;number_string&lt;/th&gt; &#xA;    &lt;th&gt;kv_retrieval&lt;/th&gt; &#xA;    &lt;th&gt;longbook_choice_eng&lt;/th&gt; &#xA;    &lt;th&gt;longbook_qa_chn&lt;/th&gt; &#xA;    &lt;th&gt;longbook_qa_eng&lt;/th&gt; &#xA;    &lt;th&gt;longbook_sum_eng&lt;/th&gt; &#xA;    &lt;th&gt;longdialogue_qa_eng&lt;/th&gt; &#xA;    &lt;th&gt;math_calc&lt;/th&gt; &#xA;    &lt;th&gt;math_find&lt;/th&gt; &#xA;    &lt;th&gt;code_debug&lt;/th&gt; &#xA;    &lt;th&gt;code_run&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;LWM-Text-128k&lt;/td&gt; &#xA;    &lt;td&gt;24.45&lt;/td&gt; &#xA;    &lt;td&gt;33.62&lt;/td&gt; &#xA;    &lt;td&gt;100&lt;/td&gt; &#xA;    &lt;td&gt;97.8&lt;/td&gt; &#xA;    &lt;td&gt;0.6&lt;/td&gt; &#xA;    &lt;td&gt;28.82&lt;/td&gt; &#xA;    &lt;td&gt;15.93&lt;/td&gt; &#xA;    &lt;td&gt;14.31&lt;/td&gt; &#xA;    &lt;td&gt;9.99&lt;/td&gt; &#xA;    &lt;td&gt;1.5&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;    &lt;td&gt;3.43&lt;/td&gt; &#xA;    &lt;td&gt;20.05&lt;/td&gt; &#xA;    &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Yarn-Mistral-7b-128k&lt;/td&gt; &#xA;    &lt;td&gt;19.84&lt;/td&gt; &#xA;    &lt;td&gt;27.36&lt;/td&gt; &#xA;    &lt;td&gt;92.71&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;    &lt;td&gt;27.95&lt;/td&gt; &#xA;    &lt;td&gt;15.49&lt;/td&gt; &#xA;    &lt;td&gt;9.55&lt;/td&gt; &#xA;    &lt;td&gt;9.06&lt;/td&gt; &#xA;    &lt;td&gt;7.5&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;    &lt;td&gt;17.14&lt;/td&gt; &#xA;    &lt;td&gt;0.76&lt;/td&gt; &#xA;    &lt;td&gt;1.25&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Mistral-7B-Instruct-v0.2(ABF 1000w)&lt;/td&gt; &#xA;    &lt;td&gt;27.75&lt;/td&gt; &#xA;    &lt;td&gt;36.9&lt;/td&gt; &#xA;    &lt;td&gt;100&lt;/td&gt; &#xA;    &lt;td&gt;78.98&lt;/td&gt; &#xA;    &lt;td&gt;3.6&lt;/td&gt; &#xA;    &lt;td&gt;37.12&lt;/td&gt; &#xA;    &lt;td&gt;11.74&lt;/td&gt; &#xA;    &lt;td&gt;17.37&lt;/td&gt; &#xA;    &lt;td&gt;21.12&lt;/td&gt; &#xA;    &lt;td&gt;9.5&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;    &lt;td&gt;29.43&lt;/td&gt; &#xA;    &lt;td&gt;17.51&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Yi-6B-200k&lt;/td&gt; &#xA;    &lt;td&gt;22.15&lt;/td&gt; &#xA;    &lt;td&gt;32.54&lt;/td&gt; &#xA;    &lt;td&gt;100&lt;/td&gt; &#xA;    &lt;td&gt;94.92&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;    &lt;td&gt;36.68&lt;/td&gt; &#xA;    &lt;td&gt;15.07&lt;/td&gt; &#xA;    &lt;td&gt;9.2&lt;/td&gt; &#xA;    &lt;td&gt;0.92&lt;/td&gt; &#xA;    &lt;td&gt;3.5&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;    &lt;td&gt;4.29&lt;/td&gt; &#xA;    &lt;td&gt;0.51&lt;/td&gt; &#xA;    &lt;td&gt;0.75&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;chatglm3-6b-128k&lt;/td&gt; &#xA;    &lt;td&gt;25.58&lt;/td&gt; &#xA;    &lt;td&gt;36.57&lt;/td&gt; &#xA;    &lt;td&gt;89.93&lt;/td&gt; &#xA;    &lt;td&gt;99.66&lt;/td&gt; &#xA;    &lt;td&gt;5.2&lt;/td&gt; &#xA;    &lt;td&gt;46.29&lt;/td&gt; &#xA;    &lt;td&gt;10.7&lt;/td&gt; &#xA;    &lt;td&gt;8.38&lt;/td&gt; &#xA;    &lt;td&gt;25.91&lt;/td&gt; &#xA;    &lt;td&gt;6.5&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;    &lt;td&gt;8&lt;/td&gt; &#xA;    &lt;td&gt;5.33&lt;/td&gt; &#xA;    &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;MiniCPM-2.4B-128k&lt;/td&gt; &#xA;    &lt;td&gt;27.32&lt;/td&gt; &#xA;    &lt;td&gt;37.68&lt;/td&gt; &#xA;    &lt;td&gt;98.31&lt;/td&gt; &#xA;    &lt;td&gt;99.83&lt;/td&gt; &#xA;    &lt;td&gt;9&lt;/td&gt; &#xA;    &lt;td&gt;29.69&lt;/td&gt; &#xA;    &lt;td&gt;23.06&lt;/td&gt; &#xA;    &lt;td&gt;16.33&lt;/td&gt; &#xA;    &lt;td&gt;15.73&lt;/td&gt; &#xA;    &lt;td&gt;9.5&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;    &lt;td&gt;4.29&lt;/td&gt; &#xA;    &lt;td&gt;22.08&lt;/td&gt; &#xA;    &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;MiniCPM-MoE-8x2B 模型评测&lt;/h4&gt; &#xA; &lt;div align=&#34;left&#34;&gt; &#xA;  &lt;table style=&#34;margin: 0px auto;&#34;&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;     &lt;th nowrap&gt;BBH&lt;/th&gt; &#xA;     &lt;th nowrap&gt;MMLU&lt;/th&gt; &#xA;     &lt;th nowrap&gt;CEval&lt;/th&gt; &#xA;     &lt;th nowrap&gt;CMMLU&lt;/th&gt; &#xA;     &lt;th nowrap&gt;HumanEval&lt;/th&gt; &#xA;     &lt;th nowrap&gt;MBPP†&lt;/th&gt; &#xA;     &lt;th nowrap&gt;GSM8K&lt;/th&gt; &#xA;     &lt;th nowrap&gt;MATH&lt;/th&gt; &#xA;    &lt;/tr&gt;&#xA;   &lt;/thead&gt; &#xA;   &lt;tbody align=&#34;center&#34;&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td nowrap align=&#34;left&#34;&gt;Llama2-34B*&lt;/td&gt; &#xA;     &lt;td&gt;44.1&lt;/td&gt; &#xA;     &lt;td&gt;62.6&lt;/td&gt; &#xA;     &lt;td&gt;-&lt;/td&gt; &#xA;     &lt;td&gt;-&lt;/td&gt; &#xA;     &lt;td&gt;22.6&lt;/td&gt; &#xA;     &lt;td&gt;33.0&lt;/td&gt; &#xA;     &lt;td&gt;42.2&lt;/td&gt; &#xA;     &lt;td&gt;6.24&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td nowrap align=&#34;left&#34;&gt;Mistral-7B-Instruct-v0.2&lt;/td&gt; &#xA;     &lt;td&gt;39.81&lt;/td&gt; &#xA;     &lt;td&gt;60.51&lt;/td&gt; &#xA;     &lt;td&gt;42.55&lt;/td&gt; &#xA;     &lt;td&gt;41.92&lt;/td&gt; &#xA;     &lt;td&gt;36.59&lt;/td&gt; &#xA;     &lt;td&gt;39.63&lt;/td&gt; &#xA;     &lt;td&gt;40.49&lt;/td&gt; &#xA;     &lt;td&gt;4.95&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td nowrap align=&#34;left&#34;&gt;Gemma-7B*&lt;/td&gt; &#xA;     &lt;td&gt;55.1&lt;/td&gt; &#xA;     &lt;td&gt;64.3&lt;/td&gt; &#xA;     &lt;td&gt;-&lt;/td&gt; &#xA;     &lt;td&gt;-&lt;/td&gt; &#xA;     &lt;td&gt;32.3&lt;/td&gt; &#xA;     &lt;td&gt;44.4&lt;/td&gt; &#xA;     &lt;td&gt;46.4&lt;/td&gt; &#xA;     &lt;td&gt;24.3&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td nowrap align=&#34;left&#34;&gt;Qwen1.5-7B*&lt;/td&gt; &#xA;     &lt;td&gt;40.2&lt;/td&gt; &#xA;     &lt;td&gt;61&lt;/td&gt; &#xA;     &lt;td&gt;74.1&lt;/td&gt; &#xA;     &lt;td&gt;73.1&lt;/td&gt; &#xA;     &lt;td&gt;36&lt;/td&gt; &#xA;     &lt;td&gt;37.4&lt;/td&gt; &#xA;     &lt;td&gt;62.5&lt;/td&gt; &#xA;     &lt;td&gt;20.3&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td nowrap align=&#34;left&#34;&gt;Deepseek-MoE(16B)*&lt;/td&gt; &#xA;     &lt;td&gt;-&lt;/td&gt; &#xA;     &lt;td&gt;45.0&lt;/td&gt; &#xA;     &lt;td&gt;40.6&lt;/td&gt; &#xA;     &lt;td&gt;42.5&lt;/td&gt; &#xA;     &lt;td&gt;26.8&lt;/td&gt; &#xA;     &lt;td&gt;39.2&lt;/td&gt; &#xA;     &lt;td&gt;18.8&lt;/td&gt; &#xA;     &lt;td&gt;4.3&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td nowrap align=&#34;left&#34;&gt;&lt;b&gt;MiniCPM-2.4B&lt;/b&gt;&lt;/td&gt; &#xA;     &lt;td&gt;36.87&lt;/td&gt; &#xA;     &lt;td&gt;53.46&lt;/td&gt; &#xA;     &lt;td&gt;51.13&lt;/td&gt; &#xA;     &lt;td&gt;51.07&lt;/td&gt; &#xA;     &lt;td&gt;50.00&lt;/td&gt; &#xA;     &lt;td&gt;35.93&lt;/td&gt; &#xA;     &lt;td&gt;53.83&lt;/td&gt; &#xA;     &lt;td&gt;10.24&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td nowrap align=&#34;left&#34;&gt;&lt;b&gt;MiniCPM-MoE-8x2B&lt;/b&gt;&lt;/td&gt; &#xA;     &lt;td&gt;39.22&lt;/td&gt; &#xA;     &lt;td&gt;58.90&lt;/td&gt; &#xA;     &lt;td&gt;58.11&lt;/td&gt; &#xA;     &lt;td&gt;58.80&lt;/td&gt; &#xA;     &lt;td&gt;55.49&lt;/td&gt; &#xA;     &lt;td&gt;41.68&lt;/td&gt; &#xA;     &lt;td&gt;61.56&lt;/td&gt; &#xA;     &lt;td&gt;10.52&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &#xA; &lt;/div&gt; &#xA; &lt;p&gt;注：* 表示结果取自技术报告。† 表示评测集为MBPP全集。&lt;/p&gt; &#xA; &lt;h4&gt;MiniCPM-S-1B 评测结果&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;代码生成：在 HumanEval（0-shot）和 MBPP（3-shot）上的平均 pass@1 得分。&lt;/li&gt; &#xA;  &lt;li&gt;常识推理：在 PIQA、SIQA、HellaSwag、WinoGrande 和 COPA 上的平均 0-shot 准确率。&lt;/li&gt; &#xA;  &lt;li&gt;阅读理解：在 BoolQ、LAMBADA 和 TyDi QA 上的平均 0-shot 准确率。&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;其他测试集：我们报告在GSM8K（8-shot）、MMLU（5-shot）、BBH（3-shot）和 AGI-Eval（0-shot）上的平均准确率。&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Setting&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Average&lt;br&gt;Sparsity&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Average&lt;br&gt;Performance&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Code&lt;br&gt;Generation&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Commonsense&lt;br&gt;Reasoning&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Reading&lt;br&gt;Comprehension&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;GSM8K&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;MMLU&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;BBH&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;AGI Eval&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;LLaMA2-7B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;37.96&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;16.37&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;69.59&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;61.87&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;12.96&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;44.45&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;32.96&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;27.53&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;ReluLLaMA-7B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;66.98&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;37.62&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;15.85&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;69.64&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;70.54&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;5.84&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;38.64&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;35.07&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;27.73&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ProSparse-7B&lt;/strong&gt;*&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;88.11&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;38.31&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;19.47&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;66.29&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;63.33&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;12.74&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;45.21&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;33.59&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;27.55&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ProSparse-7B&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;89.32&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;38.46&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;19.42&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;66.27&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;63.50&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;12.13&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;45.48&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;34.99&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;27.46&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;LLaMA2-13B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;44.06&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;20.19&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;72.58&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;71.55&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;22.21&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;54.69&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;37.89&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;29.33&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;ReluLLaMA-13B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;71.56&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;42.74&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;20.19&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;70.44&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;73.29&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;18.50&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;50.58&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;37.97&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;28.22&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ProSparse-13B&lt;/strong&gt;*&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;87.97&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;45.07&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;29.03&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;69.75&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;67.54&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;25.40&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;54.78&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;40.20&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;28.76&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ProSparse-13B&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;88.80&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;44.90&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;28.42&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;69.76&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;66.91&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;26.31&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;54.35&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;39.90&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;28.67&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;MiniCPM-1B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;44.44&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;36.85&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;63.67&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;60.90&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;35.48&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;50.44&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;35.03&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;28.71&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;MiniCPM-S-1B&lt;/strong&gt;*&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;86.25&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;44.72&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;41.38&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;64.55&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;60.69&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;34.72&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;49.36&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;34.04&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;28.27&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;MiniCPM-S-1B&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;87.89&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;44.72&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;42.04&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;64.37&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;60.73&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;34.57&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;49.51&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;34.08&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;27.77&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;注：&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;ReluLLaMA-7B 和 ReluLLaMA-13B 的下载链接分别是 &lt;a href=&#34;https://huggingface.co/SparseLLM/ReluLLaMA-7B&#34;&gt;7B&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/SparseLLM/ReluLLaMA-13B&#34;&gt;13B&lt;/a&gt;。&#34;ProSparse-7B*&#34;、&#34;ProSparse-13B*&#34; 和 &#34;MiniCPM-S-1B*&#34; 代表没有激活阈值偏移的 ProSparse 版本。&lt;/li&gt; &#xA;  &lt;li&gt;对于 PIQA、SIQA、HellaSwag、WinoGrande、COPA、BoolQ、LAMBADA、TyDi QA 和 AGI-Eval，我们根据各个选项的 PPL 来进行答案选择。对于 GSM8K、MMLU 和 BBH，我们直接生成答案。&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;h3&gt;模型推理&lt;/h3&gt; &#xA; &lt;h4&gt;HuggingFace、vLLM推理&lt;/h4&gt; &#xA; &lt;p&gt;参考 MiniCPM 1.0 中的&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#huggingface-%E6%8E%A8%E7%90%86&#34;&gt;模型推理&lt;/a&gt;部分。&lt;/p&gt; &#xA; &lt;h4&gt;Powerinfer 推理&lt;/h4&gt; &#xA; &lt;p&gt;针对 MiniCPM-S-1B 模型，我们可以使用 Powerinfer 进行推理加速，使用方法如下：&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;保证cmake版本3.17以上，如果已经安装过，则跳过此步骤&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  # 下载安装包&#xA;  sudo wget https://cmake.org/files/v3.23/cmake-3.23.0.tar.gz&#xA;  # 解压安装包&#xA;  sudo tar -zxvf cmake-3.23.0.tar.gz&#xA;  # 配置安装环境&#xA;  sudo ./configure&#xA;  sudo make -j8&#xA;  # 编译安装&#xA;  sudo make install&#xA;  # 查看安装后版本&#xA;  cmake --version&#xA;  # 返回版本号则安装成功&#xA;  #cmake version 3.23.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ol start=&#34;2&#34;&gt; &#xA;  &lt;li&gt;安装powerinfer：&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  git clone https://github.com/SJTU-IPADS/PowerInfer&#xA;  cd PowerInfer&#xA;  pip install -r requirements.txt # install Python helpers&#39; dependencies&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ol start=&#34;3&#34;&gt; &#xA;  &lt;li&gt;cpu版本powerinfer编译,如果你的机器只有cpu，或者只想使用cpu进行推理，则运行以下命令：&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  cmake -S . -B build&#xA;  cmake --build build --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ol start=&#34;4&#34;&gt; &#xA;  &lt;li&gt;gpu版本powerinfer编译,如果你的机器有gpu，则可以运行以下命令：&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  cmake -S . -B build -DLLAMA_CUBLAS=ON&#xA;  cmake --build build --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ol start=&#34;5&#34;&gt; &#xA;  &lt;li&gt;获取稀疏模型&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://huggingface.co/openbmb/MiniCPM-S-1B-sft-gguf/tree/main&#xA;#or&#xA;git clone https://modelscope.cn/models/OpenBMB/MiniCPM-S-1B-sft-gguf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ol start=&#34;6&#34;&gt; &#xA;  &lt;li&gt;模型推理：&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd PowerInfer&#xA;# 以下是命令模版，output_token_count为最大输出tokens，thread_num 为线程数，prompt为输入prompt字符&#xA;#./build/bin/main -m /PATH/TO/MODEL -n $output_token_count -t $thread_num -p $prompt&#xA;# 以下是示例&#xA;./build/bin/main -m /root/ld/ld_model_pretrain/1b-s-minicpm/MiniCPM-S-1B-sft.gguf -n 2048 -t 8 -p &#39;&amp;lt;用户&amp;gt;hello,tell me a story please.&amp;lt;AI&amp;gt;&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;MiniCPM 1.0&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;查看 MiniCPM 1.0 的详细信息&lt;/summary&gt; &#xA; &lt;p&gt;MiniCPM-2B 语言模型有 24亿（2.4B）的非词嵌入参数量, 总计 2.7B 参数量。&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;经过 SFT 后，MiniCPM-2B 在公开评测集上与 Mistral-7B 表现相近（中文、数学、代码能力更优），整体性能超越 Llama2-13B、MPT-30B、Falcon-40B 等模型。&lt;/li&gt; &#xA;  &lt;li&gt;经过 DPO 后，MiniCPM-2B 在 MTBench 上也超越了 Llama2-70B-Chat、Vicuna-33B、Mistral-7B-Instruct-v0.1、Zephyr-7B-alpha 等众多代表性开源大模型。&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;注意：为了保证在学术研究用途上模型的通用性，我们&lt;strong&gt;未对 MiniCPM-2B 进行任何身份认同训练&lt;/strong&gt;。同时由于我们用 ShareGPT 开源语料作为部分训练数据，模型可能会输出类似 GPT 系列模型的身份认同信息。&lt;/p&gt; &#xA; &lt;h3&gt;评测结果&lt;/h3&gt; &#xA; &lt;h4&gt;评测设置&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;由于大模型评测难以统一，且大量评测也没有公开的prompt和测试代码，对于具体评测方式，我们只能尽量做到适合各类模型。&lt;/li&gt; &#xA;  &lt;li&gt;整体而言，我们测试时采用统一的prompt输入，并按照各模型对应的模板进行输入调整。&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;评测脚本及prompt已开源在我们的Github仓库中，也欢迎更多开发者来不断改进我们的评测方式。&lt;/strong&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;文本评测部分，采用了我们的开源大模型能力评测框架&lt;a href=&#34;https://github.com/OpenBMB/UltraEval&#34;&gt;UltraEval&lt;/a&gt;。以下为开源模型复现流程： &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;安装UltraEval &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/OpenBMB/UltraEval.git&#xA;cd UltraEval&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;      &lt;li&gt;下载相关数据并解压处理 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget -O RawData.zip &#34;https://cloud.tsinghua.edu.cn/f/71b5232264ae4833a4d0/?dl=1&#34;&#xA;unzip RawData.zip&#xA;python data_process.py&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;      &lt;li&gt;执行评测脚本(提供了模板，可自定义) &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bash run_eval.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;     &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;部署模式&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;因为MiniCPM采用Mup的结构，与现有模型在具体计算上有细微差别，我们是基于vllm=0.2.2版本进行了我们模型的实现。&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;对于非MiniCPM模型，我们采用了vllm=0.2.7的最新版本进行推理。&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;评测度量&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;对于QA任务（选择题任务），我们选用两种方式进行测试： &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;PPL：将选项作为题目生成的延续，并根据各个选项的PPL来进行答案选择；&lt;/li&gt; &#xA;    &lt;li&gt;第二种是直接生成答案选项。&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;对于不同模型，这两种方式得到的结果差异较大。MiniCPM两种模式上的结果较为接近，而Mistral-7B-v0.1等模型在PPL上表现较好，直接生成上效果较差。&lt;/li&gt; &#xA;  &lt;li&gt;在具体评测时，我们以两种评测方式得分的最高者为最终结果，以此保证对比的公平性(以下表格中*号表示采用PPL)。&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;文本模型评测&lt;/h4&gt; &#xA; &lt;p&gt;&lt;strong&gt;越级比较:&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;模型&lt;/th&gt; &#xA;    &lt;th&gt;平均分&lt;/th&gt; &#xA;    &lt;th&gt;英文均分&lt;/th&gt; &#xA;    &lt;th&gt;中文均分&lt;/th&gt; &#xA;    &lt;th&gt;C-Eval&lt;/th&gt; &#xA;    &lt;th&gt;CMMLU&lt;/th&gt; &#xA;    &lt;th&gt;MMLU&lt;/th&gt; &#xA;    &lt;th&gt;HumanEval&lt;/th&gt; &#xA;    &lt;th&gt;MBPP&lt;/th&gt; &#xA;    &lt;th&gt;GSM8K&lt;/th&gt; &#xA;    &lt;th&gt;MATH&lt;/th&gt; &#xA;    &lt;th&gt;BBH&lt;/th&gt; &#xA;    &lt;th&gt;ARC-E&lt;/th&gt; &#xA;    &lt;th&gt;ARC-C&lt;/th&gt; &#xA;    &lt;th&gt;HellaSwag&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Llama2-7B&lt;/td&gt; &#xA;    &lt;td&gt;35.40&lt;/td&gt; &#xA;    &lt;td&gt;36.21&lt;/td&gt; &#xA;    &lt;td&gt;31.765&lt;/td&gt; &#xA;    &lt;td&gt;32.42&lt;/td&gt; &#xA;    &lt;td&gt;31.11&lt;/td&gt; &#xA;    &lt;td&gt;44.32&lt;/td&gt; &#xA;    &lt;td&gt;12.2&lt;/td&gt; &#xA;    &lt;td&gt;27.17&lt;/td&gt; &#xA;    &lt;td&gt;13.57&lt;/td&gt; &#xA;    &lt;td&gt;1.8&lt;/td&gt; &#xA;    &lt;td&gt;33.23&lt;/td&gt; &#xA;    &lt;td&gt;75.25&lt;/td&gt; &#xA;    &lt;td&gt;42.75&lt;/td&gt; &#xA;    &lt;td&gt;75.62*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Qwen-7B&lt;/td&gt; &#xA;    &lt;td&gt;49.46&lt;/td&gt; &#xA;    &lt;td&gt;47.19&lt;/td&gt; &#xA;    &lt;td&gt;59.655&lt;/td&gt; &#xA;    &lt;td&gt;58.96&lt;/td&gt; &#xA;    &lt;td&gt;60.35&lt;/td&gt; &#xA;    &lt;td&gt;57.65&lt;/td&gt; &#xA;    &lt;td&gt;17.07&lt;/td&gt; &#xA;    &lt;td&gt;42.15&lt;/td&gt; &#xA;    &lt;td&gt;41.24&lt;/td&gt; &#xA;    &lt;td&gt;5.34&lt;/td&gt; &#xA;    &lt;td&gt;37.75&lt;/td&gt; &#xA;    &lt;td&gt;83.42&lt;/td&gt; &#xA;    &lt;td&gt;64.76&lt;/td&gt; &#xA;    &lt;td&gt;75.32*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Deepseek-7B&lt;/td&gt; &#xA;    &lt;td&gt;39.96&lt;/td&gt; &#xA;    &lt;td&gt;39.15&lt;/td&gt; &#xA;    &lt;td&gt;43.64&lt;/td&gt; &#xA;    &lt;td&gt;42.82&lt;/td&gt; &#xA;    &lt;td&gt;44.45&lt;/td&gt; &#xA;    &lt;td&gt;47.82&lt;/td&gt; &#xA;    &lt;td&gt;20.12&lt;/td&gt; &#xA;    &lt;td&gt;41.45&lt;/td&gt; &#xA;    &lt;td&gt;15.85&lt;/td&gt; &#xA;    &lt;td&gt;1.53&lt;/td&gt; &#xA;    &lt;td&gt;33.38&lt;/td&gt; &#xA;    &lt;td&gt;74.58*&lt;/td&gt; &#xA;    &lt;td&gt;42.15*&lt;/td&gt; &#xA;    &lt;td&gt;75.45*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Mistral-7B&lt;/td&gt; &#xA;    &lt;td&gt;48.97&lt;/td&gt; &#xA;    &lt;td&gt;49.96&lt;/td&gt; &#xA;    &lt;td&gt;44.54&lt;/td&gt; &#xA;    &lt;td&gt;46.12&lt;/td&gt; &#xA;    &lt;td&gt;42.96&lt;/td&gt; &#xA;    &lt;td&gt;62.69&lt;/td&gt; &#xA;    &lt;td&gt;27.44&lt;/td&gt; &#xA;    &lt;td&gt;45.2&lt;/td&gt; &#xA;    &lt;td&gt;33.13&lt;/td&gt; &#xA;    &lt;td&gt;5.0&lt;/td&gt; &#xA;    &lt;td&gt;41.06&lt;/td&gt; &#xA;    &lt;td&gt;83.92&lt;/td&gt; &#xA;    &lt;td&gt;70.73&lt;/td&gt; &#xA;    &lt;td&gt;80.43*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Llama2-13B&lt;/td&gt; &#xA;    &lt;td&gt;41.48&lt;/td&gt; &#xA;    &lt;td&gt;42.44&lt;/td&gt; &#xA;    &lt;td&gt;37.19&lt;/td&gt; &#xA;    &lt;td&gt;37.32&lt;/td&gt; &#xA;    &lt;td&gt;37.06&lt;/td&gt; &#xA;    &lt;td&gt;54.71&lt;/td&gt; &#xA;    &lt;td&gt;17.07&lt;/td&gt; &#xA;    &lt;td&gt;32.55&lt;/td&gt; &#xA;    &lt;td&gt;21.15&lt;/td&gt; &#xA;    &lt;td&gt;2.25&lt;/td&gt; &#xA;    &lt;td&gt;37.92&lt;/td&gt; &#xA;    &lt;td&gt;78.87*&lt;/td&gt; &#xA;    &lt;td&gt;58.19&lt;/td&gt; &#xA;    &lt;td&gt;79.23*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;MPT-30B&lt;/td&gt; &#xA;    &lt;td&gt;38.17&lt;/td&gt; &#xA;    &lt;td&gt;39.82&lt;/td&gt; &#xA;    &lt;td&gt;30.72&lt;/td&gt; &#xA;    &lt;td&gt;29.34&lt;/td&gt; &#xA;    &lt;td&gt;32.09&lt;/td&gt; &#xA;    &lt;td&gt;46.56&lt;/td&gt; &#xA;    &lt;td&gt;21.95&lt;/td&gt; &#xA;    &lt;td&gt;35.36&lt;/td&gt; &#xA;    &lt;td&gt;10.31&lt;/td&gt; &#xA;    &lt;td&gt;1.56&lt;/td&gt; &#xA;    &lt;td&gt;38.22&lt;/td&gt; &#xA;    &lt;td&gt;78.66*&lt;/td&gt; &#xA;    &lt;td&gt;46.08*&lt;/td&gt; &#xA;    &lt;td&gt;79.72*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Falcon-40B&lt;/td&gt; &#xA;    &lt;td&gt;43.62&lt;/td&gt; &#xA;    &lt;td&gt;44.21&lt;/td&gt; &#xA;    &lt;td&gt;40.93&lt;/td&gt; &#xA;    &lt;td&gt;40.29&lt;/td&gt; &#xA;    &lt;td&gt;41.57&lt;/td&gt; &#xA;    &lt;td&gt;53.53&lt;/td&gt; &#xA;    &lt;td&gt;24.39&lt;/td&gt; &#xA;    &lt;td&gt;36.53&lt;/td&gt; &#xA;    &lt;td&gt;22.44&lt;/td&gt; &#xA;    &lt;td&gt;1.92&lt;/td&gt; &#xA;    &lt;td&gt;36.24&lt;/td&gt; &#xA;    &lt;td&gt;81.94*&lt;/td&gt; &#xA;    &lt;td&gt;57.68&lt;/td&gt; &#xA;    &lt;td&gt;83.26*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;MiniCPM-2B&lt;/td&gt; &#xA;    &lt;td&gt;52.33&lt;/td&gt; &#xA;    &lt;td&gt;52.6&lt;/td&gt; &#xA;    &lt;td&gt;51.1&lt;/td&gt; &#xA;    &lt;td&gt;51.13&lt;/td&gt; &#xA;    &lt;td&gt;51.07&lt;/td&gt; &#xA;    &lt;td&gt;53.46&lt;/td&gt; &#xA;    &lt;td&gt;50.00&lt;/td&gt; &#xA;    &lt;td&gt;47.31&lt;/td&gt; &#xA;    &lt;td&gt;53.83&lt;/td&gt; &#xA;    &lt;td&gt;10.24&lt;/td&gt; &#xA;    &lt;td&gt;36.87&lt;/td&gt; &#xA;    &lt;td&gt;85.44&lt;/td&gt; &#xA;    &lt;td&gt;68.00&lt;/td&gt; &#xA;    &lt;td&gt;68.25&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;&lt;strong&gt;同级比较：&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;模型&lt;/th&gt; &#xA;    &lt;th&gt;平均分&lt;/th&gt; &#xA;    &lt;th&gt;英文均分&lt;/th&gt; &#xA;    &lt;th&gt;中文均分&lt;/th&gt; &#xA;    &lt;th&gt;C-Eval&lt;/th&gt; &#xA;    &lt;th&gt;CMMLU&lt;/th&gt; &#xA;    &lt;th&gt;MMLU&lt;/th&gt; &#xA;    &lt;th&gt;HumanEval&lt;/th&gt; &#xA;    &lt;th&gt;MBPP&lt;/th&gt; &#xA;    &lt;th&gt;GSM8K&lt;/th&gt; &#xA;    &lt;th&gt;MATH&lt;/th&gt; &#xA;    &lt;th&gt;BBH&lt;/th&gt; &#xA;    &lt;th&gt;ARC-E&lt;/th&gt; &#xA;    &lt;th&gt;ARC-C&lt;/th&gt; &#xA;    &lt;th&gt;HellaSwag&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;TinyLlama-1.1B&lt;/td&gt; &#xA;    &lt;td&gt;25.36&lt;/td&gt; &#xA;    &lt;td&gt;25.55&lt;/td&gt; &#xA;    &lt;td&gt;24.525&lt;/td&gt; &#xA;    &lt;td&gt;25.02&lt;/td&gt; &#xA;    &lt;td&gt;24.03&lt;/td&gt; &#xA;    &lt;td&gt;24.3&lt;/td&gt; &#xA;    &lt;td&gt;6.71&lt;/td&gt; &#xA;    &lt;td&gt;19.91&lt;/td&gt; &#xA;    &lt;td&gt;2.27&lt;/td&gt; &#xA;    &lt;td&gt;0.74&lt;/td&gt; &#xA;    &lt;td&gt;28.78&lt;/td&gt; &#xA;    &lt;td&gt;60.77*&lt;/td&gt; &#xA;    &lt;td&gt;28.15*&lt;/td&gt; &#xA;    &lt;td&gt;58.33*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Qwen-1.8B&lt;/td&gt; &#xA;    &lt;td&gt;34.72&lt;/td&gt; &#xA;    &lt;td&gt;31.87&lt;/td&gt; &#xA;    &lt;td&gt;47.57&lt;/td&gt; &#xA;    &lt;td&gt;49.81&lt;/td&gt; &#xA;    &lt;td&gt;45.32&lt;/td&gt; &#xA;    &lt;td&gt;43.37&lt;/td&gt; &#xA;    &lt;td&gt;7.93&lt;/td&gt; &#xA;    &lt;td&gt;17.80&lt;/td&gt; &#xA;    &lt;td&gt;19.26&lt;/td&gt; &#xA;    &lt;td&gt;2.42&lt;/td&gt; &#xA;    &lt;td&gt;29.07&lt;/td&gt; &#xA;    &lt;td&gt;63.97*&lt;/td&gt; &#xA;    &lt;td&gt;43.69&lt;/td&gt; &#xA;    &lt;td&gt;59.28*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Gemini Nano-3B&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;27.2(report)&lt;/td&gt; &#xA;    &lt;td&gt;22.8(report)&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;42.4(report)&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;StableLM-Zephyr-3B&lt;/td&gt; &#xA;    &lt;td&gt;43.46&lt;/td&gt; &#xA;    &lt;td&gt;46.31&lt;/td&gt; &#xA;    &lt;td&gt;30.62&lt;/td&gt; &#xA;    &lt;td&gt;30.34&lt;/td&gt; &#xA;    &lt;td&gt;30.89&lt;/td&gt; &#xA;    &lt;td&gt;45.9&lt;/td&gt; &#xA;    &lt;td&gt;35.37&lt;/td&gt; &#xA;    &lt;td&gt;31.85&lt;/td&gt; &#xA;    &lt;td&gt;52.54&lt;/td&gt; &#xA;    &lt;td&gt;12.49&lt;/td&gt; &#xA;    &lt;td&gt;37.68&lt;/td&gt; &#xA;    &lt;td&gt;73.78&lt;/td&gt; &#xA;    &lt;td&gt;55.38&lt;/td&gt; &#xA;    &lt;td&gt;71.87*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Phi-2-2B&lt;/td&gt; &#xA;    &lt;td&gt;48.84&lt;/td&gt; &#xA;    &lt;td&gt;54.41&lt;/td&gt; &#xA;    &lt;td&gt;23.78&lt;/td&gt; &#xA;    &lt;td&gt;23.37&lt;/td&gt; &#xA;    &lt;td&gt;24.18&lt;/td&gt; &#xA;    &lt;td&gt;52.66&lt;/td&gt; &#xA;    &lt;td&gt;47.56&lt;/td&gt; &#xA;    &lt;td&gt;55.04&lt;/td&gt; &#xA;    &lt;td&gt;57.16&lt;/td&gt; &#xA;    &lt;td&gt;3.5&lt;/td&gt; &#xA;    &lt;td&gt;43.39&lt;/td&gt; &#xA;    &lt;td&gt;86.11&lt;/td&gt; &#xA;    &lt;td&gt;71.25&lt;/td&gt; &#xA;    &lt;td&gt;73.07*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;MiniCPM-2B&lt;/td&gt; &#xA;    &lt;td&gt;52.33&lt;/td&gt; &#xA;    &lt;td&gt;52.6&lt;/td&gt; &#xA;    &lt;td&gt;51.10&lt;/td&gt; &#xA;    &lt;td&gt;51.13&lt;/td&gt; &#xA;    &lt;td&gt;51.07&lt;/td&gt; &#xA;    &lt;td&gt;53.46&lt;/td&gt; &#xA;    &lt;td&gt;50.00&lt;/td&gt; &#xA;    &lt;td&gt;47.31&lt;/td&gt; &#xA;    &lt;td&gt;53.83&lt;/td&gt; &#xA;    &lt;td&gt;10.24&lt;/td&gt; &#xA;    &lt;td&gt;36.87&lt;/td&gt; &#xA;    &lt;td&gt;85.44&lt;/td&gt; &#xA;    &lt;td&gt;68.00&lt;/td&gt; &#xA;    &lt;td&gt;68.25&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;&lt;strong&gt;Chat模型比较：&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;模型&lt;/th&gt; &#xA;    &lt;th&gt;平均分&lt;/th&gt; &#xA;    &lt;th&gt;英文均分&lt;/th&gt; &#xA;    &lt;th&gt;中文均分&lt;/th&gt; &#xA;    &lt;th&gt;C-Eval&lt;/th&gt; &#xA;    &lt;th&gt;CMMLU&lt;/th&gt; &#xA;    &lt;th&gt;MMLU&lt;/th&gt; &#xA;    &lt;th&gt;HumanEval&lt;/th&gt; &#xA;    &lt;th&gt;MBPP&lt;/th&gt; &#xA;    &lt;th&gt;GSM8K&lt;/th&gt; &#xA;    &lt;th&gt;MATH&lt;/th&gt; &#xA;    &lt;th&gt;BBH&lt;/th&gt; &#xA;    &lt;th&gt;ARC-E&lt;/th&gt; &#xA;    &lt;th&gt;ARC-C&lt;/th&gt; &#xA;    &lt;th&gt;HellaSwag&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;    &lt;td&gt;37.98&lt;/td&gt; &#xA;    &lt;td&gt;35.17&lt;/td&gt; &#xA;    &lt;td&gt;50.63&lt;/td&gt; &#xA;    &lt;td&gt;52.05&lt;/td&gt; &#xA;    &lt;td&gt;49.21&lt;/td&gt; &#xA;    &lt;td&gt;45.77&lt;/td&gt; &#xA;    &lt;td&gt;10.37&lt;/td&gt; &#xA;    &lt;td&gt;9.38&lt;/td&gt; &#xA;    &lt;td&gt;22.74&lt;/td&gt; &#xA;    &lt;td&gt;5.96&lt;/td&gt; &#xA;    &lt;td&gt;32.6&lt;/td&gt; &#xA;    &lt;td&gt;74.45&lt;/td&gt; &#xA;    &lt;td&gt;56.82&lt;/td&gt; &#xA;    &lt;td&gt;58.48*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Mistral-7B-Instruct-v0.1&lt;/td&gt; &#xA;    &lt;td&gt;44.36&lt;/td&gt; &#xA;    &lt;td&gt;45.89&lt;/td&gt; &#xA;    &lt;td&gt;37.51&lt;/td&gt; &#xA;    &lt;td&gt;38.06&lt;/td&gt; &#xA;    &lt;td&gt;36.96&lt;/td&gt; &#xA;    &lt;td&gt;53.56&lt;/td&gt; &#xA;    &lt;td&gt;29.27&lt;/td&gt; &#xA;    &lt;td&gt;39.34&lt;/td&gt; &#xA;    &lt;td&gt;28.73&lt;/td&gt; &#xA;    &lt;td&gt;3.48&lt;/td&gt; &#xA;    &lt;td&gt;39.52&lt;/td&gt; &#xA;    &lt;td&gt;81.61&lt;/td&gt; &#xA;    &lt;td&gt;63.99&lt;/td&gt; &#xA;    &lt;td&gt;73.47*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Mistral-7B-Instruct-v0.2&lt;/td&gt; &#xA;    &lt;td&gt;50.91&lt;/td&gt; &#xA;    &lt;td&gt;52.83&lt;/td&gt; &#xA;    &lt;td&gt;42.235&lt;/td&gt; &#xA;    &lt;td&gt;42.55&lt;/td&gt; &#xA;    &lt;td&gt;41.92&lt;/td&gt; &#xA;    &lt;td&gt;60.51&lt;/td&gt; &#xA;    &lt;td&gt;36.59&lt;/td&gt; &#xA;    &lt;td&gt;48.95&lt;/td&gt; &#xA;    &lt;td&gt;40.49&lt;/td&gt; &#xA;    &lt;td&gt;4.95&lt;/td&gt; &#xA;    &lt;td&gt;39.81&lt;/td&gt; &#xA;    &lt;td&gt;86.28&lt;/td&gt; &#xA;    &lt;td&gt;73.38&lt;/td&gt; &#xA;    &lt;td&gt;84.55*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Qwen-7B-Chat&lt;/td&gt; &#xA;    &lt;td&gt;44.93&lt;/td&gt; &#xA;    &lt;td&gt;42.05&lt;/td&gt; &#xA;    &lt;td&gt;57.9&lt;/td&gt; &#xA;    &lt;td&gt;58.57&lt;/td&gt; &#xA;    &lt;td&gt;57.23&lt;/td&gt; &#xA;    &lt;td&gt;56.03&lt;/td&gt; &#xA;    &lt;td&gt;15.85&lt;/td&gt; &#xA;    &lt;td&gt;40.52&lt;/td&gt; &#xA;    &lt;td&gt;42.23&lt;/td&gt; &#xA;    &lt;td&gt;8.3&lt;/td&gt; &#xA;    &lt;td&gt;37.34&lt;/td&gt; &#xA;    &lt;td&gt;64.44*&lt;/td&gt; &#xA;    &lt;td&gt;39.25*&lt;/td&gt; &#xA;    &lt;td&gt;74.52*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Yi-6B-Chat&lt;/td&gt; &#xA;    &lt;td&gt;50.46&lt;/td&gt; &#xA;    &lt;td&gt;45.89&lt;/td&gt; &#xA;    &lt;td&gt;70.995&lt;/td&gt; &#xA;    &lt;td&gt;70.88&lt;/td&gt; &#xA;    &lt;td&gt;71.11&lt;/td&gt; &#xA;    &lt;td&gt;62.95&lt;/td&gt; &#xA;    &lt;td&gt;14.02&lt;/td&gt; &#xA;    &lt;td&gt;28.34&lt;/td&gt; &#xA;    &lt;td&gt;36.54&lt;/td&gt; &#xA;    &lt;td&gt;3.88&lt;/td&gt; &#xA;    &lt;td&gt;37.43&lt;/td&gt; &#xA;    &lt;td&gt;84.89&lt;/td&gt; &#xA;    &lt;td&gt;70.39&lt;/td&gt; &#xA;    &lt;td&gt;74.6*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Baichuan2-7B-Chat&lt;/td&gt; &#xA;    &lt;td&gt;44.68&lt;/td&gt; &#xA;    &lt;td&gt;42.74&lt;/td&gt; &#xA;    &lt;td&gt;53.39&lt;/td&gt; &#xA;    &lt;td&gt;53.28&lt;/td&gt; &#xA;    &lt;td&gt;53.5&lt;/td&gt; &#xA;    &lt;td&gt;53&lt;/td&gt; &#xA;    &lt;td&gt;21.34&lt;/td&gt; &#xA;    &lt;td&gt;32.32&lt;/td&gt; &#xA;    &lt;td&gt;25.25&lt;/td&gt; &#xA;    &lt;td&gt;6.32&lt;/td&gt; &#xA;    &lt;td&gt;37.46&lt;/td&gt; &#xA;    &lt;td&gt;79.63&lt;/td&gt; &#xA;    &lt;td&gt;60.15&lt;/td&gt; &#xA;    &lt;td&gt;69.23*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Deepseek-7B-chat&lt;/td&gt; &#xA;    &lt;td&gt;49.34&lt;/td&gt; &#xA;    &lt;td&gt;49.56&lt;/td&gt; &#xA;    &lt;td&gt;48.335&lt;/td&gt; &#xA;    &lt;td&gt;46.95&lt;/td&gt; &#xA;    &lt;td&gt;49.72&lt;/td&gt; &#xA;    &lt;td&gt;51.67&lt;/td&gt; &#xA;    &lt;td&gt;40.85&lt;/td&gt; &#xA;    &lt;td&gt;48.48&lt;/td&gt; &#xA;    &lt;td&gt;48.52&lt;/td&gt; &#xA;    &lt;td&gt;4.26&lt;/td&gt; &#xA;    &lt;td&gt;35.7&lt;/td&gt; &#xA;    &lt;td&gt;76.85&lt;/td&gt; &#xA;    &lt;td&gt;63.05&lt;/td&gt; &#xA;    &lt;td&gt;76.68*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Llama2-7B-Chat&lt;/td&gt; &#xA;    &lt;td&gt;38.16&lt;/td&gt; &#xA;    &lt;td&gt;39.17&lt;/td&gt; &#xA;    &lt;td&gt;33.59&lt;/td&gt; &#xA;    &lt;td&gt;34.54&lt;/td&gt; &#xA;    &lt;td&gt;32.64&lt;/td&gt; &#xA;    &lt;td&gt;47.64&lt;/td&gt; &#xA;    &lt;td&gt;14.02&lt;/td&gt; &#xA;    &lt;td&gt;27.4&lt;/td&gt; &#xA;    &lt;td&gt;21.15&lt;/td&gt; &#xA;    &lt;td&gt;2.08&lt;/td&gt; &#xA;    &lt;td&gt;35.54&lt;/td&gt; &#xA;    &lt;td&gt;74.28&lt;/td&gt; &#xA;    &lt;td&gt;54.78&lt;/td&gt; &#xA;    &lt;td&gt;75.65*&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;MiniCPM-2B&lt;/td&gt; &#xA;    &lt;td&gt;52.33&lt;/td&gt; &#xA;    &lt;td&gt;52.6&lt;/td&gt; &#xA;    &lt;td&gt;51.10&lt;/td&gt; &#xA;    &lt;td&gt;51.13&lt;/td&gt; &#xA;    &lt;td&gt;51.07&lt;/td&gt; &#xA;    &lt;td&gt;53.46&lt;/td&gt; &#xA;    &lt;td&gt;50.00&lt;/td&gt; &#xA;    &lt;td&gt;47.31&lt;/td&gt; &#xA;    &lt;td&gt;53.83&lt;/td&gt; &#xA;    &lt;td&gt;10.24&lt;/td&gt; &#xA;    &lt;td&gt;36.87&lt;/td&gt; &#xA;    &lt;td&gt;85.44&lt;/td&gt; &#xA;    &lt;td&gt;68.00&lt;/td&gt; &#xA;    &lt;td&gt;68.25&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;&lt;strong&gt;DPO后模型比较：&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;模型&lt;/th&gt; &#xA;    &lt;th&gt;MT-bench&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;GPT-4-turbo&lt;/td&gt; &#xA;    &lt;td&gt;9.32&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;GPT-3.5-turbo&lt;/td&gt; &#xA;    &lt;td&gt;8.39&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Mistral-8*7b-Instruct-v0.1&lt;/td&gt; &#xA;    &lt;td&gt;8.30&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Claude-2.1&lt;/td&gt; &#xA;    &lt;td&gt;8.18&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Zephyr-7B-beta&lt;/td&gt; &#xA;    &lt;td&gt;7.34&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;strong&gt;MiniCPM-2B&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;7.25&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Vicuna-33B&lt;/td&gt; &#xA;    &lt;td&gt;7.12&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Zephyr-7B-alpha&lt;/td&gt; &#xA;    &lt;td&gt;6.88&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;LLaMA-2-70B-chat&lt;/td&gt; &#xA;    &lt;td&gt;6.86&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Mistral-7B-Instruct-v0.1&lt;/td&gt; &#xA;    &lt;td&gt;6.84&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;MPT-34B-instruct&lt;/td&gt; &#xA;    &lt;td&gt;6.39&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;快速上手&lt;/h3&gt; &#xA; &lt;h4&gt;在线体验&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1tJcfPyWGWA5HezO7GKLeyeIso0HyOc0l?usp=sharing&#34;&gt;Colab&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;基于Gradio的网页版Demo&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;使用如下命令启动基于Gradio的网页版demo：&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# generation powered by vllm&#xA;python demo/minicpm/vllm_based_demo.py --model_path &amp;lt;vllmcpm_repo_path&amp;gt;&#xA;# generation powered by huggingface&#xA;python demo/minicpm/hf_based_demo.py --model_path &amp;lt;hf_repo_path&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;HuggingFace 推理&lt;/h4&gt; &#xA; &lt;h5&gt;MiniCPM-2B&lt;/h5&gt; &#xA; &lt;p&gt;安装&lt;code&gt;transformers&amp;gt;=4.36.0&lt;/code&gt;以及&lt;code&gt;accelerate&lt;/code&gt;后，运行以下代码：&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;import torch&#xA;torch.manual_seed(0)&#xA;&#xA;path = &#39;openbmb/MiniCPM-2B-dpo-bf16&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(path)&#xA;model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map=&#39;cuda&#39;, trust_remote_code=True)&#xA;&#xA;responds, history = model.chat(tokenizer, &#34;山东省最高的山是哪座山, 它比黄山高还是矮？差距多少？&#34;, temperature=0.5, top_p=0.8, repetition_penalty=1.02)&#xA;print(responds)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h5&gt;MiniCPM-2B （Llama Format）&lt;/h5&gt; &#xA; &lt;p&gt;我们将MiniCPM的模型权重转化成了Llama代码可以直接调用的&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16-llama-format&#34;&gt;格式&lt;/a&gt;，以便大家尝试:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import LlamaTokenizerFast, LlamaForCausalLM&#xA;model_path = &#34;openbmb/MiniCPM-2B-dpo-bf16-llama-format&#34;&#xA;tokenizer = LlamaTokenizerFast.from_pretrained(model_path)&#xA;model = LlamaForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, device_map=&#39;cuda&#39;, trust_remote_code=True)&#xA;&#xA;prompt=&#34;Now you act like a terminal situated within a beginner&#39;s C++ practice repository folder, please provide the output for the command: `ls -l`&#34;&#xA;input_ids = tokenizer.encode(&#34;&amp;lt;用户&amp;gt;{}&amp;lt;AI&amp;gt;&#34;.format(prompt), return_tensors=&#39;pt&#39;, add_special_tokens=True).cuda()&#xA;responds = model.generate(input_ids, temperature=0.3, top_p=0.8, repetition_penalty=1.02, max_length=1024)&#xA;responds = tokenizer.decode(responds[0], skip_special_tokens=True)&#xA;print(responds)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;vLLM 推理&lt;/h4&gt; &#xA; &lt;p&gt;安装 &lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt;。&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#34;vllm&amp;gt;=0.4.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;具体推理代码见&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#vllm&#34;&gt;这里&lt;/a&gt;。&lt;/p&gt; &#xA; &lt;h4&gt;SGLang 推理&lt;/h4&gt; &#xA; &lt;p&gt;安装 &lt;a href=&#34;https://github.com/sgl-project/sglang&#34;&gt;SGLang&lt;/a&gt;。&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;首先需要启动一个服务:&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m sglang.launch_server --model-path openbmb/MiniCPM-2B-dpo-fp16 --trust-remote-code --port 30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;下面是一个推理代码的样例:&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sglang import function, gen, set_default_backend, RuntimeEndpoint&#xA;&#xA;@function&#xA;def text_qa(s, question):&#xA;    s += &#34;&amp;lt;用户&amp;gt;&#34; + question + &#34;&amp;lt;AI&amp;gt;&#34;&#xA;    s += gen(&#34;answer&#34;, max_tokens=1024, temperature=0.7, top_p=0.7)&#xA;&#xA;set_default_backend(RuntimeEndpoint(&#34;http://localhost:30000&#34;))&#xA;&#xA;state = text_qa.run(&#xA;    question=&#34;What is the capital of China?&#34;,&#xA;)&#xA;&#xA;print(state[&#34;answer&#34;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;llama.cpp、Ollama、fastllm、mlx_lm推理&lt;/h4&gt; &#xA; &lt;p&gt;MiniCPM支持&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/&#34;&gt;llama.cpp&lt;/a&gt; 、&lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;ollama&lt;/a&gt;、&lt;a href=&#34;https://github.com/ztxz16/fastllm&#34;&gt;fastllm&lt;/a&gt;、&lt;a href=&#34;https://github.com/ml-explore/mlx-examples&#34;&gt;mlx_lm&lt;/a&gt;推理。感谢&lt;a href=&#34;https://github.com/runfuture&#34;&gt;@runfuture&lt;/a&gt;对llama.cpp和ollama的适配。&lt;/p&gt; &#xA; &lt;p&gt;请参考 MiniCPM 知识库中的&lt;a href=&#34;https://modelbest.feishu.cn/wiki/EatbwdLuvitbbMk2X5wcX6h5n7c&#34;&gt;量化指南&lt;/a&gt;。&lt;/p&gt; &#xA; &lt;h4&gt;模型微调&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;一张 1080/2080 可实现高效参数微调：&lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/tree/main/finetune&#34;&gt;代码&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;mlx 微调：&lt;a href=&#34;https://modelbest.feishu.cn/wiki/AIU3wbREcirOm9kkvd7cxujFnMb#share-ASrDdvFAloHtycxfy85cLNhAnd3&#34;&gt;教程&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/InternLM/xtuner&#34;&gt;xtuner&lt;/a&gt;: &lt;a href=&#34;https://modelbest.feishu.cn/wiki/AIU3wbREcirOm9kkvd7cxujFnMb#AMdXdzz8qoadZhxU4EucELWznzd&#34;&gt;MiniCPM高效率微调的不二选择&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory.git&#34;&gt;LLaMA-Factory&lt;/a&gt;：&lt;a href=&#34;https://modelbest.feishu.cn/wiki/AIU3wbREcirOm9kkvd7cxujFnMb#BAWrdSjXuoFvX4xuIuzc8Amln5E&#34;&gt;MiniCPM微调一键式解决方案&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;开源协议&lt;/h2&gt; &#xA;&lt;h4&gt;模型协议&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;本仓库中代码依照 &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/LICENSE&#34;&gt;Apache-2.0&lt;/a&gt; 协议开源&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM 模型权重的使用则需要遵循 &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/MiniCPM%E6%A8%A1%E5%9E%8B%E5%95%86%E7%94%A8%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.md&#34;&gt;MiniCPM 模型商用许可协议&lt;/a&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM 模型权重对学术研究完全开放，在填写&lt;a href=&#34;https://modelbest.feishu.cn/share/base/form/shrcnpV5ZT9EJ6xYjh3Kx0J6v8g&#34;&gt;问卷&lt;/a&gt;进行登记后亦允许免费商业使用。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;声明&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;作为一个语言模型，MiniCPM 通过学习大量的文本来生成内容，但它无法理解、表达个人观点或价值判断，它所输出的任何内容都不代表模型开发者的观点和立场。&lt;/li&gt; &#xA; &lt;li&gt;因此用户在使用 MiniCPM 生成的内容时，应自行负责对其进行评估和验证。&lt;/li&gt; &#xA; &lt;li&gt;如果由于使用 MiniCPM 开源模型而导致的任何问题，包括但不限于数据安全问题、公共舆论风险，或模型被误导、滥用、传播或不当利用所带来的任何风险和问题，我们将不承担任何责任。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;开发机构&lt;/h2&gt; &#xA;&lt;p&gt;本项目由以下机构共同开发：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/modelbest.png&#34; width=&#34;28px&#34;&gt; &lt;a href=&#34;https://modelbest.cn/&#34;&gt;面壁智能&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/thunlp.png&#34; width=&#34;28px&#34;&gt; &lt;a href=&#34;https://nlp.csai.tsinghua.edu.cn/&#34;&gt;清华大学自然语言处理实验室&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;工作引用&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;如果觉得MiniCPM有助于您的工作，请引用我们的&lt;a href=&#34;https://arxiv.org/abs/2404.06395&#34;&gt;论文&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{hu2024minicpm,&#xA;  title={MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies},&#xA;  author={Hu, Shengding and Tu, Yuge and Han, Xu and He, Chaoqun and Cui, Ganqu and Long, Xiang and Zheng, Zhi and Fang, Yewei and Huang, Yuxiang and Zhao, Weilin and others},&#xA;  journal={arXiv preprint arXiv:2404.06395},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>ChrisTitusTech/linutil</title>
    <updated>2024-09-15T01:41:17Z</updated>
    <id>tag:github.com,2024-09-15:/ChrisTitusTech/linutil</id>
    <link href="https://github.com/ChrisTitusTech/linutil" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Chris Titus Tech&#39;s Linux Toolbox - Linutil is a distro-agnostic toolbox designed to simplify everyday Linux tasks.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Chris Titus Tech&#39;s Linux Utility&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ChrisTitusTech/linutil/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/ChrisTitusTech/linutil?color=%230567ff&amp;amp;label=Latest%20Release&amp;amp;style=for-the-badge&#34; alt=&#34;Version&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/downloads/ChrisTitusTech/linutil/linutil?label=Total%20Downloads&amp;amp;style=for-the-badge&#34; alt=&#34;GitHub Downloads (specific asset, all releases)&#34;&gt; &lt;a href=&#34;https://discord.gg/bujFYKAHSp&#34;&gt;&lt;img src=&#34;https://dcbadge.limes.pink/api/server/https://discord.gg/bujFYKAHSp&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ChrisTitusTech/linutil/main/docs/assets/preview.png&#34; alt=&#34;Preview&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Linutil&lt;/strong&gt; is a distro-agnostic toolbox designed to simplify everyday Linux tasks. It helps you set up applications and optimize your system for specific use cases. The utility is actively developed in Rust 🦀, providing performance and reliability.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Since the project is still in active development, you may encounter some issues. Please consider &lt;a href=&#34;https://github.com/ChrisTitusTech/linutil/issues&#34;&gt;submitting feedback&lt;/a&gt; if you do.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;💡 Usage&lt;/h2&gt; &#xA;&lt;p&gt;To get started, pick which branch you would like to use, then run the command in your terminal:&lt;/p&gt; &#xA;&lt;h3&gt;Stable Branch (Recommended)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -fsSL https://christitus.com/linux | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dev branch&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -fsSL https://christitus.com/linuxdev | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;💖 Support&lt;/h2&gt; &#xA;&lt;p&gt;If you find Linutil helpful, please consider giving it a ⭐️ to show your support!&lt;/p&gt; &#xA;&lt;h2&gt;🎓 Documentation&lt;/h2&gt; &#xA;&lt;p&gt;For comprehensive information on how to use Linutil, visit the &lt;a href=&#34;https://christitustech.github.io/linutil/&#34;&gt;Linutil Official Documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;🛠 Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the community! Before you start, please review our &lt;a href=&#34;https://raw.githubusercontent.com/ChrisTitusTech/linutil/main/CONTRIBUTING.md&#34;&gt;Contributing Guidelines&lt;/a&gt; to understand how to make the most effective and efficient contributions.&lt;/p&gt; &#xA;&lt;h2&gt;🏅 Thanks to All Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Thank you to everyone who has contributed to the development of Linutil. Your efforts are greatly appreciated, and you’re helping make this tool better for everyone!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ChrisTitusTech/linutil/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=ChrisTitusTech/linutil&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📜 Credits&lt;/h2&gt; &#xA;&lt;p&gt;Linutil’s Rust shell was developed by &lt;a href=&#34;https://github.com/JustLinuxUser&#34;&gt;@JustLinuxUser&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>