<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-01-19T01:36:52Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dnhkng/GlaDOS</title>
    <updated>2025-01-19T01:36:52Z</updated>
    <id>tag:github.com,2025-01-19:/dnhkng/GlaDOS</id>
    <link href="https://github.com/dnhkng/GlaDOS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This is the Personality Core for GLaDOS, the first steps towards a real-life implementation of the AI from the Portal series by Valve.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://trendshift.io/repositories/9828&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/9828&#34; alt=&#34;dnhkng%2FGlaDOS | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;GLaDOS Personality Core&lt;/h1&gt; &#xA;&lt;p&gt;This is a project dedicated to building a real-life version of GLaDOS!&lt;/p&gt; &#xA;&lt;p&gt;NEW: If you want to chat or join the community, &lt;a href=&#34;https://discord.com/invite/ERTDKwpjNB&#34;&gt;Join our discord!&lt;/a&gt; If you want to support, &lt;a href=&#34;https://ko-fi.com/dnhkng&#34;&gt;sponsor the project here!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/c22049e4-7fba-4e84-8667-2c6657a656a0&#34;&gt;https://github.com/user-attachments/assets/c22049e4-7fba-4e84-8667-2c6657a656a0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Update 3-1-2025 &lt;em&gt;Got GLaDOS running on an 8Gb SBC!&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/99e599bb-4701-438a-a311-8e6cd595796c&#34;&gt;https://github.com/user-attachments/assets/99e599bb-4701-438a-a311-8e6cd595796c&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is really tricky, so only for hardcore geeks! Checkout the &#39;rock5b&#39; branch, and my OpenAI API for the &lt;a href=&#34;https://github.com/dnhkng/RKLLM-Gradio&#34;&gt;RK3588 NPU system&lt;/a&gt; Don&#39;t expect support for this, it&#39;s in active development, and requires lots of messing about in armbian linux etc.&lt;/p&gt; &#xA;&lt;h2&gt;Goals&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;This is a hardware and software project that will create an aware, interactive, and embodied GLaDOS.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;This will entail:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Train GLaDOS voice generator&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Generate a prompt that leads to a realistic &#34;Personality Core&#34;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Generate a medium- and long-term memory for GLaDOS (Probably a custom vector DB in a simpy Numpy array!)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Give GLaDOS vision via a VLM (either a full VLM for everything, or a &#39;vision module&#39; using a tiny VLM the GLaDOS can function call!)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Create 3D-printable parts&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Design the animatronics system&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Software Architecture&lt;/h2&gt; &#xA;&lt;p&gt;The initial goals are to develop a low-latency platform, where GLaDOS can respond to voice interactions within 600ms.&lt;/p&gt; &#xA;&lt;p&gt;To do this, the system constantly records data to a circular buffer, waiting for &lt;a href=&#34;https://github.com/snakers4/silero-vad&#34;&gt;voice to be detected&lt;/a&gt;. When it&#39;s determined that the voice has stopped (including detection of normal pauses), it will be &lt;a href=&#34;https://github.com/huggingface/distil-whisper&#34;&gt;transcribed quickly&lt;/a&gt;. This is then passed to streaming &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;local Large Language Model&lt;/a&gt;, where the streamed text is broken by sentence, and passed to a &lt;a href=&#34;https://github.com/rhasspy/piper&#34;&gt;text-to-speech system&lt;/a&gt;. This means further sentences can be generated while the current is playing, reducing latency substantially.&lt;/p&gt; &#xA;&lt;h3&gt;Subgoals&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The other aim of the project is to minimize dependencies, so this can run on constrained hardware. That means no PyTorch or other large packages.&lt;/li&gt; &#xA; &lt;li&gt;As I want to fully understand the system, I have removed a large amount of redirection: which means extracting and rewriting code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Hardware System&lt;/h2&gt; &#xA;&lt;p&gt;This will be based on servo- and stepper-motors. 3D printable STL will be provided to create GlaDOS&#39;s body, and she will be given a set of animations to express herself. The vision system will allow her to track and turn toward people and things of interest.&lt;/p&gt; &#xA;&lt;h1&gt;Installation Instruction&lt;/h1&gt; &#xA;&lt;p&gt;Try this simplified process, but be aware it&#39;s still in the experimental stage! For all operating systems, you&#39;ll first need to install Ollama to run the LLM.&lt;/p&gt; &#xA;&lt;h2&gt;Install Drivers in necessary&lt;/h2&gt; &#xA;&lt;p&gt;If you are an Nvidia system with CUDA, make sure you install the necessary drivers and CUDA, info here: &lt;a href=&#34;https://onnxruntime.ai/docs/install/&#34;&gt;https://onnxruntime.ai/docs/install/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you are using another accelerator (ROCm, DirectML etc.), after following the instructions below for you platform, follow up with installing the &lt;a href=&#34;https://onnxruntime.ai/docs/install/&#34;&gt;best onnxruntime version&lt;/a&gt; for your system.&lt;/p&gt; &#xA;&lt;h2&gt;Set up a local LLM server:&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download and install &lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;Ollama&lt;/a&gt; for your operating system.&lt;/li&gt; &#xA; &lt;li&gt;Once installed, download a small 2B model for testing, at a terminal or command prompt use: &lt;code&gt;ollama pull llama3.2&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: You can use any OpenAI or Ollama compatible server, local or cloud based. Just edit the glados_config.yaml and update the completion_url, model and the api_key if necessary.&lt;/p&gt; &#xA;&lt;h2&gt;Windows Installation Process&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open the Microsoft Store, search for &lt;code&gt;python&lt;/code&gt; and install Python 3.12&lt;/li&gt; &#xA; &lt;li&gt;Download this repository, either: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Download and unzip this repository somewhere in your home folder, or&lt;/li&gt; &#xA;   &lt;li&gt;If you have Git set up, &lt;code&gt;git clone&lt;/code&gt; this repository using &lt;code&gt;git clone github.com/dnhkng/glados.git&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;In the repository folder, run the &lt;code&gt;install_windows.bat&lt;/code&gt;, and wait until the installation in complete.&lt;/li&gt; &#xA; &lt;li&gt;Double click &lt;code&gt;start_windows.bat&lt;/code&gt; to start GLaDOS!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;macOS Installation Process&lt;/h2&gt; &#xA;&lt;p&gt;This is still experimental. Any issues can be addressed in the Discord server. If you create an issue related to this, you will be referred to the Discord server. Note: I was getting Segfaults! Please leave feedback!&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download this repository, either:&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Download and unzip this repository somewhere in your home folder, or&lt;/li&gt; &#xA;   &lt;li&gt;In a terminal, &lt;code&gt;git clone&lt;/code&gt; this repository using &lt;code&gt;git clone github.com/dnhkng/glados.git&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In a terminal, go to the repository folder and run these commands:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  chmod +x install_mac.command&#xA;  chmod +x start_mac.command&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In the Finder, double click &lt;code&gt;install_mac.command&lt;/code&gt;, and wait until the installation in complete.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Double click &lt;code&gt;start_mac.command&lt;/code&gt; to start GLaDOS!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Linux Installation Process&lt;/h2&gt; &#xA;&lt;p&gt;This is still experimental. Any issues can be addressed in the Discord server. If you create an issue related to this, you will be referred to the Discord server. This has been tested on Ubuntu 24.04.1 LTS&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install the PortAudio library, if you don&#39;t yet have it installed:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  sudo apt update&#xA;  sudo apt install libportaudio2&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Download this repository, either:&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Download and unzip this repository somewhere in your home folder, or&lt;/li&gt; &#xA;   &lt;li&gt;In a terminal, &lt;code&gt;git clone&lt;/code&gt; this repository using &lt;code&gt;git clone github.com/dnhkng/glados.git&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In a terminal, go to the repository folder and run these commands:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  chmod +x install_ubuntu.sh&#xA;  chmod +x start_ubuntu.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In the a terminal in the GLaODS folder, run &lt;code&gt;./install_ubuntu.sh&lt;/code&gt;, and wait until the installation in complete.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;./start_ubuntu.sh&lt;/code&gt; to start GLaDOS!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Changing the LLM Model&lt;/h2&gt; &#xA;&lt;p&gt;To use other models, use the command: &lt;code&gt;ollama pull {modelname}&lt;/code&gt; and then add {modelname} to glados_config.yaml as the model. You can find &lt;a href=&#34;https://ollama.com/library&#34;&gt;more models here!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Common Issues&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;If you find you are getting stuck in loops, as GLaDOS is hearing herself speak, you have two options: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Solve this by upgrading your hardware. You need to you either headphone, so she can&#39;t physically hear herself speak, or a conference-style room microphone/speaker. These have hardware sound cancellation, and prevent these loops.&lt;/li&gt; &#xA;   &lt;li&gt;Disable voice interruption. This means neither you nor GLaDOS can interrupt when GLaDOS is speaking. To accomplish this, edit the &lt;code&gt;glados_config.yaml&lt;/code&gt;, and change &lt;code&gt;interruptible:&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;If you want to the the Text UI, you should use the glados-ui.py file instead of glado.py&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Testing the submodules&lt;/h2&gt; &#xA;&lt;p&gt;You can test the systems by exploring the &#39;demo.ipynb&#39;.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#dnhkng/GlaDOS&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=dnhkng/GlaDOS&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>harry0703/MoneyPrinterTurbo</title>
    <updated>2025-01-19T01:36:52Z</updated>
    <id>tag:github.com,2025-01-19:/harry0703/MoneyPrinterTurbo</id>
    <link href="https://github.com/harry0703/MoneyPrinterTurbo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;利用AI大模型，一键生成高清短视频 Generate short videos with one click using AI LLM.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt;MoneyPrinterTurbo 💸&lt;/h1&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/harry0703/MoneyPrinterTurbo/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&#34; alt=&#34;Stargazers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/harry0703/MoneyPrinterTurbo/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/harry0703/MoneyPrinterTurbo/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&#34; alt=&#34;Forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/harry0703/MoneyPrinterTurbo/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA; &lt;br&gt; &#xA; &lt;h3&gt;简体中文 | &lt;a href=&#34;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/README-en.md&#34;&gt;English&lt;/a&gt;&lt;/h3&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;a href=&#34;https://trendshift.io/repositories/8731&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/8731&#34; alt=&#34;harry0703%2FMoneyPrinterTurbo | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;br&gt; 只需提供一个视频 &#xA; &lt;b&gt;主题&lt;/b&gt; 或 &#xA; &lt;b&gt;关键词&lt;/b&gt; ，就可以全自动生成视频文案、视频素材、视频字幕、视频背景音乐，然后合成一个高清的短视频。 &#xA; &lt;br&gt; &#xA; &lt;h4&gt;Web界面&lt;/h4&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/webui.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA; &lt;h4&gt;API界面&lt;/h4&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/api.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;特别感谢 🙏&lt;/h2&gt; &#xA;&lt;p&gt;由于该项目的 &lt;strong&gt;部署&lt;/strong&gt; 和 &lt;strong&gt;使用&lt;/strong&gt;，对于一些小白用户来说，还是 &lt;strong&gt;有一定的门槛&lt;/strong&gt;，在此特别感谢 &lt;strong&gt;录咖（AI智能 多媒体服务平台）&lt;/strong&gt; 网站基于该项目，提供的免费&lt;code&gt;AI视频生成器&lt;/code&gt;服务，可以不用部署，直接在线使用，非常方便。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;中文版：&lt;a href=&#34;https://reccloud.cn&#34;&gt;https://reccloud.cn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;英文版：&lt;a href=&#34;https://reccloud.com&#34;&gt;https://reccloud.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/reccloud.cn.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;感谢赞助 🙏&lt;/h2&gt; &#xA;&lt;p&gt;感谢佐糖 &lt;a href=&#34;https://picwish.cn&#34;&gt;https://picwish.cn&lt;/a&gt; 对该项目的支持和赞助，使得该项目能够持续的更新和维护。&lt;/p&gt; &#xA;&lt;p&gt;佐糖专注于&lt;strong&gt;图像处理领域&lt;/strong&gt;，提供丰富的&lt;strong&gt;图像处理工具&lt;/strong&gt;，将复杂操作极致简化，真正实现让图像处理更简单。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/picwish.jpg&#34; alt=&#34;picwish.jpg&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;功能特性 🎯&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 完整的 &lt;strong&gt;MVC架构&lt;/strong&gt;，代码 &lt;strong&gt;结构清晰&lt;/strong&gt;，易于维护，支持 &lt;code&gt;API&lt;/code&gt; 和 &lt;code&gt;Web界面&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持视频文案 &lt;strong&gt;AI自动生成&lt;/strong&gt;，也可以&lt;strong&gt;自定义文案&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持多种 &lt;strong&gt;高清视频&lt;/strong&gt; 尺寸 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 竖屏 9:16，&lt;code&gt;1080x1920&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 横屏 16:9，&lt;code&gt;1920x1080&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持 &lt;strong&gt;批量视频生成&lt;/strong&gt;，可以一次生成多个视频，然后选择一个最满意的&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持 &lt;strong&gt;视频片段时长&lt;/strong&gt; 设置，方便调节素材切换频率&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持 &lt;strong&gt;中文&lt;/strong&gt; 和 &lt;strong&gt;英文&lt;/strong&gt; 视频文案&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持 &lt;strong&gt;多种语音&lt;/strong&gt; 合成，可 &lt;strong&gt;实时试听&lt;/strong&gt; 效果&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持 &lt;strong&gt;字幕生成&lt;/strong&gt;，可以调整 &lt;code&gt;字体&lt;/code&gt;、&lt;code&gt;位置&lt;/code&gt;、&lt;code&gt;颜色&lt;/code&gt;、&lt;code&gt;大小&lt;/code&gt;，同时支持&lt;code&gt;字幕描边&lt;/code&gt;设置&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持 &lt;strong&gt;背景音乐&lt;/strong&gt;，随机或者指定音乐文件，可设置&lt;code&gt;背景音乐音量&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 视频素材来源 &lt;strong&gt;高清&lt;/strong&gt;，而且 &lt;strong&gt;无版权&lt;/strong&gt;，也可以使用自己的 &lt;strong&gt;本地素材&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持 &lt;strong&gt;OpenAI&lt;/strong&gt;、&lt;strong&gt;Moonshot&lt;/strong&gt;、&lt;strong&gt;Azure&lt;/strong&gt;、&lt;strong&gt;gpt4free&lt;/strong&gt;、&lt;strong&gt;one-api&lt;/strong&gt;、&lt;strong&gt;通义千问&lt;/strong&gt;、&lt;strong&gt;Google Gemini&lt;/strong&gt;、&lt;strong&gt;Ollama&lt;/strong&gt;、 &lt;strong&gt;DeepSeek&lt;/strong&gt;、 &lt;strong&gt;文心一言&lt;/strong&gt; 等多种模型接入 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;中国用户建议使用 &lt;strong&gt;DeepSeek&lt;/strong&gt; 或 &lt;strong&gt;Moonshot&lt;/strong&gt; 作为大模型提供商（国内可直接访问，不需要VPN。注册就送额度，基本够用）&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;后期计划 📅&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; GPT-SoVITS 配音支持&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 优化语音合成，利用大模型，使其合成的声音，更加自然，情绪更加丰富&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 增加视频转场效果，使其看起来更加的流畅&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 增加更多视频素材来源，优化视频素材和文案的匹配度&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 增加视频长度选项：短、中、长&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 支持更多的语音合成服务商，比如 OpenAI TTS&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 自动上传到YouTube平台&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;交流讨论 💬&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/wechat-group.jpg&#34; width=&#34;250&#34;&gt; &#xA;&lt;h2&gt;视频演示 📺&lt;/h2&gt; &#xA;&lt;h3&gt;竖屏 9:16&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&#xA;    &lt;g-emoji class=&#34;g-emoji&#34; alias=&#34;arrow_forward&#34;&gt;&#xA;     ▶️&#xA;    &lt;/g-emoji&gt; 《如何增加生活的乐趣》&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&#xA;    &lt;g-emoji class=&#34;g-emoji&#34; alias=&#34;arrow_forward&#34;&gt;&#xA;     ▶️&#xA;    &lt;/g-emoji&gt; 《金钱的作用》&lt;br&gt;更真实的合成声音&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&#xA;    &lt;g-emoji class=&#34;g-emoji&#34; alias=&#34;arrow_forward&#34;&gt;&#xA;     ▶️&#xA;    &lt;/g-emoji&gt; 《生命的意义是什么》&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;video src=&#34;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6&#34;&gt;&lt;/video&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;video src=&#34;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8&#34;&gt;&lt;/video&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;video src=&#34;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476&#34;&gt;&lt;/video&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;横屏 16:9&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&#xA;    &lt;g-emoji class=&#34;g-emoji&#34; alias=&#34;arrow_forward&#34;&gt;&#xA;     ▶️&#xA;    &lt;/g-emoji&gt;《生命的意义是什么》&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&#xA;    &lt;g-emoji class=&#34;g-emoji&#34; alias=&#34;arrow_forward&#34;&gt;&#xA;     ▶️&#xA;    &lt;/g-emoji&gt;《为什么要运动》&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;video src=&#34;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073&#34;&gt;&lt;/video&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;video src=&#34;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87&#34;&gt;&lt;/video&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;配置要求 📦&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;建议最低 CPU 4核或以上，内存 8G 或以上，显卡非必须&lt;/li&gt; &#xA; &lt;li&gt;Windows 10 或 MacOS 11.0 以上系统&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;快速开始 🚀&lt;/h2&gt; &#xA;&lt;p&gt;下载一键启动包，解压直接使用（路径不要有 &lt;strong&gt;中文&lt;/strong&gt;、&lt;strong&gt;特殊字符&lt;/strong&gt;、&lt;strong&gt;空格&lt;/strong&gt;）&lt;/p&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;百度网盘（1.2.1 最新版本）: &lt;a href=&#34;https://pan.baidu.com/s/1pSNjxTYiVENulTLm6zieMQ?pwd=g36q&#34;&gt;https://pan.baidu.com/s/1pSNjxTYiVENulTLm6zieMQ?pwd=g36q&lt;/a&gt; 提取码: g36q&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;下载后，建议先&lt;strong&gt;双击执行&lt;/strong&gt; &lt;code&gt;update.bat&lt;/code&gt; 更新到&lt;strong&gt;最新代码&lt;/strong&gt;，然后双击 &lt;code&gt;start.bat&lt;/code&gt; 启动&lt;/p&gt; &#xA;&lt;p&gt;启动后，会自动打开浏览器（如果打开是空白，建议换成 &lt;strong&gt;Chrome&lt;/strong&gt; 或者 &lt;strong&gt;Edge&lt;/strong&gt; 打开）&lt;/p&gt; &#xA;&lt;h3&gt;其他系统&lt;/h3&gt; &#xA;&lt;p&gt;还没有制作一键启动包，看下面的 &lt;strong&gt;安装部署&lt;/strong&gt; 部分，建议使用 &lt;strong&gt;docker&lt;/strong&gt; 部署，更加方便。&lt;/p&gt; &#xA;&lt;h2&gt;安装部署 📥&lt;/h2&gt; &#xA;&lt;h3&gt;前提条件&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;尽量不要使用 &lt;strong&gt;中文路径&lt;/strong&gt;，避免出现一些无法预料的问题&lt;/li&gt; &#xA; &lt;li&gt;请确保你的 &lt;strong&gt;网络&lt;/strong&gt; 是正常的，VPN需要打开&lt;code&gt;全局流量&lt;/code&gt;模式&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;① 克隆代码&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;② 修改配置文件&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;将 &lt;code&gt;config.example.toml&lt;/code&gt; 文件复制一份，命名为 &lt;code&gt;config.toml&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;按照 &lt;code&gt;config.toml&lt;/code&gt; 文件中的说明，配置好 &lt;code&gt;pexels_api_keys&lt;/code&gt; 和 &lt;code&gt;llm_provider&lt;/code&gt;，并根据 llm_provider 对应的服务商，配置相关的 API Key&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Docker部署 🐳&lt;/h3&gt; &#xA;&lt;h4&gt;① 启动Docker&lt;/h4&gt; &#xA;&lt;p&gt;如果未安装 Docker，请先安装 &lt;a href=&#34;https://www.docker.com/products/docker-desktop/&#34;&gt;https://www.docker.com/products/docker-desktop/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;如果是Windows系统，请参考微软的文档：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/zh-cn/windows/wsl/install&#34;&gt;https://learn.microsoft.com/zh-cn/windows/wsl/install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&#34;&gt;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd MoneyPrinterTurbo&#xA;docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;注意：最新版的docker安装时会自动以插件的形式安装docker compose，启动命令调整为docker compose up&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;② 访问Web界面&lt;/h4&gt; &#xA;&lt;p&gt;打开浏览器，访问 &lt;a href=&#34;http://0.0.0.0:8501&#34;&gt;http://0.0.0.0:8501&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;③ 访问API文档&lt;/h4&gt; &#xA;&lt;p&gt;打开浏览器，访问 &lt;a href=&#34;http://0.0.0.0:8080/docs&#34;&gt;http://0.0.0.0:8080/docs&lt;/a&gt; 或者 &lt;a href=&#34;http://0.0.0.0:8080/redoc&#34;&gt;http://0.0.0.0:8080/redoc&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;手动部署 📦&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;视频教程&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;完整的使用演示：&lt;a href=&#34;https://v.douyin.com/iFhnwsKY/&#34;&gt;https://v.douyin.com/iFhnwsKY/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;如何在Windows上部署：&lt;a href=&#34;https://v.douyin.com/iFyjoW3M&#34;&gt;https://v.douyin.com/iFyjoW3M&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;① 创建虚拟环境&lt;/h4&gt; &#xA;&lt;p&gt;建议使用 &lt;a href=&#34;https://conda.io/projects/conda/en/latest/user-guide/install/index.html&#34;&gt;conda&lt;/a&gt; 创建 python 虚拟环境&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git&#xA;cd MoneyPrinterTurbo&#xA;conda create -n MoneyPrinterTurbo python=3.11&#xA;conda activate MoneyPrinterTurbo&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;② 安装好 ImageMagick&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;下载 &lt;a href=&#34;https://imagemagick.org/script/download.php&#34;&gt;https://imagemagick.org/script/download.php&lt;/a&gt; 选择Windows版本，切记一定要选择 &lt;strong&gt;静态库&lt;/strong&gt; 版本，比如 ImageMagick-7.1.1-32-Q16-x64-&lt;strong&gt;static&lt;/strong&gt;.exe&lt;/li&gt; &#xA;   &lt;li&gt;安装下载好的 ImageMagick，&lt;strong&gt;注意不要修改安装路径&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;修改 &lt;code&gt;配置文件 config.toml&lt;/code&gt; 中的 &lt;code&gt;imagemagick_path&lt;/code&gt; 为你的 &lt;strong&gt;实际安装路径&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MacOS:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;brew install imagemagick&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install imagemagick&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;CentOS&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo yum install ImageMagick&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;③ 启动Web界面 🌐&lt;/h4&gt; &#xA;&lt;p&gt;注意需要到 MoneyPrinterTurbo 项目 &lt;code&gt;根目录&lt;/code&gt; 下执行以下命令&lt;/p&gt; &#xA;&lt;h6&gt;Windows&lt;/h6&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bat&#34;&gt;conda activate MoneyPrinterTurbo&#xA;webui.bat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h6&gt;MacOS or Linux&lt;/h6&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda activate MoneyPrinterTurbo&#xA;sh webui.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;启动后，会自动打开浏览器（如果打开是空白，建议换成 &lt;strong&gt;Chrome&lt;/strong&gt; 或者 &lt;strong&gt;Edge&lt;/strong&gt; 打开）&lt;/p&gt; &#xA;&lt;h4&gt;④ 启动API服务 🚀&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;启动后，可以查看 &lt;code&gt;API文档&lt;/code&gt; &lt;a href=&#34;http://127.0.0.1:8080/docs&#34;&gt;http://127.0.0.1:8080/docs&lt;/a&gt; 或者 &lt;a href=&#34;http://127.0.0.1:8080/redoc&#34;&gt;http://127.0.0.1:8080/redoc&lt;/a&gt; 直接在线调试接口，快速体验。&lt;/p&gt; &#xA;&lt;h2&gt;语音合成 🗣&lt;/h2&gt; &#xA;&lt;p&gt;所有支持的声音列表，可以查看：&lt;a href=&#34;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/voice-list.txt&#34;&gt;声音列表&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;2024-04-16 v1.1.2 新增了9种Azure的语音合成声音，需要配置API KEY，该声音合成的更加真实。&lt;/p&gt; &#xA;&lt;h2&gt;字幕生成 📜&lt;/h2&gt; &#xA;&lt;p&gt;当前支持2种字幕生成方式：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;edge&lt;/strong&gt;: 生成&lt;code&gt;速度快&lt;/code&gt;，性能更好，对电脑配置没有要求，但是质量可能不稳定&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;whisper&lt;/strong&gt;: 生成&lt;code&gt;速度慢&lt;/code&gt;，性能较差，对电脑配置有一定要求，但是&lt;code&gt;质量更可靠&lt;/code&gt;。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;可以修改 &lt;code&gt;config.toml&lt;/code&gt; 配置文件中的 &lt;code&gt;subtitle_provider&lt;/code&gt; 进行切换&lt;/p&gt; &#xA;&lt;p&gt;建议使用 &lt;code&gt;edge&lt;/code&gt; 模式，如果生成的字幕质量不好，再切换到 &lt;code&gt;whisper&lt;/code&gt; 模式&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;注意：&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;whisper 模式下需要到 HuggingFace 下载一个模型文件，大约 3GB 左右，请确保网络通畅&lt;/li&gt; &#xA; &lt;li&gt;如果留空，表示不生成字幕。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;由于国内无法访问 HuggingFace，可以使用以下方法下载 &lt;code&gt;whisper-large-v3&lt;/code&gt; 的模型文件&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;下载地址：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;百度网盘: &lt;a href=&#34;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&#34;&gt;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;夸克网盘：&lt;a href=&#34;https://pan.quark.cn/s/3ee3d991d64b&#34;&gt;https://pan.quark.cn/s/3ee3d991d64b&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;模型下载后解压，整个目录放到 &lt;code&gt;.\MoneyPrinterTurbo\models&lt;/code&gt; 里面， 最终的文件路径应该是这样: &lt;code&gt;.\MoneyPrinterTurbo\models\whisper-large-v3&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MoneyPrinterTurbo  &#xA;  ├─models&#xA;  │   └─whisper-large-v3&#xA;  │          config.json&#xA;  │          model.bin&#xA;  │          preprocessor_config.json&#xA;  │          tokenizer.json&#xA;  │          vocabulary.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;背景音乐 🎵&lt;/h2&gt; &#xA;&lt;p&gt;用于视频的背景音乐，位于项目的 &lt;code&gt;resource/songs&lt;/code&gt; 目录下。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;当前项目里面放了一些默认的音乐，来自于 YouTube 视频，如有侵权，请删除。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;字幕字体 🅰&lt;/h2&gt; &#xA;&lt;p&gt;用于视频字幕的渲染，位于项目的 &lt;code&gt;resource/fonts&lt;/code&gt; 目录下，你也可以放进去自己的字体。&lt;/p&gt; &#xA;&lt;h2&gt;常见问题 🤔&lt;/h2&gt; &#xA;&lt;h3&gt;❓如何使用免费的OpenAI GPT-3.5模型?&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://openai.com/blog/start-using-chatgpt-instantly&#34;&gt;OpenAI宣布ChatGPT里面3.5已经免费了&lt;/a&gt;，有开发者将其封装成了API，可以直接调用&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;确保你安装和启动了docker服务&lt;/strong&gt;，执行以下命令启动docker服务&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -p 3040:3040 missuo/freegpt35&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;启动成功后，修改 &lt;code&gt;config.toml&lt;/code&gt; 中的配置&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;llm_provider&lt;/code&gt; 设置为 &lt;code&gt;openai&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;openai_api_key&lt;/code&gt; 随便填写一个即可，比如 &#39;123456&#39;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;openai_base_url&lt;/code&gt; 改为 &lt;code&gt;http://localhost:3040/v1/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;openai_model_name&lt;/code&gt; 改为 &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;注意：该方式稳定性较差&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;❓AttributeError: &#39;str&#39; object has no attribute &#39;choices&#39;`&lt;/h3&gt; &#xA;&lt;p&gt;这个问题是由于大模型没有返回正确的回复导致的。&lt;/p&gt; &#xA;&lt;p&gt;大概率是网络原因， 使用 &lt;strong&gt;VPN&lt;/strong&gt;，或者设置 &lt;code&gt;openai_base_url&lt;/code&gt; 为你的代理 ，应该就可以解决了。&lt;/p&gt; &#xA;&lt;p&gt;同时建议使用 &lt;strong&gt;Moonshot&lt;/strong&gt; 或 &lt;strong&gt;DeepSeek&lt;/strong&gt; 作为大模型提供商，这两个服务商在国内访问速度更快，更加稳定。&lt;/p&gt; &#xA;&lt;h3&gt;❓RuntimeError: No ffmpeg exe could be found&lt;/h3&gt; &#xA;&lt;p&gt;通常情况下，ffmpeg 会被自动下载，并且会被自动检测到。 但是如果你的环境有问题，无法自动下载，可能会遇到如下错误：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;RuntimeError: No ffmpeg exe could be found.&#xA;Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;此时你可以从 &lt;a href=&#34;https://www.gyan.dev/ffmpeg/builds/&#34;&gt;https://www.gyan.dev/ffmpeg/builds/&lt;/a&gt; 下载ffmpeg，解压后，设置 &lt;code&gt;ffmpeg_path&lt;/code&gt; 为你的实际安装路径即可。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[app]&#xA;# 请根据你的实际路径设置，注意 Windows 路径分隔符为 \\&#xA;ffmpeg_path = &#34;C:\\Users\\harry\\Downloads\\ffmpeg.exe&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;❓ImageMagick的安全策略阻止了与临时文件@/tmp/tmpur5hyyto.txt相关的操作&lt;/h3&gt; &#xA;&lt;p&gt;可以在ImageMagick的配置文件policy.xml中找到这些策略。 这个文件通常位于 /etc/ImageMagick-&lt;code&gt;X&lt;/code&gt;/ 或 ImageMagick 安装目录的类似位置。 修改包含&lt;code&gt;pattern=&#34;@&#34;&lt;/code&gt;的条目，将&lt;code&gt;rights=&#34;none&#34;&lt;/code&gt;更改为&lt;code&gt;rights=&#34;read|write&#34;&lt;/code&gt;以允许对文件的读写操作。&lt;/p&gt; &#xA;&lt;h3&gt;❓OSError: [Errno 24] Too many open files&lt;/h3&gt; &#xA;&lt;p&gt;这个问题是由于系统打开文件数限制导致的，可以通过修改系统的文件打开数限制来解决。&lt;/p&gt; &#xA;&lt;p&gt;查看当前限制&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ulimit -n&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;如果过低，可以调高一些，比如&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ulimit -n 10240&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;❓Whisper 模型下载失败，出现如下错误&lt;/h3&gt; &#xA;&lt;p&gt;LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and outgoing trafic has been disabled. To enablerepo look-ups and downloads online, pass &#39;local files only=False&#39; as input.&lt;/p&gt; &#xA;&lt;p&gt;或者&lt;/p&gt; &#xA;&lt;p&gt;An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Trying to load the model directly from the local cache, if it exists.&lt;/p&gt; &#xA;&lt;p&gt;解决方法：&lt;a href=&#34;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-&#34;&gt;点击查看如何从网盘手动下载模型&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;反馈建议 📢&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;可以提交 &lt;a href=&#34;https://github.com/harry0703/MoneyPrinterTurbo/issues&#34;&gt;issue&lt;/a&gt; 或者 &lt;a href=&#34;https://github.com/harry0703/MoneyPrinterTurbo/pulls&#34;&gt;pull request&lt;/a&gt;。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;参考项目 📚&lt;/h2&gt; &#xA;&lt;p&gt;该项目基于 &lt;a href=&#34;https://github.com/FujiwaraChoki/MoneyPrinter&#34;&gt;https://github.com/FujiwaraChoki/MoneyPrinter&lt;/a&gt; 重构而来，做了大量的优化，增加了更多的功能。 感谢原作者的开源精神。&lt;/p&gt; &#xA;&lt;h2&gt;许可证 📝&lt;/h2&gt; &#xA;&lt;p&gt;点击查看 &lt;a href=&#34;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/LICENSE&#34;&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; 文件&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>unclecode/crawl4ai</title>
    <updated>2025-01-19T01:36:52Z</updated>
    <id>tag:github.com,2025-01-19:/unclecode/crawl4ai</id>
    <link href="https://github.com/unclecode/crawl4ai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🚀🤖 Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scraper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🚀🤖 Crawl4AI: Open-source LLM Friendly Web Crawler &amp;amp; Scraper.&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://trendshift.io/repositories/11716&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/11716&#34; alt=&#34;unclecode%2Fcrawl4ai | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/unclecode/crawl4ai/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/unclecode/crawl4ai?style=social&#34; alt=&#34;GitHub Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/unclecode/crawl4ai?style=social&#34; alt=&#34;GitHub Forks&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://badge.fury.io/py/crawl4ai&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/crawl4ai.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/crawl4ai/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/crawl4ai&#34; alt=&#34;Python Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/crawl4ai&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/crawl4ai/month&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;!-- [![Documentation Status](https://readthedocs.org/projects/crawl4ai/badge/?version=latest)](https://crawl4ai.readthedocs.io/) --&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/unclecode/crawl4ai&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/psf/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;Code style: black&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PyCQA/bandit&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/security-bandit-yellow.svg?sanitize=true&#34; alt=&#34;Security: bandit&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/unclecode/crawl4ai/main/code_of_conduct.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg?sanitize=true&#34; alt=&#34;Contributor Covenant&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Crawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for LLMs, AI agents, and data pipelines. Open source, flexible, and built for real-time performance, Crawl4AI empowers developers with unmatched speed, precision, and deployment ease.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/unclecode/crawl4ai/main/#-recent-updates&#34;&gt;✨ Check out latest update v0.4.24x&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;🎉 &lt;strong&gt;Version 0.4.24x is out!&lt;/strong&gt; Major improvements in extraction strategies with enhanced JSON handling, SSL security, and Amazon product extraction. Plus, a completely revamped content filtering system! &lt;a href=&#34;https://docs.crawl4ai.com/blog&#34;&gt;Read the release notes →&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🧐 Why Crawl4AI?&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Built for LLMs&lt;/strong&gt;: Creates smart, concise Markdown optimized for RAG and fine-tuning applications.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Lightning Fast&lt;/strong&gt;: Delivers results 6x faster with real-time, cost-efficient performance.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flexible Browser Control&lt;/strong&gt;: Offers session management, proxies, and custom hooks for seamless data access.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Heuristic Intelligence&lt;/strong&gt;: Uses advanced algorithms for efficient extraction, reducing reliance on costly models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Open Source &amp;amp; Deployable&lt;/strong&gt;: Fully open-source with no API keys—ready for Docker and cloud integration.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Thriving Community&lt;/strong&gt;: Actively maintained by a vibrant community and the #1 trending GitHub repository.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install Crawl4AI:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Install the package&#xA;pip install -U crawl4ai&#xA;&#xA;# Run post-installation setup&#xA;crawl4ai-setup&#xA;&#xA;# Verify your installation&#xA;crawl4ai-doctor&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you encounter any browser-related issues, you can install them manually:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m playwright install --with-deps chromium&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Run a simple web crawl:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;from crawl4ai import *&#xA;&#xA;async def main():&#xA;    async with AsyncWebCrawler() as crawler:&#xA;        result = await crawler.arun(&#xA;            url=&#34;https://www.nbcnews.com/business&#34;,&#xA;        )&#xA;        print(result.markdown)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;✨ Features&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;📝 &lt;strong&gt;Markdown Generation&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;🧹 &lt;strong&gt;Clean Markdown&lt;/strong&gt;: Generates clean, structured Markdown with accurate formatting.&lt;/li&gt; &#xA;  &lt;li&gt;🎯 &lt;strong&gt;Fit Markdown&lt;/strong&gt;: Heuristic-based filtering to remove noise and irrelevant parts for AI-friendly processing.&lt;/li&gt; &#xA;  &lt;li&gt;🔗 &lt;strong&gt;Citations and References&lt;/strong&gt;: Converts page links into a numbered reference list with clean citations.&lt;/li&gt; &#xA;  &lt;li&gt;🛠️ &lt;strong&gt;Custom Strategies&lt;/strong&gt;: Users can create their own Markdown generation strategies tailored to specific needs.&lt;/li&gt; &#xA;  &lt;li&gt;📚 &lt;strong&gt;BM25 Algorithm&lt;/strong&gt;: Employs BM25-based filtering for extracting core information and removing irrelevant content.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;📊 &lt;strong&gt;Structured Data Extraction&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;🤖 &lt;strong&gt;LLM-Driven Extraction&lt;/strong&gt;: Supports all LLMs (open-source and proprietary) for structured data extraction.&lt;/li&gt; &#xA;  &lt;li&gt;🧱 &lt;strong&gt;Chunking Strategies&lt;/strong&gt;: Implements chunking (topic-based, regex, sentence-level) for targeted content processing.&lt;/li&gt; &#xA;  &lt;li&gt;🌌 &lt;strong&gt;Cosine Similarity&lt;/strong&gt;: Find relevant content chunks based on user queries for semantic extraction.&lt;/li&gt; &#xA;  &lt;li&gt;🔎 &lt;strong&gt;CSS-Based Extraction&lt;/strong&gt;: Fast schema-based data extraction using XPath and CSS selectors.&lt;/li&gt; &#xA;  &lt;li&gt;🔧 &lt;strong&gt;Schema Definition&lt;/strong&gt;: Define custom schemas for extracting structured JSON from repetitive patterns.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🌐 &lt;strong&gt;Browser Integration&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;🖥️ &lt;strong&gt;Managed Browser&lt;/strong&gt;: Use user-owned browsers with full control, avoiding bot detection.&lt;/li&gt; &#xA;  &lt;li&gt;🔄 &lt;strong&gt;Remote Browser Control&lt;/strong&gt;: Connect to Chrome Developer Tools Protocol for remote, large-scale data extraction.&lt;/li&gt; &#xA;  &lt;li&gt;🔒 &lt;strong&gt;Session Management&lt;/strong&gt;: Preserve browser states and reuse them for multi-step crawling.&lt;/li&gt; &#xA;  &lt;li&gt;🧩 &lt;strong&gt;Proxy Support&lt;/strong&gt;: Seamlessly connect to proxies with authentication for secure access.&lt;/li&gt; &#xA;  &lt;li&gt;⚙️ &lt;strong&gt;Full Browser Control&lt;/strong&gt;: Modify headers, cookies, user agents, and more for tailored crawling setups.&lt;/li&gt; &#xA;  &lt;li&gt;🌍 &lt;strong&gt;Multi-Browser Support&lt;/strong&gt;: Compatible with Chromium, Firefox, and WebKit.&lt;/li&gt; &#xA;  &lt;li&gt;📐 &lt;strong&gt;Dynamic Viewport Adjustment&lt;/strong&gt;: Automatically adjusts the browser viewport to match page content, ensuring complete rendering and capturing of all elements.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🔎 &lt;strong&gt;Crawling &amp;amp; Scraping&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;🖼️ &lt;strong&gt;Media Support&lt;/strong&gt;: Extract images, audio, videos, and responsive image formats like &lt;code&gt;srcset&lt;/code&gt; and &lt;code&gt;picture&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;🚀 &lt;strong&gt;Dynamic Crawling&lt;/strong&gt;: Execute JS and wait for async or sync for dynamic content extraction.&lt;/li&gt; &#xA;  &lt;li&gt;📸 &lt;strong&gt;Screenshots&lt;/strong&gt;: Capture page screenshots during crawling for debugging or analysis.&lt;/li&gt; &#xA;  &lt;li&gt;📂 &lt;strong&gt;Raw Data Crawling&lt;/strong&gt;: Directly process raw HTML (&lt;code&gt;raw:&lt;/code&gt;) or local files (&lt;code&gt;file://&lt;/code&gt;).&lt;/li&gt; &#xA;  &lt;li&gt;🔗 &lt;strong&gt;Comprehensive Link Extraction&lt;/strong&gt;: Extracts internal, external links, and embedded iframe content.&lt;/li&gt; &#xA;  &lt;li&gt;🛠️ &lt;strong&gt;Customizable Hooks&lt;/strong&gt;: Define hooks at every step to customize crawling behavior.&lt;/li&gt; &#xA;  &lt;li&gt;💾 &lt;strong&gt;Caching&lt;/strong&gt;: Cache data for improved speed and to avoid redundant fetches.&lt;/li&gt; &#xA;  &lt;li&gt;📄 &lt;strong&gt;Metadata Extraction&lt;/strong&gt;: Retrieve structured metadata from web pages.&lt;/li&gt; &#xA;  &lt;li&gt;📡 &lt;strong&gt;IFrame Content Extraction&lt;/strong&gt;: Seamless extraction from embedded iframe content.&lt;/li&gt; &#xA;  &lt;li&gt;🕵️ &lt;strong&gt;Lazy Load Handling&lt;/strong&gt;: Waits for images to fully load, ensuring no content is missed due to lazy loading.&lt;/li&gt; &#xA;  &lt;li&gt;🔄 &lt;strong&gt;Full-Page Scanning&lt;/strong&gt;: Simulates scrolling to load and capture all dynamic content, perfect for infinite scroll pages.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🚀 &lt;strong&gt;Deployment&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;🐳 &lt;strong&gt;Dockerized Setup&lt;/strong&gt;: Optimized Docker image with API server for easy deployment.&lt;/li&gt; &#xA;  &lt;li&gt;🔄 &lt;strong&gt;API Gateway&lt;/strong&gt;: One-click deployment with secure token authentication for API-based workflows.&lt;/li&gt; &#xA;  &lt;li&gt;🌐 &lt;strong&gt;Scalable Architecture&lt;/strong&gt;: Designed for mass-scale production and optimized server performance.&lt;/li&gt; &#xA;  &lt;li&gt;⚙️ &lt;strong&gt;DigitalOcean Deployment&lt;/strong&gt;: Ready-to-deploy configurations for DigitalOcean and similar platforms.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🎯 &lt;strong&gt;Additional Features&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;🕶️ &lt;strong&gt;Stealth Mode&lt;/strong&gt;: Avoid bot detection by mimicking real users.&lt;/li&gt; &#xA;  &lt;li&gt;🏷️ &lt;strong&gt;Tag-Based Content Extraction&lt;/strong&gt;: Refine crawling based on custom tags, headers, or metadata.&lt;/li&gt; &#xA;  &lt;li&gt;🔗 &lt;strong&gt;Link Analysis&lt;/strong&gt;: Extract and analyze all links for detailed data exploration.&lt;/li&gt; &#xA;  &lt;li&gt;🛡️ &lt;strong&gt;Error Handling&lt;/strong&gt;: Robust error management for seamless execution.&lt;/li&gt; &#xA;  &lt;li&gt;🔐 &lt;strong&gt;CORS &amp;amp; Static Serving&lt;/strong&gt;: Supports filesystem-based caching and cross-origin requests.&lt;/li&gt; &#xA;  &lt;li&gt;📖 &lt;strong&gt;Clear Documentation&lt;/strong&gt;: Simplified and updated guides for onboarding and advanced usage.&lt;/li&gt; &#xA;  &lt;li&gt;🙌 &lt;strong&gt;Community Recognition&lt;/strong&gt;: Acknowledges contributors and pull requests for transparency.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Try it Now!&lt;/h2&gt; &#xA;&lt;p&gt;✨ Play around with this &lt;a href=&#34;https://colab.research.google.com/drive/1SgRPrByQLzjRfwoRNq1wSGE9nYY_EE8C?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;✨ Visit our &lt;a href=&#34;https://docs.crawl4ai.com/&#34;&gt;Documentation Website&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation 🛠️&lt;/h2&gt; &#xA;&lt;p&gt;Crawl4AI offers flexible installation options to suit various use cases. You can install it as a Python package or use Docker.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🐍 &lt;strong&gt;Using pip&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;p&gt;Choose the installation option that best fits your needs:&lt;/p&gt; &#xA; &lt;h3&gt;Basic Installation&lt;/h3&gt; &#xA; &lt;p&gt;For basic web crawling and scraping tasks:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install crawl4ai&#xA;crawl4ai-setup # Setup the browser&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;By default, this will install the asynchronous version of Crawl4AI, using Playwright for web crawling.&lt;/p&gt; &#xA; &lt;p&gt;👉 &lt;strong&gt;Note&lt;/strong&gt;: When you install Crawl4AI, the &lt;code&gt;crawl4ai-setup&lt;/code&gt; should automatically install and set up Playwright. However, if you encounter any Playwright-related errors, you can manually install it using one of these methods:&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt; &lt;p&gt;Through the command line:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;playwright install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;If the above doesn&#39;t work, try this more specific command:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m playwright install chromium&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;p&gt;This second method has proven to be more reliable in some cases.&lt;/p&gt; &#xA; &lt;hr&gt; &#xA; &lt;h3&gt;Installation with Synchronous Version&lt;/h3&gt; &#xA; &lt;p&gt;The sync version is deprecated and will be removed in future versions. If you need the synchronous version using Selenium:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install crawl4ai[sync]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;hr&gt; &#xA; &lt;h3&gt;Development Installation&lt;/h3&gt; &#xA; &lt;p&gt;For contributors who plan to modify the source code:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/unclecode/crawl4ai.git&#xA;cd crawl4ai&#xA;pip install -e .                    # Basic installation in editable mode&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Install optional features:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -e &#34;.[torch]&#34;           # With PyTorch features&#xA;pip install -e &#34;.[transformer]&#34;     # With Transformer features&#xA;pip install -e &#34;.[cosine]&#34;          # With cosine similarity features&#xA;pip install -e &#34;.[sync]&#34;            # With synchronous crawling (Selenium)&#xA;pip install -e &#34;.[all]&#34;             # Install all optional features&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🐳 &lt;strong&gt;Docker Deployment&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;p&gt;🚀 &lt;strong&gt;Major Changes Coming!&lt;/strong&gt; We&#39;re developing a completely new Docker implementation that will make deployment even more efficient and seamless. The current Docker setup is being deprecated in favor of this new solution.&lt;/p&gt; &#xA; &lt;/blockquote&gt; &#xA; &lt;h3&gt;Current Docker Support&lt;/h3&gt; &#xA; &lt;p&gt;The existing Docker implementation is being deprecated and will be replaced soon. If you still need to use Docker with the current version:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;📚 &lt;a href=&#34;https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/deprecated/docker-deployment.md&#34;&gt;Deprecated Docker Setup&lt;/a&gt; - Instructions for the current Docker implementation&lt;/li&gt; &#xA;  &lt;li&gt;⚠️ Note: This setup will be replaced in the next major release&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h3&gt;What&#39;s Coming Next?&lt;/h3&gt; &#xA; &lt;p&gt;Our new Docker implementation will bring:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Improved performance and resource efficiency&lt;/li&gt; &#xA;  &lt;li&gt;Streamlined deployment process&lt;/li&gt; &#xA;  &lt;li&gt;Better integration with Crawl4AI features&lt;/li&gt; &#xA;  &lt;li&gt;Enhanced scalability options&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;Stay connected with our &lt;a href=&#34;https://github.com/unclecode/crawl4ai&#34;&gt;GitHub repository&lt;/a&gt; for updates!&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Quick Test&lt;/h3&gt; &#xA;&lt;p&gt;Run a quick test (works for both Docker options):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import requests&#xA;&#xA;# Submit a crawl job&#xA;response = requests.post(&#xA;    &#34;http://localhost:11235/crawl&#34;,&#xA;    json={&#34;urls&#34;: &#34;https://example.com&#34;, &#34;priority&#34;: 10}&#xA;)&#xA;task_id = response.json()[&#34;task_id&#34;]&#xA;&#xA;# Continue polling until the task is complete (status=&#34;completed&#34;)&#xA;result = requests.get(f&#34;http://localhost:11235/task/{task_id}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more examples, see our &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/docs/examples/docker_example.py&#34;&gt;Docker Examples&lt;/a&gt;. For advanced configuration, environment variables, and usage examples, see our &lt;a href=&#34;https://docs.crawl4ai.com/basic/docker-deployment/&#34;&gt;Docker Deployment Guide&lt;/a&gt;.&lt;/p&gt;  &#xA;&lt;h2&gt;🔬 Advanced Usage Examples 🔬&lt;/h2&gt; &#xA;&lt;p&gt;You can check the project structure in the directory &lt;a href=&#34;https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/examples&#34;&gt;https://github.com/unclecode/crawl4ai/docs/examples&lt;/a&gt;. Over there, you can find a variety of examples; here, some popular examples are shared.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;📝 &lt;strong&gt;Heuristic Markdown Generation with Clean and Fit Markdown&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode&#xA;from crawl4ai.content_filter_strategy import PruningContentFilter, BM25ContentFilter&#xA;from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator&#xA;&#xA;async def main():&#xA;    browser_config = BrowserConfig(&#xA;        headless=True,  &#xA;        verbose=True,&#xA;    )&#xA;    run_config = CrawlerRunConfig(&#xA;        cache_mode=CacheMode.ENABLED,&#xA;        markdown_generator=DefaultMarkdownGenerator(&#xA;            content_filter=PruningContentFilter(threshold=0.48, threshold_type=&#34;fixed&#34;, min_word_threshold=0)&#xA;        ),&#xA;        # markdown_generator=DefaultMarkdownGenerator(&#xA;        #     content_filter=BM25ContentFilter(user_query=&#34;WHEN_WE_FOCUS_BASED_ON_A_USER_QUERY&#34;, bm25_threshold=1.0)&#xA;        # ),&#xA;    )&#xA;    &#xA;    async with AsyncWebCrawler(config=browser_config) as crawler:&#xA;        result = await crawler.arun(&#xA;            url=&#34;https://docs.micronaut.io/4.7.6/guide/&#34;,&#xA;            config=run_config&#xA;        )&#xA;        print(len(result.markdown))&#xA;        print(len(result.fit_markdown))&#xA;        print(len(result.markdown_v2.fit_markdown))&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🖥️ &lt;strong&gt;Executing JavaScript &amp;amp; Extract Structured Data without LLMs&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode&#xA;from crawl4ai.extraction_strategy import JsonCssExtractionStrategy&#xA;import json&#xA;&#xA;async def main():&#xA;    schema = {&#xA;    &#34;name&#34;: &#34;KidoCode Courses&#34;,&#xA;    &#34;baseSelector&#34;: &#34;section.charge-methodology .w-tab-content &amp;gt; div&#34;,&#xA;    &#34;fields&#34;: [&#xA;        {&#xA;            &#34;name&#34;: &#34;section_title&#34;,&#xA;            &#34;selector&#34;: &#34;h3.heading-50&#34;,&#xA;            &#34;type&#34;: &#34;text&#34;,&#xA;        },&#xA;        {&#xA;            &#34;name&#34;: &#34;section_description&#34;,&#xA;            &#34;selector&#34;: &#34;.charge-content&#34;,&#xA;            &#34;type&#34;: &#34;text&#34;,&#xA;        },&#xA;        {&#xA;            &#34;name&#34;: &#34;course_name&#34;,&#xA;            &#34;selector&#34;: &#34;.text-block-93&#34;,&#xA;            &#34;type&#34;: &#34;text&#34;,&#xA;        },&#xA;        {&#xA;            &#34;name&#34;: &#34;course_description&#34;,&#xA;            &#34;selector&#34;: &#34;.course-content-text&#34;,&#xA;            &#34;type&#34;: &#34;text&#34;,&#xA;        },&#xA;        {&#xA;            &#34;name&#34;: &#34;course_icon&#34;,&#xA;            &#34;selector&#34;: &#34;.image-92&#34;,&#xA;            &#34;type&#34;: &#34;attribute&#34;,&#xA;            &#34;attribute&#34;: &#34;src&#34;&#xA;        }&#xA;    }&#xA;}&#xA;&#xA;    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)&#xA;&#xA;    browser_config = BrowserConfig(&#xA;        headless=False,&#xA;        verbose=True&#xA;    )&#xA;    run_config = CrawlerRunConfig(&#xA;        extraction_strategy=extraction_strategy,&#xA;        js_code=[&#34;&#34;&#34;(async () =&amp;gt; {const tabs = document.querySelectorAll(&#34;section.charge-methodology .tabs-menu-3 &amp;gt; div&#34;);for(let tab of tabs) {tab.scrollIntoView();tab.click();await new Promise(r =&amp;gt; setTimeout(r, 500));}})();&#34;&#34;&#34;],&#xA;        cache_mode=CacheMode.BYPASS&#xA;    )&#xA;        &#xA;    async with AsyncWebCrawler(config=browser_config) as crawler:&#xA;        &#xA;        result = await crawler.arun(&#xA;            url=&#34;https://www.kidocode.com/degrees/technology&#34;,&#xA;            config=run_config&#xA;        )&#xA;&#xA;        companies = json.loads(result.extracted_content)&#xA;        print(f&#34;Successfully extracted {len(companies)} companies&#34;)&#xA;        print(json.dumps(companies[0], indent=2))&#xA;&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;📚 &lt;strong&gt;Extracting Structured Data with LLMs&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;import asyncio&#xA;from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode&#xA;from crawl4ai.extraction_strategy import LLMExtractionStrategy&#xA;from pydantic import BaseModel, Field&#xA;&#xA;class OpenAIModelFee(BaseModel):&#xA;    model_name: str = Field(..., description=&#34;Name of the OpenAI model.&#34;)&#xA;    input_fee: str = Field(..., description=&#34;Fee for input token for the OpenAI model.&#34;)&#xA;    output_fee: str = Field(..., description=&#34;Fee for output token for the OpenAI model.&#34;)&#xA;&#xA;async def main():&#xA;    browser_config = BrowserConfig(verbose=True)&#xA;    run_config = CrawlerRunConfig(&#xA;        word_count_threshold=1,&#xA;        extraction_strategy=LLMExtractionStrategy(&#xA;            # Here you can use any provider that Litellm library supports, for instance: ollama/qwen2&#xA;            # provider=&#34;ollama/qwen2&#34;, api_token=&#34;no-token&#34;, &#xA;            provider=&#34;openai/gpt-4o&#34;, api_token=os.getenv(&#39;OPENAI_API_KEY&#39;), &#xA;            schema=OpenAIModelFee.schema(),&#xA;            extraction_type=&#34;schema&#34;,&#xA;            instruction=&#34;&#34;&#34;From the crawled content, extract all mentioned model names along with their fees for input and output tokens. &#xA;            Do not miss any models in the entire content. One extracted model JSON format should look like this: &#xA;            {&#34;model_name&#34;: &#34;GPT-4&#34;, &#34;input_fee&#34;: &#34;US$10.00 / 1M tokens&#34;, &#34;output_fee&#34;: &#34;US$30.00 / 1M tokens&#34;}.&#34;&#34;&#34;&#xA;        ),            &#xA;        cache_mode=CacheMode.BYPASS,&#xA;    )&#xA;    &#xA;    async with AsyncWebCrawler(config=browser_config) as crawler:&#xA;        result = await crawler.arun(&#xA;            url=&#39;https://openai.com/api/pricing/&#39;,&#xA;            config=run_config&#xA;        )&#xA;        print(result.extracted_content)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🤖 &lt;strong&gt;Using You own Browser with Custom User Profile&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os, sys&#xA;from pathlib import Path&#xA;import asyncio, time&#xA;from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode&#xA;&#xA;async def test_news_crawl():&#xA;    # Create a persistent user data directory&#xA;    user_data_dir = os.path.join(Path.home(), &#34;.crawl4ai&#34;, &#34;browser_profile&#34;)&#xA;    os.makedirs(user_data_dir, exist_ok=True)&#xA;&#xA;    browser_config = BrowserConfig(&#xA;        verbose=True,&#xA;        headless=True,&#xA;        user_data_dir=user_data_dir,&#xA;        use_persistent_context=True,&#xA;    )&#xA;    run_config = CrawlerRunConfig(&#xA;        cache_mode=CacheMode.BYPASS&#xA;    )&#xA;    &#xA;    async with AsyncWebCrawler(config=browser_config) as crawler:&#xA;        url = &#34;ADDRESS_OF_A_CHALLENGING_WEBSITE&#34;&#xA;        &#xA;        result = await crawler.arun(&#xA;            url,&#xA;            config=run_config,&#xA;            magic=True,&#xA;        )&#xA;        &#xA;        print(f&#34;Successfully crawled {url}&#34;)&#xA;        print(f&#34;Content length: {len(result.markdown)}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;✨ Recent Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🔒 &lt;strong&gt;Enhanced SSL &amp;amp; Security&lt;/strong&gt;: New SSL certificate handling with custom paths and validation options for secure crawling&lt;/li&gt; &#xA; &lt;li&gt;🔍 &lt;strong&gt;Smart Content Filtering&lt;/strong&gt;: Advanced filtering system with regex support and efficient chunking strategies&lt;/li&gt; &#xA; &lt;li&gt;📦 &lt;strong&gt;Improved JSON Extraction&lt;/strong&gt;: Support for complex JSONPath, JSON-CSS, and Microdata extraction&lt;/li&gt; &#xA; &lt;li&gt;🏗️ &lt;strong&gt;New Field Types&lt;/strong&gt;: Added &lt;code&gt;computed&lt;/code&gt;, &lt;code&gt;conditional&lt;/code&gt;, &lt;code&gt;aggregate&lt;/code&gt;, and &lt;code&gt;template&lt;/code&gt; field types&lt;/li&gt; &#xA; &lt;li&gt;⚡ &lt;strong&gt;Performance Boost&lt;/strong&gt;: Optimized caching, parallel processing, and memory management&lt;/li&gt; &#xA; &lt;li&gt;🐛 &lt;strong&gt;Better Error Handling&lt;/strong&gt;: Enhanced debugging capabilities with detailed error tracking&lt;/li&gt; &#xA; &lt;li&gt;🔐 &lt;strong&gt;Security Features&lt;/strong&gt;: Improved input validation and safe expression evaluation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Read the full details of this release in our &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/CHANGELOG.md&#34;&gt;0.4.24 Release Notes&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;📖 Documentation &amp;amp; Roadmap&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;🚨 &lt;strong&gt;Documentation Update Alert&lt;/strong&gt;: We&#39;re undertaking a major documentation overhaul next week to reflect recent updates and improvements. Stay tuned for a more comprehensive and up-to-date guide!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;For current documentation, including installation instructions, advanced features, and API reference, visit our &lt;a href=&#34;https://docs.crawl4ai.com/&#34;&gt;Documentation Website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To check our development plans and upcoming features, visit our &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/ROADMAP.md&#34;&gt;Roadmap&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;📈 &lt;strong&gt;Development TODOs&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 0. Graph Crawler: Smart website traversal using graph search algorithms for comprehensive nested page extraction&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 1. Question-Based Crawler: Natural language driven web discovery and content extraction&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 2. Knowledge-Optimal Crawler: Smart crawling that maximizes knowledge while minimizing data extraction&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 3. Agentic Crawler: Autonomous system for complex multi-step crawling operations&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 4. Automated Schema Generator: Convert natural language to extraction schemas&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 5. Domain-Specific Scrapers: Pre-configured extractors for common platforms (academic, e-commerce)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 6. Web Embedding Index: Semantic search infrastructure for crawled content&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 7. Interactive Playground: Web UI for testing, comparing strategies with AI assistance&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 8. Performance Monitor: Real-time insights into crawler operations&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 9. Cloud Integration: One-click deployment solutions across cloud providers&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 10. Sponsorship Program: Structured support system with tiered benefits&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 11. Educational Content: &#34;How to Crawl&#34; video series and interactive tutorials&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;🤝 Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the open-source community. Check out our &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/CONTRIBUTORS.md&#34;&gt;contribution guidelines&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;📄 License&lt;/h2&gt; &#xA;&lt;p&gt;Crawl4AI is released under the &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/LICENSE&#34;&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;📧 Contact&lt;/h2&gt; &#xA;&lt;p&gt;For questions, suggestions, or feedback, feel free to reach out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GitHub: &lt;a href=&#34;https://github.com/unclecode&#34;&gt;unclecode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Twitter: &lt;a href=&#34;https://twitter.com/unclecode&#34;&gt;@unclecode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Website: &lt;a href=&#34;https://crawl4ai.com&#34;&gt;crawl4ai.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Happy Crawling! 🕸️🚀&lt;/p&gt; &#xA;&lt;h2&gt;🗾 Mission&lt;/h2&gt; &#xA;&lt;p&gt;Our mission is to unlock the value of personal and enterprise data by transforming digital footprints into structured, tradeable assets. Crawl4AI empowers individuals and organizations with open-source tools to extract and structure data, fostering a shared data economy.&lt;/p&gt; &#xA;&lt;p&gt;We envision a future where AI is powered by real human knowledge, ensuring data creators directly benefit from their contributions. By democratizing data and enabling ethical sharing, we are laying the foundation for authentic AI advancement.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🔑 &lt;strong&gt;Key Opportunities&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Data Capitalization&lt;/strong&gt;: Transform digital footprints into measurable, valuable assets.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Authentic AI Data&lt;/strong&gt;: Provide AI systems with real human insights.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Shared Economy&lt;/strong&gt;: Create a fair data marketplace that benefits data creators.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;🚀 &lt;strong&gt;Development Pathway&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Open-Source Tools&lt;/strong&gt;: Community-driven platforms for transparent data extraction.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Digital Asset Structuring&lt;/strong&gt;: Tools to organize and value digital knowledge.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Ethical Data Marketplace&lt;/strong&gt;: A secure, fair platform for exchanging structured data.&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;p&gt;For more details, see our &lt;a href=&#34;https://raw.githubusercontent.com/unclecode/crawl4ai/main/MISSION.md&#34;&gt;full mission statement&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#unclecode/crawl4ai&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=unclecode/crawl4ai&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>