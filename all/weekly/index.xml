<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-23T01:34:20Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mendableai/firecrawl</title>
    <updated>2024-05-23T01:34:20Z</updated>
    <id>tag:github.com,2024-05-23:/mendableai/firecrawl</id>
    <link href="https://github.com/mendableai/firecrawl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ðŸ”¥ Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl, search and extract with a single API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ðŸ”¥ Firecrawl&lt;/h1&gt; &#xA;&lt;p&gt;Crawl and convert any website into LLM-ready markdown. Built by &lt;a href=&#34;https://mendable.ai?ref=gfirecrawl&#34;&gt;Mendable.ai&lt;/a&gt; and the firecrawl community.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;This repository is in its early development stages. We are still merging custom modules in the mono repo. It&#39;s not completely yet ready for full self-host deployment, but you can already run it locally.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Firecrawl?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://firecrawl.dev?ref=github&#34;&gt;Firecrawl&lt;/a&gt; is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Pst. hey, you, join our stargazers :)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://github.com/mendableai/firecrawl/assets/44934913/53c4483a-0f0e-40c6-bd84-153a07f94d29&#34; width=&#34;200&#34;&gt; &#xA;&lt;h2&gt;How to use it?&lt;/h2&gt; &#xA;&lt;p&gt;We provide an easy to use API with our hosted version. You can find the playground and documentation &lt;a href=&#34;https://firecrawl.dev/playground&#34;&gt;here&lt;/a&gt;. You can also self host the backend if you&#39;d like.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://firecrawl.dev/playground&#34;&gt;API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://github.com/mendableai/firecrawl/tree/main/apps/python-sdk&#34;&gt;Python SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://github.com/mendableai/firecrawl/tree/main/apps/js-sdk&#34;&gt;Node SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://python.langchain.com/docs/integrations/document_loaders/firecrawl/&#34;&gt;Langchain Integration ðŸ¦œðŸ”—&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader&#34;&gt;Llama Index Integration ðŸ¦™&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl&#34;&gt;Langchain JS Integration ðŸ¦œðŸ”—&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Want an SDK or Integration? Let us know by opening an issue.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To run locally, refer to guide &lt;a href=&#34;https://github.com/mendableai/firecrawl/raw/main/CONTRIBUTING.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;API Key&lt;/h3&gt; &#xA;&lt;p&gt;To use the API, you need to sign up on &lt;a href=&#34;https://firecrawl.dev&#34;&gt;Firecrawl&lt;/a&gt; and get an API key.&lt;/p&gt; &#xA;&lt;h3&gt;Crawling&lt;/h3&gt; &#xA;&lt;p&gt;Used to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X POST https://api.firecrawl.dev/v0/crawl \&#xA;    -H &#39;Content-Type: application/json&#39; \&#xA;    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \&#xA;    -d &#39;{&#xA;      &#34;url&#34;: &#34;https://mendable.ai&#34;&#xA;    }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Returns a jobId&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{ &#34;jobId&#34;: &#34;1234-5678-9101&#34; }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Check Crawl Job&lt;/h3&gt; &#xA;&lt;p&gt;Used to check the status of a crawl job and get its result.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X GET https://api.firecrawl.dev/v0/crawl/status/1234-5678-9101 \&#xA;  -H &#39;Content-Type: application/json&#39; \&#xA;  -H &#39;Authorization: Bearer YOUR_API_KEY&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;status&#34;: &#34;completed&#34;,&#xA;  &#34;current&#34;: 22,&#xA;  &#34;total&#34;: 22,&#xA;  &#34;data&#34;: [&#xA;    {&#xA;      &#34;content&#34;: &#34;Raw Content &#34;,&#xA;      &#34;markdown&#34;: &#34;# Markdown Content&#34;,&#xA;      &#34;provider&#34;: &#34;web-scraper&#34;,&#xA;      &#34;metadata&#34;: {&#xA;        &#34;title&#34;: &#34;Mendable | AI for CX and Sales&#34;,&#xA;        &#34;description&#34;: &#34;AI for CX and Sales&#34;,&#xA;        &#34;language&#34;: null,&#xA;        &#34;sourceURL&#34;: &#34;https://www.mendable.ai/&#34;&#xA;      }&#xA;    }&#xA;  ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Scraping&lt;/h3&gt; &#xA;&lt;p&gt;Used to scrape a URL and get its content.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X POST https://api.firecrawl.dev/v0/scrape \&#xA;    -H &#39;Content-Type: application/json&#39; \&#xA;    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \&#xA;    -d &#39;{&#xA;      &#34;url&#34;: &#34;https://mendable.ai&#34;&#xA;    }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Response:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;success&#34;: true,&#xA;  &#34;data&#34;: {&#xA;    &#34;content&#34;: &#34;Raw Content &#34;,&#xA;    &#34;markdown&#34;: &#34;# Markdown Content&#34;,&#xA;    &#34;provider&#34;: &#34;web-scraper&#34;,&#xA;    &#34;metadata&#34;: {&#xA;      &#34;title&#34;: &#34;Mendable | AI for CX and Sales&#34;,&#xA;      &#34;description&#34;: &#34;AI for CX and Sales&#34;,&#xA;      &#34;language&#34;: null,&#xA;      &#34;sourceURL&#34;: &#34;https://www.mendable.ai/&#34;&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Search (Beta)&lt;/h3&gt; &#xA;&lt;p&gt;Used to search the web, get the most relevant results, scrape each page and return the markdown.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X POST https://api.firecrawl.dev/v0/search \&#xA;    -H &#39;Content-Type: application/json&#39; \&#xA;    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \&#xA;    -d &#39;{&#xA;      &#34;query&#34;: &#34;firecrawl&#34;,&#xA;      &#34;pageOptions&#34;: {&#xA;        &#34;fetchPageContent&#34;: true // false for a fast serp api&#xA;      }&#xA;    }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;success&#34;: true,&#xA;  &#34;data&#34;: [&#xA;    {&#xA;      &#34;url&#34;: &#34;https://mendable.ai&#34;,&#xA;      &#34;markdown&#34;: &#34;# Markdown Content&#34;,&#xA;      &#34;provider&#34;: &#34;web-scraper&#34;,&#xA;      &#34;metadata&#34;: {&#xA;        &#34;title&#34;: &#34;Mendable | AI for CX and Sales&#34;,&#xA;        &#34;description&#34;: &#34;AI for CX and Sales&#34;,&#xA;        &#34;language&#34;: null,&#xA;        &#34;sourceURL&#34;: &#34;https://www.mendable.ai/&#34;&#xA;      }&#xA;    }&#xA;  ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Intelligent Extraction (Beta)&lt;/h3&gt; &#xA;&lt;p&gt;Used to extract structured data from scraped pages.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X POST https://api.firecrawl.dev/v0/scrape \&#xA;    -H &#39;Content-Type: application/json&#39; \&#xA;    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \&#xA;    -d &#39;{&#xA;      &#34;url&#34;: &#34;https://www.mendable.ai/&#34;,&#xA;      &#34;extractorOptions&#34;: {&#xA;        &#34;mode&#34;: &#34;llm-extraction&#34;,&#xA;        &#34;extractionPrompt&#34;: &#34;Based on the information on the page, extract the information from the schema. &#34;,&#xA;        &#34;extractionSchema&#34;: {&#xA;          &#34;type&#34;: &#34;object&#34;,&#xA;          &#34;properties&#34;: {&#xA;            &#34;company_mission&#34;: {&#xA;                      &#34;type&#34;: &#34;string&#34;&#xA;            },&#xA;            &#34;supports_sso&#34;: {&#xA;                      &#34;type&#34;: &#34;boolean&#34;&#xA;            },&#xA;            &#34;is_open_source&#34;: {&#xA;                      &#34;type&#34;: &#34;boolean&#34;&#xA;            },&#xA;            &#34;is_in_yc&#34;: {&#xA;                      &#34;type&#34;: &#34;boolean&#34;&#xA;            }&#xA;          },&#xA;          &#34;required&#34;: [&#xA;            &#34;company_mission&#34;,&#xA;            &#34;supports_sso&#34;,&#xA;            &#34;is_open_source&#34;,&#xA;            &#34;is_in_yc&#34;&#xA;          ]&#xA;        }&#xA;      }&#xA;    }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;success&#34;: true,&#xA;    &#34;data&#34;: {&#xA;      &#34;content&#34;: &#34;Raw Content&#34;,&#xA;      &#34;metadata&#34;: {&#xA;        &#34;title&#34;: &#34;Mendable&#34;,&#xA;        &#34;description&#34;: &#34;Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide&#34;,&#xA;        &#34;robots&#34;: &#34;follow, index&#34;,&#xA;        &#34;ogTitle&#34;: &#34;Mendable&#34;,&#xA;        &#34;ogDescription&#34;: &#34;Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide&#34;,&#xA;        &#34;ogUrl&#34;: &#34;https://mendable.ai/&#34;,&#xA;        &#34;ogImage&#34;: &#34;https://mendable.ai/mendable_new_og1.png&#34;,&#xA;        &#34;ogLocaleAlternate&#34;: [],&#xA;        &#34;ogSiteName&#34;: &#34;Mendable&#34;,&#xA;        &#34;sourceURL&#34;: &#34;https://mendable.ai/&#34;&#xA;      },&#xA;      &#34;llm_extraction&#34;: {&#xA;        &#34;company_mission&#34;: &#34;Train a secure AI on your technical resources that answers customer and employee questions so your team doesn&#39;t have to&#34;,&#xA;        &#34;supports_sso&#34;: true,&#xA;        &#34;is_open_source&#34;: false,&#xA;        &#34;is_in_yc&#34;: true&#xA;      }&#xA;    }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using Python SDK&lt;/h2&gt; &#xA;&lt;h3&gt;Installing Python SDK&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install firecrawl-py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Crawl a website&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from firecrawl import FirecrawlApp&#xA;&#xA;app = FirecrawlApp(api_key=&#34;YOUR_API_KEY&#34;)&#xA;&#xA;crawl_result = app.crawl_url(&#39;mendable.ai&#39;, {&#39;crawlerOptions&#39;: {&#39;excludes&#39;: [&#39;blog/*&#39;]}})&#xA;&#xA;# Get the markdown&#xA;for result in crawl_result:&#xA;    print(result[&#39;markdown&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Scraping a URL&lt;/h3&gt; &#xA;&lt;p&gt;To scrape a single URL, use the &lt;code&gt;scrape_url&lt;/code&gt; method. It takes the URL as a parameter and returns the scraped data as a dictionary.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;url = &#39;https://example.com&#39;&#xA;scraped_data = app.scrape_url(url)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Extracting structured data from a URL&lt;/h3&gt; &#xA;&lt;p&gt;With LLM extraction, you can easily extract structured data from any URL. We support pydanti schemas to make it easier for you too. Here is how you to use it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class ArticleSchema(BaseModel):&#xA;    title: str&#xA;    points: int &#xA;    by: str&#xA;    commentsURL: str&#xA;&#xA;class TopArticlesSchema(BaseModel):&#xA;    top: List[ArticleSchema] = Field(..., max_items=5, description=&#34;Top 5 stories&#34;)&#xA;&#xA;data = app.scrape_url(&#39;https://news.ycombinator.com&#39;, {&#xA;    &#39;extractorOptions&#39;: {&#xA;        &#39;extractionSchema&#39;: TopArticlesSchema.model_json_schema(),&#xA;        &#39;mode&#39;: &#39;llm-extraction&#39;&#xA;    },&#xA;    &#39;pageOptions&#39;:{&#xA;        &#39;onlyMainContent&#39;: True&#xA;    }&#xA;})&#xA;print(data[&#34;llm_extraction&#34;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Search for a query&lt;/h3&gt; &#xA;&lt;p&gt;Performs a web search, retrieve the top results, extract data from each page, and returns their markdown.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;query = &#39;What is Mendable?&#39;&#xA;search_result = app.search(query)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using the Node SDK&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;To install the Firecrawl Node SDK, you can use npm:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install @mendable/firecrawl-js&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Get an API key from &lt;a href=&#34;https://firecrawl.dev&#34;&gt;firecrawl.dev&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Set the API key as an environment variable named &lt;code&gt;FIRECRAWL_API_KEY&lt;/code&gt; or pass it as a parameter to the &lt;code&gt;FirecrawlApp&lt;/code&gt; class.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Scraping a URL&lt;/h3&gt; &#xA;&lt;p&gt;To scrape a single URL with error handling, use the &lt;code&gt;scrapeUrl&lt;/code&gt; method. It takes the URL as a parameter and returns the scraped data as a dictionary.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;try {&#xA;  const url = &#39;https://example.com&#39;;&#xA;  const scrapedData = await app.scrapeUrl(url);&#xA;  console.log(scrapedData);&#xA;&#xA;} catch (error) {&#xA;  console.error(&#xA;    &#39;Error occurred while scraping:&#39;,&#xA;    error.message&#xA;  );&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Crawling a Website&lt;/h3&gt; &#xA;&lt;p&gt;To crawl a website with error handling, use the &lt;code&gt;crawlUrl&lt;/code&gt; method. It takes the starting URL and optional parameters as arguments. The &lt;code&gt;params&lt;/code&gt; argument allows you to specify additional options for the crawl job, such as the maximum number of pages to crawl, allowed domains, and the output format.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const crawlUrl = &#39;https://example.com&#39;;&#xA;const params = {&#xA;  crawlerOptions: {&#xA;    excludes: [&#39;blog/&#39;],&#xA;    includes: [], // leave empty for all pages&#xA;    limit: 1000,&#xA;  },&#xA;  pageOptions: {&#xA;    onlyMainContent: true&#xA;  }&#xA;};&#xA;const waitUntilDone = true;&#xA;const timeout = 5;&#xA;const crawlResult = await app.crawlUrl(&#xA;  crawlUrl,&#xA;  params,&#xA;  waitUntilDone,&#xA;  timeout&#xA;);&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Checking Crawl Status&lt;/h3&gt; &#xA;&lt;p&gt;To check the status of a crawl job with error handling, use the &lt;code&gt;checkCrawlStatus&lt;/code&gt; method. It takes the job ID as a parameter and returns the current status of the crawl job.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const status = await app.checkCrawlStatus(jobId);&#xA;console.log(status);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Extracting structured data from a URL&lt;/h3&gt; &#xA;&lt;p&gt;With LLM extraction, you can easily extract structured data from any URL. We support zod schema to make it easier for you too. Here is how you to use it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import FirecrawlApp from &#34;@mendable/firecrawl-js&#34;;&#xA;import { z } from &#34;zod&#34;;&#xA;&#xA;const app = new FirecrawlApp({&#xA;  apiKey: &#34;fc-YOUR_API_KEY&#34;,&#xA;});&#xA;&#xA;// Define schema to extract contents into&#xA;const schema = z.object({&#xA;  top: z&#xA;    .array(&#xA;      z.object({&#xA;        title: z.string(),&#xA;        points: z.number(),&#xA;        by: z.string(),&#xA;        commentsURL: z.string(),&#xA;      })&#xA;    )&#xA;    .length(5)&#xA;    .describe(&#34;Top 5 stories on Hacker News&#34;),&#xA;});&#xA;&#xA;const scrapeResult = await app.scrapeUrl(&#34;https://news.ycombinator.com&#34;, {&#xA;  extractorOptions: { extractionSchema: schema },&#xA;});&#xA;&#xA;console.log(scrapeResult.data[&#34;llm_extraction&#34;]);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Search for a query&lt;/h3&gt; &#xA;&lt;p&gt;With the &lt;code&gt;search&lt;/code&gt; method, you can search for a query in a search engine and get the top results along with the page content for each result. The method takes the query as a parameter and returns the search results.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const query = &#39;what is mendable?&#39;;&#xA;const searchResults = await app.search(query, {&#xA;  pageOptions: {&#xA;    fetchPageContent: true // Fetch the page content for each search result&#xA;  }&#xA;});&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We love contributions! Please read our &lt;a href=&#34;https://raw.githubusercontent.com/mendableai/firecrawl/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; before submitting a pull request.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;It is the sole responsibility of the end users to respect websites&#39; policies when scraping, searching and crawling with Firecrawl. Users are advised to adhere to the applicable privacy policies and terms of use of the websites prior to initiating any scraping activities. By default, Firecrawl respects the directives specified in the websites&#39; robots.txt files when crawling. By utilizing Firecrawl, you expressly agree to comply with these conditions.&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>google-research/timesfm</title>
    <updated>2024-05-23T01:34:20Z</updated>
    <id>tag:github.com,2024-05-23:/google-research/timesfm</id>
    <link href="https://github.com/google-research/timesfm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TimesFM&lt;/h1&gt; &#xA;&lt;p&gt;TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Paper: &lt;a href=&#34;https://arxiv.org/abs/2310.10688&#34;&gt;A decoder-only foundation model for time-series forecasting&lt;/a&gt;, to appear in ICML 2024.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/&#34;&gt;Google Research blog&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/google/timesfm-1.0-200m&#34;&gt;Hugging Face checkpoint repo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This repo contains the code to load public TimesFM checkpoints and run model inference. Please visit our &lt;a href=&#34;https://huggingface.co/google/timesfm-1.0-200m&#34;&gt;Hugging Face checkpoint repo&lt;/a&gt; to download model checkpoints.&lt;/p&gt; &#xA;&lt;p&gt;This is not an officially supported Google product.&lt;/p&gt; &#xA;&lt;h2&gt;Checkpoint timesfm-1.0-200m&lt;/h2&gt; &#xA;&lt;p&gt;timesfm-1.0-200m is the first open model checkpoint:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It performs univariate time series forecasting for context lengths up to 512 timepoints and any horizon lengths, with an optional frequency indicator.&lt;/li&gt; &#xA; &lt;li&gt;It focuses on point forecasts, and does not support probabilistic forecasts. We experimentally offer quantile heads but they have not been calibrated after pretraining.&lt;/li&gt; &#xA; &lt;li&gt;It requires the context to be contiguous (i.e. no &#34;holes&#34;), and the context and the horizon to be of the same frequency.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to our result tables on the &lt;a href=&#34;https://raw.githubusercontent.com/google-research/timesfm/master/experiments/extended_benchmarks/tfm_results.png&#34;&gt;extended benchmarks&lt;/a&gt; and the &lt;a href=&#34;https://raw.githubusercontent.com/google-research/timesfm/master/experiments/long_horizon_benchmarks/tfm_long_horizon.png&#34;&gt;long horizon benchmarks&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please look into the README files in the respective benchmark directories within &lt;code&gt;experiments/&lt;/code&gt; for instructions for running TimesFM on the respective benchmarks.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;For calling TimesFM, We have two environment files. Inside &lt;code&gt;timesfm&lt;/code&gt;, for GPU installation (assuming CUDA 12 has been setup), you can create a conda environment &lt;code&gt;tfm_env&lt;/code&gt; from the base folder through:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create --file=environment.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For a CPU setup please use,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create --file=environment_cpu.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to create the environment instead.&lt;/p&gt; &#xA;&lt;p&gt;Follow by&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda activate tfm_env&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to install the package.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Running the provided benchmarks would require additional dependencies. Please use the environment files under &lt;code&gt;experiments&lt;/code&gt; instead.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The dependency &lt;code&gt;lingvo&lt;/code&gt; does not support ARM architectures, and the code is not working for machines with Apple silicon. We are aware of this issue and are working on a solution. Stay tuned.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Initialize the model and load a checkpoint.&lt;/h3&gt; &#xA;&lt;p&gt;Then the base class can be loaded as,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import timesfm&#xA;&#xA;tfm = timesfm.TimesFm(&#xA;    context_len=&amp;lt;context&amp;gt;,&#xA;    horizon_len=&amp;lt;horizon&amp;gt;,&#xA;    input_patch_len=32,&#xA;    output_patch_len=128,&#xA;    num_layers=20,&#xA;    model_dims=1280,&#xA;    backend=&amp;lt;backend&amp;gt;,&#xA;)&#xA;tfm.load_from_checkpoint(repo_id=&#34;google/timesfm-1.0-200m&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the four parameters are fixed to load the 200m model&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;input_patch_len=32,&#xA;output_patch_len=128,&#xA;num_layers=20,&#xA;model_dims=1280,&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;context_len&lt;/code&gt; here can be set as the max context length &lt;strong&gt;of the model&lt;/strong&gt;. &lt;strong&gt;It needs to be a multiplier of &lt;code&gt;input_patch_len&lt;/code&gt;, i.e. a multiplier of 32.&lt;/strong&gt; You can provide a shorter series to the &lt;code&gt;tfm.forecast()&lt;/code&gt; function and the model will handle it. Currently, the model handles a max context length of 512, which can be increased in later releases. The input time series can have &lt;strong&gt;any context length&lt;/strong&gt;. Padding / truncation will be handled by the inference code if needed.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The horizon length can be set to anything. We recommend setting it to the largest horizon length you would need in the forecasting tasks for your application. We generally recommend horizon length &amp;lt;= context length but it is not a requirement in the function call.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;backend&lt;/code&gt; is one of &#34;cpu&#34;, &#34;gpu&#34; or &#34;tpu&#34;, case sensitive.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Perform inference&lt;/h3&gt; &#xA;&lt;p&gt;We provide APIs to forecast from either array inputs or &lt;code&gt;pandas&lt;/code&gt; dataframe. Both forecast methods expect (1) the input time series contexts, (2) along with their frequencies. Please look at the documentation of the functions &lt;code&gt;tfm.forecast()&lt;/code&gt; and &lt;code&gt;tfm.forecast_on_df()&lt;/code&gt; for detailed instructions.&lt;/p&gt; &#xA;&lt;p&gt;In particular regarding the frequency, TimesFM expects a categorical indicator valued in {0, 1, 2}:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;0&lt;/strong&gt; (default): high frequency, long horizon time series. We recommend using this for time series up to daily granularity.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;1&lt;/strong&gt;: medium frequency time series. We recommend using this for weekly and monthly data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2&lt;/strong&gt;: low frequency, short horizon time series. We recommend using this for anything beyond monthly, e.g. quarterly or yearly.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This categorical value should be directly provided with the array inputs. For dataframe inputs, we convert the conventional letter coding of frequencies to our expected categories, that&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;0&lt;/strong&gt;: T, MIN, H, D, B, U&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;1&lt;/strong&gt;: W, M&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2&lt;/strong&gt;: Q, Y&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Notice you do &lt;strong&gt;NOT&lt;/strong&gt; have to strictly follow our recommendation here. Although this is our setup during model training and we expect it to offer the best forecast result, you can also view the frequency input as a free parameter and modify it per your specific use case.&lt;/p&gt; &#xA;&lt;p&gt;Examples:&lt;/p&gt; &#xA;&lt;p&gt;Array inputs, with the frequencies set to low, medium and high respectively.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np&#xA;forecast_input = [&#xA;    np.sin(np.linspace(0, 20, 100)),&#xA;    np.sin(np.linspace(0, 20, 200)),&#xA;    np.sin(np.linspace(0, 20, 400)),&#xA;]&#xA;frequency_input = [0, 1, 2]&#xA;&#xA;point_forecast, experimental_quantile_forecast = tfm.forecast(&#xA;    forecast_input,&#xA;    freq=frequency_input,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;pandas&lt;/code&gt; dataframe, with the frequency set to &#34;M&#34; monthly.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd&#xA;&#xA;# e.g. input_df is&#xA;#       unique_id  ds          y&#xA;# 0     T1         1975-12-31  697458.0&#xA;# 1     T1         1976-01-31  1187650.0&#xA;# 2     T1         1976-02-29  1069690.0&#xA;# 3     T1         1976-03-31  1078430.0&#xA;# 4     T1         1976-04-30  1059910.0&#xA;# ...   ...        ...         ...&#xA;# 8175  T99        1986-01-31  602.0&#xA;# 8176  T99        1986-02-28  684.0&#xA;# 8177  T99        1986-03-31  818.0&#xA;# 8178  T99        1986-04-30  836.0&#xA;# 8179  T99        1986-05-31  878.0&#xA;&#xA;forecast_df = tfm.forecast_on_df(&#xA;    inputs=input_df,&#xA;    freq=&#34;M&#34;,  # monthly&#xA;    value_name=&#34;y&#34;,&#xA;    num_jobs=-1,&#xA;)```&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>N64Recomp/N64Recomp</title>
    <updated>2024-05-23T01:34:20Z</updated>
    <id>tag:github.com,2024-05-23:/N64Recomp/N64Recomp</id>
    <link href="https://github.com/N64Recomp/N64Recomp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tool to statically recompile N64 games into native executables&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;N64: Recompiled&lt;/h1&gt; &#xA;&lt;p&gt;N64: Recompiled is a tool to statically recompile N64 binaries into C code that can be compiled for any platform. This can be used for ports or tools as well as for simulating behaviors significantly faster than interpreters or dynamic recompilation can. More widely, it can be used in any context where you want to run some part of an N64 binary in a standalone environment.&lt;/p&gt; &#xA;&lt;p&gt;This is not the first project that uses static recompilation on game console binaries. A well known example is &lt;a href=&#34;https://github.com/andrewrk/jamulator&#34;&gt;jamulator&lt;/a&gt;, which targets NES binaries. Additionally, this is not even the first project to apply static recompilation to N64-related projects: the &lt;a href=&#34;https://github.com/decompals/ido-static-recomp&#34;&gt;IDO static recompilation&lt;/a&gt; recompiles the SGI IRIX IDO compiler on modern systems to faciliate matching decompilation of N64 games. This project works similarly to the IDO static recomp project in some ways, and that project was my main inspiration for making this.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/N64Recomp/N64Recomp/main/#how-it-works&#34;&gt;How it Works&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/N64Recomp/N64Recomp/main/#overlays&#34;&gt;Overlays&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/N64Recomp/N64Recomp/main/#how-to-use&#34;&gt;How to Use&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/N64Recomp/N64Recomp/main/#single-file-output-mode-for-patches&#34;&gt;Single File Output Mode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/N64Recomp/N64Recomp/main/#rsp-microcode-support&#34;&gt;RSP Microcode Support&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/N64Recomp/N64Recomp/main/#planned-features&#34;&gt;Planned Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/N64Recomp/N64Recomp/main/#building&#34;&gt;Building&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How it Works&lt;/h2&gt; &#xA;&lt;p&gt;The recompiler works by accepting a list of symbols and metadata alongside the binary with the goal of splitting the input binary into functions that are each individually recompiled into a C function, named according to the metadata.&lt;/p&gt; &#xA;&lt;p&gt;Instructions are processed one-by-one and corresponding C code is emitted as each one gets processed. This translation is very literal in order to keep complexity low. For example, the instruction &lt;code&gt;addiu $r4, $r4, 0x20&lt;/code&gt;, which adds &lt;code&gt;0x20&lt;/code&gt; to the 32-bit value in the low bytes of register &lt;code&gt;$r4&lt;/code&gt; and stores the sign extended 64-bit result in &lt;code&gt;$r4&lt;/code&gt;, gets recompiled into &lt;code&gt;ctx-&amp;gt;r4 = ADD32(ctx-&amp;gt;r4, 0X20);&lt;/code&gt; The &lt;code&gt;jal&lt;/code&gt; (jump-and-link) instruction is recompiled directly into a function call, and &lt;code&gt;j&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt; instructions (unconditional jumps and branches) that can be identified as tail-call optimizations are also recompiled into function calls as well. Branch delay slots are handled by duplicating instructions as necessary. There are other specific behaviors for certain instructions, such as the recompiler attempting to turn a &lt;code&gt;jr&lt;/code&gt; instruction into a switch-case statement if it can tell that it&#39;s being used with a jump table. The recompiler has mostly been tested on binaries built with old MIPS compilers (e.g. mips gcc 2.7.2 and IDO) as well as modern clang targeting mips. Modern mips gcc may trip up the recompiler due to certain optimizations it can do, but those cases can probably be avoided by setting specific compilation flags.&lt;/p&gt; &#xA;&lt;p&gt;Every output function created by the recompiler is currently emitted into its own file. An option may be provided in the future to group functions together into output files, which should help improve build times of the recompiler output by reducing file I/O in the build process.&lt;/p&gt; &#xA;&lt;p&gt;Recompiler output can be compiled with any C compiler (tested with msvc, gcc and clang). The output is expected to be used with a runtime that can provide the necessary functionality and macro implementations to run it. An example of most of the required macro implementations can be found in the Zelda 64: Recompiled project &lt;a href=&#34;https://github.com/Mr-Wiseguy/Zelda64Recomp/raw/dev/include/recomp.h&#34;&gt;here&lt;/a&gt;, with the project also containing accompanying code for implementing the rest of the required runtime.&lt;/p&gt; &#xA;&lt;h2&gt;Overlays&lt;/h2&gt; &#xA;&lt;p&gt;Statically linked and relocatable overlays can both be handled by this tool. In both cases, the tool emits function lookups for jump-and-link-register (i.e. function pointers or virtual functions) which the provided runtime can implement using any sort of lookup table. For example, the instruction &lt;code&gt;jalr $25&lt;/code&gt; would get recompiled as &lt;code&gt;LOOKUP_FUNC(ctx-&amp;gt;r25)(rdram, ctx);&lt;/code&gt; The runtime can then maintain a list of which program sections are loaded and at what address they are at in order to determine which function to run whenever a lookup is triggered during runtime.&lt;/p&gt; &#xA;&lt;p&gt;For relocatable overlays, the tool will modify supported instructions possessing relocation data (&lt;code&gt;lui&lt;/code&gt;, &lt;code&gt;addiu&lt;/code&gt;, load and store instructions) by emitting an extra macro that enables the runtime to relocate the instruction&#39;s immediate value field. For example, the instruction &lt;code&gt;lui $24, 0x80C0&lt;/code&gt; in a section beginning at address &lt;code&gt;0x80BFA100&lt;/code&gt; with a relocation against a symbol with an address of &lt;code&gt;0x80BFA730&lt;/code&gt; will get recompiled as &lt;code&gt;ctx-&amp;gt;r24 = S32(RELOC_HI16(1754, 0X630) &amp;lt;&amp;lt; 16);&lt;/code&gt;, where 1754 is the index of this section. The runtime can then implement the RELOC_HI16 and RELOC_LO16 macros in order to handle modifying the immediate based on the current loaded address of the section.&lt;/p&gt; &#xA;&lt;p&gt;Support for relocations for TLB mapping is coming in the future, which will add the ability to provide a list of MIPS32 relocations so that the runtime can relocate them on load. Combining this with the functionality used for relocatable overlays should allow running most TLB mapped code without incurring a performance penalty on every RAM access.&lt;/p&gt; &#xA;&lt;h2&gt;How to Use&lt;/h2&gt; &#xA;&lt;p&gt;The recompiler is configured by providing a toml file in order to configure the recompiler behavior, which is the only argument provided to the recompiler. The toml is where you specify input and output file paths, as well as optionally stub out specific functions, skip recompilation of specific functions, and patch single instructions in the target binary. There is also planned functionality to be able to emit hooks in the recompiler output by adding them to the toml (the &lt;code&gt;[[patches.func]]&lt;/code&gt; and &lt;code&gt;[[patches.hook]]&lt;/code&gt; sections of the linked toml below), but this is currently unimplemented. Documentation on every option that the recompiler provides is not currently available, but an example toml can be found in the Zelda 64: Recompiled project &lt;a href=&#34;https://github.com/Mr-Wiseguy/Zelda64Recomp/raw/dev/us.rev1.toml&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Currently, the only way to provide the required metadata is by passing an elf file to this tool. The easiest way to get such an elf is to set up a disassembly or decompilation of the target binary, but there will be support for providing the metadata via a custom format to bypass the need to do so in the future.&lt;/p&gt; &#xA;&lt;h2&gt;Single File Output Mode (for Patches)&lt;/h2&gt; &#xA;&lt;p&gt;This tool can also be configured to recompile in &#34;single file output&#34; mode via an option in the configuration toml. This will emit all of the functions in the provided elf into a single output file. The purpose of this mode is to be able to compile patched versions of functions from the target binary.&lt;/p&gt; &#xA;&lt;p&gt;This mode can be combined with the functionality provided by almost all linkers (ld, lld, MSVC&#39;s link.exe, etc.) to replace functions from the original recompiler output with modified versions. Those linkers only look for symbols in a static library if they weren&#39;t already found in a previous input file, so providing the recompiled patches to the linker before providing the original recompiler output will result in the patches taking priority over functions with the same names from the original recompiler output.&lt;/p&gt; &#xA;&lt;p&gt;This saves a tremendous amount of time while iterating on patches for the target binary, as you can bypass rerunning the recompiler on the target binary as well as compiling the original recompiler output. An example of using this single file output mode for that purpose can be found in the Zelda 64: Recompiled project &lt;a href=&#34;https://github.com/Mr-Wiseguy/Zelda64Recomp/raw/dev/patches.toml&#34;&gt;here&lt;/a&gt;, with the corresponding Makefile that gets used to build the elf for those patches &lt;a href=&#34;https://github.com/Mr-Wiseguy/Zelda64Recomp/raw/dev/patches/Makefile&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;RSP Microcode Support&lt;/h2&gt; &#xA;&lt;p&gt;RSP microcode can also be recompiled with this tool. Currently there is no support for recompiling RSP overlays, but it may be added in the future if desired. Documentation on how to use this functionality will be coming soon.&lt;/p&gt; &#xA;&lt;h2&gt;Planned Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Custom metadata format to provide symbol names, relocations, and any other necessary data in order to operate without an elf&lt;/li&gt; &#xA; &lt;li&gt;Emitting multiple functions per output file to speed up compilation&lt;/li&gt; &#xA; &lt;li&gt;Support for recording MIPS32 relocations to allow runtimes to relocate them for TLB mapping&lt;/li&gt; &#xA; &lt;li&gt;Ability to recompile into a dynamic language (such as Lua) to be able to load code at runtime for mod support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;This project can be built with CMake 3.20 or above and a C++ compiler that supports C++20. This repo uses git submodules, so be sure to clone recursively (&lt;code&gt;git clone --recurse-submodules&lt;/code&gt;) or initialize submodules recursively after cloning (&lt;code&gt;git submodule update --init --recursive&lt;/code&gt;). From there, building is identical to any other cmake project, e.g. run &lt;code&gt;cmake&lt;/code&gt; in the target build folder and point it at the root of this repo, then run &lt;code&gt;cmake --build .&lt;/code&gt; from that target folder.&lt;/p&gt; &#xA;&lt;h2&gt;Libraries Used&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Decompollaborate/rabbitizer&#34;&gt;rabbitizer&lt;/a&gt; for instruction decoding/analysis&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/serge1/ELFIO&#34;&gt;ELFIO&lt;/a&gt; for elf parsing&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ToruNiina/toml11&#34;&gt;toml11&lt;/a&gt; for toml parsing&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/fmtlib/fmt&#34;&gt;fmtlib&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>