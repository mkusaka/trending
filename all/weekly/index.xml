<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-18T01:35:27Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>LLaVA-VL/LLaVA-NeXT</title>
    <updated>2024-08-18T01:35:27Z</updated>
    <id>tag:github.com,2024-08-18:/LLaVA-VL/LLaVA-NeXT</id>
    <link href="https://github.com/LLaVA-VL/LLaVA-NeXT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://i.postimg.cc/pL17YtG4/WX20240508-220230-2x.png&#34; width=&#34;80%&#34; height=&#34;80%&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;LLaVA-NeXT: Open Large Multimodal Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2408.03326&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/llava_onevision-paper-green&#34; alt=&#34;Static Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://llava-vl.github.io/blog/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/llava_next-blog-green&#34; alt=&#34;llava_next-blog&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://llava-onevision.lmms-lab.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/llava_onevision-demo-red&#34; alt=&#34;llava_onevision-demo&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/lmms-lab/LLaVA-NeXT-Interleave-Demo&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/llava_next-interleave_demo-red&#34; alt=&#34;llava_next-interleave_demo&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/WildVision/vision-arena&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/llava_next-video_demo-red&#34; alt=&#34;llava_next-video_demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://huggingface.co/collections/lmms-lab/llava-onevision-66a259c3526e15166d6bba37&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/llava_onevision-checkpoints-blue&#34; alt=&#34;llava_onevision-checkpoints&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/collections/lmms-lab/llava-next-interleave-66763c55c411b340b35873d1&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/llava_next-interleave_checkpoints-blue&#34; alt=&#34;llava_next-interleave_checkpoints&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/collections/lmms-lab/llava-next-video-661e86f5e8dabc3ff793c944&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/llava_next-video_checkpoints-blue&#34; alt=&#34;llava_next-video_checkpoints&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/lmms-lab&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/llava_next-image_checkpoints-blue&#34; alt=&#34;llava_next-image_checkpoints&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Release Notes&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[2024/08/06] 🔥 &lt;strong&gt;LLaVA-OneVision&lt;/strong&gt; is &lt;a href=&#34;https://llava-vl.github.io/blog/2024-08-05-llava-onevision/&#34;&gt;released&lt;/a&gt;. The new 0.5/7/72B model achieves the state-of-the-art level and comparable to most powerful commercial models performance on several single-image, multi-image, and video benchmarks. We benchmarked on a total of 47 benchmarks to comprehensively reflect our model&#39;s true capabilities in diverse domains. We also release our training code, and single-image/multi-image data mixture in &lt;a href=&#34;https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Data&#34;&gt;LLaVA-OneVision Data&lt;/a&gt;! Our video part data will be released via next upgrade of video specific model, stay tuned! Our training code can be directly used to train on single-image, multi-image and video data.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Check our &lt;a href=&#34;https://arxiv.org/abs/2408.03326&#34;&gt;Paper&lt;/a&gt; for more details and to see our insights on training one model to rule them all.&lt;/li&gt; &#xA;   &lt;li&gt;Check our &lt;a href=&#34;https://github.com/LLaVA-VL/LLaVA-NeXT/raw/main/docs/LLaVA_OneVision.md&#34;&gt;LLaVA-OneVision Doc&lt;/a&gt; for inference and evaluation guidance.&lt;/li&gt; &#xA;   &lt;li&gt;Check our &lt;a href=&#34;https://github.com/LLaVA-VL/LLaVA-NeXT/raw/main/scripts/train&#34;&gt;Training Scripts&lt;/a&gt; to start training models on single-image/multi-image/video data.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[2024/07/16] 🔥 &lt;strong&gt;LLaVA-NeXT-Video&lt;/strong&gt; has been upgraded. The new 32B model achieves the best open-source performance on several video benchmarks, including &lt;a href=&#34;https://video-mme.github.io/home_page.html#leaderboard&#34;&gt;Video-MME&lt;/a&gt;. Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LLaVA-NeXT-Video_0716.md&#34;&gt;this page&lt;/a&gt; for details, refer to &lt;a href=&#34;https://huggingface.co/spaces/WildVision/vision-arena&#34;&gt;llava_next-video_demo&lt;/a&gt; for demo.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[2024/06/23] 🔥 &lt;strong&gt;LLaVA-NeXT-Interleave&lt;/strong&gt; is released. We utilize image-text interleaved format to unify multi-image, video, and 3D tasks in one LLM and achieve &lt;strong&gt;SoTA&lt;/strong&gt; performance on a wide range of benchmarks. Check out &lt;a href=&#34;https://arxiv.org/pdf/2407.07895&#34;&gt;paper&lt;/a&gt;, &lt;a href=&#34;https://llava-vl.github.io/blog/2024-06-16-llava-next-interleave/&#34;&gt;blog&lt;/a&gt;, and &lt;a href=&#34;https://huggingface.co/collections/lmms-lab/llava-next-interleave-66763c55c411b340b35873d1&#34;&gt;checkpoints&lt;/a&gt; to see new capabilities and improved performance! We have released 0.5b, 7b, and 7b-dpo models.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An all-round LLM for multi-image, video, and 3D with strong performance [&lt;a href=&#34;https://huggingface.co/spaces/lmms-lab/LLaVA-NeXT-Interleave-Demo&#34;&gt;demo&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Construct interleave training data &lt;a href=&#34;https://huggingface.co/datasets/lmms-lab/M4-Instruct-Data&#34;&gt;&lt;strong&gt;M4-Instruct&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Construct multi-image benchmark &lt;a href=&#34;https://huggingface.co/datasets/lmms-lab/LLaVA-NeXT-Interleave-Bench&#34;&gt;&lt;strong&gt;LLaVA-Interleave Bench&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[2024/05/25] 🔥 Wondering &#34;&lt;a href=&#34;https://llava-vl.github.io/blog/2024-05-25-llava-next-ablations/&#34;&gt;What Else Influences Visual Instruction Tuning Beyond Data?&lt;/a&gt;&#34; Our new &lt;a href=&#34;https://llava-vl.github.io/blog/2024-05-25-llava-next-ablations/&#34;&gt;blog&lt;/a&gt; summarizes empirical explorations to ablate the various design choices in improving LMMs except instruct data itself. Meanwhile, open-source the recapioned high-quality data using LLaVA-NeXT-34B on &lt;a href=&#34;https://huggingface.co/datasets/lmms-lab/LLaVA-ReCap-118K&#34;&gt;[COCO]&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/datasets/lmms-lab/LLaVA-ReCap-558K&#34;&gt;[LCS]&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/datasets/lmms-lab/LLaVA-ReCap-CC3M&#34;&gt;[CC3M]&lt;/a&gt;.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Architectures (LMM &amp;amp; Vision Encoder)&lt;/li&gt; &#xA;   &lt;li&gt;Visual Representations (Resolution &amp;amp; # Tokens)&lt;/li&gt; &#xA;   &lt;li&gt;Training Strategies (High-quality data &amp;amp; Trainable modules)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[2024/05/10] 🔥 &lt;strong&gt;LLaVA-NeXT&lt;/strong&gt; (Stronger) models are released, with support of stronger LMM inlcuding LLama-3 (8B) and Qwen-1.5 (72B/110B) Check out [&lt;a href=&#34;https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/&#34;&gt;blog&lt;/a&gt;] and [&lt;a href=&#34;https://huggingface.co/lmms-lab&#34;&gt;checkpoints&lt;/a&gt;] to see improved performance!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[2024/05/10] 🔥 &lt;strong&gt;LLaVA-NeXT&lt;/strong&gt; (Video) is released. The image-only-trained LLaVA-NeXT model is surprisingly strong on video tasks with zero-shot modality transfer. DPO training with AI feedback on videos can yield significant improvement. [&lt;a href=&#34;https://llava-vl.github.io/blog/2024-04-30-llava-next-video/&#34;&gt;Blog&lt;/a&gt;], [&lt;a href=&#34;https://huggingface.co/collections/lmms-lab/llava-next-video-661e86f5e8dabc3ff793c944&#34;&gt;checkpoints&lt;/a&gt;] and [&lt;a href=&#34;https://github.com/sgl-project/sglang&#34;&gt;sglang&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[2024/01/30] 🔥 &lt;strong&gt;LLaVA-NeXT&lt;/strong&gt; is out! With additional scaling to LLaVA-1.5, LLaVA-NeXT-34B outperforms Gemini Pro on some benchmarks. It can now process 4x more pixels and perform more tasks/applications than before. Check out the &lt;a href=&#34;https://llava-vl.github.io/blog/2024-01-30-llava-next/&#34;&gt;blog post&lt;/a&gt;, and explore the &lt;a href=&#34;https://llava.hliu.cc/&#34;&gt;demo&lt;/a&gt;! Models are available in &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/MODEL_ZOO.md&#34;&gt;Model Zoo&lt;/a&gt;. Training/eval data and scripts coming soon.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;More&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2024/03/10] 🔥 Releasing &lt;strong&gt;LMMs-Eval&lt;/strong&gt;, a highly efficient evaluation pipeline we used when developing LLaVA-NeXT. It supports the evaluation of LMMs on dozens of public datasets and allows new dataset onboarding, making the dev of new LMMs much faster. [&lt;a href=&#34;https://lmms-lab.github.io/lmms-eval-blog/lmms-eval-0.1/&#34;&gt;Blog&lt;/a&gt;] [&lt;a href=&#34;https://github.com/EvolvingLMMs-Lab/lmms-eval&#34;&gt;Codebase&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/11/10] &lt;a href=&#34;https://llava-vl.github.io/llava-plus/&#34;&gt;LLaVA-Plus&lt;/a&gt; is released: Learning to Use Tools for Creating Multimodal Agents, with LLaVA-Plus (LLaVA that Plug and Learn to Use Skills). [&lt;a href=&#34;https://llava-vl.github.io/llava-plus/&#34;&gt;Project Page&lt;/a&gt;] [&lt;a href=&#34;https://llavaplus.ngrok.io/&#34;&gt;Demo&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LLaVA-VL/LLaVA-Plus-Codebase&#34;&gt;Code&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/abs/2311.05437&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/11/02] &lt;a href=&#34;https://llava-vl.github.io/llava-interactive/&#34;&gt;LLaVA-Interactive&lt;/a&gt; is released: Experience the future of human-AI multimodal interaction with an all-in-one demo for Image Chat, Segmentation, Generation and Editing. [&lt;a href=&#34;https://llava-vl.github.io/llava-interactive/&#34;&gt;Project Page&lt;/a&gt;] [&lt;a href=&#34;https://llavainteractive.ngrok.io/&#34;&gt;Demo&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LLaVA-VL/LLaVA-Interactive-Demo&#34;&gt;Code&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/abs/2311.00571&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/10/26] 🔥 LLaVA-1.5 with LoRA achieves comparable performance as full-model finetuning, with a reduced GPU RAM requirement (&lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/MODEL_ZOO.md#llava-v15&#34;&gt;ckpts&lt;/a&gt;, &lt;a href=&#34;https://github.com/haotian-liu/LLaVA#train&#34;&gt;script&lt;/a&gt;). We also provide a &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/Finetune_Custom_Data.md&#34;&gt;doc&lt;/a&gt; on how to finetune LLaVA-1.5 on your own dataset with LoRA.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/10/12] Check out the Korean LLaVA (Ko-LLaVA), created by ETRI, who has generously supported our research! [&lt;a href=&#34;https://huggingface.co/spaces/etri-vilab/Ko-LLaVA&#34;&gt;🤗 Demo&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/10/05] 🔥 LLaVA-1.5 is out! Achieving SoTA on 11 benchmarks, with just simple modifications to the original LLaVA, utilizes all public data, completes training in ~1 day on a single 8-A100 node, and surpasses methods like Qwen-VL-Chat that use billion-scale data. Check out the &lt;a href=&#34;https://arxiv.org/abs/2310.03744&#34;&gt;technical report&lt;/a&gt;, and explore the &lt;a href=&#34;https://llava.hliu.cc/&#34;&gt;demo&lt;/a&gt;! Models are available in &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/MODEL_ZOO.md&#34;&gt;Model Zoo&lt;/a&gt;. The training data and scripts of LLaVA-1.5 are released &lt;a href=&#34;https://github.com/haotian-liu/LLaVA#train&#34;&gt;here&lt;/a&gt;, and evaluation scripts are released &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/Evaluation.md&#34;&gt;here&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/09/26] LLaVA is improved with reinforcement learning from human feedback (RLHF) to improve fact grounding and reduce hallucination. Check out the new SFT and RLHF checkpoints at project &lt;a href=&#34;https://llava-rlhf.github.io/&#34;&gt;[LLavA-RLHF]&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/09/22] &lt;a href=&#34;https://arxiv.org/abs/2304.08485&#34;&gt;LLaVA&lt;/a&gt; is accepted by NeurIPS 2023 as &lt;strong&gt;oral presentation&lt;/strong&gt;, and &lt;a href=&#34;https://arxiv.org/abs/2306.00890&#34;&gt;LLaVA-Med&lt;/a&gt; is accepted by NeurIPS 2023 Datasets and Benchmarks Track as &lt;strong&gt;spotlight presentation&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/11/06] Support &lt;strong&gt;Intel&lt;/strong&gt; dGPU and CPU platforms. &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/tree/intel/docs/intel&#34;&gt;More details here.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/10/12] LLaVA is now supported in &lt;a href=&#34;https://github.com/ggerganov/llama.cpp/pull/3436&#34;&gt;llama.cpp&lt;/a&gt; with 4-bit / 5-bit quantization support!&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/10/11] The training data and scripts of LLaVA-1.5 are released &lt;a href=&#34;https://github.com/haotian-liu/LLaVA#train&#34;&gt;here&lt;/a&gt;, and evaluation scripts are released &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/Evaluation.md&#34;&gt;here&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/10/10] &lt;a href=&#34;https://blog.roboflow.com/first-impressions-with-llava-1-5/&#34;&gt;Roboflow Deep Dive&lt;/a&gt;: First Impressions with LLaVA-1.5.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;[2023/09/20] We summarize our empirical study of training 33B and 65B LLaVA models in a &lt;a href=&#34;https://arxiv.org/abs/2309.09958&#34;&gt;note&lt;/a&gt;. Further, if you are interested in the comprehensive review, evolution and trend of multimodal foundation models, please check out our recent survey paper &lt;a href=&#34;https://arxiv.org/abs/2309.10020&#34;&gt;``Multimodal Foundation Models: From Specialists to General-Purpose Assistants&#39;&#39;.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/Computer-Vision-in-the-Wild/CVinW_Readings/raw/main/images/mfm_evolution.jpeg?raw=true&#34; width=&#34;50%/&#34;&gt; &lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;[2023/07/19] 🔥 We release a major upgrade, including support for LLaMA-2, LoRA training, 4-/8-bit inference, higher resolution (336x336), and a lot more. We release &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/LLaVA_Bench.md&#34;&gt;LLaVA Bench&lt;/a&gt; for benchmarking open-ended visual chat with results from Bard and Bing-Chat. We also support and verify training with RTX 3090 and RTX A6000. Check out &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/LLaVA_from_LLaMA2.md&#34;&gt;LLaVA-from-LLaMA-2&lt;/a&gt;, and our &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/MODEL_ZOO.md&#34;&gt;model zoo&lt;/a&gt;!&lt;/li&gt; &#xA;  &lt;li&gt;[2023/06/26] &lt;a href=&#34;https://vlp-tutorial.github.io/&#34;&gt;CVPR 2023 Tutorial&lt;/a&gt; on &lt;strong&gt;Large Multimodal Models: Towards Building and Surpassing Multimodal GPT-4&lt;/strong&gt;! Please check out [&lt;a href=&#34;https://datarelease.blob.core.windows.net/tutorial/vision_foundation_models_2023/slides/Chunyuan_cvpr2023_tutorial_lmm.pdf&#34;&gt;Slides&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/abs/2306.14895&#34;&gt;Notes&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/mkI7EPD1vp8&#34;&gt;YouTube&lt;/a&gt;] [&lt;a href=&#34;https://www.bilibili.com/video/BV1Ng4y1T7v3/&#34;&gt;Bilibli&lt;/a&gt;].&lt;/li&gt; &#xA;  &lt;li&gt;[2023/06/11] We released the preview for the most requested feature: DeepSpeed and LoRA support! Please see documentations &lt;a href=&#34;https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LoRA.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;[2023/06/01] We released &lt;strong&gt;LLaVA-Med: Large Language and Vision Assistant for Biomedicine&lt;/strong&gt;, a step towards building biomedical domain large language and vision models with GPT-4 level capabilities. Checkout the &lt;a href=&#34;https://arxiv.org/abs/2306.00890&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https://github.com/microsoft/LLaVA-Med&#34;&gt;page&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;[2023/05/06] We are releasing &lt;a href=&#34;https://huggingface.co/liuhaotian/LLaVA-Lightning-MPT-7B-preview&#34;&gt;LLaVA-Lighting-MPT-7B-preview&lt;/a&gt;, based on MPT-7B-Chat! See &lt;a href=&#34;https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/#LLaVA-MPT-7b&#34;&gt;here&lt;/a&gt; for more details.&lt;/li&gt; &#xA;  &lt;li&gt;[2023/05/02] 🔥 We are releasing LLaVA-Lighting! Train a lite, multimodal GPT-4 with just $40 in 3 hours! See &lt;a href=&#34;https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/#train-llava-lightning&#34;&gt;here&lt;/a&gt; for more details.&lt;/li&gt; &#xA;  &lt;li&gt;[2023/04/27] Thanks to the community effort, LLaVA-13B with 4-bit quantization allows you to run on a GPU with as few as 12GB VRAM! Try it out &lt;a href=&#34;https://github.com/oobabooga/text-generation-webui/tree/main/extensions/llava&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;[2023/04/17] 🔥 We released &lt;strong&gt;LLaVA: Large Language and Vision Assistant&lt;/strong&gt;. We propose visual instruction tuning, towards building large language and vision models with GPT-4 level capabilities. Checkout the &lt;a href=&#34;https://arxiv.org/abs/2304.08485&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https://llava.hliu.cc/&#34;&gt;demo&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;!-- &lt;a href=&#34;https://llava.hliu.cc/&#34;&gt;&lt;img src=&#34;assets/demo.gif&#34; width=&#34;70%&#34;&gt;&lt;/a&gt; --&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage and License Notices&lt;/strong&gt;: This project utilizes certain datasets and checkpoints that are subject to their respective original licenses. Users must comply with all terms and conditions of these original licenses, including but not limited to the &lt;a href=&#34;https://openai.com/policies/terms-of-use&#34;&gt;OpenAI Terms of Use&lt;/a&gt; for the dataset and the specific licenses for base language models for checkpoints trained using the dataset (e.g. &lt;a href=&#34;https://ai.meta.com/llama/license/&#34;&gt;Llama-1/2 community license&lt;/a&gt; for LLaMA-2 and Vicuna-v1.5, &lt;a href=&#34;https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat/blob/main/LICENSE&#34;&gt;Tongyi Qianwen RESEARCH LICENSE AGREEMENT&lt;/a&gt; and &lt;a href=&#34;https://llama.meta.com/llama3/license/&#34;&gt;Llama-3 Research License&lt;/a&gt;). This project does not impose any additional constraints beyond those stipulated in the original licenses. Furthermore, users are reminded to ensure that their use of the dataset and checkpoints is in compliance with all applicable laws and regulations.&lt;/p&gt; &#xA;&lt;h2&gt;Models &amp;amp; Scripts&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;h4&gt;1. &lt;strong&gt;Clone this repository and navigate to the LLaVA folder:&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/LLaVA-VL/LLaVA-NeXT&#xA;cd LLaVA-NeXT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. &lt;strong&gt;Install the inference package:&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n llava python=3.10 -y&#xA;conda activate llava&#xA;pip install --upgrade pip  # Enable PEP 660 support.&#xA;pip install -e &#34;.[train]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Project Navigation&lt;/h3&gt; &#xA;&lt;p&gt;Please checkout the following page for more inference &amp;amp; evaluation details.&lt;/p&gt; &#xA;&lt;h4&gt;- &lt;strong&gt;LLaVA-NeXT: Stronger LLMs Supercharge Multimodal Capabilities in the Wild&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LLaVA-NeXT.md&#34;&gt;LLaVA-NeXT-Image&lt;/a&gt;: for image demo inference and evaluation of stronger LMMs using &lt;a href=&#34;https://github.com/EvolvingLMMs-Lab/lmms-eval&#34;&gt;lmms-eval&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;- LLaVA-NeXT: A Strong Zero-shot Video Understanding Model&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LLaVA-NeXT-Video.md&#34;&gt;LLaVA-NeXT-Video&lt;/a&gt;: for video inference and evaluation scripts. We recommend to use &lt;a href=&#34;https://lmms-lab.github.io/posts/lmms-eval-0.2/&#34;&gt;LMMs-video&lt;/a&gt; for evaluation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;- LLaVA-NeXT: Tackling Multi-image, Video, and 3D in Large Multimodal Models&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LLaVA-VL/LLaVA-NeXT/main/docs/LLaVA-NeXT-Interleave.md&#34;&gt;LLaVA-NeXT-Interleave&lt;/a&gt;: for multi-image demo and evaluation scripts.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;SGLang for SpeedUp Inference and Deployment&lt;/h2&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/sgl-project/sglang&#34;&gt;SGLang&lt;/a&gt; to speed up inference and deployment of LLaVA-NeXT. You could make LLaVA-NeXT as a backend API service with SGLang.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Prepare Environment&lt;/strong&gt;: Following the instruction in the &lt;a href=&#34;https://github.com/sgl-project/sglang?tab=readme-ov-file#install&#34;&gt;sglang&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;LLaVA-NeXT (Image)&lt;/h3&gt; &#xA;&lt;p&gt;Checkout the HTTP Post/Get and SRT usage at &lt;a href=&#34;https://github.com/sgl-project/sglang/raw/main/examples/usage/llava&#34;&gt;sglang/examples/usage/llava&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;LLaVA-NeXT (Video)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Launch and Run on (K) Nodes&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go to sglang project &lt;pre&gt;&lt;code&gt;cd PATH_TO/sglang&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;First node: &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bash examples/usage/llava_video/srt_example_llava_v.sh K 0 YOUR_VIDEO_PATH YOUR_MODEL_PATH FRAMES_PER_VIDEO&#xA;(e.g. bash examples/usage/llava_video/srt_example_llava_v.sh K 0 examples/usage/llava_video/videos/Q98Z4OTh8RwmDonc.mp4 lmms-lab/LLaVA-NeXT-Video-7B-DPO 16)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Second node: &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bash examples/usage/llava_video/srt_example_llava_v.sh K 1 YOUR_VIDEO_PATH YOUR_MODEL_PATH FRAMES_PER_VIDEO&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;The K node: &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bash examples/usage/llava_video/srt_example_llava_v.sh K K-1 YOUR_VIDEO_PATH YOUR_MODEL_PATH FRAMES_PER_VIDEO&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find it useful for your research and applications, please cite related papers/blogs using this BibTeX:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{li2024llava,&#xA;  title={LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models},&#xA;  author={Li, Feng and Zhang, Renrui and Zhang, Hao and Zhang, Yuanhan and Li, Bo and Li, Wei and Ma, Zejun and Li, Chunyuan},&#xA;  journal={arXiv preprint arXiv:2407.07895},&#xA;  year={2024}&#xA;}&#xA;&#xA;@misc{li2024llavanext-ablations,&#xA;&#x9;title={LLaVA-NeXT: What Else Influences Visual Instruction Tuning Beyond Data?},&#xA;&#x9;url={https://llava-vl.github.io/blog/2024-05-25-llava-next-ablations/},&#xA;&#x9;author={Li, Bo and Zhang, Hao and Zhang, Kaichen and Guo, Dong and Zhang, Yuanhan and Zhang, Renrui and Li, Feng and Liu, Ziwei and Li, Chunyuan},&#xA;&#x9;month={May},&#xA;&#x9;year={2024}&#xA;}&#xA;&#xA;@misc{li2024llavanext-strong,&#xA;    title={LLaVA-NeXT: Stronger LLMs Supercharge Multimodal Capabilities in the Wild},&#xA;    url={https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/},&#xA;    author={Li, Bo and Zhang, Kaichen and Zhang, Hao and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Yuanhan and Liu, Ziwei and Li, Chunyuan},&#xA;    month={May},&#xA;    year={2024}&#xA;}&#xA;&#xA;@misc{zhang2024llavanext-video,&#xA;  title={LLaVA-NeXT: A Strong Zero-shot Video Understanding Model},&#xA;  url={https://llava-vl.github.io/blog/2024-04-30-llava-next-video/},&#xA;  author={Zhang, Yuanhan and Li, Bo and Liu, haotian and Lee, Yong jae and Gui, Liangke and Fu, Di and Feng, Jiashi and Liu, Ziwei and Li, Chunyuan},&#xA;  month={April},&#xA;  year={2024}&#xA;}&#xA;&#xA;@misc{liu2024llavanext,&#xA;    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},&#xA;    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},&#xA;    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},&#xA;    month={January},&#xA;    year={2024}&#xA;}&#xA;&#xA;@misc{liu2023improvedllava,&#xA;      title={Improved Baselines with Visual Instruction Tuning}, &#xA;      author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},&#xA;      publisher={arXiv:2310.03744},&#xA;      year={2023},&#xA;}&#xA;&#xA;@misc{liu2023llava,&#xA;      title={Visual Instruction Tuning}, &#xA;      author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},&#xA;      publisher={NeurIPS},&#xA;      year={2023},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;Vicuna&lt;/a&gt;: the codebase we built upon, and our base model Vicuna-13B that has the amazing language capabilities!&lt;/li&gt; &#xA; &lt;li&gt;The LLaVA-NeXT project is currently maintained by the team along with our contributors (listed alphabetically by the first names): &lt;a href=&#34;https://brianboli.com/&#34;&gt;Bo Li&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/dongguoset/&#34;&gt;Dong Guo&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?hl=zh-CN&amp;amp;user=ybRe9GcAAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate&#34;&gt;Feng Li&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=B8hPxMQAAAAJ&amp;amp;hl=en&#34;&gt;Hao Zhang&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/kaichen-zhang-014b17219/?originalSubdomain=sg&#34;&gt;Kaichen Zhang&lt;/a&gt;, &lt;a href=&#34;https://zrrskywalker.github.io/&#34;&gt;Renrui Zhang&lt;/a&gt;, &lt;a href=&#34;https://zhangyuanhan-ai.github.io/&#34;&gt;Yuanhan Zhang&lt;/a&gt;, led by &lt;a href=&#34;https://chunyuan.li/&#34;&gt;Chunyuan Li&lt;/a&gt; and with the guidance and help from &lt;a href=&#34;https://hliu.cc/&#34;&gt;Haotian Liu&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;﻿lmms-eval&lt;/code&gt; framework and its core contributors, including Peiyuan Zhang, Fanyi Pu, Joshua Adrian Cahyono, and Kairui Hu, for their support on the evaluation side.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Related Projects&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&#34;&gt;Instruction Tuning with GPT-4&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/LLaVA-Med&#34;&gt;LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Luodian/Otter&#34;&gt;Otter: In-Context Multi-Modal Instruction Tuning&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For future project ideas, please check out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once&#34;&gt;SEEM: Segment Everything Everywhere All at Once&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/IDEA-Research/Grounded-Segment-Anything&#34;&gt;Grounded-Segment-Anything&lt;/a&gt; to detect, segment, and generate anything by marrying &lt;a href=&#34;https://github.com/IDEA-Research/GroundingDINO&#34;&gt;Grounding DINO&lt;/a&gt; and &lt;a href=&#34;https://github.com/facebookresearch/segment-anything&#34;&gt;Segment-Anything&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>penpot/penpot</title>
    <updated>2024-08-18T01:35:27Z</updated>
    <id>tag:github.com,2024-08-18:/penpot/penpot</id>
    <link href="https://github.com/penpot/penpot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Penpot: The open-source design tool for design and code collaboration&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; &#xA; &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://penpot.app/images/readme/github-dark-mode.png&#34;&gt; &#xA; &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://penpot.app/images/readme/github-light-mode.png&#34;&gt; &#xA; &lt;img alt=&#34;penpot header image&#34; src=&#34;https://penpot.app/images/readme/github-light-mode.png&#34;&gt; &#xA;&lt;/picture&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.mozilla.org/en-US/MPL/2.0&#34; rel=&#34;nofollow&#34;&gt;&lt;img src=&#34;https://camo.githubusercontent.com/3fcf3d6b678ea15fde3cf7d6af0e242160366282d62a7c182d83a50bfee3f45e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d504c2d322e302d626c75652e737667&#34; alt=&#34;License: MPL-2.0&#34; data-canonical-src=&#34;https://img.shields.io/badge/MPL-2.0-blue.svg&#34; style=&#34;max-width:100%;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/penpot/community&#34; rel=&#34;nofollow&#34;&gt;&lt;img src=&#34;https://camo.githubusercontent.com/5b0aecb33434f82a7b158eab7247544235ada0cf7eeb9ce8e52562dd67f614b7/68747470733a2f2f6261646765732e6769747465722e696d2f736572656e6f2d78797a2f636f6d6d756e6974792e737667&#34; alt=&#34;Gitter&#34; data-canonical-src=&#34;https://badges.gitter.im/sereno-xyz/community.svg&#34; style=&#34;max-width:100%;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://tree.taiga.io/project/penpot/&#34; title=&#34;Managed with Taiga.io&#34; rel=&#34;nofollow&#34;&gt;&lt;img src=&#34;https://camo.githubusercontent.com/4a1d1112f0272e3393b1e8da312ff4435418e9e2eb4c0964881e3680f90a653c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d616e61676564253230776974682d54414947412e696f2d3730396631342e737667&#34; alt=&#34;Managed with Taiga.io&#34; data-canonical-src=&#34;https://img.shields.io/badge/managed%20with-TAIGA.io-709f14.svg&#34; style=&#34;max-width:100%;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitpod.io/#https://github.com/penpot/penpot&#34; rel=&#34;nofollow&#34;&gt;&lt;img src=&#34;https://camo.githubusercontent.com/daadb4894128d1e19b72d80236f5959f1f2b47f9fe081373f3246131f0189f6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f476974706f642d72656164792d2d746f2d2d636f64652d626c75653f6c6f676f3d676974706f64&#34; alt=&#34;Gitpod ready-to-code&#34; data-canonical-src=&#34;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&#34; style=&#34;max-width:100%;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://penpot.app/&#34;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; • &lt;a href=&#34;https://help.penpot.app/technical-guide/getting-started/&#34;&gt;&lt;b&gt;Getting Started&lt;/b&gt;&lt;/a&gt; • &lt;a href=&#34;https://help.penpot.app/user-guide/&#34;&gt;&lt;b&gt;User Guide&lt;/b&gt;&lt;/a&gt; • &lt;a href=&#34;https://help.penpot.app/user-guide/introduction/info/&#34;&gt;&lt;b&gt;Tutorials &amp;amp; Info&lt;/b&gt;&lt;/a&gt; • &lt;a href=&#34;https://community.penpot.app/&#34;&gt;&lt;b&gt;Community&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.youtube.com/@Penpot&#34;&gt;&lt;b&gt;Youtube&lt;/b&gt;&lt;/a&gt; • &lt;a href=&#34;https://peertube.kaleidos.net/a/penpot_app/video-channels&#34;&gt;&lt;b&gt;Peertube&lt;/b&gt;&lt;/a&gt; • &lt;a href=&#34;https://www.linkedin.com/company/penpot/&#34;&gt;&lt;b&gt;Linkedin&lt;/b&gt;&lt;/a&gt; • &lt;a href=&#34;https://instagram.com/penpot.app&#34;&gt;&lt;b&gt;Instagram&lt;/b&gt;&lt;/a&gt; • &lt;a href=&#34;https://fosstodon.org/@penpot/&#34;&gt;&lt;b&gt;Mastodon&lt;/b&gt;&lt;/a&gt; • &lt;a href=&#34;https://twitter.com/penpotapp&#34;&gt;&lt;b&gt;X&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/penpot/penpot/assets/5446186/b8ad0764-585e-4ddc-b098-9b4090d337cc&#34;&gt;Penpot video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Penpot is the first &lt;strong&gt;open-source&lt;/strong&gt; design tool for design and code collaboration. Designers can create stunning designs, interactive prototypes, design systems at scale, while developers enjoy ready-to-use code and make their workflow easy and fast. And all of this with no handoff drama.&lt;/p&gt; &#xA;&lt;p&gt;Penpot is available on browser and &lt;a href=&#34;https://penpot.app/self-host&#34;&gt;self host&lt;/a&gt;. It’s web-based and works with open standards (SVG, CSS and HTML). And last but not least, it’s free!&lt;/p&gt; &#xA;&lt;p&gt;Penpot’s latest &lt;a href=&#34;https://penpot.app/dev-diaries&#34;&gt;huge release 2.0&lt;/a&gt;, takes the platform to a whole new level. This update introduces the ground-breaking &lt;a href=&#34;https://penpot.app/penpot-2.0&#34;&gt;CSS Grid Layout feature&lt;/a&gt;, a complete UI redesign, a new Components system, and much more. Plus, it&#39;s faster and more accessible.&lt;/p&gt; &#xA;&lt;p&gt;🎇 &lt;strong&gt;Penpot Fest&lt;/strong&gt; is our design, code &amp;amp; Open Source event. Check out the highlights from &lt;a href=&#34;https://www.youtube.com/watch?v=sOpLZaK5mDc&#34;&gt;Penpot Fest 2023 edition&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/penpot/penpot/develop/#why-penpot&#34;&gt;Why Penpot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/penpot/penpot/develop/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/penpot/penpot/develop/#community&#34;&gt;Community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/penpot/penpot/develop/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/penpot/penpot/develop/#resources&#34;&gt;Resources&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/penpot/penpot/develop/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why Penpot&lt;/h2&gt; &#xA;&lt;p&gt;Penpot expresses designs as code. Designers can do their best work and see it will be beautifully implemented by developers in a two-way collaboration.&lt;/p&gt; &#xA;&lt;h3&gt;Designed for developers&lt;/h3&gt; &#xA;&lt;p&gt;Penpot was built to serve both designers and developers and create a fluid design-code process. You have the choice to enjoy real-time collaboration or play &#34;solo&#34;.&lt;/p&gt; &#xA;&lt;h3&gt;Inspect mode&lt;/h3&gt; &#xA;&lt;p&gt;Work with ready-to-use code and make your workflow easy and fast. The inspect tab gives instant access to SVG, CSS and HTML code.&lt;/p&gt; &#xA;&lt;h3&gt;Self host your own instance&lt;/h3&gt; &#xA;&lt;p&gt;Provide your team or organization with a completely owned collaborative design tool. Use Penpot&#39;s cloud service or deploy your own Penpot server.&lt;/p&gt; &#xA;&lt;h3&gt;Integrations&lt;/h3&gt; &#xA;&lt;p&gt;Penpot offers integration into the development toolchain, thanks to its support for webhooks and an API accessible through access tokens.&lt;/p&gt; &#xA;&lt;h3&gt;What’s great for design&lt;/h3&gt; &#xA;&lt;p&gt;With Penpot you can design libraries to share and reuse; turn design elements into components and tokens to allow reusability and scalability; and build realistic user flows and interactions.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://img.plasmic.app/img-optimizer/v1/img?src=https%3A%2F%2Fimg.plasmic.app%2Fimg-optimizer%2Fv1%2Fimg%2F9dd677c36afb477e9666ccd1d3f009ad.png&#34; alt=&#34;Open Source&#34; style=&#34;width: 65%;&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;h3&gt;Install with Elestio&lt;/h3&gt; &#xA;&lt;p&gt;Penpot is the only design &amp;amp; prototype platform that is deployment agnostic. You can use it or deploy it anywhere.&lt;/p&gt; &#xA;&lt;p&gt;Learn how to install it with Elestio and Docker, or other options on &lt;a href=&#34;https://penpot.app/self-host&#34;&gt;our website&lt;/a&gt;. &lt;br&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://site-assets.plasmic.app/2168cf524dd543caeff32384eb9ea0a1.svg?sanitize=true&#34; alt=&#34;Open Source&#34; style=&#34;width: 65%;&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;We love the Open Source software community. Contributing is our passion and if it’s yours too, participate and &lt;a href=&#34;https://community.penpot.app/c/help-us-improve-penpot/7&#34;&gt;improve&lt;/a&gt; Penpot. All your designs, code and ideas are welcome!&lt;/p&gt; &#xA;&lt;p&gt;If you need help or have any questions; if you’d like to share your experience using Penpot or get inspired; if you’d rather meet our community of developers and designers, &lt;a href=&#34;https://community.penpot.app/&#34;&gt;join our Community&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt;You will find the following categories:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://community.penpot.app/c/ask-for-help-using-penpot/6&#34;&gt;Ask the Community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://community.penpot.app/c/technical/8&#34;&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://community.penpot.app/c/help-us-improve-penpot/7&#34;&gt;Help us Improve Penpot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://community.penpot.app/c/madewithpenpot/9&#34;&gt;#MadeWithPenpot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://community.penpot.app/c/announcements/5&#34;&gt;Events and Announcements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://community.penpot.app/c/inside-penpot/21&#34;&gt;Inside Penpot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://community.penpot.app/c/penpot-in-your-language/12&#34;&gt;Penpot in your language&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://community.penpot.app/c/design-and-code-essentials/22&#34;&gt;Design and Code Essentials&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/penpot/penpot/assets/5446186/6ac62220-a16c-46c9-ab21-d24ae357ed03&#34; alt=&#34;Community&#34; style=&#34;width: 65%;&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Any contribution will make a difference to improve Penpot. How can you get involved?&lt;/p&gt; &#xA;&lt;p&gt;Choose your way:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create and &lt;a href=&#34;https://penpot.app/libraries-templates.html&#34;&gt;share Libraries &amp;amp; Templates&lt;/a&gt; that will be helpful for the community&lt;/li&gt; &#xA; &lt;li&gt;Invite your &lt;a href=&#34;https://design.penpot.app/#/auth/register&#34;&gt;team to join&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Star this repo and follow us on Social Media: &lt;a href=&#34;https://fosstodon.org/@penpot/&#34;&gt;Mastodon&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/c/Penpot&#34;&gt;Youtube&lt;/a&gt;, &lt;a href=&#34;https://instagram.com/penpot.app&#34;&gt;Instagram&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/company/penpotdesign&#34;&gt;Linkedin&lt;/a&gt;, &lt;a href=&#34;https://peertube.kaleidos.net/a/penpot_app&#34;&gt;Peertube&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/penpotapp&#34;&gt;X&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Participate in the &lt;a href=&#34;https://community.penpot.app/&#34;&gt;Community&lt;/a&gt; space by asking and answering questions; reacting to others’ articles; opening your own conversations and following along on decisions affecting the project.&lt;/li&gt; &#xA; &lt;li&gt;Report bugs with our easy &lt;a href=&#34;https://help.penpot.app/contributing-guide/reporting-bugs/&#34;&gt;guide for bugs hunting&lt;/a&gt; or &lt;a href=&#34;https://github.com/penpot/penpot/issues&#34;&gt;GitHub issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Become a &lt;a href=&#34;https://help.penpot.app/contributing-guide/translations&#34;&gt;translator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Give feedback: &lt;a href=&#34;mailto:support@penpot.app&#34;&gt;Email us&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Contribute to Penpot&#39;s code:&lt;/strong&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=TpN0osiY-8k&#34;&gt;Watch this video&lt;/a&gt; by Alejandro Alonso, CIO and developer at Penpot, where he gives us a hands-on demo of how to use Penpot’s repository and make changes in both front and back end&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To find (almost) everything you need to know on how to contribute to Penpot, refer to the &lt;a href=&#34;https://help.penpot.app/contributing-guide/&#34;&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/penpot/penpot/assets/5446186/fea18923-dc06-49be-86ad-c3496a7956e6&#34; alt=&#34;Libraries and templates&#34; style=&#34;width: 65%;&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;p&gt;You can ask and answer questions, have open-ended conversations, and follow along on decisions affecting the project.&lt;/p&gt; &#xA;&lt;p&gt;💾 &lt;a href=&#34;https://help.penpot.app/technical-guide/&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;🚀 &lt;a href=&#34;https://help.penpot.app/technical-guide/getting-started/&#34;&gt;Getting Started&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;✏️ &lt;a href=&#34;https://www.youtube.com/playlist?list=PLgcCPfOv5v54WpXhHmNO7T-YC7AE-SRsr&#34;&gt;Tutorials&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;🏘️ &lt;a href=&#34;https://help.penpot.app/technical-guide/developer/architecture/&#34;&gt;Architecture&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;📚 &lt;a href=&#34;https://penpot.app/dev-diaries.html&#34;&gt;Dev Diaries&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;This Source Code Form is subject to the terms of the Mozilla Public&#xA;License, v. 2.0. If a copy of the MPL was not distributed with this&#xA;file, You can obtain one at http://mozilla.org/MPL/2.0/.&#xA;&#xA;Copyright (c) KALEIDOS INC&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Penpot is a Kaleidos’ &lt;a href=&#34;https://kaleidos.net/&#34;&gt;open source project&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Raphire/Win11Debloat</title>
    <updated>2024-08-18T01:35:27Z</updated>
    <id>tag:github.com,2024-08-18:/Raphire/Win11Debloat</id>
    <link href="https://github.com/Raphire/Win11Debloat" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A simple, easy to use PowerShell script to remove pre-installed apps from Windows, disable telemetry, remove Bing from Windows search as well as perform various other changes to declutter and improve your Windows experience. This script works for both Windows 10 and Windows 11.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Win11Debloat&lt;/h1&gt; &#xA;&lt;p&gt;Win11Debloat is a simple, easy to use and lightweight PowerShell script that can remove pre-installed Windows bloatware apps, disable telemetry and declutter the experience by disabling or removing intrusive interface elements, ads and more. No need to painstakingly go through all the settings yourself, or remove apps one by one. Win11Debloat makes the process quick and easy!&lt;/p&gt; &#xA;&lt;p&gt;You can pick and choose exactly which modifications you want the script to make, or use the default settings. If you are unhappy with any of the changes you can easily revert them by using the registry files that are included in the &#39;Regfiles&#39; folder. All of the apps that are removed can be reinstalled from the Microsoft store.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Raphire/Win11Debloat/master/Assets/menu.png&#34; alt=&#34;Win11Debloat Menu&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Did this script help you? Please consider buying me a cup of coffee to support my work&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ko-fi.com/M4M5C6UPC&#34;&gt;&lt;img src=&#34;https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true&#34; alt=&#34;ko-fi&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!Tip] Select the custom mode to customize the script to your needs or select the &lt;a href=&#34;https://raw.githubusercontent.com/Raphire/Win11Debloat/master/#default-mode&#34;&gt;default mode&lt;/a&gt; to apply the recommended changes.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;App Removal&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Remove a wide variety of bloatware apps.&lt;/li&gt; &#xA; &lt;li&gt;Remove all pinned apps from start for the current user, or for all existing &amp;amp; new users. (Windows 11 only)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Telemetry, Tracking &amp;amp; Suggested Content&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Disable telemetry, diagnostic data, activity history, app-launch tracking &amp;amp; targeted ads.&lt;/li&gt; &#xA; &lt;li&gt;Disable tips, tricks, suggestions and ads in start, settings, notifications, File Explorer, and on the lockscreen.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Bing Web Search, Copilot &amp;amp; More&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Disable &amp;amp; remove Bing web search &amp;amp; Cortana from Windows search.&lt;/li&gt; &#xA; &lt;li&gt;Disable Windows Copilot. (Windows 11 only)&lt;/li&gt; &#xA; &lt;li&gt;Disable Windows Recall snapshots. (Windows 11 only)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;File Explorer&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Show hidden files, folders and drives.&lt;/li&gt; &#xA; &lt;li&gt;Show file extensions for known file types.&lt;/li&gt; &#xA; &lt;li&gt;Hide the gallery section from the File Explorer sidepanel. (Windows 11 only)&lt;/li&gt; &#xA; &lt;li&gt;Hide the 3D objects, music or onedrive folder from the File Explorer sidepanel. (Windows 10 only)&lt;/li&gt; &#xA; &lt;li&gt;Hide duplicate removable drive entries from the File Explorer sidepanel, so only the entry under &#39;This PC&#39; remains.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Taskbar&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Align taskbar icons to the left. (Windows 11 only)&lt;/li&gt; &#xA; &lt;li&gt;Hide or change the search icon/box on the taskbar. (Windows 11 only)&lt;/li&gt; &#xA; &lt;li&gt;Hide the taskview button from the taskbar. (Windows 11 only)&lt;/li&gt; &#xA; &lt;li&gt;Disable the widgets service &amp;amp; hide icon from the taskbar.&lt;/li&gt; &#xA; &lt;li&gt;Hide the chat (meet now) icon from the taskbar.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Context Menu&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Restore the old Windows 10 style context menu. (Windows 11 only)&lt;/li&gt; &#xA; &lt;li&gt;Hide the &#39;Include in library&#39;, &#39;Give access to&#39; and &#39;Share&#39; options from the context menu. (Windows 10 only)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Other&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Disable Xbox game/screen recording (Also stops gaming overlay popups)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Advanced Features&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sysprep mode to apply changes to the Windows Default user profile.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Default Mode&lt;/h2&gt; &#xA;&lt;p&gt;The default mode applies the changes that are recommended for most users, expand the section below for more info.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Click to expand&lt;/summary&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;pre&gt;&lt;code&gt;Default mode applies the following changes:&#xA;- Remove the default selection of bloatware apps. (See below for full list)&#xA;- Disable telemetry, diagnostic data, activity history, app-launch tracking &amp;amp; targeted ads.&#xA;- Disable tips, tricks, suggestions and ads in start, settings, notifications, File Explorer, and on the lockscreen.&#xA;- Disable &amp;amp; remove Bing web search &amp;amp; Cortana from Windows search.&#xA;- Disable Windows Copilot. (Windows 11 only)&#xA;- Show file extensions for known file types.&#xA;- Hide the 3D objects folder under &#39;This pc&#39; from File Explorer. (Windows 10 only)&#xA;- Disable the widget service &amp;amp; hide the icon from the taskbar.&#xA;- Hide the Chat (meet now) icon from the taskbar.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;/blockquote&gt; &#xA; &lt;h4&gt;Apps that ARE removed by default&lt;/h4&gt; &#xA; &lt;details&gt; &#xA;  &lt;summary&gt;Click to expand&lt;/summary&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;pre&gt;&lt;code&gt;  Microsoft bloat:&#xA;  - Clipchamp.Clipchamp  &#xA;  - Microsoft.3DBuilder  &#xA;  - Microsoft.549981C3F5F10 (Cortana app)&#xA;  - Microsoft.BingFinance  &#xA;  - Microsoft.BingFoodAndDrink &#xA;  - Microsoft.BingHealthAndFitness&#xA;  - Microsoft.BingNews  &#xA;  - Microsoft.BingSearch* (Bing web search in Windows)&#xA;  - Microsoft.BingSports  &#xA;  - Microsoft.BingTranslator  &#xA;  - Microsoft.BingTravel   &#xA;  - Microsoft.BingWeather  &#xA;  - Microsoft.Getstarted (Cannot be uninstalled in Windows 11)&#xA;  - Microsoft.Messaging  &#xA;  - Microsoft.Microsoft3DViewer  &#xA;  - Microsoft.MicrosoftJournal&#xA;  - Microsoft.MicrosoftOfficeHub  &#xA;  - Microsoft.MicrosoftPowerBIForWindows  &#xA;  - Microsoft.MicrosoftSolitaireCollection  &#xA;  - Microsoft.MicrosoftStickyNotes  &#xA;  - Microsoft.MixedReality.Portal  &#xA;  - Microsoft.NetworkSpeedTest  &#xA;  - Microsoft.News  &#xA;  - Microsoft.Office.OneNote (Discontinued UWP version only, does not remove new MS365 versions)&#xA;  - Microsoft.Office.Sway  &#xA;  - Microsoft.OneConnect  &#xA;  - Microsoft.Print3D  &#xA;  - Microsoft.SkypeApp  &#xA;  - Microsoft.Todos  &#xA;  - Microsoft.WindowsAlarms  &#xA;  - Microsoft.WindowsFeedbackHub  &#xA;  - Microsoft.WindowsMaps  &#xA;  - Microsoft.WindowsSoundRecorder  &#xA;  - Microsoft.XboxApp (Old Xbox Console Companion App, no longer supported)&#xA;  - Microsoft.ZuneVideo  &#xA;  - MicrosoftCorporationII.MicrosoftFamily (Microsoft Family Safety)&#xA;  - MicrosoftTeams (Old personal version of MS Teams from the MS Store)&#xA;  - MSTeams (New MS Teams app)&#xA;&#xA;  Third party bloat:&#xA;  - ACGMediaPlayer  &#xA;  - ActiproSoftwareLLC  &#xA;  - AdobeSystemsIncorporated.AdobePhotoshopExpress  &#xA;  - Amazon.com.Amazon  &#xA;  - AmazonVideo.PrimeVideo&#xA;  - Asphalt8Airborne   &#xA;  - AutodeskSketchBook  &#xA;  - CaesarsSlotsFreeCasino  &#xA;  - COOKINGFEVER  &#xA;  - CyberLinkMediaSuiteEssentials  &#xA;  - DisneyMagicKingdoms  &#xA;  - Disney &#xA;  - Dolby  &#xA;  - DrawboardPDF  &#xA;  - Duolingo-LearnLanguagesforFree  &#xA;  - EclipseManager  &#xA;  - Facebook  &#xA;  - FarmVille2CountryEscape  &#xA;  - fitbit  &#xA;  - Flipboard  &#xA;  - HiddenCity  &#xA;  - HULULLC.HULUPLUS  &#xA;  - iHeartRadio  &#xA;  - Instagram&#xA;  - king.com.BubbleWitch3Saga  &#xA;  - king.com.CandyCrushSaga  &#xA;  - king.com.CandyCrushSodaSaga  &#xA;  - LinkedInforWindows  &#xA;  - MarchofEmpires  &#xA;  - Netflix  &#xA;  - NYTCrossword  &#xA;  - OneCalendar  &#xA;  - PandoraMediaInc  &#xA;  - PhototasticCollage  &#xA;  - PicsArt-PhotoStudio  &#xA;  - Plex  &#xA;  - PolarrPhotoEditorAcademicEdition  &#xA;  - Royal Revolt  &#xA;  - Shazam  &#xA;  - Sidia.LiveWallpaper  &#xA;  - SlingTV  &#xA;  - Speed Test  &#xA;  - Spotify  &#xA;  - TikTok&#xA;  - TuneInRadio  &#xA;  - Twitter  &#xA;  - Viber  &#xA;  - WinZipUniversal  &#xA;  - Wunderlist  &#xA;  - XING&#xA;  &#xA;  * App is removed when disabling Bing in Windows search.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/blockquote&gt; &#xA; &lt;/details&gt; &#xA; &lt;h4&gt;Apps that are NOT removed by default&lt;/h4&gt; &#xA; &lt;details&gt; &#xA;  &lt;summary&gt;Click to expand&lt;/summary&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;pre&gt;&lt;code&gt;  General apps that are not removed by default:&#xA;  - Microsoft.Edge (Edge browser, only removeable in the EEA)&#xA;  - Microsoft.GetHelp (Required for some Windows 11 Troubleshooters)&#xA;  - Microsoft.MSPaint (Paint 3D)&#xA;  - Microsoft.OutlookForWindows* (New mail app)&#xA;  - Microsoft.OneDrive (OneDrive consumer)&#xA;  - Microsoft.Paint (Classic Paint)&#xA;  - Microsoft.People* (Required for &amp;amp; included with Mail &amp;amp; Calendar)&#xA;  - Microsoft.ScreenSketch (Snipping Tool)&#xA;  - Microsoft.Whiteboard (Only preinstalled on devices with touchscreen and/or pen support)&#xA;  - Microsoft.Windows.Photos&#xA;  - Microsoft.WindowsCalculator&#xA;  - Microsoft.WindowsCamera&#xA;  - Microsoft.windowscommunicationsapps* (Mail &amp;amp; Calendar)&#xA;  - Microsoft.WindowsStore (Microsoft Store, NOTE: This app cannot be reinstalled!)&#xA;  - Microsoft.WindowsTerminal (New default terminal app in Windows 11)&#xA;  - Microsoft.YourPhone (Phone Link)&#xA;  - Microsoft.Xbox.TCUI (UI framework, removing this may break MS store, photos and certain games)&#xA;  - Microsoft.ZuneMusic (Modern Media Player)&#xA;&#xA;  Gaming related apps that are not removed by default:&#xA;  - Microsoft.GamingApp* (Modern Xbox Gaming App, required for installing some games)&#xA;  - Microsoft.XboxGameOverlay* (Game overlay, required for some games)&#xA;  - Microsoft.XboxGamingOverlay* (Game overlay, required for some games)&#xA;  - Microsoft.XboxIdentityProvider (Xbox sign-in framework, required for some games)&#xA;  - Microsoft.XboxSpeechToTextOverlay (Might be required for some games, NOTE: This app cannot be reinstalled!)&#xA;&#xA;  Developer related apps that are not removed by default:&#xA;  - Microsoft.PowerAutomateDesktop*&#xA;  - Microsoft.RemoteDesktop*&#xA;  - Windows.DevHome*&#xA;&#xA;  * Can be removed by running the script with the relevant parameter. (See parameters section below)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/blockquote&gt; &#xA; &lt;/details&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!Warning] Great care went into making sure this script does not unintentionally break any OS functionality, but use at your own risk!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Quick method&lt;/h3&gt; &#xA;&lt;p&gt;Download &amp;amp; run the script automatically via PowerShell.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open PowerShell as an administrator.&lt;/li&gt; &#xA; &lt;li&gt;Copy and paste the code below into PowerShell, press enter to run the script:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-PowerShell&#34;&gt;&amp;amp; ([scriptblock]::Create((irm &#34;https://win11debloat.raphi.re/&#34;)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Wait for the script to automatically download Win11Debloat.&lt;/li&gt; &#xA; &lt;li&gt;A new PowerShell window will open showing the Win11Debloat menu. Select either the default or custom mode to continue.&lt;/li&gt; &#xA; &lt;li&gt;Carefully read through and follow the on-screen instructions.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This method supports &lt;a href=&#34;https://raw.githubusercontent.com/Raphire/Win11Debloat/master/#parameters&#34;&gt;parameters&lt;/a&gt;. To use parameters simply run the script as explained above, but add the parameters at the end with spaces in between. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-PowerShell&#34;&gt;&amp;amp; ([scriptblock]::Create((irm &#34;https://win11debloat.raphi.re/&#34;))) -RunDefaults -Silent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Traditional method&lt;/h3&gt; &#xA;&lt;p&gt;Manually download &amp;amp; run the script.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Raphire/Win11Debloat/archive/master.zip&#34;&gt;Download the latest version of the script&lt;/a&gt;, and extract the .ZIP file to your desired location.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the Win11Debloat folder&lt;/li&gt; &#xA; &lt;li&gt;Double click the &lt;code&gt;Run.bat&lt;/code&gt; file to start the script. NOTE: If the console window immediately closes and nothing happens, try the advanced method below.&lt;/li&gt; &#xA; &lt;li&gt;Accept the Windows UAC prompt to run the script as administrator, this is required for the script to function.&lt;/li&gt; &#xA; &lt;li&gt;A new PowerShell window will now open showing the Win11Debloat menu. Select either the default or custom mode to continue.&lt;/li&gt; &#xA; &lt;li&gt;Carefully read through and follow the on-screen instructions.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Advanced method&lt;/h3&gt; &#xA;&lt;p&gt;Manually download the script &amp;amp; run the script via PowerShell. Only recommended for advanced users.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Raphire/Win11Debloat/archive/master.zip&#34;&gt;Download the latest version of the script&lt;/a&gt;, and extract the .ZIP file to your desired location.&lt;/li&gt; &#xA; &lt;li&gt;Open PowerShell as an administrator.&lt;/li&gt; &#xA; &lt;li&gt;Enable PowerShell execution by entering the following command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-PowerShell&#34;&gt;Set-ExecutionPolicy Unrestricted -Scope Process&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;In PowerShell, navigate to the directory where the files were extracted. Example: &lt;code&gt;cd c:\Win11Debloat&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Now run the script by entering the following command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-PowerShell&#34;&gt;.\Win11Debloat.ps1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;The Win11Debloat menu will now open. Select either the default or custom setup to continue.&lt;/li&gt; &#xA; &lt;li&gt;Carefully read through and follow the on-screen instructions.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This method supports &lt;a href=&#34;https://raw.githubusercontent.com/Raphire/Win11Debloat/master/#parameters&#34;&gt;parameters&lt;/a&gt;. To use parameters simply run the script as explained above, but add the parameters at the end with spaces in between. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-PowerShell&#34;&gt;.\Win11Debloat.ps1 -RemoveApps -DisableBing -Silent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Parameters&lt;/h3&gt; &#xA;&lt;p&gt;The quick and advanced method support parameters to tailor the behaviour of the script to your needs. A list of all the supported parameters and what they do can be found below.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Parameter&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-Silent&lt;/td&gt; &#xA;   &lt;td&gt;Suppresses all interactive prompts, so the script will run without requiring any user input.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-Sysprep&lt;/td&gt; &#xA;   &lt;td&gt;Run the script in Sysprep mode. All changes will be applied to the Windows default user profile and will only affect new user accounts.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-RunDefaults&lt;/td&gt; &#xA;   &lt;td&gt;Run the script with the default settings.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-RemoveApps&lt;/td&gt; &#xA;   &lt;td&gt;Remove the default selection of bloatware apps.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-RemoveAppsCustom&lt;/td&gt; &#xA;   &lt;td&gt;Remove all apps from the &#39;CustomAppsList&#39; file. IMPORTANT: Run the script with the &lt;code&gt;-RunAppConfigurator&lt;/code&gt; parameter to create this file first. No apps will be removed if this file does not exist!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-RunAppConfigurator&lt;/td&gt; &#xA;   &lt;td&gt;Run the app configurator to create a &#39;CustomAppsList&#39; file. Run the script with the &lt;code&gt;-RemoveAppsCustom&lt;/code&gt; parameter to remove these apps.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-RemoveCommApps&lt;/td&gt; &#xA;   &lt;td&gt;Remove the Mail, Calendar, and People apps.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-RemoveW11Outlook&lt;/td&gt; &#xA;   &lt;td&gt;Remove the new Outlook for Windows app.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-RemoveDevApps&lt;/td&gt; &#xA;   &lt;td&gt;Remove developer-related apps such as Remote Desktop, DevHome and Power Automate.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-RemoveGamingApps&lt;/td&gt; &#xA;   &lt;td&gt;Remove the Xbox App and Xbox Gamebar.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-ForceRemoveEdge&lt;/td&gt; &#xA;   &lt;td&gt;Forcefully remove Microsoft Edge, this option leaves Core, WebView and Update components installed for compatibility. NOT RECOMMENDED!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-DisableDVR&lt;/td&gt; &#xA;   &lt;td&gt;Disable Xbox game/screen recording feature &amp;amp; stop gaming overlay popups.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-ClearStart&lt;/td&gt; &#xA;   &lt;td&gt;Remove all pinned apps from start for the current user (Windows 11 update 22H2 or later only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-ClearStartAllUsers&lt;/td&gt; &#xA;   &lt;td&gt;Remove all pinned apps from start for all existing and new users. (Windows 11 update 22H2 or later only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-DisableTelemetry&lt;/td&gt; &#xA;   &lt;td&gt;Disable telemetry, diagnostic data &amp;amp; targeted ads.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-DisableBing&lt;/td&gt; &#xA;   &lt;td&gt;Disable &amp;amp; remove Bing web search, Bing AI &amp;amp; Cortana in Windows search.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-DisableSuggestions&lt;/td&gt; &#xA;   &lt;td&gt;Disable tips, tricks, suggestions and ads in start, settings, notifications and File Explorer.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;pre&gt;-DisableLockscreenTips&lt;/pre&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Disable tips &amp;amp; tricks on the lockscreen.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-RevertContextMenu&lt;/td&gt; &#xA;   &lt;td&gt;Restore the old Windows 10 style context menu. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-ShowHiddenFolders&lt;/td&gt; &#xA;   &lt;td&gt;Show hidden files, folders and drives.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-ShowKnownFileExt&lt;/td&gt; &#xA;   &lt;td&gt;Show file extensions for known file types.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideDupliDrive&lt;/td&gt; &#xA;   &lt;td&gt;Hide duplicate removable drive entries from the File Explorer sidepanel, so only the entry under &#39;This PC&#39; remains.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-TaskbarAlignLeft&lt;/td&gt; &#xA;   &lt;td&gt;Align taskbar icons to the left. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideSearchTb&lt;/td&gt; &#xA;   &lt;td&gt;Hide search icon from the taskbar. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-ShowSearchIconTb&lt;/td&gt; &#xA;   &lt;td&gt;Show search icon on the taskbar. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-ShowSearchLabelTb&lt;/td&gt; &#xA;   &lt;td&gt;Show search icon with label on the taskbar. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-ShowSearchBoxTb&lt;/td&gt; &#xA;   &lt;td&gt;Show search box on the taskbar. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideTaskview&lt;/td&gt; &#xA;   &lt;td&gt;Hide the taskview button from the taskbar. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideChat&lt;/td&gt; &#xA;   &lt;td&gt;Hide the chat (meet now) icon from the taskbar.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-DisableWidgets&lt;/td&gt; &#xA;   &lt;td&gt;Disable the widget service &amp;amp; hide the widget (news and interests) icon from the taskbar.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-DisableCopilot&lt;/td&gt; &#xA;   &lt;td&gt;Disable Windows copilot. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-DisableRecall&lt;/td&gt; &#xA;   &lt;td&gt;Disable Windows Recall snapshots. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideGallery&lt;/td&gt; &#xA;   &lt;td&gt;Hide the gallery section from the File Explorer sidepanel. (Windows 11 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideOnedrive&lt;/td&gt; &#xA;   &lt;td&gt;Hide the onedrive folder from the File Explorer sidepanel. (Windows 10 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-Hide3dObjects&lt;/td&gt; &#xA;   &lt;td&gt;Hide the 3D objects folder under &#39;This pc&#39; in File Explorer. (Windows 10 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideMusic&lt;/td&gt; &#xA;   &lt;td&gt;Hide the music folder under &#39;This pc&#39; in File Explorer. (Windows 10 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideIncludeInLibrary&lt;/td&gt; &#xA;   &lt;td&gt;Hide the &#39;Include in library&#39; option in the context menu. (Windows 10 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideGiveAccessTo&lt;/td&gt; &#xA;   &lt;td&gt;Hide the &#39;Give access to&#39; option in the context menu. (Windows 10 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-HideShare&lt;/td&gt; &#xA;   &lt;td&gt;Hide the &#39;Share&#39; option in the context menu. (Windows 10 only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>