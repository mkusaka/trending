<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-02T01:39:25Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>deepseek-ai/awesome-deepseek-integration</title>
    <updated>2025-02-02T01:39:25Z</updated>
    <id>tag:github.com,2025-02-02:/deepseek-ai/awesome-deepseek-integration</id>
    <link href="https://github.com/deepseek-ai/awesome-deepseek-integration" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;1000px&#34; alt=&#34;Awesome DeepSeek Integrations&#34; src=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/Awesome%20DeepSeek%20Integrations.png&#34;&gt; &lt;/p&gt; &#xA; &lt;h1&gt;Awesome DeepSeek Integrations &lt;img src=&#34;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true&#34; alt=&#34;Awesome&#34;&gt;&lt;/h1&gt; &#xA; &lt;p&gt;Integrate the DeepSeek API into popular softwares. Access &lt;a href=&#34;https://platform.deepseek.com/&#34;&gt;DeepSeek Open Platform&lt;/a&gt; to get an API key.&lt;/p&gt; &#xA; &lt;p&gt;English/&lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/README_cn.md&#34;&gt;简体中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Applications&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/13600976/224d547a-6fbc-47c8-859f-aa14813e2b0f&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/chatbox/README.md&#34;&gt;Chatbox&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Chatbox is a desktop client for multiple cutting-edge LLM models, available on Windows, Mac and Linux. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/bb65404c-f867-42d8-ae2b-281fe953ab54&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/chatgpt_next_web/README.md&#34;&gt; ChatGPT-Next-Web &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; ChatGPT Next Web is a cross-platform ChatGPT web UI, with GPT3, GPT4 &amp;amp; Gemini Pro support. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/liubai/assets/liubai-logo.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/liubai/README.md&#34;&gt;Liubai&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Liubai allows DeepSeek to have arms and legs to manipulate your notes, tasks, calendars, and to-do lists just on WeChat! &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/1ac9791b-87f7-41d9-9282-a70698344e1d&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/pal/README.md&#34;&gt; Pal - AI Chat Client&lt;br&gt;(iOS, ipadOS) &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Pal is a customized chat playground on iOS. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://www.librechat.ai/librechat.svg?sanitize=true&#34; alt=&#34;LibreChat&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://www.librechat.ai/docs/configuration/librechat_yaml/ai_endpoints/deepseek&#34;&gt;LibreChat&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; LibreChat is a customizable open-source app that seamlessly integrates DeepSeek for enhanced AI interactions. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/rss-translator/RSS-Translator/main/core/static/favicon.ico&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/rss_translator/README.md&#34;&gt; RSS Translator &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Translate RSS feeds into your language! &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ysnows/enconvo_media/main/logo.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/enconvo/README.md&#34;&gt; Enconvo &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Enconvo is the Launcher of the AI era, the entry point for all AI functions, and a thoughtful intelligent assistant.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/kangfenmao/cherry-studio/raw/main/src/renderer/src/assets/images/logo.png?raw=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34; style=&#34;border-radius: 10px&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/cherrystudio/README.md&#34;&gt;Cherry Studio&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A powerful desktop AI assistant for producer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://tomemo.top/images/logo.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/tomemo/README.md&#34;&gt; ToMemo (iOS, ipadOS) &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; A phrasebook + clipboard history + keyboard iOS app with integrated AI macromodeling for quick output use in the keyboard.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/buxuku/video-subtitle-master/refs/heads/main/resources/icon.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/buxuku/video-subtitle-master&#34;&gt;Video Subtitle Master&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt; Batch generate subtitles for videos, with the ability to translate subtitles into other languages. This is a client-side tool that supports both Mac and Windows platforms and integrates with multiple translation services such as Baidu, Volcengine, DeepLx, OpenAI, DeepSeek, and Ollama.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/UnknownEnergy/chatgpt-api/raw/master/dist/assets/chatworm-72x72.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/UnknownEnergy/chatgpt-api/raw/master/README.md&#34;&gt;Chatworm&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Chatworm is a webapp for multiple cutting-edge LLM models, open-source and also available on Android. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/tisfeng/ImageBed/main/uPic/icon_512x512@2x.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/tisfeng/Easydict&#34;&gt;Easydict&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt; Easydict is a concise and easy-to-use translation dictionary macOS App that allows you to easily and elegantly look up words or translate text. Supports calling large language model APIs for translation.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://www.raycast.com/favicon-production.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/raycast/README.md&#34;&gt;Raycast&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raycast.com/?via=ViGeng&#34;&gt;Raycast&lt;/a&gt; is a productivity tool for macOS that lets you control your tools with a few keystrokes. It supports various extensions including DeepSeek AI.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/193405629?s=200&amp;amp;v=4&#34; alt=&#34;PHP Client&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-php/deepseek-php-client/raw/master/README.md&#34;&gt;PHP Client&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Deepseek PHP Client is a robust and community-driven PHP client library for seamless integration with the Deepseek API. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/958072?s=200&amp;amp;v=4&#34; alt=&#34;Laravel Integration&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-php/deepseek-laravel/raw/master/README.md&#34;&gt;Laravel Integration&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Laravel wrapper for Deepseek PHP client, to seamless deepseek API integration with laravel applications.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/zotero/assets/zotero-icon.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/zotero/README_cn.md&#34;&gt;Zotero&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://www.zotero.org&#34;&gt;Zotero&lt;/a&gt; is a free, easy-to-use tool to help you collect, organize, annotate, cite, and share research.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/Siyuan/assets/image-20250122162731-7wkftbw.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/Siyuan/README.md&#34;&gt;SiYuan&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; SiYuan is a privacy-first personal knowledge management system that supports complete offline usage, as well as end-to-end encrypted data sync.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/ArvinLovegood/go-stock/raw/master/build/appicon.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/ArvinLovegood/go-stock/raw/master/README.md&#34;&gt;go-stock&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;go-stock is a Chinese stock data viewer built by Wails with NativeUI and powered by LLM.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/102771702?s=200&amp;amp;v=4&#34; alt=&#34;Wordware&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/wordware/README.md&#34;&gt;Wordware&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.wordware.ai/&#34;&gt;Wordware&lt;/a&gt; is a toolkit that enables anyone to build, iterate, and deploy their AI stack with just natural language.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://framerusercontent.com/images/xRJ6vNo9mUYeVNxt0KITXCXEuSk.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/langgenius/dify/&#34;&gt;Dify&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://dify.ai/&#34;&gt;Dify&lt;/a&gt; is an LLM application development platform that supports DeepSeek models for creating assistants, workflows, text generators, and more. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/refs/heads/v2-dev/public/favicon.ico&#34; alt=&#34;Big-AGI&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/enricoros/big-AGI/raw/v2-dev/README.md&#34;&gt;Big-AGI&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://big-agi.com/&#34;&gt;Big-AGI&lt;/a&gt; is a groundbreaking AI suite designed to democratize access to advanced artificial intelligence for everyone.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/LiberSonora/LiberSonora/raw/main/assets/avatar.jpeg?raw=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/LiberSonora/LiberSonora/raw/main/README_en.md&#34;&gt;LiberSonora&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; LiberSonora, meaning &#34;Voice of Freedom&#34;, is an AI-powered, robust, open-source audiobook toolkit that includes features like intelligent subtitle extraction, AI title generation, multilingual translation, with support for GPU acceleration and batch offline processing.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ripperhe/Bob/master/docs/_media/icon_128.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://bobtranslate.com/&#34;&gt;Bob&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://bobtranslate.com/&#34;&gt;Bob&lt;/a&gt; is a macOS translation &amp;amp; OCR tool ready to use in any app — right out of the box!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://agenticflow.ai/favicon.ico&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://agenticflow.ai/&#34;&gt;AgenticFlow&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://agenticflow.ai/&#34;&gt;AgenticFlow&lt;/a&gt; is a no-code platform where marketers build agentic AI workflows for go-to-market automation, powered by hundreds of everyday apps as tools for your AI agents.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;AI Agent frameworks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://panda.fans/_assets/favicons/apple-touch-icon.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/anda/README.md&#34;&gt;Anda&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;A Rust framework for AI agent development, designed to build a highly composable, autonomous, and perpetually memorizing network of AI agents.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;RAG frameworks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/33142505/77093e84-9f7c-4716-9168-bac962fa1372&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/ragflow/README.md&#34;&gt; RAGFlow &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; An open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models) to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted data. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;IM Application Plugins&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/InternLM/HuixiangDou/releases/download/v0.1.0rc1/huixiangdou.jpg&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/huixiangdou/README_cn.md&#34;&gt;HuixiangDou&lt;br&gt;(wechat,lark)&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Domain knowledge assistant in personal WeChat and Feishu, focusing on answering questions.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/RockChinQ/QChatGPT/raw/master/res/logo.png?raw=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/RockChinQ/QChatGPT&#34;&gt;QChatGPT&lt;br&gt;（QQ）&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; A QQ chatbot with high stability, plugin support, and real-time networking. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Browser Extensions&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/9d3f42b8-fcd0-47ab-8b06-1dd0554dd80e&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/immersive_translate/README.md&#34;&gt; Immersive Translate &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Immersive Translate is a bilingual webpage translation plugin. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://lh3.googleusercontent.com/K9i0qJb8phasC5wWf5tU68rhnfvX4swsE0hrhJP-WB3WV7MwE5KpMUIJvHKNHHRE6GKNIvIdTNSWoDMl_NggrmUsaw=s120&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/immersive_reading_guide/README.md&#34;&gt; Immersive Reading Guide &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; NO Sidebar!!! Immersive AI web summarization, ask questions... &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/8a301619-a3de-489b-81fd-69aaa7c1c561&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/chatgpt_box/README.md&#34;&gt; ChatGPT Box &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; ChatGPT Box is a ChatGPT integration in browser, completely for free. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/c3d9d100-247a-41cc-97c1-10b01ed25e70&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/hcfy/README.md&#34;&gt; hcfy (划词翻译) &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; hcfy (划词翻译) is a web browser extension to integrate multiple translation services. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://static.eudic.net/web/trans/en_trans.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/Lulu%20Translate/README.md&#34;&gt; Lulu Translate &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; The plugin provides mouse selection translation, paragraph-by-paragraph comparison translation, and PDF document translation functionalities. It can utilize various translation engines, such as DeepSeek AI, Bing, GPT, Google, etc. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/Bistutu/FluentRead/raw/refs/heads/main/public/icon/192.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://fluent.thinkstu.com/&#34;&gt; FluentRead &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; A revolutionary open-source browser translation plugin that enables everyone to have a native-like reading experience &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;VS Code Extensions&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/e4d082de-6f64-44b9-beaa-0de55d70cfab&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/continue/README.md&#34;&gt; Continue &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Continue is an open-source autopilot in IDE. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/cline/assets/favicon.png?raw=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/cline/README.md&#34;&gt; Cline &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Meet Cline, an AI assistant that can use your CLI aNd Editor. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;neovim Extensions&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/user-attachments/assets/d66dfc62-8e69-4b00-8549-d0158e48e2e0&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/avante.nvim/README.md&#34;&gt; avante.nvim &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; avante.nvim is an open-source autopilot in IDE. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/user-attachments/assets/d66dfc62-8e69-4b00-8549-d0158e48e2e0&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/llm.nvim/README.md&#34;&gt; llm.nvim &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; A free large language model(LLM) plugin that allows you to interact with LLM in Neovim. Supports any LLM, such as Deepseek, GPT, GLM, Kimi or local LLMs (such as ollama). &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/user-attachments/assets/d66dfc62-8e69-4b00-8549-d0158e48e2e0&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/codecompanion.nvim/README.md&#34;&gt; codecompanion.nvim &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; AI-powered coding, seamlessly in Neovim. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;JetBrains Extensions&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://plugins.jetbrains.com/files/21520/412905/icon/pluginIcon.svg?sanitize=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://ide.unitmesh.cc/quick-start&#34;&gt; AutoDev &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;‍AutoDev is an open-source AI coding assistant in JetBrain&#39;s IDE. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://plugins.jetbrains.com/files/21410/561595/icon/pluginIcon.svg?sanitize=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://plugins.jetbrains.com/plugin/21410-onegai-copilot&#34;&gt; Onegai Copilot &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Onegai Copilot is an AI coding assistant in JetBrain&#39;s IDE. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/e4d082de-6f64-44b9-beaa-0de55d70cfab&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/raw/main/docs/continue/README.md&#34;&gt; Continue &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Continue is an open-source autopilot in IDE. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/a18792721831/studyplugin/535b9cab69da0f97b42dcaebb00bb0d4ed15c8a6/translate/src/main/resources/META-INF/pluginIcon.svg?sanitize=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://plugins.jetbrains.com/plugin/18336-chinese-english-translate&#34;&gt;Chinese-English Translate&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Chinese-English Translate is a multiple translation services in JetBrain&#39;s IDE. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://plugins.jetbrains.com/files/24851/659002/icon/pluginIcon.svg?sanitize=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://plugins.jetbrains.com/plugin/24851-ai-git-commit&#34;&gt;AI Git Commit&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; This plugin uses AI to automatically generate commit messages based on the changes in your code. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Cursor&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://global.discourse-cdn.com/flex020/uploads/cursor1/original/2X/a/a4f78589d63edd61a2843306f8e11bad9590f0ca.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://www.cursor.com/&#34;&gt; Cursor &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;‍The AI Code Editor&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Emacs&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/0/08/EmacsIcon.svg?sanitize=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/karthink/gptel&#34;&gt; gptel &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;A simple LLM client for Emacs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/0/08/EmacsIcon.svg?sanitize=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/milanglacier/minuet-ai.el&#34;&gt; Minuet AI &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Dance with Intelligence in Your Code 💃&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Others&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/assets/59196087/c1e47b01-1766-4f7e-bfe6-ab3cb3991c30&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/deepseek-ai/awesome-deepseek-integration/tree/main/docs/siri_deepseek_shortcut&#34;&gt; siri_deepseek_shortcut &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Siri equiped with the DeepSeek API &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://github.com/n8n-io/n8n/raw/master/assets/n8n-logo.png?raw=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/rubickecho/n8n-deepseek&#34;&gt; n8n-nodes-deepseek &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; An N8N community node that supports direct integration with the DeepSeek API into workflows. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://framerusercontent.com/images/8rF2JOaZ8l9AvM4H6ezliw44aI.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/BerriAI/litellm&#34;&gt; LiteLLM &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format. Supports DeepSeek AI with cost tracking as well. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://i.postimg.cc/k5Z4YWjt/Screenshot-2025-01-23-at-6-08-01-PM.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/mem0ai/mem0&#34;&gt; Mem0 &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Mem0 enhances AI assistants with an intelligent memory layer, enabling personalized interactions and continuous learning over time. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://geneplore.com/img/geneplore_color_logo_circular.png&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://geneplore.com/bot&#34;&gt; Geneplore AI &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Geneplore AI runs one of the largest AI Discord bots, now with Deepseek v3 and R1. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://www.promptfoo.dev/img/logo-panda.svg?sanitize=true&#34; alt=&#34;Icon&#34; width=&#34;64&#34; height=&#34;auto&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/awesome-deepseek-integration/main/docs/promptfoo/README.md&#34;&gt; promptfoo &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Test and evaluate LLM prompts, including DeepSeek models. Compare different LLM providers, catch regressions, and evaluate responses. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>deepseek-ai/DeepSeek-Coder-V2</title>
    <updated>2025-02-02T01:39:25Z</updated>
    <id>tag:github.com,2025-02-02:/deepseek-ai/DeepSeek-Coder-V2</id>
    <link href="https://github.com/deepseek-ai/DeepSeek-Coder-V2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/logo.svg?raw=true&#34; width=&#34;60%&#34; alt=&#34;DeepSeek-V2&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34; style=&#34;line-height: 1;&#34;&gt; &#xA; &lt;a href=&#34;https://www.deepseek.com/&#34; target=&#34;_blank&#34; style=&#34;margin: 2px;&#34;&gt; &lt;img alt=&#34;Homepage&#34; src=&#34;https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/badge.svg?raw=true&#34; style=&#34;display: inline-block; vertical-align: middle;&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://chat.deepseek.com/&#34; target=&#34;_blank&#34; style=&#34;margin: 2px;&#34;&gt; &lt;img alt=&#34;Chat&#34; src=&#34;https://img.shields.io/badge/%F0%9F%A4%96%2520Chat-DeepSeek%2520V2-536af5?color=536af5&amp;amp;logoColor=white&#34; style=&#34;display: inline-block; vertical-align: middle;&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://huggingface.co/deepseek-ai&#34; target=&#34;_blank&#34; style=&#34;margin: 2px;&#34;&gt; &lt;img alt=&#34;Hugging Face&#34; src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&amp;amp;logoColor=white&#34; style=&#34;display: inline-block; vertical-align: middle;&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34; style=&#34;line-height: 1;&#34;&gt; &#xA; &lt;a href=&#34;https://discord.gg/Tc7c45Zzu5&#34; target=&#34;_blank&#34; style=&#34;margin: 2px;&#34;&gt; &lt;img alt=&#34;Discord&#34; src=&#34;https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&amp;amp;logoColor=white&amp;amp;color=7289da&#34; style=&#34;display: inline-block; vertical-align: middle;&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/qr.jpeg?raw=true&#34; target=&#34;_blank&#34; style=&#34;margin: 2px;&#34;&gt; &lt;img alt=&#34;Wechat&#34; src=&#34;https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&amp;amp;logoColor=white&#34; style=&#34;display: inline-block; vertical-align: middle;&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://twitter.com/deepseek_ai&#34; target=&#34;_blank&#34; style=&#34;margin: 2px;&#34;&gt; &lt;img alt=&#34;Twitter Follow&#34; src=&#34;https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&amp;amp;logoColor=white&#34; style=&#34;display: inline-block; vertical-align: middle;&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34; style=&#34;line-height: 1;&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-V2/raw/main/LICENSE-CODE&#34; style=&#34;margin: 2px;&#34;&gt; &lt;img alt=&#34;Code License&#34; src=&#34;https://img.shields.io/badge/Code_License-MIT-f5de53?&amp;amp;color=f5de53&#34; style=&#34;display: inline-block; vertical-align: middle;&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-V2/raw/main/LICENSE-MODEL&#34; style=&#34;margin: 2px;&#34;&gt; &lt;img alt=&#34;Model License&#34; src=&#34;https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&amp;amp;color=f5de53&#34; style=&#34;display: inline-block; vertical-align: middle;&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/#2-model-downloads&#34;&gt;Model Download&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/#3-evaluation-results&#34;&gt;Evaluation Results&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/#5-api-platform&#34;&gt;API Platform&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/#6-how-to-run-locally&#34;&gt;How to Use&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/#7-license&#34;&gt;License&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/#8-citation&#34;&gt;Citation&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://arxiv.org/pdf/2406.11931&#34;&gt;&lt;b&gt;Paper Link&lt;/b&gt;👁️&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1&gt;DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence&lt;/h1&gt; &#xA;&lt;h2&gt;1. Introduction&lt;/h2&gt; &#xA;&lt;p&gt;We present DeepSeek-Coder-V2, an open-source Mixture-of-Experts (MoE) code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks. Specifically, DeepSeek-Coder-V2 is further pre-trained from an intermediate checkpoint of DeepSeek-V2 with additional 6 trillion tokens. Through this continued pre-training, DeepSeek-Coder-V2 substantially enhances the coding and mathematical reasoning capabilities of DeepSeek-V2, while maintaining comparable performance in general language tasks. Compared to DeepSeek-Coder-33B, DeepSeek-Coder-V2 demonstrates significant advancements in various aspects of code-related tasks, as well as reasoning and general capabilities. Additionally, DeepSeek-Coder-V2 expands its support for programming languages from 86 to 338, while extending the context length from 16K to 128K.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;100%&#34; src=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/figures/performance.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;In standard benchmark evaluations, DeepSeek-Coder-V2 achieves superior performance compared to closed-source models such as GPT4-Turbo, Claude 3 Opus, and Gemini 1.5 Pro in coding and math benchmarks. The list of supported programming languages can be found &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/supported_langs.txt&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;2. Model Downloads&lt;/h2&gt; &#xA;&lt;p&gt;We release the DeepSeek-Coder-V2 with 16B and 236B parameters based on the &lt;a href=&#34;https://arxiv.org/pdf/2401.06066&#34;&gt;DeepSeekMoE&lt;/a&gt; framework, which has actived parameters of only 2.4B and 21B , including base and instruct models, to the public.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;#Total Params&lt;/strong&gt;&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;#Active Params&lt;/strong&gt;&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Context Length&lt;/strong&gt;&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;DeepSeek-Coder-V2-Lite-Base&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;16B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;2.4B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;128k&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Base&#34;&gt;🤗 HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;DeepSeek-Coder-V2-Lite-Instruct&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;16B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;2.4B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;128k&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct&#34;&gt;🤗 HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;DeepSeek-Coder-V2-Base&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;236B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;21B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;128k&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Base&#34;&gt;🤗 HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;DeepSeek-Coder-V2-Instruct&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;236B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;21B&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;128k&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct&#34;&gt;🤗 HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;3. Evaluation Results&lt;/h2&gt; &#xA;&lt;h3&gt;3.1 Code Generation&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;#TP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;#AP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;HumanEval&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MBPP+&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;LiveCodeBench&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;USACO&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Closed-Source Models&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Gemini-1.5-Pro&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;83.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;74.6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Claude-3-Opus&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;84.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;72.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;GPT-4-Turbo-1106&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;87.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;37.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;GPT-4-Turbo-0409&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;88.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;72.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;45.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;GPT-4o-0513&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;91.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;73.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;18.8&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Open-Source Models&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;CodeStral&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;78.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;DeepSeek-Coder-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;79.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Llama3-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;81.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;DeepSeek-Coder-V2-Lite-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.4B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;81.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;DeepSeek-Coder-V2-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;236B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;90.2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;76.2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;43.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;12.1&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;3.2 Code Completion&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;#TP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;#AP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;RepoBench (Python)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;RepoBench (Java)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;HumanEval FIM&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;CodeStral&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;46.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;45.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;83.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;DeepSeek-Coder-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;86.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;DeepSeek-Coder-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;86.4&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;DeepSeek-Coder-V2-Lite-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.4B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;86.4&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;3.3 Code Fixing&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;#TP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;#AP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Defects4J&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;SWE-Bench&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Aider&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Closed-Source Models&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemini-1.5-Pro&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;57.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Claude-3-Opus&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GPT-4-Turbo-1106&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;65.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GPT-4-Turbo-0409&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;63.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GPT-4o-0513&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;26.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;26.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;72.9&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Open-Source Models&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;CodeStral&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;DeepSeek-Coder-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama3-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;DeepSeek-Coder-V2-Lite-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.4B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;DeepSeek-Coder-V2-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;236B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;21.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;12.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;73.7&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;3.4 Mathematical Reasoning&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;#TP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;#AP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MATH&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;AIME 2024&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Math Odyssey&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Closed-Source Models&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemini-1.5-Pro&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;90.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;67.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2/30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Claude-3-Opus&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;95.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2/30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GPT-4-Turbo-1106&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;91.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;64.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1/30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GPT-4-Turbo-0409&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;93.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;73.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;3/30&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GPT-4o-0513&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;95.8&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;76.6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2/30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;53.2&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Open-Source Models&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama3-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;93.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1/30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;DeepSeek-Coder-V2-Lite-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.4B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;86.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0/30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;DeepSeek-Coder-V2-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;236B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;94.9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;75.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;4/30&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;53.7&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;3.5 General Natural Language&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Benchmark&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Domain&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;DeepSeek-V2-Lite Chat&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;DeepSeek-Coder-V2-Lite Instruct&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;DeepSeek-V2 Chat&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;DeepSeek-Coder-V2 Instruct&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;BBH&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;English&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;79.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;83.9&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;MMLU&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;English&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;55.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;78.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;79.2&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ARC-Easy&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;English&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;86.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;88.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;98.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;97.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ARC-Challenge&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;English&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;73.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;77.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;92.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;92.8&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;TriviaQA&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;English&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;65.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;59.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;86.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;82.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;NaturalQuestions&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;English&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;53.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;AGIEval&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;English&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;61.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;CLUEWSC&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Chinese&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;80.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;76.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;89.9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;85.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;C-Eval&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Chinese&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;78.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;79.4&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;CMMLU&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Chinese&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;62.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;62.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;81.6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;80.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Arena-Hard&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;65.0&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;AlpaceEval 2.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;38.9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;MT-Bench&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.37&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.81&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;8.97&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Alignbench&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.83&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;7.91&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.84&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;3.6 Context Window&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;80%&#34; src=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/figures/long_context.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Evaluation results on the &lt;code&gt;Needle In A Haystack&lt;/code&gt; (NIAH) tests. DeepSeek-Coder-V2 performs well across all context window lengths up to &lt;strong&gt;128K&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;4. Chat Website&lt;/h2&gt; &#xA;&lt;p&gt;You can chat with the DeepSeek-Coder-V2 on DeepSeek&#39;s official website: &lt;a href=&#34;https://coder.deepseek.com/sign_in&#34;&gt;coder.deepseek.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;5. API Platform&lt;/h2&gt; &#xA;&lt;p&gt;We also provide OpenAI-Compatible API at DeepSeek Platform: &lt;a href=&#34;https://platform.deepseek.com/&#34;&gt;platform.deepseek.com&lt;/a&gt;, and you can also pay-as-you-go at an unbeatable price.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;40%&#34; src=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/figures/model_price.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;6. How to run locally&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Here, we provide some examples of how to use DeepSeek-Coder-V2-Lite model. If you want to utilize DeepSeek-Coder-V2 in BF16 format for inference, 80GB*8 GPUs are required.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Inference with Huggingface&#39;s Transformers&lt;/h3&gt; &#xA;&lt;p&gt;You can directly employ &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Huggingface&#39;s Transformers&lt;/a&gt; for model inference.&lt;/p&gt; &#xA;&lt;h4&gt;Code Completion&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;import torch&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;deepseek-ai/DeepSeek-Coder-V2-Lite-Base&#34;, trust_remote_code=True)&#xA;model = AutoModelForCausalLM.from_pretrained(&#34;deepseek-ai/DeepSeek-Coder-V2-Lite-Base&#34;, trust_remote_code=True, torch_dtype=torch.bfloat16).cuda()&#xA;input_text = &#34;#write a quick sort algorithm&#34;&#xA;inputs = tokenizer(input_text, return_tensors=&#34;pt&#34;).to(model.device)&#xA;outputs = model.generate(**inputs, max_length=128)&#xA;print(tokenizer.decode(outputs[0], skip_special_tokens=True))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Code Insertion&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;import torch&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;deepseek-ai/DeepSeek-Coder-V2-Lite-Base&#34;, trust_remote_code=True)&#xA;model = AutoModelForCausalLM.from_pretrained(&#34;deepseek-ai/DeepSeek-Coder-V2-Lite-Base&#34;, trust_remote_code=True, torch_dtype=torch.bfloat16).cuda()&#xA;input_text = &#34;&#34;&#34;&amp;lt;｜fim▁begin｜&amp;gt;def quick_sort(arr):&#xA;    if len(arr) &amp;lt;= 1:&#xA;        return arr&#xA;    pivot = arr[0]&#xA;    left = []&#xA;    right = []&#xA;&amp;lt;｜fim▁hole｜&amp;gt;&#xA;        if arr[i] &amp;lt; pivot:&#xA;            left.append(arr[i])&#xA;        else:&#xA;            right.append(arr[i])&#xA;    return quick_sort(left) + [pivot] + quick_sort(right)&amp;lt;｜fim▁end｜&amp;gt;&#34;&#34;&#34;&#xA;inputs = tokenizer(input_text, return_tensors=&#34;pt&#34;).to(model.device)&#xA;outputs = model.generate(**inputs, max_length=128)&#xA;print(tokenizer.decode(outputs[0], skip_special_tokens=True)[len(input_text):])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Chat Completion&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;import torch&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct&#34;, trust_remote_code=True)&#xA;model = AutoModelForCausalLM.from_pretrained(&#34;deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct&#34;, trust_remote_code=True, torch_dtype=torch.bfloat16).cuda()&#xA;messages=[&#xA;    { &#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#34;write a quick sort algorithm in python.&#34;}&#xA;]&#xA;inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=&#34;pt&#34;).to(model.device)&#xA;# tokenizer.eos_token_id is the id of &amp;lt;｜end▁of▁sentence｜&amp;gt; token&#xA;outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)&#xA;print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The complete chat template can be found within &lt;code&gt;tokenizer_config.json&lt;/code&gt; located in the huggingface model repository.&lt;/p&gt; &#xA;&lt;p&gt;An example of chat template is as belows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt;｜begin▁of▁sentence｜&amp;gt;User: {user_message_1}&#xA;&#xA;Assistant: {assistant_message_1}&amp;lt;｜end▁of▁sentence｜&amp;gt;User: {user_message_2}&#xA;&#xA;Assistant:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also add an optional system message:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt;｜begin▁of▁sentence｜&amp;gt;{system_message}&#xA;&#xA;User: {user_message_1}&#xA;&#xA;Assistant: {assistant_message_1}&amp;lt;｜end▁of▁sentence｜&amp;gt;User: {user_message_2}&#xA;&#xA;Assistant:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the last round of dialogue, note that &#34;Assistant:&#34; has no space after the colon. Adding a space might cause the following issues on the 16B-Lite model:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;English questions receiving Chinese responses.&lt;/li&gt; &#xA; &lt;li&gt;Responses containing garbled text.&lt;/li&gt; &#xA; &lt;li&gt;Responses repeating excessively.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Older versions of Ollama had this bug (see &lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-Coder-V2/issues/12&#34;&gt;https://github.com/deepseek-ai/DeepSeek-Coder-V2/issues/12&lt;/a&gt;), but it has been fixed in the latest version.&lt;/p&gt; &#xA;&lt;h3&gt;Inference with SGLang (recommended)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/sgl-project/sglang&#34;&gt;SGLang&lt;/a&gt; currently supports MLA optimizations, FP8 (W8A8), FP8 KV Cache, and Torch Compile, offering the best latency and throughput among open-source frameworks. Here are some example commands to launch an OpenAI API-compatible server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# BF16, tensor parallelism = 8&#xA;python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-Coder-V2-Instruct --tp 8 --trust-remote-code&#xA;&#xA;# BF16, w/ torch.compile (The compilation can take several minutes)&#xA;python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct --trust-remote-code --enable-torch-compile&#xA;&#xA;# FP8, tensor parallelism = 8, FP8 KV cache&#xA;python3 -m sglang.launch_server --model neuralmagic/DeepSeek-Coder-V2-Instruct-FP8 --tp 8 --trust-remote-code --kv-cache-dtype fp8_e5m2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After launching the server, you can query it with OpenAI API&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import openai&#xA;client = openai.Client(&#xA;    base_url=&#34;http://127.0.0.1:30000/v1&#34;, api_key=&#34;EMPTY&#34;)&#xA;&#xA;# Chat completion&#xA;response = client.chat.completions.create(&#xA;    model=&#34;default&#34;,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful AI assistant&#34;},&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;List 3 countries and their capitals.&#34;},&#xA;    ],&#xA;    temperature=0,&#xA;    max_tokens=64,&#xA;)&#xA;print(response)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Inference with vLLM (recommended)&lt;/h3&gt; &#xA;&lt;p&gt;To utilize &lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt; for model inference, please merge this Pull Request into your vLLM codebase: &lt;a href=&#34;https://github.com/vllm-project/vllm/pull/4650&#34;&gt;https://github.com/vllm-project/vllm/pull/4650&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer&#xA;from vllm import LLM, SamplingParams&#xA;&#xA;max_model_len, tp_size = 8192, 1&#xA;model_name = &#34;deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct&#34;&#xA;tokenizer = AutoTokenizer.from_pretrained(model_name)&#xA;llm = LLM(model=model_name, tensor_parallel_size=tp_size, max_model_len=max_model_len, trust_remote_code=True, enforce_eager=True)&#xA;sampling_params = SamplingParams(temperature=0.3, max_tokens=256, stop_token_ids=[tokenizer.eos_token_id])&#xA;&#xA;messages_list = [&#xA;    [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Who are you?&#34;}],&#xA;    [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;write a quick sort algorithm in python.&#34;}],&#xA;    [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Write a piece of quicksort code in C++.&#34;}],&#xA;]&#xA;&#xA;prompt_token_ids = [tokenizer.apply_chat_template(messages, add_generation_prompt=True) for messages in messages_list]&#xA;&#xA;outputs = llm.generate(prompt_token_ids=prompt_token_ids, sampling_params=sampling_params)&#xA;&#xA;generated_text = [output.outputs[0].text for output in outputs]&#xA;print(generated_text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;7. License&lt;/h2&gt; &#xA;&lt;p&gt;This code repository is licensed under &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/LICENSE-CODE&#34;&gt;the MIT License&lt;/a&gt;. The use of DeepSeek-Coder-V2 Base/Instruct models is subject to &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/LICENSE-MODEL&#34;&gt;the Model License&lt;/a&gt;. DeepSeek-Coder-V2 series (including Base and Instruct) supports commercial use.&lt;/p&gt; &#xA;&lt;h2&gt;8. Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@article{zhu2024deepseek,&#xA;  title={DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence},&#xA;  author={Zhu, Qihao and Guo, Daya and Shao, Zhihong and Yang, Dejian and Wang, Peiyi and Xu, Runxin and Wu, Y and Li, Yukun and Gao, Huazuo and Ma, Shirong and others},&#xA;  journal={arXiv preprint arXiv:2406.11931},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;9. Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, please raise an issue or contact us at &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-Coder-V2/main/service@deepseek.com&#34;&gt;service@deepseek.com&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lightpanda-io/browser</title>
    <updated>2025-02-02T01:39:25Z</updated>
    <id>tag:github.com,2025-02-02:/lightpanda-io/browser</id>
    <link href="https://github.com/lightpanda-io/browser" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lightpanda: the headless browser designed for AI and automation&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://lightpanda.io&#34;&gt;&lt;img src=&#34;https://cdn.lightpanda.io/assets/images/logo/lpd-logo.png&#34; alt=&#34;Logo&#34; height=&#34;170&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;Lightpanda Browser&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://lightpanda.io/&#34;&gt;lightpanda.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/lightpanda-io/browser/commits/main&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/m/lightpanda-io/browser&#34; alt=&#34;Commit Activity&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lightpanda-io/browser/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/lightpanda-io/browser&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/lightpanda_io&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/lightpanda_io&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lightpanda-io/browser&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/lightpanda-io/browser&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://trendshift.io/repositories/12815&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/12815&#34; alt=&#34;lightpanda-io%2Fbrowser | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Lightpanda is the open-source browser made for headless usage:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Javascript execution&lt;/li&gt; &#xA; &lt;li&gt;Support of Web APIs (partial, WIP)&lt;/li&gt; &#xA; &lt;li&gt;Compatible with Playwright, Puppeteer through CDP (WIP)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Fast web automation for AI agents, LLM training, scraping and testing with minimal memory footprint:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ultra-low memory footprint (9x less than Chrome)&lt;/li&gt; &#xA; &lt;li&gt;Exceptionally fast execution (11x faster than Chrome) &amp;amp; instant startup&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img width=&#34;500px&#34; src=&#34;https://cdn.lightpanda.io/assets/images/benchmark_2024-12-04.png&#34;&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/lightpanda-io/demo&#34;&gt;benchmark details&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;h3&gt;Install from the nightly builds&lt;/h3&gt; &#xA;&lt;p&gt;You can download the last binary from the &lt;a href=&#34;https://github.com/lightpanda-io/browser/releases/tag/nightly&#34;&gt;nightly builds&lt;/a&gt; for Linux x86_64 and MacOS aarch64.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# Download the binary&#xA;$ wget https://github.com/lightpanda-io/browser/releases/download/nightly/lightpanda-x86_64-linux&#xA;$ chmod a+x ./lightpanda-x86_64-linux&#xA;$ ./lightpanda-x86_64-linux -h&#xA;usage: ./lightpanda-x86_64-linux [options] [URL]&#xA;&#xA;  start Lightpanda browser&#xA;&#xA;  * if an url is provided the browser will fetch the page and exit&#xA;  * otherwhise the browser starts a CDP server&#xA;&#xA;  -h, --help      Print this help message and exit.&#xA;  --host          Host of the CDP server (default &#34;127.0.0.1&#34;)&#xA;  --port          Port of the CDP server (default &#34;9222&#34;)&#xA;  --timeout       Timeout for incoming connections of the CDP server (in seconds, default &#34;3&#34;)&#xA;  --dump          Dump document in stdout (fetch mode only)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dump an URL&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./lightpanda-x86_64-linux --dump https://lightpanda.io&#xA;info(browser): GET https://lightpanda.io/ http.Status.ok&#xA;info(browser): fetch script https://api.website.lightpanda.io/js/script.js: http.Status.ok&#xA;info(browser): eval remote https://api.website.lightpanda.io/js/script.js: TypeError: Cannot read properties of undefined (reading &#39;pushState&#39;)&#xA;&amp;lt;!DOCTYPE html&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Start a CDP server&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./lightpanda-x86_64-linux --host 127.0.0.1 --port 9222&#xA;info(websocket): starting blocking worker to listen on 127.0.0.1:9222&#xA;info(server): accepting new conn...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the CDP server started, you can run a Puppeteer script by configuring the &lt;code&gt;browserWSEndpoint&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;&#39;use strict&#39;&#xA;&#xA;import puppeteer from &#39;puppeteer-core&#39;;&#xA;&#xA;// use browserWSEndpoint to pass the Lightpanda&#39;s CDP server address.&#xA;const browser = await puppeteer.connect({&#xA;  browserWSEndpoint: &#34;ws://127.0.0.1:9222&#34;,&#xA;});&#xA;&#xA;// The rest of your script remains the same.&#xA;const context = await browser.createBrowserContext();&#xA;const page = await context.newPage();&#xA;&#xA;await page.goto(&#39;https://wikipedia.com/&#39;);&#xA;&#xA;await page.close();&#xA;await context.close();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Build from sources&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;Lightpanda is written with &lt;a href=&#34;https://ziglang.org/&#34;&gt;Zig&lt;/a&gt; &lt;code&gt;0.13.0&lt;/code&gt;. You have to install it with the right version in order to build the project.&lt;/p&gt; &#xA;&lt;p&gt;Lightpanda also depends on &lt;a href=&#34;https://github.com/lightpanda-io/zig-js-runtime/&#34;&gt;zig-js-runtime&lt;/a&gt; (with v8), &lt;a href=&#34;https://www.netsurf-browser.org/&#34;&gt;Netsurf libs&lt;/a&gt; and &lt;a href=&#34;https://microsoft.github.io/mimalloc&#34;&gt;Mimalloc&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To be able to build the v8 engine for zig-js-runtime, you have to install some libs:&lt;/p&gt; &#xA;&lt;p&gt;For Debian/Ubuntu based Linux:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt install xz-utils \&#xA;    python3 ca-certificates git \&#xA;    pkg-config libglib2.0-dev \&#xA;    gperf libexpat1-dev \&#xA;    cmake clang&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For MacOS, you only need cmake:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install cmake&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install and build dependencies&lt;/h3&gt; &#xA;&lt;h4&gt;All in one build&lt;/h4&gt; &#xA;&lt;p&gt;You can run &lt;code&gt;make install&lt;/code&gt; to install deps all in one (or &lt;code&gt;make install-dev&lt;/code&gt; if you need the development versions).&lt;/p&gt; &#xA;&lt;p&gt;Be aware that the build task is very long and cpu consuming, as you will build from sources all dependencies, including the v8 Javascript engine.&lt;/p&gt; &#xA;&lt;h4&gt;Step by step build dependency&lt;/h4&gt; &#xA;&lt;p&gt;The project uses git submodules for dependencies.&lt;/p&gt; &#xA;&lt;p&gt;To init or update the submodules in the &lt;code&gt;vendor/&lt;/code&gt; directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make install-submodule&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Netsurf libs&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Netsurf libs are used for HTML parsing and DOM tree generation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make install-netsurf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For dev env, use &lt;code&gt;make install-netsurf-dev&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Mimalloc&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Mimalloc is used as a C memory allocator.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make install-mimalloc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For dev env, use &lt;code&gt;make install-mimalloc-dev&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note: when Mimalloc is built in dev mode, you can dump memory stats with the env var &lt;code&gt;MIMALLOC_SHOW_STATS=1&lt;/code&gt;. See &lt;a href=&#34;https://microsoft.github.io/mimalloc/environment.html&#34;&gt;https://microsoft.github.io/mimalloc/environment.html&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;zig-js-runtime&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Our own Zig/Javascript runtime, which includes the v8 Javascript engine.&lt;/p&gt; &#xA;&lt;p&gt;This build task is very long and cpu consuming, as you will build v8 from sources.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make install-zig-js-runtime&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For dev env, use &lt;code&gt;make install-zig-js-runtime-dev&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Test&lt;/h2&gt; &#xA;&lt;h3&gt;Unit Tests&lt;/h3&gt; &#xA;&lt;p&gt;You can test Lightpanda by running &lt;code&gt;make test&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Web Platform Tests&lt;/h3&gt; &#xA;&lt;p&gt;Lightpanda is tested against the standardized &lt;a href=&#34;https://web-platform-tests.org/&#34;&gt;Web Platform Tests&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The relevant tests cases are committed in a &lt;a href=&#34;https://github.com/lightpanda-io/wpt&#34;&gt;dedicated repository&lt;/a&gt; which is fetched by the &lt;code&gt;make install-submodule&lt;/code&gt; command.&lt;/p&gt; &#xA;&lt;p&gt;All the tests cases executed are located in the &lt;code&gt;tests/wpt&lt;/code&gt; sub-directory.&lt;/p&gt; &#xA;&lt;p&gt;For reference, you can easily execute a WPT test case with your browser via &lt;a href=&#34;https://wpt.live&#34;&gt;wpt.live&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Run WPT test suite&lt;/h4&gt; &#xA;&lt;p&gt;To run all the tests:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make wpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or one specific test:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make wpt Node-childNodes.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Add a new WPT test case&lt;/h4&gt; &#xA;&lt;p&gt;We add new relevant tests cases files when we implemented changes in Lightpanda.&lt;/p&gt; &#xA;&lt;p&gt;To add a new test, copy the file you want from the &lt;a href=&#34;https://github.com/web-platform-tests/wpt&#34;&gt;WPT repo&lt;/a&gt; into the &lt;code&gt;tests/wpt&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;⚠&lt;/span&gt; Please keep the original directory tree structure of &lt;code&gt;tests/wpt&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Lightpanda accepts pull requests through GitHub.&lt;/p&gt; &#xA;&lt;p&gt;You have to sign our &lt;a href=&#34;https://raw.githubusercontent.com/lightpanda-io/browser/main/CLA.md&#34;&gt;CLA&lt;/a&gt; during the pull request process otherwise we&#39;re not able to accept your contributions.&lt;/p&gt; &#xA;&lt;h2&gt;Why?&lt;/h2&gt; &#xA;&lt;h3&gt;Javascript execution is mandatory for the modern web&lt;/h3&gt; &#xA;&lt;p&gt;In the good old days, scraping a webpage was as easy as making an HTTP request, cURL-like. It’s not possible anymore, because Javascript is everywhere, like it or not:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ajax, Single Page App, infinite loading, “click to display”, instant search, etc.&lt;/li&gt; &#xA; &lt;li&gt;JS web frameworks: React, Vue, Angular &amp;amp; others&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Chrome is not the right tool&lt;/h3&gt; &#xA;&lt;p&gt;If we need Javascript, why not use a real web browser? Take a huge desktop application, hack it, and run it on the server. Hundreds or thousands of instances of Chrome if you use it at scale. Are you sure it’s such a good idea?&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Heavy on RAM and CPU, expensive to run&lt;/li&gt; &#xA; &lt;li&gt;Hard to package, deploy and maintain at scale&lt;/li&gt; &#xA; &lt;li&gt;Bloated, lots of features are not useful in headless usage&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Lightpanda is built for performance&lt;/h3&gt; &#xA;&lt;p&gt;If we want both Javascript and performance in a true headless browser, we need to start from scratch. Not another iteration of Chromium, really from a blank page. Crazy right? But that’s what we did:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Not based on Chromium, Blink or WebKit&lt;/li&gt; &#xA; &lt;li&gt;Low-level system programming language (Zig) with optimisations in mind&lt;/li&gt; &#xA; &lt;li&gt;Opinionated: without graphical rendering&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Status&lt;/h2&gt; &#xA;&lt;p&gt;Lightpanda is still a work in progress and is currently at a Beta stage.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;⚠&lt;/span&gt; You should expect most websites to fail or crash.&lt;/p&gt; &#xA;&lt;p&gt;Here are the key features we have implemented:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; HTTP loader&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; HTML parser and DOM tree (based on Netsurf libs)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Javascript support (v8)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Basic DOM APIs&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Ajax &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; XHR API&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Fetch API&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; DOM dump&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Basic CDP/websockets server&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;NOTE: There are hundreds of Web APIs. Developing a browser (even just for headless mode) is a huge task. Coverage will increase over time.&lt;/p&gt; &#xA;&lt;p&gt;You can also follow the progress of our Javascript support in our dedicated &lt;a href=&#34;https://github.com/lightpanda-io/zig-js-runtime#development&#34;&gt;zig-js-runtime&lt;/a&gt; project.&lt;/p&gt;</summary>
  </entry>
</feed>