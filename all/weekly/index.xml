<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-08T01:49:15Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>alist-org/alist</title>
    <updated>2023-01-08T01:49:15Z</updated>
    <id>tag:github.com,2023-01-08:/alist-org/alist</id>
    <link href="https://github.com/alist-org/alist" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üóÇÔ∏èA file list program that supports multiple storage, powered by Gin and Solidjs. / ‰∏Ä‰∏™ÊîØÊåÅÂ§öÂ≠òÂÇ®ÁöÑÊñá‰ª∂ÂàóË°®Á®ãÂ∫èÔºå‰ΩøÁî® Gin Âíå Solidjs„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://alist.nn.ci&#34;&gt;&lt;img height=&#34;100px&#34; alt=&#34;logo&#34; src=&#34;https://cdn.jsdelivr.net/gh/alist-org/logo@main/logo.svg?sanitize=true&#34;&gt;&lt;/a&gt; &#xA; &lt;p&gt;&lt;em&gt;üóÇÔ∏èA file list program that supports multiple storage, powered by Gin and Solidjs.&lt;/em&gt;&lt;/p&gt; &#xA; &lt;div&gt; &#xA;  &lt;a href=&#34;https://goreportcard.com/report/github.com/alist-org/alist/v3&#34;&gt; &lt;img src=&#34;https://goreportcard.com/badge/github.com/alist-org/alist/v3&#34; alt=&#34;latest version&#34;&gt; &lt;/a&gt; &#xA;  &lt;a href=&#34;https://github.com/Xhofe/alist/raw/main/LICENSE&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/Xhofe/alist&#34; alt=&#34;License&#34;&gt; &lt;/a&gt; &#xA;  &lt;a href=&#34;https://github.com/Xhofe/alist/actions?query=workflow%3ABuild&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/Xhofe/alist/build.yml?branch=main&#34; alt=&#34;Build status&#34;&gt; &lt;/a&gt; &#xA;  &lt;a href=&#34;https://github.com/Xhofe/alist/releases&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/release/Xhofe/alist&#34; alt=&#34;latest version&#34;&gt; &lt;/a&gt; &#xA;  &lt;a title=&#34;Crowdin&#34; target=&#34;_blank&#34; href=&#34;https://crwd.in/alist&#34;&gt; &lt;img src=&#34;https://badges.crowdin.net/alist/localized.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;div&gt; &#xA;  &lt;a href=&#34;https://github.com/Xhofe/alist/discussions&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/discussions/Xhofe/alist?color=%23ED8936&#34; alt=&#34;discussions&#34;&gt; &lt;/a&gt; &#xA;  &lt;a href=&#34;https://discord.gg/F4ymsH4xv2&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1018870125102895134?logo=discord&#34; alt=&#34;discussions&#34;&gt; &lt;/a&gt; &#xA;  &lt;a href=&#34;https://github.com/Xhofe/alist/releases&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/downloads/Xhofe/alist/total?color=%239F7AEA&amp;amp;logo=github&#34; alt=&#34;Downloads&#34;&gt; &lt;/a&gt; &#xA;  &lt;a href=&#34;https://hub.docker.com/r/xhofe/alist&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/xhofe/alist?color=%2348BB78&amp;amp;logo=docker&amp;amp;label=pulls&#34; alt=&#34;Downloads&#34;&gt; &lt;/a&gt; &#xA;  &lt;a href=&#34;https://alist.nn.ci/guide/sponsor.html&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/%24-sponsor-F87171.svg?sanitize=true&#34; alt=&#34;sponsor&#34;&gt; &lt;/a&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/alist-org/alist/main/README_cn.md&#34;&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/alist-org/alist/main/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/alist-org/alist/main/CODE_OF_CONDUCT.md&#34;&gt;CODE_OF_CONDUCT&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multiple storage &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Local storage&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.aliyundrive.com/&#34;&gt;Aliyundrive&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; OneDrive / Sharepoint (&lt;a href=&#34;https://www.office.com/&#34;&gt;global&lt;/a&gt;, &lt;a href=&#34;https://portal.partner.microsoftonline.cn&#34;&gt;cn&lt;/a&gt;,de,us)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://cloud.189.cn&#34;&gt;189cloud&lt;/a&gt; (Personal, Family)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://drive.google.com/&#34;&gt;GoogleDrive&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.123pan.com/&#34;&gt;123pan&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; FTP / SFTP&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.mypikpak.com/&#34;&gt;PikPak&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://aws.amazon.com/s3/&#34;&gt;S3&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.upyun.com/products/file-storage&#34;&gt;UPYUN Storage Service&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; WebDav(Support OneDrive/SharePoint without API)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Teambition(&lt;a href=&#34;https://www.teambition.com/&#34;&gt;China&lt;/a&gt;,&lt;a href=&#34;https://us.teambition.com/&#34;&gt;International&lt;/a&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.mediatrack.cn/&#34;&gt;Mediatrack&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://yun.139.com/&#34;&gt;139yun&lt;/a&gt; (Personal, Family)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://disk.yandex.com/&#34;&gt;YandexDisk&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;http://pan.baidu.com/&#34;&gt;BaiduNetdisk&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://pan.quark.cn&#34;&gt;Quark&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://pan.xunlei.com&#34;&gt;Thunder&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.lanzou.com/&#34;&gt;Lanzou&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.aliyundrive.com/&#34;&gt;Aliyundrive share&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://photos.google.com/&#34;&gt;Google photo&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://mega.nz&#34;&gt;Mega.nz&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://photo.baidu.com/&#34;&gt;Baidu photo&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; SMB&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://115.com/&#34;&gt;115&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Easy to deploy and out-of-the-box&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; File preview (PDF, markdown, code, plain text, ...)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Image preview in gallery mode&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Video and audio preview, support lyrics and subtitles&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Office documents preview (docx, pptx, xlsx, ...)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;code&gt;README.md&lt;/code&gt; preview rendering&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; File permalink copy and direct file download&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Dark mode&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; I18n&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Protected routes (password protection and authentication)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; WebDav (see &lt;a href=&#34;https://alist.nn.ci/guide/webdav.html&#34;&gt;https://alist.nn.ci/guide/webdav.html&lt;/a&gt; for details)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://hub.docker.com/r/xhofe/alist&#34;&gt;Docker Deploy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Cloudflare workers proxy&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; File/Folder package download&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Web upload(Can allow visitors to upload), delete, mkdir, rename, move and copy&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Offline download&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Copy files between two storage&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Document&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://alist.nn.ci/&#34;&gt;https://alist.nn.ci/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://al.nn.ci&#34;&gt;https://al.nn.ci&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Discussion&lt;/h2&gt; &#xA;&lt;p&gt;Please go to our &lt;a href=&#34;https://github.com/Xhofe/alist/discussions&#34;&gt;discussion forum&lt;/a&gt; for general questions, &lt;strong&gt;issues are for bug reports and feature request only.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Sponsor&lt;/h2&gt; &#xA;&lt;p&gt;AList is an open-source software, if you happen to like this project and want me to keep going, please consider sponsoring me or providing a single donation! Thanks for all the love and support: &lt;a href=&#34;https://alist.nn.ci/guide/sponsor.html&#34;&gt;https://alist.nn.ci/guide/sponsor.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Special sponsors&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhaoziyuan.la/&#34;&gt;ÊâæËµÑÊ∫ê - ÈòøÈáå‰∫ëÁõòËµÑÊ∫êÊêúÁ¥¢ÂºïÊìé&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kinhdown.com&#34;&gt;KinhDown ÁôæÂ∫¶‰∫ëÁõò‰∏çÈôêÈÄü‰∏ãËΩΩÔºÅÊ∞∏‰πÖÂÖçË¥πÔºÅÂ∑≤Á®≥ÂÆöËøêË°å3Âπ¥ÔºÅÈùûÂ∏∏ÂèØÈù†ÔºÅQÁæ§ -&amp;gt; 786799372&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jetbrains.com/&#34;&gt;JetBrains: Essential tools for software developers and teams&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Thanks goes to these wonderful people:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/alist-org/alist/graphs/contributors&#34;&gt;&lt;img src=&#34;http://contributors.nn.ci/api?repo=alist-org/alist&amp;amp;repo=alist-org/alist-web&amp;amp;repo=alist-org/docs&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;AList&lt;/code&gt; is open-source software licensed under the AGPL-3.0 license.&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This program is a free and open source project. It is designed to share files on the network disk, which is convenient for downloading and learning golang. Please abide by relevant laws and regulations when using it, and do not abuse it;&lt;/li&gt; &#xA; &lt;li&gt;This program is implemented by calling the official sdk/interface, without destroying the official interface behavior;&lt;/li&gt; &#xA; &lt;li&gt;This program only does 302 redirect/traffic forwarding, and does not intercept, store, or tamper with any user data;&lt;/li&gt; &#xA; &lt;li&gt;Before using this program, you should understand and bear the corresponding risks, including but not limited to account ban, download speed limit, etc., which is none of this program&#39;s business;&lt;/li&gt; &#xA; &lt;li&gt;If there is any infringement, please contact me by &lt;a href=&#34;mailto:i@nn.ci&#34;&gt;email&lt;/a&gt;, and it will be dealt with in time.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://nn.ci/&#34;&gt;@Blog&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/Xhofe&#34;&gt;@GitHub&lt;/a&gt; ¬∑ &lt;a href=&#34;https://t.me/alist_chat&#34;&gt;@TelegramGroup&lt;/a&gt; ¬∑ &lt;a href=&#34;https://discord.gg/F4ymsH4xv2&#34;&gt;@Discord&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
  <entry>
    <title>lucidrains/PaLM-rlhf-pytorch</title>
    <updated>2023-01-08T01:49:15Z</updated>
    <id>tag:github.com,2023-01-08:/lucidrains/PaLM-rlhf-pytorch</id>
    <link href="https://github.com/lucidrains/PaLM-rlhf-pytorch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;PaLM + RLHF - Pytorch (wip)&lt;/h2&gt; &#xA;&lt;p&gt;Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Maybe I&#39;ll add retrieval functionality too, √† la &lt;a href=&#34;https://github.com/lucidrains/RETRO-pytorch&#34;&gt;RETRO&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you are interested in replicating something like ChatGPT out in the open, please consider joining &lt;a href=&#34;https://discord.gg/xBPBXfcFHd&#34;&gt;Laion &lt;img alt=&#34;Join us on Discord&#34; src=&#34;https://img.shields.io/discord/823813159592001537?color=5865F2&amp;amp;logo=discord&amp;amp;logoColor=white&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository has gone viral without my permission. Next time, if you are promoting my unfinished repositories (notice the work in progress flag) for twitter engagement or eyeballs, at least (1) do your research or (2) be totally transparent with your readers about the capacity of the repository without resorting to clickbait. (1) I was not the first, CarperAI had been working on RLHF months before, link below. (2) There is no trained model. This is just the ship and overall map. We still need millions of dollars of compute + data to sail to the correct point in high dimensional parameter space. Even then, you need professional sailors (like Robin Rombach of Stable Diffusion fame) to actually guide the ship through turbulent times to that point.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://carper.ai/&#34;&gt;CarperAI&lt;/a&gt; had been working on &lt;a href=&#34;https://github.com/CarperAI/trlx&#34;&gt;an RLHF framework&lt;/a&gt; for large language models&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=sswA4j_IUxg&#34;&gt;Yannic Kilcher&lt;/a&gt; is also working on an &lt;a href=&#34;https://github.com/LAION-AI/Open-Assistant&#34;&gt;open sourced implementation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=SWwQ3k-DWyo&#34;&gt;AI Coffeebreak w/ Letitia&lt;/a&gt; | &lt;a href=&#34;https://www.youtube.com/watch?v=NpmnWgQgcsA&#34;&gt;Code Emporium&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Appreciation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://stability.ai/&#34;&gt;Stability.ai&lt;/a&gt; for the generous sponsorship to work on cutting edge artificial intelligence research&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/&#34;&gt;ü§ó Hugging Face&lt;/a&gt; and &lt;a href=&#34;https://carper.ai/&#34;&gt;CarperAI&lt;/a&gt; for penning the blog post &lt;a href=&#34;https://huggingface.co/blog/rlhf&#34;&gt;Illustrating Reinforcement Learning from Human Feedback (RLHF)&lt;/a&gt;, and the former also for their &lt;a href=&#34;https://huggingface.co/docs/accelerate/index&#34;&gt;accelerate&lt;/a&gt; library&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install palm-rlhf-pytorch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;First train &lt;code&gt;PaLM&lt;/code&gt;, like any other autoregressive transformer&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from palm_rlhf_pytorch import PaLM&#xA;&#xA;palm = PaLM(&#xA;    num_tokens = 20000,&#xA;    dim = 512,&#xA;    depth = 12&#xA;).cuda()&#xA;&#xA;seq = torch.randint(0, 20000, (1, 2048)).cuda()&#xA;&#xA;loss = palm(seq, return_loss = True)&#xA;loss.backward()&#xA;&#xA;# after much training, you can now generate sequences&#xA;&#xA;generated = palm.generate(2048) # (1, 2048)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then train your reward model, with the curated human feedback. In the original paper, they could not get reward model to be finetuned from a pretrained transformer without overfitting, but I gave the option to finetune with &lt;code&gt;LoRA&lt;/code&gt; anyways, since it is still open research.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from palm_rlhf_pytorch import PaLM, RewardModel&#xA;&#xA;palm = PaLM(&#xA;    num_tokens = 20000,&#xA;    dim = 512,&#xA;    depth = 12,&#xA;    causal = False&#xA;)&#xA;&#xA;reward_model = RewardModel(&#xA;    palm,&#xA;    num_binned_output = 5 # say rating from 1 to 5&#xA;).cuda()&#xA;&#xA;# mock data&#xA;&#xA;seq = torch.randint(0, 20000, (1, 1024)).cuda()&#xA;prompt_mask = torch.zeros(1, 1024).bool().cuda() # which part of the sequence is prompt, which part is response&#xA;labels = torch.randint(0, 5, (1,)).cuda()&#xA;&#xA;# train&#xA;&#xA;loss = reward_model(seq, prompt_mask = prompt_mask, labels = labels)&#xA;loss.backward()&#xA;&#xA;# after much training&#xA;&#xA;reward = reward_model(seq, prompt_mask = prompt_mask)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then you will pass your transformer and the rewards model to the &lt;code&gt;RLHFTrainer&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from palm_rlhf_pytorch import PaLM, RewardModel, RLHFTrainer&#xA;&#xA;# load your pretrained palm&#xA;&#xA;palm = PaLM(&#xA;    num_tokens = 20000,&#xA;    dim = 512,&#xA;    depth = 12&#xA;).cuda()&#xA;&#xA;palm.load(&#39;./path/to/pretrained/palm.pt&#39;)&#xA;&#xA;# load your pretrained reward model&#xA;&#xA;reward_model = RewardModel(&#xA;    palm,&#xA;    num_binned_output = 5&#xA;).cuda()&#xA;&#xA;reward_model.load(&#39;./path/to/pretrained/reward_model.pt&#39;)&#xA;&#xA;# ready your list of prompts for reinforcement learning&#xA;&#xA;prompts = torch.randint(0, 256, (50000, 512)).cuda() # 50k prompts&#xA;&#xA;# pass it all to the trainer and train&#xA;&#xA;trainer = RLHFTrainer(&#xA;    palm = palm,&#xA;    reward_model = reward_model,&#xA;    prompt_token_ids = prompts&#xA;)&#xA;&#xA;trainer.train(num_episodes = 50000)&#xA;&#xA;# then, if it succeeded...&#xA;# generate say 10 samples and use the reward model to return the best one&#xA;&#xA;answer = trainer.generate(2048, prompt = prompts[0], num_samples = 10) # (&amp;lt;= 2048,)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Todo&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;p&gt;clone base transformer with separate lora for critic&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;p&gt;also allow for non-LoRA based finetuning&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;p&gt;redo normalize to be able to have a masked version, not sure if anyone will ever use per token rewards / values, but good practice to implement&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;add Hugging Face accelerate and test out wandb instrumentation&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;search literature to figure out what is the latest SOTA for PPO, assuming RL field is still making progress.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;test the system using a pretrained sentiment network as reward model&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;write the memory in PPO to memmapped numpy file&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;get sampling with variable lengthed prompts working, even if it is not needed given bottleneck is human feedback&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;allow for finetuning penultimate N layers only in either actor or critic, assuming if pretrained&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;incorporate some learning points from Sparrow, given Letitia&#39;s video&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;simple web interface with django + htmx for collecting human feedback&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;equip with &lt;a href=&#34;https://github.com/hazyResearch/flash-attention&#34;&gt;the best attention&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citations&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{Stiennon2020LearningTS,&#xA;    title   = {Learning to summarize from human feedback},&#xA;    author  = {Nisan Stiennon and Long Ouyang and Jeff Wu and Daniel M. Ziegler and Ryan J. Lowe and Chelsea Voss and Alec Radford and Dario Amodei and Paul Christiano},&#xA;    journal = {ArXiv},&#xA;    year    = {2020},&#xA;    volume  = {abs/2009.01325}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{Chowdhery2022PaLMSL,&#xA;    title   = {PaLM: Scaling Language Modeling with Pathways},&#xA;    author  = {Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam M. Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Benton C. Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garc{\&#39;i}a and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Oliveira Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathleen S. Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},&#xA;    year    = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{Hu2021LoRALA,&#xA;    title   = {LoRA: Low-Rank Adaptation of Large Language Models},&#xA;    author  = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Weizhu Chen},&#xA;    journal = {ArXiv},&#xA;    year    = {2021},&#xA;    volume  = {abs/2106.09685}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{Sun2022ALT,&#xA;  title     = {A Length-Extrapolatable Transformer},&#xA;  author    = {Yutao Sun and Li Dong and Barun Patra and Shuming Ma and Shaohan Huang and Alon Benhaim and Vishrav Chaudhary and Xia Song and Furu Wei},&#xA;  year      = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>antonputra/tutorials</title>
    <updated>2023-01-08T01:49:15Z</updated>
    <id>tag:github.com,2023-01-08:/antonputra/tutorials</id>
    <link href="https://github.com/antonputra/tutorials" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DevOps by Example&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tutorials&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/antonputra/tutorials/main/assets/youtube-art.png?raw=true&#34; alt=&#34;YouTube Art&#34; title=&#34;Title&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Support&lt;/h1&gt; &#xA;&lt;p&gt;‚òï - &lt;a href=&#34;https://www.buymeacoffee.com/antonputra&#34;&gt;Buy Me a Coffee&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Contents&lt;/h1&gt; &#xA;&lt;p&gt;üìö - &lt;a href=&#34;https://raw.githubusercontent.com/antonputra/tutorials/main/docs/contents.md&#34;&gt;Lessons&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Social&lt;/h1&gt; &#xA;&lt;p&gt;üé• - &lt;a href=&#34;https://www.youtube.com/c/AntonPutra&#34;&gt;YouTube&lt;/a&gt;&lt;br&gt; üíº - &lt;a href=&#34;https://www.linkedin.com/in/anton-putra&#34;&gt;LinkedIn&lt;/a&gt;&lt;br&gt; üéô - &lt;a href=&#34;https://twitter.com/antonvputra&#34;&gt;Twitter&lt;/a&gt;&lt;br&gt; üì® - &lt;a href=&#34;mailto:me@antonputra.com&#34;&gt;me@antonputra.com&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>