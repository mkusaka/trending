<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-19T01:47:12Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>hpcaitech/ColossalAI</title>
    <updated>2023-02-19T01:47:12Z</updated>
    <id>tag:github.com,2023-02-19:/hpcaitech/ColossalAI</id>
    <link href="https://github.com/hpcaitech/ColossalAI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Making big AI models cheaper, easier, and more scalable&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Colossal-AI&lt;/h1&gt; &#xA;&lt;div id=&#34;top&#34; align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.colossalai.org/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/colossal-ai_logo_vertical.png&#34; alt=&#34;logo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;Colossal-AI: Making big AI models cheaper, easier, and more scalable&lt;/p&gt; &#xA; &lt;h3&gt; &lt;a href=&#34;https://arxiv.org/abs/2110.14883&#34;&gt; Paper &lt;/a&gt; | &lt;a href=&#34;https://www.colossalai.org/&#34;&gt; Documentation &lt;/a&gt; | &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples&#34;&gt; Examples &lt;/a&gt; | &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/discussions&#34;&gt; Forum &lt;/a&gt; | &lt;a href=&#34;https://medium.com/@hpcaitech&#34;&gt; Blog &lt;/a&gt;&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml&#34;&gt;&lt;img src=&#34;https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colossalai.readthedocs.io/en/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/colossalai/badge/?version=latest&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.codefactor.io/repository/github/hpcaitech/colossalai&#34;&gt;&lt;img src=&#34;https://www.codefactor.io/repository/github/hpcaitech/colossalai/badge&#34; alt=&#34;CodeFactor&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/hpcai-tech&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97HuggingFace-Join-yellow&#34; alt=&#34;HuggingFace badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp;amp;amp&#34; alt=&#34;slack badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E5%BE%AE%E4%BF%A1-%E5%8A%A0%E5%85%A5-green?logo=wechat&amp;amp;amp&#34; alt=&#34;WeChat badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;| &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/README.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/README-zh-Hans.md&#34;&gt;‰∏≠Êñá&lt;/a&gt; |&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Latest News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2023/02] &lt;a href=&#34;https://www.hpc-ai.tech/blog/colossal-ai-chatgpt&#34;&gt;Open source solution replicates ChatGPT training process! Ready to go with only 1.6GB GPU memory&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2023/01] &lt;a href=&#34;https://www.hpc-ai.tech/blog/colossal-ai-0-2-0&#34;&gt;Hardware Savings Up to 46 Times for AIGC and Automatic Parallelism&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2022/11] &lt;a href=&#34;https://www.hpc-ai.tech/blog/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper&#34;&gt;Diffusion Pretraining and Hardware Fine-Tuning Can Be Almost 7X Cheaper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2022/10] &lt;a href=&#34;https://www.hpc-ai.tech/blog/use-a-laptop-to-analyze-90-of-proteins-with-a-single-gpu-inference-sequence-exceeding&#34;&gt;Use a Laptop to Analyze 90% of Proteins, With a Single-GPU Inference Sequence Exceeding 10,000&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2022/09] &lt;a href=&#34;https://www.hpc-ai.tech/blog/hpc-ai-tech-completes-6-million-seed-and-angel-round-fundraising-led-by-bluerun-ventures-in-the&#34;&gt;HPC-AI Tech Completes $6 Million Seed and Angel Round Fundraising&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Why-Colossal-AI&#34;&gt;Why Colossal-AI&lt;/a&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Features&#34;&gt;Features&lt;/a&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Parallel-Training-Demo&#34;&gt;Parallel Training Demo&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#GPT-3&#34;&gt;GPT-3&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#GPT-2&#34;&gt;GPT-2&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#BERT&#34;&gt;BERT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#PaLM&#34;&gt;PaLM&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#OPT&#34;&gt;OPT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#ViT&#34;&gt;ViT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Recommendation-System-Models&#34;&gt;Recommendation System Models&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Single-GPU-Training-Demo&#34;&gt;Single GPU Training Demo&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#GPT-2-Single&#34;&gt;GPT-2&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#PaLM-Single&#34;&gt;PaLM&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Inference-Energon-AI-Demo&#34;&gt;Inference (Energon-AI) Demo&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#GPT-3-Inference&#34;&gt;GPT-3&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#OPT-Serving&#34;&gt;OPT-175B Online Serving for Text Generation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#BLOOM-Inference&#34;&gt;176B BLOOM&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Colossal-AI-in-the-Real-World&#34;&gt;Colossal-AI for Real World Applications&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#ChatGPT&#34;&gt;ChatGPT: Low-cost ChatGPT Equivalent Implementation Process&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#AIGC&#34;&gt;AIGC: Acceleration of Stable Diffusion&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Biomedicine&#34;&gt;Biomedicine: Acceleration of AlphaFold Protein Structure&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Installation&#34;&gt;Installation&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#PyPI&#34;&gt;PyPI&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Install-From-Source&#34;&gt;Install From Source&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Use-Docker&#34;&gt;Use Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Community&#34;&gt;Community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Cite-Us&#34;&gt;Cite Us&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why Colossal-AI&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://youtu.be/KnXSfjqkKN0&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/JamesDemmel_Colossal-AI.png&#34; width=&#34;600&#34;&gt; &lt;/a&gt; &#xA; &lt;p&gt;Prof. James Demmel (UC Berkeley): Colossal-AI makes training AI models efficient, easy, and scalable.&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;Colossal-AI provides a collection of parallel components for you. We aim to support you to write your distributed deep learning models just like how you write your model on your laptop. We provide user-friendly tools to kickstart distributed training and inference in a few lines.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Parallelism strategies&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Data Parallelism&lt;/li&gt; &#xA;   &lt;li&gt;Pipeline Parallelism&lt;/li&gt; &#xA;   &lt;li&gt;1D, &lt;a href=&#34;https://arxiv.org/abs/2104.05343&#34;&gt;2D&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2105.14500&#34;&gt;2.5D&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2105.14450&#34;&gt;3D&lt;/a&gt; Tensor Parallelism&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2105.13120&#34;&gt;Sequence Parallelism&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1910.02054&#34;&gt;Zero Redundancy Optimizer (ZeRO)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.02599&#34;&gt;Auto-Parallelism&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Heterogeneous Memory Management&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.05818&#34;&gt;PatrickStar&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Friendly Usage&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Parallelism based on configuration file&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Inference&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/EnergonAI&#34;&gt;Energon-AI&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Parallel Training Demo&lt;/h2&gt; &#xA;&lt;h3&gt;GPT-3&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT3-v5.png&#34; width=&#34;700/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Save 50% GPU resources, and 10.7% acceleration&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;GPT-2&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2.png&#34; width=&#34;800/&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;11x lower GPU memory consumption, and superlinear scaling efficiency with Tensor Parallelism&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/(updated)GPT-2.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;24x larger model size on the same hardware&lt;/li&gt; &#xA; &lt;li&gt;over 3x acceleration&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;BERT&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BERT.png&#34; width=&#34;800/&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2x faster training, or 50% longer sequence length&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;PaLM&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/PaLM-colossalai&#34;&gt;PaLM-colossalai&lt;/a&gt;: Scalable implementation of Google&#39;s Pathways Language Model (&lt;a href=&#34;https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html&#34;&gt;PaLM&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;OPT&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/OPT_update.png&#34; width=&#34;800/&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/metaseq&#34;&gt;Open Pretrained Transformer (OPT)&lt;/a&gt;, a 175-Billion parameter AI language model released by Meta, which stimulates AI programmers to perform various downstream tasks and application deployments because public pretrained model weights.&lt;/li&gt; &#xA; &lt;li&gt;45% speedup fine-tuning OPT at low cost in lines. &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples/language/opt&#34;&gt;[Example]&lt;/a&gt; &lt;a href=&#34;https://colossalai.org/docs/advanced_tutorials/opt_service&#34;&gt;[Online Serving]&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please visit our &lt;a href=&#34;https://www.colossalai.org/&#34;&gt;documentation&lt;/a&gt; and &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples&#34;&gt;examples&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h3&gt;ViT&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/ViT.png&#34; width=&#34;450&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;14x larger batch size, and 5x faster training for Tensor Parallelism = 64&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Recommendation System Models&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/CachedEmbedding&#34;&gt;Cached Embedding&lt;/a&gt;, utilize software cache to train larger embedding tables with a smaller GPU memory budget.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Single GPU Training Demo&lt;/h2&gt; &#xA;&lt;h3&gt;GPT-2&lt;/h3&gt; &#xA;&lt;p id=&#34;GPT-2-Single&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-GPU1.png&#34; width=&#34;450/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;20x larger model size on the same hardware&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;GPT-2-NVME&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-NVME.png&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;120x larger model size on the same hardware (RTX 3080)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;PaLM&lt;/h3&gt; &#xA;&lt;p id=&#34;PaLM-Single&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/PaLM-GPU1.png&#34; width=&#34;450/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;34x larger model size on the same hardware&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Inference (Energon-AI) Demo&lt;/h2&gt; &#xA;&lt;p id=&#34;GPT-3-Inference&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/inference_GPT-3.jpg&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/hpcaitech/EnergonAI&#34;&gt;Energon-AI&lt;/a&gt;: 50% inference acceleration on the same hardware&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://colossalai.org/docs/advanced_tutorials/opt_service&#34;&gt;OPT Serving&lt;/a&gt;: Try 175-billion-parameter OPT online services&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;BLOOM-Inference&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BLOOM%20Inference.PNG&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/EnergonAI/tree/main/examples/bloom&#34;&gt;BLOOM&lt;/a&gt;: Reduce hardware deployment costs of 176-billion-parameter BLOOM by more than 10 times.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Colossal-AI in the Real World&lt;/h2&gt; &#xA;&lt;h3&gt;ChatGPT&lt;/h3&gt; &#xA;&lt;p&gt;A low-cost &lt;a href=&#34;https://openai.com/blog/chatgpt/&#34;&gt;ChatGPT&lt;/a&gt; equivalent implementation process. &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/applications/ChatGPT&#34;&gt;[code]&lt;/a&gt; &lt;a href=&#34;https://www.hpc-ai.tech/blog/colossal-ai-chatgpt&#34;&gt;[blog]&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p id=&#34;ChatGPT_scaling&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT%20scaling.png&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Up to 7.73 times faster for single server training and 1.42 times faster for single-GPU inference&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;ChatGPT-1GPU&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT-1GPU.jpg&#34; width=&#34;450/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Up to 10.3x growth in model capacity on one GPU&lt;/li&gt; &#xA; &lt;li&gt;A mini demo training process requires only 1.62GB of GPU memory (any consumer-grade GPU)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;inference&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/LoRA%20data.jpg&#34; width=&#34;600/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Increase the capacity of the fine-tuning model by up to 3.7 times on a single GPU&lt;/li&gt; &#xA; &lt;li&gt;Keep in a sufficiently high running speed&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h3&gt;AIGC&lt;/h3&gt; &#xA;&lt;p&gt;Acceleration of AIGC (AI-Generated Content) models such as &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion v1&lt;/a&gt; and &lt;a href=&#34;https://github.com/Stability-AI/stablediffusion&#34;&gt;Stable Diffusion v2&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p id=&#34;diffusion_train&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20v2.png&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion&#34;&gt;Training&lt;/a&gt;: Reduce Stable Diffusion memory consumption by up to 5.6x and hardware cost by up to 46x (from A100 to RTX3060).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;diffusion_demo&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/DreamBooth.png&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/dreambooth&#34;&gt;DreamBooth Fine-tuning&lt;/a&gt;: Personalize your model using just 3-5 images of the desired subject.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;inference&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20Inference.jpg&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion&#34;&gt;Inference&lt;/a&gt;: Reduce inference GPU memory consumption by 2.5x.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h3&gt;Biomedicine&lt;/h3&gt; &#xA;&lt;p&gt;Acceleration of &lt;a href=&#34;https://alphafold.ebi.ac.uk/&#34;&gt;AlphaFold Protein Structure&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p id=&#34;FastFold&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/FastFold.jpg&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/FastFold&#34;&gt;FastFold&lt;/a&gt;: accelerating training and inference on GPU Clusters, faster data processing, inference sequence containing more than 10000 residues.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;xTrimoMultimer&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/xTrimoMultimer_Table.jpg&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biomap-research/xTrimoMultimer&#34;&gt;xTrimoMultimer&lt;/a&gt;: accelerating structure prediction of protein monomers and multimer by 11x.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Install from PyPI&lt;/h3&gt; &#xA;&lt;p&gt;You can easily install Colossal-AI with the following command. &lt;strong&gt;By defualt, we do not build PyTorch extensions during installation.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install colossalai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;However, if you want to build the PyTorch extensions during installation, you can set &lt;code&gt;CUDA_EXT=1&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_EXT=1 pip install colossalai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Otherwise, CUDA kernels will be built during runtime when you actually need it.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;We also keep release the nightly version to PyPI on a weekly basis. This allows you to access the unreleased features and bug fixes in the main branch. Installation can be made via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install colossalai-nightly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Download From Source&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The version of Colossal-AI will be in line with the main branch of the repository. Feel free to raise an issue if you encounter any problem. :)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/hpcaitech/ColossalAI.git&#xA;cd ColossalAI&#xA;&#xA;# install colossalai&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, we do not compile CUDA/C++ kernels. ColossalAI will build them during runtime. If you want to install and enable CUDA kernel fusion (compulsory installation when using fused optimizer):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;CUDA_EXT=1 pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Use Docker&lt;/h2&gt; &#xA;&lt;h3&gt;Pull from DockerHub&lt;/h3&gt; &#xA;&lt;p&gt;You can directly pull the docker image from our &lt;a href=&#34;https://hub.docker.com/r/hpcaitech/colossalai&#34;&gt;DockerHub page&lt;/a&gt;. The image is automatically uploaded upon release.&lt;/p&gt; &#xA;&lt;h3&gt;Build On Your Own&lt;/h3&gt; &#xA;&lt;p&gt;Run the following command to build a docker image from Dockerfile provided.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Building Colossal-AI from scratch requires GPU support, you need to use Nvidia Docker Runtime as the default when doing &lt;code&gt;docker build&lt;/code&gt;. More details can be found &lt;a href=&#34;https://stackoverflow.com/questions/59691207/docker-build-with-nvidia-runtime&#34;&gt;here&lt;/a&gt;. We recommend you install Colossal-AI from our &lt;a href=&#34;https://www.colossalai.org&#34;&gt;project page&lt;/a&gt; directly.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ColossalAI&#xA;docker build -t colossalai ./docker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the following command to start the docker container in interactive mode.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -ti --gpus all --rm --ipc=host colossalai bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;Join the Colossal-AI community on &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/discussions&#34;&gt;Forum&lt;/a&gt;, &lt;a href=&#34;https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w&#34;&gt;Slack&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png&#34; title=&#34;qrcode&#34;&gt;WeChat&lt;/a&gt; to share your suggestions, feedback, and questions with our engineering team.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you wish to contribute to this project, please follow the guideline in &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Thanks so much to all of our amazing contributors!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/graphs/contributors&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/contributor_avatar.png&#34; width=&#34;800px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;The order of contributor avatars is randomly shuffled.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;CI/CD&lt;/h2&gt; &#xA;&lt;p&gt;We leverage the power of &lt;a href=&#34;https://github.com/features/actions&#34;&gt;GitHub Actions&lt;/a&gt; to automate our development, release and deployment workflows. Please check out this &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/.github/workflows/README.md&#34;&gt;documentation&lt;/a&gt; on how the automated workflows are operated.&lt;/p&gt; &#xA;&lt;h2&gt;Cite Us&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{bian2021colossal,&#xA;  title={Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training},&#xA;  author={Bian, Zhengda and Liu, Hongxin and Wang, Boxiang and Huang, Haichen and Li, Yongbin and Wang, Chuanrui and Cui, Fan and You, Yang},&#xA;  journal={arXiv preprint arXiv:2110.14883},&#xA;  year={2021}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Colossal-AI has been accepted as official tutorials by top conference &lt;a href=&#34;https://sc22.supercomputing.org/&#34;&gt;SC&lt;/a&gt;, &lt;a href=&#34;https://aaai.org/Conferences/AAAI-23/&#34;&gt;AAAI&lt;/a&gt;, &lt;a href=&#34;https://ppopp23.sigplan.org/&#34;&gt;PPoPP&lt;/a&gt;, &lt;a href=&#34;https://cvpr2023.thecvf.com/&#34;&gt;CVPR&lt;/a&gt;, etc.&lt;/p&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>amazon-science/mm-cot</title>
    <updated>2023-02-19T01:47:12Z</updated>
    <id>tag:github.com,2023-02-19:/amazon-science/mm-cot</id>
    <link href="https://github.com/amazon-science/mm-cot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official implementation for &#34;Multimodal Chain-of-Thought Reasoning in Language Models&#34; (stay tuned and more will be updated)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Multimodal Chain-of-Thought Reasoning in Language Models&lt;/h1&gt; &#xA;&lt;h5 align=&#34;center&#34;&gt;&lt;i&gt;&#34;Imagine learning a textbook without figures or tables.&#34;&lt;/i&gt;&lt;/h5&gt; &#xA;&lt;p&gt;Multimodal-CoT incorporates vision features in a decoupled training framework. The framework consists of two training stages: (i) rationale generation and (ii) answer inference. Both stages share the same model architecture but differ in the input and output.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/amazon-science/mm-cot/main/vision_features/mm-cot.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Install all required python dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;p&gt;Download the dataset from the following repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://github.com/lupantech/ScienceQA/tree/main/data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Download the extracted vision features from &lt;a href=&#34;https://drive.google.com/file/d/13B0hc_F_45-UlqPLKSgRz-ALtFQ8kIJr/view?usp=share_link&#34;&gt;vision_features&lt;/a&gt; and unzip the files under &lt;code&gt;vision_features&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Training&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# rationale generation&#xA;CUDA_VISIBLE_DEVICES=0,1 python main.py \&#xA;    --model allenai/unifiedqa-t5-base \&#xA;    --user_msg rationale --img_type detr \&#xA;    --bs 8 --eval_bs 4 --eval_acc 10 --output_len 512 \&#xA;    --final_eval --prompt_format QCM-LE&#xA;&#xA;# answer inference&#xA;CUDA_VISIBLE_DEVICES=0,1 python main.py \&#xA;    --model allenai/unifiedqa-t5-base \&#xA;    --user_msg answer --img_type detr \&#xA;    --bs 8 --eval_bs 4 --eval_acc 10 --output_len 64 \&#xA;    --final_eval --prompt_format QCMG-A \&#xA;    --eval_le experiments/rationale_allenai-unifiedqa-t5-base_detr_QCM-LE_lr5e-05_bs16_op512_ep20/predictions_ans_eval.json \&#xA;    --test_le experiments/rationale_allenai-unifiedqa-t5-base_detr_QCM-LE_lr5e-05_bs16_op512_ep20/predictions_ans_test.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Inference&lt;/h3&gt; &#xA;&lt;p&gt;Our trained models are available at &lt;a href=&#34;https://drive.google.com/file/d/1FtTYOJPHnWnFfCxNC6M3gar4RAX5E21b/view?usp=share_link&#34;&gt;models&lt;/a&gt;. To use our trained models, please put the them under the &lt;code&gt;models&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# rationale generation&#xA;CUDA_VISIBLE_DEVICES=0,1 python main.py \&#xA;    --model allenai/unifiedqa-t5-base \&#xA;    --user_msg rationale --img_type detr \&#xA;    --bs 8 --eval_bs 4 --eval_acc 10 --output_len 512 \&#xA;    --final_eval --prompt_format QCM-LE \&#xA;    --evaluate_dir models/MM-CoT-UnifiedQA-base-Rationale&#xA;&#xA;# answer inference&#xA;CUDA_VISIBLE_DEVICES=0,1 python main.py \&#xA;    --model allenai/unifiedqa-t5-base \&#xA;    --user_msg answer --img_type detr \&#xA;    --bs 8 --eval_bs 4 --eval_acc 10 --output_len 64 \&#xA;    --final_eval --prompt_format QCMG-A \&#xA;    --eval_le models/rationale/predictions_ans_eval.json \&#xA;    --test_le models/rationale/predictions_ans_test.json \&#xA;    --evaluate_dir models/MM-CoT-UnifiedQA-base-Answer&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citing MM-CoT&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{zhang2023multicot,&#xA;  title={Multimodal Chain-of-Thought Reasoning in Language Models},&#xA;  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex},&#xA;  journal={arXiv preprint arXiv:2302.00923},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache-2.0 License.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;Part of our codes are adapted from &lt;a href=&#34;https://github.com/lupantech/ScienceQA&#34;&gt;ScienceQA&lt;/a&gt; and &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Transformers&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We thank Pan Lu for providing parameter size for ScienceQA baselines.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>alibaba/lowcode-engine</title>
    <updated>2023-02-19T01:47:12Z</updated>
    <id>tag:github.com,2023-02-19:/alibaba/lowcode-engine</id>
    <link href="https://github.com/alibaba/lowcode-engine" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An enterprise-class low-code technology stack with scale-out design / ‰∏ÄÂ•óÈù¢ÂêëÊâ©Â±ïËÆæËÆ°ÁöÑ‰ºÅ‰∏öÁ∫ß‰Ωé‰ª£Á†ÅÊäÄÊúØ‰ΩìÁ≥ª&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;http://lowcode-engine.cn&#34;&gt; &lt;img width=&#34;200&#34; src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01i8K9cD1d0HU7TjDtv_!!6000000003673-2-tps-500-591.png&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;LowCodeEngine&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;An enterprise-class low-code technology stack with scale-out design&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;http://npmjs.org/package/@alilc/lowcode-engine&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/@alilc/lowcode-engine.svg?style=flat-square&#34; alt=&#34;NPM version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://npmjs.org/package/@alilc/lowcode-engine&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/dm/@alilc/lowcode-engine.svg?style=flat-square&#34; alt=&#34;NPM downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/actions-cool/issues-helper&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/using-issues--helper-orange?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/alibaba/lowcode-engine/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22&#34;&gt;&lt;img src=&#34;https://flat.badgen.net/github/label-issues/alibaba/lowcode-engine/help%20wanted/open&#34; alt=&#34;Issues need help&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://codecov.io/gh/alibaba/lowcode-engine&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/alibaba/lowcode-engine/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://opensource.alibaba.com/contribution_leaderboard/details?projectValue=lowcode-engine&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/LowCodeEngine-Check%20Your%20Contribution-orange&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://lowcode-engine.cn&#34;&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i2/O1CN01UhoS7C1sNNhySvfWi_!!6000000005754-2-tps-2878-1588.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/alibaba/lowcode-engine/main/packages/engine/README-zh_CN.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‚ú® Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üåà An extension-oriented kernel engine extracted from an enterprise-level low-code platform, pursuing the design concept of the smallest kernel and the strongest ecology&lt;/li&gt; &#xA; &lt;li&gt;üì¶ Out-of-the-box high-quality ecological elements, including material systems, setters, plugins, etc.&lt;/li&gt; &#xA; &lt;li&gt;‚öôÔ∏è A complete tool chain, supporting the full-link R&amp;amp;D cycle of ecological elements such as material systems, setters, and plug-ins&lt;/li&gt; &#xA; &lt;li&gt;üîå Powerful expansion capability, has supported nearly 100 various vertical low-code platforms&lt;/li&gt; &#xA; &lt;li&gt;üõ° Developed with TypeScript, providing complete type definition files&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üéØ Compatible Environments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Modern browsers (Chrome &amp;gt;= 80, Edge &amp;gt;= 80, last 2 safari versions, last 2 firefox versions)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìö Engine Protocol&lt;/h2&gt; &#xA;&lt;p&gt;The engine fully implements the &#34;LowCodeEngine Basic Construction Protocol Specification&#34; and &#34;LowCodeEngine Material Protocol Specification&#34;. The protocol stack is a key part of whether materials in the low-code field can be circulated.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01IisBcy1dNBIg16QFM_!!6000000003723-2-tps-1916-1070.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üå∞ Usage example&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install @alilc/lowcode-engine --save-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;TIPS: Only cdn import is supported, npm package is used to provide code hinting capabilities such as typings&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;import { init, skeleton } from &#39;@alilc/lowcode-engine&#39;;&#xA;&#xA;skeleton.add({&#xA;  area: &#39;topArea&#39;,&#xA;  type: &#39;Widget&#39;,&#xA;  name: &#39;logo&#39;,&#xA;  content: YourFantaticLogo,&#xA;  contentProps: {&#xA;    logo:&#xA;      &#39;https://img.alicdn.com/tfs/TB1_SocGkT2gK0jSZFkXXcIQFXa-66-66.png&#39;,&#xA;    href: &#39;/&#39;,&#xA;  },&#xA;  props: {&#xA;    align: &#39;left&#39;,&#xA;    width: 100,&#xA;  },&#xA;});&#xA;&#xA;init(document.getElementById(&#39;lce&#39;));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Engineering configuration:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;externals&#34;: {&#xA;    &#34;@alilc/lowcode-engine&#34;: &#34;var window.AliLowCodeEngine&#34;,&#xA;    &#34;@alilc/lowcode-engine-ext&#34;: &#34;var window.AliLowCodeEngineExt&#34;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;cdn optional method:&lt;/h3&gt; &#xA;&lt;h4&gt;Method 1: alifd cdn&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;https://alifd.alicdn.com/npm/@alilc/lowcode-engine@1.0.18/dist/js/engine-core.js&#xA;&#xA;https://alifd.alicdn.com/npm/@alilc/lowcode-react-simulator-renderer@1.0.18/dist/js/react-simulator-renderer.js&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Method 2: uipaas cdn&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;https://uipaas-assets.com/prod/npm/@alilc/lowcode-engine/1.0.18/dist/js/engine-core.js&#xA;&#xA;https://uipaas-assets.com/prod/npm/@alilc/lowcode-react-simulator-renderer/1.0.18/dist/js/react-simulator-renderer.js&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Method 3: unpkg&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;https://unpkg.com/@alilc/lowcode-engine@1.0.18/dist/js/engine-core.js&#xA;&#xA;https://unpkg.com/@alilc/lowcode-react-simulator-renderer@1.0.18/dist/js/react-simulator-renderer.js&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Method 4: jsdelivr&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;https://cdn.jsdelivr.net/npm/@alilc/lowcode-engine@1.0.18/dist/js/engine-core.js&#xA;&#xA;https://cdn.jsdelivr.net/npm/@alilc/lowcode-react-simulator-renderer@1.0.18/dist/js/react-simulator-renderer.js&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Method 5: Use your own cdn&lt;/h4&gt; &#xA;&lt;p&gt;Pass the files under packages/engine/dist and packages/(react|rax)-simulator-renderer/dist in the source code to your cdn provider&lt;/p&gt; &#xA;&lt;h2&gt;üîó Related Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://lowcode-engine.cn/&#34;&gt;Official website home page&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://lowcode-engine.cn/demo&#34;&gt;Demo Play Now&lt;/a&gt; | &lt;a href=&#34;https://github.com/alibaba/lowcode-demo&#34;&gt;Engine Demo Repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/alibaba/lowcode-materials&#34;&gt;Official Materials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/alibaba/lowcode-engine-ext&#34;&gt;official setter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/alibaba/lowcode-plugins&#34;&gt;Official plugin (plugin)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lowcode-engine.cn/site/docs/guide/expand/editor/cli&#34;&gt;Ecological elements (materials, setters, plugins) toolchain&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://lowcode-engine.cn/doc&#34;&gt;User Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lowcode-engine.cn/site/docs/api/&#34;&gt;API&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This &lt;a href=&#34;https://github.com/lowcode-workspace/awesome-lowcode-engine&#34;&gt;awesome-lowcode-engine&lt;/a&gt; page links to a repository which records all of the tools\materials\solutions that use or built for the lowcode-engine, PR is welcomed.&lt;/p&gt; &#xA;&lt;h2&gt;üíª Local debugging&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone git@github.com:alibaba/lowcode-engine.git&#xA;$ cd lowcode-engine&#xA;$ npm install&#xA;$ npm run setup&#xA;$ npm start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;üì¢ npm access speed is slow, Alibaba employees can use tnpm, other students recommend using cnpm or specifying a mirror registry.&lt;/p&gt; &#xA; &lt;p&gt;üì¢ Windows environment must use &lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/install&#34;&gt;WSL&lt;/a&gt;, other terminals are not guaranteed to work normally&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;After lowcode-engine is started, several umd files are provided, which can be debugged in combination with the &lt;a href=&#34;https://github.com/alibaba/lowcode-demo&#34;&gt;lowcode-demo&lt;/a&gt; project. Refer to the file proxy rules &lt;a href=&#34;https://lowcode-engine.cn/site/docs/participate/prepare&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;ü§ù Participation&lt;/h2&gt; &#xA;&lt;p&gt;Please read first:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lowcode-engine.cn/site/docs/participate/prepare&#34;&gt;How to configure the engine debugging environment? &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lowcode-engine.cn/site/docs/participate/flow&#34;&gt;About the R&amp;amp;D collaboration process of the engine&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lowcode-engine.cn/site/docs/participate/config&#34;&gt;Engineering Configuration of Engine&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Strongly recommend reading &lt;a href=&#34;https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way&#34;&gt;&#34;The Wisdom of Asking Questions&#34;&lt;/a&gt;, [&#34;How to Ask Questions to the Open Source Community&#34;](https: //github.com/seajs/seajs/issues/545) and &lt;a href=&#34;http://www.chiark.greenend.org.uk/%7Esgtatham/bugs-cn.html&#34;&gt;How to Report Bugs Effectively&lt;/a&gt;, &lt;a href=&#34;https://zhuanlan.zhihu.com/p/25795393&#34;&gt; &#34;How to Submit Unanswerable Questions to Open Source Projects&#34;&lt;/a&gt;, better questions are easier to get help. (This paragraph refers to &lt;a href=&#34;https://github.com/ant-design/ant-design&#34;&gt;antd&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;About Pull Request:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the target branch to &lt;strong&gt;develop&lt;/strong&gt; other than &lt;strong&gt;main&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚ù§Ô∏è Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Special thanks to everyone who contributed to this project.&lt;/p&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://github.com/alibaba/lowcode-engine/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=alibaba/lowcode-engine&#34;&gt;&lt;/a&gt; &lt;/p&gt;</summary>
  </entry>
</feed>