<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-12-01T01:40:21Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>abi/screenshot-to-code</title>
    <updated>2024-12-01T01:40:21Z</updated>
    <id>tag:github.com,2024-12-01:/abi/screenshot-to-code</id>
    <link href="https://github.com/abi/screenshot-to-code" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Drop in a screenshot and convert it to clean code (HTML/Tailwind/React/Vue)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;screenshot-to-code&lt;/h1&gt; &#xA;&lt;p&gt;A simple tool to convert screenshots, mockups and Figma designs into clean, functional code using AI. &lt;strong&gt;Now supporting Claude Sonnet 3.5 and GPT-4o!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/abi/screenshot-to-code/assets/23818/6cebadae-2fe3-4986-ac6a-8fb9db030045&#34;&gt;https://github.com/abi/screenshot-to-code/assets/23818/6cebadae-2fe3-4986-ac6a-8fb9db030045&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Supported stacks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;HTML + Tailwind&lt;/li&gt; &#xA; &lt;li&gt;HTML + CSS&lt;/li&gt; &#xA; &lt;li&gt;React + Tailwind&lt;/li&gt; &#xA; &lt;li&gt;Vue + Tailwind&lt;/li&gt; &#xA; &lt;li&gt;Bootstrap&lt;/li&gt; &#xA; &lt;li&gt;Ionic + Tailwind&lt;/li&gt; &#xA; &lt;li&gt;SVG&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Supported AI models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Claude Sonnet 3.5 - Best model!&lt;/li&gt; &#xA; &lt;li&gt;GPT-4o - also recommended!&lt;/li&gt; &#xA; &lt;li&gt;DALL-E 3 or Flux Schnell (using Replicate) for image generation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/abi/screenshot-to-code/main/#-examples&#34;&gt;Examples&lt;/a&gt; section below for more demos.&lt;/p&gt; &#xA;&lt;p&gt;We also just added experimental support for taking a video/screen recording of a website in action and turning that into a functional prototype.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/abi/screenshot-to-code/assets/23818/8758ffa4-9483-4b9b-bb66-abd6d1594c33&#34; alt=&#34;google in app quick 3&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/abi/screenshot-to-code/wiki/Screen-Recording-to-Code&#34;&gt;Learn more about video here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/_abi_&#34;&gt;Follow me on Twitter for updates&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üåç Hosted Version&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://screenshottocode.com&#34;&gt;Try it live on the hosted version (paid)&lt;/a&gt;. If you&#39;re a large or medium enterprise (50+ employees), &lt;a href=&#34;https://cal.com/abi-raja-wy2pfh/30min&#34;&gt;book a meeting to explore custom enterprise plans&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üõ† Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The app has a React/Vite frontend and a FastAPI backend.&lt;/p&gt; &#xA;&lt;p&gt;Keys needed:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/abi/screenshot-to-code/raw/main/Troubleshooting.md&#34;&gt;OpenAI API key with access to GPT-4&lt;/a&gt; or Anthropic key (optional)&lt;/li&gt; &#xA; &lt;li&gt;Both are recommended so you can compare results from both Claude and GPT4o&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you&#39;d like to run the app with Ollama open source models (not recommended due to poor quality results), &lt;a href=&#34;https://github.com/abi/screenshot-to-code/issues/354#issuecomment-2435479853&#34;&gt;follow this comment&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Run the backend (I use Poetry for package management - &lt;code&gt;pip install poetry&lt;/code&gt; if you don&#39;t have it):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd backend&#xA;echo &#34;OPENAI_API_KEY=sk-your-key&#34; &amp;gt; .env&#xA;echo &#34;ANTHROPIC_API_KEY=your-key&#34; &amp;gt; .env&#xA;poetry install&#xA;poetry shell&#xA;poetry run uvicorn main:app --reload --port 7001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also set up the keys using the settings dialog on the front-end (click the gear icon after loading the frontend).&lt;/p&gt; &#xA;&lt;p&gt;Run the frontend:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd frontend&#xA;yarn&#xA;yarn dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open &lt;a href=&#34;http://localhost:5173&#34;&gt;http://localhost:5173&lt;/a&gt; to use the app.&lt;/p&gt; &#xA;&lt;p&gt;If you prefer to run the backend on a different port, update VITE_WS_BACKEND_URL in &lt;code&gt;frontend/.env.local&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;For debugging purposes, if you don&#39;t want to waste GPT4-Vision credits, you can run the backend in mock mode (which streams a pre-recorded response):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;MOCK=true poetry run uvicorn main:app --reload --port 7001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Docker&lt;/h2&gt; &#xA;&lt;p&gt;If you have Docker installed on your system, in the root directory, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#34;OPENAI_API_KEY=sk-your-key&#34; &amp;gt; .env&#xA;docker-compose up -d --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The app will be up and running at &lt;a href=&#34;http://localhost:5173&#34;&gt;http://localhost:5173&lt;/a&gt;. Note that you can&#39;t develop the application with this setup as the file changes won&#39;t trigger a rebuild.&lt;/p&gt; &#xA;&lt;h2&gt;üôã‚Äç‚ôÇÔ∏è FAQs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;I&#39;m running into an error when setting up the backend. How can I fix it?&lt;/strong&gt; &lt;a href=&#34;https://github.com/abi/screenshot-to-code/issues/3#issuecomment-1814777959&#34;&gt;Try this&lt;/a&gt;. If that still doesn&#39;t work, open an issue.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How do I get an OpenAI API key?&lt;/strong&gt; See &lt;a href=&#34;https://github.com/abi/screenshot-to-code/raw/main/Troubleshooting.md&#34;&gt;https://github.com/abi/screenshot-to-code/blob/main/Troubleshooting.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How can I configure an OpenAI proxy?&lt;/strong&gt; - If you&#39;re not able to access the OpenAI API directly (due to e.g. country restrictions), you can try a VPN or you can configure the OpenAI base URL to use a proxy: Set OPENAI_BASE_URL in the &lt;code&gt;backend/.env&lt;/code&gt; or directly in the UI in the settings dialog. Make sure the URL has &#34;v1&#34; in the path so it should look like this: &lt;code&gt;https://xxx.xxxxx.xxx/v1&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How can I update the backend host that my front-end connects to?&lt;/strong&gt; - Configure VITE_HTTP_BACKEND_URL and VITE_WS_BACKEND_URL in front/.env.local For example, set VITE_HTTP_BACKEND_URL=&lt;a href=&#34;http://124.10.20.1:7001&#34;&gt;http://124.10.20.1:7001&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Seeing UTF-8 errors when running the backend?&lt;/strong&gt; - On windows, open the .env file with notepad++, then go to Encoding and select UTF-8.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How can I provide feedback?&lt;/strong&gt; For feedback, feature requests and bug reports, open an issue or ping me on &lt;a href=&#34;https://twitter.com/_abi_&#34;&gt;Twitter&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìö Examples&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;NYTimes&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Original&lt;/th&gt; &#xA;   &lt;th&gt;Replica&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;1238&#34; alt=&#34;Screenshot 2023-11-20 at 12 54 03 PM&#34; src=&#34;https://github.com/abi/screenshot-to-code/assets/23818/3b644dfa-9ca6-4148-84a7-3405b6671922&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;1414&#34; alt=&#34;Screenshot 2023-11-20 at 12 59 56 PM&#34; src=&#34;https://github.com/abi/screenshot-to-code/assets/23818/26201c9f-1a28-4f35-a3b1-1f04e2b8ce2a&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Instagram page (with not Taylor Swift pics)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/abi/screenshot-to-code/assets/23818/503eb86a-356e-4dfc-926a-dabdb1ac7ba1&#34;&gt;https://github.com/abi/screenshot-to-code/assets/23818/503eb86a-356e-4dfc-926a-dabdb1ac7ba1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Hacker News&lt;/strong&gt; but it gets the colors wrong at first so we nudge it&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/abi/screenshot-to-code/assets/23818/3fec0f77-44e8-4fb3-a769-ac7410315e5d&#34;&gt;https://github.com/abi/screenshot-to-code/assets/23818/3fec0f77-44e8-4fb3-a769-ac7410315e5d&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ed-donner/llm_engineering</title>
    <updated>2024-12-01T01:40:21Z</updated>
    <id>tag:github.com,2024-12-01:/ed-donner/llm_engineering</id>
    <link href="https://github.com/ed-donner/llm_engineering" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Repo to accompany my mastering LLM engineering course&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLM Engineering - Master AI and LLMs&lt;/h1&gt; &#xA;&lt;h2&gt;Your 8 week journey to proficiency starts today&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ed-donner/llm_engineering/main/voyage.jpg&#34; alt=&#34;Voyage&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;I&#39;m so happy you&#39;re joining me on this path. We&#39;ll be building immensely satisfying projects in the coming weeks. Some will be easy, some will be challenging, many will ASTOUND you! The projects build on each other so you develop deeper and deeper expertise each week. One thing&#39;s for sure: you&#39;re going to have a lot of fun along the way.&lt;/p&gt; &#xA;&lt;h3&gt;A note before you begin&lt;/h3&gt; &#xA;&lt;p&gt;I&#39;m here to help you be most successful with your learning! If you hit any snafus, or if you have any ideas on how I can improve the course, please do reach out in the platform or by emailing me direct (&lt;a href=&#34;mailto:ed@edwarddonner.com&#34;&gt;ed@edwarddonner.com&lt;/a&gt;). It&#39;s always great to connect with people on LinkedIn to build up the community - you&#39;ll find me here:&lt;br&gt; &lt;a href=&#34;https://www.linkedin.com/in/eddonner/&#34;&gt;https://www.linkedin.com/in/eddonner/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Resources to accompany the course, including the slides and useful links, are here:&lt;br&gt; &lt;a href=&#34;https://edwarddonner.com/2024/11/13/llm-engineering-resources/&#34;&gt;https://edwarddonner.com/2024/11/13/llm-engineering-resources/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Instant Gratification instructions for Week 1, Day 1&lt;/h2&gt; &#xA;&lt;p&gt;We will start the course by installing Ollama so you can see results immediately!&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download and install Ollama from &lt;a href=&#34;https://ollama.com&#34;&gt;https://ollama.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;On a PC, start a Command prompt / Powershell (Press Win + R, type &lt;code&gt;cmd&lt;/code&gt;, and press Enter). On a Mac, start a Terminal (Applications &amp;gt; Utilities &amp;gt; Terminal).&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;ollama run llama3.2&lt;/code&gt; or for smaller machines try &lt;code&gt;ollama run llama3.2:1b&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;If this doesn&#39;t work, you may need to run &lt;code&gt;ollama serve&lt;/code&gt; in another Powershell (Windows) or Terminal (Mac), and try step 3 again&lt;/li&gt; &#xA; &lt;li&gt;And if that doesn&#39;t work on your box, I&#39;ve set up this on the cloud. This is on Google Colab, which will need you to have a Google account to sign in, but is free: &lt;a href=&#34;https://colab.research.google.com/drive/1-_f5XZPsChvfU1sJ0QqCePtIuc55LSdu?usp=sharing&#34;&gt;https://colab.research.google.com/drive/1-_f5XZPsChvfU1sJ0QqCePtIuc55LSdu?usp=sharing&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Any problems, please contact me!&lt;/p&gt; &#xA;&lt;h2&gt;Then, Setup instructions&lt;/h2&gt; &#xA;&lt;p&gt;After we do the Ollama quick project, and after I introduce myself and the course, we get to work with the full environment setup.&lt;/p&gt; &#xA;&lt;p&gt;Hopefully I&#39;ve done a decent job of making these guides bulletproof - but please contact me right away if you hit roadblocks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PC people please follow the instructions in &lt;a href=&#34;https://raw.githubusercontent.com/ed-donner/llm_engineering/main/SETUP-PC.md&#34;&gt;SETUP-PC.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Mac people please follow the instructions in &lt;a href=&#34;https://raw.githubusercontent.com/ed-donner/llm_engineering/main/SETUP-mac.md&#34;&gt;SETUP-mac.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Linux people, the Mac instructions should be close enough!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;An important point on API costs (which are optional! No need to spend if you don&#39;t wish)&lt;/h3&gt; &#xA;&lt;p&gt;During the course, I&#39;ll suggest you try out the leading models at the forefront of progress, known as the Frontier models. I&#39;ll also suggest you run open-source models using Google Colab. These services have some charges, but I&#39;ll keep cost minimal - like, a few cents at a time. And I&#39;ll provide alternatives if you&#39;d prefer not to use them.&lt;/p&gt; &#xA;&lt;p&gt;Please do monitor your API usage to ensure you&#39;re comfortable with spend; I&#39;ve included links below. There&#39;s no need to spend anything more than a couple of dollars for the entire course. Some AI providers such as OpenAI require a minimum credit like $5 or local equivalent; we should only spend a fraction of it, and you&#39;ll have plenty of opportunity to put it to good use in your own projects. During Week 7 you have an option to spend a bit more if you&#39;re enjoying the process - I spend about $10 myself and the results make me very happy indeed! But it&#39;s not necessary in the least; the important part is that you focus on learning.&lt;/p&gt; &#xA;&lt;p&gt;I&#39;ll also show you an alternative if you&#39;d rather not spend anything on APIs.&lt;/p&gt; &#xA;&lt;h3&gt;How this Repo is organized&lt;/h3&gt; &#xA;&lt;p&gt;There are folders for each of the &#34;weeks&#34;, representing modules of the class, culminating in a powerful autonomous Agentic AI solution in Week 8 that draws on many of the prior weeks.&lt;br&gt; Follow the setup instructions above, then open the Week 1 folder and prepare for joy.&lt;/p&gt; &#xA;&lt;h3&gt;The most important part&lt;/h3&gt; &#xA;&lt;p&gt;The mantra of the course is: the best way to learn is by &lt;strong&gt;DOING&lt;/strong&gt;. I don&#39;t type all the code during the course; I execute it for you to see the results. You should work along with me or after each lecture, running each cell, inspecting the objects to get a detailed understanding of what&#39;s happening. Then tweak the code and make it your own. There are juicy challenges for you throughout the course. I&#39;d love it if you wanted to push your code so I can follow along with your progress, and I can make your solutions available to others so we share in your progress. While the projects are enjoyable, they are first and foremost designed to be &lt;em&gt;educational&lt;/em&gt;, teaching you business skills that can be put into practice in your work.&lt;/p&gt; &#xA;&lt;h2&gt;Starting in Week 3, we&#39;ll also be using Google Colab for running with GPUs&lt;/h2&gt; &#xA;&lt;p&gt;You should be able to use the free tier or minimal spend to complete all the projects in the class. I personally signed up for Colab Pro+ and I&#39;m loving it - but it&#39;s not required.&lt;/p&gt; &#xA;&lt;p&gt;Learn about Google Colab and set up a Google account (if you don&#39;t already have one) &lt;a href=&#34;https://colab.research.google.com/&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The colab links are in the Week folders and also here:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For week 3 day 1, this Google Colab shows what &lt;a href=&#34;https://colab.research.google.com/drive/1DjcrYDZldAXKJ08x1uYIVCtItoLPk1Wr?usp=sharing&#34;&gt;colab can do&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;For week 3 day 2, here is a colab for the HuggingFace &lt;a href=&#34;https://colab.research.google.com/drive/1aMaEw8A56xs0bRM4lu8z7ou18jqyybGm?usp=sharing&#34;&gt;pipelines API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;For week 3 day 3, here&#39;s the colab on &lt;a href=&#34;https://colab.research.google.com/drive/1WD6Y2N7ctQi1X9wa6rpkg8UfyA4iSVuz?usp=sharing&#34;&gt;Tokenizers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;For week 3 day 4, we go to a colab with HuggingFace &lt;a href=&#34;https://colab.research.google.com/drive/1hhR9Z-yiqjUe7pJjVQw4c74z_V3VchLy?usp=sharing&#34;&gt;models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;For week 3 day 5, we return to colab to make our &lt;a href=&#34;https://colab.research.google.com/drive/1KSMxOCprsl1QRpt_Rq0UqCAyMtPqDQYx?usp=sharing&#34;&gt;Meeting Minutes product&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;For week 7, we will use these Colab books: &lt;a href=&#34;https://colab.research.google.com/drive/15rqdMTJwK76icPBxNoqhI7Ww8UM-Y7ni?usp=sharing&#34;&gt;Day 1&lt;/a&gt; | &lt;a href=&#34;https://colab.research.google.com/drive/1T72pbfZw32fq-clQEp-p8YQ4_qFKv4TP?usp=sharing&#34;&gt;Day 2&lt;/a&gt; | &lt;a href=&#34;https://colab.research.google.com/drive/1csEdaECRtjV_1p9zMkaKKjCpYnltlN3M?usp=sharing&#34;&gt;Days 3 and 4&lt;/a&gt; | &lt;a href=&#34;https://colab.research.google.com/drive/1igA0HF0gvQqbdBD4GkcK3GpHtuDLijYn?usp=sharing&#34;&gt;Day 5&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Monitoring API charges&lt;/h3&gt; &#xA;&lt;p&gt;You can keep your API spend very low throughout this course; you can monitor spend at the dashboards: &lt;a href=&#34;https://platform.openai.com/usage&#34;&gt;here&lt;/a&gt; for OpenAI, &lt;a href=&#34;https://console.anthropic.com/settings/cost&#34;&gt;here&lt;/a&gt; for Anthropic and &lt;a href=&#34;https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/cost&#34;&gt;here&lt;/a&gt; for Google Gemini.&lt;/p&gt; &#xA;&lt;p&gt;The charges for the exercsies in this course should always be quite low, but if you&#39;d prefer to keep them minimal, then be sure to always choose the cheapest versions of models:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;For OpenAI: Always use model &lt;code&gt;gpt-4o-mini&lt;/code&gt; in the code instead of &lt;code&gt;gpt-4o&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;For Anthropic: Always use model &lt;code&gt;claude-3-haiku-20240307&lt;/code&gt; in the code instead of the other Claude models&lt;/li&gt; &#xA; &lt;li&gt;During week 7, look out for my instructions for using the cheaper dataset&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Please do message me or email me at &lt;a href=&#34;mailto:ed@edwarddonner.com&#34;&gt;ed@edwarddonner.com&lt;/a&gt; if this doesn&#39;t work or if I can help with anything. I can&#39;t wait to hear how you get on.&lt;/p&gt; &#xA;&lt;table style=&#34;margin: 0; text-align: left;&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td style=&#34;width: 150px; height: 150px; vertical-align: middle;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ed-donner/llm_engineering/main/resources.jpg&#34; width=&#34;150&#34; height=&#34;150&#34; style=&#34;display: block;&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;h2 style=&#34;color:#f71;&#34;&gt;Other resources&lt;/h2&gt; &lt;span style=&#34;color:#f71;&#34;&gt;I&#39;ve put together this webpage with useful resources for the course. This includes links to all the slides.&lt;br&gt; &lt;a href=&#34;https://edwarddonner.com/2024/11/13/llm-engineering-resources/&#34;&gt;https://edwarddonner.com/2024/11/13/llm-engineering-resources/&lt;/a&gt;&lt;br&gt; Please keep this bookmarked, and I&#39;ll continue to add more useful links there over time. &lt;/span&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>shader-slang/slang</title>
    <updated>2024-12-01T01:40:21Z</updated>
    <id>tag:github.com,2024-12-01:/shader-slang/slang</id>
    <link href="https://github.com/shader-slang/slang" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Making it easier to work with shaders&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Slang&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/shader-slang/slang/actions/workflows/ci.yml/badge.svg?branch=master&#34; alt=&#34;CI Status&#34;&gt; &lt;img src=&#34;https://github.com/shader-slang/slang/actions/workflows/vk-gl-cts-nightly.yml/badge.svg?sanitize=true&#34; alt=&#34;CTS Status&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Slang is a shading language that makes it easier to build and maintain large shader codebases in a modular and extensible fashion, while also maintaining the highest possible performance on modern GPUs and graphics APIs. Slang is based on years of collaboration between researchers at NVIDIA, Carnegie Mellon University, Stanford, MIT, UCSD and the University of Washington.&lt;/p&gt; &#xA;&lt;h2&gt;Why Slang?&lt;/h2&gt; &#xA;&lt;p&gt;The Slang shading language is designed to enable real-time graphics developers to work with large-scale, high-performance shader code.&lt;/p&gt; &#xA;&lt;h3&gt;Write Shaders Once, Run Anywhere&lt;/h3&gt; &#xA;&lt;p&gt;The Slang compiler can generate code for a wide variety of targets: D3D12, Vulkan, Metal, D3D11, OpenGL, CUDA, and even generate code to run on a CPU. For textual targets, such as Metal Shading Language (MSL) and CUDA, Slang produces readable code that preserves original identifier names, as well as the type and call structure, making it easier to debug.&lt;/p&gt; &#xA;&lt;h3&gt;Access the Latest GPU Features&lt;/h3&gt; &#xA;&lt;p&gt;Slang code is highly portable, but can still leverage unique platform capabilities, including the latest features in Direct3D and Vulkan. For example, developers can make full use of &lt;a href=&#34;https://shader-slang.com/slang/user-guide/convenience-features.html#pointers-limited&#34;&gt;pointers&lt;/a&gt; when generating SPIR-V. Slang&#39;s &lt;a href=&#34;https://shader-slang.com/slang/user-guide/capabilities.html&#34;&gt;capability system&lt;/a&gt; helps applications manage feature set differences across target platforms by ensuring code only uses available features during the type-checking step, before generating final code. Additionally, Slang provides &lt;a href=&#34;https://shader-slang.com/slang/user-guide/a1-04-interop.html&#34;&gt;flexible interop&lt;/a&gt; features to enable directly embedding target code or SPIR-V into generated shaders.&lt;/p&gt; &#xA;&lt;h3&gt;Leverage Neural Graphics with Automatic Differentiation&lt;/h3&gt; &#xA;&lt;p&gt;Slang can &lt;a href=&#34;https://shader-slang.com/slang/user-guide/autodiff.html&#34;&gt;automatically generate both forward and backward derivative propagation code&lt;/a&gt; for complex functions that involve arbitrary control flow and dynamic dispatch. This allows existing rendering codebases to easily become differentiable, or for Slang to serve as the kernel language in a PyTorch-driven machine learning framework via &lt;a href=&#34;https://shader-slang.com/slang/user-guide/a1-02-slangpy.html&#34;&gt;&lt;code&gt;slangtorch&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Scalable Software Development with Modules&lt;/h3&gt; &#xA;&lt;p&gt;Slang provides a &lt;a href=&#34;https://shader-slang.com/slang/user-guide/modules.html&#34;&gt;module system&lt;/a&gt; that enables logical organization of code for separate compilation. Slang modules can be independently compiled offline to a custom IR (with optional obfuscation) and then linked at runtime to generate code in formats such as DXIL or SPIR-V.&lt;/p&gt; &#xA;&lt;h3&gt;Code Specialization that Works with Modules&lt;/h3&gt; &#xA;&lt;p&gt;Slang supports &lt;a href=&#34;https://shader-slang.com/slang/user-guide/interfaces-generics.html&#34;&gt;generics and interfaces&lt;/a&gt; (a.k.a. type traits/protocols), allowing for clear expression of shader specialization without the need for preprocessor techniques or string-pasting. Unlike C++ templates, Slang&#39;s generics are pre-checked and don&#39;t produce cascading error messages that are difficult to diagnose. The same generic shader can be specialized for a variety of different types to produce specialized code ahead of time, or on the fly, entirely under application control.&lt;/p&gt; &#xA;&lt;h3&gt;Easy On-ramp for HLSL and GLSL Codebases&lt;/h3&gt; &#xA;&lt;p&gt;Slang&#39;s syntax is similar to HLSL, and most existing HLSL code can be compiled with the Slang compiler out-of-the-box, or with just minor modifications. This allows existing shader codebases to immediately benefit from Slang without requiring a complete rewrite or port.&lt;/p&gt; &#xA;&lt;p&gt;Slang provides a compatibility module that enables the use of most GLSL intrinsic functions and GLSL&#39;s parameter binding syntax.&lt;/p&gt; &#xA;&lt;h3&gt;Comprehensive Tooling Support&lt;/h3&gt; &#xA;&lt;p&gt;Slang comes with full support of IntelliSense editing features in Visual Studio Code and Visual Studio through the Language Server Protocol. Full debugging capabilities are also available through RenderDoc and SPIR-V based tools.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The fastest way to get started using Slang in your own development is to use a pre-built binary package, available through GitHub &lt;a href=&#34;https://github.com/shader-slang/slang/releases&#34;&gt;releases&lt;/a&gt;. Slang binaries are also included in the &lt;a href=&#34;https://vulkan.lunarg.com/sdk/home&#34;&gt;Vulkan SDK&lt;/a&gt; since version 1.3.296.0.&lt;/p&gt; &#xA;&lt;p&gt;There are packages built for 32- and 64-bit Windows, as well as 64-bit Ubuntu. Each binary release includes the command-line &lt;code&gt;slangc&lt;/code&gt; compiler, a shared library for the compiler, and the &lt;code&gt;slang.h&lt;/code&gt; header.&lt;/p&gt; &#xA;&lt;p&gt;See the user-guide for info on using the &lt;code&gt;slangc&lt;/code&gt; command-line tool: &lt;a href=&#34;https://shader-slang.com/slang/user-guide/compiling.html#command-line-compilation-with-slangc&#34;&gt;Slang Command Line Usage&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you want to try out the Slang language without installing anything, a fast and simple way is to use the &lt;a href=&#34;https://shader-slang.com/slang-playground&#34;&gt;Slang Playground&lt;/a&gt;. The playground allows you to compile Slang code to a variety of targets, and even run some simple shaders directly within the browser. The playground loads Slang compiler to your browser and runs all compilation locally. No data will be sent to any servers.&lt;/p&gt; &#xA;&lt;p&gt;If you would like to build Slang from source, please consult the &lt;a href=&#34;https://raw.githubusercontent.com/shader-slang/slang/master/docs/building.md&#34;&gt;build instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The Slang project provides a variety of different &lt;a href=&#34;https://raw.githubusercontent.com/shader-slang/slang/master/docs/&#34;&gt;documentation&lt;/a&gt;, but most users would be well served starting with the &lt;a href=&#34;https://shader-slang.github.io/slang/user-guide/&#34;&gt;User&#39;s Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For developers writing Slang code, the &lt;a href=&#34;https://shader-slang.com/stdlib-reference/&#34;&gt;Slang Core Module Reference&lt;/a&gt; provides detailed documentation on Slang&#39;s built-in types and functions.&lt;/p&gt; &#xA;&lt;p&gt;We also provide a few &lt;a href=&#34;https://raw.githubusercontent.com/shader-slang/slang/master/examples/&#34;&gt;examples&lt;/a&gt; of how to integrate Slang into a rendering application.&lt;/p&gt; &#xA;&lt;p&gt;These examples use a graphics layer that we include with Slang called &#34;GFX&#34; which is an abstraction library of various graphics APIs (D3D11, D2D12, OpenGL, Vulkan, CUDA, and the CPU) to support cross-platform applications using GPU graphics and compute capabilities. If you&#39;d like to learn more about GFX, see the &lt;a href=&#34;https://shader-slang.com/slang/gfx-user-guide/index.html&#34;&gt;GFX User Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Additionally, we recommend checking out &lt;a href=&#34;https://github.com/nvpro-samples/vk_mini_samples/&#34;&gt;Vulkan Mini Examples&lt;/a&gt; for more examples of using Slang&#39;s language features available on Vulkan, such as pointers and the ray tracing intrinsics.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;d like to contribute to the project, we are excited to have your input. The following guidelines should be observed by contributors:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Please follow the contributor &lt;a href=&#34;https://raw.githubusercontent.com/shader-slang/slang/master/CODE_OF_CONDUCT.md&#34;&gt;Code of Conduct&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Bugs reports and feature requests should go through the GitHub issue tracker&lt;/li&gt; &#xA; &lt;li&gt;Changes should ideally come in as small pull requests on top of &lt;code&gt;master&lt;/code&gt;, coming from your own personal fork of the project&lt;/li&gt; &#xA; &lt;li&gt;Large features that will involve multiple contributors or a long development time should be discussed in issues, and broken down into smaller pieces that can be implemented and checked in in stages&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/shader-slang/slang/master/CONTRIBUTING.md&#34;&gt;Contribution guide&lt;/a&gt; describes the workflow for contributors at more detail.&lt;/p&gt; &#xA;&lt;h2&gt;Limitations and Support&lt;/h2&gt; &#xA;&lt;h3&gt;Platform support&lt;/h3&gt; &#xA;&lt;p&gt;The Slang compiler and libraries can be built on the following platforms:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Windows&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Linux&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MacOS&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;WebAssembly&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;supported&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;supported&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;supported&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;experimental&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Both &lt;code&gt;x86_64&lt;/code&gt; and &lt;code&gt;aarch64&lt;/code&gt; architectures are supported on Windows, Linux and MacOS platforms.&lt;/p&gt; &#xA;&lt;h3&gt;Target support&lt;/h3&gt; &#xA;&lt;p&gt;Slang can compile shader code to the following targets:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Target&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Status&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Output Formats&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Direct3D 11&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://shader-slang.com/slang/user-guide/targets.html#direct3d-11&#34;&gt;supported&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;HLSL&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Direct3D 12&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://shader-slang.com/slang/user-guide/targets.html#direct3d-12&#34;&gt;supported&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;HLSL&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Vulkan&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://shader-slang.com/slang/user-guide/targets.html#vulkan&#34;&gt;supported&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;SPIRV, GLSL&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Metal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://shader-slang.com/slang/user-guide/targets.html#metal&#34;&gt;experimental*&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Metal Shading Language&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;WebGPU&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;experimental**&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;WGSL&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;CUDA&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://shader-slang.com/slang/user-guide/targets.html#cuda-and-optix&#34;&gt;supported&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C++ (compute only)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Optix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://shader-slang.com/slang/user-guide/targets.html#cuda-and-optix&#34;&gt;experimental&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C++ (WIP)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;CPU&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://shader-slang.com/slang/user-guide/targets.html#cpu-compute&#34;&gt;experimental&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C++ (kernel), C++ (host), standalone executable, dynamic library&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;*Slang currently supports generating vertex, fragment, compute, task and mesh shaders for Metal.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;**WGSL support is still work in-progress.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;For greater detail, see the &lt;a href=&#34;https://shader-slang.com/slang/user-guide/targets.html&#34;&gt;Supported Compilation Targets&lt;/a&gt; section of the &lt;a href=&#34;https://shader-slang.github.io/slang/user-guide/&#34;&gt;User Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Slang project has been used for production applications and large shader codebases, but it is still under active development. Support is currently focused on the platforms (Windows, Linux) and target APIs (Direct3D 12, Vulkan) where Slang is used most heavily. Users who are looking for support on other platforms or APIs should coordinate with the development team via the issue tracker to make sure that their use cases can be supported.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The Slang code itself is under the Apache 2.0 with LLVM Exception license (see &lt;a href=&#34;https://raw.githubusercontent.com/shader-slang/slang/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Builds of the core Slang tools depend on the following projects, either automatically or optionally, which may have their own licenses:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/KhronosGroup/glslang&#34;&gt;&lt;code&gt;glslang&lt;/code&gt;&lt;/a&gt; (BSD)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lz4/lz4&#34;&gt;&lt;code&gt;lz4&lt;/code&gt;&lt;/a&gt; (BSD)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/richgel999/miniz&#34;&gt;&lt;code&gt;miniz&lt;/code&gt;&lt;/a&gt; (MIT)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/KhronosGroup/SPIRV-Headers&#34;&gt;&lt;code&gt;spirv-headers&lt;/code&gt;&lt;/a&gt; (Modified MIT)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/KhronosGroup/SPIRV-Tools&#34;&gt;&lt;code&gt;spirv-tools&lt;/code&gt;&lt;/a&gt; (Apache 2.0)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/martinus/unordered_dense&#34;&gt;&lt;code&gt;ankerl::unordered_dense::{map, set}&lt;/code&gt;&lt;/a&gt; (MIT)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Slang releases may include &lt;a href=&#34;https://github.com/shader-slang/slang-llvm&#34;&gt;slang-llvm&lt;/a&gt; which includes &lt;a href=&#34;https://github.com/llvm/llvm-project&#34;&gt;LLVM&lt;/a&gt; under the license:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://llvm.org/docs/DeveloperPolicy.html#new-llvm-project-license-framework&#34;&gt;&lt;code&gt;llvm&lt;/code&gt;&lt;/a&gt; (Apache 2.0 License with LLVM exceptions)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Some of the tests and example programs that build with Slang use the following projects, which may have their own licenses:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/g-truc/glm&#34;&gt;&lt;code&gt;glm&lt;/code&gt;&lt;/a&gt; (MIT)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stb_image&lt;/code&gt; and &lt;code&gt;stb_image_write&lt;/code&gt; from the &lt;a href=&#34;https://github.com/nothings/stb&#34;&gt;&lt;code&gt;stb&lt;/code&gt;&lt;/a&gt; collection of single-file libraries (Public Domain)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tinyobjloader/tinyobjloader&#34;&gt;&lt;code&gt;tinyobjloader&lt;/code&gt;&lt;/a&gt; (MIT)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>