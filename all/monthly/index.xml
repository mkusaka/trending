<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-01T02:07:58Z</updated>
  <subtitle>Monthly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>xiangsx/gpt4free-ts</title>
    <updated>2023-07-01T02:07:58Z</updated>
    <id>tag:github.com,2023-07-01:/xiangsx/gpt4free-ts</id>
    <link href="https://github.com/xiangsx/gpt4free-ts" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Providing a free OpenAI GPT-4 API ! This is a replication project for the typescript version of xtekky/gpt4free&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;GPT4Free TypeScript Version ğŸ†“&lt;/h1&gt; &#xA; &lt;h6&gt;Providing a free OpenAI GPT-4 API!&lt;/h6&gt; &#xA; &lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/xiangsx/gpt4free-ts/master/README_zh.md&#34;&gt;ä¸­æ–‡&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/xiangsx/gpt4free-ts/master/README_ja.md&#34;&gt;æ—¥æœ¬èª&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/cYUU8mCDMd&#34;&gt;&lt;img src=&#34;https://discordapp.com/api/guilds/1115852499535020084/widget.png?style=banner2&amp;amp;count=true&#34; alt=&#34;Discord Server&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;You can join our discord: &lt;a href=&#34;https://discord.gg/cYUU8mCDMd&#34;&gt;discord.gg/gptgod&lt;/a&gt;&lt;a&gt; for further updates. &lt;/a&gt;&lt;a href=&#34;https://discord.gg/cYUU8mCDMd&#34;&gt;&lt;img align=&#34;center&#34; alt=&#34;gpt4free Discord&#34; width=&#34;22px&#34; src=&#34;https://raw.githubusercontent.com/peterthehan/peterthehan/master/assets/discord.svg?sanitize=true&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;ğŸš© Reverse target&lt;/h2&gt; &#xA;&lt;p&gt;I suggest you fork this project first. Some websites may go offline at any time.&lt;/p&gt; &#xA;&lt;p&gt;Still striving to keep updating.&lt;/p&gt; &#xA;&lt;p&gt;Have implemented models here: If you do not want your website to appear here, please raise an issue and I will remove it immediately.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;model&lt;/th&gt; &#xA;   &lt;th&gt;support&lt;/th&gt; &#xA;   &lt;th&gt;status&lt;/th&gt; &#xA;   &lt;th&gt;active time&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;vita&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ‘gpt3.5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://img.shields.io/badge/Active-brightgreen&#34; alt=&#34;Active&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;after 2023-06-17&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;chatdemo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ‘gpt3.5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://img.shields.io/badge/Active-brightgreen&#34; alt=&#34;Active&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;after 2023-06-17&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://you.com&#34;&gt;you.com&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ‘GPT-3.5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://img.shields.io/badge/Active-brightgreen&#34; alt=&#34;Active&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;after 2023-06-17&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.phind.com/&#34;&gt;phind.com&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Gpt3.5/ Internet / good search&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://img.shields.io/badge/Active-brightgreen&#34; alt=&#34;Active&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;after 2023-06-17&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat.forefront.ai&#34;&gt;forefront.ai&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPT-4/gpt3.5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://img.shields.io/badge/Active-lightgrey&#34; alt=&#34;Active&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://bing.com/chat&#34;&gt;bing.com/chat&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPT-4/3.5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://poe.com&#34;&gt;poe.com&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPT-4/3.5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://writesonic.com&#34;&gt;writesonic.com&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPT-3.5 / Internet&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://t3nsor.com&#34;&gt;t3nsor.com&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPT-3.5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ğŸƒâ€â™‚ï¸ Run&lt;/h2&gt; &#xA;&lt;p&gt;First of all, you should create file &lt;code&gt;.env&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;em&gt;&lt;strong&gt;All operation methods require this step.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-env&#34;&gt;http_proxy=http://host:port&#xA;rapid_api_key=xxxxxxxxxx&#xA;EMAIL_TYPE=temp-email44&#xA;DEBUG=0&#xA;POOL_SIZE=0&#xA;PHIND_POOL_SIZE=0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;http_proxy&lt;/code&gt;: config your proxy if you can not access target website directly; If you dont need proxy, delete this line;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;forefront&lt;/code&gt; use env(this site has been removed): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;rapid_api_key&lt;/code&gt;: you should config this if you use forefront api, this apikey is used for receive register email, get api key here&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;EMAIL_TYPE&lt;/code&gt;: temp email type includes &lt;code&gt;temp-email&lt;/code&gt; &lt;code&gt;temp-email44&lt;/code&gt; &lt;code&gt;tempmail-lol&lt;/code&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://rapidapi.com/Privatix/api/temp-mail&#34;&gt;temp-email&lt;/a&gt;: soft limit 100req/days, if over use money, need bind credit card! Very Stable!&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://rapidapi.com/calvinloveland335703-0p6BxLYIH8f/api/temp-mail44&#34;&gt;temp-email44&lt;/a&gt;: hard limit 100req/days! Stable!&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;&#34;&gt;tempmail-lol&lt;/a&gt;: nothing need, limit 25request/5min. Not Stable.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;DEBUG&lt;/code&gt;: Valid when use &lt;code&gt;forefront&lt;/code&gt; You can set =1 when you run local. show reverse process&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;POOL_SIZE&lt;/code&gt;: &lt;code&gt;forefront&lt;/code&gt; concurrency size. Keep set=1 until you run it successfully!!! You can engage in {POOL_SIZE} conversations concurrently. More pool size, More conversation can be done simultaneously, But use more RAM&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;phind&lt;/code&gt; use env: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;PHIND_POOL_SIZE&lt;/code&gt;: &lt;code&gt;phind&lt;/code&gt; concurrency size.You can engage in {POOL_SIZE} conversations concurrently. More pool size, More conversation can be done simultaneously, But use more RAM&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Run local ğŸ–¥ï¸&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# install module&#xA;yarn&#xA;# start server&#xA;yarn start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run with docker(Suggest!) ğŸ³&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -p 3000:3000 --env-file .env xiangsx/gpt4free-ts:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Deploy with docker-compose ğŸ­&lt;/h3&gt; &#xA;&lt;p&gt;first, you should create file .env; Follow step &#34;Run with docker&lt;/p&gt; &#xA;&lt;p&gt;deploy&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose up --build -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸš€ Let&#39;s Use GPT4&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Return when chat complete &lt;a href=&#34;http://127.0.0.1:3000/ask?prompt=***&amp;amp;model=***&amp;amp;site=&#34;&gt;http://127.0.0.1:3000/ask?prompt=***&amp;amp;model=***&amp;amp;site=&lt;/a&gt;***&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Return with eventstream &lt;a href=&#34;http://127.0.0.1:3000/ask/stream?prompt=***&amp;amp;model=***&amp;amp;site=&#34;&gt;http://127.0.0.1:3000/ask/stream?prompt=***&amp;amp;model=***&amp;amp;site=&lt;/a&gt;***&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Request Params ğŸ“&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;prompt&lt;/code&gt;: your question. It can be a &lt;code&gt;string&lt;/code&gt; or &lt;code&gt;jsonstr&lt;/code&gt;. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;example &lt;code&gt;jsonstr&lt;/code&gt;:&lt;code&gt;[{&#34;role&#34;:&#34;user&#34;,&#34;content&#34;:&#34;hello\n&#34;},{&#34;role&#34;:&#34;assistant&#34;,&#34;content&#34;:&#34;Hi there! How can I assist you today?&#34;},{&#34;role&#34;:&#34;user&#34;,&#34;content&#34;:&#34;who are you&#34;}]&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;example &lt;code&gt;string&lt;/code&gt;: &lt;code&gt;who are you&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: default &lt;code&gt;gpt3.5-turbo&lt;/code&gt;. model include:&lt;code&gt;gpt4&lt;/code&gt; &lt;code&gt;gpt3.5-turbo&lt;/code&gt; &lt;code&gt;net-gpt3.5-turbo&lt;/code&gt; &lt;code&gt;gpt-3.5-turbo-16k&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;site&lt;/code&gt;: default &lt;code&gt;you&lt;/code&gt;. target site, include &lt;code&gt;fakeopen&lt;/code&gt; &lt;code&gt;better&lt;/code&gt; &lt;code&gt;forefront&lt;/code&gt; &lt;code&gt;you&lt;/code&gt; &lt;code&gt;chatdemo&lt;/code&gt; &lt;code&gt;phind&lt;/code&gt; &lt;code&gt;vita&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Site Support Model ğŸ§©&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;forefront&lt;/code&gt; :&lt;code&gt;gpt4&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;you&lt;/code&gt;: &lt;code&gt;gpt3.5-turbo&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;chatdemo&lt;/code&gt;: &lt;code&gt;gpt3.5-turbo&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;phind&lt;/code&gt;: &lt;code&gt;net-gpt3.5-turbo&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Response Params ğŸ”™&lt;/h3&gt; &#xA;&lt;p&gt;Response when chat end(/ask):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;interface ChatResponse {&#xA;    content: string;&#xA;    error?: string;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Response with stream like, Suggest!!(/ask/stream):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;event: message&#xA;data: {&#34;content&#34;:&#34;I&#34;}&#xA;&#xA;event: done&#xA;data: {&#34;content&#34;:&#34;&#39;m&#34;}&#xA;&#xA;event: error&#xA;data: {&#34;error&#34;:&#34;some thind wrong&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ExampleğŸ’¡&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;request to site you with history&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;req:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;127.0.0.1:3000/ask?site=you&amp;amp;prompt=[{&#34;role&#34;:&#34;user&#34;,&#34;content&#34;:&#34;hello&#34;},{&#34;role&#34;:&#34;assistant&#34;,&#34;content&#34;:&#34;Hi there! How can I assist you today?&#34;},{&#34;role&#34;:&#34;user&#34;,&#34;content&#34;:&#34;who are you&#34;}]&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;res:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;content&#34;: &#34;Hi there! How can I assist you today?&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;127.0.0.1:3000/ask?site=you&amp;amp;prompt=[{&#34;role&#34;:&#34;user&#34;,&#34;content&#34;:&#34;ä½ å¥½\n&#34;},{&#34;role&#34;:&#34;assistant&#34;,&#34;content&#34;:&#34;ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ&#34;},{&#34;role&#34;:&#34;user&#34;,&#34;content&#34;:&#34;ä½ æ˜¯è°&#34;}]&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;request to site you with stream return&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;req:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;127.0.0.1:3000/ask/stream?site=you&amp;amp;prompt=who are you&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;res:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;event: message&#xA;data: {&#34;content&#34;:&#34;I&#34;}&#xA;&#xA;event: message&#xA;data: {&#34;content&#34;:&#34;&#39;m&#34;}&#xA;&#xA;event: message&#xA;data: {&#34;content&#34;:&#34; a&#34;}&#xA;&#xA;event: message&#xA;data: {&#34;content&#34;:&#34; search&#34;}&#xA;&#xA;event: message&#xA;data: {&#34;content&#34;:&#34; assistant&#34;}&#xA;........&#xA;event: done&#xA;data: {&#34;content&#34;:&#34;done&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ‘¥ Wechat Group&lt;/h2&gt; &#xA;&lt;img src=&#34;https://github.com/xiangsx/gpt4free-ts/assets/29322721/d926db6d-1711-479e-aae4-726cbcecd6ed&#34; width=&#34;240&#34;&gt; &#xA;&lt;img src=&#34;https://github.com/xiangsx/gpt4free-ts/assets/29322721/6a1b6f3f-f4f3-4483-b379-4de931b546eb&#34; width=&#34;240&#34;&gt; &#xA;&lt;img src=&#34;https://github.com/xiangsx/gpt4free-ts/assets/29322721/51125eb9-4032-4fa0-aa32-f3c527100ac2&#34; width=&#34;240&#34;&gt; &#xA;&lt;h2&gt;ğŸŒŸ Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#xiangsx/gpt4free-ts&amp;amp;&amp;amp;type=Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=xiangsx/gpt4free-ts&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You may join our discord: &lt;a href=&#34;https://discord.com/invite/gpt4free&#34;&gt;discord.gg/gpt4free&lt;/a&gt;&lt;a&gt; for further updates. &lt;/a&gt;&lt;a href=&#34;https://discord.gg/gpt4free&#34;&gt;&lt;img align=&#34;center&#34; alt=&#34;gpt4free Discord&#34; width=&#34;22px&#34; src=&#34;https://raw.githubusercontent.com/peterthehan/peterthehan/master/assets/discord.svg?sanitize=true&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a replication project for the typescript version of &lt;a href=&#34;https://github.com/xtekky/gpt4free&#34;&gt;gpt4free&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img alt=&#34;gpt4free logo&#34; src=&#34;https://user-images.githubusercontent.com/98614666/233799515-1a7cb6a3-b17f-42c4-956d-8d2a0664466f.png&#34;&gt; &#xA;&lt;h2&gt;Legal Notice &lt;a name=&#34;legal-notice&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;This repository is &lt;em&gt;not&lt;/em&gt; associated with or endorsed by providers of the APIs contained in this GitHub repository. This project is intended &lt;strong&gt;for educational purposes only&lt;/strong&gt;. This is just a little personal project. Sites may contact me to improve their security or request the removal of their site from this repository.&lt;/p&gt; &#xA;&lt;p&gt;Please note the following:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: The APIs, services, and trademarks mentioned in this repository belong to their respective owners. This project is &lt;em&gt;not&lt;/em&gt; claiming any right over them nor is it affiliated with or endorsed by any of the providers mentioned.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Responsibility&lt;/strong&gt;: The author of this repository is &lt;em&gt;not&lt;/em&gt; responsible for any consequences, damages, or losses arising from the use or misuse of this repository or the content provided by the third-party APIs. Users are solely responsible for their actions and any repercussions that may follow. We strongly recommend the users to follow the TOS of the each Website.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Educational Purposes Only&lt;/strong&gt;: This repository and its content are provided strictly for educational purposes. By using the information and code provided, users acknowledge that they are using the APIs and models at their own risk and agree to comply with any applicable laws and regulations.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Copyright&lt;/strong&gt;: All content in this repository, including but not limited to code, images, and documentation, is the intellectual property of the repository author, unless otherwise stated. Unauthorized copying, distribution, or use of any content in this repository is strictly prohibited without the express written consent of the repository author.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Indemnification&lt;/strong&gt;: Users agree to indemnify, defend, and hold harmless the author of this repository from and against any and all claims, liabilities, damages, losses, or expenses, including legal fees and costs, arising out of or in any way connected with their use or misuse of this repository, its content, or related third-party APIs.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Updates and Changes&lt;/strong&gt;: The author reserves the right to modify, update, or remove any content, information, or features in this repository at any time without prior notice. Users are responsible for regularly reviewing the content and any changes made to this repository.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;By using this repository or any code related to it, you agree to these terms. The author is not responsible for any copies, forks, or reuploads made by other users. This is the author&#39;s only account and repository. To prevent impersonation or irresponsible actions, you may comply with the GNU GPL license this Repository uses.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>NaiboWang/EasySpider</title>
    <updated>2023-07-01T02:07:58Z</updated>
    <id>tag:github.com,2023-07-01:/NaiboWang/EasySpider</id>
    <link href="https://github.com/NaiboWang/EasySpider" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A visual no-code/code-free web crawler/spideræ˜“é‡‡é›†ï¼šä¸€ä¸ªå¯è§†åŒ–çˆ¬è™«è½¯ä»¶ï¼Œå¯ä»¥æ— ä»£ç å›¾å½¢åŒ–çš„è®¾è®¡å’Œæ‰§è¡Œçˆ¬è™«ä»»åŠ¡&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;è¯·æ‚¨Star/Please Star&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœæ‚¨è§‰å¾—æ­¤å·¥å…·ä¸é”™ï¼Œè¯·è½»è½»ç‚¹å‡»æ­¤é¡µé¢å³ä¸Šè§’&lt;strong&gt;Star&lt;/strong&gt;æŒ‰é’®å¢åŠ é¡¹ç›®æ›å…‰åº¦ï¼Œè°¢è°¢ï¼è½¯ä»¶å®Œå…¨å…è´¹ï¼ˆå•†ç”¨é™¤å¤–ï¼‰ï¼Œåªæ±‚å¤§å®¶Starå’Œå®£ä¼ ç»™å…¶ä»–éœ€è¦çš„æœ‹å‹ï¼Œè°¢è°¢ï¼&lt;/p&gt; &#xA;&lt;p&gt;If you think this tool is good, please gently click the &lt;strong&gt;Star&lt;/strong&gt; button in the upper right corner at this page to increase the project exposure, thank you! The software is completely free (except for commercial use), only ask everyone to Star and promote it to other friends in need, thank you!&lt;/p&gt; &#xA;&lt;h2&gt;å®˜æ–¹ç½‘ç«™/Official Website&lt;/h2&gt; &#xA;&lt;p&gt;è®¿é—®æ˜“é‡‡é›†å®˜ç½‘ï¼šwww.easyspider.cn&lt;/p&gt; &#xA;&lt;p&gt;Visit the official website of EasySpider: &lt;a href=&#34;http://www.easyspider.net&#34;&gt;www.easyspider.net&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;æ˜“é‡‡é›†/EasySpider: Visual Code-Free Web Crawler&lt;/h1&gt; &#xA;&lt;p&gt;ä¸€ä¸ªå¯è§†åŒ–çˆ¬è™«è½¯ä»¶ï¼Œå¯ä»¥ä½¿ç”¨å›¾å½¢åŒ–ç•Œé¢ï¼Œæ— ä»£ç å¯è§†åŒ–çš„è®¾è®¡å’Œæ‰§è¡Œçˆ¬è™«ä»»åŠ¡ã€‚åªéœ€è¦åœ¨ç½‘é¡µä¸Šé€‰æ‹©è‡ªå·±æƒ³è¦çˆ¬çš„å†…å®¹å¹¶æ ¹æ®æç¤ºæ¡†æ“ä½œå³å¯å®Œæˆçˆ¬è™«è®¾è®¡å’Œæ‰§è¡Œã€‚åŒæ—¶è½¯ä»¶è¿˜å¯ä»¥å•ç‹¬ä»¥å‘½ä»¤è¡Œçš„æ–¹å¼è¿›è¡Œæ‰§è¡Œï¼Œä»è€Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„åµŒå…¥åˆ°å…¶ä»–ç³»ç»Ÿä¸­ã€‚&lt;/p&gt; &#xA;&lt;p&gt;A visual code-free/no-code web crawler/spider, just select the content you want to crawl on the web page and operate according to the prompt box to complete the design and execution of the crawler. At the same time, the software can be executed by command line alone, so it can be easily embedded into other systems.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/animation_zh.gif&#34; alt=&#34;animation_zh&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/animation_en.gif&#34; alt=&#34;animation_en&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ä¸‹è½½æ˜“é‡‡é›†/Download EasySpider&lt;/h2&gt; &#xA;&lt;p&gt;è¿›å…¥ &lt;a href=&#34;https://github.com/NaiboWang/EasySpider/releases&#34;&gt;Releases Page&lt;/a&gt; ä¸‹è½½æœ€æ–°ç‰ˆæœ¬ã€‚å¦‚æœä¸‹è½½é€Ÿåº¦æ…¢ï¼Œå¯ä»¥è€ƒè™‘ä¸­å›½å¢ƒå†…ä¸‹è½½åœ°å€ï¼š&lt;a href=&#34;https://github.com/NaiboWang/EasySpider/releases/download/v0.3.2/Download_Link_Address_in_China_Mainland.txt&#34;&gt;ä¸­å›½å¢ƒå†…ä¸‹è½½åœ°å€&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŠ QQç¾¤ä»ç¾¤æ–‡ä»¶ä¸‹è½½æ˜¯å›½å†…ä¸‹è½½æœ€å¿«çš„æ–¹å¼ï¼Œä½†ä½¿ç”¨è½¯ä»¶çš„è¿‡ç¨‹ä¸­å‘ç”Ÿäº†é—®é¢˜æ±‚åŠ©è¿˜æ˜¯è¯·ä»GitHubæissueï¼Œå› ä¸ºç¾¤ä¸»ä¸æ€ä¹ˆçœ‹ç¾¤ï¼Œç¾¤å·ï¼š&lt;strong&gt;682921940&lt;/strong&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;Refer to the &lt;a href=&#34;https://github.com/NaiboWang/EasySpider/releases&#34;&gt;Releases Page&lt;/a&gt; to download the latest version of EasySpider.&lt;/p&gt; &#xA;&lt;h2&gt;æ–‡æ¡£/Documentation&lt;/h2&gt; &#xA;&lt;p&gt;è¯·ç‚¹æ­¤è¿›å…¥&lt;a href=&#34;https://github.com/NaiboWang/EasySpider/wiki&#34;&gt;æ•™ç¨‹æ–‡æ¡£&lt;/a&gt;ï¼Œå¦‚æœ‰è‹±æ–‡å¯æš‚æ—¶ç¿»è¯‘ä¸€ä¸‹ï¼Œæˆ–çœ‹ä½œè€…çš„&lt;a href=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/Docs/%E9%9D%A2%E5%90%91WEB%E5%BA%94%E7%94%A8%E7%9A%84%E6%99%BA%E8%83%BD%E5%8C%96%E6%9C%8D%E5%8A%A1%E5%B0%81%E8%A3%85%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf&#34;&gt;ç¡•å£«æ¯•ä¸šè®ºæ–‡&lt;/a&gt;ï¼ˆä¸»è¦çœ‹ç¬¬ä¸‰ç« å’Œç¬¬äº”ç« ï¼‰ã€‚&lt;/p&gt; &#xA;&lt;p&gt;Ebayæ ·ä¾‹åšå®¢ï¼š&lt;a href=&#34;https://blog.csdn.net/ihero/article/details/130805504&#34;&gt;https://blog.csdn.net/ihero/article/details/130805504&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Documentation can be found from &lt;a href=&#34;https://github.com/NaiboWang/EasySpider/wiki&#34;&gt;GitHub Wiki&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;è§†é¢‘æ•™ç¨‹/Video Tutorials&lt;/h2&gt; &#xA;&lt;p&gt;Bilibili/Bç«™è§†é¢‘æ•™ç¨‹:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Fk4y1L7xX/&#34;&gt;EasySpiderä»‹ç» - ä¸­å›½åœ°éœ‡å°ç½‘é‡‡é›†æ¡ˆä¾‹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1pu411a7pK/&#34;&gt;è‡ªåŠ¨/æ‰‹åŠ¨åŒç±»å‹å…ƒç´ åŒ¹é…åŠŸèƒ½è¯´æ˜&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1HV4y1r7v8&#34;&gt;å¦‚ä½•æ— ä»£ç å¯è§†åŒ–çš„çˆ¬å–éœ€è¦ç™»å½•æ‰èƒ½çˆ¬çš„ç½‘ç«™ - çŸ¥ä¹ç½‘ç«™æ¡ˆä¾‹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1RW4y197ih/&#34;&gt;å®æˆ˜é‡‡é›†æ±½è½¦ç½‘æ–‡ç« å†…å®¹å¹¶ä¸‹è½½æ–‡ç« å†…å›¾ç‰‡&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV14V4y1m7iL/&#34;&gt;å®šæ—¶æ‰§è¡Œä»»åŠ¡+é€‰ä¸­å­å…ƒç´ å¤šç§æ¨¡å¼+å°†æå–å€¼ä½œä¸ºå˜é‡è¾“å…¥&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1mu411x7Nn/&#34;&gt;ã€é‡è¦ã€‘è‡ªå®šä¹‰æ¡ä»¶åˆ¤æ–­ä¹‹ä½¿ç”¨å¾ªç¯é¡¹å†…çš„JSå‘½ä»¤è¿”å›å€¼ - ç¬¬äºŒå¼¹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1YL411z7uW&#34;&gt;æµç¨‹å›¾æ‰§è¡Œé€»è¾‘è§£æ - 58åŒåŸæˆ¿æºæè¿°é‡‡é›†æ¡ˆä¾‹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1WL411h71r&#34;&gt;MacOSç³»ç»Ÿè®¾è®¡å’Œæ‰§è¡ŒeBayç½‘ç«™çˆ¬è™«ä»»åŠ¡æ•™ç¨‹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1qs4y1z7Hc/&#34;&gt;å¦‚ä½•æ‰§è¡Œè‡ªå·±å†™çš„JSä»£ç å’Œç³»ç»Ÿä»£ç  ï¼ˆè‡ªå®šä¹‰æ“ä½œï¼‰&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Ys4y1z777/&#34;&gt;å¦‚ä½•è‡ªå®šä¹‰å¾ªç¯å’Œåˆ¤æ–­æ¡ä»¶ - ç¬¬ä¸€å¼¹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1dV4y1z764/&#34;&gt;å¦‚ä½•å¯¹å…ƒç´ å’Œç½‘é¡µæˆªå›¾åŠå‘½ä»¤è¡Œæ‰§è¡ŒæŒ‡å—&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1xz4y1b72D/&#34;&gt;OCRè¯†åˆ«å…ƒç´ å†…å®¹åŠŸèƒ½&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV18c411K7FH&#34;&gt;å¦‚ä½•çˆ¬éœ€è¦è¾“å…¥éªŒè¯ç çš„ç½‘ç«™&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1KT411t79n&#34;&gt;å¦‚ä½•åˆ‡æ¢IPæ± å’Œä½¿ç”¨éš§é“IP - æ‰“å¼€è¯¦æƒ…é¡µé‡‡é›†æ¡ˆä¾‹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV13c411G7LE/&#34;&gt;å¦‚ä½•åŒæ—¶æ‰§è¡Œå¤šä¸ªä»»åŠ¡ï¼ˆå¹¶è¡Œå¤šå¼€ï¼‰&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV11W4y1D71t/&#34;&gt;å®ä¾‹ - åäººç±»ç½‘ç«™æ–‡ç« é‡‡é›†å’Œä»£ç è°ƒè¯•&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Refer to &lt;a href=&#34;https://youtube.com/playlist?list=PL0kEFEkWrT7mt9MUlEBV2DTo1QsaanUTp&#34;&gt;Youtube Playlist&lt;/a&gt; to see the video tutorials of EasySpider.&lt;/p&gt; &#xA;&lt;h2&gt;æ ·ä¾‹ä»»åŠ¡/Sample Tasks&lt;/h2&gt; &#xA;&lt;p&gt;ä»æœ¬é¡¹ç›®çš„&lt;a href=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/Examples&#34;&gt;Examples&lt;/a&gt;æ–‡ä»¶å¤¹ä¸­ä¸‹è½½æ ·ä¾‹ä»»åŠ¡ï¼Œæ›´åä¸ºå¤§äº0çš„æ•°å­—ï¼Œå¯¼å…¥åˆ°EasySpiderä¸­çš„&lt;code&gt;tasks&lt;/code&gt;æ–‡ä»¶å¤¹ä¸­ï¼Œç„¶ååœ¨EasySpiderä¸­æ‰“å¼€å³å¯ã€‚&lt;/p&gt; &#xA;&lt;p&gt;Download sample tasks from the &lt;a href=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/Examples&#34;&gt;Examples&lt;/a&gt; folder of this project, rename them to numbers greater than 0, import them into the &lt;code&gt;tasks&lt;/code&gt; folder in EasySpider, and then open them in EasySpider.&lt;/p&gt; &#xA;&lt;h2&gt;å£°æ˜/Declaration&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬è½¯ä»¶ä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ï¼Œ&lt;strong&gt;ä¸¥ç¦ä½¿ç”¨è½¯ä»¶è¿›è¡Œä»»ä½•è¿æ³•è¿è§„çš„æ“ä½œï¼Œå¦‚çˆ¬å–ä¸å…è®¸çˆ¬å–çš„æ”¿åºœ/å†›äº‹æœºå…³ç½‘ç«™ç­‰&lt;/strong&gt;ã€‚ä½¿ç”¨æœ¬è½¯ä»¶æ‰€é€ æˆçš„&lt;strong&gt;ä¸€åˆ‡åæœç”±ä½¿ç”¨è€…è‡ªè´Ÿ&lt;/strong&gt;ï¼Œä¸ä½œè€…æœ¬äººæ— å…³ï¼Œ&lt;strong&gt;ä½œè€…ä¸ä¼šæ‰¿æ‹…ä»»ä½•è´£ä»»&lt;/strong&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;This software is for learning and communication only. &lt;strong&gt;It is strictly forbidden to use the software for any illegal operations, such as crawling government/military websites that are not allowed to be crawled.&lt;/strong&gt; All consequences caused by the use of this software are &lt;strong&gt;at the user&#39;s own risk, and the author is not responsible for any consequences&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;å¯¹äºæ”¿åºœå’Œå†›äº‹æœºå…³ç­‰ç½‘ç«™çš„çˆ¬è™«æ“ä½œï¼Œ&lt;strong&gt;ä½œè€…å°†ä¸ä¼šè¿›è¡Œä»»ä½•ç­”ç–‘&lt;/strong&gt;ï¼Œä»¥å…è¿åå›½å®¶ç›¸å…³æ³•å¾‹æ³•è§„å’Œæ”¿ç­–ã€‚&lt;/p&gt; &#xA;&lt;p&gt;For the crawler operations of government and military websites, &lt;strong&gt;the author will not answer any questions&lt;/strong&gt; in order to avoid violating relevant national laws, regulations and policies.&lt;/p&gt; &#xA;&lt;p&gt;åŒæ—¶ï¼Œè½¯ä»¶å—åˆ°ä¸“åˆ©æƒä¿æŠ¤ï¼Œå¦‚è¦ç”¨äºå•†ä¸šç”¨é€”ï¼Œè¯·è”ç³»&lt;a href=&#34;http://www.tqip.com/&#34;&gt;æ­å·å¤©å‹¤çŸ¥è¯†äº§æƒä»£ç†æœ‰é™å…¬å¸&lt;/a&gt;è¿›è¡Œä¸“åˆ©æˆæƒç­‰ä»˜è´¹æ“ä½œã€‚&lt;/p&gt; &#xA;&lt;p&gt;At the same time, the software is protected by patent rights. If you want to use it for commercial purposes, please contact &lt;a href=&#34;http://www.tqip.com/&#34;&gt;Hangzhou Tianqin Intellectual Property Agency&lt;/a&gt; for patent authorization and other paid operations.&lt;/p&gt; &#xA;&lt;h2&gt;å‡ºç‰ˆç‰©/Publications&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;This software has been accepted by The Web Conference (WWW) 2023 (ä¸­å›½è®¡ç®—æœºå­¦ä¼šé¡¶çº§ä¼šè®®ï¼ŒCCF A): &lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3543873.3587345&#34;&gt;EasySpider: A No-Code Visual System for Crawling the Web&lt;/a&gt;, April 2023.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ä¸­å›½å›½å®¶çŸ¥è¯†äº§æƒå±€å‘æ˜ä¸“åˆ©ï¼Œ&lt;a href=&#34;https://www.patentguru.com/cn/search?q=%E4%B8%80%E7%A7%8D%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8F%90%E5%8F%96%E6%B5%81%E7%A8%8B%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%B0%81%E8%A3%85%E7%B3%BB%E7%BB%9F&#34;&gt;ä¸€ç§è‡ªå®šä¹‰æå–æµç¨‹çš„æœåŠ¡å°è£…ç³»ç»Ÿ&lt;/a&gt;ï¼Œ 2022å¹´5æœˆã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://d.wanfangdata.com.cn/thesis/Y3691829&#34;&gt;æµ™æ±Ÿå¤§å­¦ç¡•å£«è®ºæ–‡&lt;/a&gt;ï¼Œ&lt;a href=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/Docs/%E9%9D%A2%E5%90%91WEB%E5%BA%94%E7%94%A8%E7%9A%84%E6%99%BA%E8%83%BD%E5%8C%96%E6%9C%8D%E5%8A%A1%E5%B0%81%E8%A3%85%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf&#34;&gt;é¢å‘WEBåº”ç”¨çš„æ™ºèƒ½åŒ–æœåŠ¡å°è£…ç³»ç»Ÿè®¾è®¡ä¸å®ç°&lt;/a&gt;ï¼Œ2020å¹´6æœˆã€‚&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- - See the [Copyright Declaration Page](https://github.com/NaiboWang/EasySpider/blob/master/media/readme_back.md) here.&#xA; --&gt; &#xA;&lt;h2&gt;ä¸­æ–‡ç•Œé¢æˆªå›¾&lt;/h2&gt; &#xA;&lt;h4&gt;è½¯ä»¶ç•Œé¢ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;å—å’Œå­å—åŠè¡¨å•å®šä¹‰&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture2.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;å·²é€‰ä¸­å’Œå¾…é€‰æ‹©ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture7.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;äº¬ä¸œå•†å“å—é€‰æ‹©ç¤ºä¾‹ï¼š&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture1.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;äº¬ä¸œå•†å“æ ‡é¢˜è‡ªåŠ¨åŒ¹é…é€‰æ‹©ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture5.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;åˆ†å—é€‰æ‹©æ‰€æœ‰å­å…ƒç´ ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture6.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;åŒç±»å‹å…ƒç´ è‡ªåŠ¨å’Œæ‰‹åŠ¨åŒ¹é…ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture8.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;å››ç§é€‰æ‹©æ–¹å¼ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture90.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;è¾“å…¥æ–‡å­—ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture10.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;å¾ªç¯ç‚¹å‡»58åŒåŸæˆ¿å±‹æ ‡é¢˜ä»¥è¿›å…¥è¯¦æƒ…é¡µé‡‡é›†ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture12.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;é‡‡é›†å…ƒç´ æ–‡æœ¬ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture14.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;æµç¨‹å›¾ç•Œé¢ä»‹ç»&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture4.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;å¾ªç¯é€‰é¡¹ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture9.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;å¾ªç¯ç‚¹å‡»ä¸‹ä¸€é¡µç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture11.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;æ¡ä»¶åˆ†æ”¯ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture13.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;å®Œæ•´é‡‡é›†æµç¨‹å›¾ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture16.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;å®Œæ•´é‡‡é›†æµç¨‹å›¾è½¬æ¢ä¸ºå¸¸è§„æµç¨‹å›¾ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture91.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;æœåŠ¡ä¿¡æ¯ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture15.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;æœåŠ¡è°ƒç”¨ç¤ºä¾‹&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture17.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;58 åŒåŸæˆ¿æºä¿¡æ¯é‡‡é›†æœåŠ¡éƒ¨åˆ†é‡‡é›†ç»“æœå±•ç¤º&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture18.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt; &#xA;&lt;!-- ## Ethics Discussion&#xA;Various fields can benefit from web crawlers due to their open access nature.&#xA;Inevitably, there will be some risk of malicious use or data infringement issue, e.g., automatic order swiping and ticket grabbing, but this is contrary to our expectations. As a tool developer, we only hope that it can be used for legitimate purposes. We advocate the reasonable and legal utilization of our system, respecting and protecting the data security and privacy. --&gt;</summary>
  </entry>
  <entry>
    <title>PromtEngineer/localGPT</title>
    <updated>2023-07-01T02:07:58Z</updated>
    <id>tag:github.com,2023-07-01:/PromtEngineer/localGPT</id>
    <link href="https://github.com/PromtEngineer/localGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Chat with your documents on your local device using GPT models. No data leaves your device and 100% private.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;localGPT&lt;/h1&gt; &#xA;&lt;p&gt;This project was inspired by the original &lt;a href=&#34;https://github.com/imartinez/privateGPT&#34;&gt;privateGPT&lt;/a&gt;. Most of the description here is inspired by the original privateGPT.&lt;/p&gt; &#xA;&lt;p&gt;For detailed overview of the project, Watch this &lt;a href=&#34;https://youtu.be/MlyoObdIHyo&#34;&gt;Youtube Video&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In this model, I have replaced the GPT4ALL model with Vicuna-7B model and we are using the InstructorEmbeddings instead of LlamaEmbeddings as used in the original privateGPT. Both Embeddings as well as LLM will run on GPU instead of CPU. It also has CPU support if you do not have a GPU (see below for instruction).&lt;/p&gt; &#xA;&lt;p&gt;Ask questions to your documents without an internet connection, using the power of LLMs. 100% private, no data leaves your execution environment at any point. You can ingest documents and ask questions without an internet connection!&lt;/p&gt; &#xA;&lt;p&gt;Built with &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/TheBloke/vicuna-7B-1.1-HF&#34;&gt;Vicuna-7B&lt;/a&gt; and &lt;a href=&#34;https://instructor-embedding.github.io/&#34;&gt;InstructorEmbeddings&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Environment Setup&lt;/h1&gt; &#xA;&lt;p&gt;In order to set your environment up to run the code here, first install all requirements:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then install AutoGPTQ - if you want to run quantized models for GPU&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/PanQiWei/AutoGPTQ.git&#xA;cd AutoGPTQ&#xA;git checkout v0.2.2&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more support on [AutoGPTQ] (&lt;a href=&#34;https://github.com/PanQiWei/AutoGPTQ&#34;&gt;https://github.com/PanQiWei/AutoGPTQ&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;Test dataset&lt;/h2&gt; &#xA;&lt;p&gt;This repo uses a &lt;a href=&#34;https://constitutioncenter.org/media/files/constitution.pdf&#34;&gt;Constitution of USA &lt;/a&gt; as an example.&lt;/p&gt; &#xA;&lt;h2&gt;Instructions for ingesting your own dataset&lt;/h2&gt; &#xA;&lt;p&gt;Put any and all of your .txt, .pdf, or .csv files into the SOURCE_DOCUMENTS directory in the load_documents() function, replace the docs_path with the absolute path of your source_documents directory.&lt;/p&gt; &#xA;&lt;p&gt;The current default file types are .txt, .pdf, .csv, and .xlsx, if you want to use any other file type, you will need to convert it to one of the default file types.&lt;/p&gt; &#xA;&lt;p&gt;Run the following command to ingest all the data.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python ingest.py  # defaults to cuda&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use the device type argument to specify a given device.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python ingest.py --device_type cpu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use help for a full list of supported devices.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python ingest.py --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will create an index containing the local vectorstore. Will take time, depending on the size of your documents. You can ingest as many documents as you want, and all will be accumulated in the local embeddings database. If you want to start from an empty database, delete the &lt;code&gt;index&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note: When you run this for the first time, it will download take time as it has to download the embedding model. In the subseqeunt runs, no data will leave your local enviroment and can be run without internet connection.&lt;/p&gt; &#xA;&lt;h2&gt;Ask questions to your documents, locally!&lt;/h2&gt; &#xA;&lt;p&gt;In order to ask a question, run a command like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python run_localGPT.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And wait for the script to require your input.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; Enter a query:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Hit enter. Wait while the LLM model consumes the prompt and prepares the answer. Once done, it will print the answer and the 4 sources it used as context from your documents; you can then ask another question without re-running the script, just wait for the prompt again.&lt;/p&gt; &#xA;&lt;p&gt;Note: When you run this for the first time, it will need internet connection to download the vicuna-7B model. After that you can turn off your internet connection, and the script inference would still work. No data gets out of your local environment.&lt;/p&gt; &#xA;&lt;p&gt;Type &lt;code&gt;exit&lt;/code&gt; to finish the script.&lt;/p&gt; &#xA;&lt;h1&gt;Run it on CPU&lt;/h1&gt; &#xA;&lt;p&gt;By default, localGPT will use your GPU to run both the &lt;code&gt;ingest.py&lt;/code&gt; and &lt;code&gt;run_localGPT.py&lt;/code&gt; scripts. But if you do not have a GPU and want to run this on CPU, now you can do that (Warning: Its going to be slow!). You will need to use &lt;code&gt;--device_type cpu&lt;/code&gt;flag with both scripts.&lt;/p&gt; &#xA;&lt;p&gt;For Ingestion run the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python ingest.py --device_type cpu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In order to ask a question, run a command like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python run_localGPT.py --device_type cpu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Run the UI&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Start by opening up &lt;code&gt;run_localGPT_API.py&lt;/code&gt; in a code editor of your choice. If you are using gpu skip to step 3.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you are running on cpu change &lt;code&gt;DEVICE_TYPE = &#39;cuda&#39;&lt;/code&gt; to &lt;code&gt;DEVICE_TYPE = &#39;cpu&#39;&lt;/code&gt;.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Comment out the following:&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;model_id = &#34;TheBloke/WizardLM-7B-uncensored-GPTQ&#34;&#xA;model_basename = &#34;WizardLM-7B-uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors&#34;&#xA;LLM = load_model(device_type=DEVICE_TYPE, model_id=model_id, model_basename = model_basename)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Uncomment:&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;model_id = &#34;TheBloke/guanaco-7B-HF&#34; # or some other -HF or .bin model&#xA;LLM = load_model(device_type=DEVICE_TYPE, model_id=model_id)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;If you are running gpu there should be nothing to change. Save and close &lt;code&gt;run_localGPT_API.py&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open up a terminal and activate your python environment that contains the dependencies installed from requirements.txt.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to the &lt;code&gt;/LOCALGPT&lt;/code&gt; directory.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the following command &lt;code&gt;python run_localGPT_API.py&lt;/code&gt;. The API should being to run.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Wait until everything has loaded in. You should see something like &lt;code&gt;INFO:werkzeug:Press CTRL+C to quit&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open up a second terminal and activate the same python environment.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to the &lt;code&gt;/LOCALGPT/localGPTUI&lt;/code&gt; directory.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the command &lt;code&gt;python localGPTUI.py&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open up a web browser and go the address &lt;code&gt;http://localhost:5111/&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;How does it work?&lt;/h1&gt; &#xA;&lt;p&gt;Selecting the right local models and the power of &lt;code&gt;LangChain&lt;/code&gt; you can run the entire pipeline locally, without any data leaving your environment, and with reasonable performance.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;ingest.py&lt;/code&gt; uses &lt;code&gt;LangChain&lt;/code&gt; tools to parse the document and create embeddings locally using &lt;code&gt;InstructorEmbeddings&lt;/code&gt;. It then stores the result in a local vector database using &lt;code&gt;Chroma&lt;/code&gt; vector store.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;run_localGPT.py&lt;/code&gt; uses a local LLM (Vicuna-7B in this case) to understand questions and create answers. The context for the answers is extracted from the local vector store using a similarity search to locate the right piece of context from the docs.&lt;/li&gt; &#xA; &lt;li&gt;You can replace this local LLM with any other LLM from the HuggingFace. Make sure whatever LLM you select is in the HF format.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;How to select different LLM models?&lt;/h1&gt; &#xA;&lt;p&gt;The following will provide instructions on how you can select a different LLM model to create your response:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Open up &lt;code&gt;run_localGPT.py&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Go to &lt;code&gt;def main(device_type, show_sources)&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Go to the comment where it says &lt;code&gt;# load the LLM for generating Natural Language responses&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Below it, it details a bunch of examples on models from HuggingFace that have already been tested to be run with the original trained model (ending with HF or have a .bin in its &#34;Files and versions&#34;), and quantized models (ending with GPTQ or have a .no-act-order or .safetensors in its &#34;Files and versions&#34;).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For models that end with HF or have a .bin inside its &#34;Files and versions&#34; on its HuggingFace page.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Make sure you have a model_id selected. For example -&amp;gt; &lt;code&gt;model_id = &#34;TheBloke/guanaco-7B-HF&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;If you go to its HuggingFace [Site] (&lt;a href=&#34;https://huggingface.co/TheBloke/guanaco-7B-HF&#34;&gt;https://huggingface.co/TheBloke/guanaco-7B-HF&lt;/a&gt;) and go to &#34;Files and versions&#34; you will notice model files that end with a .bin extension.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Any model files that contain .bin extensions will be run with the following code where the &lt;code&gt;# load the LLM for generating Natural Language responses&lt;/code&gt; comment is found.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;model_id = &#34;TheBloke/guanaco-7B-HF&#34;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;llm = load_model(device_type, model_id=model_id)&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For models that contain GPTQ in its name and or have a .no-act-order or .safetensors extension inside its &#34;Files and versions on its HuggingFace page.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Make sure you have a model_id selected. For example -&amp;gt; model_id = &lt;code&gt;&#34;TheBloke/wizardLM-7B-GPTQ&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;You will also need its model basename file selected. For example -&amp;gt; &lt;code&gt;model_basename = &#34;wizardLM-7B-GPTQ-4bit.compat.no-act-order.safetensors&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;If you go to its HuggingFace [Site] (&lt;a href=&#34;https://huggingface.co/TheBloke/wizardLM-7B-GPTQ&#34;&gt;https://huggingface.co/TheBloke/wizardLM-7B-GPTQ&lt;/a&gt;) and go to &#34;Files and versions&#34; you will notice a model file that ends with a .safetensors extension.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Any model files that contain no-act-order or .safetensors extensions will be run with the following code where the &lt;code&gt;# load the LLM for generating Natural Language responses&lt;/code&gt; comment is found.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;model_id = &#34;TheBloke/WizardLM-7B-uncensored-GPTQ&#34;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;model_basename = &#34;WizardLM-7B-uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors&#34;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;llm = load_model(device_type, model_id=model_id, model_basename = model_basename)&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Comment out all other instances of &lt;code&gt;model_id=&#34;other model names&#34;&lt;/code&gt;, &lt;code&gt;model_basename=other base model names&lt;/code&gt;, and &lt;code&gt;llm = load_model(args*)&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;System Requirements&lt;/h1&gt; &#xA;&lt;h2&gt;Python Version&lt;/h2&gt; &#xA;&lt;p&gt;To use this software, you must have Python 3.10 or later installed. Earlier versions of Python will not compile.&lt;/p&gt; &#xA;&lt;h2&gt;C++ Compiler&lt;/h2&gt; &#xA;&lt;p&gt;If you encounter an error while building a wheel during the &lt;code&gt;pip install&lt;/code&gt; process, you may need to install a C++ compiler on your computer.&lt;/p&gt; &#xA;&lt;h3&gt;For Windows 10/11&lt;/h3&gt; &#xA;&lt;p&gt;To install a C++ compiler on Windows 10/11, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install Visual Studio 2022.&lt;/li&gt; &#xA; &lt;li&gt;Make sure the following components are selected: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Universal Windows Platform development&lt;/li&gt; &#xA;   &lt;li&gt;C++ CMake tools for Windows&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Download the MinGW installer from the &lt;a href=&#34;https://sourceforge.net/projects/mingw/&#34;&gt;MinGW website&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run the installer and select the &#34;gcc&#34; component.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;NVIDIA Driver&#39;s Issues:&lt;/h3&gt; &#xA;&lt;p&gt;Follow this &lt;a href=&#34;https://linuxconfig.org/how-to-install-the-nvidia-drivers-on-ubuntu-22-04&#34;&gt;page&lt;/a&gt; to install NVIDIA Drivers.&lt;/p&gt; &#xA;&lt;h3&gt;M1/M2 Macbook users:&lt;/h3&gt; &#xA;&lt;p&gt;1- Follow this &lt;a href=&#34;https://developer.apple.com/metal/pytorch/&#34;&gt;page&lt;/a&gt; to build up PyTorch with Metal Performance Shaders (MPS) support. PyTorch uses the new MPS backend for GPU training acceleration. It is good practice to verify mps support using a simple Python script as mentioned in the provided link.&lt;/p&gt; &#xA;&lt;p&gt;2- By following the page, here is an example of what you may initiate in your terminal&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;xcode-select --install&#xA;conda install pytorch torchvision torchaudio -c pytorch-nightly&#xA;pip install chardet&#xA;pip install cchardet&#xA;pip uninstall charset_normalizer&#xA;pip install charset_normalizer&#xA;pip install pdfminer.six&#xA;pip install xformers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;3- Please keep in mind that the quantized models are not yet supported by Apple Silicon (M1/M2) by auto-gptq library that is being used for loading quantized models, &lt;a href=&#34;https://github.com/PanQiWei/AutoGPTQ/issues/133#issuecomment-1575002893&#34;&gt;see here&lt;/a&gt;. Therefore, you will not be able to run quantized models on M1/M2.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#PromtEngineer/localGPT&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=PromtEngineer/localGPT&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Disclaimer&lt;/h1&gt; &#xA;&lt;p&gt;This is a test project to validate the feasibility of a fully local solution for question answering using LLMs and Vector embeddings. It is not production ready, and it is not meant to be used in production. Vicuna-7B is based on the Llama model so that has the original Llama license.&lt;/p&gt;</summary>
  </entry>
</feed>