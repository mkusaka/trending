<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-01T01:57:57Z</updated>
  <subtitle>Monthly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>geohot/tinygrad</title>
    <updated>2022-12-01T01:57:57Z</updated>
    <id>tag:github.com,2022-12-01:/geohot/tinygrad</id>
    <link href="https://github.com/geohot/tinygrad" rel="alternate"></link>
    <summary type="html">&lt;p&gt;You like pytorch? You like micrograd? You love tinygrad! ❤️&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geohot/tinygrad/master/docs/logo.png&#34;&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/geohot/tinygrad/workflows/Unit%20Tests/badge.svg?sanitize=true&#34; alt=&#34;Unit Tests&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;For something in between a &lt;a href=&#34;https://github.com/pytorch/pytorch&#34;&gt;pytorch&lt;/a&gt; and a &lt;a href=&#34;https://github.com/karpathy/micrograd&#34;&gt;karpathy/micrograd&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This may not be the best deep learning framework, but it is a deep learning framework.&lt;/p&gt; &#xA;&lt;p&gt;The sub 1000 line core of it is in &lt;code&gt;tinygrad/&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Due to its extreme simplicity, it aims to be the easiest framework to add new accelerators to, with support for both inference and training. Support the simple basic ops, and you get SOTA &lt;a href=&#34;https://arxiv.org/abs/1905.11946&#34;&gt;vision&lt;/a&gt; &lt;code&gt;models/efficientnet.py&lt;/code&gt; and &lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;language&lt;/a&gt; &lt;code&gt;models/transformer.py&lt;/code&gt; models.&lt;/p&gt; &#xA;&lt;p&gt;We are working on support for the Apple Neural Engine and the Google TPU in the &lt;code&gt;accel/&lt;/code&gt; folder. Eventually, &lt;a href=&#34;https://geohot.github.io/blog/jekyll/update/2021/06/13/a-breakdown-of-ai-chip-companies.html&#34;&gt;we will build custom hardware&lt;/a&gt; for tinygrad, and it will be blindingly fast. Now, it is slow.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/geohot/tinygrad.git&#xA;cd tinygrad&#xA;python3 setup.py develop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Contributing&lt;/h3&gt; &#xA;&lt;p&gt;There&#39;s a lot of interest in tinygrad lately. Here&#39;s some guidelines for contributing:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bugfixes are the best and always welcome! Like &lt;a href=&#34;https://github.com/geohot/tinygrad/pull/421/files&#34;&gt;this one&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you don&#39;t understand the code you are changing, don&#39;t change it!&lt;/li&gt; &#xA; &lt;li&gt;All code golf PRs will be closed, but &lt;a href=&#34;https://github.com/geohot/tinygrad/pull/372/files&#34;&gt;conceptual cleanups&lt;/a&gt; are great.&lt;/li&gt; &#xA; &lt;li&gt;Features are welcome. Though if you are adding a feature, you need to include tests.&lt;/li&gt; &#xA; &lt;li&gt;Improving test coverage is great, with reliable non brittle tests.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Example&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tinygrad.tensor import Tensor&#xA;&#xA;x = Tensor.eye(3, requires_grad=True)&#xA;y = Tensor([[2.0,0,-2.0]], requires_grad=True)&#xA;z = y.matmul(x).sum()&#xA;z.backward()&#xA;&#xA;print(x.grad)  # dz/dx&#xA;print(y.grad)  # dz/dy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Same example in torch&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;&#xA;x = torch.eye(3, requires_grad=True)&#xA;y = torch.tensor([[2.0,0,-2.0]], requires_grad=True)&#xA;z = y.matmul(x).sum()&#xA;z.backward()&#xA;&#xA;print(x.grad)  # dz/dx&#xA;print(y.grad)  # dz/dy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Neural networks?&lt;/h2&gt; &#xA;&lt;p&gt;It turns out, a decent autograd tensor library is 90% of what you need for neural networks. Add an optimizer (SGD, RMSprop, and Adam implemented) from tinygrad.nn.optim, write some boilerplate minibatching code, and you have all you need.&lt;/p&gt; &#xA;&lt;h3&gt;Neural network example (from test/test_mnist.py)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tinygrad.tensor import Tensor&#xA;import tinygrad.nn.optim as optim&#xA;&#xA;class TinyBobNet:&#xA;  def __init__(self):&#xA;    self.l1 = Tensor.uniform(784, 128)&#xA;    self.l2 = Tensor.uniform(128, 10)&#xA;&#xA;  def forward(self, x):&#xA;    return x.dot(self.l1).relu().dot(self.l2).logsoftmax()&#xA;&#xA;model = TinyBobNet()&#xA;optim = optim.SGD([model.l1, model.l2], lr=0.001)&#xA;&#xA;# ... and complete like pytorch, with (x,y) data&#xA;&#xA;out = model.forward(x)&#xA;loss = out.mul(y).mean()&#xA;optim.zero_grad()&#xA;loss.backward()&#xA;optim.step()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;GPU and Accelerator Support&lt;/h2&gt; &#xA;&lt;p&gt;tinygrad supports GPUs through PyOpenCL.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tinygrad.tensor import Tensor&#xA;(Tensor.ones(4,4).gpu() + Tensor.ones(4,4).gpu()).cpu()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ANE Support?! (broken)&lt;/h3&gt; &#xA;&lt;p&gt;If all you want to do is ReLU, you are in luck! You can do very fast ReLU (at least 30 MEGAReLUs/sec confirmed)&lt;/p&gt; &#xA;&lt;p&gt;Requires your Python to be signed with &lt;code&gt;ane/lib/sign_python.sh&lt;/code&gt; to add the &lt;code&gt;com.apple.ane.iokit-user-access&lt;/code&gt; entitlement, which also requires &lt;code&gt;sudo nvram boot-args=&#34;amfi_get_out_of_my_way=1 ipc_control_port_options=0&#34;&lt;/code&gt;. Build the library with &lt;code&gt;ane/lib/build.sh&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;In order to set boot-args and for the AMFI kext to respect that arg, run &lt;code&gt;csrutil enable --without-kext --without-nvram&lt;/code&gt; in recovery mode.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tinygrad.tensor import Tensor&#xA;&#xA;a = Tensor([-2,-1,0,1,2]).ane()&#xA;b = a.relu()&#xA;print(b.cpu())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Warning: do not rely on the ANE port. It segfaults sometimes. So if you were doing something important with tinygrad and wanted to use the ANE, you might have a bad time.&lt;/p&gt; &#xA;&lt;h3&gt;hlops (in tensor.py)&lt;/h3&gt; &#xA;&lt;p&gt;hlops are syntactic sugar around mlops. They support most things torch does.&lt;/p&gt; &#xA;&lt;h3&gt;mlops&lt;/h3&gt; &#xA;&lt;p&gt;mlops are mid level ops, there&#39;s 15 of them. They understand memory allocation and derivatives&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Relu, Log, Exp                          # unary ops&#xA;Sum, Max                                # reduce ops (with axis argument)&#xA;Add, Sub, Mul, Pow                      # binary ops (no broadcasting, use expand)&#xA;Reshape, Permute, Slice, Expand, Flip   # movement ops&#xA;Conv2D(NCHW)                            # processing op (Matmul is also Conv2D)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You no longer need to write mlops for a new accelerator&lt;/p&gt; &#xA;&lt;h3&gt;Adding an accelerator (llops)&lt;/h3&gt; &#xA;&lt;p&gt;The autodiff stuff is all in mlops now so you can focus on the raw operations&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Buffer                                                     # class of memory on this device&#xA;unary_op  (RELU, EXP, LOG, NEG, SIGN)                      # A -&amp;gt; A&#xA;reduce_op (SUM, MAX)                                       # A -&amp;gt; B (smaller size, B has 1 in shape)&#xA;binary_op (ADD, SUB, MUL, DIV, POW, CMPEQ)                 # A + B -&amp;gt; C (all the same size)&#xA;movement_op (RESHAPE, PERMUTE, PAD, SHRINK, EXPAND, FLIP)  # A -&amp;gt; B (different size)&#xA;processing_op (CONV)                                       # A + B -&amp;gt; C&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When tinygrad moves to lazy evaluation, optimizations will happen here.&lt;/p&gt; &#xA;&lt;h2&gt;ImageNet inference&lt;/h2&gt; &#xA;&lt;p&gt;Despite being tiny, tinygrad supports the full EfficientNet. Pass in a picture to discover what it is.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ipython3 examples/efficientnet.py https://media.istockphoto.com/photos/hen-picture-id831791190&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, if you have a webcam and cv2 installed&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ipython3 examples/efficientnet.py webcam&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;PROTIP: Set &#34;GPU=1&#34; environment variable if you want this to go faster.&lt;/p&gt; &#xA;&lt;p&gt;PROPROTIP: Set &#34;DEBUG=1&#34; environment variable if you want to see why it&#39;s slow.&lt;/p&gt; &#xA;&lt;h3&gt;tinygrad supports Stable Diffusion!&lt;/h3&gt; &#xA;&lt;p&gt;Run &lt;code&gt;TORCH=1 python3 examples/stable_diffusion.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;(or without torch: &lt;code&gt;OPT=2 OPENCL=1 python3 examples/stable_diffusion.py&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geohot/tinygrad/master/docs/stable_diffusion_by_tinygrad.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &#34;a horse sized cat eating a bagel&#34; &lt;/p&gt; &#xA;&lt;h3&gt;tinygrad supports GANs&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;code&gt;examples/mnist_gan.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geohot/tinygrad/master/docs/mnist_by_tinygrad.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;tinygrad supports yolo&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;code&gt;examples/yolov3.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geohot/tinygrad/master/docs/yolo_by_tinygrad.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;The promise of small&lt;/h2&gt; &#xA;&lt;p&gt;tinygrad will always be below 1000 lines. If it isn&#39;t, we will revert commits until tinygrad becomes smaller.&lt;/p&gt; &#xA;&lt;h3&gt;Drawing Execution Graph&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Nodes are Tensors&lt;/li&gt; &#xA; &lt;li&gt;Black edge is a forward pass&lt;/li&gt; &#xA; &lt;li&gt;Blue edge is a backward pass&lt;/li&gt; &#xA; &lt;li&gt;Red edge is data the backward pass depends on&lt;/li&gt; &#xA; &lt;li&gt;Purple edge is intermediates created in the forward&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GRAPH=1 python3 test/test_mnist.py TestMNIST.test_sgd_onestep&#xA;# requires dot, outputs /tmp/net.svg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running tests&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 -m pytest&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>rome/tools</title>
    <updated>2022-12-01T01:57:57Z</updated>
    <id>tag:github.com,2022-12-01:/rome/tools</id>
    <link href="https://github.com/rome/tools" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Unified developer tools for JavaScript, TypeScript, and the web&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/rome/brand/main/PNG/logo_white_yellow_transparent.png&#34; width=&#34;700&#34;&gt; &#xA;  &lt;img alt=&#34;Rome&#39;s logo depicting an ancient Roman arch with the word Rome to its side&#34; src=&#34;https://raw.githubusercontent.com/rome/brand/main/PNG/logo_transparent.png&#34; width=&#34;700&#34;&gt; &#xA; &lt;/picture&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rome/tools/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue.svg?color=brightgreen&#34; alt=&#34;MIT licensed&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/rome&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/678763474494423051?logo=discord&amp;amp;label=discord&amp;amp;color=brightgreen&#34; alt=&#34;Discord chat&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/rome/tools/actions/workflows/main.yml&#34;&gt;&lt;img src=&#34;https://github.com/rome/tools/actions/workflows/main.yml/badge.svg?sanitize=true&#34; alt=&#34;CI on main&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmjs.com/package/rome/v/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/rome/latest?color=brightgreen&#34; alt=&#34;npm version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=rome.rome&#34;&gt;&lt;img src=&#34;https://img.shields.io/visual-studio-marketplace/v/rome.rome?color=brightgreen&amp;amp;label=vscode&#34; alt=&#34;VSCode version&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rome&lt;/strong&gt; is a formatter, linter, bundler, and &lt;a href=&#34;https://rome.tools/&#34;&gt;more&lt;/a&gt; for JavaScript, TypeScript, JSON, HTML, Markdown, and CSS.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rome&lt;/strong&gt; is designed to replace &lt;a href=&#34;https://babeljs.io/&#34;&gt;Babel&lt;/a&gt;, &lt;a href=&#34;https://eslint.org/&#34;&gt;ESLint&lt;/a&gt;, &lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;, &lt;a href=&#34;https://prettier.io/&#34;&gt;Prettier&lt;/a&gt;, &lt;a href=&#34;https://jestjs.io/&#34;&gt;Jest&lt;/a&gt;, and others.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rome&lt;/strong&gt; unifies functionality that has previously been separate tools. Building upon a shared base allows us to provide a cohesive experience for processing code, displaying errors, parallelizing work, caching, and configuration.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rome&lt;/strong&gt; has strong conventions and aims to have minimal configuration. Read more about our &lt;a href=&#34;https://docs.rome.tools/internals/philosophy/&#34;&gt;project philosophy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rome&lt;/strong&gt; is &lt;a href=&#34;https://rome.tools/blog/2021/09/21/rome-will-be-rewritten-in-rust.html&#34;&gt;written in Rust&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rome&lt;/strong&gt; has first-class IDE support, with a sophisticated parser that represents the source text in full fidelity and top-notch error recovery.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rome&lt;/strong&gt; is &lt;a href=&#34;https://github.com/rome/tools/tree/main/LICENSE&#34;&gt;MIT licensed&lt;/a&gt; and moderated under the &lt;a href=&#34;https://github.com/rome/tools/tree/main/CODE_OF_CONDUCT.md&#34;&gt;Contributor Covenant Code of Conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Check out our &lt;a href=&#34;https://rome.tools&#34;&gt;homepage&lt;/a&gt; to learn more about Rome, or directly head to the &lt;a href=&#34;https://docs.rome.tools/guides/getting-started/&#34;&gt;Getting Started guide&lt;/a&gt; if you want to start using Rome.&lt;/p&gt; &#xA;&lt;h2&gt;Technical documentation&lt;/h2&gt; &#xA;&lt;p&gt;Browse Rome&#39;s internal &lt;a href=&#34;https://rustdocs.rome.tools/&#34;&gt;Rust API Documentation&lt;/a&gt; if you&#39;re interested to learn more about how Rome works.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>shadcn/taxonomy</title>
    <updated>2022-12-01T01:57:57Z</updated>
    <id>tag:github.com,2022-12-01:/shadcn/taxonomy</id>
    <link href="https://github.com/shadcn/taxonomy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An open source application built using the new router, server components and everything new in Next.js 13.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Taxonomy&lt;/h1&gt; &#xA;&lt;p&gt;An open source application built using the new router, server components and everything new in Next.js 13.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt; This app is a work in progress. I&#39;m building this in public. You can follow the progress on Twitter &lt;a href=&#34;https://twitter.com/shadcn&#34;&gt;@shadcn&lt;/a&gt;. See the roadmap below.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/124599/198038921-2b16b18b-cb4d-44b1-bd1d-6419d4a8d92c.png&#34; alt=&#34;screenshot-2&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;About this project&lt;/h2&gt; &#xA;&lt;p&gt;Right now, I&#39;m using this project as an experiment to see how a modern app (with features like authentication, subscriptions, API routes, static pages for docs ...etc) would work in Next.js 13 and server components.&lt;/p&gt; &#xA;&lt;p&gt;I&#39;ll be posting updates and issues here.&lt;/p&gt; &#xA;&lt;p&gt;A few people have asked me to turn this into a starter. I think we could do that once the new features are out of beta.&lt;/p&gt; &#xA;&lt;h2&gt;Note on Performance&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt; This app is using the canary releases for Next.js 13 and React 18. The new router and app dir is still in beta and not production-ready. NextAuth.js, which is used for authentication, is also not fully supported in Next.js 13 and RSC. &lt;strong&gt;Expect some performance hits when testing the dashboard&lt;/strong&gt;. If you see something broken, you can ping me &lt;a href=&#34;https://twitter.com/shadcn&#34;&gt;@shadcn&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;New &lt;code&gt;/app&lt;/code&gt; dir,&lt;/li&gt; &#xA; &lt;li&gt;Routing, Layouts, Nested Layouts and Layout Groups&lt;/li&gt; &#xA; &lt;li&gt;Data Fetching, Caching and Mutation&lt;/li&gt; &#xA; &lt;li&gt;Loading UI&lt;/li&gt; &#xA; &lt;li&gt;Server and Client Components&lt;/li&gt; &#xA; &lt;li&gt;API Routes and Middlewares&lt;/li&gt; &#xA; &lt;li&gt;Authentication using &lt;strong&gt;NextAuth.js&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;ORM using &lt;strong&gt;Prisma&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Database on &lt;strong&gt;PlanetScale&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;UI Components built using &lt;strong&gt;Radix UI&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Documentation and blog using &lt;strong&gt;MDX&lt;/strong&gt; and &lt;strong&gt;Contentlayer&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Subscriptions using &lt;strong&gt;Stripe&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Styled using &lt;strong&gt;Tailwind CSS&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Validations using &lt;strong&gt;Zod&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Written in &lt;strong&gt;TypeScript&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;del&gt;Add MDX support for basic pages&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;del&gt;Build marketing pages&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;del&gt;Subscriptions using Stripe&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;del&gt;Responsive styles&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;del&gt;Add OG image for blog using @vercel/og&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add tests&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Dark mode&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Known Issues&lt;/h2&gt; &#xA;&lt;p&gt;A list of things not working right now:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;del&gt;GitHub authentication (use email)&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;del&gt;&lt;a href=&#34;https://github.com/prisma/prisma/issues/16117&#34;&gt;Prisma: Error: ENOENT: no such file or directory, open &#39;/var/task/.next/server/chunks/schema.prisma&#39;&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;del&gt;&lt;a href=&#34;https://github.com/vercel/next.js/issues/42414&#34;&gt;Next.js 13: Client side navigation does not update head&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Why not tRPC, Turborepo or X?&lt;/h2&gt; &#xA;&lt;p&gt;I might add this later. For now, I want to see how far we can get using Next.js only.&lt;/p&gt; &#xA;&lt;p&gt;If you have some suggestions, feel free to create an issue.&lt;/p&gt; &#xA;&lt;h2&gt;Running Locally&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install dependencies using pnpm:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pnpm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env.local&lt;/code&gt; and update the variables.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start the development server:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pnpm dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Licensed under the &lt;a href=&#34;https://github.com/reflexjs/reflex/raw/master/LICENSE&#34;&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>