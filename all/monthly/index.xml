<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-01T01:59:38Z</updated>
  <subtitle>Monthly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>atherosai/ui</title>
    <updated>2024-04-01T01:59:38Z</updated>
    <id>tag:github.com,2024-04-01:/atherosai/ui</id>
    <link href="https://github.com/atherosai/ui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Simple UI examples from my social media&lt;/p&gt;&lt;hr&gt;&lt;p&gt;This is repository with examples of simple UI components. The repository is based on Next.js and React.js.&lt;/p&gt; &#xA;&lt;h1&gt;installation&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Clone the repo with&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:atherosai/ui.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;For HTML/CSS/JS&lt;/h1&gt; &#xA;&lt;p&gt;Just navigate to the folder with your chosen example and open html file in the browser.&lt;/p&gt; &#xA;&lt;h1&gt;For React Examples&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install npm packages&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm i &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run development mode&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now the app is accessible at &lt;code&gt;localhost:3000&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h1&gt;My Social Media&lt;/h1&gt; &#xA;&lt;p&gt;The examples are posted here:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.tiktok.com/@davidm_ai&#34;&gt;TikTok&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.instagram.com/davidm_ai/&#34;&gt;Instagram&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/@Atheroslearning&#34;&gt;Youtube&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://twitter.com/davidm_ml&#34;&gt;Twitter&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/david-mraz/&#34;&gt;Linkedin&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.threads.net/@davidm_ai&#34;&gt;Threads&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Learn more at &lt;a href=&#34;https://learning.atheros.ai&#34;&gt;Atheros Learning&lt;/a&gt;! HTML and CSS course is coming this month!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>nvim-lua/kickstart.nvim</title>
    <updated>2024-04-01T01:59:38Z</updated>
    <id>tag:github.com,2024-04-01:/nvim-lua/kickstart.nvim</id>
    <link href="https://github.com/nvim-lua/kickstart.nvim" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A launch point for your personal nvim configuration&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;kickstart.nvim&lt;/h1&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;A starting point for Neovim that is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Small&lt;/li&gt; &#xA; &lt;li&gt;Single-file&lt;/li&gt; &#xA; &lt;li&gt;Completely Documented&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOT&lt;/strong&gt; a Neovim distribution, but instead a starting point for your configuration.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Install Neovim&lt;/h3&gt; &#xA;&lt;p&gt;Kickstart.nvim targets &lt;em&gt;only&lt;/em&gt; the latest &lt;a href=&#34;https://github.com/neovim/neovim/releases/tag/stable&#34;&gt;&#39;stable&#39;&lt;/a&gt; and latest &lt;a href=&#34;https://github.com/neovim/neovim/releases/tag/nightly&#34;&gt;&#39;nightly&#39;&lt;/a&gt; of Neovim. If you are experiencing issues, please make sure you have the latest versions.&lt;/p&gt; &#xA;&lt;h3&gt;Install External Dependencies&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/nvim-lua/kickstart.nvim/master/#FAQ&#34;&gt;Backup&lt;/a&gt; your previous configuration (if any exists)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;External Requirements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Basic utils: &lt;code&gt;git&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt;, &lt;code&gt;unzip&lt;/code&gt;, C Compiler (&lt;code&gt;gcc&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BurntSushi/ripgrep#installation&#34;&gt;ripgrep&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://www.nerdfonts.com/&#34;&gt;Nerd Font&lt;/a&gt;: optional, provides various icons &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;if you have it set &lt;code&gt;vim.g.have_nerd_font&lt;/code&gt; in &lt;code&gt;init.lua&lt;/code&gt; to true&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Language Setup: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;If want to write Typescript, you need &lt;code&gt;npm&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;If want to write Golang, you will need &lt;code&gt;go&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;etc.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; See &lt;a href=&#34;https://raw.githubusercontent.com/nvim-lua/kickstart.nvim/master/#Install-Recipes&#34;&gt;Install Recipes&lt;/a&gt; for additional Windows and Linux specific notes and quick install snippets&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Neovim&#39;s configurations are located under the following paths, depending on your OS:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;OS&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;PATH&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Linux, MacOS&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;$XDG_CONFIG_HOME/nvim&lt;/code&gt;, &lt;code&gt;~/.config/nvim&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Windows (cmd)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;%userprofile%\AppData\Local\nvim\&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Windows (powershell)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;$env:USERPROFILE\AppData\Local\nvim\&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Install Kickstart&lt;/h3&gt; &#xA;&lt;h4&gt;Recommended Step&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.github.com/en/get-started/quickstart/fork-a-repo&#34;&gt;Fork&lt;/a&gt; this repo so that you have your own copy that you can modify, then install by cloning the fork to your machine using one of the commands below, depending on your OS.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; Your fork&#39;s url will be something like this: &lt;code&gt;https://github.com/&amp;lt;your_github_username&amp;gt;/kickstart.nvim.git&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Clone kickstart.nvim&lt;/h4&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; If following the recommended step above (i.e., forking the repo), replace &lt;code&gt;nvim-lua&lt;/code&gt; with &lt;code&gt;&amp;lt;your_github_username&amp;gt;&lt;/code&gt; in the commands below&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; Linux and Mac &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/nvim-lua/kickstart.nvim.git &#34;${XDG_CONFIG_HOME:-$HOME/.config}&#34;/nvim&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; Windows &lt;/summary&gt; &#xA; &lt;p&gt;If you&#39;re using &lt;code&gt;cmd.exe&lt;/code&gt;:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;git clone https://github.com/nvim-lua/kickstart.nvim.git %userprofile%\AppData\Local\nvim\&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;If you&#39;re using &lt;code&gt;powershell.exe&lt;/code&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;git clone https://github.com/nvim-lua/kickstart.nvim.git $env:USERPROFILE\AppData\Local\nvim\&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Post Installation&lt;/h3&gt; &#xA;&lt;p&gt;Start Neovim&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;nvim&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it! Lazy will install all the plugins you have. Use &lt;code&gt;:Lazy&lt;/code&gt; to view current plugin status. Hit &lt;code&gt;q&lt;/code&gt; to close the window.&lt;/p&gt; &#xA;&lt;p&gt;Read through the &lt;code&gt;init.lua&lt;/code&gt; file in your configuration folder for more information about extending and exploring Neovim.&lt;/p&gt; &#xA;&lt;h4&gt;Examples of adding popularly requested plugins&lt;/h4&gt; &#xA;&lt;p&gt;NOTE: You&#39;ll need to uncomment the line in the init.lua that turns on loading custom plugins.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Adding autopairs&lt;/summary&gt; &#xA; &lt;p&gt;This will automatically install &lt;a href=&#34;https://github.com/windwp/nvim-autopairs&#34;&gt;windwp/nvim-autopairs&lt;/a&gt; and enable it on startup. For more information, see documentation for &lt;a href=&#34;https://github.com/folke/lazy.nvim&#34;&gt;lazy.nvim&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;In the file: &lt;code&gt;lua/custom/plugins/autopairs.lua&lt;/code&gt;, add:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;-- File: lua/custom/plugins/autopairs.lua&#xA;&#xA;return {&#xA;  &#34;windwp/nvim-autopairs&#34;,&#xA;  -- Optional dependency&#xA;  dependencies = { &#39;hrsh7th/nvim-cmp&#39; },&#xA;  config = function()&#xA;    require(&#34;nvim-autopairs&#34;).setup {}&#xA;    -- If you want to automatically add `(` after selecting a function or method&#xA;    local cmp_autopairs = require(&#39;nvim-autopairs.completion.cmp&#39;)&#xA;    local cmp = require(&#39;cmp&#39;)&#xA;    cmp.event:on(&#xA;      &#39;confirm_done&#39;,&#xA;      cmp_autopairs.on_confirm_done()&#xA;    )&#xA;  end,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Adding a file tree plugin&lt;/summary&gt; &#xA; &lt;p&gt;This will install the tree plugin and add the command &lt;code&gt;:Neotree&lt;/code&gt; for you. For more information, see the documentation at &lt;a href=&#34;https://github.com/nvim-neo-tree/neo-tree.nvim&#34;&gt;neo-tree.nvim&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;In the file: &lt;code&gt;lua/custom/plugins/filetree.lua&lt;/code&gt;, add:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;-- File: lua/custom/plugins/filetree.lua&#xA;&#xA;return {&#xA;  &#34;nvim-neo-tree/neo-tree.nvim&#34;,&#xA;  version = &#34;*&#34;,&#xA;  dependencies = {&#xA;    &#34;nvim-lua/plenary.nvim&#34;,&#xA;    &#34;nvim-tree/nvim-web-devicons&#34;, -- not strictly required, but recommended&#xA;    &#34;MunifTanjim/nui.nvim&#34;,&#xA;  },&#xA;  config = function ()&#xA;    require(&#39;neo-tree&#39;).setup {}&#xA;  end,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Getting Started&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/m8C0Cq9Uv9o&#34;&gt;The Only Video You Need to Get Started with Neovim&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;FAQ&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;What should I do if I already have a pre-existing neovim configuration? &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;You should back it up and then delete all associated files.&lt;/li&gt; &#xA;   &lt;li&gt;This includes your existing init.lua and the neovim files in &lt;code&gt;~/.local&lt;/code&gt; which can be deleted with &lt;code&gt;rm -rf ~/.local/share/nvim/&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Can I keep my existing configuration in parallel to kickstart? &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Yes! You can use &lt;a href=&#34;https://neovim.io/doc/user/starting.html#%24NVIM_APPNAME&#34;&gt;NVIM_APPNAME&lt;/a&gt;&lt;code&gt;=nvim-NAME&lt;/code&gt; to maintain multiple configurations. For example, you can install the kickstart configuration in &lt;code&gt;~/.config/nvim-kickstart&lt;/code&gt; and create an alias: &lt;pre&gt;&lt;code&gt;alias nvim-kickstart=&#39;NVIM_APPNAME=&#34;nvim-kickstart&#34; nvim&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; When you run Neovim using &lt;code&gt;nvim-kickstart&lt;/code&gt; alias it will use the alternative config directory and the matching local directory &lt;code&gt;~/.local/share/nvim-kickstart&lt;/code&gt;. You can apply this approach to any Neovim distribution that you would like to try out.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;What if I want to &#34;uninstall&#34; this configuration: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;See &lt;a href=&#34;https://github.com/folke/lazy.nvim#-uninstalling&#34;&gt;lazy.nvim uninstall&lt;/a&gt; information&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Why is the kickstart &lt;code&gt;init.lua&lt;/code&gt; a single file? Wouldn&#39;t it make sense to split it into multiple files? &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The main purpose of kickstart is to serve as a teaching tool and a reference configuration that someone can easily use to &lt;code&gt;git clone&lt;/code&gt; as a basis for their own. As you progress in learning Neovim and Lua, you might consider splitting &lt;code&gt;init.lua&lt;/code&gt; into smaller parts. A fork of kickstart that does this while maintaining the same functionality is available here: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/dam9000/kickstart-modular.nvim&#34;&gt;kickstart-modular.nvim&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Discussions on this topic can be found here: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/nvim-lua/kickstart.nvim/issues/218&#34;&gt;Restructure the configuration&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/nvim-lua/kickstart.nvim/pull/473&#34;&gt;Reorganize init.lua into a multi-file setup&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Install Recipes&lt;/h3&gt; &#xA;&lt;p&gt;Below you can find OS specific install instructions for Neovim and dependencies.&lt;/p&gt; &#xA;&lt;p&gt;After installing all the dependencies continue with the &lt;a href=&#34;https://raw.githubusercontent.com/nvim-lua/kickstart.nvim/master/#Install-Kickstart&#34;&gt;Install Kickstart&lt;/a&gt; step.&lt;/p&gt; &#xA;&lt;h4&gt;Windows Installation&lt;/h4&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Windows with Microsoft C++ Build Tools and CMake&lt;/summary&gt; Installation may require installing build tools and updating the run command for `telescope-fzf-native` &#xA; &lt;p&gt;See &lt;code&gt;telescope-fzf-native&lt;/code&gt; documentation for &lt;a href=&#34;https://github.com/nvim-telescope/telescope-fzf-native.nvim#installation&#34;&gt;more details&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;This requires:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Install CMake and the Microsoft C++ Build Tools on Windows&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;{&#39;nvim-telescope/telescope-fzf-native.nvim&#39;, build = &#39;cmake -S. -Bbuild -DCMAKE_BUILD_TYPE=Release &amp;amp;&amp;amp; cmake --build build --config Release &amp;amp;&amp;amp; cmake --install build --prefix build&#39; }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Windows with gcc/make using chocolatey&lt;/summary&gt; Alternatively, one can install gcc and make which don&#39;t require changing the config, the easiest way is to use choco: &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;install &lt;a href=&#34;https://chocolatey.org/install&#34;&gt;chocolatey&lt;/a&gt; either follow the instructions on the page or use winget, run in cmd as &lt;strong&gt;admin&lt;/strong&gt;:&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code&gt;winget install --accept-source-agreements chocolatey.chocolatey&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ol start=&#34;2&#34;&gt; &#xA;  &lt;li&gt;install all requirements using choco, exit previous cmd and open a new one so that choco path is set, and run in cmd as &lt;strong&gt;admin&lt;/strong&gt;:&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code&gt;choco install -y neovim git ripgrep wget fd unzip gzip mingw make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;WSL (Windows Subsystem for Linux)&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;wsl --install&#xA;wsl&#xA;sudo add-apt-repository ppa:neovim-ppa/unstable -y&#xA;sudo apt update&#xA;sudo apt install make gcc ripgrep unzip neovim&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h4&gt;Linux Install&lt;/h4&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Ubuntu Install Steps&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo add-apt-repository ppa:neovim-ppa/unstable -y&#xA;sudo apt update&#xA;sudo apt install make gcc ripgrep unzip neovim&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Debian Install Steps&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt update&#xA;sudo apt install make gcc ripgrep unzip git&#xA;echo &#34;deb https://deb.debian.org/debian unstable main&#34; | sudo tee -a /etc/apt/sources.list&#xA;sudo apt update&#xA;sudo apt install -t unstable neovim&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Fedora Install Steps&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo dnf install -y gcc make git ripgrep fd-find neovim&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt;</summary>
  </entry>
  <entry>
    <title>roboflow/supervision</title>
    <updated>2024-04-01T01:59:38Z</updated>
    <id>tag:github.com,2024-04-01:/roboflow/supervision</id>
    <link href="https://github.com/roboflow/supervision" rel="alternate"></link>
    <summary type="html">&lt;p&gt;We write your reusable computer vision tools. 💜&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; &lt;a align=&#34;center&#34; href=&#34;&#34; target=&#34;https://supervision.roboflow.com&#34;&gt; &lt;img width=&#34;100%&#34; src=&#34;https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/roboflow/notebooks&#34;&gt;notebooks&lt;/a&gt; | &lt;a href=&#34;https://github.com/roboflow/inference&#34;&gt;inference&lt;/a&gt; | &lt;a href=&#34;https://github.com/autodistill/autodistill&#34;&gt;autodistill&lt;/a&gt; | &lt;a href=&#34;https://github.com/roboflow/multimodal-maestro&#34;&gt;maestro&lt;/a&gt;&lt;/p&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://badge.fury.io/py/supervision&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/supervision.svg?sanitize=true&#34; alt=&#34;version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypistats.org/packages/supervision&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/supervision&#34; alt=&#34;downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/roboflow/supervision/raw/main/LICENSE.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/l/supervision&#34; alt=&#34;license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://badge.fury.io/py/supervision&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/supervision&#34; alt=&#34;python-version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/Roboflow/Annotators&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;gradio&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/GbfgXGJ8Bk&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1159501506232451173&#34; alt=&#34;discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://squidfunk.github.io/mkdocs-material/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white&#34; alt=&#34;built-with-material-for-mkdocs&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;👋 hello&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! 🤝&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/orgs/roboflow/projects/10&#34;&gt;&lt;img src=&#34;https://github.com/roboflow/supervision/assets/26109316/c05cc954-b9a6-4ed5-9a52-d0b4b619ff65&#34; alt=&#34;supervision-hackfest&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;💻 install&lt;/h2&gt; &#xA;&lt;p&gt;Pip install the supervision package in a &lt;a href=&#34;https://www.python.org/&#34;&gt;&lt;strong&gt;Python&amp;gt;=3.8&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install supervision&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href=&#34;https://roboflow.github.io/supervision/&#34;&gt;guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;🔥 quickstart&lt;/h2&gt; &#xA;&lt;h3&gt;models&lt;/h3&gt; &#xA;&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href=&#34;https://supervision.roboflow.com/latest/detection/core/#detections&#34;&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cv2&#xA;import supervision as sv&#xA;from ultralytics import YOLO&#xA;&#xA;image = cv2.imread(...)&#xA;model = YOLO(&#39;yolov8s.pt&#39;)&#xA;result = model(image)[0]&#xA;detections = sv.Detections.from_ultralytics(result)&#xA;&#xA;len(detections)&#xA;# 5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;👉 more model connectors&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href=&#34;https://github.com/roboflow/inference&#34;&gt;Inference&lt;/a&gt; requires a &lt;a href=&#34;https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key&#34;&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cv2&#xA;import supervision as sv&#xA;from inference.models.utils import get_roboflow_model&#xA;&#xA;image = cv2.imread(...)&#xA;model = get_roboflow_model(model_id=&#34;yolov8s-640&#34;, api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)&#xA;result = model.infer(image)[0]&#xA;detections = sv.Detections.from_inference(result)&#xA;&#xA;len(detections)&#xA;#&amp;nbsp;5&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;annotators&lt;/h3&gt; &#xA;&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href=&#34;https://supervision.roboflow.com/latest/annotators/&#34;&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cv2&#xA;import supervision as sv&#xA;&#xA;image = cv2.imread(...)&#xA;detections = sv.Detections(...)&#xA;&#xA;bounding_box_annotator = sv.BoundingBoxAnnotator()&#xA;annotated_frame = bounding_box_annotator.annotate(&#xA;    scene=image.copy(),&#xA;    detections=detections&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&#34;&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;datasets&lt;/h3&gt; &#xA;&lt;p&gt;Supervision provides a set of &lt;a href=&#34;https://supervision.roboflow.com/latest/datasets/&#34;&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import supervision as sv&#xA;&#xA;dataset = sv.DetectionDataset.from_yolo(&#xA;    images_directory_path=...,&#xA;    annotations_directory_path=...,&#xA;    data_yaml_path=...&#xA;)&#xA;&#xA;dataset.classes&#xA;[&#39;dog&#39;, &#39;person&#39;]&#xA;&#xA;len(dataset)&#xA;#&amp;nbsp;1000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details close&gt; &#xA; &lt;summary&gt;👉 more dataset utils&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dataset = sv.DetectionDataset.from_yolo(&#xA;    images_directory_path=...,&#xA;    annotations_directory_path=...,&#xA;    data_yaml_path=...&#xA;)&#xA;&#xA;dataset = sv.DetectionDataset.from_pascal_voc(&#xA;    images_directory_path=...,&#xA;    annotations_directory_path=...&#xA;)&#xA;&#xA;dataset = sv.DetectionDataset.from_coco(&#xA;    images_directory_path=...,&#xA;    annotations_path=...&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)&#xA;test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)&#xA;&#xA;len(train_dataset), len(test_dataset), len(valid_dataset)&#xA;#&amp;nbsp;(700, 150, 150)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ds_1 = sv.DetectionDataset(...)&#xA;len(ds_1)&#xA;#&amp;nbsp;100&#xA;ds_1.classes&#xA;#&amp;nbsp;[&#39;dog&#39;, &#39;person&#39;]&#xA;&#xA;ds_2 = sv.DetectionDataset(...)&#xA;len(ds_2)&#xA;# 200&#xA;ds_2.classes&#xA;#&amp;nbsp;[&#39;cat&#39;]&#xA;&#xA;ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])&#xA;len(ds_merged)&#xA;#&amp;nbsp;300&#xA;ds_merged.classes&#xA;#&amp;nbsp;[&#39;cat&#39;, &#39;dog&#39;, &#39;person&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dataset.as_yolo(&#xA;    images_directory_path=...,&#xA;    annotations_directory_path=...,&#xA;    data_yaml_path=...&#xA;)&#xA;&#xA;dataset.as_pascal_voc(&#xA;    images_directory_path=...,&#xA;    annotations_directory_path=...&#xA;)&#xA;&#xA;dataset.as_coco(&#xA;    images_directory_path=...,&#xA;    annotations_path=...&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sv.DetectionDataset.from_yolo(&#xA;    images_directory_path=...,&#xA;    annotations_directory_path=...,&#xA;    data_yaml_path=...&#xA;).as_pascal_voc(&#xA;    images_directory_path=...,&#xA;    annotations_directory_path=...&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;🎬 tutorials&lt;/h2&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://youtu.be/uWP6UjDeZvY&#34; title=&#34;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&#34;&gt;&lt;img src=&#34;https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91&#34; alt=&#34;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&#34; width=&#34;300px&#34; align=&#34;left&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/uWP6UjDeZvY&#34; title=&#34;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&#34;&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;&#xA;&lt;div&gt;&#xA; &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt; | &#xA; &lt;strong&gt;Updated: 11 Jan 2024&lt;/strong&gt;&#xA;&lt;/div&gt; &#xA;&lt;br&gt; Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.&#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://youtu.be/4Q3ut7vqD5o&#34; title=&#34;Traffic Analysis with YOLOv8 and ByteTrack - Vehicle Detection and Tracking&#34;&gt;&lt;img src=&#34;https://github.com/roboflow/supervision/assets/26109316/54afdf1c-218c-4451-8f12-627fb85f1682&#34; alt=&#34;Traffic Analysis with YOLOv8 and ByteTrack - Vehicle Detection and Tracking&#34; width=&#34;300px&#34; align=&#34;left&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/4Q3ut7vqD5o&#34; title=&#34;Traffic Analysis with YOLOv8 and ByteTrack - Vehicle Detection and Tracking&#34;&gt;&lt;strong&gt;Traffic Analysis with YOLOv8 and ByteTrack - Vehicle Detection and Tracking&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;&#xA;&lt;div&gt;&#xA; &lt;strong&gt;Created: 6 Sep 2023&lt;/strong&gt; | &#xA; &lt;strong&gt;Updated: 6 Sep 2023&lt;/strong&gt;&#xA;&lt;/div&gt; &#xA;&lt;br&gt; In this video, we explore real-time traffic analysis using YOLOv8 and ByteTrack to detect and track vehicles on aerial images. Harnessing the power of Python and Supervision, we delve deep into assigning cars to specific entry zones and understanding their direction of movement. By visualizing their paths, we gain insights into traffic flow across bustling roundabouts... &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h2&gt;💜 built with supervision&lt;/h2&gt; &#xA;&lt;p&gt;Did you build something cool using supervision? &lt;a href=&#34;https://github.com/roboflow/supervision/discussions/categories/built-with-supervision&#34;&gt;Let us know!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&#34;&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&#34;&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&#34;&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📚 documentation&lt;/h2&gt; &#xA;&lt;p&gt;Visit our &lt;a href=&#34;https://roboflow.github.io/supervision&#34;&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; &#xA;&lt;h2&gt;🏆 contribution&lt;/h2&gt; &#xA;&lt;p&gt;We love your input! Please see our &lt;a href=&#34;https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; to get started. Thank you 🙏 to all our contributors!&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/roboflow/supervision/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=roboflow/supervision&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;a href=&#34;https://youtube.com/roboflow&#34;&gt; &lt;img src=&#34;https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652&#34; width=&#34;3%&#34;&gt; &lt;/a&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&#34; width=&#34;3%&#34;&gt; &#xA;  &lt;a href=&#34;https://roboflow.com&#34;&gt; &lt;img src=&#34;https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649&#34; width=&#34;3%&#34;&gt; &lt;/a&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&#34; width=&#34;3%&#34;&gt; &#xA;  &lt;a href=&#34;https://www.linkedin.com/company/roboflow-ai/&#34;&gt; &lt;img src=&#34;https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691&#34; width=&#34;3%&#34;&gt; &lt;/a&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&#34; width=&#34;3%&#34;&gt; &#xA;  &lt;a href=&#34;https://docs.roboflow.com&#34;&gt; &lt;img src=&#34;https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511&#34; width=&#34;3%&#34;&gt; &lt;/a&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&#34; width=&#34;3%&#34;&gt; &#xA;  &lt;a href=&#34;https://disuss.roboflow.com&#34;&gt; &lt;img src=&#34;https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584&#34; width=&#34;3%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&#34; width=&#34;3%&#34;&gt; &lt;/a&gt;&#xA;  &lt;a href=&#34;https://blog.roboflow.com&#34;&gt; &lt;img src=&#34;https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605&#34; width=&#34;3%&#34;&gt; &lt;/a&gt;  &#xA; &lt;/div&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
</feed>