<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-01T01:43:44Z</updated>
  <subtitle>Monthly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>yeongpin/cursor-free-vip</title>
    <updated>2025-05-01T01:43:44Z</updated>
    <id>tag:github.com,2025-05-01:/yeongpin/cursor-free-vip</id>
    <link href="https://github.com/yeongpin/cursor-free-vip" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[Support 0.49.x]（Reset Cursor AI MachineID &amp; Bypass Higher Token Limit） Cursor Ai ，自动重置机器ID ， 免费升级使用Pro功能: You&#39;ve reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;➤ Cursor Free VIP&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/logo.png&#34; alt=&#34;Cursor Pro Logo&#34; width=&#34;200&#34; style=&#34;border-radius: 6px;&#34;&gt; &lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/yeongpin/cursor-free-vip/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/release/yeongpin/cursor-free-vip&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg?sanitize=true&#34; alt=&#34;License: CC BY-NC-ND 4.0&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/yeongpin/cursor-free-vip/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/stars/yeongpin/cursor-free-vip&#34; alt=&#34;Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/yeongpin/cursor-free-vip/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/yeongpin/cursor-free-vip/total&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://buymeacoffee.com/yeongpin&#34; target=&#34;_blank&#34;&gt;&lt;img alt=&#34;Buy Me a Coffee&#34; src=&#34;https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://deepwiki.com/yeongpin/cursor-free-vip&#34;&gt;&lt;img src=&#34;https://devin.ai/assets/deepwiki-badge.png&#34; alt=&#34;Ask DeepWiki.com&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://trendshift.io/repositories/13425&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/13425&#34; alt=&#34;yeongpin%2Fcursor-free-vip | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://www.buymeacoffee.com/yeongpin&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.buymeacoffee.com/button-api/?text=buy%20me%20a%20coffee&amp;amp;emoji=%E2%98%95&amp;amp;slug=yeongpin&amp;amp;button_colour=ffda33&amp;amp;font_colour=000000&amp;amp;font_family=Bree&amp;amp;outline_colour=000000&amp;amp;coffee_colour=FFDD00&amp;amp;latest=2&#34; width=&#34;160&#34; height=&#34;55&#34; alt=&#34;Buy Me a Coffee&#34;&gt; &lt;/a&gt;&lt;/p&gt; &#xA; &lt;h4&gt;Support Latest 0.49.x Version | 支持最新 0.49.x 版本&lt;/h4&gt; &#xA; &lt;p&gt;This tool is for educational purposes, currently the repo does not violate any laws. Please support the original project. This tool will not generate any fake email accounts and OAuth access.&lt;/p&gt; &#xA; &lt;p&gt;Supports Windows, macOS and Linux.&lt;/p&gt; &#xA; &lt;p&gt;For optimal performance, run with privileges and always stay up to date.&lt;/p&gt; &#xA; &lt;p&gt;這是一款用於學習和研究的工具，目前 repo 沒有違反任何法律。請支持原作者。 這款工具不會生成任何假的電子郵件帳戶和 OAuth 訪問。&lt;/p&gt; &#xA; &lt;p&gt;支持 Windows、macOS 和 Linux。&lt;/p&gt; &#xA; &lt;p&gt;對於最佳性能，請以管理員身份運行並始終保持最新。&lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/product_2025-04-16_10-40-21.png&#34; alt=&#34;new&#34; width=&#34;800&#34; style=&#34;border-radius: 6px;&#34;&gt;&lt;br&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🔄 Change Log | 更新日志&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/CHANGELOG.md&#34;&gt;Watch Change Log | 查看更新日志&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;✨ Features | 功能特點&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Support Windows macOS and Linux systems&lt;br&gt;支持 Windows、macOS 和 Linux 系統&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Reset Cursor&#39;s configuration&lt;br&gt;重置 Cursor 的配置&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Multi-language support (English, 简体中文, 繁體中文, Vietnamese)&lt;br&gt;多語言支持（英文、简体中文、繁體中文、越南語）&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;💻 System Support | 系統支持&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Operating System&lt;/th&gt; &#xA;   &lt;th&gt;Architecture&lt;/th&gt; &#xA;   &lt;th&gt;Supported&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Windows&lt;/td&gt; &#xA;   &lt;td&gt;x64, x86&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;macOS&lt;/td&gt; &#xA;   &lt;td&gt;Intel, Apple Silicon&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Linux&lt;/td&gt; &#xA;   &lt;td&gt;x64, x86, ARM64&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;👀 How to use | 如何使用&lt;/h2&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;b&gt;⭐ Auto Run Script | 腳本自動化運行&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;h3&gt;&lt;strong&gt;Linux/macOS&lt;/strong&gt;&lt;/h3&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.sh -o install.sh &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h3&gt;&lt;strong&gt;Archlinux&lt;/strong&gt;&lt;/h3&gt; &#xA; &lt;p&gt;Install via &lt;a href=&#34;https://aur.archlinux.org/packages/cursor-free-vip-git&#34;&gt;AUR&lt;/a&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yay -S cursor-free-vip-git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h3&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/h3&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;If you want to stop the script, please press Ctrl+C&lt;br&gt;要停止腳本，請按 Ctrl+C&lt;/p&gt; &#xA;&lt;h2&gt;❗ Note | 注意事項&lt;/h2&gt; &#xA;&lt;p&gt;📝 Config | 文件配置 &lt;code&gt;Win / Macos / Linux Path | 路徑 [Documents/.cursor-free-vip/config.ini]&lt;/code&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;⭐ Config | 文件配置&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;[Chrome]&#xA;# Default Google Chrome Path | 默認Google Chrome 遊覽器路徑&#xA;chromepath = C:\Program Files\Google/Chrome/Application/chrome.exe&#xA;&#xA;[Turnstile]&#xA;# Handle Turnstile Wait Time | 等待人機驗證時間&#xA;handle_turnstile_time = 2&#xA;# Handle Turnstile Wait Random Time (must merge 1-3 or 1,3) | 等待人機驗證隨機時間（必須是 1-3 或者 1,3 這樣的組合）&#xA;handle_turnstile_random_time = 1-3&#xA;&#xA;[OSPaths]&#xA;# Storage Path | 存儲路徑&#xA;storage_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/storage.json&#xA;# SQLite Path | SQLite路徑&#xA;sqlite_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/state.vscdb&#xA;# Machine ID Path | 機器ID路徑&#xA;machine_id_path = /Users/username/Library/Application Support/Cursor/machineId&#xA;# For Linux users: ~/.config/cursor/machineid&#xA;&#xA;[Timing]&#xA;# Min Random Time | 最小隨機時間&#xA;min_random_time = 0.1&#xA;# Max Random Time | 最大隨機時間&#xA;max_random_time = 0.8&#xA;# Page Load Wait | 頁面加載等待時間&#xA;page_load_wait = 0.1-0.8&#xA;# Input Wait | 輸入等待時間&#xA;input_wait = 0.3-0.8&#xA;# Submit Wait | 提交等待時間&#xA;submit_wait = 0.5-1.5&#xA;# Verification Code Input | 驗證碼輸入等待時間&#xA;verification_code_input = 0.1-0.3&#xA;# Verification Success Wait | 驗證成功等待時間&#xA;verification_success_wait = 2-3&#xA;# Verification Retry Wait | 驗證重試等待時間&#xA;verification_retry_wait = 2-3&#xA;# Email Check Initial Wait | 郵件檢查初始等待時間&#xA;email_check_initial_wait = 4-6&#xA;# Email Refresh Wait | 郵件刷新等待時間&#xA;email_refresh_wait = 2-4&#xA;# Settings Page Load Wait | 設置頁面加載等待時間&#xA;settings_page_load_wait = 1-2&#xA;# Failed Retry Time | 失敗重試時間&#xA;failed_retry_time = 0.5-1&#xA;# Retry Interval | 重試間隔&#xA;retry_interval = 8-12&#xA;# Max Timeout | 最大超時時間&#xA;max_timeout = 160&#xA;&#xA;[Utils]&#xA;# Check Update | 檢查更新&#xA;check_update = True&#xA;# Show Account Info | 顯示賬號信息&#xA;show_account_info = True&#xA;&#xA;[WindowsPaths]&#xA;storage_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\storage.json&#xA;sqlite_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\state.vscdb&#xA;machine_id_path = C:\Users\yeongpin\AppData\Roaming\Cursor\machineId&#xA;cursor_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app&#xA;updater_path = C:\Users\yeongpin\AppData\Local\cursor-updater&#xA;update_yml_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app-update.yml&#xA;product_json_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app\product.json&#xA;&#xA;[Browser]&#xA;default_browser = opera&#xA;chrome_path = C:\Program Files\Google\Chrome\Application\chrome.exe&#xA;edge_path = C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe&#xA;firefox_path = C:\Program Files\Mozilla Firefox\firefox.exe&#xA;brave_path = C:\Program Files\BraveSoftware/Brave-Browser/Application/brave.exe&#xA;chrome_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe&#xA;edge_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\msedgedriver.exe&#xA;firefox_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\geckodriver.exe&#xA;brave_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe&#xA;opera_path = C:\Users\yeongpin\AppData\Local\Programs\Opera\opera.exe&#xA;opera_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe&#xA;&#xA;[OAuth]&#xA;show_selection_alert = False&#xA;timeout = 120&#xA;max_attempts = 3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Use administrator privileges to run the script &lt;br&gt;請使用管理員身份運行腳本&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Confirm that Cursor is closed before running the script &lt;br&gt;請確保在運行腳本前已經關閉 Cursor&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;This tool is only for learning and research purposes &lt;br&gt;此工具僅供學習和研究使用&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Please comply with the relevant software usage terms when using this tool &lt;br&gt;使用本工具時請遵守相關軟件使用條款&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🚨 Common Issues | 常見問題&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;如果遇到權限問題，請確保：&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;此腳本以管理員身份運行&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;If you encounter permission issues, please ensure:&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;This script is run with administrator privileges&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Error &#39;User is not authorized&#39;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;This means your account was banned for using temporary (disposal) mail. Ensure using a non-temporary mail service&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;🤩 Contribution | 貢獻&lt;/h2&gt; &#xA;&lt;p&gt;歡迎提交 Issue 和 Pull Request！&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/yeongpin/cursor-free-vip/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=yeongpin/cursor-free-vip&amp;amp;preview=true&amp;amp;max=&amp;amp;columns=&#34;&gt; &lt;/a&gt; &#xA;&lt;br&gt;&#xA;&lt;br&gt; &#xA;&lt;h2&gt;📩 Disclaimer | 免責聲明&lt;/h2&gt; &#xA;&lt;p&gt;本工具僅供學習和研究使用，使用本工具所產生的任何後果由使用者自行承擔。 &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;This tool is only for learning and research purposes, and any consequences arising from the use of this tool are borne by the user.&lt;/p&gt; &#xA;&lt;h2&gt;💰 Buy Me a Coffee | 請我喝杯咖啡&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr&gt; &#xA;    &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/provi-code.jpg&#34; alt=&#34;buy_me_a_coffee&#34; width=&#34;280&#34;&gt;&lt;br&gt; &lt;/td&gt; &#xA;    &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/paypal.png&#34; alt=&#34;buy_me_a_coffee&#34; width=&#34;280&#34;&gt;&lt;br&gt; &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;⭐ Star History | 星星數&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://star-history.com/#yeongpin/cursor-free-vip&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=yeongpin/cursor-free-vip&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;📝 License | 授權&lt;/h2&gt; &#xA;&lt;p&gt;本項目採用 &lt;a href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt; 授權。 Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/LICENSE.md&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>GoogleCloudPlatform/agent-starter-pack</title>
    <updated>2025-05-01T01:43:44Z</updated>
    <id>tag:github.com,2025-05-01:/GoogleCloudPlatform/agent-starter-pack</id>
    <link href="https://github.com/GoogleCloudPlatform/agent-starter-pack" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A collection of production-ready Generative AI Agent templates built for Google Cloud. It accelerates development by providing a holistic, production-ready solution, addressing common challenges (Deployment &amp; Operations, Evaluation, Customization, Observability) in building and deploying GenAI agents.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🚀 Agent Starter Pack&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/agent-starter-pack?color=blue&#34; alt=&#34;Version&#34;&gt; &lt;a href=&#34;https://youtu.be/jHt-ZVD660g&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/1--Minute%20Overview-gray&#34; alt=&#34;1-Minute Video Overview&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/README.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-gray&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://studio.firebase.google.com/new?template=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fagent-starter-pack%2Ftree%2Fmain%2Fsrc%2Fresources%2Fidx&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://cdn.firebasestudio.dev/btn/try_light_20.svg&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://cdn.firebasestudio.dev/btn/try_dark_20.svg&#34;&gt; &#xA;   &lt;img height=&#34;20&#34; alt=&#34;Try in Firebase Studio&#34; src=&#34;https://cdn.firebasestudio.dev/btn/try_blue_20.svg?sanitize=true&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/stars/GoogleCloudPlatform/agent-starter-pack?color=yellow&#34; alt=&#34;Stars&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;agent-starter-pack&lt;/code&gt; is a collection of production-ready Generative AI Agent templates built for Google Cloud. &lt;br&gt; It accelerates development by providing a holistic, production-ready solution, addressing common challenges (Deployment &amp;amp; Operations, Evaluation, Customization, Observability) in building and deploying GenAI agents.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;⚡️ Launch&lt;/th&gt; &#xA;   &lt;th&gt;🧪 Experiment&lt;/th&gt; &#xA;   &lt;th&gt;✅ Deploy&lt;/th&gt; &#xA;   &lt;th&gt;🛠️ Customize&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/agents/&#34;&gt;Pre-built agent templates&lt;/a&gt; (ReAct, RAG, multi-agent, Live Multimodal API).&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview&#34;&gt;Vertex AI evaluation&lt;/a&gt; and an interactive playground.&lt;/td&gt; &#xA;   &lt;td&gt;Production-ready infra with &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/observability.md&#34;&gt;monitoring, observability&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/deployment.md&#34;&gt;CI/CD&lt;/a&gt; on &lt;a href=&#34;https://cloud.google.com/run&#34;&gt;Cloud Run&lt;/a&gt; or &lt;a href=&#34;https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview&#34;&gt;Agent Engine&lt;/a&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;Extend and customize templates according to your needs.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;⚡ Get Started in 1 Minute&lt;/h2&gt; &#xA;&lt;p&gt;Ready to build your AI agent? Simply run this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Create and activate a Python virtual environment&#xA;python -m venv venv &amp;amp;&amp;amp; source venv/bin/activate&#xA;&#xA;# Install the agent starter pack&#xA;pip install agent-starter-pack&#xA;&#xA;# Create a new agent project&#xA;agent-starter-pack create my-awesome-agent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;That&#39;s it!&lt;/strong&gt; You now have a fully functional agent project—complete with backend, frontend, and deployment infrastructure—ready for you to explore and customize. For more installation options, see the &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/installation.md&#34;&gt;Installation Guide&lt;/a&gt;. You can also &lt;a href=&#34;https://studio.firebase.google.com/new?template=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fagent-starter-pack%2Ftree%2Fmain%2Fsrc%2Fresources%2Fidx&#34;&gt;try it in Firebase Studio&lt;/a&gt; with zero setup.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;🆕 The starter pack offers full support for Agent Engine, a new fully managed solution to deploy agents. Simply run this command to get started:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;agent-starter-pack create my-agent -d agent_engine -a adk_base&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/cli/create.md&#34;&gt;full list of options&lt;/a&gt; for details.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🤖 Agents&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Agent Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;adk_base&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A base ReAct agent implemented using Google&#39;s &lt;a href=&#34;https://github.com/google/adk-python&#34;&gt;Agent Development Kit&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;agentic_rag&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A RAG agent for document retrieval and Q&amp;amp;A. Supporting &lt;a href=&#34;https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction&#34;&gt;Vertex AI Search&lt;/a&gt; and &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/vector-search/overview&#34;&gt;Vector Search&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;langgraph_base_react&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;An agent implementing a base ReAct agent using LangGraph&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;crewai_coding_crew&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A multi-agent system implemented with CrewAI created to support coding activities&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;live_api&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A real-time multimodal RAG agent powered by Gemini, supporting audio/video/text chat with vector DB-backed responses&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;More agents are on the way!&lt;/strong&gt; We are continuously expanding our &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/agents/&#34;&gt;agent library&lt;/a&gt;. Have a specific agent type in mind? &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/#contributing&#34;&gt;Contribute!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;🔍 ADK Samples&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Looking to explore more ADK examples? Check out the &lt;a href=&#34;https://github.com/google/adk-samples&#34;&gt;ADK Samples Repository&lt;/a&gt; for additional examples and use cases demonstrating ADK&#39;s capabilities.&lt;/p&gt; &#xA;&lt;h4&gt;Extra Features&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;agent-starter-pack&lt;/code&gt; offers two key features to accelerate and simplify the development of your agent:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;🔄 &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/cli/setup_cicd.md&#34;&gt;CI/CD Automation (Experimental)&lt;/a&gt;&lt;/strong&gt; - One command to set up a complete GitHub + Cloud Build pipeline for all environments&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;📥 &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/data-ingestion.md&#34;&gt;Data Pipeline for RAG with Terraform/CI-CD&lt;/a&gt;&lt;/strong&gt; - Seamlessly integrate a data pipeline to process embeddings for RAG into your agent system. Supporting &lt;a href=&#34;https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction&#34;&gt;Vertex AI Search&lt;/a&gt; and &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/vector-search/overview&#34;&gt;Vector Search&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;High-Level Architecture&lt;/h2&gt; &#xA;&lt;p&gt;This starter pack covers all aspects of Agent development, from prototyping and evaluation to deployment and monitoring.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/images/ags_high_level_architecture.png&#34; alt=&#34;High Level Architecture&#34; title=&#34;Architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;🔧 Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.10+&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cloud.google.com/sdk/docs/install&#34;&gt;Google Cloud SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.hashicorp.com/terraform/downloads&#34;&gt;Terraform&lt;/a&gt; (for deployment)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;📚 Documentation&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/&#34;&gt;documentation&lt;/a&gt; for more details:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/why_starter_pack.md&#34;&gt;Why Use the Starter Pack?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/installation.md&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/deployment.md&#34;&gt;Deployment&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/data-ingestion.md&#34;&gt;Data Ingestion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/observability.md&#34;&gt;Observability&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/cli/README.md&#34;&gt;CLI Reference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/troubleshooting.md&#34;&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Video Walkthrough:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;March 6, 2025&lt;/strong&gt;: A &lt;a href=&#34;https://www.youtube.com/watch?v=yIRIT_EtALs&amp;amp;t=235s&#34;&gt;120 Minute livestream video demo&lt;/a&gt; of the new &lt;code&gt;agent-starter-pack&lt;/code&gt; were we build 3 Agents under 30 minutes!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Oct 29, 2024&lt;/strong&gt;: A &lt;a href=&#34;https://youtu.be/kwRG7cnqSu0&#34;&gt;20-Minute Video Walkthrough&lt;/a&gt; is available, showcasing the previous &lt;code&gt;agent-starter-pack&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Explore More Generative AI Resources&lt;/h2&gt; &#xA;&lt;p&gt;Looking for more examples and resources for Generative AI on Google Cloud? Check out the &lt;a href=&#34;https://github.com/GoogleCloudPlatform/generative-ai&#34;&gt;GoogleCloudPlatform/generative-ai&lt;/a&gt; repository for notebooks, code samples, and more!&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome! See the &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/CONTRIBUTING.md&#34;&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Feedback&lt;/h2&gt; &#xA;&lt;p&gt;We value your input! Your feedback helps us improve this starter pack and make it more useful for the community.&lt;/p&gt; &#xA;&lt;h3&gt;Getting Help&lt;/h3&gt; &#xA;&lt;p&gt;If you encounter any issues or have specific suggestions, please first consider &lt;a href=&#34;https://github.com/GoogleCloudPlatform/generative-ai/issues&#34;&gt;raising an issue&lt;/a&gt; on our GitHub repository.&lt;/p&gt; &#xA;&lt;h3&gt;Share Your Experience&lt;/h3&gt; &#xA;&lt;p&gt;For other types of feedback, or if you&#39;d like to share a positive experience or success story using this starter pack, we&#39;d love to hear from you! You can reach out to us at &lt;a href=&#34;mailto:agent-starter-pack@google.com&#34;&gt;&lt;/a&gt;&lt;a href=&#34;mailto:agent-starter-pack@google.com&#34;&gt;agent-starter-pack@google.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Thank you for your contributions!&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This repository is for demonstrative purposes only and is not an officially supported Google product.&lt;/p&gt; &#xA;&lt;h2&gt;Terms of Service&lt;/h2&gt; &#xA;&lt;p&gt;The agent-starter-pack templating CLI and the templates in this starter pack leverage Google Cloud APIs. When you use this starter pack, you&#39;ll be deploying resources in your own Google Cloud project and will be responsible for those resources. Please review the &lt;a href=&#34;https://cloud.google.com/terms/service-terms&#34;&gt;Google Cloud Service Terms&lt;/a&gt; for details on the terms of service associated with these APIs.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>simular-ai/Agent-S</title>
    <updated>2025-05-01T01:43:44Z</updated>
    <id>tag:github.com,2025-05-01:/simular-ai/Agent-S</id>
    <link href="https://github.com/simular-ai/Agent-S" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Agent S: an open agentic framework that uses computers like a human&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/images/agent_s.png&#34; alt=&#34;Logo&#34; style=&#34;vertical-align:middle&#34; width=&#34;60&#34;&gt; Agent S2: &lt;small&gt;A Compositional Generalist-Specialist Framework for Computer Use Agents&lt;/small&gt; &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&amp;nbsp; 🌐 &lt;a href=&#34;https://www.simular.ai/articles/agent-s2-technical-review&#34;&gt;[S2 blog]&lt;/a&gt;&amp;nbsp; 📄 &lt;a href=&#34;https://arxiv.org/abs/2504.00906&#34;&gt;[S2 Paper]&lt;/a&gt;&amp;nbsp; 🎥 &lt;a href=&#34;https://www.youtube.com/watch?v=wUGVQl7c0eg&#34;&gt;[S2 Video]&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&amp;nbsp; 🌐 &lt;a href=&#34;https://www.simular.ai/agent-s&#34;&gt;[S1 blog]&lt;/a&gt;&amp;nbsp; 📄 &lt;a href=&#34;https://arxiv.org/abs/2410.08164&#34;&gt;[S1 Paper (ICLR 2025)]&lt;/a&gt;&amp;nbsp; 🎥 &lt;a href=&#34;https://www.youtube.com/watch?v=OBDE3Knte0g&#34;&gt;[S1 Video]&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&amp;nbsp; &lt;a href=&#34;https://trendshift.io/repositories/13151&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/13151&#34; alt=&#34;simular-ai%2FAgent-S | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/E2XfsK9fPV&#34;&gt; &lt;img src=&#34;https://dcbadge.limes.pink/api/server/https://discord.gg/E2XfsK9fPV?style=flat&#34; alt=&#34;Discord&#34;&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://pepy.tech/projects/gui-agents&#34;&gt; &lt;img src=&#34;https://static.pepy.tech/badge/gui-agents&#34; alt=&#34;PyPI Downloads&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;🥳 Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;2025/04/01&lt;/strong&gt;: Released &lt;a href=&#34;https://arxiv.org/abs/2504.00906&#34;&gt;Agent S2 paper&lt;/a&gt; with new SOTA results on OSWorld, WindowsAgentArena, and AndroidWorld!&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;2025/03/12&lt;/strong&gt;: Released Agent S2 along with v0.2.0 of &lt;a href=&#34;https://github.com/simular-ai/Agent-S&#34;&gt;gui-agents&lt;/a&gt;, the new state-of-the-art for computer use agents (CUA), outperforming OpenAI&#39;s CUA/Operator and Anthropic&#39;s Claude 3.7 Sonnet Computer-Use!&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;2025/01/22&lt;/strong&gt;: The &lt;a href=&#34;https://arxiv.org/abs/2410.08164&#34;&gt;Agent S paper&lt;/a&gt; is accepted to ICLR 2025!&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;2025/01/21&lt;/strong&gt;: Released v0.1.2 of &lt;a href=&#34;https://github.com/simular-ai/Agent-S&#34;&gt;gui-agents&lt;/a&gt; library, with support for Linux and Windows!&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;2024/12/05&lt;/strong&gt;: Released v0.1.0 of &lt;a href=&#34;https://github.com/simular-ai/Agent-S&#34;&gt;gui-agents&lt;/a&gt; library, allowing you to use Agent-S for Mac, OSWorld, and WindowsAgentArena with ease!&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;2024/10/10&lt;/strong&gt;: Released the &lt;a href=&#34;https://arxiv.org/abs/2410.08164&#34;&gt;Agent S paper&lt;/a&gt; and codebase!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/#-introduction&#34;&gt;💡 Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/#-current-results&#34;&gt;🎯 Current Results&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/#%EF%B8%8F-installation--setup&#34;&gt;🛠️ Installation &amp;amp; Setup&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/#-usage&#34;&gt;🚀 Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/#-acknowledgements&#34;&gt;🤝 Acknowledgements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/#-citation&#34;&gt;💬 Citation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;💡 Introduction&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/images/agent_s2_teaser.png&#34; width=&#34;800&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Welcome to &lt;strong&gt;Agent S&lt;/strong&gt;, an open-source framework designed to enable autonomous interaction with computers through Agent-Computer Interface. Our mission is to build intelligent GUI agents that can learn from past experiences and perform complex tasks autonomously on your computer.&lt;/p&gt; &#xA;&lt;p&gt;Whether you&#39;re interested in AI, automation, or contributing to cutting-edge agent-based systems, we&#39;re excited to have you here!&lt;/p&gt; &#xA;&lt;h2&gt;🎯 Current Results&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/images/agent_s2_osworld_result.png&#34; width=&#34;600&#34;&gt; &lt;br&gt; Results of Agent S2&#39;s Successful Rate (%) on the OSWorld full test set using Screenshot input only. &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table border=&#34;0&#34; cellspacing=&#34;0&#34; cellpadding=&#34;5&#34;&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Benchmark&lt;/th&gt; &#xA;    &lt;th&gt;Agent S2&lt;/th&gt; &#xA;    &lt;th&gt;Previous SOTA&lt;/th&gt; &#xA;    &lt;th&gt;Δ improve&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;OSWorld (15 step)&lt;/td&gt; &#xA;    &lt;td&gt;27.0%&lt;/td&gt; &#xA;    &lt;td&gt;22.7% (UI-TARS)&lt;/td&gt; &#xA;    &lt;td&gt;+4.3%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;OSWorld (50 step)&lt;/td&gt; &#xA;    &lt;td&gt;34.5%&lt;/td&gt; &#xA;    &lt;td&gt;32.6% (OpenAI CUA)&lt;/td&gt; &#xA;    &lt;td&gt;+1.9%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;WindowsAgentArena&lt;/td&gt; &#xA;    &lt;td&gt;29.8%&lt;/td&gt; &#xA;    &lt;td&gt;19.5% (NAVI)&lt;/td&gt; &#xA;    &lt;td&gt;+10.3%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;AndroidWorld&lt;/td&gt; &#xA;    &lt;td&gt;54.3%&lt;/td&gt; &#xA;    &lt;td&gt;46.8% (UI-TARS)&lt;/td&gt; &#xA;    &lt;td&gt;+7.5%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🛠️ Installation &amp;amp; Setup&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;❗&lt;strong&gt;Warning&lt;/strong&gt;❗: If you are on a Linux machine, creating a &lt;code&gt;conda&lt;/code&gt; environment will interfere with &lt;code&gt;pyatspi&lt;/code&gt;. As of now, there&#39;s no clean solution for this issue. Proceed through the installation without using &lt;code&gt;conda&lt;/code&gt; or any virtual environment.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;⚠️&lt;strong&gt;Disclaimer&lt;/strong&gt;⚠️: To leverage the full potential of Agent S2, we utilize &lt;a href=&#34;https://github.com/bytedance/UI-TARS&#34;&gt;UI-TARS&lt;/a&gt; as a grounding model (7B-DPO or 72B-DPO for better performance). They can be hosted locally, or on Hugging Face Inference Endpoints. Our code supports Hugging Face Inference Endpoints. Check out &lt;a href=&#34;https://huggingface.co/learn/cookbook/en/enterprise_dedicated_endpoints&#34;&gt;Hugging Face Inference Endpoints&lt;/a&gt; for more information on how to set up and query this endpoint. However, running Agent S2 does not require this model, and you can use alternative API based models for visual grounding, such as Claude.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Install the package:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install gui-agents&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Set your LLM API Keys and other environment variables. You can do this by adding the following line to your .bashrc (Linux), or .zshrc (MacOS) file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export OPENAI_API_KEY=&amp;lt;YOUR_API_KEY&amp;gt;&#xA;export ANTHROPIC_API_KEY=&amp;lt;YOUR_ANTHROPIC_API_KEY&amp;gt;&#xA;export HF_TOKEN=&amp;lt;YOUR_HF_TOKEN&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can set the environment variable in your Python script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import os&#xA;os.environ[&#34;OPENAI_API_KEY&#34;] = &#34;&amp;lt;YOUR_API_KEY&amp;gt;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We also support Azure OpenAI, Anthropic, Gemini, Open Router, and vLLM inference. For more information refer to &lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/models.md&#34;&gt;models.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Setup Retrieval from Web using Perplexica&lt;/h3&gt; &#xA;&lt;p&gt;Agent S works best with web-knowledge retrieval. To enable this feature, you need to setup Perplexica:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Ensure Docker Desktop is installed and running on your system.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to the directory containing the project files.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; cd Perplexica&#xA; git submodule update --init&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Rename the &lt;code&gt;sample.config.toml&lt;/code&gt; file to &lt;code&gt;config.toml&lt;/code&gt;. For Docker setups, you need only fill in the following fields:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;OPENAI&lt;/code&gt;: Your OpenAI API key. &lt;strong&gt;You only need to fill this if you wish to use OpenAI&#39;s models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;OLLAMA&lt;/code&gt;: Your Ollama API URL. You should enter it as &lt;code&gt;http://host.docker.internal:PORT_NUMBER&lt;/code&gt;. If you installed Ollama on port 11434, use &lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;. For other ports, adjust accordingly. &lt;strong&gt;You need to fill this if you wish to use Ollama&#39;s models instead of OpenAI&#39;s&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;GROQ&lt;/code&gt;: Your Groq API key. &lt;strong&gt;You only need to fill this if you wish to use Groq&#39;s hosted models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;ANTHROPIC&lt;/code&gt;: Your Anthropic API key. &lt;strong&gt;You only need to fill this if you wish to use Anthropic models&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You can change these after starting Perplexica from the settings dialog.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;SIMILARITY_MEASURE&lt;/code&gt;: The similarity measure to use (This is filled by default; you can leave it as is if you are unsure about it.)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ensure you are in the directory containing the &lt;code&gt;docker-compose.yaml&lt;/code&gt; file and execute:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Next, export your Perplexica URL. This URL is used to interact with the Perplexica API backend. The port is given by the &lt;code&gt;config.toml&lt;/code&gt; in your Perplexica directory.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PERPLEXICA_URL=http://localhost:{port}/api/search&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Our implementation of Agent S incorporates the Perplexica API to integrate a search engine capability, which allows for a more convenient and responsive user experience. If you want to tailor the API to your settings and specific requirements, you may modify the URL and the message of request parameters in &lt;code&gt;agent_s/query_perplexica.py&lt;/code&gt;. For a comprehensive guide on configuring the Perplexica API, please refer to &lt;a href=&#34;https://github.com/ItzCrazyKns/Perplexica/raw/master/docs/API/SEARCH.md&#34;&gt;Perplexica Search API Documentation&lt;/a&gt;. For a more detailed setup and usage guide, please refer to the &lt;a href=&#34;https://github.com/ItzCrazyKns/Perplexica.git&#34;&gt;Perplexica Repository&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;❗&lt;strong&gt;Warning&lt;/strong&gt;❗: The agent will directly run python code to control your computer. Please use with care.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;🚀 Usage&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Our best configuration uses Claude 3.7 with extended thinking and UI-TARS-72B-DPO. If you are unable to run UI-TARS-72B-DPO due to resource constraints, UI-TARS-7B-DPO can be used as a lighter alternative with minimal performance degradation.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;CLI&lt;/h3&gt; &#xA;&lt;p&gt;Run Agent S2 with a specific model (default is &lt;code&gt;gpt-4o&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;agent_s2 \&#xA;  --provider &#34;anthropic&#34; \&#xA;  --model &#34;claude-3-7-sonnet-20250219&#34; \&#xA;  --grounding_model_provider &#34;anthropic&#34; \&#xA;  --grounding_model &#34;claude-3-7-sonnet-20250219&#34; \&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or use a custom endpoint:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;agent_s2 \&#xA;  --provider &#34;anthropic&#34; \&#xA;  --model &#34;claude-3-7-sonnet-20250219&#34; \&#xA;  --endpoint_provider &#34;huggingface&#34; \&#xA;  --endpoint_url &#34;&amp;lt;endpoint_url&amp;gt;/v1/&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Main Model Settings&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;--provider&lt;/code&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;code&gt;--model&lt;/code&gt;&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Purpose: Specifies the main generation model&lt;/li&gt; &#xA;   &lt;li&gt;Supports: all model providers in &lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/models.md&#34;&gt;models.md&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Default: &lt;code&gt;--provider &#34;anthropic&#34; --model &#34;claude-3-7-sonnet-20250219&#34;&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Grounding Configuration Options&lt;/h4&gt; &#xA;&lt;p&gt;You can use either Configuration 1 or Configuration 2:&lt;/p&gt; &#xA;&lt;h5&gt;&lt;strong&gt;(Default) Configuration 1: API-Based Models&lt;/strong&gt;&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;--grounding_model_provider&lt;/code&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;code&gt;--grounding_model&lt;/code&gt;&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Purpose: Specifies the model for visual grounding (coordinate prediction)&lt;/li&gt; &#xA;   &lt;li&gt;Supports: all model providers in &lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/models.md&#34;&gt;models.md&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Default: &lt;code&gt;--grounding_model_provider &#34;anthropic&#34; --grounding_model &#34;claude-3-7-sonnet-20250219&#34;&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;❗&lt;strong&gt;Important&lt;/strong&gt;❗ &lt;strong&gt;&lt;code&gt;--grounding_model_resize_width&lt;/code&gt;&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Purpose: Some API providers automatically rescale images. Therefore, the generated (x, y) will be relative to the rescaled image dimensions, instead of the original image dimensions.&lt;/li&gt; &#xA;   &lt;li&gt;Supports: &lt;a href=&#34;https://docs.anthropic.com/en/docs/build-with-claude/vision#&#34;&gt;Anthropic rescaling&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Tips: If your grounding is inaccurate even for very simple queries, double check your rescaling width is correct for your machine&#39;s resolution.&lt;/li&gt; &#xA;   &lt;li&gt;Default: &lt;code&gt;--grounding_model_resize_width 1366&lt;/code&gt; (Anthropic)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;&lt;strong&gt;Configuration 2: Custom Endpoint&lt;/strong&gt;&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--endpoint_provider&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Purpose: Specifies the endpoint provider&lt;/li&gt; &#xA;   &lt;li&gt;Supports: HuggingFace TGI, vLLM, Open Router&lt;/li&gt; &#xA;   &lt;li&gt;Default: None&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--endpoint_url&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Purpose: The URL for your custom endpoint&lt;/li&gt; &#xA;   &lt;li&gt;Default: None&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Configuration 2 takes precedence over Configuration 1.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;This will show a user query prompt where you can enter your query and interact with Agent S2. You can use any model from the list of supported models in &lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/models.md&#34;&gt;models.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;gui_agents&lt;/code&gt; SDK&lt;/h3&gt; &#xA;&lt;p&gt;First, we import the necessary modules. &lt;code&gt;AgentS2&lt;/code&gt; is the main agent class for Agent S2. &lt;code&gt;OSWorldACI&lt;/code&gt; is our grounding agent that translates agent actions into executable python code.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import pyautogui&#xA;import io&#xA;from gui_agents.s2.agents.agent_s import AgentS2&#xA;from gui_agents.s2.agents.grounding import OSWorldACI&#xA;&#xA;# Load in your API keys.&#xA;from dotenv import load_dotenv&#xA;load_dotenv()&#xA;&#xA;current_platform = &#34;linux&#34;  # &#34;darwin&#34;, &#34;windows&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, we define our engine parameters. &lt;code&gt;engine_params&lt;/code&gt; is used for the main agent, and &lt;code&gt;engine_params_for_grounding&lt;/code&gt; is for grounding. For &lt;code&gt;engine_params_for_grounding&lt;/code&gt;, we support the Claude, GPT series, and Hugging Face Inference Endpoints.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;engine_type_for_grounding = &#34;huggingface&#34;&#xA;&#xA;engine_params = {&#xA;    &#34;engine_type&#34;: &#34;openai&#34;,&#xA;    &#34;model&#34;: &#34;gpt-4o&#34;,&#xA;}&#xA;&#xA;if engine_type_for_grounding == &#34;huggingface&#34;:&#xA;  engine_params_for_grounding = {&#xA;      &#34;engine_type&#34;: &#34;huggingface&#34;,&#xA;      &#34;endpoint_url&#34;: &#34;&amp;lt;endpoint_url&amp;gt;/v1/&#34;,&#xA;  }&#xA;elif engine_type_for_grounding == &#34;claude&#34;:&#xA;  engine_params_for_grounding = {&#xA;      &#34;engine_type&#34;: &#34;claude&#34;,&#xA;      &#34;model&#34;: &#34;claude-3-7-sonnet-20250219&#34;,&#xA;  }&#xA;elif engine_type_for_grounding == &#34;gpt&#34;:&#xA;  engine_params_for_grounding = {&#xA;    &#34;engine_type&#34;: &#34;gpt&#34;,&#xA;    &#34;model&#34;: &#34;gpt-4o&#34;,&#xA;  }&#xA;else:&#xA;  raise ValueError(&#34;Invalid engine type for grounding&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, we define our grounding agent and Agent S2.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;grounding_agent = OSWorldACI(&#xA;    platform=current_platform,&#xA;    engine_params_for_generation=engine_params,&#xA;    engine_params_for_grounding=engine_params_for_grounding&#xA;)&#xA;&#xA;agent = AgentS2(&#xA;  engine_params,&#xA;  grounding_agent,&#xA;  platform=current_platform,&#xA;  action_space=&#34;pyautogui&#34;,&#xA;  observation_type=&#34;mixed&#34;,&#xA;  search_engine=&#34;Perplexica&#34;  # Assuming you have set up Perplexica.&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, let&#39;s query the agent!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Get screenshot.&#xA;screenshot = pyautogui.screenshot()&#xA;buffered = io.BytesIO() &#xA;screenshot.save(buffered, format=&#34;PNG&#34;)&#xA;screenshot_bytes = buffered.getvalue()&#xA;&#xA;obs = {&#xA;  &#34;screenshot&#34;: screenshot_bytes,&#xA;}&#xA;&#xA;instruction = &#34;Close VS Code&#34;&#xA;info, action = agent.predict(instruction=instruction, observation=obs)&#xA;&#xA;exec(action[0])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Refer to &lt;code&gt;gui_agents/s2/cli_app.py&lt;/code&gt; for more details on how the inference loop works.&lt;/p&gt; &#xA;&lt;h4&gt;Downloading the Knowledge Base&lt;/h4&gt; &#xA;&lt;p&gt;Agent S2 uses a knowledge base that continually updates with new knowledge during inference. The knowledge base is initially downloaded when initializing &lt;code&gt;AgentS2&lt;/code&gt;. The knowledge base is stored as assets under our &lt;a href=&#34;https://github.com/simular-ai/Agent-S/releases&#34;&gt;GitHub Releases&lt;/a&gt;. The &lt;code&gt;AgentS2&lt;/code&gt; initialization will only download the knowledge base for your specified platform and agent version (e.g s1, s2). If you&#39;d like to download the knowledge base programmatically, you can use the following code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;download_kb_data(&#xA;    version=&#34;s2&#34;,&#xA;    release_tag=&#34;v0.2.2&#34;,&#xA;    download_dir=&#34;kb_data&#34;,&#xA;    platform=&#34;linux&#34;  # &#34;darwin&#34;, &#34;windows&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will download Agent S2&#39;s knowledge base for Linux from release tag &lt;code&gt;v0.2.2&lt;/code&gt; to the &lt;code&gt;kb_data&lt;/code&gt; directory. Refer to our &lt;a href=&#34;https://github.com/simular-ai/Agent-S/releases&#34;&gt;GitHub Releases&lt;/a&gt; or release tags that include the knowledge bases.&lt;/p&gt; &#xA;&lt;h3&gt;OSWorld&lt;/h3&gt; &#xA;&lt;p&gt;To deploy Agent S2 in OSWorld, follow the &lt;a href=&#34;https://raw.githubusercontent.com/simular-ai/Agent-S/main/OSWorld.md&#34;&gt;OSWorld Deployment instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;🤝 Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;We extend our sincere thanks to Tianbao Xie for developing OSWorld and discussing computer use challenges. We also appreciate the engaging discussions with Yujia Qin and Shihao Liang regarding UI-TARS.&lt;/p&gt; &#xA;&lt;h2&gt;💬 Citations&lt;/h2&gt; &#xA;&lt;p&gt;If you find this codebase useful, please cite&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{Agent-S2,&#xA;      title={Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents}, &#xA;      author={Saaket Agashe and Kyle Wong and Vincent Tu and Jiachen Yang and Ang Li and Xin Eric Wang},&#xA;      year={2025},&#xA;      eprint={2504.00906},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.AI},&#xA;      url={https://arxiv.org/abs/2504.00906}, &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{Agent-S,&#xA;    title={{Agent S: An Open Agentic Framework that Uses Computers Like a Human}},&#xA;    author={Saaket Agashe and Jiuzhou Han and Shuyu Gan and Jiachen Yang and Ang Li and Xin Eric Wang},&#xA;    booktitle={International Conference on Learning Representations (ICLR)},&#xA;    year={2025},&#xA;    url={https://arxiv.org/abs/2410.08164}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>