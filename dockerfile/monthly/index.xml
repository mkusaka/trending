<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Dockerfile Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-01T02:11:39Z</updated>
  <subtitle>Monthly Trending of Dockerfile in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>madMAx43v3r/chia-gigahorse</title>
    <updated>2023-10-01T02:11:39Z</updated>
    <id>tag:github.com,2023-10-01:/madMAx43v3r/chia-gigahorse</id>
    <link href="https://github.com/madMAx43v3r/chia-gigahorse" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Gigahorse Compressed Plots&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/951738/217386439-751908c7-f1b3-4c4e-9c7a-073d9c9fa721.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Since Chia still has a plot filter of 512 until some time in 2024, the farming capacity is twice that until then.&lt;/p&gt; &#xA;&lt;p&gt;MMX testnet10 and mainnet will have a plot filter of 256.&lt;/p&gt; &#xA;&lt;p&gt;Join the Discord for support: &lt;a href=&#34;https://discord.gg/BswFhNkMzY&#34;&gt;https://discord.gg/BswFhNkMzY&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;RAM / VRAM requirements to farm&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/951738/217621063-bec9e8b7-3fc0-40f9-a6d7-649e3d90b015.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/951738/217621150-b110fb00-12be-452d-8ea5-ece2fb69cc40.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;When you mix different K size and C levels, only the higest RAM / VRAM requirement will apply.&lt;/p&gt; &#xA;&lt;h2&gt;Chia Gigahorse Node / Farmer / Harvester&lt;/h2&gt; &#xA;&lt;p&gt;In the &lt;a href=&#34;https://github.com/madMAx43v3r/chia-gigahorse/releases&#34;&gt;release&lt;/a&gt; section you can find Chia Blockchain binaries to farm compressed plots created with the new plotters provided in this repository.&lt;/p&gt; &#xA;&lt;p&gt;The compressed plot harvester and farmer are not compatible with the official Chia node, it only works together with the Gigahorse node. However it&#39;s possible to use a wallet from the official Chia repository, instead of the Gigahorse binary wallet.&lt;/p&gt; &#xA;&lt;p&gt;Both NFT and OG plots are supported, as well as solo and pool farming (via the official pool protocol). Regular uncompressed plots are supported as well, so you can use the Gigahorse version while re-plotting your farm.&lt;/p&gt; &#xA;&lt;p&gt;The dev fee is as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;3.125 % when using GPU(s) to farm compressed plots&lt;/li&gt; &#xA; &lt;li&gt;1.562 % when using CPU(s) to farm compressed plots&lt;/li&gt; &#xA; &lt;li&gt;0 % for regular uncompressed plots&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When you find a block there&#39;s a chance the 0.25 XCH farmer reward is used as fee, this is a random process. In case of CPU farming it&#39;s 1 out of 8 blocks on average, and for GPU farming it&#39;s 1 out of 4 blocks on average.&lt;/p&gt; &#xA;&lt;p&gt;When the fee is paid from a block, you will see a log entry like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;full_node: WARNING  Used farmer reward of block 2187769 as dev fee (3.125 % on average)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will show the block height as well as the average fee that applies, depending on if the proof was computed via CPU or GPU.&lt;/p&gt; &#xA;&lt;h3&gt;Pool Partial Difficulty&lt;/h3&gt; &#xA;&lt;p&gt;When farming NFT plots on a pool it is recommended to set the partial difficulty to 20 or more, otherwise your harvester will be overloaded with computing full proofs.&lt;/p&gt; &#xA;&lt;p&gt;The chance of having to compute a full proof is roughly &lt;code&gt;1 / (2 * difficulty)&lt;/code&gt;. The cost of computing a full proof is 8 (for C6+) or 16 (for C5 and lower) times that of a quality lookup.&lt;/p&gt; &#xA;&lt;p&gt;For example:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Difficulty 20 (at C6+): &lt;code&gt;8 / 40 = 20 %&lt;/code&gt; compute overhead&lt;/li&gt; &#xA; &lt;li&gt;Difficulty 100 (at C6+): &lt;code&gt;8 / 200 = 4 %&lt;/code&gt; compute overhead&lt;/li&gt; &#xA; &lt;li&gt;Difficulty 1000 (at C6+): &lt;code&gt;8 / 2000 = 0.4 %&lt;/code&gt; compute overhead&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Plot Reload Interval&lt;/h3&gt; &#xA;&lt;p&gt;It is recommended to increase your plot reload interval to at least 3600 seconds in &lt;code&gt;config.yaml&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;harvester:&#xA;  plots_refresh_parameter:&#xA;    interval_seconds: 3600&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The default value of 120 sec will cause too much CPU load with large plot counts.&lt;/p&gt; &#xA;&lt;h3&gt;Usage Linux&lt;/h3&gt; &#xA;&lt;p&gt;Make sure to close any other instances first:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;chia stop all -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or close the Chia GUI if you are running it. Otherwise you cannot start the Gigahorse version.&lt;/p&gt; &#xA;&lt;p&gt;Using the Gigahorse binaries is pretty much the same as with a normal Chia installation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd chia-gigahorse-farmer&#xA;./chia.bin start farmer (full node + farmer + harvester)&#xA;./chia.bin start harvester (remote harvester)&#xA;./chia.bin show -s&#xA;./chia.bin farm summary&#xA;./chia.bin plotnft show&#xA;./chia.bin wallet show&#xA;./chia.bin stop all -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note the usage of &lt;code&gt;./chia.bin ...&lt;/code&gt; instead of just &lt;code&gt;chia ...&lt;/code&gt;, this is the only difference in usage with Gigahorse.&lt;/p&gt; &#xA;&lt;p&gt;Alternatively, you can &lt;code&gt;. ./activate.sh&lt;/code&gt; in &lt;code&gt;chia-gigahorse-farmer&lt;/code&gt; to be able to use &lt;code&gt;chia ...&lt;/code&gt; commands instead of &lt;code&gt;./chia.bin ...&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Usage Windows&lt;/h3&gt; &#xA;&lt;p&gt;Make sure to close any running Chia GUI first, otherwise you cannot start the Gigahorse version.&lt;/p&gt; &#xA;&lt;p&gt;To start the farmer double click &lt;code&gt;start_farmer.cmd&lt;/code&gt; in &lt;code&gt;chia-gigahorse-farmer&lt;/code&gt;, this will open a terminal where you can continue to issue commands. To only open a terminal without starting anything you can use &lt;code&gt;chia.cmd&lt;/code&gt;. To stop everything you can use &lt;code&gt;stop_all.cmd&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The usage in general is the same as normal chia:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;chia.exe start farmer (not: chia start farmer)&#xA;chia.exe start harvester (not: chia start harvester)&#xA;chia show -s&#xA;chia farm summary&#xA;chia plotnft show&#xA;chia wallet show&#xA;chia stop all -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Official GUI + Gigahorse&lt;/h3&gt; &#xA;&lt;p&gt;You can start the official Chia GUI after starting Gigahorse in a terminal, however it needs to be the same version. It will still complain about version mismatch but when the base version (like &lt;code&gt;1.6.2&lt;/code&gt;) is the same then it works.&lt;/p&gt; &#xA;&lt;p&gt;When you close the GUI everything will be stopped, so you need to restart Gigahorse in the terminal again if so desired.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;Note: There is no need to re-sync the blockchain, Gigahorse node will re-use your existing DB and config. Even the old v1 DB format still works.&lt;/p&gt; &#xA;&lt;h4&gt;Linux&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt install libgomp1 ocl-icd-libopencl1&#xA;tar xf chia-gigahorse-farmer-*.tar.gz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Windows&lt;/h4&gt; &#xA;&lt;p&gt;Just unzip the chia-gigahorse-farmer-*.zip somewhere.&lt;/p&gt; &#xA;&lt;p&gt;You might also have to install latest Microsoft Visual C++ Redistributable: &lt;a href=&#34;https://aka.ms/vs/17/release/vc_redist.x64.exe&#34;&gt;https://aka.ms/vs/17/release/vc_redist.x64.exe&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Limit GPU / RAM usage&lt;/h3&gt; &#xA;&lt;p&gt;Please take a look at:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/madMAx43v3r/chia-gigahorse/raw/master/chiapos/README.md#limit-gpu-usage&#34;&gt;How to limit GPU usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/madMAx43v3r/chia-gigahorse/raw/master/chiapos/README.md#limit-ram-usage&#34;&gt;How to limit RAM usage&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note: When changing environment variables you need to restart the Chia daemon for it to take effect: &lt;code&gt;./chia.bin stop all -d&lt;/code&gt; or &lt;code&gt;chia.exe stop all -d&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Remote Compute&lt;/h3&gt; &#xA;&lt;p&gt;It&#39;s possible to move the compute task to another machine or machines, in order to avoid having to install a GPU or powerful CPU in every harvester:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/madMAx43v3r/chia-gigahorse/assets/951738/9bb8d9b7-6a15-4b4a-82aa-6ab72471d5e5&#34; alt=&#34;Remote_Compute_Drawings drawio&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;To use the remote compute feature:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Start &lt;code&gt;chia_recompute_server&lt;/code&gt; on the machine that is doing the compute (included in release).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;export CHIAPOS_RECOMPUTE_HOST=...&lt;/code&gt; on the harvester (replace &lt;code&gt;...&lt;/code&gt; with the IP address or host name of the compute machine, and make sure to restart via &lt;code&gt;chia stop all -d&lt;/code&gt; or &lt;code&gt;stop_all.cmd&lt;/code&gt; on windows)&lt;/li&gt; &#xA; &lt;li&gt;On Windows you need to set &lt;code&gt;CHIAPOS_RECOMPUTE_HOST&lt;/code&gt; variable via system settings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CHIAPOS_RECOMPUTE_HOST&lt;/code&gt; can be a list of recompute servers, such as &lt;code&gt;CHIAPOS_RECOMPUTE_HOST=192.168.0.11,192.168.0.12&lt;/code&gt;. A non-standard port can be specified via &lt;code&gt;HOST:PORT&lt;/code&gt; syntax, such as &lt;code&gt;localhost:12345&lt;/code&gt;. Multiple servers are load balanced in a fault tolerant way.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CHIAPOS_RECOMPUTE_PORT&lt;/code&gt; can be set to specify a custom default port for &lt;code&gt;chia_recompute_server&lt;/code&gt; (default = 11989).&lt;/li&gt; &#xA; &lt;li&gt;See &lt;code&gt;chia_recompute_server --help&lt;/code&gt; for available options.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To use the remote compute proxy:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Start &lt;code&gt;chia_recompute_proxy -n B -n C ...&lt;/code&gt; on a machine &lt;code&gt;A&lt;/code&gt;. (&lt;code&gt;B&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt;, etc are running &lt;code&gt;chia_recompute_server&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Set &lt;code&gt;CHIAPOS_RECOMPUTE_HOST&lt;/code&gt; on your harvester(s) to machine A.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;chia_recompute_proxy&lt;/code&gt; can be run on a central machine, or on each harvester itself, in which case &lt;code&gt;A = localhost&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;See &lt;code&gt;chia_recompute_proxy --help&lt;/code&gt; for available options.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When using &lt;code&gt;CHIAPOS_RECOMPUTE_HOST&lt;/code&gt;, the local CPU and GPUs are not used, unless you run a local &lt;code&gt;chia_recompute_server&lt;/code&gt; and &lt;code&gt;CHIAPOS_RECOMPUTE_HOST&lt;/code&gt; includes the local machine.&lt;/p&gt; &#xA;&lt;h4&gt;CPU based Compute Servers&lt;/h4&gt; &#xA;&lt;p&gt;For CPU based compute it&#39;s important to increase &lt;code&gt;CHIAPOS_MAX_CORES&lt;/code&gt; on the harvesters to achieve full CPU utilization on compute servers. Because &lt;code&gt;CHIAPOS_MAX_CORES&lt;/code&gt; is the maximum parallel requests made from a harvester to recompute servers, and a request is processed on a single CPU core only. By default &lt;code&gt;CHIAPOS_MAX_CORES&lt;/code&gt; is the number of phsical CPU cores on the harvester.&lt;/p&gt; &#xA;&lt;p&gt;For example if you have a single compute server with 32 CPU cores, you should set &lt;code&gt;CHIAPOS_MAX_CORES&lt;/code&gt; on the harvesters to 32. The sum of &lt;code&gt;CHIAPOS_MAX_CORES&lt;/code&gt; accross all harvesters should be greater or equal to the sum of CPU cores on all compute servers. In case of low number of harvesters (ie. 1-3) you should set &lt;code&gt;CHIAPOS_MAX_CORES&lt;/code&gt; to the number of CPU cores on your compute server.&lt;/p&gt; &#xA;&lt;h3&gt;Known Issues&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;AMD GPU getting stuck in Linux, workaround is: &lt;code&gt;watch -n 0.1 sudo cat /sys/kernel/debug/dri/0/amdgpu_pm_info&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Fixed in latest version&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Harvester crashing randomly after some time&lt;/li&gt; &#xA; &lt;li&gt;Multiple OpenCL GPUs not working together when farming&lt;/li&gt; &#xA; &lt;li&gt;Multiple GPUs not being fully utilized when farming&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Gigahorse GPU Plotter&lt;/h2&gt; &#xA;&lt;p&gt;You can find the GPU plotter binaries in &lt;a href=&#34;https://github.com/madMAx43v3r/chia-gigahorse/tree/master/cuda-plotter&#34;&gt;cuda-plotter&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;They support plotting for Chia as well as MMX.&lt;/p&gt; &#xA;&lt;h2&gt;CPU Plotter&lt;/h2&gt; &#xA;&lt;p&gt;You can find the CPU plotter binaries in &lt;a href=&#34;https://github.com/madMAx43v3r/chia-gigahorse/tree/master/cpu-plotter&#34;&gt;cpu-plotter&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;They support plotting for Chia as well as MMX.&lt;/p&gt; &#xA;&lt;h2&gt;Farming Benchmark&lt;/h2&gt; &#xA;&lt;p&gt;To test how many plots you can farm on a given system you can use the &lt;code&gt;ProofOfSpace&lt;/code&gt; tool in &lt;a href=&#34;https://github.com/madMAx43v3r/chia-gigahorse/tree/master/chiapos&#34;&gt;chiapos&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Plot Sink&lt;/h2&gt; &#xA;&lt;p&gt;Plot Sink is a tool to receive plots over the network and copy them to multiple HDDs in parallel.&lt;/p&gt; &#xA;&lt;p&gt;You can find binaries in &lt;a href=&#34;https://github.com/madMAx43v3r/chia-gigahorse/tree/master/plot-sink&#34;&gt;plot-sink&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See also the open source repository: &lt;a href=&#34;https://github.com/madMAx43v3r/chia-plot-sink&#34;&gt;https://github.com/madMAx43v3r/chia-plot-sink&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Docker Usage&lt;/h2&gt; &#xA;&lt;p&gt;The Dockerfile file uses multiple build stages to support 3 different applications CPU-Only, AMD-GPU, NVIDIA-GPU.&lt;/p&gt; &#xA;&lt;p&gt;Each image provides a volume for &lt;code&gt;/data&lt;/code&gt; which you can override with your own volume or a mapped path to customize the storage location of the node data.&lt;/p&gt; &#xA;&lt;p&gt;The default behavior of the container is to look in &lt;code&gt;/data&lt;/code&gt; for an existing db/config and use it. Otherwise it will generate a fresh config and start syncing the node from scratch.&lt;/p&gt; &#xA;&lt;p&gt;You can set which services to run with the &lt;code&gt;CHIA_SERVICES&lt;/code&gt; environment variable.&lt;/p&gt; &#xA;&lt;p&gt;Docker Run Examples:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;-e CHIA_SERVICES=&#34;harvester&#34;&#xA;-e CHIA_SERVICES=&#34;node farmer-only&#34;&#xA;-e CHIA_SERVICES=&#34;node farmer-only wallet&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Docker Compose Examples:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;environment:&#xA;  - CHIA_SERVICES=&#34;harvester&#34;&#xA;&#xA;environment:&#xA;  - CHIA_SERVICES=&#34;node farmer-only&#34;&#xA;  &#xA;environment:&#xA;  - CHIA_SERVICES=&#34;node farmer-only wallet&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;CPU-Only&lt;/h3&gt; &#xA;&lt;p&gt;Docker Run Example:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;docker run --rm -it -v /path/to/.chia:/data chia-gigahorse&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Docker Compose Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;version: &#39;3&#39;&#xA;services:&#xA;  node:&#xA;    image: chia-gigahorse&#xA;    restart: unless-stopped&#xA;    volumes:&#xA;      - /path/to/.chia:/data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;AMD-GPU&lt;/h3&gt; &#xA;&lt;p&gt;Docker Run Example:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;docker run --rm -it --device=/dev/kfd --device=/dev/dri --group-add video --group-add render -v /path/to/.chia:/data chia-gigahorse-amd&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Docker Compose Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;version: &#39;3&#39;&#xA;services:&#xA;  node:&#xA;    image: chia-gigahorse-amd&#xA;    restart: unless-stopped&#xA;    group_add:&#xA;      - video&#xA;      - render&#xA;    devices:&#xA;      - /dev/dri:/dev/dri&#xA;      - /dev/kfd:/dev/kfd&#xA;    volumes:&#xA;      - /path/to/.chia:/data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: &lt;code&gt;- render&lt;/code&gt; in &lt;code&gt;group_add&lt;/code&gt; might need to be removed, depending on your system.&lt;/p&gt; &#xA;&lt;h3&gt;NVIDIA-GPU&lt;/h3&gt; &#xA;&lt;p&gt;Docker Run Example:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;docker run --rm -it --runtime=nvidia -v /path/to/.chia:/data chia-gigahorse-nvidia&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Docker Compose Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;version: &#39;3&#39;&#xA;services:&#xA;  node:&#xA;    image: chia-gigahorse-nvidia&#xA;    restart: unless-stopped&#xA;    runtime: nvidia&#xA;    volumes:&#xA;      - /path/to/.chia:/data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: for nvidia you also need the &lt;code&gt;NVIDIA Container Toolkit&lt;/code&gt; installed on the host, for more info please see: &lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker&#34;&gt;https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kavidu-dilhara/Kali-Linux-VPS</title>
    <updated>2023-10-01T02:11:39Z</updated>
    <id>tag:github.com,2023-10-01:/kavidu-dilhara/Kali-Linux-VPS</id>
    <link href="https://github.com/kavidu-dilhara/Kali-Linux-VPS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository contains the configuration files and Docker setup for a Kali Linux virtual private server (VPS) on Railway.app.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kali Linux VPS&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://github.com/kavidu-dilhara/Kali-Linux-VPS/raw/main/img/kali-logo.jpeg?resize=1024%2C555&amp;amp;ssl=1&#34; alt=&#34;kali&#34;&gt;&lt;/p&gt; &#xA;&lt;h5 align=&#34;left&#34;&gt; This repository provides instructions and scripts for creating a Kali Linux virtual private server (VPS) using a Kali Linux Docker image, Railway, and Ngrok.(Completely free) &lt;/h5&gt; &#xA;&lt;center&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/kavidu-dilhara/Kali-Linux-VPS/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/kavidu-dilhara/Kali-Linux-VPS?style=social&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/forks/kavidu-dilhara/Kali-Linux-VPS?style=social&#34; alt=&#34;GitHub fork&#34;&gt; &lt;a href=&#34;https://github.com/kavidu-dilhara/Kali-Linux-VPS/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kavidu-dilhara/Kali-Linux-VPS/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/version-1.0.0-green.svg?sanitize=true&#34; alt=&#34;Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kavidu-dilhara/Kali-Linux-VPS/commits/master&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/last-commit/kavidu-dilhara/Kali-Linux-VPS.svg?sanitize=true&#34; alt=&#34;Last Commit&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/center&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Before you get started, make sure you have the following:&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;1.Github account&lt;/code&gt; &lt;br&gt; &lt;code&gt;2.Railway account&lt;/code&gt;&lt;br&gt; &lt;code&gt;3.Ngrok account&lt;/code&gt; &lt;br&gt; (you can sign up for free)&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/kavidu-dilhara/Kali-Linux-VPS/raw/main/deploy.md&#34;&gt;&lt;img src=&#34;https://railway.app/button.svg?sanitize=true&#34; alt=&#34;Deploy on Railway&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Limitations&lt;/h2&gt; &#xA;&lt;blockquote&gt;&#xA;  Railway.app may have its own limitations on the amount of resources (CPU, memory, disk) that you can use for your VPS, depending on your subscription plan. &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Note:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Read this Before Deploy : &lt;a href=&#34;https://railway.app/legal/fair-use&#34;&gt;Term Of Service Railway&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;This repository is intended for educational and experimental purposes only. Using Kali Linux or its tools for unauthorized or illegal activities is prohibited and may result in legal consequences.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;Use this application at your own risk. We are not affiliated with railway.app and cannot be held responsible for any account suspensions or terminations due to suspicious activity.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Taiyo-ai/ts-mesh-pipeline</title>
    <updated>2023-10-01T02:11:39Z</updated>
    <id>tag:github.com,2023-10-01:/Taiyo-ai/ts-mesh-pipeline</id>
    <link href="https://github.com/Taiyo-ai/ts-mesh-pipeline" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Use this template repository to write time series data ingestion pipelines&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Data Ingestion Pipeline Template&lt;/h1&gt; &#xA;&lt;p&gt;This repository consists of boilerplate folder structure to write and organize your scripts for a data ingestion pipeline&lt;/p&gt; &#xA;&lt;h2&gt;Folder Structure&lt;/h2&gt; &#xA;&lt;p&gt;The tree diagram below represents a general file structure&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;|--- data_source_name                      &#xA;     |--- deploy                            # pipeline orchestration and configuration of DAGs&#xA;     |    |---dev              &#xA;     |    |---prod&#xA;     |--- src&#xA;          |--- dependencies&#xA;          |    |--- cleaning&#xA;          |    |    |--- __init__.py&#xA;          |    |    |--- cleaner.py         ## Cleaning script here&#xA;          |    |--- geocoding&#xA;          |    |    |--- __init__.py&#xA;          |    |    |--- geocoder.py        ## Geocoding script here&#xA;          |    |--- scraping                # This folder contains all data harvesting scipts&#xA;          |    |    |--- __init__.py&#xA;          |    |    |--- scraper.py         ## Harvesting script here&#xA;          |    |--- standardization&#xA;          |    |    |--- __init__.py&#xA;          |    |    |--- standardizer.py    ## Standardization script here&#xA;          |    |--- utils                   # Utility and helper scipts to be placed here&#xA;          |         |--- __init__.py&#xA;          |--- .dockerignore&#xA;          |--- Dockerfile&#xA;          |--- client.py                    # Master script that connects all the above blocks&#xA;          |--- requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Different Blocks of ETL pipeline&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Scraping/Data Harvesting &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Contains all the scripts that extracts metadata and raw data to be processed further from database, websites, webservices, APIs, etc.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Cleaning &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Treatment missing fields and values&lt;/li&gt; &#xA;   &lt;li&gt;Treatment of duplicate entries&lt;/li&gt; &#xA;   &lt;li&gt;Convert country codes to &lt;code&gt;ISO 3166-1 alpha3&lt;/code&gt; i.e. 3 letter format&lt;/li&gt; &#xA;   &lt;li&gt;Identify region name and region code using the country code&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Geocoding &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Based upon location information available in the data &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Location label&lt;/li&gt; &#xA;     &lt;li&gt;Geo-spatial coordinates&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Missing field can be found either by using geocoding or reverse geocoding with max precision available&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Standardization &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fields to be strictly in &lt;strong&gt;lower snake casing&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Taking care of data types and consistency of fields&lt;/li&gt; &#xA;   &lt;li&gt;Standardize fields like &lt;code&gt;sector&lt;/code&gt;, &lt;code&gt;subsector&lt;/code&gt;, &lt;code&gt;domain&lt;/code&gt;, &lt;code&gt;subdomain&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Renaming of field names as per required standards&lt;/li&gt; &#xA;   &lt;li&gt;Manipulation of certain fields and values to meet up the global standards for presentation, analytics and business use of data&lt;/li&gt; &#xA;   &lt;li&gt;Refer to the &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1Zyn0qLI1JdZD-3EQdvpi7twzUUy3vExg80SL3CK6sWI/edit#gid=0&#34;&gt;Global Field Standards&lt;/a&gt; spreadsheet for the standards to be followed&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Note&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Depending upon what fields are already available in the data &lt;code&gt;GEOCODING&lt;/code&gt; step may or may not be required.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;It is recommended that the resultant data after each and every step is stored and backed up for recovery purpose.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Apart from the primary fields listed down in &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1Zyn0qLI1JdZD-3EQdvpi7twzUUy3vExg80SL3CK6sWI/edit#gid=0&#34;&gt;Global Field Standards&lt;/a&gt; spreadsheet, there are several other secondary fields that are to be scraped; given by the data provider for every document that holds significant business importance.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Submission and Evaluation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For assignment submission guidelines and evaluation criteria refer to the &lt;a href=&#34;https://github.com/Taiyo-ai/ts-mesh-pipeline/wiki&#34;&gt;WIKI&lt;/a&gt; documentation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Copyright © 2021 Taiyō.ai Inc.&lt;/p&gt;</summary>
  </entry>
</feed>