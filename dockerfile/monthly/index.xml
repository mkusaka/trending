<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Dockerfile Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-03-01T01:54:00Z</updated>
  <subtitle>Monthly Trending of Dockerfile in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>coollabsio/documentation-coolify</title>
    <updated>2025-03-01T01:54:00Z</updated>
    <id>tag:github.com,2025-03-01:/coollabsio/documentation-coolify</id>
    <link href="https://github.com/coollabsio/documentation-coolify" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Documentation for Coolify&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Coolify Documentation&lt;/h1&gt; &#xA;&lt;p&gt;This is the official repository for Coolify documentation, available at &lt;a href=&#34;https://coolify.io/docs&#34;&gt;https://coolify.io/docs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributors should follow the guide at: &lt;a href=&#34;https://coolify.io/docs/resource/contribute/documentation&#34;&gt;https://coolify.io/docs/resource/contribute/documentation&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>MicrosoftDocs/windows-powershell-docs</title>
    <updated>2025-03-01T01:54:00Z</updated>
    <id>tag:github.com,2025-03-01:/MicrosoftDocs/windows-powershell-docs</id>
    <link href="https://github.com/MicrosoftDocs/windows-powershell-docs" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repo is used to contribute to Windows 10, Windows Server 2016, and MDOP PowerShell module documentation.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Windows IT professional documentation&lt;/h1&gt; &#xA;&lt;p&gt;This repository houses the Windows client, Windows Server, and MDOP PowerShell module docs that are written for IT professionals.&lt;/p&gt; &#xA;&lt;p&gt;Edits to this content are published in the following places:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Various versions of &lt;a href=&#34;https://learn.microsoft.com/powershell/windows/get-started&#34;&gt;Windows client and Windows Server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/powershell/mdop/get-started&#34;&gt;Microsoft Desktop Optimization Pack&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;PowerShell Updatable Help (CabGen) CI Build Status&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://apidrop.visualstudio.com/Content%20CI/_build/latest?definitionId=5077&amp;amp;repoName=MicrosoftDocs%2Fwindows-powershell-docs&amp;amp;branchName=live&#34;&gt;&lt;img src=&#34;https://apidrop.visualstudio.com/Content%20CI/_apis/build/status/PROD/CabGen(PowerShell_Updatable_Help)/GitHub_MicrosoftDocs_windows-powershell-docs/46a32786-a1f6-1250-e1e1-2a4554025dc9_cabgen_Publish-Updatable-Help?repoName=MicrosoftDocs%2Fwindows-powershell-docs&amp;amp;branchName=live&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We actively merge contributions into this repository via &lt;a href=&#34;https://help.github.com/articles/using-pull-requests/&#34;&gt;pull request&lt;/a&gt; into the &lt;em&gt;main&lt;/em&gt; branch. If you are not a Microsoft employee, before you submit a pull request you must sign a &lt;a href=&#34;https://cla.microsoft.com/&#34;&gt;Contribution License Agreement&lt;/a&gt; to ensure that the community is free to use your submissions. For more information on contributing, read our &lt;a href=&#34;https://raw.githubusercontent.com/MicrosoftDocs/windows-powershell-docs/main/CONTRIBUTING.md&#34;&gt;contributions guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information, see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;!-- link references --&gt;</summary>
  </entry>
  <entry>
    <title>mattcurf/ollama-intel-gpu</title>
    <updated>2025-03-01T01:54:00Z</updated>
    <id>tag:github.com,2025-03-01:/mattcurf/ollama-intel-gpu</id>
    <link href="https://github.com/mattcurf/ollama-intel-gpu" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ollama-intel-gpu&lt;/h1&gt; &#xA;&lt;p&gt;This repo illustrates the use of Ollama with support for Intel ARC GPU based via ipex-llm and Ollama Portable ZIP support. Run the recently released &lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-R1&#34;&gt;deepseek-r1&lt;/a&gt; model on your local Intel ARC GPU based PC using Linux&lt;/p&gt; &#xA;&lt;h2&gt;Important Note&lt;/h2&gt; &#xA;&lt;p&gt;All Ollama based ipex-llm defects should be reported directly to the ipex-llm project at &lt;a href=&#34;https://github.com/intel/ipex-llm&#34;&gt;https://github.com/intel/ipex-llm&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Screenshot&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mattcurf/ollama-intel-gpu/main/doc/screenshot.png&#34; alt=&#34;screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Prerequisites&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ubuntu 24.04 or newer (for Intel ARC GPU kernel driver support. Tested with Ubuntu 24.04.02&lt;/li&gt; &#xA; &lt;li&gt;Installed Docker and Docker-compose tools&lt;/li&gt; &#xA; &lt;li&gt;Intel ARC series GPU (tested with Intel ARC A770 16GB and Intel(R) Core(TM) Ultra 5 125H integrated GPU)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;The following will build the Ollama with Intel ARC GPU support, and compose those with the public docker image based on OpenWEB UI from &lt;a href=&#34;https://github.com/open-webui/open-webui&#34;&gt;https://github.com/open-webui/open-webui&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Linux:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/mattcurf/ollama-intel-gpu&#xA;$ cd ollama-intel-gpu&#xA;$ docker compose up &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; If you have multiple GPU&#39;s installed (like integrated and discrete), set the ONEAPI_DEVICE_DELECTOR environment variable in the docker compose file to select the intended device to use.&lt;/p&gt; &#xA;&lt;p&gt;Then launch your web browser to &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; to launch the web ui. Create a local OpenWeb UI credential, then click the settings icon in the top right of the screen, then select &#39;Models&#39;, then click &#39;Show&#39;, then download a model like &#39;llama3.1:8b-instruct-q8_0&#39; for Intel ARC A770 16GB VRAM&lt;/p&gt; &#xA;&lt;h1&gt;References&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dgpu-docs.intel.com/driver/client/overview.html&#34;&gt;https://dgpu-docs.intel.com/driver/client/overview.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/intel/ipex-llm/raw/main/docs/mddocs/Quickstart/ollama_portablze_zip_quickstart.md&#34;&gt;https://github.com/intel/ipex-llm/blob/main/docs/mddocs/Quickstart/ollama_portablze_zip_quickstart.md&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>