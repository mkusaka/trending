<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Dockerfile Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-05T01:36:14Z</updated>
  <subtitle>Daily Trending of Dockerfile in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Y1ran/Free-VPN-for-Coursera</title>
    <updated>2022-10-05T01:36:14Z</updated>
    <id>tag:github.com,2022-10-05:/Y1ran/Free-VPN-for-Coursera</id>
    <link href="https://github.com/Y1ran/Free-VPN-for-Coursera" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🔑 🔓免费开源的科学上网工具&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VPN-for-Coursera&lt;/h1&gt; &#xA;&lt;p&gt;科学上网工具：主要是为了解决部分用户在Coursera上遇到的视频无法观看，黑屏，缓冲问题。&lt;br&gt;更多解决方法见： &lt;a href=&#34;https://blog.csdn.net/qq_39521554/article/details/79039548#comments&#34;&gt;Coursera视频无法观看的三种不同解决方法（亲测有效）&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;VPN工具一：Shadow-SSR-4.0&lt;/h2&gt; &#xA;&lt;h3&gt;使用方法&lt;br&gt;&lt;/h3&gt; &#xA;&lt;br&gt; 第一步：将文件解压缩至本地&#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Y1ran/JavaSE/raw/master/%E6%95%99%E7%A8%8B%E5%9B%BE%E7%89%87/1.JPG&#34; alt=&#34;步骤一&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; 第二步：打开Shadow-ssr-dot-4.0（粉红小飞机图标）&#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Y1ran/JavaSE/raw/master/%E6%95%99%E7%A8%8B%E5%9B%BE%E7%89%87/2.JPG&#34; alt=&#34;步骤一&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; 第三步：在任务栏图标处找到白色小飞机&#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Y1ran/JavaSE/raw/master/%E6%95%99%E7%A8%8B%E5%9B%BE%E7%89%87/3.JPG&#34; alt=&#34;步骤一&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; 第四步：右键白色小飞机，选择import-SSR links from-clipboard &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Y1ran/JavaSE/raw/master/%E6%95%99%E7%A8%8B%E5%9B%BE%E7%89%87/4.JPG&#34; alt=&#34;步骤一&#34;&gt; &lt;br&gt; &lt;em&gt;执行这一步前请先在项目文件内找到&lt;strong&gt;节点.txt&lt;/strong&gt;并ctrl+C复制里面内容)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;br&gt; 第五步：双击白色小飞机，更改设置如下 &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Y1ran/JavaSE/raw/master/%E6%95%99%E7%A8%8B%E5%9B%BE%E7%89%87/Capture.JPG&#34; alt=&#34;步骤一&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;此时点击OK进行连接，即可科学上网，除了Coursera还可以上谷歌,FB,INS等网站&lt;/p&gt; &#xA;&lt;h2&gt;VPN工具二：SSTap&lt;/h2&gt; &#xA;&lt;h3&gt;使用方法&lt;br&gt;&lt;/h3&gt; &#xA;&lt;br&gt; 第一步：将文件解压缩至本地&#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Y1ran/JavaSE/raw/master/%E6%95%99%E7%A8%8B%E5%9B%BE%E7%89%87/5.JPG&#34; alt=&#34;步骤一&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; 第二步：打开红色标记图标&#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Y1ran/JavaSE/raw/master/%E6%95%99%E7%A8%8B%E5%9B%BE%E7%89%87/6.JPG&#34; alt=&#34;步骤一&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; 第三步：单击绿色加号，选择第三个选项&#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Y1ran/JavaSE/raw/master/%E6%95%99%E7%A8%8B%E5%9B%BE%E7%89%87/7.JPG&#34; alt=&#34;步骤一&#34;&gt; &lt;br&gt; &lt;em&gt;执行这一步前请先在项目文件内找到&lt;strong&gt;节点.txt&lt;/strong&gt;并ctrl+C复制里面内容)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;第四步：点击闪电标志进行测试，如果运行正常则如下图所示 &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Y1ran/JavaSE/raw/master/%E6%95%99%E7%A8%8B%E5%9B%BE%E7%89%87/8.JPG&#34; alt=&#34;步骤一&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>smy20011/dreambooth-docker</title>
    <updated>2022-10-05T01:36:14Z</updated>
    <id>tag:github.com,2022-10-05:/smy20011/dreambooth-docker</id>
    <link href="https://github.com/smy20011/dreambooth-docker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DreamBooth local docker file for windows/linux&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2208.12242&#34;&gt;DreamBooth&lt;/a&gt; is a method to personalize text2image models like stable diffusion given just a few(3~5) images of a subject.&lt;/p&gt; &#xA;&lt;p&gt;The training script in this repo is adapted from ShivamShrirao&#39;s diffuser repo. See &lt;a href=&#34;https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth&#34;&gt;here&lt;/a&gt; for detailed training command.&lt;/p&gt; &#xA;&lt;p&gt;Docker file copy the ShivamShrirao&#39;s train_dreambooth.py to root directory. Replace any train_dreambooth.py in original doc with /train_dreambooth.py. Eg, if you want to run &lt;code&gt;accelerate launch train_dreambooth.py&lt;/code&gt; you need to run following&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run -it --gpus=all --ipc=host -v $(pwd):/train -e HUGGING_FACE_HUB_TOKEN=$(cat ~/.huggingface/token)  smy20011/dreambooth:latest \&#xA;  accelerate launch /train_dreambooth.py (your arguments here)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running locally&lt;/h2&gt; &#xA;&lt;p&gt;You need to install WSL with docker support. For linux users, make sure you have NVIDIA driver installed and have latest docker installed.&lt;/p&gt; &#xA;&lt;p&gt;For Windows users, follow the guide &lt;a href=&#34;https://docs.nvidia.com/cuda/wsl-user-guide/index.html&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://learn.microsoft.com/en-us/windows/wsl/tutorials/wsl-containers&#34;&gt;here&lt;/a&gt;. You don&#39;t need to do the &#34;CUDA Support for WSL2 section&#34;. You can also follow this &lt;a href=&#34;https://www.youtube.com/watch?v=YozfiLI1ogY&#34;&gt;Youtube&lt;/a&gt; video for reference as well.&lt;/p&gt; &#xA;&lt;p&gt;Open the WSL terminal in Windows or open the terminal in Linux. Makesure you have &lt;a href=&#34;https://huggingface.co/docs/huggingface_hub/quick-start&#34;&gt;huggingface-cli&lt;/a&gt; installed.&lt;/p&gt; &#xA;&lt;h3&gt;Dog toy example&lt;/h3&gt; &#xA;&lt;p&gt;You need to accept the model license before downloading or using the weights. In this example we&#39;ll use model version &lt;code&gt;v1-4&lt;/code&gt;, so you&#39;ll need to visit &lt;a href=&#34;https://huggingface.co/CompVis/stable-diffusion-v1-4&#34;&gt;its card&lt;/a&gt;, read the license and tick the checkbox if you agree.&lt;/p&gt; &#xA;&lt;p&gt;You have to be a registered user in 🤗 Hugging Face Hub, and you&#39;ll also need to use an access token for the code to work. For more information on access tokens, please refer to &lt;a href=&#34;https://huggingface.co/docs/hub/security-tokens&#34;&gt;this section of the documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Run the following command to authenticate your token&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Now let&#39;s get our dataset. Download images from &lt;a href=&#34;https://drive.google.com/drive/folders/1BO_dyz-p65qhBRRMRA4TbZ8qW4rB99JZ&#34;&gt;here&lt;/a&gt; and save them in a directory. This will be our training data.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;cd&lt;/code&gt; to the directory in your terminal. Run following command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export MODEL_NAME=&#34;CompVis/stable-diffusion-v1-4&#34;&#xA;export INSTANCE_DIR=&#34;path-to-instance-images&#34;&#xA;export OUTPUT_DIR=&#34;path-to-save-model&#34;&#xA;&#xA;sudo docker run -it --gpus=all --ipc=host -v $(pwd):/train -e HUGGING_FACE_HUB_TOKEN=$(cat ~/.huggingface/token)  smy20011/dreambooth:latest \&#xA;  accelerate launch /train_dreambooth.py \&#xA;  --pretrained_model_name_or_path=$MODEL_NAME --use_auth_token \&#xA;  --instance_data_dir=$INSTANCE_DIR \&#xA;  --output_dir=$OUTPUT_DIR \&#xA;  --instance_prompt=&#34;a photo of sks dog&#34; \&#xA;  --resolution=512 \&#xA;  --train_batch_size=1 \&#xA;  --gradient_accumulation_steps=1 \&#xA;  --learning_rate=5e-6 \&#xA;  --lr_scheduler=&#34;constant&#34; \&#xA;  --lr_warmup_steps=0 \&#xA;  --max_train_steps=400&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Training with prior-preservation loss&lt;/h3&gt; &#xA;&lt;p&gt;Prior-preservation is used to avoid overfitting and language-drift. Refer to the paper to learn more about it. For prior-preservation we first generate images using the model with a class prompt and then use those during training along with our data. According to the paper, it&#39;s recommened to generate &lt;code&gt;num_epochs * num_samples&lt;/code&gt; images for prior-preservation. 200-300 works well for most cases.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export MODEL_NAME=&#34;CompVis/stable-diffusion-v1-4&#34;&#xA;export INSTANCE_DIR=&#34;path-to-instance-images&#34;&#xA;export CLASS_DIR=&#34;path-to-class-images&#34;&#xA;export OUTPUT_DIR=&#34;path-to-save-model&#34;&#xA;&#xA;sudo docker run -it --gpus=all --ipc=host -v $(pwd):/train -e HUGGING_FACE_HUB_TOKEN=$(cat ~/.huggingface/token)  smy20011/dreambooth:latest \&#xA;  accelerate launch /train_dreambooth.py \&#xA;  --pretrained_model_name_or_path=$MODEL_NAME --use_auth_token \&#xA;  --instance_data_dir=$INSTANCE_DIR \&#xA;  --class_data_dir=$CLASS_DIR \&#xA;  --output_dir=$OUTPUT_DIR \&#xA;  --with_prior_preservation --prior_loss_weight=1.0 \&#xA;  --instance_prompt=&#34;a photo of sks dog&#34; \&#xA;  --class_prompt=&#34;a photo of dog&#34; \&#xA;  --resolution=512 \&#xA;  --train_batch_size=1 \&#xA;  --gradient_accumulation_steps=1 \&#xA;  --learning_rate=5e-6 \&#xA;  --lr_scheduler=&#34;constant&#34; \&#xA;  --lr_warmup_steps=0 \&#xA;  --num_class_images=200 \&#xA;  --max_train_steps=800&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Training on a 16GB GPU:&lt;/h3&gt; &#xA;&lt;p&gt;With the help of gradient checkpointing and the 8-bit optimizer from bitsandbytes it&#39;s possible to run train dreambooth on a 16GB GPU.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export MODEL_NAME=&#34;CompVis/stable-diffusion-v1-4&#34;&#xA;export INSTANCE_DIR=&#34;path-to-instance-images&#34;&#xA;export CLASS_DIR=&#34;path-to-class-images&#34;&#xA;export OUTPUT_DIR=&#34;path-to-save-model&#34;&#xA;&#xA;sudo docker run -it --gpus=all --ipc=host -v $(pwd):/train -e HUGGING_FACE_HUB_TOKEN=$(cat ~/.huggingface/token)  smy20011/dreambooth:latest \&#xA;  accelerate launch /train_dreambooth.py \&#xA;  --pretrained_model_name_or_path=$MODEL_NAME --use_auth_token \&#xA;  --instance_data_dir=$INSTANCE_DIR \&#xA;  --class_data_dir=$CLASS_DIR \&#xA;  --output_dir=$OUTPUT_DIR \&#xA;  --with_prior_preservation --prior_loss_weight=1.0 \&#xA;  --instance_prompt=&#34;a photo of sks dog&#34; \&#xA;  --class_prompt=&#34;a photo of dog&#34; \&#xA;  --resolution=512 \&#xA;  --train_batch_size=1 \&#xA;  --gradient_accumulation_steps=2 --gradient_checkpointing \&#xA;  --use_8bit_adam \&#xA;  --learning_rate=5e-6 \&#xA;  --lr_scheduler=&#34;constant&#34; \&#xA;  --lr_warmup_steps=0 \&#xA;  --num_class_images=200 \&#xA;  --max_train_steps=800&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>AlexisAhmed/BugBountyToolkit</title>
    <updated>2022-10-05T01:36:14Z</updated>
    <id>tag:github.com,2022-10-05:/AlexisAhmed/BugBountyToolkit</id>
    <link href="https://github.com/AlexisAhmed/BugBountyToolkit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A multi-platform bug bounty toolkit that can be installed on Debian/Ubuntu or set up with Docker.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://hackersploit.org/wp-content/uploads/2020/12/Bug-Bounty-Toolkit-No-Image-758x426.png&#34; alt=&#34;BugBountyToolkit&#34; style=&#34;float: left; margin-right: 10px;&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Bug Bounty Toolkit&lt;/h1&gt; &#xA;&lt;p&gt;A multiplatform bug bounty toolkit that can be installed on Debian/Ubuntu or setup with Docker.&lt;/p&gt; &#xA;&lt;h2&gt;Why should you use this toolkit?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The objective of this toolkit is to provide pentesters, security researchers and bug bounty hunters with a pre-configured environment that has some of the most popular tools and frameworks already installed and configured.&lt;/li&gt; &#xA; &lt;li&gt;This toolkit offers a multiplatform base to work with as the script can be installed on Linux, setup with Docker or installed on Windows with WSL (Windows Subsystem For Linux).&lt;/li&gt; &#xA; &lt;li&gt;The installer script can be customized to add or remove specific tools based on your requirements.&lt;/li&gt; &#xA; &lt;li&gt;Tools are constantly being added, updated and fixed.&lt;/li&gt; &#xA; &lt;li&gt;Pull once. Update as needed.&lt;/li&gt; &#xA; &lt;li&gt;In addition to the tools that are already installed, you can use the Katoolin script to install additional tools that you may require during your engagements.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Docker Pull Instructions&lt;/h2&gt; &#xA;&lt;p&gt;Docker Hub Link: &lt;a href=&#34;https://hub.docker.com/r/hackersploit/bugbountytoolkit&#34;&gt;https://hub.docker.com/r/hackersploit/bugbountytoolkit&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker pull hackersploit/bugbountytoolkit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Docker Run Instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Run with Bash&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -it hackersploit/bugbountytoolkit /bin/bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run with ZSH&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -it hackersploit/bugbountytoolkit /usr/bin/zsh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://asciinema.org/a/sMorBlA5yzTIwfdiWzdRR3yEh&#34;&gt;&lt;img src=&#34;https://asciinema.org/a/sMorBlA5yzTIwfdiWzdRR3yEh.svg?sanitize=true&#34; alt=&#34;asciicast&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Docker Build Instructions&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker build . -t hackersploit/bugbountytoolkit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Installation Instructions - Ubuntu/Debian&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/AlexisAhmed/BugBountyToolkit.git&#xA;cd BugBountyToolkit&#xA;chmod +x install.sh&#xA;./install.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Installing New Tools&lt;/h2&gt; &#xA;&lt;p&gt;You can install new tools from the Kali Linux repositories by utilizing the Katoolin script.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd ~/toolkit&#xA;cd katoolin&#xA;./katoolin.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Installed Tools&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; altdns&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; amass&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; awscli&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; bucket_finder&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CloudFlair&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; commix&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; dirb&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; dirsearch&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; dnsenum&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; dnsrecon&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; dotdotpwn&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; droopescan&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; fierce&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ffuf&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; gobuster&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; gitGraber&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; httprobe&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; joomscan&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Knockpy&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; masscan&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; massdns&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Nikto&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Nmap&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Recon-ng&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; s3recon&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; S3Scanner&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; sqlmap&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; subfinder&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Sublist3r&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; subjack&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; SubOver&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; teh_s3_bucketeers&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; thc-hydra&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; theHarvester&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; tmux&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; virtual-host-discovery&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; wafw00f&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; waybackurls&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; wfuzz&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; whatweb&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; wpscan&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; XSStrike&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; zsh&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Wordlists&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;SecLists&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Tools being added&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Sn1per Framework&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rishabhdeepsingh&#34;&gt;https://github.com/rishabhdeepsingh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/brutalgg&#34;&gt;https://github.com/brutalgg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vimicasa&#34;&gt;https://github.com/vimicasa&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/muokicaleb&#34;&gt;https://github.com/muokicaleb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mcnamee&#34;&gt;https://github.com/mcnamee&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>