<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Dockerfile Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-07T01:34:56Z</updated>
  <subtitle>Daily Trending of Dockerfile in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>JadenKim-dev/9roomthon-node</title>
    <updated>2023-07-07T01:34:56Z</updated>
    <id>tag:github.com,2023-07-07:/JadenKim-dev/9roomthon-node</id>
    <link href="https://github.com/JadenKim-dev/9roomthon-node" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>opendatahub-io/caikit-tgis-serving</title>
    <updated>2023-07-07T01:34:56Z</updated>
    <id>tag:github.com,2023-07-07:/opendatahub-io/caikit-tgis-serving</id>
    <link href="https://github.com/opendatahub-io/caikit-tgis-serving" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Setting up an OpenShift cluster is outside the scope of this document&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Set up Istio: &lt;a href=&#34;https://knative.dev/docs/install/installing-istio&#34;&gt;Istio install doc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Set up KNative Serving: &lt;a href=&#34;https://knative.dev/docs/install/yaml-install/serving/install-serving-with-yaml/&#34;&gt;Knative Serving install doc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install Cert Manager: &lt;a href=&#34;https://cert-manager.io/docs/installation/&#34;&gt;Cert Manager install doc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install KServe:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl apply -f https://github.com/kserve/kserve/releases/download/v0.10.0/kserve.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Setting up Caikit&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Set up servingruntime&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The following servingruntime configures caikit&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;oc apply -f caikit-servingruntime.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you have the ability to create inference services for caikit format models&lt;/p&gt; &#xA;&lt;h2&gt;Converting Model Using Caikit-NLP&lt;/h2&gt; &#xA;&lt;p&gt;Caikit does not have the ability to load generic models, but they can be converted (mostly) from existing HuggingFace models&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Ensure git/git-lfs is installed&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;yum -y install git git-lfs&#xA;git lfs install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Clone given model (note that the git repo for flan-t5-xl requires roughly 64Gb of storage)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://huggingface.co/google/flan-t5-xl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;An alternative method that may be a bit smaller of a download&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import transformers&#xA;&#xA;pipeline = transformers.pipeline(model=&#34;google/flan-tf-xl&#34;)&#xA;&#xA;# Model files will be under ~/.cache/huggingface&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create virtualenv&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 -m virtualenv venv&#xA;source venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Clone caikit-nlp and install&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/Xaenalt/caikit-nlp&#xA;pip install ./caikit-nlp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Convert model&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import caikit_nlp&#xA;&#xA;base_model_path = &#34;flan-t5-xl&#34;&#xA;saved_model_path = &#34;flan-t5-xl-caikit&#34;&#xA;&#xA;# This step imports the model into caikit_nlp and configures in caikit format&#xA;model = caikit_nlp.text_generation.TextGeneration.bootstrap(model_path)&#xA;&#xA;# This saves the model out to disk in caikit format. It will consist of a directory with a config.yml and an artifacts directory&#xA;model.save(model_path=model_save_path)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Inference with Caikit-Serving&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create inferenceservice&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Edit the yaml to include the storage path of the caikit-format model&#xA;&#xA;oc apply -f caikit-isvc.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Determine endpoint&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;oc get isvc&#xA;&#xA;# Take note of the URL, it will be of the format: isvc-name.project.apps.cluster-name.openshiftapps.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Use gRPC to do inference&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# -insecure because the cert is self-signed in this demo environment&#xA;# The header mm-model-id is the name of the model loaded in caikit, named the same as the directory the caikit model resides in&#xA;&#xA;grpcurl -insecure -d &#39;{&#34;text&#34;: &#34;At what temperature does liquid Nitrogen boil?&#34;}&#39; -H &#34;mm-model-id: flan-t5-xl-caikit&#34; isvc-name.project.apps.cluster-name.openshiftapps.com:443 caikit.runtime.Nlp.NlpService/TextGenerationTaskPredict&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output will be similar to (may not be identical, and like sample output may be incorrect):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;generated_token_count&#34;: &#34;20&#34;,&#xA;  &#34;text&#34;: &#34; The boiling point of Nitrogen is about -78.0Â°C, which is the boiling point of&#34;,&#xA;  &#34;stop_reason&#34;: &#34;MAX_TOKENS&#34;,&#xA;  &#34;producer_id&#34;: {&#xA;    &#34;name&#34;: &#34;Text Generation&#34;,&#xA;    &#34;version&#34;: &#34;0.1.0&#34;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>