<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Dockerfile Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-05T01:34:29Z</updated>
  <subtitle>Daily Trending of Dockerfile in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>anibali/docker-pytorch</title>
    <updated>2023-07-05T01:34:29Z</updated>
    <id>tag:github.com,2023-07-05:/anibali/docker-pytorch</id>
    <link href="https://github.com/anibali/docker-pytorch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Docker image for PyTorch&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PyTorch Docker image&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/anibali/pytorch/&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/image-size/anibali/pytorch/latest&#34; alt=&#34;Docker image version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/anibali/pytorch/&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/anibali/pytorch&#34; alt=&#34;Docker image pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/anibali/pytorch/&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/v/anibali/pytorch/latest&#34; alt=&#34;Docker image size&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Ubuntu + PyTorch + CUDA (optional)&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;In order to use this image you must have Docker Engine installed. Instructions for setting up Docker Engine are &lt;a href=&#34;https://docs.docker.com/engine/installation/&#34;&gt;available on the Docker website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;CUDA requirements&lt;/h3&gt; &#xA;&lt;p&gt;If you have a CUDA-compatible NVIDIA graphics card, you can use a CUDA-enabled version of the PyTorch image to enable hardware acceleration. I have only tested this in Ubuntu Linux.&lt;/p&gt; &#xA;&lt;p&gt;Firstly, ensure that you install the appropriate NVIDIA drivers. On Ubuntu, I&#39;ve found that the easiest way of ensuring that you have the right version of the drivers set up is by installing a version of CUDA &lt;em&gt;at least as new as the image you intend to use&lt;/em&gt; via &lt;a href=&#34;https://developer.nvidia.com/cuda-downloads&#34;&gt;the official NVIDIA CUDA download page&lt;/a&gt;. As an example, if you intend on using the &lt;code&gt;cuda-10.1&lt;/code&gt; image then setting up CUDA 10.1 or CUDA 10.2 should ensure that you have the correct graphics drivers.&lt;/p&gt; &#xA;&lt;p&gt;You will also need to install the NVIDIA Container Toolkit to enable GPU device access within Docker containers. This can be found at &lt;a href=&#34;https://github.com/NVIDIA/nvidia-docker&#34;&gt;NVIDIA/nvidia-docker&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Prebuilt images&lt;/h2&gt; &#xA;&lt;p&gt;Prebuilt images are available on Docker Hub under the name &lt;a href=&#34;https://hub.docker.com/r/anibali/pytorch/&#34;&gt;anibali/pytorch&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For example, you can pull an image with PyTorch 2.0.0 and CUDA 11.8 using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker pull anibali/pytorch:2.0.0-cuda11.8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Running PyTorch scripts&lt;/h3&gt; &#xA;&lt;p&gt;It is possible to run PyTorch programs inside a container using the &lt;code&gt;python3&lt;/code&gt; command. For example, if you are within a directory containing some PyTorch project with entrypoint &lt;code&gt;main.py&lt;/code&gt;, you could run it with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run --rm -it --init \&#xA;  --gpus=all \&#xA;  --ipc=host \&#xA;  --user=&#34;$(id -u):$(id -g)&#34; \&#xA;  --volume=&#34;$PWD:/app&#34; \&#xA;  anibali/pytorch python3 main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here&#39;s a description of the Docker command-line options shown above:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--gpus=all&lt;/code&gt;: Required if using CUDA, optional otherwise. Passes the graphics cards from the host to the container. You can also more precisely control which graphics cards are exposed using this option (see documentation at &lt;a href=&#34;https://github.com/NVIDIA/nvidia-docker&#34;&gt;https://github.com/NVIDIA/nvidia-docker&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--ipc=host&lt;/code&gt;: Required if using multiprocessing, as explained at &lt;a href=&#34;https://github.com/pytorch/pytorch#docker-image&#34;&gt;https://github.com/pytorch/pytorch#docker-image&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--user=&#34;$(id -u):$(id -g)&#34;&lt;/code&gt;: Sets the user inside the container to match your user and group ID. Optional, but is useful for writing files with correct ownership.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--volume=&#34;$PWD:/app&#34;&lt;/code&gt;: Mounts the current working directory into the container. The default working directory inside the container is &lt;code&gt;/app&lt;/code&gt;. Optional.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Running graphical applications&lt;/h3&gt; &#xA;&lt;p&gt;If you are running on a Linux host, you can get code running inside the Docker container to display graphics using the host X server (this allows you to use OpenCV&#39;s imshow, for example). Here we describe a quick-and-dirty (but INSECURE) way of doing this. For a more comprehensive guide on GUIs and Docker check out &lt;a href=&#34;http://wiki.ros.org/docker/Tutorials/GUI&#34;&gt;http://wiki.ros.org/docker/Tutorials/GUI&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;On the host run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo xhost +local:root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can revoke these access permissions later with &lt;code&gt;sudo xhost -local:root&lt;/code&gt;. Now when you run a container make sure you add the options &lt;code&gt;-e &#34;DISPLAY&#34;&lt;/code&gt; and &lt;code&gt;--volume=&#34;/tmp/.X11-unix:/tmp/.X11-unix:rw&#34;&lt;/code&gt;. This will provide the container with your X11 socket for communication and your display ID. Here&#39;s an example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run --rm -it --init \&#xA;  --gpus=all \&#xA;  -e &#34;DISPLAY&#34; --volume=&#34;/tmp/.X11-unix:/tmp/.X11-unix:rw&#34; \&#xA;  anibali/pytorch python3 -c &#34;import tkinter; tkinter.Tk().mainloop()&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Deriving your own images&lt;/h3&gt; &#xA;&lt;p&gt;The recommended way of adding additional dependencies to an image is to create your own Dockerfile using one of the PyTorch images from this project as a base.&lt;/p&gt; &#xA;&lt;p&gt;For example, let&#39;s say that you require OpenCV and wish to work with PyTorch 2.0.0. You can create your own Dockerfile using &lt;code&gt;anibali/pytorch:2.0.0-cuda11.8-ubuntu22.04&lt;/code&gt; as the base image and install OpenCV using additional build steps:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;FROM anibali/pytorch:2.0.0-cuda11.8-ubuntu22.04&#xA;&#xA;# Set up time zone.&#xA;ENV TZ=UTC&#xA;RUN sudo ln -snf /usr/share/zoneinfo/$TZ /etc/localtime&#xA;&#xA;# Install system libraries required by OpenCV.&#xA;RUN sudo apt-get update \&#xA; &amp;amp;&amp;amp; sudo apt-get install -y libgl1-mesa-glx libgtk2.0-0 libsm6 libxext6 \&#xA; &amp;amp;&amp;amp; sudo rm -rf /var/lib/apt/lists/*&#xA;&#xA;# Install OpenCV from PyPI.&#xA;RUN pip install opencv-python==4.5.1.48&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Development and contributing&lt;/h2&gt; &#xA;&lt;p&gt;The Dockerfiles in the &lt;code&gt;dockerfiles/&lt;/code&gt; directory are automatically generated by the &lt;code&gt;manager.py&lt;/code&gt; script using details in &lt;code&gt;images.yml&lt;/code&gt; and the templates in &lt;code&gt;templates/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s an example workflow illustrating how to create a new Dockerfile.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;(Optional) Create a new template file in &lt;code&gt;templates/&lt;/code&gt; if none of the existing ones are appropriate.&lt;/li&gt; &#xA; &lt;li&gt;Create a new entry in &lt;code&gt;images.yml&lt;/code&gt; (see the existing entries for examples).&lt;/li&gt; &#xA; &lt;li&gt;Generate the Dockerfile by running &lt;code&gt;python manager.py&lt;/code&gt;. A new directory containing the Dockerfile will be created in &lt;code&gt;dockerfiles/&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Build the generated Dockerfile and test that it works. You can stop here if you are creating an image for your own use.&lt;/li&gt; &#xA; &lt;li&gt;(Optional) Submit a PR if you think that your new image might be useful for others, and it will be considered for publication.&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
</feed>