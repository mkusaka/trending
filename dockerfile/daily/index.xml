<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Dockerfile Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-14T01:32:10Z</updated>
  <subtitle>Daily Trending of Dockerfile in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>tmm1/flyapp-mastodon</title>
    <updated>2022-11-14T01:32:10Z</updated>
    <id>tag:github.com,2022-11-14:/tmm1/flyapp-mastodon</id>
    <link href="https://github.com/tmm1/flyapp-mastodon" rel="alternate"></link>
    <summary type="html">&lt;p&gt;mastodon on fly.io&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Mastodon on fly.io&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mastodon/mastodon&#34;&gt;Mastodon&lt;/a&gt; is a free, open-source social network server based on ActivityPub.&lt;/p&gt; &#xA;&lt;p&gt;The Mastodon server is implemented a rails app, which relies on postgres and redis. It uses sidekiq for background jobs, along with a separate nodejs http streaming server.&lt;/p&gt; &#xA;&lt;p&gt;Docker images: &lt;a href=&#34;https://hub.docker.com/r/tootsuite/mastodon/&#34;&gt;https://hub.docker.com/r/tootsuite/mastodon/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Dockerfile: &lt;a href=&#34;https://github.com/mastodon/mastodon/raw/main/Dockerfile&#34;&gt;https://github.com/mastodon/mastodon/blob/main/Dockerfile&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;docker-compose.yml: &lt;a href=&#34;https://github.com/mastodon/mastodon/raw/main/docker-compose.yml&#34;&gt;https://github.com/mastodon/mastodon/blob/main/docker-compose.yml&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;h4&gt;App&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ fly apps create --region iad --name mastodon&#xA;$ fly scale memory 512 # rails needs more than 256mb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Secrets&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ SECRET_KEY_BASE=$(docker run --rm -it tootsuite/mastodon:latest bin/rake secret)&#xA;$ OTP_SECRET=$(docker run --rm -it tootsuite/mastodon:latest bin/rake secret)&#xA;$ fly secrets set OTP_SECRET=$OTP_SECRET SECRET_KEY_BASE=$SECRET_KEY_BASE&#xA;$ docker run --rm -e OTP_SECRET=$OTP_SECRET -e SECRET_KEY_BASE=$SECRET_KEY_BASE -it tootsuite/mastodon:latest bin/rake mastodon:webpush:generate_vapid_key | fly secrets import&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Redis server&lt;/h4&gt; &#xA;&lt;p&gt;Redis is used to store the home/list feeds, along with the sidekiq queue information. The feeds can be regenerated using &lt;code&gt;tootctl&lt;/code&gt;, so persistence is &lt;a href=&#34;https://docs.joinmastodon.org/admin/backups/#failure&#34;&gt;not strictly necessary&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ fly apps create --region iad --name mastodon-redis&#xA;$ fly volumes create -c fly.redis.toml --region iad mastodon_redis&#xA;$ fly deploy --config fly.redis.toml --build-target redis-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Storage (user uploaded photos and videos)&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;fly.toml&lt;/code&gt; uses a &lt;code&gt;[mounts]&lt;/code&gt; section to connect the &lt;code&gt;/opt/mastodon/public/system&lt;/code&gt; folder to a persistent volume.&lt;/p&gt; &#xA;&lt;p&gt;Create that volume below, or remove the &lt;code&gt;[mounts]&lt;/code&gt; section and uncomment &lt;code&gt;[env] &amp;gt; S3_ENABLED&lt;/code&gt; for S3 storage.&lt;/p&gt; &#xA;&lt;h5&gt;Option 1: Local volume&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ fly volumes create --region iad mastodon_uploads&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Option 2: S3, etc&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ fly secrets set AWS_ACCESS_KEY_ID=xxx AWS_SECRET_ACCESS_KEY=yyy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/mastodon/mastodon/raw/5ba46952af87e42a64962a34f7ec43bc710bdcaf/lib/tasks/mastodon.rake#L137&#34;&gt;lib/tasks/mastodon.rake&lt;/a&gt; for how to change your &lt;code&gt;[env]&lt;/code&gt; section for Wasabi, Minio or Google Cloud Storage.&lt;/p&gt; &#xA;&lt;h4&gt;Postgres database&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ fly pg create --region iad --name mastodon-pg&#xA;$ fly pg attach --postgres-app mastodon-pg&#xA;$ fly deploy -c fly.setup.toml # run `rails db:setup`&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Deploy&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ fly deploy&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>jenkinsci/docker-agent</title>
    <updated>2022-11-14T01:32:10Z</updated>
    <id>tag:github.com,2022-11-14:/jenkinsci/docker-agent</id>
    <link href="https://github.com/jenkinsci/docker-agent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Base Docker image for Jenkins Agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Jenkins Agent Docker image&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/jenkinsci/docker?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/jenkinsci/docker.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/jenkinsci/docker&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jenkinsci/docker-agent&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/jenkinsci/docker-agent?label=GitHub%20stars&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/jenkins/agent/&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/jenkins/agent.svg?sanitize=true&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jenkinsci/docker-agent/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/jenkinsci/docker-agent.svg?label=changelog&#34; alt=&#34;GitHub release&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a base image for Docker, which includes JDK and the Jenkins agent executable (agent.jar). This executable is an instance of the &lt;a href=&#34;https://github.com/jenkinsci/remoting&#34;&gt;Jenkins Remoting library&lt;/a&gt;. JDK version depends on the image and the platform, see the &lt;em&gt;Configurations&lt;/em&gt; section below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚ùó&lt;/span&gt; &lt;strong&gt;Warning!&lt;/strong&gt; This image used to be published as &lt;a href=&#34;https://hub.docker.com/r/jenkinsci/slave/&#34;&gt;jenkinsci/slave&lt;/a&gt; and &lt;a href=&#34;https://hub.docker.com/r/jenkins/slave/&#34;&gt;jenkins/slave&lt;/a&gt;. These images are now deprecated, use &lt;a href=&#34;https://hub.docker.com/r/jenkins/agent/&#34;&gt;jenkins/agent&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/jenkinsci/docker-agent/releases&#34;&gt;GitHub releases&lt;/a&gt; for versions &lt;code&gt;3.35-1&lt;/code&gt; and above. There is no changelog for previous versions, see the commit history.&lt;/p&gt; &#xA;&lt;p&gt;Jenkins remoting changelogs are available &lt;a href=&#34;https://github.com/jenkinsci/remoting/releases&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;This image is used as the basis for the &lt;a href=&#34;https://github.com/jenkinsci/docker-inbound-agent/&#34;&gt;Docker Inbound Agent&lt;/a&gt; image. In that image, the container is launched externally and attaches to Jenkins.&lt;/p&gt; &#xA;&lt;p&gt;This image may instead be used to launch an agent using the &lt;strong&gt;Launch method&lt;/strong&gt; of &lt;strong&gt;Launch agent via execution of command on the master&lt;/strong&gt;. For example on Linux you can try&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run -i --rm --name agent --init jenkins/agent java -jar /usr/share/jenkins/agent.jar&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;after setting &lt;strong&gt;Remote root directory&lt;/strong&gt; to &lt;code&gt;/home/jenkins/agent&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;or if using Windows Containers&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;docker run -i --rm --name agent --init jenkins/agent:jdk11-windowsservercore-ltsc2019 java -jar C:/ProgramData/Jenkins/agent.jar&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;after setting &lt;strong&gt;Remote root directory&lt;/strong&gt; to &lt;code&gt;C:\Users\jenkins\Agent&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Agent Work Directories&lt;/h3&gt; &#xA;&lt;p&gt;Starting from &lt;a href=&#34;https://github.com/jenkinsci/remoting/raw/master/CHANGELOG.md#38&#34;&gt;Remoting 3.8&lt;/a&gt; there is a support of Work directories, which provides logging by default and change the JAR Caching behavior.&lt;/p&gt; &#xA;&lt;p&gt;Call example for Linux:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run -i --rm --name agent1 --init -v agent1-workdir:/home/jenkins/agent jenkins/agent java -jar /usr/share/jenkins/agent.jar -workDir /home/jenkins/agent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Call example for Windows Containers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;docker run -i --rm --name agent1 --init -v agent1-workdir:C:/Users/jenkins/Work jenkins/agent:jdk11-windowsservercore-ltsc2019 java -jar C:/ProgramData/Jenkins/agent.jar -workDir C:/Users/jenkins/Work&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configurations&lt;/h2&gt; &#xA;&lt;p&gt;The image has several supported configurations, which can be accessed via the following tags:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Linux Images: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;latest&lt;/code&gt; (&lt;code&gt;jdk11&lt;/code&gt;, &lt;code&gt;bullseye-jdk11&lt;/code&gt;, &lt;code&gt;latest-bullseye-jdk11&lt;/code&gt;, &lt;code&gt;latest-jdk11&lt;/code&gt;): Latest version with the newest remoting and Java 11 (based on &lt;code&gt;debian:bullseye-${builddate}&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;alpine&lt;/code&gt; (&lt;code&gt;alpine-jdk11&lt;/code&gt;, &lt;code&gt;latest-alpine&lt;/code&gt;, &lt;code&gt;latest-alpine-jdk11&lt;/code&gt;): Small image based on Alpine Linux (based on &lt;code&gt;alpine:${version}&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;archlinux&lt;/code&gt; (&lt;code&gt;latest-archlinux&lt;/code&gt;, &lt;code&gt;archlinux-jdk11&lt;/code&gt;, &lt;code&gt;latest-archlinux-jdk11&lt;/code&gt;): Image based on Arch Linux with JDK11 (based on &lt;code&gt;archlinux:latest&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;bullseye-jdk17&lt;/code&gt; (&lt;code&gt;jdk17&lt;/code&gt;, &lt;code&gt;latest-bullseye-jdk17&lt;/code&gt;, &lt;code&gt;latest-jdk17&lt;/code&gt;): JDK17 version with the newest remoting (based on &lt;code&gt;debian:bullseye-${builddate}&lt;/code&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;From version 4.11.2, the alpine images are tagged using the alpine OS version as well (i.e. &lt;code&gt;alpine&lt;/code&gt; ==&amp;gt; &lt;code&gt;alpine3.16&lt;/code&gt;, &lt;code&gt;alpine-jdk11&lt;/code&gt; ==&amp;gt; &lt;code&gt;alpine3.16-jdk11&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows Images: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;jdk11-windowsservercore-ltsc2019&lt;/code&gt;: Latest version with the newest remoting and Java 11 (based on &lt;code&gt;eclipse-temurin:11.xxx-jdk-windowsservercore-ltsc2019&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;jdk11-nanoserver-1809&lt;/code&gt;: Latest version with the newest remoting with Windows Nano Server and Java 11 (based on &lt;code&gt;eclipse-temurin:11.xxx-jdk-nanoserver-1809&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;jdk17-windowsservercore-ltsc2019&lt;/code&gt;: Latest version with the newest remoting and Java 17 (based on &lt;code&gt;eclipse-temurin:17.xxx-jdk-windowsservercore-ltsc2019&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;jdk17-nanoserver-1809&lt;/code&gt;: Latest version with the newest remoting with Windows Nano Server and Java 17 (based on &lt;code&gt;eclipse-temurin:17.xxx-jdk-nanoserver-1809&lt;/code&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The file &lt;code&gt;docker-bake.hcl&lt;/code&gt; defines all the configuration for Linux images and their associated tags.&lt;/p&gt; &#xA;&lt;p&gt;There are also versioned tags in DockerHub, and they are recommended for production use. See the full list &lt;a href=&#34;https://hub.docker.com/r/jenkins/agent/tags&#34;&gt;here&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>deemoprobe/kubernetes</title>
    <updated>2022-11-14T01:32:10Z</updated>
    <id>tag:github.com,2022-11-14:/deemoprobe/kubernetes</id>
    <link href="https://github.com/deemoprobe/kubernetes" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Some notes about k8s.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;KubernetesÂü∫Á°Ä‰πãÈ´òÂèØÁî®ÈõÜÁæ§Êê≠Âª∫-kubeadmÊñπÂºè&lt;/h1&gt; &#xA;&lt;h2&gt;ÁéØÂ¢ÉËØ¥Êòé&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ÂÆø‰∏ªÊú∫Á≥ªÁªü: Windows 10&lt;/li&gt; &#xA; &lt;li&gt;ËôöÊãüÊú∫ÁâàÊú¨: VMware¬Æ Workstation 16 Pro&lt;/li&gt; &#xA; &lt;li&gt;IOSÈïúÂÉèÁâàÊú¨: CentOS Linux release 7.9.2009&lt;/li&gt; &#xA; &lt;li&gt;ÈõÜÁæ§Êìç‰ΩúÁî®Êà∑: root&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;CentOS7ËôöÊãüÊú∫ÂÆâË£ÖÂíåÈÖçÁΩÆÈùôÊÄÅIPËØ∑ÂèÇËÄÉÂçöÂÆ¢ÊñáÁ´†Ôºö&lt;a href=&#34;http://www.deemoprobe.com/principle/vmware-workstation%e5%ae%89%e8%a3%85centos7%e5%b9%b6%e9%85%8d%e7%bd%ae%e9%9d%99%e6%80%81ip/&#34;&gt;VMWARE WORKSTATIONÂÆâË£ÖCENTOS7Âπ∂ÈÖçÁΩÆÈùôÊÄÅIP&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ËµÑÊ∫êÂàÜÈÖç&lt;/h2&gt; &#xA;&lt;h3&gt;ÁΩëÊÆµÂàíÂàÜ&lt;/h3&gt; &#xA;&lt;p&gt;KubernetesÈõÜÁæ§ÈúÄË¶ÅËßÑÂàí‰∏â‰∏™ÁΩëÊÆµÔºö&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ÂÆø‰∏ªÊú∫ÁΩëÊÆµÔºöKubernetesÈõÜÁæ§ËäÇÁÇπÁöÑÁΩëÊÆµ&lt;/li&gt; &#xA; &lt;li&gt;PodÁΩëÊÆµÔºöÈõÜÁæ§ÂÜÖPodÁöÑÁΩëÊÆµÔºåÁõ∏ÂΩì‰∫éÂÆπÂô®ÁöÑIP&lt;/li&gt; &#xA; &lt;li&gt;ServiceÁΩëÊÆµÔºöÈõÜÁæ§ÂÜÖÊúçÂä°ÂèëÁé∞‰ΩøÁî®ÁöÑÁΩëÊÆµÔºåserviceÁî®‰∫éÈõÜÁæ§ÂÆπÂô®ÈÄö‰ø°&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Áîü‰∫ßÁéØÂ¢ÉÊ†πÊçÆÁî≥ËØ∑Âà∞ÁöÑIPËµÑÊ∫êËøõË°åÂàÜÈÖçÂç≥ÂèØÔºåÂéüÂàôÊòØ‰∏â‰∏™ÁΩëÊÆµ‰∏çË¶ÅÊúâ‰∫§Âèâ„ÄÇÊú¨ÊñáËôöÊãüÊú∫ÁªÉ‰π†ÁéØÂ¢ÉIPÂú∞ÂùÄÊÆµÂàÜÈÖçÂ¶Ç‰∏ãÔºö&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ÂÆø‰∏ªÊú∫ÁΩëÊÆµÔºö&lt;code&gt;192.168.43.1/24&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;PodÁΩëÊÆµÔºö&lt;code&gt;172.16.0.0/12&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;ServiceÔºö&lt;code&gt;10.96.0.0/12&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ËäÇÁÇπÂàÜÈÖç&lt;/h3&gt; &#xA;&lt;p&gt;Êú¨Ê¨°ÂÆûÈ™åÈááÁî®3ÁÆ°ÁêÜËäÇÁÇπ2Â∑•‰ΩúËäÇÁÇπÁöÑÈ´òÂèØÁî®KubernetesÈõÜÁæ§Ê®°Âºè:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;k8s-master01/k8s-master02/k8s-master03 ÈõÜÁæ§ÁöÑMasterËäÇÁÇπ&lt;/li&gt; &#xA; &lt;li&gt;‰∏â‰∏™masterËäÇÁÇπÂêåÊó∂ÂÅöetcdÈõÜÁæ§&lt;/li&gt; &#xA; &lt;li&gt;k8s-node01/k8s-node02 ÈõÜÁæ§ÁöÑNodeËäÇÁÇπ&lt;/li&gt; &#xA; &lt;li&gt;k8s-master-vip: 192.168.43.182,ÊòØÂÅöÈ´òÂèØÁî®k8s-master01~3ÁöÑËôöÊãüIP,‰∏çÂç†Áî®Áâ©ÁêÜËµÑÊ∫ê&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;‰∏ªÊú∫ËäÇÁÇπÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;IP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;CPUÊ†∏ÂøÉÊï∞&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ÂÜÖÂ≠òÂ§ßÂ∞è&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Á£ÅÁõòÂ§ßÂ∞è&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;k8s-master-vip&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;192.168.43.182&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;/&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;/&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;k8s-master01&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;192.168.43.183&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;k8s-master02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;192.168.43.184&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;k8s-master03&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;192.168.43.185&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;k8s-node01&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;192.168.43.186&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;k8s-node02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;192.168.43.187&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Êìç‰ΩúÊ≠•È™§&lt;/h2&gt; &#xA;&lt;p&gt;Â∞èÊã¨Âè∑Ê≥®ÈáäËØ¥ÊòéÔºö&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ALL ÊâÄÊúâËäÇÁÇπÈÉΩË¶ÅÊâßË°å&lt;/li&gt; &#xA; &lt;li&gt;Master Âè™ÈúÄË¶ÅÂú®masterËäÇÁÇπ(k8s-master01/k8s-master02/k8s-master03)ÊâßË°å&lt;/li&gt; &#xA; &lt;li&gt;Node Âè™ÈúÄË¶ÅÂú®nodeËäÇÁÇπ(k8s-node01/k8s-node02)ÊâßË°å&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ÂáÜÂ§áÂ∑•‰Ωú(ALL)&lt;/h3&gt; &#xA;&lt;p&gt;Ê∑ªÂä†‰∏ªÊú∫‰ø°ÊÅØ„ÄÅÂÖ≥Èó≠Èò≤ÁÅ´Â¢ô„ÄÅÂÖ≥Èó≠swap„ÄÅÂÖ≥Èó≠SELinux„ÄÅdnsmasq„ÄÅNetworkManager&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ‰ª•k8s-master01‰∏∫‰æã&#xA;[root@k8s-master01 ~]# cat &amp;lt;&amp;lt; EOF &amp;gt;&amp;gt; /etc/hosts&#xA;192.168.43.182    k8s-master-vip&#xA;192.168.43.183    k8s-master01&#xA;192.168.43.184    k8s-master02&#xA;192.168.43.185    k8s-master03&#xA;192.168.43.186    k8s-node01&#xA;192.168.43.187    k8s-node02&#xA;EOF&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Áõ¥Êé•ÊâßË°å‰∏ãÈù¢ÂëΩ‰ª§&#xA;systemctl stop firewalld&#xA;systemctl disable firewalld&#xA;systemctl disable --now dnsmasq&#xA;systemctl disable --now NetworkManager&#xA;&#xA;swapoff -a&#xA;sed -i &#39;/swap/s/^\(.*\)$/#\1/g&#39; /etc/fstab&#xA;&#xA;setenforce 0&#xA;sed -i &#34;s/=enforcing/=disabled/g&#34; /etc/selinux/config&#xA;&#xA;# ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØ/etc/sysconfig/selinuxÊñá‰ª∂ÊòØ/etc/selinux/configÊñá‰ª∂ÁöÑËΩØËøûÊé•ÔºåÁî®sed -iÂëΩ‰ª§‰øÆÊîπËΩØËøûÊé•Êñá‰ª∂ÁöÑËØù‰ºöÁ†¥ÂùèËΩØËøûÊé•Â±ûÊÄßÔºåÂ∞Ü/etc/sysconfig/selinuxÂèò‰∏∫‰∏Ä‰∏™Êñá‰ª∂ÔºåÂç≥‰ΩøËØ•Êñá‰ª∂Ë¢´‰øÆÊîπ‰∫ÜÔºå‰ΩÜÊ∫êÊñá‰ª∂/etc/selinux/configÈÖçÁΩÆÊòØÊ≤°ÂèòÁöÑÔºåÊâÄ‰ª•Êé®ËçêÁõ¥Êé•‰øÆÊîπ/etc/selinux/config‰∏≠ÁöÑÈÖçÁΩÆÔºåË¶Å‰πàÂ∞±Áõ¥Êé•vimÁºñËæëÊñá‰ª∂ÔºàÁºñËæëÊ®°Âºè‰∏ç‰ºö‰øÆÊîπÊñá‰ª∂Â±ûÊÄßÔºâ‰øÆÊîπ‰πüÂèØ‰ª•&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Êõ¥Êñ∞Ê∫êÂπ∂ÂçáÁ∫ßÂÜÖÊ†∏(ALL)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ÈªòËÆ§ÁöÑyumÊ∫êÂ§™ÊÖ¢ÔºåÊõ¥Êñ∞‰∏∫ÈòøÈáåÊ∫êÔºåÂêåÊó∂Áî®sedÂëΩ‰ª§Âà†Èô§ÂåÖÂê´‰∏ãÈù¢‰∏çÈúÄË¶ÅÁöÑ‰∏§‰∏™URLÁöÑË°å&#xA;curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo&#xA;sed -i -e &#39;/mirrors.cloud.aliyuncs.com/d&#39; -e &#39;/mirrors.aliyuncs.com/d&#39; /etc/yum.repos.d/CentOS-Base.repo&#xA;# ÈÖçÁΩÆÈòøÈáå‰∫ëKubernetesÈïúÂÉèÊ∫ê&#xA;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo&#xA;[kubernetes]&#xA;name=Kubernetes&#xA;baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/&#xA;enabled=1&#xA;gpgcheck=1&#xA;repo_gpgcheck=1&#xA;gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg&#xA;       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg&#xA;EOF&#xA;&#xA;# ÂÆâË£ÖÂ∏∏Áî®Â∑•ÂÖ∑ÂåÖÔºàÂú®ÈúÄË¶ÅÊó∂ÂÆâË£Ö‰πüÂèØ‰ª•ÔºåÈÄöÂ∏∏‰∏ÄËµ∑Ë£Ö‰∫ÜÊØîËæÉÁúÅ‰∫ãÔºâ&#xA;yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvk8s-master02 git -y&#xA;&#xA;# ÂçáÁ∫ßÂÜÖÊ†∏Ôºå4.17‰ª•‰∏ãÁöÑÂÜÖÊ†∏cgroupÂ≠òÂú®ÂÜÖÂ≠òÊ≥ÑÊºèÁöÑBUGÔºåÂÖ∑‰ΩìÂàÜÊûêËøáÁ®ãÊµèËßàÂô®Êêú‰∏Ä‰∏ã‚ÄúKubernetesÈõÜÁæ§‰∏∫‰ªÄ‰πàË¶ÅÂçáÁ∫ßÂÜÖÊ†∏‚Äù‰ºöÊúâ‰∏ÄÂ§ßÊ≥¢ÊñáÁ´†&#xA;cd /root&#xA;wget http://193.49.22.109/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-4.19.12-1.el7.elrepo.x86_64.rpm&#xA;wget http://193.49.22.109/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-4.19.12-1.el7.elrepo.x86_64.rpm&#xA;# ÊâÄÊúâËäÇÁÇπÂÆâË£ÖÂÜÖÊ†∏&#xA;cd /root &amp;amp;&amp;amp; yum localinstall -y kernel-ml*&#xA;# ÊâÄÊúâËäÇÁÇπÊõ¥ÊîπÂÜÖÊ†∏ÂêØÂä®È°∫Â∫è&#xA;grub2-set-default  0 &amp;amp;&amp;amp; grub2-mkconfig -o /etc/grub2.cfg&#xA;grubby --args=&#34;user_namespace.enable=1&#34; --update-kernel=&#34;$(grubby --default-kernel)&#34;&#xA;# Ê£ÄÊü•ÈªòËÆ§ÂÜÖÊ†∏ÊòØ‰∏çÊòØ4.19ÔºåÂπ∂ÈáçÂêØËäÇÁÇπ&#xA;grubby --default-kernel&#xA;reboot&#xA;&#xA;# Ê£ÄÊü•ÂÜÖÊ†∏ÊòØ‰∏çÊòØ4.19&#xA;uname -a&#xA;# ÔºàÂèØÈÄâÔºâÂà†Èô§ËÄÅÁâàÊú¨ÁöÑÂÜÖÊ†∏ÔºåÈÅøÂÖç‰ª•ÂêéË¢´ÂçáÁ∫ßÂèñ‰ª£ÈªòËÆ§ÁöÑÂºÄÊú∫4.19ÂÜÖÊ†∏&#xA;rpm -qa | grep kernel&#xA;yum remove -y kernel-3*&#xA;&#xA;# ÂçáÁ∫ßÁ≥ªÁªüËΩØ‰ª∂ÂåÖÔºàÂ¶ÇÊûúË∑≥ËøáÂÜÖÊ†∏ÂçáÁ∫ßÂä†ÂèÇÊï∞ --exclude=kernel*Ôºâ&#xA;yum update -y&#xA;&#xA;# ÂÆâË£ÖIPVSÂÜÖÊ†∏Ê®°ÂùóÔºåÁî±‰∫éIPVSÂú®ËµÑÊ∫êÊ∂àËÄóÂíåÊÄßËÉΩ‰∏äÂùáÂ∑≤ÊòéÊòæ‰ºò‰∫éiptablesÔºåÊâÄ‰ª•Êé®ËçêÂºÄÂêØ&#xA;# ÂÖ∑‰ΩìÂéüÂõ†ÂèØÂèÇËÄÉÂÆòÁΩë‰ªãÁªç https://kubernetes.io/zh/blog/2018/07/09/ipvs-based-in-cluster-load-balancing-deep-dive/&#xA;yum install ipvsadm ipset sysstat conntrack libseccomp -y&#xA;# Âä†ËΩΩÊ®°ÂùóÔºåÊúÄÂêé‰∏ÄÊù°4.18‰ª•‰∏ãÂÜÖÊ†∏‰ΩøÁî®nf_conntrack_ipv4Ôºå4.19Â∑≤Êîπ‰∏∫nf_conntrack&#xA;modprobe -- ip_vs&#xA;modprobe -- ip_vs_rr&#xA;modprobe -- ip_vs_wrr&#xA;modprobe -- ip_vs_sh&#xA;modprobe -- nf_conntrack&#xA;# ÁºñÂÜôÂèÇÊï∞Êñá‰ª∂&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/modules-load.d/ipvs.conf &#xA;ip_vs&#xA;ip_vs_lc&#xA;ip_vs_wlc&#xA;ip_vs_rr&#xA;ip_vs_wrr&#xA;ip_vs_lblc&#xA;ip_vs_lblcr&#xA;ip_vs_dh&#xA;ip_vs_sh&#xA;ip_vs_fo&#xA;ip_vs_nq&#xA;ip_vs_sed&#xA;ip_vs_ftp&#xA;ip_vs_sh&#xA;nf_conntrack&#xA;ip_tables&#xA;ip_set&#xA;xt_set&#xA;ipt_set&#xA;ipt_rpfilter&#xA;ipt_REJECT&#xA;ipip&#xA;EOF&#xA;# Âä†ËΩΩ&#xA;systemctl enable --now systemd-modules-load.service&#xA;# Ëá™ÂÆö‰πâÂÜÖÊ†∏ÂèÇÊï∞ÈÖçÁΩÆÊñá‰ª∂&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/sysctl.d/kubernetes.conf&#xA;net.ipv4.ip_forward = 1&#xA;net.bridge.bridge-nf-call-iptables = 1&#xA;net.bridge.bridge-nf-call-ip6tables = 1&#xA;fs.may_detach_mounts = 1&#xA;net.ipv4.conf.all.route_localnet = 1&#xA;vm.overcommit_memory=1&#xA;vm.panic_on_oom=0&#xA;fs.inotify.max_user_watches=89100&#xA;fs.file-max=52706963&#xA;fs.nr_open=52706963&#xA;net.netfilter.nf_conntrack_max=2310720&#xA;net.ipv4.tcp_keepalive_time = 600&#xA;net.ipv4.tcp_keepalive_probes = 3&#xA;net.ipv4.tcp_keepalive_intvl =15&#xA;net.ipv4.tcp_max_tw_buckets = 36000&#xA;net.ipv4.tcp_tw_reuse = 1&#xA;net.ipv4.tcp_max_orphans = 327680&#xA;net.ipv4.tcp_orphan_retries = 3&#xA;net.ipv4.tcp_syncookies = 1&#xA;net.ipv4.tcp_max_syn_backlog = 16384&#xA;net.ipv4.ip_conntrack_max = 65536&#xA;net.ipv4.tcp_max_syn_backlog = 16384&#xA;net.ipv4.tcp_timestamps = 0&#xA;net.core.somaxconn = 16384&#xA;EOF&#xA;# Âä†ËΩΩ&#xA;sysctl --system&#xA;# ÈáçÂêØÊü•ÁúãPIVSÊ®°ÂùóÊòØÂê¶‰æùÊóßÂä†ËΩΩ&#xA;reboot&#xA;lsmod | grep ip_vs&#xA;&#xA;# ÈÖçÁΩÆntpdate,ÂêåÊ≠•ÊúçÂä°Âô®Êó∂Èó¥&#xA;rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm&#xA;yum install ntpdate -y&#xA;# ÂêåÊ≠•Êó∂Âå∫ÂíåÊó∂Èó¥&#xA;ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime&#xA;echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone&#xA;ntpdate time2.aliyun.com&#xA;&#xA;# ÈÖçÁΩÆlimits&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt;&amp;gt; /etc/security/limits.conf&#xA;* soft nofile 655360&#xA;* hard nofile 131072&#xA;* soft nproc 655350&#xA;* hard nproc 655350&#xA;* soft memlock unlimited&#xA;* hard memlock unlimited&#xA;EOF&#xA;&#xA;# ÈÖçÁΩÆÂÖçÂØÜÁôªÂΩï, k8s-master01Âà∞ÂÖ∂‰ªñËäÇÁÇπ&#xA;# ÂÖàÁîüÊàêËÆ§ËØÅÊñá‰ª∂&#xA;ssh-keygen -t rsa&#xA;# Êã∑Ë¥ùÂÖ¨Èí•‰ø°ÊÅØÂà∞ÂÖ∂‰ªñËäÇÁÇπÔºåÂêåÊó∂ËÆ§ËØÅ‰∏ÄÊ¨°ÂêÑ‰∏™ËäÇÁÇπÁöÑrootÂØÜÁ†ÅÔºå‰ª•ÂêéÂ∞±ÂèØ‰ª•ÂÖçÂØÜsshÂà∞ÂÖ∂‰ªñËäÇÁÇπ&#xA;for i in k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i .ssh/id_rsa.pub $i;done&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ÈÉ®ÁΩ≤Docker(ALL)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Âç∏ËΩΩÂ∑≤Â≠òÂú®dockerÔºåÊñ∞Êú∫Âô®ÁöÑËØùËøôÊ≠•ÂèØ‰ª•ÂøΩÁï•&#xA;yum remove -y docker \&#xA;              docker-client \&#xA;              docker-client-latest \&#xA;              docker-common \&#xA;              docker-latest \&#xA;              docker-latest-logrotate \&#xA;              docker-logrotate \&#xA;              docker-engine&#xA;&#xA;yum remove -y docker-ce docker-ce-cli containerd.io&#xA;&#xA;# ËÆæÁΩÆdocker‰ªìÂ∫ì&#xA;yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo&#xA;&#xA;# ÂÆâË£ÖÊúÄÊñ∞ÁâàÊú¨docker&#xA;yum install docker-ce docker-ce-cli containerd.io -y&#xA;&#xA;# ÔºàÂèØÈÄâÔºâÂ¶ÇÊûúÊÉ≥Ë¶ÅÂÆâË£ÖÊåáÂÆöÁâàÊú¨dockerÔºåÂÖàÊü•ËØ¢‰∏Ä‰∏ã„ÄÇÂÆâË£ÖÊåáÂÆöÁâàÊú¨Ôºå‰æãÂ¶Ç20.10.9-3.el7&#xA;yum list docker-ce docker-ce-cli --showduplicates | grep &#34;^doc&#34; | sort -r&#xA;yum install docker-ce-20.10.9-3.el7 docker-ce-cli-20.10.9-3.el7 containerd.io -y&#xA;&#xA;# Âä†ÂÖ•ÂºÄÊú∫ÂêØÂä®Âπ∂ÂêØÂä®&#xA;systemctl enable docker&#xA;systemctl start docker&#xA;&#xA;# ÊµãËØïËøêË°åhello-worldÈïúÂÉèÂπ∂Êü•ÁúãdockerÁâàÊú¨‰ø°ÊÅØ&#xA;docker run hello-world&#xA;docker version&#xA;&#xA;# ÈÖçÁΩÆÈòøÈáådockerÈïúÂÉèÂä†ÈÄüÂô®ÔºåÈòøÈáå‰∫ë(ÁôªÂΩïË¥¶Âè∑--&amp;gt;ÁÇπÂáªÁÆ°ÁêÜÊéßÂà∂Âè∞--&amp;gt;ÊêúÁ¥¢ÂÆπÂô®ÈïúÂÉèÊúçÂä°--&amp;gt;ÈïúÂÉèÂ∑•ÂÖ∑--&amp;gt;ÈïúÂÉèÂä†ÈÄüÂô®--&amp;gt;Â§çÂà∂Âä†ÈÄüÂô®Âú∞ÂùÄ)&#xA;# dockerÊñá‰ª∂È©±Âä®ÊîπÊàê systemd&#xA;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/docker/daemon.json&#xA;{&#xA;  &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],&#xA;  &#34;registry-mirror&#34;: [&#34;https://ynirk4k5.mirror.aliyuncs.com&#34;]&#xA;}&#xA;EOF&#xA;&#xA;# ÈáçÂêØdocker&#xA;systemctl restart docker&#xA;# Â¶ÇÊûúÂêØÂä®Â§±Ë¥•,Âº∫Âà∂Âä†ËΩΩÂÜçÂêØÂä®ËØïËØï&#xA;systemctl reset-failed docker&#xA;systemctl restart docker&#xA;&#xA;# Êü•ÁúãdockerÈÖçÁΩÆ‰ø°ÊÅØ&#xA;docker info&#xA;docker info | grep Driver&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ÂÆâË£Ökubernetes(ALL)&lt;/h3&gt; &#xA;&lt;p&gt;‰∏ÄËà¨kebectlÂú®masterËäÇÁÇπÂÆâË£ÖÂç≥ÂèØ,nodeËäÇÁÇπË£Ö‰∏çË£ÖÂùáÂèØ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Êü•ÁúãÂèØ‰ª•ÂÆâË£ÖÁöÑÁâàÊú¨Âè∑&#xA;yum list kubeadm --showduplicates | sort -r&#xA;# ‰∏çÊåáÂÆöÁâàÊú¨ÁöÑËØùÈªòËÆ§ÂÆâË£ÖÊúÄÊñ∞ÁâàÊú¨ÂÆâË£Ö&#xA;yum install -y kubelet kubeadm kubectl&#xA;# ÊåáÂÆöÁâàÊú¨ËøõË°åÂÆâË£ÖÔºåÂ¶Ç1.22.4&#xA;yum install -y kubelet-1.22.4 kubeadm-1.22.4 kubectl-1.22.4&#xA;# ÈÖçÁΩÆpauseÈïúÂÉè‰ªìÂ∫ìÔºåÈªòËÆ§ÁöÑgcr.ioÂõΩÂÜÖÊó†Ê≥ïËÆøÈóÆÔºåÂèØ‰ª•‰ΩøÁî®ÈòøÈáå‰ªìÂ∫ì&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/sysconfig/kubelet&#xA;KUBELET_EXTRA_ARGS=&#34;--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5&#34;&#xA;EOF&#xA;# ÂÖàÂä†ÂÖ•ÂºÄÊú∫ÂêØÂä®&#xA;systemctl enable kubelet&#xA;# ÂÖà‰∏çÂêØÂä®kubelet,Âõ†‰∏∫‰ºöÂêØÂä®Â§±Ë¥•,ÊèêÁ§∫ÂàùÂßãÂåñÊñá‰ª∂‰∏çÂ≠òÂú®,kubernetesÈõÜÁæ§ÂàùÂßãÂåñÂÆåÊàêÂêé‰ºöÂêØÂä®&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;È´òÂèØÁî®ÁªÑ‰ª∂ÂÆâË£Ö(Master)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ÊâÄÊúâmasterËäÇÁÇπÂÆâË£ÖKeepalivedÂíåhaproxy&#xA;yum install keepalived haproxy -y&#xA;# ‰∏∫ÊâÄÊúâmasterËäÇÁÇπÊ∑ªÂä†haproxyÈÖçÁΩÆÔºåÈÖçÁΩÆÈÉΩ‰∏ÄÊ†∑ÔºåÊ£ÄÊü•ÊúÄÂêé‰∏âË°å‰∏ªÊú∫ÂêçÂíåIPÂú∞ÂùÄÂØπÂ∫î‰∏äÂ∞±Ë°å&#xA;mkdir /etc/haproxy&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/haproxy/haproxy.cfg&#xA;global&#xA;  maxconn  2000&#xA;  ulimit-n  16384&#xA;  log  127.0.0.1 local0 err&#xA;  stats timeout 30s&#xA;&#xA;defaults&#xA;  log global&#xA;  mode  http&#xA;  option  httplog&#xA;  timeout connect 5000&#xA;  timeout client  50000&#xA;  timeout server  50000&#xA;  timeout http-request 15s&#xA;  timeout http-keep-alive 15s&#xA;&#xA;frontend monitor-in&#xA;  bind *:33305&#xA;  mode http&#xA;  option httplog&#xA;  monitor-uri /monitor&#xA;&#xA;frontend k8s-master&#xA;  bind 0.0.0.0:16443&#xA;  bind 127.0.0.1:16443&#xA;  mode tcp&#xA;  option tcplog&#xA;  tcp-request inspect-delay 5s&#xA;  default_backend k8s-master&#xA;&#xA;backend k8s-master&#xA;  mode tcp&#xA;  option tcplog&#xA;  option tcp-check&#xA;  balance roundrobin&#xA;  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100&#xA;  server k8s-master01  192.168.43.183:6443  check&#xA;  server k8s-master02  192.168.43.184:6443  check&#xA;  server k8s-master03  192.168.43.185:6443  check&#xA;EOF&#xA;# keepalivedÈÖçÁΩÆ‰∏ç‰∏ÄÊ†∑ÔºåÊ≥®ÊÑèÂå∫ÂàÜÁΩëÂç°Âêç„ÄÅIPÂú∞ÂùÄÂíåËôöÊãüIPÂú∞ÂùÄ&#xA;# Ê£ÄÊü•ÊúçÂä°Âô®ÁΩëÂç°Âêç&#xA;ip a Êàñ ifconfig&#xA;# k8s-master01 KeepalivedÈÖçÁΩÆ&#xA;mkdir /etc/keepalived&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/keepalived/keepalived.conf&#xA;! Configuration File for keepalived&#xA;global_defs {&#xA;    router_id LVS_DEVEL&#xA;script_user root&#xA;    enable_script_security&#xA;}&#xA;vrrp_script chk_apiserver {&#xA;    script &#34;/etc/keepalived/check_apiserver.sh&#34;&#xA;    interval 5&#xA;    weight -5&#xA;    fall 2  &#xA;rise 1&#xA;}&#xA;vrrp_instance VI_1 {&#xA;    state MASTER&#xA;    interface ens33&#xA;    mcast_src_ip 192.168.43.183&#xA;    virtual_router_id 51&#xA;    priority 101&#xA;    advert_int 2&#xA;    authentication {&#xA;        auth_type PASS&#xA;        auth_pass K8SHA_KA_AUTH&#xA;    }&#xA;    virtual_ipaddress {&#xA;        192.168.43.182&#xA;    }&#xA;    track_script {&#xA;       chk_apiserver&#xA;    }&#xA;}&#xA;EOF&#xA;# k8s-master02 KeepalivedÈÖçÁΩÆ&#xA;mkdir /etc/keepalived&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/keepalived/keepalived.conf&#xA;! Configuration File for keepalived&#xA;global_defs {&#xA;    router_id LVS_DEVEL&#xA;script_user root&#xA;    enable_script_security&#xA;}&#xA;vrrp_script chk_apiserver {&#xA;    script &#34;/etc/keepalived/check_apiserver.sh&#34;&#xA;   interval 5&#xA;    weight -5&#xA;    fall 2  &#xA;rise 1&#xA;}&#xA;vrrp_instance VI_1 {&#xA;    state BACKUP&#xA;    interface ens33&#xA;    mcast_src_ip 192.168.43.184&#xA;    virtual_router_id 51&#xA;    priority 100&#xA;    advert_int 2&#xA;    authentication {&#xA;        auth_type PASS&#xA;        auth_pass K8SHA_KA_AUTH&#xA;    }&#xA;    virtual_ipaddress {&#xA;        192.168.43.182&#xA;    }&#xA;    track_script {&#xA;       chk_apiserver&#xA;    }&#xA;}&#xA;EOF&#xA;# k8s-master03 KeepalivedÈÖçÁΩÆ&#xA;mkdir /etc/keepalived&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/keepalived/keepalived.conf&#xA;! Configuration File for keepalived&#xA;global_defs {&#xA;    router_id LVS_DEVEL&#xA;script_user root&#xA;    enable_script_security&#xA;}&#xA;vrrp_script chk_apiserver {&#xA;    script &#34;/etc/keepalived/check_apiserver.sh&#34;&#xA; interval 5&#xA;    weight -5&#xA;    fall 2  &#xA;rise 1&#xA;}&#xA;vrrp_instance VI_1 {&#xA;    state BACKUP&#xA;    interface ens33&#xA;    mcast_src_ip 192.168.43.185&#xA;    virtual_router_id 51&#xA;    priority 100&#xA;    advert_int 2&#xA;    authentication {&#xA;        auth_type PASS&#xA;        auth_pass K8SHA_KA_AUTH&#xA;    }&#xA;    virtual_ipaddress {&#xA;        192.168.43.182&#xA;    }&#xA;    track_script {&#xA;       chk_apiserver&#xA;    }&#xA;}&#xA;EOF&#xA;# ÊâÄÊúâmasterËäÇÁÇπÈÖçÁΩÆKeepalivedÂÅ•Â∫∑Ê£ÄÊü•ËÑöÊú¨&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/keepalived/check_apiserver.sh &#xA;#!/bin/bash&#xA;err=0&#xA;for k in $(seq 1 3)&#xA;do&#xA;    check_code=$(pgrep haproxy)&#xA;    if [[ $check_code == &#34;&#34; ]]; then&#xA;        err=$(expr $err + 1)&#xA;        sleep 1&#xA;        continue&#xA;    else&#xA;        err=0&#xA;        break&#xA;    fi&#xA;done&#xA;&#xA;if [[ $err != &#34;0&#34; ]]; then&#xA;    echo &#34;systemctl stop keepalived&#34;&#xA;    /usr/bin/systemctl stop keepalived&#xA;    exit 1&#xA;else&#xA;    exit 0&#xA;fi&#xA;EOF&#xA;# Ëµã‰∫àÂèØÊâßË°åÊùÉÈôê&#xA;chmod +x /etc/keepalived/check_apiserver.sh&#xA;# ÂêØÂä®haproxyÂíåKeepalivedÂπ∂Âä†ÂÖ•ÂºÄÊú∫ÂêØÂä®&#xA;systemctl start haproxy&#xA;systemctl start keepalived&#xA;systemctl enable haproxy&#xA;systemctl enable keepalived&#xA;&#xA;# ÊµãËØï‰∏ÄÊ≥¢&#xA;telnet k8s-master-vip 16443&#xA;ping k8s-master-vip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ÈÉ®ÁΩ≤k8s-master(k8s-master01)&lt;/h3&gt; &#xA;&lt;p&gt;Âú®k8s-master01ËäÇÁÇπ‰∏äÊâßË°åÔºå‰∏™Âà´Ê≠•È™§Âú®ÊâÄÊúâmasterËäÇÁÇπÊâßË°åÔºåÂ∑≤Âè¶Ë°åËØ¥ÊòéÔºåÊ≤°ËØ¥ÊòéÁöÑÂùáÊòØÂú®k8s-master01ÊâßË°å„ÄÇ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ÂàõÂª∫ÂàùÂßãÂåñÊñá‰ª∂ÔºåÊ≥®ÊÑèÁâàÊú¨Âè∑ÂíåIPÂØπÂ∫î‰∏äÔºå&#xA;cat &amp;lt;&amp;lt; EOF &amp;gt; kubeadm-config.yaml&#xA;apiVersion: kubeadm.k8s.io/v1beta2&#xA;bootstrapTokens:&#xA;- groups:&#xA;  - system:bootstrappers:kubeadm:default-node-token&#xA;  token: 7t2weq.bjbawausm0jaxury&#xA;  ttl: 24h0m0s&#xA;  usages:&#xA;  - signing&#xA;  - authentication&#xA;kind: InitConfiguration&#xA;localAPIEndpoint:&#xA;  advertiseAddress: 192.168.43.183&#xA;  bindPort: 6443&#xA;nodeRegistration:&#xA;  criSocket: /var/run/dockershim.sock&#xA;  name: k8s-master01&#xA;  taints:&#xA;  - effect: NoSchedule&#xA;    key: node-role.kubernetes.io/master&#xA;---&#xA;apiServer:&#xA;  certSANs:&#xA;  - 192.168.43.182&#xA;  timeoutForControlPlane: 4m0s&#xA;apiVersion: kubeadm.k8s.io/v1beta2&#xA;certificatesDir: /etc/kubernetes/pki&#xA;clusterName: kubernetes&#xA;controlPlaneEndpoint: 192.168.43.182:16443&#xA;controllerManager: {}&#xA;dns:&#xA;  type: CoreDNS&#xA;etcd:&#xA;  local:&#xA;    dataDir: /var/lib/etcd&#xA;imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers&#xA;kind: ClusterConfiguration&#xA;kubernetesVersion: v1.23.0&#xA;networking:&#xA;  dnsDomain: cluster.local&#xA;  podSubnet: 172.16.0.0/12&#xA;  serviceSubnet: 10.96.0.0/12&#xA;scheduler: {}&#xA;EOF&#xA;&#xA;# Êõ¥Êñ∞ÂàùÂßãÂåñÊñá‰ª∂&#xA;kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml&#xA;# Â∞Ünew.yamlÂ§çÂà∂Âà∞ÂÖ∂‰ªñmasterËäÇÁÇπ‰∏ä&#xA;for i in k8s-master02 k8s-master03;do scp new.yaml $i:/root/;done&#xA;&#xA;# ÈïúÂÉèÈ¢Ñ‰∏ãËΩΩÔºåËäÇÁúÅÈõÜÁæ§ÂàùÂßãÂåñÁöÑÊó∂Èó¥ÔºàËøô‰∏ÄÊ≠•Âú®ÊâÄÊúâmasterËäÇÁÇπ‰∏äÊâßË°åÔºâ&#xA;kubeadm config images pull --config /root/new.yaml&#xA;# ÊâßË°åÁªìÊûúÂ¶Ç‰∏ã&#xA;[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.23.0&#xA;[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.23.0&#xA;[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.23.0&#xA;[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.23.0&#xA;[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&#xA;[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.1-0&#xA;[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.6&#xA;&#xA;# master01ÂàùÂßãÂåñÔºåÂàùÂßãÂåñÂÆåÊàêÂêéÔºåÂä†ÂÖ•ÂÖ∂‰ªñËäÇÁÇπÂç≥ÂèØ&#xA;kubeadm init --config /root/new.yaml  --upload-certs&#xA;# ÂàùÂßãÂåñÂ¶ÇÊûúÂ§±Ë¥•ÔºåÂèØÁî®‰∏ãÈù¢ÂëΩ‰ª§Ê∏ÖÈô§ÂàùÂßãÂåñ‰ø°ÊÅØÔºåÁÑ∂ÂêéÂÜçÊ¨°Â∞ùËØïÂàùÂßãÂåñ&#xA;kubeadm reset -f ; ipvsadm --clear  ; rm -rf ~/.kube&#xA;# ÂàùÂßãÂåñÊàêÂäüÁ±ª‰ºº‰∫é‰∏ãÈù¢ËæìÂá∫Ôºå‰øùÂ≠òÂ•ΩËøô‰∫õ‰ø°ÊÅØ&#xA;...&#xA;Your Kubernetes control-plane has initialized successfully!&#xA;&#xA;To start using your cluster, you need to run the following as a regular user:&#xA;&#xA;  mkdir -p $HOME/.kube&#xA;  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config&#xA;  sudo chown $(id -u):$(id -g) $HOME/.kube/config&#xA;&#xA;Alternatively, if you are the root user, you can run:&#xA;&#xA;  export KUBECONFIG=/etc/kubernetes/admin.conf&#xA;&#xA;You should now deploy a pod network to the cluster.&#xA;Run &#34;kubectl apply -f [podnetwork].yaml&#34; with one of the options listed at:&#xA;  https://kubernetes.io/docs/concepts/cluster-administration/addons/&#xA;&#xA;You can now join any number of the control-plane node running the following command on each as root:&#xA;&#xA;  kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury \&#xA;        --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b \&#xA;        --control-plane --certificate-key 9a2e86718fceba001c96e503e9df47db3a645d4917bf783decaea9c5d0a726ed&#xA;&#xA;Please note that the certificate-key gives access to cluster sensitive data, keep it secret!&#xA;As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use&#xA;&#34;kubeadm init phase upload-certs --upload-certs&#34; to reload certs afterward.&#xA;&#xA;Then you can join any number of worker nodes by running the following on each as root:&#xA;&#xA;kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury \&#xA;        --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b&#xA;&#xA;# ÊåâÁÖßÊèêÁ§∫ÔºåÂ¶ÇÊûú‰Ω†ÊòØÊôÆÈÄöÁî®Êà∑Âú®Êìç‰ΩúÔºåÊâßË°å‰∏Ä‰∏ã‰∏ãÈù¢Âá†Êù°&#xA;mkdir -p $HOME/.kube&#xA;sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config&#xA;sudo chown $(id -u):$(id -g) $HOME/.kube/config&#xA;# Â¶ÇÊûúÊòØrootÁî®Êà∑Âú®Êìç‰ΩúÂàùÂßãÂåñÔºåÊâßË°å‰∏ãÈù¢‰∏ÄÊù°Âç≥ÂèØ&#xA;export KUBECONFIG=/etc/kubernetes/admin.conf&#xA;&#xA;# Êü•ÁúãdockerÈïúÂÉè,ÂèØ‰ª•ÁúãÂà∞kube..ÂíåetcdÁ≠âÈïúÂÉè&#xA;docker images&#xA;&#xA;# TokenËøáÊúüÂêéÁîüÊàêÊñ∞ÁöÑtokenÔºàÊ≤°ÊèêÁ§∫ËøáÊúü‰∏ãÈù¢‰∏§Ê≠•Â∞±‰∏çÁî®ÁÆ°‰∫ÜÔºâ&#xA;kubeadm token create --print-join-command&#xA;# MasterÈúÄË¶ÅÁîüÊàê--certificate-key&#xA;kubeadm init phase upload-certs  --upload-certs&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ÂÖ∂‰ªñËäÇÁÇπÂä†ÂÖ•ÈõÜÁæ§&lt;/h3&gt; &#xA;&lt;p&gt;ÂÖ∂‰ªñmasterËäÇÁÇπÂä†ÂÖ•k8s-master01&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Ê†πÊçÆkubeadm initÊèêÁ§∫ÁöÑtoken&#xA;kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury \&#xA;        --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b \&#xA;        --control-plane --certificate-key 9a2e86718fceba001c96e503e9df47db3a645d4917bf783decaea9c5d0a726ed&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;nodeËäÇÁÇπÂä†ÂÖ•k8s-master01&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Ê†πÊçÆkubeadm initÊèêÁ§∫ÁöÑtoken&#xA;kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury \&#xA;        --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# master01‰∏äÊü•ÁúãÂä†ÂÖ•ÂêéÁöÑËäÇÁÇπ‰ø°ÊÅØÔºåÂõ†‰∏∫ËøòÊú™ÈÖçÁΩÆCNIÊèí‰ª∂ÔºåÊâÄ‰ª•node‰πãÈó¥ÈÄö‰ø°ËøòÊú™ÊâìÈÄö&#xA;[root@k8s-master01 ~]# kubectl get no&#xA;NAME           STATUS     ROLES                  AGE     VERSION&#xA;k8s-master01   NotReady   control-plane,master   19m     v1.23.0&#xA;k8s-master02   NotReady   control-plane,master   3m39s   v1.23.0&#xA;k8s-master03   NotReady   control-plane,master   3m35s   v1.23.0&#xA;k8s-node01     NotReady   &amp;lt;none&amp;gt;                 2m21s   v1.23.0&#xA;k8s-node02     NotReady   &amp;lt;none&amp;gt;                 2m21s   v1.23.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ÈÖçÁΩÆcalicoÁΩëÁªú&lt;/h3&gt; &#xA;&lt;p&gt;Âú®k8s-master01ËäÇÁÇπ‰∏äÊâßË°å&lt;/p&gt; &#xA;&lt;p&gt;ÁΩëÁªúÊñπÊ°à‰πüÂèØ‰ª•ÈÄâÊã©ÂÖ∂‰ªñ(‰æãÂ¶ÇÔºöflannelÁ≠â)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ÂÖàÊääÊâÄÈúÄÁöÑÈÖçÁΩÆÊñá‰ª∂‰ªéGitHubÊãâ‰∏ãÊù•&#xA;git clone https://github.com/deemoprobe/k8s-ha-install.git&#xA;# ÂàáÊç¢Âà∞1.23ÂàÜÊîØÂπ∂ËøõÂÖ•calicoÊñá‰ª∂Â§π&#xA;cd /root/k8s-ha-install &amp;amp;&amp;amp; git checkout manual-installation-v1.23.x &amp;amp;&amp;amp; cd calico/&#xA;# ÊõøÊç¢‰∏Ä‰∏ãPODÁΩëÊÆµ&#xA;POD_SUBNET=`cat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-cidr= | awk -F= &#39;{print $NF}&#39;`&#xA;sed -i &#34;s#POD_CIDR#${POD_SUBNET}#g&#34; calico.yaml&#xA;# Â∫îÁî®calicoÊèí‰ª∂&#xA;kubectl apply -f calico.yaml&#xA;# ÈõÜÁæ§ËäÇÁÇπÂùáÂ∑≤Â§Ñ‰∫éReadyÁä∂ÊÄÅ&#xA;[root@k8s-master01 calico]# kubectl get no&#xA;NAME           STATUS   ROLES                  AGE   VERSION&#xA;k8s-master01   Ready    control-plane,master   29m   v1.23.0&#xA;k8s-master02   Ready    control-plane,master   13m   v1.23.0&#xA;k8s-master03   Ready    control-plane,master   13m   v1.23.0&#xA;k8s-node01     Ready    &amp;lt;none&amp;gt;                 11m   v1.23.0&#xA;k8s-node02     Ready    &amp;lt;none&amp;gt;                 11m   v1.23.0&#xA;# Êü•Áúãcalico PodÊòØÂê¶ÈÉΩÊ≠£Â∏∏&#xA;kubectl get pod -A&#xA;# Â¶ÇÊûú‰∏çÊ≠£Â∏∏ÔºåÂèØ‰ª•ÊéíÊü•‰∏Ä‰∏ãÔºå‰∏ÄËà¨ÊòØÈïúÂÉèÊãâÂèñÈóÆÈ¢òÔºåÂ§öÁ≠âÂæÖÂá†ÂàÜÈíüÂç≥ÂèØÔºå‰πüÂèØ‰ª•Ê†πÊçÆÊä•ÈîôÁÆÄÂçïÂ§ÑÁêÜ‰∏Ä‰∏ã&#xA;kubectl describe pod XXX -n kube-system&#xA;# ÊØîÂ¶ÇÊàëËøôÈáåÊúâ‰∏™podÂ§Ñ‰∫épendingÁä∂ÊÄÅÔºåÊü•Áúã‰∏Ä‰∏ãÂéüÂõ†&#xA;[root@k8s-master01 calico]# kubectl get pod -A&#xA;NAMESPACE     NAME                                       READY   STATUS    RESTARTS      AGE&#xA;...&#xA;kube-system   calico-typha-8445487f56-hx8w9              1/1     Running   0             11m&#xA;kube-system   calico-typha-8445487f56-mh6tp              0/1     Pending   0             11m&#xA;kube-system   calico-typha-8445487f56-pxthb              1/1     Running   0             11m&#xA;...&#xA;# ÂèØ‰ª•ÁúãÂà∞ÊèêÁ§∫ËØ¥2‰∏™nodeËäÇÁÇπÊó†Ê≥ïÊèê‰æõË∂≥ÈáèÁöÑpodÁ´ØÂè£ÂàÜÈÖçÈúÄÊ±ÇÔºåËÄå‰∏îÊèêÁ§∫masterËäÇÁÇπËÆæÁΩÆ‰∫ÜÊ±°ÁÇπ&#xA;[root@k8s-master01 calico]# kubectl describe pod calico-typha-8445487f56-mh6tp -n kube-system&#xA;...&#xA;Events:&#xA;  Type     Reason            Age                    From               Message&#xA;  ----     ------            ----                   ----               -------&#xA;  Warning  FailedScheduling  11m                    default-scheduler  0/5 nodes are available: 2 node(s) had taint {node.kubernetes.io/not-ready: }, that the pod didn&#39;t tolerate, 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn&#39;t tolerate.&#xA;  Warning  FailedScheduling  10m                    default-scheduler  0/5 nodes are available: 1 node(s) didn&#39;t have free ports for the requested pod ports, 1 node(s) had taint {node.kubernetes.io/not-ready: }, that the pod didn&#39;t tolerate, 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn&#39;t tolerate.&#xA;  Warning  FailedScheduling  10m                    default-scheduler  0/5 nodes are available: 2 node(s) didn&#39;t have free ports for the requested pod ports, 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn&#39;t tolerate.&#xA;  Warning  FailedScheduling  8m24s (x1 over 9m24s)  default-scheduler  0/5 nodes are available: 2 node(s) didn&#39;t have free ports for the requested pod ports, 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn&#39;t tolerate.&#39;&#xA;# Á°ÆËÆ§‰∏Ä‰∏ãÔºåÂèØ‰ª•ÁúãÂà∞‰∏â‰∏™masterËäÇÁÇπÊâì‰∏ä‰∫Ü‰∏çÂèØË∞ÉÂ∫¶podÁöÑÊ±°ÁÇπ&#xA;[root@k8s-master01 calico]# for i in k8s-master01 k8s-master02 k8s-master03;do kubectl describe node $i | grep -i taint;done&#xA;Taints:             node-role.kubernetes.io/master:NoSchedule&#xA;Taints:             node-role.kubernetes.io/master:NoSchedule&#xA;Taints:             node-role.kubernetes.io/master:NoSchedule&#xA;# Áî±‰∫éÊòØÁªÉ‰π†ÁéØÂ¢ÉÔºåÊàëÂ∞±Êää‰∏çÂèØË∞ÉÂ∫¶ÁöÑÊ±°ÁÇπÂèñÊ∂à‰∫ÜÔºåÂ¶ÇÊûúÊòØÁîü‰∫ßÁéØÂ¢ÉÔºåÂª∫ËÆÆÊâ©ÂÆπnodeÂ∑•‰ΩúËäÇÁÇπÊù•ÂÆûÁé∞Ë∂≥ÈáèÁöÑÁ´ØÂè£ÂàÜÈÖç&#xA;[root@k8s-master01 calico]# for i in k8s-master01 k8s-master02 k8s-master03;do kubectl taint node $i node-role.kubernetes.io/master:NoSchedule-;done&#xA;node/k8s-master01 untainted&#xA;node/k8s-master02 untainted&#xA;node/k8s-master03 untainted&#xA;# Ê±°ÁÇπÊàêÂäüÂèñÊ∂à&#xA;[root@k8s-master01 calico]# for i in k8s-master01 k8s-master02 k8s-master03;do kubectl describe node $i | grep -i taint;done&#xA;Taints:             &amp;lt;none&amp;gt;&#xA;Taints:             &amp;lt;none&amp;gt;&#xA;Taints:             &amp;lt;none&amp;gt;&#xA;# ÂÜçÊü•ÁúãÂàöÊâçÂ§Ñ‰∫épendingÁöÑpodÂèëÁé∞Â∑≤ÁªèÂ§Ñ‰∫érunningÁä∂ÊÄÅ‰∫Ü&#xA;[root@k8s-master01 calico]# kubectl get po -A | grep calico-typha-8445487f56-mh6tp&#xA;kube-system   calico-typha-8445487f56-mh6tp              1/1     Running   0             23m&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ÈÉ®ÁΩ≤Metrics&lt;/h2&gt; &#xA;&lt;p&gt;Âú®Êñ∞ÁâàÁöÑKubernetes‰∏≠Á≥ªÁªüËµÑÊ∫êÁöÑÈááÈõÜÂùá‰ΩøÁî®Metrics-serverÔºåÂèØ‰ª•ÈÄöËøáMetricsÈááÈõÜËäÇÁÇπÂíåPodÁöÑÂÜÖÂ≠ò„ÄÅÁ£ÅÁõò„ÄÅCPUÂíåÁΩëÁªúÁöÑ‰ΩøÁî®Áéá„ÄÇ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Â∞ÜMaster01ËäÇÁÇπÁöÑfront-proxy-ca.crtÂ§çÂà∂Âà∞ÊâÄÊúâNodeËäÇÁÇπ&#xA;[root@k8s-master01 calico]# for i in k8s-node01 k8s-node02;do scp /etc/kubernetes/pki/front-proxy-ca.crt $i:/etc/kubernetes/pki/front-proxy-ca.crt;done&#xA;front-proxy-ca.crt                                                                                                   100% 1115   593.4KB/s   00:00    &#xA;front-proxy-ca.crt                                                                                                   100% 1115     1.4MB/s   00:00  &#xA;# ÂÆâË£Ömetrics server&#xA;[root@k8s-master01 calico]# cd /root/k8s-ha-install/kubeadm-metrics-server&#xA;[root@k8s-master01 kubeadm-metrics-server]# kubectl apply -f comp.yaml &#xA;serviceaccount/metrics-server created&#xA;clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created&#xA;clusterrole.rbac.authorization.k8s.io/system:metrics-server created&#xA;rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created&#xA;clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created&#xA;clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created&#xA;service/metrics-server created&#xA;deployment.apps/metrics-server created&#xA;apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created&#xA;# Êü•ÁúãËøêË°åÁä∂ÊÄÅ&#xA;[root@k8s-master01 kubeadm-metrics-server]# kubectl get po -A | grep metrics&#xA;kube-system   metrics-server-5cf8885b66-2nnb6            1/1     Running   0             68s&#xA;# ÈÉ®ÁΩ≤Âêé‰æøÂèØ‰ª•Êü•ÁúãÊåáÊ†á‰∫Ü&#xA;[root@k8s-master01 kubeadm-metrics-server]# kubectl top node&#xA;NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   &#xA;k8s-master01   177m         8%     1196Mi          64%       &#xA;k8s-master02   153m         7%     1101Mi          58%       &#xA;k8s-master03   163m         8%     1102Mi          58%       &#xA;k8s-node01     88m          4%     848Mi           45%       &#xA;k8s-node02     85m          4%     842Mi           45%       &#xA;[root@k8s-master01 kubeadm-metrics-server]# kubectl top po&#xA;NAME                     CPU(cores)   MEMORY(bytes)   &#xA;nginx-85b98978db-7mn6r   0m           3Mi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ÈÉ®ÁΩ≤Dashboard&lt;/h2&gt; &#xA;&lt;p&gt;DashboardÊòØ‰∏Ä‰∏™Â±ïÁ§∫KubernetesÈõÜÁæ§ËµÑÊ∫êÂíåPodÊó•ÂøóÔºåÁîöËá≥ÂèØ‰ª•ÊâßË°åÂÆπÂô®ÂëΩ‰ª§ÁöÑwebÊéßÂà∂Âè∞„ÄÇ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Áõ¥Êé•ÈÉ®ÁΩ≤Âç≥ÂèØ&#xA;[root@k8s-master01 kubeadm-metrics-server]# cd /root/k8s-ha-install/dashboard/&#xA;[root@k8s-master01 dashboard]# ls&#xA;dashboard-user.yaml  dashboard.yaml&#xA;[root@k8s-master01 dashboard]# kubectl apply -f .&#xA;serviceaccount/admin-user created&#xA;clusterrolebinding.rbac.authorization.k8s.io/admin-user created&#xA;namespace/kubernetes-dashboard created&#xA;serviceaccount/kubernetes-dashboard created&#xA;service/kubernetes-dashboard created&#xA;secret/kubernetes-dashboard-certs created&#xA;secret/kubernetes-dashboard-csrf created&#xA;secret/kubernetes-dashboard-key-holder created&#xA;configmap/kubernetes-dashboard-settings created&#xA;role.rbac.authorization.k8s.io/kubernetes-dashboard created&#xA;clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created&#xA;rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created&#xA;clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created&#xA;deployment.apps/kubernetes-dashboard created&#xA;service/dashboard-metrics-scraper created&#xA;deployment.apps/dashboard-metrics-scraper created&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Êü•ÁúãdashboardÁ´ØÂè£ÔºåÈªòËÆ§ÊòØNodePortÊ®°ÂºèÔºåËÆøÈóÆÈõÜÁæ§ÂÜÖ‰ªªÊÑèËäÇÁÇπÁöÑ31073Á´ØÂè£Âç≥ÂèØ&#xA;[root@k8s-master01 dashboard]# kubectl get svc -owide -A | grep dash&#xA;kubernetes-dashboard   dashboard-metrics-scraper   ClusterIP   10.105.172.8    &amp;lt;none&amp;gt;        8000/TCP                 19m    k8s-app=dashboard-metrics-scraper&#xA;kubernetes-dashboard   kubernetes-dashboard        NodePort    10.99.148.159   &amp;lt;none&amp;gt;        443:31073/TCP            19m    k8s-app=kubernetes-dashboard&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ËÆøÈóÆdashboardÔºö&lt;a href=&#34;https://%E9%9B%86%E7%BE%A4%E5%86%85%E4%BB%BB%E6%84%8F%E8%8A%82%E7%82%B9IP:31073&#34;&gt;https://ÈõÜÁæ§ÂÜÖ‰ªªÊÑèËäÇÁÇπIP:31073&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ÂèëÁé∞ÊèêÁ§∫ÈöêÁßÅËÆæÁΩÆÈîôËØØÁöÑÈóÆÈ¢òÔºåÂ¶ÇÂõæÔºö&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213153948.png&#34; alt=&#34;20211213153948&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Âú®ChromeÊµèËßàÂô®ÂêØÂä®ÂèÇÊï∞Âä†ÂÖ•&lt;code&gt;--test-type --ignore-certificate-errors&lt;/code&gt;ÔºåÁÑ∂ÂêéÂÜçËÆøÈóÆÂ∞±Ê≤°ÊúâËøô‰∏™ÂÆâÂÖ®ÊèêÁ§∫‰∫Ü&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213154024.png&#34; alt=&#34;20211213154024&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213154133.png&#34; alt=&#34;20211213154133&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Ëé∑ÂèñÁôªÈôÜ‰ª§ÁâåÔºàtokenÔºâ&#xA;[root@k8s-master01 dashboard]# kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#39;{print $1}&#39;)&#xA;Name:         admin-user-token-mwnfs&#xA;Namespace:    kube-system&#xA;Labels:       &amp;lt;none&amp;gt;&#xA;Annotations:  kubernetes.io/service-account.name: admin-user&#xA;              kubernetes.io/service-account.uid: 29584392-1cbd-4d5c-91af-9dd4703008aa&#xA;&#xA;Type:  kubernetes.io/service-account-token&#xA;&#xA;Data&#xA;====&#xA;ca.crt:     1099 bytes&#xA;namespace:  11 bytes&#xA;token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IjRyZlh6Ukxta0FlajlHREF5ei1mdl8tZmR6ekwteV9fVEIwalQtejRwUk0ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLW13bmZzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIyOTU4NDM5Mi0xY2JkLTRkNWMtOTFhZi05ZGQ0NzAzMDA4YWEiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pMBMkLAP2AoymIXJC7H47IPu3avdBWPYSZfvjRME7lEQAnbe-SM-yrTFGPzcsJQC3O9gPDvXgIZ1x1tQUtQhc_333GtDMj_VL9oEZxYiOdd578CnBiFmF0BWVX06pAzONgKbguamMD8XEPAvKt4mnlDUr7WCeQJZf_juXKdl7ZOBtrM5Zae0UQHFG6juKLmFP-XxIgoDVIPhcxeAH1ktOHM9Fk1M831hywL1SL2OLHiN52wGLT4WuYrP2iUbJkNpt2PYitSp3iNuh7rESL4Ur7lmFQkLZa9e5vNMCc1wTwOAWvaW4P5TbxtfI_ng4NK_avquiXJY-67D77G-8WKzWg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213154451.png&#34; alt=&#34;20211213154451&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‰∏Ä‰∫õÂøÖË¶ÅÁöÑÊõ¥Êîπ&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Êõ¥Êîπkube-proxyÊ®°Âºè‰∏∫ipvs&#xA;[root@k8s-master01 dashboard]# kubectl edit cm kube-proxy -n kube-system&#xA;mode: &#34;ipvs&#34;&#xA;# Êõ¥Êñ∞kube-proxyÁöÑpod&#xA;[root@k8s-master01 dashboard]# kubectl patch daemonset kube-proxy -p &#34;{\&#34;spec\&#34;:{\&#34;template\&#34;:{\&#34;metadata\&#34;:{\&#34;annotations\&#34;:{\&#34;date\&#34;:\&#34;`date +&#39;%s&#39;`\&#34;}}}}}&#34; -n kube-system&#xA;daemonset.apps/kube-proxy patched&#xA;# È™åËØÅ&#xA;[root@k8s-master01 dashboard]# curl 127.0.0.1:10249/proxyMode&#xA;ipvs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ÊµãËØïÈõÜÁæ§&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Â¢ûÂä†nodeËäÇÁÇπÁöÑËäÇÁÇπroleÂêçÁß∞&#xA;kubectl label nodes k8s-node1 node-role.kubernetes.io/node=&#xA;# Âà†Èô§nodeËäÇÁÇπÁöÑËäÇÁÇπroleÂêçÁß∞&#xA;kubectl label nodes k8s-node1 node-role.kubernetes.io/node-&#xA;&#xA;# Ê∑ªÂä†Ê†áÁ≠æÂêéÊü•ÁúãÈõÜÁæ§Áä∂ÊÄÅ&#xA;[root@k8s-master01 calico]# kubectl get no&#xA;NAME           STATUS   ROLES                  AGE   VERSION&#xA;k8s-master01   Ready    control-plane,master   56m   v1.23.0&#xA;k8s-master02   Ready    control-plane,master   40m   v1.23.0&#xA;k8s-master03   Ready    control-plane,master   39m   v1.23.0&#xA;k8s-node01     Ready    node                   38m   v1.23.0&#xA;k8s-node02     Ready    node                   38m   v1.23.0&#xA;&#xA;# ÊµãËØïnamespace&#xA;kubectl get namespace&#xA;kubectl create namespace test&#xA;kubectl get namespace&#xA;kubectl delete namespace test&#xA;&#xA;# ÂàõÂª∫nginxÂÆû‰æãÂπ∂ÂºÄÊîæÁ´ØÂè£&#xA;kubectl create deployment nginx --image=nginx&#xA;kubectl expose deployment nginx --port=80 --type=NodePort&#xA;# Êü•ÁúãË∞ÉÂ∫¶Áä∂ÊÄÅÂíåÁ´ØÂè£Âè∑&#xA;[root@k8s-master01 calico]# kubectl get pod,svc -owide&#xA;NAME                         READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES&#xA;pod/nginx-85b98978db-7mn6r   1/1     Running   0          2m16s   172.27.14.193   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;&#xA;&#xA;NAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE    SELECTOR&#xA;service/kubernetes   ClusterIP   10.96.0.1      &amp;lt;none&amp;gt;        443/TCP        59m    &amp;lt;none&amp;gt;&#xA;service/nginx        NodePort    10.104.33.99   &amp;lt;none&amp;gt;        80:31720/TCP   2m6s   app=nginx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÂèØËßÅË∞ÉÂ∫¶Âà∞‰∫Ük8s-node02Ôºànode IPÂú∞ÂùÄÊòØ192.168.43.184Ôºâ‰∏äÔºåÂØπÂ∫îÁöÑNodePort‰∏∫31720&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Âú®ÊµèËßàÂô®ËæìÂÖ•&lt;a href=&#34;http://192.168.43.184:31720/&#34;&gt;http://192.168.43.184:31720/&lt;/a&gt; ËÆøÈóÆnginxÔºåËÆøÈóÆÁªìÊûúÂ¶ÇÂõæ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213143124.png&#34; alt=&#34;20211213143124&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Ëá≥Ê≠§ÔºåÂü∫‰∫ékubeadmÁöÑKubernetesÈ´òÂèØÁî®ÈõÜÁæ§Êê≠Âª∫ÊàêÂäü„ÄÇ&lt;/p&gt;</summary>
  </entry>
</feed>