<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Perl Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-01T01:49:59Z</updated>
  <subtitle>Daily Trending of Perl in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>adrienverge/openfortivpn</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/adrienverge/openfortivpn</id>
    <link href="https://github.com/adrienverge/openfortivpn" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Client for PPP+SSL VPN tunnel services&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;openfortivpn&lt;/h1&gt; &#xA;&lt;p&gt;openfortivpn is a client for PPP+SSL VPN tunnel services. It spawns a pppd process and operates the communication between the gateway and this process.&lt;/p&gt; &#xA;&lt;p&gt;It is compatible with Fortinet VPNs.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;man openfortivpn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Simply connect to a VPN:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;openfortivpn vpn-gateway:8443 --username=foo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Connect to a VPN using an authentication realm:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;openfortivpn vpn-gateway:8443 --username=foo --realm=bar&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Store password securely with a pinentry program:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;openfortivpn vpn-gateway:8443 --username=foo --pinentry=pinentry-mac&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Connect with a user certificate and no password:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;openfortivpn vpn-gateway:8443 --username= --password= --user-cert=cert.pem --user-key=key.pem&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Don&#39;t set IP routes and don&#39;t add VPN nameservers to &lt;code&gt;/etc/resolv.conf&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;openfortivpn vpn-gateway:8443 -u foo --no-routes --no-dns --pppd-no-peerdns&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Using a configuration file:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;openfortivpn -c /etc/openfortivpn/my-config&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With &lt;code&gt;/etc/openfortivpn/my-config&lt;/code&gt; containing:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;host = vpn-gateway&#xA;port = 8443&#xA;username = foo&#xA;set-dns = 0&#xA;pppd-use-peerdns = 0&#xA;# X509 certificate sha256 sum, trust only this one!&#xA;trusted-cert = e46d4aff08ba6914e64daa85bc6112a422fa7ce16631bff0b592a28556f993db&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For the full list of config options, see the &lt;code&gt;CONFIGURATION&lt;/code&gt; section of&lt;/p&gt; &lt;pre&gt;&lt;code&gt;man openfortivpn&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Smartcard&lt;/h2&gt; &#xA;&lt;p&gt;Smartcard support needs &lt;code&gt;openssl pkcs engine&lt;/code&gt; and &lt;code&gt;opensc&lt;/code&gt; to be installed. The pkcs11-engine from libp11 needs to be compiled with p11-kit-devel installed. Check &lt;a href=&#34;https://github.com/adrienverge/openfortivpn/issues/464&#34;&gt;#464&lt;/a&gt; for a discussion of known issues in this area.&lt;/p&gt; &#xA;&lt;p&gt;To make use of your smartcard put at least &lt;code&gt;pkcs11:&lt;/code&gt; to the user-cert config or commandline option. It takes the full or a partial PKCS#11 token URI.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;user-cert = pkcs11:&#xA;user-cert = pkcs11:token=someuser&#xA;user-cert = pkcs11:model=PKCS%2315%20emulated;manufacturer=piv_II;serial=012345678;token=someuser&#xA;username =&#xA;password =&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In most cases &lt;code&gt;user-cert = pkcs11:&lt;/code&gt; will do it, but if needed you can get the token-URI with &lt;code&gt;p11tool --list-token-urls&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Multiple readers are currently not supported.&lt;/p&gt; &#xA;&lt;p&gt;Smartcard support has been tested with Yubikey under Linux, but other PIV enabled smartcards may work too. On Mac OS X Mojave it is known that the pkcs engine-by-id is not found.&lt;/p&gt; &#xA;&lt;h2&gt;Installing&lt;/h2&gt; &#xA;&lt;h3&gt;Installing existing packages&lt;/h3&gt; &#xA;&lt;p&gt;Some Linux distributions provide &lt;code&gt;openfortivpn&lt;/code&gt; packages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://apps.fedoraproject.org/packages/openfortivpn&#34;&gt;Fedora / CentOS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://software.opensuse.org/package/openfortivpn&#34;&gt;openSUSE / SLE&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://packages.gentoo.org/packages/net-vpn/openfortivpn&#34;&gt;Gentoo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/networking/openfortivpn&#34;&gt;NixOS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.archlinux.org/packages/community/x86_64/openfortivpn&#34;&gt;Arch Linux&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://packages.debian.org/stable/openfortivpn&#34;&gt;Debian&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://packages.ubuntu.com/search?keywords=openfortivpn&#34;&gt;Ubuntu&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dev.getsol.us/source/openfortivpn/&#34;&gt;Solus&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;On macOS both &lt;a href=&#34;https://formulae.brew.sh/formula/openfortivpn&#34;&gt;Homebrew&lt;/a&gt; and &lt;a href=&#34;https://ports.macports.org/port/openfortivpn&#34;&gt;MacPorts&lt;/a&gt; provide an &lt;code&gt;openfortivpn&lt;/code&gt; package. Either &lt;a href=&#34;https://brew.sh/&#34;&gt;install Homebrew&lt;/a&gt; then install openfortivpn:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Install &#39;Homebrew&#39;&#xA;/usr/bin/ruby -e &#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&#34;&#xA;&#xA;# Install &#39;openfortivpn&#39;&#xA;brew install openfortivpn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or &lt;a href=&#34;https://www.macports.org/install.php&#34;&gt;install MacPorts&lt;/a&gt; then install openfortivpn:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Install &#39;openfortivpn&#39;&#xA;sudo port install openfortivpn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A more complete overview can be obtained from &lt;a href=&#34;https://repology.org/project/openfortivpn/versions&#34;&gt;repology&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Building and installing from source&lt;/h3&gt; &#xA;&lt;p&gt;For other distros, you&#39;ll need to build and install from source:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install build dependencies.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;RHEL/CentOS/Fedora: &lt;code&gt;gcc&lt;/code&gt; &lt;code&gt;automake&lt;/code&gt; &lt;code&gt;autoconf&lt;/code&gt; &lt;code&gt;openssl-devel&lt;/code&gt; &lt;code&gt;make&lt;/code&gt; &lt;code&gt;pkg-config&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Debian/Ubuntu: &lt;code&gt;gcc&lt;/code&gt; &lt;code&gt;automake&lt;/code&gt; &lt;code&gt;autoconf&lt;/code&gt; &lt;code&gt;libssl-dev&lt;/code&gt; &lt;code&gt;make&lt;/code&gt; &lt;code&gt;pkg-config&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Arch Linux: &lt;code&gt;gcc&lt;/code&gt; &lt;code&gt;automake&lt;/code&gt; &lt;code&gt;autoconf&lt;/code&gt; &lt;code&gt;openssl&lt;/code&gt; &lt;code&gt;pkg-config&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Gentoo Linux: &lt;code&gt;net-dialup/ppp&lt;/code&gt; &lt;code&gt;pkg-config&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;openSUSE: &lt;code&gt;gcc&lt;/code&gt; &lt;code&gt;automake&lt;/code&gt; &lt;code&gt;autoconf&lt;/code&gt; &lt;code&gt;libopenssl-devel&lt;/code&gt; &lt;code&gt;pkg-config&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;macOS (Homebrew): &lt;code&gt;automake&lt;/code&gt; &lt;code&gt;autoconf&lt;/code&gt; &lt;code&gt;openssl@1.1&lt;/code&gt; &lt;code&gt;pkg-config&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;FreeBSD: &lt;code&gt;automake&lt;/code&gt; &lt;code&gt;autoconf&lt;/code&gt; &lt;code&gt;libressl&lt;/code&gt; &lt;code&gt;pkgconf&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;On Linux, if you manage your kernel yourself, ensure to compile those modules:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CONFIG_PPP=m&#xA;CONFIG_PPP_ASYNC=m&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;On macOS, install &#39;Homebrew&#39; to install the build dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Install &#39;Homebrew&#39;&#xA;/usr/bin/ruby -e &#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&#34;&#xA;&#xA;# Install Dependencies&#xA;brew install automake autoconf openssl@1.1 pkg-config&#xA;&#xA;# You may need to make this openssl available to compilers and pkg-config&#xA;export LDFLAGS=&#34;-L/usr/local/opt/openssl/lib $LDFLAGS&#34;&#xA;export CPPFLAGS=&#34;-I/usr/local/opt/openssl/include $CPPFLAGS&#34;&#xA;export PKG_CONFIG_PATH=&#34;/usr/local/opt/openssl/lib/pkgconfig:$PKG_CONFIG_PATH&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build and install.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;./autogen.sh&#xA;./configure --prefix=/usr/local --sysconfdir=/etc&#xA;make&#xA;sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you need to specify the openssl location you can set the &lt;code&gt;$PKG_CONFIG_PATH&lt;/code&gt; environment variable. For fine-tuning check the available configure arguments with &lt;code&gt;./configure --help&lt;/code&gt; especially when you are cross compiling.&lt;/p&gt; &lt;p&gt;Finally, install runtime dependency &lt;code&gt;ppp&lt;/code&gt; or &lt;code&gt;pppd&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Running as root?&lt;/h2&gt; &#xA;&lt;p&gt;openfortivpn needs elevated privileges at three steps during tunnel set up:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;when spawning a &lt;code&gt;/usr/sbin/pppd&lt;/code&gt; process;&lt;/li&gt; &#xA; &lt;li&gt;when setting IP routes through VPN (when the tunnel is up);&lt;/li&gt; &#xA; &lt;li&gt;when adding nameservers to &lt;code&gt;/etc/resolv.conf&lt;/code&gt; (when the tunnel is up).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For these reasons, you need to use &lt;code&gt;sudo openfortivpn&lt;/code&gt;. If you need it to be usable by non-sudoer users, you might consider adding an entry in &lt;code&gt;/etc/sudoers&lt;/code&gt; or a file under &lt;code&gt;/etc/sudoers.d&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For example: &lt;code&gt;visudo -f /etc/sudoers.d/openfortivpn&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Cmnd_Alias  OPENFORTIVPN = /usr/bin/openfortivpn&#xA;&#xA;%adm       ALL = (ALL) OPENFORTIVPN&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Adapt the above example by changing the &lt;code&gt;openfortivpn&lt;/code&gt; path or choosing a group different from &lt;code&gt;adm&lt;/code&gt; - such as a dedicated &lt;code&gt;openfortivpn&lt;/code&gt; group.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: Make sure only trusted users can run openfortivpn as root! As described in &lt;a href=&#34;https://github.com/adrienverge/openfortivpn/issues/54&#34;&gt;#54&lt;/a&gt;, a malicious user could use &lt;code&gt;--pppd-plugin&lt;/code&gt; and &lt;code&gt;--pppd-log&lt;/code&gt; options to divert the program&#39;s behaviour.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to make pull requests!&lt;/p&gt; &#xA;&lt;p&gt;C coding style should follow the &lt;a href=&#34;http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/Documentation/process/coding-style.rst?id=refs/heads/master&#34;&gt;Linux kernel Documentation/CodingStyle&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>get-iplayer/get_iplayer</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/get-iplayer/get_iplayer</id>
    <link href="https://github.com/get-iplayer/get_iplayer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A utility for downloading TV and radio programmes from BBC iPlayer and BBC Sounds&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;get_iplayer: BBC iPlayer/BBC Sounds Indexing Tool and PVR&lt;/h2&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Downloads TV and radio programmes from BBC iPlayer/BBC Sounds&lt;/li&gt; &#xA; &lt;li&gt;Allows multiple programmes to be downloaded using a single command&lt;/li&gt; &#xA; &lt;li&gt;Indexing of most available iPlayer/Sounds catch-up programmes from previous 30 days (not Red Button, iPlayer Exclusive, or Podcast-only)&lt;/li&gt; &#xA; &lt;li&gt;Caching of programme index with automatic updating&lt;/li&gt; &#xA; &lt;li&gt;Regex search on programme name&lt;/li&gt; &#xA; &lt;li&gt;Regex search on programme description and episode title&lt;/li&gt; &#xA; &lt;li&gt;Filter search results by channel&lt;/li&gt; &#xA; &lt;li&gt;Direct download via programme ID or URL&lt;/li&gt; &#xA; &lt;li&gt;PVR capability (may be used with cron or Task Scheduler)&lt;/li&gt; &#xA; &lt;li&gt;HTTP proxy support&lt;/li&gt; &#xA; &lt;li&gt;Perl 5.16+ required, plus LWP, LWP::Protocol::https, XML::LibXML, Mojolicious, and CGI modules&lt;/li&gt; &#xA; &lt;li&gt;Requires ffmpeg for conversion to MP4 and AtomicParsley for metadata tagging&lt;/li&gt; &#xA; &lt;li&gt;Runs on Linux/BSD (Ubuntu, Fedora, OpenBSD and others), macOS (10.10+), Windows (7/8/10)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;get_iplayer can only search for programmes that were scheduled for broadcast on BBC linear services within the previous 30 days, even if some are available for more than 30 days on the iPlayer/Sounds sites. Red button programmes, iPlayer box sets, web-only content, and BBC podcasts are not searchable. Programmes that are still available after 30 days must be located on the iPlayer/Sounds sites and downloaded directly via PID or URL.&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;get_iplayer does not support downloading news/sport videos, other embedded media, archive programmes, special collections, educational material, programme clips or any content other than whole episodes of programmes scheduled for broadcast on BBC linear services within the previous 30 days. However, it is generally possible to download other content such as red button programmes, iPlayer box sets, or podcasts directly via PID or URL. get_iplayer DOES NOT support live recording from BBC channels.&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/get-iplayer/get_iplayer/wiki&#34;&gt;https://github.com/get-iplayer/get_iplayer/wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/get-iplayer/get_iplayer/wiki/installation&#34;&gt;https://github.com/get-iplayer/get_iplayer/wiki/installation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;get_iplayer --help&#xA;get_iplayer --basic-help&#xA;get_iplayer --long-help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;List all TV programmes (&lt;code&gt;--type=tv&lt;/code&gt; set by default):&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer &#34;.*&#34;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Search output appears in this format:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  ...&#xA;  208:  Doctor Who: Series 7 Part 2 - 1. The Bells of Saint John, BBC One, b01rryzz&#xA;  209:  Doctor Who: Series 7 Part 2 - 2. The Rings Of Akhaten, BBC One, b01rx0lj&#xA;  210:  Doctor Who: Series 7 Part 2 - 3. Cold War, BBC One, b01s1cz7&#xA;  ...&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Format = &lt;code&gt;&amp;lt;index&amp;gt;: &amp;lt;name&amp;gt; - &amp;lt;episode&amp;gt;, &amp;lt;channel&amp;gt;, &amp;lt;pid&amp;gt;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;List all TV programmes with long descriptions:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --long &#34;.*&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;List all radio programmes:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --type=radio &#34;.*&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;List all TV programmes with &#34;doctor who&#34; in the name (matching is case-insensitive):&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer &#34;doctor who&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;List all TV and radio programmes with &#34;doctor who&#34; in the name:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --type tv,radio &#34;doctor who&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;List all BBC One programmes:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --channel=&#34;BBC One&#34; &#34;.*&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;List Radio 4 and Radio 4 Extra programmes with &#34;Book at Bedtime&#34; in the title:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --type=radio --channel=&#34;Radio 4&#34; &#34;Book at Bedtime&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;List only Radio 4 programmes with &#34;Book at Bedtime&#34; in the title:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --type=radio --channel=&#34;Radio 4$&#34; &#34;Book at Bedtime&#34;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;(The &lt;code&gt;$&lt;/code&gt; regular expression metacharacter matches &#34;Radio 4&#34; only at the end of the channel name, thus avoiding matches against &#34;Radio 4 Extra&#34;)&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record TV programme number 208 (index from search results) in HD, with fallback to lower quality if not available:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --get 208&lt;/code&gt; [default setting]&lt;/p&gt; &lt;p&gt;or&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --get 208 --tv-quality=hd,sd,web,mobile&lt;/code&gt; [explicit setting]&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record TV programme number 208 in lower resolution only (704x396@50):&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --get 208 --tv-quality=web&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record TV programme number 208 and download subtitles in SubRip (SRT) format:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --get 208 --subtitles&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record multiple TV programmes (using index numbers from search results):&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --get 208 209 210&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record a TV programme using its iPlayer URL:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer https://www.bbc.co.uk/iplayer/episode/b01sc0wf/Doctors_Series_15_Perfect/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record a TV programme using the PID (b01sc0wf) from its iPlayer URL:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --pid=b01sc0wf&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record a radio programme using its Sounds URL:&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer https://www.bbc.co.uk/sounds/play/b07gcv34&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record a radio programme using the PID (b07gcv34) from its Sounds URL in high quality (320k), with fallback to lower quality if not available (default setting):&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --pid=b07gcv34&lt;/code&gt; [default setting]&lt;/p&gt; &lt;p&gt;OR&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --pid=b07gcv34 --radio-quality=high,std,med,low&lt;/code&gt; [explicit setting]&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record a radio programme using the PID (b07gcv34) from its Sounds URL with lower bit rate only (96k):&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --pid=b07gcv34 --radio-quality=med&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Record multiple radio programmes (using PIDs from Sounds URLs):&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --pid=b07gcv34,b07h60ld&lt;/code&gt; [comma-separated list]&lt;/p&gt; &lt;p&gt;OR&lt;/p&gt; &lt;p&gt;&lt;code&gt;get_iplayer --pid=b07gcv34 --pid=b07h60ld&lt;/code&gt; [multiple arguments]&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;NOTE: Sometimes you may not be able to download a listed programme immediately after broadcast (usually available within 24hrs of airing). Some BBC programmes may not be available from iPlayer/Sounds.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>glpi-project/glpi-agent</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/glpi-project/glpi-agent</id>
    <link href="https://github.com/glpi-project/glpi-agent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GLPI Agent&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/glpi-project/glpi-agent/develop/share/html/logo.png&#34; alt=&#34;GLPI Agent&#34; width=&#34;32&#34; height=&#34;32&#34;&gt; GLPI Agent&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/glpi-project/glpi-agent/actions/workflows/glpi-agent-ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/glpi-project/glpi-agent/actions/workflows/glpi-agent-ci.yml/badge.svg?sanitize=true&#34; alt=&#34;GLPI Agent CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/glpi-project/glpi-agent/actions/workflows/glpi-agent-packaging.yml&#34;&gt;&lt;img src=&#34;https://github.com/glpi-project/glpi-agent/actions/workflows/glpi-agent-packaging.yml/badge.svg?sanitize=true&#34; alt=&#34;GLPI Agent Packaging&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/glpi-project/glpi-agent/develop/#download&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/glpi-project/glpi-agent/total.svg?sanitize=true&#34; alt=&#34;Github All Releases&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/GLPI_PROJECT&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/GLPI_PROJECT.svg?style=social&amp;amp;label=Follow&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Summary&lt;/h2&gt; &#xA;&lt;p&gt;The GLPI Agent is a generic management agent. It can perform a certain number of tasks, according to its own execution plan, or on behalf of a GLPI server acting as a control point.&lt;/p&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;This agent is based on a fork of &lt;a href=&#34;https://github.com/fusioninventory/fusioninventory-agent&#34;&gt;FusionInventory agent&lt;/a&gt; and so works mainly like FusionInventory agent. It introduces new features and a new protocol to communicate directly with a GLPI server and its native inventory feature. Anyway it also keeps the compatibility with &lt;a href=&#34;https://github.com/fusioninventory/fusioninventory-for-glpi&#34;&gt;FusionInventory for GLPI plugin&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Release: See &lt;a href=&#34;https://github.com/glpi-project/glpi-agent/releases&#34;&gt;our github releases&lt;/a&gt; for official win32, MacOSX &amp;amp; linux packages.&lt;/li&gt; &#xA; &lt;li&gt;Development builds: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;nightly builds for last &#39;develop&#39; branch commits: &lt;a href=&#34;http://nightly.glpi-project.org/glpi-agent&#34;&gt;GLPI-Agent nightly builds&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;with a github account, you can also access artifacts for any other branches supporting &lt;a href=&#34;https://github.com/glpi-project/glpi-agent/actions/workflows/glpi-agent-packaging.yml?query=is%3Asuccess+event%3Apush+-branch%3Adevelop&#34;&gt;&#34;GLPI Agent Packaging&#34; workflow&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The GLPI Agent has its &lt;a href=&#34;https://github.com/glpi-project/doc-agent&#34;&gt;dedicated documentation project&lt;/a&gt; where any contribution will also be appreciated.&lt;/p&gt; &#xA;&lt;p&gt;The documentation itself is &lt;a href=&#34;https://glpi-agent.readthedocs.io/&#34;&gt;readable online&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://glpi-agent.readthedocs.io/en/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/glpi-agent/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;h3&gt;Core&lt;/h3&gt; &#xA;&lt;p&gt;Minimum perl version: 5.8&lt;/p&gt; &#xA;&lt;p&gt;Mandatory Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;File::Which&lt;/li&gt; &#xA; &lt;li&gt;LWP::UserAgent&lt;/li&gt; &#xA; &lt;li&gt;Net::IP&lt;/li&gt; &#xA; &lt;li&gt;Text::Template&lt;/li&gt; &#xA; &lt;li&gt;UNIVERSAL::require&lt;/li&gt; &#xA; &lt;li&gt;XML::TreePP&lt;/li&gt; &#xA; &lt;li&gt;Cpanel::JSON::XS&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Compress::Zlib, for message compression&lt;/li&gt; &#xA; &lt;li&gt;HTTP::Daemon, for web interface&lt;/li&gt; &#xA; &lt;li&gt;IO::Socket::SSL, for HTTPS support&lt;/li&gt; &#xA; &lt;li&gt;LWP::Protocol::https, for HTTPS support&lt;/li&gt; &#xA; &lt;li&gt;Proc::Daemon, for daemon mode (Unix only)&lt;/li&gt; &#xA; &lt;li&gt;Proc::PID::File, for daemon mode (Unix only)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Inventory task&lt;/h3&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::CUPS, for printers detection&lt;/li&gt; &#xA; &lt;li&gt;Parse::EDID, for EDID data parsing&lt;/li&gt; &#xA; &lt;li&gt;DateTime, for reliable timezone name extraction&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional programs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;dmidecode, for DMI data retrieval&lt;/li&gt; &#xA; &lt;li&gt;lspci, for PCI bus scanning&lt;/li&gt; &#xA; &lt;li&gt;hdparm, for additional disk drive info retrieval&lt;/li&gt; &#xA; &lt;li&gt;monitor-get-edid-using-vbe, monitor-get-edid or get-edid, for EDID data access&lt;/li&gt; &#xA; &lt;li&gt;ssh-keyscan, for host SSH public key retrieval&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Network discovery tasks&lt;/h3&gt; &#xA;&lt;p&gt;Mandatory Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Thread::Queue&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::NBName, for NetBios method support&lt;/li&gt; &#xA; &lt;li&gt;Net::SNMP, for SNMP method support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional programs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;arp, for arp table lookup method support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Network inventory tasks&lt;/h3&gt; &#xA;&lt;p&gt;Mandatory Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::SNMP&lt;/li&gt; &#xA; &lt;li&gt;Thread::Queue&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Crypt::DES, for SNMPv3 support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Wake on LAN task&lt;/h3&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::Write::Layer2, for ethernet method support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Deploy task&lt;/h3&gt; &#xA;&lt;p&gt;Mandatory Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Archive::Extract&lt;/li&gt; &#xA; &lt;li&gt;Digest::SHA&lt;/li&gt; &#xA; &lt;li&gt;File::Copy::Recursive&lt;/li&gt; &#xA; &lt;li&gt;JSON::PP&lt;/li&gt; &#xA; &lt;li&gt;URI::Escape&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Mandatory Perl modules for P2P Support:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::Ping&lt;/li&gt; &#xA; &lt;li&gt;Parallel::ForkManager&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;MSI Packaging&lt;/h3&gt; &#xA;&lt;p&gt;Tools:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glpi-project/dmidecode&#34;&gt;dmidecode&lt;/a&gt; modified to be built with mingw32&lt;/li&gt; &#xA; &lt;li&gt;hdparm&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.7-zip.org/&#34;&gt;7zip&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Mandatory Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Perl::Dist::Strawberry&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;MacOSX Packaging&lt;/h3&gt; &#xA;&lt;p&gt;Tools:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glpi-project/dmidecode/tree/macosx&#34;&gt;dmidecode&lt;/a&gt; modified to be built on macosx&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/munki/munki-pkg&#34;&gt;munkipkg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Xcode&lt;/li&gt; &#xA; &lt;li&gt;productbuild&lt;/li&gt; &#xA; &lt;li&gt;hdiutil&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Public databases&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pci.ids&lt;/li&gt; &#xA; &lt;li&gt;Usb.ids&lt;/li&gt; &#xA; &lt;li&gt;SysObject.ids: &lt;a href=&#34;https://github.com/glpi-project/sysobject.ids&#34;&gt;sysobject.ids&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Related contribs&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/glpi-project/glpi-agent/develop/CONTRIB.md&#34;&gt;CONTRIB&lt;/a&gt; to find references to GLPI Agent related scritps/files&lt;/p&gt; &#xA;&lt;h2&gt;Contacts&lt;/h2&gt; &#xA;&lt;p&gt;Project websites:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;main site: &lt;a href=&#34;https://glpi-project.org/&#34;&gt;https://glpi-project.org/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;forum: &lt;a href=&#34;https://forum.glpi-project.org/&#34;&gt;https://forum.glpi-project.org/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;github: &lt;a href=&#34;http://github.com/glpi-project/glpi-agent&#34;&gt;http://github.com/glpi-project/glpi-agent&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Project Telegram channel:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://t.me/glpien&#34;&gt;https://t.me/glpien&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please report any issues on project &lt;a href=&#34;https://github.com/glpi-project/glpi-agent/issues&#34;&gt;github issue tracker&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Active authors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Guillaume Bougard &lt;a href=&#34;mailto:gbougard@teclib.com&#34;&gt;gbougard@teclib.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Copyright 2006-2010 &lt;a href=&#34;https://www.ocsinventory-ng.org/&#34;&gt;OCS Inventory contributors&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Copyright 2010-2019 &lt;a href=&#34;https://fusioninventory.org&#34;&gt;FusionInventory Team&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Copyright 2011-2021 &lt;a href=&#34;https://www.teclib-edition.com/&#34;&gt;Teclib Editions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-GPL%20v2-blue.svg?sanitize=true&#34; alt=&#34;License: GPL v2&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This software is licensed under the terms of GPLv2+, see LICENSE file for details.&lt;/p&gt; &#xA;&lt;h2&gt;Additional pieces of software&lt;/h2&gt; &#xA;&lt;p&gt;The glpi-injector script is based on fusioninventory-injector script:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;author: Pascal Danek&lt;/li&gt; &#xA; &lt;li&gt;copyright: 2005 Pascal Danek&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;GLPI::Agent::Task::Inventory::Vmsystem contains code from imvirt:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;url: &lt;a href=&#34;http://micky.ibh.net/~liske/imvirt.html&#34;&gt;http://micky.ibh.net/~liske/imvirt.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;author: Thomas Liske &lt;a href=&#34;mailto:liske@ibh.de&#34;&gt;liske@ibh.de&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;copyright: 2008 IBH IT-Service GmbH &lt;a href=&#34;http://www.ibh.de/&#34;&gt;http://www.ibh.de/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;License: GPLv2+&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ToolBox HTTP daemon plugin uses flatpickr lightweight and powerful datetime picker js library.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;author: Gregory Petrosyan&lt;/li&gt; &#xA; &lt;li&gt;url: &lt;a href=&#34;https://flatpickr.js.org/&#34;&gt;https://flatpickr.js.org/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;copyright: 2017 Gregory Petrosyan&lt;/li&gt; &#xA; &lt;li&gt;License: License MIT&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>tseemann/snippy</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/tseemann/snippy</id>
    <link href="https://github.com/tseemann/snippy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;✂️ ⚡ Rapid haploid variant calling and core genome alignment&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/tseemann/snippy&#34;&gt;&lt;img src=&#34;https://travis-ci.org/tseemann/snippy.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-GPL%20v2-blue.svg?sanitize=true&#34; alt=&#34;License: GPL v2&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/Language-Perl_5-steelblue.svg?sanitize=true&#34; alt=&#34;Don&#39;t judge me&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Snippy&lt;/h1&gt; &#xA;&lt;p&gt;Rapid haploid variant calling and core genome alignment&lt;/p&gt; &#xA;&lt;h2&gt;Author&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/torstenseemann&#34;&gt;Torsten Seemann&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Synopsis&lt;/h2&gt; &#xA;&lt;p&gt;Snippy finds SNPs between a haploid reference genome and your NGS sequence reads. It will find both substitutions (snps) and insertions/deletions (indels). It will use as many CPUs as you can give it on a single computer (tested to 64 cores). It is designed with speed in mind, and produces a consistent set of output files in a single folder. It can then take a set of Snippy results using the same reference and generate a core SNP alignment (and ultimately a phylogenomic tree).&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;% snippy --cpus 16 --outdir mysnps --ref Listeria.gbk --R1 FDA_R1.fastq.gz --R2 FDA_R2.fastq.gz&#xA;&amp;lt;cut&amp;gt;&#xA;Walltime used: 3 min, 42 sec&#xA;Results folder: mysnps&#xA;Done.&#xA;&#xA;% ls mysnps&#xA;snps.vcf snps.bed snps.gff snps.csv snps.tab snps.html &#xA;snps.bam snps.txt reference/ ...&#xA;&#xA;% head -5 mysnps/snps.tab&#xA;CHROM  POS     TYPE    REF   ALT    EVIDENCE        FTYPE STRAND NT_POS AA_POS LOCUS_TAG GENE PRODUCT EFFECT&#xA;chr      5958  snp     A     G      G:44 A:0        CDS   +      41/600 13/200 ECO_0001  dnaA replication protein DnaA missense_variant c.548A&amp;gt;C p.Lys183Thr&#xA;chr     35524  snp     G     T      T:73 G:1 C:1    tRNA  -   &#xA;chr     45722  ins     ATT   ATTT   ATTT:43 ATT:1   CDS   -                    ECO_0045  gyrA DNA gyrase&#xA;chr    100541  del     CAAA  CAA    CAA:38 CAAA:1   CDS   +                    ECO_0179      hypothetical protein&#xA;plas      619  complex GATC  AATA   GATC:28 AATA:0  &#xA;plas     3221  mnp     GA    CT     CT:39 CT:0      CDS   +                    ECO_p012  rep  hypothetical protein&#xA;&#xA;% snippy-core --prefix core mysnps1 mysnps2 mysnps3 mysnps4 &#xA;Loaded 4 SNP tables.&#xA;Found 2814 core SNPs from 96615 SNPs.&#xA;&#xA;% ls core.*&#xA;core.aln core.tab core.tab core.txt core.vcf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;h2&gt;Conda&lt;/h2&gt; &#xA;&lt;p&gt;Install &lt;a href=&#34;https://bioconda.github.io/user/install.html&#34;&gt;Bioconda&lt;/a&gt; then:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install -c conda-forge -c bioconda -c defaults snippy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Homebrew&lt;/h2&gt; &#xA;&lt;p&gt;Install &lt;a href=&#34;http://brew.sh/&#34;&gt;Homebrew&lt;/a&gt; (MacOS) or &lt;a href=&#34;http://linuxbrew.sh/&#34;&gt;LinuxBrew&lt;/a&gt; (Linux) then:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install brewsci/bio/snippy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Source&lt;/h2&gt; &#xA;&lt;p&gt;This will install the latest version direct from Github. You&#39;ll need to add Snippy&#39;s &lt;code&gt;bin&lt;/code&gt; directory to your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd $HOME&#xA;git clone https://github.com/tseemann/snippy.git&#xA;$HOME/snippy/bin/snippy --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Check installation&lt;/h1&gt; &#xA;&lt;p&gt;Ensure you have the desired version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;snippy --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Check that all dependencies are installed and working:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;snippy --check&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Calling SNPs&lt;/h1&gt; &#xA;&lt;h2&gt;Input Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;a reference genome in FASTA or GENBANK format (can be in multiple contigs)&lt;/li&gt; &#xA; &lt;li&gt;sequence read file(s) in FASTQ or FASTA format (can be .gz compressed) format&lt;/li&gt; &#xA; &lt;li&gt;a folder to put the results in&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Output Files&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Extension&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.tab&lt;/td&gt; &#xA;   &lt;td&gt;A simple &lt;a href=&#34;http://en.wikipedia.org/wiki/Tab-separated_values&#34;&gt;tab-separated&lt;/a&gt; summary of all the variants&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.csv&lt;/td&gt; &#xA;   &lt;td&gt;A &lt;a href=&#34;http://en.wikipedia.org/wiki/Comma-separated_values&#34;&gt;comma-separated&lt;/a&gt; version of the .tab file&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.html&lt;/td&gt; &#xA;   &lt;td&gt;A &lt;a href=&#34;http://en.wikipedia.org/wiki/HTML&#34;&gt;HTML&lt;/a&gt; version of the .tab file&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.vcf&lt;/td&gt; &#xA;   &lt;td&gt;The final annotated variants in &lt;a href=&#34;http://en.wikipedia.org/wiki/Variant_Call_Format&#34;&gt;VCF&lt;/a&gt; format&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.bed&lt;/td&gt; &#xA;   &lt;td&gt;The variants in &lt;a href=&#34;http://genome.ucsc.edu/FAQ/FAQformat.html#format1&#34;&gt;BED&lt;/a&gt; format&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.gff&lt;/td&gt; &#xA;   &lt;td&gt;The variants in &lt;a href=&#34;http://www.sequenceontology.org/gff3.shtml&#34;&gt;GFF3&lt;/a&gt; format&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.bam&lt;/td&gt; &#xA;   &lt;td&gt;The alignments in &lt;a href=&#34;http://en.wikipedia.org/wiki/SAMtools&#34;&gt;BAM&lt;/a&gt; format. Includes unmapped, multimapping reads. Excludes duplicates.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.bam.bai&lt;/td&gt; &#xA;   &lt;td&gt;Index for the .bam file&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.log&lt;/td&gt; &#xA;   &lt;td&gt;A log file with the commands run and their outputs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.aligned.fa&lt;/td&gt; &#xA;   &lt;td&gt;A version of the reference but with &lt;code&gt;-&lt;/code&gt; at position with &lt;code&gt;depth=0&lt;/code&gt; and &lt;code&gt;N&lt;/code&gt; for &lt;code&gt;0 &amp;lt; depth &amp;lt; --mincov&lt;/code&gt; (&lt;strong&gt;does not have variants&lt;/strong&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.consensus.fa&lt;/td&gt; &#xA;   &lt;td&gt;A version of the reference genome with &lt;em&gt;all&lt;/em&gt; variants instantiated&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.consensus.subs.fa&lt;/td&gt; &#xA;   &lt;td&gt;A version of the reference genome with &lt;em&gt;only substitution&lt;/em&gt; variants instantiated&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.raw.vcf&lt;/td&gt; &#xA;   &lt;td&gt;The unfiltered variant calls from Freebayes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.filt.vcf&lt;/td&gt; &#xA;   &lt;td&gt;The filtered variant calls from Freebayes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.vcf.gz&lt;/td&gt; &#xA;   &lt;td&gt;Compressed .vcf file via &lt;a href=&#34;http://blastedbio.blogspot.com.au/2011/11/bgzf-blocked-bigger-better-gzip.html&#34;&gt;BGZIP&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.vcf.gz.csi&lt;/td&gt; &#xA;   &lt;td&gt;Index for the .vcf.gz via &lt;code&gt;bcftools index&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;span&gt;⚠&lt;/span&gt; &lt;span&gt;❌&lt;/span&gt; Snippy 4.x does &lt;strong&gt;NOT&lt;/strong&gt; produce the following files that Snippy 3.x did&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Extension&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.vcf.gz.tbi&lt;/td&gt; &#xA;   &lt;td&gt;Index for the .vcf.gz via &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/27/5/718.full&#34;&gt;TABIX&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.depth.gz&lt;/td&gt; &#xA;   &lt;td&gt;Output of &lt;code&gt;samtools depth -aa&lt;/code&gt; for the &lt;code&gt;.bam&lt;/code&gt; file&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.depth.gz.tbi&lt;/td&gt; &#xA;   &lt;td&gt;Index for the &lt;code&gt;.depth.gz&lt;/code&gt; file&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Columns in the TAB/CSV/HTML formats&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CHROM&lt;/td&gt; &#xA;   &lt;td&gt;The sequence the variant was found in eg. the name after the &lt;code&gt;&amp;gt;&lt;/code&gt; in the FASTA reference&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;POS&lt;/td&gt; &#xA;   &lt;td&gt;Position in the sequence, counting from 1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TYPE&lt;/td&gt; &#xA;   &lt;td&gt;The variant type: snp msp ins del complex&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;REF&lt;/td&gt; &#xA;   &lt;td&gt;The nucleotide(s) in the reference&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ALT&lt;/td&gt; &#xA;   &lt;td&gt;The alternate nucleotide(s) supported by the reads&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;EVIDENCE&lt;/td&gt; &#xA;   &lt;td&gt;Frequency counts for REF and ALT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;If you supply a Genbank file as the &lt;code&gt;--reference&lt;/code&gt; rather than a FASTA file, Snippy will fill in these extra columns by using the genome annotation to tell you which feature was affected by the variant:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FTYPE&lt;/td&gt; &#xA;   &lt;td&gt;Class of feature affected: CDS tRNA rRNA ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;STRAND&lt;/td&gt; &#xA;   &lt;td&gt;Strand the feature was on: + - .&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;NT_POS&lt;/td&gt; &#xA;   &lt;td&gt;Nucleotide position of the variant withinthe feature / Length in nt&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AA_POS&lt;/td&gt; &#xA;   &lt;td&gt;Residue position / Length in aa (only if FTYPE is CDS)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LOCUS_TAG&lt;/td&gt; &#xA;   &lt;td&gt;The &lt;code&gt;/locus_tag&lt;/code&gt; of the feature (if it existed)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GENE&lt;/td&gt; &#xA;   &lt;td&gt;The &lt;code&gt;/gene&lt;/code&gt; tag of the feature (if it existed)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PRODUCT&lt;/td&gt; &#xA;   &lt;td&gt;The &lt;code&gt;/product&lt;/code&gt; tag of the feature (if it existed)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;EFFECT&lt;/td&gt; &#xA;   &lt;td&gt;The &lt;code&gt;snpEff&lt;/code&gt; annotated consequence of this variant (ANN tag in .vcf)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Variant Types&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Example&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;snp&lt;/td&gt; &#xA;   &lt;td&gt;Single Nucleotide Polymorphism&lt;/td&gt; &#xA;   &lt;td&gt;A =&amp;gt; T&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mnp&lt;/td&gt; &#xA;   &lt;td&gt;Multiple Nuclotide Polymorphism&lt;/td&gt; &#xA;   &lt;td&gt;GC =&amp;gt; AT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ins&lt;/td&gt; &#xA;   &lt;td&gt;Insertion&lt;/td&gt; &#xA;   &lt;td&gt;ATT =&amp;gt; AGTT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;del&lt;/td&gt; &#xA;   &lt;td&gt;Deletion&lt;/td&gt; &#xA;   &lt;td&gt;ACGG =&amp;gt; ACG&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;complex&lt;/td&gt; &#xA;   &lt;td&gt;Combination of snp/mnp&lt;/td&gt; &#xA;   &lt;td&gt;ATTC =&amp;gt; GTTA&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;The variant caller&lt;/h2&gt; &#xA;&lt;p&gt;The variant calling is done by &lt;a href=&#34;https://github.com/ekg/freebayes&#34;&gt;Freebayes&lt;/a&gt;. The key parameters under user control are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--mincov&lt;/code&gt; - the minimum number of reads covering a site to be considered (default=10)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--minfrac&lt;/code&gt; - the minimum proportion of those reads which must differ from the reference&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--minqual&lt;/code&gt; - the minimum VCF variant call &#34;quality&#34; (default=100)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Looking at variants in detail with &lt;code&gt;snippy-vcf_report&lt;/code&gt;&lt;/h2&gt; &#xA;&lt;p&gt;If you run Snippy with the &lt;code&gt;--report&lt;/code&gt; option it will automatically run &lt;code&gt;snippy-vcf_report&lt;/code&gt; and generate a &lt;code&gt;snps.report.txt&lt;/code&gt; which has a section like this for each SNP in &lt;code&gt;snps.vcf&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&amp;gt;LBB_contig000001:10332 snp A=&amp;gt;T DP=7 Q=66.3052 [7]&#xA;&#xA;         10301     10311     10321     10331     10341     10351     10361&#xA;tcttctccgagaagggaatataatttaaaaaaattcttaaataattcccttccctcccgttataaaaattcttcgcttat&#xA;........................................T.......................................&#xA;,,,,,,  ,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,t,,t,,,,,,,,,,,,,,,,g,,,,,,,g,,,,,,,,,t,&#xA;,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, .......T..................A............A.......&#xA;.........................A........A.....T...........    .........C..............&#xA;.....A.....................C..C........CT.................TA.............&#xA;,a,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,t,,,g,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,&#xA;,,,,,ga,,,,,,,c,,,,,,,t,,,,,,,,,,g,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,&#xA;                            ............T.C..............G...............G......&#xA;                                                    ,,,,,,,g,,,,,,,,g,,,,,,,,,,,&#xA;                                                           g,,,,,,,,,,,,,,,,,,,,&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you wish to generate this report &lt;em&gt;after&lt;/em&gt; you have run Snippy, you can run it directly:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd snippydir&#xA;snippy-vcf_report --cpus 8 --auto &amp;gt; snps.report.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want a HTML version for viewing in a web browser, use the &lt;code&gt;--html&lt;/code&gt; option:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd snippydir&#xA;snippy-vcf_report --html --cpus 16 --auto &amp;gt; snps.report.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It works by running &lt;code&gt;samtools tview&lt;/code&gt; for each variant, which can be very slow if you have 1000s of variants. Using &lt;code&gt;--cpus&lt;/code&gt; as high as possible is recommended.&lt;/p&gt; &#xA;&lt;h2&gt;Options&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--rgid&lt;/code&gt; will set the Read Group (&lt;code&gt;RG&lt;/code&gt;) ID (&lt;code&gt;ID&lt;/code&gt;) and Sample (&lt;code&gt;SM&lt;/code&gt;) in the BAM and VCF file. If not supplied, it will will use the &lt;code&gt;--outdir&lt;/code&gt; folder name for both &lt;code&gt;ID&lt;/code&gt; and &lt;code&gt;SM&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--mapqual&lt;/code&gt; is the minimum mapping quality to accept in variant calling. BWA MEM using &lt;code&gt;60&lt;/code&gt; to mean a read is &#34;uniquely mapped&#34;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--basequal&lt;/code&gt; is minimum quality a nucleotide needs to be used in variant calling. We use &lt;code&gt;13&lt;/code&gt; which corresponds to error probability of ~5%. It is a traditional SAMtools value.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--maxsoft&lt;/code&gt; is how many bases of an alignment to allow to be soft-clipped before discarding the alignment. This is to encourage global over local alignment, and is passed to the &lt;code&gt;samclip&lt;/code&gt; tool.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--mincov&lt;/code&gt; and &lt;code&gt;--minfrac&lt;/code&gt; are used to apply hard thresholds to the variant calling beyond the existing statistical measure.. The optimal values depend on your sequencing depth and contamination rate. Values of 10 and 0.9 are commonly used.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--targets&lt;/code&gt; takes a BED file and only calls variants in those regions. Not normally needed unless you are only interested in variants in specific locii (eg. AMR genes) but are still performing WGS rather than amplicon sequencing.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--contigs&lt;/code&gt; allows you to call SNPs from contigs rather than reads. It shreds the contigs into synthetic reads, as to put the calls on even footing with other read samples in a multi-sample analysis.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Core SNP phylogeny&lt;/h1&gt; &#xA;&lt;p&gt;If you call SNPs for multiple isolates from the same reference, you can produce an alignment of &#34;core SNPs&#34; which can be used to build a high-resolution phylogeny (ignoring possible recombination). A &#34;core site&#34; is a genomic position that is present in &lt;em&gt;all&lt;/em&gt; the samples. A core site can have the same nucleotide in every sample (&#34;monomorphic&#34;) or some samples can be different (&#34;polymorphic&#34; or &#34;variant&#34;). If we ignore the complications of &#34;ins&#34;, &#34;del&#34; variant types, and just use variant sites, these are the &#34;core SNP genome&#34;.&lt;/p&gt; &#xA;&lt;h2&gt;Input Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;a set of Snippy folders which used the same &lt;code&gt;--ref&lt;/code&gt; sequence.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Using &lt;code&gt;snippy-multi&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;To simplify running a set of isolate sequences (reads or contigs) against the same reference, you can use the &lt;code&gt;snippy-multi&lt;/code&gt; script. This script requires a &lt;em&gt;tab separated&lt;/em&gt; input file as follows, and can handle paired-end reads, single-end reads, and assembled contigs.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# input.tab = ID R1 [R2]&#xA;Isolate1&#x9;/path/to/R1.fq.gz&#x9;/path/to/R2.fq.gz&#xA;Isolate1b&#x9;/path/to/R1.fastq.gz&#x9;/path/to/R2.fastq.gz&#xA;Isolate1c&#x9;/path/to/R1.fa&#x9;&#x9;/path/to/R2.fa&#xA;# single end reads supported too&#xA;Isolate2&#x9;/path/to/SE.fq.gz&#xA;Isolate2b&#x9;/path/to/iontorrent.fastq&#xA;# or already assembled contigs if you don&#39;t have reads&#xA;Isolate3&#x9;/path/to/contigs.fa&#xA;Isolate3b&#x9;/path/to/reference.fna.gz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then one would run this to generate the output script. The first parameter should be the &lt;code&gt;input.tab&lt;/code&gt; file. The remaining parameters should be any remaining shared &lt;code&gt;snippy&lt;/code&gt; parameters. The &lt;code&gt;ID&lt;/code&gt; will be used for each isolate&#39;s &lt;code&gt;--outdir&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% snippy-multi input.tab --ref Reference.gbk --cpus 16 &amp;gt; runme.sh&#xA;&#xA;% less runme.sh   # check the script makes sense&#xA;&#xA;% sh ./runme.sh   # leave it running over lunch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will also run &lt;code&gt;snippy-core&lt;/code&gt; at the end to generate the core genome SNP alignment files &lt;code&gt;core.*&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Output Files&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Extension&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.aln&lt;/td&gt; &#xA;   &lt;td&gt;A core SNP alignment in the &lt;code&gt;--aformat&lt;/code&gt; format (default FASTA)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.full.aln&lt;/td&gt; &#xA;   &lt;td&gt;A whole genome SNP alignment (includes invariant sites)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.tab&lt;/td&gt; &#xA;   &lt;td&gt;Tab-separated columnar list of &lt;strong&gt;core&lt;/strong&gt; SNP sites with alleles but NO annotations&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.vcf&lt;/td&gt; &#xA;   &lt;td&gt;Multi-sample VCF file with genotype &lt;code&gt;GT&lt;/code&gt; tags for all discovered alleles&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.txt&lt;/td&gt; &#xA;   &lt;td&gt;Tab-separated columnar list of alignment/core-size statistics&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.ref.fa&lt;/td&gt; &#xA;   &lt;td&gt;FASTA version/copy of the &lt;code&gt;--ref&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.self_mask.bed&lt;/td&gt; &#xA;   &lt;td&gt;BED file generated if &lt;code&gt;--mask auto&lt;/code&gt; is used.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Why is &lt;code&gt;core.full.aln&lt;/code&gt; an alphabet soup?&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;core.full.aln&lt;/code&gt; file is a FASTA formatted mutliple sequence alignment file. It has one sequence for the reference, and one for each sample participating in the core genome calculation. Each sequence has the same length as the reference sequence.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Character&lt;/th&gt; &#xA;   &lt;th&gt;Meaning&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;ATGC&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Same as the reference&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;atgc&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Different from the reference&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;-&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Zero coverage in this sample &lt;strong&gt;or&lt;/strong&gt; a deletion relative to the reference&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;N&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Low coverage in this sample (based on &lt;code&gt;--mincov&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;X&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Masked region of reference (from &lt;code&gt;--mask&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;n&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Heterozygous or poor quality genotype (has &lt;code&gt;GT=0/1&lt;/code&gt; or &lt;code&gt;QUAL &amp;lt; --minqual&lt;/code&gt; in &lt;code&gt;snps.raw.vcf&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;You can remove all the &#34;weird&#34; characters and replace them with &lt;code&gt;N&lt;/code&gt; using the included &lt;code&gt;snippy-clean_full_aln&lt;/code&gt;. This is useful when you need to pass it to a tree-building or recombination-removal tool:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% snippy-clean_full_aln core.full.aln &amp;gt; clean.full.aln&#xA;% run_gubbins.py -p gubbins clean.full.aln&#xA;% snp-sites -c gubbins.filtered_polymorphic_sites.fasta &amp;gt; clean.core.aln&#xA;% FastTree -gtr -nt clean.core.aln &amp;gt; clean.core.tree&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Options&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you want to mask certain regions of the genome, you can provide a BED file with the &lt;code&gt;--mask&lt;/code&gt; parameter. Any SNPs in those regions will be excluded. This is common for genomes like &lt;em&gt;M.tuberculosis&lt;/em&gt; where pesky repetitive PE/PPE/PGRS genes cause false positives, or masking phage regions. A &lt;code&gt;--mask&lt;/code&gt; bed file for &lt;em&gt;M.tb&lt;/em&gt; is provided with Snippy in the &lt;code&gt;etc/Mtb_NC_000962.3_mask.bed&lt;/code&gt; folder. It is derived from the XLSX file from &lt;a href=&#34;https://gph.niid.go.jp/tgs-tb/&#34;&gt;https://gph.niid.go.jp/tgs-tb/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you use the &lt;code&gt;snippy --cleanup&lt;/code&gt; option the reference files will be deleted. This means &lt;code&gt;snippy-core&lt;/code&gt; can not &#34;auto-find&#34; the reference. In this case you simply use &lt;code&gt;snippy-core --reference REF&lt;/code&gt; to provide the reference in FASTA format.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Advanced usage&lt;/h1&gt; &#xA;&lt;h2&gt;Increasing speed when too many reads&lt;/h2&gt; &#xA;&lt;p&gt;Sometimes you will have far more sequencing depth that you need to call SNPs. A common problem is a whole MiSeq flowcell for a single bacterial isolate, where 25 million reads results in genome depth as high as 2000x. This makes Snippy far slower than it needs to be, as most SNPs will be recovered with 50-100x depth. If you know you have 10 times as much data as you need, Snippy can randomly sub-sample your FASTQ data:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# have 1000x depth, only need 100x so sample at 10%&#xA;snippy --subsample 0.1  ...&#xA;&amp;lt;snip&amp;gt;&#xA;Sub-sampling reads at rate 0.1&#xA;&amp;lt;snip&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Only calling SNPs in particular regions&lt;/h2&gt; &#xA;&lt;p&gt;If you are looking for specific SNPs, say AMR releated ones in particular genes in your reference genome, you can save much time by only calling variants there. Just put the regions of interest into a BED file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;snippy --targets sites.bed ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Finding SNPs between contigs&lt;/h2&gt; &#xA;&lt;p&gt;Sometimes one of your samples is only available as contigs, without corresponding FASTQ reads. You can still use these contigs with Snippy to find variants against a reference. It does this by shredding the contigs into 250 bp single-end reads at &lt;code&gt;2 &amp;amp;times; --mincov&lt;/code&gt; uniform coverage.&lt;/p&gt; &#xA;&lt;p&gt;To use this feature, instead of providing &lt;code&gt;--R1&lt;/code&gt; and &lt;code&gt;--R2&lt;/code&gt; you use the &lt;code&gt;--ctgs&lt;/code&gt; option with the contigs file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% ls&#xA;ref.gbk mutant.fasta&#xA;&#xA;% snippy --outdir mut1 --ref ref.gbk --ctgs mut1.fasta&#xA;Shredding mut1.fasta into pseudo-reads.&#xA;Identified 257 variants.&#xA;&#xA;% snippy --outdir mut2 --ref ref.gbk --ctgs mut2.fasta&#xA;Shredding mut2.fasta into pseudo-reads.&#xA;Identified 413 variants.&#xA;&#xA;% snippy-core mut1 mut2 &#xA;Found 129 core SNPs from 541 variant sites.&#xA;&#xA;% ls&#xA;core.aln core.full.aln ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This output folder is completely compatible with &lt;code&gt;snippy-core&lt;/code&gt; so you can mix FASTQ and contig based &lt;code&gt;snippy&lt;/code&gt; output folders to produce alignments.&lt;/p&gt; &#xA;&lt;h2&gt;Correcting assembly errors&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;em&gt;de novo&lt;/em&gt; assembly process attempts to reconstruct the reads into the original DNA sequences they were derived from. These reconstructed sequences are called &lt;em&gt;contigs&lt;/em&gt; or &lt;em&gt;scaffolds&lt;/em&gt;. For various reasons, small errors can be introduced into the assembled contigs which are not supported by the original reads used in the assembly process.&lt;/p&gt; &#xA;&lt;p&gt;A common strategy is to align the reads back to the contigs to check for discrepancies. These errors appear as variants (SNPs and indels). If we can &lt;em&gt;reverse&lt;/em&gt; these variants than we can &#34;correct&#34; the contigs to match the evidence provided by the original reads. Obviously this strategy can go wrong if one is not careful about &lt;em&gt;how&lt;/em&gt; the read alignment is performed and which variants are accepted.&lt;/p&gt; &#xA;&lt;p&gt;Snippy is able to help with this contig correction process. In fact, it produces a &lt;code&gt;snps.consensus.fa&lt;/code&gt; FASTA file which is the &lt;code&gt;ref.fa&lt;/code&gt; input file provided but with the discovered variants in &lt;code&gt;snps.vcf&lt;/code&gt; applied!&lt;/p&gt; &#xA;&lt;p&gt;However, Snippy is not perfect and sometimes finds questionable variants. Typically you would make a copy of &lt;code&gt;snps.vcf&lt;/code&gt; (let&#39;s call it &lt;code&gt;corrections.vcf&lt;/code&gt;) and remove those lines corresponding to variants we don&#39;t trust. For example, when correcting Roche 454 and PacBio SMRT contigs, we primarily expect to find homopolymer errors and hence expect to see &lt;code&gt;ins&lt;/code&gt; more than &lt;code&gt;snp&lt;/code&gt; type variants.&lt;/p&gt; &#xA;&lt;p&gt;In this case you need to run the correcting process manually using these steps:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% cd snippy-outdir&#xA;% cp snps.vcf corrections.vcf&#xA;% $EDITOR corrections.vcf&#xA;% bgzip -c corrections.vcf &amp;gt; corrections.vcf.gz&#xA;% tabix -p vcf corrections.vcf.gz&#xA;% vcf-consensus corrections.vcf.gz &amp;lt; ref.fa &amp;gt; corrected.fa&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may wish to &lt;em&gt;iterate&lt;/em&gt; this process by using &lt;code&gt;corrected.fa&lt;/code&gt; as a new &lt;code&gt;--ref&lt;/code&gt; for a repeated run of Snippy. Sometimes correcting one error allows BWA to align things it couldn&#39;t before, and new errors are uncovered.&lt;/p&gt; &#xA;&lt;p&gt;Snippy may not be the best way to correct assemblies - you should consider dedicated tools such as &lt;a href=&#34;http://www.broadinstitute.org/software/pilon/&#34;&gt;PILON&lt;/a&gt; or &lt;a href=&#34;http://icorn.sourceforge.net/&#34;&gt;iCorn2&lt;/a&gt;, or adjust the Quiver parameters (for Pacbio data).&lt;/p&gt; &#xA;&lt;h2&gt;Unmapped Reads&lt;/h2&gt; &#xA;&lt;p&gt;Sometimes you are interested in the reads which did &lt;em&gt;not&lt;/em&gt; align to the reference genome. These reads represent DNA that was novel to &lt;em&gt;your&lt;/em&gt; sample which is potentially interesting. A standard strategy is to &lt;em&gt;de novo&lt;/em&gt; assemble the unmapped reads to discover these novel DNA elements, which often comprise mobile genetic elements such as plasmids.&lt;/p&gt; &#xA;&lt;p&gt;By default, Snippy does &lt;strong&gt;not&lt;/strong&gt; keep the unmapped reads, not even in the BAM file. If you wish to keep them, use the &lt;code&gt;--unmapped&lt;/code&gt; option and the unaligned reads will be saved to a compressed FASTQ file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% snippy --outdir out --unmapped ....&#xA;&#xA;% ls out/&#xA;snps.unmapped.fastq.gz ....&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Information&lt;/h1&gt; &#xA;&lt;h2&gt;Etymology&lt;/h2&gt; &#xA;&lt;p&gt;The name Snippy is a combination of &lt;a href=&#34;http://en.wikipedia.org/wiki/Single-nucleotide_polymorphism&#34;&gt;SNP&lt;/a&gt; (pronounced &#34;snip&#34;) , &lt;a href=&#34;http://www.thefreedictionary.com/snappy&#34;&gt;snappy&lt;/a&gt; (meaning &#34;quick&#34;) and &lt;a href=&#34;http://en.wikipedia.org/wiki/Skippy_the_Bush_Kangaroo&#34;&gt;Skippy the Bush Kangaroo&lt;/a&gt; (to represent its Australian origin)&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Snippy is free software, released under the &lt;a href=&#34;https://raw.githubusercontent.com/tseemann/snippy/master/LICENSE&#34;&gt;GPL (version 2)&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Issues&lt;/h2&gt; &#xA;&lt;p&gt;Please submit suggestions and bug reports to the &lt;a href=&#34;https://github.com/tseemann/snippy/issues&#34;&gt;Issue Tracker&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;perl &amp;gt;= 5.18&lt;/li&gt; &#xA; &lt;li&gt;bioperl &amp;gt;= 1.7&lt;/li&gt; &#xA; &lt;li&gt;bwa mem &amp;gt;= 0.7.12&lt;/li&gt; &#xA; &lt;li&gt;minimap2 &amp;gt;= 2.0&lt;/li&gt; &#xA; &lt;li&gt;samtools &amp;gt;= 1.7&lt;/li&gt; &#xA; &lt;li&gt;bcftools &amp;gt;= 1.7&lt;/li&gt; &#xA; &lt;li&gt;bedtools &amp;gt;= 2.0&lt;/li&gt; &#xA; &lt;li&gt;GNU parallel &amp;gt;= 2013xxxx&lt;/li&gt; &#xA; &lt;li&gt;freebayes &amp;gt;= 1.1 (freebayes, freebayes-parallel, fasta_generate_regions.py)&lt;/li&gt; &#xA; &lt;li&gt;vcflib &amp;gt;= 1.0 (vcfstreamsort, vcfuniq, vcffirstheader)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://genome.sph.umich.edu/wiki/Vt&#34;&gt;vt&lt;/a&gt; &amp;gt;= 0.5&lt;/li&gt; &#xA; &lt;li&gt;snpEff &amp;gt;= 4.3&lt;/li&gt; &#xA; &lt;li&gt;samclip &amp;gt;= 0.2&lt;/li&gt; &#xA; &lt;li&gt;seqtk &amp;gt;= 1.2&lt;/li&gt; &#xA; &lt;li&gt;snp-sites &amp;gt;= 2.0&lt;/li&gt; &#xA; &lt;li&gt;any2fasta &amp;gt;= 0.4&lt;/li&gt; &#xA; &lt;li&gt;wgsim &amp;gt;= 1.8 (for testing only - &lt;code&gt;wgsim&lt;/code&gt; command)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Bundled binaries&lt;/h2&gt; &#xA;&lt;p&gt;For Linux (compiled on Ubuntu 16.04 LTS) and macOS (compiled on High Sierra Brew) some of the binaries, JARs and scripts are included.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>sullo/nikto</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/sullo/nikto</id>
    <link href="https://github.com/sullo/nikto" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Nikto web server scanner&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;nikto&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.patreon.com/sullo&#34;&gt;&lt;img src=&#34;https://cirt.net/images/patreon.png&#34; alt=&#34;alt text&#34; title=&#34;Become a patron of Nikto!&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Nikto web server scanner - &lt;a href=&#34;https://cirt.net/Nikto2&#34;&gt;https://cirt.net/Nikto2&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Full documentation - &lt;a href=&#34;https://github.com/sullo/nikto/wiki&#34;&gt;https://github.com/sullo/nikto/wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Run normally:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/sullo/nikto&#xA;# Main script is in program/&#xA;cd nikto/program&#xA;# Run using the shebang interpreter&#xA;./nikto.pl -h http://www.example.com&#xA;# Run using perl (if you forget to chmod)&#xA;perl nikto.pl -h http://www.example.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run as a Docker container:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/sullo/nikto.git&#xA;cd nikto&#xA;docker build -t sullo/nikto .&#xA;# Call it without arguments to display the full help&#xA;docker run --rm sullo/nikto&#xA;# Basic usage&#xA;docker run --rm sullo/nikto -h http://www.example.com&#xA;# To save the report in a specific format, mount /tmp as a volume:&#xA;docker run --rm -v $(pwd):/tmp sullo/nikto -h http://www.example.com -o /tmp/out.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Basic usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;   Options:&#xA;       -ask+               Whether to ask about submitting updates&#xA;                               yes   Ask about each (default)&#xA;                               no    Don&#39;t ask, don&#39;t send&#xA;                               auto  Don&#39;t ask, just send&#xA;       -Cgidirs+           Scan these CGI dirs: &#34;none&#34;, &#34;all&#34;, or values like &#34;/cgi/ /cgi-a/&#34;&#xA;       -config+            Use this config file&#xA;       -Display+           Turn on/off display outputs:&#xA;                               1     Show redirects&#xA;                               2     Show cookies received&#xA;                               3     Show all 200/OK responses&#xA;                               4     Show URLs which require authentication&#xA;                               D     Debug output&#xA;                               E     Display all HTTP errors&#xA;                               P     Print progress to STDOUT&#xA;                               S     Scrub output of IPs and hostnames&#xA;                               V     Verbose output&#xA;       -dbcheck           Check database and other key files for syntax errors&#xA;       -evasion+          Encoding technique:&#xA;                               1     Random URI encoding (non-UTF8)&#xA;                               2     Directory self-reference (/./)&#xA;                               3     Premature URL ending&#xA;                               4     Prepend long random string&#xA;                               5     Fake parameter&#xA;                               6     TAB as request spacer&#xA;                               7     Change the case of the URL&#xA;                               8     Use Windows directory separator (\)&#xA;                               A     Use a carriage return (0x0d) as a request spacer&#xA;                               B     Use binary value 0x0b as a request spacer&#xA;        -Format+           Save file (-o) format:&#xA;                               csv   Comma-separated-value&#xA;                               htm   HTML Format&#xA;                               msf+  Log to Metasploit&#xA;                               nbe   Nessus NBE format&#xA;                               txt   Plain text&#xA;                               xml   XML Format&#xA;                               (if not specified the format will be taken from the file extension passed to -output)&#xA;       -Help              Extended help information&#xA;       -host+             Target host&#xA;       -IgnoreCode        Ignore Codes--treat as negative responses&#xA;       -id+               Host authentication to use, format is id:pass or id:pass:realm&#xA;       -key+              Client certificate key file&#xA;       -list-plugins      List all available plugins, perform no testing&#xA;       -maxtime+          Maximum testing time per host&#xA;       -mutate+           Guess additional file names:&#xA;                               1     Test all files with all root directories&#xA;                               2     Guess for password file names&#xA;                               3     Enumerate user names via Apache (/~user type requests)&#xA;                               4     Enumerate user names via cgiwrap (/cgi-bin/cgiwrap/~user type requests)&#xA;                               5     Attempt to brute force sub-domain names, assume that the host name is the parent domain&#xA;                               6     Attempt to guess directory names from the supplied dictionary file&#xA;       -mutate-options    Provide information for mutates&#xA;       -nointeractive     Disables interactive features&#xA;       -nolookup          Disables DNS lookups&#xA;       -nossl             Disables the use of SSL&#xA;       -no404             Disables nikto attempting to guess a 404 page&#xA;       -output+           Write output to this file (&#39;.&#39; for auto-name)&#xA;       -Pause+            Pause between tests (seconds, integer or float)&#xA;       -Plugins+          List of plugins to run (default: ALL)&#xA;       -port+             Port to use (default 80)&#xA;       -RSAcert+          Client certificate file&#xA;       -root+             Prepend root value to all requests, format is /directory&#xA;       -Save              Save positive responses to this directory (&#39;.&#39; for auto-name)&#xA;       -ssl               Force ssl mode on port&#xA;       -Tuning+           Scan tuning:&#xA;                               1     Interesting File / Seen in logs&#xA;                               2     Misconfiguration / Default File&#xA;                               3     Information Disclosure&#xA;                               4     Injection (XSS/Script/HTML)&#xA;                               5     Remote File Retrieval - Inside Web Root&#xA;                               6     Denial of Service&#xA;                               7     Remote File Retrieval - Server Wide&#xA;                               8     Command Execution / Remote Shell&#xA;                               9     SQL Injection&#xA;                               0     File Upload&#xA;                               a     Authentication Bypass&#xA;                               b     Software Identification&#xA;                               c     Remote Source Inclusion&#xA;                               x     Reverse Tuning Options (i.e., include all except specified)&#xA;       -timeout+          Timeout for requests (default 10 seconds)&#xA;       -Userdbs           Load only user databases, not the standard databases&#xA;                               all   Disable standard dbs and load only user dbs&#xA;                               tests Disable only db_tests and load udb_tests&#xA;       -until             Run until the specified time or duration&#xA;       -update            Update databases and plugins from CIRT.net&#xA;       -useproxy          Use the proxy defined in nikto.conf&#xA;       -Version           Print plugin and database versions&#xA;       -vhost+            Virtual host (for Host header)&#xA;              + requires a value&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;Copyright (C) 2001 Chris Sullo&lt;/p&gt; &#xA;&lt;p&gt;This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; version 2 of the License only.&lt;/p&gt; &#xA;&lt;p&gt;This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.&lt;/p&gt; &#xA;&lt;p&gt;You should have received a copy of the GNU General Public License along with this program; if not, write to Free Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>asbru-cm/asbru-cm</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/asbru-cm/asbru-cm</id>
    <link href="https://github.com/asbru-cm/asbru-cm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Ásbrú Connection Manager is a user interface that helps organizing remote terminal sessions and automating repetitive tasks.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ásbrú Connection Manager&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://app.travis-ci.com/github/asbru-cm/asbru-cm&#34;&gt;&lt;img src=&#34;https://api.travis-ci.com/asbru-cm/asbru-cm.svg?branch=master&#34; alt=&#34;Travis&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/asbru-cm/asbru-cm/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-GPL--3-blue.svg?style=flat&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagecloud.io/asbru-cm/asbru-cm?filter=rpms&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Packages-RPM-blue.svg?style=flat&#34; alt=&#34;RPM Packages&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagecloud.io/asbru-cm/asbru-cm?filter=debs&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Packages-Debian-blue.svg?style=flat&#34; alt=&#34;Debian Packages&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://liberapay.com/asbru-cm/donate&#34;&gt;&lt;img src=&#34;http://img.shields.io/liberapay/patrons/asbru-cm.svg?logo=liberapay&#34; alt=&#34;Liberapay&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://blockchain.info/address/19ZsvCafwRCwQSPcvfzgyiHD3Viptb4F45&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/bitcoin-19ZsvCafwRCwQSPcvfzgyiHD3Viptb4F45-D28138.svg?style=flat-square&#34; alt=&#34;Donate Bitcoins&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://asbru-cm.net&#34;&gt;&lt;img src=&#34;https://www.asbru-cm.net/assets/img/asbru-logo-200.png&#34; align=&#34;right&#34; width=&#34;200px&#34; height=&#34;200px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;A free and open-source connection manager&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Ásbrú Connection Manager&lt;/strong&gt; is a user interface that helps organizing remote terminal sessions and automating repetitive tasks.&lt;/p&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Simple GUI to manage/launch connections to remote machines&lt;/li&gt; &#xA; &lt;li&gt;Scripting possibilities, &#39;ala&#39; SecureCRT&lt;/li&gt; &#xA; &lt;li&gt;Configurable pre or post connection local commands execution&lt;/li&gt; &#xA; &lt;li&gt;Configurable list of macros (commands) to execute locally when connected or to send to connected client&lt;/li&gt; &#xA; &lt;li&gt;Configurable list of conditional executions on connected machine via &#39;Expect&#39;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;forget about SSH certificates&lt;/li&gt; &#xA;   &lt;li&gt;chain multiple SSH connections&lt;/li&gt; &#xA;   &lt;li&gt;automate tunnels creation&lt;/li&gt; &#xA;   &lt;li&gt;with line-send delay capabilities&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://keepassxc.org/&#34;&gt;KeePassXC&lt;/a&gt; integration&lt;/li&gt; &#xA; &lt;li&gt;Ability to connect to machines through a Proxy server&lt;/li&gt; &#xA; &lt;li&gt;Cluster connections&lt;/li&gt; &#xA; &lt;li&gt;Tabbed/Windowed terminals&lt;/li&gt; &#xA; &lt;li&gt;Wake On LAN capabilities&lt;/li&gt; &#xA; &lt;li&gt;Local and global variables, eg.: write down a password once, use it ANY where, centralizing its modification for faster changes! use them for: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;password vault&lt;/li&gt; &#xA;   &lt;li&gt;reusing connection strings&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Seamless Gnome/Gtk integration&lt;/li&gt; &#xA; &lt;li&gt;Tray icon for &#39;right button&#39; quick launching of managed connections. Screenshots and statistics.&lt;/li&gt; &#xA; &lt;li&gt;DEB, RPM and .TAR.GZ packages available&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;We recommend installing Ásbrú Connection Manager using our latest pre-built packages hosted on &lt;a href=&#34;https://cloudsmith.io/&#34;&gt;cloudsmith.io&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To do so, execute the following commands:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Debian / Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code&gt;curl -1sLf &#39;https://dl.cloudsmith.io/public/asbru-cm/release/cfg/setup/bash.deb.sh&#39; | sudo -E bash&#xA;sudo apt-get install asbru-cm&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fedora&lt;/p&gt; &lt;pre&gt;&lt;code&gt;curl -1sLf &#39;https://dl.cloudsmith.io/public/asbru-cm/release/cfg/setup/bash.rpm.sh&#39; | sudo -E bash&#xA;sudo dnf install asbru-cm&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Pacman-based (e.g. Arch Linux, Manjaro)&lt;/p&gt; &lt;pre&gt;&lt;code&gt;git clone https://aur.archlinux.org/asbru-cm-git.git &amp;amp;&amp;amp; cd asbru-cm-git&#xA;makepkg -si&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MX Linux&lt;/p&gt; &lt;p&gt;Ásbrú Connection Manager can be installed through the MX Package Installer under the Test Repo tab or by enabling the Test Repo and running&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo apt-get install asbru-cm&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Windows&lt;/p&gt; &lt;p&gt;It is possible to run Asbru-CM on Windows 10 by enabling WSL and installing &lt;a href=&#34;http://www.straightrunning.com/XmingNotes/&#34;&gt;Xming&lt;/a&gt;. The application &lt;a href=&#34;https://github.com/SegiH/Asbru-CM-Runner&#34;&gt;Asbru-CM Runner&lt;/a&gt; has detailed instructions on how to do this and allows you to run Asbru-CM on Windows 10 without a console window open in the background.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Once installed on your system, type &lt;code&gt;asbru-cm&lt;/code&gt; in your terminal.&lt;/p&gt; &#xA;&lt;h3&gt;Testing new features&lt;/h3&gt; &#xA;&lt;p&gt;Our master and the snapshots are being kept as stable as possible. New features for new major releases are being developed inside the &#34;loki&#34; branch.&lt;/p&gt; &#xA;&lt;p&gt;Beware that &lt;a href=&#34;https://en.wikipedia.org/wiki/Loki&#34;&gt;Loki&lt;/a&gt; can sometimes behave in an unexpected manner to you. This is somehow the same concept as the &#34;&lt;a href=&#34;https://www.debian.org/releases/sid/&#34;&gt;Debian sid&lt;/a&gt;&#34; release.&lt;/p&gt; &#xA;&lt;p&gt;You are welcome to contribute and test by checking out &#34;loki&#34; or by installing our builds.&lt;/p&gt; &#xA;&lt;p&gt;If you do not wish to run third party scripts on your systems, you can always access manual install instructions at &lt;a href=&#34;https://cloudsmith.io/~asbru-cm/repos/loki/setup/&#34;&gt;https://cloudsmith.io/~asbru-cm/repos/loki/setup/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Debian / Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code&gt; curl -1sLf &#39;https://dl.cloudsmith.io/public/asbru-cm/loki/cfg/setup/bash.deb.sh&#39; | sudo -E bash&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fedora&lt;/p&gt; &lt;pre&gt;&lt;code&gt; curl -1sLf &#39;https://dl.cloudsmith.io/public/asbru-cm/loki/cfg/setup/bash.rpm.sh&#39; | sudo -E bash&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation of legacy 5.x&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Debian / Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ curl -s https://packagecloud.io/install/repositories/asbru-cm/v5/script.deb.sh | sudo bash&#xA;$ sudo apt-get install asbru-cm&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fedora&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ curl -s https://packagecloud.io/install/repositories/asbru-cm/v5/script.rpm.sh | sudo bash&#xA;$ sudo dnf install asbru-cm&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Frequenty Asked Questions&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Why did you call that project &#34;Ásbrú&#34; ?&lt;/p&gt; &lt;p&gt;In Norse mythology, &lt;a href=&#34;https://en.wikipedia.org/wiki/Bifr%C3%B6st&#34;&gt;Ásbrú&lt;/a&gt; refers to a burning rainbow bridge that connects Midgard (Earth) and Asgard, the realm of the gods.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Is this a fork of PAC (Perl Auto Connector) Manager ?&lt;/p&gt; &lt;p&gt;Yes.&lt;/p&gt; &lt;p&gt;As &lt;a href=&#34;https://github.com/perseo22&#34;&gt;David Torrejon Vaquerizas&lt;/a&gt;, the author of PAC Manager, could not find time, for some reasons that we respect, to continue the work on his project and was not open for external contributions (&lt;a href=&#34;https://github.com/perseo22/pacmanager/issues/57&#34;&gt;see this&lt;/a&gt;), a fork was needed to ensure the future and give the opportunity to the community to take over.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;More questions can be found on the &lt;a href=&#34;https://github.com/asbru-cm/asbru-cm/wiki/Frequently-Asked-Questions&#34;&gt;dedicated project wiki page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Contributing&lt;/h3&gt; &#xA;&lt;p&gt;If you want to contribute to Ásbrú Connection Manager, first check out the &lt;a href=&#34;https://github.com/asbru-cm/asbru-cm/issues&#34;&gt;issues&lt;/a&gt; and see if your request is not listed yet. Issues and pull requests will be triaged and responded to as quickly as possible.&lt;/p&gt; &#xA;&lt;p&gt;Before contributing, please review our &lt;a href=&#34;https://github.com/asbru-cm/asbru-cm/raw/master/CONTRIBUTING.md&#34;&gt;contributing doc&lt;/a&gt; for info on how to make feature requests and bear in mind that we adhere to the &lt;a href=&#34;https://github.com/asbru-cm/asbru-cm/raw/master/CODE_OF_CONDUCT.md&#34;&gt;Contributor Covenant code of conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Financial support&lt;/h3&gt; &#xA;&lt;p&gt;If you like Ásbrú Connection Manager, you may also consider supporting the project financially by donating on &lt;a title=&#34;Donate Liberapay&#34; href=&#34;https://liberapay.com/asbru-cm/donate&#34;&gt;Liberapay&lt;/a&gt; or by donating to one of &lt;a href=&#34;https://docs.asbru-cm.net/Contributing/Financial_Contribution/&#34;&gt;our cryptocurrency addresses&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;Ásbrú Connection Manager is licensed under the GNU General Public License version 3 &lt;a href=&#34;http://www.gnu.org/licenses/gpl-3.0.html&#34;&gt;http://www.gnu.org/licenses/gpl-3.0.html&lt;/a&gt;. A full copy of the license can be found in the &lt;a href=&#34;https://github.com/asbru-cm/asbru-cm/raw/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;h3&gt;Sponsors&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a title=&#34;Cloudflare&#34; href=&#34;https://cloudflare.com/&#34;&gt;&lt;img height=&#34;105&#34; width=&#34;230&#34; alt=&#34;Cloudflare&#34; src=&#34;https://www.cloudflare.com/img/logo-web-badges/cf-logo-on-white-bg.svg?sanitize=true&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Packages&lt;/h3&gt; &#xA;&lt;p&gt;The repositories for our RPM and DEB builds are thankfully sponsored by &lt;a href=&#34;https://packagecloud.io/&#34;&gt;packagecloud&lt;/a&gt; and &lt;a href=&#34;https://cloudsmith.io&#34;&gt;Cloudsmith&lt;/a&gt;. A great thanks to them.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a title=&#34;Private Maven, RPM, DEB, PyPi and RubyGem Repository&#34; href=&#34;https://packagecloud.io/&#34;&gt;&lt;img height=&#34;46&#34; width=&#34;158&#34; alt=&#34;Private Maven, RPM, DEB, PyPi and RubyGem Repository&#34; src=&#34;https://packagecloud.io/images/packagecloud-badge.png&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cloudsmith.com/&#34;&gt;&lt;img height=&#34;46&#34; widht=&#34;158&#34; alt=&#34;Fast, secure development and distribution. Universal, web-scale package management&#34; src=&#34;https://www.asbru-cm.net/assets/img/misc/cloudsmith-logo-color.png&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>brendangregg/FlameGraph</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/brendangregg/FlameGraph</id>
    <link href="https://github.com/brendangregg/FlameGraph" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stack trace visualizer&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Flame Graphs visualize profiled code&lt;/h1&gt; &#xA;&lt;p&gt;Main Website: &lt;a href=&#34;http://www.brendangregg.com/flamegraphs.html&#34;&gt;http://www.brendangregg.com/flamegraphs.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Example (click to zoom):&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.brendangregg.com/FlameGraphs/cpu-bash-flamegraph.svg&#34;&gt;&lt;img src=&#34;http://www.brendangregg.com/FlameGraphs/cpu-bash-flamegraph.svg?sanitize=true&#34; alt=&#34;Example&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Click a box to zoom the Flame Graph to this stack frame only. To search and highlight all stack frames matching a regular expression, click the &lt;em&gt;search&lt;/em&gt; button in the upper right corner or press Ctrl-F. By default, search is case sensitive, but this can be toggled by pressing Ctrl-I or by clicking the &lt;em&gt;ic&lt;/em&gt; button in the upper right corner.&lt;/p&gt; &#xA;&lt;p&gt;Other sites:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The Flame Graph article in ACMQ and CACM: &lt;a href=&#34;http://queue.acm.org/detail.cfm?id=2927301&#34;&gt;http://queue.acm.org/detail.cfm?id=2927301&lt;/a&gt; &lt;a href=&#34;http://cacm.acm.org/magazines/2016/6/202665-the-flame-graph/abstract&#34;&gt;http://cacm.acm.org/magazines/2016/6/202665-the-flame-graph/abstract&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CPU profiling using Linux perf_events, DTrace, SystemTap, or ktap: &lt;a href=&#34;http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html&#34;&gt;http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CPU profiling using XCode Instruments: &lt;a href=&#34;http://schani.wordpress.com/2012/11/16/flame-graphs-for-instruments/&#34;&gt;http://schani.wordpress.com/2012/11/16/flame-graphs-for-instruments/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CPU profiling using Xperf.exe: &lt;a href=&#34;http://randomascii.wordpress.com/2013/03/26/summarizing-xperf-cpu-usage-with-flame-graphs/&#34;&gt;http://randomascii.wordpress.com/2013/03/26/summarizing-xperf-cpu-usage-with-flame-graphs/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Memory profiling: &lt;a href=&#34;http://www.brendangregg.com/FlameGraphs/memoryflamegraphs.html&#34;&gt;http://www.brendangregg.com/FlameGraphs/memoryflamegraphs.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Other examples, updates, and news: &lt;a href=&#34;http://www.brendangregg.com/flamegraphs.html#Updates&#34;&gt;http://www.brendangregg.com/flamegraphs.html#Updates&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Flame graphs can be created in three steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Capture stacks&lt;/li&gt; &#xA; &lt;li&gt;Fold stacks&lt;/li&gt; &#xA; &lt;li&gt;flamegraph.pl&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;1. Capture stacks&lt;/h1&gt; &#xA;&lt;p&gt;Stack samples can be captured using Linux perf_events, FreeBSD pmcstat (hwpmc), DTrace, SystemTap, and many other profilers. See the stackcollapse-* converters.&lt;/p&gt; &#xA;&lt;h3&gt;Linux perf_events&lt;/h3&gt; &#xA;&lt;p&gt;Using Linux perf_events (aka &#34;perf&#34;) to capture 60 seconds of 99 Hertz stack samples, both user- and kernel-level stacks, all processes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# perf record -F 99 -a -g -- sleep 60&#xA;# perf script &amp;gt; out.perf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now only capturing PID 181:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# perf record -F 99 -p 181 -g -- sleep 60&#xA;# perf script &amp;gt; out.perf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;DTrace&lt;/h3&gt; &#xA;&lt;p&gt;Using DTrace to capture 60 seconds of kernel stacks at 997 Hertz:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# dtrace -x stackframes=100 -n &#39;profile-997 /arg0/ { @[stack()] = count(); } tick-60s { exit(0); }&#39; -o out.kern_stacks&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Using DTrace to capture 60 seconds of user-level stacks for PID 12345 at 97 Hertz:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# dtrace -x ustackframes=100 -n &#39;profile-97 /pid == 12345 &amp;amp;&amp;amp; arg1/ { @[ustack()] = count(); } tick-60s { exit(0); }&#39; -o out.user_stacks&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;60 seconds of user-level stacks, including time spent in-kernel, for PID 12345 at 97 Hertz:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# dtrace -x ustackframes=100 -n &#39;profile-97 /pid == 12345/ { @[ustack()] = count(); } tick-60s { exit(0); }&#39; -o out.user_stacks&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Switch &lt;code&gt;ustack()&lt;/code&gt; for &lt;code&gt;jstack()&lt;/code&gt; if the application has a ustack helper to include translated frames (eg, node.js frames; see: &lt;a href=&#34;http://dtrace.org/blogs/dap/2012/01/05/where-does-your-node-program-spend-its-time/&#34;&gt;http://dtrace.org/blogs/dap/2012/01/05/where-does-your-node-program-spend-its-time/&lt;/a&gt;). The rate for user-level stack collection is deliberately slower than kernel, which is especially important when using &lt;code&gt;jstack()&lt;/code&gt; as it performs additional work to translate frames.&lt;/p&gt; &#xA;&lt;h1&gt;2. Fold stacks&lt;/h1&gt; &#xA;&lt;p&gt;Use the stackcollapse programs to fold stack samples into single lines. The programs provided are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse.pl&lt;/code&gt;: for DTrace stacks&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-perf.pl&lt;/code&gt;: for Linux perf_events &#34;perf script&#34; output&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-pmc.pl&lt;/code&gt;: for FreeBSD pmcstat -G stacks&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-stap.pl&lt;/code&gt;: for SystemTap stacks&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-instruments.pl&lt;/code&gt;: for XCode Instruments&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-vtune.pl&lt;/code&gt;: for Intel VTune profiles&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-ljp.awk&lt;/code&gt;: for Lightweight Java Profiler&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-jstack.pl&lt;/code&gt;: for Java jstack(1) output&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-gdb.pl&lt;/code&gt;: for gdb(1) stacks&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-go.pl&lt;/code&gt;: for Golang pprof stacks&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-vsprof.pl&lt;/code&gt;: for Microsoft Visual Studio profiles&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stackcollapse-wcp.pl&lt;/code&gt;: for wallClockProfiler output&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Usage example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;For perf_events:&#xA;$ ./stackcollapse-perf.pl out.perf &amp;gt; out.folded&#xA;&#xA;For DTrace:&#xA;$ ./stackcollapse.pl out.kern_stacks &amp;gt; out.kern_folded&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The output looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;unix`_sys_sysenter_post_swapgs 1401&#xA;unix`_sys_sysenter_post_swapgs;genunix`close 5&#xA;unix`_sys_sysenter_post_swapgs;genunix`close;genunix`closeandsetf 85&#xA;unix`_sys_sysenter_post_swapgs;genunix`close;genunix`closeandsetf;c2audit`audit_closef 26&#xA;unix`_sys_sysenter_post_swapgs;genunix`close;genunix`closeandsetf;c2audit`audit_setf 5&#xA;unix`_sys_sysenter_post_swapgs;genunix`close;genunix`closeandsetf;genunix`audit_getstate 6&#xA;unix`_sys_sysenter_post_swapgs;genunix`close;genunix`closeandsetf;genunix`audit_unfalloc 2&#xA;unix`_sys_sysenter_post_swapgs;genunix`close;genunix`closeandsetf;genunix`closef 48&#xA;[...]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;3. flamegraph.pl&lt;/h1&gt; &#xA;&lt;p&gt;Use flamegraph.pl to render a SVG.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./flamegraph.pl out.kern_folded &amp;gt; kernel.svg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;An advantage of having the folded input file (and why this is separate to flamegraph.pl) is that you can use grep for functions of interest. Eg:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ grep cpuid out.kern_folded | ./flamegraph.pl &amp;gt; cpuid.svg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Provided Examples&lt;/h1&gt; &#xA;&lt;h3&gt;Linux perf_events&lt;/h3&gt; &#xA;&lt;p&gt;An example output from Linux &#34;perf script&#34; is included, gzip&#39;d, as example-perf-stacks.txt.gz. The resulting flame graph is example-perf.svg:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.brendangregg.com/FlameGraphs/example-perf.svg&#34;&gt;&lt;img src=&#34;http://www.brendangregg.com/FlameGraphs/example-perf.svg?sanitize=true&#34; alt=&#34;Example&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can create this using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ gunzip -c example-perf-stacks.txt.gz | ./stackcollapse-perf.pl --all | ./flamegraph.pl --color=java --hash &amp;gt; example-perf.svg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This shows my typical workflow: I&#39;ll gzip profiles on the target, then copy them to my laptop for analysis. Since I have hundreds of profiles, I leave them gzip&#39;d!&lt;/p&gt; &#xA;&lt;p&gt;Since this profile included Java, I used the flamegraph.pl --color=java palette. I&#39;ve also used stackcollapse-perf.pl --all, which includes all annotations that help flamegraph.pl use separate colors for kernel and user level code. The resulting flame graph uses: green == Java, yellow == C++, red == user-mode native, orange == kernel.&lt;/p&gt; &#xA;&lt;p&gt;This profile was from an analysis of vert.x performance. The benchmark client, wrk, is also visible in the flame graph.&lt;/p&gt; &#xA;&lt;h3&gt;DTrace&lt;/h3&gt; &#xA;&lt;p&gt;An example output from DTrace is also included, example-dtrace-stacks.txt, and the resulting flame graph, example-dtrace.svg:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.brendangregg.com/FlameGraphs/example-dtrace.svg&#34;&gt;&lt;img src=&#34;http://www.brendangregg.com/FlameGraphs/example-dtrace.svg?sanitize=true&#34; alt=&#34;Example&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can generate this using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./stackcollapse.pl example-stacks.txt | ./flamegraph.pl &amp;gt; example.svg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This was from a particular performance investigation: the Flame Graph identified that CPU time was spent in the lofs module, and quantified that time.&lt;/p&gt; &#xA;&lt;h1&gt;Options&lt;/h1&gt; &#xA;&lt;p&gt;See the USAGE message (--help) for options:&lt;/p&gt; &#xA;&lt;p&gt;USAGE: ./flamegraph.pl [options] infile &amp;gt; outfile.svg&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;--title TEXT     # change title text&#xA;--subtitle TEXT  # second level title (optional)&#xA;--width NUM      # width of image (default 1200)&#xA;--height NUM     # height of each frame (default 16)&#xA;--minwidth NUM   # omit smaller functions (default 0.1 pixels)&#xA;--fonttype FONT  # font type (default &#34;Verdana&#34;)&#xA;--fontsize NUM   # font size (default 12)&#xA;--countname TEXT # count type label (default &#34;samples&#34;)&#xA;--nametype TEXT  # name type label (default &#34;Function:&#34;)&#xA;--colors PALETTE # set color palette. choices are: hot (default), mem,&#xA;                 # io, wakeup, chain, java, js, perl, red, green, blue,&#xA;                 # aqua, yellow, purple, orange&#xA;--bgcolors COLOR # set background colors. gradient choices are yellow&#xA;                 # (default), blue, green, grey; flat colors use &#34;#rrggbb&#34;&#xA;--hash           # colors are keyed by function name hash&#xA;--cp             # use consistent palette (palette.map)&#xA;--reverse        # generate stack-reversed flame graph&#xA;--inverted       # icicle graph&#xA;--flamechart     # produce a flame chart (sort by time, do not merge stacks)&#xA;--negate         # switch differential hues (blue&amp;lt;-&amp;gt;red)&#xA;--notes TEXT     # add notes comment in SVG (for debugging)&#xA;--help           # this message&#xA;&#xA;eg,&#xA;./flamegraph.pl --title=&#34;Flame Graph: malloc()&#34; trace.txt &amp;gt; graph.svg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As suggested in the example, flame graphs can process traces of any event, such as malloc()s, provided stack traces are gathered.&lt;/p&gt; &#xA;&lt;h1&gt;Consistent Palette&lt;/h1&gt; &#xA;&lt;p&gt;If you use the &lt;code&gt;--cp&lt;/code&gt; option, it will use the $colors selection and randomly generate the palette like normal. Any future flamegraphs created using the &lt;code&gt;--cp&lt;/code&gt; option will use the same palette map. Any new symbols from future flamegraphs will have their colors randomly generated using the $colors selection.&lt;/p&gt; &#xA;&lt;p&gt;If you don&#39;t like the palette, just delete the palette.map file.&lt;/p&gt; &#xA;&lt;p&gt;This allows your to change your colorscheme between flamegraphs to make the differences REALLY stand out.&lt;/p&gt; &#xA;&lt;p&gt;Example:&lt;/p&gt; &#xA;&lt;p&gt;Say we have 2 captures, one with a problem, and one when it was working (whatever &#34;it&#34; is):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cat working.folded | ./flamegraph.pl --cp &amp;gt; working.svg&#xA;# this generates a palette.map, as per the normal random generated look.&#xA;&#xA;cat broken.folded | ./flamegraph.pl --cp --colors mem &amp;gt; broken.svg&#xA;# this svg will use the same palette.map for the same events, but a very&#xA;# different colorscheme for any new events.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Take a look at the demo directory for an example:&lt;/p&gt; &#xA;&lt;p&gt;palette-example-working.svg&lt;br&gt; palette-example-broken.svg&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>centreon/centreon-plugins</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/centreon/centreon-plugins</id>
    <link href="https://github.com/centreon/centreon-plugins" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Collection of standard plugins to discover and gather cloud-to-edge metrics and status across your whole IT infrastructure.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;centreon-plugins&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/centreon/centreon-plugins/raw/master/LICENSE.txt&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-APACHE2-brightgreen.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- SHIELDS --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/centreon/centreon-plugins/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/centreon/centreon-plugins?color=%2384BD00&amp;amp;label=CONTRIBUTORS&amp;amp;style=for-the-badge&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/centreon/centreon-plugins/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/centreon/centreon-plugins?color=%23433b02a&amp;amp;label=STARS&amp;amp;style=for-the-badge&#34; alt=&#34;Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/centreon/centreon-plugins/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/centreon/centreon-plugins?color=%23009fdf&amp;amp;label=FORKS&amp;amp;style=for-the-badge&#34; alt=&#34;Forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/centreon/centreon-plugins/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/centreon/centreon-plugins?color=%230072ce&amp;amp;label=ISSUES&amp;amp;style=for-the-badge&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;“centreon-plugins” is a free and open source project to monitor systems. The project can be used with Centreon and all monitoring softwares compatible with Nagios plugins.&lt;/p&gt; &#xA;&lt;p&gt;You can monitor many systems:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;application: Apache, Asterisk, Elasticsearch, Github, Jenkins, Kafka, Nginx, Pfsense, Redis, Tomcat, Varnish,...&lt;/li&gt; &#xA; &lt;li&gt;cloud: AWS, Azure, Docker, Office365, Nutanix, Prometheus,...&lt;/li&gt; &#xA; &lt;li&gt;database: Firebird, Informix, MS SQL, MySQL, Oracle, Postgres, Cassandra&lt;/li&gt; &#xA; &lt;li&gt;hardware: printers (rfc3805), UPS (Powerware, Mge, Standard), Sun Hardware, Cisco UCS, SensorIP, HP Proliant, HP Bladechassis, Dell Openmanage, Dell CMC, Raritan,...&lt;/li&gt; &#xA; &lt;li&gt;network: Aruba, Brocade, Bluecoat, Brocade, Checkpoint, Cisco AP/IronPort/ASA/Standard, Extreme, Fortigate, H3C, Hirschmann, HP Procurve, F5 BIG-IP, Juniper, PaloAlto, Redback, Riverbed, Ruggedcom, Stonesoft,...&lt;/li&gt; &#xA; &lt;li&gt;os: Linux (SNMP, NRPE), Freebsd (SNMP), AIX (SNMP), Solaris (SNMP)...&lt;/li&gt; &#xA; &lt;li&gt;storage: EMC Clariion, Netapp, Nimble, HP MSA p2000, Dell EqualLogic, Qnap, Panzura, Synology...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Basic Usage&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;ll use a basic example to show you how to monitor a system. I have finished the install section and I want to monitor a Linux in SNMP. First, I need to find the plugin to use in the list:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ perl centreon_plugins.pl --list-plugin | grep -i linux | grep &#39;PLUGIN&#39;&#xA;PLUGIN: os::linux::local::plugin&#xA;PLUGIN: os::linux::snmp::plugin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It seems that &#39;os::linux::snmp::plugin&#39; is the good one. So I verify with the option &lt;code&gt;--help&lt;/code&gt; to be sure:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ perl centreon_plugins.pl --plugin=os::linux::snmp::plugin --help&#xA;...&#xA;Plugin Description:&#xA;  Check Linux operating systems in SNMP.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It&#39;s exactly what I need. Now I&#39;ll add the option &lt;code&gt;--list-mode&lt;/code&gt; to know what can I do with it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ perl centreon_plugins.pl --plugin=os::linux::snmp::plugin --list-mode&#xA;...&#xA;Modes Available:&#xA; processcount&#xA; time&#xA; list-storages&#xA; disk-usage&#xA; diskio&#xA; uptime&#xA; swap&#xA; cpu-detailed&#xA; load&#xA; traffic&#xA; cpu&#xA; inodes&#xA; list-diskspath&#xA; list-interfaces&#xA; packet-errors&#xA; memory&#xA; tcpcon&#xA; storage&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;I would like to test the &#39;load&#39; mode:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ perl centreon_plugins.pl --plugin=os::linux::snmp::plugin --mode=load&#xA;UNKNOWN: Missing parameter --hostname.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It&#39;s not working because some options are missing. I can have a description of the mode and options with the option &lt;code&gt;--help&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ perl centreon_plugins.pl --plugin=os::linux::snmp::plugin --mode=load --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Eventually, I have to configure some SNMP options:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ perl centreon_plugins.pl --plugin=os::linux::snmp::plugin --mode=load --hostname=127.0.0.1 --snmp-version=2c --snmp-community=public&#xA;OK: Load average: 0.00, 0.00, 0.00 | &#39;load1&#39;=0.00;;;0; &#39;load5&#39;=0.00;;;0; &#39;load15&#39;=0.00;;;0;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;I can set threshold with options &lt;code&gt;--warning&lt;/code&gt; and &lt;code&gt;--critical&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ perl centreon_plugins.pl --plugin=os::linux::snmp::plugin --mode=load --hostname=127.0.0.1 --snmp-version=2c --snmp-community=public --warning=1,2,3 --critical=2,3,4&#xA;OK: Load average: 0.00, 0.00, 0.00 | &#39;load1&#39;=0.00;0:1;0:2;0; &#39;load5&#39;=0.00;0:2;0:3;0; &#39;load15&#39;=0.00;0:3;0:4;0;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information or help, please read &lt;a href=&#34;https://raw.githubusercontent.com/centreon/centreon-plugins/master/doc/en/user/guide.rst&#34;&gt;&#39;doc/en/user/guide.rst&#39;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!-- URL AND IMAGES FOR SHIELDS --&gt;</summary>
  </entry>
  <entry>
    <title>tseemann/prokka</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/tseemann/prokka</id>
    <link href="https://github.com/tseemann/prokka" rel="alternate"></link>
    <summary type="html">&lt;p&gt;⚡ ♒ Rapid prokaryotic genome annotation&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/tseemann/prokka&#34;&gt;&lt;img src=&#34;https://travis-ci.org/tseemann/prokka.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.gnu.org/licenses/gpl-3.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-GPL%20v3-blue.svg?sanitize=true&#34; alt=&#34;License: GPL v3&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1093/bioinformatics/btu153&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.1093/bioinformatics/btu153.svg?sanitize=true&#34; alt=&#34;DOI:10.1093/bioinformatics/btu153&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/Language-Perl_5-steelblue.svg?sanitize=true&#34; alt=&#34;Don&#39;t judge me&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Prokka: rapid prokaryotic genome annotation&lt;/h1&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Whole genome annotation is the process of identifying features of interest in a set of genomic DNA sequences, and labelling them with useful information. Prokka is a software tool to annotate bacterial, archaeal and viral genomes quickly and produce standards-compliant output files.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Bioconda&lt;/h3&gt; &#xA;&lt;p&gt;If you use &lt;a href=&#34;https://conda.io/docs/install/quick.html&#34;&gt;Conda&lt;/a&gt; you can use the &lt;a href=&#34;https://bioconda.github.io/&#34;&gt;Bioconda channel&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install -c conda-forge -c bioconda -c defaults prokka&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Brew&lt;/h3&gt; &#xA;&lt;p&gt;If you are using the &lt;a href=&#34;http://brew.sh/&#34;&gt;MacOS Brew&lt;/a&gt; or &lt;a href=&#34;http://brew.sh/linuxbrew/&#34;&gt;LinuxBrew&lt;/a&gt; packaging system:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install brewsci/bio/prokka&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;Maintained by &lt;a href=&#34;https://hub.docker.com/u/staphb&#34;&gt;https://hub.docker.com/u/staphb&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;docker pull staphb/prokka:latest&#xA;docker run staphb/prokka:latest prokka -h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Singularity&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;singularity build prokka.sif docker://staphb/prokka:latest&#xA;singularity exec prokka.sif prokka -h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Ubuntu/Debian/Mint&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt-get install libdatetime-perl libxml-simple-perl libdigest-md5-perl git default-jre bioperl&#xA;sudo cpan Bio::Perl&#xA;git clone https://github.com/tseemann/prokka.git $HOME/prokka&#xA;$HOME/prokka/bin/prokka --setupdb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Centos/Fedora/RHEL&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo yum install git perl-Time-Piece perl-XML-Simple perl-Digest-MD5 perl-App-cpanminus git java perl-CPAN perl-Module-Build&#xA;sudo cpanm Bio::Perl&#xA;git clone https://github.com/tseemann/prokka.git $HOME/prokka&#xA;$HOME/prokka/bin/prokka --setupdb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;MacOS&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo cpan Time::Piece XML::Simple Digest::MD5 Bio::Perl&#xA;git clone https://github.com/tseemann/prokka.git $HOME/prokka&#xA;$HOME/prokka/bin/prokka --setupdb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Test&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Type &lt;code&gt;prokka&lt;/code&gt; and it should output its help screen.&lt;/li&gt; &#xA; &lt;li&gt;Type &lt;code&gt;prokka --version&lt;/code&gt; and you should see an output like &lt;code&gt;prokka 1.x&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Type &lt;code&gt;prokka --listdb&lt;/code&gt; and it will show you what databases it has installed to use.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Invoking Prokka&lt;/h2&gt; &#xA;&lt;h3&gt;Beginner&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Vanilla (but with free toppings)&#xA;% prokka contigs.fa&#xA;&#xA;# Look for a folder called PROKKA_yyyymmdd (today&#39;s date) and look at stats&#xA;% cat PROKKA_yyyymmdd/*.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Moderate&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Choose the names of the output files&#xA;% prokka --outdir mydir --prefix mygenome contigs.fa&#xA;&#xA;# Visualize it in Artemis&#xA;% art mydir/mygenome.gff&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Specialist&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Have curated genomes I want to use to annotate from&#xA;% prokka --proteins MG1655.gbk --outdir mutant --prefix K12_mut contigs.fa&#xA;&#xA;# Look at tabular features&#xA;% less -S mutant/K12_mut.tsv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Expert&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# It&#39;s not just for bacteria, people&#xA;% prokka --kingdom Archaea --outdir mydir --genus Pyrococcus --locustag PYCC&#xA;&#xA;# Search for your favourite gene&#xA;% exonerate --bestn 1 zetatoxin.fasta mydir/PYCC_06072012.faa | less&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Wizard&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Watch and learn&#xA;% prokka --outdir mydir --locustag EHEC --proteins NewToxins.faa --evalue 0.001 --gram neg --addgenes contigs.fa&#xA;&#xA;# Check to see if anything went really wrong&#xA;% less mydir/EHEC_06072012.err&#xA;&#xA;# Add final details using Sequin&#xA;% sequin mydir/EHEC_0607201.sqn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;NCBI Genbank submitter&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Register your BioProject (e.g. PRJNA123456) and your locus_tag prefix (e.g. EHEC) first!&#xA;% prokka --compliant --centre UoN --outdir PRJNA123456 --locustag EHEC --prefix EHEC-Chr1 contigs.fa&#xA;&#xA;# Check to see if anything went really wrong&#xA;% less PRJNA123456/EHEC-Chr1.err&#xA;&#xA;# Add final details using Sequin&#xA;% sequin PRJNA123456/EHEC-Chr1.sqn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;European Nucleotide Archive (ENA) submitter&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Register your BioProject (e.g. PRJEB12345) and your locus_tag (e.g. EHEC) prefix first!&#xA;% prokka --compliant --centre UoN --outdir PRJEB12345 --locustag EHEC --prefix EHEC-Chr1 contigs.fa&#xA;&#xA;# Check to see if anything went really wrong&#xA;% less PRJNA123456/EHEC-Chr1.err&#xA;&#xA;# Install and run Sanger Pathogen group&#39;s Prokka GFF3 to EMBL converter&#xA;# available from https://github.com/sanger-pathogens/gff3toembl&#xA;# Find the closest NCBI taxonomy id (e.g. 562 for Escherichia coli)&#xA;% gff3_to_embl -i &#34;Submitter, A.&#34; \&#xA;    -m &#34;Escherichia coli EHEC annotated using Prokka.&#34; \&#xA;    -g linear -c PROK -n 11 -f PRJEB12345/EHEC-Chr1.embl \&#xA;    &#34;Escherichia coli&#34; 562 PRJEB12345 &#34;Escherichia coli strain EHEC&#34; PRJEB12345/EHEC-Chr1.gff&#xA;&#xA;# Download and run the latest EMBL validator prior to submitting the EMBL flat file&#xA;# from http://central.maven.org/maven2/uk/ac/ebi/ena/sequence/embl-api-validator/&#xA;# which at the time of writing is v1.1.129&#xA;% curl -L -O http://central.maven.org/maven2/uk/ac/ebi/ena/sequence/embl-api-validator/1.1.129/embl-api-validator-1.1.129.jar&#xA;% java -jar embl-api-validator-1.1.129.jar -r PRJEB12345/EHEC-Chr1.embl&#xA;&#xA;# Compress the file ready to upload to ENA, and calculate MD5 checksum&#xA;% gzip PRJEB12345/EHEC-Chr1.embl&#xA;% md5sum PRJEB12345/EHEC-Chr1.embl.gz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Crazy Person&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# No stinking Perl script is going to control me&#xA;% prokka \&#xA;        --outdir $HOME/genomes/Ec_POO247 --force \&#xA;        --prefix Ec_POO247 --addgenes --locustag ECPOOp \&#xA;        --increment 10 --gffver 2 --centre CDC  --compliant \&#xA;        --genus Escherichia --species coli --strain POO247 --plasmid pECPOO247 \&#xA;        --kingdom Bacteria --gcode 11 --usegenus \&#xA;        --proteins /opt/prokka/db/trusted/Ecocyc-17.6 \&#xA;        --evalue 1e-9 --rfam \&#xA;        plasmid-closed.fna&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Output Files&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Extension&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.gff&lt;/td&gt; &#xA;   &lt;td&gt;This is the master annotation in GFF3 format, containing both sequences and annotations. It can be viewed directly in Artemis or IGV.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.gbk&lt;/td&gt; &#xA;   &lt;td&gt;This is a standard Genbank file derived from the master .gff. If the input to prokka was a multi-FASTA, then this will be a multi-Genbank, with one record for each sequence.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.fna&lt;/td&gt; &#xA;   &lt;td&gt;Nucleotide FASTA file of the input contig sequences.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.faa&lt;/td&gt; &#xA;   &lt;td&gt;Protein FASTA file of the translated CDS sequences.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.ffn&lt;/td&gt; &#xA;   &lt;td&gt;Nucleotide FASTA file of all the prediction transcripts (CDS, rRNA, tRNA, tmRNA, misc_RNA)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.sqn&lt;/td&gt; &#xA;   &lt;td&gt;An ASN1 format &#34;Sequin&#34; file for submission to Genbank. It needs to be edited to set the correct taxonomy, authors, related publication etc.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.fsa&lt;/td&gt; &#xA;   &lt;td&gt;Nucleotide FASTA file of the input contig sequences, used by &#34;tbl2asn&#34; to create the .sqn file. It is mostly the same as the .fna file, but with extra Sequin tags in the sequence description lines.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.tbl&lt;/td&gt; &#xA;   &lt;td&gt;Feature Table file, used by &#34;tbl2asn&#34; to create the .sqn file.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.err&lt;/td&gt; &#xA;   &lt;td&gt;Unacceptable annotations - the NCBI discrepancy report.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.log&lt;/td&gt; &#xA;   &lt;td&gt;Contains all the output that Prokka produced during its run. This is a record of what settings you used, even if the --quiet option was enabled.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.txt&lt;/td&gt; &#xA;   &lt;td&gt;Statistics relating to the annotated features found.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;.tsv&lt;/td&gt; &#xA;   &lt;td&gt;Tab-separated file of all features: locus_tag,ftype,len_bp,gene,EC_number,COG,product&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Command line options&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;General:&#xA;  --help            This help&#xA;  --version         Print version and exit&#xA;  --citation        Print citation for referencing Prokka&#xA;  --quiet           No screen output (default OFF)&#xA;  --debug           Debug mode: keep all temporary files (default OFF)&#xA;Setup:&#xA;  --listdb          List all configured databases&#xA;  --setupdb         Index all installed databases&#xA;  --cleandb         Remove all database indices&#xA;  --depends         List all software dependencies&#xA;Outputs:&#xA;  --outdir [X]      Output folder [auto] (default &#39;&#39;)&#xA;  --force           Force overwriting existing output folder (default OFF)&#xA;  --prefix [X]      Filename output prefix [auto] (default &#39;&#39;)&#xA;  --addgenes        Add &#39;gene&#39; features for each &#39;CDS&#39; feature (default OFF)&#xA;  --locustag [X]    Locus tag prefix (default &#39;PROKKA&#39;)&#xA;  --increment [N]   Locus tag counter increment (default &#39;1&#39;)&#xA;  --gffver [N]      GFF version (default &#39;3&#39;)&#xA;  --compliant       Force Genbank/ENA/DDJB compliance: --genes --mincontiglen 200 --centre XXX (default OFF)&#xA;  --centre [X]      Sequencing centre ID. (default &#39;&#39;)&#xA;Organism details:&#xA;  --genus [X]       Genus name (default &#39;Genus&#39;)&#xA;  --species [X]     Species name (default &#39;species&#39;)&#xA;  --strain [X]      Strain name (default &#39;strain&#39;)&#xA;  --plasmid [X]     Plasmid name or identifier (default &#39;&#39;)&#xA;Annotations:&#xA;  --kingdom [X]     Annotation mode: Archaea|Bacteria|Mitochondria|Viruses (default &#39;Bacteria&#39;)&#xA;  --gcode [N]       Genetic code / Translation table (set if --kingdom is set) (default &#39;0&#39;)&#xA;  --prodigaltf [X]  Prodigal training file (default &#39;&#39;)&#xA;  --gram [X]        Gram: -/neg +/pos (default &#39;&#39;)&#xA;  --usegenus        Use genus-specific BLAST databases (needs --genus) (default OFF)&#xA;  --proteins [X]    Fasta file of trusted proteins to first annotate from (default &#39;&#39;)&#xA;  --hmms [X]        Trusted HMM to first annotate from (default &#39;&#39;)&#xA;  --metagenome      Improve gene predictions for highly fragmented genomes (default OFF)&#xA;  --rawproduct      Do not clean up /product annotation (default OFF)&#xA;Computation:&#xA;  --fast            Fast mode - skip CDS /product searching (default OFF)&#xA;  --cpus [N]        Number of CPUs to use [0=all] (default &#39;8&#39;)&#xA;  --mincontiglen [N] Minimum contig size [NCBI needs 200] (default &#39;1&#39;)&#xA;  --evalue [n.n]    Similarity e-value cut-off (default &#39;1e-06&#39;)&#xA;  --rfam            Enable searching for ncRNAs with Infernal+Rfam (SLOW!) (default &#39;0&#39;)&#xA;  --norrna          Don&#39;t run rRNA search (default OFF)&#xA;  --notrna          Don&#39;t run tRNA search (default OFF)&#xA;  --rnammer         Prefer RNAmmer over Barrnap for rRNA prediction (default OFF)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Option: --proteins&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;--proteins&lt;/code&gt; option is recommended when you have good quality reference genomes and want to ensure gene naming is consistent. Some species use specific terminology which will be often lost if you rely on the default Swiss-Prot database included with Prokka.&lt;/p&gt; &#xA;&lt;p&gt;If you have Genbank or Protein FASTA file(s) that you want to annotate genes from as the first priority, use the &lt;code&gt;--proteins myfile.gbk&lt;/code&gt;. Please make sure it has a recognisable file extension like &lt;code&gt;.gb&lt;/code&gt; or &lt;code&gt;.gbk&lt;/code&gt; or auto-detect will fail. The use of Genbank is recommended over FASTA, because it will provide &lt;code&gt;/gene&lt;/code&gt; and &lt;code&gt;/EC_number&lt;/code&gt; annotations that a typical &lt;code&gt;.faa&lt;/code&gt; file will not provide, unless you have specially formatted it for Prokka.&lt;/p&gt; &#xA;&lt;h3&gt;Option: --prodigaltf&lt;/h3&gt; &#xA;&lt;p&gt;Instead of letting &lt;code&gt;prodigal&lt;/code&gt; train its gene model on the contigs you provide, you can pre-train it on some good closed reference genomes first using the &lt;code&gt;prodigal -t&lt;/code&gt; option. Once you&#39;ve done that, provide &lt;code&gt;prokka&lt;/code&gt; the training file using the &lt;code&gt;--prodgialtf&lt;/code&gt; option.&lt;/p&gt; &#xA;&lt;h3&gt;Option: --rawproduct&lt;/h3&gt; &#xA;&lt;p&gt;Prokka annotates proteins by using sequence similarity to other proteins in its database, or the databases the user provides via &lt;code&gt;--proteins&lt;/code&gt;. By default, Prokka tries to &#34;cleans&#34; the &lt;code&gt;/product&lt;/code&gt; names to ensure they are compliant with Genbank/ENA conventions. Some of the main things it does is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set vague names to &lt;code&gt;hypothetical protein&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;consistifies terms like &lt;code&gt;possible&lt;/code&gt;, &lt;code&gt;probable&lt;/code&gt;, &lt;code&gt;predicted&lt;/code&gt;, ... to &lt;code&gt;putative&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;removes EC, COG and locus_tag identifiers&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Full details can be found in the &lt;code&gt;cleanup_product()&lt;/code&gt; function in the &lt;code&gt;prokka&lt;/code&gt; script. If you feel your annotations are being ruined, try using the &lt;code&gt;--rawproduct&lt;/code&gt; option, and please &lt;a href=&#34;https://github.com/tseemann/prokka/issues/&#34;&gt;file an issue&lt;/a&gt; if you find an example of where it is &#34;behaving badly&#34; and I will fix it.&lt;/p&gt; &#xA;&lt;h2&gt;Databases&lt;/h2&gt; &#xA;&lt;h3&gt;The Core (BLAST+) Databases&lt;/h3&gt; &#xA;&lt;p&gt;Prokka uses a variety of databases when trying to assign function to the predicted CDS features. It takes a hierarchical approach to make it fast.&lt;br&gt; A small, core set of well characterized proteins are first searched using BLAST+. This combination of small database and fast search typically completes about 70% of the workload. Then a series of slower but more sensitive HMM databases are searched using HMMER3.&lt;/p&gt; &#xA;&lt;p&gt;The three core databases, applied in order, are:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://isfinder.biotoul.fr/&#34;&gt;ISfinder&lt;/a&gt;: Only the tranposase (protein) sequences; the whole transposon is not annotated.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/bioproject/313047&#34;&gt;NCBI Bacterial Antimicrobial Resistance Reference Gene Database&lt;/a&gt;: Antimicrobial resistance genes curated by NCBI.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.uniprot.org/uniprot/?query=reviewed:yes&#34;&gt;UniProtKB (SwissProt)&lt;/a&gt;: For each &lt;code&gt;--kingdom&lt;/code&gt; we include curated proteins with evidence that (i) from Bacteria (or Archaea or Viruses); (ii) not be &#34;Fragment&#34; entries; and (iii) have an evidence level (&#34;PE&#34;) of 2 or lower, which corresponds to experimental mRNA or proteomics evidence.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Making a Core Databases&lt;/h4&gt; &#xA;&lt;p&gt;If you want to modify these core databases, the included script &lt;code&gt;prokka-uniprot_to_fasta_db&lt;/code&gt;, along with the official &lt;code&gt;uniprot_sprot.dat&lt;/code&gt;, can be used to generate a new database to put in &lt;code&gt;/opt/prokka/db/kingdom/&lt;/code&gt;. If you add new ones, the command &lt;code&gt;prokka --listdb&lt;/code&gt; will show you whether it has been detected properly.&lt;/p&gt; &#xA;&lt;h4&gt;The Genus Databases&lt;/h4&gt; &#xA;&lt;p&gt;&lt;span&gt;⚠&lt;/span&gt; This is no longer recommended. Please use &lt;code&gt;--proteins&lt;/code&gt; instead.&lt;/p&gt; &#xA;&lt;p&gt;If you enable &lt;code&gt;--usegenus&lt;/code&gt; and also provide a Genus via &lt;code&gt;--genus&lt;/code&gt; then it will first use a BLAST database which is Genus specific. Prokka comes with a set of databases for the most common Bacterial genera; type prokka &lt;code&gt;--listdb&lt;/code&gt; to see what they are.&lt;/p&gt; &#xA;&lt;h4&gt;Adding a Genus Databases&lt;/h4&gt; &#xA;&lt;p&gt;If you have a set of Genbank files and want to create a new Genus database, Prokka comes with a tool called &lt;code&gt;prokka-genbank_to_fasta_db&lt;/code&gt; to help. For example, if you had four annotated &#34;Coccus&#34; genomes, you could do the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% prokka-genbank_to_fasta_db Coccus1.gbk Coccus2.gbk Coccus3.gbk Coccus4.gbk &amp;gt; Coccus.faa&#xA;% cd-hit -i Coccus.faa -o Coccus -T 0 -M 0 -g 1 -s 0.8 -c 0.9&#xA;% rm -fv Coccus.faa Coccus.bak.clstr Coccus.clstr&#xA;% makeblastdb -dbtype prot -in Coccus&#xA;% mv Coccus.p* /path/to/prokka/db/genus/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;The HMM Databases&lt;/h3&gt; &#xA;&lt;p&gt;Prokka comes with a bunch of HMM libraries for HMMER3. They are mostly Bacteria-specific. They are searched after the core and genus databases. You can add more simply by putting them in &lt;code&gt;/opt/prokka/db/hmm&lt;/code&gt;. Type &lt;code&gt;prokka --listdb&lt;/code&gt; to confirm they are recognised.&lt;/p&gt; &#xA;&lt;h3&gt;FASTA database format&lt;/h3&gt; &#xA;&lt;p&gt;Prokka understands two annotation tag formats, a plain one and a detailed one.&lt;/p&gt; &#xA;&lt;p&gt;The plain one is a standard FASTA-like line with the ID after the &lt;code&gt;&amp;gt;&lt;/code&gt; sign, and the protein &lt;code&gt;/product&lt;/code&gt; after the ID (the &#34;description&#34; part of the line):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;SeqID product&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The detailed one consists of a special encoded three-part description line. The parts are the &lt;code&gt;/EC_number&lt;/code&gt;, the &lt;code&gt;/gene&lt;/code&gt; code, then the &lt;code&gt;/product&lt;/code&gt; - and they are separated by a special &#34;~~~&#34; sequence:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;SeqID EC_number~~~gene~~~product~~~COG&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here are some examples. Note that not all parts need to be present, but the &#34;~~~&#34; should still be there:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;YP_492693.1 2.1.1.48~~~ermC~~~rRNA adenine N-6-methyltransferase~~~COG1234&#xA;MNEKNIKHSQNFITSKHNIDKIMTNIRLNEHDNIFEIGSGKGHFTLELVQRCNFVTAIEI&#xA;DHKLCKTTENKLVDHDNFQVLNKDILQFKFPKNQSYKIFGNIPYNISTDIIRKIVF*&#xA;&amp;gt;YP_492697.1 ~~~traB~~~transfer complex protein TraB~~~&#xA;MIKKFSLTTVYVAFLSIVLSNITLGAENPGPKIEQGLQQVQTFLTGLIVAVGICAGVWIV&#xA;LKKLPGIDDPMVKNEMFRGVGMVLAGVAVGAALVWLVPWVYNLFQ*&#xA;&amp;gt;YP_492694.1 ~~~~~~transposase~~~&#xA;MNYFRYKQFNKDVITVAVGYYLRYALSYRDISEILRGRGVNVHHSTVYRWVQEYAPILYQ&#xA;QSINTAKNTLKGIECIYALYKKNRRSLQIYGFSPCHEISIMLAS*&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The same description lines apply to HMM models, except the &#34;NAME&#34; and &#34;DESC&#34; fields are used:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;NAME  PRK00001&#xA;ACC   PRK00001&#xA;DESC  2.1.1.48~~~ermC~~~rRNA adenine N-6-methyltransferase~~~COG1234&#xA;LENG  284&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Where does the name &#34;Prokka&#34; come from?&lt;/strong&gt;&lt;br&gt; Prokka is a contraction of &#34;prokaryotic annotation&#34;. It&#39;s also relatively unique within Google, and also rhymes with a native Australian marsupial called the quokka.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Can I annotate by eukaryote genome with Prokka?&lt;/strong&gt;&lt;br&gt; No. Prokka is specifically designed for Bacteria, Archaea and Viruses. It can&#39;t handle multi-exon gene models; I would recommend using MAKER 2 for that purpose.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Why does Prokka keeps on crashing when it gets to the &#34;tbl2asn&#34; stage?&lt;/strong&gt;&lt;br&gt; It seems that the tbl2asn program from NCBI &#34;expires&#34; after 6-12 months, and refuses to run. Unfortunately you need to install a newer version which you can download from &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/genbank/tbl2asn2/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;The hmmscan step seems to hang and do nothing?&lt;/strong&gt;&lt;br&gt; The problem here is GNU Parallel. It seems the Debian package for hmmer has modified it to require the &lt;code&gt;--gnu&lt;/code&gt; option to behave in the &#39;default&#39; way. There is no clear reason for this. The only way to restore normal behaviour is to edit the prokka script and change &lt;code&gt;parallel&lt;/code&gt; to &lt;code&gt;parallel --gnu&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Why does prokka fail when it gets to hmmscan?&lt;/strong&gt;&lt;br&gt; Unfortunately HMMER keeps changing its database format, and they aren&#39;t upward compatible. If you upgraded HMMER (from 3.0 to 3.1 say) then you need to &#34;re-press&#34; the files. This can be done as follows:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd /path/to/prokka/db/hmm&#xA;mkdir new&#xA;for D in *.hmm ; do hmmconvert $D &amp;gt; new/$D ; done&#xA;cd new&#xA;for D in *.hmm ; do hmmpress $D ; done&#xA;mv * ..&#xA;rmdir new&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Why can&#39;t I load Prokka .GBK files into Mauve?&lt;/strong&gt;&lt;br&gt; Mauve uses BioJava to parse GenBank files, and it is very picky about Genbank files. It does not like long contig names, like those from Velvet or Spades. One solution is to use &lt;code&gt;--centre XXX&lt;/code&gt; in Prokka and it will rename all your contigs to be NCBI (and Mauve) compliant. It does not like the ACCESSION and VERSION strings that Prokka produces via the &#34;tbl2asn&#34; tool. The following Unix command will fix them: &lt;code&gt;egrep -v &#39;^(ACCESSION|VERSION)&#39; prokka.gbk &amp;gt; mauve.gbk&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;How can I make my GFF not have the contig sequences in it?&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;sed &#39;/^##FASTA/Q&#39; prokka.gff &amp;gt; nosequence.gff&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Bugs&lt;/h2&gt; &#xA;&lt;p&gt;Submit problems or requests to the &lt;a href=&#34;https://github.com/tseemann/prokka/issues&#34;&gt;Issue Tracker&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Changes&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Read the &lt;a href=&#34;https://github.com/tseemann/prokka/releases&#34;&gt;release notes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Read the &lt;a href=&#34;https://raw.githubusercontent.com/tseemann/prokka/master/doc/ChangeLog.txt&#34;&gt;ChangeLog.txt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Look at the &lt;a href=&#34;https://github.com/tseemann/prokka/commits/master&#34;&gt;Github commits&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Seemann T.&lt;br&gt; &lt;em&gt;Prokka: rapid prokaryotic genome annotation&lt;/em&gt;&lt;br&gt; &lt;strong&gt;Bioinformatics&lt;/strong&gt; 2014 Jul 15;30(14):2068-9. &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/24642063&#34;&gt;PMID:24642063&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;h3&gt;Mandatory&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;BioPerl&lt;/strong&gt;&lt;br&gt; Used for input/output of various file formats&lt;br&gt; &lt;em&gt;Stajich et al, The Bioperl toolkit: Perl modules for the life sciences. Genome Res. 2002 Oct;12(10):1611-8.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;GNU Parallel&lt;/strong&gt;&lt;br&gt; A shell tool for executing jobs in parallel using one or more computers&lt;br&gt; &lt;em&gt;O. Tange, GNU Parallel - The Command-Line Power Tool, ;login: The USENIX Magazine, Feb 2011:42-47.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;BLAST+&lt;/strong&gt;&lt;br&gt; Used for similarity searching against protein sequence libraries&lt;br&gt; &lt;em&gt;Camacho C et al. BLAST+: architecture and applications. BMC Bioinformatics. 2009 Dec 15;10:421.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prodigal&lt;/strong&gt;&lt;br&gt; Finds protein-coding features (CDS)&lt;br&gt; &lt;em&gt;Hyatt D et al. Prodigal: prokaryotic gene recognition and translation initiation site identification. BMC Bioinformatics. 2010 Mar 8;11:119.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;TBL2ASN&lt;/strong&gt; Prepare sequence records for Genbank submission &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/genbank/tbl2asn2/&#34;&gt;Tbl2asn home page&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Recommended&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aragorn&lt;/strong&gt;&lt;br&gt; Finds transfer RNA features (tRNA)&lt;br&gt; &lt;em&gt;Laslett D, Canback B. ARAGORN, a program to detect tRNA genes and tmRNA genes in nucleotide sequences. Nucleic Acids Res. 2004 Jan 2;32(1):11-6.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Barrnap&lt;/strong&gt;&lt;br&gt; Used to predict ribosomal RNA features (rRNA). My licence-free replacement for RNAmmmer.&lt;br&gt; &lt;em&gt;Manuscript under preparation.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;HMMER3&lt;/strong&gt;&lt;br&gt; Used for similarity searching against protein family profiles&lt;br&gt; &lt;em&gt;Finn RD et al. HMMER web server: interactive sequence similarity searching. Nucleic Acids Res. 2011 Jul;39(Web Server issue):W29-37.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Optional&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;minced&lt;/strong&gt;&lt;br&gt; Finds CRISPR arrays &lt;a href=&#34;https://github.com/ctSkennerton/minced&#34;&gt;Minced home page&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;RNAmmer&lt;/strong&gt;&lt;br&gt; Finds ribosomal RNA features (rRNA)&lt;br&gt; &lt;em&gt;Lagesen K et al. RNAmmer: consistent and rapid annotation of ribosomal RNA genes. Nucleic Acids Res. 2007;35(9):3100-8.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;SignalP&lt;/strong&gt;&lt;br&gt; Finds signal peptide features in CDS (sig_peptide)&lt;br&gt; &lt;em&gt;Petersen TN et al. SignalP 4.0: discriminating signal peptides from transmembrane regions. Nat Methods. 2011 Sep 29;8(10):785-6.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Infernal&lt;/strong&gt;&lt;br&gt; Used for similarity searching against ncRNA family profiles&lt;br&gt; &lt;em&gt;D. L. Kolbe, S. R. Eddy. Fast Filtering for RNA Homology Search. Bioinformatics, 27:3102-3109, 2011.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Licence&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tseemann/prokka/master/doc/LICENSE.Prokka&#34;&gt;GPL v3&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Author&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Torsten Seemann&lt;/li&gt; &#xA; &lt;li&gt;Web: &lt;a href=&#34;https://tseemann.github.io/&#34;&gt;https://tseemann.github.io/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Twitter: &lt;a href=&#34;https://twitter.com/torstenseemann&#34;&gt;@torstenseemann&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Blog: &lt;a href=&#34;https://thegenomefactory.blogspot.com/&#34;&gt;The Genome Factory&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>docker-library/repo-info</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/docker-library/repo-info</id>
    <link href="https://github.com/docker-library/repo-info" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Extended information (especially license and layer details) about the published Official Images&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Official Images &#34;Extended Information&#34;&lt;/h1&gt; &#xA;&lt;p&gt;This repository includes a set of scripts for generating reports of extended information about published official image repositories.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s still a firm Work In Progress, and concrete suggestions for improvement in gathering or presentation are welcome!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://doi-janky.infosiftr.net/job/repo-info/job/remote/&#34;&gt;Automated &lt;code&gt;update-remote.sh&lt;/code&gt;:&lt;br&gt; &lt;img src=&#34;https://doi-janky.infosiftr.net/job/repo-info/job/remote/badge/icon&#34; alt=&#34;build status badge&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://doi-janky.infosiftr.net/job/repo-info/job/local/&#34;&gt;Automated &lt;code&gt;scan-local.sh&lt;/code&gt; (one job per repo)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Ensembl/ensembl-vep</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/Ensembl/ensembl-vep</id>
    <link href="https://github.com/Ensembl/ensembl-vep" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Ensembl Variant Effect Predictor predicts the functional effects of genomic variants&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ensembl-vep&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Ensembl/ensembl-vep/raw/106/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/Ensembl/ensembl-vep.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/Ensembl/ensembl-vep?branch=106&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/Ensembl/ensembl-vep/badge.svg?branch=106&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/ensemblorg/ensembl-vep&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/build/ensemblorg/ensembl-vep.svg?sanitize=true&#34; alt=&#34;Docker Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/ensemblorg/ensembl-vep&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/ensemblorg/ensembl-vep.svg?sanitize=true&#34; alt=&#34;Docker Hub Pulls&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;VEP&lt;/strong&gt; (Variant Effect Predictor) predicts the functional effects of genomic variants.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Haplosaurus&lt;/strong&gt; uses phased genotype data to predict whole-transcript haplotype sequences.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Variant Recoder&lt;/strong&gt; translates between different variant encodings.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;Table of contents&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#install&#34;&gt;Installation and requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#vep&#34;&gt;VEP&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#vepusage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#haplo&#34;&gt;Haplosaurus&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#haplousage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#haplooutput&#34;&gt;Output&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#haploREST&#34;&gt;REST&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#haploflags&#34;&gt;Flags&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#recoder&#34;&gt;Variant Recoder&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#recoderusage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#recoderoutput&#34;&gt;Output&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a name=&#34;install&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Installation and requirements&lt;/h3&gt; &#xA;&lt;p&gt;The VEP package requires:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;gcc&lt;/strong&gt;, &lt;strong&gt;g++&lt;/strong&gt; and &lt;strong&gt;make&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Perl&lt;/strong&gt; (&amp;gt;=5.10 recommended, tested on 5.10, 5.14, 5.18, 5.22, 5.26)&lt;/li&gt; &#xA; &lt;li&gt;Perl libraries &lt;a href=&#34;https://metacpan.org/pod/Archive::Zip&#34;&gt;Archive::Zip&lt;/a&gt; and &lt;a href=&#34;https://metacpan.org/pod/DBI&#34;&gt;DBI&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The remaining dependencies can be installed using the included &lt;a href=&#34;http://www.ensembl.org/info/docs/tools/vep/script/vep_download.html#installer&#34;&gt;INSTALL.pl&lt;/a&gt; script. Basic instructions:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/Ensembl/ensembl-vep.git&#xA;cd ensembl-vep&#xA;perl INSTALL.pl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The installer may also be used to check for updates to this and co-dependent packages, simply re-run INSTALL.pl.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;http://www.ensembl.org/info/docs/tools/vep/script/vep_download.html&#34;&gt;documentation&lt;/a&gt; for full installation instructions.&lt;/p&gt; &#xA;&lt;h4&gt;Additional CPAN modules&lt;/h4&gt; &#xA;&lt;p&gt;The following modules are optional but most users will benefit from installing them. We recommend using &lt;a href=&#34;http://search.cpan.org/~miyagawa/Menlo-1.9003/script/cpanm-menlo&#34;&gt;cpanminus&lt;/a&gt; to install.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://search.cpan.org/~michielb/DBD-mysql/lib/DBD/mysql.pm&#34;&gt;DBD::mysql&lt;/a&gt; - required for database access (&lt;code&gt;--database&lt;/code&gt; or &lt;code&gt;--cache&lt;/code&gt; without &lt;code&gt;--offline&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://search.cpan.org/~benbooth/Set-IntervalTree/lib/Set/IntervalTree.pm&#34;&gt;Set::IntervalTree&lt;/a&gt; - required for Haplosaurus, also confers speed updates to VEP&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://search.cpan.org/dist/JSON/&#34;&gt;JSON&lt;/a&gt; - required for writing JSON output&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://search.cpan.org/~nwclark/PerlIO-gzip-0.19/gzip.pm&#34;&gt;PerlIO::gzip&lt;/a&gt; - faster compressed file parsing&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://search.cpan.org/~lds/Bio-BigFile-1.07/lib/Bio/DB/BigFile.pm&#34;&gt;Bio::DB::BigFile&lt;/a&gt; - required for reading custom annotation data from BigWig files&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Docker&lt;/h4&gt; &#xA;&lt;p&gt;A docker image for VEP is available from &lt;a href=&#34;https://hub.docker.com/r/ensemblorg/ensembl-vep&#34;&gt;DockerHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;http://www.ensembl.org/info/docs/tools/vep/script/vep_download.html#docker&#34;&gt;documentation&lt;/a&gt; for the Docker installation instructions.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a name=&#34;vep&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;VEP&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a name=&#34;vepusage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./vep -i input.vcf -o out.txt -offline&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;http://www.ensembl.org/info/docs/tools/vep/script/vep_options.html#basic&#34;&gt;documentation&lt;/a&gt; for full command line instructions.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Please report any bugs or issues by &lt;a href=&#34;http://www.ensembl.org/info/about/contact/index.html&#34;&gt;contacting Ensembl&lt;/a&gt; or creating a &lt;a href=&#34;https://github.com/Ensembl/ensembl-vep/issues&#34;&gt;GitHub issue&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a name=&#34;haplo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Haplosaurus&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;haplo&lt;/code&gt; is a local tool implementation of the same functionality that powers the &lt;a href=&#34;http://www.ensembl.org/Homo_sapiens/Transcript/Haplotypes?t=ENST00000304748&#34;&gt;Ensembl transcript haplotypes view&lt;/a&gt;. It takes phased genotypes from a VCF and constructs a pair of haplotype sequences for each overlapped transcript; these sequences are also translated into predicted protein haplotype sequences. Each variant haplotype sequence is aligned and compared to the reference, and an HGVS-like name is constructed representing its differences to the reference.&lt;/p&gt; &#xA;&lt;p&gt;This approach offers an advantage over VEP&#39;s analysis, which treats each input variant independently. By considering the combined change contributed by all the variant alleles across a transcript, the compound effects the variants may have are correctly accounted for.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;haplo&lt;/code&gt; shares much of the same command line functionality with &lt;code&gt;vep&lt;/code&gt;, and can use VEP caches, Ensembl databases, GFF and GTF files as sources of transcript data; all &lt;code&gt;vep&lt;/code&gt; command line flags relating to this functionality work the same with &lt;code&gt;haplo&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;haplousage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Input data must be a &lt;a href=&#34;http://samtools.github.io/hts-specs/VCFv4.3.pdf&#34;&gt;VCF&lt;/a&gt; containing phased genotype data for at least one individual and file must be sorted by chromosome and genomic position; no other formats are currently supported.&lt;/p&gt; &#xA;&lt;p&gt;When using a VEP cache as the source of transcript annotation, the first time you run &lt;code&gt;haplo&lt;/code&gt; with a particular cache it will spend some time scanning transcript locations in the cache.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./haplo -i input.vcf -o out.txt -cache&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;haplooutput&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Output&lt;/h3&gt; &#xA;&lt;p&gt;The default output format is a simple tab-delimited file reporting all observed non-reference haplotypes. It has the following fields:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Transcript stable ID&lt;/li&gt; &#xA; &lt;li&gt;CDS haplotype name&lt;/li&gt; &#xA; &lt;li&gt;Comma-separated list of &lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#haploflags&#34;&gt;flags&lt;/a&gt; for CDS haplotype&lt;/li&gt; &#xA; &lt;li&gt;Protein haplotype name&lt;/li&gt; &#xA; &lt;li&gt;Comma-separated list of &lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#haploflags&#34;&gt;flags&lt;/a&gt; for protein haplotype&lt;/li&gt; &#xA; &lt;li&gt;Comma-separated list of frequency data for protein haplotype&lt;/li&gt; &#xA; &lt;li&gt;Comma-separated list of contributing variants&lt;/li&gt; &#xA; &lt;li&gt;Comma-separated list of sample:count that exhibit this haplotype&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The altered haplotype sequences can be obtained by switching to JSON output using &lt;code&gt;--json&lt;/code&gt; which will display them by default. Each transcript analysed is summarised as a JSON object written to one line of the output file.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#haploREST&#34;&gt;JSON output&lt;/a&gt; structure matches the format of the &lt;a href=&#34;https://rest.ensembl.org/documentation/info/transcript_haplotypes_get&#34;&gt;transcript haplotype REST endpoint&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You may exclude fields in the JSON from being exported with &lt;code&gt;--dont_export field1,field2&lt;/code&gt;. This may be used, for example, to exclude the full haplotype sequence and aligned sequences from the output with &lt;code&gt;--dont_export seq,aligned_sequences&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note JSON output does not currently include side-loaded frequency data.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a name=&#34;haploREST&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;REST service&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://rest.ensembl.org/documentation/info/transcript_haplotypes_get&#34;&gt;transcript haplotype REST endpoint&lt;/a&gt;. returns arrays of protein_haplotypes and cds_haplotypes for a given transcript. The default haplotype record includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;population_counts&lt;/strong&gt;: the number of times the haplotype is seen in each population&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;population_frequencies&lt;/strong&gt;: the frequency of the haplotype in each population&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;contributing_variants&lt;/strong&gt;: variants contributing to the haplotype&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;diffs&lt;/strong&gt;: differences between the reference and this haplotype&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;hex&lt;/strong&gt;: the md5 hex of this haplotype sequence&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;other_hexes&lt;/strong&gt;: the md5 hex of other related haplotype sequences ( CDSHaplotypes that translate to this ProteinHaplotype or ProteinHaplotype representing the translation of this CDSHaplotype)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;has_indel&lt;/strong&gt;: does the haplotype contain insertions or deletions&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;type&lt;/strong&gt;: the type of haplotype - cds, protein&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;name&lt;/strong&gt;: a human readable name for the haplotype (sequence id + REF or a change description)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;flags&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/Ensembl/ensembl-vep/release/106/#haploflags&#34;&gt;flags&lt;/a&gt; for the haplotype&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;frequency&lt;/strong&gt;: haplotype frequency in full sample set&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;count&lt;/strong&gt;: haplotype count in full sample set&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The REST service does not return raw sequences, sample-haplotype assignments and the aligned sequences used to generate differences by default.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;haploflags&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Flags&lt;/h3&gt; &#xA;&lt;p&gt;Haplotypes may be flagged with one or more of the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;indel&lt;/strong&gt;: haplotype contains an insertion or deletion (indel) relative to the reference.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;frameshift:&lt;/strong&gt; haplotype contains at least one indel that disrupts the reading frame of the transcript.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;resolved_frameshift:&lt;/strong&gt; haplotype contains two or more indels whose combined effect restores the reading frame of the transcript.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;stop_changed:&lt;/strong&gt; indicates either a STOP codon is gained (protein truncating variant, PTV) or the existing reference STOP codon is lost.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;deleterious_sift_or_polyphen:&lt;/strong&gt; haplotype contains at least one single amino acid substitution event flagged as deleterious (SIFT) or probably damaging (PolyPhen2).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a name=&#34;bioperl-ext&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;bioperl-ext&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;haplo&lt;/code&gt; can make use of a fast compiled alignment algorithm from the &lt;a href=&#34;https://github.com/bioperl/bioperl-ext&#34;&gt;bioperl-ext&lt;/a&gt; package; this can speed up analysis, particularly in longer transcripts where insertions and/or deletions are introduced. The bioperl-ext package is no longer maintained and requires some tweaking to install. The following instructions install the package in &lt;code&gt;$HOME/perl5&lt;/code&gt;; edit &lt;code&gt;PREFIX=[path]&lt;/code&gt; to change this. You may also need to edit the &lt;code&gt;export&lt;/code&gt; command to point to the path created for the architecture on your machine.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/bioperl/bioperl-ext.git&#xA;cd bioperl-ext/Bio/Ext/Align/&#xA;perl -pi -e&#34;s|(cd libs.+)CFLAGS=\\\&#39;|\$1CFLAGS=\\\&#39;-fPIC |&#34; Makefile.PL&#xA;perl Makefile.PL PREFIX=~/perl5&#xA;make&#xA;make install&#xA;cd -&#xA;export PERL5LIB=${PERL5LIB}:${HOME}/perl5/lib/x86_64-linux-gnu/perl/5.22.1/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If successful the following should print &lt;code&gt;OK&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;perl -MBio::Tools::dpAlign -e&#34;print qq{OK\n}&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a name=&#34;recoder&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Variant Recoder&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;variant_recoder&lt;/code&gt; is a tool for translating between different variant encodings. It accepts as input any format supported by VEP (VCF, variant ID, HGVS), with extensions to allow for parsing of potentially ambiguous HGVS notations. For each input variant, &lt;code&gt;variant_recoder&lt;/code&gt; reports all possible encodings including variant IDs from &lt;a href=&#34;http://www.ensembl.org/info/genome/variation/species/sources_documentation.html&#34;&gt;all sources imported into the Ensembl database&lt;/a&gt; and HGVS (genomic, transcript and protein), reported on Ensembl, RefSeq and LRG sequences.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;recoderusage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;variant_recoder&lt;/code&gt; depends on database access for identifier lookup, and cannot be used in offline mode as per VEP. The output format is JSON and the &lt;a href=&#34;http://search.cpan.org/dist/JSON/&#34;&gt;JSON perl module&lt;/a&gt; is required.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./variant_recoder --id [input_data_string]&#xA;./variant_recoder -i [input_file] --species [species]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;recoderoutput&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Output&lt;/h3&gt; &#xA;&lt;p&gt;Output is a JSON array of objects, one per input variant, with the following keys:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;input&lt;/strong&gt;: input string&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;id&lt;/strong&gt;: variant identifiers&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;hgvsg&lt;/strong&gt;: HGVS genomic nomenclature&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;hgvsc&lt;/strong&gt;: HGVS transcript nomenclature&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;hgvsp&lt;/strong&gt;: HGVS protein nomenclature&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;spdi&lt;/strong&gt;: Genomic SPDI notation&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;vcf_string&lt;/strong&gt;: VCF format (optional)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;var_synonyms&lt;/strong&gt;: Variation synonyms (optional)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;mane_select&lt;/strong&gt;: MANE Select transcripts (optional)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;warnings&lt;/strong&gt;: Warnings generated e.g. for invalid HGVS&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Use &lt;code&gt;--pretty&lt;/code&gt; to pre-format and indent JSON output.&lt;/p&gt; &#xA;&lt;p&gt;Example output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./variant_recoder --id &#34;AGT:p.Met259Thr&#34; --pretty&#xA;[&#xA;   {&#xA;     &#34;warnings&#34; : [&#xA;         &#34;Possible invalid use of gene or protein identifier &#39;AGT&#39; as HGVS reference; AGT:p.Met259Thr may resolve to multiple genomic locations&#34;&#xA;      ],&#xA;     &#34;C&#34; : {&#xA;        &#34;input&#34; : &#34;AGT:p.Met259Thr&#34;,&#xA;        &#34;id&#34; : [&#xA;           &#34;rs699&#34;,&#xA;           &#34;CM920010&#34;,&#xA;           &#34;COSV64184214&#34;&#xA;        ],&#xA;        &#34;hgvsg&#34; : [&#xA;           &#34;NC_000001.11:g.230710048A&amp;gt;G&#34;&#xA;        ],&#xA;        &#34;hgvsc&#34; : [&#xA;           &#34;ENST00000366667.6:c.776T&amp;gt;C&#34;,&#xA;           &#34;ENST00000679684.1:c.776T&amp;gt;C&#34;,&#xA;           &#34;ENST00000679738.1:c.776T&amp;gt;C&#34;,&#xA;           &#34;ENST00000679802.1:c.776T&amp;gt;C&#34;,&#xA;           &#34;ENST00000679854.1:n.1287T&amp;gt;C&#34;,&#xA;           &#34;ENST00000679957.1:c.776T&amp;gt;C&#34;,&#xA;           &#34;ENST00000680041.1:c.776T&amp;gt;C&#34;,&#xA;           &#34;ENST00000680783.1:c.776T&amp;gt;C&#34;,&#xA;           &#34;ENST00000681269.1:c.776T&amp;gt;C&#34;,&#xA;           &#34;ENST00000681347.1:n.1287T&amp;gt;C&#34;,&#xA;           &#34;ENST00000681514.1:c.776T&amp;gt;C&#34;,&#xA;           &#34;ENST00000681772.1:c.776T&amp;gt;C&#34;,&#xA;           &#34;NM_001382817.3:c.776T&amp;gt;C&#34;,&#xA;           &#34;NM_001384479.1:c.776T&amp;gt;C&#34;&#xA;        ],&#xA;        &#34;hgvsp&#34; : [&#xA;           &#34;ENSP00000355627.5:p.Met259Thr&#34;,&#xA;           &#34;ENSP00000505981.1:p.Met259Thr&#34;,&#xA;           &#34;ENSP00000505063.1:p.Met259Thr&#34;,&#xA;           &#34;ENSP00000505184.1:p.Met259Thr&#34;,&#xA;           &#34;ENSP00000506646.1:p.Met259Thr&#34;,&#xA;           &#34;ENSP00000504866.1:p.Met259Thr&#34;,&#xA;           &#34;ENSP00000506329.1:p.Met259Thr&#34;,&#xA;           &#34;ENSP00000505985.1:p.Met259Thr&#34;,&#xA;           &#34;ENSP00000505963.1:p.Met259Thr&#34;,&#xA;           &#34;ENSP00000505829.1:p.Met259Thr&#34;,&#xA;           &#34;NP_001369746.2:p.Met259Thr&#34;,&#xA;           &#34;NP_001371408.1:p.Met259Thr&#34;&#xA;        ],&#xA;        &#34;spdi&#34; : [&#xA;           &#34;NC_000001.11:230710047:A:G&#34;&#xA;        ]&#xA;     }&#xA;   }&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;recoderopts&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Options&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;variant_recoder&lt;/code&gt; shares many of the same command line flags as VEP. Others are unique to &lt;code&gt;variant_recoder&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;-id|--input_data [input_string]&lt;/code&gt;: a single variant as a string.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-i|--input_file [input_file]&lt;/code&gt;: input file containing one or more variants, one per line. Mixed formats disallowed.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--species&lt;/code&gt;: species to use (default: homo_sapiens).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--grch37&lt;/code&gt;: use GRCh37 assembly instead of GRCh38.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--genomes&lt;/code&gt;: set database parameters for &lt;a href=&#34;http://ensemblgenomes.org/&#34;&gt;Ensembl Genomes&lt;/a&gt; species.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--pretty&lt;/code&gt;: write pre-formatted indented JSON.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--fields [field1,field2]&lt;/code&gt;: limit output fields. Comma-separated list, one or more of: &lt;code&gt;id&lt;/code&gt;, &lt;code&gt;hgvsg&lt;/code&gt;, &lt;code&gt;hgvsc&lt;/code&gt;, &lt;code&gt;hgvsp&lt;/code&gt;, &lt;code&gt;spdi&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--vcf_string&lt;/code&gt; : report VCF&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--var_synonyms&lt;/code&gt; : report variation synonyms&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--mane_select&lt;/code&gt; : report MANE Select transcripts in HGVS format&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--host [db_host]&lt;/code&gt;: change database host from default &lt;code&gt;ensembldb.ensembl.org&lt;/code&gt; (UK); geographic mirrors are &lt;code&gt;useastdb.ensembl.org&lt;/code&gt; (US East Coast) and &lt;code&gt;asiadb.ensembl.org&lt;/code&gt; (Asia). &lt;code&gt;--user&lt;/code&gt;, &lt;code&gt;--port&lt;/code&gt; and &lt;code&gt;--pass&lt;/code&gt; may also be set.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--pick&lt;/code&gt;, &lt;code&gt;--per_gene&lt;/code&gt;, &lt;code&gt;--pick_allele&lt;/code&gt;, &lt;code&gt;--pick_allele_gene&lt;/code&gt;, &lt;code&gt;--pick_order&lt;/code&gt;: set and customise transcript selection process, see &lt;a href=&#34;http://www.ensembl.org/info/docs/tools/vep/script/vep_other.html#pick&#34;&gt;VEP documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>maxmind/MaxMind-DB</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/maxmind/MaxMind-DB</id>
    <link href="https://github.com/maxmind/MaxMind-DB" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Spec and test data for the MaxMind DB file format&lt;/p&gt;&lt;hr&gt;&lt;p&gt;MaxMind DB is a binary file format that stores data indexed by IP address subnets (IPv4 or IPv6).&lt;/p&gt; &#xA;&lt;p&gt;This repository contains the spec for that format.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ThePrimeagen/.dotfiles</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/ThePrimeagen/.dotfiles</id>
    <link href="https://github.com/ThePrimeagen/.dotfiles" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;.dotfiles&lt;/h1&gt; &#xA;&lt;h3&gt;Kinesis Advantage 360&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Will there be a travel case?&lt;/li&gt; &#xA; &lt;li&gt;Will there be blank key caps?&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>movabletype/movabletype</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/movabletype/movabletype</id>
    <link href="https://github.com/movabletype/movabletype" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Movable Type&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to Movable Type&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/movabletype/movabletype&#34;&gt;&lt;img src=&#34;https://travis-ci.org/movabletype/movabletype.svg?branch=develop&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://circleci.com/gh/movabletype/movabletype/tree/develop&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/movabletype/movabletype/tree/develop.svg?style=svg&amp;amp;circle-token=698358bf40b4ca0bda1e4e9571ffce0cb5584d41&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/movabletype/movabletype?branch=develop&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/movabletype/movabletype/badge.svg?branch=develop&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Thank you for choosing Movable Type, the premiere solution for your blogging and website management needs. This file will explain how to get up and running; click on the highlighted sections for more information on that subject.&lt;/p&gt; &#xA;&lt;h2&gt;Before You Begin&lt;/h2&gt; &#xA;&lt;p&gt;Movable Type requires the following applications:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Perl 5.10.1 or greater;&lt;/li&gt; &#xA; &lt;li&gt;A web server like nginx, Apache or Windows IIS;&lt;/li&gt; &#xA; &lt;li&gt;Access to a database like MySQL;&lt;/li&gt; &#xA; &lt;li&gt;The following Perl modules:&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/DBI&#34;&gt;DBI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Image::Size&#34;&gt;Image::Size&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/CGI::Cookie&#34;&gt;CGI::Cookie&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/HTML::Entities&#34;&gt;HTML::Entities&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Consult the CPAN documentation to learn how to &lt;a href=&#34;http://www.cpan.org/misc/cpan-faq.html#How_installed_modules&#34;&gt;determine if a Perl module is already installed&lt;/a&gt; and, if they are not, &lt;a href=&#34;http://www.cpan.org/misc/cpan-faq.html#How_install_Perl_modules&#34;&gt;how to install them&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Upgrading Movable Type&lt;/h2&gt; &#xA;&lt;p&gt;If you are upgrading to Movable Type 7 from a previous version, we recommend that you first back up your old installation. Database backup is especially important to restore your system in case of any trouble during the upgrade process. Upload Movable Type 7&#39;s files over the same files from the previous version of Movable Type. Access Movable Type as you normally do, and you will be taken through the upgrade process.&lt;/p&gt; &#xA;&lt;h2&gt;Installing Movable Type&lt;/h2&gt; &#xA;&lt;p&gt;Before you install Movable Type:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Upload all of Movable Type&#39;s files into a directory or folder accessible via your web browser. We recommend that you separate your published content from the Movable Type executable programs by placing each in a separate directory. Typically, the installation directory is called &#39;mt&#39; and is located in the root directory of your website or within an existing directory that is already configured to allow CGI script execution.&lt;/li&gt; &#xA; &lt;li&gt;Make sure that the &#39;mt&#39; directory containing the uploaded Movable Type files has been &lt;a href=&#34;http://httpd.apache.org/docs/2.0/howto/cgi.html#nonscriptalias&#34;&gt;enabled to execute CGI scripts&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Make sure that each .cgi file (e.g. mt.cgi, mt-search.cgi, etc.) found in the Movable Type directory has the &lt;a href=&#34;http://www.elated.com/articles/understanding-permissions/&#34;&gt;execute permission&lt;/a&gt; enabled.&lt;/li&gt; &#xA; &lt;li&gt;Open that folder in your web browser -- &lt;code&gt;i.e. http://www.mywebsite.com/mt/&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You should see a Movable Type welcome screen that will take you through the installation process. If the welcome screen does not appear, please consult Troubleshooting Movable Type below.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Troubleshooting Movable Type&lt;/h2&gt; &#xA;&lt;h3&gt;Setting up your static web path&lt;/h3&gt; &#xA;&lt;p&gt;Some web servers and configurations do not allow static files such as JavaScript, CSS and image files to be located inside of a directory where CGI scripts are located. If you installed Movable Type into a cgi-bin directory, you may need to relocate the &#39;mt-static&#39; directory to another web accessible location. Read our documentation on setting up your &lt;a href=&#34;https://movabletype.org/documentation/installation/file-system.html#static-directory&#34;&gt;mt-static directory&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Internal Server Errors&lt;/h3&gt; &#xA;&lt;p&gt;If you receive an &#34;Internal Server Error&#34; message, a configuration change may be required on your web server. Please consult our &lt;a href=&#34;https://www.movabletype.org/documentation/installation/&#34;&gt;installation guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Finding more help&lt;/h3&gt; &#xA;&lt;p&gt;Need additional information or support? Check out the &lt;a href=&#34;https://www.movabletype.org/documentation/installation/&#34;&gt;Detailed Installation Guide&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>linux-test-project/lcov</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/linux-test-project/lcov</id>
    <link href="https://github.com/linux-test-project/lcov" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LCOV&lt;/p&gt;&lt;hr&gt;&lt;hr&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;README file for the LTP GCOV extension (LCOV) -&lt;/li&gt; &#xA; &lt;li&gt;Last changes: 2019-02-28 -&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;LCOV is an extension of GCOV, a GNU tool which provides information about what parts of a program are actually executed (i.e. &#34;covered&#34;) while running a particular test case. The extension consists of a set of Perl scripts which build on the textual GCOV output to implement the following enhanced functionality:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;* HTML based output: coverage rates are additionally indicated using bar&#xA;  graphs and specific colors.&#xA;&#xA;* Support for large projects: overview pages allow quick browsing of&#xA;  coverage data by providing three levels of detail: directory view,&#xA;  file view and source code view.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;LCOV was initially designed to support Linux kernel coverage measurements, but works as well for coverage measurements on standard user space applications.&lt;/p&gt; &#xA;&lt;h2&gt;Further README contents&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Included files&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Installing LCOV&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;An example of how to access kernel coverage data&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;An example of how to access coverage data for a user space program&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Questions and Comments&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Important files&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;README - This README file CHANGES - List of changes between releases bin/lcov - Tool for capturing LCOV coverage data bin/genhtml - Tool for creating HTML output from LCOV data bin/gendesc - Tool for creating description files as used by genhtml bin/geninfo - Internal tool (creates LCOV data files) bin/genpng - Internal tool (creates png overviews of source files) bin/install.sh - Internal tool (takes care of un-/installing) man - Directory containing man pages for included tools example - Directory containing an example to demonstrate LCOV lcovrc - LCOV configuration file Makefile - Makefile providing &#39;install&#39; and &#39;uninstall&#39; targets&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Installing LCOV&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;The LCOV package is available as either RPM or tarball from:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://ltp.sourceforge.net/coverage/lcov.php&#34;&gt;http://ltp.sourceforge.net/coverage/lcov.php&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To install the tarball, unpack it to a directory and run:&lt;/p&gt; &#xA;&lt;p&gt;make install&lt;/p&gt; &#xA;&lt;p&gt;Use Git for the most recent (but possibly unstable) version:&lt;/p&gt; &#xA;&lt;p&gt;git clone &lt;a href=&#34;https://github.com/linux-test-project/lcov.git&#34;&gt;https://github.com/linux-test-project/lcov.git&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Change to the resulting lcov directory and type:&lt;/p&gt; &#xA;&lt;p&gt;make install&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;An example of how to access kernel coverage data&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Requirements: get and install the gcov-kernel package from&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://sourceforge.net/projects/ltp&#34;&gt;http://sourceforge.net/projects/ltp&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Copy the resulting gcov kernel module file to either the system wide modules directory or the same directory as the Perl scripts. As root, do the following:&lt;/p&gt; &#xA;&lt;p&gt;a) Resetting counters&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; lcov --zerocounters&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;b) Capturing the current coverage state to a file&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; lcov --capture --output-file kernel.info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;c) Getting HTML output&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; genhtml kernel.info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Point the web browser of your choice to the resulting index.html file.&lt;/p&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;An example of how to access coverage data for a user space program&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Requirements: compile the program in question using GCC with the options -fprofile-arcs and -ftest-coverage. During linking, make sure to specify -lgcov or -coverage.&lt;/p&gt; &#xA;&lt;p&gt;Assuming the compile directory is called &#34;appdir&#34;, do the following:&lt;/p&gt; &#xA;&lt;p&gt;a) Resetting counters&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; lcov --directory appdir --zerocounters&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;b) Capturing the current coverage state to a file&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; lcov --directory appdir --capture --output-file app.info&#xA;&#xA; Note that this step only works after the application has&#xA; been started and stopped at least once. Otherwise lcov will&#xA; abort with an error mentioning that there are no data/.gcda files.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;c) Getting HTML output&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; genhtml app.info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Point the web browser of your choice to the resulting index.html file.&lt;/p&gt; &#xA;&lt;p&gt;Please note that independently of where the application is installed or from which directory it is run, the --directory statement needs to point to the directory in which the application was compiled.&lt;/p&gt; &#xA;&lt;p&gt;For further information on the gcc profiling mechanism, please also consult the gcov man page.&lt;/p&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Questions and comments&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;See the included man pages for more information on how to use the LCOV tools.&lt;/p&gt; &#xA;&lt;p&gt;Please email further questions or comments regarding this tool to the LTP Mailing list at &lt;a href=&#34;mailto:ltp-coverage@lists.sourceforge.net&#34;&gt;ltp-coverage@lists.sourceforge.net&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>major/MySQLTuner-perl</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/major/MySQLTuner-perl</id>
    <link href="https://github.com/major/MySQLTuner-perl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;MySQLTuner is a script written in Perl that will assist you with your MySQL configuration and make recommendations for increased performance and stability.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://github.com/major/MySQLTuner-perl/raw/master/mtlogo.png&#34; alt=&#34;MySQLTuner-perl&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/major/MySQLTuner-perl&#34;&gt;&lt;img src=&#34;https://travis-ci.org/major/MySQLTuner-perl.svg?branch=master&#34; alt=&#34;Build Status - Master&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://opensource.box.com/badges&#34;&gt;&lt;img src=&#34;http://opensource.box.com/badges/active.svg?sanitize=true&#34; alt=&#34;Project Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://opensource.box.com/badges&#34;&gt;&lt;img src=&#34;http://opensource.box.com/badges/maintenance.svg?sanitize=true&#34; alt=&#34;Project Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://isitmaintained.com/project/major/MySQLTuner-perl&#34; title=&#34;Average time to resolve an issue&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/resolution/major/MySQLTuner-perl.svg?sanitize=true&#34; alt=&#34;Average time to resolve an issue&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://isitmaintained.com/project/major/MySQLTuner-perl&#34; title=&#34;Percentage of issues still open&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/open/major/MySQLTuner-perl.svg?sanitize=true&#34; alt=&#34;Percentage of open issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/GPL-3.0/&#34;&gt;&lt;img src=&#34;https://badges.frapsoft.com/os/gpl/gpl.png?v=103&#34; alt=&#34;GPL License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MySQLTuner&lt;/strong&gt; is a script written in Perl that allows you to review a MySQL installation quickly and make adjustments to increase performance and stability. The current configuration variables and status data is retrieved and presented in a brief format along with some basic performance suggestions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MySQLTuner&lt;/strong&gt; supports ~300 indicators for MySQL/MariaDB/Percona Server in this last version.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MySQLTuner&lt;/strong&gt; is maintained and indicator collect is increasing week after week supporting a lot of configuration such as &lt;a href=&#34;http://galeracluster.com/&#34;&gt;Galera Cluster&lt;/a&gt;, &lt;a href=&#34;https://www.percona.com/software/mysql-database/percona-tokudb&#34;&gt;TokuDB&lt;/a&gt;, &lt;a href=&#34;https://github.com/mysql/mysql-sys&#34;&gt;Performance schema&lt;/a&gt;, Linux OS metrics, &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.7/en/innodb-storage-engine.html&#34;&gt;InnoDB&lt;/a&gt;, &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.7/en/myisam-storage-engine.html&#34;&gt;MyISAM&lt;/a&gt;, &lt;a href=&#34;https://mariadb.com/kb/en/mariadb/aria/&#34;&gt;Aria&lt;/a&gt;, ...&lt;/p&gt; &#xA;&lt;p&gt;You can find more details on these indicators here: &lt;a href=&#34;https://github.com/major/MySQLTuner-perl/raw/master/INTERNALS.md&#34;&gt;Indicators description&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/major/MySQLTuner-perl/raw/master/mysqltuner.png&#34; alt=&#34;MysqlTuner&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;MySQLTuner needs you:&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;MySQLTuner&lt;/strong&gt; needs contributors for documentation, code and feedback..&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Please join us on issue track at &lt;a href=&#34;https://github.com/major/MySQLTuner-perl/issues&#34;&gt;GitHub tracker&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Contribution guide is available following &lt;a href=&#34;https://github.com/major/MySQLTuner-perl/raw/master/CONTRIBUTING.md&#34;&gt;MySQLTuner contributing guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Star &lt;strong&gt;MySQLTuner project&lt;/strong&gt; at &lt;a href=&#34;https://github.com/major/MySQLTuner-perl&#34;&gt;MySQLTuner Git Hub Project&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Paid support for Releem available here: &lt;a href=&#34;https://releem.com/&#34;&gt;Releem App&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Stargazers over time&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://starcharts.herokuapp.com/major/MySQLTuner-perl&#34;&gt;&lt;img src=&#34;https://starcharts.herokuapp.com/major/MySQLTuner-perl.svg?sanitize=true&#34; alt=&#34;Stargazers over time&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Compatibility&lt;/h1&gt; &#xA;&lt;p&gt;Test result are available here: &lt;a href=&#34;https://travis-ci.org/major/MySQLTuner-perl&#34;&gt;Travis CI/MySQLTuner-perl&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;MySQL 8.0 (partial support, password checks don&#39;t work)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Percona Server 8.0 (partial support, password checks don&#39;t work)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MySQL 5.7 (full support)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Percona Server 5.7 (full support)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MariaDB 10.6 (full support)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MariaDB 10.5 (full support)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MariaDB 10.4 (full support)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MariaDB 10.3 (full support)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Galera replication (full support)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Percona XtraDB cluster (full support)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Mysql Replications (partial support, no test environment)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MySQL 5.6 (no support, deprecated version)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Percona Server 5.6 (no support, deprecated version)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MySQL 5.5 (no support, deprecated version)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MariaDB 5.5 (no support, deprecated version)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MariaDB 10.2 (no support, deprecated version)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MariaDB 10.1 (no support, deprecated version)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MariaDB 10.0 (no support, deprecated version)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MySQL 3.23, 4.0, 4.1, 5.0, 5.1 (no support - deprecated version)&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;*** Windows Support is partial ***&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows is now supported at this time&lt;/li&gt; &#xA; &lt;li&gt;Successfully run MySQLtuner across WSL2 (Windows Subsystem Linux )&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/&#34;&gt;https://docs.microsoft.com/en-us/windows/wsl/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;*** UNSUPPORTED ENVIRONMENTS - NEED HELP FOR THAT :) ***&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cloud based is not supported at this time (Help wanted !!!!! GCP, AWS, Azure support asked)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;*** Unsupported storage engines: PRs welcome ***&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;NDB is not supported feel free to Pull Request code :)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MyISAM is to old is no longer active&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;RockDB&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Archive&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Spider&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ColummStore&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;TokuDB&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;XtraDB&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Connect&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;CVE vulnerabilities detection support from &lt;a href=&#34;https://cve.mitre.org&#34;&gt;https://cve.mitre.org&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;*** MINIMAL REQUIREMENTS ***&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Perl 5.6 or later (with &lt;a href=&#34;http://search.cpan.org/~dapm/perl-5.14.4/pod/perldoc.pod&#34;&gt;perl-doc&lt;/a&gt; package)&lt;/li&gt; &#xA; &lt;li&gt;Unix/Linux based operating system (tested on Linux, BSD variants, and Solaris variants)&lt;/li&gt; &#xA; &lt;li&gt;Unrestricted read access to the MySQL server (OS root access recommended for MySQL &amp;lt; 5.1)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;strong&gt;WARNING&lt;/strong&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;It is &lt;strong&gt;extremely important&lt;/strong&gt; for you to fully understand each change you make to a MySQL database server. If you don&#39;t understand portions of the script&#39;s output, or if you don&#39;t understand the recommendations, &lt;strong&gt;you should consult&lt;/strong&gt; a knowledgeable DBA or system administrator that you trust. &lt;strong&gt;Always&lt;/strong&gt; test your changes on staging environments, and always keep in mind that improvements in one area can &lt;strong&gt;negatively affect&lt;/strong&gt; MySQL in other areas.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s &lt;strong&gt;also important&lt;/strong&gt; to wait at least a day of uptime to get accurate results. In fact, running &lt;strong&gt;mysqltuner&lt;/strong&gt; on a fresh restarted server is completely useless.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Seriously - please review the FAQ section below.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Security recommendations&lt;/h2&gt; &#xA;&lt;p&gt;Hi directadmin user! We detected that you run mysqltuner with da_admin&#39;s credentials taken from &lt;code&gt;/usr/local/directadmin/conf/my.cnf&lt;/code&gt;, which might bring to a password discovery! Read link for more details &lt;a href=&#34;https://github.com/major/MySQLTuner-perl/issues/289&#34;&gt;Issue #289&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;What MySQLTuner is checking exactly ?&lt;/h2&gt; &#xA;&lt;p&gt;All checks done by &lt;strong&gt;MySQLTuner&lt;/strong&gt; are documented in &lt;a href=&#34;https://github.com/major/MySQLTuner-perl/raw/master/INTERNALS.md&#34;&gt;MySQLTuner Internals&lt;/a&gt; documentation.&lt;/p&gt; &#xA;&lt;h2&gt;Download/Installation&lt;/h2&gt; &#xA;&lt;p&gt;Choose one of these methods:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Script direct download (the simplest and shortest method):&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;wget http://mysqltuner.pl/ -O mysqltuner.pl&#xA;wget https://raw.githubusercontent.com/major/MySQLTuner-perl/master/basic_passwords.txt -O basic_passwords.txt&#xA;wget https://raw.githubusercontent.com/major/MySQLTuner-perl/master/vulnerabilities.csv -O vulnerabilities.csv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;You can download the entire repository by using &lt;code&gt;git clone&lt;/code&gt; or &lt;code&gt;git clone --depth 1 -b master&lt;/code&gt; followed by the cloning URL above.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Optional Sysschema installation for MySQL 5.6&lt;/h2&gt; &#xA;&lt;p&gt;Sysschema is installed by default under MySQL 5.7 and MySQL 8 from Oracle. By default, on MySQL 5.6/5.7/8, performance schema is enabled by default. For previous MySQL 5.6 version, you can follow this command to create a new database sys containing very useful view on Performance schema:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl &#34;https://codeload.github.com/mysql/mysql-sys/zip/master&#34; &amp;gt; sysschema.zip&#xA;# check zip file&#xA;unzip -l sysschema.zip&#xA;unzip sysschema.zip&#xA;cd mysql-sys-master&#xA;mysql -uroot -p &amp;lt; sys_56.sql&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Optional Performance schema and Sysschema installation for MariaDB 10.x&lt;/h2&gt; &#xA;&lt;p&gt;Sysschema is not installed by default under MariaDB prior to 10.6 By default, on MariaDB, performance schema is disabled by default. consider activating performance schema across your my.cnf configuration file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[mysqld]&#xA;performance_schema = on&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can follow this command to create a new database sys containing very useful view on Performance schema:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl &#34;https://codeload.github.com/FromDual/mariadb-sys/zip/master&#34; &amp;gt; mariadb-sys.zip&#xA;# check zip file&#xA;unzip -l mariadb-sys.zip&#xA;unzip mariadb-sys.zip&#xA;cd mariadb-sys-master/&#xA;mysql -u root -p &amp;lt; ./sys_10.sql&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Errors &amp;amp; solutions for performance schema installation&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; ERROR at line 21: Failed to open file &#39;./tables/sys_config_data_10.sql -- ported&#39;, error: 2&#xA; Have a look at #452 solution given by @ericx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Performance tips&lt;/h2&gt; &#xA;&lt;p&gt;Metadata statistic updates can impact strongly performance of database servers and MySQLTuner. Be sure that innodb_stats_on_metadata is disabled.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;set global innodb_stats_on_metadata = 0;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Specific usage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Minimal usage locally&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --host 127.0.0.1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Of course, you can add the execute bit (&lt;code&gt;chmod +x mysqltuner.pl&lt;/code&gt;) so you can execute it without calling perl directly.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Minimal usage remotely&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --host targetDNS_IP --user admin_user --pass admin_password&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Enable maximum output information around MySQL/MariaDb without debugging&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --verbose&#xA;perl mysqltuner.pl --buffers --dbstat --idxstat --sysstat --pfstat --tbstat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Enable CVE vulnerabilities check for your MariaDB or MySQL version&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --cvefile=vulnerabilities.csv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Write your result in a file with information displayed&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --outputfile /tmp/result_mysqltuner.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Write your result in a file &lt;strong&gt;without outputting information&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --silent --outputfile /tmp/result_mysqltuner.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Using template model to customize your reporting file based on &lt;a href=&#34;https://metacpan.org/pod/Text::Template&#34;&gt;Text::Template&lt;/a&gt; syntax.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --silent --reportfile /tmp/result_mysqltuner.txt --template=/tmp/mymodel.tmpl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Enable debugging information&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Update MySQLTuner and data files (password and cve) if needed&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --checkversion --updateversion&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;HTML reports based on Python Jinja2&lt;/h2&gt; &#xA;&lt;p&gt;HTML generation is based on Python/Jinja2&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;HTML generation Procedure&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate mysqltuner.pl report using JSON format (--json)&lt;/li&gt; &#xA; &lt;li&gt;Generate HTML report using j2 python tools&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Jinja2 Templates are located under templates sub directory&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;A basic example is called basic.html.j2&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Installation Python j2&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -mvenv j2&#xA;source ./j2/bin/activate&#xA;(j2) pip install j2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Using Html report generation&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --verbose --json &amp;gt; reports.json&#xA;cat reports.json  j2 -f json MySQLTuner-perl/templates/basic.html.j2 &amp;gt; variables.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --verbose --json | j2 -f json MySQLTuner-perl/templates/basic.html.j2 &amp;gt; variables.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;HTML reports based on AHA&lt;/h2&gt; &#xA;&lt;p&gt;HTML generation is based on AHA&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;HTML generation Procedure&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate mysqltuner.pl report using standard text reports&lt;/li&gt; &#xA; &lt;li&gt;Generate HTML report using aha&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Installation Aha&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Follow instructions from Github repo&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/theZiz/aha&#34;&gt;GitHub AHA main repository&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Using AHA Html report generation&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --verbose --color &amp;gt; reports.txt&#xA;aha --black --title &#34;MySQLTuner&#34; -f &#34;reports.txt&#34; &amp;gt; &#34;reports.html&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl mysqltuner.pl --verbose --color | aha --black --title &#34;MySQLTuner&#34; &amp;gt; reports.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Question: Will MySQLTuner fix my slow MySQL server?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;No.&lt;/strong&gt; MySQLTuner is a read only script. It won&#39;t write to any configuration files, change the status of any daemons, or call your mother to wish her a happy birthday. It will give you an overview of your server&#39;s performance and make some basic recommendations for improvements that you can make after it completes. &lt;em&gt;Make sure you read the warning above prior to following any recommendations.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Question: Can I fire my DBA now?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MySQLTuner will not replace your DBA in any form or fashion.&lt;/strong&gt; If your DBA constantly takes your parking spot and steals your lunch from the fridge, then you may want to consider it - but that&#39;s your call.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Question: Why does MySQLTuner keep asking me the login credentials for MySQL over and over?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The script will try its best to log in via any means possible. It will check for ~/.my.cnf files, Plesk password files, and empty password root logins. If none of those are available, then you&#39;ll be prompted for a password. If you&#39;d like the script to run in an automated fashion without user intervention, then create a .my.cnf file in your home directory which contains:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[client]&#xA;user=someusername&#xA;password=thatuserspassword&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once you create it, make sure it&#39;s owned by your user and the mode on the file is 0600. This should prevent the prying eyes from getting your database login credentials under normal conditions. If a &lt;a href=&#34;https://en.wikipedia.org/wiki/T-1000&#34;&gt;T-1000 shows up in a LAPD uniform&lt;/a&gt; and demands your database credentials, you won&#39;t have much of an option.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Question: Is there another way to secure credentials on latest MySQL and MariaDB distributions ?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You could use mysql_config_editor utilities.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#x9;$ mysql_config_editor set --login-path=client --user=someusername --password --host=localhost&#xA;&#x9;Enter password: ********&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After which, &lt;code&gt;~/.mylogin.cnf&lt;/code&gt; will be created with the appropriate access.&lt;/p&gt; &#xA;&lt;p&gt;To get information about stored credentials, use the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$mysql_config_editor print&#xA;[client]&#xA;user = someusername&#xA;password = *****&#xA;host = localhost&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Question: What&#39;s minimum privileges needed by a specific mysqltuner user in database ?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;    mysql&amp;gt;GRANT SELECT, PROCESS,EXECUTE, REPLICATION CLIENT,SHOW DATABASES,SHOW VIEW ON *.* TO &#39;mysqltuner&#39;@&#39;localhost&#39; identified by pwd1234;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Question: It&#39;s not working on my OS! What gives?!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;These kinds of things are bound to happen. Here are the details I need from you in order to research the problem thoroughly:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;OS and OS version&lt;/li&gt; &#xA; &lt;li&gt;Architecture (x86, x86_64, IA64, Commodore 64)&lt;/li&gt; &#xA; &lt;li&gt;Exact MySQL version&lt;/li&gt; &#xA; &lt;li&gt;Where you obtained your MySQL version (OS package, source, etc)&lt;/li&gt; &#xA; &lt;li&gt;The full text of the error&lt;/li&gt; &#xA; &lt;li&gt;A copy of SHOW VARIABLES and SHOW GLOBAL STATUS output (if possible)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Question: How to perform CVE vulnerability checks?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download vulnerabilities.csv from this repository.&lt;/li&gt; &#xA; &lt;li&gt;use option --cvefile to perform CVE checks&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Question: How to use mysqltuner from a remote host?&lt;/strong&gt; Thanks to &lt;a href=&#34;http://dba.stackexchange.com/users/877/rolandomysqldba&#34;&gt;@rolandomysqldba&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You will still have to connect like a mysql client:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Connection and Authentication&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;--host &amp;lt;hostname&amp;gt; Connect to a remote host to perform tests (default: localhost)&#xA;--socket &amp;lt;socket&amp;gt; Use a different socket for a local connection&#xA;--port &amp;lt;port&amp;gt;     Port to use for connection (default: 3306)&#xA;--user &amp;lt;username&amp;gt; Username to use for authentication&#xA;--pass &amp;lt;password&amp;gt; Password to use for authentication&#xA;--defaults-file &amp;lt;path&amp;gt; defaults file for credentials&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Since you are using a remote host, use parameters to supply values from the OS&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;--forcemem &amp;lt;size&amp;gt;  Amount of RAM installed in megabytes&#xA;--forceswap &amp;lt;size&amp;gt; Amount of swap memory configured in megabytes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You may have to contact your remote SysAdmin to ask how much RAM and swap you have&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If the database has too many tables, or very large table, use this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;--skipsize           Don&#39;t enumerate tables and their types/sizes (default: on)&#xA;                     (Recommended for servers with many tables)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Question: Can I install this project using homebrew on Apple Macintosh?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Yes! &lt;code&gt;brew install mysqltuner&lt;/code&gt; can be used to install this application using &lt;a href=&#34;https://brew.sh/&#34;&gt;homebrew&lt;/a&gt; on Apple Macintosh.&lt;/p&gt; &#xA;&lt;h2&gt;MySQLTuner and Vagrant&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;MySQLTuner&lt;/strong&gt; contains following Vagrant configurations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fedora Core 30 / Docker&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Vagrant File&lt;/strong&gt; is stored in Vagrant subdirectory.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Follow following step after vagrant installation: $ vagrant up&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;MySQLTuner&lt;/strong&gt; contains a Vagrant configurations for test purpose and development&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install VirtualBox and Vagrant &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.virtualbox.org/wiki/Downloads&#34;&gt;https://www.virtualbox.org/wiki/Downloads&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.vagrantup.com/downloads.html&#34;&gt;https://www.vagrantup.com/downloads.html&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Clone repository &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;git clone &lt;a href=&#34;https://github.com/major/MySQLTuner-perl.git&#34;&gt;https://github.com/major/MySQLTuner-perl.git&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Install Vagrant plugins vagrant-hostmanager and vagrant-vbguest &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;vagrant plugin install vagrant-hostmanager&lt;/li&gt; &#xA;   &lt;li&gt;vagrant plugin install vagrant-vbguest&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Add Fedora Core 30 box for official Fedora Download Website &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;vagrant box add --name generic/fedora30&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Create a data directory &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;mkdir data&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;setup test environments&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sh build/createTestEnvs.sh&#xA;&#xA;$ source build/bashrc&#xA;$ mysql_percona80 sakila&#xA;sakila&amp;gt; ...&#xA;&#xA;$ docker images&#xA;mariadb                  10.1                fc612450e1f1        12 days ago         352MB&#xA;mariadb                  10.2                027b7c57b8c6        12 days ago         340MB&#xA;mariadb                  10.3                47dff68107c4        12 days ago         343MB&#xA;mariadb                  10.4                92495405fc36        12 days ago         356MB&#xA;mysql                    5.6                 95e0fc47b096        2 weeks ago         257MB&#xA;mysql                    5.7                 383867b75fd2        2 weeks ago         373MB&#xA;mysql                    8.0                 b8fd9553f1f0        2 weeks ago         445MB&#xA;percona/percona-server   5.7                 ddd245ed3496        5 weeks ago         585MB&#xA;percona/percona-server   5.6                 ed0a36e0cf1b        6 weeks ago         421MB&#xA;percona/percona-server   8.0                 390ae97d57c6        6 weeks ago         697MB&#xA;mariadb                  5.5                 c7bf316a4325        4 months ago        352MB&#xA;mariadb                  10.0                d1bde56970c6        4 months ago        353MB&#xA;mysql                    5.5                 d404d78aa797        4 months ago        205MB&#xA;&#xA;$ docker ps&#xA;CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS                               NAMES&#xA;da2be9b050c9        mariadb:5.5                  &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          0.0.0.0:5311-&amp;gt;3306/tcp              mariadb55&#xA;5deca25d5ac8        mariadb:10.0                 &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          0.0.0.0:5310-&amp;gt;3306/tcp              mariadb100&#xA;73aaeb37e2c2        mariadb:10.1                 &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          0.0.0.0:5309-&amp;gt;3306/tcp              mariadb101&#xA;72ffa77e01ec        mariadb:10.2                 &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          0.0.0.0:5308-&amp;gt;3306/tcp              mariadb102&#xA;f5996f2041df        mariadb:10.3                 &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          0.0.0.0:5307-&amp;gt;3306/tcp              mariadb103&#xA;4890c52372bb        mariadb:10.4                 &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          0.0.0.0:5306-&amp;gt;3306/tcp              mariadb104&#xA;6b9dc078e921        percona/percona-server:5.6   &#34;/docker-entrypoint.…&#34;   7 hours ago         Up 7 hours          0.0.0.0:4308-&amp;gt;3306/tcp              percona56&#xA;3a4c7c826d4c        percona/percona-server:5.7   &#34;/docker-entrypoint.…&#34;   7 hours ago         Up 7 hours          0.0.0.0:4307-&amp;gt;3306/tcp              percona57&#xA;3dda408c91b0        percona/percona-server:8.0   &#34;/docker-entrypoint.…&#34;   7 hours ago         Up 7 hours          33060/tcp, 0.0.0.0:4306-&amp;gt;3306/tcp   percona80&#xA;600a4e7e9dcd        mysql:5.5                    &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          0.0.0.0:3309-&amp;gt;3306/tcp              mysql55&#xA;4bbe54342e5d        mysql:5.6                    &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          0.0.0.0:3308-&amp;gt;3306/tcp              mysql56&#xA;a49783249a11        mysql:5.7                    &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          33060/tcp, 0.0.0.0:3307-&amp;gt;3306/tcp   mysql57&#xA;d985820667c2        mysql:8.0                    &#34;docker-entrypoint.s…&#34;   7 hours ago         Up 7 hours          0.0.0.0:3306-&amp;gt;3306/tcp, 33060/tcp   mysql 8    0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;MySQLTuner needs you&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;MySQLTuner&lt;/strong&gt; needs contributors for documentation, code and feedback..&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Please join us on issue track at &lt;a href=&#34;https://github.com/major/MySQLTuner-perl/issues&#34;&gt;GitHub tracker&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Contribution guide is available following &lt;a href=&#34;https://github.com/major/MySQLTuner-perl/raw/master/CONTRIBUTING.md&#34;&gt;MySQLTuner contributing guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Star &lt;strong&gt;MySQLTuner project&lt;/strong&gt; at &lt;a href=&#34;https://github.com/major/MySQLTuner-perl&#34;&gt;MySQLTuner Git Hub Project&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributions welcome !&lt;/h2&gt; &#xA;&lt;p&gt;How to contribute using Pull Request ? Follow this guide : &lt;a href=&#34;https://opensource.com/article/19/7/create-pull-request-github&#34;&gt;Pull request creation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Simple steps to create a pull request:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fork this Github project&lt;/li&gt; &#xA; &lt;li&gt;Clone it to your local system&lt;/li&gt; &#xA; &lt;li&gt;Make a new branch&lt;/li&gt; &#xA; &lt;li&gt;Make your changes&lt;/li&gt; &#xA; &lt;li&gt;Push it back to your repo&lt;/li&gt; &#xA; &lt;li&gt;Click the Compare &amp;amp; pull request button&lt;/li&gt; &#xA; &lt;li&gt;Click Create pull request to open a new pull request&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ocpi/ocpi</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/ocpi/ocpi</id>
    <link href="https://github.com/ocpi/ocpi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Open Charge Point Interface (OCPI) allows for a scalable, automated roaming setup between Charge Point Operators and e-Mobility Service Providers. It supports authorisation, charge point information exchange (incl transaction events), charge detail record exchange and finally, the exchange of smart-charging commands between parties.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;This repository contains the OCPI specification, latest release: &lt;a href=&#34;https://evroaming.org/app/uploads/2021/11/OCPI-2.2.1.pdf&#34;&gt;&lt;code&gt;OCPI 2.2.1&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The branch with the latest fixes to the 2.2.1 documentation is &lt;a href=&#34;https://github.com/ocpi/ocpi/tree/release-2.2.1-bugfixes&#34;&gt;&lt;code&gt;release-2.2.1-bugfixes&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;-The branch with the latest fixes to the 2.2 documentation is &lt;a href=&#34;https://github.com/ocpi/ocpi/tree/release-2.2-bugfixes&#34;&gt;&lt;code&gt;release-2.2-bugfixes&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The branch with the latest fixes to the 2.1.1 documentation is &lt;a href=&#34;https://github.com/ocpi/ocpi/tree/release-2.1.1-bugfixes&#34;&gt;&lt;code&gt;release-2.1.1-bugfixes&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;master&lt;/code&gt; branch always contains the latest official release.&lt;/p&gt; &#xA;&lt;p&gt;Development of the next version of OCPI, new functionality, is done in the &lt;a href=&#34;https://github.com/ocpi/ocpi-3/&#34;&gt;ocpi-3 repository&lt;/a&gt;, which is only accessible to Contributors of the &lt;a href=&#34;https://evroaming.org/how-to-join/&#34;&gt;EV Roaming Foundation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/version_history.asciidoc&#34;&gt;&lt;strong&gt;Version History&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/introduction.asciidoc&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/terminology.asciidoc&#34;&gt;Terminology and Definitions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/topology.asciidoc&#34;&gt;Supported Topologies&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Protocol Meta Information&lt;/strong&gt;, describes the connections between the parties&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/transport_and_format.asciidoc&#34;&gt;Transport and Format&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/status_codes.asciidoc&#34;&gt;Status codes&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/version_information_endpoint.asciidoc&#34;&gt;Version information endpoint&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/credentials.asciidoc&#34;&gt;Credentials &amp;amp; registration&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Overview of Modules&lt;/strong&gt;, each section describes one module.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/mod_locations.asciidoc&#34;&gt;Locations&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/mod_sessions.asciidoc&#34;&gt;Sessions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/mod_cdrs.asciidoc&#34;&gt;CDRs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/mod_tariffs.asciidoc&#34;&gt;Tariffs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/mod_tokens.asciidoc&#34;&gt;Tokens&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/mod_commands.asciidoc&#34;&gt;Commands&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/mod_charging_profiles.asciidoc&#34;&gt;Charging Profiles&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/mod_hub_client_info.asciidoc&#34;&gt;Hub Client Info&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Generic Types&lt;/strong&gt;, describing all data types that are used by multiple objects&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/types.asciidoc&#34;&gt;Types&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/changelog.asciidoc&#34;&gt;&lt;strong&gt;Changelog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Current versions&lt;/h3&gt; &#xA;&lt;h4&gt;Release 2.2.1&lt;/h4&gt; &#xA;&lt;p&gt;Only minor changes, but breaking compatibility with 2.2 in order to support signed data exchange so that parties using OCPI can comply with consumer protection legislation. A more detailed overview is inside &lt;a href=&#34;https://evroaming.org/app/uploads/2021/11/OCPI-2.2.1.pdf&#34;&gt;the specification document itself&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Release 2.2-d2&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support for Hubs &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Message routing headers&lt;/li&gt; &#xA;   &lt;li&gt;Hub Client Info&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Support Platforms with multiple/different roles, additional roles&lt;/li&gt; &#xA; &lt;li&gt;Charging Profiles&lt;/li&gt; &#xA; &lt;li&gt;based Smart Charging&lt;/li&gt; &#xA; &lt;li&gt;Improvements: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;CDRs: Credit CDRs, VAT, Calibration law/Eichrecht support, Session_id, AuthorizationReference, CdrLocation, CdrToken&lt;/li&gt; &#xA;   &lt;li&gt;Sessions: VAT, CdrToken, How to add a Charging Period&lt;/li&gt; &#xA;   &lt;li&gt;Tariffs: Tariff types, Min/Max price, reservation tariff, Much more examples&lt;/li&gt; &#xA;   &lt;li&gt;Locations: Multiple Tariffs, Lost of small improvements&lt;/li&gt; &#xA;   &lt;li&gt;Tokens: Group_id, energy contract&lt;/li&gt; &#xA;   &lt;li&gt;Commands: Cancel Reservation added&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;fixes some bugs of 2.1.1&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Release 2.1.1-d2&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Improvements from rel. 2.0&lt;/li&gt; &#xA; &lt;li&gt;Chargepoint commands&lt;/li&gt; &#xA; &lt;li&gt;realtime authorization&lt;/li&gt; &#xA; &lt;li&gt;fixes some bugs of 2.1 (2.1 is now deprecated)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Release 2.0&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Charge Point Exchange Static &amp;amp; Dynamic (with tariffing covering only start/kWh/time)&lt;/li&gt; &#xA; &lt;li&gt;Authorization &amp;amp; token data exchange&lt;/li&gt; &#xA; &lt;li&gt;Tariffing&lt;/li&gt; &#xA; &lt;li&gt;Session Info exchange (cdr &amp;amp; ndr)&lt;/li&gt; &#xA; &lt;li&gt;Registration (How to connect) &amp;amp; Security&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Planned releases&lt;/h3&gt; &#xA;&lt;h4&gt;Release 3.0&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ISO 15118 Plug&amp;amp;Charge&lt;/li&gt; &#xA; &lt;li&gt;Eichrecht support&lt;/li&gt; &#xA; &lt;li&gt;Performance improvements&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building Process&lt;/h2&gt; &#xA;&lt;p&gt;The OCPI Build Process has been improved. OCPI 2.0/2.1.1 was in markdown format, and diagrams where Plantuml.&lt;/p&gt; &#xA;&lt;p&gt;For OCPI 2.2, the text of OCPI has been converted to asciidoc. Asciidoc is easier to format the output, and chapter numbering and internal links are much easier to work with.&lt;/p&gt; &#xA;&lt;p&gt;The Plantuml is no longer converted to PNG images, but the SVG, making them much better readable, and even searchable in the PDF.&lt;/p&gt; &#xA;&lt;p&gt;In OCPI 2.0 and 2.1.1, the JSON examples contained a lot of mistakes, where outdated compared to the text, or not even valid JSON. To prevent issues with the examples in the specification, the examples are not placed in separate JSON files. At the moment, the JSON files are check if they are valid JSON.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;1 Dec 2014 &lt;a href=&#34;https://raw.githubusercontent.com/ocpi/ocpi/master/releases/old/OCPI-Draftv4.pdf&#34;&gt;Draft v4&lt;/a&gt; is published 17 June 2015 [Draft v5] is moved to a new branch that will be used as a reference as the OCPI specifications are being redefined and the specifications are restructured in different files, a file per chapter&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>AlDanial/cloc</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/AlDanial/cloc</id>
    <link href="https://github.com/AlDanial/cloc" rel="alternate"></link>
    <summary type="html">&lt;p&gt;cloc counts blank lines, comment lines, and physical lines of source code in many programming languages.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name=&#34;___top&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;cloc&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Count Lines of Code&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;cloc counts blank lines, comment lines, and physical lines of source code in many programming languages.&lt;/p&gt; &#xA;&lt;p&gt;Latest release: v1.92 (Dec. 5, 2021)&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/AlDanial/cloc/graphs/contributors&#34; alt=&#34;Contributors&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/contributors/AlDanial/cloc&#34;&gt;&lt;/a&gt; &#xA;&lt;a href=&#34;https://zenodo.org/badge/latestdoi/42029482&#34;&gt; &lt;img src=&#34;https://zenodo.org/badge/42029482.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt; &#xA;&lt;img src=&#34;https://img.shields.io/badge/Maintained%3F-yes-green.svg&gt;&#34;&gt; &#xA;&lt;p&gt;cloc moved to GitHub in September 2015 after being hosted at &lt;a href=&#34;http://cloc.sourceforge.net/&#34;&gt;http://cloc.sourceforge.net/&lt;/a&gt; since August 2006.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#quick-start-&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#overview-&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AlDanial/cloc/releases/latest&#34;&gt;Download&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#install-via-package-manager&#34;&gt;Install via package manager&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#stable-release&#34;&gt;Stable release&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#development-version&#34;&gt;Development version&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#license-&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#why-use-cloc-&#34;&gt;Why Use cloc?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#other-counters-&#34;&gt;Other Counters&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#building-a-windows-executable-&#34;&gt;Building a Windows Executable&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#basic-use-&#34;&gt;Basic Use&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#options-&#34;&gt;Options&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#recognized-languages-&#34;&gt;Recognized Languages&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#how-it-works-&#34;&gt;How it Works&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#advanced-use-&#34;&gt;Advanced Use&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#remove-comments-from-source-code-&#34;&gt;Remove Comments from Source Code&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#work-with-compressed-archives-&#34;&gt;Work with Compressed Archives&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#differences-&#34;&gt;Differences&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#create-custom-language-definitions-&#34;&gt;Create Custom Language Definitions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#combine-reports-&#34;&gt;Combine Reports&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#sql-&#34;&gt;SQL&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#custom-column-output-&#34;&gt;Custom Column Output&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#wrapping-cloc-in-other-scripts-&#34;&gt;Wrapping cloc in other scripts&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#git-and-UTF8-pathnames-&#34;&gt;git and UTF8 pathnames&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#third-generation-language-scale-factors-&#34;&gt;Third Generation Language Scale Factors&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#optionstxt-configuration-file-&#34;&gt;options.txt configuration file&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#complex-regular-subexpression-recursion-limit-&#34;&gt;Complex regular subexpression recursion limit &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#limitations-&#34;&gt;Limitations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#requesting-support-for-additional-languages-&#34;&gt;Requesting Support for Additional Languages&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#reporting-problems-&#34;&gt;Reporting Problems&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#citation-&#34;&gt;Citation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#acknowledgments-&#34;&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#copyright-&#34;&gt;Copyright&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a name=&#34;Quick_Start&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Quick Start ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Step 1: Download cloc (several methods, see below) or run cloc&#39;s &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#Docker-&#34;&gt;docker image&lt;/a&gt;. The Windows executable has no requirements. The source version of cloc requires a Perl interpreter, and the Docker version of cloc requires a Docker installation.&lt;/p&gt; &#xA;&lt;p&gt;Step 2: Open a terminal (&lt;code&gt;cmd.exe&lt;/code&gt; on Windows).&lt;/p&gt; &#xA;&lt;p&gt;Step 3: Invoke cloc to count your source files, directories, archives, or git commits. The executable name differs depending on whether you use the development source version (&lt;code&gt;cloc&lt;/code&gt;), source for a released version (&lt;code&gt;cloc-1.92.pl&lt;/code&gt;) or a Windows executable (&lt;code&gt;cloc-1.92.exe&lt;/code&gt;). On this page, &lt;code&gt;cloc&lt;/code&gt; is the generic term used to refer to any of these.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;a file&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; cloc hello.c&#xA;       1 text file.&#xA;       1 unique file.&#xA;       0 files ignored.&#xA;&#xA;https://github.com/AlDanial/cloc v 1.65  T=0.04 s (28.3 files/s, 340.0 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;C                                1              0              7              5&#xA;-------------------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;a directory&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; cloc gcc-5.2.0/gcc/c&#xA;      16 text files.&#xA;      15 unique files.&#xA;       3 files ignored.&#xA;&#xA;https://github.com/AlDanial/cloc v 1.65  T=0.23 s (57.1 files/s, 188914.0 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;C                               10           4680           6621          30812&#xA;C/C++ Header                     3             99            286            496&#xA;-------------------------------------------------------------------------------&#xA;SUM:                            13           4779           6907          31308&#xA;-------------------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;an archive&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;We&#39;ll pull cloc&#39;s source zip file from GitHub, then count the contents:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; wget https://github.com/AlDanial/cloc/archive/master.zip&#xA;&#xA;prompt&amp;gt; cloc master.zip&#xA;https://github.com/AlDanial/cloc v 1.65  T=0.07 s (26.8 files/s, 141370.3 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;Perl                             2            725           1103           8713&#xA;-------------------------------------------------------------------------------&#xA;SUM:                             2            725           1103           8713&#xA;-------------------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;a git repository, using a specific commit&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;This example uses code from &lt;a href=&#34;https://pypi.python.org/pypi/pudb&#34;&gt;PuDB&lt;/a&gt;, a fantastic Python debugger.&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; git clone http://git.tiker.net/trees/pudb.git&#xA;&#xA;prompt&amp;gt; cd pudb&#xA;&#xA;prompt&amp;gt; cloc 6be804e07a5db&#xA;      48 text files.&#xA;      48 unique files.&#xA;      15 files ignored.&#xA;&#xA;github.com/AlDanial/cloc v 1.73  T=0.15 s (223.1 files/s, 46159.0 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;Python                          28           1519            728           4659&#xA;YAML                             2              9              2             75&#xA;Bourne Shell                     3              6              0             17&#xA;make                             1              4              6             10&#xA;-------------------------------------------------------------------------------&#xA;SUM:                            34           1538            736           4761&#xA;-------------------------------------------------------------------------------&#xA;&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;each subdirectory of a particular directory&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Say you have a directory with three different git-managed projects, Project0, Project1, and Project2. You can use your shell&#39;s looping capability to count the code in each. This example uses bash (scroll down for cmd.exe example):&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; for d in ./*/ ; do (cd &#34;$d&#34; &amp;amp;&amp;amp; echo &#34;$d&#34; &amp;amp;&amp;amp; cloc --vcs git); done&#xA;./Project0/&#xA;7 text files.&#xA;       7 unique files.&#xA;       1 file ignored.&#xA;&#xA;github.com/AlDanial/cloc v 1.71  T=0.02 s (390.2 files/s, 25687.6 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;D                                4             61             32            251&#xA;Markdown                         1              9              0             38&#xA;make                             1              0              0              4&#xA;-------------------------------------------------------------------------------&#xA;SUM:                             6             70             32            293&#xA;-------------------------------------------------------------------------------&#xA;./Project1/&#xA;       7 text files.&#xA;       7 unique files.&#xA;       0 files ignored.&#xA;&#xA;github.com/AlDanial/cloc v 1.71  T=0.02 s (293.0 files/s, 52107.1 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;Go                               7            165            282            798&#xA;-------------------------------------------------------------------------------&#xA;SUM:                             7            165            282            798&#xA;-------------------------------------------------------------------------------&#xA;./Project2/&#xA;      49 text files.&#xA;      47 unique files.&#xA;      13 files ignored.&#xA;&#xA;github.com/AlDanial/cloc v 1.71  T=0.10 s (399.5 files/s, 70409.4 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;Python                          33           1226           1026           3017&#xA;C                                4            327            337            888&#xA;Markdown                         1             11              0             28&#xA;YAML                             1              0              2             12&#xA;-------------------------------------------------------------------------------&#xA;SUM:                            39           1564           1365           3945&#xA;-------------------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;each subdirectory of a particular directory (Windows/cmd.exe)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;for /D %I in (.\*) do cd %I &amp;amp;&amp;amp; cloc --vcs git &amp;amp;&amp;amp; cd ..&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;Overview&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Overview ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;cloc counts blank lines, comment lines, and physical lines of source code in &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#Languages&#34;&gt;many programming languages&lt;/a&gt;. Given two versions of a code base, cloc can compute differences in blank, comment, and source lines. It is written entirely in Perl with no dependencies outside the standard distribution of Perl v5.6 and higher (code from some external modules is &lt;a href=&#34;https://github.com/AlDanial/cloc#regexp_common&#34;&gt;embedded within cloc&lt;/a&gt;) and so is quite portable. cloc is known to run on many flavors of Linux, FreeBSD, NetBSD, OpenBSD, macOS, AIX, HP-UX, Solaris, IRIX, z/OS, and Windows. (To run the Perl source version of cloc on Windows one needs &lt;a href=&#34;http://www.activestate.com/activeperl&#34;&gt;ActiveState Perl&lt;/a&gt; 5.6.1 or higher, &lt;a href=&#34;http://strawberryperl.com/&#34;&gt;Strawberry Perl&lt;/a&gt;, Windows Subsystem for Linux, &lt;a href=&#34;http://www.cygwin.com/&#34;&gt;Cygwin&lt;/a&gt;, &lt;a href=&#34;http://mobaxterm.mobatek.net/&#34;&gt;MobaXTerm&lt;/a&gt; with the Perl plug-in installed, or a mingw environment and terminal such as provided by &lt;a href=&#34;https://gitforwindows.org/&#34;&gt;Git for Windows&lt;/a&gt;. Alternatively one can use the Windows binary of cloc generated with &lt;a href=&#34;http://search.cpan.org/~rschupp/PAR-Packer-1.019/lib/pp.pm&#34;&gt;PAR::Packer&lt;/a&gt; to run on Windows computers that have neither Perl nor Cygwin.)&lt;/p&gt; &#xA;&lt;p&gt;In addition to counting code in individual text files, directories, and git repositories, cloc can also count code in archive files such as &lt;code&gt;.tar&lt;/code&gt; (including compressed versions), &lt;code&gt;.zip&lt;/code&gt;, Python wheel &lt;code&gt;.whl&lt;/code&gt;, Jupyter notebook &lt;code&gt;.ipynb&lt;/code&gt;, source RPMs &lt;code&gt;.rpm&lt;/code&gt; or &lt;code&gt;.src&lt;/code&gt; (requires &lt;code&gt;rpm2cpio&lt;/code&gt;), and Debian &lt;code&gt;.deb&lt;/code&gt; files (requires &lt;code&gt;dpkg-deb&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;cloc contains code from David Wheeler&#39;s &lt;a href=&#34;http://www.dwheeler.com/sloccount/&#34;&gt;SLOCCount&lt;/a&gt;, Damian Conway and Abigail&#39;s Perl module &lt;a href=&#34;http://search.cpan.org/%7Eabigail/Regexp-Common-2.120/lib/Regexp/Common.pm&#34;&gt;Regexp::Common&lt;/a&gt;, Sean M. Burke&#39;s Perl module &lt;a href=&#34;http://search.cpan.org/%7Esburke/Win32-Autoglob-1.01/Autoglob.pm&#34;&gt;Win32::Autoglob&lt;/a&gt;, and Tye McQueen&#39;s Perl module &lt;a href=&#34;http://search.cpan.org/%7Etyemq/Algorithm-Diff-1.1902/lib/Algorithm/Diff.pm&#34;&gt;Algorithm::Diff&lt;/a&gt;. Language scale factors were derived from Mayes Consulting, LLC web site &lt;a href=&#34;http://softwareestimator.com/IndustryData2.htm&#34;&gt;http://softwareestimator.com/IndustryData2.htm&lt;/a&gt;. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;Docker&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Run via docker&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run --rm -v $PWD:/tmp aldanial/cloc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Install via package manager&lt;/h2&gt; &#xA;&lt;p&gt;Depending your operating system, one of these installation methods may work for you (all but the last two entries for Windows require a Perl interpreter):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm install -g cloc              # https://www.npmjs.com/package/cloc&#xA;sudo apt install cloc            # Debian, Ubuntu&#xA;sudo yum install cloc            # Red Hat, Fedora&#xA;sudo dnf install cloc            # Fedora 22 or later&#xA;sudo pacman -S cloc              # Arch&#xA;sudo emerge -av dev-util/cloc    # Gentoo https://packages.gentoo.org/packages/dev-util/cloc&#xA;sudo apk add cloc                # Alpine Linux&#xA;doas pkg_add cloc                # OpenBSD&#xA;sudo pkg install cloc            # FreeBSD&#xA;sudo port install cloc           # macOS with MacPorts&#xA;brew install cloc                # macOS with Homebrew&#xA;choco install cloc               # Windows with Chocolatey&#xA;scoop install cloc               # Windows with Scoop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: I don&#39;t control any of these packages. If you encounter a bug in cloc using one of the above packages, try with cloc pulled from the latest stable release here on GitHub (link follows below) before submitting a problem report. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;Stable&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Stable release&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/AlDanial/cloc/releases/latest&#34;&gt;https://github.com/AlDanial/cloc/releases/latest&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;Dev&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Development version&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/AlDanial/cloc/raw/master/cloc&#34;&gt;https://github.com/AlDanial/cloc/raw/master/cloc&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;License ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;cloc is licensed under the &lt;a href=&#34;http://www.gnu.org/licenses/gpl-2.0.html&#34;&gt;GNU General Public License, v 2&lt;/a&gt;, excluding portions which are copied from other sources. Code copied from the Regexp::Common, Win32::Autoglob, and Algorithm::Diff Perl modules is subject to the &lt;a href=&#34;http://www.opensource.org/licenses/artistic-license-2.0.php&#34;&gt;Artistic License&lt;/a&gt;. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;why_use&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Why Use cloc? ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;cloc has many features that make it easy to use, thorough, extensible, and portable:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Exists as a single, self-contained file that requires minimal installation effort---just download the file and run it.&lt;/li&gt; &#xA; &lt;li&gt;Can read language comment definitions from a file and thus potentially work with computer languages that do not yet exist.&lt;/li&gt; &#xA; &lt;li&gt;Allows results from multiple runs to be summed together by language and by project.&lt;/li&gt; &#xA; &lt;li&gt;Can produce results in a variety of formats: plain text, SQL, JSON, XML, YAML, comma separated values.&lt;/li&gt; &#xA; &lt;li&gt;Can count code within compressed archives (tar balls, Zip files, Java .ear files).&lt;/li&gt; &#xA; &lt;li&gt;Has numerous troubleshooting options.&lt;/li&gt; &#xA; &lt;li&gt;Handles file and directory names with spaces and other unusual characters.&lt;/li&gt; &#xA; &lt;li&gt;Has no dependencies outside the standard Perl distribution.&lt;/li&gt; &#xA; &lt;li&gt;Runs on Linux, FreeBSD, NetBSD, OpenBSD, macOS, AIX, HP-UX, Solaris, IRIX, and z/OS systems that have Perl 5.6 or higher. The source version runs on Windows with either ActiveState Perl, Strawberry Perl, Cygwin, or MobaXTerm+Perl plugin. Alternatively on Windows one can run the Windows binary which has no dependencies. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a name=&#34;Other_Counters&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Other Counters ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;If cloc does not suit your needs here are other freely available counters to consider:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cgag/loc/&#34;&gt;loc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/JoaoDanielRufino/gcloc&#34;&gt;gcloc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hhatto/gocloc/&#34;&gt;gocloc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/blackducksoftware/ohcount/&#34;&gt;Ohcount&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/boyter/scc/&#34;&gt;scc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://code.google.com/archive/p/sclc/&#34;&gt;sclc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.dwheeler.com/sloccount/&#34;&gt;SLOCCount&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.sonarsource.org/&#34;&gt;Sonar&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Aaronepower/tokei/&#34;&gt;tokei&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://csse.usc.edu/ucc_new/wordpress/&#34;&gt;Unified Code Count&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Other references:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;QSM&#39;s &lt;a href=&#34;http://www.qsm.com/CodeCounters.html&#34;&gt;directory&lt;/a&gt; of code counting tools.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;http://en.wikipedia.org/wiki/Source_lines_of_code&#34;&gt;Wikipedia entry&lt;/a&gt; for source code line counts. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;&lt;a name=&#34;regexp_common&#34;&gt;Regexp::Common, Digest::MD5, Win32::Autoglob, Algorithm::Diff&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Although cloc does not need Perl modules outside those found in the standard distribution, cloc does rely on a few external modules. Code from three of these external modules--Regexp::Common, Win32::Autoglob, and Algorithm::Diff--is embedded within cloc. A fourth module, Digest::MD5, is used only if it is available. If cloc finds Regexp::Common or Algorithm::Diff installed locally it will use those installation. If it doesn&#39;t, cloc will install the parts of Regexp::Common and/or Algorithm:Diff it needs to temporary directories that are created at the start of a cloc run then removed when the run is complete. The necessary code from Regexp::Common v2.120 and Algorithm::Diff v1.1902 are embedded within the cloc source code (see subroutines &lt;code&gt;Install_Regexp_Common()&lt;/code&gt; and &lt;code&gt;Install_Algorithm_Diff()&lt;/code&gt; ). Only three lines are needed from Win32::Autoglob and these are included directly in cloc.&lt;/p&gt; &#xA;&lt;p&gt;Additionally, cloc will use Digest::MD5 to validate uniqueness among equally-sized input files if Digest::MD5 is installed locally.&lt;/p&gt; &#xA;&lt;p&gt;A parallel processing option, &lt;tt&gt;--processes=&lt;i&gt;N&lt;/i&gt;&lt;/tt&gt;, was introduced with cloc version 1.76 to enable faster runs on multi-core machines. However, to use it, one must have the module Parallel::ForkManager installed. This module does not work reliably on Windows so parallel processing will only work on Unix-like operating systems.&lt;/p&gt; &#xA;&lt;p&gt;The Windows binary is built on a computer that has both Regexp::Common and Digest::MD5 installed locally. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;building_exe&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Building a Windows Executable ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;The Windows downloads &lt;tt&gt;cloc-1.92.exe&lt;/tt&gt;, &lt;tt&gt;cloc-1.90.exe&lt;/tt&gt; and &lt;tt&gt;cloc-1.88.exe&lt;/tt&gt; were built on a 64 bit Windows 10 computer using &lt;a href=&#34;http://strawberryperl.com/&#34;&gt;Strawberry Perl&lt;/a&gt; 5.30.2 and &lt;a href=&#34;http://search.cpan.org/~rschupp/PAR-Packer-1.050/lib/pp.pm&#34;&gt;PAR::Packer&lt;/a&gt; to build the &lt;code&gt;.exe&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Release 1.86 was built on a 64 bit Windows 10 virtual machine downloaded from &lt;a href=&#34;https://developer.microsoft.com/en-us/microsoft-edge/tools/vms/&#34;&gt;https://developer.microsoft.com/en-us/microsoft-edge/tools/vms/&lt;/a&gt;; releases 1.74 through 1.84 were was built on a 32 bit Windows 7 virtual machine using Strawberry Perl 5.26.1.1, while 1.70 and 1.72 were built with Strawberry Perl 5.24.0.1 on an Amazon Web Services t2.micro instance running Microsoft Windows Server 2008 (32 bit for 1.70 and 1.72; 64 bit for 1.74). Release 1.66 was built on a 32 bit Windows 7 VirtualBox image. Windows executables of cloc versions 1.60 and earlier were built with &lt;a href=&#34;http://www.indigostar.com/perl2exe/&#34;&gt;perl2exe&lt;/a&gt; on a 32 bit Windows XP computer. A small modification was made to the cloc source code before passing it to perl2exe; lines 87 and 88 were uncommented:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&lt;font color=&#34;gray&#34;&gt;85&lt;/font&gt;  # Uncomment next two lines when building Windows executable with perl2exe&#xA;&lt;font color=&#34;gray&#34;&gt;86&lt;/font&gt;  # or if running on a system that already has Regexp::Common.&#xA;&lt;font color=&#34;gray&#34;&gt;87&lt;/font&gt;  &lt;font color=&#34;red&#34;&gt;#use Regexp::Common;&lt;/font&gt;&#xA;&lt;font color=&#34;gray&#34;&gt;88&lt;/font&gt;  &lt;font color=&#34;red&#34;&gt;#$HAVE_Rexexp_Common = 1;&lt;/font&gt;&#xA;&lt;/pre&gt; &#xA;&lt;h4&gt;Is the Windows executable safe to run? Does it have malware?&lt;/h4&gt; &#xA;&lt;p&gt;Ideally, no one would need the Windows executable because they have a Perl interpreter installed on their machines and can run the cloc source file. On centrally-managed corporate Windows machines, however, this this may be difficult or impossible.&lt;/p&gt; &#xA;&lt;p&gt;The Windows executable distributed with cloc is provided as a best-effort of a virus and malware-free &lt;code&gt;.exe&lt;/code&gt;. You are encouraged to run your own virus scanners against the executable and also check sites such &lt;a href=&#34;https://www.virustotal.com/&#34;&gt;https://www.virustotal.com/&lt;/a&gt; . The entries for recent versions are:&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.92.exe: &lt;a href=&#34;https://www.virustotal.com/gui/file/2668fcf8609c431e8934fe9e1866bc620c58d198c4eb262f1d3ef31ef4a690f7&#34;&gt;https://www.virustotal.com/gui/file/2668fcf8609c431e8934fe9e1866bc620c58d198c4eb262f1d3ef31ef4a690f7&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.90.exe: &lt;a href=&#34;https://www.virustotal.com/gui/file/d655caae55486f9bac39f7e3c7b7553bcfcfe2b88914c79bfc328055f22b8a37/detection&#34;&gt;https://www.virustotal.com/gui/file/d655caae55486f9bac39f7e3c7b7553bcfcfe2b88914c79bfc328055f22b8a37/detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.88.exe: &lt;a href=&#34;https://www.virustotal.com/gui/file/97d5d2631d1cccdbfd99267ab8a4cf5968816bbe52c0f9324e72e768857f642d/detection&#34;&gt;https://www.virustotal.com/gui/file/97d5d2631d1cccdbfd99267ab8a4cf5968816bbe52c0f9324e72e768857f642d/detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.86.exe: &lt;a href=&#34;https://www.virustotal.com/gui/file/1b2e189df1834411b34534db446330d1c379b4bc008af3042ee9ade818c6a1c8/detection&#34;&gt;https://www.virustotal.com/gui/file/1b2e189df1834411b34534db446330d1c379b4bc008af3042ee9ade818c6a1c8/detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.84.exe: &lt;a href=&#34;https://www.virustotal.com/gui/file/e73d490c1e4ae2f50ee174005614029b4fa2610dcb76988714839d7be68479af/detection&#34;&gt;https://www.virustotal.com/gui/file/e73d490c1e4ae2f50ee174005614029b4fa2610dcb76988714839d7be68479af/detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.82.exe: &lt;a href=&#34;https://www.virustotal.com/#/file/2e5fb443fdefd776d7b6b136a25e5ee2048991e735042897dbd0bf92efb16563/detection&#34;&gt;https://www.virustotal.com/#/file/2e5fb443fdefd776d7b6b136a25e5ee2048991e735042897dbd0bf92efb16563/detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.80.exe: &lt;a href=&#34;https://www.virustotal.com/#/file/9e547b01c946aa818ffad43b9ebaf05d3da08ed6ca876ef2b6847be3bf1cf8be/detection&#34;&gt;https://www.virustotal.com/#/file/9e547b01c946aa818ffad43b9ebaf05d3da08ed6ca876ef2b6847be3bf1cf8be/detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.78.exe: &lt;a href=&#34;https://www.virustotal.com/#/file/256ade3df82fa92febf2553853ed1106d96c604794606e86efd00d55664dd44f/detection&#34;&gt;https://www.virustotal.com/#/file/256ade3df82fa92febf2553853ed1106d96c604794606e86efd00d55664dd44f/detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.76.exe: &lt;a href=&#34;https://www.virustotal.com/#/url/c1b9b9fe909f91429f95d41e9a9928ab7c58b21351b3acd4249def2a61acd39d/detection&#34;&gt;https://www.virustotal.com/#/url/c1b9b9fe909f91429f95d41e9a9928ab7c58b21351b3acd4249def2a61acd39d/detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc-1.74_x86.exe: &lt;a href=&#34;https://www.virustotal.com/#/file/b73dece71f6d3199d90d55db53a588e1393c8dbf84231a7e1be2ce3c5a0ec75b/detection&#34;&gt;https://www.virustotal.com/#/file/b73dece71f6d3199d90d55db53a588e1393c8dbf84231a7e1be2ce3c5a0ec75b/detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc 1.72 exe: &lt;a href=&#34;https://www.virustotal.com/en/url/8fd2af5cd972f648d7a2d7917bc202492012484c3a6f0b48c8fd60a8d395c98c/analysis/&#34;&gt;https://www.virustotal.com/en/url/8fd2af5cd972f648d7a2d7917bc202492012484c3a6f0b48c8fd60a8d395c98c/analysis/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc 1.70 exe: &lt;a href=&#34;https://www.virustotal.com/en/url/63edef209099a93aa0be1a220dc7c4c7ed045064d801e6d5daa84ee624fc0b4a/analysis/&#34;&gt;https://www.virustotal.com/en/url/63edef209099a93aa0be1a220dc7c4c7ed045064d801e6d5daa84ee624fc0b4a/analysis/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc 1.68 exe: &lt;a href=&#34;https://www.virustotal.com/en/file/c484fc58615fc3b0d5569b9063ec1532980281c3155e4a19099b11ef1c24443b/analysis/&#34;&gt;https://www.virustotal.com/en/file/c484fc58615fc3b0d5569b9063ec1532980281c3155e4a19099b11ef1c24443b/analysis/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;cloc 1.66 exe: &lt;a href=&#34;https://www.virustotal.com/en/file/54d6662e59b04be793dd10fa5e5edf7747cf0c0cc32f71eb67a3cf8e7a171d81/analysis/1453601367/&#34;&gt;https://www.virustotal.com/en/file/54d6662e59b04be793dd10fa5e5edf7747cf0c0cc32f71eb67a3cf8e7a171d81/analysis/1453601367/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Why is the Windows executable so large?&lt;/h4&gt; &#xA;&lt;p&gt;Windows executables of cloc versions 1.60 and earlier, created with perl2exe as noted above, are about 1.6 MB, while versions 1.62 and 1.54, created with &lt;code&gt;PAR::Packer&lt;/code&gt;, are 11 MB. Version 1.66, built with a newer version of &lt;code&gt;PAR::Packer&lt;/code&gt;, is about 5.5 MB. Why are the &lt;code&gt;PAR::Packer&lt;/code&gt;, executables so much larger than those built with perl2exe? My theory is that perl2exe uses smarter tree pruning logic than &lt;code&gt;PAR::Packer&lt;/code&gt;, but that&#39;s pure speculation.&lt;/p&gt; &#xA;&lt;h4&gt;Create your own executable&lt;/h4&gt; &#xA;&lt;p&gt;The most robust option for creating a Windows executable of cloc is to use &lt;a href=&#34;http://www.activestate.com/perl-dev-kit&#34;&gt;ActiveState&#39;s Perl Development Kit&lt;/a&gt;. It includes a utility, &lt;code&gt;perlapp&lt;/code&gt;, which can build stand-alone Windows, Mac, and Linux binaries of Perl source code.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.indigostar.com/perl2exe/&#34;&gt;perl2exe&lt;/a&gt; will also do the trick. If you do have &lt;code&gt;perl2exe&lt;/code&gt;, modify lines 84-87 in the cloc source code for a minor code modification that is necessary to make a cloc Windows executable.&lt;/p&gt; &#xA;&lt;p&gt;Otherwise, to build a Windows executable with &lt;code&gt;pp&lt;/code&gt; from &lt;code&gt;PAR::Packer&lt;/code&gt;, first install a Windows-based Perl distribution (for example Strawberry Perl or ActivePerl) following their instructions. Next, open a command prompt, aka a DOS window and install the PAR::Packer module. Finally, invoke the newly installed &lt;code&gt;pp&lt;/code&gt; command with the cloc source code to create an &lt;code&gt;.exe&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;C:&amp;gt; cpan -i Digest::MD5&#xA;C:&amp;gt; cpan -i Regexp::Common&#xA;C:&amp;gt; cpan -i Algorithm::Diff&#xA;C:&amp;gt; cpan -i PAR::Packer&#xA;C:&amp;gt; pp -M Digest::MD5 -c -x -o cloc-1.92.exe cloc-1.92.pl&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;A variation on the instructions above is if you installed the portable version of Strawberry Perl, you will need to run &lt;code&gt;portableshell.bat&lt;/code&gt; first to properly set up your environment.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;Basic_Use&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Basic Use ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;cloc is a command line program that takes file, directory, and/or archive names as inputs. Here&#39;s an example of running cloc against the Perl v5.22.0 source distribution:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; cloc perl-5.22.0.tar.gz&#xA;    5605 text files.&#xA;    5386 unique files.&#xA;    2176 files ignored.&#xA;&#xA;https://github.com/AlDanial/cloc v 1.65  T=25.49 s (134.7 files/s, 51980.3 lines/s)&#xA;-----------------------------------------------------------------------------------&#xA;Language                         files          blank        comment           code&#xA;-----------------------------------------------------------------------------------&#xA;Perl                              2892         136396         184362         536445&#xA;C                                  130          24676          33684         155648&#xA;C/C++ Header                       148           9766          16569         147858&#xA;Bourne Shell                       112           4044           6796          42668&#xA;Pascal                               8            458           1603           8592&#xA;XML                                 33            142              0           2410&#xA;YAML                                49             20             15           2078&#xA;C++                                 10            313            277           2033&#xA;make                                 4            426            488           1986&#xA;Prolog                              12            438              2           1146&#xA;JSON                                14              1              0           1037&#xA;yacc                                 1             85             76            998&#xA;Windows Message File                 1            102             11            489&#xA;DOS Batch                           14             92             41            389&#xA;Windows Resource File                3             10              0             85&#xA;D                                    1              5              7              8&#xA;Lisp                                 2              0              3              4&#xA;-----------------------------------------------------------------------------------&#xA;SUM:                              3434         176974         243934         903874&#xA;-----------------------------------------------------------------------------------&#xA;&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;To run cloc on Windows computers, open up a command (aka DOS) window and invoke cloc.exe from the command line there. Alternatively, try ClocViewer, the GUI wrapper around cloc found at &lt;a href=&#34;https://github.com/Roemer/ClocViewer&#34;&gt;https://github.com/Roemer/ClocViewer&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See also &lt;a href=&#34;https://github.com/jmensch1/codeflower&#34;&gt;https://github.com/jmensch1/codeflower&lt;/a&gt; for a graphical rendering of cloc results. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;Options&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Options ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; cloc --help&#xA;&#xA;Usage: cloc [options] &amp;lt;file(s)/dir(s)/git hash(es)&amp;gt; | &amp;lt;set 1&amp;gt; &amp;lt;set 2&amp;gt; | &amp;lt;report files&amp;gt;&#xA;&#xA; Count, or compute differences of, physical lines of source code in the&#xA; given files (may be archives such as compressed tarballs or zip files,&#xA; or git commit hashes or branch names) and/or recursively below the&#xA; given directories.&#xA;&#xA; Input Options&#xA;   --extract-with=&amp;lt;cmd&amp;gt;      This option is only needed if cloc is unable&#xA;                             to figure out how to extract the contents of&#xA;                             the input file(s) by itself.&#xA;                             Use &amp;lt;cmd&amp;gt; to extract binary archive files (e.g.:&#xA;                             .tar.gz, .zip, .Z).  Use the literal &#39;&amp;gt;FILE&amp;lt;&#39; as&#xA;                             a stand-in for the actual file(s) to be&#xA;                             extracted.  For example, to count lines of code&#xA;                             in the input files&#xA;                                gcc-4.2.tar.gz  perl-5.8.8.tar.gz&#xA;                             on Unix use&#xA;                               --extract-with=&#39;gzip -dc &amp;gt;FILE&amp;lt; | tar xf -&#39;&#xA;                             or, if you have GNU tar,&#xA;                               --extract-with=&#39;tar zxf &amp;gt;FILE&amp;lt;&#39;&#xA;                             and on Windows use, for example:&#xA;                               --extract-with=&#34;\&#34;c:\Program Files\WinZip\WinZip32.exe\&#34; -e -o &amp;gt;FILE&amp;lt; .&#34;&#xA;                             (if WinZip is installed there).&#xA;   --list-file=&amp;lt;file&amp;gt;        Take the list of file and/or directory names to&#xA;                             process from &amp;lt;file&amp;gt;, which has one file/directory&#xA;                             name per line.  Only exact matches are counted;&#xA;                             relative path names will be resolved starting from&#xA;                             the directory where cloc is invoked.  Set &amp;lt;file&amp;gt;&#xA;                             to - to read file names from a STDIN pipe.&#xA;                             See also --exclude-list-file.&#xA;   --diff-list-file=&amp;lt;file&amp;gt;   Take the pairs of file names to be diff&#39;ed from&#xA;                             &amp;lt;file&amp;gt;, whose format matches the output of&#xA;                             --diff-alignment.  (Run with that option to&#xA;                             see a sample.)  The language identifier at the&#xA;                             end of each line is ignored.  This enables --diff&#xA;                             mode and bypasses file pair alignment logic.&#xA;   --vcs=&amp;lt;VCS&amp;gt;               Invoke a system call to &amp;lt;VCS&amp;gt; to obtain a list of&#xA;                             files to work on.  If &amp;lt;VCS&amp;gt; is &#39;git&#39;, then will&#xA;                             invoke &#39;git ls-files&#39; to get a file list and&#xA;                             &#39;git submodule status&#39; to get a list of submodules&#xA;                             whose contents will be ignored.  See also --git&#xA;                             which accepts git commit hashes and branch names.&#xA;                             If &amp;lt;VCS&amp;gt; is &#39;svn&#39; then will invoke &#39;svn list -R&#39;.&#xA;                             The primary benefit is that cloc will then skip&#xA;                             files explicitly excluded by the versioning tool&#xA;                             in question, ie, those in .gitignore or have the&#xA;                             svn:ignore property.&#xA;                             Alternatively &amp;lt;VCS&amp;gt; may be any system command&#xA;                             that generates a list of files.&#xA;                             Note:  cloc must be in a directory which can read&#xA;                             the files as they are returned by &amp;lt;VCS&amp;gt;.  cloc will&#xA;                             not download files from remote repositories.&#xA;                             &#39;svn list -R&#39; may refer to a remote repository&#xA;                             to obtain file names (and therefore may require&#xA;                             authentication to the remote repository), but&#xA;                             the files themselves must be local.&#xA;                             Setting &amp;lt;VCS&amp;gt; to &#39;auto&#39; selects between &#39;git&#39;&#xA;                             and &#39;svn&#39; (or neither) depending on the presence&#xA;                             of a .git or .svn subdirectory below the directory&#xA;                             where cloc is invoked.&#xA;   --unicode                 Check binary files to see if they contain Unicode&#xA;                             expanded ASCII text.  This causes performance to&#xA;                             drop noticeably.&#xA;&#xA; Processing Options&#xA;   --autoconf                Count .in files (as processed by GNU autoconf) of&#xA;                             recognized languages.  See also --no-autogen.&#xA;   --by-file                 Report results for every source file encountered.&#xA;   --by-file-by-lang         Report results for every source file encountered&#xA;                             in addition to reporting by language.&#xA;   --config &amp;lt;file&amp;gt;           Read command line switches from &amp;lt;file&amp;gt; instead of&#xA;                             the default location of /home/al/.config/cloc/options.txt.&#xA;                             The file should contain one switch, along with&#xA;                             arguments (if any), per line.  Blank lines and lines&#xA;                             beginning with &#39;#&#39; are skipped.  Options given on&#xA;                             the command line take priority over entries read from&#xA;                             the file.&#xA;   --count-and-diff &amp;lt;set1&amp;gt; &amp;lt;set2&amp;gt;&#xA;                             First perform direct code counts of source file(s)&#xA;                             of &amp;lt;set1&amp;gt; and &amp;lt;set2&amp;gt; separately, then perform a diff&#xA;                             of these.  Inputs may be pairs of files, directories,&#xA;                             or archives.  If --out or --report-file is given,&#xA;                             three output files will be created, one for each&#xA;                             of the two counts and one for the diff.  See also&#xA;                             --diff, --diff-alignment, --diff-timeout,&#xA;                             --ignore-case, --ignore-whitespace.&#xA;   --diff &amp;lt;set1&amp;gt; &amp;lt;set2&amp;gt;      Compute differences in code and comments between&#xA;                             source file(s) of &amp;lt;set1&amp;gt; and &amp;lt;set2&amp;gt;.  The inputs&#xA;                             may be any mix of files, directories, archives,&#xA;                             or git commit hashes.  Use --diff-alignment to&#xA;                             generate a list showing which file pairs where&#xA;                             compared.  When comparing git branches, only files&#xA;                             which have changed in either commit are compared.&#xA;                             See also --git, --count-and-diff, --diff-alignment,&#xA;                             --diff-list-file, --diff-timeout, --ignore-case,&#xA;                             --ignore-whitespace.&#xA;   --diff-timeout &amp;lt;N&amp;gt;        Ignore files which take more than &amp;lt;N&amp;gt; seconds&#xA;                             to process.  Default is 10 seconds.  Setting &amp;lt;N&amp;gt;&#xA;                             to 0 allows unlimited time.  (Large files with many&#xA;                             repeated lines can cause Algorithm::Diff::sdiff()&#xA;                             to take hours.) See also --timeout.&#xA;   --docstring-as-code       cloc considers docstrings to be comments, but this is&#xA;                             not always correct as docstrings represent regular&#xA;                             strings when they appear on the right hand side of an&#xA;                             assignment or as function arguments.  This switch&#xA;                             forces docstrings to be counted as code.&#xA;   --follow-links            [Unix only] Follow symbolic links to directories&#xA;                             (sym links to files are always followed).&#xA;                             See also --stat.&#xA;   --force-lang=&amp;lt;lang&amp;gt;[,&amp;lt;ext&amp;gt;]&#xA;                             Process all files that have a &amp;lt;ext&amp;gt; extension&#xA;                             with the counter for language &amp;lt;lang&amp;gt;.  For&#xA;                             example, to count all .f files with the&#xA;                             Fortran 90 counter (which expects files to&#xA;                             end with .f90) instead of the default Fortran 77&#xA;                             counter, use&#xA;                               --force-lang=&#34;Fortran 90&#34;,f&#xA;                             If &amp;lt;ext&amp;gt; is omitted, every file will be counted&#xA;                             with the &amp;lt;lang&amp;gt; counter.  This option can be&#xA;                             specified multiple times (but that is only&#xA;                             useful when &amp;lt;ext&amp;gt; is given each time).&#xA;                             See also --script-lang, --lang-no-ext.&#xA;   --force-lang-def=&amp;lt;file&amp;gt;   Load language processing filters from &amp;lt;file&amp;gt;,&#xA;                             then use these filters instead of the built-in&#xA;                             filters.  Note:  languages which map to the same&#xA;                             file extension (for example:&#xA;                             MATLAB/Mathematica/Objective-C/MUMPS/Mercury;&#xA;                             Pascal/PHP; Lisp/OpenCL; Lisp/Julia; Perl/Prolog)&#xA;                             will be ignored as these require additional&#xA;                             processing that is not expressed in language&#xA;                             definition files.  Use --read-lang-def to define&#xA;                             new language filters without replacing built-in&#xA;                             filters (see also --write-lang-def,&#xA;                             --write-lang-def-incl-dup).&#xA;   --git                     Forces the inputs to be interpreted as git targets&#xA;                             (commit hashes, branch names, et cetera) if these&#xA;                             are not first identified as file or directory&#xA;                             names.  This option overrides the --vcs=git logic&#xA;                             if this is given; in other words, --git gets its&#xA;                             list of files to work on directly from git using&#xA;                             the hash or branch name rather than from&#xA;                             &#39;git ls-files&#39;.  This option can be used with&#xA;                             --diff to perform line count diffs between git&#xA;                             commits, or between a git commit and a file,&#xA;                             directory, or archive.  Use -v/--verbose to see&#xA;                             the git system commands cloc issues.&#xA;   --git-diff-rel            Same as --git --diff, or just --diff if the inputs&#xA;                             are recognized as git targets.  Only files which&#xA;                             have changed in either commit are compared.&#xA;   --git-diff-all            Git diff strategy #2:  compare all files in the&#xA;                             repository between the two commits.&#xA;   --ignore-whitespace       Ignore horizontal white space when comparing files&#xA;                             with --diff.  See also --ignore-case.&#xA;   --ignore-case             Ignore changes in case within file contents;&#xA;                             consider upper- and lowercase letters equivalent&#xA;                             when comparing files with --diff.  See also&#xA;                             --ignore-whitespace.&#xA;   --ignore-case-ext         Ignore case of file name extensions.  This will&#xA;                             cause problems counting some languages&#xA;                             (specifically, .c and .C are associated with C and&#xA;                             C++; this switch would count .C files as C rather&#xA;                             than C++ on *nix operating systems).  File name&#xA;                             case insensitivity is always true on Windows.&#xA;   --lang-no-ext=&amp;lt;lang&amp;gt;      Count files without extensions using the &amp;lt;lang&amp;gt;&#xA;                             counter.  This option overrides internal logic&#xA;                             for files without extensions (where such files&#xA;                             are checked against known scripting languages&#xA;                             by examining the first line for #!).  See also&#xA;                             --force-lang, --script-lang.&#xA;   --max-file-size=&amp;lt;MB&amp;gt;      Skip files larger than &amp;lt;MB&amp;gt; megabytes when&#xA;                             traversing directories.  By default, &amp;lt;MB&amp;gt;=100.&#xA;                             cloc&#39;s memory requirement is roughly twenty times&#xA;                             larger than the largest file so running with&#xA;                             files larger than 100 MB on a computer with less&#xA;                             than 2 GB of memory will cause problems.&#xA;                             Note:  this check does not apply to files&#xA;                             explicitly passed as command line arguments.&#xA;   --no-autogen[=list]       Ignore files generated by code-production systems&#xA;                             such as GNU autoconf.  To see a list of these files&#xA;                             (then exit), run with --no-autogen list&#xA;                             See also --autoconf.&#xA;   --original-dir            [Only effective in combination with&#xA;                             --strip-comments]  Write the stripped files&#xA;                             to the same directory as the original files.&#xA;   --read-binary-files       Process binary files in addition to text files.&#xA;                             This is usually a bad idea and should only be&#xA;                             attempted with text files that have embedded&#xA;                             binary data.&#xA;   --read-lang-def=&amp;lt;file&amp;gt;    Load new language processing filters from &amp;lt;file&amp;gt;&#xA;                             and merge them with those already known to cloc.&#xA;                             If &amp;lt;file&amp;gt; defines a language cloc already knows&#xA;                             about, cloc&#39;s definition will take precedence.&#xA;                             Use --force-lang-def to over-ride cloc&#39;s&#xA;                             definitions (see also --write-lang-def,&#xA;                             --write-lang-def-incl-dup).&#xA;   --script-lang=&amp;lt;lang&amp;gt;,&amp;lt;s&amp;gt;  Process all files that invoke &amp;lt;s&amp;gt; as a #!&#xA;                             scripting language with the counter for language&#xA;                             &amp;lt;lang&amp;gt;.  For example, files that begin with&#xA;                                #!/usr/local/bin/perl5.8.8&#xA;                             will be counted with the Perl counter by using&#xA;                                --script-lang=Perl,perl5.8.8&#xA;                             The language name is case insensitive but the&#xA;                             name of the script language executable, &amp;lt;s&amp;gt;,&#xA;                             must have the right case.  This option can be&#xA;                             specified multiple times.  See also --force-lang,&#xA;                             --lang-no-ext.&#xA;   --sdir=&amp;lt;dir&amp;gt;              Use &amp;lt;dir&amp;gt; as the scratch directory instead of&#xA;                             letting File::Temp chose the location.  Files&#xA;                             written to this location are not removed at&#xA;                             the end of the run (as they are with File::Temp).&#xA;   --skip-uniqueness         Skip the file uniqueness check.  This will give&#xA;                             a performance boost at the expense of counting&#xA;                             files with identical contents multiple times&#xA;                             (if such duplicates exist).&#xA;   --stat                    Some file systems (AFS, CD-ROM, FAT, HPFS, SMB)&#xA;                             do not have directory &#39;nlink&#39; counts that match&#xA;                             the number of its subdirectories.  Consequently&#xA;                             cloc may undercount or completely skip the&#xA;                             contents of such file systems.  This switch forces&#xA;                             File::Find to stat directories to obtain the&#xA;                             correct count.  File search speed will decrease.&#xA;                             See also --follow-links.&#xA;   --stdin-name=&amp;lt;file&amp;gt;       Give a file name to use to determine the language&#xA;                             for standard input.  (Use - as the input name to&#xA;                             receive source code via STDIN.)&#xA;   --strip-comments=&amp;lt;ext&amp;gt;    For each file processed, write to the current&#xA;                             directory a version of the file which has blank&#xA;                             and commented lines removed (in-line comments&#xA;                             persist).  The name of each stripped file is the&#xA;                             original file name with .&amp;lt;ext&amp;gt; appended to it.&#xA;                             It is written to the current directory unless&#xA;                             --original-dir is on.&#xA;   --strip-str-comments      Replace comment markers embedded in strings with&#xA;                             &#39;xx&#39;.  This attempts to work around a limitation&#xA;                             in Regexp::Common::Comment where comment markers&#xA;                             embedded in strings are seen as actual comment&#xA;                             markers and not strings, often resulting in a&#xA;                             &#39;Complex regular subexpression recursion limit&#39;&#xA;                             warning and incorrect counts.  There are two&#xA;                             disadvantages to using this switch:  1/code count&#xA;                             performance drops, and 2/code generated with&#xA;                             --strip-comments will contain different strings&#xA;                             where ever embedded comments are found.&#xA;   --sum-reports             Input arguments are report files previously&#xA;                             created with the --report-file option in plain&#xA;                             format (eg. not JSON, YAML, XML, or SQL).&#xA;                             Makes a cumulative set of results containing the&#xA;                             sum of data from the individual report files.&#xA;   --timeout &amp;lt;N&amp;gt;             Ignore files which take more than &amp;lt;N&amp;gt; seconds&#xA;                             to process at any of the language&#39;s filter stages.&#xA;                             The default maximum number of seconds spent on a&#xA;                             filter stage is the number of lines in the file&#xA;                             divided by one thousand.  Setting &amp;lt;N&amp;gt; to 0 allows&#xA;                             unlimited time.  See also --diff-timeout.&#xA;   --processes=NUM           [Available only on systems with a recent version&#xA;                             of the Parallel::ForkManager module.  Not&#xA;                             available on Windows.] Sets the maximum number of&#xA;                             cores that cloc uses.  The default value of 0&#xA;                             disables multiprocessing.&#xA;   --unix                    Override the operating system autodetection&#xA;                             logic and run in UNIX mode.  See also&#xA;                             --windows, --show-os.&#xA;   --use-sloccount           If SLOCCount is installed, use its compiled&#xA;                             executables c_count, java_count, pascal_count,&#xA;                             php_count, and xml_count instead of cloc&#39;s&#xA;                             counters.  SLOCCount&#39;s compiled counters are&#xA;                             substantially faster than cloc&#39;s and may give&#xA;                             a performance improvement when counting projects&#xA;                             with large files.  However, these cloc-specific&#xA;                             features will not be available: --diff,&#xA;                             --count-and-diff, --strip-comments, --unicode.&#xA;   --windows                 Override the operating system autodetection&#xA;                             logic and run in Microsoft Windows mode.&#xA;                             See also --unix, --show-os.&#xA;&#xA; Filter Options&#xA;   --exclude-content=&amp;lt;regex&amp;gt; Exclude files containing text that matches the given&#xA;                             regular expression.&#xA;   --exclude-dir=&amp;lt;D1&amp;gt;[,D2,]  Exclude the given comma separated directories&#xA;                             D1, D2, D3, et cetera, from being scanned.  For&#xA;                             example  --exclude-dir=.cache,test  will skip&#xA;                             all files and subdirectories that have /.cache/&#xA;                             or /test/ as their parent directory.&#xA;                             Directories named .bzr, .cvs, .hg, .git, .svn,&#xA;                             and .snapshot are always excluded.&#xA;                             This option only works with individual directory&#xA;                             names so including file path separators is not&#xA;                             allowed.  Use --fullpath and --not-match-d=&amp;lt;regex&amp;gt;&#xA;                             to supply a regex matching multiple subdirectories.&#xA;   --exclude-ext=&amp;lt;ext1&amp;gt;[,&amp;lt;ext2&amp;gt;[...]]&#xA;                             Do not count files having the given file name&#xA;                             extensions.&#xA;   --exclude-lang=&amp;lt;L1&amp;gt;[,L2[...]]&#xA;                             Exclude the given comma separated languages&#xA;                             L1, L2, L3, et cetera, from being counted.&#xA;   --exclude-list-file=&amp;lt;file&amp;gt;  Ignore files and/or directories whose names&#xA;                             appear in &amp;lt;file&amp;gt;.  &amp;lt;file&amp;gt; should have one file&#xA;                             name per line.  Only exact matches are ignored;&#xA;                             relative path names will be resolved starting from&#xA;                             the directory where cloc is invoked.&#xA;                             See also --list-file.&#xA;   --fullpath                Modifies the behavior of --match-f, --not-match-f,&#xA;                             and --not-match-d to include the file&#39;s path&#xA;                             in the regex, not just the file&#39;s basename.&#xA;                             (This does not expand each file to include its&#xA;                             absolute path, instead it uses as much of&#xA;                             the path as is passed in to cloc.)&#xA;                             Note:  --match-d always looks at the full&#xA;                             path and therefore is unaffected by --fullpath.&#xA;   --include-ext=&amp;lt;ext1&amp;gt;[,ext2[...]]&#xA;                             Count only languages having the given comma&#xA;                             separated file extensions.  Use --show-ext to&#xA;                             see the recognized extensions.&#xA;   --include-lang=&amp;lt;L1&amp;gt;[,L2[...]]&#xA;                             Count only the given comma separated languages&#xA;                             L1, L2, L3, et cetera.  Use --show-lang to see&#xA;                             the list of recognized languages.&#xA;   --match-d=&amp;lt;regex&amp;gt;         Only count files in directories matching the Perl&#xA;                             regex.  For example&#xA;                               --match-d=&#39;/(src|include)/&#39;&#xA;                             only counts files in directories containing&#xA;                             /src/ or /include/.  Unlike --not-match-d,&#xA;                             --match-f, and --not-match-f, --match-d always&#xA;                             compares the fully qualified path against the&#xA;                             regex.&#xA;   --not-match-d=&amp;lt;regex&amp;gt;     Count all files except those in directories&#xA;                             matching the Perl regex.  Only the trailing&#xA;                             directory name is compared, for example, when&#xA;                             counting in /usr/local/lib, only &#39;lib&#39; is&#xA;                             compared to the regex.&#xA;                             Add --fullpath to compare parent directories to&#xA;                             the regex.&#xA;                             Do not include file path separators at the&#xA;                             beginning or end of the regex.&#xA;   --match-f=&amp;lt;regex&amp;gt;         Only count files whose basenames match the Perl&#xA;                             regex.  For example&#xA;                               --match-f=&#39;^[Ww]idget&#39;&#xA;                             only counts files that start with Widget or widget.&#xA;                             Add --fullpath to include parent directories&#xA;                             in the regex instead of just the basename.&#xA;   --not-match-f=&amp;lt;regex&amp;gt;     Count all files except those whose basenames&#xA;                             match the Perl regex.  Add --fullpath to include&#xA;                             parent directories in the regex instead of just&#xA;                             the basename.&#xA;   --skip-archive=&amp;lt;regex&amp;gt;    Ignore files that end with the given Perl regular&#xA;                             expression.  For example, if given&#xA;                               --skip-archive=&#39;(zip|tar(.(gz|Z|bz2|xz|7z))?)&#39;&#xA;                             the code will skip files that end with .zip,&#xA;                             .tar, .tar.gz, .tar.Z, .tar.bz2, .tar.xz, and&#xA;                             .tar.7z.&#xA;   --skip-win-hidden         On Windows, ignore hidden files.&#xA;&#xA; Debug Options&#xA;   --categorized=&amp;lt;file&amp;gt;      Save names of categorized files to &amp;lt;file&amp;gt;.&#xA;   --counted=&amp;lt;file&amp;gt;          Save names of processed source files to &amp;lt;file&amp;gt;.&#xA;   --diff-alignment=&amp;lt;file&amp;gt;   Write to &amp;lt;file&amp;gt; a list of files and file pairs&#xA;                             showing which files were added, removed, and/or&#xA;                             compared during a run with --diff.  This switch&#xA;                             forces the --diff mode on.&#xA;   --explain=&amp;lt;lang&amp;gt;          Print the filters used to remove comments for&#xA;                             language &amp;lt;lang&amp;gt; and exit.  In some cases the&#xA;                             filters refer to Perl subroutines rather than&#xA;                             regular expressions.  An examination of the&#xA;                             source code may be needed for further explanation.&#xA;   --help                    Print this usage information and exit.&#xA;   --found=&amp;lt;file&amp;gt;            Save names of every file found to &amp;lt;file&amp;gt;.&#xA;   --ignored=&amp;lt;file&amp;gt;          Save names of ignored files and the reason they&#xA;                             were ignored to &amp;lt;file&amp;gt;.&#xA;   --print-filter-stages     Print processed source code before and after&#xA;                             each filter is applied.&#xA;   --show-ext[=&amp;lt;ext&amp;gt;]        Print information about all known (or just the&#xA;                             given) file extensions and exit.&#xA;   --show-lang[=&amp;lt;lang&amp;gt;]      Print information about all known (or just the&#xA;                             given) languages and exit.&#xA;   --show-os                 Print the value of the operating system mode&#xA;                             and exit.  See also --unix, --windows.&#xA;   -v[=&amp;lt;n&amp;gt;]                  Verbose switch (optional numeric value).&#xA;   -verbose[=&amp;lt;n&amp;gt;]            Long form of -v.&#xA;   --version                 Print the version of this program and exit.&#xA;   --write-lang-def=&amp;lt;file&amp;gt;   Writes to &amp;lt;file&amp;gt; the language processing filters&#xA;                             then exits.  Useful as a first step to creating&#xA;                             custom language definitions. Note: languages which&#xA;                             map to the same file extension will be excluded.&#xA;                             (See also --force-lang-def, --read-lang-def).&#xA;   --write-lang-def-incl-dup=&amp;lt;file&amp;gt;&#xA;                             Same as --write-lang-def, but includes duplicated&#xA;                             extensions.  This generates a problematic language&#xA;                             definition file because cloc will refuse to use&#xA;                             it until duplicates are removed.&#xA;&#xA; Output Options&#xA;   --3                       Print third-generation language output.&#xA;                             (This option can cause report summation to fail&#xA;                             if some reports were produced with this option&#xA;                             while others were produced without it.)&#xA;   --by-percent  X           Instead of comment and blank line counts, show&#xA;                             these values as percentages based on the value&#xA;                             of X in the denominator:&#xA;                                X = &#39;c&#39;   -&amp;gt; # lines of code&#xA;                                X = &#39;cm&#39;  -&amp;gt; # lines of code + comments&#xA;                                X = &#39;cb&#39;  -&amp;gt; # lines of code + blanks&#xA;                                X = &#39;cmb&#39; -&amp;gt; # lines of code + comments + blanks&#xA;                             For example, if using method &#39;c&#39; and your code&#xA;                             has twice as many lines of comments as lines&#xA;                             of code, the value in the comment column will&#xA;                             be 200%.  The code column remains a line count.&#xA;   --csv                     Write the results as comma separated values.&#xA;   --csv-delimiter=&amp;lt;C&amp;gt;       Use the character &amp;lt;C&amp;gt; as the delimiter for comma&#xA;                             separated files instead of ,.  This switch forces --csv to be on.&#xA;   --file-encoding=&amp;lt;E&amp;gt;       Write output files using the &amp;lt;E&amp;gt; encoding instead of&#xA;                             the default ASCII (&amp;lt;E&amp;gt; = &#39;UTF-7&#39;).  Examples: &#39;UTF-16&#39;,&#xA;                             &#39;euc-kr&#39;, &#39;iso-8859-16&#39;.  Known encodings can be&#xA;                             printed with&#xA;                               perl -MEncode -e &#39;print join(&#34;\n&#34;, Encode-&amp;gt;encodings(&#34;:all&#34;)), &#34;\n&#34;&#39;&#xA;   --hide-rate               Do not show line and file processing rates in the&#xA;                             output header. This makes output deterministic.&#xA;   --json                    Write the results as JavaScript Object Notation&#xA;                             (JSON) formatted output.&#xA;   --md                      Write the results as Markdown-formatted text.&#xA;   --out=&amp;lt;file&amp;gt;              Synonym for --report-file=&amp;lt;file&amp;gt;.&#xA;   --progress-rate=&amp;lt;n&amp;gt;       Show progress update after every &amp;lt;n&amp;gt; files are&#xA;                             processed (default &amp;lt;n&amp;gt;=100).  Set &amp;lt;n&amp;gt; to 0 to&#xA;                             suppress progress output (useful when redirecting&#xA;                             output to STDOUT).&#xA;   --quiet                   Suppress all information messages except for&#xA;                             the final report.&#xA;   --report-file=&amp;lt;file&amp;gt;      Write the results to &amp;lt;file&amp;gt; instead of STDOUT.&#xA;   --sql=&amp;lt;file&amp;gt;              Write results as SQL create and insert statements&#xA;                             which can be read by a database program such as&#xA;                             SQLite.  If &amp;lt;file&amp;gt; is -, output is sent to STDOUT.&#xA;   --sql-append              Append SQL insert statements to the file specified&#xA;                             by --sql and do not generate table creation&#xA;                             statements.  Only valid with the --sql option.&#xA;   --sql-project=&amp;lt;name&amp;gt;      Use &amp;lt;name&amp;gt; as the project identifier for the&#xA;                             current run.  Only valid with the --sql option.&#xA;   --sql-style=&amp;lt;style&amp;gt;       Write SQL statements in the given style instead&#xA;                             of the default SQLite format.  Styles include&#xA;                             &#39;Oracle&#39; and &#39;Named_Columns&#39;.&#xA;   --sum-one                 For plain text reports, show the SUM: output line&#xA;                             even if only one input file is processed.&#xA;   --xml                     Write the results in XML.&#xA;   --xsl=&amp;lt;file&amp;gt;              Reference &amp;lt;file&amp;gt; as an XSL stylesheet within&#xA;                             the XML output.  If &amp;lt;file&amp;gt; is 1 (numeric one),&#xA;                             writes a default stylesheet, cloc.xsl (or&#xA;                             cloc-diff.xsl if --diff is also given).&#xA;                             This switch forces --xml on.&#xA;   --yaml                    Write the results in YAML.&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;Languages&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Recognized Languages ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; cloc --show-lang&#xA;&#xA;ABAP                       (abap)&#xA;ActionScript               (as)&#xA;Ada                        (ada, adb, ads, pad)&#xA;ADSO/IDSM                  (adso)&#xA;Agda                       (agda, lagda)&#xA;AMPLE                      (ample, dofile, startup)&#xA;Ant                        (build.xml, build.xml)&#xA;ANTLR Grammar              (g, g4)&#xA;Apex Class                 (cls)&#xA;Apex Trigger               (trigger)&#xA;APL                        (apl, apla, aplc, aplf, apli, apln, aplo, dyalog, dyapp, mipage)&#xA;Arduino Sketch             (ino, pde)&#xA;AsciiDoc                   (adoc, asciidoc)&#xA;ASP                        (asa, ashx, asp, axd)&#xA;ASP.NET                    (asax, ascx, asmx, aspx, master, sitemap, webinfo)&#xA;AspectJ                    (aj)&#xA;Assembly                   (a51, asm, nasm, S, s)&#xA;AutoHotkey                 (ahk, ahkl)&#xA;awk                        (auk, awk, gawk, mawk, nawk)&#xA;Bazel                      (BUILD)&#xA;BizTalk Orchestration      (odx)&#xA;BizTalk Pipeline           (btp)&#xA;Blade                      (blade, blade.php)&#xA;Bourne Again Shell         (bash)&#xA;Bourne Shell               (sh)&#xA;BrightScript               (brs)&#xA;builder                    (xml.builder)&#xA;C                          (c, cats, ec, idc, pgc)&#xA;C Shell                    (csh, tcsh)&#xA;C#                         (cs)&#xA;C# Designer                (designer.cs)&#xA;C++                        (C, c++, cc, CPP, cpp, cxx, h++, inl, ipp, pcc, tcc, tpp)&#xA;C/C++ Header               (H, h, hh, hpp, hxx)&#xA;Cake Build Script          (cake)&#xA;CCS                        (ccs)&#xA;Chapel                     (chpl)&#xA;Clean                      (dcl, icl)&#xA;Clojure                    (boot, cl2, clj, cljs.hl, cljscm, cljx, hic, riemann.config)&#xA;ClojureC                   (cljc)&#xA;ClojureScript              (cljs)&#xA;CMake                      (cmake, cmake.in, CMakeLists.txt)&#xA;COBOL                      (CBL, cbl, ccp, COB, cob, cobol, cpy)&#xA;CoffeeScript               (_coffee, cakefile, cjsx, coffee, iced)&#xA;ColdFusion                 (cfm, cfml)&#xA;ColdFusion CFScript        (cfc)&#xA;Coq                        (v)&#xA;Crystal                    (cr)&#xA;CSON                       (cson)&#xA;CSS                        (css)&#xA;CSV                        (csv)&#xA;Cucumber                   (feature)&#xA;CUDA                       (cu, cuh)&#xA;Cython                     (pxd, pxi, pyx)&#xA;D                          (d)&#xA;DAL                        (da)&#xA;Dart                       (dart)&#xA;Delphi Form                (dfm)&#xA;dhall                      (dhall)&#xA;DIET                       (dt)&#xA;diff                       (diff, patch)&#xA;DITA                       (dita)&#xA;Dockerfile                 (Dockerfile, dockerfile)&#xA;DOORS Extension Language   (dxl)&#xA;DOS Batch                  (BAT, bat, BTM, btm, CMD, cmd)&#xA;Drools                     (drl)&#xA;DTD                        (dtd)&#xA;dtrace                     (d)&#xA;ECPP                       (ecpp)&#xA;EEx                        (eex)&#xA;EJS                        (ejs)&#xA;Elixir                     (ex, exs)&#xA;Elm                        (elm)&#xA;Embedded Crystal           (ecr)&#xA;ERB                        (ERB, erb)&#xA;Erlang                     (app.src, emakefile, erl, hrl, rebar.config, rebar.config.lock, rebar.lock, xrl, yrl)&#xA;Expect                     (exp)&#xA;F#                         (fsi, fs, fs)&#xA;F# Script                  (fsx)&#xA;Fennel                     (fnl)&#xA;Fish Shell                 (fish)&#xA;Flatbuffers                (fbs)&#xA;Focus                      (focexec)&#xA;Forth                      (4th, e4, f83, fb, forth, fpm, fr, frt, ft, fth, rx, fs, f, for)&#xA;Fortran 77                 (F, F77, f77, FOR, FTN, ftn, pfo, f, for)&#xA;Fortran 90                 (F90, f90)&#xA;Fortran 95                 (F95, f95)&#xA;Freemarker Template        (ftl)&#xA;FXML                       (fxml)&#xA;GDScript                   (gd)&#xA;Gencat NLS                 (msg)&#xA;Glade                      (glade, ui)&#xA;Gleam                      (gleam)&#xA;GLSL                       (comp, fp, frag, frg, fsh, fshader, geo, geom, glsl, glslv, gshader, tesc, tese, vert, vrx, vsh, vshader)&#xA;Go                         (go)&#xA;Godot Resource             (tres)&#xA;Godot Scene                (tscn)&#xA;Gradle                     (gradle, gradle.kts)&#xA;Grails                     (gsp)&#xA;GraphQL                    (gql, graphql, graphqls)&#xA;Groovy                     (gant, groovy, grt, gtpl, gvy, jenkinsfile)&#xA;Haml                       (haml, haml.deface)&#xA;Handlebars                 (handlebars, hbs)&#xA;Harbour                    (hb)&#xA;Haskell                    (hs, hsc, lhs)&#xA;Haxe                       (hx, hxsl)&#xA;HCL                        (hcl, nomad, tf, tfvars)&#xA;HLSL                       (cg, cginc, fxh, hlsl, hlsli, shader)&#xA;Hoon                       (hoon)&#xA;HTML                       (htm, html, html.hl, xht)&#xA;IDL                        (dlm, idl, pro)&#xA;Idris                      (idr)&#xA;Igor Pro                   (ipf)&#xA;Imba                       (imba)&#xA;INI                        (buildozer.spec, ini, lektorproject, prefs)&#xA;InstallShield              (ism)&#xA;IPL                        (ipl)&#xA;Java                       (java)&#xA;JavaScript                 (_js, bones, es6, jake, jakefile, js, jsb, jscad, jsfl, jsm, jss, mjs, njs, pac, sjs, ssjs, xsjs, xsjslib)&#xA;JavaServer Faces           (jsf)&#xA;JCL                        (jcl)&#xA;Jinja Template             (jinja, jinja2)&#xA;JSON                       (arcconfig, avsc, composer.lock, geojson, gltf, har, htmlhintrc, json, json-tmlanguage, jsonl, mcmeta, mcmod.info, tern-config, tern-project, tfstate, tfstate.backup, topojson, watchmanconfig, webapp, webmanifest, yyp)&#xA;JSON5                      (json5)&#xA;JSP                        (jsp, jspf)&#xA;JSX                        (jsx)&#xA;Julia                      (jl)&#xA;Juniper Junos              (junos)&#xA;Jupyter Notebook           (ipynb)&#xA;Kermit                     (ksc)&#xA;Korn Shell                 (ksh)&#xA;Kotlin                     (kt, ktm, kts)&#xA;Lean                       (hlean, lean)&#xA;LESS                       (less)&#xA;lex                        (l, lex)&#xA;LFE                        (lfe)&#xA;liquid                     (liquid)&#xA;Lisp                       (asd, el, lisp, lsp, cl, jl)&#xA;Literate Idris             (lidr)&#xA;LiveLink OScript           (oscript)&#xA;LLVM IR                    (ll)&#xA;Logos                      (x, xm)&#xA;Logtalk                    (lgt, logtalk)&#xA;Lua                        (lua, nse, p8, pd_lua, rbxs, wlua)&#xA;m4                         (ac, m4)&#xA;make                       (am, Gnumakefile, gnumakefile, Makefile, makefile, mk)&#xA;Mako                       (mako, mao)&#xA;Markdown                   (contents.lr, markdown, md, mdown, mdwn, mdx, mkd, mkdn, mkdown, ronn, workbook)&#xA;Mathematica                (cdf, ma, mathematica, mt, nbp, wl, wlt, m)&#xA;MATLAB                     (m)&#xA;Maven                      (pom, pom.xml)&#xA;Meson                      (meson.build)&#xA;Metal                      (metal)&#xA;Modula3                    (i3, ig, m3, mg)&#xA;Mojo                       (mojom)&#xA;MSBuild script             (btproj, csproj, msbuild, vcproj, wdproj, wixproj)&#xA;MUMPS                      (mps, m)&#xA;Mustache                   (mustache)&#xA;MXML                       (mxml)&#xA;NAnt script                (build)&#xA;NASTRAN DMAP               (dmap)&#xA;Nemerle                    (n)&#xA;Nim                        (nim, nim.cfg, nimble, nimrod, nims)&#xA;Nix                        (nix)&#xA;Objective-C                (m)&#xA;Objective-C++              (mm)&#xA;OCaml                      (eliom, eliomi, ml, ml4, mli, mll, mly)&#xA;Odin                       (odin)&#xA;OpenCL                     (cl)&#xA;Oracle Forms               (fmt)&#xA;Oracle PL/SQL              (bod, fnc, prc, spc, trg)&#xA;Oracle Reports             (rex)&#xA;Pascal                     (dpr, lpr, p, pas, pascal)&#xA;Pascal/Puppet              (pp)&#xA;Patran Command Language    (pcl, ses)&#xA;Perl                       (ack, al, cpanfile, makefile.pl, perl, ph, plh, plx, pm, psgi, rexfile, pl, p6)&#xA;PHP                        (aw, ctp, phakefile, php, php3, php4, php5, php_cs, php_cs.dist, phps, phpt, phtml)&#xA;PHP/Pascal                 (inc)&#xA;Pig Latin                  (pig)&#xA;PL/I                       (pl1)&#xA;PL/M                       (lit, plm)&#xA;PlantUML                   (puml)&#xA;PO File                    (po)&#xA;PowerBuilder               (pbt, sra, srf, srm, srs, sru, srw)&#xA;PowerShell                 (ps1, psd1, psm1)&#xA;ProGuard                   (pro)&#xA;Prolog                     (P, prolog, yap, pl, p6, pro)&#xA;Properties                 (properties)&#xA;Protocol Buffers           (proto)&#xA;Pug                        (jade, pug)&#xA;PureScript                 (purs)&#xA;Python                     (buck, build.bazel, gclient, gyp, gypi, lmi, py, py3, pyde, pyi, pyp, pyt, pyw, sconscript, sconstruct, snakefile, tac, workspace, wscript, wsgi, xpy)&#xA;QML                        (qbs, qml)&#xA;Qt                         (ui)&#xA;Qt Linguist                (ts)&#xA;Qt Project                 (pro)&#xA;R                          (expr-dist, R, r, rd, rprofile, rsx)&#xA;Racket                     (rkt, rktd, rktl, scrbl)&#xA;Raku                       (pm6, raku, rakumod)&#xA;Raku/Prolog                (P6, p6)&#xA;RAML                       (raml)&#xA;RapydScript                (pyj)&#xA;Razor                      (cshtml, razor)&#xA;ReasonML                   (re, rei)&#xA;ReScript                   (res, resi)&#xA;reStructuredText           (rest, rest.txt, rst, rst.txt)&#xA;Rexx                       (pprx, rexx)&#xA;Ring                       (rform, rh, ring)&#xA;Rmd                        (Rmd)&#xA;RobotFramework             (robot)&#xA;Ruby                       (appraisals, berksfile, brewfile, builder, buildfile, capfile, dangerfile, deliverfile, eye, fastfile, gemfile, gemfile.lock, gemspec, god, guardfile, irbrc, jarfile, jbuilder, mavenfile, mspec, podfile, podspec, pryrc, puppetfile, rabl, rake, rb, rbuild, rbw, rbx, ru, snapfile, thor, thorfile, vagrantfile, watchr)&#xA;Ruby HTML                  (rhtml)&#xA;Rust                       (rs, rs.in)&#xA;SaltStack                  (sls)&#xA;SAS                        (sas)&#xA;Sass                       (sass)&#xA;Scala                      (kojo, sbt, scala)&#xA;Scheme                     (sc, sch, scm, sld, sps, ss, sls)&#xA;SCSS                       (scss)&#xA;sed                        (sed)&#xA;SKILL                      (il)&#xA;SKILL++                    (ils)&#xA;Slice                      (ice)&#xA;Slim                       (slim)&#xA;Smalltalk                  (st, cs)&#xA;Smarty                     (smarty, tpl)&#xA;Softbridge Basic           (SBL, sbl)&#xA;Solidity                   (sol)&#xA;SparForte                  (sp)&#xA;Specman e                  (e)&#xA;SQL                        (cql, mysql, psql, SQL, sql, tab, udf, viw)&#xA;SQL Data                   (data.sql)&#xA;SQL Stored Procedure       (spc.sql, spoc.sql, sproc.sql, udf.sql)&#xA;Squirrel                   (nut)&#xA;Standard ML                (fun, sig, sml)&#xA;Starlark                   (bazel, bzl)&#xA;Stata                      (ado, DO, do, doh, ihlp, mata, matah, sthlp)&#xA;Stylus                     (styl)&#xA;SugarSS                    (sss)&#xA;Svelte                     (svelte)&#xA;SVG                        (SVG, svg)&#xA;Swift                      (swift)&#xA;SWIG                       (i)&#xA;TableGen                   (tb)&#xA;Tcl/Tk                     (itk, tcl, tk)&#xA;Teamcenter met             (met)&#xA;Teamcenter mth             (mth)&#xA;TeX                        (aux, bbx, bib, bst, cbx, dtx, ins, lbx, ltx, mkii, mkiv, mkvi, sty, tex, cls)&#xA;Thrift                     (thrift)&#xA;TITAN Project File Information (tpd)&#xA;Titanium Style Sheet       (tss)&#xA;TNSDL                      (cii, cin, in1, in2, in3, in4, inf, interface, rou, sdl, sdt, spd, ssc, sst)&#xA;TOML                       (toml)&#xA;TTCN                       (ttcn, ttcn2, ttcn3, ttcnpp)&#xA;Twig                       (twig)&#xA;TypeScript                 (tsx, ts)&#xA;Umka                       (um)&#xA;Unity-Prefab               (mat, prefab)&#xA;Vala                       (vala)&#xA;Vala Header                (vapi)&#xA;VB for Applications        (VBA, vba)&#xA;Velocity Template Language (vm)&#xA;Verilog-SystemVerilog      (sv, svh, v)&#xA;VHDL                       (VHD, vhd, VHDL, vhdl, vhf, vhi, vho, vhs, vht, vhw)&#xA;vim script                 (vim)&#xA;Visual Basic               (BAS, bas, ctl, dsr, frm, FRX, frx, VBHTML, vbhtml, vbp, vbw, cls)&#xA;Visual Basic .NET          (VB, vb, vbproj)&#xA;Visual Basic Script        (VBS, vbs)&#xA;Visual Fox Pro             (SCA, sca)&#xA;Visual Studio Solution     (sln)&#xA;Visualforce Component      (component)&#xA;Visualforce Page           (page)&#xA;Vuejs Component            (vue)&#xA;Web Services Description   (wsdl)&#xA;WebAssembly                (wast, wat)&#xA;Windows Message File       (mc)&#xA;Windows Module Definition  (def)&#xA;Windows Resource File      (rc, rc2)&#xA;WiX include                (wxi)&#xA;WiX source                 (wxs)&#xA;WiX string localization    (wxl)&#xA;WXML                       (wxml)&#xA;WXSS                       (wxss)&#xA;XAML                       (xaml)&#xA;xBase                      (prg, prw)&#xA;xBase Header               (ch)&#xA;XHTML                      (xhtml)&#xA;XMI                        (XMI, xmi)&#xA;XML                        (adml, admx, ant, app.config, axml, builds, ccproj, ccxml, classpath, clixml, cproject, cscfg, csdef, csl, ct, depproj, ditamap, ditaval, dll.config, dotsettings, filters, fsproj, gmx, grxml, iml, ivy, jelly, jsproj, kml, launch, mdpolicy, mjml, natvis, ndproj, nproj, nuget.config, nuspec, odd, osm, packages.config, pkgproj, plist, proj, project, props, ps1xml, psc1, pt, rdf, resx, rss, scxml, settings.stylecop, sfproj, shproj, srdf, storyboard, sttheme, sublime-snippet, targets, tmcommand, tml, tmlanguage, tmpreferences, tmsnippet, tmtheme, urdf, ux, vcxproj, vsixmanifest, vssettings, vstemplate, vxml, web.config, web.debug.config, web.release.config, wsf, x3d, xacro, xib, xlf, xliff, XML, xml, xml.dist, xproj, xspec, xul, zcml)&#xA;XQuery                     (xq, xql, xqm, xquery, xqy)&#xA;XSD                        (XSD, xsd)&#xA;XSLT                       (XSL, xsl, XSLT, xslt)&#xA;Xtend                      (xtend)&#xA;yacc                       (y, yacc)&#xA;YAML                       (clang-format, clang-tidy, gemrc, glide.lock, mir, reek, rviz, sublime-syntax, syntax, yaml, yaml-tmlanguage, yml, yml.mysql)&#xA;Zig                        (zig)&#xA;zsh                        (zsh)&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;The above list can be customized by reading language definitions from a file with the &lt;code&gt;--read-lang-def&lt;/code&gt; or &lt;code&gt;--force-lang-def&lt;/code&gt; options.&lt;/p&gt; &#xA;&lt;p&gt;These file extensions map to multiple languages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;cl&lt;/code&gt; files could be Lisp or OpenCL&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cls&lt;/code&gt; files could be Visual Basic, TeX or Apex Class&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cs&lt;/code&gt; files could be C# or Smalltalk&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;d&lt;/code&gt; files could be D or dtrace&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;f&lt;/code&gt; files could be Fortran 77 or Forth&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;fnc&lt;/code&gt; files could be Oracle PL or SQL&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;for&lt;/code&gt; files could be Fortran 77 or Forth&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;fs&lt;/code&gt; files could be F# or Forth&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;inc&lt;/code&gt; files could be PHP or Pascal&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;itk&lt;/code&gt; files could be Tcl or Tk&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;jl&lt;/code&gt; files could be Lisp or Julia&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;lit&lt;/code&gt; files could be PL or M&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;m&lt;/code&gt; files could be MATLAB, Mathematica, Objective-C, MUMPS or Mercury&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;p6&lt;/code&gt; files could be Perl or Prolog&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pl&lt;/code&gt; files could be Perl or Prolog&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PL&lt;/code&gt; files could be Perl or Prolog&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pp&lt;/code&gt; files could be Pascal or Puppet&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pro&lt;/code&gt; files could be IDL, Qt Project, Prolog or ProGuard&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;ts&lt;/code&gt; files could be TypeScript or Qt Linguist&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;ui&lt;/code&gt; files could be Qt or Glade&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;v&lt;/code&gt; files could be Verilog-SystemVerilog or Coq&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;cloc has subroutines that attempt to identify the correct language based on the file&#39;s contents for these special cases. Language identification accuracy is a function of how much code the file contains; .m files with just one or two lines for example, seldom have enough information to correctly distinguish between MATLAB, Mercury, MUMPS, or Objective-C.&lt;/p&gt; &#xA;&lt;p&gt;Languages with file extension collisions are difficult to customize with &lt;code&gt;--read-lang-def&lt;/code&gt; or &lt;code&gt;--force-lang-def&lt;/code&gt; as they have no mechanism to identify languages with common extensions. In this situation one must modify the cloc source code. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;How_it_works&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;How It Works ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;cloc&#39;s method of operation resembles SLOCCount&#39;s: First, create a list of files to consider. Next, attempt to determine whether or not found files contain recognized computer language source code. Finally, for files identified as source files, invoke language-specific routines to count the number of source lines.&lt;/p&gt; &#xA;&lt;p&gt;A more detailed description:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;If the input file is an archive (such as a .tar.gz or .zip file), create a temporary directory and expand the archive there using a system call to an appropriate underlying utility (tar, bzip2, unzip, etc) then add this temporary directory as one of the inputs. (This works more reliably on Unix than on Windows.)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Use File::Find to recursively descend the input directories and make a list of candidate file names. Ignore binary and zero-sized files.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure the files in the candidate list have unique contents (first by comparing file sizes, then, for similarly sized files, compare MD5 hashes of the file contents with Digest::MD5). For each set of identical files, remove all but the first copy, as determined by a lexical sort, of identical files from the set. The removed files are not included in the report. (The &lt;code&gt;--skip-uniqueness&lt;/code&gt; switch disables the uniqueness tests and forces all copies of files to be included in the report.) See also the &lt;code&gt;--ignored=&lt;/code&gt; switch to see which files were ignored and why.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Scan the candidate file list for file extensions which cloc associates with programming languages (see the &lt;code&gt;--show-lang&lt;/code&gt; and &lt;code&gt;--show-ext&lt;/code&gt; options). Files which match are classified as containing source code for that language. Each file without an extensions is opened and its first line read to see if it is a Unix shell script (anything that begins with #!). If it is shell script, the file is classified by that scripting language (if the language is recognized). If the file does not have a recognized extension or is not a recognized scripting language, the file is ignored.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;All remaining files in the candidate list should now be source files for known programming languages. For each of these files:&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Read the entire file into memory.&lt;/li&gt; &#xA;   &lt;li&gt;Count the number of lines (= L&lt;sub&gt;original&lt;/sub&gt;).&lt;/li&gt; &#xA;   &lt;li&gt;Remove blank lines, then count again (= L&lt;sub&gt;non_blank&lt;/sub&gt;).&lt;/li&gt; &#xA;   &lt;li&gt;Loop over the comment filters defined for this language. (For example, C++ has two filters: (1) remove lines that start with optional whitespace followed by // and (2) remove text between /* and */) Apply each filter to the code to remove comments. Count the left over lines (= L&lt;sub&gt;code&lt;/sub&gt;).&lt;/li&gt; &#xA;   &lt;li&gt;Save the counts for this language: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;blank lines = L&lt;sub&gt;original&lt;/sub&gt; - L&lt;sub&gt;non_blank&lt;/sub&gt;&lt;/li&gt; &#xA;     &lt;li&gt;comment lines = L&lt;sub&gt;non_blank&lt;/sub&gt; - L&lt;sub&gt;code&lt;/sub&gt;&lt;/li&gt; &#xA;     &lt;li&gt;code lines = L&lt;sub&gt;code&lt;/sub&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The options modify the algorithm slightly. The &lt;code&gt;--read-lang-def&lt;/code&gt; option for example allows the user to read definitions of comment filters, known file extensions, and known scripting languages from a file. The code for this option is processed between Steps 2 and 3. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;Advanced_Use&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Advanced Use ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;strip_comments&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Remove Comments from Source Code ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;How can you tell if cloc correctly identifies comments? One way to convince yourself cloc is doing the right thing is to use its &lt;code&gt;--strip-comments&lt;/code&gt; option to remove comments and blank lines from files, then compare the stripped-down files to originals.&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s try this out with the SQLite amalgamation, a C file containing all code needed to build the SQLite library along with a header file:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; tar zxf sqlite-amalgamation-3.5.6.tar.gz&#xA;prompt&amp;gt; cd sqlite-3.5.6/&#xA;prompt&amp;gt; cloc --strip-comments=nc sqlite.c&#xA;       1 text file.&#xA;       1 unique file.&#xA;Wrote sqlite3.c.nc&#xA;       0 files ignored.&#xA;&#xA;http://cloc.sourceforge.net v 1.03  T=1.0 s (1.0 files/s, 82895.0 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language          files     blank   comment      code    scale   3rd gen. equiv&#xA;-------------------------------------------------------------------------------&#xA;C                     1      5167     26827     50901 x   0.77 =       39193.77&#xA;-------------------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;The extension argument given to --strip-comments is arbitrary; here nc was used as an abbreviation for &#34;no comments&#34;.&lt;/p&gt; &#xA;&lt;p&gt;cloc removed over 31,000 lines from the file:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; wc -l sqlite3.c sqlite3.c.nc&#xA;  82895 sqlite3.c&#xA;  50901 sqlite3.c.nc&#xA; 133796 total&#xA;prompt&amp;gt; echo &#34;82895 - 50901&#34; | bc&#xA;31994&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;We can now compare the original file, sqlite3.c and the one stripped of comments, sqlite3.c.nc with tools like diff or vimdiff and see what exactly cloc considered comments and blank lines. A rigorous proof that the stripped-down file contains the same C code as the original is to compile these files and compare checksums of the resulting object files.&lt;/p&gt; &#xA;&lt;p&gt;First, the original source file:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; gcc -c sqlite3.c&#xA;prompt&amp;gt; md5sum sqlite3.o&#xA;cce5f1a2ea27c7e44b2e1047e2588b49  sqlite3.o&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Next, the version without comments:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; mv sqlite3.c.nc sqlite3.c&#xA;prompt&amp;gt; gcc -c sqlite3.c&#xA;prompt&amp;gt; md5sum sqlite3.o&#xA;cce5f1a2ea27c7e44b2e1047e2588b49  sqlite3.o&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;cloc removed over 31,000 lines of comments and blanks but did not modify the source code in any significant way since the resulting object file matches the original. &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;compressed_arch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Work with Compressed Archives ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Versions of cloc before v1.07 required an &lt;code&gt;--extract-with=CMD&lt;/code&gt; option to tell cloc how to expand an archive file. Beginning with v1.07 this is extraction is attempted automatically. At the moment the automatic extraction method works reasonably well on Unix-type OS&#39;s for the following file types: &lt;code&gt;.tar.gz&lt;/code&gt;, &lt;code&gt;.tar.bz2&lt;/code&gt;, &lt;code&gt;.tar.xz&lt;/code&gt;, &lt;code&gt;.tgz&lt;/code&gt;, &lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.ear&lt;/code&gt;, &lt;code&gt;.deb&lt;/code&gt;. Some of these extensions work on Windows if one has WinZip installed in the default location (&lt;code&gt;C:\Program Files\WinZip\WinZip32.exe&lt;/code&gt;). Additionally, with newer versions of WinZip, the [http://www.winzip.com/downcl.htm](command line add-on) is needed for correct operation; in this case one would invoke cloc with something like &lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA; --extract-with=&#34;\&#34;c:\Program Files\WinZip\wzunzip\&#34; -e -o &amp;gt;FILE&amp;lt; .&#34;&#xA; &#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Ref. &lt;a href=&#34;http://sourceforge.net/projects/cloc/forums/forum/600963/topic/4021070?message=8938196&#34;&gt;http://sourceforge.net/projects/cloc/forums/forum/600963/topic/4021070?message=8938196&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;In situations where the automatic extraction fails, one can try the &lt;code&gt;--extract-with=CMD&lt;/code&gt; option to count lines of code within tar files, Zip files, or other compressed archives for which one has an extraction tool. cloc takes the user-provided extraction command and expands the archive to a temporary directory (created with File::Temp), counts the lines of code in the temporary directory, then removes that directory. While not especially helpful when dealing with a single compressed archive (after all, if you&#39;re going to type the extraction command anyway why not just manually expand the archive?) this option is handy for working with several archives at once.&lt;/p&gt; &#xA;&lt;p&gt;For example, say you have the following source tarballs on a Unix machine&lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;perl-5.8.5.tar.gz&#xA;Python-2.4.2.tar.gz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and you want to count all the code within them. The command would be&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;cloc --extract-with=&#39;gzip -dc &amp;gt;FILE&amp;lt; | tar xf -&#39; perl-5.8.5.tar.gz Python-2.4.2.tar.gz&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;If that Unix machine has GNU tar (which can uncompress and extract in one step) the command can be shortened to&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;cloc --extract-with=&#39;tar zxf &amp;gt;FILE&amp;lt;&#39; perl-5.8.5.tar.gz Python-2.4.2.tar.gz&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;On a Windows computer with WinZip installed in &lt;code&gt;c:\Program Files\WinZip&lt;/code&gt; the command would look like&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;cloc.exe --extract-with=&#34;\&#34;c:\Program Files\WinZip\WinZip32.exe\&#34; -e -o &amp;gt;FILE&amp;lt; .&#34; perl-5.8.5.tar.gz Python-2.4.2.tar.gz&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Java &lt;code&gt;.ear&lt;/code&gt; files are Zip files that contain additional Zip files. cloc can handle nested compressed archives without difficulty--provided all such files are compressed and archived in the same way. Examples of counting a Java &lt;code&gt;.ear&lt;/code&gt; file in Unix and Windows:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cloc --extract-with=&#34;unzip -d . &amp;gt;FILE&amp;lt; &#34; Project.ear&#xA;&lt;i&gt;DOS&amp;gt;&lt;/i&gt; cloc.exe --extract-with=&#34;\&#34;c:\Program Files\WinZip\WinZip32.exe\&#34; -e -o &amp;gt;FILE&amp;lt; .&#34; Project.ear&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;diff&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Differences ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;--diff&lt;/code&gt; switch allows one to measure the relative change in source code and comments between two versions of a file, directory, or archive. Differences reveal much more than absolute code counts of two file versions. For example, say a source file has 100 lines and its developer delivers a newer version with 102 lines. Did the developer add two comment lines, or delete seventeen source lines and add fourteen source lines and five comment lines, or did the developer do a complete rewrite, discarding all 100 original lines and adding 102 lines of all new source? The diff option tells how many lines of source were added, removed, modified or stayed the same, and how many lines of comments were added, removed, modified or stayed the same.&lt;/p&gt; &#xA;&lt;p&gt;Differences in blank lines are handled much more coarsely because these are stripped by cloc early on. Unless a file pair is identical, cloc will report only differences in absolute counts of blank lines. In other words, one can expect to see only entries for &#39;added&#39; if the second file has more blanks than the first, and &#39;removed&#39; if the situation is reversed. The entry for &#39;same&#39; will be non-zero only when the two files are identical.&lt;/p&gt; &#xA;&lt;p&gt;In addition to file pairs, one can give cloc pairs of directories, or pairs of file archives, or a file archive and a directory. cloc will try to align file pairs within the directories or archives and compare diffs for each pair. For example, to see what changed between GCC 4.4.0 and 4.5.0 one could do&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;cloc --diff gcc-4.4.0.tar.bz2  gcc-4.5.0.tar.bz2&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Be prepared to wait a while for the results though; the &lt;code&gt;--diff&lt;/code&gt; option runs much more slowly than an absolute code count.&lt;/p&gt; &#xA;&lt;p&gt;To see how cloc aligns files between the two archives, use the &lt;code&gt;--diff-alignment&lt;/code&gt; option&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;cloc --diff-alignment=align.txt gcc-4.4.0.tar.bz2  gcc-4.5.0.tar.bz2&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;to produce the file &lt;code&gt;align.txt&lt;/code&gt; which shows the file pairs as well as files added and deleted. The symbols &lt;code&gt;==&lt;/code&gt; and &lt;code&gt;!=&lt;/code&gt; before each file pair indicate if the files are identical (&lt;code&gt;==&lt;/code&gt;) or if they have different content (&lt;code&gt;!=&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s sample output showing the difference between the Python 2.6.6 and 2.7 releases:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;i&gt;prompt&amp;gt;&lt;/i&gt; cloc --diff Python-2.7.9.tgz Python-2.7.10.tar.xz&#xA;    4315 text files.&#xA;    4313 text files.s&#xA;    2173 files ignored.&#xA;&#xA;4 errors:&#xA;Diff error, exceeded timeout:  /tmp/8ToGAnB9Y1/Python-2.7.9/Mac/Modules/qt/_Qtmodule.c&#xA;Diff error, exceeded timeout:  /tmp/M6ldvsGaoq/Python-2.7.10/Mac/Modules/qt/_Qtmodule.c&#xA;Diff error (quoted comments?):  /tmp/8ToGAnB9Y1/Python-2.7.9/Mac/Modules/qd/qdsupport.py&#xA;Diff error (quoted comments?):  /tmp/M6ldvsGaoq/Python-2.7.10/Mac/Modules/qd/qdsupport.py&#xA;&#xA;https://github.com/AlDanial/cloc v 1.65  T=298.59 s (0.0 files/s, 0.0 lines/s)&#xA;-----------------------------------------------------------------------------&#xA;Language                   files          blank        comment           code&#xA;-----------------------------------------------------------------------------&#xA;Visual Basic&#xA; same                          2              0              1             12&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;make&#xA; same                         11              0            340           2952&#xA; modified                      1              0              0              1&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;diff&#xA; same                          1              0             87            105&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;CSS&#xA; same                          0              0             19            327&#xA; modified                      1              0              0              1&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;Objective-C&#xA; same                          7              0             61            635&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;NAnt script&#xA; same                          2              0              0             30&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;XML&#xA; same                          3              0              2             72&#xA; modified                      1              0              0              1&#xA; added                         0              0              0              1&#xA; removed                       0              1              0              0&#xA;Windows Resource File&#xA; same                          3              0             56            206&#xA; modified                      1              0              0              1&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;Expect&#xA; same                          6              0            161            565&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;HTML&#xA; same                         14              0             11           2344&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;vim script&#xA; same                          1              0              7            106&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;C++&#xA; same                          2              0             18            128&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;Windows Module Definition&#xA; same                          7              0            187           2080&#xA; modified                      2              0              0              0&#xA; added                         0              0              0              1&#xA; removed                       0              1              0              2&#xA;Prolog&#xA; same                          1              0              0             24&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;Javascript&#xA; same                          3              0             49            229&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;Assembly&#xA; same                         51              0           6794          12298&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;Bourne Shell&#xA; same                         41              0           7698          45024&#xA; modified                      1              0              0              3&#xA; added                         0             13              2             64&#xA; removed                       0              0              0              0&#xA;DOS Batch&#xA; same                         29              0            107            494&#xA; modified                      1              0              0              9&#xA; added                         0              1              0              3&#xA; removed                       0              0              0              0&#xA;MSBuild script&#xA; same                         77              0              3          38910&#xA; modified                      0              0              0              0&#xA; added                         0              0              0              0&#xA; removed                       0              0              0              0&#xA;Python&#xA; same                       1947              0         109012         430335&#xA; modified                    192              0             94            950&#xA; added                         2            323            283           2532&#xA; removed                       2             55             58            646&#xA;m4&#xA; same                         18              0            191          15352&#xA; modified                      1              0              0              2&#xA; added                         1             31              0            205&#xA; removed                       0              0              0              0&#xA;C&#xA; same                        505              0          37439         347837&#xA; modified                     45              0             13            218&#xA; added                         0             90             33            795&#xA; removed                       0              9              2            148&#xA;C/C++ Header&#xA; same                        255              0          10361          66635&#xA; modified                      5              0              5              7&#xA; added                         0              1              3            300&#xA; removed                       0              0              0              0&#xA;---------------------------------------------------------------------&#xA;SUM:&#xA; same                       2986              0         172604         966700&#xA; modified                    251              0            112           1193&#xA; added                         3            459            321           3901&#xA; removed                       2             66             60            796&#xA;---------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;A pair of errors occurred. The first pair was caused by timing out when computing diffs of the file &lt;code&gt;Python-X/Mac/Modules/qt/_Qtmodule.c&lt;/code&gt; in each Python version. This file has &amp;gt; 26,000 lines of C code and takes more than 10 seconds--the default maximum duration for diff&#39;ing a single file--on my slow computer. (Note: this refers to performing differences with the &lt;code&gt;sdiff()&lt;/code&gt; function in the Perl &lt;code&gt;Algorithm::Diff&lt;/code&gt; module, not the command line &lt;code&gt;diff&lt;/code&gt; utility.) This error can be overcome by raising the time to, say, 20 seconds with &lt;code&gt;--diff-timeout 20&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The second error is more problematic. The files &lt;code&gt;Python-X/Mac/Modules/qd/qdsupport.py&lt;/code&gt; include Python docstring (text between pairs of triple quotes) containing C comments. cloc treats docstrings as comments and handles them by first converting them to C comments, then using the C comment removing regular expression. Nested C comments yield erroneous results however.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;custom_lang&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Create Custom Language Definitions ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;cloc can write its language comment definitions to a file or can read comment definitions from a file, overriding the built-in definitions. This can be useful when you want to use cloc to count lines of a language not yet included, to change association of file extensions to languages, or to modify the way existing languages are counted.&lt;/p&gt; &#xA;&lt;p&gt;The easiest way to create a custom language definition file is to make cloc write its definitions to a file, then modify that file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cloc --write-lang-def=my_definitions.txt&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;creates the file &lt;code&gt;my_definitions.txt&lt;/code&gt; which can be modified then read back in with either the &lt;code&gt;--read-lang-def&lt;/code&gt; or &lt;code&gt;--force-lang-def&lt;/code&gt; option. The difference between the options is former merges language definitions from the given file in with cloc&#39;s internal definitions with cloc&#39;s taking precedence if there are overlaps. The &lt;code&gt;--force-lang-def&lt;/code&gt; option, on the other hand, replaces cloc&#39;s definitions completely. This option has a disadvantage in preventing cloc from counting &lt;a class=&#34;u&#34; href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#extcollision&#34; name=&#34;extcollision&#34;&gt; languages whose extensions map to multiple languages &lt;/a&gt; as these languages require additional logic that is not easily expressed in a definitions file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cloc --read-lang-def=my_definitions.txt  &lt;i&gt;file1 file2 dir1 ...&lt;/i&gt;&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Each language entry has four parts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The language name starting in column 1.&lt;/li&gt; &#xA; &lt;li&gt;One or more comment &lt;em&gt;filters&lt;/em&gt; starting in column 5.&lt;/li&gt; &#xA; &lt;li&gt;One or more filename extensions starting in column 5.&lt;/li&gt; &#xA; &lt;li&gt;A 3rd generation scale factor starting in column 5. This entry must be provided but its value is not important unless you want to compare your language to a hypothetical third generation programming language.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A filter defines a method to remove comment text from the source file. For example the entry for C++ looks like this&lt;/p&gt; &#xA;&lt;pre&gt;C++&#xA;    filter call_regexp_common C++&#xA;    filter remove_inline //.*$&#xA;    extension C&#xA;    extension c++&#xA;    extension cc&#xA;    extension cpp&#xA;    extension cxx&#xA;    extension pcc&#xA;    3rd_gen_scale 1.51&#xA;    end_of_line_continuation \\$&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;C++ has two filters: first, remove lines matching Regexp::Common&#39;s C++ comment regex. The second filter using remove_inline is currently unused. Its intent is to identify lines with both code and comments and it may be implemented in the future.&lt;/p&gt; &#xA;&lt;p&gt;A more complete discussion of the different filter options may appear here in the future. The output of cloc&#39;s &lt;code&gt;--write-lang-def&lt;/code&gt; option should provide enough examples for motivated individuals to modify or extend cloc&#39;s language definitions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;combine_reports&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Combine Reports ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;If you manage multiple software projects you might be interested in seeing line counts by project, not just by language. Say you manage three software projects called MariaDB, PostgreSQL, and SQLite. The teams responsible for each of these projects run cloc on their source code and provide you with the output. For example MariaDB team does&lt;/p&gt; &#xA;&lt;pre&gt;cloc --out mariadb-10.1.txt mariadb-server-10.1.zip&lt;/pre&gt; &#xA;&lt;p&gt;and provides you with the file &lt;code&gt;mariadb-10.1.txt&lt;/code&gt;. The contents of the three files you get are&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cat mariadb-10.1.txt&#xA;https://github.com/AlDanial/cloc v 1.65  T=45.36 s (110.5 files/s, 66411.4 lines/s)&#xA;-----------------------------------------------------------------------------------&#xA;Language                         files          blank        comment           code&#xA;-----------------------------------------------------------------------------------&#xA;C++                               1613         225338         290077         983026&#xA;C                                  853          62442          73017         715018&#xA;C/C++ Header                      1327          48300         114577         209394&#xA;Bourne Shell                       256          10224          10810          61943&#xA;Perl                               147          10342           8305          35562&#xA;Pascal                             107           4907           5237          32541&#xA;HTML                                56            195              6          16489&#xA;Javascript                           5           3309           3019          15540&#xA;m4                                  30           1599            359          14215&#xA;CMake                              190           1919           4097          12206&#xA;XML                                 35            648             56           5210&#xA;Ruby                                59            619            184           4998&#xA;Puppet                              10              0              1           3848&#xA;make                               134            724            360           3631&#xA;SQL                                 23            306            377           3405&#xA;Python                              34            371            122           2545&#xA;Bourne Again Shell                  27            299            380           1604&#xA;Windows Module Definition           37             27             13           1211&#xA;lex                                  4            394            166            991&#xA;yacc                                 2            152             64            810&#xA;DOS Batch                           19             89             82            700&#xA;Prolog                               1              9             40            448&#xA;RobotFramework                       1              0              0            441&#xA;CSS                                  2             33            155            393&#xA;JSON                                 5              0              0            359&#xA;dtrace                               9             59            179            306&#xA;Windows Resource File               10             61             89            250&#xA;Assembly                             2             70            284            237&#xA;WiX source                           1             18             10            155&#xA;Visual Basic                         6              0              0             88&#xA;YAML                                 2              4              4             65&#xA;PHP                                  1             11              2             24&#xA;SKILL                                1              8             15             16&#xA;sed                                  2              0              0             16&#xA;Windows Message File                 1              2              8              6&#xA;diff                                 1              1              4              4&#xA;D                                    1              4             11              4&#xA;-----------------------------------------------------------------------------------&#xA;SUM:                              5014         372484         512110        2127699&#xA;-----------------------------------------------------------------------------------&#xA;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cat sqlite-3081101.txt&#xA;https://github.com/AlDanial/cloc v 1.65  T=1.22 s (3.3 files/s, 143783.6 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;C                                2          11059          53924         101454&#xA;C/C++ Header                     2            211           6630           1546&#xA;-------------------------------------------------------------------------------&#xA;SUM:                             4          11270          60554         103000&#xA;-------------------------------------------------------------------------------&#xA;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cat postgresql-9.4.4.txt&#xA;https://github.com/AlDanial/cloc v 1.65  T=22.46 s (172.0 files/s, 96721.6 lines/s)&#xA;-----------------------------------------------------------------------------------&#xA;Language                         files          blank        comment           code&#xA;-----------------------------------------------------------------------------------&#xA;HTML                              1254           3725              0         785991&#xA;C                                 1139         139289         244045         736519&#xA;C/C++ Header                       667          12277          32488          57014&#xA;SQL                                410          13400           8745          51926&#xA;yacc                                 8           3163           2669          28491&#xA;Bourne Shell                        41           2647           2440          17170&#xA;Perl                                81           1702           1308           9456&#xA;lex                                  9            792           1631           4285&#xA;make                               205           1525           1554           4114&#xA;m4                                  12            218             25           1642&#xA;Windows Module Definition           13              4             17           1152&#xA;XSLT                                 5             76             55            294&#xA;DOS Batch                            7             29             30             92&#xA;CSS                                  1             20              7             69&#xA;Assembly                             3             17             38             69&#xA;D                                    1             14             14             66&#xA;Windows Resource File                3              4              0             62&#xA;Lisp                                 1              1              1             16&#xA;sed                                  1              1              7             15&#xA;Python                               1              5              0             13&#xA;Bourne Again Shell                   1              8              6             10&#xA;Windows Message File                 1              0              0              5&#xA;-----------------------------------------------------------------------------------&#xA;SUM:                              3864         178917         295080        1698471&#xA;-----------------------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;While these three files are interesting, you also want to see the combined counts from all projects. That can be done with cloc&#39;s &lt;code&gt;--sum_reports&lt;/code&gt; option:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cloc --sum-reports --out=databases mariadb-10.1.txt  sqlite-3081101.txt  postgresql-9.4.4.txt&#xA;Wrote databases.lang&#xA;Wrote databases.file&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;The report combination produces two output files, one for sums by programming language (&lt;code&gt;databases.lang&lt;/code&gt;) and one by project (&lt;code&gt;databases.file&lt;/code&gt;). Their contents are&lt;/p&gt; &#xA;&lt;pre&gt;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cat databases.lang&#xA;https://github.com/AlDanial/cloc v 1.65&#xA;--------------------------------------------------------------------------------&#xA;Language                      files          blank        comment           code&#xA;--------------------------------------------------------------------------------&#xA;C                              1994         212790         370986        1552991&#xA;C++                            1613         225338         290077         983026&#xA;HTML                           1310           3920              6         802480&#xA;C/C++ Header                   1996          60788         153695         267954&#xA;Bourne Shell                    297          12871          13250          79113&#xA;SQL                             433          13706           9122          55331&#xA;Perl                            228          12044           9613          45018&#xA;Pascal                          107           4907           5237          32541&#xA;yacc                             10           3315           2733          29301&#xA;m4                               42           1817            384          15857&#xA;Javascript                        5           3309           3019          15540&#xA;CMake                           190           1919           4097          12206&#xA;make                            339           2249           1914           7745&#xA;lex                              13           1186           1797           5276&#xA;XML                              35            648             56           5210&#xA;Ruby                             59            619            184           4998&#xA;Puppet                           10              0              1           3848&#xA;Python                           35            376            122           2558&#xA;Windows Module Definition        50             31             30           2363&#xA;Bourne Again Shell               28            307            386           1614&#xA;DOS Batch                        26            118            112            792&#xA;CSS                               3             53            162            462&#xA;Prolog                            1              9             40            448&#xA;RobotFramework                    1              0              0            441&#xA;JSON                              5              0              0            359&#xA;Windows Resource File            13             65             89            312&#xA;Assembly                          5             87            322            306&#xA;dtrace                            9             59            179            306&#xA;XSLT                              5             76             55            294&#xA;WiX source                        1             18             10            155&#xA;Visual Basic                      6              0              0             88&#xA;D                                 2             18             25             70&#xA;YAML                              2              4              4             65&#xA;sed                               3              1              7             31&#xA;PHP                               1             11              2             24&#xA;SKILL                             1              8             15             16&#xA;Lisp                              1              1              1             16&#xA;Windows Message File              2              2              8             11&#xA;diff                              1              1              4              4&#xA;--------------------------------------------------------------------------------&#xA;SUM:                           8882         562671         867744        3929170&#xA;--------------------------------------------------------------------------------&#xA;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cat databases.file&#xA;----------------------------------------------------------------------------------&#xA;File                            files          blank        comment           code&#xA;----------------------------------------------------------------------------------&#xA;mariadb-10.1.txt                 5014         372484         512110        2127699&#xA;postgresql-9.4.4.txt             3864         178917         295080        1698471&#xA;sqlite-3081101.txt                  4          11270          60554         103000&#xA;----------------------------------------------------------------------------------&#xA;SUM:                             8882         562671         867744        3929170&#xA;----------------------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Report files themselves can be summed together. Say you also manage development of Perl and Python and you want to keep track of those line counts separately from your database projects. First create reports for Perl and Python separately:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;cloc --out perl-5.22.0.txt   perl-5.22.0.tar.gz&#xA;cloc --out python-2.7.10.txt Python-2.7.10.tar.xz&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;then sum these together with&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cloc --sum-reports --out script_lang perl-5.22.0.txt python-2.7.10.txt&#xA;Wrote script_lang.lang&#xA;Wrote script_lang.file&#xA;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cat script_lang.lang&#xA;https://github.com/AlDanial/cloc v 1.65&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;Perl                          2892         136396         184362         536445&#xA;C                              680          75566          71211         531203&#xA;Python                        2141          89642         109524         434015&#xA;C/C++ Header                   408          16433          26938         214800&#xA;Bourne Shell                   154          11088          14496          87759&#xA;MSBuild script                  77              0              3          38910&#xA;m4                              20           1604            191          15559&#xA;Assembly                        51           3775           6794          12298&#xA;Pascal                           8            458           1603           8592&#xA;make                            16            897            828           4939&#xA;XML                             37            198              2           2484&#xA;HTML                            14            393             11           2344&#xA;C++                             12            338            295           2161&#xA;Windows Module Definition        9            171            187           2081&#xA;YAML                            49             20             15           2078&#xA;Prolog                          12            438              2           1146&#xA;JSON                            14              1              0           1037&#xA;yacc                             1             85             76            998&#xA;DOS Batch                       44            199            148            895&#xA;Objective-C                      7             98             61            635&#xA;Expect                           6            104            161            565&#xA;Windows Message File             1            102             11            489&#xA;CSS                              1             98             19            328&#xA;Windows Resource File            7             55             56            292&#xA;Javascript                       3             31             49            229&#xA;vim script                       1             36              7            106&#xA;diff                             1             17             87            105&#xA;NAnt script                      2              1              0             30&#xA;IDL                              1              0              0             24&#xA;Visual Basic                     2              1              1             12&#xA;D                                1              5              7              8&#xA;Lisp                             2              0              3              4&#xA;-------------------------------------------------------------------------------&#xA;SUM:                          6674         338250         417148        1902571&#xA;-------------------------------------------------------------------------------&#xA;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cat script_lang.file&#xA;-------------------------------------------------------------------------------&#xA;File                         files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;python-2.7.10.txt             3240         161276         173214         998697&#xA;perl-5.22.0.txt               3434         176974         243934         903874&#xA;-------------------------------------------------------------------------------&#xA;SUM:                          6674         338250         417148        1902571&#xA;-------------------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, combine the combination files:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cloc --sum-reports --report_file=everything databases.lang script_lang.lang&#xA;Wrote everything.lang&#xA;Wrote everything.file&#xA;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cat everything.lang&#xA;https://github.com/AlDanial/cloc v 1.65&#xA;---------------------------------------------------------------------------------&#xA;Language                       files          blank        comment           code&#xA;---------------------------------------------------------------------------------&#xA;C                               2674         288356         442197        2084194&#xA;C++                             1625         225676         290372         985187&#xA;HTML                            1324           4313             17         804824&#xA;Perl                            3120         148440         193975         581463&#xA;C/C++ Header                    2404          77221         180633         482754&#xA;Python                          2176          90018         109646         436573&#xA;Bourne Shell                     451          23959          27746         166872&#xA;SQL                              433          13706           9122          55331&#xA;Pascal                           115           5365           6840          41133&#xA;MSBuild script                    77              0              3          38910&#xA;m4                                62           3421            575          31416&#xA;yacc                              11           3400           2809          30299&#xA;Javascript                         8           3340           3068          15769&#xA;make                             355           3146           2742          12684&#xA;Assembly                          56           3862           7116          12604&#xA;CMake                            190           1919           4097          12206&#xA;XML                               72            846             58           7694&#xA;lex                               13           1186           1797           5276&#xA;Ruby                              59            619            184           4998&#xA;Windows Module Definition         59            202            217           4444&#xA;Puppet                            10              0              1           3848&#xA;YAML                              51             24             19           2143&#xA;DOS Batch                         70            317            260           1687&#xA;Bourne Again Shell                28            307            386           1614&#xA;Prolog                            13            447             42           1594&#xA;JSON                              19              1              0           1396&#xA;CSS                                4            151            181            790&#xA;Objective-C                        7             98             61            635&#xA;Windows Resource File             20            120            145            604&#xA;Expect                             6            104            161            565&#xA;Windows Message File               3            104             19            500&#xA;RobotFramework                     1              0              0            441&#xA;dtrace                             9             59            179            306&#xA;XSLT                               5             76             55            294&#xA;WiX source                         1             18             10            155&#xA;diff                               2             18             91            109&#xA;vim script                         1             36              7            106&#xA;Visual Basic                       8              1              1            100&#xA;D                                  3             23             32             78&#xA;sed                                3              1              7             31&#xA;NAnt script                        2              1              0             30&#xA;IDL                                1              0              0             24&#xA;PHP                                1             11              2             24&#xA;Lisp                               3              1              4             20&#xA;SKILL                              1              8             15             16&#xA;---------------------------------------------------------------------------------&#xA;SUM:                           15556         900921        1284892        5831741&#xA;---------------------------------------------------------------------------------&#xA;&#xA;&lt;i&gt;Unix&amp;gt;&lt;/i&gt; cat everything.file&#xA;-------------------------------------------------------------------------------&#xA;File                         files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;databases.lang                8882         562671         867744        3929170&#xA;script_lang.lang              6674         338250         417148        1902571&#xA;-------------------------------------------------------------------------------&#xA;SUM:                         15556         900921        1284892        5831741&#xA;-------------------------------------------------------------------------------&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;One limitation of the &lt;code&gt;--sum-reports&lt;/code&gt; feature is that the individual counts must be saved in the plain text format. Counts saved as XML, JSON, YAML, or SQL will produce errors if used in a summation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;sql&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;SQL ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Cloc can write results in the form of SQL table create and insert statements for use with relational database programs such as SQLite, MySQL, PostgreSQL, Oracle, or Microsoft SQL. Once the code count information is in a database, the information can be interrogated and displayed in interesting ways.&lt;/p&gt; &#xA;&lt;p&gt;A database created from cloc SQL output has two tables, &lt;strong&gt;metadata&lt;/strong&gt; and &lt;strong&gt;t&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;p&gt;Table &lt;strong&gt;metadata&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Field&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;timestamp&lt;/td&gt; &#xA;   &lt;td&gt;text&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;project&lt;/td&gt; &#xA;   &lt;td&gt;text&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;elapsed_s&lt;/td&gt; &#xA;   &lt;td&gt;text&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Table &lt;strong&gt;t&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Field&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;project&lt;/td&gt; &#xA;   &lt;td&gt;text&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;language&lt;/td&gt; &#xA;   &lt;td&gt;text&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;file&lt;/td&gt; &#xA;   &lt;td&gt;text&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;nBlank&lt;/td&gt; &#xA;   &lt;td&gt;integer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;nComment&lt;/td&gt; &#xA;   &lt;td&gt;integer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;nCode&lt;/td&gt; &#xA;   &lt;td&gt;integer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;nScaled&lt;/td&gt; &#xA;   &lt;td&gt;real&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The &lt;strong&gt;metadata&lt;/strong&gt; table contains information about when the cloc run was made. The &lt;code&gt;--sql-append&lt;/code&gt; switch allows one to combine many runs in a single database; each run adds a row to the metadata table. The code count information resides in table &lt;strong&gt;t&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s repeat the code count examples of Perl, Python, SQLite, MySQL and PostgreSQL tarballs shown in the &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#combine_reports&#34;&gt;Combine Reports&lt;/a&gt; example above, this time using the SQL output options and the &lt;a href=&#34;http://www.sqlite.org/&#34;&gt;SQLite&lt;/a&gt; database engine.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;--sql&lt;/code&gt; switch tells cloc to generate output in the form of SQL table &lt;code&gt;create&lt;/code&gt; and &lt;code&gt;insert&lt;/code&gt; commands. The switch takes an argument of a file name to write these SQL statements into, or, if the argument is 1 (numeric one), streams output to STDOUT. Since the SQLite command line program, &lt;code&gt;sqlite3&lt;/code&gt;, can read commands from STDIN, we can dispense with storing SQL statements to a file and use &lt;code&gt;--sql 1&lt;/code&gt; to pipe data directly into the SQLite executable:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;cloc --sql 1 --sql-project mariadb mariadb-server-10.1.zip | sqlite3 code.db&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;--sql-project mariadb&lt;/code&gt; part is optional; there&#39;s no need to specify a project name when working with just one code base. However, since we&#39;ll be adding code counts from four other tarballs, we&#39;ll only be able to identify data by input source if we supply a project name for each run.&lt;/p&gt; &#xA;&lt;p&gt;Now that we have a database we will need to pass in the &lt;code&gt;--sql-append&lt;/code&gt; switch to tell cloc not to wipe out this database but instead add more data:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;cloc --sql 1 --sql-project postgresql --sql-append postgresql-9.4.4.tar.bz2        | sqlite3 code.db&#xA;cloc --sql 1 --sql-project sqlite     --sql-append sqlite-amalgamation-3081101.zip | sqlite3 code.db&#xA;cloc --sql 1 --sql-project python     --sql-append Python-2.7.10.tar.xz            | sqlite3 code.db&#xA;cloc --sql 1 --sql-project perl       --sql-append perl-5.22.0.tar.gz              | sqlite3 code.db&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Now the fun begins--we have a database, &lt;code&gt;code.db&lt;/code&gt;, with lots of information about the five projects and can query it for all manner of interesting facts.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Which is the longest file over all projects?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; sqlite3 code.db &#39;select project,file,nBlank+nComment+nCode as nL from t&#xA;                                 where nL = (select max(nBlank+nComment+nCode) from t)&#39;&#xA;&#xA;sqlite|sqlite-amalgamation-3081101/sqlite3.c|161623&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;sqlite3&lt;/code&gt;&#39;s default output format leaves a bit to be desired. We can add an option to the program&#39;s rc file, &lt;code&gt;~/.sqliterc&lt;/code&gt;, to show column headers:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;  .header on&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;One might be tempted to also include&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;  .mode column&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;in &lt;code&gt;~/.sqliterc&lt;/code&gt; but this causes problems when the output has more than one row since the widths of entries in the first row govern the maximum width for all subsequent rows. Often this leads to truncated output--not at all desirable. One option is to write a custom SQLite output formatter such as &lt;code&gt;sqlite_formatter&lt;/code&gt;, included with cloc.&lt;/p&gt; &#xA;&lt;p&gt;To use it, simply pass &lt;code&gt;sqlite3&lt;/code&gt;&#39;s STDOUT into &lt;code&gt;sqlite_formatter&lt;/code&gt; via a pipe:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; sqlite3 code.db &#39;select project,file,nBlank+nComment+nCode as nL from t&#xA;                         where nL = (select max(nBlank+nComment+nCode) from t)&#39; | ./sqlite_formatter&#xA;  &lt;font color=&#34;darkgreen&#34;&gt;&#xA;  -- Loading resources from ~/.sqliterc&#xA;  Project File                                  nL&#xA;  _______ _____________________________________ ______&#xA;  sqlite  sqlite-amalgamation-3081101/sqlite3.c 161623&#xA;  &lt;/font&gt;&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;If the &#34;Project File&#34; line doesn&#39;t appear, add &lt;code&gt;.header on&lt;/code&gt; to your &lt;code&gt;~/.sqliterc&lt;/code&gt; file as explained above.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What is the longest file over all projects?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; sqlite3 code.db &#39;select project,file,nBlank+nComment+nCode as nL from t&#xA;                         where nL = (select max(nBlank+nComment+nCode) from t)&#39; | sqlite_formatter&#xA;&#xA;Project File                                  nL&#xA;_______ _____________________________________ ______&#xA;sqlite  sqlite-amalgamation-3081101/sqlite3.c 161623&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;What is the longest file in each project?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; sqlite3 code.db &#39;select project,file,max(nBlank+nComment+nCode) as nL from t&#xA;                          group by project order by nL;&#39; | sqlite_formatter&#xA;&#xA;Project    File                                                             nL&#xA;__________ ________________________________________________________________ ______&#xA;python     Python-2.7.10/Mac/Modules/qt/_Qtmodule.c                          28091&#xA;postgresql postgresql-9.4.4/src/interfaces/ecpg/preproc/preproc.c            54623&#xA;mariadb    server-10.1/storage/mroonga/vendor/groonga/lib/nfkc.c             80246&#xA;perl       perl-5.22.0/cpan/Locale-Codes/lib/Locale/Codes/Language_Codes.pm 100747&#xA;sqlite     sqlite-amalgamation-3081101/sqlite3.c                            161623&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Which files in each project have the most code lines?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; sqlite3 code.db &#39;select project,file,max(nCode) as nL from t&#xA;                         group by project order by nL desc;&#39; | sqlite_formatter&#xA;&#xA;Project    File                                                             nL&#xA;__________ ________________________________________________________________ ______&#xA;perl       perl-5.22.0/cpan/Locale-Codes/lib/Locale/Codes/Language_Codes.pm 100735&#xA;sqlite     sqlite-amalgamation-3081101/sqlite3.c                             97469&#xA;mariadb    server-10.1/storage/mroonga/vendor/groonga/lib/nfkc.c             80221&#xA;postgresql postgresql-9.4.4/src/interfaces/ecpg/preproc/preproc.c            45297&#xA;python     Python-2.7.10/Mac/Modules/qt/_Qtmodule.c                          26705&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Which C source files with more than 300 lines have a comment ratio below 1%?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; sqlite3 code.db &#39;select project, file, nCode, nComment,&#xA;                         (100.0*nComment)/(nComment+nCode) as comment_ratio from t&#xA;                         where language=&#34;C&#34; and nCode &amp;gt; 300 and&#xA;                         comment_ratio &amp;lt; 1 order by comment_ratio;&#39; | sqlite_formatter&#xA;&#xA;Project    File                                                                                            nCode nComment comment_ratio&#xA;__________ _______________________________________________________________________________________________ _____ ________ __________________&#xA;mariadb    server-10.1/storage/mroonga/vendor/groonga/lib/nfkc.c                                           80221       14 0.0174487443135789&#xA;python     Python-2.7.10/Python/graminit.c                                                                  2175        1 0.0459558823529412&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_turkish.c                            2095        1 0.0477099236641221&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_french.c                             1211        1 0.0825082508250825&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_french.c                        1201        1 0.0831946755407654&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_hungarian.c                          1182        1 0.084530853761623&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_hungarian.c                     1178        1 0.0848176420695505&#xA;mariadb    server-10.1/strings/ctype-eucjpms.c                                                             67466       60 0.0888546633889169&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_english.c                            1072        1 0.0931966449207828&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_english.c                       1064        1 0.0938967136150235&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_spanish.c                            1053        1 0.094876660341556&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_spanish.c                       1049        1 0.0952380952380952&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_italian.c                            1031        1 0.0968992248062016&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_italian.c                       1023        1 0.09765625&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_portuguese.c                          981        1 0.10183299389002&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_portuguese.c                     975        1 0.102459016393443&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_romanian.c                            967        1 0.103305785123967&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_2_romanian.c                       961        1 0.103950103950104&#xA;mariadb    server-10.1/strings/ctype-ujis.c                                                                67177       79 0.117461639110265&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_finnish.c                             720        1 0.13869625520111&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_porter.c                              717        1 0.139275766016713&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_finnish.c                        714        1 0.13986013986014&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_porter.c                         711        1 0.140449438202247&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_KOI8_R_russian.c                            660        1 0.151285930408472&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_russian.c                             654        1 0.152671755725191&#xA;python     Python-2.7.10/Mac/Modules/qt/_Qtmodule.c                                                        26705       42 0.157026956294164&#xA;python     Python-2.7.10/Mac/Modules/icn/_Icnmodule.c                                                       1521        3 0.196850393700787&#xA;mariadb    server-10.1/strings/ctype-extra.c                                                                8282       18 0.216867469879518&#xA;postgresql postgresql-9.4.4/src/bin/psql/sql_help.c                                                         3576        8 0.223214285714286&#xA;mariadb    server-10.1/strings/ctype-sjis.c                                                                34006       86 0.252258594391646&#xA;python     Python-2.7.10/Python/Python-ast.c                                                                6554       17 0.258712524729874&#xA;mariadb    server-10.1/strings/ctype-cp932.c                                                               34609       92 0.265122042592432&#xA;perl       perl-5.22.0/keywords.c                                                                           2815        8 0.283386468296139&#xA;python     Python-2.7.10/Mac/Modules/menu/_Menumodule.c                                                     3263       10 0.305530094714329&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_dutch.c                               596        2 0.334448160535117&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_dutch.c                          586        2 0.340136054421769&#xA;mariadb    server-10.1/strings/ctype-gbk.c                                                                 10684       38 0.354411490393583&#xA;python     Python-2.7.10/Mac/Modules/qd/_Qdmodule.c                                                         6694       24 0.357249181303959&#xA;python     Python-2.7.10/Mac/Modules/win/_Winmodule.c                                                       3056       11 0.358656667753505&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_german.c                              476        2 0.418410041841004&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_german.c                         470        2 0.423728813559322&#xA;mariadb    server-10.1/strings/ctype-euc_kr.c                                                               9956       44 0.44&#xA;postgresql postgresql-9.4.4/src/backend/utils/fmgrtab.c                                                     4815       23 0.475403059115337&#xA;python     Python-2.7.10/Mac/Modules/ctl/_Ctlmodule.c                                                       5442       28 0.511882998171846&#xA;python     Python-2.7.10/Mac/Modules/ae/_AEmodule.c                                                         1347        7 0.51698670605613&#xA;python     Python-2.7.10/Mac/Modules/app/_Appmodule.c                                                       1712        9 0.52295177222545&#xA;mariadb    server-10.1/strings/ctype-gb2312.c                                                               6377       35 0.54585152838428&#xA;mariadb    server-10.1/storage/tokudb/ft-index/third_party/xz-4.999.9beta/src/liblzma/lzma/fastpos_table.c   516        3 0.578034682080925&#xA;python     Python-2.7.10/Mac/Modules/evt/_Evtmodule.c                                                        504        3 0.591715976331361&#xA;python     Python-2.7.10/Modules/expat/xmlrole.c                                                            1256        8 0.632911392405063&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_UTF_8_danish.c                              312        2 0.636942675159236&#xA;postgresql postgresql-9.4.4/src/backend/snowball/libstemmer/stem_ISO_8859_1_danish.c                         310        2 0.641025641025641&#xA;python     Python-2.7.10/Mac/Modules/res/_Resmodule.c                                                       1621       12 0.734843845682792&#xA;python     Python-2.7.10/Mac/Modules/drag/_Dragmodule.c                                                     1046        8 0.759013282732448&#xA;python     Python-2.7.10/Mac/Modules/list/_Listmodule.c                                                     1021        8 0.777453838678329&#xA;python     Python-2.7.10/Mac/Modules/te/_TEmodule.c                                                         1198       10 0.827814569536424&#xA;python     Python-2.7.10/Mac/Modules/cg/_CGmodule.c                                                         1190       10 0.833333333333333&#xA;python     Python-2.7.10/Modules/clmodule.c                                                                 2379       23 0.957535387177352&#xA;python     Python-2.7.10/Mac/Modules/folder/_Foldermodule.c                                                  306        3 0.970873786407767&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;What are the ten longest files (based on code lines) that have no comments at all? Exclude header, .html, and YAML files.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; sqlite3 code.db &#39;select project, file, nCode from t&#xA;                         where nComment = 0 and&#xA;                         language not in (&#34;C/C++ Header&#34;, &#34;YAML&#34;, &#34;HTML&#34;)&#xA;                         order by nCode desc limit 10;&#39; | sqlite_formatter&#xA;&#xA;Project File                                                                 nCode&#xA;_______ ____________________________________________________________________ _____&#xA;perl    perl-5.22.0/cpan/Unicode-Collate/Collate/Locale/ja.pl                 1938&#xA;python  Python-2.7.10/PCbuild/pythoncore.vcproj                               1889&#xA;python  Python-2.7.10/PC/VS8.0/pythoncore.vcproj                              1889&#xA;mariadb server-10.1/mysql-test/extra/binlog_tests/mysqlbinlog_row_engine.inc  1862&#xA;perl    perl-5.22.0/cpan/Unicode-Collate/Collate/Locale/zh_strk.pl            1589&#xA;perl    perl-5.22.0/cpan/Unicode-Collate/Collate/Locale/zh_zhu.pl             1563&#xA;mariadb server-10.1/storage/mroonga/vendor/groonga/configure.ac               1526&#xA;perl    perl-5.22.0/cpan/Unicode-Collate/Collate/Locale/zh_pin.pl             1505&#xA;mariadb server-10.1/mysql-test/suite/funcs_1/storedproc/storedproc_02.inc     1465&#xA;python  Python-2.7.10/PC/VS8.0/_bsddb.vcproj                                  1463&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;What are the most popular languages (in terms of lines of code) in each project?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;prompt&amp;gt; sqlite3 code.db &#39;select project, language, sum(nCode) as SumCode from t&#xA;                         group by project,language&#xA;                         order by project,SumCode desc;&#39; | sqlite_formatter&#xA;Project    Language                  SumCode&#xA;__________ _________________________ _______&#xA;mariadb    C++                        983026&#xA;mariadb    C                          715018&#xA;mariadb    C/C++ Header               209394&#xA;mariadb    Bourne Shell                61943&#xA;mariadb    Perl                        35562&#xA;mariadb    Pascal                      32541&#xA;mariadb    HTML                        16489&#xA;mariadb    Javascript                  15540&#xA;mariadb    m4                          14215&#xA;mariadb    CMake                       12206&#xA;mariadb    XML                          5210&#xA;mariadb    Ruby                         4998&#xA;mariadb    Puppet                       3848&#xA;mariadb    make                         3631&#xA;mariadb    SQL                          3405&#xA;mariadb    Python                       2545&#xA;mariadb    Bourne Again Shell           1604&#xA;mariadb    Windows Module Definition    1211&#xA;mariadb    lex                           991&#xA;mariadb    yacc                          810&#xA;mariadb    DOS Batch                     700&#xA;mariadb    Prolog                        448&#xA;mariadb    RobotFramework                441&#xA;mariadb    CSS                           393&#xA;mariadb    JSON                          359&#xA;mariadb    dtrace                        306&#xA;mariadb    Windows Resource File         250&#xA;mariadb    Assembly                      237&#xA;mariadb    WiX source                    155&#xA;mariadb    Visual Basic                   88&#xA;mariadb    YAML                           65&#xA;mariadb    PHP                            24&#xA;mariadb    SKILL                          16&#xA;mariadb    sed                            16&#xA;mariadb    Windows Message File            6&#xA;mariadb    D                               4&#xA;mariadb    diff                            4&#xA;perl       Perl                       536445&#xA;perl       C                          155648&#xA;perl       C/C++ Header               147858&#xA;perl       Bourne Shell                42668&#xA;perl       Pascal                       8592&#xA;perl       XML                          2410&#xA;perl       YAML                         2078&#xA;perl       C++                          2033&#xA;perl       make                         1986&#xA;perl       Prolog                       1146&#xA;perl       JSON                         1037&#xA;perl       yacc                          998&#xA;perl       Windows Message File          489&#xA;perl       DOS Batch                     389&#xA;perl       Windows Resource File          85&#xA;perl       D                               8&#xA;perl       Lisp                            4&#xA;postgresql HTML                       785991&#xA;postgresql C                          736519&#xA;postgresql C/C++ Header                57014&#xA;postgresql SQL                         51926&#xA;postgresql yacc                        28491&#xA;postgresql Bourne Shell                17170&#xA;postgresql Perl                         9456&#xA;postgresql lex                          4285&#xA;postgresql make                         4114&#xA;postgresql m4                           1642&#xA;postgresql Windows Module Definition    1152&#xA;postgresql XSLT                          294&#xA;postgresql DOS Batch                      92&#xA;postgresql Assembly                       69&#xA;postgresql CSS                            69&#xA;postgresql D                              66&#xA;postgresql Windows Resource File          62&#xA;postgresql Lisp                           16&#xA;postgresql sed                            15&#xA;postgresql Python                         13&#xA;postgresql Bourne Again Shell             10&#xA;postgresql Windows Message File            5&#xA;python     Python                     434015&#xA;python     C                          375555&#xA;python     C/C++ Header                66942&#xA;python     Bourne Shell                45091&#xA;python     MSBuild script              38910&#xA;python     m4                          15559&#xA;python     Assembly                    12298&#xA;python     make                         2953&#xA;python     HTML                         2344&#xA;python     Windows Module Definition    2081&#xA;python     Objective-C                   635&#xA;python     Expect                        565&#xA;python     DOS Batch                     506&#xA;python     CSS                           328&#xA;python     Javascript                    229&#xA;python     Windows Resource File         207&#xA;python     C++                           128&#xA;python     vim script                    106&#xA;python     diff                          105&#xA;python     XML                            74&#xA;python     NAnt script                    30&#xA;python     Prolog                         24&#xA;python     Visual Basic                   12&#xA;sqlite     C                          101454&#xA;sqlite     C/C++ Header                 1546&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;custom_column_output&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Custom Column Output ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Cloc&#39;s default output is a text table with five columns: language, file count, number of blank lines, number of comment lines and number of code lines. The switches &lt;code&gt;--by-file&lt;/code&gt;, &lt;code&gt;--3&lt;/code&gt;, and &lt;code&gt;--by-percent&lt;/code&gt; generate additional information but sometimes even those are insufficient.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;--sql&lt;/code&gt; option described in the previous section offers the ability to create custom output. This section has a pair of examples that show how to create custom columns. The first example includes an extra column, &lt;strong&gt;Total&lt;/strong&gt;, which is the sum of the numbers of blank, comment, and code lines. The second shows how to include the language name when running with &lt;code&gt;--by-file&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 1: Add a &#34;Totals&#34; column.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The first step is to run cloc and save the output to a relational database, SQLite in this case:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;cloc --sql 1 --sql-project x yaml-cpp-yaml-cpp-0.5.3.tar.gz | sqlite3 counts.db&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;(the tar file comes from the &lt;a href=&#34;https://github.com/jbeder/yaml-cpp&#34;&gt;YAML-C++&lt;/a&gt; project).&lt;/p&gt; &#xA;&lt;p&gt;Second, we craft an SQL query that returns the regular cloc output plus an extra column for totals, then save the SQL statement to a file, &lt;code&gt;query_with_totals.sql&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;-- file query_with_totals.sql&#xA;select Language, count(File)   as files                       ,&#xA;                 sum(nBlank)   as blank                       ,&#xA;                 sum(nComment) as comment                     ,&#xA;                 sum(nCode)    as code                        ,&#xA;                 sum(nBlank)+sum(nComment)+sum(nCode) as Total&#xA;    from t group by Language order by code desc;&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Third, we run this query through SQLite using the &lt;code&gt;counts.db&lt;/code&gt; database. We&#39;ll include the &lt;code&gt;-header&lt;/code&gt; switch so that SQLite prints the column names:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&amp;gt; cat query_with_totals.sql | sqlite3 -header counts.db&#xA;Language|files|blank|comment|code|Total&#xA;C++|141|12786|17359|60378|90523&#xA;C/C++ Header|110|8566|17420|51502|77488&#xA;Bourne Shell|10|6351|6779|38264|51394&#xA;m4|11|2037|260|17980|20277&#xA;Python|30|1613|2486|4602|8701&#xA;MSBuild script|11|0|0|1711|1711&#xA;CMake|7|155|285|606|1046&#xA;make|5|127|173|464|764&#xA;Markdown|2|30|0|39|69&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;The extra column for &lt;strong&gt;Total&lt;/strong&gt; is there but the format is unappealing. Running the output through &lt;code&gt;sqlite_formatter&lt;/code&gt; yields the desired result:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&amp;gt; cat query_with_totals.sql | sqlite3 -header counts.db | sqlite_formatter&#xA;Language       files blank comment code  Total&#xA;______________ _____ _____ _______ _____ _____&#xA;C++              141 12786   17359 60378 90523&#xA;C/C++ Header     110  8566   17420 51502 77488&#xA;Bourne Shell      10  6351    6779 38264 51394&#xA;m4                11  2037     260 17980 20277&#xA;Python            30  1613    2486  4602  8701&#xA;MSBuild script    11     0       0  1711  1711&#xA;CMake              7   155     285   606  1046&#xA;make               5   127     173   464   764&#xA;Markdown           2    30       0    39    69&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;The next section, &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#wrapping-cloc-in-other-scripts-&#34;&gt;Wrapping cloc in other scripts&lt;/a&gt;, shows one way these commands can be combined into a new utility program.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 2: Include a column for &#34;Language&#34; when running with &lt;code&gt;--by-file&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Output from &lt;code&gt;--by-file&lt;/code&gt; omits each file&#39;s language to save screen real estate; file paths for large projects can be long and including an extra 20 or so characters for a Language column can be excessive.&lt;/p&gt; &#xA;&lt;p&gt;As an example, here are the first few lines of output using the same code base as in Example 1:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&amp;gt; cloc --by-file yaml-cpp-yaml-cpp-0.5.3.tar.gz&#xA;github.com/AlDanial/cloc v 1.81  T=1.14 s (287.9 files/s, 221854.9 lines/s)&#xA;--------------------------------------------------------------------------------------------------------------------------------------------&#xA;File                                                                                                     blank        comment           code&#xA;--------------------------------------------------------------------------------------------------------------------------------------------&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/configure                                                        2580           2264          13691&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/configure                                                  2541           2235          13446&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/fused-src/gtest/gtest.h                                    1972           4681          13408&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/fused-src/gmock/gmock.h                                          1585           3397           9216&#xA;yaml-cpp-yaml-cpp-0.5.3/test/integration/gen_emitter_test.cpp                                              999              0           8760&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/aclocal.m4                                                        987            100           8712&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/m4/libtool.m4                                               760             65           7176&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/build-aux/ltmain.sh                                         959           1533           7169&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/fused-src/gmock-gtest-all.cc                                     1514           3539           6390&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/fused-src/gtest/gtest-all.cc                               1312           2896           5384&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/test/gtest_unittest.cc                                     1226           1091           5098&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/include/gtest/internal/gtest-param-util-generated.h         349            235           4559&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;The absence of language identification for each file is a bit disappointing, but this can be remedied with a custom column solution.&lt;/p&gt; &#xA;&lt;p&gt;The first step, creating a database, matches that from Example 1 so we&#39;ll go straight to the second step of creating the desired SQL query. We&#39;ll store this one in the file &lt;code&gt;by_file_with_language.sql&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;-- file by_file_with_language.sql&#xA;select File, Language, nBlank   as blank  ,&#xA;                       nComment as comment,&#xA;                       nCode    as code&#xA;    from t order by code desc;&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Our desired extra column appears when we pass this custom SQL query through our database:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;&amp;gt; cat by_file_with_language.sql | sqlite3 -header counts.db | sqlite_formatter&#xA;File                                                                                               Language       blank comment code&#xA;__________________________________________________________________________________________________ ______________ _____ _______ _____&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/configure                                                 Bourne Shell    2580    2264 13691&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/configure                                           Bourne Shell    2541    2235 13446&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/fused-src/gtest/gtest.h                             C/C++ Header    1972    4681 13408&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/fused-src/gmock/gmock.h                                   C/C++ Header    1585    3397  9216&#xA;yaml-cpp-yaml-cpp-0.5.3/test/integration/gen_emitter_test.cpp                                      C++              999       0  8760&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/aclocal.m4                                                m4               987     100  8712&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/m4/libtool.m4                                       m4               760      65  7176&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/build-aux/ltmain.sh                                 Bourne Shell     959    1533  7169&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/fused-src/gmock-gtest-all.cc                              C++             1514    3539  6390&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/fused-src/gtest/gtest-all.cc                        C++             1312    2896  5384&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/test/gtest_unittest.cc                              C++             1226    1091  5098&#xA;yaml-cpp-yaml-cpp-0.5.3/test/gmock-1.7.0/gtest/include/gtest/internal/gtest-param-util-generated.h C/C++ Header     349     235  4559&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;wrapping_cloc_in_other_scripts&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt; * &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#wrapping-cloc-in-other-scripts-&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Wrapping cloc in other scripts ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;More complex code counting solutions are possible by wrapping cloc in scripts or programs. The &#34;total lines&#34; column from example 1 of &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#custom-column-output-&#34;&gt;Custom Column Output&lt;/a&gt; could be simplified to a single command with this shell script (on Linux):&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;#!/bin/sh&#xA;#&#xA;# These commands must be in the user&#39;s $PATH:&#xA;#   cloc&#xA;#   sqlite3&#xA;#   sqlite_formatter&#xA;#&#xA;if test $# -eq 0 ; then&#xA;    echo &#34;Usage: $0  [cloc arguments]&#34;&#xA;    echo &#34;       Run cloc to count lines of code with an additional&#34;&#xA;    echo &#34;       output column for total lines (code+comment+blank).&#34;&#xA;    exit&#xA;fi&#xA;DBFILE=`tempfile`&#xA;cloc --sql 1 --sql-project x $@ | sqlite3 ${DBFILE}&#xA;SQL=&#34;select Language, count(File)   as files                       ,&#xA;                      sum(nBlank)   as blank                       ,&#xA;                      sum(nComment) as comment                     ,&#xA;                      sum(nCode)    as code                        ,&#xA;                      sum(nBlank)+sum(nComment)+sum(nCode) as Total&#xA;         from t group by Language order by code desc;&#xA;&#34;&#xA;echo ${SQL} | sqlite3 -header ${DBFILE} | sqlite_formatter&#xA;rm ${DBFILE}&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Saving the lines above to &lt;code&gt;total_columns.sh&lt;/code&gt; and making it executable (&lt;code&gt;chmod +x total_columns.sh&lt;/code&gt;) would let us do&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;./total_columns.sh yaml-cpp-yaml-cpp-0.5.3.tar.gz&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;to directly get&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;Language       files blank comment code  Total&#xA;______________ _____ _____ _______ _____ _____&#xA;C++              141 12786   17359 60378 90523&#xA;C/C++ Header     110  8566   17420 51502 77488&#xA;Bourne Shell      10  6351    6779 38264 51394&#xA;m4                11  2037     260 17980 20277&#xA;Python            30  1613    2486  4602  8701&#xA;MSBuild script    11     0       0  1711  1711&#xA;CMake              7   155     285   606  1046&#xA;make               5   127     173   464   764&#xA;Markdown           2    30       0    39    69&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Other examples:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Count code from a specific branch of a web-hosted git repository and send the results as a .csv email attachment: &lt;a href=&#34;https://github.com/dannyloweatx/checkmarx&#34;&gt;https://github.com/dannyloweatx/checkmarx&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;git_and_UTF8_pathnames&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;git and UTF8 pathnames ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;cloc&#39;s &lt;code&gt;--git&lt;/code&gt; option may fail if you work with directory or file names with UTF-8 characters (for example, see &lt;a href=&#34;https://github.com/AlDanial/cloc/issues/457&#34;&gt;issue 457&lt;/a&gt;). The solution, &lt;a href=&#34;https://stackoverflow.com/questions/22827239/how-to-make-git-properly-display-utf-8-encoded-pathnames-in-the-console-window&#34;&gt;https://stackoverflow.com/questions/22827239/how-to-make-git-properly-display-utf-8-encoded-pathnames-in-the-console-window&lt;/a&gt;, is to apply this git configuration command:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;git config --global core.quotepath off&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Your console&#39;s font will need to be capable of displaying Unicode characters.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;scale_factors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Third Generation Language Scale Factors ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;cloc versions before 1.50 by default computed, for the provided inputs, a rough estimate of how many lines of code would be needed to write the same code in a hypothetical third-generation computer language. To produce this output one must now use the &lt;code&gt;--3&lt;/code&gt; switch.&lt;/p&gt; &#xA;&lt;p&gt;Scale factors were derived from the 2006 version of language gearing ratios listed at Mayes Consulting web site, &lt;a href=&#34;http://softwareestimator.com/IndustryData2.htm&#34;&gt;http://softwareestimator.com/IndustryData2.htm&lt;/a&gt;, using this equation:&lt;/p&gt; &#xA;&lt;p&gt;cloc scale factor for language X = 3rd generation default gearing ratio / language X gearing ratio&lt;/p&gt; &#xA;&lt;p&gt;For example, cloc 3rd generation scale factor for DOS Batch = 80 / 128 = 0.625.&lt;/p&gt; &#xA;&lt;p&gt;The biggest flaw with this approach is that gearing ratios are defined for logical lines of source code not physical lines (which cloc counts). The values in cloc&#39;s &#39;scale&#39; and &#39;3rd gen. equiv.&#39; columns should be taken with a large grain of salt.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;options_txt&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;options.txt configuration file ▲&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;If you find yourself using the same command line switches every time you invoke cloc, you can save some typing by adding those switches to the &lt;code&gt;options.txt&lt;/code&gt; runtime configuration file. cloc will look for this file in the following default locations:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;# Linux, NetBSD, FreeBSD, macOS:&#xA;/home/USERNAME/.config/cloc/options.txt&#xA;&#xA;# Windows&#xA;C:\Users\USERNAME\AppData\cloc\options.txt&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;Place each switch and arguments, if any, on a line by itself. Lines prefixed with &lt;code&gt;#&lt;/code&gt; symbol are ignored as comments and blank lines are skipped. Leading hyphens on the switches are optional. Here&#39;s a sample file:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;# options.txt&#xA;--vcs git&#xA;v      # verbose level 1&#xA;exclude-ext svg,html&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;The path to the &lt;code&gt;options.txt&lt;/code&gt; file can also be specified with the &lt;code&gt;--config FILE&lt;/code&gt; switch.&lt;/p&gt; &#xA;&lt;p&gt;Finally, if cloc finds an &lt;code&gt;options.txt&lt;/code&gt; file in the same directory as files given by any of these switches (in the listed priority), it will use that configuration file from that location:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;--list-file&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--exclude-list-file&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--read-lang-def&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--force-lang-def&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--diff-list-file&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Run with &lt;code&gt;--verbose&lt;/code&gt; to have cloc tell you which, if any, &lt;code&gt;options.txt&lt;/code&gt; file it uses.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;complex_regex_recursion&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Complex regular subexpression recursion limit ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;cloc relies on the Regexp::Common module&#39;s regular expressions to remove comments from source code. If comments are malformed, for example the &lt;code&gt;/*&lt;/code&gt; start comment marker appears in a C program without a corresponding &lt;code&gt;*/&lt;/code&gt; marker, the regular expression engine could enter a recursive loop, eventually triggering the warning &lt;code&gt;Complex regular subexpression recursion limit&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The most common cause for this warning is the existence of comment markers in string literals. While language compilers and interpreters are smart enough to recognize that &lt;code&gt;&#34;/*&#34;&lt;/code&gt; (for example) is a string and not a comment, cloc is fooled. File path globs, as in this line of JavaScript&lt;/p&gt; &#xA;&lt;pre&gt;var paths = globArray(&#34;**/*.js&#34;, {cwd: srcPath});&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;are frequent culprits.&lt;/p&gt; &#xA;&lt;p&gt;In an attempt to overcome this problem, a different algorithm which removes comment markers in strings can be enabled with the &lt;code&gt;--strip-str-comments&lt;/code&gt; switch. Doing so, however, has drawbacks: cloc will run more slowly and the output of &lt;code&gt;--strip-comments&lt;/code&gt; will contain strings that no longer match the input source.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;Limitations&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Limitations ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Identifying comments within source code is trickier than one might expect. Many languages would need a complete parser to be counted correctly. cloc does not attempt to parse any of the languages it aims to count and therefore is an imperfect tool. The following are known problems:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; Lines containing both source code and comments are counted as lines of code. &lt;/li&gt; &#xA; &lt;li&gt; Comment markers within strings or &lt;a href=&#34;http://www.faqs.org/docs/abs/HTML/here-docs.html&#34;&gt;here-documents&lt;/a&gt; are treated as actual comment markers and not string literals. For example the following lines of C code &lt;pre&gt;printf(&#34; /* &#34;);&#xA;for (i = 0; i &amp;lt; 100; i++) {&#xA;    a += i;&#xA;}&#xA;printf(&#34; */ &#34;);&#xA;&lt;/pre&gt; look to cloc like this: &lt;pre&gt;printf(&#34; xxxxxxx&#xA;xxxxxxx&#xA;xxxxxxx&#xA;xxxxxxx&#xA;xxxxxxx     &#34;);&#xA;&lt;/pre&gt; where &lt;tt&gt;xxxxxxx&lt;/tt&gt; represents cloc&#39;s view of commented text. Therefore cloc counts the five lines as two lines of C code and three lines of comments (lines with both code and comment are counted as code). &lt;p&gt;If you suspect your code has such strings, use the switch &lt;code&gt;--strip-str-comments&lt;/code&gt; to switch to the algorithm which removes embedded comment markers. Its use will render the five lines above as&lt;/p&gt; &lt;pre&gt;printf(&#34;  &#34;);&#xA;for (i = 0; i &amp;lt; 100; i++) {&#xA;    a += i;&#xA;}&#xA;printf(&#34;  &#34;);&#xA;&lt;/pre&gt; &lt;p&gt;and therefore return a count of five lines of code. See the &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#complex-regular-subexpression-recursion-limit-&#34;&gt;previous section&lt;/a&gt; on drawbacks to using &lt;code&gt;--strip-str-comments&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; Embedded languages are not recognized. For example, an HTML file containing JavaScript will be counted entirely as HTML. &lt;/li&gt; &#xA; &lt;li&gt; Python docstrings can serve several purposes. They may contain documentation, comment out blocks of code, or they can be regular strings (when they appear on the right hand side of an assignment or as a function argument). cloc is unable to infer the meaning of docstrings by context; by default cloc treats all docstrings as comments. The switch &lt;tt&gt;--docstring-as-code&lt;/tt&gt; treats all docstrings as code. &lt;/li&gt; &#xA; &lt;li&gt; Language definition files read with &lt;tt&gt;--read-lang-def&lt;/tt&gt; or &lt;tt&gt;--force-lang-def&lt;/tt&gt; must be plain ASCII text files. &lt;/li&gt; &#xA; &lt;li&gt; cloc treats compiler pragma&#39;s, for example &lt;tt&gt;#if&lt;/tt&gt; / &lt;tt&gt;#endif&lt;/tt&gt;, as code even if these are used to block lines of source from being compiled; the blocked lines still contribute to the code count. &lt;/li&gt; &#xA; &lt;li&gt; On Windows, cloc will fail with &lt;tt&gt;Can&#39;t cd to ... No such file or directory at &#xA;   &lt;embedded&gt;&#xA;    /File/Find.pm&#xA;   &lt;/embedded&gt;&lt;/tt&gt; if the code being scanned has file paths longer than 255 characters. A work-around is to run cloc from the Windows Subsystem for Linux (WSL). &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;AdditionalLanguages&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Requesting Support for Additional Languages ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;If cloc does not recognize a language you are interested in counting, create a &lt;a href=&#34;https://github.com/AlDanial/cloc/issues&#34;&gt;GitHub issue&lt;/a&gt; requesting support for your language. Include this information:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; File extensions associated with the language. If the language does not rely on file extensions and instead works with fixed file names or with `#!` style program invocations, explain what those are.&lt;/li&gt; &#xA; &lt;li&gt; A description of how comments are defined.&lt;/li&gt; &#xA; &lt;li&gt; Links to sample code.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;reporting_problems&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Reporting Problems ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;If you encounter a problem with cloc, first check to see if you&#39;re running with the latest version of the tool:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;  cloc --version&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;If the version is older than the most recent release at &lt;a href=&#34;https://github.com/AlDanial/cloc/releases&#34;&gt;https://github.com/AlDanial/cloc/releases&lt;/a&gt;, download the latest version and see if it solves your problem.&lt;/p&gt; &#xA;&lt;p&gt;If the problem happens with the latest release, submit a new issue at &lt;a href=&#34;https://github.com/AlDanial/cloc/issues&#34;&gt;https://github.com/AlDanial/cloc/issues&lt;/a&gt; &lt;em&gt;only&lt;/em&gt; if you can supply enough information for anyone reading the issue report to reproduce the problem. That means providing&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; the operating system you&#39;re running on&lt;/li&gt; &#xA; &lt;li&gt; the cloc command with all options&lt;/li&gt; &#xA; &lt;li&gt; the code you are counting (URL to a public git repo or zip file or tar file, et cetera)&lt;/li&gt; &#xA;&lt;/ol&gt; The last item is generally problematic. If the code base is proprietary or amounts to more than a few dozen kilobytes, you&#39;ll need to try to reconstruct similar inputs or demonstrate the problem with an existing public code base. &#xA;&lt;p&gt;Problem reports that cannot be reproduced will be ignored and eventually closed.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;citation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Citation ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Please use the following bibtex entry to cite cloc in a publication:&lt;/p&gt; &#xA;&lt;pre&gt;&#xA;@software{adanial_cloc,&#xA;  author       = {Albert Danial},&#xA;  title        = {cloc: v1.92},&#xA;  month        = dec,&#xA;  year         = 2021,&#xA;  publisher    = {Zenodo},&#xA;  version      = {v1.92},&#xA;  doi          = {10.5281/zenodo.5760077},&#xA;  url          = {https://doi.org/10.5281/zenodo.5760077}&#xA;}&#xA;&lt;/pre&gt; &#xA;&lt;p&gt;(Update the version number and corresponding year if this entry is outdated.)&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;Acknowledgments&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Acknowledgments ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/wolframroesler&#34;&gt;Wolfram Rösler&lt;/a&gt; provided most of the code examples in the test suite. These examples come from his &lt;a href=&#34;http://helloworldcollection.de/&#34;&gt;Hello World collection&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Ismet Kursunoglu found errors with the MUMPS counter and provided access to a computer with a large body of MUMPS code to test cloc.&lt;/p&gt; &#xA;&lt;p&gt;Tod Huggins gave helpful suggestions for the Visual Basic filters.&lt;/p&gt; &#xA;&lt;p&gt;Anton Demichev found a flaw with the JSP counter in cloc v0.76 and wrote the XML output generator for the &lt;code&gt;--xml&lt;/code&gt; option.&lt;/p&gt; &#xA;&lt;p&gt;Reuben Thomas pointed out that ISO C99 allows &lt;code&gt;//&lt;/code&gt; as a comment marker, provided code for the &lt;code&gt;--no3&lt;/code&gt; and &lt;code&gt;--stdin-name&lt;/code&gt; options, counting the m4 language, and suggested several user-interface enhancements.&lt;/p&gt; &#xA;&lt;p&gt;Michael Bello provided code for the &lt;code&gt;--opt-match-f&lt;/code&gt;, &lt;code&gt;--opt-not-match-f&lt;/code&gt;, &lt;code&gt;--opt-match-d&lt;/code&gt;, and &lt;code&gt;--opt-not-match-d&lt;/code&gt; options.&lt;/p&gt; &#xA;&lt;p&gt;Mahboob Hussain inspired the &lt;code&gt;--original-dir&lt;/code&gt; and &lt;code&gt;--skip-uniqueness&lt;/code&gt; options, found a bug in the duplicate file detection logic and improved the JSP filter.&lt;/p&gt; &#xA;&lt;p&gt;Randy Sharo found and fixed an uninitialized variable bug for shell scripts having only one line.&lt;/p&gt; &#xA;&lt;p&gt;Steven Baker found and fixed a problem with the YAML output generator.&lt;/p&gt; &#xA;&lt;p&gt;Greg Toth provided code to improve blank line detection in COBOL.&lt;/p&gt; &#xA;&lt;p&gt;Joel Oliveira provided code to let &lt;code&gt;--exclude-list-file&lt;/code&gt; handle directory name exclusion.&lt;/p&gt; &#xA;&lt;p&gt;Blazej Kroll provided code to produce an XSLT file, &lt;code&gt;cloc-diff.xsl&lt;/code&gt;, when producing XML output for the &lt;code&gt;--diff&lt;/code&gt; option.&lt;/p&gt; &#xA;&lt;p&gt;Denis Silakov enhanced the code which generates &lt;code&gt;cloc.xsl&lt;/code&gt; when using &lt;code&gt;--by-file&lt;/code&gt; and &lt;code&gt;--by-file-by-lang&lt;/code&gt; options, and provided an XSL file that works with &lt;code&gt;--diff&lt;/code&gt; output.&lt;/p&gt; &#xA;&lt;p&gt;Andy (&lt;a href=&#34;mailto:awalshe@sf.net&#34;&gt;awalshe@sf.net&lt;/a&gt;) provided code to fix several bugs: correct output of &lt;code&gt;--counted&lt;/code&gt; so that only files that are used in the code count appear and that results are shown by language rather than file name; allow &lt;code&gt;--diff&lt;/code&gt; output from multiple runs to be summed together with &lt;code&gt;--sum-reports&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Jari Aalto created the initial version of &lt;code&gt;cloc.1.pod&lt;/code&gt; and maintains the Debian package for cloc.&lt;/p&gt; &#xA;&lt;p&gt;Mikkel Christiansen (&lt;a href=&#34;mailto:mikkels@gmail.com&#34;&gt;mikkels@gmail.com&lt;/a&gt;) provided counter definitions for Clojure and ClojureScript.&lt;/p&gt; &#xA;&lt;p&gt;Vera Djuraskovic from &lt;a href=&#34;http://webhostinggeeks.com/&#34;&gt;Webhostinggeeks.com&lt;/a&gt; provided the &lt;a href=&#34;http://science.webhostinggeeks.com/cloc&#34;&gt;Serbo-Croatian&lt;/a&gt; translation.&lt;/p&gt; &#xA;&lt;p&gt;Gill Ajoft of &lt;a href=&#34;http://www.ajoft.com&#34;&gt;Ajoft Softwares&lt;/a&gt; provided the &lt;a href=&#34;http://www.ajoft.com/wpaper/aj-cloc.html&#34;&gt;Bulgarian&lt;/a&gt; translation.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;http://newknowledgez.com/&#34;&gt;Knowledge Team&lt;/a&gt; provided the &lt;a href=&#34;http://newknowledgez.com/cloc.html&#34;&gt;Slovakian&lt;/a&gt; translation.&lt;/p&gt; &#xA;&lt;p&gt;Erik Gooven Arellano Casillas provided an update to the MXML counter to recognize ActionScript comments.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://g14n.info&#34;&gt;Gianluca Casati&lt;/a&gt; created the &lt;a href=&#34;https://metacpan.org/pod/App::cloc&#34;&gt;cloc CPAN package&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!-- broken link&#xA;Mary Stefanova provided the&#xA;[Polish](http://www.trevister.com/blog/cloc.html)&#xA;translation. ---&gt; &#xA;&lt;p&gt;Ryan Lindeman implemented the &lt;code&gt;--by-percent&lt;/code&gt; feature.&lt;/p&gt; &#xA;&lt;p&gt;Kent C. Dodds, &lt;a href=&#34;https://twitter.com/kentcdodd&#34;&gt;@kentcdodds&lt;/a&gt;, created and maintains the npm package of cloc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://kudoybook.com&#34;&gt;Viktoria Parnak&lt;/a&gt; provided the &lt;a href=&#34;http://blog.kudoybook.com/cloc/&#34;&gt;Ukrainian&lt;/a&gt; translation.&lt;/p&gt; &#xA;&lt;p&gt;Natalie Harmann provided the &lt;a href=&#34;http://www.besteonderdelen.nl/blog/?p=5426&#34;&gt;Belarussian&lt;/a&gt; translation.&lt;/p&gt; &#xA;&lt;p&gt;Nithyal at &lt;a href=&#34;http://healthcareadministrationdegree.co/&#34;&gt;Healthcare Administration Portal&lt;/a&gt; provided the &lt;a href=&#34;http://healthcareadministrationdegree.co/socialwork/aldanial-cloc/&#34;&gt;Tamil&lt;/a&gt; translation.&lt;/p&gt; &#xA;&lt;p&gt;Patricia Motosan provided the &lt;a href=&#34;http://www.bildelestore.dk/blog/cloc-contele-de-linii-de-cod/&#34;&gt;Romanian&lt;/a&gt; translation.&lt;/p&gt; &#xA;&lt;!-- broken link&#xA;The [Garcinia Cambogia Review Team](http://www.garciniacambogiareviews.ca/)&#xA;provided the&#xA;[Arabic translation](http://www.garciniacambogiareviews.ca/translations/aldanial-cloc/). ---&gt; &#xA;&lt;p&gt;Gajk Melikyan provided the provided the &lt;a href=&#34;http://students.studybay.com/?p=34&#34;&gt;Armenian translation&lt;/a&gt; for &lt;a href=&#34;http://studybay.com&#34;&gt;http://studybay.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.forallworld.com/cloc-grof-sornyi-kodot/&#34;&gt;Hungarian translation&lt;/a&gt; courtesy of &lt;a href=&#34;http://www.forallworld.com/&#34;&gt;Zsolt Boros&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/stsnel&#34;&gt;Sietse Snel&lt;/a&gt; implemented the parallel processing capability available with the &lt;tt&gt;--processes=&lt;i&gt;N&lt;/i&gt;&lt;/tt&gt; switch.&lt;/p&gt; &#xA;&lt;p&gt;The development of cloc was partially funded by the Northrop Grumman Corporation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt; &lt;a name=&#34;Copyright&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/%7B%7B%7B1&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/#___top&#34; title=&#34;click to go to top of document&#34;&gt;Copyright ▲&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Copyright (c) 2006-2018, &lt;a href=&#34;https://github.com/AlDanial&#34;&gt;Al Danial&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/AlDanial/cloc/master/1%7D%7D%7D&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ZeWaren/pSSOd</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/ZeWaren/pSSOd</id>
    <link href="https://github.com/ZeWaren/pSSOd" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Scripts to synchronize users and groups from Active Directory with virtually anything&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;pSSOd&lt;/h1&gt; &#xA;&lt;p&gt;pSSOd is a collection of scripts that you can use to synchronize an Active Directory database (including passwords) with virtually everything, be it a sql database, an openldap server, a text file, or a samba passdb file.&lt;/p&gt; &#xA;&lt;h2&gt;How does it work&lt;/h2&gt; &#xA;&lt;p&gt;pSSOd is composed of several perl scripts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;perlsync.pl&lt;/code&gt;: fetches the user and groups from AD (excluding passwords, since you just can&#39;t).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;perlssod.pl&lt;/code&gt;: provides a server for the &lt;em&gt;Password Synchronization&lt;/em&gt; module from the role &lt;em&gt;Microsoft Identity Management for UNIX&lt;/em&gt;, so you can get plain text passwords when they change.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For now, you can find more information at: &lt;a href=&#34;http://zewaren.net/site/?q=node/92&#34;&gt;http://zewaren.net/site/?q=node/92&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Copy the perl files where you desire and run/start them as you wish.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;perlsync.pl&lt;/code&gt; can be called periodically using cron if you run it on an UNIX platform.&lt;/p&gt; &#xA;&lt;h3&gt;Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;You will need Perl and the following modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Net::LDAP&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Digest::SHA1&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Crypt::ECB&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Crypt::DES&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MIME::Base64&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Log::Log4perl&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Data::Dumper&lt;/code&gt; (if you first want to dump the data)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;DBI&lt;/code&gt; and the relevant drivers (if you want to store the information into a SQL database)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Apache::Htpasswd&lt;/code&gt; and &lt;code&gt;Apache::Htgroup&lt;/code&gt; (if you want to store the information into htpasswd and htgroup files)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Debian (squeeze)&lt;/h4&gt; &#xA;&lt;p&gt;Install the following packages using aptitude or dpkg:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;libnet-ldap-perl&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libnet-server-perl&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libdigest-sha1-perl&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libcrypt-ecb-perl&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libcrypt-des-perl&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;liblog-log4perl-perl&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libdbi-perl&lt;/code&gt; and the relevant drivers (&lt;code&gt;libdbd-mysql-perl&lt;/code&gt;, &lt;code&gt;libdbd-pg-perl&lt;/code&gt;, &lt;code&gt;libdbd-sqlite3-perl&lt;/code&gt;, etc.) (if you want to store the information into a SQL database)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libapache-htpasswd-perl&lt;/code&gt; (if you want to store the information into htpasswd and htgroup files)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Install the following modules using cpan:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Apache::Htgroup&lt;/code&gt; (if you want to store the information into htpasswd and htgroup files)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;FreeBSD (8 and later)&lt;/h4&gt; &#xA;&lt;p&gt;Install the following ports:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;net/p5-perl-ldap&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;net/p5-Net-Server&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;security/p5-Digest-SHA1&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;security/p5-Crypt-ECB&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;security/p5-Crypt-DES&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;devel/p5-Log-Log4perl&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;databases/p5-DBI&lt;/code&gt; and the relevant drivers (&lt;code&gt;databases/p5-DBD-mysql&lt;/code&gt;, &lt;code&gt;databases/p5-DBD-Pg&lt;/code&gt;, &lt;code&gt;databases/p5-DBD-SQLite&lt;/code&gt;, etc.) (if you want to store the information into a SQL database)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;security/p5-Apache-Htpasswd&lt;/code&gt; and &lt;code&gt;www/p5-Apache-Htgroup&lt;/code&gt; (if you want to store the information into htpasswd and htgroup files)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;CentOS&lt;/h4&gt; &#xA;&lt;p&gt;Thank Marcos Carraro for the list:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;yum install perl-LDAP&lt;/li&gt; &#xA; &lt;li&gt;yum install perl-Digest-SHA1.x86_64&lt;/li&gt; &#xA; &lt;li&gt;yum install perl-Crypt-ECB&lt;/li&gt; &#xA; &lt;li&gt;yum install perl-Crypt-DES&lt;/li&gt; &#xA; &lt;li&gt;yum install perl-MIME-Base64&lt;/li&gt; &#xA; &lt;li&gt;yum install perl-Log-Log4perl&lt;/li&gt; &#xA; &lt;li&gt;yum install perl-Data-Dumper&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Non technical information&lt;/h2&gt; &#xA;&lt;p&gt;pSSOd was written in September 2012 by: ZeWaren / Erwan Martin &amp;lt;&lt;a href=&#34;mailto:public@fzwte.net&#34;&gt;public@fzwte.net&lt;/a&gt;&amp;gt;.&lt;/p&gt; &#xA;&lt;p&gt;It is licensed under the MIT License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Perl/perl5</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/Perl/perl5</id>
    <link href="https://github.com/Perl/perl5" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🐫 The Perl programming language&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Perl is Copyright (C) 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022 by Larry Wall and others. All rights reserved.&lt;/p&gt; &#xA;&lt;h1&gt;ABOUT PERL&lt;/h1&gt; &#xA;&lt;p&gt;Perl is a general-purpose programming language originally developed for text manipulation and now used for a wide range of tasks including system administration, web development, network programming, GUI development, and more.&lt;/p&gt; &#xA;&lt;p&gt;The language is intended to be practical (easy to use, efficient, complete) rather than beautiful (tiny, elegant, minimal). Its major features are that it&#39;s easy to use, supports both procedural and object-oriented (OO) programming, has powerful built-in support for text processing, and has one of the world&#39;s most impressive collections of third-party modules.&lt;/p&gt; &#xA;&lt;p&gt;For an introduction to the language&#39;s features, see pod/perlintro.pod.&lt;/p&gt; &#xA;&lt;p&gt;For a discussion of the important changes in this release, see pod/perldelta.pod.&lt;/p&gt; &#xA;&lt;p&gt;There are also many Perl books available, covering a wide variety of topics, from various publishers. See pod/perlbook.pod for more information.&lt;/p&gt; &#xA;&lt;h1&gt;INSTALLATION&lt;/h1&gt; &#xA;&lt;p&gt;If you&#39;re using a relatively modern operating system and want to install this version of Perl locally, run the following commands:&lt;/p&gt; &#xA;&lt;p&gt;./Configure -des -Dprefix=$HOME/localperl make test make install&lt;/p&gt; &#xA;&lt;p&gt;This will configure and compile perl for your platform, run the regression tests, and install perl in a subdirectory &#34;localperl&#34; of your home directory.&lt;/p&gt; &#xA;&lt;p&gt;If you run into any trouble whatsoever or you need to install a customized version of Perl, you should read the detailed instructions in the &#34;INSTALL&#34; file that came with this distribution. Additionally, there are a number of &#34;README&#34; files with hints and tips about building and using Perl on a wide variety of platforms, some more common than others.&lt;/p&gt; &#xA;&lt;p&gt;Once you have Perl installed, a wealth of documentation is available to you through the &#39;perldoc&#39; tool. To get started, run this command:&lt;/p&gt; &#xA;&lt;p&gt;perldoc perl&lt;/p&gt; &#xA;&lt;h1&gt;IF YOU RUN INTO TROUBLE&lt;/h1&gt; &#xA;&lt;p&gt;Perl is a large and complex system that&#39;s used for everything from knitting to rocket science. If you run into trouble, it&#39;s quite likely that someone else has already solved the problem you&#39;re facing. Once you&#39;ve exhausted the documentation, please report bugs to us at the GitHub issue tracker at &lt;a href=&#34;https://github.com/Perl/perl5/issues&#34;&gt;https://github.com/Perl/perl5/issues&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;While it was current when we made it available, Perl is constantly evolving and there may be a more recent version that fixes bugs you&#39;ve run into or adds new features that you might find useful.&lt;/p&gt; &#xA;&lt;p&gt;You can always find the latest version of perl on a CPAN (Comprehensive Perl Archive Network) site near you at &lt;a href=&#34;https://www.cpan.org/src/&#34;&gt;https://www.cpan.org/src/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to submit a simple patch to the perl source, see the &#34;SUPER QUICK PATCH GUIDE&#34; in pod/perlhack.pod.&lt;/p&gt; &#xA;&lt;p&gt;Just a personal note: I want you to know that I create nice things like this because it pleases the Author of my story. If this bothers you, then your notion of Authorship needs some revision. But you can use perl anyway. :-)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#x9;&#x9;&#x9;&#x9;&#x9;&#x9;The author.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;LICENSING&lt;/h1&gt; &#xA;&lt;p&gt;This program is free software; you can redistribute it and/or modify it under the terms of either:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;a) the GNU General Public License as published by the Free&#xA;Software Foundation; either version 1, or (at your option) any&#xA;later version, or&#xA;&#xA;b) the &#34;Artistic License&#34; which comes with this Kit.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See either the GNU General Public License or the Artistic License for more details.&lt;/p&gt; &#xA;&lt;p&gt;You should have received a copy of the Artistic License with this Kit, in the file named &#34;Artistic&#34;. If not, I&#39;ll be glad to provide one.&lt;/p&gt; &#xA;&lt;p&gt;You should also have received a copy of the GNU General Public License along with this program in the file named &#34;Copying&#34;. If not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA or visit their web page on the internet at &lt;a href=&#34;https://www.gnu.org/copyleft/gpl.html&#34;&gt;https://www.gnu.org/copyleft/gpl.html&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For those of you that choose to use the GNU General Public License, my interpretation of the GNU General Public License is that no Perl script falls under the terms of the GPL unless you explicitly put said script under the terms of the GPL yourself. Furthermore, any object code linked with perl does not automatically fall under the terms of the GPL, provided such object code only adds definitions of subroutines and variables, and does not otherwise impair the resulting interpreter from executing any standard Perl script. I consider linking in C subroutines in this manner to be the moral equivalent of defining subroutines in the Perl language itself. You may sell such an object file as proprietary provided that you provide or offer to provide the Perl source, as specified by the GNU General Public License. (This is merely an alternate way of specifying input to the program.) You may also sell a binary produced by the dumping of a running Perl script that belongs to you, provided that you provide or offer to provide the Perl source as specified by the GPL. (The fact that a Perl interpreter and your code are in the same binary file is, in this case, a form of mere aggregation.) This is my interpretation of the GPL. If you still have concerns or difficulties understanding my intent, feel free to contact me. Of course, the Artistic License spells all this out for your protection, so you may prefer to use that.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cmatsuoka/asciiquarium</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/cmatsuoka/asciiquarium</id>
    <link href="https://github.com/cmatsuoka/asciiquarium" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Enjoy the mysteries of the sea from the safety of your own terminal!&lt;/p&gt;&lt;hr&gt;&lt;pre&gt;&lt;code&gt;                          Asciiquarium v1.1&#xA;                by Kirk Baucom &amp;lt;kbaucom@schizoid.com&amp;gt;&#xA;                      http://www.robobunny.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Asciiquarium is an aquarium/sea animation in ASCII art.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Asciiquarium is a single perl script, so all you have to do is make sure it&#39;s executable and put it somewhere convenient, like /usr/local/bin or /usr/local/games.&lt;/p&gt; &#xA;&lt;h2&gt;Ubuntu&lt;/h2&gt; &#xA;&lt;p&gt;Out-of-the-box ubuntu doesn&#39;t satisfy the Requirements below, so here&#39;s how to get them:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Get perl&#39;s curses package which is available from apt: sudo apt-get install libcurses-perl&lt;/li&gt; &#xA; &lt;li&gt;Run cpan at the shell. Agree to the defaults for everything. To leave cpan, type quit&lt;/li&gt; &#xA; &lt;li&gt;Type sudo cpan Term::Animation&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;You must have the Term::Animation module, which you can get from &lt;a href=&#34;http://www.cpan.org&#34;&gt;http://www.cpan.org&lt;/a&gt;. The Term::Animation module also requires the Curses module, which you can also get from CPAN. This program will only run on platforms that have a Curses library (so it won&#39;t work on Windows, but you might get it to run under cygwin).&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Command line arguments: -c &#34;classic&#34; mode, only show species from Asciiquarium 1.0&lt;/p&gt; &#xA;&lt;p&gt;While running: q quit r redraw (will recreate all entities) p toggle pause&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;New fish species backported from the Android live wallpaper and other minor improvements by Claudio Matsuoka.&lt;/p&gt; &#xA;&lt;p&gt;Pretty much all of the ASCII art was done by Joan Stark: &lt;a href=&#34;http://www.geocities.com/SoHo/7373/&#34;&gt;http://www.geocities.com/SoHo/7373/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Anything that she didn&#39;t do, I don&#39;t have a source for.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>darold/ora2pg</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/darold/ora2pg</id>
    <link href="https://github.com/darold/ora2pg" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Ora2Pg is a free tool used to migrate an Oracle database to a PostgreSQL compatible schema. It connects your Oracle database, scan it automatically and extracts its structure or data, it then generates SQL scripts that you can load into PostgreSQL.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;NAME Ora2Pg - Oracle to PostgreSQL database schema converter&lt;/p&gt; &#xA;&lt;p&gt;DESCRIPTION Ora2Pg is a free tool used to migrate an Oracle database to a PostgreSQL compatible schema. It connects your Oracle database, scans it automatically and extracts its structure or data, then generates SQL scripts that you can load into your PostgreSQL database.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Ora2Pg can be used for anything from reverse engineering Oracle database&#xA;to huge enterprise database migration or simply replicating some Oracle&#xA;data into a PostgreSQL database. It is really easy to use and doesn&#39;t&#xA;require any Oracle database knowledge other than providing the&#xA;parameters needed to connect to the Oracle database.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;FEATURES Ora2Pg consist of a Perl script (ora2pg) and a Perl module (Ora2Pg.pm), the only thing you have to modify is the configuration file ora2pg.conf by setting the DSN to the Oracle database and optionally the name of a schema. Once that&#39;s done you just have to set the type of export you want: TABLE with constraints, VIEW, MVIEW, TABLESPACE, SEQUENCE, INDEXES, TRIGGER, GRANT, FUNCTION, PROCEDURE, PACKAGE, PARTITION, TYPE, INSERT or COPY, FDW, QUERY, KETTLE, SYNONYM.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;By default Ora2Pg exports to a file that you can load into PostgreSQL&#xA;with the psql client, but you can also import directly into a PostgreSQL&#xA;database by setting its DSN into the configuration file. With all&#xA;configuration options of ora2pg.conf you have full control of what&#xA;should be exported and how.&#xA;&#xA;Features included:&#xA;&#xA;        - Export full database schema (tables, views, sequences, indexes), with&#xA;          unique, primary, foreign key and check constraints.&#xA;        - Export grants/privileges for users and groups.&#xA;        - Export range/list partitions and sub partitions.&#xA;        - Export a table selection (by specifying the table names).&#xA;        - Export Oracle schema to a PostgreSQL 8.4+ schema.&#xA;        - Export predefined functions, triggers, procedures, packages and&#xA;          package bodies.&#xA;        - Export full data or following a WHERE clause.&#xA;        - Full support of Oracle BLOB object as PG BYTEA.&#xA;        - Export Oracle views as PG tables.&#xA;        - Export Oracle user defined types.&#xA;        - Provide some basic automatic conversion of PLSQL code to PLPGSQL.&#xA;        - Works on any platform.&#xA;        - Export Oracle tables as foreign data wrapper tables.&#xA;        - Export materialized view.&#xA;        - Show a  report of an Oracle database content.&#xA;        - Migration cost assessment of an Oracle database.&#xA;        - Migration difficulty level assessment of an Oracle database.&#xA;        - Migration cost assessment of PL/SQL code from a file.&#xA;        - Migration cost assessment of Oracle SQL queries stored in a file.&#xA;        - Generate XML ktr files to be used with Penthalo Data Integrator (Kettle)&#xA;        - Export Oracle locator and spatial geometries into PostGis.&#xA;        - Export DBLINK as Oracle FDW.&#xA;        - Export SYNONYMS as views.&#xA;        - Export DIRECTORY as external table or directory for external_file extension.&#xA;        - Full MySQL export just like Oracle database.&#xA;        - Dispatch a list of SQL orders over multiple PostgreSQL connections&#xA;        - Perform a diff between Oracle and PostgreSQL database for test purpose.&#xA;&#xA;Ora2Pg does its best to automatically convert your Oracle database to&#xA;PostgreSQL but there&#39;s still manual works to do. The Oracle specific&#xA;PL/SQL code generated for functions, procedures, packages and triggers&#xA;has to be reviewed to match the PostgreSQL syntax. You will find some&#xA;useful recommendations on porting Oracle PL/SQL code to PostgreSQL&#xA;PL/PGSQL at &#34;Converting from other Databases to PostgreSQL&#34;, section:&#xA;Oracle (http://wiki.postgresql.org/wiki/Main_Page).&#xA;&#xA;See http://ora2pg.darold.net/report.html for a HTML sample of an Oracle&#xA;database migration report.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;INSTALLATION All Perl modules can always be found at CPAN (&lt;a href=&#34;http://search.cpan.org/&#34;&gt;http://search.cpan.org/&lt;/a&gt;). Just type the full name of the module (ex: DBD::Oracle) into the search input box, it will brings you the page for download.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Releases of Ora2Pg stay at SF.net&#xA;(https://sourceforge.net/projects/ora2pg/).&#xA;&#xA;Under Windows you should install Strawberry Perl&#xA;(http://strawberryperl.com/) and the OSes corresponding Oracle clients.&#xA;Since version 5.32 this Perl distribution include pre-compiled driver of&#xA;DBD::Oracle and DBD::Pg.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Requirement The Oracle Instant Client or a full Oracle installation must be installed on the system. You can download the RPM from Oracle download center:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;    rpm -ivh oracle-instantclient12.2-basic-12.2.0.1.0-1.x86_64.rpm&#xA;    rpm -ivh oracle-instantclient12.2-devel-12.2.0.1.0-1.x86_64.rpm&#xA;    rpm -ivh oracle-instantclient12.2-jdbc-12.2.0.1.0-1.x86_64.rpm&#xA;    rpm -ivh oracle-instantclient12.2-sqlplus-12.2.0.1.0-1.x86_64.rpm&#xA;&#xA;or simply download the corresponding ZIP archives from Oracle download&#xA;center and install them where you want, for example:&#xA;/opt/oracle/instantclient_12_2/&#xA;&#xA;You also need a modern Perl distribution (perl 5.10 and more). To&#xA;connect to a database and proceed to his migration you need the DBI Perl&#xA;module &amp;gt; 1.614. To migrate an Oracle database you need the DBD::Oracle&#xA;Perl modules to be installed. To migrate a MySQL database you need the&#xA;DBD::MySQL Perl modules. These modules are used to connect to the&#xA;database but they are not mandatory if you want to migrate DDL input&#xA;files.&#xA;&#xA;To install DBD::Oracle and have it working you need to have the Oracle&#xA;client libraries installed and the ORACLE_HOME environment variable must&#xA;be defined.&#xA;&#xA;If you plan to export a MySQL database you need to install the Perl&#xA;module DBD::mysql which requires that the mysql client libraries are&#xA;installed.&#xA;&#xA;On some Perl distribution you may need to install the Time::HiRes Perl&#xA;module.&#xA;&#xA;If your distribution doesn&#39;t include these Perl modules you can install&#xA;them using CPAN:&#xA;&#xA;        perl -MCPAN -e &#39;install DBD::Oracle&#39;&#xA;        perl -MCPAN -e &#39;install DBD::MySQL&#39;&#xA;        perl -MCPAN -e &#39;install Time::HiRes&#39;&#xA;&#xA;otherwise use the packages provided by your distribution.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Optional By default Ora2Pg dumps export to flat files, to load them into your PostgreSQL database you need the PostgreSQL client (psql). If you don&#39;t have it on the host running Ora2Pg you can always transfer these files to a host with the psql client installed. If you prefer to load export &#39;on the fly&#39;, the perl module DBD::Pg is required.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Ora2Pg allows you to dump all output in a compressed gzip file, to do&#xA;that you need the Compress::Zlib Perl module or if you prefer using&#xA;bzip2 compression, the program bzip2 must be available in your PATH.&#xA;&#xA;If your distribution doesn&#39;t include these Perl modules you can install&#xA;them using CPAN:&#xA;&#xA;        perl -MCPAN -e &#39;install DBD::Pg&#39;&#xA;        perl -MCPAN -e &#39;install Compress::Zlib&#39;&#xA;&#xA;otherwise use the packages provided by your distribution.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Installing Ora2Pg Like any other Perl Module Ora2Pg can be installed with the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        tar xjf ora2pg-x.x.tar.bz2&#xA;        cd ora2pg-x.x/&#xA;        perl Makefile.PL&#xA;        make &amp;amp;&amp;amp; make install&#xA;&#xA;This will install Ora2Pg.pm into your site Perl repository, ora2pg into&#xA;/usr/local/bin/ and ora2pg.conf into /etc/ora2pg/.&#xA;&#xA;On Windows(tm) OSes you may use instead:&#xA;&#xA;        perl Makefile.PL&#xA;        gmake &amp;amp;&amp;amp; gmake install&#xA;&#xA;This will install scripts and libraries into your Perl site installation&#xA;directory and the ora2pg.conf file as well as all documentation files&#xA;into C:\ora2pg\&#xA;&#xA;To install ora2pg in a different directory than the default one, simply&#xA;use this command:&#xA;&#xA;        perl Makefile.PL PREFIX=&amp;lt;your_install_dir&amp;gt;&#xA;        make &amp;amp;&amp;amp; make install&#xA;&#xA;then set PERL5LIB to the path to your installation directory before&#xA;using Ora2Pg.&#xA;&#xA;        export PERL5LIB=&amp;lt;your_install_dir&amp;gt;&#xA;        ora2pg -c config/ora2pg.conf -t TABLE -b outdir/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Packaging If you want to build the binary package for your preferred Linux distribution take a look at the packaging/ directory of the source tarball. There is everything to build RPM, Slackware and Debian packages. See README file in that directory.&lt;/p&gt; &#xA;&lt;p&gt;Installing DBD::Oracle Ora2Pg needs the Perl module DBD::Oracle for connectivity to an Oracle database from perl DBI. To get DBD::Oracle get it from CPAN a perl module repository.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;After setting ORACLE_HOME and LD_LIBRARY_PATH environment variables as&#xA;root user, install DBD::Oracle. Proceed as follow:&#xA;&#xA;        export LD_LIBRARY_PATH=/usr/lib/oracle/12.2/client64/lib&#xA;        export ORACLE_HOME=/usr/lib/oracle/12.2/client64&#xA;        perl -MCPAN -e &#39;install DBD::Oracle&#39;&#xA;&#xA;If you are running for the first time it will ask many questions; you&#xA;can keep defaults by pressing ENTER key, but you need to give one&#xA;appropriate mirror site for CPAN to download the modules. Install&#xA;through CPAN manually if the above doesn&#39;t work:&#xA;&#xA;        #perl -MCPAN -e shell&#xA;        cpan&amp;gt; get DBD::Oracle&#xA;        cpan&amp;gt; quit&#xA;        cd ~/.cpan/build/DBD-Oracle*&#xA;        export LD_LIBRARY_PATH=/usr/lib/oracle/11.2/client64/lib&#xA;        export ORACLE_HOME=/usr/lib/oracle/11.2/client64&#xA;        perl Makefile.PL&#xA;        make&#xA;        make install&#xA;&#xA;Installing DBD::Oracle require that the three Oracle packages:&#xA;instant-client, SDK and SQLplus are installed as well as the libaio1&#xA;library.&#xA;&#xA;If you are using Instant Client from ZIP archives, the LD_LIBRARY_PATH&#xA;and ORACLE_HOME will be the same and must be set to the directory where&#xA;you have installed the files. For example:&#xA;/opt/oracle/instantclient_12_2/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;CONFIGURATION Ora2Pg configuration can be as simple as choosing the Oracle database to export and choose the export type. This can be done in a minute.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;By reading this documentation you will also be able to:&#xA;&#xA;        - Select only certain tables and/or column for export.&#xA;        - Rename some tables and/or column during export.&#xA;        - Select data to export following a WHERE clause per table.&#xA;        - Delay database constraints during data loading.&#xA;        - Compress exported data to save disk space.&#xA;        - and much more.&#xA;&#xA;The full control of the Oracle database migration is taken though a&#xA;single configuration file named ora2pg.conf. The format of this file&#xA;consist in a directive name in upper case followed by tab character and&#xA;a value. Comments are lines beginning with a #.&#xA;&#xA;There&#39;s no specific order to place the configuration directives, they&#xA;are set at the time they are read in the configuration file.&#xA;&#xA;For configuration directives that just take a single value, you can use&#xA;them multiple time in the configuration file but only the last&#xA;occurrence found in the file will be used. For configuration directives&#xA;that allow a list of value, you can use it multiple time, the values&#xA;will be appended to the list. If you use the IMPORT directive to load a&#xA;custom configuration file, directives defined in this file will be&#xA;stores from the place the IMPORT directive is found, so it is better to&#xA;put it at the end of the configuration file.&#xA;&#xA;Values set in command line options will override values from the&#xA;configuration file.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ora2Pg usage First of all be sure that libraries and binaries path include the Oracle Instant Client installation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        export LD_LIBRARY_PATH=/usr/lib/oracle/11.2/client64/lib&#xA;        export PATH=&#34;/usr/lib/oracle/11.2/client64/bin:$PATH&#34;&#xA;&#xA;By default Ora2Pg will look for /etc/ora2pg/ora2pg.conf configuration&#xA;file, if the file exist you can simply execute:&#xA;&#xA;        /usr/local/bin/ora2pg&#xA;&#xA;or under Windows(tm) run ora2pg.bat file, located in your perl bin&#xA;directory. Windows(tm) users may also find a template configuration file&#xA;in C:\ora2pg&#xA;&#xA;If you want to call another configuration file, just give the path as&#xA;command line argument:&#xA;&#xA;        /usr/local/bin/ora2pg -c /etc/ora2pg/new_ora2pg.conf&#xA;&#xA;Here are all command line parameters available when using ora2pg:&#xA;&#xA;Usage: ora2pg [-dhpqv --estimate_cost --dump_as_html] [--option value]&#xA;&#xA;    -a | --allow str  : Comma separated list of objects to allow from export.&#xA;                        Can be used with SHOW_COLUMN too.&#xA;    -b | --basedir dir: Set the default output directory, where files&#xA;                        resulting from exports will be stored.&#xA;    -c | --conf file  : Set an alternate configuration file other than the&#xA;                        default /etc/ora2pg/ora2pg.conf.&#xA;    -d | --debug      : Enable verbose output.&#xA;    -D | --data_type str : Allow custom type replacement at command line.&#xA;    -e | --exclude str: Comma separated list of objects to exclude from export.&#xA;                        Can be used with SHOW_COLUMN too.&#xA;    -h | --help       : Print this short help.&#xA;    -g | --grant_object type : Extract privilege from the given object type.&#xA;                        See possible values with GRANT_OBJECT configuration.&#xA;    -i | --input file : File containing Oracle PL/SQL code to convert with&#xA;                        no Oracle database connection initiated.&#xA;    -j | --jobs num   : Number of parallel process to send data to PostgreSQL.&#xA;    -J | --copies num : Number of parallel connections to extract data from Oracle.&#xA;    -l | --log file   : Set a log file. Default is stdout.&#xA;    -L | --limit num  : Number of tuples extracted from Oracle and stored in&#xA;                        memory before writing, default: 10000.&#xA;    -m | --mysql      : Export a MySQL database instead of an Oracle schema.&#xA;    -n | --namespace schema : Set the Oracle schema to extract from.&#xA;    -N | --pg_schema schema : Set PostgreSQL&#39;s search_path.&#xA;    -o | --out file   : Set the path to the output file where SQL will&#xA;                        be written. Default: output.sql in running directory.&#xA;    -p | --plsql      : Enable PLSQL to PLPGSQL code conversion.&#xA;    -P | --parallel num: Number of parallel tables to extract at the same time.&#xA;    -q | --quiet      : Disable progress bar.&#xA;    -r | --relative   : use \ir instead of \i in the psql scripts generated.&#xA;    -s | --source DSN : Allow to set the Oracle DBI datasource.&#xA;    -S | --scn    SCN : Allow to set the Oracle System Change Number (SCN)&#xA;    -t | --type export: Set the export type. It will override the one&#xA;                        given in the configuration file (TYPE).&#xA;    -T | --temp_dir dir: Set a distinct temporary directory when two&#xA;                         or more ora2pg are run in parallel.&#xA;    -u | --user name  : Set the Oracle database connection user.&#xA;                        ORA2PG_USER environment variable can be used instead.&#xA;    -v | --version    : Show Ora2Pg Version and exit.&#xA;    -w | --password pwd : Set the password of the Oracle database user.&#xA;                        ORA2PG_PASSWD environment variable can be used instead.&#xA;    -W | --where clause : Set the WHERE clause to apply to the Oracle query to&#xA;                          retrieve data. Can be used multiple time.&#xA;    --forceowner      : Force ora2pg to set tables and sequences owner like in&#xA;                  Oracle database. If the value is set to a username this one&#xA;                  will be used as the objects owner. By default it&#39;s the user&#xA;                  used to connect to the Pg database that will be the owner.&#xA;    --nls_lang code: Set the Oracle NLS_LANG client encoding.&#xA;    --client_encoding code: Set the PostgreSQL client encoding.&#xA;    --view_as_table str: Comma separated list of views to export as table.&#xA;    --estimate_cost   : Activate the migration cost evaluation with SHOW_REPORT&#xA;    --cost_unit_value minutes: Number of minutes for a cost evaluation unit.&#xA;                  default: 5 minutes, corresponds to a migration conducted by a&#xA;                  PostgreSQL expert. Set it to 10 if this is your first migration.&#xA;   --dump_as_html     : Force ora2pg to dump report in HTML, used only with&#xA;                        SHOW_REPORT. Default is to dump report as simple text.&#xA;   --dump_as_csv      : As above but force ora2pg to dump report in CSV.&#xA;   --dump_as_sheet    : Report migration assessment with one CSV line per database.&#xA;   --init_project name: Initialise a typical ora2pg project tree. Top directory&#xA;                        will be created under project base dir.&#xA;   --project_base dir : Define the base dir for ora2pg project trees. Default&#xA;                        is current directory.&#xA;   --print_header     : Used with --dump_as_sheet to print the CSV header&#xA;                        especially for the first run of ora2pg.&#xA;   --human_days_limit num : Set the number of human-days limit where the migration&#xA;                        assessment level switch from B to C. Default is set to&#xA;                        5 human-days.&#xA;   --audit_user list  : Comma separated list of usernames to filter queries in&#xA;                        the DBA_AUDIT_TRAIL table. Used only with SHOW_REPORT&#xA;                        and QUERY export type.&#xA;   --pg_dsn DSN       : Set the datasource to PostgreSQL for direct import.&#xA;   --pg_user name     : Set the PostgreSQL user to use.&#xA;   --pg_pwd password  : Set the PostgreSQL password to use.&#xA;   --count_rows       : Force ora2pg to perform a real row count in TEST action.&#xA;   --no_header        : Do not append Ora2Pg header to output file&#xA;   --oracle_speed     : Use to know at which speed Oracle is able to send&#xA;                        data. No data will be processed or written.&#xA;   --ora2pg_speed     : Use to know at which speed Ora2Pg is able to send&#xA;                        transformed data. Nothing will be written.&#xA;   --blob_to_lo       : export BLOB as large objects, can only be used with&#xA;                        action SHOW_COLUMN, TABLE and INSERT.&#xA;   --cdc_ready        : use current SCN per table to export data and register&#xA;                        them into a file named TABLES_SCN.log&#xA;   --lo_import        : use psql \lo_import command to import BLOB as large&#xA;                        object. Can be use to import data with COPY and import&#xA;                        large object manually in a second pass. It is recquired&#xA;                        for BLOB &amp;gt; 1GB. See documentation for more explanation.&#xA;&#xA;See full documentation at https://ora2pg.darold.net/ for more help or&#xA;see manpage with &#39;man ora2pg&#39;.&#xA;&#xA;ora2pg will return 0 on success, 1 on error. It will return 2 when a&#xA;child process has been interrupted and you&#39;ve gotten the warning&#xA;message: &#34;WARNING: an error occurs during data export. Please check&#xA;what&#39;s happen.&#34; Most of the time this is an OOM issue, first try&#xA;reducing DATA_LIMIT value.&#xA;&#xA;For developers, it is possible to add your own custom option(s) in the&#xA;Perl script ora2pg as any configuration directive from ora2pg.conf can&#xA;be passed in lower case to the new Ora2Pg object instance. See ora2pg&#xA;code on how to add your own option.&#xA;&#xA;Note that performance might be improved by updating stats on oracle:&#xA;&#xA;        BEGIN&#xA;        DBMS_STATS.GATHER_SCHEMA_STATS&#xA;        DBMS_STATS.GATHER_DATABASE_STATS &#xA;        DBMS_STATS.GATHER_DICTIONARY_STATS&#xA;        END;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Generate a migration template The two options --project_base and --init_project when used indicate to ora2pg that he has to create a project template with a work tree, a configuration file and a script to export all objects from the Oracle database. Here a sample of the command usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        ora2pg --project_base /app/migration/ --init_project test_project&#xA;        Creating project test_project.&#xA;        /app/migration/test_project/&#xA;                schema/&#xA;                        dblinks/&#xA;                        directories/&#xA;                        functions/&#xA;                        grants/&#xA;                        mviews/&#xA;                        packages/&#xA;                        partitions/&#xA;                        procedures/&#xA;                        sequences/&#xA;                        synonyms/&#xA;                        tables/&#xA;                        tablespaces/&#xA;                        triggers/&#xA;                        types/&#xA;                        views/&#xA;                sources/&#xA;                        functions/&#xA;                        mviews/&#xA;                        packages/&#xA;                        partitions/&#xA;                        procedures/&#xA;                        triggers/&#xA;                        types/&#xA;                        views/&#xA;                data/&#xA;                config/&#xA;                reports/&#xA;&#xA;        Generating generic configuration file&#xA;        Creating script export_schema.sh to automate all exports.&#xA;        Creating script import_all.sh to automate all imports.&#xA;&#xA;It create a generic config file where you just have to define the Oracle&#xA;database connection and a shell script called export_schema.sh. The&#xA;sources/ directory will contains the Oracle code, the schema/ will&#xA;contains the code ported to PostgreSQL. The reports/ directory will&#xA;contains the html reports with the migration cost assessment.&#xA;&#xA;If you want to use your own default config file, use the -c option to&#xA;give the path to that file. Rename it with .dist suffix if you want&#xA;ora2pg to apply the generic configuration values otherwise, the&#xA;configuration file will be copied untouched.&#xA;&#xA;Once you have set the connection to the Oracle Database you can execute&#xA;the script export_schema.sh that will export all object type from your&#xA;Oracle database and output DDL files into the schema&#39;s subdirectories.&#xA;At end of the export it will give you the command to export data later&#xA;when the import of the schema will be done and verified.&#xA;&#xA;You can choose to load the DDL files generated manually or use the&#xA;second script import_all.sh to import those file interactively. If this&#xA;kind of migration is not something current for you it&#39;s recommended you&#xA;to use those scripts.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Oracle database connection There&#39;s 5 configuration directives to control the access to the Oracle database.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ORACLE_HOME&#xA;    Used to set ORACLE_HOME environment variable to the Oracle libraries&#xA;    required by the DBD::Oracle Perl module.&#xA;&#xA;ORACLE_DSN&#xA;    This directive is used to set the data source name in the form&#xA;    standard DBI DSN. For example:&#xA;&#xA;            dbi:Oracle:host=oradb_host.myhost.com;sid=DB_SID;port=1521&#xA;&#xA;    or&#xA;&#xA;            dbi:Oracle:DB_SID&#xA;&#xA;    On 18c this could be for example:&#xA;&#xA;            dbi:Oracle:host=192.168.1.29;service_name=pdb1;port=1521&#xA;&#xA;    for the second notation the SID should be declared in the well known&#xA;    file $ORACLE_HOME/network/admin/tnsnames.ora or in the path given to&#xA;    the TNS_ADMIN environment variable.&#xA;&#xA;    For MySQL the DSN will lool like this:&#xA;&#xA;            dbi:mysql:host=192.168.1.10;database=sakila;port=3306&#xA;&#xA;    the &#39;sid&#39; part is replaced by &#39;database&#39;.&#xA;&#xA;ORACLE_USER et ORACLE_PWD&#xA;    These two directives are used to define the user and password for&#xA;    the Oracle database connection. Note that if you can it is better to&#xA;    login as Oracle super admin to avoid grants problem during the&#xA;    database scan and be sure that nothing is missing.&#xA;&#xA;    If you do not supply a credential with ORACLE_PWD and you have&#xA;    installed the Term::ReadKey Perl module, Ora2Pg will ask for the&#xA;    password interactively. If ORACLE_USER is not set it will be asked&#xA;    interactively too.&#xA;&#xA;    To connect to a local ORACLE instance with connections &#34;as sysdba&#34;&#xA;    you have to set ORACLE_USER to &#34;/&#34; and an empty password.&#xA;&#xA;USER_GRANTS&#xA;    Set this directive to 1 if you connect the Oracle database as simple&#xA;    user and do not have enough grants to extract things from the&#xA;    DBA_... tables. It will use tables ALL_... instead.&#xA;&#xA;    Warning: if you use export type GRANT, you must set this&#xA;    configuration option to 0 or it will not work.&#xA;&#xA;TRANSACTION&#xA;    This directive may be used if you want to change the default&#xA;    isolation level of the data export transaction. Default is now to&#xA;    set the level to a serializable transaction to ensure data&#xA;    consistency. The allowed values for this directive are:&#xA;&#xA;            readonly: &#39;SET TRANSACTION READ ONLY&#39;,&#xA;            readwrite: &#39;SET TRANSACTION READ WRITE&#39;,&#xA;            serializable: &#39;SET TRANSACTION ISOLATION LEVEL SERIALIZABLE&#39;&#xA;            committed: &#39;SET TRANSACTION ISOLATION LEVEL READ COMMITTED&#39;,&#xA;&#xA;    Releases before 6.2 used to set the isolation level to READ ONLY&#xA;    transaction but in some case this was breaking data consistency so&#xA;    now default is set to SERIALIZABLE.&#xA;&#xA;INPUT_FILE&#xA;    This directive did not control the Oracle database connection or&#xA;    unless it purely disables the use of any Oracle database by&#xA;    accepting a file as argument. Set this directive to a file&#xA;    containing PL/SQL Oracle Code like function, procedure or full&#xA;    package body to prevent Ora2Pg from connecting to an Oracle database&#xA;    and just apply his conversion tool to the content of the file. This&#xA;    can be used with the most of export types: TABLE, TRIGGER,&#xA;    PROCEDURE, VIEW, FUNCTION or PACKAGE, etc.&#xA;&#xA;ORA_INITIAL_COMMAND&#xA;    This directive can be used to send an initial command to Oracle,&#xA;    just after the connection. For example to unlock a policy before&#xA;    reading objects or to set some session parameters. This directive&#xA;    can be used multiple times.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Data encryption with Oracle server If your Oracle Client config file already includes the encryption method, then DBD:Oracle uses those settings to encrypt the connection while you extract the data. For example if you have configured the Oracle Client config file (sqlnet.or or .sqlnet) with the following information:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        # Configure encryption of connections to Oracle&#xA;        SQLNET.ENCRYPTION_CLIENT = required&#xA;        SQLNET.ENCRYPTION_TYPES_CLIENT = (AES256, RC4_256)&#xA;        SQLNET.CRYPTO_SEED = &#39;should be 10-70 random characters&#39;&#xA;&#xA;Any tool that uses the Oracle client to talk to the database will be&#xA;encrypted if you setup session encryption like above.&#xA;&#xA;For example, Perl&#39;s DBI uses DBD-Oracle, which uses the Oracle client&#xA;for actually handling database communication. If the installation of&#xA;Oracle client used by Perl is setup to request encrypted connections,&#xA;then your Perl connection to an Oracle database will also be encrypted.&#xA;&#xA;Full details at&#xA;https://kb.berkeley.edu/jivekb/entry.jspa?externalID=1005&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Testing connection Once you have set the Oracle database DSN you can execute ora2pg to see if it works:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        ora2pg -t SHOW_VERSION -c config/ora2pg.conf&#xA;&#xA;will show the Oracle database server version. Take some time here to&#xA;test your installation as most problems take place here, the other&#xA;configuration steps are more technical.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Troubleshooting If the output.sql file has not exported anything other than the Pg transaction header and footer there&#39;s two possible reasons. The perl script ora2pg dump an ORA-XXX error, that mean that your DSN or login information are wrong, check the error and your settings and try again. The perl script says nothing and the output file is empty: the user lacks permission to extract something from the database. Try to connect to Oracle as super user or take a look at directive USER_GRANTS above and at next section, especially the SCHEMA directive.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;LOGFILE&#xA;    By default all messages are sent to the standard output. If you give&#xA;    a file path to that directive, all output will be appended to this&#xA;    file.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Oracle schema to export The Oracle database export can be limited to a specific Schema or Namespace, this can be mandatory following the database connection user.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SCHEMA&#xA;    This directive is used to set the schema name to use during export.&#xA;    For example:&#xA;&#xA;            SCHEMA  APPS&#xA;&#xA;    will extract objects associated to the APPS schema.&#xA;&#xA;    When no schema name is provided and EXPORT_SCHEMA is enabled, Ora2Pg&#xA;    will export all objects from all schema of the Oracle instance with&#xA;    their names prefixed with the schema name.&#xA;&#xA;EXPORT_SCHEMA&#xA;    By default the Oracle schema is not exported into the PostgreSQL&#xA;    database and all objects are created under the default Pg namespace.&#xA;    If you want to also export this schema and create all objects under&#xA;    this namespace, set the EXPORT_SCHEMA directive to 1. This will set&#xA;    the schema search_path at top of export SQL file to the schema name&#xA;    set in the SCHEMA directive with the default pg_catalog schema. If&#xA;    you want to change this path, use the directive PG_SCHEMA.&#xA;&#xA;CREATE_SCHEMA&#xA;    Enable/disable the CREATE SCHEMA SQL order at starting of the output&#xA;    file. It is enable by default and concern on TABLE export type.&#xA;&#xA;COMPILE_SCHEMA&#xA;    By default Ora2Pg will only export valid PL/SQL code. You can force&#xA;    Oracle to compile again the invalidated code to get a chance to have&#xA;    it obtain the valid status and then be able to export it.&#xA;&#xA;    Enable this directive to force Oracle to compile schema before&#xA;    exporting code. When this directive is enabled and SCHEMA is set to&#xA;    a specific schema name, only invalid objects in this schema will be&#xA;    recompiled. If SCHEMA is not set then all schema will be recompiled.&#xA;    To force recompile invalid object in a specific schema, set&#xA;    COMPILE_SCHEMA to the schema name you want to recompile.&#xA;&#xA;    This will ask to Oracle to validate the PL/SQL that could have been&#xA;    invalidate after a export/import for example. The &#39;VALID&#39; or&#xA;    &#39;INVALID&#39; status applies to functions, procedures, packages and user&#xA;    defined types.&#xA;&#xA;EXPORT_INVALID&#xA;    If the above configuration directive is not enough to validate your&#xA;    PL/SQL code enable this configuration directive to allow export of&#xA;    all PL/SQL code even if it is marked as invalid. The &#39;VALID&#39; or&#xA;    &#39;INVALID&#39; status applies to functions, procedures, packages and user&#xA;    defined types.&#xA;&#xA;PG_SCHEMA&#xA;    Allow you to defined/force the PostgreSQL schema to use. By default&#xA;    if you set EXPORT_SCHEMA to 1 the PostgreSQL search_path will be set&#xA;    to the schema name exported set as value of the SCHEMA directive.&#xA;&#xA;    The value can be a comma delimited list of schema name but not when&#xA;    using TABLE export type because in this case it will generate the&#xA;    CREATE SCHEMA statement and it doesn&#39;t support multiple schema name.&#xA;    For example, if you set PG_SCHEMA to something like &#34;user_schema,&#xA;    public&#34;, the search path will be set like this:&#xA;&#xA;            SET search_path = user_schema, public;&#xA;&#xA;    forcing the use of an other schema (here user_schema) than the one&#xA;    from Oracle schema set in the SCHEMA directive.&#xA;&#xA;    You can also set the default search_path for the PostgreSQL user you&#xA;    are using to connect to the destination database by using:&#xA;&#xA;            ALTER ROLE username SET search_path TO user_schema, public;&#xA;&#xA;    in this case you don&#39;t have to set PG_SCHEMA.&#xA;&#xA;SYSUSERS&#xA;    Without explicit schema, Ora2Pg will export all objects that not&#xA;    belongs to system schema or role:&#xA;&#xA;            SYSTEM,CTXSYS,DBSNMP,EXFSYS,LBACSYS,MDSYS,MGMT_VIEW,&#xA;            OLAPSYS,ORDDATA,OWBSYS,ORDPLUGINS,ORDSYS,OUTLN,&#xA;            SI_INFORMTN_SCHEMA,SYS,SYSMAN,WK_TEST,WKSYS,WKPROXY,&#xA;            WMSYS,XDB,APEX_PUBLIC_USER,DIP,FLOWS_020100,FLOWS_030000,&#xA;            FLOWS_040100,FLOWS_010600,FLOWS_FILES,MDDATA,ORACLE_OCM,&#xA;            SPATIAL_CSW_ADMIN_USR,SPATIAL_WFS_ADMIN_USR,XS$NULL,PERFSTAT,&#xA;            SQLTXPLAIN,DMSYS,TSMSYS,WKSYS,APEX_040000,APEX_040200,&#xA;            DVSYS,OJVMSYS,GSMADMIN_INTERNAL,APPQOSSYS,DVSYS,DVF,&#xA;            AUDSYS,APEX_030200,MGMT_VIEW,ODM,ODM_MTR,TRACESRV,MTMSYS,&#xA;            OWBSYS_AUDIT,WEBSYS,WK_PROXY,OSE$HTTP$ADMIN,&#xA;            AURORA$JIS$UTILITY$,AURORA$ORB$UNAUTHENTICATED,&#xA;            DBMS_PRIVILEGE_CAPTURE,CSMIG,MGDSYS,SDE,DBSFWUSER&#xA;&#xA;    Following your Oracle installation you may have several other system&#xA;    role defined. To append these users to the schema exclusion list,&#xA;    just set the SYSUSERS configuration directive to a comma-separated&#xA;    list of system user to exclude. For example:&#xA;&#xA;            SYSUSERS        INTERNAL,SYSDBA,BI,HR,IX,OE,PM,SH&#xA;&#xA;    will add users INTERNAL and SYSDBA to the schema exclusion list.&#xA;&#xA;FORCE_OWNER&#xA;    By default the owner of the database objects is the one you&#39;re using&#xA;    to connect to PostgreSQL using the psql command. If you use an other&#xA;    user (postgres for example) you can force Ora2Pg to set the object&#xA;    owner to be the one used in the Oracle database by setting the&#xA;    directive to 1, or to a completely different username by setting the&#xA;    directive value to that username.&#xA;&#xA;FORCE_SECURITY_INVOKER&#xA;    Ora2Pg use the function&#39;s security privileges set in Oracle and it&#xA;    is often defined as SECURITY DEFINER. If you want to override those&#xA;    security privileges for all functions and use SECURITY DEFINER&#xA;    instead, enable this directive.&#xA;&#xA;USE_TABLESPACE&#xA;    When enabled this directive force ora2pg to export all tables,&#xA;    indexes constraint and indexes using the tablespace name defined in&#xA;    Oracle database. This works only with tablespace that are not TEMP,&#xA;    USERS and SYSTEM.&#xA;&#xA;WITH_OID&#xA;    Activating this directive will force Ora2Pg to add WITH (OIDS) when&#xA;    creating tables or views as tables. Default is same as PostgreSQL,&#xA;    disabled.&#xA;&#xA;LOOK_FORWARD_FUNCTION&#xA;    List of schema to get functions/procedures meta information that are&#xA;    used in the current schema export. When replacing call to function&#xA;    with OUT parameters, if a function is declared in an other package&#xA;    then the function call rewriting can not be done because Ora2Pg only&#xA;    knows about functions declared in the current schema. By setting a&#xA;    comma separated list of schema as value of this directive, Ora2Pg&#xA;    will look forward in these packages for all&#xA;    functions/procedures/packages declaration before proceeding to&#xA;    current schema export.&#xA;&#xA;NO_FUNCTION_METADATA&#xA;    Force Ora2Pg to not look for function declaration. Note that this&#xA;    will prevent Ora2Pg to rewrite function replacement call if needed.&#xA;    Do not enable it unless looking forward at function breaks other&#xA;    export.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Export type The export action is perform following a single configuration directive &#39;TYPE&#39;, some other add more control on what should be really exported.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;TYPE&#xA;    Here are the different values of the TYPE directive, default is&#xA;    TABLE:&#xA;&#xA;            - TABLE: Extract all tables with indexes, primary keys, unique keys,&#xA;              foreign keys and check constraints.&#xA;            - VIEW: Extract only views.&#xA;            - GRANT: Extract roles converted to Pg groups, users and grants on all&#xA;              objects.&#xA;            - SEQUENCE: Extract all sequence and their last position.&#xA;            - TABLESPACE: Extract storage spaces for tables and indexes (Pg &amp;gt;= v8).&#xA;            - TRIGGER: Extract triggers defined following actions.&#xA;            - FUNCTION: Extract functions.&#xA;            - PROCEDURE: Extract procedures.&#xA;            - PACKAGE: Extract packages and package bodies.&#xA;            - INSERT: Extract data as INSERT statement.&#xA;            - COPY: Extract data as COPY statement.&#xA;            - PARTITION: Extract range and list Oracle partitions with subpartitions.&#xA;            - TYPE: Extract user defined Oracle type.&#xA;            - FDW: Export Oracle tables as foreign table for oracle_fdw.&#xA;            - MVIEW: Export materialized view.&#xA;            - QUERY: Try to automatically convert Oracle SQL queries.&#xA;            - KETTLE: Generate XML ktr template files to be used by Kettle.&#xA;            - DBLINK: Generate oracle foreign data wrapper server to use as dblink.&#xA;            - SYNONYM: Export Oracle&#39;s synonyms as views on other schema&#39;s objects.&#xA;            - DIRECTORY: Export Oracle&#39;s directories as external_file extension objects.&#xA;            - LOAD: Dispatch a list of queries over multiple PostgreSQl connections.&#xA;            - TEST: perform a diff between Oracle and PostgreSQL database.&#xA;            - TEST_COUNT: perform a row count diff between Oracle and PostgreSQL table.&#xA;            - TEST_VIEW: perform a count on both side of number of rows returned by views.&#xA;            - TEST_DATA: perform data validation check on rows at both sides.&#xA;&#xA;    Only one type of export can be perform at the same time so the TYPE&#xA;    directive must be unique. If you have more than one only the last&#xA;    found in the file will be registered.&#xA;&#xA;    Some export type can not or should not be load directly into the&#xA;    PostgreSQL database and still require little manual editing. This is&#xA;    the case for GRANT, TABLESPACE, TRIGGER, FUNCTION, PROCEDURE, TYPE,&#xA;    QUERY and PACKAGE export types especially if you have PLSQL code or&#xA;    Oracle specific SQL in it.&#xA;&#xA;    For TABLESPACE you must ensure that file path exist on the system&#xA;    and for SYNONYM you may ensure that the object&#39;s owners and schemas&#xA;    correspond to the new PostgreSQL database design.&#xA;&#xA;    Note that you can chained multiple export by giving to the TYPE&#xA;    directive a comma-separated list of export type, but in this case&#xA;    you must not use COPY or INSERT with other export type.&#xA;&#xA;    Ora2Pg will convert Oracle partition using table inheritance,&#xA;    trigger and functions. See document at Pg site:&#xA;    http://www.postgresql.org/docs/current/interactive/ddl-partitioning.&#xA;    html&#xA;&#xA;    The TYPE export allow export of user defined Oracle type. If you&#xA;    don&#39;t use the --plsql command line parameter it simply dump Oracle&#xA;    user type asis else Ora2Pg will try to convert it to PostgreSQL&#xA;    syntax.&#xA;&#xA;    The KETTLE export type requires that the Oracle and PostgreSQL DNS&#xA;    are defined.&#xA;&#xA;    Since Ora2Pg v8.1 there&#39;s three new export types:&#xA;&#xA;            SHOW_VERSION : display Oracle version&#xA;            SHOW_SCHEMA  : display the list of schema available in the database.&#xA;            SHOW_TABLE   : display the list of tables available.&#xA;            SHOW_COLUMN  : display the list of tables columns available and the&#xA;                    Ora2PG conversion type from Oracle to PostgreSQL that will be&#xA;                    applied. It will also warn you if there&#39;s PostgreSQL reserved&#xA;                    words in Oracle object names.&#xA;&#xA;    Here is an example of the SHOW_COLUMN output:&#xA;&#xA;            [2] TABLE CURRENT_SCHEMA (1 rows) (Warning: &#39;CURRENT_SCHEMA&#39; is a reserved word in PostgreSQL)&#xA;                    CONSTRAINT : NUMBER(22) =&amp;gt; bigint (Warning: &#39;CONSTRAINT&#39; is a reserved word in PostgreSQL)&#xA;                    FREEZE : VARCHAR2(25) =&amp;gt; varchar(25) (Warning: &#39;FREEZE&#39; is a reserved word in PostgreSQL)&#xA;            ...&#xA;            [6] TABLE LOCATIONS (23 rows)&#xA;                    LOCATION_ID : NUMBER(4) =&amp;gt; smallint&#xA;                    STREET_ADDRESS : VARCHAR2(40) =&amp;gt; varchar(40)&#xA;                    POSTAL_CODE : VARCHAR2(12) =&amp;gt; varchar(12)&#xA;                    CITY : VARCHAR2(30) =&amp;gt; varchar(30)&#xA;                    STATE_PROVINCE : VARCHAR2(25) =&amp;gt; varchar(25)&#xA;                    COUNTRY_ID : CHAR(2) =&amp;gt; char(2)&#xA;&#xA;    Those extraction keywords are use to only display the requested&#xA;    information and exit. This allows you to quickly know on what you&#xA;    are going to work.&#xA;&#xA;    The SHOW_COLUMN allow an other ora2pg command line option: &#39;--allow&#xA;    relname&#39; or &#39;-a relname&#39; to limit the displayed information to the&#xA;    given table.&#xA;&#xA;    The SHOW_ENCODING export type will display the NLS_LANG and&#xA;    CLIENT_ENCODING values that Ora2Pg will used and the real encoding&#xA;    of the Oracle database with the corresponding client encoding that&#xA;    could be used with PostgreSQL&#xA;&#xA;    Since release v8.12, Ora2Pg allow you to export your Oracle Table&#xA;    definition to be use with the oracle_fdw foreign data wrapper. By&#xA;    using type FDW your Oracle tables will be exported as follow:&#xA;&#xA;            CREATE FOREIGN TABLE oratab (&#xA;                    id        integer           NOT NULL,&#xA;                    text      character varying(30),&#xA;                    floating  double precision  NOT NULL&#xA;            ) SERVER oradb OPTIONS (table &#39;ORATAB&#39;);&#xA;&#xA;    Now you can use the table like a regular PostgreSQL table.&#xA;&#xA;    See http://pgxn.org/dist/oracle_fdw/ for more information on this&#xA;    foreign data wrapper.&#xA;&#xA;    Release 10 adds a new export type destined to evaluate the content&#xA;    of the database to migrate, in terms of objects and cost to end the&#xA;    migration:&#xA;&#xA;            SHOW_REPORT  : show a detailed report of the Oracle database content.&#xA;&#xA;    Here is a sample of report: http://ora2pg.darold.net/report.html&#xA;&#xA;    There also a more advanced report with migration cost. See the&#xA;    dedicated chapter about Migration Cost Evaluation.&#xA;&#xA;ESTIMATE_COST&#xA;    Activate the migration cost evaluation. Must only be used with&#xA;    SHOW_REPORT, FUNCTION, PROCEDURE, PACKAGE and QUERY export type.&#xA;    Default is disabled. You may want to use the --estimate_cost command&#xA;    line option instead to activate this functionality. Note that&#xA;    enabling this directive will force PLSQL_PGSQL activation.&#xA;&#xA;COST_UNIT_VALUE&#xA;    Set the value in minutes of the migration cost evaluation unit.&#xA;    Default is five minutes per unit. See --cost_unit_value to change&#xA;    the unit value at command line.&#xA;&#xA;DUMP_AS_HTML&#xA;    By default when using SHOW_REPORT the migration report is generated&#xA;    as simple text, enabling this directive will force ora2pg to create&#xA;    a report in HTML format.&#xA;&#xA;    See http://ora2pg.darold.net/report.html for a sample report.&#xA;&#xA;HUMAN_DAYS_LIMIT&#xA;    Use this directive to redefined the number of human-days limit where&#xA;    the migration assessment level must switch from B to C. Default is&#xA;    set to 10 human-days.&#xA;&#xA;JOBS&#xA;    This configuration directive adds multiprocess support to COPY,&#xA;    FUNCTION and PROCEDURE export type, the value is the number of&#xA;    process to use. Default is multiprocess disable.&#xA;&#xA;    This directive is used to set the number of cores to used to&#xA;    parallelize data import into PostgreSQL. During FUNCTION or&#xA;    PROCEDURE export type each function will be translated to plpgsql&#xA;    using a new process, the performances gain can be very important&#xA;    when you have tons of function to convert.&#xA;&#xA;    There&#39;s no limitation in parallel processing than the number of&#xA;    cores and the PostgreSQL I/O performance capabilities.&#xA;&#xA;    Doesn&#39;t work under Windows Operating System, it is simply disabled.&#xA;&#xA;ORACLE_COPIES&#xA;    This configuration directive adds multiprocess support to extract&#xA;    data from Oracle. The value is the number of process to use to&#xA;    parallelize the select query. Default is parallel query disable.&#xA;&#xA;    The parallelism is built on splitting the query following of the&#xA;    number of cores given as value to ORACLE_COPIES as follow:&#xA;&#xA;            SELECT * FROM MYTABLE WHERE ABS(MOD(COLUMN, ORACLE_COPIES)) = CUR_PROC&#xA;&#xA;    where COLUMN is a technical key like a primary or unique key where&#xA;    split will be based and the current core used by the query&#xA;    (CUR_PROC).&#xA;&#xA;    Doesn&#39;t work under Windows Operating System, it is simply disabled.&#xA;&#xA;DEFINED_PK&#xA;    This directive is used to defined the technical key to used to split&#xA;    the query between number of cores set with the ORACLE_COPIES&#xA;    variable. For example:&#xA;&#xA;            DEFINED_PK      EMPLOYEES:employee_id&#xA;&#xA;    The parallel query that will be used supposing that -J or&#xA;    ORACLE_COPIES is set to 8:&#xA;&#xA;            SELECT * FROM EMPLOYEES WHERE ABS(MOD(employee_id, 8)) = N&#xA;&#xA;    where N is the current process forked starting from 0.&#xA;&#xA;PARALLEL_TABLES&#xA;    This directive is used to defined the number of tables that will be&#xA;    processed in parallel for data extraction. The limit is the number&#xA;    of cores on your machine. Ora2Pg will open one database connection&#xA;    for each parallel table extraction. This directive, when upper than&#xA;    1, will invalidate ORACLE_COPIES but not JOBS, so the real number of&#xA;    process that will be used is PARALLEL_TABLES * JOBS.&#xA;&#xA;    Note that this directive when set upper that 1 will also&#xA;    automatically enable the FILE_PER_TABLE directive if your are&#xA;    exporting to files. This is used to export tables and views in&#xA;    separate files.&#xA;&#xA;DEFAULT_PARALLELISM_DEGREE&#xA;    You can force Ora2Pg to use /*+ PARALLEL(tbname, degree) */ hint in&#xA;    each query used to export data from Oracle by setting a value upper&#xA;    than 1 to this directive. A value of 0 or 1 disable the use of&#xA;    parallel hint. Default is disabled.&#xA;&#xA;FDW_SERVER&#xA;    This directive is used to set the name of the foreign data server&#xA;    that is used in the &#34;CREATE SERVER name FOREIGN DATA WRAPPER&#xA;    oracle_fdw ...&#34; command. This name will then be used in the &#34;CREATE&#xA;    FOREIGN TABLE ...&#34; SQL commands and to import data using oracle_fdw.&#xA;    Default is no foreign server defined. This only concerns export type&#xA;    FDW, COPY and INSERT. For export type FDW the default value is orcl.&#xA;&#xA;ORACLE_FDW_TRANSFORM&#xA;    Use this directive to precise which transformation should be applied&#xA;    to a column when exporting data. Value must be a semicolon separated&#xA;    list of&#xA;&#xA;       TABLE[COLUMN_NAME, &amp;lt;replace code in SELECT target list&amp;gt;]&#xA;&#xA;    For example to replace string &#39;Oracle&#39; by &#39;PostgreSQL&#39; in a varchar2&#xA;    column use the following.&#xA;&#xA;       ORACLE_FDW_TRANSFORM   ERROR_LOG_SAMPLE[DBMS_TYPE:regexp_replace(&#34;DBMS_TYPE&#34;,&#39;Oracle&#39;,&#39;PostgreSQL&#39;)]&#xA;&#xA;DROP_FOREIGN_SCHEMA&#xA;    By default Ora2Pg drops the temporary schema ora2pg_fdw_import used&#xA;    to import the Oracle foreign schema before each new import. If you&#xA;    want to preserve the existing schema because of modifications or the&#xA;    use of a third party server, disable this directive.&#xA;&#xA;EXTERNAL_TO_FDW&#xA;    This directive, enabled by default, allow to export Oracle&#39;s&#xA;    External Tables as file_fdw foreign tables. To not export these&#xA;    tables at all, set the directive to 0.&#xA;&#xA;INTERNAL_DATE_MAX&#xA;    Internal timestamp retrieves from custom type are extracted in the&#xA;    following format: 01-JAN-77 12.00.00.000000 AM. It is impossible to&#xA;    know the exact century that must be used, so by default any year&#xA;    below 49 will be added to 2000 and others to 1900. You can use this&#xA;    directive to change the default value 49. this is only relevant if&#xA;    you have user defined type with a column timestamp.&#xA;&#xA;AUDIT_USER&#xA;    Set the comma separated list of username that must be used to filter&#xA;    queries from the DBA_AUDIT_TRAIL table. Default is to not scan this&#xA;    table and to never look for queries. This parameter is used only&#xA;    with SHOW_REPORT and QUERY export type with no input file for&#xA;    queries. Note that queries will be normalized before output unlike&#xA;    when a file is given at input using the -i option or INPUT&#xA;    directive.&#xA;&#xA;FUNCTION_CHECK&#xA;    Disable this directive if you want to disable check_function_bodies.&#xA;&#xA;            SET check_function_bodies = false;&#xA;&#xA;    It disables validation of the function body string during CREATE&#xA;    FUNCTION. Default is to use de postgresql.conf setting that enable&#xA;    it by default.&#xA;&#xA;ENABLE_BLOB_EXPORT&#xA;    Exporting BLOB takes time, in some circumstances you may want to&#xA;    export all data except the BLOB columns. In this case disable this&#xA;    directive and the BLOB columns will not be included into data&#xA;    export. Take care that the target bytea column do not have a NOT&#xA;    NULL constraint.&#xA;&#xA;DATA_EXPORT_ORDER&#xA;    By default data export order will be done by sorting on table name.&#xA;    If you have huge tables at end of alphabetic order and you are using&#xA;    multiprocess, it can be better to set the sort order on size so that&#xA;    multiple small tables can be processed before the largest tables&#xA;    finish. In this case set this directive to size. Possible values are&#xA;    name and size. Note that export type SHOW_TABLE and SHOW_COLUMN will&#xA;    use this sort order too, not only COPY or INSERT export type.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Limiting objects to export You may want to export only a part of an Oracle database, here are a set of configuration directives that will allow you to control what parts of the database should be exported.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ALLOW&#xA;    This directive allows you to set a list of objects on which the&#xA;    export must be limited, excluding all other objects in the same type&#xA;    of export. The value is a space or comma-separated list of objects&#xA;    name to export. You can include valid regex into the list. For&#xA;    example:&#xA;&#xA;            ALLOW           EMPLOYEES SALE_.* COUNTRIES .*_GEOM_SEQ&#xA;&#xA;    will export objects with name EMPLOYEES, COUNTRIES, all objects&#xA;    beginning with &#39;SALE_&#39; and all objects with a name ending by&#xA;    &#39;_GEOM_SEQ&#39;. The object depends of the export type. Note that regex&#xA;    will not works with 8i database, you must use the % placeholder&#xA;    instead, Ora2Pg will use the LIKE operator.&#xA;&#xA;    This is the manner to declare global filters that will be used with&#xA;    the current export type. You can also use extended filters that will&#xA;    be applied on specific objects or only on their related export type.&#xA;    For example:&#xA;&#xA;            ora2pg -p -c ora2pg.conf -t TRIGGER -a &#39;TABLE[employees]&#39;&#xA;&#xA;    will limit export of trigger to those defined on table employees. If&#xA;    you want to extract all triggers but not some INSTEAD OF triggers:&#xA;&#xA;            ora2pg -c ora2pg.conf -t TRIGGER -e &#39;VIEW[trg_view_.*]&#39;&#xA;&#xA;    Or a more complex form:&#xA;&#xA;            ora2pg -p -c ora2pg.conf -t TABLE -a &#39;TABLE[EMPLOYEES]&#39; \&#xA;                    -e &#39;INDEX[emp_.*];CKEY[emp_salary_min]&#39;&#xA;&#xA;    This command will export the definition of the employee table but&#xA;    will exclude all index beginning with &#39;emp_&#39; and the CHECK&#xA;    constraint called &#39;emp_salary_min&#39;.&#xA;&#xA;    When exporting partition you can exclude some partition tables by&#xA;    using&#xA;&#xA;            ora2pg -p -c ora2pg.conf -t PARTITION -e &#39;PARTITION[PART_199.* PART_198.*]&#39;&#xA;&#xA;    This will exclude partitioned tables for year 1980 to 1999 from the&#xA;    export but not the main partition table. The trigger will also be&#xA;    adapted to exclude those table.&#xA;&#xA;    With GRANT export you can use this extended form to exclude some&#xA;    users from the export or limit the export to some others:&#xA;&#xA;            ora2pg -p -c ora2pg.conf -t GRANT -a &#39;USER1 USER2&#39;&#xA;&#xA;    or&#xA;&#xA;            ora2pg -p -c ora2pg.conf -t GRANT -a &#39;GRANT[USER1 USER2]&#39;&#xA;&#xA;    will limit export grants to users USER1 and USER2. But if you don&#39;t&#xA;    want to export grants on some functions for these users, for&#xA;    example:&#xA;&#xA;            ora2pg -p -c ora2pg.conf -t GRANT -a &#39;USER1 USER2&#39; -e &#39;FUNCTION[adm_.*];PROCEDURE[adm_.*]&#39;&#xA;&#xA;    Advanced filters may need some learning.&#xA;&#xA;    Oracle doesn&#39;t allow the use of lookahead expression so you may want&#xA;    to exclude some object that match the ALLOW regexp you have defined.&#xA;    For example if you want to export all table starting with E but not&#xA;    those starting with EXP it is not possible to do that in a single&#xA;    expression. This is why you can start a regular expression with the&#xA;    ! character to exclude object matching the regexp given just after.&#xA;    Our previous example can be written as follow:&#xA;&#xA;            ALLOW   E.* !EXP.*&#xA;&#xA;    it will be translated into:&#xA;&#xA;             REGEXP_LIKE(..., &#39;^E.*$&#39;) AND NOT REGEXP_LIKE(..., &#39;^EXP.*$&#39;)&#xA;&#xA;    in the object search expression.&#xA;&#xA;EXCLUDE&#xA;    This directive is the opposite of the previous, it allow you to&#xA;    define a space or comma-separated list of object name to exclude&#xA;    from the export. You can include valid regex into the list. For&#xA;    example:&#xA;&#xA;            EXCLUDE         EMPLOYEES TMP_.* COUNTRIES&#xA;&#xA;    will exclude object with name EMPLOYEES, COUNTRIES and all tables&#xA;    beginning with &#39;tmp_&#39;.&#xA;&#xA;    For example, you can ban from export some unwanted function with&#xA;    this directive:&#xA;&#xA;            EXCLUDE         write_to_.* send_mail_.*&#xA;&#xA;    this example will exclude all functions, procedures or functions in&#xA;    a package with the name beginning with those regex. Note that regex&#xA;    will not work with 8i database, you must use the % placeholder&#xA;    instead, Ora2Pg will use the NOT LIKE operator.&#xA;&#xA;    See above (directive &#39;ALLOW&#39;) for the extended syntax.&#xA;&#xA;NO_EXCLUDED_TABLE&#xA;    By default Ora2Pg exclude from export some Oracle &#34;garbage&#34; tables&#xA;    that should never be part of an export. This behavior generates a&#xA;    lot of REGEXP_LIKE expressions which are slowing down the export&#xA;    when looking at tables. To disable this behavior enable this&#xA;    directive, you will have to exclude or clean up later by yourself&#xA;    the unwanted tables. The regexp used to exclude the table are&#xA;    defined in the array @EXCLUDED_TABLES in lib/Ora2Pg.pm. Note this is&#xA;    behavior is independant to the EXCLUDE configuration directive.&#xA;&#xA;VIEW_AS_TABLE&#xA;    Set which view to export as table. By default none. Value must be a&#xA;    list of view name or regexp separated by space or comma. If the&#xA;    object name is a view and the export type is TABLE, the view will be&#xA;    exported as a create table statement. If export type is COPY or&#xA;    INSERT, the corresponding data will be exported.&#xA;&#xA;    See chapter &#34;Exporting views as PostgreSQL table&#34; for more details.&#xA;&#xA;NO_VIEW_ORDERING&#xA;    By default Ora2Pg try to order views to avoid error at import time&#xA;    with nested views. With a huge number of views this can take a very&#xA;    long time, you can bypass this ordering by enabling this directive.&#xA;&#xA;GRANT_OBJECT&#xA;    When exporting GRANTs you can specify a comma separated list of&#xA;    objects for which privilege will be exported. Default is export for&#xA;    all objects. Here are the possibles values TABLE, VIEW, MATERIALIZED&#xA;    VIEW, SEQUENCE, PROCEDURE, FUNCTION, PACKAGE BODY, TYPE, SYNONYM,&#xA;    DIRECTORY. Only one object type is allowed at a time. For example&#xA;    set it to TABLE if you just want to export privilege on tables. You&#xA;    can use the -g option to overwrite it.&#xA;&#xA;    When used this directive prevent the export of users unless it is&#xA;    set to USER. In this case only users definitions are exported.&#xA;&#xA;WHERE&#xA;    This directive allows you to specify a WHERE clause filter when&#xA;    dumping the contents of tables. Value is constructs as follows:&#xA;    TABLE_NAME[WHERE_CLAUSE], or if you have only one where clause for&#xA;    each table just put the where clause as the value. Both are possible&#xA;    too. Here are some examples:&#xA;&#xA;            # Global where clause applying to all tables included in the export&#xA;            WHERE  1=1&#xA;&#xA;            # Apply the where clause only on table TABLE_NAME&#xA;            WHERE  TABLE_NAME[ID1=&#39;001&#39;]&#xA;&#xA;            # Applies two different clause on tables TABLE_NAME and OTHER_TABLE&#xA;            # and a generic where clause on DATE_CREATE to all other tables&#xA;            WHERE  TABLE_NAME[ID1=&#39;001&#39; OR ID1=&#39;002] DATE_CREATE &amp;gt; &#39;2001-01-01&#39; OTHER_TABLE[NAME=&#39;test&#39;]&#xA;&#xA;    Any where clause not included into a table name bracket clause will&#xA;    be applied to all exported table including the tables defined in the&#xA;    where clause. These WHERE clauses are very useful if you want to&#xA;    archive some data or at the opposite only export some recent data.&#xA;&#xA;    To be able to quickly test data import it is useful to limit data&#xA;    export to the first thousand tuples of each table. For Oracle define&#xA;    the following clause:&#xA;&#xA;            WHERE   ROWNUM &amp;lt; 1000&#xA;&#xA;    and for MySQL, use the following:&#xA;&#xA;            WHERE   1=1 LIMIT 1,1000&#xA;&#xA;    This can also be restricted to some tables data export.&#xA;&#xA;    Command line option -W or --where will override this directive for&#xA;    the global part and per table if the table names is the same.&#xA;&#xA;TOP_MAX&#xA;    This directive is used to limit the number of item shown in the top&#xA;    N lists like the top list of tables per number of rows and the top&#xA;    list of largest tables in megabytes. By default it is set to 10&#xA;    items.&#xA;&#xA;LOG_ON_ERROR&#xA;    Enable this directive if you want to continue direct data import on&#xA;    error. When Ora2Pg received an error in the COPY or INSERT statement&#xA;    from PostgreSQL it will log the statement to a file called&#xA;    TABLENAME_error.log in the output directory and continue to next&#xA;    bulk of data. Like this you can try to fix the statement and&#xA;    manually reload the error log file. Default is disabled: abort&#xA;    import on error.&#xA;&#xA;REPLACE_QUERY&#xA;    Sometime you may want to extract data from an Oracle table but you&#xA;    need a custom query for that. Not just a &#34;SELECT * FROM table&#34; like&#xA;    Ora2Pg do but a more complex query. This directive allows you to&#xA;    overwrite the query used by Ora2Pg to extract data. The format is&#xA;    TABLENAME[SQL_QUERY]. If you have multiple table to extract by&#xA;    replacing the Ora2Pg query, you can define multiple REPLACE_QUERY&#xA;    lines.&#xA;&#xA;            REPLACE_QUERY   EMPLOYEES[SELECT e.id,e.fisrtname,lastname FROM EMPLOYEES e JOIN EMP_UPDT u ON (e.id=u.id AND u.cdate&amp;gt;&#39;2014-08-01 00:00:00&#39;)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Control of Full Text Search export Several directives can be used to control the way Ora2Pg will export the Oracle&#39;s Text search indexes. By default CONTEXT indexes will be exported to PostgreSQL FTS indexes but CTXCAT indexes will be exported as indexes using the pg_trgm extension.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;CONTEXT_AS_TRGM&#xA;    Force Ora2Pg to translate Oracle Text indexes into PostgreSQL&#xA;    indexes using pg_trgm extension. Default is to translate CONTEXT&#xA;    indexes into FTS indexes and CTXCAT indexes using pg_trgm. Most of&#xA;    the time using pg_trgm is enough, this is why this directive stand&#xA;    for. You need to create the pg_trgm extension into the destination&#xA;    database before importing the objects:&#xA;&#xA;            CREATE EXTENSION pg_trgm;&#xA;&#xA;FTS_INDEX_ONLY&#xA;    By default Ora2Pg creates a function-based index to translate Oracle&#xA;    Text indexes.&#xA;&#xA;            CREATE INDEX ON t_document&#xA;                    USING gin(to_tsvector(&#39;pg_catalog.french&#39;, title));&#xA;&#xA;    You will have to rewrite the CONTAIN() clause using to_tsvector(),&#xA;    example:&#xA;&#xA;            SELECT id,title FROM t_document&#xA;                    WHERE to_tsvector(title)) @@ to_tsquery(&#39;search_word&#39;);&#xA;&#xA;    To force Ora2Pg to create an extra tsvector column with a dedicated&#xA;    triggers for FTS indexes, disable this directive. In this case,&#xA;    Ora2Pg will add the column as follow: ALTER TABLE t_document ADD&#xA;    COLUMN tsv_title tsvector; Then update the column to compute FTS&#xA;    vectors if data have been loaded before UPDATE t_document SET&#xA;    tsv_title = to_tsvector(&#39;pg_catalog.french&#39;, coalesce(title,&#39;&#39;)); To&#xA;    automatically update the column when a modification in the title&#xA;    column appears, Ora2Pg adds the following trigger:&#xA;&#xA;            CREATE FUNCTION tsv_t_document_title() RETURNS trigger AS $$&#xA;            BEGIN&#xA;                   IF TG_OP = &#39;INSERT&#39; OR new.title != old.title THEN&#xA;                           new.tsv_title :=&#xA;                           to_tsvector(&#39;pg_catalog.french&#39;, coalesce(new.title,&#39;&#39;));&#xA;                   END IF;&#xA;                   return new;&#xA;            END&#xA;            $$ LANGUAGE plpgsql;&#xA;            CREATE TRIGGER trig_tsv_t_document_title BEFORE INSERT OR UPDATE&#xA;             ON t_document&#xA;             FOR EACH ROW EXECUTE PROCEDURE tsv_t_document_title();&#xA;&#xA;    When the Oracle text index is defined over multiple column, Ora2Pg&#xA;    will use setweight() to set a weight in the order of the column&#xA;    declaration.&#xA;&#xA;FTS_CONFIG&#xA;    Use this directive to force text search configuration to use. When&#xA;    it is not set, Ora2Pg will autodetect the stemmer used by Oracle for&#xA;    each index and pg_catalog.english if the information is not found.&#xA;&#xA;USE_UNACCENT&#xA;    If you want to perform your text search in an accent insensitive&#xA;    way, enable this directive. Ora2Pg will create an helper function&#xA;    over unaccent() and creates the pg_trgm indexes using this function.&#xA;    With FTS Ora2Pg will redefine your text search configuration, for&#xA;    example:&#xA;&#xA;          CREATE TEXT SEARCH CONFIGURATION fr (COPY = french); &#xA;          ALTER TEXT SEARCH CONFIGURATION fr&#xA;                  ALTER MAPPING FOR hword, hword_part, word WITH unaccent, french_stem;&#xA;&#xA;    then set the FTS_CONFIG ora2pg.conf directive to fr instead of&#xA;    pg_catalog.english.&#xA;&#xA;    When enabled, Ora2pg will create the wrapper function:&#xA;&#xA;          CREATE OR REPLACE FUNCTION unaccent_immutable(text)&#xA;          RETURNS text AS&#xA;          $$&#xA;              SELECT public.unaccent(&#39;public.unaccent&#39;, $1);&#xA;          $$ LANGUAGE sql IMMUTABLE&#xA;             COST 1;&#xA;&#xA;    the indexes are exported as follow:&#xA;&#xA;          CREATE INDEX t_document_title_unaccent_trgm_idx ON t_document &#xA;              USING gin (unaccent_immutable(title) gin_trgm_ops);&#xA;&#xA;    In your queries you will need to use the same function in the search&#xA;    to be able to use the function-based index. Example:&#xA;&#xA;            SELECT * FROM t_document&#xA;                    WHERE unaccent_immutable(title) LIKE &#39;%donnees%&#39;;&#xA;&#xA;USE_LOWER_UNACCENT&#xA;    Same as above but call lower() in the unaccent_immutable() function:&#xA;&#xA;          CREATE OR REPLACE FUNCTION unaccent_immutable(text)&#xA;          RETURNS text AS&#xA;          $$&#xA;              SELECT lower(public.unaccent(&#39;public.unaccent&#39;, $1));&#xA;          $$ LANGUAGE sql IMMUTABLE;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Modifying object structure One of the great usage of Ora2Pg is its flexibility to replicate Oracle database into PostgreSQL database with a different structure or schema. There&#39;s three configuration directives that allow you to map those differences.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;REORDERING_COLUMNS&#xA;    Enable this directive to reordering columns and minimized the&#xA;    footprint on disc, so that more rows fit on a data page, which is&#xA;    the most important factor for speed. Default is disabled, that mean&#xA;    the same order than in Oracle tables definition, that&#39;s should be&#xA;    enough for most usage. This directive is only used with TABLE&#xA;    export.&#xA;&#xA;MODIFY_STRUCT&#xA;    This directive allows you to limit the columns to extract for a&#xA;    given table. The value consist in a space-separated list of table&#xA;    name with a set of column between parenthesis as follow:&#xA;&#xA;            MODIFY_STRUCT   NOM_TABLE(nomcol1,nomcol2,...) ...&#xA;&#xA;    for example:&#xA;&#xA;            MODIFY_STRUCT   T_TEST1(id,dossier) T_TEST2(id,fichier)&#xA;&#xA;    This will only extract columns &#39;id&#39; and &#39;dossier&#39; from table T_TEST1&#xA;    and columns &#39;id&#39; and &#39;fichier&#39; from the T_TEST2 table. This&#xA;    directive can only be used with TABLE, COPY or INSERT export. With&#xA;    TABLE export create table DDL will respect the new list of columns&#xA;    and all indexes or foreign key pointing to or from a column removed&#xA;    will not be exported.&#xA;&#xA;REPLACE_TABLES&#xA;    This directive allows you to remap a list of Oracle table name to a&#xA;    PostgreSQL table name during export. The value is a list of&#xA;    space-separated values with the following structure:&#xA;&#xA;            REPLACE_TABLES  ORIG_TBNAME1:DEST_TBNAME1 ORIG_TBNAME2:DEST_TBNAME2&#xA;&#xA;    Oracle tables ORIG_TBNAME1 and ORIG_TBNAME2 will be respectively&#xA;    renamed into DEST_TBNAME1 and DEST_TBNAME2&#xA;&#xA;REPLACE_COLS&#xA;    Like table name, the name of the column can be remapped to a&#xA;    different name using the following syntax:&#xA;&#xA;            REPLACE_COLS    ORIG_TBNAME(ORIG_COLNAME1:NEW_COLNAME1,ORIG_COLNAME2:NEW_COLNAME2)&#xA;&#xA;    For example:&#xA;&#xA;            REPLACE_COLS    T_TEST(dico:dictionary,dossier:folder)&#xA;&#xA;    will rename Oracle columns &#39;dico&#39; and &#39;dossier&#39; from table T_TEST&#xA;    into new name &#39;dictionary&#39; and &#39;folder&#39;.&#xA;&#xA;REPLACE_AS_BOOLEAN&#xA;    If you want to change the type of some Oracle columns into&#xA;    PostgreSQL boolean during the export you can define here a list of&#xA;    tables and column separated by space as follow.&#xA;&#xA;            REPLACE_AS_BOOLEAN     TB_NAME1:COL_NAME1 TB_NAME1:COL_NAME2 TB_NAME2:COL_NAME2&#xA;&#xA;    The values set in the boolean columns list will be replaced with the&#xA;    &#39;t&#39; and &#39;f&#39; following the default replacement values and those&#xA;    additionally set in directive BOOLEAN_VALUES.&#xA;&#xA;    Note that if you have modified the table name with REPLACE_TABLES&#xA;    and/or the column&#39;s name, you need to use the name of the original&#xA;    table and/or column.&#xA;&#xA;            REPLACE_COLS            TB_NAME1(OLD_COL_NAME1:NEW_COL_NAME1)&#xA;            REPLACE_AS_BOOLEAN      TB_NAME1:OLD_COL_NAME1&#xA;&#xA;    You can also give a type and a precision to automatically convert&#xA;    all fields of that type as a boolean. For example:&#xA;&#xA;            REPLACE_AS_BOOLEAN      NUMBER:1 CHAR:1 TB_NAME1:COL_NAME1 TB_NAME1:COL_NAME2&#xA;&#xA;    will also replace any field of type number(1) or char(1) as a&#xA;    boolean in all exported tables.&#xA;&#xA;BOOLEAN_VALUES&#xA;    Use this to add additional definition of the possible boolean values&#xA;    used in Oracle fields. You must set a space-separated list of&#xA;    TRUE:FALSE values. By default here are the values recognized by&#xA;    Ora2Pg:&#xA;&#xA;            BOOLEAN_VALUES          yes:no y:n 1:0 true:false enabled:disabled&#xA;&#xA;    Any values defined here will be added to the default list.&#xA;&#xA;REPLACE_ZERO_DATE&#xA;    When Ora2Pg find a &#34;zero&#34; date: 0000-00-00 00:00:00 it is replaced&#xA;    by a NULL. This could be a problem if your column is defined with&#xA;    NOT NULL constraint. If you can not remove the constraint, use this&#xA;    directive to set an arbitral date that will be used instead. You can&#xA;    also use -INFINITY if you don&#39;t want to use a fake date.&#xA;&#xA;INDEXES_SUFFIX&#xA;    Add the given value as suffix to indexes names. Useful if you have&#xA;    indexes with same name as tables. For example:&#xA;&#xA;            INDEXES_SUFFIX          _idx&#xA;&#xA;    will add _idx at ed of all index name. Not so common but can help.&#xA;&#xA;INDEXES_RENAMING&#xA;    Enable this directive to rename all indexes using&#xA;    tablename_columns_names. Could be very useful for database that have&#xA;    multiple time the same index name or that use the same name than a&#xA;    table, which is not allowed by PostgreSQL Disabled by default.&#xA;&#xA;USE_INDEX_OPCLASS&#xA;    Operator classes text_pattern_ops, varchar_pattern_ops, and&#xA;    bpchar_pattern_ops support B-tree indexes on the corresponding&#xA;    types. The difference from the default operator classes is that the&#xA;    values are compared strictly character by character rather than&#xA;    according to the locale-specific collation rules. This makes these&#xA;    operator classes suitable for use by queries involving pattern&#xA;    matching expressions (LIKE or POSIX regular expressions) when the&#xA;    database does not use the standard &#34;C&#34; locale. If you enable, with&#xA;    value 1, this will force Ora2Pg to export all indexes defined on&#xA;    varchar2() and char() columns using those operators. If you set it&#xA;    to a value greater than 1 it will only change indexes on columns&#xA;    where the character limit is greater or equal than this value. For&#xA;    example, set it to 128 to create these kind of indexes on columns of&#xA;    type varchar2(N) where N &amp;gt;= 128.&#xA;&#xA;PREFIX_PARTITION&#xA;    Enable this directive if you want that your partition table name&#xA;    will be exported using the parent table name. Disabled by default.&#xA;    If you have multiple partitioned table, when exported to PostgreSQL&#xA;    some partitions could have the same name but different parent&#xA;    tables. This is not allowed, table name must be unique.&#xA;&#xA;PREFIX_SUB_PARTITION&#xA;    Enable this directive if you want that your subpartition table name&#xA;    will be exported using the parent partition name. Enabled by&#xA;    default. If the partition names are a part of the subpartition&#xA;    names, you should enable this directive.&#xA;&#xA;DISABLE_PARTITION&#xA;    If you don&#39;t want to reproduce the partitioning like in Oracle and&#xA;    want to export all partitioned Oracle data into the main single&#xA;    table in PostgreSQL enable this directive. Ora2Pg will export all&#xA;    data into the main table name. Default is to use partitioning,&#xA;    Ora2Pg will export data from each partition and import them into the&#xA;    PostgreSQL dedicated partition table.&#xA;&#xA;DISABLE_UNLOGGED&#xA;    By default Ora2Pg export Oracle tables with the NOLOGGING attribute&#xA;    as UNLOGGED tables. You may want to fully disable this feature&#xA;    because you will lose all data from unlogged tables in case of a&#xA;    PostgreSQL crash. Set it to 1 to export all tables as normal tables.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Oracle Spatial to PostGis Ora2Pg fully export Spatial object from Oracle database. There&#39;s some configuration directives that could be used to control the export.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;AUTODETECT_SPATIAL_TYPE&#xA;    By default Ora2Pg is looking at indexes to see the spatial&#xA;    constraint type and dimensions defined under Oracle. Those&#xA;    constraints are passed as at index creation using for example:&#xA;&#xA;            CREATE INDEX ... INDEXTYPE IS MDSYS.SPATIAL_INDEX&#xA;            PARAMETERS(&#39;sdo_indx_dims=2, layer_gtype=point&#39;);&#xA;&#xA;    If those Oracle constraints parameters are not set, the default is&#xA;    to export those columns as generic type GEOMETRY to be able to&#xA;    receive any spatial type.&#xA;&#xA;    The AUTODETECT_SPATIAL_TYPE directive allows to force Ora2Pg to&#xA;    autodetect the real spatial type and dimension used in a spatial&#xA;    column otherwise a non- constrained &#34;geometry&#34; type is used.&#xA;    Enabling this feature will force Ora2Pg to scan a sample of 50000&#xA;    column to look at the GTYPE used. You can increase or reduce the&#xA;    sample size by setting the value of AUTODETECT_SPATIAL_TYPE to the&#xA;    desired number of line to scan. The directive is enabled by default.&#xA;&#xA;    For example, in the case of a column named shape and defined with&#xA;    Oracle type SDO_GEOMETRY, with AUTODETECT_SPATIAL_TYPE disabled it&#xA;    will be converted as:&#xA;&#xA;        shape geometry(GEOMETRY) or shape geometry(GEOMETRYZ, 4326)&#xA;&#xA;    and if the directive is enabled and the column just contains a&#xA;    single geometry type that use a single dimension:&#xA;&#xA;        shape geometry(POLYGON, 4326) or shape geometry(POLYGONZ, 4326)&#xA;&#xA;    with a two or three dimensional polygon.&#xA;&#xA;CONVERT_SRID&#xA;    This directive allows you to control the automatically conversion of&#xA;    Oracle SRID to standard EPSG. If enabled, Ora2Pg will use the Oracle&#xA;    function sdo_cs.map_oracle_srid_to_epsg() to convert all SRID.&#xA;    Enabled by default.&#xA;&#xA;    If the SDO_SRID returned by Oracle is NULL, it will be replaced by&#xA;    the default value 8307 converted to its EPSG value: 4326 (see&#xA;    DEFAULT_SRID).&#xA;&#xA;    If the value is upper than 1, all SRID will be forced to this value,&#xA;    in this case DEFAULT_SRID will not be used when Oracle returns a&#xA;    null value and the value will be forced to CONVERT_SRID.&#xA;&#xA;    Note that it is also possible to set the EPSG value on Oracle side&#xA;    when sdo_cs.map_oracle_srid_to_epsg() return NULL if your want to&#xA;    force the value:&#xA;&#xA;      system@db&amp;gt; UPDATE sdo_coord_ref_sys SET legacy_code=41014 WHERE srid = 27572;&#xA;&#xA;DEFAULT_SRID&#xA;    Use this directive to override the default EPSG SRID to used: 4326.&#xA;    Can be overwritten by CONVERT_SRID, see above.&#xA;&#xA;GEOMETRY_EXTRACT_TYPE&#xA;    This directive can take three values: WKT (default), WKB and&#xA;    INTERNAL. When it is set to WKT, Ora2Pg will use&#xA;    SDO_UTIL.TO_WKTGEOMETRY() to extract the geometry data. When it is&#xA;    set to WKB, Ora2Pg will use the binary output using&#xA;    SDO_UTIL.TO_WKBGEOMETRY(). If those two extract type are calls at&#xA;    Oracle side, they are slow and you can easily reach Out Of Memory&#xA;    when you have lot of rows. Also WKB is not able to export 3D&#xA;    geometry and some geometries like CURVEPOLYGON. In this case you may&#xA;    use the INTERNAL extraction type. It will use a Pure Perl library to&#xA;    convert the SDO_GEOMETRY data into a WKT representation, the&#xA;    translation is done on Ora2Pg side. This is a work in progress,&#xA;    please validate your exported data geometries before use. Default&#xA;    spatial object extraction type is INTERNAL.&#xA;&#xA;POSTGIS_SCHEMA&#xA;    Use this directive to add a specific schema to the search path to&#xA;    look for PostGis functions.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;PostgreSQL Import By default conversion to PostgreSQL format is written to file &#39;output.sql&#39;. The command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        psql mydb &amp;lt; output.sql&#xA;&#xA;will import content of file output.sql into PostgreSQL mydb database.&#xA;&#xA;DATA_LIMIT&#xA;    When you are performing INSERT/COPY export Ora2Pg proceed by chunks&#xA;    of DATA_LIMIT tuples for speed improvement. Tuples are stored in&#xA;    memory before being written to disk, so if you want speed and have&#xA;    enough system resources you can grow this limit to an upper value&#xA;    for example: 100000 or 1000000. Before release 7.0 a value of 0 mean&#xA;    no limit so that all tuples are stored in memory before being&#xA;    flushed to disk. In 7.x branch this has been remove and chunk will&#xA;    be set to the default: 10000&#xA;&#xA;BLOB_LIMIT&#xA;    When Ora2Pg detect a table with some BLOB it will automatically&#xA;    reduce the value of this directive by dividing it by 10 until his&#xA;    value is below 1000. You can control this value by setting&#xA;    BLOB_LIMIT. Exporting BLOB use lot of resources, setting it to a too&#xA;    high value can produce OOM.&#xA;&#xA;OUTPUT&#xA;    The Ora2Pg output filename can be changed with this directive.&#xA;    Default value is output.sql. if you set the file name with extension&#xA;    .gz or .bz2 the output will be automatically compressed. This&#xA;    require that the Compress::Zlib Perl module is installed if the&#xA;    filename extension is .gz and that the bzip2 system command is&#xA;    installed for the .bz2 extension.&#xA;&#xA;OUTPUT_DIR&#xA;    Since release 7.0, you can define a base directory where the file&#xA;    will be written. The directory must exists.&#xA;&#xA;BZIP2&#xA;    This directive allows you to specify the full path to the bzip2&#xA;    program if it can not be found in the PATH environment variable.&#xA;&#xA;FILE_PER_CONSTRAINT&#xA;    Allow object constraints to be saved in a separate file during&#xA;    schema export. The file will be named CONSTRAINTS_OUTPUT, where&#xA;    OUTPUT is the value of the corresponding configuration directive.&#xA;    You can use .gz xor .bz2 extension to enable compression. Default is&#xA;    to save all data in the OUTPUT file. This directive is usable only&#xA;    with TABLE export type.&#xA;&#xA;    The constraints can be imported quickly into PostgreSQL using the&#xA;    LOAD export type to parallelize their creation over multiple (-j or&#xA;    JOBS) connections.&#xA;&#xA;FILE_PER_INDEX&#xA;    Allow indexes to be saved in a separate file during schema export.&#xA;    The file will be named INDEXES_OUTPUT, where OUTPUT is the value of&#xA;    the corresponding configuration directive. You can use .gz xor .bz2&#xA;    file extension to enable compression. Default is to save all data in&#xA;    the OUTPUT file. This directive is usable only with TABLE AND&#xA;    TABLESPACE export type. With the TABLESPACE export, it is used to&#xA;    write &#34;ALTER INDEX ... TABLESPACE ...&#34; into a separate file named&#xA;    TBSP_INDEXES_OUTPUT that can be loaded at end of the migration after&#xA;    the indexes creation to move the indexes.&#xA;&#xA;    The indexes can be imported quickly into PostgreSQL using the LOAD&#xA;    export type to parallelize their creation over multiple (-j or JOBS)&#xA;    connections.&#xA;&#xA;FILE_PER_FKEYS&#xA;    Allow foreign key declaration to be saved in a separate file during&#xA;    schema export. By default foreign keys are exported into the main&#xA;    output file or in the CONSTRAINT_output.sql file. When enabled&#xA;    foreign keys will be exported into a file named FKEYS_output.sql&#xA;&#xA;FILE_PER_TABLE&#xA;    Allow data export to be saved in one file per table/view. The files&#xA;    will be named as tablename_OUTPUT, where OUTPUT is the value of the&#xA;    corresponding configuration directive. You can still use .gz xor&#xA;    .bz2 extension in the OUTPUT directive to enable compression.&#xA;    Default 0 will save all data in one file, set it to 1 to enable this&#xA;    feature. This is usable only during INSERT or COPY export type.&#xA;&#xA;FILE_PER_FUNCTION&#xA;    Allow functions, procedures and triggers to be saved in one file per&#xA;    object. The files will be named as objectname_OUTPUT. Where OUTPUT&#xA;    is the value of the corresponding configuration directive. You can&#xA;    still use .gz xor .bz2 extension in the OUTPUT directive to enable&#xA;    compression. Default 0 will save all in one single file, set it to 1&#xA;    to enable this feature. This is usable only during the corresponding&#xA;    export type, the package body export has a special behavior.&#xA;&#xA;    When export type is PACKAGE and you&#39;ve enabled this directive,&#xA;    Ora2Pg will create a directory per package, named with the lower&#xA;    case name of the package, and will create one file per&#xA;    function/procedure into that directory. If the configuration&#xA;    directive is not enabled, it will create one file per package as&#xA;    packagename_OUTPUT, where OUTPUT is the value of the corresponding&#xA;    directive.&#xA;&#xA;TRUNCATE_TABLE&#xA;    If this directive is set to 1, a TRUNCATE TABLE instruction will be&#xA;    add before loading data. This is usable only during INSERT or COPY&#xA;    export type.&#xA;&#xA;    When activated, the instruction will be added only if there&#39;s no&#xA;    global DELETE clause or not one specific to the current table (see&#xA;    below).&#xA;&#xA;DELETE&#xA;    Support for include a DELETE FROM ... WHERE clause filter before&#xA;    importing data and perform a delete of some lines instead of&#xA;    truncating tables. Value is construct as follow:&#xA;    TABLE_NAME[DELETE_WHERE_CLAUSE], or if you have only one where&#xA;    clause for all tables just put the delete clause as single value.&#xA;    Both are possible too. Here are some examples:&#xA;&#xA;            DELETE  1=1    # Apply to all tables and delete all tuples&#xA;            DELETE  TABLE_TEST[ID1=&#39;001&#39;]   # Apply only on table TABLE_TEST&#xA;            DELETE  TABLE_TEST[ID1=&#39;001&#39; OR ID1=&#39;002] DATE_CREATE &amp;gt; &#39;2001-01-01&#39; TABLE_INFO[NAME=&#39;test&#39;]&#xA;&#xA;    The last applies two different delete where clause on tables&#xA;    TABLE_TEST and TABLE_INFO and a generic delete where clause on&#xA;    DATE_CREATE to all other tables. If TRUNCATE_TABLE is enabled it&#xA;    will be applied to all tables not covered by the DELETE definition.&#xA;&#xA;    These DELETE clauses might be useful with regular &#34;updates&#34;.&#xA;&#xA;STOP_ON_ERROR&#xA;    Set this parameter to 0 to not include the call to \set&#xA;    ON_ERROR_STOP ON in all SQL scripts generated by Ora2Pg. By default&#xA;    this order is always present so that the script will immediately&#xA;    abort when an error is encountered.&#xA;&#xA;COPY_FREEZE&#xA;    Enable this directive to use COPY FREEZE instead of a simple COPY to&#xA;    export data with rows already frozen. This is intended as a&#xA;    performance option for initial data loading. Rows will be frozen&#xA;    only if the table being loaded has been created or truncated in the&#xA;    current sub-transaction. This will only work with export to file and&#xA;    when -J or ORACLE_COPIES is not set or default to 1. It can be used&#xA;    with direct import into PostgreSQL under the same condition but -j&#xA;    or JOBS must also be unset or default to 1.&#xA;&#xA;CREATE_OR_REPLACE&#xA;    By default Ora2Pg uses CREATE OR REPLACE in functions and views DDL,&#xA;    if you need not to override existing functions or views disable this&#xA;    configuration directive, DDL will not include OR REPLACE.&#xA;&#xA;DROP_IF_EXISTS&#xA;    To add a DROP &amp;lt;OBJECT&amp;gt; IF EXISTS before creating the object, enable&#xA;    this directive. Can be useful in an iterative work. Default is&#xA;    disabled.&#xA;&#xA;EXPORT_GTT&#xA;    PostgreSQL do not supports Global Temporary Table natively but you&#xA;    can use the pgtt extension to emulate this behavior. Enable this&#xA;    directive to export global temporary table.&#xA;&#xA;NO_HEADER&#xA;    Enabling this directive will prevent Ora2Pg to print his header into&#xA;    output files. Only the translated code will be written.&#xA;&#xA;PSQL_RELATIVE_PATH&#xA;    By default Ora2Pg use \i psql command to execute generated SQL files&#xA;    if you want to use a relative path following the script execution&#xA;    file enabling this option will use \ir. See psql help for more&#xA;    information.&#xA;&#xA;DATA_VALIDATION_ROWS&#xA;    Number of rows that must be retrieved on both side for data&#xA;    validation. Default it to compare the 10000 first rows. A value of 0&#xA;    mean compare all rows.&#xA;&#xA;DATA_VALIDATION_ORDERING&#xA;    Order of rows between both sides are different once the data have&#xA;    been modified. In this case data must be ordered using a primary key&#xA;    or a unique index, that mean that a table without such object can&#xA;    not be compared. If the validation is done just after the data&#xA;    migration without any data modification the validation can be done&#xA;    on all tables without any ordering.&#xA;&#xA;DATA_VALIDATION_ERROR&#xA;    Stop validating data from a table after a certain amount of row&#xA;    mistmatch. Default is to stop after 10 rows validation errors.&#xA;&#xA;When using Ora2Pg export type INSERT or COPY to dump data to file and&#xA;that FILE_PER_TABLE is enabled, you will be warned that Ora2Pg will not&#xA;export data again if the file already exists. This is to prevent&#xA;downloading twice table with huge amount of data. To force the download&#xA;of data from these tables you have to remove the existing output file&#xA;first.&#xA;&#xA;If you want to import data on the fly to the PostgreSQL database you&#xA;have three configuration directives to set the PostgreSQL database&#xA;connection. This is only possible with COPY or INSERT export type as for&#xA;database schema there&#39;s no real interest to do that.&#xA;&#xA;PG_DSN&#xA;    Use this directive to set the PostgreSQL data source namespace using&#xA;    DBD::Pg Perl module as follow:&#xA;&#xA;            dbi:Pg:dbname=pgdb;host=localhost;port=5432&#xA;&#xA;    will connect to database &#39;pgdb&#39; on localhost at tcp port 5432.&#xA;&#xA;    Note that this directive is only used for data export, other export&#xA;    need to be imported manually through the use og psql or any other&#xA;    PostgreSQL client.&#xA;&#xA;    To use SSL encrypted connection you must add sslmode=require to the&#xA;    connection string like follow:&#xA;&#xA;            dbi:Pg:dbname=pgdb;host=localhost;port=5432;sslmode=require&#xA;&#xA;PG_USER and PG_PWD&#xA;    These two directives are used to set the login user and password.&#xA;&#xA;    If you do not supply a credential with PG_PWD and you have installed&#xA;    the Term::ReadKey Perl module, Ora2Pg will ask for the password&#xA;    interactively. If PG_USER is not set it will be asked interactively&#xA;    too.&#xA;&#xA;SYNCHRONOUS_COMMIT&#xA;    Specifies whether transaction commit will wait for WAL records to be&#xA;    written to disk before the command returns a &#34;success&#34; indication to&#xA;    the client. This is the equivalent to set synchronous_commit&#xA;    directive of postgresql.conf file. This is only used when you load&#xA;    data directly to PostgreSQL, the default is off to disable&#xA;    synchronous commit to gain speed at writing data. Some modified&#xA;    version of PostgreSQL, like greenplum, do not have this setting, so&#xA;    in this set this directive to 1, ora2pg will not try to change the&#xA;    setting.&#xA;&#xA;PG_INITIAL_COMMAND&#xA;    This directive can be used to send an initial command to PostgreSQL,&#xA;    just after the connection. For example to set some session&#xA;    parameters. This directive can be used multiple times.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Column type control PG_NUMERIC_TYPE If set to 1 replace portable numeric type into PostgreSQL internal type. Oracle data type NUMBER(p,s) is approximatively converted to real and float PostgreSQL data type. If you have monetary fields or don&#39;t want rounding issues with the extra decimals you should preserve the same numeric(p,s) PostgreSQL data type. Do that only if you need exactness because using numeric(p,s) is slower than using real or double.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PG_INTEGER_TYPE&#xA;    If set to 1 replace portable numeric type into PostgreSQL internal&#xA;    type. Oracle data type NUMBER(p) or NUMBER are converted to&#xA;    smallint, integer or bigint PostgreSQL data type following the value&#xA;    of the precision. If NUMBER without precision are set to&#xA;    DEFAULT_NUMERIC (see below).&#xA;&#xA;DEFAULT_NUMERIC&#xA;    NUMBER without precision are converted by default to bigint only if&#xA;    PG_INTEGER_TYPE is true. You can overwrite this value to any PG&#xA;    type, like integer or float.&#xA;&#xA;DATA_TYPE&#xA;    If you&#39;re experiencing any problem in data type schema conversion&#xA;    with this directive you can take full control of the correspondence&#xA;    between Oracle and PostgreSQL types to redefine data type&#xA;    translation used in Ora2pg. The syntax is a comma-separated list of&#xA;    &#34;Oracle datatype:Postgresql datatype&#34;. Here are the default list&#xA;    used:&#xA;&#xA;            DATA_TYPE       VARCHAR2:varchar,NVARCHAR2:varchar,DATE:timestamp,LONG:text,LONG RAW:bytea,CLOB:text,NCLOB:text,BLOB:bytea,BFILE:bytea,RAW(16):uuid,RAW(32):uuid,RAW:bytea,UROWID:oid,ROWID:oid,FLOAT:double precision,DEC:decimal,DECIMAL:decimal,DOUBLE PRECISION:double precision,INT:integer,INTEGER:integer,REAL:real,SMALLINT:smallint,BINARY_FLOAT:double precision,BINARY_DOUBLE:double precision,TIMESTAMP:timestamp,XMLTYPE:xml,BINARY_INTEGER:integer,PLS_INTEGER:integer,TIMESTAMP WITH TIME ZONE:timestamp with time zone,TIMESTAMP WITH LOCAL TIME ZONE:timestamp with time zone&#xA;&#xA;    The directive and the list definition must be a single line.&#xA;&#xA;    Note that when a RAW(16) and RAW(32) columns is found or that the&#xA;    RAW column has &#34;SYS_GUID()&#34; as default value Ora2Pg will&#xA;    automatically translate the type of the column into uuid which might&#xA;    be the right translation in most of the case. In this case data will&#xA;    be automatically migrated as PostgreSQL uuid data type provided by&#xA;    the &#34;uuid-ossp&#34; extension.&#xA;&#xA;    If you want to replace a type with a precision and scale you need to&#xA;    escape the coma with a backslash. For example, if you want to&#xA;    replace all NUMBER(*,0) into bigint instead of numeric(38) add the&#xA;    following:&#xA;&#xA;           DATA_TYPE       NUMBER(*\,0):bigint&#xA;&#xA;    You don&#39;t have to recopy all default type conversion but just the&#xA;    one you want to rewrite.&#xA;&#xA;    There&#39;s a special case with BFILE when they are converted to type&#xA;    TEXT, they will just contains the full path to the external file. If&#xA;    you set the destination type to BYTEA, the default, Ora2Pg will&#xA;    export the content of the BFILE as bytea. The third case is when you&#xA;    set the destination type to EFILE, in this case, Ora2Pg will export&#xA;    it as an EFILE record: (DIRECTORY, FILENAME). Use the DIRECTORY&#xA;    export type to export the existing directories as well as privileges&#xA;    on those directories.&#xA;&#xA;    There&#39;s no SQL function available to retrieve the path to the BFILE.&#xA;    Ora2Pg have to create one using the DBMS_LOB package.&#xA;&#xA;            CREATE OR REPLACE FUNCTION ora2pg_get_bfilename( p_bfile IN BFILE )&#xA;            RETURN VARCHAR2&#xA;            AS&#xA;                l_dir   VARCHAR2(4000);&#xA;                l_fname VARCHAR2(4000);&#xA;                l_path  VARCHAR2(4000);&#xA;            BEGIN&#xA;                dbms_lob.FILEGETNAME( p_bfile, l_dir, l_fname );&#xA;                SELECT directory_path INTO l_path FROM all_directories&#xA;                    WHERE directory_name = l_dir;&#xA;                l_dir := rtrim(l_path,&#39;/&#39;);&#xA;                RETURN l_dir || &#39;/&#39; || l_fname;&#xA;            END;&#xA;&#xA;    This function is only created if Ora2Pg found a table with a BFILE&#xA;    column and that the destination type is TEXT. The function is&#xA;    dropped at the end of the export. This concern both, COPY and INSERT&#xA;    export type.&#xA;&#xA;    There&#39;s no SQL function available to retrieve BFILE as an EFILE&#xA;    record, then Ora2Pg have to create one using the DBMS_LOB package.&#xA;&#xA;            CREATE OR REPLACE FUNCTION ora2pg_get_efile( p_bfile IN BFILE )&#xA;            RETURN VARCHAR2&#xA;            AS&#xA;                l_dir   VARCHAR2(4000);&#xA;                l_fname VARCHAR2(4000);&#xA;            BEGIN&#xA;                dbms_lob.FILEGETNAME( p_bfile, l_dir, l_fname );&#xA;                RETURN &#39;(&#39; || l_dir || &#39;,&#39; || l_fnamei || &#39;)&#39;;&#xA;            END;&#xA;&#xA;    This function is only created if Ora2Pg found a table with a BFILE&#xA;    column and that the destination type is EFILE. The function is&#xA;    dropped at the end of the export. This concern both, COPY and INSERT&#xA;    export type.&#xA;&#xA;    To set the destination type, use the DATA_TYPE configuration&#xA;    directive:&#xA;&#xA;            DATA_TYPE       BFILE:EFILE&#xA;&#xA;    for example.&#xA;&#xA;    The EFILE type is a user defined type created by the PostgreSQL&#xA;    extension external_file that can be found here:&#xA;    https://github.com/darold/external_file This is a port of the BFILE&#xA;    Oracle type to PostgreSQL.&#xA;&#xA;    There&#39;s no SQL function available to retrieve the content of a&#xA;    BFILE. Ora2Pg have to create one using the DBMS_LOB package.&#xA;&#xA;            CREATE OR REPLACE FUNCTION ora2pg_get_bfile( p_bfile IN BFILE ) RETURN&#xA;            BLOB&#xA;              AS&#xA;                    filecontent BLOB := NULL;&#xA;                    src_file BFILE := NULL;&#xA;                    l_step PLS_INTEGER := 12000;&#xA;                    l_dir   VARCHAR2(4000);&#xA;                    l_fname VARCHAR2(4000);&#xA;                    offset NUMBER := 1;&#xA;              BEGIN&#xA;                IF p_bfile IS NULL THEN&#xA;                  RETURN NULL;&#xA;                END IF;&#xA;&#xA;                DBMS_LOB.FILEGETNAME( p_bfile, l_dir, l_fname );&#xA;                src_file := BFILENAME( l_dir, l_fname );&#xA;                IF src_file IS NULL THEN&#xA;                    RETURN NULL;&#xA;                END IF;&#xA;&#xA;                DBMS_LOB.FILEOPEN(src_file, DBMS_LOB.FILE_READONLY);&#xA;                DBMS_LOB.CREATETEMPORARY(filecontent, true);&#xA;                DBMS_LOB.LOADBLOBFROMFILE (filecontent, src_file, DBMS_LOB.LOBMAXSIZE, offset, offset);&#xA;                DBMS_LOB.FILECLOSE(src_file);&#xA;                RETURN filecontent;&#xA;            END;&#xA;&#xA;    This function is only created if Ora2Pg found a table with a BFILE&#xA;    column and that the destination type is bytea (the default). The&#xA;    function is dropped at the end of the export. This concern both,&#xA;    COPY and INSERT export type.&#xA;&#xA;    About the ROWID and UROWID, they are converted into OID by &#34;logical&#34;&#xA;    default but this will through an error at data import. There is no&#xA;    equivalent data type so you might want to use the DATA_TYPE&#xA;    directive to change the corresponding type in PostgreSQL. You should&#xA;    consider replacing this data type by a bigserial (autoincremented&#xA;    sequence), text or uuid data type.&#xA;&#xA;MODIFY_TYPE&#xA;    Sometimes you need to force the destination type, for example a&#xA;    column exported as timestamp by Ora2Pg can be forced into type date.&#xA;    Value is a comma-separated list of TABLE:COLUMN:TYPE structure. If&#xA;    you need to use comma or space inside type definition you will have&#xA;    to backslash them.&#xA;&#xA;            MODIFY_TYPE     TABLE1:COL3:varchar,TABLE1:COL4:decimal(9\,6)&#xA;&#xA;    Type of table1.col3 will be replaced by a varchar and table1.col4 by&#xA;    a decimal with precision and scale.&#xA;&#xA;    If the column&#39;s type is a user defined type Ora2Pg will autodetect&#xA;    the composite type and will export its data using ROW(). Some Oracle&#xA;    user defined types are just array of a native type, in this case you&#xA;    may want to transform this column in simple array of a PostgreSQL&#xA;    native type. To do so, just redefine the destination type as wanted&#xA;    and Ora2Pg will also transform the data as an array. For example,&#xA;    with the following definition in Oracle:&#xA;&#xA;            CREATE OR REPLACE TYPE mem_type IS VARRAY(10) of VARCHAR2(15);&#xA;            CREATE TABLE club (Name VARCHAR2(10),&#xA;                    Address VARCHAR2(20),&#xA;                    City VARCHAR2(20),&#xA;                    Phone VARCHAR2(8),&#xA;                    Members mem_type&#xA;            );&#xA;&#xA;    custom type &#34;mem_type&#34; is just a string array and can be translated&#xA;    into the following in PostgreSQL:&#xA;&#xA;            CREATE TABLE club (&#xA;                    name varchar(10),&#xA;                    address varchar(20),&#xA;                    city varchar(20),&#xA;                    phone varchar(8),&#xA;                    members text[]&#xA;            ) ;&#xA;&#xA;    To do so, just use the directive as follow:&#xA;&#xA;            MODIFY_TYPE     CLUB:MEMBERS:text[]&#xA;&#xA;    Ora2Pg will take care to transform all data of this column in the&#xA;    correct format. Only arrays of characters and numerics types are&#xA;    supported.&#xA;&#xA;TO_NUMBER_CONVERSION&#xA;    By default Oracle call to function TO_NUMBER will be translated as a&#xA;    cast into numeric. For example, TO_NUMBER(&#39;10.1234&#39;) is converted&#xA;    into PostgreSQL call to_number(&#39;10.1234&#39;)::numeric. If you want you&#xA;    can cast the call to integer or bigint by changing the value of the&#xA;    configuration directive. If you need better control of the format,&#xA;    just set it as value, for example: TO_NUMBER_CONVERSION&#xA;    99999999999999999999.9999999999 will convert the code above as:&#xA;    TO_NUMBER(&#39;10.1234&#39;, &#39;99999999999999999999.9999999999&#39;) Any value of&#xA;    the directive that it is not numeric, integer or bigint will be&#xA;    taken as a mask format. If set to none, no conversion will be done.&#xA;&#xA;VARCHAR_TO_TEXT&#xA;    By default varchar2 without size constraint are tranlated into text.&#xA;    If you want to keep the varchar name, disable this directive.&#xA;&#xA;FORCE_IDENTITY_BIGINT&#xA;    Usually identity column must be bigint to correspond to an auto&#xA;    increment sequence so Ora2Pg always force it to be a bigint. If, for&#xA;    any reason you want Ora2Pg to respect the DATA_TYPE you have set for&#xA;    identity column then disable this directive.&#xA;&#xA;TO_CHAR_NOTIMEZONE&#xA;    If you want Ora2Pg to remove any timezone information into the&#xA;    format part of the TO_CHAR() function, enable this directive.&#xA;    Disabled by default.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Taking export under control The following other configuration directives interact directly with the export process and give you fine granularity in database export control.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SKIP&#xA;    For TABLE export you may not want to export all schema constraints,&#xA;    the SKIP configuration directive allows you to specify a&#xA;    space-separated list of constraints that should not be exported.&#xA;    Possible values are:&#xA;&#xA;            - fkeys: turn off foreign key constraints&#xA;            - pkeys: turn off primary keys&#xA;            - ukeys: turn off unique column constraints&#xA;            - indexes: turn off all other index types&#xA;            - checks: turn off check constraints&#xA;&#xA;    For example:&#xA;&#xA;            SKIP    indexes,checks&#xA;&#xA;    will removed indexes and check constraints from export.&#xA;&#xA;PKEY_IN_CREATE&#xA;    Enable this directive if you want to add primary key definition&#xA;    inside the create table statement. If disabled (the default) primary&#xA;    key definition will be added with an alter table statement. Enable&#xA;    it if you are exporting to GreenPlum PostgreSQL database.&#xA;&#xA;KEEP_PKEY_NAMES&#xA;    By default names of the primary and unique key in the source Oracle&#xA;    database are ignored and key names are autogenerated in the target&#xA;    PostgreSQL database with the PostgreSQL internal default naming&#xA;    rules. If you want to preserve Oracle primary and unique key names&#xA;    set this option to 1.&#xA;&#xA;FKEY_ADD_UPDATE&#xA;    This directive allows you to add an ON UPDATE CASCADE option to a&#xA;    foreign key when a ON DELETE CASCADE is defined or always. Oracle do&#xA;    not support this feature, you have to use trigger to operate the ON&#xA;    UPDATE CASCADE. As PostgreSQL has this feature, you can choose how&#xA;    to add the foreign key option. There are three values to this&#xA;    directive: never, the default that mean that foreign keys will be&#xA;    declared exactly like in Oracle. The second value is delete, that&#xA;    mean that the ON UPDATE CASCADE option will be added only if the ON&#xA;    DELETE CASCADE is already defined on the foreign Keys. The last&#xA;    value, always, will force all foreign keys to be defined using the&#xA;    update option.&#xA;&#xA;FKEY_DEFERRABLE&#xA;    When exporting tables, Ora2Pg normally exports constraints as they&#xA;    are, if they are non-deferrable they are exported as non-deferrable.&#xA;    However, non-deferrable constraints will probably cause problems&#xA;    when attempting to import data to Pg. The FKEY_DEFERRABLE option set&#xA;    to 1 will cause all foreign key constraints to be exported as&#xA;    deferrable.&#xA;&#xA;DEFER_FKEY&#xA;    In addition to exporting data when the DEFER_FKEY option set to 1,&#xA;    it will add a command to defer all foreign key constraints during&#xA;    data export and the import will be done in a single transaction.&#xA;    This will work only if foreign keys have been exported as deferrable&#xA;    and you are not using direct import to PostgreSQL (PG_DSN is not&#xA;    defined). Constraints will then be checked at the end of the&#xA;    transaction.&#xA;&#xA;    This directive can also be enabled if you want to force all foreign&#xA;    keys to be created as deferrable and initially deferred during&#xA;    schema export (TABLE export type).&#xA;&#xA;DROP_FKEY&#xA;    If deferring foreign keys is not possible due to the amount of data&#xA;    in a single transaction, you&#39;ve not exported foreign keys as&#xA;    deferrable or you are using direct import to PostgreSQL, you can use&#xA;    the DROP_FKEY directive.&#xA;&#xA;    It will drop all foreign keys before all data import and recreate&#xA;    them at the end of the import.&#xA;&#xA;DROP_INDEXES&#xA;    This directive allows you to gain lot of speed improvement during&#xA;    data import by removing all indexes that are not an automatic index&#xA;    (indexes of primary keys) and recreate them at the end of data&#xA;    import. Of course it is far better to not import indexes and&#xA;    constraints before having imported all data.&#xA;&#xA;DISABLE_TRIGGERS&#xA;    This directive is used to disable triggers on all tables in COPY or&#xA;    INSERT export modes. Available values are USER (disable user-defined&#xA;    triggers only) and ALL (includes RI system triggers). Default is 0:&#xA;    do not add SQL statements to disable trigger before data import.&#xA;&#xA;    If you want to disable triggers during data migration, set the value&#xA;    to USER if your are connected as non superuser and ALL if you are&#xA;    connected as PostgreSQL superuser. A value of 1 is equal to USER.&#xA;&#xA;DISABLE_SEQUENCE&#xA;    If set to 1 it disables alter of sequences on all tables during COPY&#xA;    or INSERT export mode. This is used to prevent the update of&#xA;    sequence during data migration. Default is 0, alter sequences.&#xA;&#xA;NOESCAPE&#xA;    By default all data that are not of type date or time are escaped.&#xA;    If you experience any problem with that you can set it to 1 to&#xA;    disable character escaping during data export. This directive is&#xA;    only used during a COPY export. See STANDARD_CONFORMING_STRINGS for&#xA;    enabling/disabling escape with INSERT statements.&#xA;&#xA;STANDARD_CONFORMING_STRINGS&#xA;    This controls whether ordinary string literals (&#39;...&#39;) treat&#xA;    backslashes literally, as specified in SQL standard. This was the&#xA;    default before Ora2Pg v8.5 so that all strings was escaped first,&#xA;    now this is currently on, causing Ora2Pg to use the escape string&#xA;    syntax (E&#39;...&#39;) if this parameter is not set to 0. This is the exact&#xA;    behavior of the same option in PostgreSQL. This directive is only&#xA;    used during data export to build INSERT statements. See NOESCAPE for&#xA;    enabling/disabling escape in COPY statements.&#xA;&#xA;TRIM_TYPE&#xA;    If you want to convert CHAR(n) from Oracle into varchar(n) or text&#xA;    on PostgreSQL using directive DATA_TYPE, you might want to do some&#xA;    trimming on the data. By default Ora2Pg will auto-detect this&#xA;    conversion and remove any whitespace at both leading and trailing&#xA;    position. If you just want to remove the leadings character set the&#xA;    value to LEADING. If you just want to remove the trailing character,&#xA;    set the value to TRAILING. Default value is BOTH.&#xA;&#xA;TRIM_CHAR&#xA;    The default trimming character is space, use this directive if you&#xA;    need to change the character that will be removed. For example, set&#xA;    it to - if you have leading - in the char(n) field. To use space as&#xA;    trimming charger, comment this directive, this is the default value.&#xA;&#xA;PRESERVE_CASE&#xA;    If you want to preserve the case of Oracle object name set this&#xA;    directive to 1. By default Ora2Pg will convert all Oracle object&#xA;    names to lower case. I do not recommend to enable this unless you&#xA;    will always have to double-quote object names on all your SQL&#xA;    scripts.&#xA;&#xA;ORA_RESERVED_WORDS&#xA;    Allow escaping of column name using Oracle reserved words. Value is&#xA;    a list of comma-separated reserved word. Default:&#xA;    audit,comment,references.&#xA;&#xA;USE_RESERVED_WORDS&#xA;    Enable this directive if you have table or column names that are a&#xA;    reserved word for PostgreSQL. Ora2Pg will double quote the name of&#xA;    the object.&#xA;&#xA;GEN_USER_PWD&#xA;    Set this directive to 1 to replace default password by a random&#xA;    password for all extracted user during a GRANT export.&#xA;&#xA;PG_SUPPORTS_MVIEW&#xA;    Since PostgreSQL 9.3, materialized view are supported with the SQL&#xA;    syntax &#39;CREATE MATERIALIZED VIEW&#39;. To force Ora2Pg to use the native&#xA;    PostgreSQL support you must enable this configuration - enable by&#xA;    default. If you want to use the old style with table and a set of&#xA;    function, you should disable it.&#xA;&#xA;PG_SUPPORTS_IFEXISTS&#xA;    PostgreSQL version below 9.x do not support IF EXISTS in DDL&#xA;    statements. Disabling the directive with value 0 will prevent Ora2Pg&#xA;    to add those keywords in all generated statements. Default value is&#xA;    1, enabled.&#xA;&#xA;PG_VERSION&#xA;    Set the PostgreSQL major version number of the target database. Ex:&#xA;    9.6 or 13 Default is current major version at time of a new release.&#xA;    This replace the old and deprecadted PG_SUPPORTS_* configuration&#xA;    directives described bellow.&#xA;&#xA;PG_SUPPORTS_ROLE (Deprecated)&#xA;    This option is deprecated since Ora2Pg release v7.3.&#xA;&#xA;    By default Oracle roles are translated into PostgreSQL groups. If&#xA;    you have PostgreSQL 8.1 or more consider the use of ROLES and set&#xA;    this directive to 1 to export roles.&#xA;&#xA;PG_SUPPORTS_INOUT (Deprecated)&#xA;    This option is deprecated since Ora2Pg release v7.3.&#xA;&#xA;    If set to 0, all IN, OUT or INOUT parameters will not be used into&#xA;    the generated PostgreSQL function declarations (disable it for&#xA;    PostgreSQL database version lower than 8.1), This is now enable by&#xA;    default.&#xA;&#xA;PG_SUPPORTS_DEFAULT&#xA;    This directive enable or disable the use of default parameter value&#xA;    in function export. Until PostgreSQL 8.4 such a default value was&#xA;    not supported, this feature is now enable by default.&#xA;&#xA;PG_SUPPORTS_WHEN (Deprecated)&#xA;    Add support to WHEN clause on triggers as PostgreSQL v9.0 now&#xA;    support it. This directive is enabled by default, set it to 0&#xA;    disable this feature.&#xA;&#xA;PG_SUPPORTS_INSTEADOF (Deprecated)&#xA;    Add support to INSTEAD OF usage on triggers (used with PG &amp;gt;= 9.1),&#xA;    if this directive is disabled the INSTEAD OF triggers will be&#xA;    rewritten as Pg rules.&#xA;&#xA;PG_SUPPORTS_CHECKOPTION&#xA;    When enabled, export views with CHECK OPTION. Disable it if you have&#xA;    PostgreSQL version prior to 9.4. Default: 1, enabled.&#xA;&#xA;PG_SUPPORTS_IFEXISTS&#xA;    If disabled, do not export object with IF EXISTS statements. Enabled&#xA;    by default.&#xA;&#xA;PG_SUPPORTS_PARTITION&#xA;    PostgreSQL version prior to 10.0 do not have native partitioning.&#xA;    Enable this directive if you want to use declarative partitioning.&#xA;    Enable by default.&#xA;&#xA;PG_SUPPORTS_SUBSTR&#xA;    Some versions of PostgreSQL like Redshift doesn&#39;t support substr()&#xA;    and it need to be replaced by a call to substring(). In this case,&#xA;    disable it.&#xA;&#xA;PG_SUPPORTS_NAMED_OPERATOR&#xA;    Disable this directive if you are using PG &amp;lt; 9.5, PL/SQL operator&#xA;    used in named parameter =&amp;gt; will be replaced by PostgreSQL&#xA;    proprietary operator := Enable by default.&#xA;&#xA;PG_SUPPORTS_IDENTITY&#xA;    Enable this directive if you have PostgreSQL &amp;gt;= 10 to use IDENTITY&#xA;    columns instead of serial or bigserial data type. If&#xA;    PG_SUPPORTS_IDENTITY is disabled and there is IDENTITY column in the&#xA;    Oracle table, they are exported as serial or bigserial columns. When&#xA;    it is enabled they are exported as IDENTITY columns like:&#xA;&#xA;          CREATE TABLE identity_test_tab (&#xA;                  id bigint GENERATED ALWAYS AS IDENTITY,&#xA;                  description varchar(30)&#xA;          ) ;&#xA;&#xA;    If there is non default sequence options set in Oracle, they will be&#xA;    appended after the IDENTITY keyword. Additionally in both cases,&#xA;    Ora2Pg will create a file AUTOINCREMENT_output.sql with a embedded&#xA;    function to update the associated sequences with the restart value&#xA;    set to &#34;SELECT max(colname)+1 FROM tablename&#34;. Of course this file&#xA;    must be imported after data import otherwise sequence will be kept&#xA;    to start value. Enabled by default.&#xA;&#xA;PG_SUPPORTS_PROCEDURE&#xA;    PostgreSQL v11 adds support of PROCEDURE, enable it if you use such&#xA;    version.&#xA;&#xA;BITMAP_AS_GIN&#xA;    Use btree_gin extension to create bitmap like index with pg &amp;gt;= 9.4&#xA;    You will need to create the extension by yourself: create extension&#xA;    btree_gin; Default is to create GIN index, when disabled, a btree&#xA;    index will be created&#xA;&#xA;PG_BACKGROUND&#xA;    Use pg_background extension to create an autonomous transaction&#xA;    instead of using a dblink wrapper. With pg &amp;gt;= 9.5 only. Default is&#xA;    to use dblink. See https://github.com/vibhorkum/pg_background about&#xA;    this extension.&#xA;&#xA;DBLINK_CONN&#xA;    By default if you have an autonomous transaction translated using&#xA;    dblink extension instead of pg_background the connection is defined&#xA;    using the values set with PG_DSN, PG_USER and PG_PWD. If you want to&#xA;    fully override the connection string use this directive as follow to&#xA;    set the connection in the autonomous transaction wrapper function.&#xA;    For example:&#xA;&#xA;            DBLINK_CONN    port=5432 dbname=pgdb host=localhost user=pguser password=pgpass&#xA;&#xA;LONGREADLEN&#xA;    Use this directive to set the database handle&#39;s &#39;LongReadLen&#39;&#xA;    attribute to a value that will be the larger than the expected size&#xA;    of the LOBs. The default is 1MB witch may not be enough to extract&#xA;    BLOBs or CLOBs. If the size of the LOB exceeds the &#39;LongReadLen&#39;&#xA;    DBD::Oracle will return a &#39;ORA-24345: A Truncation&#39; error. Default:&#xA;    1023*1024 bytes.&#xA;&#xA;    Take a look at this page to learn more:&#xA;    http://search.cpan.org/~pythian/DBD-Oracle-1.22/Oracle.pm#Data_Inter&#xA;    face_for_Persistent_LOBs&#xA;&#xA;    Important note: If you increase the value of this directive take&#xA;    care that DATA_LIMIT will probably needs to be reduced. Even if you&#xA;    only have a 1MB blob, trying to read 10000 of them (the default&#xA;    DATA_LIMIT) all at once will require 10GB of memory. You may extract&#xA;    data from those table separately and set a DATA_LIMIT to 500 or&#xA;    lower, otherwise you may experience some out of memory.&#xA;&#xA;LONGTRUNKOK&#xA;    If you want to bypass the &#39;ORA-24345: A Truncation&#39; error, set this&#xA;    directive to 1, it will truncate the data extracted to the&#xA;    LongReadLen value. Disable by default so that you will be warned if&#xA;    your LongReadLen value is not high enough.&#xA;&#xA;USE_LOB_LOCATOR&#xA;    Disable this if you want to load full content of BLOB and CLOB and&#xA;    not use LOB locators. In this case you will have to set LONGREADLEN&#xA;    to the right value. Note that this will not improve speed of BLOB&#xA;    export as most of the time is always consumed by the bytea escaping&#xA;    and in this case export is done line by line and not by chunk of&#xA;    DATA_LIMIT rows. For more information on how it works, see&#xA;    http://search.cpan.org/~pythian/DBD-Oracle-1.74/lib/DBD/Oracle.pm#Da&#xA;    ta_Interface_for_LOB_Locators&#xA;&#xA;    Default is enabled, it use LOB locators.&#xA;&#xA;LOB_CHUNK_SIZE&#xA;    Oracle recommends reading from and writing to a LOB in batches using&#xA;    a multiple of the LOB chunk size. This chunk size defaults to 8k&#xA;    (8192). Recent tests shown that the best performances can be reach&#xA;    with higher value like 512K or 4Mb.&#xA;&#xA;    A quick benchmark with 30120 rows with different size of BLOB&#xA;    (200x5Mb, 19800x212k, 10000x942K, 100x17Mb, 20x156Mb), with&#xA;    DATA_LIMIT=100, LONGREADLEN=170Mb and a total table size of 20GB&#xA;    gives:&#xA;&#xA;           no lob locator  : 22m46,218s (1365 sec., avg: 22 recs/sec)&#xA;           chunk size 8k   : 15m50,886s (951 sec., avg: 31 recs/sec)&#xA;           chunk size 512k : 1m28,161s (88 sec., avg: 342 recs/sec)&#xA;           chunk size 4Mb  : 1m23,717s (83 sec., avg: 362 recs/sec)&#xA;&#xA;    In conclusion it can be more than 10 time faster with LOB_CHUNK_SIZE&#xA;    set to 4Mb. Depending of the size of most BLOB you may want to&#xA;    adjust the value here. For example if you have a majority of small&#xA;    lobs bellow 8K, using 8192 is better to not waste space. Default&#xA;    value for LOB_CHUNK_SIZE is 512000.&#xA;&#xA;XML_PRETTY&#xA;    Force the use getStringVal() instead of getClobVal() for XML data&#xA;    export. Default is 1, enabled for backward compatibility. Set it to&#xA;    0 to use extract method a la CLOB. Note that XML value extracted&#xA;    with getStringVal() must not exceed VARCHAR2 size limit (4000)&#xA;    otherwise it will return an error.&#xA;&#xA;ENABLE_MICROSECOND&#xA;    Set it to O if you want to disable export of millisecond from Oracle&#xA;    timestamp columns. By default milliseconds are exported with the use&#xA;    of following format:&#xA;&#xA;            &#39;YYYY-MM-DD HH24:MI:SS.FF&#39;&#xA;&#xA;    Disabling will force the use of the following Oracle format:&#xA;&#xA;            to_char(..., &#39;YYYY-MM-DD HH24:MI:SS&#39;)&#xA;&#xA;    By default milliseconds are exported.&#xA;&#xA;DISABLE_COMMENT&#xA;    Set this to 1 if you don&#39;t want to export comment associated to&#xA;    tables and columns definition. Default is enabled.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Control MySQL export behavior MYSQL_PIPES_AS_CONCAT Enable this if double pipe and double ampersand (|| and &amp;amp;&amp;amp;) should not be taken as equivalent to OR and AND. It depend of the variable @sql_mode, Use it only if Ora2Pg fail on auto detecting this behavior.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MYSQL_INTERNAL_EXTRACT_FORMAT&#xA;    Enable this directive if you want EXTRACT() replacement to use the&#xA;    internal format returned as an integer, for example DD HH24:MM:SS&#xA;    will be replaced with format; DDHH24MMSS::bigint, this depend of&#xA;    your apps usage.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Special options to handle character encoding NLS_LANG and NLS_NCHAR By default Ora2Pg will set NLS_LANG to AMERICAN_AMERICA.AL32UTF8 and NLS_NCHAR to AL32UTF8. It is not recommended to change those settings but in some case it could be useful. Using your own settings with those configuration directive will change the client encoding at Oracle side by setting the environment variables $ENV{NLS_LANG} and $ENV{NLS_NCHAR}.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;BINMODE&#xA;    By default Ora2Pg will force Perl to use utf8 I/O encoding. This is&#xA;    done through a call to the Perl pragma:&#xA;&#xA;            use open &#39;:utf8&#39;;&#xA;&#xA;    You can override this encoding by using the BINMODE directive, for&#xA;    example you can set it to :locale to use your locale or iso-8859-7,&#xA;    it will respectively use&#xA;&#xA;            use open &#39;:locale&#39;;&#xA;            use open &#39;:encoding(iso-8859-7)&#39;;&#xA;&#xA;    If you have change the NLS_LANG in non UTF8 encoding, you might want&#xA;    to set this directive. See http://perldoc.perl.org/5.14.2/open.html&#xA;    for more information. Most of the time, leave this directive&#xA;    commented.&#xA;&#xA;CLIENT_ENCODING&#xA;    By default PostgreSQL client encoding is automatically set to UTF8&#xA;    to avoid encoding issue. If you have changed the value of NLS_LANG&#xA;    you might have to change the encoding of the PostgreSQL client.&#xA;&#xA;    You can take a look at the PostgreSQL supported character sets here:&#xA;    http://www.postgresql.org/docs/9.0/static/multibyte.html&#xA;&#xA;FORCE_PLSQL_ENCODING&#xA;    To force utf8 encoding of the PL/SQL code exported, enable this&#xA;    directive. Could be helpful in some rare condition.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;PLSQL to PLPGSQL conversion Automatic code conversion from Oracle PLSQL to PostgreSQL PLPGSQL is a work in progress in Ora2Pg and surely you will always have manual work. The Perl code used for automatic conversion is all stored in a specific Perl Module named Ora2Pg/PLSQL.pm feel free to modify/add you own code and send me patches. The main work in on function, procedure, package and package body headers and parameters rewrite.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PLSQL_PGSQL&#xA;    Enable/disable PLSQL to PLPGSQL conversion. Enabled by default.&#xA;&#xA;NULL_EQUAL_EMPTY&#xA;    Ora2Pg can replace all conditions with a test on NULL by a call to&#xA;    the coalesce() function to mimic the Oracle behavior where empty&#xA;    string are considered equal to NULL.&#xA;&#xA;            (field1 IS NULL) is replaced by (coalesce(field1::text, &#39;&#39;) = &#39;&#39;)&#xA;            (field2 IS NOT NULL) is replaced by (field2 IS NOT NULL AND field2::text &amp;lt;&amp;gt; &#39;&#39;)&#xA;&#xA;    You might want this replacement to be sure that your application&#xA;    will have the same behavior but if you have control on you&#xA;    application a better way is to change it to transform empty string&#xA;    into NULL because PostgreSQL makes the difference.&#xA;&#xA;EMPTY_LOB_NULL&#xA;    Force empty_clob() and empty_blob() to be exported as NULL instead&#xA;    as empty string for the first one and &#39;\x&#39; for the second. If NULL&#xA;    is allowed in your column this might improve data export speed if&#xA;    you have lot of empty lob. Default is to preserve the exact data&#xA;    from Oracle.&#xA;&#xA;PACKAGE_AS_SCHEMA&#xA;    If you don&#39;t want to export package as schema but as simple&#xA;    functions you might also want to replace all call to&#xA;    package_name.function_name. If you disable the PACKAGE_AS_SCHEMA&#xA;    directive then Ora2Pg will replace all call to&#xA;    package_name.function_name() by package_name_function_name().&#xA;    Default is to use a schema to emulate package.&#xA;&#xA;    The replacement will be done in all kind of DDL or code that is&#xA;    parsed by the PLSQL to PLPGSQL converter. PLSQL_PGSQL must be&#xA;    enabled or -p used in command line.&#xA;&#xA;REWRITE_OUTER_JOIN&#xA;    Enable this directive if the rewrite of Oracle native syntax (+) of&#xA;    OUTER JOIN is broken. This will force Ora2Pg to not rewrite such&#xA;    code, default is to try to rewrite simple form of right outer join&#xA;    for the moment.&#xA;&#xA;UUID_FUNCTION&#xA;    By default Ora2Pg will convert call to SYS_GUID() Oracle function&#xA;    with a call to uuid_generate_v4 from uuid-ossp extension. You can&#xA;    redefined it to use the gen_random_uuid function from pgcrypto&#xA;    extension by changing the function name. Default to&#xA;    uuid_generate_v4.&#xA;&#xA;    Note that when a RAW(16) and RAW(32) columns is found or that the&#xA;    RAW column has &#34;SYS_GUID()&#34; as default value Ora2Pg will&#xA;    automatically translate the type of the column into uuid which might&#xA;    be the right translation in most of the case. In this case data will&#xA;    be automatically migrated as PostgreSQL uuid data type provided by&#xA;    the &#34;uuid-ossp&#34; extension.&#xA;&#xA;FUNCTION_STABLE&#xA;    By default Oracle functions are marked as STABLE as they can not&#xA;    modify data unless when used in PL/SQL with variable assignment or&#xA;    as conditional expression. You can force Ora2Pg to create these&#xA;    function as VOLATILE by disabling this configuration directive.&#xA;&#xA;COMMENT_COMMIT_ROLLBACK&#xA;    By default call to COMMIT/ROLLBACK are kept untouched by Ora2Pg to&#xA;    force the user to review the logic of the function. Once it is fixed&#xA;    in Oracle source code or you want to comment this calls enable the&#xA;    following directive.&#xA;&#xA;COMMENT_SAVEPOINT&#xA;    It is common to see SAVEPOINT call inside PL/SQL procedure together&#xA;    with a ROLLBACK TO savepoint_name. When COMMENT_COMMIT_ROLLBACK is&#xA;    enabled you may want to also comment SAVEPOINT calls, in this case&#xA;    enable it.&#xA;&#xA;STRING_CONSTANT_REGEXP&#xA;    Ora2Pg replace all string constant during the pl/sql to plpgsql&#xA;    translation, string constant are all text include between single&#xA;    quote. If you have some string placeholder used in dynamic call to&#xA;    queries you can set a list of regexp to be temporary replaced to not&#xA;    break the parser. For example:&#xA;&#xA;            STRING_CONSTANT_REGEXP         &amp;lt;placeholder value=&#34;.*&#34;&amp;gt;&#xA;&#xA;    The list of regexp must use the semi colon as separator.&#xA;&#xA;ALTERNATIVE_QUOTING_REGEXP&#xA;    To support the Alternative Quoting Mechanism (&#39;Q&#39; or &#39;q&#39;) for String&#xA;    Literals set the regexp with the text capture to use to extract the&#xA;    text part. For example with a variable declared as&#xA;&#xA;            c_sample VARCHAR2(100 CHAR) := q&#39;{This doesn&#39;t work.}&#39;;&#xA;&#xA;    the regexp to use must be:&#xA;&#xA;            ALTERNATIVE_QUOTING_REGEXP     q&#39;{(.*)}&#39;&#xA;&#xA;    ora2pg will use the $$ delimiter, with the example the result will&#xA;    be:&#xA;&#xA;            c_sample varchar(100) := $$This doesn&#39;t work.$$;&#xA;&#xA;    The value of this configuration directive can be a list of regexp&#xA;    separated by a semi colon. The capture part (between parenthesis) is&#xA;    mandatory in each regexp if you want to restore the string constant.&#xA;&#xA;USE_ORAFCE&#xA;    If you want to use functions defined in the Orafce library and&#xA;    prevent Ora2Pg to translate call to these functions, enable this&#xA;    directive. The Orafce library can be found here:&#xA;    https://github.com/orafce/orafce&#xA;&#xA;    By default Ora2pg rewrite add_month(), add_year(), date_trunc() and&#xA;    to_char() functions, but you may prefer to use the orafce version of&#xA;    these function that do not need any code transformation.&#xA;&#xA;AUTONOMOUS_TRANSACTION&#xA;    Enable translation of autonomous transactions into a wrapper&#xA;    function using dblink or pg_background extension. If you don&#39;t want&#xA;    to use this translation and just want the function to be exported as&#xA;    a normal one without the pragma call, disable this directive.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Materialized view Materialized views are exported as snapshot &#34;Snapshot Materialized Views&#34; as PostgreSQL only supports full refresh.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;If you want to import the materialized views in PostgreSQL prior to 9.3&#xA;you have to set configuration directive PG_SUPPORTS_MVIEW to 0. In this&#xA;case Ora2Pg will export all materialized views as explain in this&#xA;document:&#xA;&#xA;        http://tech.jonathangardner.net/wiki/PostgreSQL/Materialized_Views.&#xA;&#xA;When exporting materialized view Ora2Pg will first add the SQL code to&#xA;create the &#34;materialized_views&#34; table:&#xA;&#xA;        CREATE TABLE materialized_views (&#xA;                mview_name text NOT NULL PRIMARY KEY,&#xA;                view_name text NOT NULL,&#xA;                iname text,&#xA;                last_refresh TIMESTAMP WITH TIME ZONE&#xA;        );&#xA;&#xA;all materialized views will have an entry in this table. It then adds&#xA;the plpgsql code to create tree functions:&#xA;&#xA;        create_materialized_view(text, text, text) used to create a materialized view&#xA;        drop_materialized_view(text) used to delete a materialized view&#xA;        refresh_full_materialized_view(text) used to refresh a view&#xA;&#xA;then it adds the SQL code to create the view and the materialized view:&#xA;&#xA;        CREATE VIEW mviewname_mview AS&#xA;        SELECT ... FROM ...;&#xA;&#xA;        SELECT create_materialized_view(&#39;mviewname&#39;,&#39;mviewname_mview&#39;, change with the name of the column to used for the index);&#xA;&#xA;The first argument is the name of the materialized view, the second the&#xA;name of the view on which the materialized view is based and the third&#xA;is the column name on which the index should be build (aka most of the&#xA;time the primary key). This column is not automatically deduced so you&#xA;need to replace its name.&#xA;&#xA;As said above Ora2Pg only supports snapshot materialized views so the&#xA;table will be entirely refreshed by issuing first a truncate of the&#xA;table and then by load again all data from the view:&#xA;&#xA;         refresh_full_materialized_view(&#39;mviewname&#39;);&#xA;&#xA;To drop the materialized view you just have to call the&#xA;drop_materialized_view() function with the name of the materialized view&#xA;as parameter.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Other configuration directives DEBUG Set it to 1 will enable verbose output.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;IMPORT&#xA;    You can define common Ora2Pg configuration directives into a single&#xA;    file that can be imported into other configuration files with the&#xA;    IMPORT configuration directive as follow:&#xA;&#xA;            IMPORT  commonfile.conf&#xA;&#xA;    will import all configuration directives defined into&#xA;    commonfile.conf into the current configuration file.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Exporting views as PostgreSQL tables You can export any Oracle view as a PostgreSQL table simply by setting TYPE configuration option to TABLE to have the corresponding create table statement. Or use type COPY or INSERT to export the corresponding data. To allow that you have to specify your views in the VIEW_AS_TABLE configuration option.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Then if Ora2Pg finds the view it will extract its schema (if TYPE=TABLE)&#xA;into a PG create table form, then it will extract the data (if TYPE=COPY&#xA;or INSERT) following the view schema.&#xA;&#xA;For example, with the following view:&#xA;&#xA;        CREATE OR REPLACE VIEW product_prices (category_id, product_count, low_price, high_price) AS&#xA;        SELECT  category_id, COUNT(*) as product_count,&#xA;            MIN(list_price) as low_price,&#xA;            MAX(list_price) as high_price&#xA;         FROM   product_information&#xA;        GROUP BY category_id;&#xA;&#xA;Setting VIEW_AS_TABLE to product_prices and using export type TABLE,&#xA;will force Ora2Pg to detect columns returned types and to generate a&#xA;create table statement:&#xA;&#xA;        CREATE TABLE product_prices (&#xA;                category_id bigint,&#xA;                product_count integer,&#xA;                low_price numeric,&#xA;                high_price numeric&#xA;        );&#xA;&#xA;Data will be loaded following the COPY or INSERT export type and the&#xA;view declaration.&#xA;&#xA;You can use the ALLOW and EXCLUDE directive in addition to filter other&#xA;objects to export.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Export as Kettle transformation XML files The KETTLE export type is useful if you want to use Penthalo Data Integrator (Kettle) to import data to PostgreSQL. With this type of export Ora2Pg will generate one XML Kettle transformation files (.ktr) per table and add a line to manually execute the transformation in the output.sql file. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        ora2pg -c ora2pg.conf -t KETTLE -j 12 -a MYTABLE -o load_mydata.sh&#xA;&#xA;will generate one file called &#39;HR.MYTABLE.ktr&#39; and add a line to the&#xA;output file (load_mydata.sh):&#xA;&#xA;        #!/bin/sh&#xA;&#xA;        KETTLE_TEMPLATE_PATH=&#39;.&#39;&#xA;&#xA;        JAVAMAXMEM=4096 ./pan.sh -file $KETTLE_TEMPLATE_PATH/HR.MYTABLE.ktr -level Detailed&#xA;&#xA;The -j 12 option will create a template with 12 processes to insert data&#xA;into PostgreSQL. It is also possible to specify the number of parallel&#xA;queries used to extract data from the Oracle with the -J command line&#xA;option as follow:&#xA;&#xA;        ora2pg -c ora2pg.conf -t KETTLE -J 4 -j 12 -a EMPLOYEES -o load_mydata.sh&#xA;&#xA;This is only possible if you have defined the technical key to used to&#xA;split the query between cores in the DEFINED_PKEY configuration&#xA;directive. For example:&#xA;&#xA;        DEFINED_PK      EMPLOYEES:employee_id&#xA;&#xA;will force the number of Oracle connection copies to 4 and defined the&#xA;SQL query as follow in the Kettle XML transformation file:&#xA;&#xA;        &amp;lt;sql&amp;gt;SELECT * FROM HR.EMPLOYEES WHERE ABS(MOD(employee_id,${Internal.Step.Unique.Count}))=${Internal.Step.Unique.Number}&amp;lt;/sql&amp;gt;&#xA;&#xA;The KETTLE export type requires that the Oracle and PostgreSQL DSN are&#xA;defined. You can also activate the TRUNCATE_TABLE directive to force a&#xA;truncation of the table before data import.&#xA;&#xA;The KETTLE export type is an original work of Marc Cousin.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Migration cost assessment Estimating the cost of a migration process from Oracle to PostgreSQL is not easy. To obtain a good assessment of this migration cost, Ora2Pg will inspect all database objects, all functions and stored procedures to detect if there&#39;s still some objects and PL/SQL code that can not be automatically converted by Ora2Pg.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Ora2Pg has a content analysis mode that inspect the Oracle database to&#xA;generate a text report on what the Oracle database contains and what can&#xA;not be exported.&#xA;&#xA;To activate the &#34;analysis and report&#34; mode, you have to use the export&#xA;de type SHOW_REPORT like in the following command:&#xA;&#xA;        ora2pg -t SHOW_REPORT&#xA;&#xA;Here is a sample report obtained with this command:&#xA;&#xA;        --------------------------------------&#xA;        Ora2Pg: Oracle Database Content Report&#xA;        --------------------------------------&#xA;        Version Oracle Database 10g Enterprise Edition Release 10.2.0.1.0&#xA;        Schema  HR&#xA;        Size  880.00 MB&#xA;     &#xA;        --------------------------------------&#xA;        Object  Number  Invalid Comments&#xA;        --------------------------------------&#xA;        CLUSTER   2 0 Clusters are not supported and will not be exported.&#xA;        FUNCTION  40  0 Total size of function code: 81992.&#xA;        INDEX     435 0 232 index(es) are concerned by the export, others are automatically generated and will&#xA;                                        do so on PostgreSQL. 1 bitmap index(es). 230 b-tree index(es). 1 reversed b-tree index(es)&#xA;                                        Note that bitmap index(es) will be exported as b-tree index(es) if any. Cluster, domain,&#xA;                                        bitmap join and IOT indexes will not be exported at all. Reverse indexes are not exported&#xA;                                        too, you may use a trigram-based index (see pg_trgm) or a reverse() function based index&#xA;                                        and search. You may also use &#39;varchar_pattern_ops&#39;, &#39;text_pattern_ops&#39; or &#39;bpchar_pattern_ops&#39;&#xA;                                        operators in your indexes to improve search with the LIKE operator respectively into&#xA;                                        varchar, text or char columns.&#xA;        MATERIALIZED VIEW 1 0 All materialized view will be exported as snapshot materialized views, they&#xA;                                        are only updated when fully refreshed.&#xA;        PACKAGE BODY  2 1 Total size of package code: 20700.&#xA;        PROCEDURE 7 0 Total size of procedure code: 19198.&#xA;        SEQUENCE  160 0 Sequences are fully supported, but all call to sequence_name.NEXTVAL or sequence_name.CURRVAL&#xA;                                        will be transformed into NEXTVAL(&#39;sequence_name&#39;) or CURRVAL(&#39;sequence_name&#39;).&#xA;        TABLE     265 0 1 external table(s) will be exported as standard table. See EXTERNAL_TO_FDW configuration&#xA;                                        directive to export as file_fdw foreign tables or use COPY in your code if you just&#xA;                                        want to load data from external files. 2 binary columns. 4 unknown types.&#xA;        TABLE PARTITION 8 0 Partitions are exported using table inheritance and check constraint. 1 HASH partitions.&#xA;                                        2 LIST partitions. 6 RANGE partitions. Note that Hash partitions are not supported.&#xA;        TRIGGER   30  0 Total size of trigger code: 21677.&#xA;        TYPE      7 1 5 type(s) are concerned by the export, others are not supported. 2 Nested Tables.&#xA;                                        2 Object type. 1 Subtype. 1 Type Boby. 1 Type inherited. 1 Varrays. Note that Type&#xA;                                        inherited and Subtype are converted as table, type inheritance is not supported.&#xA;        TYPE BODY 0 3 Export of type with member method are not supported, they will not be exported.&#xA;        VIEW      7 0 Views are fully supported, but if you have updatable views you will need to use&#xA;                                        INSTEAD OF triggers.&#xA;        DATABASE LINK 1 0 Database links will not be exported. You may try the dblink perl contrib module or use&#xA;                                        the SQL/MED PostgreSQL features with the different Foreign Data Wrapper (FDW) extensions.&#xA;                                    &#xA;        Note: Invalid code will not be exported unless the EXPORT_INVALID configuration directive is activated.&#xA;&#xA;Once the database can be analysed, Ora2Pg, by his ability to convert SQL&#xA;and PL/SQL code from Oracle syntax to PostgreSQL, can go further by&#xA;estimating the code difficulties and estimate the time necessary to&#xA;operate a full database migration.&#xA;&#xA;To estimate the migration cost in man-days, Ora2Pg allow you to use a&#xA;configuration directive called ESTIMATE_COST that you can also enabled&#xA;at command line:&#xA;&#xA;        --estimate_cost&#xA;&#xA;This feature can only be used with the SHOW_REPORT, FUNCTION, PROCEDURE,&#xA;PACKAGE and QUERY export type.&#xA;&#xA;        ora2pg -t SHOW_REPORT  --estimate_cost&#xA;&#xA;The generated report is same as above but with a new &#39;Estimated cost&#39;&#xA;column as follow:&#xA;&#xA;        --------------------------------------&#xA;        Ora2Pg: Oracle Database Content Report&#xA;        --------------------------------------&#xA;        Version Oracle Database 10g Express Edition Release 10.2.0.1.0&#xA;        Schema  HR&#xA;        Size  890.00 MB&#xA;     &#xA;        --------------------------------------&#xA;        Object  Number  Invalid Estimated cost  Comments&#xA;        --------------------------------------&#xA;        DATABASE LINK  3 0 9 Database links will be exported as SQL/MED PostgreSQL&#39;s Foreign Data Wrapper (FDW) extensions&#xA;                                        using oracle_fdw.&#xA;        FUNCTION  2 0 7 Total size of function code: 369 bytes. HIGH_SALARY: 2, VALIDATE_SSN: 3.&#xA;        INDEX 21  0 11  11 index(es) are concerned by the export, others are automatically generated and will do so&#xA;                                        on PostgreSQL. 11 b-tree index(es). Note that bitmap index(es) will be exported as b-tree&#xA;                                        index(es) if any. Cluster, domain, bitmap join and IOT indexes will not be exported at all.&#xA;                                        Reverse indexes are not exported too, you may use a trigram-based index (see pg_trgm) or a&#xA;                                        reverse() function based index and search. You may also use &#39;varchar_pattern_ops&#39;, &#39;text_pattern_ops&#39;&#xA;                                        or &#39;bpchar_pattern_ops&#39; operators in your indexes to improve search with the LIKE operator&#xA;                                        respectively into varchar, text or char columns.&#xA;        JOB 0 0 0 Job are not exported. You may set external cron job with them.&#xA;        MATERIALIZED VIEW 1 0 3 All materialized view will be exported as snapshot materialized views, they&#xA;                                                are only updated when fully refreshed.&#xA;        PACKAGE BODY  0 2 54  Total size of package code: 2487 bytes. Number of procedures and functions found&#xA;                                                inside those packages: 7. two_proc.get_table: 10, emp_mgmt.create_dept: 4,&#xA;                                                emp_mgmt.hire: 13, emp_mgmt.increase_comm: 4, emp_mgmt.increase_sal: 4,&#xA;                                                emp_mgmt.remove_dept: 3, emp_mgmt.remove_emp: 2.&#xA;        PROCEDURE 4 0 39  Total size of procedure code: 2436 bytes. TEST_COMMENTAIRE: 2, SECURE_DML: 3,&#xA;                                                PHD_GET_TABLE: 24, ADD_JOB_HISTORY: 6.&#xA;        SEQUENCE  3 0 0 Sequences are fully supported, but all call to sequence_name.NEXTVAL or sequence_name.CURRVAL&#xA;                                                will be transformed into NEXTVAL(&#39;sequence_name&#39;) or CURRVAL(&#39;sequence_name&#39;).&#xA;        SYNONYM   3 0 4 SYNONYMs will be exported as views. SYNONYMs do not exists with PostgreSQL but a common workaround&#xA;                                                is to use views or set the PostgreSQL search_path in your session to access&#xA;                                                object outside the current schema.&#xA;                                                user1.emp_details_view_v is an alias to hr.emp_details_view.&#xA;                                                user1.emp_table is an alias to hr.employees@other_server.&#xA;                                                user1.offices is an alias to hr.locations.&#xA;        TABLE 17  0 8.5 1 external table(s) will be exported as standard table. See EXTERNAL_TO_FDW configuration&#xA;                                        directive to export as file_fdw foreign tables or use COPY in your code if you just want to&#xA;                                        load data from external files. 2 binary columns. 4 unknown types.&#xA;        TRIGGER 1 1 4 Total size of trigger code: 123 bytes. UPDATE_JOB_HISTORY: 2.&#xA;        TYPE  7 1 5 5 type(s) are concerned by the export, others are not supported. 2 Nested Tables. 2 Object type.&#xA;                                        1 Subtype. 1 Type Boby. 1 Type inherited. 1 Varrays. Note that Type inherited and Subtype are&#xA;                                        converted as table, type inheritance is not supported.&#xA;        TYPE BODY 0 3 30  Export of type with member method are not supported, they will not be exported.&#xA;        VIEW  1 1 1 Views are fully supported, but if you have updatable views you will need to use INSTEAD OF triggers.&#xA;        --------------------------------------&#xA;        Total 65  8 162.5 162.5 cost migration units means approximatively 2 man day(s).&#xA;&#xA;The last line shows the total estimated migration code in man-days&#xA;following the number of migration units estimated for each object. This&#xA;migration unit represent around five minutes for a PostgreSQL expert. If&#xA;this is your first migration you can get it higher with the&#xA;configuration directive COST_UNIT_VALUE or the --cost_unit_value command&#xA;line option:&#xA;&#xA;        ora2pg -t SHOW_REPORT  --estimate_cost --cost_unit_value 10&#xA;&#xA;Ora2Pg is also able to give you a migration difficulty level assessment,&#xA;here a sample:&#xA;&#xA;Migration level: B-5&#xA;&#xA;    Migration levels:&#xA;        A - Migration that might be run automatically&#xA;        B - Migration with code rewrite and a human-days cost up to 5 days&#xA;        C - Migration with code rewrite and a human-days cost above 5 days&#xA;    Technical levels:&#xA;        1 = trivial: no stored functions and no triggers&#xA;        2 = easy: no stored functions but with triggers, no manual rewriting&#xA;        3 = simple: stored functions and/or triggers, no manual rewriting&#xA;        4 = manual: no stored functions but with triggers or views with code rewriting&#xA;        5 = difficult: stored functions and/or triggers with code rewriting&#xA;&#xA;This assessment consist in a letter A or B to specify if the migration&#xA;needs manual rewriting or not. And a number from 1 up to 5 to give you a&#xA;technical difficulty level. You have an additional option&#xA;--human_days_limit to specify the number of human-days limit where the&#xA;migration level should be set to C to indicate that it need a huge&#xA;amount of work and a full project management with migration support.&#xA;Default is 10 human-days. You can use the configuration directive&#xA;HUMAN_DAYS_LIMIT to change this default value permanently.&#xA;&#xA;This feature has been developed to help you or your boss to decide which&#xA;database to migrate first and the team that must be mobilized to operate&#xA;the migration.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Global Oracle and MySQL migration assessment Ora2Pg come with a script ora2pg_scanner that can be used when you have a huge number of instances and schema to scan for migration assessment.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Usage: ora2pg_scanner -l CSVFILE [-o OUTDIR]&#xA;&#xA;   -b | --binpath DIR: full path to directory where the ora2pg binary stays.&#xA;                Might be useful only on Windows OS.&#xA;   -c | --config FILE: set custom configuration file to use otherwise ora2pg&#xA;                will use the default: /etc/ora2pg/ora2pg.conf.&#xA;   -l | --list FILE : CSV file containing a list of databases to scan with&#xA;                all required information. The first line of the file&#xA;                can contain the following header that describes the&#xA;                format that must be used:&#xA;&#xA;                &#34;type&#34;,&#34;schema/database&#34;,&#34;dsn&#34;,&#34;user&#34;,&#34;password&#34;&#xA;&#xA;   -o | --outdir DIR : (optional) by default all reports will be dumped to a&#xA;                directory named &#39;output&#39;, it will be created automatically.&#xA;                If you want to change the name of this directory, set the name&#xA;                at second argument.&#xA;&#xA;   -t | --test : just try all connections by retrieving the required schema&#xA;                 or database name. Useful to validate your CSV list file.&#xA;   -u | --unit MIN : redefine globally the migration cost unit value in minutes.&#xA;                 Default is taken from the ora2pg.conf (default 5 minutes).&#xA;&#xA;   Here is a full example of a CSV databases list file:&#xA;&#xA;        &#34;type&#34;,&#34;schema/database&#34;,&#34;dsn&#34;,&#34;user&#34;,&#34;password&#34;&#xA;        &#34;MYSQL&#34;,&#34;sakila&#34;,&#34;dbi:mysql:host=192.168.1.10;database=sakila;port=3306&#34;,&#34;root&#34;,&#34;secret&#34;&#xA;        &#34;ORACLE&#34;,&#34;HR&#34;,&#34;dbi:Oracle:host=192.168.1.10;sid=XE;port=1521&#34;,&#34;system&#34;,&#34;manager&#34;&#xA;&#xA;   The CSV field separator must be a comma.&#xA;&#xA;   Note that if you want to scan all schemas from an Oracle instance you just&#xA;   have to leave the schema field empty, Ora2Pg will automatically detect all&#xA;   available schemas and generate a report for each one. Of course you need to&#xA;   use a connection user with enough privileges to be able to scan all schemas.&#xA;   For example:&#xA;&#xA;        &#34;ORACLE&#34;,&#34;&#34;,&#34;dbi:Oracle:host=192.168.1.10;sid=XE;port=1521&#34;,&#34;system&#34;,&#34;manager&#34;&#xA;&#xA;   will generate a report for all schema in the XE instance. Note that in this&#xA;   case the SCHEMA directive in ora2pg.conf must not be set.&#xA;&#xA;It will generate a CSV file with the assessment result, one line per&#xA;schema or database and a detailed HTML report for each database scanned.&#xA;&#xA;Hint: Use the -t | --test option before to test all your connections in&#xA;your CSV file.&#xA;&#xA;For Windows users you must use the -b command line option to set the&#xA;directory where ora2pg_scanner stays otherwise the ora2pg command calls&#xA;will fail.&#xA;&#xA;In the migration assessment details about functions Ora2Pg always&#xA;include per default 2 migration units for TEST and 1 unit for SIZE per&#xA;1000 characters in the code. This mean that by default it will add 15&#xA;minutes in the migration assessment per function. Obviously if you have&#xA;unitary tests or very simple functions this will not represent the real&#xA;migration time.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Migration assessment method Migration unit scores given to each type of Oracle database object are defined in the Perl library lib/Ora2Pg/PLSQL.pm in the %OBJECT_SCORE variable definition.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;The number of PL/SQL lines associated to a migration unit is also&#xA;defined in this file in the $SIZE_SCORE variable value.&#xA;&#xA;The number of migration units associated to each PL/SQL code&#xA;difficulties can be found in the same Perl library lib/Ora2Pg/PLSQL.pm&#xA;in the hash %UNCOVERED_SCORE initialization.&#xA;&#xA;This assessment method is a work in progress so I&#39;m expecting feedbacks&#xA;on migration experiences to polish the scores/units attributed in those&#xA;variables.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Improving indexes and constraints creation speed Using the LOAD export type and a file containing SQL orders to perform, it is possible to dispatch those orders over multiple PostgreSQL connections. To be able to use this feature, the PG_DSN, PG_USER and PG_PWD must be set. Then:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        ora2pg -t LOAD -c config/ora2pg.conf -i schema/tables/INDEXES_table.sql -j 4&#xA;&#xA;will dispatch indexes creation over 4 simultaneous PostgreSQL&#xA;connections.&#xA;&#xA;This will considerably accelerate this part of the migration process&#xA;with huge data size.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Exporting LONG RAW If you still have columns defined as LONG RAW, Ora2Pg will not be able to export these kind of data. The OCI library fail to export them and always return the same first record. To be able to export the data you need to transform the field as BLOB by creating a temporary table before migrating data. For example, the Oracle table:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        SQL&amp;gt; DESC TEST_LONGRAW&#xA;         Name                 NULL ?   Type&#xA;         -------------------- -------- ----------------------------&#xA;         ID                            NUMBER&#xA;         C1                            LONG RAW&#xA;&#xA;need to be &#34;translated&#34; into a table using BLOB as follow:&#xA;&#xA;        CREATE TABLE test_blob (id NUMBER, c1 BLOB);&#xA;&#xA;And then copy the data with the following INSERT query:&#xA;&#xA;        INSERT INTO test_blob SELECT id, to_lob(c1) FROM test_longraw;&#xA;&#xA;Then you just have to exclude the original table from the export (see&#xA;EXCLUDE directive) and to renamed the new temporary table on the fly&#xA;using the REPLACE_TABLES configuration directive.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Global variables Oracle allow the use of global variables defined in packages. Ora2Pg will export these variables for PostgreSQL as user defined custom variables available in a session. Oracle variables assignment are exported as call to:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;    PERFORM set_config(&#39;pkgname.varname&#39;, value, false);&#xA;&#xA;Use of these variables in the code is replaced by:&#xA;&#xA;    current_setting(&#39;pkgname.varname&#39;)::global_variables_type;&#xA;&#xA;where global_variables_type is the type of the variable extracted from&#xA;the package definition.&#xA;&#xA;If the variable is a constant or have a default value assigned at&#xA;declaration, Ora2Pg will create a file global_variables.conf with the&#xA;definition to include in the postgresql.conf file so that their values&#xA;will already be set at database connection. Note that the value can&#xA;always modified by the user so you can not have exactly a constant.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Hints Converting your queries with Oracle style outer join (+) syntax to ANSI standard SQL at the Oracle side can save you lot of time for the migration. You can use TOAD Query Builder can re-write these using the proper ANSI syntax, see: &lt;a href=&#34;http://www.toadworld.com/products/toad-for-oracle/f/10/t/9518.aspx&#34;&gt;http://www.toadworld.com/products/toad-for-oracle/f/10/t/9518.aspx&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;There&#39;s also an alternative with SQL Developer Data Modeler, see&#xA;http://www.thatjeffsmith.com/archive/2012/01/sql-developer-data-modeler-&#xA;quick-tip-use-oracle-join-syntax-or-ansi/&#xA;&#xA;Toad is also able to rewrite the native Oracle DECODE() syntax into ANSI&#xA;standard SQL CASE statement. You can find some slide about this in a&#xA;presentation given at PgConf.RU:&#xA;http://ora2pg.darold.net/slides/ora2pg_the_hard_way.pdf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Test the migration The type of action called TEST allow you to check that all objects from Oracle database have been created under PostgreSQL. Of course PG_DSN must be set to be able to check PostgreSQL side.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Note that this feature respect the schema name limitation if&#xA;EXPORT_SCHEMA and SCHEMA or PG_SCHEMA are defined. If only EXPORT_SCHEMA&#xA;is set all schemes from Oracle and PostgreSQL are scanned. You can&#xA;filter to a single schema using SCHEMA and/or PG_SCHEMA but you can not&#xA;filter on a list of schema. To test a list of schema you will have to&#xA;repeat the calls to Ora2Pg by specifying a single schema each time.&#xA;&#xA;For example command:&#xA;&#xA;        ora2pg -t TEST -c config/ora2pg.conf &amp;gt; migration_diff.txt&#xA;&#xA;Will create a file containing the report of all object and row count on&#xA;both side, Oracle and PostgreSQL, with an error section giving you the&#xA;detail of the differences for each kind of object. Here is a sample&#xA;result:&#xA;&#xA;        [TEST INDEXES COUNT]&#xA;        ORACLEDB:DEPARTMENTS:2&#xA;        POSTGRES:departments:1&#xA;        ORACLEDB:EMPLOYEES:6&#xA;        POSTGRES:employees:6&#xA;        [ERRORS INDEXES COUNT]&#xA;        Table departments doesn&#39;t have the same number of indexes in Oracle (2) and in PostgreSQL (1).&#xA;&#xA;        [TEST UNIQUE CONSTRAINTS COUNT]&#xA;        ORACLEDB:DEPARTMENTS:1&#xA;        POSTGRES:departments:1&#xA;        ORACLEDB:EMPLOYEES:1&#xA;        POSTGRES:employees:1&#xA;        [ERRORS UNIQUE CONSTRAINTS COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of unique constraints.&#xA;&#xA;        [TEST PRIMARY KEYS COUNT]&#xA;        ORACLEDB:DEPARTMENTS:1&#xA;        POSTGRES:departments:1&#xA;        ORACLEDB:EMPLOYEES:1&#xA;        POSTGRES:employees:1&#xA;        [ERRORS PRIMARY KEYS COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of primary keys.&#xA;&#xA;        [TEST CHECK CONSTRAINTS COUNT]&#xA;        ORACLEDB:DEPARTMENTS:1&#xA;        POSTGRES:departments:1&#xA;        ORACLEDB:EMPLOYEES:1&#xA;        POSTGRES:employees:1&#xA;        [ERRORS CHECK CONSTRAINTS COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of check constraints.&#xA;&#xA;        [TEST NOT NULL CONSTRAINTS COUNT]&#xA;        ORACLEDB:DEPARTMENTS:1&#xA;        POSTGRES:departments:1&#xA;        ORACLEDB:EMPLOYEES:1&#xA;        POSTGRES:employees:1&#xA;        [ERRORS NOT NULL CONSTRAINTS COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of not null constraints.&#xA;&#xA;        [TEST COLUMN DEFAULT VALUE COUNT]&#xA;        ORACLEDB:DEPARTMENTS:1&#xA;        POSTGRES:departments:1&#xA;        ORACLEDB:EMPLOYEES:1&#xA;        POSTGRES:employees:1&#xA;        [ERRORS COLUMN DEFAULT VALUE COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of column default value.&#xA;&#xA;        [TEST IDENTITY COLUMN COUNT]&#xA;        ORACLEDB:DEPARTMENTS:1&#xA;        POSTGRES:departments:1&#xA;        ORACLEDB:EMPLOYEES:0&#xA;        POSTGRES:employees:0&#xA;        [ERRORS IDENTITY COLUMN COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of identity column.&#xA;&#xA;        [TEST FOREIGN KEYS COUNT]&#xA;        ORACLEDB:DEPARTMENTS:0&#xA;        POSTGRES:departments:0&#xA;        ORACLEDB:EMPLOYEES:1&#xA;        POSTGRES:employees:1&#xA;        [ERRORS FOREIGN KEYS COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of foreign keys.&#xA;&#xA;        [TEST TABLE COUNT]&#xA;        ORACLEDB:TABLE:2&#xA;        POSTGRES:TABLE:2&#xA;        [ERRORS TABLE COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of TABLE.&#xA;&#xA;        [TEST TABLE TRIGGERS COUNT]&#xA;        ORACLEDB:DEPARTMENTS:0&#xA;        POSTGRES:departments:0&#xA;        ORACLEDB:EMPLOYEES:1&#xA;        POSTGRES:employees:1&#xA;        [ERRORS TABLE TRIGGERS COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of table triggers.&#xA;&#xA;        [TEST TRIGGER COUNT]&#xA;        ORACLEDB:TRIGGER:2&#xA;        POSTGRES:TRIGGER:2&#xA;        [ERRORS TRIGGER COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of TRIGGER.&#xA;&#xA;        [TEST VIEW COUNT]&#xA;        ORACLEDB:VIEW:1&#xA;        POSTGRES:VIEW:1&#xA;        [ERRORS VIEW COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of VIEW.&#xA;&#xA;        [TEST MVIEW COUNT]&#xA;        ORACLEDB:MVIEW:0&#xA;        POSTGRES:MVIEW:0&#xA;        [ERRORS MVIEW COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of MVIEW.&#xA;&#xA;        [TEST SEQUENCE COUNT]&#xA;        ORACLEDB:SEQUENCE:1&#xA;        POSTGRES:SEQUENCE:0&#xA;        [ERRORS SEQUENCE COUNT]&#xA;        SEQUENCE does not have the same count in Oracle (1) and in PostgreSQL (0).&#xA;&#xA;        [TEST TYPE COUNT]&#xA;        ORACLEDB:TYPE:1&#xA;        POSTGRES:TYPE:0&#xA;        [ERRORS TYPE COUNT]&#xA;        TYPE does not have the same count in Oracle (1) and in PostgreSQL (0).&#xA;&#xA;        [TEST FDW COUNT]&#xA;        ORACLEDB:FDW:0&#xA;        POSTGRES:FDW:0&#xA;        [ERRORS FDW COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of FDW.&#xA;&#xA;        [TEST FUNCTION COUNT]&#xA;        ORACLEDB:FUNCTION:3&#xA;        POSTGRES:FUNCTION:3&#xA;        [ERRORS FUNCTION COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of functions.&#xA;&#xA;        [TEST SEQUENCE VALUES]&#xA;        ORACLEDB:EMPLOYEES_NUM_SEQ:1285&#xA;        POSTGRES:employees_num_seq:1285&#xA;        [ERRORS SEQUENCE VALUES COUNT]&#xA;        OK, Oracle and PostgreSQL have the same values for sequences&#xA;&#xA;        [TEST ROWS COUNT]&#xA;        ORACLEDB:DEPARTMENTS:27&#xA;        POSTGRES:departments:27&#xA;        ORACLEDB:EMPLOYEES:854&#xA;        POSTGRES:employees:854&#xA;        [ERRORS ROWS COUNT]&#xA;        OK, Oracle and PostgreSQL have the same number of rows.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Data validation Data validation consists in comparing data retrieved from a foreign table pointing to the source Oracle table and a local PostgreSQL table resulting from the data export.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;To run data validation you can use a direct connection like any other&#xA;Ora2Pg action but you can also use the oracle_fdw or mysql_fdw extension&#xA;provided that FDW_SERVER and PG_DSN configuration directives are set.&#xA;&#xA;By default Ora2Pg will extract the 10000 first rows from both side, you&#xA;can change this value using directive DATA_VALIDATION_ROWS. When it is&#xA;set to zero all rows of the tables will be compared.&#xA;&#xA;Data validation requires that the table has a primary key or unique&#xA;index and that the key columns is not a LOB. Rows will be sorted using&#xA;this unique key. Due to differences in sort behavior between Oracle and&#xA;PostgreSQL, if the collation of unique key columns in PostgreSQL is not&#xA;&#39;C&#39;, the sort order can be different compared to Oracle. In this case&#xA;the data validation will fail.&#xA;&#xA;Data validation must be done before any data is modified.&#xA;&#xA;Ora2Pg will stop comparing two tables after DATA_VALIDATION_ROWS is&#xA;reached or that 10 errors has been encountered, result is dumped in a&#xA;file named &#34;data_validation.log&#34; written in the current directory by&#xA;default. The number of error before stopping the diff between rows can&#xA;be controlled using the configuration directive DATA_VALIDATION_ERROR.&#xA;All rows in errors are printed to the output file for your analyze.&#xA;&#xA;It is possible to parallelize data validation by using -P option or the&#xA;corresponding configuration directive PARALLEL_TABLES in ora2pg.conf.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use of System Change Number (SCN) Ora2Pg is able to export data as of a specific SCN. You can set it at command line using the -S or --scn option. You can give a specific SCN or if you want to use the current SCN at first connection time set the value to &#39;current&#39;. In this last case the connection user has the &#34;SELECT ANY DICTIONARY&#34; or the &#34;SELECT_CATALOG_ROLE&#34; role, the current SCN is looked at the v$database view.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Example of use:&#xA;&#xA;    ora2pg -c ora2pg.conf -t COPY --scn 16605281&#xA;&#xA;This adds the following clause to the query used to retrieve data for&#xA;example:&#xA;&#xA;    AS OF SCN 16605281&#xA;&#xA;You can also use th --scn option to use the Oracle flashback capabality&#xA;by specifying a timestamp expression instead of a SCN. For example:&#xA;&#xA;    ora2pg -c ora2pg.conf -t COPY --scn &#34;TO_TIMESTAMP(&#39;2021-12-01 00:00:00&#39;, &#39;YYYY-MM-DD HH:MI:SS&#39;)&#34;&#xA;&#xA;This will add the following clause to the query used to retrieve data:&#xA;&#xA;    AS OF TIMESTAMP TO_TIMESTAMP(&#39;2021-12-01 00:00:00&#39;, &#39;YYYY-MM-DD HH:MI:SS&#39;)&#xA;&#xA;or for example to only retrive yesterday&#39;s data:&#xA;&#xA;    ora2pg -c ora2pg.conf -t COPY --scn &#34;SYSDATE - 1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Change Data Capture (CDC) Ora2Pg do not have such feature which allow to import data and to only apply changes after the first import. But you can use the --cdc_ready option to export data with registration of the SCN at the time of the table export. All SCN per tables are written to a file name TABLES_SCN.log. This SCN can be used with a CDC tool.&lt;/p&gt; &#xA;&lt;p&gt;Importing BLOB as large objects By default Ora2Pg imports Oracle BLOB as bytea, the destination column is created using the bytea data type. If you want to use large object instead of bytea, just add the --blob_to_lo option to the ora2pg command. It will create the destination column as data type Oid and will save the BLOB as a large object using the lo_from_bytea() function. The Oid returned by the call to lo_from_bytea() is inserted in the destination column instead of a bytea. Because of the use of the function this option can only be used with actions SHOW_COLUMN, TABLE and INSERT. Action COPY is not allowed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;If you want to use COPY or have huge size BLOB ( &amp;gt; 1GB) than can not be&#xA;imported using lo_from_bytea() you can add option --lo_import to the&#xA;ora2pg command. This will allow to import data in two passes.&#xA;&#xA;1) Export data using COPY or INSERT will set the Oid destination column&#xA;for BLOB to value 0 and save the BLOB value into a dedicated file. It&#xA;will also create a Shell script to import the BLOB files into the&#xA;database using psql command \lo_import and to update the table Oid&#xA;column to the returned large object Oid. The script is named&#xA;lo_import-TABLENAME.sh&#xA;&#xA;2) Execute all scripts lo_import-TABLENAME.sh after setting the&#xA;environment variables PGDATABASE and optionally PGHOST, PGPORT, PGUSER,&#xA;etc. if they do not correspond to the default values for libpq.&#xA;&#xA;You might also execute manually a VACUUM FULL on the table to remove the&#xA;bloat created by the table update.&#xA;&#xA;Limitation: the table must have a primary key, it is used to set the&#xA;WHERE clause to update the Oid column after the large object import.&#xA;Importing BLOB using this second method (--lo_import) is very slow so it&#xA;should be reserved to rows where the BLOB &amp;gt; 1GB for all other rows use&#xA;the option --blob_to_lo. To filter the rows you can use the WHERE&#xA;configuration directive in ora2pg.conf.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;SUPPORT Author / Maintainer Gilles Darold &#xA; &lt;gilles at darold dot net&gt;&lt;/gilles&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Please report any bugs, patches, help, etc. to &amp;lt;gilles AT darold DOT&#xA;net&amp;gt;.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Feature request If you need new features let me know at &#xA; &lt;gilles at darold dot net&gt;&#xA;  . This help a lot to develop a better/useful tool.&#xA; &lt;/gilles&gt;&lt;/p&gt; &#xA;&lt;p&gt;How to contribute ? Any contribution to build a better tool is welcome, you just have to send me your ideas, features request or patches and there will be applied.&lt;/p&gt; &#xA;&lt;p&gt;LICENSE Copyright (c) 2000-2022 Gilles Darold - All rights reserved.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;        This program is free software: you can redistribute it and/or modify&#xA;        it under the terms of the GNU General Public License as published by&#xA;        the Free Software Foundation, either version 3 of the License, or&#xA;        any later version.&#xA;&#xA;        This program is distributed in the hope that it will be useful,&#xA;        but WITHOUT ANY WARRANTY; without even the implied warranty of&#xA;        MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the&#xA;        GNU General Public License for more details.&#xA;&#xA;        You should have received a copy of the GNU General Public License&#xA;        along with this program.  If not, see &amp;lt; http://www.gnu.org/licenses/ &amp;gt;.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ACKNOWLEDGEMENT I must thanks a lot all the great contributors, see changelog for all acknowledgments.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>PiratenHi/Mitgliederverwaltung</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/PiratenHi/Mitgliederverwaltung</id>
    <link href="https://github.com/PiratenHi/Mitgliederverwaltung" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Skripte für die Mitgliederverwaltung&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>fusioninventory/fusioninventory-agent</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/fusioninventory/fusioninventory-agent</id>
    <link href="https://github.com/fusioninventory/fusioninventory-agent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;FusionInventory Agent&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FusionInventory Agent&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/fusioninventory/fusioninventory-agent&#34;&gt;&lt;img src=&#34;https://travis-ci.org/fusioninventory/fusioninventory-agent.svg?branch=develop&#34; alt=&#34;Travis Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ci.appveyor.com/project/fusioninventory/fusioninventory-agent&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/f2oh6p3qnr2bck1b?svg=true&#34; alt=&#34;Appveyor Build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://circleci.com/gh/fusioninventory/fusioninventory-agent&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/fusioninventory/fusioninventory-agent.svg?style=svg&#34; alt=&#34;CircleCI Build status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Summary&lt;/h2&gt; &#xA;&lt;p&gt;The FusionInventory agent is a generic management agent. It can perform a certain number of tasks, according to its own execution plan, or on behalf of a GLPI server with fusioninventory plugin, acting as a control point.&lt;/p&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;http://fusioninventory.org/overview/&#34;&gt;FusionInventory solution overview&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;h3&gt;Core&lt;/h3&gt; &#xA;&lt;p&gt;Minimum perl version: 5.8&lt;/p&gt; &#xA;&lt;p&gt;Mandatory Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;File::Which&lt;/li&gt; &#xA; &lt;li&gt;LWP::UserAgent&lt;/li&gt; &#xA; &lt;li&gt;Net::IP&lt;/li&gt; &#xA; &lt;li&gt;Text::Template&lt;/li&gt; &#xA; &lt;li&gt;UNIVERSAL::require&lt;/li&gt; &#xA; &lt;li&gt;XML::TreePP&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Compress::Zlib, for message compression&lt;/li&gt; &#xA; &lt;li&gt;HTTP::Daemon, for web interface&lt;/li&gt; &#xA; &lt;li&gt;IO::Socket::SSL, for HTTPS support&lt;/li&gt; &#xA; &lt;li&gt;LWP::Protocol::https, for HTTPS support&lt;/li&gt; &#xA; &lt;li&gt;Proc::Daemon, for daemon mode (Unix only)&lt;/li&gt; &#xA; &lt;li&gt;Proc::PID::File, for daemon mode (Unix only)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Inventory task&lt;/h3&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::CUPS, for printers detection&lt;/li&gt; &#xA; &lt;li&gt;Parse::EDID, for EDID data parsing&lt;/li&gt; &#xA; &lt;li&gt;DateTime, for reliable timezone name extraction&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional programs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;dmidecode, for DMI data retrieval&lt;/li&gt; &#xA; &lt;li&gt;lspci, for PCI bus scanning&lt;/li&gt; &#xA; &lt;li&gt;hdparm, for additional disk drive info retrieval&lt;/li&gt; &#xA; &lt;li&gt;monitor-get-edid-using-vbe, monitor-get-edid or get-edid, for EDID data access&lt;/li&gt; &#xA; &lt;li&gt;ssh-keyscan, for host SSH public key retrieval&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Network discovery tasks&lt;/h3&gt; &#xA;&lt;p&gt;Mandatory Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Thread::Queue&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::NBName, for NetBios method support&lt;/li&gt; &#xA; &lt;li&gt;Net::SNMP, for SNMP method support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional programs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;arp, for arp table lookup method support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Network inventory tasks&lt;/h3&gt; &#xA;&lt;p&gt;Mandatory Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::SNMP&lt;/li&gt; &#xA; &lt;li&gt;Thread::Queue&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Crypt::DES, for SNMPv3 support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Wake on LAN task&lt;/h3&gt; &#xA;&lt;p&gt;Optional Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::Write::Layer2, for ethernet method support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Deploy task&lt;/h3&gt; &#xA;&lt;p&gt;Mandatory Perl modules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Archive::Extract&lt;/li&gt; &#xA; &lt;li&gt;Digest::SHA&lt;/li&gt; &#xA; &lt;li&gt;File::Copy::Recursive&lt;/li&gt; &#xA; &lt;li&gt;JSON::PP&lt;/li&gt; &#xA; &lt;li&gt;URI::Escape&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Mandatory Perl modules for P2P Support:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Net::Ping&lt;/li&gt; &#xA; &lt;li&gt;Parallel::ForkManager&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Related contribs&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/fusioninventory/fusioninventory-agent/develop/CONTRIB.md&#34;&gt;CONTRIB&lt;/a&gt; to find references to FusionInventory Agent related scritps/files&lt;/p&gt; &#xA;&lt;h2&gt;Contacts&lt;/h2&gt; &#xA;&lt;p&gt;Project websites:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;main site: &lt;a href=&#34;http://www.fusioninventory.org&#34;&gt;http://www.fusioninventory.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Github org: &lt;a href=&#34;http://github.com/fusioninventory/&#34;&gt;http://github.com/fusioninventory/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Project mailing lists:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://lists.alioth.debian.org/mailman/listinfo/fusioninventory-user&#34;&gt;http://lists.alioth.debian.org/mailman/listinfo/fusioninventory-user&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://lists.alioth.debian.org/mailman/listinfo/fusioninventory-devel&#34;&gt;http://lists.alioth.debian.org/mailman/listinfo/fusioninventory-devel&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Project IRC channel:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;#FusionInventory on FreeNode IRC Network&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please report any issues on Github.&lt;/p&gt; &#xA;&lt;h2&gt;Copyrights&lt;/h2&gt; &#xA;&lt;p&gt;Copyright 2006-2010 &lt;a href=&#34;https://www.ocsinventory-ng.org/&#34;&gt;OCS Inventory contributors&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Copyright 2010-2021 &lt;a href=&#34;https://fusioninventory.org&#34;&gt;FusionInventory Team&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Copyright 2011-2021 &lt;a href=&#34;https://www.teclib-edition.com/&#34;&gt;Teclib Editions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This software is licensed under the terms of GPLv2+, see LICENSE file for details.&lt;/p&gt; &#xA;&lt;h2&gt;Additional pieces of software&lt;/h2&gt; &#xA;&lt;p&gt;The fusioninventory-injector script:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;author: Pascal Danek&lt;/li&gt; &#xA; &lt;li&gt;copyright: 2005 Pascal Danek&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;FusionInventory::Agent::Task::Inventory::Input::Virtualization::Vmsystem contains code from imvirt:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;url: &lt;a href=&#34;http://micky.ibh.net/~liske/imvirt.html&#34;&gt;http://micky.ibh.net/~liske/imvirt.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;author: Thomas Liske &lt;a href=&#34;mailto:liske@ibh.de&#34;&gt;liske@ibh.de&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;copyright: 2008 IBH IT-Service GmbH &lt;a href=&#34;http://www.ibh.de/&#34;&gt;http://www.ibh.de/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;License: GPLv2+&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>trinityrnaseq/trinityrnaseq</title>
    <updated>2022-06-01T01:49:59Z</updated>
    <id>tag:github.com,2022-06-01:/trinityrnaseq/trinityrnaseq</id>
    <link href="https://github.com/trinityrnaseq/trinityrnaseq" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Trinity RNA-Seq de novo transcriptome assembly&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;trinityrnaseq&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/trinityrnaseq/trinityrnaseq&#34;&gt;&lt;img src=&#34;https://travis-ci.org/trinityrnaseq/trinityrnaseq.svg?branch=devel&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://bioconda.github.io/recipes/trinity/README.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg?style=flat-square&#34; alt=&#34;install with bioconda&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Trinity RNA-Seq de novo transcriptome assembly see the main webpage &lt;a href=&#34;http://trinityrnaseq.github.io&#34;&gt;http://trinityrnaseq.github.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We encourage you to contribute to Trinity! Please check out the &lt;a href=&#34;https://github.com/trinityrnaseq/trinityrnaseq/wiki/Contributing&#34;&gt;Contributing&lt;/a&gt; for the guidelines.&lt;/p&gt;</summary>
  </entry>
</feed>