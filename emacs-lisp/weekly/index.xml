<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Emacs Lisp Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-19T01:55:32Z</updated>
  <subtitle>Weekly Trending of Emacs Lisp in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>rksm/org-ai</title>
    <updated>2023-03-19T01:55:32Z</updated>
    <id>tag:github.com,2023-03-19:/rksm/org-ai</id>
    <link href="https://github.com/rksm/org-ai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGPT and DALL-E in org-mode using the OpenAI APIs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;org-ai&lt;/h1&gt; &#xA;&lt;p&gt;Minor mode for Emacs org-mode that provides access to OpenAI API&#39;s. Inside an org-mode buffer you can&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;use ChatGPT to generate text, having full control over system and user prompts (&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#chatgpt-in-org-mode&#34;&gt;demo&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;generate images with a text prompt using DALL-E (&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#dall-e-in-org-mode&#34;&gt;demo&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;generate image variations of an input image (&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#image-variations&#34;&gt;demo&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Implemented in pure Emacs Lisp, no external dependencies required (except currently for image variations[^1]).&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: In order to use this you&#39;ll need an &lt;a href=&#34;https://platform.openai.com/&#34;&gt;OpenAI account&lt;/a&gt; and you need to get an API token. As far as I can tell, the current usage limits for the free tier get you pretty far.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#demos&#34;&gt;Demos&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#chatgpt-in-org-mode&#34;&gt;ChatGPT in org-mode&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#dall-e-in-org-mode&#34;&gt;DALL-E in org-mode&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#image-variations&#34;&gt;Image variations&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#options&#34;&gt;Options&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#setup&#34;&gt;Setup&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#melpa&#34;&gt;Melpa&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#straightel&#34;&gt;Straight.el&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#manual&#34;&gt;Manual&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#faq&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;code&gt;#+begin_ai...#+end_ai&lt;/code&gt; special blocks&lt;/h3&gt; &#xA;&lt;p&gt;Similar to org-babel, these blocks demarcate input (and for ChatGPT also output) for the AI model. You can use it for AI chat, text completion and text -&amp;gt; image generation. See &lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#options&#34;&gt;options&lt;/a&gt; below for more information.&lt;/p&gt; &#xA;&lt;p&gt;Create a block like&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-org&#34;&gt;#+begin_ai&#xA;Is Emacs the greatest editor?&#xA;#+end_ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and press &lt;code&gt;C-c C-c&lt;/code&gt;. The Chat input will appear inline and once the response is complete, you can enter your reply and so on. See &lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#chatgpt-in-org-mode&#34;&gt;the demo&lt;/a&gt; below. You can press &lt;code&gt;C-g&lt;/code&gt; while the ai request is running to cancel it.&lt;/p&gt; &#xA;&lt;p&gt;You can also modify the &lt;em&gt;system&lt;/em&gt; prompt and other parameters used. The system prompt is injected before the user&#39;s input and &#34;primes&#34; the model to answer in a certain style. For example you can do:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-org&#34;&gt;#+begin_ai :max-tokens 250&#xA;[SYS]: Act as if you are a powerful medival king.&#xA;[ME]: What will you eat today?&#xA;#+end_ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will result in an API payload like&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;messages&#34;: [&#xA;    {&#xA;      &#34;role&#34;: &#34;system&#34;,&#xA;      &#34;content&#34;: &#34;Act as if you are a powerful medival king.&#34;&#xA;    },&#xA;    {&#xA;      &#34;role&#34;: &#34;user&#34;,&#xA;      &#34;content&#34;: &#34;What will you eat today?&#34;&#xA;    }&#xA;  ],&#xA;  &#34;model&#34;: &#34;gpt-3.5-turbo&#34;,&#xA;  &#34;stream&#34;: true,&#xA;  &#34;max_tokens&#34;: 250,&#xA;  &#34;temperature&#34;: 1.2&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For some prompt ideas see for example &lt;a href=&#34;https://github.com/f/awesome-chatgpt-prompts&#34;&gt;Awesome ChatGPT Prompts&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When generating images using the &lt;code&gt;:image&lt;/code&gt; flag, images will appear underneath the ai block inline. Images will be stored (together with their prompt) inside &lt;code&gt;org-ai-image-directory&lt;/code&gt; which defaults to &lt;code&gt;~/org/org-ai-images/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Image variation&lt;/h3&gt; &#xA;&lt;p&gt;You can also use an existing image as input to generate more similar looking images. The &lt;code&gt;org-ai-image-variation&lt;/code&gt; command will prompt for a file path to an image, a size and a count and will then generate as many images and insert links to them inside the current &lt;code&gt;org-mode&lt;/code&gt; buffer. Images will be stored inside &lt;code&gt;org-ai-image-directory&lt;/code&gt;. See the &lt;a href=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/#image-variations&#34;&gt;demo&lt;/a&gt; below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://platform.openai.com/docs/guides/images/variations&#34;&gt;For more information see the OpenAI documentation&lt;/a&gt;. The input image needs to be square and its size needs to be less than 4MB. And you currently need curl available as a command line tool[^1].&lt;/p&gt; &#xA;&lt;p&gt;[^1]: &lt;strong&gt;Note:&lt;/strong&gt; Currenly the image variation implementation requires a command line curl to be installed. Reason for that is that the OpenAI API expects multipart/form-data requests and the emacs built-in &lt;code&gt;url-retrieve&lt;/code&gt; does not support that (At least I haven&#39;t figured out how). Switching to &lt;code&gt;request.el&lt;/code&gt; might be a better alternative. If you&#39;re interested in contributing, PRs are very welcome!&lt;/p&gt; &#xA;&lt;h2&gt;Demos&lt;/h2&gt; &#xA;&lt;h3&gt;ChatGPT in org-mode&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-org&#34;&gt;#+begin_ai&#xA;Is Emacs the greatest editor?&#xA;#+end_ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/doc/org-ai-demo-1.gif&#34; alt=&#34;chat-gpt in org-mode&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can continue to type and press &lt;code&gt;C-c C-c&lt;/code&gt; to create a conversation. &lt;code&gt;C-g&lt;/code&gt; will interrupt a running request.&lt;/p&gt; &#xA;&lt;h3&gt;DALL-E in org-mode&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-org&#34;&gt;#+begin_ai :image :size 256x256&#xA;Hyper realistic sci-fi rendering of super complicated technical machine.&#xA;#+end_ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/doc/org-ai-demo-2.gif&#34; alt=&#34;dall-e in org-mode&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Image variations&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rksm/org-ai/master/doc/org-ai-demo-3.gif&#34; alt=&#34;dall-e image generation in org-mode&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Options&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;#+begin_ai...#+end_ai&lt;/code&gt; block can take the following options.&lt;/p&gt; &#xA;&lt;h3&gt;For ChatGPT&lt;/h3&gt; &#xA;&lt;p&gt;By default, the content of ai blocks are interpreted as messages for ChatGPT. Text following &lt;code&gt;[ME]:&lt;/code&gt; is associated with the user, text following &lt;code&gt;[AI]:&lt;/code&gt; is associated as the model&#39;s response. Optionally you can start the block with a &lt;code&gt;[SYS]: &amp;lt;behahvior&amp;gt;&lt;/code&gt; input to prime the model (see &lt;code&gt;org-ai-default-chat-system-prompt&lt;/code&gt; below).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;:max-tokens number&lt;/code&gt; - number of maximum tokens to generate (default: nil, use OpenAI&#39;s default)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;:temperature number&lt;/code&gt; - temperature of the model (default: 1)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;:top-p number&lt;/code&gt; - top_p of the model (default: 1)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;:frequency-penalty number&lt;/code&gt; - frequency penalty of the model (default: 0)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;:presence-penalty&lt;/code&gt; - presence penalty of the model (default: 0)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;:sys-everywhere&lt;/code&gt; - repeat the system prompt for every user message (default: nil)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following custom variables can be used to configure the chat:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;org-ai-default-chat-model&lt;/code&gt; (default: &lt;code&gt;&#34;gpt-3.5-turbo&#34;&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;org-ai-default-max-tokens&lt;/code&gt; How long the response should be. Currently cannot exceed 4096. If this value is too small an answer might be cut off (default: nil)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;org-ai-default-chat-system-prompt&lt;/code&gt; How to &#34;prime&#34; the model. This is a prompt that is injected before the user&#39;s input. (default: &lt;code&gt;&#34;You are a helpful assistant inside Emacs.&#34;&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;org-ai-default-inject-sys-prompt-for-all-messages&lt;/code&gt; Wether to repeat the system prompt for every user message. Sometimes the model &#34;forgets&#34; how it was primed. This can help remind it. (default: &lt;code&gt;nil&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;For DALL-E&lt;/h3&gt; &#xA;&lt;p&gt;When you add an &lt;code&gt;:image&lt;/code&gt; option to the ai block, the prompt will be used for image generation.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;:image&lt;/code&gt; - generate an image instead of text&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;:size&lt;/code&gt; - size of the image to generate (default: 256x256, can be 512x512 or 1024x1024)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;:n&lt;/code&gt; - the number of images to generate (default: 1)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following custom variables can be used to configure the image generation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;org-ai-image-directory&lt;/code&gt; - where to store the generated images (default: &lt;code&gt;~/org/org-ai-images/&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Other text models&lt;/h3&gt; &#xA;&lt;p&gt;The older completion models can also be prompted by adding the &lt;code&gt;:completion&lt;/code&gt; option to the ai block.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;:completion&lt;/code&gt; - instead of using the chatgpt model, use the completion model&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;:model&lt;/code&gt; - which model to use, see &lt;a href=&#34;https://platform.openai.com/docs/models&#34;&gt;https://platform.openai.com/docs/models&lt;/a&gt; for a list of models&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For the detailed meaning of those parameters see the &lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat&#34;&gt;OpenAI API documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The following custom variables can be used to configure the text generation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;org-ai-default-completion-model&lt;/code&gt; (default: &lt;code&gt;&#34;text-davinci-003&#34;&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Melpa&lt;/h3&gt; &#xA;&lt;p&gt;The PR for &lt;a href=&#34;https://github.com/melpa/melpa/pull/8429&#34;&gt;melpa is currently pending&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Straight.el&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(straight-use-package&#xA; &#39;(org-ai :type git :host github :repo &#34;rksm/org-ai&#34;&#xA;          :local-repo &#34;org-ai&#34;&#xA;          :files (&#34;*.el&#34; &#34;README.md&#34;)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Manual&lt;/h3&gt; &#xA;&lt;p&gt;Checkout this repository.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone&#xA;https://github.com/rksm/org-ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, if you use &lt;code&gt;use-package&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(use-package org-ai&#xA;  :load-path (lambda () &#34;path/to/org-ai&#34;)&#xA;  :commands (org-ai-mode)&#xA;  :custom&#xA;  (org-ai-openai-api-token &#34;&amp;lt;ENTER YOUR API TOKEN HERE&amp;gt;&#34;)&#xA;  :init&#xA;  (add-hook &#39;org-mode-hook #&#39;org-ai-mode)&#xA;  :config&#xA;  ;; if you are using yasnippet and want `ai` snippets&#xA;  (org-ai-install-yasnippets))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or just with &lt;code&gt;require&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(add-to-list &#39;load-path &#34;path/to/org-ai&#34;)&#xA;(require &#39;org)&#xA;(require &#39;org-ai)&#xA;(add-hook &#39;org-mode-hook #&#39;org-ai-mode)&#xA;(org-ai-install-yasnippets) ;; if you are using yasnippet and want `ai` snippets&#xA;(setq org-ai-openai-api-token &#34;&amp;lt;ENTER YOUR API TOKEN HERE&amp;gt;&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;API key with auth-source&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;org-ai&lt;/code&gt; supports &lt;code&gt;auth-source&lt;/code&gt; for retrieving your API key. You can store a secret in the format&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;machine api.openai.com login org-ai password &amp;lt;your-api-key&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If this is present, &lt;code&gt;org-ai-openai-api-token&lt;/code&gt; will be automatically set that value. If you do not want &lt;code&gt;org-ai&lt;/code&gt; to try to retrieve the key from &lt;code&gt;auth-source&lt;/code&gt;, you can set &lt;code&gt;org-ai-use-auth-source&lt;/code&gt; to &lt;code&gt;nil&lt;/code&gt; before loading &lt;code&gt;org-ai&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;Is this OpenAI specfic?&lt;/h3&gt; &#xA;&lt;p&gt;Currently yes but once there are more high-quality APIs available I&#39;m planning on supporting those as well.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>CarlQLange/chatgpt-arcana.el</title>
    <updated>2023-03-19T01:55:32Z</updated>
    <id>tag:github.com,2023-03-19:/CarlQLange/chatgpt-arcana.el</id>
    <link href="https://github.com/CarlQLange/chatgpt-arcana.el" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Put ChatGPT in your emacs. Yer a space wizard now, Harry.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT-Arcana&lt;/h1&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;🔮 ChatGPT-Arcana is an Emacs Lisp package that gives you arcane powers. Yer a space wizard now, Harry.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;h4&gt;Create and edit code&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/859820/222489571-27901725-158e-4a2a-899a-36a3f4eea2c1.mp4&#34;&gt;https://user-images.githubusercontent.com/859820/222489571-27901725-158e-4a2a-899a-36a3f4eea2c1.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Write a doc about ffmpeg in org-mode&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/859820/222561453-031d271f-4fee-46f4-b63e-734729e01745.mp4&#34;&gt;https://user-images.githubusercontent.com/859820/222561453-031d271f-4fee-46f4-b63e-734729e01745.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Explain code in the selected region&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/859820/222563046-5928a98d-7498-4bce-9916-f5a7d24acc81.mp4&#34;&gt;https://user-images.githubusercontent.com/859820/222563046-5928a98d-7498-4bce-9916-f5a7d24acc81.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Have a lovely chat&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/859820/222718608-b767a663-86f9-4c56-acbe-192e1e91fe26.mp4&#34;&gt;https://user-images.githubusercontent.com/859820/222718608-b767a663-86f9-4c56-acbe-192e1e91fe26.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;There are various interactive functions available. Some of them even work.&lt;/p&gt; &#xA;&lt;p&gt;This package, for now, provides the following functionality:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Chat with GPT in Emacs with &lt;code&gt;chatgpt-arcana-chat-start-chat&lt;/code&gt; (this is the best part of this package).&lt;/li&gt; &#xA; &lt;li&gt;Generate text content based on prompt and optionally selected region using &lt;code&gt;chatgpt-arcana-query&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Replace selected text region with generated text content using &lt;code&gt;chatgpt-arcana-replace-region&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Insert generated text at the current cursor position with informative context lines using &lt;code&gt;chatgpt-arcana-insert-at-point-with-context&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Insert generated text at, after or before selected text region using &lt;code&gt;chatgpt-arcana-insert-after-region&lt;/code&gt; and &lt;code&gt;chatgpt-arcana-insert-before-region&lt;/code&gt; and &lt;code&gt;chatgpt-arcana-insert-at-point&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Chat buffer auto-naming (modify prompt with custom var &lt;code&gt;chatgpt-arcana-generated-buffer-name-prompt&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Chat session autosave and automatic file naming (disable with custom var&lt;code&gt;chatgpt-arcana-chat-autosave-enabled&lt;/code&gt;, modify save directory with &lt;code&gt;chatgpt-arcana-chat-autosave-directory&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;ChatGPT-Arcana isn’t on melpa or elpa. You can use use-package to install from github:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(use-package chatgpt-arcana&#xA;  :straight (:host github :repo &#34;CarlQLange/ChatGPT-Arcana.el&#34; :files (&#34;*.el&#34;))&#xA;  :init (setq chatgpt-arcana-api-key &#34;your-api-key-here&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;My own config adds a few extra parts that don&#39;t need to be part of the package.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(use-package chatgpt-arcana&#xA;  :straight (:host github :repo &#34;CarlQLange/ChatGPT-Arcana.el&#34; :files (&#34;*.el&#34;))&#xA;  :init (setq chatgpt-arcana-api-key &#34;your-api-key-here&#34;)&#xA;  :config &#xA;  (use-package all-the-icons&#xA;    :config&#xA;    (add-to-list &#39;all-the-icons-mode-icon-alist&#xA;                 &#39;(chatgpt-arcana-chat-mode all-the-icons-octicon &#34;comment-discussion&#34; :height 1.0 :v-adjust -0.1 :face all-the-icons-purple)))&#xA;&#xA;  (use-package pretty-hydra&#xA;    :config&#xA;    (eval `(pretty-hydra-define chatgpt-arcana-hydra (:color blue :quit-key &#34;q&#34; :title &#34;ChatGPT Arcana&#34;)&#xA;             (&#34;Query&#34;&#xA;              ((&#34;a&#34; chatgpt-arcana-query &#34;Query&#34;)&#xA;               (&#34;r&#34; chatgpt-arcana-replace-region &#34;Replace region&#34;))&#xA;              &#34;Insert&#34;&#xA;              ((&#34;i&#34; chatgpt-arcana-insert-at-point-with-context &#34;At point with context&#34;)&#xA;               (&#34;I&#34; chatgpt-arcana-insert-at-point &#34;At point&#34;)&#xA;               (&#34;j&#34; chatgpt-arcana-insert-after-region &#34;Before region&#34;)&#xA;               (&#34;J&#34; chatgpt-arcana-insert-before-region &#34;After region&#34;))&#xA;              &#34;Chat&#34;&#xA;              ((&#34;c&#34; chatgpt-arcana-start-chat &#34;Start chat&#34;))&#xA;              &#34;Shortcuts&#34;&#xA;              (,@(chatgpt-arcana-generate-prompt-shortcuts))))))&#xA;&#xA;  (map! :leader&#xA;        :prefix (&#34;[&#34; . &#34;ChatGPT&#34;)&#xA;        :desc &#34;Start chat&#34; :g &#34;c&#34; #&#39;chatgpt-arcana-start-chat&#xA;        :desc &#34;Start chat&#34; :g &#34;[&#34; #&#39;chatgpt-arcana-start-chat&#xA;        :desc &#34;Open Hydra&#34; :g &#34;h&#34; #&#39;chatgpt-arcana-hydra/body))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You are going to want to add a keymap of your own, that&#39;s for sure :)&lt;/p&gt; &#xA;&lt;p&gt;I have to stress at this point that this package is very new, and I only wrote it to scratch an itch. Sorry if it turns you into a chicken or something.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;You will need to have an API key from OpenAI’s GPT-3 language model to use this package, and set it as &lt;code&gt;chatgpt-arcana-api-key&lt;/code&gt;. You can sign up for an API key on the OpenAI website. Depending on how much you use the package, the API cost may vary.&lt;/p&gt; &#xA;&lt;p&gt;I strongly recommend setting a low usage limit on your account to stop runaway spending. The default model is quite cheap but it costs nothing to be prudent.&lt;/p&gt; &#xA;&lt;h2&gt;Limitations&lt;/h2&gt; &#xA;&lt;p&gt;I have done exactly zero work in terms of compatibility. It works on my machine, sometimes. Maybe it&#39;ll even work on yours. Also, even though ChatGPT is pretty much the largest computing leap since the iPhone, it has its own limitations. Particularly, I&#39;ve noticed it&#39;s pretty terrible at writing org-mode - I guess due to a lack of source data. Hence, the &lt;code&gt;chatgpt-arcana-chat-mode&lt;/code&gt; is based on Markdown.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;This package was developed by Carl Lange with judicious help from ChatGPT.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This package is licensed under the &lt;a href=&#34;https://www.gnu.org/licenses/gpl-3.0.en.html&#34;&gt;GNU General Public License v3.0&lt;/a&gt;. &lt;em&gt;Important note&lt;/em&gt;: code generated by ChatGPT probably has a massive license headache attached to it and may result in RMS eating your dog.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>purcell/diredfl</title>
    <updated>2023-03-19T01:55:32Z</updated>
    <id>tag:github.com,2023-03-19:/purcell/diredfl</id>
    <link href="https://github.com/purcell/diredfl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Extra Emacs font lock rules for a more colourful dired&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;http://melpa.org/#/diredfl&#34;&gt;&lt;img src=&#34;http://melpa.org/packages/diredfl-badge.svg?sanitize=true&#34; alt=&#34;Melpa Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://stable.melpa.org/#/diredfl&#34;&gt;&lt;img src=&#34;http://stable.melpa.org/packages/diredfl-badge.svg?sanitize=true&#34; alt=&#34;Melpa Stable Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/purcell/diredfl/actions&#34;&gt;&lt;img src=&#34;https://github.com/purcell/diredfl/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.patreon.com/sanityinc&#34;&gt;&lt;img alt=&#34;Support me&#34; src=&#34;https://img.shields.io/badge/Support%20Me-%F0%9F%92%97-ff69b4.svg?sanitize=true&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Extra font lock rules for a more colourful dired&lt;/h1&gt; &#xA;&lt;p&gt;This is adapted from the extra font lock rules provided by Drew Adams&#39; &lt;code&gt;dired+&lt;/code&gt; package, but published via a modern means, and with support for older Emacsen removed.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/purcell/diredfl/master/screenshot.png&#34; alt=&#34;Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;re an Emacs 24 user or you have a recent version of &lt;code&gt;package.el&lt;/code&gt; you can install &lt;code&gt;diredfl&lt;/code&gt; from the &lt;a href=&#34;http://melpa.org&#34;&gt;MELPA&lt;/a&gt; repository. The version of &lt;code&gt;diredfl&lt;/code&gt; there will always be up-to-date.&lt;/p&gt; &#xA;&lt;p&gt;Enable &lt;code&gt;diredfl-mode&lt;/code&gt; in all &lt;code&gt;dired-mode&lt;/code&gt; buffers by calling or customising &lt;code&gt;diredfl-global-mode&lt;/code&gt; as desired.&lt;/p&gt; &#xA;&lt;h2&gt;Related packages&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Fuco1/dired-hacks#dired-rainbow&#34;&gt;dired-hacks&lt;/a&gt; also contains some enhanced font-lock support for &lt;code&gt;dired&lt;/code&gt;, but with different goals from this package.&lt;/p&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;Author: Steve Purcell &#xA; &lt;steve at sanityinc dot com&gt;&lt;/steve&gt;&lt;/p&gt; &#xA;&lt;p&gt;Homepage: &lt;a href=&#34;https://github.com/purcell/diredfl&#34;&gt;https://github.com/purcell/diredfl&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Author links:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.patreon.com/sanityinc&#34;&gt;💝 Support this project and my other Open Source work&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://uk.linkedin.com/in/stevepurcell&#34;&gt;💼 LinkedIn profile&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.sanityinc.com/&#34;&gt;✍ sanityinc.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/sanityinc&#34;&gt;🐦 @sanityinc&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>