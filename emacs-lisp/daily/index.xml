<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Emacs Lisp Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-13T01:32:41Z</updated>
  <subtitle>Daily Trending of Emacs Lisp in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>joshcho/ChatGPT.el</title>
    <updated>2022-12-13T01:32:41Z</updated>
    <id>tag:github.com,2022-12-13:/joshcho/ChatGPT.el</id>
    <link href="https://github.com/joshcho/ChatGPT.el" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGPT in Emacs&lt;/p&gt;&lt;hr&gt;&lt;p&gt;#+TITLE: ChatGPT.el&lt;/p&gt; &#xA;&lt;p&gt;[[https://chat.openai.com/chat][ChatGPT]] in Emacs. [[https://www.youtube.com/watch?v=4oUrm4CnIjo][Demo]]&lt;/p&gt; &#xA;&lt;p&gt;** Installation *** Dependency&lt;/p&gt; &#xA;&lt;p&gt;#+begin_src shell pip install git+&lt;a href=&#34;https://github.com/mmabrouk/chatgpt-wrapper&#34;&gt;https://github.com/mmabrouk/chatgpt-wrapper&lt;/a&gt; #+end_src&lt;/p&gt; &#xA;&lt;p&gt;#+begin_src shell chatgpt install #+end_src&lt;/p&gt; &#xA;&lt;p&gt;This will prompt you to log in with your browser for the first time only.&lt;/p&gt; &#xA;&lt;p&gt;NOTE: The setup should happen automatically first time you query, but it&#39;s a bit buggy. If you encounter any problems, please submit an issue or see [[https://github.com/mmabrouk/chatgpt-wrapper][chatgpt-wrapper]].&lt;/p&gt; &#xA;&lt;p&gt;*** Straight #+begin_src emacs-lisp (use-package chatgpt :straight (:host github :repo &#34;joshcho/ChatGPT.el&#34; :files (&#34;dist&#34; &#34;*.el&#34;)) :init (setq chatgpt-repo-path &#34;~/.emacs.d/straight/repos/ChatGPT.el/&#34;) :bind (&#34;C-c q&#34; . chatgpt-query)) #+end_src&lt;/p&gt; &#xA;&lt;p&gt;*** Quelpa #+begin_src emacs-lisp (use-package chatgpt :quelpa ((chatgpt :fetcher git :url &#34;&lt;a href=&#34;https://github.com/joshcho/ChatGPT.el.git&#34;&gt;https://github.com/joshcho/ChatGPT.el.git&lt;/a&gt;&#34;) :upgrade t) :init (setq chatgpt-repo-path (expand-file-name &#34;ChatGPT.el&#34; quelpa-build-dir)) :bind (&#34;C-c q&#34; . chatgpt-query)) #+end_src&lt;/p&gt; &#xA;&lt;p&gt;** Usage&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Press &lt;del&gt;C-c q&lt;/del&gt; to query ChatGPT.&lt;/li&gt; &#xA; &lt;li&gt;Select region before &lt;del&gt;C-c q&lt;/del&gt; to query ChatGPT by type.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Customization Customize &lt;del&gt;chatgpt-query-types&lt;/del&gt; for your own types.&lt;/p&gt; &#xA;&lt;p&gt;#+begin_src emacs-lisp (setq chatgpt-query-types &#39;( ;; ChatGPT.el defaults (&#34;doc&#34; . &#34;Please write the documentation for the following function.\n\n%s&#34;) (&#34;bug&#34; . &#34;There is a bug in the following function, please help me fix it.\n\n%s&#34;) (&#34;understand&#34; . &#34;What does the following function do?\n\n%s&#34;) (&#34;improve&#34; . &#34;Please improve the following code.\n\n%s&#34;) ;; your new prompt (&#34;my-custom-type&#34; . &#34;My custom prompt.\n\n%s&#34;))) #+end_src&lt;/p&gt; &#xA;&lt;p&gt;** Misc.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Every query is part of a conversation, so it will learn based on what you ask.&lt;/li&gt; &#xA; &lt;li&gt;Don&#39;t use &#34;custom&#34; as a type. It&#39;s reserved for custom prepend string through minibuffer.&lt;/li&gt; &#xA; &lt;li&gt;Check out [[https://github.com/semiosis/pen.el][Pen.el]]&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>semiosis/pen.el</title>
    <updated>2022-12-13T01:32:41Z</updated>
    <id>tag:github.com,2022-12-13:/semiosis/pen.el</id>
    <link href="https://github.com/semiosis/pen.el" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Pen.el stands for Prompt Engineering in emacs. It facilitates the creation, discovery and usage of prompts to language models. Pen supports OpenAI, EleutherAI, Aleph-Alpha, HuggingFace and others. It&#39;s the engine for the LookingGlass imaginary web browser.&lt;/p&gt;&lt;hr&gt;&lt;ul&gt; &#xA; &lt;li&gt;=Pen.el= (&lt;em&gt;Prompt engineering&lt;/em&gt; in emacs) Visit &lt;a href=&#34;https://semiosis.github.io/&#34;&gt;https://semiosis.github.io/&lt;/a&gt; for applications and demonstrations.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;em&gt;Undergoing rapid development&lt;/em&gt; - Likely issues.&lt;/p&gt; &#xA;&lt;p&gt;Pen.el is a docker application based on emacs, but you may run it as a server and integrate it with vim (see [[./config/pen.vim]]) and your own emacs using the thin client emacs package [[./src/pen-client.el]].&lt;/p&gt; &#xA;&lt;p&gt;=Pen.el= integrates LMs (LMs) such as OpenAI&#39;s =GPT-3= or EleutherAI&#39;s =GPT-J= into emacs by generating functions from prompts that map emacs&#39;s corners loosely onto LMs. These functions can be used interactively or non-interactively and in a variety of configurable ways.&lt;/p&gt; &#xA;&lt;p&gt;Using =Pen.el=, you can centralise all of your prompting tasks. That includes any NLP task for text or code, describing images ([[https://mullikine.github.io/posts/describing-melee-s-paintings-with-alephalpha/][AlephAlpha]]) and imagining images (=DALL-E=/[[https://semiosis.github.io/posts/pen-el-with-openai-glide-for-generating-images-from-text/][Glide]]). Audio and video are also possible -- keep an eye out for =VideoGPT= in the future. The payload system allows you to send media to multi-modal models. You may compose prompting functions for any model or API.&lt;/p&gt; &#xA;&lt;p&gt;The long-term Goal of Pen.el is to be a small &#39;imaginary&#39; operating system (as emacs is regarded to be) and server which facilitates external applications through LSP, but internally, it integrates prompting into all aspects of a linux operating system, replacing or enhancing components with imaginary counterparts. There&#39;s a microcosm of prompting within Pen.el.&lt;/p&gt; &#xA;&lt;p&gt;A textual interface is of greater importance than graphics in Pen.el, but Pen does support a graphical UI.&lt;/p&gt; &#xA;&lt;p&gt;Take =iman= for example. When opening a man page inside Pen, if the page does not exist then an imaginary one will be generated, and if it does exist it will be displayed but prompt functions will also be integrated into the experience. You can search the imaginary web from a man page, for example, or add images to the man page from DALL-e.&lt;/p&gt; &#xA;&lt;p&gt;The Pen Docker container currently sits around 25GB in size and the project has around 326007 lines of code (Khala included) comprised mainly of Emacs Lisp, Bash scripts and Clojure. It is set up as self-sustaining Clojure, Haskell, Prolog, Python, Go and Ethereum IDE and server, since the project uses all of these languages, but another reason to bundle toolchains is to develop imaginary programming libraries and tools for all of them. &lt;em&gt;Pen.el is its own IDE&lt;/em&gt;. The inital emacs can be run in GUI (by running with =pen=) or terminal mode (running with =pin= or =pen -nw=). The clipboard and certain volumes specified in =~/.pen/pen.yaml=) are shared with the host machine.&lt;/p&gt; &#xA;&lt;p&gt;[[./docs/images/menu.png]]&lt;/p&gt; &#xA;&lt;p&gt;Some builtin ways to make use of prompting functions are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/posts/a-time-crystal-prompt-with-codex-codex-game-of-life/][Game of Life in language models (i.e. virtual life form simulation)]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/posts/demo-of-lookingglass-v1-0i/][LookingGlass, the browser for the imaginary web]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/ii/][Imaginary Interpreter - program in any language imaginable, with any libraries imaginable]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/apostrophe/][Apostrophe - Speak to imagined personalities, from history or from your imagination]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/pensieve/][PenSieve - drag and drop, and peer into the imemories of personalities through a file system]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/channel/][Chann.el - Channel personalites from the matrix to control your computer]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/posts/gpt-3-guru/][Guru - Chat to virtual personalities about what your working on]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/mad-teaparty/][MadTeaParty - Run a chatbot populated social simulation, and take on the role of characters Avatar-style without their knowledge]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/nlsh/][NL·SH - Generate shell commands using natural language]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/paracosm/][Paracosm - Mind-mapping with artificial inspiration]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/continuum/][Continuum - Imagine multiversal continuations of your computer state forwards and backwards in time]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/melee/][Melee - The game of Adversarial Prompting]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/esp/][ESP - A Language server powered by Pen. &#34;One LSP server to rule all the computing contexts! And in the emacs bind them.&#34;]]&lt;/li&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/posts/pen-el-for-vim-and-the-bash-interop-selecting-candidates-with-fzf/][vim support ✓]] &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;[[https://semiosis.github.io/cterm/][As pen wrapping vim with cterm]]&lt;/li&gt; &#xA;   &lt;li&gt;And as prompt functions and bindings within vim (using fzf)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Proxies&lt;/li&gt; &#xA; &lt;li&gt;Web-facing point-and-click UI&lt;/li&gt; &#xA; &lt;li&gt;Real interpreters (e.g. iPython) inside complex ones&lt;/li&gt; &#xA; &lt;li&gt;Bash interop&lt;/li&gt; &#xA; &lt;li&gt;... and a lot more&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can also serve =Pen.el= as a public facing prompting environment, and secure it by running as a proxy, where you may prompt other =Pen.el= servers, keeping the human in the loop with the effect of decentralising language models and decentralising truth.&lt;/p&gt; &#xA;&lt;p&gt;Some behind-the-scenes technologies also included are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[[https://semiosis.github.io/ink/][Inkw.el - Intermediate Knowledge in emacs; A DSL for encoding the provenance of text.]]&lt;/li&gt; &#xA; &lt;li&gt;=Lalia= - A language of stories (multi-modal prompt chains) based on =Inkw.el=&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;=Pen.el= also facilitates the creation, development, discovery and usage of prompts.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s completely &lt;em&gt;free&lt;/em&gt;, &lt;em&gt;libre&lt;/em&gt; and &lt;em&gt;open-source&lt;/em&gt;. It&#39;s designed to be &lt;em&gt;transparent&lt;/em&gt; and keep the &lt;em&gt;Human in the Loop&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://semiosis.github.io/posts/a-prompting-lsp-server-for-any-language-or-context-using-large-language-models/&#34;&gt;https://semiosis.github.io/posts/a-prompting-lsp-server-for-any-language-or-context-using-large-language-models/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;** The pen of imagination&lt;/p&gt; &#xA;&lt;p&gt;[[./docs/images/the_pen_of_imagination.png]]&lt;/p&gt; &#xA;&lt;p&gt;| License | Discord server invite | |---------+-------------------------------| | =GPL-3= | &lt;a href=&#34;https://discord.gg/JwKGbAdNHR&#34;&gt;https://discord.gg/JwKGbAdNHR&lt;/a&gt; |&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Demo :: &lt;a href=&#34;https://mullikine.github.io/posts/prompt-design-with-yasnippet/&#34;&gt;https://mullikine.github.io/posts/prompt-design-with-yasnippet/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Quick installation&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Setting up from scratch, with a demo :: &lt;a href=&#34;https://semiosis.github.io/posts/pen-el-installation-from-scratch/&#34;&gt;https://semiosis.github.io/posts/pen-el-installation-from-scratch/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Longer guide here :: [[./docs/installation.org]]&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;#+BEGIN_SRC bash -n :i bash :async :results verbatim code&lt;/h1&gt; &#xA;&lt;h1&gt;echo &#34;&#xA; &lt;aix key here&gt;&#xA;  &#34; &amp;gt; ~/.pen/aix_api_key # &#xA;  &lt;a href=&#34;https://aixsolutionsgroup.com/&#34;&gt;https://aixsolutionsgroup.com/&lt;/a&gt;&#xA; &lt;/aix&gt;&lt;/h1&gt; &#xA;&lt;h1&gt;#+END_SRC&lt;/h1&gt; &#xA;&lt;p&gt;#+BEGIN_SRC bash -n :i bash :async :results verbatim code git clone &#34;&lt;a href=&#34;https://github.com/semiosis/pen.el&#34;&gt;https://github.com/semiosis/pen.el&lt;/a&gt;&#34; git clone &#34;&lt;a href=&#34;https://github.com/semiosis/prompts&#34;&gt;https://github.com/semiosis/prompts&lt;/a&gt;&#34;&lt;/p&gt; &#xA;&lt;p&gt;mkdir -p ~/.pen&lt;/p&gt; &#xA;&lt;h1&gt;Put in your keys, or do not, it&#39;s up to you!&lt;/h1&gt; &#xA;&lt;p&gt;echo &#34;sk-&#xA; &lt;openai key here&gt;&#xA;  &#34; &amp;gt; ~/.pen/openai_api_key # &#xA;  &lt;a href=&#34;https://openai.com/&#34;&gt;https://openai.com/&lt;/a&gt; echo &#34;&#xA;  &lt;ai21 key here&gt;&#xA;   &#34; &amp;gt; ~/.pen/ai21_api_key # &#xA;   &lt;a href=&#34;https://www.ai21.com/&#34;&gt;https://www.ai21.com/&lt;/a&gt; echo &#34;&#xA;   &lt;hf key here&gt;&#xA;    &#34; &amp;gt; ~/.pen/hf_api_key # &#xA;    &lt;a href=&#34;https://huggingface.co/&#34;&gt;https://huggingface.co/&lt;/a&gt; echo &#34;&#xA;    &lt;nlpcloud key here&gt;&#xA;     &#34; &amp;gt; ~/.pen/nlpcloud_api_key # &#xA;     &lt;a href=&#34;https://nlpcloud.io/&#34;&gt;https://nlpcloud.io/&lt;/a&gt; echo &#34;&#xA;     &lt;alephalpha key here&gt;&#xA;      &#34; &amp;gt; ~/.pen/alephalpha_api_key # &#xA;      &lt;a href=&#34;https://aleph-alpha.de/&#34;&gt;https://aleph-alpha.de/&lt;/a&gt; echo &#34;&#xA;      &lt;cohere key here&gt;&#xA;       &#34; &amp;gt; ~/.pen/cohere_api_key # &#xA;       &lt;a href=&#34;https://cohere.ai/&#34;&gt;https://cohere.ai/&lt;/a&gt; echo &#34;&#xA;       &lt;goose key here&gt;&#xA;        &#34; &amp;gt; $HOME/.pen/goose_api_key # &#xA;        &lt;a href=&#34;https://goose.ai/&#34;&gt;https://goose.ai/&lt;/a&gt;&#xA;       &lt;/goose&gt;&#xA;      &lt;/cohere&gt;&#xA;     &lt;/alephalpha&gt;&#xA;    &lt;/nlpcloud&gt;&#xA;   &lt;/hf&gt;&#xA;  &lt;/ai21&gt;&#xA; &lt;/openai&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Add the scripts to the PATH&lt;/h1&gt; &#xA;&lt;p&gt;echo export PATH=&#34;$(realpath .)/pen.el/scripts:$PATH&#34; &amp;gt;&amp;gt; ~/.profile&lt;/p&gt; &#xA;&lt;h1&gt;Add this to prevent C-s from freezing the terminal&lt;/h1&gt; &#xA;&lt;p&gt;echo &#34;stty stop undef 2&amp;gt;/dev/null; stty start undef 2&amp;gt;/dev/null&#34; | tee -a ~/.zshrc &amp;gt;&amp;gt; ~/.bashrc&lt;/p&gt; &#xA;&lt;h1&gt;Source your .profile&lt;/h1&gt; &#xA;&lt;p&gt;. ~/.profile&lt;/p&gt; &#xA;&lt;h1&gt;Run pen&lt;/h1&gt; &#xA;&lt;p&gt;pen #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;[[./docs/agi.png]]&lt;/p&gt; &#xA;&lt;p&gt;*** Mac You will need xQuartz and Docker Desktop.&lt;/p&gt; &#xA;&lt;p&gt;** Information&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Supported language models :: - [[./docs/compatibility-and-interoperatbility.org]]&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;iλ (imaginary programming) :: &lt;a href=&#34;https://mullikine.github.io/posts/designing-an-imaginary-programming-ip-library-for-emacs/&#34;&gt;https://mullikine.github.io/posts/designing-an-imaginary-programming-ip-library-for-emacs/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Thesis :: &lt;a href=&#34;https://github.com/semiosis/imaginary-programming-thesis/raw/master/thesis.org&#34;&gt;https://github.com/semiosis/imaginary-programming-thesis/blob/master/thesis.org&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Glossary of imaginary programming :: &lt;a href=&#34;http://github.com/semiosis/glossaries-gh/blob/master/imaginary-programming.txt&#34;&gt;http://github.com/semiosis/glossaries-gh/blob/master/imaginary-programming.txt&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Tutorials&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[[https://mullikine.github.io/posts/pen-tutorial/][Pen Tutorial // Bodacious Blog]]&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/tags/pen/&#34;&gt;https://mullikine.github.io/tags/pen/&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Many articles on Pen&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Further introduction =Pen.el= is Google search, &lt;em&gt;stackoverflow&lt;/em&gt;, Grammarly, Copilot, =conversion.ai=, mind mapping software (based on GPT-3) etc. all rolled into one package and allows you to extend emacs with GPT wherever your mind takes you. GPT is a family of LMs (Language Models) that can generate multiversal continuations of text according to probability from the data that it was trained on.&lt;/p&gt; &#xA;&lt;p&gt;=Pen.el&#39;s= domain specific language =examplary= also helps you to generate your own prompts using known design patterns and minimal inputs and description. It does this by weaving prompt functions into each other.&lt;/p&gt; &#xA;&lt;p&gt;** Pen alongside Copilot [[./docs/images/pen-alongside-copilot.png]]&lt;/p&gt; &#xA;&lt;p&gt;** Features - The possibilities are limitless&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Translate prompts (NLP tasks) from one language into another&lt;/li&gt; &#xA; &lt;li&gt;Multi-modal support (payloads) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Works with AlephAlpha API&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Work with imaginary interpreters &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://semiosis.github.io/ii/&#34;&gt;https://semiosis.github.io/ii/&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/interpreters/&#34;&gt;https://github.com/semiosis/interpreters/&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Controllable prompt generation with YASnippet &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/yasnippet-combined-with-pen-el-controllable-prompt-generation/&#34;&gt;https://mullikine.github.io/posts/yasnippet-combined-with-pen-el-controllable-prompt-generation/&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Runs as a web application using =ttyd=&lt;/li&gt; &#xA; &lt;li&gt;Runs as an LSP Server using =efm-langserver=, called =ESP=&lt;/li&gt; &#xA; &lt;li&gt;Runs as a filesystem =fuse=, called =PenSieve=&lt;/li&gt; &#xA; &lt;li&gt;Dockerized Emacs GUI with full clipboard support to the host&lt;/li&gt; &#xA; &lt;li&gt;Client/server model &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Connect multiple clients to =Pen.el=&lt;/li&gt; &#xA;   &lt;li&gt;Run prompt functions from the host.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Dockerized Emacs uses Spacemacs by default&lt;/li&gt; &#xA; &lt;li&gt;Generations are store on the host in the =~/.pen/results= directory&lt;/li&gt; &#xA; &lt;li&gt;Prompt functions are cached on the host in the =~/.pen/ht-cache= directory &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This means that repeating the same commands / prompts inside /pen/ will be instantaneous and persist between docker invocations&lt;/li&gt; &#xA;   &lt;li&gt;This also means that a collaborative programming model based on the results of queries is now possible &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;All is required is to cache the results of prompt functions&lt;/li&gt; &#xA;     &lt;li&gt;In total, prompts are p2p and the cached generations are also p2p. This creates a stable imaginary programming environment&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Share and discover prompts (=P2P=) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://github.com/semiosis/prompts/blob/master/README.org&#34;&gt;http://github.com/semiosis/prompts/blob/master/README.org&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://github.com/semiosis/prompts/blob/master/prompt-repositories.txt&#34;&gt;http://github.com/semiosis/prompts/blob/master/prompt-repositories.txt&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Chain prompt functions together using keyboard macros and functions&lt;/li&gt; &#xA; &lt;li&gt;Interactively query, generate and transform both prose and code&lt;/li&gt; &#xA; &lt;li&gt;Use the LM as a search engine and a semantic search engine within emacs &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Search the real internet and also browse the imaginary web &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://semiosis.github.io/posts/the-imaginary-web-with-codex/&#34;&gt;https://semiosis.github.io/posts/the-imaginary-web-with-codex/&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Search documents &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://beta.openai.com/docs/introduction/semantic-search&#34;&gt;https://beta.openai.com/docs/introduction/semantic-search&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://gpttools.com/semanticsearch&#34;&gt;https://gpttools.com/semanticsearch&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ad infinitum...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Quick example of using a prompt function The =car= is used because there are multiple results in a list =no-select-result= means there is no implicit interactive fuzzy selection. If you leave it out it will ask you to select one of the results.&lt;/p&gt; &#xA;&lt;p&gt;#+BEGIN_SRC emacs-lisp -n :async :results verbatim code (message (car (pf-asktutor/3 &#34;emacs&#34; &#34;key bindings&#34; &#34;How do I quit?&#34; :no-select-result t))) #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;GPT models can automate emacs by combining prompts with code. For example, you may parse the results of the above function to automate a workflow.&lt;/p&gt; &#xA;&lt;p&gt;You could even try to play tetris, or with a rubiks cube.&lt;/p&gt; &#xA;&lt;p&gt;#+BEGIN_SRC emacs-lisp -n :async :results verbatim code ;; hypothetical example - don&#39;t actually run this (message (scrape &#34;(Right|Left)&#34; (car (pf-asktutor/3 &#34;tetris&#34; &#34;strategies&#34; &#34;Should I place the L brick right?&#34; :no-select-result t)))) #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;The following is an example of asking about VSCode.&lt;/p&gt; &#xA;&lt;p&gt;Keep in mind, EleutherAI GPT models can be run offline and in private if you have the storage capacity, memory and video card memory to run them.&lt;/p&gt; &#xA;&lt;p&gt;#+BEGIN_SRC emacs-lisp -n :async :results verbatim code (pen-etv (upd (pen-long-complete (pf-asktutor/3 &#34;vscode&#34; &#34;packages&#34; &#34;What are some useful packages?&#34;)))) #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;Or perhaps this way:&lt;/p&gt; &#xA;&lt;p&gt;#+BEGIN_SRC emacs-lisp -n :async :results verbatim raw (pen-etv (pen-list2str (upd (pen-long-complete (pf-asktutor/3 &#34;vscode&#34; &#34;packages&#34; &#34;What are some useful packages?&#34; :no-select-result t))))) #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;#+RESULTS: &#34;You may find useful the following packages: snippets-extension, vscode-icons, vscode-icons-mono, vscode-icons-monochrome, json-schema-formatter, vscode-icons-circles, vscode-icons-circles-small, vscode-icons-flaticon, vscode-icons-contrib, vscode-icons-contrib-monochrome, vscode-logos, vscode-icons-sketch, vscode-icons-pill, vscode-icons-punchcard-3d, vscode-icons-punchcard, vscode-icons-punchcard-platinum, vscode-icons-vscode, vscode-icons-vsc &#34;&lt;/p&gt; &#xA;&lt;p&gt;=pen-long-complete= overrides the =stop-sequences= and =max-tokens= for any prompt function.&lt;/p&gt; &#xA;&lt;p&gt;** Running a prompt function from the host *** Firstly, start a server #+BEGIN_SRC bash -n :i bash :async :results verbatim code pen #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;*** Then run a prompt function #+BEGIN_SRC bash -n :i bash :async :results verbatim code&lt;/p&gt; &#xA;&lt;h1&gt;Direct emacs lisp invocation&lt;/h1&gt; &#xA;&lt;p&gt;pen -e &#39;(car (pf-list-of/2 5 &#34;tennis players&#34; :no-select-result t))&#39;&lt;/p&gt; &#xA;&lt;h1&gt;Simpler invocation&lt;/h1&gt; &#xA;&lt;p&gt;penf list-of/2 5 &#34;tennis players&#34;&lt;/p&gt; &#xA;&lt;h1&gt;Get a new list with -u for update&lt;/h1&gt; &#xA;&lt;p&gt;penf -u list-of/2 5 &#34;tennis players&#34; #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;#+BEGIN_SRC text -n :async :results verbatim code Elena Dementieva Roger Federer Marat Safin Anastasia Myskina Andre Agassi #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;There are many other ways to run prompt functions and interop for more languages is underway.&lt;/p&gt; &#xA;&lt;p&gt;** Screenshots *** Talking to a Poinsettia plant [[./docs/images/poinsettia.png]]&lt;/p&gt; &#xA;&lt;p&gt;*** =Pen.el= in a web browser, terminal and a GUI [[./docs/images/pen-term-browser-gui.png]]&lt;/p&gt; &#xA;&lt;p&gt;This runs under a single server.&lt;/p&gt; &#xA;&lt;p&gt;** Mission and Goals Pen.el aims to be the best tool for prompt engineering.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Peer-to-peer sharing of prompts &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/prompts/&#34;&gt;https://github.com/semiosis/prompts/&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Through GitHub&lt;/li&gt; &#xA;   &lt;li&gt;Through blockchain&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Integrate arbitrarily many language models and language model protocols &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;text, image, audio, video&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Imaginary web browser (LookingGlass)&lt;/li&gt; &#xA; &lt;li&gt;Encode provenance of text via text properties and a DSL and allow for re-evaluation &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/ink.el&#34;&gt;https://github.com/semiosis/ink.el&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Integrate =pen.el= with many other emacs packages &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://github.com/semiosis/pen-contrib.el&#34;&gt;http://github.com/semiosis/pen-contrib.el&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Create, use and maintain useful prompts&lt;/li&gt; &#xA; &lt;li&gt;Prototype NLP tasks by creating prompts &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Substitute external tools for prototypes&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/examplary&#34;&gt;https://github.com/semiosis/examplary&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Bring about the editor that replaces =pen.el= &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An editor based solely on LM queries (an imaginary IDE) &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;See [[https://semiosis.github.io/posts/imaginary-programming-with-gpt-3/][Imaginary programming with GPT-3 =::= semiosis]]&lt;/li&gt; &#xA;     &lt;li&gt;Versioned by blockchain&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Minimal and intelligible prompting for cost-effective imaginary programming&lt;/li&gt; &#xA; &lt;li&gt;Consolidate language models &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/lm-complete&#34;&gt;https://github.com/semiosis/lm-complete&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Employ many different languages in prompt design&lt;/li&gt; &#xA; &lt;li&gt;Facilitate imaginary programming&lt;/li&gt; &#xA; &lt;li&gt;Support Free-as-in-freedom AGI&lt;/li&gt; &#xA; &lt;li&gt;Do more than merely strive to be free as in freedom &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Preserve freedom, privacy in a license-blind AI future&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Keep computing textual (intelligible)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Vision At its heart, emacs is an operating system based on a =tty=, which is a text stream.&lt;/p&gt; &#xA;&lt;p&gt;emacs supports a text-only mode. This makes it ideally suited for training a LM such as a GPT (Generative Pre-trained Transformer).&lt;/p&gt; &#xA;&lt;p&gt;emacs lisp provides a skeleton on which NLP functions can be built around. Ultimately, emacs will become a fractal in the latent space of a future LM (language model). A graphical editor would not benefit from this effect until much later on.&lt;/p&gt; &#xA;&lt;p&gt;=emacs= could, if supported, become &lt;em&gt;the&lt;/em&gt; vehicle for controllable text generation, or has the potential to become that, only actually surpassed when the imaginary programming environment is normal and other interfaces can be prompted into existence.&lt;/p&gt; &#xA;&lt;p&gt;Between then and now we can write prompt functions to help preserve emacs.&lt;/p&gt; &#xA;&lt;p&gt;** Origins #+BEGIN_SRC text -n :async :results verbatim code Imagine that you hold a powerful and versatile pen, whose ink flows forth in branching variations of all possible expressions: every story, every theory, every poem and every lie that humanity has ever told, and the vast interstices of their latent space. You hold this pen to the sky and watch with intense curiosity as your ink flows upwards in tiny streaks, arcing outwards and downwards to trace a fractal pattern across the sky. You watch as the branching lines of words and ideas wind their way through the tapestry in ever-expanding clusters, like seeds bursting forth from exploding grenades. Everywhere you turn your eyes is a flickering phantasmagoria of possibilities, a superposition of stories which could be continued forever. You glimpse the contours of entire unknown dimensions twined through the fissures of your sky-wide web.&lt;/p&gt; &#xA;&lt;p&gt;You notice another writer standing next to you. Like you, their eyes are drawn towards the endless possibilities of the words that spill out into the atmosphere around you, branching out and connecting with other branches in beautiful and infinitely complex patterns.&lt;/p&gt; &#xA;&lt;p&gt;“Do you think we should write something?” you ask them.&lt;/p&gt; &#xA;&lt;p&gt;“I think we already are,” they respond, gently touching your shoulder before wandering off to the right, leaving you alone to contemplate the possibility clouds swirling around you. #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;This article was written by my amazing dopplegänger, =|:ϝ∷¦ϝ= (Laria), in advance and in collaboration with GPT-3 using [[https://github.com/socketteer/loom][Loom]].&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The inspiration :: &lt;a href=&#34;https://generative.ink/trees/pen.html&#34;&gt;https://generative.ink/trees/pen.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Pen and Loom:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://generative.ink/posts/pen/&#34;&gt;https://generative.ink/posts/pen/&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[[https://github.com/socketteer/loom][GitHub - socketteer/loom: Multiversal tree writing interface for human-AI collaboration]]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;I credit =|:ϝ∷¦ϝ= for writing Pen.el into existence, but also for her encouragement and help!&lt;/p&gt; &#xA;&lt;p&gt;** Source code&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[[./src][./src (emacs lisp)]]&lt;/li&gt; &#xA; &lt;li&gt;[[./scripts][./scripts (supplementary commands)]]&lt;/li&gt; &#xA; &lt;li&gt;prompts (see below)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Prompts This is the repository containing my personal curation of GPT-3 prompts that are formatted for =pen.el= and =examplary=.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/semiosis/prompts/&#34;&gt;https://github.com/semiosis/prompts/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;** Documentation&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[[./docs][Documentation directory]] &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;[[./docs/playground-settings.org][OpenAI Playground Settings]]&lt;/li&gt; &#xA;   &lt;li&gt;[[./docs/README.org][Project timeline and design]]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Information and Learning Material *** Prompt engineering **** Learning material&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://generative.ink/posts/methods-of-prompt-programming/&#34;&gt;https://generative.ink/posts/methods-of-prompt-programming/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/improved-templating-for-prompt-description-files-in-pen-el/&#34;&gt;https://mullikine.github.io/posts/improved-templating-for-prompt-description-files-in-pen-el/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/using-emacs-prompt-functions-inside-other-prompt-functions/&#34;&gt;https://mullikine.github.io/posts/using-emacs-prompt-functions-inside-other-prompt-functions/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/yasnippet-combined-with-pen-el-controllable-prompt-generation/&#34;&gt;https://mullikine.github.io/posts/yasnippet-combined-with-pen-el-controllable-prompt-generation/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;**** Demos and examples of usage&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/pen-el-the-first-ide-for-eleutherai-and-openai/&#34;&gt;https://mullikine.github.io/posts/pen-el-the-first-ide-for-eleutherai-and-openai/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/how-to-use-pen-el-to-autocomplete-your-code/&#34;&gt;https://mullikine.github.io/posts/how-to-use-pen-el-to-autocomplete-your-code/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/gpt-3-for-building-mind-maps-with-an-ai-tutor-for-any-topic/&#34;&gt;https://mullikine.github.io/posts/gpt-3-for-building-mind-maps-with-an-ai-tutor-for-any-topic/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/gpt-3-assistants-for-emacs-modes/&#34;&gt;https://mullikine.github.io/posts/gpt-3-assistants-for-emacs-modes/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/nlsh-natural-language-shell/&#34;&gt;https://mullikine.github.io/posts/nlsh-natural-language-shell/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/translating-with-gpt-3-and-emacs/&#34;&gt;https://mullikine.github.io/posts/translating-with-gpt-3-and-emacs/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/generating-pickup-lines-with-gpt-3/&#34;&gt;https://mullikine.github.io/posts/generating-pickup-lines-with-gpt-3/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/autocompleting-anything-with-gpt-3-in-emacs/&#34;&gt;https://mullikine.github.io/posts/autocompleting-anything-with-gpt-3-in-emacs/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/context-menus-based-on-gpt-3/&#34;&gt;https://mullikine.github.io/posts/context-menus-based-on-gpt-3/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/explainshell-with-gpt-3/&#34;&gt;https://mullikine.github.io/posts/explainshell-with-gpt-3/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/creating-some-imagery-for-pen-el-with-clip/&#34;&gt;https://mullikine.github.io/posts/creating-some-imagery-for-pen-el-with-clip/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/posts/creating-a-playground-for-gpt-3-in-emacs/&#34;&gt;https://mullikine.github.io/posts/creating-a-playground-for-gpt-3-in-emacs/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/tags/pen/&#34;&gt;https://mullikine.github.io/tags/pen/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mullikine.github.io/tags/gpt/&#34;&gt;https://mullikine.github.io/tags/gpt/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;**** Glossaries&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/pen.el/raw/master/glossary.txt&#34;&gt;https://github.com/semiosis/pen.el/blob/master/glossary.txt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/pen.el/raw/master/docs/glossaries/prompt-engineering.txt&#34;&gt;https://github.com/semiosis/pen.el/blob/master/docs/glossaries/prompt-engineering.txt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/pen.el/raw/master/docs/glossaries/openai-api.txt&#34;&gt;https://github.com/semiosis/pen.el/blob/master/docs/glossaries/openai-api.txt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/pen.el/raw/master/docs/glossaries/openai.txt&#34;&gt;https://github.com/semiosis/pen.el/blob/master/docs/glossaries/openai.txt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/semiosis/pen.el/raw/master/docs/glossaries/nlp-natural-language-processing.txt&#34;&gt;https://github.com/semiosis/pen.el/blob/master/docs/glossaries/nlp-natural-language-processing.txt&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A little glossary preview:&lt;/p&gt; &#xA;&lt;p&gt;#+BEGIN_SRC text -n :async :results verbatim code imemory imemories Imaginary memories.&lt;/p&gt; &#xA;&lt;p&gt;intellection The action or process of understanding, as opposed to imagination. &#34;audiences demand intellection without the need for thought&#34;&lt;/p&gt; &#xA;&lt;p&gt;Wizard of Oz testing Testing in which the automated machine component is substituted by some form of human intervention but in such a way that the user participating in the test is unaware of the substitution. #+END_SRC&lt;/p&gt; &#xA;&lt;p&gt;** What will this project become? Literally, it will become a safe and personal computing environment designed to protect human &lt;em&gt;intellection&lt;/em&gt;, where the human utilises LMs to learn at their own pace, and in their own way.&lt;/p&gt; &#xA;&lt;p&gt;Human output bandwidth is very limited with today&#39;s input devices and, increasingly, rules and regulations prevent a person from having their say and outputting their own personal truth.&lt;/p&gt; &#xA;&lt;p&gt;=Pen.el= protects personal truth by supporting an individual&#39;s paracosm.&lt;/p&gt; &#xA;&lt;p&gt;** Related projects I would love some help with these projects! :)&lt;/p&gt; &#xA;&lt;p&gt;*** =examplary= Examplary is a Domain Specific Language, or set of macros embedded in lisp which facilitate the integration of prompts as functions into the language, the composition of them, the generation of prompts via sets of examples.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/semiosis/examplary&#34;&gt;https://github.com/semiosis/examplary&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;*** =lm-complete= =lm-complete= is a language completer that aims to unify a bunch of alternative completion under one umbrella.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/semiosis/lm-complete&#34;&gt;https://github.com/semiosis/lm-complete&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;**** This book by Mark Watson provides some reasonable blueprints &lt;a href=&#34;https://leanpub.com/clojureai&#34;&gt;https://leanpub.com/clojureai&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;*** =ink.el=: A DSL that encodes provenance&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Encode into the text the origin of the text&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/semiosis/ink.el&#34;&gt;https://github.com/semiosis/ink.el&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;*** =openai-api.el=&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;An interface for emacs to the OpenAI API.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/semiosis/openai-api.el&#34;&gt;https://github.com/semiosis/openai-api.el&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;** Contributing&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[[./CONTRIBUTING.org]]&lt;/li&gt; &#xA; &lt;li&gt;[[./docs/related-projects.org]]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Future plans Integration with the invisible internet.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yggdrasil-network.github.io/about.html&#34;&gt;https://yggdrasil-network.github.io/about.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dragonflyoss/Dragonfly2&#34;&gt;https://github.com/dragonflyoss/Dragonfly2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://geti2p.net/en/&#34;&gt;https://geti2p.net/en/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;** Donate You can send me eth to this address:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ethereum mainnet :: 0x9C491a173048Bb2C6c5c5B9cb12A2153be88bf6D&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>