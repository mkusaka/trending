<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Emacs Lisp Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-03T01:33:05Z</updated>
  <subtitle>Daily Trending of Emacs Lisp in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>emacs-openai/openai</title>
    <updated>2023-04-03T01:33:05Z</updated>
    <id>tag:github.com,2023-04-03:/emacs-openai/openai</id>
    <link href="https://github.com/emacs-openai/openai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Elisp library for the OpenAI API&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://www.gnu.org/licenses/gpl-3.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-GPL%20v3-blue.svg?sanitize=true&#34; alt=&#34;License: GPL v3&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://jcs-emacs.github.io/jcs-elpa/#/openai&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jcs-emacs/badges/master/elpa/v/openai.svg?sanitize=true&#34; alt=&#34;JCS-ELPA&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;OpenAI.el&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Elisp library for the OpenAI API&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/emacs-openai/openai/actions/workflows/test.yml&#34;&gt;&lt;img src=&#34;https://github.com/emacs-openai/openai/actions/workflows/test.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The OpenAI Elisp library provides convenient access to the OpenAI API from applications written in the Elips language.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;P.S. This package is expected to be used as a library, so there are only a few interactable commands you can use, and those are mostly examples.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📚 Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://beta.openai.com/docs/introduction&#34;&gt;OpenAI API docs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- markdown-toc start - Don&#39;t edit this section. Run M-x markdown-toc-refresh-toc --&gt; &#xA;&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#%F0%9F%94%A8-usage&#34;&gt;🔨 Usage&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#%F0%9F%94%B0-the-simplest-example&#34;&gt;🔰 The simplest example&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#%F0%9F%93%A8-sending-request&#34;&gt;📨 Sending Request&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#%F0%9F%93%A2-api-functions&#34;&gt;📢 API functions&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#%F0%9F%94%8D-parameters&#34;&gt;🔍 Parameters&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#%F0%9F%96%A5-setting-model&#34;&gt;🖥 Setting Model&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#%F0%9F%9B%91-debugging&#34;&gt;🛑 Debugging&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#%F0%9F%93%82-example-projects&#34;&gt;📂 Example projects&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#%F0%9F%94%97-references&#34;&gt;🔗 References&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/emacs-openai/openai/master/#contribute&#34;&gt;Contribute&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- markdown-toc end --&gt; &#xA;&lt;h2&gt;🔨 Usage&lt;/h2&gt; &#xA;&lt;p&gt;You will need to set up your API key before you can use this library.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(setq openai-key &#34;[YOUR API KEY]&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For requests that need your user identifier,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(setq openai-user &#34;[YOUR USER UID]&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;💡 Tip&lt;/p&gt; &#xA; &lt;p&gt;The two variables &lt;code&gt;openai-key&lt;/code&gt; and &lt;code&gt;openai-user&lt;/code&gt; are the default values for sending requests! However, you can still overwrite the value by passing the keywords &lt;code&gt;:key&lt;/code&gt; and &lt;code&gt;:user&lt;/code&gt;!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;🔰 The simplest example&lt;/h3&gt; &#xA;&lt;p&gt;Here is the simplest example that teaches you how to use this library. This is a function with a &lt;code&gt;query&lt;/code&gt; and a callback function.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(openai-completion &#34;How are you?&#34;&#xA;                   (lambda (data)&#xA;                     (message &#34;%s&#34; data)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;📨 Sending Request&lt;/h3&gt; &#xA;&lt;p&gt;All arguments are exposed in the argument list, so you can send any request in any way you want.&lt;/p&gt; &#xA;&lt;p&gt;For example, the request function &lt;code&gt;openai-completion&lt;/code&gt; accepts argument &lt;code&gt;max-tokens&lt;/code&gt;. By seeing OpenAI&#39;s references page:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;code&gt;max_tokens&lt;/code&gt; integer Optional Defaults to 16&lt;/p&gt; &#xA; &lt;p&gt;The maximum number of tokens to generate in the completion.&lt;/p&gt; &#xA; &lt;p&gt;The token count of your prompt plus &lt;code&gt;max_tokens&lt;/code&gt; cannot exceed the model&#39;s context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096).&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(openai-completion ...&#xA;                   ...&#xA;                   :max-tokens 4069)  ; max out tokens!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;📢 API functions&lt;/h3&gt; &#xA;&lt;p&gt;The API functions are followed by this pattern:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[PACKAGE NAME]-[API TYPE]-[REQUEST NAME]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(openai-file-list ...)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;openai&lt;/code&gt; - is the package name&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;file&lt;/code&gt; - is the api type, see &lt;a href=&#34;https://platform.openai.com/docs/api-reference/introduction&#34;&gt;OpenAI API reference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;list&lt;/code&gt; - is the request name&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;🔍 Parameters&lt;/h4&gt; &#xA;&lt;p&gt;The function&#39;s parameters are followed in this order:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;required - variables are required for this type of request&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;callback&lt;/code&gt; - execution after the request is made&lt;/li&gt; &#xA; &lt;li&gt;optional - other variables that are not required, but will affect the final output&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(openai-completion &#34;How are you?&#34;          ; required&#xA;                   (lambda (data)          ; callback&#xA;                     ...)&#xA;                   :max-tokens 4069)       ; optional&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;🖥 Setting Model&lt;/h3&gt; &#xA;&lt;p&gt;Every type of request has a default &lt;code&gt;model&lt;/code&gt;, and we hope this benefits the users to not worry about what model to use for their request! However, if you want to use other models, you can use the keyword &lt;code&gt;:model&lt;/code&gt; to replace them!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(openai-completion ...&#xA;                   ... &#xA;                   :model &#34;text-davinci-003&#34;)  ; replace the default model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;🛑 Debugging&lt;/h2&gt; &#xA;&lt;p&gt;While playing through this library, you might see this error quite often.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;400 - Bad request.  Please check error message and your parameters&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Try set the variable &lt;code&gt;openai--show-log&lt;/code&gt; to &lt;code&gt;t&lt;/code&gt;, it will show more error messages.&lt;/p&gt; &#xA;&lt;h2&gt;📂 Example projects&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/emacs-openai/codegpt&#34;&gt;codegpt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/emacs-openai/chatgpt&#34;&gt;chatgpt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/emacs-openai/dall-e&#34;&gt;dall-e&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🔗 References&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=timkmecl.codegpt3&#34;&gt;CodeGPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/junjizhi/aide.el&#34;&gt;aide.el&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/joshcho/ChatGPT.el&#34;&gt;ChatGPT.el&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://makeapullrequest.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bbatsov/emacs-lisp-style-guide&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/elisp-style%20guide-purple&#34; alt=&#34;Elisp styleguide&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.paypal.me/jcs090218&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/paypal-donate-1?logo=paypal&amp;amp;color=blue&#34; alt=&#34;Donate on paypal&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.patreon.com/jcs090218&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/patreon-become%20a%20patron-orange.svg?logo=patreon&#34; alt=&#34;Become a patron&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you would like to contribute to this project, you may either clone and make pull requests to this repository. Or you can clone the project and establish your own branch of this tool. Any methods are welcome!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>iwahbe/chat.el</title>
    <updated>2023-04-03T01:33:05Z</updated>
    <id>tag:github.com,2023-04-03:/iwahbe/chat.el</id>
    <link href="https://github.com/iwahbe/chat.el" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An Emacs facade for ChatGPT&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;chat.el&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iwahbe/chat.el/main/gifs/chat-demo.gif&#34; alt=&#34;Chat Demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;chat.el&lt;/code&gt; is an pure Emacs package for interacting with OpenAI&#39;s ChatGPT models such as GPT3. It interacts directly with the OpenAI API vie Emac&#39;s built-in &lt;code&gt;url&lt;/code&gt; package.&lt;/p&gt; &#xA;&lt;p&gt;It offers several helpful features that enable users to perform, such as writing this README for me. Functionality can be broken down into two basic categories.&lt;/p&gt; &#xA;&lt;h3&gt;Transient Queries&lt;/h3&gt; &#xA;&lt;p&gt;The package offers different ways of querying the ChatGPT model based on user input and region selection, which include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;chat-query-user&lt;/code&gt;: Query ChatGPT&#39;s response to a user-specified input, either displaying or inserting it.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;chat-query-region&lt;/code&gt;: Sends the active region to ChatGPT for responses relevant to the content.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;chat-query-dwim&lt;/code&gt;: A prompt for querying ChatGPT prompts users to either specify a region of text or ask for machine learning recommendations based on a prompt.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Interactive ChatGPT conversation&lt;/h3&gt; &#xA;&lt;p&gt;A &lt;code&gt;chat-mode&lt;/code&gt; allows users to communicate with the ChatGPT model in a &#34;conversation-like&#34; format with prompts. To start an interactive session, run &lt;code&gt;chat&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The package also supports &lt;code&gt;custom.el&lt;/code&gt;, facilitating configuration of API keys and user-specific settings.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;In the configuration section, &lt;code&gt;chat-api-env-key&lt;/code&gt; set the environmental variable used to look up an API key if not specified, while &lt;code&gt;chat-api-key&lt;/code&gt; sets the OpenAI API key directly.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;chat-max-tokens&lt;/code&gt; sets the maximum number of tokens for ChatGPT to return for a single request.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;chat-system-prompt&lt;/code&gt; sets the system prompt given to all ChatGPT requests.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;chat-user-prompt&lt;/code&gt; sets the text prompt for by the user when in &lt;code&gt;chat-mode&lt;/code&gt;. Defaults to &lt;code&gt;&#34;You &amp;gt; &#34;&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;chat-bot-prompt&lt;/code&gt; sets the prompt faced by the AI in &lt;code&gt;chat-mode&lt;/code&gt;. Defaults to &lt;code&gt;&#34;Bot &amp;gt; &#34;&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;chat-tempature&lt;/code&gt; sets the &lt;code&gt;tempature&lt;/code&gt; parameter for requests. Defaults to &lt;code&gt;nil&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;chat-top-p&lt;/code&gt; sets the &lt;code&gt;top_p&lt;/code&gt; parameter for requests. Defaults to &lt;code&gt;nil&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To install &lt;code&gt;chat.el&lt;/code&gt;, follow these simple steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download &#34;chat.el&#34; file to your machine.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In your Emacs configuration file, add this line:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-emacs-lisp&#34;&gt;         (add-to-list &#39;load-path &#34;/path/to/chat.el/directory&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Evaluating &lt;code&gt;(require &#39;chat)&lt;/code&gt; in emacs will load the package.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you want to give a custom configuration, add your configuration to your emacs configuration file.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;To configure this package, customize &lt;code&gt;chat-mode&lt;/code&gt; to control the Chat GPT interaction behavior.&lt;/p&gt;</summary>
  </entry>
</feed>