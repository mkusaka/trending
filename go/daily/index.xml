<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-29T01:27:56Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>talostrading/sonic</title>
    <updated>2024-04-29T01:27:56Z</updated>
    <id>tag:github.com,2024-04-29:/talostrading/sonic</id>
    <link href="https://github.com/talostrading/sonic" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Sonic is a Go library for network and I/O programming that provides developers with a consistent asynchronous model, with a focus on achieving the lowest possible latency and jitter in Go.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;work-in-progress - expect breaking changes until v1.0.0&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Sonic&lt;/h1&gt; &#xA;&lt;p&gt;Sonic is a Go library for network and I/O programming that provides developers with a consistent asynchronous model, with a focus on achieving the lowest possible latency and jitter in Go. Sonic aims to make it easy to write network protocols (websocket, http2, custom exchange binary) on a series of bytestreams and then make use of those bytestreams through multiple connections running in a &lt;strong&gt;single-thread and goroutine&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Sonic is an alternative to the &lt;code&gt;net&lt;/code&gt; package. It removes the need to use multiple goroutines to handle multiple connections and reads/writes in the same process. By doing that, a single goroutine and thread is used to read/write from multiple connections which brings several benefits:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;No need to use synchronization primitives (channels, mutexes, etc.) as multiple connections can be handled in the same goroutine.&lt;/li&gt; &#xA; &lt;li&gt;It removes the need for the Go scheduler to do any work which could slow down the program.&lt;/li&gt; &#xA; &lt;li&gt;It allows latency-sensitive programs to run in a hot-loop pinned to a thread on an isolated core in order to achieve low latency and jitter.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Sonic currently supports only Unix-based systems (BSD, macOS, Linux).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main() {&#xA;    // Create an IO object which can execute asynchronous operations on the&#xA;    // current goroutine.&#xA;    ioc := sonic.MustIO()&#xA;    defer ioc.Close()&#xA;&#xA;    // Create 10 connections. Each connection reads a message into it&#39;s&#xA;    // buffer and then closes.&#xA;    for i := 0; i &amp;lt; 10; i++ {&#xA;        conn, _ := sonic.Dial(ioc, &#34;tcp&#34;, &#34;localhost:8080&#34;)&#xA;&#x9;&#x9;&#xA;        b := make([]byte, 128)&#xA;        conn.AsyncRead(b, func(err error, n int) {&#xA;            if err != nil {&#xA;                fmt.Printf(&#34;could not read from %d err=%v\n&#34;, i, err)&#xA;            } else {&#xA;                b = b[:n]&#xA;                fmt.Println(&#34;got=&#34;, string(b))&#xA;                conn.Close()&#xA;            }&#xA;        })&#xA;    }&#xA;&#xA;    // Execute all pending reads scheduled in the for-loop, then exit.&#xA;    ioc.RunPending()&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;code&gt;examples/&lt;/code&gt;. A good starting point is &lt;code&gt;examples/timer&lt;/code&gt;. All examples can be built by calling &lt;code&gt;make&lt;/code&gt; in the root path of sonic. The builds will be put in &lt;code&gt;bin/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;UDP Multicast&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;sonic&lt;/code&gt; offers a full-featured &lt;code&gt;UDP Multicast&lt;/code&gt; peer for both &lt;code&gt;IPv4&lt;/code&gt; and &lt;code&gt;IPv6&lt;/code&gt;. See &lt;code&gt;multicast/peer.go&lt;/code&gt;. This peer can read and write data to a multicast group, join a group with source-IP and network interface filtering, and control its group membership by blocking/unblocking source-IPs at runtime.&lt;/p&gt; &#xA;&lt;p&gt;Moreover, this peer, unlike the &lt;code&gt;websocket&lt;/code&gt; client, does not allocate and copy any data in any of its functions. Additionally, the peer gives the programmer the option to change its read buffer after scheduling a read on it i.e.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var (&#xA;    b1, b2 []byte&#xA;)&#xA;peer.AsyncRead(b1, func(...) { ... }) // schedule an asynchronous read in b1&#xA;// ... some other code here&#xA;peer.SetAsyncReadBuffer(b2) // make the previously scheduled asynchronous read use b2 instead of b1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is very useful when multiple &lt;code&gt;UDP&lt;/code&gt; peers share the same read buffer. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;b := make([]byte, 1024 * 1024)&#xA;&#xA;// We expect packets to be less than 256 bytes. When either peer reads, it calls the updateAndProcessBuffer function.&#xA;peer1.AsyncRead(b[:256], func(...) { updateAndProcessBuffer() })&#xA;peer2.AsyncRead(b[:256], func(...) { updateAndProcessBuffer() })&#xA;&#xA;func updateAndProcessBuffer() {&#xA;    // One of the peers read something. We instruct the peers to read into the next 256 byte chunk of b such that we can&#xA;    // process the previous 256 bytes.&#xA;    peer1.AsyncRead(b[256:512], func(...) { updateAndProcessBuffer() })&#xA;    peer2.AsyncRead(b[256:512], func(...) { updateAndProcessBuffer() })&#xA;&#xA;    go process(b[:256])&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Zero-copy FIFO buffers&lt;/h3&gt; &#xA;&lt;p&gt;We provide two types of FIFO buffers with zero-copy semantics. Regardless of the type, a FIFO buffer is essential when writing protocol encoders/decoders over UDP or TCP with Linux&#39;s socket API to minimize syscalls. For example, say we have a simple protocol where each message has a fixed-size header and a variable-sized payload - the length of the payload is in the header. Say we read data through TCP. We then have two options:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// buffer in which we read; assume header size is 1 byte.&#xA;&#xA;b := make([]byte, 1024)&#xA;&#xA;// option 1: read the header first and then the payload from the network&#xA;conn.Read(b[:1]) // read the header&#xA;payloadSize := int(b[0])&#xA;payload := b[1:payloadSize]&#xA;conn.Read(payload) // read the payload&#xA;// do something with the payload&#xA;&#xA;// option 2: read as much as you can from the network and then parse the bytes&#xA;conn.Read(b)&#xA;i := 0&#xA;while i &amp;lt; len(b) {&#xA;    payloadSize := int(b[i:i+1])&#xA;    if i + 1 + payloadSize &amp;lt;= len(b) {&#xA;        payload := b[i+1:i+1+payloadSize]&#xA;        process(payload)&#xA;    }&#xA;    i += 1 + payloadSize&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;option 1&lt;/code&gt; is not efficient as &lt;code&gt;n&lt;/code&gt; messages need &lt;code&gt;n * 2&lt;/code&gt; syscalls. &lt;code&gt;option 2&lt;/code&gt; is efficient as the number if syscalls is minimized - in the limit, we need just 1 syscall to read &lt;code&gt;n&lt;/code&gt; messages. &lt;code&gt;option 2&lt;/code&gt; however is missing something:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;what if the last read message was incomplete i.e. we read the header with its size, say &lt;code&gt;255&lt;/code&gt;, but only had space to read &lt;code&gt;100&lt;/code&gt; of those bytes into &lt;code&gt;b&lt;/code&gt; as we&#39;re near the end of &lt;code&gt;b&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;to read the rest of the &lt;code&gt;255 - 100 = 155&lt;/code&gt; bytes of the payload, we need to move the read &lt;code&gt;100&lt;/code&gt; bytes to the beginning of &lt;code&gt;b&lt;/code&gt;, overwriting the already processed payloads.&lt;/li&gt; &#xA; &lt;li&gt;in other words, we need FIFO semantics over &lt;code&gt;b&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The naive way of offering FIFO semantics over b would be to simply copy the &lt;code&gt;100&lt;/code&gt; bytes to the beginning of the slice. But that&#39;s a &lt;code&gt;memcpy&lt;/code&gt; that will take a lot of time if the message is relatively big, say over 1KB. That&#39;s not acceptable even though that&#39;s how we do things for websocket (see &lt;code&gt;byte_buffer.go&lt;/code&gt; and &lt;code&gt;codec/websocket/codec.go&lt;/code&gt;). In those cases we offer two types of FIFO semantics over a byte slice, both offering the same API:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Claim(n) []byte&lt;/code&gt; - claim at most n bytes from the underlying &lt;code&gt;[]byte&lt;/code&gt; slice. Callers can now read into the returned slice.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Commit(n) int&lt;/code&gt; - commit at most n previously claimed bytes i.e. queue at most &lt;code&gt;n&lt;/code&gt; bytes&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Consume(n) int&lt;/code&gt; - consume at most n previously committed/queued bytes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Mirrored Buffer&lt;/h4&gt; &#xA;&lt;p&gt;This is a zero-copy FIFO buffer that works for both TCP and UDP protocols. It offers contiguous byte slices in a FIFO manner without care for wrapping. See &lt;code&gt;bytes/mirrored_buffer.go&lt;/code&gt;. The only limitations are that the buffer size must be a multiple of the system&#39;s page size and the system must expose a shared memory filesystem like &lt;code&gt;/dev/shm&lt;/code&gt;. In short, the mirrored buffer provides zero-copy FIFO semantics over a byte slice in the following way:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;it creates the underlying byte slice of size &lt;code&gt;n&lt;/code&gt; (where &lt;code&gt;n&lt;/code&gt; is a multiple of page size) and &lt;strong&gt;maps it twice, contiguously, in the process&#39; virtual address space&lt;/strong&gt; with &lt;code&gt;mmap&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;there are &lt;code&gt;n&lt;/code&gt; physical bytes backing up the underlying byte slice and &lt;code&gt;n * 2&lt;/code&gt; virtual bytes&lt;/li&gt; &#xA; &lt;li&gt;the buffer is mirrored in a sense that reading/writing to the sequence &lt;code&gt;b[n], b[n+1], ..., b[2*n-1]&lt;/code&gt; is permitted and in fact, touches the bytes at &lt;code&gt;b[0], b[1], ..., b[n-1]&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Bip Buffer&lt;/h4&gt; &#xA;&lt;p&gt;This is a zero-copy FIFO buffer meant solely for writing packet-based (UDP) protocols. Refer to the creator&#39;s &lt;a href=&#34;https://www.codeproject.com/Articles/3479/The-Bip-Buffer-The-Circular-Buffer-with-a-Twist&#34;&gt;post&lt;/a&gt; for an explanation of how it works.&lt;/p&gt; &#xA;&lt;h4&gt;What is next&lt;/h4&gt; &#xA;&lt;p&gt;The two buffers above are not yet standardized across sonic. TCP codecs, including &lt;code&gt;websocket&lt;/code&gt;, still use the &lt;code&gt;memcpy&lt;/code&gt; based byte buffer abstraction &lt;code&gt;byte_buffer.go&lt;/code&gt; which is not that performant for large messages. The plan is to port websocket to use the mirrored buffer by &lt;code&gt;v1.0.0&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The Bip Buffer is actively used in Talos UDP-based gateways.&lt;/p&gt; &#xA;&lt;h2&gt;Peculiarities&lt;/h2&gt; &#xA;&lt;h3&gt;Async preemption&lt;/h3&gt; &#xA;&lt;p&gt;If, for some reason, you have a single goroutine that ends up waiting for more than 10ms for something to happen, sonic will crash on Linux due to &lt;code&gt;epoll_wait&lt;/code&gt; being interrupted by the signal SIGURG. This happens because, by default, the Go runtime non-cooperatively preempts goroutines that are idle for more than 10ms. To turn off this behavior, set &lt;code&gt;GODEBUG=asyncpreemptoff=1&lt;/code&gt; before running your binary.&lt;/p&gt; &#xA;&lt;p&gt;This issue has been addressed in &lt;a href=&#34;https://github.com/talostrading/sonic/commit/d59145deb86647460abd9e85eddbdb03f50e2b01&#34;&gt;this&lt;/a&gt; commit.&lt;/p&gt; &#xA;&lt;h3&gt;Credits&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.boost.org/doc/libs/1_75_0/doc/html/boost_asio.html&#34;&gt;boost.asio&lt;/a&gt; - the main inspiration for the sonic API&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/boostorg/beast&#34;&gt;boost.beast&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tokio-rs/mio&#34;&gt;mio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snapview/tungstenite-rs&#34;&gt;tungstenite-rs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://c.tenor.com/OTDlqAguqpEAAAAi/sonic-running.gif&#34;&gt; &lt;/p&gt;</summary>
  </entry>
</feed>