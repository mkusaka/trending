<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-19T01:30:39Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>envoyproxy/ratelimit</title>
    <updated>2024-06-19T01:30:39Z</updated>
    <id>tag:github.com,2024-06-19:/envoyproxy/ratelimit</id>
    <link href="https://github.com/envoyproxy/ratelimit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Go/gRPC service designed to enable generic rate limit scenarios from different types of applications.&lt;/p&gt;&lt;hr&gt;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#docker-image&#34;&gt;Docker Image&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#supported-envoy-apis&#34;&gt;Supported Envoy APIs&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#api-deprecation-history&#34;&gt;API Deprecation History&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#building-and-testing&#34;&gt;Building and Testing&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#docker-compose-setup&#34;&gt;Docker-compose setup&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#full-test-environment---configure-rate-limits-through-files&#34;&gt;Full test environment - Configure rate limits through files&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#full-test-environment---configure-rate-limits-through-an-xds-management-server&#34;&gt;Full test environment - Configure rate limits through an xDS Management Server&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#self-contained-end-to-end-integration-test&#34;&gt;Self-contained end-to-end integration test&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#configuration&#34;&gt;Configuration&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#the-configuration-format&#34;&gt;The configuration format&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#definitions&#34;&gt;Definitions&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#descriptor-list-definition&#34;&gt;Descriptor list definition&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#rate-limit-definition&#34;&gt;Rate limit definition&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#replaces&#34;&gt;Replaces&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#shadowmode&#34;&gt;ShadowMode&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#including-detailed-metrics-for-unspecified-values&#34;&gt;Including detailed metrics for unspecified values&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#examples&#34;&gt;Examples&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example-1&#34;&gt;Example 1&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example-2&#34;&gt;Example 2&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example-3&#34;&gt;Example 3&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example-4&#34;&gt;Example 4&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example-5&#34;&gt;Example 5&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example-6&#34;&gt;Example 6&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example-7&#34;&gt;Example 7&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example-8&#34;&gt;Example 8&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example-9&#34;&gt;Example 9&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#loading-configuration&#34;&gt;Loading Configuration&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#file-based-configuration-loading&#34;&gt;File Based Configuration Loading&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#xds-management-server-based-configuration-loading&#34;&gt;xDS Management Server Based Configuration Loading&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#log-format&#34;&gt;Log Format&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#grpc-keepalive&#34;&gt;GRPC Keepalive&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#health-check&#34;&gt;Health-check&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#health-check-configurations&#34;&gt;Health-check configurations&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#grpc-server&#34;&gt;GRPC server&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#request-fields&#34;&gt;Request Fields&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#grpc-client&#34;&gt;GRPC Client&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#commandline-flags&#34;&gt;Commandline flags&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#global-shadowmode&#34;&gt;Global ShadowMode&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#configuration-1&#34;&gt;Configuration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#statistics&#34;&gt;Statistics&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#statistics-1&#34;&gt;Statistics&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#statistics-options&#34;&gt;Statistics options&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#dogstatsd&#34;&gt;DogStatsD&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#example&#34;&gt;Example&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#continued-example&#34;&gt;Continued example:&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#http-port&#34;&gt;HTTP Port&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#json-endpoint&#34;&gt;/json endpoint&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#debug-port&#34;&gt;Debug Port&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#local-cache&#34;&gt;Local Cache&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#redis&#34;&gt;Redis&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#redis-type&#34;&gt;Redis type&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#pipelining&#34;&gt;Pipelining&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#one-redis-instance&#34;&gt;One Redis Instance&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#two-redis-instances&#34;&gt;Two Redis Instances&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#health-checking-for-redis-active-connection&#34;&gt;Health Checking for Redis Active Connection&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#memcache&#34;&gt;Memcache&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#custom-headers&#34;&gt;Custom headers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#tracing&#34;&gt;Tracing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#mtls&#34;&gt;mTLS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#contact&#34;&gt;Contact&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt; &#xA;&lt;h1&gt;Overview&lt;/h1&gt; &#xA;&lt;p&gt;The rate limit service is a Go/gRPC service designed to enable generic rate limit scenarios from different types of applications. Applications request a rate limit decision based on a domain and a set of descriptors. The service reads the configuration from disk via &lt;a href=&#34;https://github.com/lyft/goruntime&#34;&gt;runtime&lt;/a&gt;, composes a cache key, and talks to the Redis cache. A decision is then returned to the caller.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://securityscorecards.dev/viewer/?uri=github.com/envoyproxy/ratelimit&#34;&gt;&lt;img src=&#34;https://api.securityscorecards.dev/projects/github.com/envoyproxy/ratelimit/badge&#34; alt=&#34;OpenSSF Scorecard&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Docker Image&lt;/h1&gt; &#xA;&lt;p&gt;For every main commit, an image is pushed to &lt;a href=&#34;https://hub.docker.com/r/envoyproxy/ratelimit/tags?page=1&amp;amp;ordering=last_updated&#34;&gt;Dockerhub&lt;/a&gt;. There is currently no versioning (post v1.4.0) and tags are based on commit sha.&lt;/p&gt; &#xA;&lt;h1&gt;Supported Envoy APIs&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/envoyproxy/data-plane-api/raw/master/envoy/service/ratelimit/v3/rls.proto&#34;&gt;v3 rls.proto&lt;/a&gt; is currently supported. Support for &lt;a href=&#34;https://github.com/envoyproxy/data-plane-api/raw/master/envoy/service/ratelimit/v2/rls.proto&#34;&gt;v2 rls proto&lt;/a&gt; is now deprecated.&lt;/p&gt; &#xA;&lt;h2&gt;API Deprecation History&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;v1.0.0&lt;/code&gt; tagged on commit &lt;code&gt;0ded92a2af8261d43096eba4132e45b99a3b8b14&lt;/code&gt;. Ratelimit has been in production use at Lyft for over 2 years.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;v1.1.0&lt;/code&gt; introduces the data-plane-api proto and initiates the deprecation of the legacy &lt;a href=&#34;https://github.com/lyft/ratelimit/raw/0ded92a2af8261d43096eba4132e45b99a3b8b14/proto/ratelimit/ratelimit.proto&#34;&gt;ratelimit.proto&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;e91321b&lt;/code&gt; &lt;a href=&#34;https://github.com/envoyproxy/ratelimit/commit/e91321b10f1ad7691d0348e880bd75d0fca05758&#34;&gt;commit&lt;/a&gt; deleted support for the legacy &lt;a href=&#34;https://github.com/envoyproxy/ratelimit/raw/0ded92a2af8261d43096eba4132e45b99a3b8b14/proto/ratelimit/ratelimit.proto&#34;&gt;ratelimit.proto&lt;/a&gt;. The current version of ratelimit protocol is changed to &lt;a href=&#34;https://github.com/envoyproxy/data-plane-api/raw/master/envoy/service/ratelimit/v3/rls.proto&#34;&gt;v3 rls.proto&lt;/a&gt; while &lt;a href=&#34;https://github.com/envoyproxy/data-plane-api/raw/master/envoy/service/ratelimit/v3/rls.proto&#34;&gt;v2 rls.proto&lt;/a&gt; is still supported as a legacy protocol.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;4bb32826&lt;/code&gt; deleted support for legacy &lt;a href=&#34;https://github.com/envoyproxy/data-plane-api/raw/master/envoy/service/ratelimit/v3/rls.proto&#34;&gt;v2 rls.proto&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Building and Testing&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Install Redis-server.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure go is setup correctly and checkout rate limit service into your go path. More information about installing go &lt;a href=&#34;https://golang.org/doc/install&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In order to run the integration tests using a local Redis server please run two Redis-server instances: one on port &lt;code&gt;6379&lt;/code&gt; and another on port &lt;code&gt;6380&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;redis-server --port 6379 &amp;amp;&#xA;redis-server --port 6380 &amp;amp;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To setup for the first time (only done once):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make bootstrap&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To compile:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make compile&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Ensure you set the correct platform if running OSX host with a linux container e.g.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GOOS=linux make compile&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To compile and run tests:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make tests&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To run the server locally using some sensible default settings you can do this (this will setup the server to read the configuration files from the path you specify):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;USE_STATSD=false LOG_LEVEL=debug REDIS_SOCKET_TYPE=tcp REDIS_URL=localhost:6379 RUNTIME_ROOT=/home/user/src/runtime/data RUNTIME_SUBDIRECTORY=ratelimit RUNTIME_APPDIRECTORY=config&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Docker-compose setup&lt;/h2&gt; &#xA;&lt;p&gt;The docker-compose setup has three containers: redis, ratelimit-build, and ratelimit. In order to run the docker-compose setup from the root of the repo, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The ratelimit-build container will build the ratelimit binary. Then via a shared volume the binary will be shared with the ratelimit container. This dual container setup is used in order to use a a minimal container to run the application, rather than the heftier container used to build it.&lt;/p&gt; &#xA;&lt;p&gt;If you want to run with &lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#two-redis-instances&#34;&gt;two redis instances&lt;/a&gt;, you will need to modify the docker-compose.yml file to run a second redis container, and change the environment variables as explained in the &lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#two-redis-instances&#34;&gt;two redis instances&lt;/a&gt; section.&lt;/p&gt; &#xA;&lt;h2&gt;Full test environment - Configure rate limits through files&lt;/h2&gt; &#xA;&lt;p&gt;To run a fully configured environment to demo Envoy based rate limiting, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export CONFIG_TYPE=FILE&#xA;docker-compose -f docker-compose-example.yml up --build --remove-orphans&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will run ratelimit, redis, prom-statsd-exporter and two Envoy containers such that you can demo rate limiting by hitting the below endpoints.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl localhost:8888/test&#xA;curl localhost:8888/header -H &#34;foo: foo&#34; # Header based&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;bar: bar&#34; # Two headers&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;baz: baz&#34;  # This will be rate limited&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;bar: banned&#34; # Ban a particular header value&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;baz: shady&#34; # This will never be ratelimited since &#34;baz&#34; with value &#34;shady&#34; is in shadow_mode&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;baz: not-so-shady&#34; # This is subject to rate-limiting because the it&#39;s now in shadow_mode&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;examples/ratelimit/config/example.yaml&lt;/code&gt; to test different rate limit configs. Hot reloading is enabled.&lt;/p&gt; &#xA;&lt;p&gt;The descriptors in &lt;code&gt;example.yaml&lt;/code&gt; and the actions in &lt;code&gt;examples/envoy/proxy.yaml&lt;/code&gt; should give you a good idea on how to configure rate limits.&lt;/p&gt; &#xA;&lt;p&gt;To see the metrics in the example&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# The metrics for the shadow_mode keys&#xA;curl http://localhost:9102/metrics | grep -i shadow&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Full test environment - Configure rate limits through an xDS Management Server&lt;/h2&gt; &#xA;&lt;p&gt;To run a fully configured environment to demo Envoy based rate limiting, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export CONFIG_TYPE=GRPC_XDS_SOTW&#xA;docker-compose -f docker-compose-example.yml --profile xds-config up --build --remove-orphans&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will run in &lt;code&gt;xds-config&lt;/code&gt; docker-compose profile which will run example xDS-Server, ratelimit, redis, prom-statsd-exporter and two Envoy containers such that you can demo rate limiting by hitting the below endpoints.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl localhost:8888/test&#xA;curl localhost:8888/header -H &#34;foo: foo&#34; # Header based&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;bar: bar&#34; # Two headers&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;baz: baz&#34;  # This will be rate limited&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;bar: banned&#34; # Ban a particular header value&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;baz: shady&#34; # This will never be ratelimited since &#34;baz&#34; with value &#34;shady&#34; is in shadow_mode&#xA;curl localhost:8888/twoheader -H &#34;foo: foo&#34; -H &#34;baz: not-so-shady&#34; # This is subject to rate-limiting because the it&#39;s now in shadow_mode&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Edit&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/examples/xds-sotw-config-server/resource.go&#34;&gt;&lt;code&gt;examples/xds-sotw-config-server/resource.go&lt;/code&gt;&lt;/a&gt; to test different rate limit configs.&lt;/p&gt; &#xA;&lt;p&gt;To see the metrics in the example&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# The metrics for the shadow_mode keys&#xA;curl http://localhost:9102/metrics | grep -i shadow&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Self-contained end-to-end integration test&lt;/h2&gt; &#xA;&lt;p&gt;Integration tests are coded as bash-scripts in &lt;code&gt;integration-test/scripts&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The test suite will spin up a docker-compose environment from &lt;code&gt;integration-test/docker-compose-integration-test.yml&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;If the test suite fails it will exit with code 1.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make integration_tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Configuration&lt;/h1&gt; &#xA;&lt;h2&gt;The configuration format&lt;/h2&gt; &#xA;&lt;p&gt;The rate limit configuration file format is YAML (mainly so that comments are supported).&lt;/p&gt; &#xA;&lt;h3&gt;Definitions&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Domain:&lt;/strong&gt; A domain is a container for a set of rate limits. All domains known to the Ratelimit service must be globally unique. They serve as a way for different teams/projects to have rate limit configurations that don&#39;t conflict.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Descriptor:&lt;/strong&gt; A descriptor is a list of key/value pairs owned by a domain that the Ratelimit service uses to select the correct rate limit to use when limiting. Descriptors are case-sensitive. Examples of descriptors are: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;(&#34;database&#34;, &#34;users&#34;)&lt;/li&gt; &#xA;   &lt;li&gt;(&#34;message_type&#34;, &#34;marketing&#34;),(&#34;to_number&#34;,&#34;2061234567&#34;)&lt;/li&gt; &#xA;   &lt;li&gt;(&#34;to_cluster&#34;, &#34;service_a&#34;)&lt;/li&gt; &#xA;   &lt;li&gt;(&#34;to_cluster&#34;, &#34;service_a&#34;),(&#34;from_cluster&#34;, &#34;service_b&#34;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Descriptor list definition&lt;/h3&gt; &#xA;&lt;p&gt;Each configuration contains a top level descriptor list and potentially multiple nested lists beneath that. The format is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: &amp;lt;unique domain ID&amp;gt;&#xA;descriptors:&#xA;  - key: &amp;lt;rule key: required&amp;gt;&#xA;    value: &amp;lt;rule value: optional&amp;gt;&#xA;    rate_limit: (optional block)&#xA;      name: (optional)&#xA;      replaces: (optional)&#xA;       - name: (optional)&#xA;      unit: &amp;lt;see below: required&amp;gt;&#xA;      requests_per_unit: &amp;lt;see below: required&amp;gt;&#xA;    shadow_mode: (optional)&#xA;    detailed_metric: (optional)&#xA;    descriptors: (optional block)&#xA;      - ... (nested repetition of above)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Each descriptor in a descriptor list must have a key. It can also optionally have a value to enable a more specific match. The &#34;rate_limit&#34; block is optional and if present sets up an actual rate limit rule. See below for how the rule is defined. If the rate limit is not present and there are no nested descriptors, then the descriptor is effectively whitelisted. Otherwise, nested descriptors allow more complex matching and rate limiting scenarios.&lt;/p&gt; &#xA;&lt;h3&gt;Rate limit definition&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;rate_limit:&#xA;  unit: &amp;lt;second, minute, hour, day&amp;gt;&#xA;  requests_per_unit: &amp;lt;uint&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The rate limit block specifies the actual rate limit that will be used when there is a match. Currently the service supports per second, minute, hour, and day limits. More types of limits may be added in the future based on user demand.&lt;/p&gt; &#xA;&lt;h3&gt;Replaces&lt;/h3&gt; &#xA;&lt;p&gt;The replaces key indicates that this descriptor will replace the configuration set by another descriptor.&lt;/p&gt; &#xA;&lt;p&gt;If there is a rule being evaluated, and multiple descriptors can apply, the replaces descriptor will drop evaluation of the descriptor which it is replacing.&lt;/p&gt; &#xA;&lt;p&gt;To enable this, any descriptor which should potentially be replaced by another should have a name keyword in the rate_limit section, and any descriptor which should potentially replace the original descriptor should have a name keyword in its respective replaces section. Whenever limits match to both rules, only the rule which replaces the original will take effect, and the limit of the original will not be changed after evaluation.&lt;/p&gt; &#xA;&lt;p&gt;For example, let&#39;s say you have a bunch of endpoints and each is classified under read or write, with read having a certain limit and write having another. Each user has a certain limit for both endpoints. However, let&#39;s say that you want to increase a user&#39;s limit to a single read endpoint. The only option without using replaces would be to increase their limit for the read category. The replaces keyword allows increasing the limit of a single endpoint in this case.&lt;/p&gt; &#xA;&lt;h3&gt;ShadowMode&lt;/h3&gt; &#xA;&lt;p&gt;A shadow_mode key in a rule indicates that whatever the outcome of the evaluation of the rule, the end-result will always be &#34;OK&#34;.&lt;/p&gt; &#xA;&lt;p&gt;When a block is in ShadowMode all functions of the rate limiting service are executed as normal, with cache-lookup and statistics&lt;/p&gt; &#xA;&lt;p&gt;An additional statistic is added to keep track of how many times a key with &#34;shadow_mode&#34; has overridden result.&lt;/p&gt; &#xA;&lt;p&gt;There is also a Global Shadow Mode&lt;/p&gt; &#xA;&lt;h3&gt;Including detailed metrics for unspecified values&lt;/h3&gt; &#xA;&lt;p&gt;Setting the &lt;code&gt;detailed_metric: true&lt;/code&gt; for a descriptor will extend the metrics that are produced. Normally a descriptor that matches a value that is not explicitly listed in the configuration will from a metrics point-of-view be rolled-up into the base entry. This can be problematic if you want to have those details available for analysis.&lt;/p&gt; &#xA;&lt;p&gt;NB! This should only be enabled in situations where the potentially large cardinality of metrics that this can lead to is acceptable.&lt;/p&gt; &#xA;&lt;h3&gt;Examples&lt;/h3&gt; &#xA;&lt;h4&gt;Example 1&lt;/h4&gt; &#xA;&lt;p&gt;Let&#39;s start with a simple example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: mongo_cps&#xA;descriptors:&#xA;  - key: database&#xA;    value: users&#xA;    rate_limit:&#xA;      unit: second&#xA;      requests_per_unit: 500&#xA;&#xA;  - key: database&#xA;    value: default&#xA;    rate_limit:&#xA;      unit: second&#xA;      requests_per_unit: 500&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the configuration above the domain is &#34;mongo_cps&#34; and we setup 2 different rate limits in the top level descriptor list. Each of the limits have the same key (&#34;database&#34;). They have a different value (&#34;users&#34;, and &#34;default&#34;), and each of them setup a 500 request per second rate limit.&lt;/p&gt; &#xA;&lt;h4&gt;Example 2&lt;/h4&gt; &#xA;&lt;p&gt;A slightly more complex example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: messaging&#xA;descriptors:&#xA;  # Only allow 5 marketing messages a day&#xA;  - key: message_type&#xA;    value: marketing&#xA;    descriptors:&#xA;      - key: to_number&#xA;        rate_limit:&#xA;          unit: day&#xA;          requests_per_unit: 5&#xA;&#xA;  # Only allow 100 messages a day to any unique phone number&#xA;  - key: to_number&#xA;    rate_limit:&#xA;      unit: day&#xA;      requests_per_unit: 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the preceding example, the domain is &#34;messaging&#34; and we setup two different scenarios that illustrate more complex functionality. First, we want to limit on marketing messages to a specific number. To enable this, we make use of &lt;em&gt;nested descriptor lists.&lt;/em&gt; The top level descriptor is (&#34;message_type&#34;, &#34;marketing&#34;). However this descriptor does not have a limit assigned so it&#39;s just a placeholder. Contained within this entry we have another descriptor list that includes an entry with key &#34;to_number&#34;. However, notice that no value is provided. This means that the service will match against any value supplied for &#34;to_number&#34; and generate a unique limit. Thus, (&#34;message_type&#34;, &#34;marketing&#34;), (&#34;to_number&#34;, &#34;2061111111&#34;) and (&#34;message_type&#34;, &#34;marketing&#34;),(&#34;to_number&#34;, &#34;2062222222&#34;) will each get 5 requests per day.&lt;/p&gt; &#xA;&lt;p&gt;The configuration also sets up another rule without a value. This one creates an overall limit for messages sent to any particular number during a 1 day period. Thus, (&#34;to_number&#34;, &#34;2061111111&#34;) and (&#34;to_number&#34;, &#34;2062222222&#34;) both get 100 requests per day.&lt;/p&gt; &#xA;&lt;p&gt;When calling the rate limit service, the client can specify &lt;em&gt;multiple descriptors&lt;/em&gt; to limit on in a single call. This limits round trips and allows limiting on aggregate rule definitions. For example, using the preceding configuration, the client could send this complete request (in pseudo IDL):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;RateLimitRequest:&#xA;  domain: messaging&#xA;  descriptor: (&#34;message_type&#34;, &#34;marketing&#34;),(&#34;to_number&#34;, &#34;2061111111&#34;)&#xA;  descriptor: (&#34;to_number&#34;, &#34;2061111111&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And the service will rate limit against &lt;em&gt;all&lt;/em&gt; matching rules and return an aggregate result; a logical OR of all the individual rate limit decisions.&lt;/p&gt; &#xA;&lt;h4&gt;Example 3&lt;/h4&gt; &#xA;&lt;p&gt;An example to illustrate matching order.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: edge_proxy_per_ip&#xA;descriptors:&#xA;  - key: remote_address&#xA;    rate_limit:&#xA;      unit: second&#xA;      requests_per_unit: 10&#xA;&#xA;  # Black list IP&#xA;  - key: remote_address&#xA;    value: 50.0.0.5&#xA;    rate_limit:&#xA;      unit: second&#xA;      requests_per_unit: 0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the preceding example, we setup a generic rate limit for individual IP addresses. The architecture&#39;s edge proxy can be configured to make a rate limit service call with the descriptor &lt;code&gt;(&#34;remote_address&#34;, &#34;50.0.0.1&#34;)&lt;/code&gt; for example. This IP would get 10 requests per second as would any other IP. However, the configuration also contains a second configuration that explicitly defines a value along with the same key. If the descriptor &lt;code&gt;(&#34;remote_address&#34;, &#34;50.0.0.5&#34;)&lt;/code&gt; is received, the service will &lt;em&gt;attempt the most specific match possible&lt;/em&gt;. This means the most specific descriptor at the same level as your request. Thus, key/value is always attempted as a match before just key.&lt;/p&gt; &#xA;&lt;h4&gt;Example 4&lt;/h4&gt; &#xA;&lt;p&gt;The Ratelimit service matches requests to configuration entries with the same level, i.e same number of tuples in the request&#39;s descriptor as nested levels of descriptors in the configuration file. For instance, the following request:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;RateLimitRequest:&#xA;  domain: example4&#xA;  descriptor: (&#34;key&#34;, &#34;value&#34;),(&#34;subkey&#34;, &#34;subvalue&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Would &lt;strong&gt;not&lt;/strong&gt; match the following configuration. Even though the first descriptor in the request matches the 1st level descriptor in the configuration, the request has two tuples in the descriptor.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: example4&#xA;descriptors:&#xA;  - key: key&#xA;    value: value&#xA;    rate_limit:&#xA;      requests_per_unit: 300&#xA;      unit: second&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;However, it would match the following configuration:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: example4&#xA;descriptors:&#xA;  - key: key&#xA;    value: value&#xA;    descriptors:&#xA;      - key: subkey&#xA;        rate_limit:&#xA;          requests_per_unit: 300&#xA;          unit: second&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Example 5&lt;/h4&gt; &#xA;&lt;p&gt;We can also define unlimited rate limit descriptors:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: internal&#xA;descriptors:&#xA;  - key: ldap&#xA;    rate_limit:&#xA;      unlimited: true&#xA;&#xA;  - key: azure&#xA;    rate_limit:&#xA;      unit: minute&#xA;      requests_per_unit: 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For an unlimited descriptor, the request will not be sent to the underlying cache (Redis/Memcached), but will be quickly returned locally by the ratelimit instance. This can be useful for collecting statistics, or if one wants to define a descriptor that has no limit but the client wants to distinguish between such descriptor and one that does not exist.&lt;/p&gt; &#xA;&lt;p&gt;The return value for unlimited descriptors will be an OK status code with the LimitRemaining field set to MaxUint32 value.&lt;/p&gt; &#xA;&lt;h4&gt;Example 6&lt;/h4&gt; &#xA;&lt;p&gt;A rule using shadow_mode is useful for soft-launching rate limiting. In this example&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;RateLimitRequest:&#xA;  domain: example6&#xA;  descriptor: (&#34;service&#34;, &#34;auth-service&#34;),(&#34;user&#34;, &#34;user-a&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;user-a&lt;/code&gt; of the &lt;code&gt;auth-service&lt;/code&gt; would not get rate-limited regardless of the rate of requests, there would however be statistics related to the breach of the configured limit of 10 req / sec.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;user-b&lt;/code&gt; would be limited to 20 req / sec however.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: example6&#xA;descriptors:&#xA;  - key: service&#xA;    descriptors:&#xA;      - key: user&#xA;        value: user-a&#xA;        rate_limit:&#xA;          requests_per_unit: 10&#xA;          unit: second&#xA;        shadow_mode: true&#xA;      - key: user&#xA;        value: user-b&#xA;        rate_limit:&#xA;          requests_per_unit: 20&#xA;          unit: second&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Example 7&lt;/h4&gt; &#xA;&lt;p&gt;When the replaces keyword is used, that limit will replace any limit which has the name being replaced as its name, and the original descriptor&#39;s limit will not be affected.&lt;/p&gt; &#xA;&lt;p&gt;In the example below, the following limits will apply:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(key_1, value_1), (user, bkthomps): 5 / sec&#xA;(key_2, value_2), (user, bkthomps): 10 / sec&#xA;(key_1, value_1), (key_2, value_2), (user, bkthomps): 10 / sec since the (key_1, value_1), (user, bkthomps) rule was replaced and this will not affect the 5 / sec limit that would take effect with (key_2, value_2), (user, bkthomps)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: example7&#xA;descriptors:&#xA;  - key: key_1&#xA;    value: value_1&#xA;    descriptors:&#xA;      - key: user&#xA;        value: bkthomps&#xA;        rate_limit:&#xA;          name: specific_limit&#xA;          requests_per_unit: 5&#xA;          unit: second&#xA;  - key: key_2&#xA;    value: value_2&#xA;    descriptors:&#xA;      - key: user&#xA;        value: bkthomps&#xA;        rate_limit:&#xA;          replaces:&#xA;            - name: specific_limit&#xA;          requests_per_unit: 10&#xA;          unit: second&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Example 8&lt;/h4&gt; &#xA;&lt;p&gt;In this example we demonstrate how a descriptor without a specified value is configured to override the default behavior and include the matched-value in the metrics.&lt;/p&gt; &#xA;&lt;p&gt;Rate limiting configuration and tracking works as normally&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(key_1, unspecified_value): 10 / sec&#xA;(key_1, unspecified_value2): 10 / sec&#xA;(key_1, value_1): 20 / sec&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: example8&#xA;descriptors:&#xA;  - key: key1&#xA;    detailed_metric: true&#xA;    rate_limit:&#xA;      unit: minute&#xA;      requests_per_unit: 10&#xA;  - key: key1&#xA;    value: value1&#xA;    rate_limit:&#xA;      unit: minute&#xA;      requests_per_unit: 20&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The metrics keys will be the following:&lt;/p&gt; &#xA;&lt;p&gt;&#34;key1_unspecified_value&#34; &#34;key1_unspecified_value2&#34; &#34;key1_value1&#34;&lt;/p&gt; &#xA;&lt;p&gt;rather than the normal &#34;key1&#34; &#34;key1_value1&#34;&lt;/p&gt; &#xA;&lt;h4&gt;Example 9&lt;/h4&gt; &#xA;&lt;p&gt;Value supports wildcard matching to apply rate-limit for nested endpoints:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(key_1, value_1): 20 / sec&#xA;(key_1, value_2): 20 / sec&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;domain: example9&#xA;descriptors:&#xA;  - key: key1&#xA;    value: value*&#xA;    rate_limit:&#xA;      unit: minute&#xA;      requests_per_unit: 20&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Loading Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Rate limit service supports following configuration loading methods. You can define which methods to use by configuring environment variable &lt;code&gt;CONFIG_TYPE&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Config Loading Method&lt;/th&gt; &#xA;   &lt;th&gt;Value for Environment Variable &lt;code&gt;CONFIG_TYPE&lt;/code&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#file-based-configuration-loading&#34;&gt;File Based Configuration Loading&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;FILE&lt;/code&gt; (Default)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/#xds-server-based-configuration-loading&#34;&gt;xDS Server Based Configuration Loading&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;GRPC_XDS_SOTW&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;When the environment variable &lt;code&gt;FORCE_START_WITHOUT_INITIAL_CONFIG&lt;/code&gt; set to &lt;code&gt;false&lt;/code&gt;, the Rate limit service will wait for initial rate limit configuration before starting the server (gRPC, Rest server endpoints). When set to &lt;code&gt;true&lt;/code&gt; the server will start even without initial configuration.&lt;/p&gt; &#xA;&lt;h3&gt;File Based Configuration Loading&lt;/h3&gt; &#xA;&lt;p&gt;The Ratelimit service uses a library written by Lyft called &lt;a href=&#34;https://github.com/lyft/goruntime&#34;&gt;goruntime&lt;/a&gt; to do configuration loading. Goruntime monitors a designated path, and watches for symlink swaps to files in the directory tree to reload configuration files.&lt;/p&gt; &#xA;&lt;p&gt;The path to watch can be configured via the &lt;a href=&#34;https://github.com/envoyproxy/ratelimit/raw/master/src/settings/settings.go&#34;&gt;settings&lt;/a&gt; package with the following environment variables:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;RUNTIME_ROOT default:&#34;/srv/runtime_data/current&#34;&#xA;RUNTIME_SUBDIRECTORY&#xA;RUNTIME_APPDIRECTORY default:&#34;config&#34;&#xA;RUNTIME_IGNOREDOTFILES default:&#34;false&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Configuration files are loaded from RUNTIME_ROOT/RUNTIME_SUBDIRECTORY/RUNTIME_APPDIRECTORY/*.yaml&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;There are two methods for triggering a configuration reload:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Symlink RUNTIME_ROOT to a different directory.&lt;/li&gt; &#xA; &lt;li&gt;Update the contents inside &lt;code&gt;RUNTIME_ROOT/RUNTIME_SUBDIRECTORY/RUNTIME_APPDIRECTORY/&lt;/code&gt; directly.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The former is the default behavior. To use the latter method, set the &lt;code&gt;RUNTIME_WATCH_ROOT&lt;/code&gt; environment variable to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The following filesystem operations on configuration files inside &lt;code&gt;RUNTIME_ROOT/RUNTIME_SUBDIRECTORY/RUNTIME_APPDIRECTORY/&lt;/code&gt; will force a reload of all config files:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Write&lt;/li&gt; &#xA; &lt;li&gt;Create&lt;/li&gt; &#xA; &lt;li&gt;Chmod&lt;/li&gt; &#xA; &lt;li&gt;Remove&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For more information on how runtime works you can read its &lt;a href=&#34;https://github.com/lyft/goruntime&#34;&gt;README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;By default it is not possible to define multiple configuration files within &lt;code&gt;RUNTIME_SUBDIRECTORY&lt;/code&gt; referencing the same domain. To enable this behavior set &lt;code&gt;MERGE_DOMAIN_CONFIG&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;xDS Management Server Based Configuration Loading&lt;/h3&gt; &#xA;&lt;p&gt;xDS Management Server is a gRPC server which implements the &lt;a href=&#34;https://github.com/envoyproxy/data-plane-api/raw/97b6dae39046f7da1331a4dc57830d20e842fc26/envoy/service/discovery/v3/ads.proto&#34;&gt;Aggregated Discovery Service (ADS)&lt;/a&gt;. The xDS Management server serves &lt;a href=&#34;https://github.com/envoyproxy/data-plane-api/raw/97b6dae39046f7da1331a4dc57830d20e842fc26/envoy/service/discovery/v3/discovery.proto#L69&#34;&gt;Discovery Response&lt;/a&gt; with &lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/api/ratelimit/config/ratelimit/v3/rls_conf.proto&#34;&gt;Ratelimit Configuration Resources&lt;/a&gt; and with Type URL &lt;code&gt;&#34;type.googleapis.com/ratelimit.config.ratelimit.v3.RateLimitConfig&#34;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The xDS client in the Rate limit service configure Rate limit service with the provided configuration. In case of connection failures, the xDS Client retries the connection to the xDS server with exponential backoff and the backoff parameters are configurable.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;XDS_CLIENT_BACKOFF_JITTER&lt;/code&gt;: set to &lt;code&gt;&#34;true&#34;&lt;/code&gt; to add jitter to the exponential backoff.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;XDS_CLIENT_BACKOFF_INITIAL_INTERVAL&lt;/code&gt;: The base amount of time the xDS client waits before retyring the connection after failure. Default: &#34;10s&#34;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;XDS_CLIENT_BACKOFF_MAX_INTERVAL&lt;/code&gt;: The max backoff interval is the upper limit on the amount of time the xDS client will wait between retries. After reaching the max backoff interval, the next retries will continue using the max interval. Default: &#34;60s&#34;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;XDS_CLIENT_BACKOFF_RANDOM_FACTOR&lt;/code&gt;: This is a factor by which the initial interval is multiplied to calculate the next backoff interval. Default: &#34;0.5&#34;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For more information on xDS protocol please refer to the &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol&#34;&gt;envoy proxy documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can refer to &lt;a href=&#34;https://raw.githubusercontent.com/envoyproxy/ratelimit/main/examples/xds-sotw-config-server/README.md&#34;&gt;the sample xDS configuration management server&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The xDS server for listening for configuration can be set via &lt;a href=&#34;https://github.com/envoyproxy/ratelimit/raw/master/src/settings/settings.go&#34;&gt;settings&lt;/a&gt; package with the following environment variables:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;CONFIG_GRPC_XDS_NODE_ID default:&#34;default&#34;&#xA;CONFIG_GRPC_XDS_SERVER_URL default:&#34;localhost:18000&#34;&#xA;CONFIG_GRPC_XDS_SERVER_CONNECT_RETRY_INTERVAL default:&#34;3s&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As well Ratelimit supports TLS connections, these can be configured using the following environment variables:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;CONFIG_GRPC_XDS_SERVER_USE_TLS&lt;/code&gt;: set to &lt;code&gt;&#34;true&#34;&lt;/code&gt; to enable a TLS connection with the xDS configuration management server.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CONFIG_GRPC_XDS_CLIENT_TLS_CERT&lt;/code&gt;, &lt;code&gt;CONFIG_GRPC_XDS_CLIENT_TLS_KEY&lt;/code&gt;, and &lt;code&gt;CONFIG_GRPC_XDS_SERVER_TLS_CACERT&lt;/code&gt; to provides files to specify a TLS connection configuration to the xDS configuration management server.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CONFIG_GRPC_XDS_SERVER_TLS_SAN&lt;/code&gt;: (Optional) Override the SAN value to validate from the server certificate.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;When using xDS you can configure extra headers that will be added to GRPC requests to the xDS Management server. Extra headers can be useful for providing additional authorization information. This can be configured using the following environment variable:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;CONFIG_GRPC_XDS_CLIENT_ADDITIONAL_HEADERS&lt;/code&gt; - set to &lt;code&gt;&#34;&amp;lt;k1:v1&amp;gt;,&amp;lt;k2:v2&amp;gt;&#34;&lt;/code&gt; to add multiple headers to GRPC requests.&lt;/p&gt; &#xA;&lt;h2&gt;Log Format&lt;/h2&gt; &#xA;&lt;p&gt;A centralized log collection system works better with logs in json format. JSON format avoids the need for custom parsing rules. The Ratelimit service produces logs in a text format by default. For Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;time=&#34;2020-09-10T17:22:35Z&#34; level=debug msg=&#34;loading domain: messaging&#34;&#xA;time=&#34;2020-09-10T17:22:35Z&#34; level=debug msg=&#34;loading descriptor: key=messaging.message_type_marketing&#34;&#xA;time=&#34;2020-09-10T17:22:35Z&#34; level=debug msg=&#34;loading descriptor: key=messaging.message_type_marketing.to_number ratelimit={requests_per_unit=5, unit=DAY}&#34;&#xA;time=&#34;2020-09-10T17:22:35Z&#34; level=debug msg=&#34;loading descriptor: key=messaging.to_number ratelimit={requests_per_unit=100, unit=DAY}&#34;&#xA;time=&#34;2020-09-10T17:21:55Z&#34; level=warning msg=&#34;Listening for debug on &#39;:6070&#39;&#34;&#xA;time=&#34;2020-09-10T17:21:55Z&#34; level=warning msg=&#34;Listening for HTTP on &#39;:8080&#39;&#34;&#xA;time=&#34;2020-09-10T17:21:55Z&#34; level=debug msg=&#34;waiting for runtime update&#34;&#xA;time=&#34;2020-09-10T17:21:55Z&#34; level=warning msg=&#34;Listening for gRPC on &#39;:8081&#39;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;JSON Log format can be configured using the following environment variables:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;LOG_FORMAT=json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#34;@message&#34;:&#34;loading domain: messaging&#34;,&#34;@timestamp&#34;:&#34;2020-09-10T17:22:44.926010192Z&#34;,&#34;level&#34;:&#34;debug&#34;}&#xA;{&#34;@message&#34;:&#34;loading descriptor: key=messaging.message_type_marketing&#34;,&#34;@timestamp&#34;:&#34;2020-09-10T17:22:44.926019315Z&#34;,&#34;level&#34;:&#34;debug&#34;}&#xA;{&#34;@message&#34;:&#34;loading descriptor: key=messaging.message_type_marketing.to_number ratelimit={requests_per_unit=5, unit=DAY}&#34;,&#34;@timestamp&#34;:&#34;2020-09-10T17:22:44.926037174Z&#34;,&#34;level&#34;:&#34;debug&#34;}&#xA;{&#34;@message&#34;:&#34;loading descriptor: key=messaging.to_number ratelimit={requests_per_unit=100, unit=DAY}&#34;,&#34;@timestamp&#34;:&#34;2020-09-10T17:22:44.926048993Z&#34;,&#34;level&#34;:&#34;debug&#34;}&#xA;{&#34;@message&#34;:&#34;Listening for debug on &#39;:6070&#39;&#34;,&#34;@timestamp&#34;:&#34;2020-09-10T17:22:44.926113905Z&#34;,&#34;level&#34;:&#34;warning&#34;}&#xA;{&#34;@message&#34;:&#34;Listening for gRPC on &#39;:8081&#39;&#34;,&#34;@timestamp&#34;:&#34;2020-09-10T17:22:44.926182006Z&#34;,&#34;level&#34;:&#34;warning&#34;}&#xA;{&#34;@message&#34;:&#34;Listening for HTTP on &#39;:8080&#39;&#34;,&#34;@timestamp&#34;:&#34;2020-09-10T17:22:44.926227031Z&#34;,&#34;level&#34;:&#34;warning&#34;}&#xA;{&#34;@message&#34;:&#34;waiting for runtime update&#34;,&#34;@timestamp&#34;:&#34;2020-09-10T17:22:44.926267808Z&#34;,&#34;level&#34;:&#34;debug&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;GRPC Keepalive&lt;/h2&gt; &#xA;&lt;p&gt;Client-side GRPC DNS re-resolution in scenarios with auto scaling enabled might not work as expected and the current workaround is to &lt;a href=&#34;https://github.com/grpc/grpc/issues/12295#issuecomment-382794204&#34;&gt;configure connection keepalive&lt;/a&gt; on server-side. The behavior can be fixed by configuring the following env variables for the ratelimit server:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;GRPC_MAX_CONNECTION_AGE&lt;/code&gt;: a duration for the maximum amount of time a connection may exist before it will be closed by sending a GoAway. A random jitter of +/-10% will be added to MaxConnectionAge to spread out connection storms.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;GRPC_MAX_CONNECTION_AGE_GRACE&lt;/code&gt;: an additive period after MaxConnectionAge after which the connection will be forcibly closed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Health-check&lt;/h2&gt; &#xA;&lt;p&gt;Health check status is determined internally by individual components. Currently, we have three components that determine the overall health status of the rate limit service. Each of the individual component&#39;s health needs to be healthy for the overall to report healthy. Some components may be turned OFF via configurations so overall health is not effected by that component&#39;s health status.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Redis health (Turned ON. Defaults to healthy)&lt;/li&gt; &#xA; &lt;li&gt;Configuration status (Turned OFF unless configured to be ON via &lt;code&gt;HEALTHY_WITH_AT_LEAST_ONE_CONFIG_LOADED&lt;/code&gt; see below section. Defaults to unhealthy) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;If the environment variable is enabled then, it will start in an unhealthy state and become healthy when at least one config is loaded. If we later fail to load any configs, it will go unhealthy again.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Sigterm (Turned ON. Defaults to healthy) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Turns unhealthy if receives sigterm signal All components needs to be healthy for overall health to be healthy.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Health-check configurations&lt;/h3&gt; &#xA;&lt;p&gt;Health check can be configured to check if rate-limit configurations are loaded using the following environment variable.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;HEALTHY_WITH_AT_LEAST_ONE_CONFIG_LOADED default:&#34;false&#34;`&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If &lt;code&gt;HEALTHY_WITH_AT_LEAST_ONE_CONFIG_LOADED&lt;/code&gt; is enabled then health check will start as unhealthy and becomes healthy if it detects at least one domain is loaded with the config. If it detects no config again then it will change to unhealthy.&lt;/p&gt; &#xA;&lt;h2&gt;GRPC server&lt;/h2&gt; &#xA;&lt;p&gt;By default the ratelimit gRPC server binds to &lt;code&gt;0.0.0.0:8081&lt;/code&gt;. To change this set &lt;code&gt;GRPC_HOST&lt;/code&gt; and/or &lt;code&gt;GRPC_PORT&lt;/code&gt;. If you want to run the server on a unix domain socket then set &lt;code&gt;GRPC_UDS&lt;/code&gt;, e.g. &lt;code&gt;GRPC_UDS=/&amp;lt;dir&amp;gt;/ratelimit.sock&lt;/code&gt; and leave &lt;code&gt;GRPC_HOST&lt;/code&gt; and &lt;code&gt;GRPC_PORT&lt;/code&gt; unmodified.&lt;/p&gt; &#xA;&lt;h1&gt;Request Fields&lt;/h1&gt; &#xA;&lt;p&gt;For information on the fields of a Ratelimit gRPC request please read the information on the RateLimitRequest message type in the Ratelimit &lt;a href=&#34;https://github.com/envoyproxy/envoy/raw/master/api/envoy/service/ratelimit/v3/rls.proto&#34;&gt;proto file.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;GRPC Client&lt;/h1&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/envoyproxy/ratelimit/raw/master/src/client_cmd/main.go&#34;&gt;gRPC client&lt;/a&gt; will interact with ratelimit server and tell you if the requests are over limit.&lt;/p&gt; &#xA;&lt;h2&gt;Commandline flags&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;-dial_string&lt;/code&gt;: used to specify the address of ratelimit server. It defaults to &lt;code&gt;localhost:8081&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-domain&lt;/code&gt;: used to specify the domain.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-descriptors&lt;/code&gt;: used to specify one descriptor. You can pass multiple descriptors like following:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;go run main.go -domain test \&#xA;-descriptors name=foo,age=14 -descriptors name=bar,age=18&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Global ShadowMode&lt;/h1&gt; &#xA;&lt;p&gt;There is a global shadow-mode which can make it easier to introduce rate limiting into an existing service landscape. It will override whatever result is returned by the regular rate limiting process.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;The global shadow mode is configured with an environment variable&lt;/p&gt; &#xA;&lt;p&gt;Setting environment variable &lt;code&gt;SHADOW_MODE&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; will enable the feature.&lt;/p&gt; &#xA;&lt;h2&gt;Statistics&lt;/h2&gt; &#xA;&lt;p&gt;There is an additional service-level statistics generated that will increment whenever the global shadow mode has overridden a rate limiting result.&lt;/p&gt; &#xA;&lt;h1&gt;Statistics&lt;/h1&gt; &#xA;&lt;p&gt;The rate limit service generates various statistics for each configured rate limit rule that will be useful for end users both for visibility and for setting alarms. Ratelimit uses &lt;a href=&#34;https://github.com/lyft/gostats&#34;&gt;gostats&lt;/a&gt; as its statistics library. Please refer to &lt;a href=&#34;https://godoc.org/github.com/lyft/gostats&#34;&gt;gostats&#39; documentation&lt;/a&gt; for more information on the library.&lt;/p&gt; &#xA;&lt;p&gt;Statistics default to using &lt;a href=&#34;https://github.com/statsd/statsd&#34;&gt;StatsD&lt;/a&gt; and configured via the env vars from &lt;a href=&#34;https://github.com/lyft/gostats&#34;&gt;gostats&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To output statistics to stdout instead, set env var &lt;code&gt;USE_STATSD&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Configure statistics output frequency with &lt;code&gt;STATS_FLUSH_INTERVAL&lt;/code&gt;, where the type is &lt;code&gt;time.Duration&lt;/code&gt;, e.g. &lt;code&gt;10s&lt;/code&gt; is the default value.&lt;/p&gt; &#xA;&lt;p&gt;To disable statistics entirely, set env var &lt;code&gt;DISABLE_STATS&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Rate Limit Statistic Path:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ratelimit.service.rate_limit.DOMAIN.KEY_VALUE.STAT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;DOMAIN:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;As specified in the domain value in the YAML runtime file&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;KEY_VALUE:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A combination of the key value&lt;/li&gt; &#xA; &lt;li&gt;Nested descriptors would be suffixed in the stats path&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The default mode is that the value-part is omitted if the rule that matches is a descriptor without a value. Specifying the &lt;code&gt;detailed_metric&lt;/code&gt; configuration parameter changes this behavior and creates a unique metric even in this situation.&lt;/p&gt; &#xA;&lt;p&gt;STAT:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;near_limit: Number of rule hits over the NearLimit ratio threshold (currently 80%) but under the threshold rate.&lt;/li&gt; &#xA; &lt;li&gt;over_limit: Number of rule hits exceeding the threshold rate&lt;/li&gt; &#xA; &lt;li&gt;total_hits: Number of rule hits in total&lt;/li&gt; &#xA; &lt;li&gt;shadow_mode: Number of rule hits where shadow_mode would trigger and override the over_limit result&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To use a custom near_limit ratio threshold, you can specify with &lt;code&gt;NEAR_LIMIT_RATIO&lt;/code&gt; environment variable. It defaults to &lt;code&gt;0.8&lt;/code&gt; (0-1 scale). These are examples of generated stats for some configured rate limit rules from the above examples:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ratelimit.service.rate_limit.mongo_cps.database_default.over_limit: 0&#xA;ratelimit.service.rate_limit.mongo_cps.database_default.total_hits: 2846&#xA;ratelimit.service.rate_limit.mongo_cps.database_users.over_limit: 0&#xA;ratelimit.service.rate_limit.mongo_cps.database_users.total_hits: 2939&#xA;ratelimit.service.rate_limit.messaging.message_type_marketing.to_number.over_limit: 0&#xA;ratelimit.service.rate_limit.messaging.message_type_marketing.to_number.total_hits: 0&#xA;ratelimit.service.rate_limit.messaging.auth-service.over_limit.total_hits: 1&#xA;ratelimit.service.rate_limit.messaging.auth-service.over_limit.over_limit: 1&#xA;ratelimit.service.rate_limit.messaging.auth-service.over_limit.shadow_mode: 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Statistics options&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;EXTRA_TAGS&lt;/code&gt;: set to &lt;code&gt;&#34;&amp;lt;k1:v1&amp;gt;,&amp;lt;k2:v2&amp;gt;&#34;&lt;/code&gt; to tag all emitted stats with the provided tags. You might want to tag build commit or release version, for example.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;DogStatsD&lt;/h2&gt; &#xA;&lt;p&gt;To enable dogstatsd integration set:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;USE_DOG_STATSD&lt;/code&gt;: &lt;code&gt;true&lt;/code&gt; to use &lt;a href=&#34;https://docs.datadoghq.com/developers/dogstatsd/?code-lang=go&#34;&gt;DogStatsD&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;dogstatsd also enables so called &lt;code&gt;mogrifiers&lt;/code&gt; which can convert from traditional stats tags into a combination of stat name and tags.&lt;/p&gt; &#xA;&lt;p&gt;To enable mogrifiers, set a comma-separated list of them in &lt;code&gt;DOG_STATSD_MOGRIFIERS&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;e.g. &lt;code&gt;USE_DOG_STATSD_MOGRIFIERS&lt;/code&gt;: &lt;code&gt;FOO,BAR&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;For each mogrifier, define variables that declare the mogrification&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;DOG_STATSD_MOGRIFIERS_%s_PATTERN&lt;/code&gt;: The regex pattern to match on&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;DOG_STATSD_MOGRIFIERS_%s_NAME&lt;/code&gt;: The name of the metric to emit. Can contain variables.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;DOG_STATSD_MOGRIFIERS_%s_TAGS&lt;/code&gt;: Comma-separated list of tags to emit. Can contain variables.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Variables within mogrifiers are strings such as &lt;code&gt;$1&lt;/code&gt;, &lt;code&gt;$2&lt;/code&gt;, &lt;code&gt;$3&lt;/code&gt; which can be used to reference a match group from the regex pattern.&lt;/p&gt; &#xA;&lt;h3&gt;Example&lt;/h3&gt; &#xA;&lt;p&gt;In the example below we will set mogrifier DOMAIN to adjust &lt;code&gt;some.original.metric.TAG&lt;/code&gt; to &lt;code&gt;some.original.metric&lt;/code&gt; with tag &lt;code&gt;domain:TAG&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;First enable a single mogrifier:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;USE_DOG_STATSD_MOGRIFIERS&lt;/code&gt;: &lt;code&gt;DOMAIN&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Then, declare the rules for the &lt;code&gt;DOMAIN&lt;/code&gt; modifier:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;DOG_STATSD_MOGRIFIER_DOMAIN_PATTERN&lt;/code&gt;: &lt;code&gt;^some\.original\.metric\.(.*)$&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;DOG_STATSD_MOGRIFIER_DOMAIN_NAME&lt;/code&gt;: &lt;code&gt;some.original.metric&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;DOG_STATSD_MOGRIFIER_DOMAIN_TAGS&lt;/code&gt;: &lt;code&gt;domain:$1&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Continued example:&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s also set another mogrifier which outputs the hits metrics with a domain and descriptor tag&lt;/p&gt; &#xA;&lt;p&gt;First, enable an extra mogrifier:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;USE_DOG_STATSD_MOGRIFIERS&lt;/code&gt;: &lt;code&gt;DOMAIN,HITS&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Then, declare additional rules for the &lt;code&gt;DESCRIPTOR&lt;/code&gt; mogrifier&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;DOG_STATSD_MOGRIFIER_HITS_PATTERN&lt;/code&gt;: &lt;code&gt;^ratelimit\.service\.rate_limit\.(.*)\.(.*)\.(.*)$&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;DOG_STATSD_MOGRIFIER_HITS_NAME&lt;/code&gt;: &lt;code&gt;ratelimit.service.rate_limit.$3&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;DOG_STATSD_MOGRIFIER_HITS_TAGS&lt;/code&gt;: &lt;code&gt;domain:$1,descriptor:$2&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;HTTP Port&lt;/h1&gt; &#xA;&lt;p&gt;The ratelimit service listens to HTTP 1.1 (by default on port 8080) with two endpoints:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;/healthcheck → return a 200 if this service is healthy&lt;/li&gt; &#xA; &lt;li&gt;/json → HTTP 1.1 endpoint for interacting with ratelimit service&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;/json endpoint&lt;/h2&gt; &#xA;&lt;p&gt;Takes an HTTP POST with a JSON body of the form e.g.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;domain&#34;: &#34;dummy&#34;,&#xA;  &#34;descriptors&#34;: [&#xA;    { &#34;entries&#34;: [{ &#34;key&#34;: &#34;one_per_day&#34;, &#34;value&#34;: &#34;something&#34; }] }&#xA;  ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The service will return an http 200 if this request is allowed (if no ratelimits exceeded) or 429 if one or more ratelimits were exceeded.&lt;/p&gt; &#xA;&lt;p&gt;The response is a RateLimitResponse encoded with &lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3#json&#34;&gt;proto3-to-json mapping&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;overallCode&#34;: &#34;OVER_LIMIT&#34;,&#xA;  &#34;statuses&#34;: [&#xA;    {&#xA;      &#34;code&#34;: &#34;OVER_LIMIT&#34;,&#xA;      &#34;currentLimit&#34;: {&#xA;        &#34;requestsPerUnit&#34;: 1,&#xA;        &#34;unit&#34;: &#34;MINUTE&#34;&#xA;      }&#xA;    },&#xA;    {&#xA;      &#34;code&#34;: &#34;OK&#34;,&#xA;      &#34;currentLimit&#34;: {&#xA;        &#34;requestsPerUnit&#34;: 2,&#xA;        &#34;unit&#34;: &#34;MINUTE&#34;&#xA;      },&#xA;      &#34;limitRemaining&#34;: 1&#xA;    }&#xA;  ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Debug Port&lt;/h1&gt; &#xA;&lt;p&gt;The debug port can be used to interact with the running process.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ curl 0:6070/&#xA;/debug/pprof/: root of various pprof endpoints. hit for help.&#xA;/rlconfig: print out the currently loaded configuration for debugging&#xA;/stats: print out stats&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can specify the debug server address with the &lt;code&gt;DEBUG_HOST&lt;/code&gt; and &lt;code&gt;DEBUG_PORT&lt;/code&gt; environment variables. They currently default to &lt;code&gt;0.0.0.0&lt;/code&gt; and &lt;code&gt;6070&lt;/code&gt; respectively.&lt;/p&gt; &#xA;&lt;h1&gt;Local Cache&lt;/h1&gt; &#xA;&lt;p&gt;Ratelimit optionally uses &lt;a href=&#34;https://github.com/coocood/freecache&#34;&gt;freecache&lt;/a&gt; as its local caching layer, which stores the over-the-limit cache keys, and thus avoids reading the redis cache again for the already over-the-limit keys. The local cache size can be configured via &lt;code&gt;LocalCacheSizeInBytes&lt;/code&gt; in the &lt;a href=&#34;https://github.com/envoyproxy/ratelimit/raw/master/src/settings/settings.go&#34;&gt;settings&lt;/a&gt;. If &lt;code&gt;LocalCacheSizeInBytes&lt;/code&gt; is 0, local cache is disabled.&lt;/p&gt; &#xA;&lt;h1&gt;Redis&lt;/h1&gt; &#xA;&lt;p&gt;Ratelimit uses Redis as its caching layer. Ratelimit supports two operation modes:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;One Redis server for all limits.&lt;/li&gt; &#xA; &lt;li&gt;Two Redis instances: one for per second limits and another one for all other limits.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;As well Ratelimit supports TLS connections and authentication. These can be configured using the following environment variables:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_TLS&lt;/code&gt; &amp;amp; &lt;code&gt;REDIS_PERSECOND_TLS&lt;/code&gt;: set to &lt;code&gt;&#34;true&#34;&lt;/code&gt; to enable a TLS connection for the specific connection type.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_TLS_CLIENT_CERT&lt;/code&gt;, &lt;code&gt;REDIS_TLS_CLIENT_KEY&lt;/code&gt;, and &lt;code&gt;REDIS_TLS_CACERT&lt;/code&gt; to provides files to specify a TLS connection configuration to Redis server that requires client certificate verification. (This is effective when &lt;code&gt;REDIS_TLS&lt;/code&gt; or &lt;code&gt;REDIS_PERSECOND_TLS&lt;/code&gt; is set to to &lt;code&gt;&#34;true&#34;&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_TLS_SKIP_HOSTNAME_VERIFICATION&lt;/code&gt; set to &lt;code&gt;&#34;true&#34;&lt;/code&gt; will skip hostname verification in environments where the certificate has an invalid hostname, such as GCP Memorystore.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_AUTH&lt;/code&gt; &amp;amp; &lt;code&gt;REDIS_PERSECOND_AUTH&lt;/code&gt;: set to &lt;code&gt;&#34;password&#34;&lt;/code&gt; to enable password-only authentication to the redis host.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_AUTH&lt;/code&gt; &amp;amp; &lt;code&gt;REDIS_PERSECOND_AUTH&lt;/code&gt;: set to &lt;code&gt;&#34;username:password&#34;&lt;/code&gt; to enable username-password authentication to the redis host.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CACHE_KEY_PREFIX&lt;/code&gt;: a string to prepend to all cache keys&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For controlling the behavior of cache key incrementation when any of them is already over the limit, you can use the following configuration:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;STOP_CACHE_KEY_INCREMENT_WHEN_OVERLIMIT&lt;/code&gt;: Set this configuration to &lt;code&gt;true&lt;/code&gt; to disallow key incrementation when one of the keys is already over the limit.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;code&gt;STOP_CACHE_KEY_INCREMENT_WHEN_OVERLIMIT&lt;/code&gt; is useful when multiple descriptors are included in a single request. Setting this to &lt;code&gt;true&lt;/code&gt; can prevent the incrementation of other descriptors&#39; counters if any of the descriptors is already over the limit.&lt;/p&gt; &#xA;&lt;h2&gt;Redis type&lt;/h2&gt; &#xA;&lt;p&gt;Ratelimit supports different types of redis deployments:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Single instance (default): Talk to a single instance of redis, or a redis proxy (e.g. &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/other_protocols/redis&#34;&gt;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/other_protocols/redis&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Sentinel: Talk to a redis deployment with sentinel instances (see &lt;a href=&#34;https://redis.io/topics/sentinel&#34;&gt;https://redis.io/topics/sentinel&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Cluster: Talk to a redis in cluster mode (see &lt;a href=&#34;https://redis.io/topics/cluster-spec&#34;&gt;https://redis.io/topics/cluster-spec&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The deployment type can be specified with the &lt;code&gt;REDIS_TYPE&lt;/code&gt; / &lt;code&gt;REDIS_PERSECOND_TYPE&lt;/code&gt; environment variables. Depending on the type defined, the &lt;code&gt;REDIS_URL&lt;/code&gt; and &lt;code&gt;REDIS_PERSECOND_URL&lt;/code&gt; are expected to have the following formats:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&#34;single&#34;: Depending on the socket type defined, either a single hostname:port pair or a unix domain socket reference.&lt;/li&gt; &#xA; &lt;li&gt;&#34;sentinel&#34;: A comma separated list with the first string as the master name of the sentinel cluster followed by hostname:port pairs. The list size should be &amp;gt;= 2. The first item is the name of the master and the rest are the sentinels.&lt;/li&gt; &#xA; &lt;li&gt;&#34;cluster&#34;: A comma separated list of hostname:port pairs with all the nodes in the cluster.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Pipelining&lt;/h2&gt; &#xA;&lt;p&gt;By default, for each request, ratelimit will pick up a connection from pool, write multiple redis commands in a single write then reads their responses in a single read. This reduces network delay.&lt;/p&gt; &#xA;&lt;p&gt;For high throughput scenarios, ratelimit also support &lt;a href=&#34;https://github.com/mediocregopher/radix/raw/v3.5.1/pool.go#L238&#34;&gt;implicit pipelining&lt;/a&gt; . It can be configured using the following environment variables:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_PIPELINE_WINDOW&lt;/code&gt; &amp;amp; &lt;code&gt;REDIS_PERSECOND_PIPELINE_WINDOW&lt;/code&gt;: sets the duration after which internal pipelines will be flushed. If window is zero then implicit pipelining will be disabled.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_PIPELINE_LIMIT&lt;/code&gt; &amp;amp; &lt;code&gt;REDIS_PERSECOND_PIPELINE_LIMIT&lt;/code&gt;: sets maximum number of commands that can be pipelined before flushing. If limit is zero then no limit will be used and pipelines will only be limited by the specified time window.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;code&gt;implicit pipelining&lt;/code&gt; is disabled by default. To enable it, you can use default values &lt;a href=&#34;https://github.com/mediocregopher/radix/raw/v3.5.1/pool.go#L278&#34;&gt;used by radix&lt;/a&gt; and tune for the optimal value.&lt;/p&gt; &#xA;&lt;h2&gt;One Redis Instance&lt;/h2&gt; &#xA;&lt;p&gt;To configure one Redis instance use the following environment variables:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_SOCKET_TYPE&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_URL&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_POOL_SIZE&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_TYPE&lt;/code&gt; (optional)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This setup will use the same Redis server for all limits.&lt;/p&gt; &#xA;&lt;h2&gt;Two Redis Instances&lt;/h2&gt; &#xA;&lt;p&gt;To configure two Redis instances use the following environment variables:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_SOCKET_TYPE&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_URL&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_POOL_SIZE&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_PERSECOND&lt;/code&gt;: set this to &lt;code&gt;&#34;true&#34;&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_PERSECOND_SOCKET_TYPE&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_PERSECOND_URL&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_PERSECOND_POOL_SIZE&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_PERSECOND_TYPE&lt;/code&gt; (optional)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This setup will use the Redis server configured with the &lt;code&gt;_PERSECOND_&lt;/code&gt; vars for per second limits, and the other Redis server for all other limits.&lt;/p&gt; &#xA;&lt;h2&gt;Health Checking for Redis Active Connection&lt;/h2&gt; &#xA;&lt;p&gt;To configure whether to return health check failure if there is no active redis connection&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;REDIS_HEALTH_CHECK_ACTIVE_CONNECTION&lt;/code&gt; : (default is &#34;false&#34;)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Memcache&lt;/h1&gt; &#xA;&lt;p&gt;Experimental Memcache support has been added as an alternative to Redis in v1.5.&lt;/p&gt; &#xA;&lt;p&gt;To configure a Memcache instance use the following environment variables instead of the Redis variables:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;MEMCACHE_HOST_PORT=&lt;/code&gt;: a comma separated list of hostname:port pairs for memcache nodes (mutually exclusive with &lt;code&gt;MEMCACHE_SRV&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MEMCACHE_SRV=&lt;/code&gt;: an SRV record to lookup hosts from (mutually exclusive with &lt;code&gt;MEMCACHE_HOST_PORT&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MEMCACHE_SRV_REFRESH=0&lt;/code&gt;: refresh the list of hosts every n seconds, if 0 no refreshing will happen, supports duration suffixes: &#34;ns&#34;, &#34;us&#34; (or &#34;µs&#34;), &#34;ms&#34;, &#34;s&#34;, &#34;m&#34;, &#34;h&#34;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;BACKEND_TYPE=memcache&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CACHE_KEY_PREFIX&lt;/code&gt;: a string to prepend to all cache keys&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MEMCACHE_MAX_IDLE_CONNS=2&lt;/code&gt;: the maximum number of idle TCP connections per memcache node, &lt;code&gt;2&lt;/code&gt; is the default of the underlying library&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MEMCACHE_TLS&lt;/code&gt;: set to &lt;code&gt;&#34;true&#34;&lt;/code&gt; to connect to the server with TLS.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MEMCACHE_TLS_CLIENT_CERT&lt;/code&gt;, &lt;code&gt;MEMCACHE_TLS_CLIENT_KEY&lt;/code&gt;, and &lt;code&gt;MEMCACHE_TLS_CACERT&lt;/code&gt; to provide files that parameterize the memcache client TLS connection configuration.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MEMCACHE_TLS_SKIP_HOSTNAME_VERIFICATION&lt;/code&gt; set to &lt;code&gt;&#34;true&#34;&lt;/code&gt; will skip hostname verification in environments where the certificate has an invalid hostname.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;With memcache mode increments will happen asynchronously, so it&#39;s technically possible for a client to exceed quota briefly if multiple requests happen at exactly the same time.&lt;/p&gt; &#xA;&lt;p&gt;Note that Memcache has a max key length of 250 characters, so operations referencing very long descriptors will fail. Descriptors sent to Memcache should not contain whitespaces or control characters.&lt;/p&gt; &#xA;&lt;p&gt;When using multiple memcache nodes in &lt;code&gt;MEMCACHE_HOST_PORT=&lt;/code&gt;, one should provide the identical list of memcache nodes to all ratelimiter instances to ensure that a particular cache key is always hashed to the same memcache node.&lt;/p&gt; &#xA;&lt;h1&gt;Custom headers&lt;/h1&gt; &#xA;&lt;p&gt;Ratelimit service can be configured to return custom headers with the ratelimit information. It will populate the response_headers_to_add as part of the &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-v3/service/ratelimit/v3/rls.proto#service-ratelimit-v3-ratelimitresponse&#34;&gt;RateLimitResponse&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The following environment variables control the custom response feature:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;LIMIT_RESPONSE_HEADERS_ENABLED&lt;/code&gt; - Enables the custom response headers&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;LIMIT_LIMIT_HEADER&lt;/code&gt; - The default value is &#34;RateLimit-Limit&#34;, setting the environment variable will specify an alternative header name&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;LIMIT_REMAINING_HEADER&lt;/code&gt; - The default value is &#34;RateLimit-Remaining&#34;, setting the environment variable will specify an alternative header name&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;LIMIT_RESET_HEADER&lt;/code&gt; - The default value is &#34;RateLimit-Reset&#34;, setting the environment variable will specify an alternative header name&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Tracing&lt;/h1&gt; &#xA;&lt;p&gt;Ratelimit service supports exporting spans in OLTP format. See &lt;a href=&#34;https://opentelemetry.io/&#34;&gt;OpenTelemetry&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;The following environment variables control the tracing feature:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;TRACING_ENABLED&lt;/code&gt; - Enables the tracing feature. Only &#34;true&#34; and &#34;false&#34;(default) are allowed in this field.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;TRACING_EXPORTER_PROTOCOL&lt;/code&gt; - Controls the protocol of exporter in tracing feature. Only &#34;http&#34;(default) and &#34;grpc&#34; are allowed in this field.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;TRACING_SERVICE_NAME&lt;/code&gt; - Controls the service name appears in tracing span. The default value is &#34;RateLimit&#34;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;TRACING_SERVICE_NAMESPACE&lt;/code&gt; - Controls the service namespace appears in tracing span. The default value is empty.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;TRACING_SERVICE_INSTANCE_ID&lt;/code&gt; - Controls the service instance id appears in tracing span. It is recommended to put the pod name or container name in this field. The default value is a randomly generated version 4 uuid if unspecified.&lt;/li&gt; &#xA; &lt;li&gt;Other fields in &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-specification/raw/v1.8.0/specification/protocol/exporter.md&#34;&gt;OTLP Exporter Documentation&lt;/a&gt;. These section needs to be correctly configured in order to enable the exporter to export span to the correct destination.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;TRACING_SAMPLING_RATE&lt;/code&gt; - Controls the sampling rate, defaults to 1 which means always sample. Valid range: 0.0-1.0. For high volume services, adjusting the sampling rate is recommended.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You may use the following commands to quickly setup a openTelemetry collector together with a Jaeger all-in-one binary for quickstart:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --name otlp -d -p 4318 -p 4317 -v examples/otlp-collector:/tmp/otlp-collector otel/opentelemetry-collector:0.48.0 -- --config /tmp/otlp-collector/config.yaml&#xA;otelcol-contrib --config examples/otlp-collector/config.yaml&#xA;&#xA;docker run -d --name jaeger -p 16686:16686 -p 14250:14250 jaegertracing/all-in-one:1.33&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;mTLS&lt;/h1&gt; &#xA;&lt;p&gt;Ratelimit supports mTLS when Envoy sends requests to the service.&lt;/p&gt; &#xA;&lt;p&gt;The following environment variables control the mTLS feature:&lt;/p&gt; &#xA;&lt;p&gt;The following variables can be set to enable mTLS on the Ratelimit service.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;GRPC_SERVER_USE_TLS&lt;/code&gt; - Enables gprc connections to server over TLS&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;GRPC_SERVER_TLS_CERT&lt;/code&gt; - Path to the file containing the server cert chain&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;GRPC_SERVER_TLS_KEY&lt;/code&gt; - Path to the file containing the server private key&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;GRPC_CLIENT_TLS_CACERT&lt;/code&gt; - Path to the file containing the client CA certificate.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;GRPC_CLIENT_TLS_SAN&lt;/code&gt; - (Optional) DNS Name to validate from the client cert during mTLS auth&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;In the envoy config use, add the &lt;code&gt;transport_socket&lt;/code&gt; section to the ratelimit service cluster config&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;&#34;name&#34;: &#34;ratelimit&#34;&#xA;&#34;transport_socket&#34;:&#xA;  &#34;name&#34;: &#34;envoy.transport_sockets.tls&#34;&#xA;  &#34;typed_config&#34;:&#xA;    &#34;@type&#34;: &#34;type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext&#34;&#xA;    &#34;common_tls_context&#34;:&#xA;      &#34;tls_certificates&#34;:&#xA;        - &#34;certificate_chain&#34;:&#xA;            &#34;filename&#34;: &#34;/opt/envoy/tls/ratelimit-client-cert.pem&#34;&#xA;          &#34;private_key&#34;:&#xA;            &#34;filename&#34;: &#34;/opt/envoy/tls/ratelimit-client-key.pem&#34;&#xA;      &#34;validation_context&#34;:&#xA;        &#34;match_subject_alt_names&#34;:&#xA;          - &#34;exact&#34;: &#34;ratelimit.server.dnsname&#34;&#xA;        &#34;trusted_ca&#34;:&#xA;          &#34;filename&#34;: &#34;/opt/envoy/tls/ratelimit-server-ca.pem&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Contact&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/envoy-announce&#34;&gt;envoy-announce&lt;/a&gt;: Low frequency mailing list where we will email announcements only.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/envoy-users&#34;&gt;envoy-users&lt;/a&gt;: General user discussion. Please add &lt;code&gt;[ratelimit]&lt;/code&gt; to the email subject.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/envoy-dev&#34;&gt;envoy-dev&lt;/a&gt;: Envoy developer discussion (APIs, feature design, etc.). Please add &lt;code&gt;[ratelimit]&lt;/code&gt; to the email subject.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://envoyproxy.slack.com/&#34;&gt;Slack&lt;/a&gt;: Slack, to get invited go &lt;a href=&#34;http://envoyslack.cncf.io&#34;&gt;here&lt;/a&gt;. We have the IRC/XMPP gateways enabled if you prefer either of those. Once an account is created, connection instructions for IRC/XMPP can be found &lt;a href=&#34;https://envoyproxy.slack.com/account/gateways&#34;&gt;here&lt;/a&gt;. The &lt;code&gt;#ratelimit-users&lt;/code&gt; channel is used for discussions about the ratelimit service.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>