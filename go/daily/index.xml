<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-29T01:34:44Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>prometheus/client_golang</title>
    <updated>2022-10-29T01:34:44Z</updated>
    <id>tag:github.com,2022-10-29:/prometheus/client_golang</id>
    <link href="https://github.com/prometheus/client_golang" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Prometheus instrumentation library for Go applications&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Prometheus Go client library&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://circleci.com/gh/prometheus/client_golang/tree/main&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/prometheus/client_golang/tree/main.svg?style=svg&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/prometheus/client_golang&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/prometheus/client_golang&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pkg.go.dev/github.com/prometheus/client_golang&#34;&gt;&lt;img src=&#34;https://pkg.go.dev/badge/github.com/prometheus/client_golang.svg?sanitize=true&#34; alt=&#34;Go Reference&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://slack.cncf.io/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/join%20slack-%23prometheus--client_golang-brightgreen.svg?sanitize=true&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is the &lt;a href=&#34;http://golang.org&#34;&gt;Go&lt;/a&gt; client library for &lt;a href=&#34;http://prometheus.io&#34;&gt;Prometheus&lt;/a&gt;. It has two separate parts, one for instrumenting application code, and one for creating clients that talk to the Prometheus HTTP API.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;This library requires Go1.17 or later.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Important note about releases and stability&lt;/h2&gt; &#xA;&lt;p&gt;This repository generally follows &lt;a href=&#34;https://semver.org/&#34;&gt;Semantic Versioning&lt;/a&gt;. However, the API client in prometheus/client_golang/api/… is still considered experimental. Breaking changes of the API client will &lt;em&gt;not&lt;/em&gt; trigger a new major release. The same is true for selected other new features explicitly marked as &lt;strong&gt;EXPERIMENTAL&lt;/strong&gt; in CHANGELOG.md.&lt;/p&gt; &#xA;&lt;p&gt;Features that require breaking changes in the stable parts of the repository are being batched up and tracked in the &lt;a href=&#34;https://github.com/prometheus/client_golang/milestone/2&#34;&gt;v2 milestone&lt;/a&gt;. The v2 development happens in a &lt;a href=&#34;https://github.com/prometheus/client_golang/tree/dev-v2&#34;&gt;separate branch&lt;/a&gt; for the time being. v2 releases off that branch will happen once sufficient stability is reached. In view of the widespread use of this repository, v1 and v2 will coexist for a while to enable a convenient transition.&lt;/p&gt; &#xA;&lt;h2&gt;Instrumenting applications&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://gocover.io/github.com/prometheus/client_golang/prometheus&#34;&gt;&lt;img src=&#34;http://gocover.io/_badge/github.com/prometheus/client_golang/prometheus&#34; alt=&#34;code-coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pkg.go.dev/github.com/prometheus/client_golang/prometheus&#34;&gt;&lt;img src=&#34;https://pkg.go.dev/badge/github.com/prometheus/client_golang/prometheus.svg?sanitize=true&#34; alt=&#34;Go Reference&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/prometheus/client_golang/tree/main/prometheus&#34;&gt;&lt;code&gt;prometheus&lt;/code&gt; directory&lt;/a&gt; contains the instrumentation library. See the &lt;a href=&#34;https://prometheus.io/docs/guides/go-application/&#34;&gt;guide&lt;/a&gt; on the Prometheus website to learn more about instrumenting applications.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/prometheus/client_golang/tree/main/examples&#34;&gt;&lt;code&gt;examples&lt;/code&gt; directory&lt;/a&gt; contains simple examples of instrumented code.&lt;/p&gt; &#xA;&lt;h2&gt;Client for the Prometheus HTTP API&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://gocover.io/github.com/prometheus/client_golang/api/prometheus/v1&#34;&gt;&lt;img src=&#34;http://gocover.io/_badge/github.com/prometheus/client_golang/api/prometheus/v1&#34; alt=&#34;code-coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pkg.go.dev/github.com/prometheus/client_golang/api&#34;&gt;&lt;img src=&#34;https://pkg.go.dev/badge/github.com/prometheus/client_golang/api.svg?sanitize=true&#34; alt=&#34;Go Reference&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/prometheus/client_golang/tree/main/api/prometheus&#34;&gt;&lt;code&gt;api/prometheus&lt;/code&gt; directory&lt;/a&gt; contains the client for the &lt;a href=&#34;http://prometheus.io/docs/querying/api/&#34;&gt;Prometheus HTTP API&lt;/a&gt;. It allows you to write Go applications that query time series data from a Prometheus server. It is still in alpha stage.&lt;/p&gt; &#xA;&lt;h2&gt;Where is &lt;code&gt;model&lt;/code&gt;, &lt;code&gt;extraction&lt;/code&gt;, and &lt;code&gt;text&lt;/code&gt;?&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;model&lt;/code&gt; packages has been moved to &lt;a href=&#34;https://github.com/prometheus/common/tree/main/model&#34;&gt;&lt;code&gt;prometheus/common/model&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;extraction&lt;/code&gt; and &lt;code&gt;text&lt;/code&gt; packages are now contained in &lt;a href=&#34;https://github.com/prometheus/common/tree/main/expfmt&#34;&gt;&lt;code&gt;prometheus/common/expfmt&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing and community&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/prometheus/client_golang/main/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt; and the &lt;a href=&#34;http://prometheus.io/community/&#34;&gt;Community section&lt;/a&gt; of the homepage.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;clint_golang&lt;/code&gt; community is also present on the CNCF Slack &lt;code&gt;#prometheus-client_golang&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>containerd/containerd</title>
    <updated>2022-10-29T01:34:44Z</updated>
    <id>tag:github.com,2022-10-29:/containerd/containerd</id>
    <link href="https://github.com/containerd/containerd" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An open and reliable container runtime&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cncf/artwork/master/projects/containerd/horizontal/color/containerd-horizontal-color.png#gh-light-mode-only&#34; alt=&#34;containerd banner light mode&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cncf/artwork/master/projects/containerd/horizontal/white/containerd-horizontal-white.png#gh-dark-mode-only&#34; alt=&#34;containerd banner dark mode&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pkg.go.dev/github.com/containerd/containerd&#34;&gt;&lt;img src=&#34;https://pkg.go.dev/badge/github.com/containerd/containerd&#34; alt=&#34;PkgGoDev&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/containerd/containerd/actions?query=workflow%3ACI&#34;&gt;&lt;img src=&#34;https://github.com/containerd/containerd/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/containerd/containerd/actions?query=workflow%3ANightly&#34;&gt;&lt;img src=&#34;https://github.com/containerd/containerd/workflows/Nightly/badge.svg?sanitize=true&#34; alt=&#34;Nightlies&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/containerd/containerd&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/containerd/containerd&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://bestpractices.coreinfrastructure.org/projects/1271&#34;&gt;&lt;img src=&#34;https://bestpractices.coreinfrastructure.org/projects/1271/badge&#34; alt=&#34;CII Best Practices&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;containerd is an industry-standard container runtime with an emphasis on simplicity, robustness and portability. It is available as a daemon for Linux and Windows, which can manage the complete container lifecycle of its host system: image transfer and storage, container execution and supervision, low-level storage and network attachments, etc.&lt;/p&gt; &#xA;&lt;p&gt;containerd is a member of CNCF with &lt;a href=&#34;https://landscape.cncf.io/?selected=containerd&#34;&gt;&#39;graduated&#39;&lt;/a&gt; status.&lt;/p&gt; &#xA;&lt;p&gt;containerd is designed to be embedded into a larger system, rather than being used directly by developers or end-users.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/historical/design/architecture.png&#34; alt=&#34;architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Announcements&lt;/h2&gt; &#xA;&lt;h3&gt;Hello Kubernetes v1.24!&lt;/h3&gt; &#xA;&lt;p&gt;The containerd project would like to announce containerd &lt;a href=&#34;https://github.com/containerd/containerd/releases/tag/v1.6.4&#34;&gt;v1.6.4&lt;/a&gt;. While other prior releases are supported, this latest release and the containerd &lt;a href=&#34;https://github.com/containerd/containerd/releases/tag/v1.5.11&#34;&gt;v1.5.11&lt;/a&gt; release are recommended for Kubernetes v1.24.&lt;/p&gt; &#xA;&lt;p&gt;We felt it important to announce this, particularly in view of &lt;a href=&#34;https://kubernetes.io/blog/2022/05/03/dockershim-historical-context/&#34;&gt;the dockershim removal from this release of Kubernetes&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It should be noted here that moving to CRI integrations has been in the plan for many years. &lt;code&gt;containerd&lt;/code&gt; began as part of &lt;code&gt;Docker&lt;/code&gt; and was donated to &lt;code&gt;CNCF&lt;/code&gt;. &lt;code&gt;containerd&lt;/code&gt; remains in use today by Docker/moby/buildkit etc., and has many other &lt;a href=&#34;https://github.com/containerd/containerd/raw/main/ADOPTERS.md&#34;&gt;adopters&lt;/a&gt;. &lt;code&gt;containerd&lt;/code&gt; has a namespace that isolates use of &lt;code&gt;containerd&lt;/code&gt; from various clients/adopters. The Kubernetes namespace is appropriately named &lt;code&gt;k8s.io&lt;/code&gt;. The CRI API and &lt;code&gt;containerd&lt;/code&gt; CRI plugin project has, from the start, been an effort to reduce the impact surface for Kubernetes container runtime integration. If you can&#39;t tell, we are excited to see this come to fruition.&lt;/p&gt; &#xA;&lt;p&gt;If you have any concerns or questions, we will be here to answer them in &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/#communication&#34;&gt;issues, discussions, and/or on slack&lt;/a&gt;. Below you will find information / detail about our &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/#cri&#34;&gt;CRI Integration&lt;/a&gt; implementation.&lt;/p&gt; &#xA;&lt;p&gt;For containerd users already on v1.6.0-v1.6.3, there are known issues addressed by &lt;a href=&#34;https://github.com/containerd/containerd/releases/tag/v1.6.4&#34;&gt;v1.6.4&lt;/a&gt;. The issues are primarily related to &lt;a href=&#34;https://github.com/kubernetes/website/raw/dev-1.24/content/en/docs/tasks/administer-cluster/migrating-from-dockershim/troubleshooting-cni-plugin-related-errors.md&#34;&gt;CNI setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Now Recruiting&lt;/h3&gt; &#xA;&lt;p&gt;We are a large inclusive OSS project that is welcoming help of any kind shape or form:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Documentation help is needed to make the product easier to consume and extend.&lt;/li&gt; &#xA; &lt;li&gt;We need OSS community outreach / organizing help to get the word out; manage and create messaging and educational content; and to help with social media, community forums/groups, and google groups.&lt;/li&gt; &#xA; &lt;li&gt;We are actively inviting new &lt;a href=&#34;https://github.com/containerd/project/raw/main/GOVERNANCE.md#security-advisors&#34;&gt;security advisors&lt;/a&gt; to join the team.&lt;/li&gt; &#xA; &lt;li&gt;New sub-projects are being created, core and non-core that could use additional development help.&lt;/li&gt; &#xA; &lt;li&gt;Each of the &lt;a href=&#34;https://github.com/containerd&#34;&gt;containerd projects&lt;/a&gt; has a list of issues currently being worked on or that need help resolving. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;If the issue has not already been assigned to someone, or has not made recent progress and you are interested, please inquire.&lt;/li&gt; &#xA;   &lt;li&gt;If you are interested in starting with a smaller / beginner level issue, look for issues with an &lt;code&gt;exp/beginner&lt;/code&gt; tag, for example &lt;a href=&#34;https://github.com/containerd/containerd/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%2Fbeginner&#34;&gt;containerd/containerd beginner issues.&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;See our documentation on &lt;a href=&#34;https://containerd.io&#34;&gt;containerd.io&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/ops.md&#34;&gt;for ops and admins&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/namespaces.md&#34;&gt;namespaces&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/client-opts.md&#34;&gt;client options&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See how to build containerd from source at &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/BUILDING.md&#34;&gt;BUILDING&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you are interested in trying out containerd see our example at &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/getting-started.md&#34;&gt;Getting Started&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Nightly builds&lt;/h2&gt; &#xA;&lt;p&gt;There are nightly builds available for download &lt;a href=&#34;https://github.com/containerd/containerd/actions?query=workflow%3ANightly&#34;&gt;here&lt;/a&gt;. Binaries are generated from &lt;code&gt;main&lt;/code&gt; branch every night for &lt;code&gt;Linux&lt;/code&gt; and &lt;code&gt;Windows&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please be aware: nightly builds might have critical bugs, it&#39;s not recommended for use in production and no support provided.&lt;/p&gt; &#xA;&lt;h2&gt;Runtime Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Runtime requirements for containerd are very minimal. Most interactions with the Linux and Windows container feature sets are handled via &lt;a href=&#34;https://github.com/opencontainers/runc&#34;&gt;runc&lt;/a&gt; and/or OS-specific libraries (e.g. &lt;a href=&#34;https://github.com/Microsoft/hcsshim&#34;&gt;hcsshim&lt;/a&gt; for Microsoft). The current required version of &lt;code&gt;runc&lt;/code&gt; is described in &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/RUNC.md&#34;&gt;RUNC.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There are specific features used by containerd core code and snapshotters that will require a minimum kernel version on Linux. With the understood caveat of distro kernel versioning, a reasonable starting point for Linux is a minimum 4.x kernel version.&lt;/p&gt; &#xA;&lt;p&gt;The overlay filesystem snapshotter, used by default, uses features that were finalized in the 4.x kernel series. If you choose to use btrfs, there may be more flexibility in kernel version (minimum recommended is 3.18), but will require the btrfs kernel module and btrfs tools to be installed on your Linux distribution.&lt;/p&gt; &#xA;&lt;p&gt;To use Linux checkpoint and restore features, you will need &lt;code&gt;criu&lt;/code&gt; installed on your system. See more details in &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/#checkpoint-and-restore&#34;&gt;Checkpoint and Restore&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Build requirements for developers are listed in &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/BUILDING.md&#34;&gt;BUILDING&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Registries&lt;/h2&gt; &#xA;&lt;p&gt;Any registry which is compliant with the &lt;a href=&#34;https://github.com/opencontainers/distribution-spec&#34;&gt;OCI Distribution Specification&lt;/a&gt; is supported by containerd.&lt;/p&gt; &#xA;&lt;p&gt;For configuring registries, see &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/hosts.md&#34;&gt;registry host configuration documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt;Client&lt;/h3&gt; &#xA;&lt;p&gt;containerd offers a full client package to help you integrate containerd into your platform.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;&#xA;import (&#xA;  &#34;context&#34;&#xA;&#xA;  &#34;github.com/containerd/containerd&#34;&#xA;  &#34;github.com/containerd/containerd/cio&#34;&#xA;  &#34;github.com/containerd/containerd/namespaces&#34;&#xA;)&#xA;&#xA;&#xA;func main() {&#xA;&#x9;client, err := containerd.New(&#34;/run/containerd/containerd.sock&#34;)&#xA;&#x9;defer client.Close()&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Namespaces&lt;/h3&gt; &#xA;&lt;p&gt;Namespaces allow multiple consumers to use the same containerd without conflicting with each other. It has the benefit of sharing content but still having separation with containers and images.&lt;/p&gt; &#xA;&lt;p&gt;To set a namespace for requests to the API:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;context = context.Background()&#xA;// create a context for docker&#xA;docker = namespaces.WithNamespace(context, &#34;docker&#34;)&#xA;&#xA;containerd, err := client.NewContainer(docker, &#34;id&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To set a default namespace on the client:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;client, err := containerd.New(address, containerd.WithDefaultNamespace(&#34;docker&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Distribution&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// pull an image&#xA;image, err := client.Pull(context, &#34;docker.io/library/redis:latest&#34;)&#xA;&#xA;// push an image&#xA;err := client.Push(context, &#34;docker.io/library/redis:latest&#34;, image.Target())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Containers&lt;/h3&gt; &#xA;&lt;p&gt;In containerd, a container is a metadata object. Resources such as an OCI runtime specification, image, root filesystem, and other metadata can be attached to a container.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;redis, err := client.NewContainer(context, &#34;redis-master&#34;)&#xA;defer redis.Delete(context)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;OCI Runtime Specification&lt;/h3&gt; &#xA;&lt;p&gt;containerd fully supports the OCI runtime specification for running containers. We have built in functions to help you generate runtime specifications based on images as well as custom parameters.&lt;/p&gt; &#xA;&lt;p&gt;You can specify options when creating a container about how to modify the specification.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;redis, err := client.NewContainer(context, &#34;redis-master&#34;, containerd.WithNewSpec(oci.WithImageConfig(image)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Root Filesystems&lt;/h3&gt; &#xA;&lt;p&gt;containerd allows you to use overlay or snapshot filesystems with your containers. It comes with built in support for overlayfs and btrfs.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// pull an image and unpack it into the configured snapshotter&#xA;image, err := client.Pull(context, &#34;docker.io/library/redis:latest&#34;, containerd.WithPullUnpack)&#xA;&#xA;// allocate a new RW root filesystem for a container based on the image&#xA;redis, err := client.NewContainer(context, &#34;redis-master&#34;,&#xA;&#x9;containerd.WithNewSnapshot(&#34;redis-rootfs&#34;, image),&#xA;&#x9;containerd.WithNewSpec(oci.WithImageConfig(image)),&#xA;)&#xA;&#xA;// use a readonly filesystem with multiple containers&#xA;for i := 0; i &amp;lt; 10; i++ {&#xA;&#x9;id := fmt.Sprintf(&#34;id-%s&#34;, i)&#xA;&#x9;container, err := client.NewContainer(ctx, id,&#xA;&#x9;&#x9;containerd.WithNewSnapshotView(id, image),&#xA;&#x9;&#x9;containerd.WithNewSpec(oci.WithImageConfig(image)),&#xA;&#x9;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Tasks&lt;/h3&gt; &#xA;&lt;p&gt;Taking a container object and turning it into a runnable process on a system is done by creating a new &lt;code&gt;Task&lt;/code&gt; from the container. A task represents the runnable object within containerd.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// create a new task&#xA;task, err := redis.NewTask(context, cio.NewCreator(cio.WithStdio))&#xA;defer task.Delete(context)&#xA;&#xA;// the task is now running and has a pid that can be used to setup networking&#xA;// or other runtime settings outside of containerd&#xA;pid := task.Pid()&#xA;&#xA;// start the redis-server process inside the container&#xA;err := task.Start(context)&#xA;&#xA;// wait for the task to exit and get the exit status&#xA;status, err := task.Wait(context)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Checkpoint and Restore&lt;/h3&gt; &#xA;&lt;p&gt;If you have &lt;a href=&#34;https://criu.org/Main_Page&#34;&gt;criu&lt;/a&gt; installed on your machine you can checkpoint and restore containers and their tasks. This allows you to clone and/or live migrate containers to other machines.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// checkpoint the task then push it to a registry&#xA;checkpoint, err := task.Checkpoint(context)&#xA;&#xA;err := client.Push(context, &#34;myregistry/checkpoints/redis:master&#34;, checkpoint)&#xA;&#xA;// on a new machine pull the checkpoint and restore the redis container&#xA;checkpoint, err := client.Pull(context, &#34;myregistry/checkpoints/redis:master&#34;)&#xA;&#xA;redis, err = client.NewContainer(context, &#34;redis-master&#34;, containerd.WithNewSnapshot(&#34;redis-rootfs&#34;, checkpoint))&#xA;defer container.Delete(context)&#xA;&#xA;task, err = redis.NewTask(context, cio.NewCreator(cio.WithStdio), containerd.WithTaskCheckpoint(checkpoint))&#xA;defer task.Delete(context)&#xA;&#xA;err := task.Start(context)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Snapshot Plugins&lt;/h3&gt; &#xA;&lt;p&gt;In addition to the built-in Snapshot plugins in containerd, additional external plugins can be configured using GRPC. An external plugin is made available using the configured name and appears as a plugin alongside the built-in ones.&lt;/p&gt; &#xA;&lt;p&gt;To add an external snapshot plugin, add the plugin to containerd&#39;s config file (by default at &lt;code&gt;/etc/containerd/config.toml&lt;/code&gt;). The string following &lt;code&gt;proxy_plugin.&lt;/code&gt; will be used as the name of the snapshotter and the address should refer to a socket with a GRPC listener serving containerd&#39;s Snapshot GRPC API. Remember to restart containerd for any configuration changes to take effect.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[proxy_plugins]&#xA;  [proxy_plugins.customsnapshot]&#xA;    type = &#34;snapshot&#34;&#xA;    address =  &#34;/var/run/mysnapshotter.sock&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/PLUGINS.md&#34;&gt;PLUGINS.md&lt;/a&gt; for how to create plugins&lt;/p&gt; &#xA;&lt;h3&gt;Releases and API Stability&lt;/h3&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/RELEASES.md&#34;&gt;RELEASES.md&lt;/a&gt; for details on versioning and stability of containerd components.&lt;/p&gt; &#xA;&lt;p&gt;Downloadable 64-bit Intel/AMD binaries of all official releases are available on our &lt;a href=&#34;https://github.com/containerd/containerd/releases&#34;&gt;releases page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For other architectures and distribution support, you will find that many Linux distributions package their own containerd and provide it across several architectures, such as &lt;a href=&#34;https://launchpad.net/ubuntu/bionic/+package/containerd&#34;&gt;Canonical&#39;s Ubuntu packaging&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Enabling command auto-completion&lt;/h4&gt; &#xA;&lt;p&gt;Starting with containerd 1.4, the urfave client feature for auto-creation of bash and zsh autocompletion data is enabled. To use the autocomplete feature in a bash shell for example, source the autocomplete/ctr file in your &lt;code&gt;.bashrc&lt;/code&gt;, or manually like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ source ./contrib/autocomplete/ctr&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Distribution of &lt;code&gt;ctr&lt;/code&gt; autocomplete for bash and zsh&lt;/h4&gt; &#xA;&lt;p&gt;For bash, copy the &lt;code&gt;contrib/autocomplete/ctr&lt;/code&gt; script into &lt;code&gt;/etc/bash_completion.d/&lt;/code&gt; and rename it to &lt;code&gt;ctr&lt;/code&gt;. The &lt;code&gt;zsh_autocomplete&lt;/code&gt; file is also available and can be used similarly for zsh users.&lt;/p&gt; &#xA;&lt;p&gt;Provide documentation to users to &lt;code&gt;source&lt;/code&gt; this file into their shell if you don&#39;t place the autocomplete file in a location where it is automatically loaded for the user&#39;s shell environment.&lt;/p&gt; &#xA;&lt;h3&gt;CRI&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;cri&lt;/code&gt; is a &lt;a href=&#34;https://containerd.io/&#34;&gt;containerd&lt;/a&gt; plugin implementation of the Kubernetes &lt;a href=&#34;https://github.com/kubernetes/cri-api/raw/master/pkg/apis/runtime/v1/api.proto&#34;&gt;container runtime interface (CRI)&lt;/a&gt;. With it, you are able to use containerd as the container runtime for a Kubernetes cluster.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/cri/cri.png&#34; alt=&#34;cri&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;CRI Status&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;cri&lt;/code&gt; is a native plugin of containerd. Since containerd 1.1, the cri plugin is built into the release binaries and enabled by default.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; As of containerd 1.5, the &lt;code&gt;cri&lt;/code&gt; plugin is merged into the containerd/containerd repo. For example, the source code previously stored under &lt;a href=&#34;https://github.com/containerd/cri/tree/release/1.4/pkg&#34;&gt;&lt;code&gt;containerd/cri/pkg&lt;/code&gt;&lt;/a&gt; was moved to &lt;a href=&#34;https://github.com/containerd/containerd/tree/main/pkg/cri&#34;&gt;&lt;code&gt;containerd/containerd/pkg/cri&lt;/code&gt; package&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;The &lt;code&gt;cri&lt;/code&gt; plugin has reached GA status, representing that it is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Feature complete&lt;/li&gt; &#xA; &lt;li&gt;Works with Kubernetes 1.10 and above&lt;/li&gt; &#xA; &lt;li&gt;Passes all &lt;a href=&#34;https://github.com/kubernetes/community/raw/master/contributors/devel/sig-node/cri-validation.md&#34;&gt;CRI validation tests&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Passes all &lt;a href=&#34;https://github.com/kubernetes/community/raw/master/contributors/devel/sig-node/e2e-node-tests.md&#34;&gt;node e2e tests&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Passes all &lt;a href=&#34;https://github.com/kubernetes/community/raw/master/contributors/devel/sig-testing/e2e-tests.md&#34;&gt;e2e tests&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See results on the containerd k8s &lt;a href=&#34;https://k8s-testgrid.appspot.com/sig-node-containerd&#34;&gt;test dashboard&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Validating Your &lt;code&gt;cri&lt;/code&gt; Setup&lt;/h4&gt; &#xA;&lt;p&gt;A Kubernetes incubator project, &lt;a href=&#34;https://github.com/kubernetes-sigs/cri-tools&#34;&gt;cri-tools&lt;/a&gt;, includes programs for exercising CRI implementations. More importantly, cri-tools includes the program &lt;code&gt;critest&lt;/code&gt; which is used for running &lt;a href=&#34;https://github.com/kubernetes/community/raw/master/contributors/devel/sig-node/cri-validation.md&#34;&gt;CRI Validation Testing&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;CRI Guides&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/contrib/ansible/README.md&#34;&gt;Installing with Ansible and Kubeadm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/cri/installation.md&#34;&gt;For Non-Ansible Users, Preforming a Custom Installation Using the Release Tarball and Kubeadm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/cri/testing.md&#34;&gt;CRI Plugin Testing Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/cri/crictl.md&#34;&gt;Debugging Pods, Containers, and Images with &lt;code&gt;crictl&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/cri/config.md&#34;&gt;Configuring &lt;code&gt;cri&lt;/code&gt; Plugins&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/containerd/containerd/raw/main/docs/man/containerd-config.8.md&#34;&gt;Configuring containerd&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Communication&lt;/h3&gt; &#xA;&lt;p&gt;For async communication and long running discussions please use issues and pull requests on the github repo. This will be the best place to discuss design and implementation.&lt;/p&gt; &#xA;&lt;p&gt;For sync communication catch us in the &lt;code&gt;#containerd&lt;/code&gt; and &lt;code&gt;#containerd-dev&lt;/code&gt; slack channels on Cloud Native Computing Foundation&#39;s (CNCF) slack - &lt;code&gt;cloud-native.slack.com&lt;/code&gt;. Everyone is welcome to join and chat. &lt;a href=&#34;https://slack.cncf.io&#34;&gt;Get Invite to CNCF slack.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Security audit&lt;/h3&gt; &#xA;&lt;p&gt;A third party security audit was performed by Cure53 in 4Q2018; the &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/docs/SECURITY_AUDIT.pdf&#34;&gt;full report&lt;/a&gt; is available in our docs/ directory.&lt;/p&gt; &#xA;&lt;h3&gt;Reporting security issues&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;If you are reporting a security issue, please reach out discreetly at &lt;a href=&#34;mailto:security@containerd.io&#34;&gt;security@containerd.io&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Licenses&lt;/h2&gt; &#xA;&lt;p&gt;The containerd codebase is released under the &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;. The README.md file, and files in the &#34;docs&#34; folder are licensed under the Creative Commons Attribution 4.0 International License. You may obtain a copy of the license, titled CC-BY-4.0, at &lt;a href=&#34;http://creativecommons.org/licenses/by/4.0/&#34;&gt;http://creativecommons.org/licenses/by/4.0/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Project details&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;containerd&lt;/strong&gt; is the primary open source project within the broader containerd GitHub organization. However, all projects within the repo have common maintainership, governance, and contributing guidelines which are stored in a &lt;code&gt;project&lt;/code&gt; repository commonly for all containerd projects.&lt;/p&gt; &#xA;&lt;p&gt;Please find all these core project documents, including the:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/containerd/project/raw/main/GOVERNANCE.md&#34;&gt;Project governance&lt;/a&gt;,&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/containerd/project/raw/main/MAINTAINERS&#34;&gt;Maintainers&lt;/a&gt;,&lt;/li&gt; &#xA; &lt;li&gt;and &lt;a href=&#34;https://github.com/containerd/project/raw/main/CONTRIBUTING.md&#34;&gt;Contributing guidelines&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;information in our &lt;a href=&#34;https://github.com/containerd/project&#34;&gt;&lt;code&gt;containerd/project&lt;/code&gt;&lt;/a&gt; repository.&lt;/p&gt; &#xA;&lt;h2&gt;Adoption&lt;/h2&gt; &#xA;&lt;p&gt;Interested to see who is using containerd? Are you using containerd in a project? Please add yourself via pull request to our &lt;a href=&#34;https://raw.githubusercontent.com/containerd/containerd/main/ADOPTERS.md&#34;&gt;ADOPTERS.md&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kcp-dev/kcp</title>
    <updated>2022-10-29T01:34:44Z</updated>
    <id>tag:github.com,2022-10-29:/kcp-dev/kcp</id>
    <link href="https://github.com/kcp-dev/kcp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;kcp is a Kubernetes-like control plane for workloads on many clusters&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img alt=&#34;Logo&#34; width=&#34;196px&#34; align=&#34;left&#34; src=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/contrib/logo/blue-green.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;kcp&lt;/h1&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;kcp is a Kubernetes-like control plane focusing on:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;strong&gt;control plane&lt;/strong&gt; for many independent, &lt;strong&gt;isolated&lt;/strong&gt; “clusters” known as &lt;strong&gt;workspaces&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Enabling API service providers to &lt;strong&gt;offer APIs centrally&lt;/strong&gt; using &lt;strong&gt;multi-tenant operators&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Easy &lt;strong&gt;API consumption&lt;/strong&gt; for users in their workspaces&lt;/li&gt; &#xA; &lt;li&gt;Flexible &lt;strong&gt;scheduling&lt;/strong&gt; of workloads to physical clusters&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Transparent movement&lt;/strong&gt; of workloads among compatible physical clusters&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Advanced deployment strategies&lt;/strong&gt; for scenarios such as affinity/anti-affinity, geographic replication, cross-cloud replication, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;kcp can be a building block for SaaS service providers who need a &lt;strong&gt;massively multi-tenant platform&lt;/strong&gt; to offer services to a large number of fully isolated tenants using Kubernetes-native APIs. The goal is to be useful to cloud providers as well as enterprise IT departments offering APIs within their company.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;A Kubernetes cluster (for local testing, consider &lt;a href=&#34;http://kind.sigs.k8s.io&#34;&gt;kind&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Download kcp&lt;/h3&gt; &#xA;&lt;p&gt;Visit our &lt;a href=&#34;https://github.com/kcp-dev/kcp/releases/latest&#34;&gt;latest release page&lt;/a&gt; and download &lt;code&gt;kcp&lt;/code&gt; and &lt;code&gt;kubectl-kcp-plugin&lt;/code&gt; that match your operating system and architecture.&lt;/p&gt; &#xA;&lt;p&gt;Extract &lt;code&gt;kcp&lt;/code&gt; and &lt;code&gt;kubectl-kcp-plugin&lt;/code&gt; and place all the files in the &lt;code&gt;bin&lt;/code&gt; directories somewhere in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Start kcp&lt;/h3&gt; &#xA;&lt;p&gt;You can start kcp using this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kcp start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This launches kcp in the foreground. You can press &lt;code&gt;ctrl-c&lt;/code&gt; to stop it.&lt;/p&gt; &#xA;&lt;p&gt;To see a complete list of server options, run &lt;code&gt;kcp start options&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Set your KUBECONFIG&lt;/h3&gt; &#xA;&lt;p&gt;During its startup, kcp generates a kubeconfig in &lt;code&gt;.kcp/admin.kubeconfig&lt;/code&gt;. Use this to connect to kcp and display the version to confirm it&#39;s working:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ export KUBECONFIG=.kcp/admin.kubeconfig&#xA;$ kubectl version&#xA;WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.&#xA;Client Version: version.Info{Major:&#34;1&#34;, Minor:&#34;24&#34;, GitVersion:&#34;v1.24.4&#34;, GitCommit:&#34;95ee5ab382d64cfe6c28967f36b53970b8374491&#34;, GitTreeState:&#34;clean&#34;, BuildDate:&#34;2022-08-17T18:46:11Z&#34;, GoVersion:&#34;go1.19&#34;, Compiler:&#34;gc&#34;, Platform:&#34;darwin/amd64&#34;}&#xA;Kustomize Version: v4.5.4&#xA;Server Version: version.Info{Major:&#34;1&#34;, Minor:&#34;24&#34;, GitVersion:&#34;v1.24.3+kcp-v0.8.0&#34;, GitCommit:&#34;41863897&#34;, GitTreeState:&#34;clean&#34;, BuildDate:&#34;2022-09-02T18:10:37Z&#34;, GoVersion:&#34;go1.18.5&#34;, Compiler:&#34;gc&#34;, Platform:&#34;darwin/amd64&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Configure kcp to sync to your cluster&lt;/h3&gt; &#xA;&lt;p&gt;kcp can&#39;t run pods by itself - it needs at least one physical cluster for that. For this example, we&#39;ll be using a local &lt;code&gt;kind&lt;/code&gt; cluster.&lt;/p&gt; &#xA;&lt;p&gt;Run the following command to tell kcp about the &lt;code&gt;kind&lt;/code&gt; cluster (replace the syncer image tag as needed):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl kcp workload sync kind --syncer-image ghcr.io/kcp-dev/kcp/syncer:v0.8.0 -o syncer-kind-main.yaml&#xA;Creating synctarget &#34;kind&#34;&#xA;Creating service account &#34;kcp-syncer-kind-25coemaz&#34;&#xA;Creating cluster role &#34;kcp-syncer-kind-25coemaz&#34; to give service account &#34;kcp-syncer-kind-25coemaz&#34;&#xA;&#xA; 1. write and sync access to the synctarget &#34;kcp-syncer-kind-25coemaz&#34;&#xA; 2. write access to apiresourceimports.&#xA;&#xA;Creating or updating cluster role binding &#34;kcp-syncer-kind-25coemaz&#34; to bind service account &#34;kcp-syncer-kind-25coemaz&#34; to cluster role &#34;kcp-syncer-kind-25coemaz&#34;.&#xA;&#xA;Wrote physical cluster manifest to syncer-kind-main.yaml for namespace &#34;kcp-syncer-kind-25coemaz&#34;. Use&#xA;&#xA;  KUBECONFIG=&amp;lt;pcluster-config&amp;gt; kubectl apply -f &#34;syncer-kind-main.yaml&#34;&#xA;&#xA;to apply it. Use&#xA;&#xA;  KUBECONFIG=&amp;lt;pcluster-config&amp;gt; kubectl get deployment -n &#34;kcp-syncer-kind-25coemaz&#34; kcp-syncer-kind-25coemaz&#xA;&#xA;to verify the syncer pod is running.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, we need to install the syncer pod on our &lt;code&gt;kind&lt;/code&gt; cluster - this is what actually syncs content from kcp to the physical cluster. Run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ KUBECONFIG=&amp;lt;/path/to/kind/kubeconfig&amp;gt; kubectl apply -f &#34;syncer-kind-main.yaml&#34;&#xA;namespace/kcp-syncer-kind-25coemaz created&#xA;serviceaccount/kcp-syncer-kind-25coemaz created&#xA;secret/kcp-syncer-kind-25coemaz-token created&#xA;clusterrole.rbac.authorization.k8s.io/kcp-syncer-kind-25coemaz created&#xA;clusterrolebinding.rbac.authorization.k8s.io/kcp-syncer-kind-25coemaz created&#xA;secret/kcp-syncer-kind-25coemaz created&#xA;deployment.apps/kcp-syncer-kind-25coemaz created&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Create a deployment in kcp&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s create a deployment in our kcp workspace and see it get synced to our cluster:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl create deployment --image=gcr.io/kuar-demo/kuard-amd64:blue --port=8080 kuard&#xA;deployment.apps/kuard created&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once your cluster has pulled the image and started the pod, you should be able to verify the deployment is running in kcp:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ kubectl get deployments&#xA;NAME    READY   UP-TO-DATE   AVAILABLE   AGE&#xA;kuard   1/1     1            1           3s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We are still working on adding support for &lt;code&gt;kubectl logs&lt;/code&gt;, &lt;code&gt;kubectl exec&lt;/code&gt;, and &lt;code&gt;kubectl port-forward&lt;/code&gt; to kcp. For the time being, you can check directly in your cluster.&lt;/p&gt; &#xA;&lt;p&gt;kcp translates the names of namespaces in workspaces to unique names in a physical cluster. We first must get this translated name; if you&#39;re following along, your translated name might be different.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ KUBECONFIG=&amp;lt;/path/to/kind/kubeconfig&amp;gt; kubectl get pods --all-namespaces --selector app=kuard&#xA;NAMESPACE          NAME                     READY   STATUS    RESTARTS   AGE&#xA;kcp-26zq2mc2yajx   kuard-7d49c786c5-wfpcc   1/1     Running   0          4m28s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now we can e.g. check the pod logs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ KUBECONFIG=&amp;lt;/path/to/kind/kubeconfig&amp;gt; kubectl --namespace kcp-26zq2mc2yajx logs deployment/kuard | head&#xA;2022/09/07 14:04:35 Starting kuard version: v0.10.0-blue&#xA;2022/09/07 14:04:35 **********************************************************************&#xA;2022/09/07 14:04:35 * WARNING: This server may expose sensitive&#xA;2022/09/07 14:04:35 * and secret information. Be careful.&#xA;2022/09/07 14:04:35 **********************************************************************&#xA;2022/09/07 14:04:35 Config:&#xA;{&#xA;  &#34;address&#34;: &#34;:8080&#34;,&#xA;  &#34;debug&#34;: false,&#xA;  &#34;debug-sitedata-dir&#34;: &#34;./sitedata&#34;,&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Next steps&lt;/h2&gt; &#xA;&lt;p&gt;Thanks for checking out our quickstart!&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re interested in learning more about all the features kcp has to offer, please check out our additional documentation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/docs/content/en/main/concepts/concepts.md&#34;&gt;Concepts&lt;/a&gt; - a high level overview of kcp concepts&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/docs/content/en/main/concepts/workspaces.md&#34;&gt;Workspaces&lt;/a&gt; - a more thorough introduction on kcp&#39;s workspaces&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/docs/content/en/main/concepts/locations-and-scheduling.md&#34;&gt;Locations &amp;amp; scheduling&lt;/a&gt; - details on kcp&#39;s primitives that abstract over clusters&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/docs/content/en/main/concepts/syncer.md&#34;&gt;Syncer&lt;/a&gt; - information on running the kcp agent that syncs content between kcp and a physical cluster&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/docs/content/en/main/concepts/kubectl-kcp-plugin.md&#34;&gt;kubectl plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/docs/content/en/main/concepts/authorization.md&#34;&gt;Authorization&lt;/a&gt; - how kcp manages access control to workspaces and content&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/docs/content/en/main/concepts/virtual-workspaces.md&#34;&gt;Virtual workspaces&lt;/a&gt; - details on kcp&#39;s mechanism for virtual views of workspace content&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We ❤️ our contributors! If you&#39;re interested in helping us out, please head over to our &lt;a href=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/kcp-dev/kcp/main/docs/developers&#34;&gt;Developer&lt;/a&gt; guides.&lt;/p&gt; &#xA;&lt;h2&gt;Getting in touch&lt;/h2&gt; &#xA;&lt;p&gt;There are several ways to communicate with us:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://app.slack.com/client/T09NY5SBT/C021U8WSAFK&#34;&gt;&lt;code&gt;#kcp-dev&lt;/code&gt; channel&lt;/a&gt; in the &lt;a href=&#34;https://slack.k8s.io&#34;&gt;Kubernetes Slack workspace&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Our mailing lists: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://groups.google.com/g/kcp-dev&#34;&gt;kcp-dev&lt;/a&gt; for development discussions&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://groups.google.com/g/kcp-users&#34;&gt;kcp-users&lt;/a&gt; for discussions among users and potential users&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Subscribe to the &lt;a href=&#34;https://calendar.google.com/calendar/embed?src=ujjomvk4fa9fgdaem32afgl7g0%40group.calendar.google.com&#34;&gt;community calendar&lt;/a&gt; for community meetings and events &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The kcp-dev mailing list is subscribed to this calendar&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;See recordings of past community meetings on &lt;a href=&#34;https://www.youtube.com/channel/UCfP_yS5uYix0ppSbm2ltS5Q&#34;&gt;YouTube&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://github.com/kcp-dev/kcp/issues?q=is%3Aissue+is%3Aopen+label%3Acommunity-meeting&#34;&gt;upcoming&lt;/a&gt; and &lt;a href=&#34;https://github.com/kcp-dev/kcp/issues?q=is%3Aissue+label%3Acommunity-meeting+is%3Aclosed&#34;&gt;past&lt;/a&gt; community meeting agendas and notes&lt;/li&gt; &#xA; &lt;li&gt;Browse the &lt;a href=&#34;https://drive.google.com/drive/folders/1FN7AZ_Q1CQor6eK0gpuKwdGFNwYI517M?usp=sharing&#34;&gt;shared Google Drive&lt;/a&gt; to share design docs, notes, etc. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Members of the kcp-dev mailing list can view this drive&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Additional references&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oaPBYUfdFE8&#34;&gt;KubeCon EU 2021: Kubernetes as the Hybrid Cloud Control Plane Keynote - Clayton Coleman (video)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Y3Y11Aj_01I&#34;&gt;OpenShift Commons: Kubernetes as the Control Plane for the Hybrid Cloud - Clayton Coleman (video)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/FD_kY3Ey2pI&#34;&gt;TGI Kubernetes 157: Exploring kcp: apiserver without Kubernetes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=YrdAYoo-UQQ&#34;&gt;K8s SIG Architecture meeting discussing kcp - June 29, 2021&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=M4mn_LlCyzk&#34;&gt;Let&#39;s Learn kcp - A minimal Kubernetes API server with Saiyam Pathak - July 7, 2021&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>