<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-05T01:32:43Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>zhu327/gemini-openai-proxy</title>
    <updated>2024-01-05T01:32:43Z</updated>
    <id>tag:github.com,2024-01-05:/zhu327/gemini-openai-proxy</id>
    <link href="https://github.com/zhu327/gemini-openai-proxy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A proxy for converting the OpenAI API protocol to the Google Gemini Pro protocol.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gemini-OpenAI-Proxy&lt;/h1&gt; &#xA;&lt;p&gt;Gemini-OpenAI-Proxy is a proxy designed to convert the OpenAI API protocol to the Google Gemini Pro protocol. This enables seamless integration of OpenAI-powered functionalities into applications using the Gemini Pro protocol.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhu327/gemini-openai-proxy/main/#gemini-openai-proxy&#34;&gt;Gemini-OpenAI-Proxy&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhu327/gemini-openai-proxy/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhu327/gemini-openai-proxy/main/#build&#34;&gt;Build&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhu327/gemini-openai-proxy/main/#deploy&#34;&gt;Deploy&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhu327/gemini-openai-proxy/main/#usage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhu327/gemini-openai-proxy/main/#compatibility-testing&#34;&gt;Compatibility Testing&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhu327/gemini-openai-proxy/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Build&lt;/h2&gt; &#xA;&lt;p&gt;To build the Gemini-OpenAI-Proxy, follow these steps:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go build -o gemini main.go&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Deploy&lt;/h2&gt; &#xA;&lt;p&gt;We recommend deploying Gemini-OpenAI-Proxy using Docker for a straightforward setup. Follow these steps to deploy with Docker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --restart=always -it -d -p 8080:8080 --name gemini zhu327/gemini-openai-proxy:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Adjust the port mapping (e.g., &lt;code&gt;-p 8080:8080&lt;/code&gt;) as needed, and ensure that the Docker image version (&lt;code&gt;zhu327/gemini-openai-proxy:latest&lt;/code&gt;) aligns with your requirements.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Gemini-OpenAI-Proxy offers a straightforward way to integrate OpenAI functionalities into any application that supports custom OpenAI API endpoints. Follow these steps to leverage the capabilities of this proxy:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Set Up OpenAI Endpoint:&lt;/strong&gt; Ensure your application is configured to use a custom OpenAI API endpoint. Gemini-OpenAI-Proxy seamlessly works with any OpenAI-compatible endpoint.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Get Google AI Studio API Key:&lt;/strong&gt; Before using the proxy, you&#39;ll need to obtain an API key from &lt;a href=&#34;https://ai.google.dev&#34;&gt;ai.google.dev&lt;/a&gt;. Treat this API key as your OpenAI API key when interacting with Gemini-OpenAI-Proxy.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Integrate the Proxy into Your Application:&lt;/strong&gt; Modify your application&#39;s API requests to target the Gemini-OpenAI-Proxy, providing the acquired Google AI Studio API key as if it were your OpenAI API key.&lt;/p&gt; &lt;p&gt;Example API Request (Assuming the proxy is hosted at &lt;code&gt;http://localhost:8080&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://localhost:8080/v1/chat/completions \&#xA; -H &#34;Content-Type: application/json&#34; \&#xA; -H &#34;Authorization: Bearer $YOUR_GOOGLE_AI_STUDIO_API_KEY&#34; \&#xA; -d &#39;{&#xA;     &#34;model&#34;: &#34;gpt-3.5-turbo&#34;,&#xA;     &#34;messages&#34;: [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Say this is a test!&#34;}],&#xA;     &#34;temperature&#34;: 0.7&#xA; }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Alternatively, use Gemini Pro Vision:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl http://localhost:8080/v1/chat/completions \&#xA; -H &#34;Content-Type: application/json&#34; \&#xA; -H &#34;Authorization: Bearer $YOUR_GOOGLE_AI_STUDIO_API_KEY&#34; \&#xA; -d &#39;{&#xA;     &#34;model&#34;: &#34;gpt-4-vision-preview&#34;,&#xA;     &#34;messages&#34;: [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: [&#xA;        {&#34;type&#34;: &#34;text&#34;, &#34;text&#34;: &#34;Whatâ€™s in this image?&#34;},&#xA;        {&#xA;          &#34;type&#34;: &#34;image_url&#34;,&#xA;          &#34;image_url&#34;: {&#xA;            &#34;url&#34;: &#34;https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg&#34;&#xA;          }&#xA;        }&#xA;     ]}],&#xA;     &#34;temperature&#34;: 0.7&#xA; }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Handle Responses:&lt;/strong&gt; Process the responses from the Gemini-OpenAI-Proxy in the same way you would handle responses from OpenAI.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Now, your application is equipped to leverage OpenAI functionality through the Gemini-OpenAI-Proxy, bridging the gap between OpenAI and applications using the Google Gemini Pro protocol.&lt;/p&gt; &#xA;&lt;h2&gt;Compatibility Testing&lt;/h2&gt; &#xA;&lt;p&gt;Gemini-OpenAI-Proxy is designed to seamlessly integrate OpenAI-powered functionalities into applications using the Google Gemini Pro protocol. To ensure comprehensive compatibility, we have conducted testing specifically targeting &lt;code&gt;chatbox&lt;/code&gt; and &lt;code&gt;openai translator&lt;/code&gt; functionalities.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Gemini-OpenAI-Proxy is licensed under the MIT License - see the &lt;a href=&#34;https://raw.githubusercontent.com/zhu327/gemini-openai-proxy/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
</feed>