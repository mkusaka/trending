<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-15T02:46:55Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>FerretDB/FerretDB</title>
    <updated>2023-04-15T02:46:55Z</updated>
    <id>tag:github.com,2023-04-15:/FerretDB/FerretDB</id>
    <link href="https://github.com/FerretDB/FerretDB" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A truly Open Source MongoDB alternative&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FerretDB&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pkg.go.dev/github.com/FerretDB/FerretDB/ferretdb&#34;&gt;&lt;img src=&#34;https://pkg.go.dev/badge/github.com/FerretDB/FerretDB/ferretdb.svg?sanitize=true&#34; alt=&#34;Go Reference&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/go.yml&#34;&gt;&lt;img src=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/go.yml/badge.svg?branch=main&#34; alt=&#34;Go&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/integration.yml&#34;&gt;&lt;img src=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/integration.yml/badge.svg?branch=main&#34; alt=&#34;Integration&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/FerretDB/FerretDB&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/FerretDB/FerretDB/branch/main/graph/badge.svg?token=JZ56XFT3DM&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/security.yml&#34;&gt;&lt;img src=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/security.yml/badge.svg?branch=main&#34; alt=&#34;Security&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/packages.yml&#34;&gt;&lt;img src=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/packages.yml/badge.svg?branch=main&#34; alt=&#34;Packages&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/docs.yml&#34;&gt;&lt;img src=&#34;https://github.com/FerretDB/FerretDB/actions/workflows/docs.yml/badge.svg?branch=main&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;FerretDB was founded to become the de-facto open-source substitute to MongoDB. FerretDB is an open-source proxy, converting the MongoDB 6.0+ wire protocol queries to SQL - using PostgreSQL as a database engine.&lt;/p&gt; &#xA;&lt;h2&gt;Why do we need FerretDB?&lt;/h2&gt; &#xA;&lt;p&gt;MongoDB was originally an eye-opening technology for many of us developers, empowering us to build applications faster than using relational databases. In its early days, its ease-to-use and well-documented drivers made MongoDB one of the simplest database solutions available. However, as time passed, MongoDB abandoned its open-source roots; changing the license to &lt;a href=&#34;https://www.mongodb.com/licensing/server-side-public-license&#34;&gt;SSPL&lt;/a&gt; - making it unusable for many open source and early-stage commercial projects.&lt;/p&gt; &#xA;&lt;p&gt;Most MongoDB users do not require any advanced features offered by MongoDB; however, they need an easy-to-use open-source document database solution. Recognizing this, FerretDB is here to fill that gap.&lt;/p&gt; &#xA;&lt;h2&gt;Scope and current state&lt;/h2&gt; &#xA;&lt;p&gt;FerretDB is compatible with MongoDB drivers and popular MongoDB tools. It functions as a drop-in replacement for MongoDB 6.0+ in many cases. Features are constantly being added to further increase compatibility and performance.&lt;/p&gt; &#xA;&lt;p&gt;We welcome all contributors. See our &lt;a href=&#34;https://github.com/orgs/FerretDB/projects/2/views/1&#34;&gt;public roadmap&lt;/a&gt;, a list of &lt;a href=&#34;https://docs.ferretdb.io/diff/&#34;&gt;known differences with MongoDB&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/FerretDB/FerretDB/main/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run -d --rm --name ferretdb -p 27017:27017 ghcr.io/ferretdb/all-in-one&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command will start a container with FerretDB, PostgreSQL, and MongoDB Shell for quick testing and experiments. However, it is unsuitable for production use cases because it keeps all data inside and loses it on shutdown. See our &lt;a href=&#34;https://docs.ferretdb.io/quickstart-guide/docker/&#34;&gt;Docker quickstart guide&lt;/a&gt; for instructions that don&#39;t have those problems.&lt;/p&gt; &#xA;&lt;p&gt;With that container running, you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Connect to it with any MongoDB client application using MongoDB URI &lt;code&gt;mongodb://127.0.0.1:27017/&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Connect to it using MongoDB Shell by just running &lt;code&gt;mongosh&lt;/code&gt;. If you don&#39;t have it installed locally, you can run &lt;code&gt;docker exec -it ferretdb mongosh&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Connect to PostgreSQL running inside the container by running &lt;code&gt;docker exec -it ferretdb psql -U username ferretdb&lt;/code&gt;. FerretDB uses PostgreSQL schemas for MongoDB databases. So, if you created some collections in the &lt;code&gt;test&lt;/code&gt; database using any MongoDB client, you can switch to it by running &lt;code&gt;SET search_path = &#39;test&#39;;&lt;/code&gt; query and see a list of PostgreSQL tables by running &lt;code&gt;\d&lt;/code&gt; &lt;code&gt;psql&lt;/code&gt; command.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can stop the container with &lt;code&gt;docker stop ferretdb&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We also provide binaries and packages for various Linux distributions. See &lt;a href=&#34;https://docs.ferretdb.io/quickstart-guide/&#34;&gt;our documentation&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Building and packaging&lt;/h2&gt; &#xA;&lt;p&gt;We strongly advise users not to build FerretDB themselves. Instead, use binaries, Docker images, or &lt;code&gt;.deb&lt;/code&gt;/&lt;code&gt;.rpm&lt;/code&gt; packages provided by us.&lt;/p&gt; &#xA;&lt;p&gt;If you want to package FerretDB for your operating system or distribution, the recommended way to build the binary is to use the &lt;code&gt;build-release&lt;/code&gt; task; see our &lt;a href=&#34;https://raw.githubusercontent.com/FerretDB/FerretDB/main/CONTRIBUTING.md&#34;&gt;instructions for contributors&lt;/a&gt; for more details. FerretDB could also be built as any other Go program, but a few generated files and build tags could affect it. See &lt;a href=&#34;https://pkg.go.dev/github.com/FerretDB/FerretDB/build/version&#34;&gt;there&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Managed FerretDB at cloud providers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.civo.com&#34;&gt;Civo&lt;/a&gt; (see &lt;a href=&#34;https://www.civo.com/marketplace/FerretDB&#34;&gt;here&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.scaleway.com/&#34;&gt;Scaleway&lt;/a&gt; (request access &lt;a href=&#34;https://www.scaleway.com/en/betas/#managed-document-database&#34;&gt;here&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.ferretdb.io/&#34;&gt;Documentation for users&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pkg.go.dev/github.com/FerretDB/FerretDB/ferretdb&#34;&gt;Documentation for Go developers about embeddable FerretDB&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Website and blog: &lt;a href=&#34;https://ferretdb.io/&#34;&gt;https://ferretdb.io&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Twitter: &lt;a href=&#34;https://twitter.com/ferret_db&#34;&gt;@ferret_db&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Mastodon: &lt;a href=&#34;https://techhub.social/@ferretdb&#34;&gt;@ferretdb@techhub.social&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://join.slack.com/t/ferretdb/shared_invite/zt-zqe9hj8g-ZcMG3~5Cs5u9uuOPnZB8~A&#34;&gt;Slack chat&lt;/a&gt; for quick questions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FerretDB/FerretDB/discussions&#34;&gt;GitHub Discussions&lt;/a&gt; for longer topics.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FerretDB/FerretDB/issues&#34;&gt;GitHub Issues&lt;/a&gt; for bugs and missing features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://calendar.google.com/event?action=TEMPLATE&amp;amp;tmeid=NjNkdTkyN3VoNW5zdHRiaHZybXFtb2l1OWtfMjAyMTEyMTNUMTgwMDAwWiBjX24zN3RxdW9yZWlsOWIwMm0wNzQwMDA3MjQ0QGc&amp;amp;tmsrc=c_n37tquoreil9b02m0740007244%40group.calendar.google.com&amp;amp;scp=ALL&#34;&gt;Open Office Hours meeting&lt;/a&gt; every Monday at 18:00 UTC at &lt;a href=&#34;https://meet.google.com/mcb-arhw-qbq&#34;&gt;Google Meet&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you want to contact FerretDB Inc., please use &lt;a href=&#34;https://www.ferretdb.io/contact/&#34;&gt;this form&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>gotzmann/llama.go</title>
    <updated>2023-04-15T02:46:55Z</updated>
    <id>tag:github.com,2023-04-15:/gotzmann/llama.go</id>
    <link href="https://github.com/gotzmann/llama.go" rel="alternate"></link>
    <summary type="html">&lt;p&gt;llama.go is like llama.cpp in pure Golang!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLaMA.go&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gotzmann/llama.go/main/assets/images/terminal.png?raw=true&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/gotzmann/llama.go/actions/workflows/coverage.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Coverage-0-red&#34; alt=&#34;Coverage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;The Goal&lt;/h2&gt; &#xA;&lt;p&gt;We dream of a world where ML hackers are able to grok with &lt;strong&gt;REALLY BIG GPT&lt;/strong&gt; models without having GPU clusters consuming a shit tons of &lt;strong&gt;$$$&lt;/strong&gt; - using only machines in their own homelabs.&lt;/p&gt; &#xA;&lt;p&gt;The code of the project is based on the legendary &lt;strong&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;ggml.cpp&lt;/a&gt;&lt;/strong&gt; framework of Georgi Gerganov written in C++&lt;/p&gt; &#xA;&lt;p&gt;We hope using our beloved Golang instead of &lt;em&gt;soo-powerful&lt;/em&gt; but &lt;em&gt;too-low-level&lt;/em&gt; language will allow much greater adoption of the &lt;strong&gt;NoGPU&lt;/strong&gt; ideas.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NB!&lt;/strong&gt; The V1 supports only FP32 math, so you&#39;ll need at least 32GB RAM to work even with the smallest &lt;strong&gt;LLaMA-7B&lt;/strong&gt; model. As a preliminary step you should have binary files converted from original LLaMA model locally.&lt;/p&gt; &#xA;&lt;h2&gt;V0 Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Move FP32 tensor math from C++ to pure Golang package GoML&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Implement LLaMA neural net architecture and model loading in Golang&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support smaller LLaMA-7B model&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Be sure Go inference works EXACT SAME way as C++ for static prompts&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Let Go shine! Enable multi-threading and boost performance&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;V1 Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Check cross-patform compatibility with Mac and Windows&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release first stable version for ML hackers&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support bigger LLaMA models: 13B, 30B, 60B&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Enable interactive mode for real-time chat with GPT&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Allow automatic download converted model weights from the Internet&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implement metrics for RAM and CPU usage&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; x8 performance boost with AVX2 support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; INT8 quantization to allow x4 bigger models fit the same memory&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Server Mode for use in clouds as part of microservice architecture&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;V2 Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; x2 performance boost with AVX512 support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; ARM NEON support on Mac machines and ARM servers&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; FP16 and BF16 support where possible&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support INT4 and GPTQ quantization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to Run&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;go run main.go --threads 8 --model ~/models/7B/ggml-model-f32.bin --temp 0.80 --context 128 --predict 128 --prompt &#34;Why Golang is so popular?&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or edit the Makefile and compile and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;make&#xA;./llama --threads 8 --model ~/models/7B/ggml-model-f32.bin --temp 0.80 --context 128 --predict 128 --prompt &#34;Why Golang is so popular?&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;1] Where might I get original LLaMA model files?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Contact Meta directly or look around for some torrent alternatives&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;2] How to convert original LLaMA files into supported format?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Youl&#39;ll need original FP16 files placed into &lt;strong&gt;models&lt;/strong&gt; directory, then convert with command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python3 ./scripts/convert.py ~/models/LLaMA/7B/ 0&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>aler9/mediamtx</title>
    <updated>2023-04-15T02:46:55Z</updated>
    <id>tag:github.com,2023-04-15:/aler9/mediamtx</id>
    <link href="https://github.com/aler9/mediamtx" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Also known as rtsp-simple-server. ready-to-use RTSP / RTMP / LL-HLS / WebRTC server and proxy that allows to read, publish and proxy video and audio streams.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/logo.png&#34; alt=&#34;MediaMTX / rtsp-simple-server&#34;&gt; &lt;/h1&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#important-announcement&#34;&gt;&lt;em&gt;MediaMTX&lt;/em&gt;&lt;/a&gt; / &lt;em&gt;rtsp-simple-server&lt;/em&gt; is a ready-to-use and zero-dependency server and proxy that allows users to publish, read and proxy live video and audio streams.&lt;/p&gt; &#xA;&lt;p&gt;Live streams can be published to the server with:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;protocol&lt;/th&gt; &#xA;   &lt;th&gt;variants&lt;/th&gt; &#xA;   &lt;th&gt;codecs&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RTSP clients (FFmpeg, GStreamer, etc)&lt;/td&gt; &#xA;   &lt;td&gt;UDP, TCP, RTSPS&lt;/td&gt; &#xA;   &lt;td&gt;H264, H265, VP8, VP9, AV1, MPEG-2 video, MPEG-2 audio, M-JPEG, MP3, MPEG-4 video, MPEG-4 Audio (AAC), Opus, G711, G722, LPCM and any RTP-compatible codec&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RTSP servers and cameras&lt;/td&gt; &#xA;   &lt;td&gt;UDP, UDP-Multicast, TCP, RTSPS&lt;/td&gt; &#xA;   &lt;td&gt;H264, H265, VP8, VP9, AV1, MPEG-2 video, MPEG-2 audio, M-JPEG, MP3, MPEG-4 video, MPEG-4 Audio (AAC), Opus, G711, G722, LPCM and any RTP-compatible codec&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RTMP clients (OBS Studio)&lt;/td&gt; &#xA;   &lt;td&gt;RTMP, RTMPS&lt;/td&gt; &#xA;   &lt;td&gt;H264, H265, MPEG-4 Audio (AAC)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RTMP servers and cameras&lt;/td&gt; &#xA;   &lt;td&gt;RTMP, RTMPS&lt;/td&gt; &#xA;   &lt;td&gt;H264, MPEG-4 Audio (AAC)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HLS servers and cameras&lt;/td&gt; &#xA;   &lt;td&gt;Low-Latency HLS, MP4-based HLS, legacy HLS&lt;/td&gt; &#xA;   &lt;td&gt;H264, H265, MPEG-4 Audio (AAC), Opus&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;UDP/MPEG-TS streams&lt;/td&gt; &#xA;   &lt;td&gt;Unicast, broadcast, multicast&lt;/td&gt; &#xA;   &lt;td&gt;H264, H265, MPEG-4 Audio (AAC), Opus&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Raspberry Pi Cameras&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;H264&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;And can be read from the server with:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;protocol&lt;/th&gt; &#xA;   &lt;th&gt;variants&lt;/th&gt; &#xA;   &lt;th&gt;codecs&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RTSP&lt;/td&gt; &#xA;   &lt;td&gt;UDP, UDP-Multicast, TCP, RTSPS&lt;/td&gt; &#xA;   &lt;td&gt;H264, H265, VP8, VP9, AV1, MPEG-2 video, MPEG-2 audio, M-JPEG, MP3, MPEG-4 video, MPEG-4 Audio (AAC), Opus, G711, G722, LPCM and any RTP-compatible codec&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RTMP&lt;/td&gt; &#xA;   &lt;td&gt;RTMP, RTMPS&lt;/td&gt; &#xA;   &lt;td&gt;H264, MPEG-4 Audio (AAC)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HLS&lt;/td&gt; &#xA;   &lt;td&gt;Low-Latency HLS, MP4-based HLS, legacy HLS&lt;/td&gt; &#xA;   &lt;td&gt;H264, H265, MPEG-4 Audio (AAC), Opus&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;WebRTC&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;H264, VP8, VP9, Opus, G711, G722&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Publish live streams to the server&lt;/li&gt; &#xA; &lt;li&gt;Read live streams from the server&lt;/li&gt; &#xA; &lt;li&gt;Proxy streams from other servers or cameras, always or on-demand&lt;/li&gt; &#xA; &lt;li&gt;Streams are automatically converted from a protocol to another. For instance, it&#39;s possible to publish a stream with RTSP and read it with HLS&lt;/li&gt; &#xA; &lt;li&gt;Serve multiple streams at once in separate paths&lt;/li&gt; &#xA; &lt;li&gt;Authenticate users; use internal or external authentication&lt;/li&gt; &#xA; &lt;li&gt;Redirect readers to other RTSP servers (load balancing)&lt;/li&gt; &#xA; &lt;li&gt;Query and control the server through an HTTP API&lt;/li&gt; &#xA; &lt;li&gt;Reload the configuration without disconnecting existing clients (hot reloading)&lt;/li&gt; &#xA; &lt;li&gt;Read Prometheus-compatible metrics&lt;/li&gt; &#xA; &lt;li&gt;Run external commands when clients connect, disconnect, read or publish streams&lt;/li&gt; &#xA; &lt;li&gt;Natively compatible with the Raspberry Pi Camera&lt;/li&gt; &#xA; &lt;li&gt;Compatible with Linux, Windows and macOS, does not require any dependency or interpreter, it&#39;s a single executable&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/aler9/mediamtx/actions?query=workflow:test&#34;&gt;&lt;img src=&#34;https://github.com/aler9/mediamtx/workflows/test/badge.svg?sanitize=true&#34; alt=&#34;Test&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/aler9/mediamtx/actions?query=workflow:lint&#34;&gt;&lt;img src=&#34;https://github.com/aler9/mediamtx/workflows/lint/badge.svg?sanitize=true&#34; alt=&#34;Lint&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/aler9/mediamtx/branch/main&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/aler9/mediamtx/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;CodeCov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/aler9/mediamtx/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/aler9/mediamtx&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/aler9/rtsp-simple-server&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docker-aler9/rtsp--simple--server-blue&#34; alt=&#34;Docker Hub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://aler9.github.io/mediamtx&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/api-documentation-blue&#34; alt=&#34;API Documentation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Important announcement&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;rtsp-simple-server&lt;/em&gt; is being rebranded as &lt;em&gt;MediaMTX&lt;/em&gt;. The reason is pretty obvious: this project started as a RTSP server but has evolved into a much more versatile media server (i like to call it a &#34;media broker&#34;, a message broker for media streams), that is not tied to the RTSP protocol anymore. Nothing will change regarding license, features and backward compatibility.&lt;/p&gt; &#xA;&lt;p&gt;Furthermore, my main open source projects are being transferred to the &lt;a href=&#34;https://github.com/bluenviron&#34;&gt;bluenviron organization&lt;/a&gt;, in order to allow the community to maintain and evolve the code regardless of my personal availability.&lt;/p&gt; &#xA;&lt;p&gt;In the next months, the repository name and the Docker image name will be changed accordingly.&lt;/p&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#installation&#34;&gt;Installation&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#standard&#34;&gt;Standard&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#docker&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#openwrt&#34;&gt;OpenWRT&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#basic-usage&#34;&gt;Basic usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#general&#34;&gt;General&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#configuration&#34;&gt;Configuration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#authentication&#34;&gt;Authentication&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#encrypt-the-configuration&#34;&gt;Encrypt the configuration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#proxy-mode&#34;&gt;Proxy mode&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#remuxing-re-encoding-compression&#34;&gt;Remuxing, re-encoding, compression&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#save-streams-to-disk&#34;&gt;Save streams to disk&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#on-demand-publishing&#34;&gt;On-demand publishing&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#start-on-boot&#34;&gt;Start on boot&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#linux&#34;&gt;Linux&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#windows&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#http-api&#34;&gt;HTTP API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#metrics&#34;&gt;Metrics&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#pprof&#34;&gt;pprof&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#compile-from-source&#34;&gt;Compile from source&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#publish-to-the-server&#34;&gt;Publish to the server&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#from-a-webcam&#34;&gt;From a webcam&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#from-a-raspberry-pi-camera&#34;&gt;From a Raspberry Pi Camera&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#from-obs-studio&#34;&gt;From OBS Studio&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#from-opencv&#34;&gt;From OpenCV&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#from-a-udp-stream&#34;&gt;From a UDP stream&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#read-from-the-server&#34;&gt;Read from the server&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#from-vlc-and-ubuntu&#34;&gt;From VLC and Ubuntu&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#rtsp-protocol&#34;&gt;RTSP protocol&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#general-usage&#34;&gt;General usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#tcp-transport&#34;&gt;TCP transport&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#udp-multicast-transport&#34;&gt;UDP-multicast transport&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#encryption&#34;&gt;Encryption&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#redirect-to-another-server&#34;&gt;Redirect to another server&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#fallback-stream&#34;&gt;Fallback stream&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#corrupted-frames&#34;&gt;Corrupted frames&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#decrease-latency&#34;&gt;Decrease latency&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#rtmp-protocol&#34;&gt;RTMP protocol&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#general-usage-1&#34;&gt;General usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#encryption-1&#34;&gt;Encryption&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#hls-protocol&#34;&gt;HLS protocol&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#general-usage-2&#34;&gt;General usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#browser-support&#34;&gt;Browser support&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#embedding&#34;&gt;Embedding&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#low-latency-variant&#34;&gt;Low-Latency variant&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#hls-on-apple-devices&#34;&gt;HLS on Apple devices&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#decrease-latency-1&#34;&gt;Decrease latency&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#webrtc-protocol&#34;&gt;WebRTC protocol&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#general-usage-3&#34;&gt;General usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#usage-inside-a-container-or-behind-a-nat&#34;&gt;Usage inside a container or behind a NAT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#embedding-1&#34;&gt;Embedding&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#standards&#34;&gt;Standards&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#links&#34;&gt;Links&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Standard&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download and extract a precompiled binary from the &lt;a href=&#34;https://github.com/aler9/mediamtx/releases&#34;&gt;release page&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start the server:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./mediamtx&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;Download and launch the image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it --network=host aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;--network=host&lt;/code&gt; flag is mandatory since Docker can change the source port of UDP packets for routing reasons, and this doesn&#39;t allow the server to find out the author of the packets. This issue can be avoided by disabling the UDP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it -e MTX_PROTOCOLS=tcp -p 8554:8554 -p 1935:1935 -p 8888:8888 -p 8889:8889 aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please keep in mind that the Docker image doesn&#39;t include &lt;em&gt;FFmpeg&lt;/em&gt;. if you need to use &lt;em&gt;FFmpeg&lt;/em&gt; for an external command or anything else, you need to build a Docker image that contains both &lt;em&gt;rtsp-simple-server&lt;/em&gt; and &lt;em&gt;FFmpeg&lt;/em&gt;, by following instructions &lt;a href=&#34;https://github.com/aler9/mediamtx/discussions/278#discussioncomment-549104&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;OpenWRT&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;In a x86 Linux system, download the OpenWRT SDK corresponding to the wanted OpenWRT version and target from the &lt;a href=&#34;https://downloads.openwrt.org/releases/&#34;&gt;OpenWRT website&lt;/a&gt; and extract it.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open a terminal in the SDK folder and setup the SDK:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./scripts/feeds update -a&#xA;./scripts/feeds install -a&#xA;make defconfig&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Download the server Makefile and set the server version inside the file:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;mkdir package/mediamtx&#xA;wget -O package/mediamtx/Makefile https://raw.githubusercontent.com/aler9/mediamtx/main/openwrt.mk&#xA;sed -i &#34;s/v0.0.0/$(git ls-remote --tags --sort=v:refname https://github.com/aler9/mediamtx | tail -n1 | sed &#39;s/.*\///; s/\^{}//&#39;)/&#34; package/mediamtx/Makefile&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Compile the server:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;make package/mediamtx/compile -j$(nproc)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Transfer the .ipk file from &lt;code&gt;bin/packages/*/base&lt;/code&gt; to the OpenWRT system and install it with:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;opkg install [ipk-file-name].ipk&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Basic usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Publish a stream. For instance, you can publish a video/audio file with &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or &lt;em&gt;GStreamer&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;gst-launch-1.0 rtspclientsink name=s location=rtsp://localhost:8554/mystream filesrc location=file.mp4 ! qtdemux name=d d.video_0 ! queue ! s.sink_0 d.audio_0 ! queue ! s.sink_1&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To publish from other hardware / software, take a look at the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#publish-to-the-server&#34;&gt;Publish to the server&lt;/a&gt; section.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open the stream. For instance, you can open the stream with &lt;em&gt;VLC&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;vlc --network-caching=50 rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or &lt;em&gt;GStreamer&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;gst-play-1.0 rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ffmpeg -i rtsp://localhost:8554/mystream -c copy output.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;General&lt;/h2&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;All the configuration parameters are listed and commented in the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/mediamtx.yml&#34;&gt;configuration file&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There are 3 ways to change the configuration:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;By editing the &lt;code&gt;mediamtx.yml&lt;/code&gt; file, that is&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;included into the release bundle&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;available in the root folder of the Docker image (&lt;code&gt;/mediamtx.yml&lt;/code&gt;); it can be overridden in this way:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker run --rm -it --network=host -v $PWD/mediamtx.yml:/mediamtx.yml aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;The configuration can be changed dynamically when the server is running (hot reloading) by writing to the configuration file. Changes are detected and applied without disconnecting existing clients, whenever it&#39;s possible.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;By overriding configuration parameters with environment variables, in the format &lt;code&gt;MTX_PARAMNAME&lt;/code&gt;, where &lt;code&gt;PARAMNAME&lt;/code&gt; is the uppercase name of a parameter. For instance, the &lt;code&gt;rtspAddress&lt;/code&gt; parameter can be overridden in the following way:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;MTX_RTSPADDRESS=&#34;127.0.0.1:8554&#34; ./mediamtx&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Parameters that have array as value can be overriden by setting a comma-separated list. For example:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;MTX_PROTOCOLS=&#34;tcp,udp&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Parameters in maps can be overridden by using underscores, in the following way:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;MTX_PATHS_TEST_SOURCE=rtsp://myurl ./mediamtx&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This method is particularly useful when using Docker; any configuration parameter can be changed by passing environment variables with the &lt;code&gt;-e&lt;/code&gt; flag:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker run --rm -it --network=host -e MTX_PATHS_TEST_SOURCE=rtsp://myurl aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;By using the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#http-api&#34;&gt;HTTP API&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Authentication&lt;/h3&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;mediamtx.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  all:&#xA;    publishUser: myuser&#xA;    publishPass: mypass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Only publishers that provide both username and password will be able to proceed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://myuser:mypass@localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It&#39;s possible to setup authentication for readers too:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  all:&#xA;    publishUser: myuser&#xA;    publishPass: mypass&#xA;&#xA;    readUser: user&#xA;    readPass: userpass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If storing plain credentials in the configuration file is a security problem, username and passwords can be stored as sha256-hashed strings; a string must be hashed with sha256 and encoded with base64:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;echo -n &#34;userpass&#34; | openssl dgst -binary -sha256 | openssl base64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then stored with the &lt;code&gt;sha256:&lt;/code&gt; prefix:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  all:&#xA;    readUser: sha256:j1tsRqDEw9xvq/D7/9tMx6Jh/jMhk3UfjwIB2f1zgMo=&#xA;    readPass: sha256:BdSWkrdV+ZxFBLUQQY7+7uv9RmiSVA8nrPmjGjJtZQQ=&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: enable encryption or use a VPN to ensure that no one is intercepting the credentials.&lt;/p&gt; &#xA;&lt;p&gt;Authentication can be delegated to an external HTTP server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;externalAuthenticationURL: http://myauthserver/auth&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Each time a user needs to be authenticated, the specified URL will be requested with the POST method and this payload:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;ip&#34;: &#34;ip&#34;,&#xA;  &#34;user&#34;: &#34;user&#34;,&#xA;  &#34;password&#34;: &#34;password&#34;,&#xA;  &#34;path&#34;: &#34;path&#34;,&#xA;  &#34;protocol&#34;: &#34;rtsp|rtmp|hls|webrtc&#34;,&#xA;  &#34;id&#34;: &#34;id&#34;,&#xA;  &#34;action&#34;: &#34;read|publish&#34;,&#xA;  &#34;query&#34;: &#34;query&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the URL returns a status code that begins with &lt;code&gt;20&lt;/code&gt; (i.e. &lt;code&gt;200&lt;/code&gt;), authentication is successful, otherwise it fails.&lt;/p&gt; &#xA;&lt;p&gt;Please be aware that it&#39;s perfectly normal for the authentication server to receive requests with empty users and passwords, i.e.:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;user&#34;: &#34;&#34;,&#xA;  &#34;password&#34;: &#34;&#34;,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This happens because a RTSP client doesn&#39;t provide credentials until it is asked to. In order to receive the credentials, the authentication server must reply with status code &lt;code&gt;401&lt;/code&gt; - the client will then send credentials.&lt;/p&gt; &#xA;&lt;h3&gt;Encrypt the configuration&lt;/h3&gt; &#xA;&lt;p&gt;The configuration file can be entirely encrypted for security purposes.&lt;/p&gt; &#xA;&lt;p&gt;An online encryption tool is &lt;a href=&#34;https://play.golang.org/p/rX29jwObNe4&#34;&gt;available here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The encryption procedure is the following:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;NaCL&#39;s &lt;code&gt;crypto_secretbox&lt;/code&gt; function is applied to the content of the configuration. NaCL is a cryptographic library available for &lt;a href=&#34;https://nacl.cr.yp.to/secretbox.html&#34;&gt;C/C++&lt;/a&gt;, &lt;a href=&#34;https://pkg.go.dev/golang.org/x/crypto/nacl/secretbox&#34;&gt;Go&lt;/a&gt;, &lt;a href=&#34;https://github.com/somdoron/NaCl.net&#34;&gt;C#&lt;/a&gt; and many other languages;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The string is prefixed with the nonce;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The string is encoded with base64.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;After performing the encryption, put the base64-encoded result into the configuration file, and launch the server with the &lt;code&gt;MTX_CONFKEY&lt;/code&gt; variable:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MTX_CONFKEY=mykey ./mediamtx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Proxy mode&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;MediaMTX&lt;/em&gt; is also a proxy, that is usually deployed in one of these scenarios:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;when there are multiple users that are reading a stream and the bandwidth is limited; the proxy is used to receive the stream once. Users can then connect to the proxy instead of the original source.&lt;/li&gt; &#xA; &lt;li&gt;when there&#39;s a NAT / firewall between a stream and the users; the proxy is installed on the NAT and makes the stream available to the outside world.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;mediamtx.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  proxied:&#xA;    # url of the source stream, in the format rtsp://user:pass@host:port/path&#xA;    source: rtsp://original-url&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After starting the server, users can connect to &lt;code&gt;rtsp://localhost:8554/proxied&lt;/code&gt;, instead of connecting to the original url. The server supports any number of source streams, it&#39;s enough to add additional entries to the &lt;code&gt;paths&lt;/code&gt; section:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  proxied1:&#xA;    source: rtsp://url1&#xA;&#xA;  proxied2:&#xA;    source: rtsp://url1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It&#39;s possible to save bandwidth by enabling the on-demand mode: the stream will be pulled only when at least a client is connected:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  proxied:&#xA;    source: rtsp://original-url&#xA;    sourceOnDemand: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Remuxing, re-encoding, compression&lt;/h3&gt; &#xA;&lt;p&gt;To change the format, codec or compression of a stream, use &lt;em&gt;FFmpeg&lt;/em&gt; or &lt;em&gt;GStreamer&lt;/em&gt; together with &lt;em&gt;MediaMTX&lt;/em&gt;. For instance, to re-encode an existing stream, that is available in the &lt;code&gt;/original&lt;/code&gt; path, and publish the resulting stream in the &lt;code&gt;/compressed&lt;/code&gt; path, edit &lt;code&gt;mediamtx.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  all:&#xA;  original:&#xA;    runOnReady: ffmpeg -i rtsp://localhost:$RTSP_PORT/$RTSP_PATH -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -max_muxing_queue_size 1024 -f rtsp rtsp://localhost:$RTSP_PORT/compressed&#xA;    runOnReadyRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Save streams to disk&lt;/h3&gt; &#xA;&lt;p&gt;To save available streams to disk, you can use the &lt;code&gt;runOnReady&lt;/code&gt; parameter and &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  mypath:&#xA;    runOnReady: ffmpeg -i rtsp://localhost:$RTSP_PORT/$RTSP_PATH -c copy -f segment -strftime 1 -segment_time 60 -segment_format mpegts saved_%Y-%m-%d_%H-%M-%S.ts&#xA;    runOnReadyRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the configuratio above, streams are saved into TS files, that can be read even if the system crashes, while MP4 files can&#39;t.&lt;/p&gt; &#xA;&lt;h3&gt;On-demand publishing&lt;/h3&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;mediamtx.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  ondemand:&#xA;    runOnDemand: ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:$RTSP_PORT/$RTSP_PATH&#xA;    runOnDemandRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The command inserted into &lt;code&gt;runOnDemand&lt;/code&gt; will start only when a client requests the path &lt;code&gt;ondemand&lt;/code&gt;, therefore the file will start streaming only when requested.&lt;/p&gt; &#xA;&lt;h3&gt;Start on boot&lt;/h3&gt; &#xA;&lt;h4&gt;Linux&lt;/h4&gt; &#xA;&lt;p&gt;Systemd is the service manager used by Ubuntu, Debian and many other Linux distributions, and allows to launch &lt;em&gt;MediaMTX&lt;/em&gt; on boot.&lt;/p&gt; &#xA;&lt;p&gt;Download a release bundle from the &lt;a href=&#34;https://github.com/aler9/mediamtx/releases&#34;&gt;release page&lt;/a&gt;, unzip it, and move the executable and configuration in the system:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo mv mediamtx /usr/local/bin/&#xA;sudo mv mediamtx.yml /usr/local/etc/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create the service:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo tee /etc/systemd/system/mediamtx.service &amp;gt;/dev/null &amp;lt;&amp;lt; EOF&#xA;[Unit]&#xA;Wants=network.target&#xA;[Service]&#xA;ExecStart=/usr/local/bin/mediamtx /usr/local/etc/mediamtx.yml&#xA;[Install]&#xA;WantedBy=multi-user.target&#xA;EOF&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Enable and start the service:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo systemctl daemon-reload&#xA;sudo systemctl enable mediamtx&#xA;sudo systemctl start mediamtx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Windows&lt;/h4&gt; &#xA;&lt;p&gt;Download the &lt;a href=&#34;https://github.com/winsw/winsw/releases/download/v2.11.0/WinSW-x64.exe&#34;&gt;WinSW v2 executable&lt;/a&gt; and place it into the same folder of &lt;code&gt;mediamtx.exe&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In the same folder, create a file named &lt;code&gt;WinSW-x64.xml&lt;/code&gt; with this content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;service&amp;gt;&#xA;  &amp;lt;id&amp;gt;mediamtx&amp;lt;/id&amp;gt;&#xA;  &amp;lt;name&amp;gt;mediamtx&amp;lt;/name&amp;gt;&#xA;  &amp;lt;description&amp;gt;&amp;lt;/description&amp;gt;&#xA;  &amp;lt;executable&amp;gt;%BASE%/mediamtx.exe&amp;lt;/executable&amp;gt;&#xA;&amp;lt;/service&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open a terminal, navigate to the folder and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;WinSW-x64 install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The server is now installed as a system service and will start at boot time.&lt;/p&gt; &#xA;&lt;h3&gt;HTTP API&lt;/h3&gt; &#xA;&lt;p&gt;The server can be queried and controlled with an HTTP API, that must be enabled by setting the &lt;code&gt;api&lt;/code&gt; parameter in the configuration:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;api: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The API listens on &lt;code&gt;apiAddress&lt;/code&gt;, that by default is &lt;code&gt;127.0.0.1:9997&lt;/code&gt;; for instance, to obtain a list of active paths, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl http://127.0.0.1:9997/v1/paths/list&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Full documentation of the API is available on the &lt;a href=&#34;https://aler9.github.io/mediamtx/&#34;&gt;dedicated site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Metrics&lt;/h3&gt; &#xA;&lt;p&gt;A metrics exporter, compatible with &lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt;, can be enabled with the parameter &lt;code&gt;metrics: yes&lt;/code&gt;; then the server can be queried for metrics with Prometheus or with a simple HTTP request:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;wget -qO- localhost:9998/metrics&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Obtaining:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;# metrics of every path&#xA;paths{name=&#34;[path_name]&#34;,state=&#34;[state]&#34;} 1&#xA;paths_bytes_received{name=&#34;[path_name]&#34;,state=&#34;[state]&#34;} 1234&#xA;&#xA;# metrics of every HLS muxer&#xA;hls_muxers{name=&#34;[name]&#34;} 1&#xA;hls_muxers_bytes_sent{name=&#34;[name]&#34;} 187&#xA;&#xA;# metrics of every RTSP connection&#xA;rtsp_conns{id=&#34;[id]&#34;} 1&#xA;rtsp_conns_bytes_received{id=&#34;[id]&#34;} 1234&#xA;rtsp_conns_bytes_sent{id=&#34;[id]&#34;} 187&#xA;&#xA;# metrics of every RTSP session&#xA;rtsp_sessions{id=&#34;[id]&#34;,state=&#34;idle&#34;} 1&#xA;rtsp_sessions_bytes_received{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1234&#xA;rtsp_sessions_bytes_sent{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 187&#xA;&#xA;# metrics of every RTSPS connection&#xA;rtsps_conns{id=&#34;[id]&#34;} 1&#xA;rtsps_conns_bytes_received{id=&#34;[id]&#34;} 1234&#xA;rtsps_conns_bytes_sent{id=&#34;[id]&#34;} 187&#xA;&#xA;# metrics of every RTSPS session&#xA;rtsps_sessions{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1&#xA;rtsps_sessions_bytes_received{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1234&#xA;rtsps_sessions_bytes_sent{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 187&#xA;&#xA;# metrics of every RTMP connection&#xA;rtmp_conns{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1&#xA;rtmp_conns_bytes_received{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1234&#xA;rtmp_conns_bytes_sent{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 187&#xA;&#xA;# metrics of every WebRTC connection&#xA;webrtc_conns{id=&#34;[id]&#34;} 1&#xA;webrtc_conns_bytes_received{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1234&#xA;webrtc_conns_bytes_sent{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 187&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;pprof&lt;/h3&gt; &#xA;&lt;p&gt;A performance monitor, compatible with pprof, can be enabled with the parameter &lt;code&gt;pprof: yes&lt;/code&gt;; then the server can be queried for metrics with pprof-compatible tools, like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;go tool pprof -text http://localhost:9999/debug/pprof/goroutine&#xA;go tool pprof -text http://localhost:9999/debug/pprof/heap&#xA;go tool pprof -text http://localhost:9999/debug/pprof/profile?seconds=30&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Compile from source&lt;/h3&gt; &#xA;&lt;h4&gt;Standard&lt;/h4&gt; &#xA;&lt;p&gt;Install Go ≥ 1.20, download the repository, open a terminal in it and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go build .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The command will produce the &lt;code&gt;mediamtx&lt;/code&gt; binary.&lt;/p&gt; &#xA;&lt;h4&gt;Raspberry Pi&lt;/h4&gt; &#xA;&lt;p&gt;The server can be compiled with native support for the Raspberry Pi Camera. Compilation must happen on a Raspberry Pi Device, with the following dependencies:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go ≥ 1.20&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libcamera-dev&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libfreetype-dev&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;xxd&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;patchelf&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Download the repository, open a terminal in it and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd internal/rpicamera/exe&#xA;make&#xA;cd ../../../&#xA;go build -tags rpicamera .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The command will produce the &lt;code&gt;mediamtx&lt;/code&gt; binary.&lt;/p&gt; &#xA;&lt;h4&gt;Compile for all supported platforms&lt;/h4&gt; &#xA;&lt;p&gt;Compilation for all supported platform can be launched by using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make binaries&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The command will produce tarballs in folder &lt;code&gt;binaries/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Publish to the server&lt;/h2&gt; &#xA;&lt;h3&gt;From a webcam&lt;/h3&gt; &#xA;&lt;p&gt;To publish the video stream of a generic webcam to the server, edit &lt;code&gt;mediamtx.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  cam:&#xA;    runOnInit: ffmpeg -f v4l2 -i /dev/video0 -pix_fmt yuv420p -preset ultrafast -b:v 600k -f rtsp rtsp://localhost:$RTSP_PORT/$RTSP_PATH&#xA;    runOnInitRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the platform is Windows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  cam:&#xA;    runOnInit: ffmpeg -f dshow -i video=&#34;USB2.0 HD UVC WebCam&#34; -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -f rtsp rtsp://localhost:$RTSP_PORT/$RTSP_PATH&#xA;    runOnInitRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Where &lt;code&gt;USB2.0 HD UVC WebCam&lt;/code&gt; is the name of your webcam, that can be obtained with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -list_devices true -f dshow -i dummy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After starting the server, the webcam can be reached on &lt;code&gt;rtsp://localhost:8554/cam&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;From a Raspberry Pi Camera&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;MediaMTX&lt;/em&gt; natively support the Raspberry Pi Camera, enabling high-quality and low-latency video streaming from the camera to any user. There are a couple of requisites:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;The server must run on a Raspberry Pi, with Raspberry Pi OS bullseye or newer as operative system. Both 32 bit and 64 bit operative systems are supported.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure that the legacy camera stack is disabled. Type &lt;code&gt;sudo raspi-config&lt;/code&gt;, then go to &lt;code&gt;Interfacing options&lt;/code&gt;, &lt;code&gt;enable/disable legacy camera support&lt;/code&gt;, choose &lt;code&gt;no&lt;/code&gt;. Reboot the system.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If you want to run the standard (non-containerized) version of the server:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure that the following packages are installed:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;libcamera0&lt;/code&gt; (at least version 0.0.2)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;libfreetype6&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;download the server executable. If you&#39;re using 64-bit version of the operative system, make sure to pick the &lt;code&gt;arm64&lt;/code&gt; variant.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;edit &lt;code&gt;mediamtx.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  cam:&#xA;    source: rpiCamera&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If you want to run the server with Docker, you need to use the &lt;code&gt;latest-rpi&lt;/code&gt; image (that already contains libcamera) and set some additional flags:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it \&#xA;--network=host \&#xA;--privileged \&#xA;--tmpfs /dev/shm:exec \&#xA;-v /run/udev:/run/udev:ro \&#xA;-e MTX_PATHS_CAM_SOURCE=rpiCamera \&#xA;aler9/rtsp-simple-server:latest-rpi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After starting the server, the camera can be reached on &lt;code&gt;rtsp://raspberry-pi:8554/cam&lt;/code&gt; or &lt;code&gt;http://raspberry-pi:8888/cam&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Camera settings can be changed by using the &lt;code&gt;rpiCamera*&lt;/code&gt; parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  cam:&#xA;    source: rpiCamera&#xA;    rpiCameraWidth: 1920&#xA;    rpiCameraHeight: 1080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;All available parameters are listed in the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/mediamtx.yml&#34;&gt;sample configuration file&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;From OBS Studio&lt;/h3&gt; &#xA;&lt;p&gt;OBS Studio can publish to the server by using the RTMP protocol. In &lt;code&gt;Settings -&amp;gt; Stream&lt;/code&gt; (or in the Auto-configuration Wizard), use the following parameters:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Service: &lt;code&gt;Custom...&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Server: &lt;code&gt;rtmp://localhost&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Stream key: &lt;code&gt;mystream&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If credentials are in use, use the following parameters:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Service: &lt;code&gt;Custom...&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Server: &lt;code&gt;rtmp://localhost&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Stream key: &lt;code&gt;mystream?user=myuser&amp;amp;pass=mypass&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you want to generate a stream that can be read with WebRTC, open &lt;code&gt;Settings -&amp;gt; Output -&amp;gt; Recording&lt;/code&gt; and use the following parameters:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;FFmpeg output type: &lt;code&gt;Output to URL&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;File path or URL: &lt;code&gt;rtsp://localhost:8554/mystream&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Container format: &lt;code&gt;rtsp&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Check &lt;code&gt;show all codecs (even if potentically incompatible&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Video encoder: &lt;code&gt;h264_nvenc (libx264)&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Video encoder settings (if any): &lt;code&gt;bf=0&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Audio track: &lt;code&gt;1&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Audio encoder: &lt;code&gt;libopus&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The use the button &lt;code&gt;Start Recording&lt;/code&gt; (instead of &lt;code&gt;Start Streaming&lt;/code&gt;) to start streaming.&lt;/p&gt; &#xA;&lt;h3&gt;From OpenCV&lt;/h3&gt; &#xA;&lt;p&gt;To publish a video stream from OpenCV to the server, OpenCV must be compiled with GStreamer support, by following this procedure:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt install -y libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev gstreamer1.0-plugins-ugly gstreamer1.0-rtsp python3-dev python3-numpy&#xA;git clone --depth=1 -b 4.5.4 https://github.com/opencv/opencv&#xA;cd opencv&#xA;mkdir build &amp;amp;&amp;amp; cd build&#xA;cmake -D CMAKE_INSTALL_PREFIX=/usr -D WITH_GSTREAMER=ON ..&#xA;make -j$(nproc)&#xA;sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can check that OpenCV has been installed correctly by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 -c &#39;import cv2; print(cv2.getBuildInformation())&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And verifying that the output contains &lt;code&gt;GStreamer: YES&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Videos can be published with &lt;code&gt;VideoWriter&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cv2&#xA;import numpy as np&#xA;from time import sleep, time&#xA;&#xA;fps = 15&#xA;width = 800&#xA;height = 600&#xA;colors = [&#xA;    (0, 0, 255),&#xA;    (255, 0, 0),&#xA;    (0, 255, 0),&#xA;]&#xA;&#xA;out = cv2.VideoWriter(&#39;appsrc ! videoconvert&#39; + \&#xA;    &#39; ! x264enc speed-preset=ultrafast bitrate=600 key-int-max=&#39; + str(fps * 2) + \&#xA;    &#39; ! video/x-h264,profile=baseline&#39; + \&#xA;    &#39; ! rtspclientsink location=rtsp://localhost:8554/mystream&#39;,&#xA;    cv2.CAP_GSTREAMER, 0, fps, (width, height), True)&#xA;if not out.isOpened():&#xA;    raise Exception(&#34;can&#39;t open video writer&#34;)&#xA;&#xA;curcolor = 0&#xA;start = time()&#xA;&#xA;while True:&#xA;    frame = np.zeros((height, width, 3), np.uint8)&#xA;&#xA;    # create a rectangle&#xA;    color = colors[curcolor]&#xA;    curcolor += 1&#xA;    curcolor %= len(colors)&#xA;    for y in range(0, int(frame.shape[0] / 2)):&#xA;        for x in range(0, int(frame.shape[1] / 2)):&#xA;            frame[y][x] = color&#xA;&#xA;    out.write(frame)&#xA;    print(&#34;frame written to the server&#34;)&#xA;&#xA;    now = time()&#xA;    diff = (1 / fps) - now - start&#xA;    if diff &amp;gt; 0:&#xA;        sleep(diff)&#xA;    start = now&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;From a UDP stream&lt;/h3&gt; &#xA;&lt;p&gt;The server supports ingesting UDP/MPEG-TS packets (i.e. MPEG-TS packets sent with UDP). Packets can be unicast, broadcast or multicast. For instance, you can generate a multicast UDP/MPEG-TS stream with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gst-launch-1.0 -v mpegtsmux name=mux alignment=1 ! udpsink host=238.0.0.1 port=1234 \&#xA;videotestsrc ! video/x-raw,width=1280,height=720 ! x264enc speed-preset=ultrafast bitrate=3000 key-int-max=60 ! video/x-h264,profile=high ! mux. \&#xA;audiotestsrc ! audioconvert ! avenc_aac ! mux.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;mediamtx.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  udp:&#xA;    source: udp://238.0.0.1:1234&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After starting the server, the stream can be reached on &lt;code&gt;rtsp://localhost:8554/udp&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Read from the server&lt;/h2&gt; &#xA;&lt;h3&gt;From VLC and Ubuntu&lt;/h3&gt; &#xA;&lt;p&gt;The VLC shipped with Ubuntu 21.10 doesn&#39;t support playing RTSP due to a license issue (see &lt;a href=&#34;https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=982299&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://stackoverflow.com/questions/69766748/cvlc-cannot-play-rtsp-omxplayer-instead-can&#34;&gt;here&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;To overcome the issue, remove the default VLC instance and install the snap version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt purge -y vlc&#xA;snap install vlc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then use it to read the stream:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;vlc rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;RTSP protocol&lt;/h2&gt; &#xA;&lt;h3&gt;General usage&lt;/h3&gt; &#xA;&lt;p&gt;RTSP is a standardized protocol that allows to publish and read streams; in particular, it supports different underlying transport protocols, that are chosen by clients during the handshake with the server:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;UDP: the most performant, but doesn&#39;t work when there&#39;s a NAT/firewall between server and clients. It doesn&#39;t support encryption.&lt;/li&gt; &#xA; &lt;li&gt;UDP-multicast: allows to save bandwidth when clients are all in the same LAN, by sending packets once to a fixed multicast IP. It doesn&#39;t support encryption.&lt;/li&gt; &#xA; &lt;li&gt;TCP: the most versatile, does support encryption.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The default transport protocol is UDP. To change the transport protocol, you have to tune the configuration of your client of choice.&lt;/p&gt; &#xA;&lt;h3&gt;TCP transport&lt;/h3&gt; &#xA;&lt;p&gt;The RTSP protocol supports the TCP transport protocol, that allows to receive packets even when there&#39;s a NAT/firewall between server and clients, and supports encryption (see &lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#encryption&#34;&gt;Encryption&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;You can use &lt;em&gt;FFmpeg&lt;/em&gt; to publish a stream with the TCP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp -rtsp_transport tcp rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can use &lt;em&gt;FFmpeg&lt;/em&gt; to read that stream with the TCP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -rtsp_transport tcp -i rtsp://localhost:8554/mystream -c copy output.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can use &lt;em&gt;GStreamer&lt;/em&gt; to read that stream with the TCP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gst-launch-1.0 rtspsrc protocols=tcp location=rtsp://localhost:8554/mystream ! fakesink&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can use &lt;em&gt;VLC&lt;/em&gt; to read that stream with the TCP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;vlc --rtsp-tcp rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;UDP-multicast transport&lt;/h3&gt; &#xA;&lt;p&gt;The RTSP protocol supports the UDP-multicast transport protocol, that allows a server to send packets once, regardless of the number of connected readers, saving bandwidth.&lt;/p&gt; &#xA;&lt;p&gt;This mode must be requested by readers when handshaking with the server; once a reader has completed a handshake, the server will start sending multicast packets. Other readers will be instructed to read existing multicast packets. When all multicast readers have disconnected from the server, the latter will stop sending multicast packets.&lt;/p&gt; &#xA;&lt;p&gt;If you want to use the UDP-multicast protocol in a Wireless LAN, please be aware that the maximum bitrate supported by multicast is the one that corresponds to the lowest enabled WiFi data rate. For instance, if the 1 Mbps data rate is enabled on your router (and it is on most routers), the maximum bitrate will be 1 Mbps. To increase the maximum bitrate, use a cabled LAN or change your router settings.&lt;/p&gt; &#xA;&lt;p&gt;To request and read a stream with UDP-multicast, you can use &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -rtsp_transport udp_multicast -i rtsp://localhost:8554/mystream -c copy output.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or &lt;em&gt;GStreamer&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gst-launch-1.0 rtspsrc protocols=udp-mcast location=rtsps://ip:8554/...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or &lt;em&gt;VLC&lt;/em&gt; (append &lt;code&gt;?vlcmulticast&lt;/code&gt; to the URL):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;vlc rtsp://localhost:8554/mystream?vlcmulticast&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Encryption&lt;/h3&gt; &#xA;&lt;p&gt;Incoming and outgoing RTSP streams can be encrypted with TLS (obtaining the RTSPS protocol). A TLS certificate is needed and can be generated with OpenSSL:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048&#xA;openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;mediamtx.yml&lt;/code&gt;, and set the &lt;code&gt;protocols&lt;/code&gt;, &lt;code&gt;encryption&lt;/code&gt;, &lt;code&gt;serverKey&lt;/code&gt; and &lt;code&gt;serverCert&lt;/code&gt; parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;protocols: [tcp]&#xA;encryption: optional&#xA;serverKey: server.key&#xA;serverCert: server.crt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Streams can be published and read with the &lt;code&gt;rtsps&lt;/code&gt; scheme and the &lt;code&gt;8322&lt;/code&gt; port:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -i rtsps://ip:8322/...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the client is &lt;em&gt;GStreamer&lt;/em&gt;, disable the certificate validation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gst-launch-1.0 rtspsrc tls-validation-flags=0 location=rtsps://ip:8322/...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;At the moment &lt;em&gt;VLC&lt;/em&gt; doesn&#39;t support reading encrypted RTSP streams. A workaround consists in launching an instance of &lt;em&gt;MediaMTX&lt;/em&gt; on the same machine in which &lt;em&gt;VLC&lt;/em&gt; is running, using it for reading the encrypted stream with the proxy mode, and reading the proxied stream with &lt;em&gt;VLC&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Redirect to another server&lt;/h3&gt; &#xA;&lt;p&gt;To redirect to another server, use the &lt;code&gt;redirect&lt;/code&gt; source:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  redirected:&#xA;    source: redirect&#xA;    sourceRedirect: rtsp://otherurl/otherpath&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Fallback stream&lt;/h3&gt; &#xA;&lt;p&gt;If no one is publishing to the server, readers can be redirected to a fallback path or URL that is serving a fallback stream:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  withfallback:&#xA;    fallback: /otherpath&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Corrupted frames&lt;/h3&gt; &#xA;&lt;p&gt;In some scenarios, when reading RTSP from the server, decoded frames can be corrupted or incomplete. This can be caused by multiple reasons:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;the packet buffer of the server is too small and can&#39;t keep up with the stream throughput. A solution consists in increasing its size:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;readBufferCount: 1024&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The stream throughput is too big and the stream can&#39;t be sent correctly with the UDP transport. UDP is more performant, faster and more efficient than TCP, but doesn&#39;t have a retransmission mechanism, that is needed in case of streams that need a large bandwidth. A solution consists in switching to TCP:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;protocols: [tcp]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In case the source is a camera:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  test:&#xA;    source: rtsp://..&#xA;    sourceProtocol: tcp&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The stream throughput is too big to be handled by the network between server and readers. Upgrade the network or decrease the stream bitrate by re-encoding it.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Decrease latency&lt;/h3&gt; &#xA;&lt;p&gt;The RTSP protocol doesn&#39;t introduce any latency by itself. Latency is usually introduced by clients, that put frames in a buffer to compensate network fluctuations. In order to decrease latency, the best way consists in tuning the client. For instance, latency can be decreased with VLC by decreasing the &lt;code&gt;Network caching&lt;/code&gt; parameter, that is available in the &lt;code&gt;Open network stream&lt;/code&gt; dialog or alternatively ca be set with the command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;vlc --network-caching=50 rtsp://...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;RTMP protocol&lt;/h2&gt; &#xA;&lt;h3&gt;General usage&lt;/h3&gt; &#xA;&lt;p&gt;RTMP is a protocol that allows to read and publish streams, but is less versatile and less efficient than RTSP (doesn&#39;t support UDP, encryption, doesn&#39;t support most RTSP codecs, doesn&#39;t support feedback mechanism). It is used when there&#39;s need of publishing or reading streams from a software that supports only RTMP (for instance, OBS Studio and DJI drones).&lt;/p&gt; &#xA;&lt;p&gt;At the moment, only the H264 and AAC codecs can be used with the RTMP protocol.&lt;/p&gt; &#xA;&lt;p&gt;Streams can be published or read with the RTMP protocol, for instance with &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f flv rtmp://localhost/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or &lt;em&gt;GStreamer&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gst-launch-1.0 -v flvmux name=s ! rtmpsink location=rtmp://localhost/mystream filesrc location=file.mp4 ! qtdemux name=d d.video_0 ! queue ! s.video d.audio_0 ! queue ! s.audio&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Credentials can be provided by appending to the URL the &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;pass&lt;/code&gt; parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f flv rtmp://localhost:8554/mystream?user=myuser&amp;amp;pass=mypass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Encryption&lt;/h3&gt; &#xA;&lt;p&gt;RTMP connections can be encrypted with TLS, obtaining the RTMPS protocol. A TLS certificate is needed and can be generated with OpenSSL:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048&#xA;openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;mediamtx.yml&lt;/code&gt;, and set the &lt;code&gt;rtmpEncryption&lt;/code&gt;, &lt;code&gt;rtmpServerKey&lt;/code&gt; and &lt;code&gt;rtmpServerCert&lt;/code&gt; parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;rtmpEncryption: optional&#xA;rtmpServerKey: server.key&#xA;rtmpServerCert: server.crt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Streams can be published and read with the &lt;code&gt;rtmps&lt;/code&gt; scheme and the &lt;code&gt;1937&lt;/code&gt; port:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;rtmps://localhost:1937/...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please be aware that RTMPS is currently unsupported by &lt;em&gt;VLC&lt;/em&gt;, &lt;em&gt;FFmpeg&lt;/em&gt; and &lt;em&gt;GStreamer&lt;/em&gt;. However, you can use a proxy like &lt;a href=&#34;https://www.stunnel.org/&#34;&gt;stunnel&lt;/a&gt; or &lt;a href=&#34;https://nginx.org/&#34;&gt;nginx&lt;/a&gt; to allow RTMP clients to access RTMPS resources.&lt;/p&gt; &#xA;&lt;h2&gt;HLS protocol&lt;/h2&gt; &#xA;&lt;h3&gt;General usage&lt;/h3&gt; &#xA;&lt;p&gt;HLS is a protocol that allows to embed live streams into web pages. It works by splitting streams into segments, and by serving these segments with the HTTP protocol. Every stream published to the server can be accessed by visiting:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;http://localhost:8888/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;mystream&lt;/code&gt; is the name of a stream that is being published.&lt;/p&gt; &#xA;&lt;h3&gt;Browser support&lt;/h3&gt; &#xA;&lt;p&gt;Although the server can produce HLS with a variety of video and audio codecs (that are listed at the beginning of the README), not all browsers can read all codecs. You can check what codecs your browser can read by visiting this page:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://jsfiddle.net/4msrhudv&#34;&gt;https://jsfiddle.net/4msrhudv&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to increase the compatibility of the stream in order to support most browsers, you have to re-encode it by using the H264 and AAC codecs, for instance by using &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -i rtsp://original-source -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -c:a aac -b:a 160k -f rtsp rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Embedding&lt;/h3&gt; &#xA;&lt;p&gt;The simples way to embed a HLS stream into a web page consists in using an iframe tag:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;iframe src=&#34;http://mediamtx-ip:8888/mystream&#34; scrolling=&#34;no&#34;&amp;gt;&amp;lt;/iframe&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more advanced options, you can create and serve a custom web page by starting from the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/internal/core/hls_index.html&#34;&gt;source code of the default page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Low-Latency variant&lt;/h3&gt; &#xA;&lt;p&gt;Low-Latency HLS is a &lt;a href=&#34;https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis&#34;&gt;recently standardized&lt;/a&gt; variant of the protocol that allows to greatly reduce playback latency. It works by splitting segments into parts, that are served before the segment is complete.&lt;/p&gt; &#xA;&lt;p&gt;LL-HLS is enabled by default. Every stream published to the server can be read with LL-HLS by visiting:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://localhost:8888/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the stream is not shown correctly, try tuning the &lt;code&gt;hlsPartDuration&lt;/code&gt; parameter, for instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;hlsPartDuration: 500ms&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;HLS on Apple devices&lt;/h3&gt; &#xA;&lt;p&gt;In order to correctly display Low-Latency HLS streams in Safari running on Apple devices (iOS or macOS), a TLS certificate is needed and can be generated with OpenSSL:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048&#xA;openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Set the &lt;code&gt;hlsEncryption&lt;/code&gt;, &lt;code&gt;hlsServerKey&lt;/code&gt; and &lt;code&gt;hlsServerCert&lt;/code&gt; parameters in the configuration file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;hlsEncryption: yes&#xA;hlsServerKey: server.key&#xA;hlsServerCert: server.crt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Keep also in mind that not all H264 video streams can be played on Apple Devices due to some intrinsic properties (distance between I-Frames, profile). If the video can&#39;t be played correctly, you can either:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;re-encode it by following the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/#remuxing-re-encoding-compression&#34;&gt;guide&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;disable the Low-latency variant of HLS and go back to the legacy variant:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;hlsVariant: mpegts&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Decrease latency&lt;/h3&gt; &#xA;&lt;p&gt;in HLS, latency is introduced since a client must wait for the server to generate segments before downloading them. This latency amounts to 500ms-3s when the low-latency HLS variant is enabled (and it is by default), otherwise amounts to 1-15secs.&lt;/p&gt; &#xA;&lt;p&gt;To decrease the latency, you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;try decreasing the &lt;code&gt;hlsPartDuration&lt;/code&gt; parameter;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;try decreasing the &lt;code&gt;hlsSegmentDuration&lt;/code&gt; parameter;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The segment duration is influenced by the interval between the IDR frames of the video track. An IDR frame is a frame that can be decoded independently from the others. The server changes the segment duration in order to include at least one IDR frame into each segment. Therefore, you need to decrease the interval between the IDR frames. This can be done in two ways:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;if the stream is being hardware-generated (i.e. by a camera), there&#39;s usually a setting called &lt;em&gt;Key-Frame Interval&lt;/em&gt; in the camera configuration page&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;otherwise, the stream must be re-encoded. It&#39;s possible to tune the IDR frame interval by using ffmpeg&#39;s &lt;code&gt;-g&lt;/code&gt; option:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ffmpeg -i rtsp://original-stream -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -max_muxing_queue_size 1024 -g 30 -f rtsp rtsp://localhost:$RTSP_PORT/compressed&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;WebRTC protocol&lt;/h2&gt; &#xA;&lt;h3&gt;General usage&lt;/h3&gt; &#xA;&lt;p&gt;Every stream published to the server can be read with WebRTC by visiting:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;http://localhost:8889/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage inside a container or behind a NAT&lt;/h3&gt; &#xA;&lt;p&gt;If the server is hosted inside a container or is behind a NAT, additional configuration is required in order to allow the two WebRTC parts (the browser and the server) to establish a connection (WebRTC/ICE connection).&lt;/p&gt; &#xA;&lt;p&gt;A first method consists into forcing all WebRTC/ICE connections to pass through a single UDP server port, by using the parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;# public IP of the server&#xA;webrtcICEHostNAT1To1IPs: [192.168.x.x]&#xA;# any port of choice&#xA;webrtcICEUDPMuxAddress: :8189&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The NAT / container must then be configured in order to route all incoming UDP packets on port 8189 to the server. If you&#39;re using Docker, this can be achieved with the flag:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it \&#xA;-p 8189:8189/udp&#xA;....&#xA;aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the UDP protocol is blocked by a firewall, all WebRTC/ICE connections can be forced to pass through a single TCP server port:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;# public IP of the server&#xA;webrtcICEHostNAT1To1IPs: [192.168.x.x]&#xA;# any port of choice&#xA;webrtcICETCPPMuxAddress: :8189&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The NAT / container must then be configured in order to redirect all incoming TCP packets on port 8189 to the server. If you&#39;re using Docker, this can be achieved with the flag:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it \&#xA;-p 8189:8189&#xA;....&#xA;aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, if none of these methods work, you can force all WebRTC/ICE connections to pass through a TURN server, like &lt;a href=&#34;https://github.com/coturn/coturn&#34;&gt;coturn&lt;/a&gt;, that must be configured externally. The server address and credentials must be set in the configuration file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;webrtcICEServers: [turn:user:pass:host:port]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Where &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;pass&lt;/code&gt; are the username and password of the server. Note that &lt;code&gt;port&lt;/code&gt; is not optional.&lt;/p&gt; &#xA;&lt;p&gt;If the server uses a secret-based authentication (for instance, coturn with the &lt;code&gt;use-auth-secret&lt;/code&gt; option), it must be configured in this way:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;webrtcICEServers: [turn:AUTH_SECRET&lt;span&gt;㊙&lt;/span&gt;host:port]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;secret&lt;/code&gt; is the secret of the TURN server. &lt;em&gt;MediaMTX&lt;/em&gt; will generate a set of credentials by using the secret, and credentials will be sent to clients before the WebRTC/ICE connection is established.&lt;/p&gt; &#xA;&lt;h3&gt;Embedding&lt;/h3&gt; &#xA;&lt;p&gt;The simples way to embed a WebRTC stream into a web page consists in using an iframe tag:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;iframe src=&#34;http://mediamtx-ip:8889/mystream&#34; scrolling=&#34;no&#34;&amp;gt;&amp;lt;/iframe&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more advanced options, you can create and serve a custom web page by starting from the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/mediamtx/main/internal/core/webrtc_index.html&#34;&gt;source code of the default page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Standards&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bluenviron/gortsplib#standards&#34;&gt;RTSP/RTP/RTCP standards&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bluenviron/gohlslib#standards&#34;&gt;HLS standards&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rtmp.veriskope.com/pdf/rtmp_specification_1.0.pdf&#34;&gt;RTMP specification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/golang-standards/project-layout&#34;&gt;Golang project layout&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;p&gt;Related projects&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bluenviron/gortsplib&#34;&gt;gortsplib (RTSP library used internally)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bluenviron/gohlslib&#34;&gt;gohlslib (HLS library used internally)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pion/sdp&#34;&gt;pion/sdp (SDP library used internally)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pion/rtp&#34;&gt;pion/rtp (RTP library used internally)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pion/rtcp&#34;&gt;pion/rtcp (RTCP library used internally)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pion/webrtc&#34;&gt;pion/webrtc (WebRTC library used internally)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/notedit/rtmp&#34;&gt;notedit/rtmp (RTMP library used internally)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/asticode/go-astits&#34;&gt;go-astits (MPEG-TS library used internally)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/abema/go-mp4&#34;&gt;go-mp4 (MP4 library used internally)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>