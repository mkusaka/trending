<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-15T01:34:14Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>charmbracelet/mods</title>
    <updated>2023-05-15T01:34:14Z</updated>
    <id>tag:github.com,2023-05-15:/charmbracelet/mods</id>
    <link href="https://github.com/charmbracelet/mods" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI on the command line&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Mods!&lt;/h1&gt; &#xA;&lt;p&gt; &lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/5442bf46-b908-47af-bf4e-60f7c38951c4&#34; width=&#34;630&#34; alt=&#34;Mods product art and type treatment&#34;&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/charmbracelet/mods/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/charmbracelet/mods.svg?sanitize=true&#34; alt=&#34;Latest Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/charmbracelet/mods/actions&#34;&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;AI for the command line, built for pipelines.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/347300c6-b382-462d-9f80-8520a27e14bb&#34; width=&#34;900&#34; alt=&#34;a GIF of mods running&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;LLM based AI is really good at interpreting the output of commands and returning the results in CLI friendly text formats like Markdown. Mods is a simple tool that makes it super easy to use AI on the command line and in your pipelines.&lt;/p&gt; &#xA;&lt;p&gt;To get started, &lt;a href=&#34;https://raw.githubusercontent.com/charmbracelet/mods/main/#installation&#34;&gt;install Mods&lt;/a&gt; and check out some of the examples below. Since Mods has built-in Markdown formatting, you may also want to grab &lt;a href=&#34;https://github.com/charmbracelet/glow&#34;&gt;Glow&lt;/a&gt; to give the output some &lt;em&gt;pizzazz&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;What Can It Do?&lt;/h2&gt; &#xA;&lt;p&gt;Mods works by reading standard in and prefacing it with a prompt supplied in the &lt;code&gt;mods&lt;/code&gt; arguments. It sends the input text to an LLM and prints out the result, optionally asking the LLM to format the response as Markdown. This gives you a way to &#34;question&#34; the output of a command. Mods will also work on standard in or an argument supplied prompt individually.&lt;/p&gt; &#xA;&lt;p&gt;For example you can:&lt;/p&gt; &#xA;&lt;h3&gt;Improve Your Code&lt;/h3&gt; &#xA;&lt;p&gt;Piping source code to Mods and giving it an instruction on what to do with it gives you a lot of options for refactoring, enhancing or debugging code.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;mods -f &#34;what are your thoughts on improving this code?&#34; &amp;lt; main.go | glow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/738fe969-1c9f-4849-af8a-cde38156ce92&#34; width=&#34;900&#34; alt=&#34;a GIF of mods offering code refactoring suggestions&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Come Up With Product Features&lt;/h3&gt; &#xA;&lt;p&gt;Mods can also come up with entirely new features based on source code (or a README file).&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;mods -f &#34;come up with 10 new features for this tool.&#34; &amp;lt; main.go | glow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/025de860-798a-4ab2-b1cf-a0b32dbdbe4d&#34; width=&#34;900&#34; alt=&#34;a GIF of mods suggesting feature improvements&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Help Write Docs&lt;/h3&gt; &#xA;&lt;p&gt;Mods can quickly give you a first draft for new documentation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;mods &#34;write a new section to this readme for a feature that sends you a free rabbit if you hit r&#34; | glow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/c26a17a9-c772-40cc-b3f1-9189ac682730&#34; width=&#34;900&#34; alt=&#34;a GIF of mods contributing to a product README&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Organize Your Videos&lt;/h3&gt; &#xA;&lt;p&gt;The file system can be an amazing source of input for Mods. If you have music or video files, Mods can parse the output of &lt;code&gt;ls&lt;/code&gt; and offer really good editorialization of your content.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ls ~/vids | mods -f &#34;organize these by decade and summarize each&#34; | glow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/8204d06a-8cf1-401d-802f-2b94345dec5d&#34; width=&#34;900&#34; alt=&#34;a GIF of mods oraganizing and summarizing video from a shell ls statement&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Make Recommendations&lt;/h3&gt; &#xA;&lt;p&gt;Mods is really good at generating recommendations based on what you have as well, both for similar content but also content in an entirely different media (like getting music recommendations based on movies you have).&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ls ~/vids | mods -f &#34;recommend me 10 shows based on these, make them obscure&#34; | glow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ls ~/vids | mods -f &#34;recommend me 10 albums based on these shows, do not include any soundtrack music or music from the show&#34; | glow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/48159b19-5cae-413b-9677-dce8c6dfb6b8&#34; width=&#34;900&#34; alt=&#34;a GIF of mods generating television show recommendations based on a file listing from a directory of videos&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Read Your Fortune&lt;/h3&gt; &#xA;&lt;p&gt;It&#39;s easy to let your downloads folder grow into a chaotic never-ending pit of files, but with Mods you can use that to your advantage!&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ls ~/Downloads | mods -f &#34;tell my fortune based on these files&#34; | glow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/da2206a8-799f-4c92-b75e-bac66c56ea88&#34; width=&#34;900&#34; alt=&#34;a GIF of mods generating a fortune from the contents of a downloads directory&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Understand APIs&lt;/h3&gt; &#xA;&lt;p&gt;Mods can parse and understand the output of an API call with &lt;code&gt;curl&lt;/code&gt; and convert it to something human readable.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;curl &#34;https://api.open-meteo.com/v1/forecast?latitude=29.00&amp;amp;longitude=-90.00&amp;amp;current_weather=true&amp;amp;hourly=temperature_2m,relativehumidity_2m,windspeed_10m&#34; 2&amp;gt;/dev/null | mods -f &#34;summarize this weather data for a human.&#34; | glow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/3af13876-46a3-4bab-986e-50d9f54d2921&#34; width=&#34;900&#34; alt=&#34;a GIF of mods summarizing the weather from JSON API output&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Read The Comments (so you don&#39;t have to)&lt;/h3&gt; &#xA;&lt;p&gt;Just like with APIs, Mods can read through raw HTML and summarize the contents.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;curl &#34;https://news.ycombinator.com/item?id=30048332&#34; 2&amp;gt;/dev/null | mods -f &#34;what are the authors of these comments saying?&#34; | glow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/charmbracelet/mods/assets/25087/e4d94ef8-43aa-45ea-9be5-fe13e53d5203&#34; width=&#34;900&#34; alt=&#34;a GIF of mods summarizing the comments on hacker news&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Mods currently works with OpenAI&#39;s models, so you&#39;ll need to set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; environment variable to a valid OpenAI key, which you can get &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;from here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Then install Mods with your package manager:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# macOS or Linux&#xA;brew install charmbracelet/tap/mods&#xA;&#xA;# Debian/Ubuntu&#xA;sudo mkdir -p /etc/apt/keyrings&#xA;curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg&#xA;echo &#34;deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *&#34; | sudo tee /etc/apt/sources.list.d/charm.list&#xA;sudo apt update &amp;amp;&amp;amp; sudo apt install mods&#xA;&#xA;# Fedora/RHEL&#xA;echo &#39;[charm]&#xA;name=Charm&#xA;baseurl=https://repo.charm.sh/yum/&#xA;enabled=1&#xA;gpgcheck=1&#xA;gpgkey=https://repo.charm.sh/yum/gpg.key&#39; | sudo tee /etc/yum.repos.d/charm.repo&#xA;sudo yum install mods&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, download it:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/charmbracelet/mods/releases&#34;&gt;Packages&lt;/a&gt; are available in Debian and RPM formats&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/charmbracelet/mods/releases&#34;&gt;Binaries&lt;/a&gt; are available for Linux, macOS, and Windows&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Or, just install it with &lt;code&gt;go&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go install github.com/charmbracelet/mods@latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Settings&lt;/h2&gt; &#xA;&lt;p&gt;Mods lets you tune your query with a variety of settings that you can use with flags or environment variables.&lt;/p&gt; &#xA;&lt;h4&gt;Model&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;, &lt;code&gt;MODS_MODEL&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Mods uses &lt;code&gt;gpt-4&lt;/code&gt; by default but you can specify any OpenAI model as long as your account has access to it. Mods also plans to eventually support local models.&lt;/p&gt; &#xA;&lt;h4&gt;Format As Markdown&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;-f&lt;/code&gt;, &lt;code&gt;--format&lt;/code&gt;, &lt;code&gt;MODS_FORMAT&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;LLMs are very good at generating their response in Markdown format. They can even organize their content naturally with headers, bullet lists... Use this option to append the phrase &#34;Format the response as Markdown.&#34; to the prompt.&lt;/p&gt; &#xA;&lt;h4&gt;Max Tokens&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;--max-tokens&lt;/code&gt;, &lt;code&gt;MODS_MAX_TOKENS&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Max tokens tells the LLM to respond in less than this number of tokens. LLMs are better at longer responses so values larger than 256 tend to work best.&lt;/p&gt; &#xA;&lt;h4&gt;Temperature&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;--temp&lt;/code&gt;, &lt;code&gt;MODS_TEMP&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Sampling temperature is a number between 0.0 and 2.0 and determines how confident the model is in its choices. Higher values make the output more random and lower values make it more deterministic.&lt;/p&gt; &#xA;&lt;h4&gt;TopP&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;--topp&lt;/code&gt;, &lt;code&gt;MODS_TOPP&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Top P is an alternative to sampling temperature. It&#39;s a number between 0.0 and 2.0 with smaller numbers narrowing the domain from which the model will create its response.&lt;/p&gt; &#xA;&lt;h4&gt;No Limit&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;--no-limit&lt;/code&gt;, &lt;code&gt;MODS_NO_LIMIT&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;By default Mods attempts to size the input to the maximum size the allowed by the model. You can potentially squeeze a few more tokens into the input by setting this but also risk getting a max token exceeded error from the OpenAI API.&lt;/p&gt; &#xA;&lt;h4&gt;Include Prompt&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;-P&lt;/code&gt;, &lt;code&gt;--prompt&lt;/code&gt;, &lt;code&gt;MODS_INCLUDE_PROMPT&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Include prompt will preface the response with the entire prompt, both standard in and the prompt supplied by the arguments.&lt;/p&gt; &#xA;&lt;h4&gt;Include Prompt Args&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--prompt-args&lt;/code&gt;, &lt;code&gt;MODS_INCLUDE_PROMPT_ARGS&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Include prompt args will include &lt;em&gt;only&lt;/em&gt; the prompt supplied by the arguments. This can be useful if your standard in content is long and you just a want a summary before the response.&lt;/p&gt; &#xA;&lt;h4&gt;Max Retries&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;--max-retries&lt;/code&gt;, &lt;code&gt;MODS_MAX_RETRIES&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The maximum number of retries to failed API calls. The retries happen with an exponential backoff.&lt;/p&gt; &#xA;&lt;h4&gt;Fanciness&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;--fanciness&lt;/code&gt;, &lt;code&gt;MODS_FANCINESS&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Your desired level of fanciness.&lt;/p&gt; &#xA;&lt;h4&gt;Quiet&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;-q&lt;/code&gt;, &lt;code&gt;--quiet&lt;/code&gt;, &lt;code&gt;MODS_QUIET&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Output nothing to standard err.&lt;/p&gt; &#xA;&lt;h2&gt;Whatcha Think?&lt;/h2&gt; &#xA;&lt;p&gt;We’d love to hear your thoughts on this project. Feel free to drop us a note.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/charmcli&#34;&gt;Twitter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mastodon.social/@charmcli&#34;&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://charm.sh/chat&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/charmbracelet/mods/raw/main/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Part of &lt;a href=&#34;https://charm.sh&#34;&gt;Charm&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://charm.sh/&#34;&gt;&lt;img alt=&#34;The Charm logo&#34; width=&#34;400&#34; src=&#34;https://stuff.charm.sh/charm-badge.jpg&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Charm热爱开源 • Charm loves open source&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>google/buzzer</title>
    <updated>2023-05-15T01:34:14Z</updated>
    <id>tag:github.com,2023-05-15:/google/buzzer</id>
    <link href="https://github.com/google/buzzer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Buzzer - An eBPF Fuzzer toolchain&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/google/buzzer/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;ci_status&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Buzzer is a fuzzer toolchain that allows to write eBPF &lt;em&gt;fuzzing strategies&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;A Fuzzing strategy is a way to generate random eBPF Programs and then validate that they don&#39;t have unexpected behaviour.&lt;/p&gt; &#xA;&lt;p&gt;To run the fuzzer follow the next steps&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install &lt;a href=&#34;https://bazel.build/&#34;&gt;bazel&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;bazel build :buzzer&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run buzzer either as root:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo ./bazel-bin/buzzer_/buzzer&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;OR with CAP_BPF:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo setcap CAP_BPF=eip bazel-bin/buzzer_/buzzer&#xA;./bazel-bin/buzzer_/buzzer&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Documents:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/buzzer/main/docs/architecture/architecture.md&#34;&gt;Overall Architecture of Buzzer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/buzzer/main/docs/guides/running_with_coverage.md&#34;&gt;How to run buzzer with coverage&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Trophies&lt;/h2&gt; &#xA;&lt;p&gt;Did you find a cool bug using &lt;em&gt;Buzzer&lt;/em&gt;? Let us know via a pull request! We&#39;d like to collect all issues discovered with this framework under this section.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=71b547f561247897a0a14f3082730156c0533fed&#34;&gt;CVE-2023-2163&lt;/a&gt;: An error in the branch pruning logic of the eBPF verifier can cause unsafe paths to not be explored. The unsafe pruned paths are the actual paths taken at runtime which causes a mismatch in what the verifier thinks the values of certain registers are versus what they actually are. This mismatch can be abused to read/write arbitrary memory in the kernel by using the confused registers as base registers for memory operations.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ava-labs/avalanchego</title>
    <updated>2023-05-15T01:34:14Z</updated>
    <id>tag:github.com,2023-05-15:/ava-labs/avalanchego</id>
    <link href="https://github.com/ava-labs/avalanchego" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Go implementation of an Avalanche node.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ava-labs/avalanchego/master/resources/AvalancheLogoRed.png?raw=true&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Node implementation for the &lt;a href=&#34;https://avax.network&#34;&gt;Avalanche&lt;/a&gt; network - a blockchains platform with high throughput, and blazing fast transactions.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Avalanche is an incredibly lightweight protocol, so the minimum computer requirements are quite modest. Note that as network usage increases, hardware requirements may change.&lt;/p&gt; &#xA;&lt;p&gt;The minimum recommended hardware specification for nodes connected to Mainnet is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CPU: Equivalent of 8 AWS vCPU&lt;/li&gt; &#xA; &lt;li&gt;RAM: 16 GiB&lt;/li&gt; &#xA; &lt;li&gt;Storage: 1 TiB&lt;/li&gt; &#xA; &lt;li&gt;OS: Ubuntu 20.04/22.04 or macOS &amp;gt;= 12&lt;/li&gt; &#xA; &lt;li&gt;Network: Reliable IPv4 or IPv6 network connection, with an open public port.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you plan to build AvalancheGo from source, you will also need the following software:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://golang.org/doc/install&#34;&gt;Go&lt;/a&gt; version &amp;gt;= 1.19.6&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gcc.gnu.org/&#34;&gt;gcc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;g++&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Building From Source&lt;/h3&gt; &#xA;&lt;h4&gt;Clone The Repository&lt;/h4&gt; &#xA;&lt;p&gt;Clone the AvalancheGo repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone git@github.com:ava-labs/avalanchego.git&#xA;cd avalanchego&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will clone and checkout the &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; &#xA;&lt;h4&gt;Building AvalancheGo&lt;/h4&gt; &#xA;&lt;p&gt;Build AvalancheGo by running the build script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./scripts/build.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;avalanchego&lt;/code&gt; binary is now in the &lt;code&gt;build&lt;/code&gt; directory. To run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./build/avalanchego&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Binary Repository&lt;/h3&gt; &#xA;&lt;p&gt;Install AvalancheGo using an &lt;code&gt;apt&lt;/code&gt; repository.&lt;/p&gt; &#xA;&lt;h4&gt;Adding the APT Repository&lt;/h4&gt; &#xA;&lt;p&gt;If you already have the APT repository added, you do not need to add it again.&lt;/p&gt; &#xA;&lt;p&gt;To add the repository on Ubuntu, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo su -&#xA;wget -qO - https://downloads.avax.network/avalanchego.gpg.key | tee /etc/apt/trusted.gpg.d/avalanchego.asc&#xA;source /etc/os-release &amp;amp;&amp;amp; echo &#34;deb https://downloads.avax.network/apt $UBUNTU_CODENAME main&#34; &amp;gt; /etc/apt/sources.list.d/avalanche.list&#xA;exit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Installing the Latest Version&lt;/h4&gt; &#xA;&lt;p&gt;After adding the APT repository, install &lt;code&gt;avalanchego&lt;/code&gt; by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt update&#xA;sudo apt install avalanchego&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Binary Install&lt;/h3&gt; &#xA;&lt;p&gt;Download the &lt;a href=&#34;https://github.com/ava-labs/avalanchego/releases/latest&#34;&gt;latest build&lt;/a&gt; for your operating system and architecture.&lt;/p&gt; &#xA;&lt;p&gt;The Avalanche binary to be executed is named &lt;code&gt;avalanchego&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Docker Install&lt;/h3&gt; &#xA;&lt;p&gt;Make sure Docker is installed on the machine - so commands like &lt;code&gt;docker run&lt;/code&gt; etc. are available.&lt;/p&gt; &#xA;&lt;p&gt;Building the Docker image of latest &lt;code&gt;avalanchego&lt;/code&gt; branch can be done by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./scripts/build_image.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To check the built image, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker image ls&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The image should be tagged as &lt;code&gt;avaplatform/avalanchego:xxxxxxxx&lt;/code&gt;, where &lt;code&gt;xxxxxxxx&lt;/code&gt; is the shortened commit of the Avalanche source it was built from. To run the Avalanche node, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run -ti -p 9650:9650 -p 9651:9651 avaplatform/avalanchego:xxxxxxxx /avalanchego/build/avalanchego&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running Avalanche&lt;/h2&gt; &#xA;&lt;h3&gt;Connecting to Mainnet&lt;/h3&gt; &#xA;&lt;p&gt;To connect to the Avalanche Mainnet, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./build/avalanchego&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see some pretty ASCII art and log messages.&lt;/p&gt; &#xA;&lt;p&gt;You can use &lt;code&gt;Ctrl+C&lt;/code&gt; to kill the node.&lt;/p&gt; &#xA;&lt;h3&gt;Connecting to Fuji&lt;/h3&gt; &#xA;&lt;p&gt;To connect to the Fuji Testnet, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./build/avalanchego --network-id=fuji&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Creating a Local Testnet&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://docs.avax.network/build/tutorials/platform/create-a-local-test-network/&#34;&gt;this tutorial.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Bootstrapping&lt;/h2&gt; &#xA;&lt;p&gt;A node needs to catch up to the latest network state before it can participate in consensus and serve API calls. This process (called bootstrapping) currently takes several days for a new node connected to Mainnet.&lt;/p&gt; &#xA;&lt;p&gt;A node will not &lt;a href=&#34;https://docs.avax.network/build/avalanchego-apis/health&#34;&gt;report healthy&lt;/a&gt; until it is done bootstrapping.&lt;/p&gt; &#xA;&lt;p&gt;Improvements that reduce the amount of time it takes to bootstrap are under development.&lt;/p&gt; &#xA;&lt;p&gt;The bottleneck during bootstrapping is typically database IO. Using a more powerful CPU or increasing the database IOPS on the computer running a node will decrease the amount of time bootstrapping takes.&lt;/p&gt; &#xA;&lt;h2&gt;Generating Code&lt;/h2&gt; &#xA;&lt;p&gt;AvalancheGo uses multiple tools to generate efficient and boilerplate code.&lt;/p&gt; &#xA;&lt;h3&gt;Running protobuf codegen&lt;/h3&gt; &#xA;&lt;p&gt;To regenerate the protobuf go code, run &lt;code&gt;scripts/protobuf_codegen.sh&lt;/code&gt; from the root of the repo.&lt;/p&gt; &#xA;&lt;p&gt;This should only be necessary when upgrading protobuf versions or modifying .proto definition files.&lt;/p&gt; &#xA;&lt;p&gt;To use this script, you must have &lt;a href=&#34;https://docs.buf.build/installation&#34;&gt;buf&lt;/a&gt; (v1.11.0), protoc-gen-go (v1.28.0) and protoc-gen-go-grpc (v1.2.0) installed.&lt;/p&gt; &#xA;&lt;p&gt;To install the buf dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28.0&#xA;go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have not already, you may need to add &lt;code&gt;$GOPATH/bin&lt;/code&gt; to your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export PATH=&#34;$PATH:$(go env GOPATH)/bin&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you extract buf to ~/software/buf/bin, the following should work:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export PATH=$PATH:~/software/buf/bin/:~/go/bin&#xA;go get google.golang.org/protobuf/cmd/protoc-gen-go&#xA;go get google.golang.org/protobuf/cmd/protoc-gen-go-grpc&#xA;scripts/protobuf_codegen.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information, refer to the &lt;a href=&#34;https://grpc.io/docs/languages/go/quickstart/&#34;&gt;GRPC Golang Quick Start Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Running protobuf codegen from docker&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker build -t avalanche:protobuf_codegen -f api/Dockerfile.buf .&#xA;docker run -t -i -v $(pwd):/opt/avalanche -w/opt/avalanche avalanche:protobuf_codegen bash -c &#34;scripts/protobuf_codegen.sh&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running mock codegen&lt;/h3&gt; &#xA;&lt;p&gt;To regenerate the &lt;a href=&#34;https://github.com/golang/mock&#34;&gt;gomock&lt;/a&gt; code, run &lt;code&gt;scripts/mock.gen.sh&lt;/code&gt; from the root of the repo.&lt;/p&gt; &#xA;&lt;p&gt;This should only be necessary when modifying exported interfaces or after modifying &lt;code&gt;scripts/mock.mockgen.txt&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Versioning&lt;/h2&gt; &#xA;&lt;h3&gt;Version Semantics&lt;/h3&gt; &#xA;&lt;p&gt;AvalancheGo is first and foremost a client for the Avalanche network. The versioning of AvalancheGo follows that of the Avalanche network.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;v0.x.x&lt;/code&gt; indicates a development network version.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;v1.x.x&lt;/code&gt; indicates a production network version.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;vx.[Upgrade].x&lt;/code&gt; indicates the number of network upgrades that have occurred.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;vx.x.[Patch]&lt;/code&gt; indicates the number of client upgrades that have occurred since the last network upgrade.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Library Compatibility Guarantees&lt;/h3&gt; &#xA;&lt;p&gt;Because AvalancheGo&#39;s version denotes the network version, it is expected that interfaces exported by AvalancheGo&#39;s packages may change in &lt;code&gt;Patch&lt;/code&gt; version updates.&lt;/p&gt; &#xA;&lt;h3&gt;API Compatibility Guarantees&lt;/h3&gt; &#xA;&lt;p&gt;APIs exposed when running AvalancheGo will maintain backwards compatibility, unless the functionality is explicitly deprecated and announced when removed.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Platforms&lt;/h2&gt; &#xA;&lt;p&gt;AvalancheGo can run on different platforms, with different support tiers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tier 1&lt;/strong&gt;: Fully supported by the maintainers, guaranteed to pass all tests including e2e and stress tests.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tier 2&lt;/strong&gt;: Passes all unit and integration tests but not necessarily e2e tests.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tier 3&lt;/strong&gt;: Builds but lightly tested (or not), considered &lt;em&gt;experimental&lt;/em&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Not supported&lt;/strong&gt;: May not build and not tested, considered &lt;em&gt;unsafe&lt;/em&gt;. To be supported in the future.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following table lists currently supported platforms and their corresponding AvalancheGo support tiers:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Architecture&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Operating system&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Support tier&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;amd64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Linux&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;arm64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Linux&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;amd64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Darwin&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;amd64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Windows&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;arm&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Linux&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Not supported&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;i386&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Linux&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Not supported&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;arm64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Darwin&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Not supported&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;To officially support a new platform, one must satisfy the following requirements:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;AvalancheGo continuous integration&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Tier 1&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Tier 2&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Tier 3&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Build passes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unit and integration tests pass&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;End-to-end and stress tests pass&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Security Bugs&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;We and our community welcome responsible disclosures.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please refer to our &lt;a href=&#34;https://raw.githubusercontent.com/ava-labs/avalanchego/master/SECURITY.md&#34;&gt;Security Policy&lt;/a&gt; and &lt;a href=&#34;https://github.com/ava-labs/avalanchego/security/advisories&#34;&gt;Security Advisories&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>