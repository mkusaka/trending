<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-26T01:29:33Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ollama/ollama</title>
    <updated>2024-01-26T01:29:33Z</updated>
    <id>tag:github.com,2024-01-26:/ollama/ollama</id>
    <link href="https://github.com/ollama/ollama" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Get up and running with Llama 2, Mistral, and other large language models locally.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img alt=&#34;ollama&#34; height=&#34;200px&#34; src=&#34;https://github.com/jmorganca/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;Ollama&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/ollama&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/ollama?style=flat&amp;amp;compact=true&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Get up and running with large language models locally.&lt;/p&gt; &#xA;&lt;h3&gt;macOS&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ollama.ai/download/Ollama-darwin.zip&#34;&gt;Download&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;p&gt;Coming soon! For now, you can install Ollama on Windows via WSL2.&lt;/p&gt; &#xA;&lt;h3&gt;Linux &amp;amp; WSL2&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl https://ollama.ai/install.sh | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jmorganca/ollama/raw/main/docs/linux.md&#34;&gt;Manual install instructions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;The official &lt;a href=&#34;https://hub.docker.com/r/ollama/ollama&#34;&gt;Ollama Docker image&lt;/a&gt; &lt;code&gt;ollama/ollama&lt;/code&gt; is available on Docker Hub.&lt;/p&gt; &#xA;&lt;h3&gt;Libraries&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ollama/ollama-python&#34;&gt;ollama-python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ollama/ollama-js&#34;&gt;ollama-js&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;To run and chat with &lt;a href=&#34;https://ollama.ai/library/llama2&#34;&gt;Llama 2&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama run llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Model library&lt;/h2&gt; &#xA;&lt;p&gt;Ollama supports a list of open-source models available on &lt;a href=&#34;https://ollama.ai/library&#34; title=&#34;ollama model library&#34;&gt;ollama.ai/library&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here are some example open-source models that can be downloaded:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Parameters&lt;/th&gt; &#xA;   &lt;th&gt;Size&lt;/th&gt; &#xA;   &lt;th&gt;Download&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 2&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llama2&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;4.1GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run mistral&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dolphin Phi&lt;/td&gt; &#xA;   &lt;td&gt;2.7B&lt;/td&gt; &#xA;   &lt;td&gt;1.6GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run dolphin-phi&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi-2&lt;/td&gt; &#xA;   &lt;td&gt;2.7B&lt;/td&gt; &#xA;   &lt;td&gt;1.7GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run phi&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Neural Chat&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;4.1GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run neural-chat&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Starling&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;4.1GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run starling-lm&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Code Llama&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run codellama&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 2 Uncensored&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llama2-uncensored&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 2 13B&lt;/td&gt; &#xA;   &lt;td&gt;13B&lt;/td&gt; &#xA;   &lt;td&gt;7.3GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llama2:13b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 2 70B&lt;/td&gt; &#xA;   &lt;td&gt;70B&lt;/td&gt; &#xA;   &lt;td&gt;39GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llama2:70b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Orca Mini&lt;/td&gt; &#xA;   &lt;td&gt;3B&lt;/td&gt; &#xA;   &lt;td&gt;1.9GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run orca-mini&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run vicuna&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaVA&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;4.5GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llava&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Customize a model&lt;/h2&gt; &#xA;&lt;h3&gt;Import from GGUF&lt;/h3&gt; &#xA;&lt;p&gt;Ollama supports importing GGUF models in the Modelfile:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a file named &lt;code&gt;Modelfile&lt;/code&gt;, with a &lt;code&gt;FROM&lt;/code&gt; instruction with the local filepath to the model you want to import.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;FROM ./vicuna-33b.Q4_0.gguf&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create the model in Ollama&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ollama create example -f Modelfile&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the model&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ollama run example&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Import from PyTorch or Safetensors&lt;/h3&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/ollama/ollama/main/docs/import.md&#34;&gt;guide&lt;/a&gt; on importing models for more information.&lt;/p&gt; &#xA;&lt;h3&gt;Customize a prompt&lt;/h3&gt; &#xA;&lt;p&gt;Models from the Ollama library can be customized with a prompt. For example, to customize the &lt;code&gt;llama2&lt;/code&gt; model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama pull llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create a &lt;code&gt;Modelfile&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;FROM llama2&#xA;&#xA;# set the temperature to 1 [higher is more creative, lower is more coherent]&#xA;PARAMETER temperature 1&#xA;&#xA;# set the system message&#xA;SYSTEM &#34;&#34;&#34;&#xA;You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.&#xA;&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, create and run the model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama create mario -f ./Modelfile&#xA;ollama run mario&#xA;&amp;gt;&amp;gt;&amp;gt; hi&#xA;Hello! It&#39;s your friend Mario.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more examples, see the &lt;a href=&#34;https://raw.githubusercontent.com/ollama/ollama/main/examples&#34;&gt;examples&lt;/a&gt; directory. For more information on working with a Modelfile, see the &lt;a href=&#34;https://raw.githubusercontent.com/ollama/ollama/main/docs/modelfile.md&#34;&gt;Modelfile&lt;/a&gt; documentation.&lt;/p&gt; &#xA;&lt;h2&gt;CLI Reference&lt;/h2&gt; &#xA;&lt;h3&gt;Create a model&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama create&lt;/code&gt; is used to create a model from a Modelfile.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama create mymodel -f ./Modelfile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pull a model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama pull llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;This command can also be used to update a local model. Only the diff will be pulled.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Remove a model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama rm llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Copy a model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama cp llama2 my-llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Multiline input&lt;/h3&gt; &#xA;&lt;p&gt;For multiline input, you can wrap text with &lt;code&gt;&#34;&#34;&#34;&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; &#34;&#34;&#34;Hello,&#xA;... world!&#xA;... &#34;&#34;&#34;&#xA;I&#39;m a basic program that prints the famous &#34;Hello, world!&#34; message to the console.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Multimodal models&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; What&#39;s in this image? /Users/jmorgan/Desktop/smile.png&#xA;The image features a yellow smiley face, which is likely the central focus of the picture.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pass in prompt as arguments&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ollama run llama2 &#34;Summarize this file: $(cat README.md)&#34;&#xA; Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;List models on your computer&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama list&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Start Ollama&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama serve&lt;/code&gt; is used when you want to start ollama without running the desktop application.&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;Install &lt;code&gt;cmake&lt;/code&gt; and &lt;code&gt;go&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install cmake go&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then generate dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;go generate ./...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then build the binary:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;go build .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More detailed instructions can be found in the &lt;a href=&#34;https://github.com/jmorganca/ollama/raw/main/docs/development.md&#34;&gt;developer guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Running local builds&lt;/h3&gt; &#xA;&lt;p&gt;Next, start the server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./ollama serve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, in a separate shell, run a model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./ollama run llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;REST API&lt;/h2&gt; &#xA;&lt;p&gt;Ollama has a REST API for running and managing models.&lt;/p&gt; &#xA;&lt;h3&gt;Generate a response&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl http://localhost:11434/api/generate -d &#39;{&#xA;  &#34;model&#34;: &#34;llama2&#34;,&#xA;  &#34;prompt&#34;:&#34;Why is the sky blue?&#34;&#xA;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Chat with a model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl http://localhost:11434/api/chat -d &#39;{&#xA;  &#34;model&#34;: &#34;mistral&#34;,&#xA;  &#34;messages&#34;: [&#xA;    { &#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;why is the sky blue?&#34; }&#xA;  ]&#xA;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/ollama/ollama/main/docs/api.md&#34;&gt;API documentation&lt;/a&gt; for all endpoints.&lt;/p&gt; &#xA;&lt;h2&gt;Community Integrations&lt;/h2&gt; &#xA;&lt;h3&gt;Web &amp;amp; Desktop&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bionic-gpt/bionic-gpt&#34;&gt;Bionic GPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rtcfirefly/ollama-ui&#34;&gt;HTML UI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ivanfioravanti/chatbot-ollama&#34;&gt;Chatbot UI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file&#34;&gt;Typescript UI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/richawo/minimal-llm-ui&#34;&gt;Minimalistic React UI for Ollama Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ollama-webui/ollama-webui&#34;&gt;Web UI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kevinhermawan/Ollamac&#34;&gt;Ollamac&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/enricoros/big-agi/raw/main/docs/config-ollama.md&#34;&gt;big-AGI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cheshire-cat-ai/core&#34;&gt;Cheshire Cat assistant framework&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/semperai/amica&#34;&gt;Amica&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BruceMacD/chatd&#34;&gt;chatd&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kghandour/Ollama-SwiftUI&#34;&gt;Ollama-SwiftUI&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Terminal&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggozad/oterm&#34;&gt;oterm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/s-kostyaev/ellama&#34;&gt;Ellama Emacs client&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zweifisch/ollama&#34;&gt;Emacs client&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/David-Kunz/gen.nvim&#34;&gt;gen.nvim&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nomnivore/ollama.nvim&#34;&gt;ollama.nvim&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huynle/ogpt.nvim&#34;&gt;ogpt.nvim&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/karthink/gptel&#34;&gt;gptel Emacs client&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dustinblackman/oatmeal&#34;&gt;Oatmeal&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pgibler/cmdh&#34;&gt;cmdh&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Database&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mindsdb/mindsdb/raw/staging/mindsdb/integrations/handlers/ollama_handler/README.md&#34;&gt;MindsDB&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Package managers&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://archlinux.org/packages/extra/x86_64/ollama/&#34;&gt;Pacman&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Libraries&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/docs/integrations/llms/ollama&#34;&gt;LangChain&lt;/a&gt; and &lt;a href=&#34;https://js.langchain.com/docs/modules/model_io/models/llms/integrations/ollama&#34;&gt;LangChain.js&lt;/a&gt; with &lt;a href=&#34;https://js.langchain.com/docs/use_cases/question_answering/local_retrieval_qa&#34;&gt;example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tmc/langchaingo/&#34;&gt;LangChainGo&lt;/a&gt; with &lt;a href=&#34;https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example&#34;&gt;example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpt-index.readthedocs.io/en/stable/examples/llm/ollama.html&#34;&gt;LlamaIndex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BerriAI/litellm&#34;&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/awaescher/OllamaSharp&#34;&gt;OllamaSharp for .NET&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gbaptista/ollama-ai&#34;&gt;Ollama for Ruby&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pepperoni21/ollama-rs&#34;&gt;Ollama-rs for Rust&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/amithkoujalgi/ollama4j&#34;&gt;Ollama4j for Java&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelfusion.dev/integration/model-provider/ollama&#34;&gt;ModelFusion Typescript Library&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kevinhermawan/OllamaKit&#34;&gt;OllamaKit for Swift&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/breitburg/dart-ollama&#34;&gt;Ollama for Dart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cloudstudio/ollama-laravel&#34;&gt;Ollama for Laravel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/davidmigloz/langchain_dart&#34;&gt;LangChainDart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama&#34;&gt;Semantic Kernel - Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepset-ai/haystack-integrations/raw/main/integrations/ollama.md&#34;&gt;Haystack&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Mobile&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AugustDev/enchanted&#34;&gt;Enchanted&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mobile-Artificial-Intelligence/maid&#34;&gt;Maid&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Extensions &amp;amp; Plugins&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MassimilianoPasquini97/raycast_ollama&#34;&gt;Raycast extension&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mxyng/discollama&#34;&gt;Discollama&lt;/a&gt; (Discord bot inside the Ollama discord channel)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/continuedev/continue&#34;&gt;Continue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hinterdupfinger/obsidian-ollama&#34;&gt;Obsidian Ollama plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/omagdy7/ollama-logseq&#34;&gt;Logseq Ollama plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/samalba/dagger-chatbot&#34;&gt;Dagger Chatbot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mekb-turtle/discord-ai-bot&#34;&gt;Discord AI Bot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ruecat/ollama-telegram&#34;&gt;Ollama Telegram Bot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ej52/hass-ollama-conversation&#34;&gt;Hass Ollama Conversation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/abrenneke/rivet-plugin-ollama&#34;&gt;Rivet plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ex3ndr/llama-coder&#34;&gt;Llama Coder&lt;/a&gt; (Copilot alternative using Ollama)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/longy2k/obsidian-bmo-chatbot&#34;&gt;Obsidian BMO Chatbot plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openinterpreter.com/language-model-setup/local-models/ollama&#34;&gt;Open Interpreter&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>projectdiscovery/cvemap</title>
    <updated>2024-01-26T01:29:33Z</updated>
    <id>tag:github.com,2024-01-26:/projectdiscovery/cvemap</id>
    <link href="https://github.com/projectdiscovery/cvemap" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Navigate the CVE jungle with ease.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;CVEMap&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-_red.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/badge/github.com/projectdiscovery/cvemap&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/projectdiscovery/cvemap&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pkg.go.dev/github.com/projectdiscovery/cvemap/pkg/cvemap&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/go-reference-blue&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/projectdiscovery/cvemap/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/projectdiscovery/cvemap&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/pdiscoveryio&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/pdiscoveryio.svg?logo=twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/projectdiscovery&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/695645237418131507.svg?logo=discord&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/cvemap/main/#features&#34;&gt;Features&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/cvemap/main/#installation&#34;&gt;Installation&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/cvemap/main/#usage&#34;&gt;Usage&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/cvemap/main/#examples&#34;&gt;Example&lt;/a&gt; • &lt;a href=&#34;https://discord.gg/projectdiscovery&#34;&gt;Join Discord&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;Navigate the Common Vulnerabilities and Exposures (CVE) jungle with ease using CVEMAP, a command-line interface (CLI) tool designed to provide a structured and easily navigable interface to various vulnerability databases.&lt;/p&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/projectdiscovery/cvemap/main/static/cvemap.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;CVE Dataset Search &amp;amp; Query&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CVE to EPSS Mapping&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CVE to KEV Mapping&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CVE to CPE Mapping&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CVE to GitHub POCs Mapping&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CVE to Nuclei Template Mapping&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CVE to HackerOne report Mapping&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Customizable Filters on CVE data&lt;/li&gt; &#xA; &lt;li&gt;STDIN Input / JSONL Output&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;cvemap requires &lt;strong&gt;Go 1.21&lt;/strong&gt; to install successfully. To install, just run the below command or download pre-compiled binary from &lt;a href=&#34;https://github.com/projectdiscovery/cvemap/releases&#34;&gt;release page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;go install github.com/projectdiscovery/cvemap/cmd/cvemap@latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;cvemap -h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will display help for the tool. Here are all the switches it supports.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;Usage:&#xA;  cvemap [flags]&#xA;&#xA;Flags:&#xA;CONFIG:&#xA;   -auth  configure projectdiscovery cloud (pdcp) api key&#xA;&#xA;OPTIONS:&#xA;   -id string[]                    cve to list for given id&#xA;   -v, -vendor string[]            cve to list for given vendor&#xA;   -p, -product string[]           cve to list for given product&#xA;   -eproduct string[]              cves to exclude based on products&#xA;   -s, -severity string[]          cve to list for given severity&#xA;   -cs, -cvss-score string[]       cve to list for given cvss score&#xA;   -c, -cpe string                 cve to list for given cpe&#xA;   -es, -epss-score string         cve to list for given epss score&#xA;   -ep, -epss-percentile string[]  cve to list for given epss percentile&#xA;   -age string                     cve to list published by given age in days&#xA;   -a, -assignee string[]          cve to list for given publisher assignee&#xA;   -vs, -vstatus value             cve to list for given vulnerability status in cli output. supported: unknown, new, confirmed, unconfirmed, modified, rejected&#xA;&#xA;UPDATE:&#xA;   -up, -update                 update cvemap to latest version&#xA;   -duc, -disable-update-check  disable automatic cvemap update check&#xA;&#xA;FILTER:&#xA;   -q, -search string  search in cve data&#xA;   -k, -kev            display cves marked as exploitable vulnerabilities by cisa (default true)&#xA;   -t, -template       display cves that has public nuclei templates (default true)&#xA;   -poc                display cves that has public published poc (default true)&#xA;   -h1, -hackerone     display cves reported on hackerone (default true)&#xA;&#xA;OUTPUT:&#xA;   -f, -field value         fields to display in cli output. supported: age, kev, template, poc, cwe, epss, assignee, product, vendor, vstatus&#xA;   -fe, -exclude value      fields to exclude from cli output. supported: age, kev, template, poc, cwe, epss, assignee, product, vendor, vstatus&#xA;   -lsi, -list-id           list only the cve ids in the output&#xA;   -l, -limit int           limit the number of results to display (default 50)&#xA;   -offset int              offset the results to display&#xA;   -j, -json                return output in json format&#xA;   -epk, -enable-page-keys  enable page keys to navigate results&#xA;&#xA;DEBUG:&#xA;   -version  Version&#xA;   -silent   Silent&#xA;   -verbose  Verbose&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configuring CVEMap CLI&lt;/h2&gt; &#xA;&lt;p&gt;CVEMap CLI is built on top of the CVEMap API that requires API Token from &lt;a href=&#34;https://cloud.projectdiscovery.io/?ref=api_key&#34;&gt;ProjectDiscovery Cloud Platform&lt;/a&gt; that can be configured using environment variable named &lt;code&gt;PDCP_API_KEY&lt;/code&gt; or using interactive &lt;code&gt;-auth&lt;/code&gt; option as shown below.&lt;/p&gt; &#xA;&lt;h3&gt;Using environment variable&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;export PDCP_API_KEY=*************&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using auth option&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;cvemap -auth&#xA;&#xA;&#xA;   ______   _____  ____ ___  ____  ____&#xA;  / ___/ | / / _ \/ __ \__ \/ __ \/ __ \&#xA; / /__ | |/ /  __/ / / / / / /_/ / /_/ /&#xA; \___/ |___/\___/_/ /_/ /_/\__,_/ .___/ &#xA;                               /_/&#xA;            &#xA;&#xA;    projectdiscovery.io&#xA;&#xA;[INF] Get your free api key by signing up at https://cloud.projectdiscovery.io&#xA;[*] Enter PDCP API Key (exit to abort): *************&#xA;[INF] Successfully logged in as (@user)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running CVEMap&lt;/h2&gt; &#xA;&lt;p&gt;For details about running cvemap, see &lt;a href=&#34;https://docs.projectdiscovery.io/tools/cvemap/running&#34;&gt;https://docs.projectdiscovery.io/tools/cvemap/running&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Note&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CVE dataset gets updated in every 6 hours.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://nvd.nist.gov/developers&#34;&gt;National Vulnerability Database (NVD)&lt;/a&gt;&lt;/strong&gt;: Comprehensive CVE vulnerability data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.cisa.gov/known-exploited-vulnerabilities-catalog&#34;&gt;Known Exploited Vulnerabilities Catalog (KEV)&lt;/a&gt;&lt;/strong&gt;: Exploited vulnerabilities catalog.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.first.org/epss/data_stats&#34;&gt;Exploit Prediction Scoring System (EPSS)&lt;/a&gt;&lt;/strong&gt;: Exploit prediction scores.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://hackerone.com/hacktivity/cve_discovery&#34;&gt;HackerOne&lt;/a&gt;&lt;/strong&gt;: CVE discoveries disclosure.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/projectdiscovery/nuclei-templates&#34;&gt;Nuclei Templates&lt;/a&gt;&lt;/strong&gt;: Vulnerability validation templates.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/Live-Hack-CVE/&#34;&gt;Live-Hack-CVE&lt;/a&gt; / &lt;a href=&#34;https://github.com/nomi-sec/PoC-in-GitHub/&#34;&gt;PoC-in-GitHub&lt;/a&gt;&lt;/strong&gt; GitHub Repository: Vulnerability PoCs references.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;cvemap&lt;/strong&gt; is made with ❤️ by the &lt;a href=&#34;https://projectdiscovery.io&#34;&gt;projectdiscovery&lt;/a&gt; team and distributed under &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/cvemap/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/projectdiscovery&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/projectdiscovery/nuclei-burp-plugin/main/static/join-discord.png&#34; width=&#34;300&#34; alt=&#34;Join Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
</feed>