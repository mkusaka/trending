<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-12T01:36:35Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>maxpert/marmot</title>
    <updated>2022-09-12T01:36:35Z</updated>
    <id>tag:github.com,2022-09-12:/maxpert/marmot</id>
    <link href="https://github.com/maxpert/marmot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A distributed SQLite replicator&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Marmot&lt;/h1&gt; &#xA;&lt;p&gt;A distributed SQLite replicator.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/maxpert/marmot/actions/workflows/go.yml&#34;&gt;&lt;img src=&#34;https://github.com/maxpert/marmot/actions/workflows/go.yml/badge.svg?sanitize=true&#34; alt=&#34;Go&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is it useful for right now?&lt;/h2&gt; &#xA;&lt;p&gt;If you are using SQLite as ephemeral storage, or a scenario where eventual consistency is fine for you. Marmot can give you a solid replication between your nodes as Marmot builds on top of fault-tolerant consensus protocol (Multi-Group Raft), thus allowing robust recovery and replication. This means if you are running a medium traffic website based on SQLite you should be easily able to handle load without any problems. Read heavy workloads won&#39;t be bottle-neck at all.&lt;/p&gt; &#xA;&lt;h2&gt;Running&lt;/h2&gt; &#xA;&lt;p&gt;Build&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;go build -o build/marmot ./marmot.go&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Make sure you have 2 SQLite DBs with exact same schemas (ideally empty):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;build/marmot -bootstrap 2@127.0.0.1:8162 -bind 127.0.0.1:8161 -bind-pane localhost:6001 -node-id 1 -replicate table1,table2 -db-path /tmp/cache-1.db&#xA;build/marmot -bootstrap 1@127.0.0.1:8161 -bind 127.0.0.1:8162 -bind-pane localhost:6002 -node-id 2 -replicate table1,table2 -db-path /tmp/cache-2.db&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Marmot is picks simplicity, and lesser knobs to configure by choice. Here are command line options you can use to configure marmot:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;cleanup&lt;/code&gt; - Just cleanup and exit marmot. Useful for scenarios where you are performing a cleanup of hooks and change logs. (default: &lt;code&gt;false&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;db-path&lt;/code&gt; - Path to DB from which given tables will be replicated. These tables can be specified in &lt;code&gt;replicate&lt;/code&gt; option. (default: &lt;code&gt;/tmp/marmot.db&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;replicate&lt;/code&gt; - A comma seperated list of tables to replicate with no spaces in between (e.g. news,history) (default: [empty])&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;node-id&lt;/code&gt; - An ID number (positive integer) to represent an ID for this node, this is required to be a unique number per node, and used for consensus protocol. (default)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;bind&lt;/code&gt; - A &lt;code&gt;host:port&lt;/code&gt; combination of listen for other nodes on (default: &lt;code&gt;0.0.0.0:8610&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;raft-path&lt;/code&gt; - Path of directory to save consensus related logs, states, and snapshots (default: &lt;code&gt;/tmp/raft&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;shards&lt;/code&gt; - Number of shards over which the tables will be replicated on, marmot uses shards to distribute the ownership of replication. Which allows you to distribute load over multiple nodes rather than single master. By default, there are 16 shards which means you should be easily able to have upto 16 master nodes. Beyond that you should this flag to have a bigger cluster. Higher shards also mean more disk space, and memory usage per node. Ideally these shards should be elastic (to be implemented).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;bootstrap&lt;/code&gt; - A comma seperated list of initial bootstrap nodes &lt;code&gt;&amp;lt;node_id&amp;gt;@&amp;lt;ip&amp;gt;:&amp;lt;port&amp;gt;&lt;/code&gt; (e.g. &lt;code&gt;2@127.0.0.1:8162,3@127.0.0.1:8163&lt;/code&gt; will specify 2 bootstrap nodes for cluster).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;bind-pane&lt;/code&gt; - A &lt;code&gt;host:port&lt;/code&gt; combination for control panel address (default: &lt;code&gt;localhost:6010&lt;/code&gt;). All the endpoints are basic auth protected which should be set via &lt;code&gt;AUTH_KEY&lt;/code&gt; env variable (e.g. &lt;code&gt;AUTH_KEY=&#39;Basic ...&#39;&lt;/code&gt;). This address should not be a public accessible, and should be only used for cluster management. This in future will serve as full control panel hosting and cluster management API.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;verbose&lt;/code&gt; - Specify if system should dump debug logs on console as well. Only use this for debugging.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How does it work?&lt;/h2&gt; &#xA;&lt;p&gt;Marmot works by using a pretty basic trick so that each process that&#39;s access database can capture changes, and then Marmot can publish them to rest of the nodes. This is how it works internally:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Each table gets a &lt;code&gt;__marmot__&amp;lt;table_name&amp;gt;_change_log&lt;/code&gt; that will record a every change via triggers to change log.&lt;/li&gt; &#xA; &lt;li&gt;Each table gets &lt;code&gt;insert&lt;/code&gt;, &lt;code&gt;update&lt;/code&gt;, &lt;code&gt;delete&lt;/code&gt; triggers in that kicks in &lt;code&gt;AFTER&lt;/code&gt; the changes have been committed to the table. These triggers record &lt;code&gt;OLD&lt;/code&gt; or &lt;code&gt;NEW&lt;/code&gt; values into the table.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When you are running Marmot process, it&#39;s watching for changes on DB file and WAL file. Everytime there is a change Marmot scans these tables to publish them to other nodes in cluster by:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Gather all change records, and for each record calculate a consistent hash based on table name and primary keys.&lt;/li&gt; &#xA; &lt;li&gt;Using the hash decide the primary shard the change belongs to.&lt;/li&gt; &#xA; &lt;li&gt;Propose the change to the cluster.&lt;/li&gt; &#xA; &lt;li&gt;As soon as quorum of nodes apply the change to local tables change is considered committed, and remove from change log table. These changes are applied in an upsert manner, meaning each tuple due to consensus will have one deterministic order of changes getting applied in case or race-condition. So it&#39;s quite possible that a change committed locally is overwritten because it was not the last one in.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Limitations&lt;/h2&gt; &#xA;&lt;p&gt;Right now there are a few limitations on current solution:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Only incremental, change stream i.e. tables should exist with matching schema, and existing rows won&#39;t be copied over. SQLite tools are enough for that.&lt;/li&gt; &#xA; &lt;li&gt;Only WAL mode supported.&lt;/li&gt; &#xA; &lt;li&gt;Won&#39;t create DB file if it doesn&#39;t exist.&lt;/li&gt; &#xA; &lt;li&gt;Right now no support for copying previous data of table into existing table, or copy schema. Would be introduced in future though.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Production status&lt;/h2&gt; &#xA;&lt;p&gt;Being used for ephemeral cache storage in production services, on a very read heavy site. You can view my personal &lt;a href=&#34;https://sibte.notion.site/Marmot-056983fad27a49d4a16fb91031e6ab98&#34;&gt;status board here&lt;/a&gt;. Here is an image from a production server running Marmot:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/22441/189140305-3b7849dc-bd26-4059-bef4-bec6549ac5a7.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;FAQs&lt;/h2&gt; &#xA;&lt;p&gt;For FAQs visit &lt;a href=&#34;https://sibte.notion.site/sibte/Marmot-056983fad27a49d4a16fb91031e6ab98&#34;&gt;this page&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>inlets/mixctl</title>
    <updated>2022-09-12T01:36:35Z</updated>
    <id>tag:github.com,2022-09-12:/inlets/mixctl</id>
    <link href="https://github.com/inlets/mixctl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A tiny TCP load balancer üç∏&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;mixctl üç∏ - a tiny TCP load balancer&lt;/h2&gt; &#xA;&lt;p&gt;mixctl by &lt;a href=&#34;https://docs.inlets.dev&#34;&gt;inlets&lt;/a&gt; is a tiny TCP load balancer written in Go. It was created to help &lt;a href=&#34;https://docs.inlets.dev&#34;&gt;inlets users&lt;/a&gt; to expose multiple services hosted on different servers over a single TCP tunnel.&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s it for?&lt;/h2&gt; &#xA;&lt;p&gt;mixctl can be used to replace HAProxy, Traefik and/or Nginx Streams in certain scenarios. It could also be used as a lightweight load-balancer for K3s servers.&lt;/p&gt; &#xA;&lt;p&gt;This is a lightweight, multi-arch, multi-OS, uncomplicated way to reverse proxy different TCP connections and/or load balance them.&lt;/p&gt; &#xA;&lt;h2&gt;Usage:&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Write a &lt;code&gt;rules.yaml&lt;/code&gt; file such as: &lt;a href=&#34;https://raw.githubusercontent.com/inlets/mixctl/master/rules.example.yaml&#34;&gt;rules.example.yaml&lt;/a&gt;:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;version: 0.1&#xA;&#xA;rules:&#xA;- name: rpi-k3s&#xA;  from: 127.0.0.1:6443&#xA;  to:&#xA;    - 192.168.1.19:6443&#xA;    - 192.168.1.21:6443&#xA;    - 192.168.1.20:6443&#xA;&#xA;- name: rpi-ssh&#xA;  from: 127.0.0.1:22222&#xA;  to:&#xA;    - 192.168.1.19:22&#xA;    - 192.168.1.21:22&#xA;    - 192.168.1.20:22&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the tool: &lt;code&gt;mixctl -f ./rules.yaml&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Test out the proxy by calling your local endpoint such as &lt;code&gt;curl -k https://127.0.0.1:6443&lt;/code&gt; and you should get a response back from each of the upstream endpoints.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Now, if you&#39;re an inlets user, run &lt;code&gt;inlets-pro tcp client --ports 6443 --ports 22222 --upstream 127.0.0.1&lt;/code&gt;, this exposes the ports that mixctl is listening to the tunnel server.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Connect to ports 6443 or 22222 on your inlets Pro tunnel server to access any of the servers in the &#34;to&#34; array. The connections will be load balanced (with a random spread) if there are multiple hosts in the &lt;code&gt;to&lt;/code&gt; field.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;To make the upstream address listen on all interfaces, use &lt;code&gt;0.0.0.0&lt;/code&gt; instead of &lt;code&gt;127.0.0.1&lt;/code&gt; in the &lt;code&gt;from&lt;/code&gt; field.&lt;/p&gt; &#xA;&lt;p&gt;The port for the from and to addresses do not need to match.&lt;/p&gt; &#xA;&lt;p&gt;See also:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;-t&lt;/code&gt; - specify the dial timeout for an upstream host in the &#34;to&#34; field of the config file.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-v&lt;/code&gt; - verbose logging - set to false to turn off logs of connections established and closed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This software is licensed MIT.&lt;/p&gt; &#xA;&lt;h2&gt;See also&lt;/h2&gt; &#xA;&lt;h3&gt;inlets-connect&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/alexellis/inlets-connect&#34;&gt;inlets-connect&lt;/a&gt; is an equally tiny HTTP CONNECT proxy, designed to help users proxy HTTP and HTTPS endpoints over a single inlets tunnel.&lt;/p&gt; &#xA;&lt;h3&gt;&#34;cloud-provision&#34; library&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/inlets/cloud-provision&#34;&gt;cloud-provision&lt;/a&gt; library is used by &lt;a href=&#34;https://github.com/inlets/inletsctl&#34;&gt;inletsctl&lt;/a&gt; to create HTTP and TCP tunnel servers (VMs) with inlets pre-installed.&lt;/p&gt; &#xA;&lt;p&gt;You can think of it like a low-level Terraform, which supports various popular clouds and VPS providers. Specify the plan, name, and user-data to configure the node with your desired software.&lt;/p&gt; &#xA;&lt;h3&gt;IPVS as an alternative to mixctl&lt;/h3&gt; &#xA;&lt;p&gt;IP Virtual Server (IPVS)? &lt;a href=&#34;https://debugged.it/blog/ipvs-the-linux-load-balancer/&#34;&gt;IPVS&lt;/a&gt; is going to be more performant because it&#39;s part of the Linux kernel-space, instead of user-space (where normal programs like mixctl run). However IPVS requires a Linux host, additional Kernel modules to be loaded, and special Linux Kernel privileges, which you may be remiss to grant if using Docker or Kubernetes.&lt;/p&gt; &#xA;&lt;p&gt;Instead, mixctl is a lightweight, multi-arch, multi-OS, uncomplicated way to reverse proxy different TCP connections and/or load balance them.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>arl/statsviz</title>
    <updated>2022-09-12T01:36:35Z</updated>
    <id>tag:github.com,2022-09-12:/arl/statsviz</id>
    <link href="https://github.com/arl/statsviz" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üöÄ Visualise Go program runtime metrics in real time in your browser&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Statsviz&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pkg.go.dev/github.com/arl/statsviz&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;amp;logoColor=white&amp;amp;style=round-square&#34; alt=&#34;go.dev reference&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/avelino/awesome-go&#34;&gt;&lt;img src=&#34;https://awesome.re/mentioned-badge.svg?sanitize=true&#34; alt=&#34;Mentioned in Awesome Go&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/arl/statsviz/tag/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/tag/arl/statsviz.svg?sanitize=true&#34; alt=&#34;Latest tag&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/arl/statsviz/actions&#34;&gt;&lt;img src=&#34;https://github.com/arl/statsviz/workflows/Tests-linux/badge.svg?sanitize=true&#34; alt=&#34;Test Actions Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/arl/statsviz/actions&#34;&gt;&lt;img src=&#34;https://github.com/arl/statsviz/workflows/Tests-others/badge.svg?sanitize=true&#34; alt=&#34;Test Actions Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/arl/statsviz&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/arl/statsviz/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;Statsviz Gopher Logo&#34; width=&#34;160&#34; src=&#34;https://raw.githubusercontent.com/arl/statsviz/readme-docs/logo.png?sanitize=true&#34;&gt; &lt;img alt=&#34;statsviz ui&#34; width=&#34;450&#34; align=&#34;right&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/window.png&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Visualise Go program runtime metrics data in real time: heap, objects, goroutines, GC pauses, scheduler, etc. in your browser.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Download the latest version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;go get github.com/arl/statsviz@latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Register statsviz endpoint on your server &lt;a href=&#34;https://pkg.go.dev/net/http?tab=doc#ServeMux&#34;&gt;http.ServeMux&lt;/a&gt; (preferred method):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;mux := http.NewServeMux()&#xA;statsviz.Register(mux)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or register on &lt;code&gt;http.DefaultServeMux&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;statsviz.RegisterDefault()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default statsviz is served at &lt;code&gt;/debug/statsviz/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If your application is not already running an HTTP server, you need to start one. Add &lt;code&gt;&#34;net/http&#34;&lt;/code&gt; and &lt;code&gt;&#34;log&#34;&lt;/code&gt; to your imports and the following code to your &lt;code&gt;main&lt;/code&gt; function:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;go func() {&#xA;    log.Println(http.ListenAndServe(&#34;localhost:6060&#34;, nil))&#xA;}()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then open your browser at &lt;a href=&#34;http://localhost:6060/debug/statsviz/&#34;&gt;http://localhost:6060/debug/statsviz/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;How does that work?&lt;/h2&gt; &#xA;&lt;p&gt;Statsviz serves 2 HTTP endpoints:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The first one (&lt;code&gt;/debug/statsviz&lt;/code&gt;) serves a web page with statsviz user interface, showing initially empty plots.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The second HTTP handler (&lt;code&gt;/debug/statsviz/ws&lt;/code&gt;) listens for a WebSocket connection that will be initiated by statsviz web page as soon as it&#39;s loaded in your browser.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;That&#39;s it, now your application sends all &lt;a href=&#34;https://pkg.go.dev/runtime/metrics&#34;&gt;runtime/metrics&lt;/a&gt; data points to the web page, once per second.&lt;/p&gt; &#xA;&lt;p&gt;Data points are stored in-browser in a circular buffer which keep tracks of a predefined number of datapoints.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;h3&gt;Go API&lt;/h3&gt; &#xA;&lt;p&gt;Check out the API reference on &lt;a href=&#34;https://pkg.go.dev/github.com/arl/statsviz#section-documentation&#34;&gt;pkg.go.dev&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;User interface&lt;/h3&gt; &#xA;&lt;p&gt;The controls at the top of the page act on all plots:&lt;/p&gt; &#xA;&lt;img alt=&#34;menu&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/menu-001.png&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;the groom icon shows/hides the vertical lines representing garbage collections.&lt;/li&gt; &#xA; &lt;li&gt;the time range selector defines the visualized time span.&lt;/li&gt; &#xA; &lt;li&gt;the play/pause icon allows to stop plots from being refreshed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;On top of each plot you&#39;ll find 2 icons:&lt;/p&gt; &#xA;&lt;img alt=&#34;menu&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/plot.menu-001.png&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;the camera icon downloads the plot as a PNG image.&lt;/li&gt; &#xA; &lt;li&gt;the info icon shows information about the current plot.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Plots&lt;/h4&gt; &#xA;&lt;h5&gt;Heap (global)&lt;/h5&gt; &#xA;&lt;img alt=&#34;Heap (global) image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/heap-global.png&#34;&gt; &#xA;&lt;h5&gt;Heap (details)&lt;/h5&gt; &#xA;&lt;img alt=&#34;Heap (details) image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/heap-details.png&#34;&gt; &#xA;&lt;h5&gt;Live Objects in Heap&lt;/h5&gt; &#xA;&lt;img alt=&#34;Live Objects in Heap image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/live-objects.png&#34;&gt; &#xA;&lt;h5&gt;Live Bytes in Heap&lt;/h5&gt; &#xA;&lt;img alt=&#34;Live Bytes in Heap image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/live-bytes.png&#34;&gt; &#xA;&lt;h5&gt;MSpan/MCache&lt;/h5&gt; &#xA;&lt;img alt=&#34;MSpan/MCache image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/mspan-mcache.png&#34;&gt; &#xA;&lt;h5&gt;Goroutines&lt;/h5&gt; &#xA;&lt;img alt=&#34;Goroutines image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/goroutines.png&#34;&gt; &#xA;&lt;h5&gt;Size Classes&lt;/h5&gt; &#xA;&lt;img alt=&#34;Size Classes image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/size-classes.png&#34;&gt; &#xA;&lt;h5&gt;Stop-the-world Pause Latencies&lt;/h5&gt; &#xA;&lt;img alt=&#34;Stop-the-world Pause Latencies image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/gc-pauses.png&#34;&gt; &#xA;&lt;h5&gt;Time Goroutines Spend in &#39;Runnable&#39;&lt;/h5&gt; &#xA;&lt;img alt=&#34;Time Goroutines Spend in &#39;Runnable&#39; image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/runnable-time.png&#34;&gt; &#xA;&lt;h5&gt;Starting Size of Goroutines Stacks&lt;/h5&gt; &#xA;&lt;img alt=&#34;Time Goroutines Spend in &#39;Runnable&#39; image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/gc-stack-size.png&#34;&gt; &#xA;&lt;h5&gt;Goroutine Scheduling Events&lt;/h5&gt; &#xA;&lt;img alt=&#34;Time Goroutines Spend in &#39;Runnable&#39; image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/sched-events.png&#34;&gt; &#xA;&lt;h5&gt;CGO Calls&lt;/h5&gt; &#xA;&lt;img alt=&#34;CGO Calls image&#34; src=&#34;https://github.com/arl/statsviz/raw/readme-docs/runtime-metrics/cgo.png&#34;&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;Check out the &lt;a href=&#34;https://raw.githubusercontent.com/arl/statsviz/main/_example/README.md&#34;&gt;_example&lt;/a&gt; directory to see various ways to use Statsviz, such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;use of &lt;code&gt;http.DefaultServeMux&lt;/code&gt; or your own &lt;code&gt;http.ServeMux&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;wrap HTTP handler behind a middleware&lt;/li&gt; &#xA; &lt;li&gt;register the web page at &lt;code&gt;/foo/bar&lt;/code&gt; instead of &lt;code&gt;/debug/statviz&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;use &lt;code&gt;https://&lt;/code&gt; rather than &lt;code&gt;http://&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;register statsviz handlers with various Go HTTP libraries/frameworks: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/valyala/fasthttp&#34;&gt;fasthttp&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/gin-gonic/gin&#34;&gt;gin&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;and many others thanks to many awesome contributors!&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Questions / Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;Use the &lt;a href=&#34;https://github.com/arl/statsviz/discussions&#34;&gt;discussions&lt;/a&gt; sections for questions.&lt;br&gt; Please use &lt;a href=&#34;https://github.com/arl/statsviz/issues/new/choose&#34;&gt;issues&lt;/a&gt; for bugs and feature requests.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Pull-requests are welcome! More details in &lt;a href=&#34;https://raw.githubusercontent.com/arl/statsviz/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/arl/statsviz/main/CHANGELOG.md&#34;&gt;CHANGELOG.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/arl/statsviz/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>