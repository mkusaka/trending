<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-11T01:34:52Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>stulzq/azure-openai-proxy</title>
    <updated>2023-04-11T01:34:52Z</updated>
    <id>tag:github.com,2023-04-11:/stulzq/azure-openai-proxy</id>
    <link href="https://github.com/stulzq/azure-openai-proxy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Azure OpenAI Service Proxy. Convert OpenAI official API request to Azure OpenAI API request. Support GPT-4.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;azure-openai-proxy&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/koordinator-sh/koordinator.svg?color=4EB1BA&amp;amp;style=flat-square&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/stulzq/azure-openai-proxy/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/stulzq/azure-openai-proxy.svg?style=flat-square&#34; alt=&#34;GitHub release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/badge/github.com/stulzq/azure-openai-proxy&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/stulzq/azure-openai-proxy&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/stulzq/azure-openai-proxy/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/stulzq/azure-openai-proxy/ci.yml?label=CI&amp;amp;logo=github&amp;amp;style=flat-square&amp;amp;branch=master&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/stulzq/azure-openai-proxy/actions/workflows/release.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/stulzq/azure-openai-proxy/release.yml?label=Release&amp;amp;logo=github&amp;amp;style=flat-square&amp;amp;branch=master&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/stulzq/azure-openai-proxy/master/CONTRIBUTING.md&#34;&gt;&lt;img src=&#34;https://badgen.net/badge/PRs/welcome/green?icon=https://api.iconify.design/octicon:git-pull-request.svg?color=white&amp;amp;style=flat-square&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;English|&lt;a href=&#34;https://www.cnblogs.com/stulzq/p/17271937.html&#34;&gt;中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Azure OpenAI Service Proxy, convert OpenAI official API request to Azure OpenAI API request, support all models, support GPT-4.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stulzq/azure-openai-proxy/master/assets/images/aoai-proxy.jpg&#34; alt=&#34;aoai-proxy.jpg&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Get Start&lt;/h2&gt; &#xA;&lt;h3&gt;Retrieve key and endpoint&lt;/h3&gt; &#xA;&lt;p&gt;To successfully make a call against Azure OpenAI, you&#39;ll need the following:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Desc&lt;/th&gt; &#xA;   &lt;th&gt;Default&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_ENDPOINT&lt;/td&gt; &#xA;   &lt;td&gt;This value can be found in the &lt;strong&gt;Keys &amp;amp; Endpoint&lt;/strong&gt; section when examining your resource from the Azure portal. Alternatively, you can find the value in &lt;strong&gt;Azure OpenAI Studio&lt;/strong&gt; &amp;gt; &lt;strong&gt;Playground&lt;/strong&gt; &amp;gt; &lt;strong&gt;Code View&lt;/strong&gt;. An example endpoint is: &lt;code&gt;https://docs-test-001.openai.azure.com/&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;N&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_API_VER&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quickstart?tabs=command-line&amp;amp;pivots=rest-api&#34;&gt;See here&lt;/a&gt; or Azure OpenAI Studio&lt;/td&gt; &#xA;   &lt;td&gt;2023-03-15-preview&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_MODEL_MAPPER&lt;/td&gt; &#xA;   &lt;td&gt;This value will correspond to the custom name you chose for your deployment when you deployed a model. This value can be found under &lt;strong&gt;Resource Management&lt;/strong&gt; &amp;gt; &lt;strong&gt;Deployments&lt;/strong&gt; in the Azure portal or alternatively under &lt;strong&gt;Management&lt;/strong&gt; &amp;gt; &lt;strong&gt;Deployments&lt;/strong&gt; in Azure OpenAI Studio.&lt;/td&gt; &#xA;   &lt;td&gt;gpt-3.5-turbo=gpt-35-turbo&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;code&gt;AZURE_OPENAI_MODEL_MAPPER&lt;/code&gt; is a mapping from Azure OpenAI deployed model names to official OpenAI model names. You can use commas to separate multiple mappings.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Format：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;AZURE_OPENAI_MODEL_MAPPER&lt;/code&gt;: &amp;lt;OpenAI Model Name&amp;gt;= &amp;lt;Azure OpenAI deployment model name&amp;gt;&lt;/p&gt; &#xA;&lt;p&gt;OpenAI Model Names: &lt;a href=&#34;https://platform.openai.com/docs/models&#34;&gt;https://platform.openai.com/docs/models&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Azure Deployment Names: &lt;strong&gt;Resource Management&lt;/strong&gt; &amp;gt; &lt;strong&gt;Deployments&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;AZURE_OPENAI_MODEL_MAPPER: gpt-3.5-turbo=azure-gpt-35&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stulzq/azure-openai-proxy/master/assets/images/endpoint.png&#34; alt=&#34;Screenshot of the overview UI for an OpenAI Resource in the Azure portal with the endpoint &amp;amp; access keys location circled in red.&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;API Key: This value can be found in the &lt;strong&gt;Keys &amp;amp; Endpoint&lt;/strong&gt; section when examining your resource from the Azure portal. You can use either &lt;code&gt;KEY1&lt;/code&gt; or &lt;code&gt;KEY2&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Use Docker&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d -p 8080:8080 --name=azure-openai-proxy \&#xA;  --env AZURE_OPENAI_ENDPOINT=your_azure_endpoint \&#xA;  --env AZURE_OPENAI_API_VER=your_azure_api_ver \&#xA;  --env AZURE_OPENAI_MODEL_MAPPER=your_azure_deploy_mapper \&#xA;  stulzq/azure-openai-proxy:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Call API:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl --location --request POST &#39;localhost:8080/v1/chat/completions&#39; \&#xA;-H &#39;Authorization: Bearer &amp;lt;Azure OpenAI Key&amp;gt;&#39; \&#xA;-H &#39;Content-Type: application/json&#39; \&#xA;-d &#39;{&#xA;    &#34;max_tokens&#34;: 1000,&#xA;    &#34;model&#34;: &#34;gpt-3.5-turbo&#34;,&#xA;    &#34;temperature&#34;: 0.8,&#xA;    &#34;top_p&#34;: 1,&#xA;    &#34;presence_penalty&#34;: 1,&#xA;    &#34;messages&#34;: [&#xA;        {&#xA;            &#34;role&#34;: &#34;user&#34;,&#xA;            &#34;content&#34;: &#34;Hello&#34;&#xA;        }&#xA;    ],&#xA;    &#34;stream&#34;: true&#xA;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Use ChatGPT-Web&lt;/h3&gt; &#xA;&lt;p&gt;ChatGPT Web: &lt;a href=&#34;https://github.com/Chanzhaoyu/chatgpt-web&#34;&gt;https://github.com/Chanzhaoyu/chatgpt-web&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stulzq/azure-openai-proxy/master/assets/images/chatgpt-web.png&#34; alt=&#34;chatgpt-web&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Envs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt; Auzre OpenAI API Key&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;AZURE_OPENAI_ENDPOINT&lt;/code&gt; Auzre OpenAI API Endpoint&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;AZURE_OPENAI_MODEL_MAPPER&lt;/code&gt; Auzre OpenAI API Deployment Name Mappings&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;docker-compose.yml:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;version: &#39;3&#39;&#xA;&#xA;services:&#xA;  chatgpt-web:&#xA;    image: chenzhaoyu94/chatgpt-web&#xA;    ports:&#xA;      - 3002:3002&#xA;    environment:&#xA;      OPENAI_API_KEY: &amp;lt;Auzre OpenAI API Key&amp;gt;&#xA;      OPENAI_API_BASE_URL: http://azure-openai:8080&#xA;      AUTH_SECRET_KEY: &#34;&#34;&#xA;      MAX_REQUEST_PER_HOUR: 1000&#xA;      TIMEOUT_MS: 60000&#xA;    depends_on:&#xA;      - azure-openai&#xA;    links:&#xA;      - azure-openai&#xA;    networks:&#xA;      - chatgpt-ns&#xA;&#xA;  azure-openai:&#xA;    image: stulzq/azure-openai-proxy&#xA;    ports:&#xA;      - 8080:8080&#xA;    environment:&#xA;      AZURE_OPENAI_ENDPOINT: &amp;lt;Auzre OpenAI API Endpoint&amp;gt;&#xA;      AZURE_OPENAI_MODEL_MAPPER: &amp;lt;Auzre OpenAI API Deployment Mapper&amp;gt;&#xA;      AZURE_OPENAI_API_VER: 2023-03-15-preview&#xA;    networks:&#xA;      - chatgpt-ns&#xA;&#xA;networks:&#xA;  chatgpt-ns:&#xA;    driver: bridge&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>inconshreveable/ngrok</title>
    <updated>2023-04-11T01:34:52Z</updated>
    <id>tag:github.com,2023-04-11:/inconshreveable/ngrok</id>
    <link href="https://github.com/inconshreveable/ngrok" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Introspected tunnels to localhost&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/inconshreveable/ngrok&#34;&gt;&lt;img src=&#34;https://travis-ci.org/inconshreveable/ngrok.svg?sanitize=true&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;ngrok - Introspected tunnels to localhost (&lt;a href=&#34;https://ngrok.com&#34;&gt;homepage&lt;/a&gt;)&lt;/h1&gt; &#xA;&lt;h3&gt;”I want to expose a local server behind a NAT or firewall to the internet.”&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://ngrok.com/static/img/overview.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is ngrok?&lt;/h2&gt; &#xA;&lt;p&gt;ngrok is a reverse proxy that creates a secure tunnel from a public endpoint to a locally running web service. ngrok captures and analyzes all traffic over the tunnel for later inspection and replay.&lt;/p&gt; &#xA;&lt;h2&gt;ngrok 2.x&lt;/h2&gt; &#xA;&lt;p&gt;ngrok 2.x is the successor to 1.x and the focus of all current development effort. Its source code is not available.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; This repository contains the code for ngrok 1.x.&lt;/p&gt; &#xA;&lt;h2&gt;Status of the ngrok 1.x project&lt;/h2&gt; &#xA;&lt;p&gt;ngrok 1.x is no longer developed, supported or maintained by its author, except to ensure that the project continues to compile. The contribution policy has the following guidelines:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;All issues against this repository will be closed unless they demonstrate a crash or other complete failure of ngrok&#39;s functionality.&lt;/li&gt; &#xA; &lt;li&gt;All issues against this repository are for 1.x only, any issues for 2.x will be closed.&lt;/li&gt; &#xA; &lt;li&gt;No new features will be added. Any pull requests with new features will be closed. Please fork the project instead.&lt;/li&gt; &#xA; &lt;li&gt;Pull requests fixing existing bugs or improving documentation are welcomed.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;The ngrok 1.x hosted service&lt;/h4&gt; &#xA;&lt;p&gt;ngrok.com ran a pay-what-you-want hosted service of 1.x from early 2013 until April 7, 2016. Afterwards, it only runs 2.x service.&lt;/p&gt; &#xA;&lt;h2&gt;Production Use&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;DO NOT RUN THIS VERSION OF NGROK (1.X) IN PRODUCTION&lt;/strong&gt;. Both the client and server are known to have serious reliability issues including memory and file descriptor leaks as well as crashes. There is also no HA story as the server is a SPOF. You are advised to run 2.0 for any production quality system.&lt;/p&gt; &#xA;&lt;h2&gt;What can I do with ngrok?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Expose any http service behind a NAT or firewall to the internet on a subdomain of ngrok.com&lt;/li&gt; &#xA; &lt;li&gt;Expose any tcp service behind a NAT or firewall to the internet on a random port of ngrok.com&lt;/li&gt; &#xA; &lt;li&gt;Inspect all http requests/responses that are transmitted over the tunnel&lt;/li&gt; &#xA; &lt;li&gt;Replay any request that was transmitted over the tunnel&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What is ngrok useful for?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Temporarily sharing a website that is only running on your development machine&lt;/li&gt; &#xA; &lt;li&gt;Demoing an app at a hackathon without deploying&lt;/li&gt; &#xA; &lt;li&gt;Developing any services which consume webhooks (HTTP callbacks) by allowing you to replay those requests&lt;/li&gt; &#xA; &lt;li&gt;Debugging and understanding any web service by inspecting the HTTP traffic&lt;/li&gt; &#xA; &lt;li&gt;Running networked services on machines that are firewalled off from the internet&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Developing on ngrok&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/inconshreveable/ngrok/master/docs/DEVELOPMENT.md&#34;&gt;ngrok developer&#39;s guide&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>