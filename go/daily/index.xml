<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-17T01:42:33Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ClickHouse/clickhouse-go</title>
    <updated>2022-06-17T01:42:33Z</updated>
    <id>tag:github.com,2022-06-17:/ClickHouse/clickhouse-go</id>
    <link href="https://github.com/ClickHouse/clickhouse-go" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Golang driver for ClickHouse&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ClickHouse &lt;a href=&#34;https://github.com/ClickHouse/clickhouse-go/actions/workflows/run-tests.yml&#34;&gt;&lt;img src=&#34;https://github.com/ClickHouse/clickhouse-go/actions/workflows/run-tests.yml/badge.svg?branch=v2&#34; alt=&#34;run-tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pkg.go.dev/github.com/ClickHouse/clickhouse-go/v2&#34;&gt;&lt;img src=&#34;https://pkg.go.dev/badge/github.com/ClickHouse/clickhouse-go/v2.svg?sanitize=true&#34; alt=&#34;Go Reference&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Golang SQL database driver for &lt;a href=&#34;https://clickhouse.com/&#34;&gt;ClickHouse&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Versions&lt;/h2&gt; &#xA;&lt;p&gt;There are two version of this driver, v1 and v2, available as separate branches.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;v1 is now in a state of a maintenance - we will only accept PRs for bug and security fixes.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Users should use v2 which is production ready and &lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/#benchmark&#34;&gt;significantly faster than v1&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Supported ClickHouse Versions&lt;/h2&gt; &#xA;&lt;p&gt;The driver is tested against the currently &lt;a href=&#34;https://github.com/ClickHouse/ClickHouse/raw/master/SECURITY.md&#34;&gt;supported versions&lt;/a&gt; of ClickHouse&lt;/p&gt; &#xA;&lt;h2&gt;Key features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Uses native ClickHouse TCP client-server protocol&lt;/li&gt; &#xA; &lt;li&gt;Compatibility with &lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/#std-databasesql-interface&#34;&gt;&lt;code&gt;database/sql&lt;/code&gt;&lt;/a&gt; (&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/#benchmark&#34;&gt;slower&lt;/a&gt; than &lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/#native-interface&#34;&gt;native interface&lt;/a&gt;!)&lt;/li&gt; &#xA; &lt;li&gt;Marshal rows into structs (&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/tests/scan_struct_test.go&#34;&gt;ScanStruct&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/native/scan_struct/main.go&#34;&gt;Select&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Unmarshal struct to row (&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/benchmark/v2/write-native-struct/main.go&#34;&gt;AppendStruct&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Connection pool&lt;/li&gt; &#xA; &lt;li&gt;Failover and load balancing&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/native/batch/main.go&#34;&gt;Bulk write support&lt;/a&gt; (for &lt;code&gt;database/sql&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/std/batch/main.go&#34;&gt;use&lt;/a&gt; &lt;code&gt;begin-&amp;gt;prepare-&amp;gt;(in loop exec)-&amp;gt;commit&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/benchmark/v2/write-async/main.go&#34;&gt;AsyncInsert&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Named and numeric placeholders support&lt;/li&gt; &#xA; &lt;li&gt;LZ4 compression support&lt;/li&gt; &#xA; &lt;li&gt;External data&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Support for the ClickHouse protocol advanced features using &lt;code&gt;Context&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Query ID&lt;/li&gt; &#xA; &lt;li&gt;Quota Key&lt;/li&gt; &#xA; &lt;li&gt;Settings&lt;/li&gt; &#xA; &lt;li&gt;OpenTelemetry&lt;/li&gt; &#xA; &lt;li&gt;Execution events: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Logs&lt;/li&gt; &#xA;   &lt;li&gt;Progress&lt;/li&gt; &#xA;   &lt;li&gt;Profile info&lt;/li&gt; &#xA;   &lt;li&gt;Profile events&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;&lt;code&gt;database/sql&lt;/code&gt; interface&lt;/h1&gt; &#xA;&lt;h2&gt;OpenDB&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;conn := clickhouse.OpenDB(&amp;amp;clickhouse.Options{&#xA;&#x9;Addr: []string{&#34;127.0.0.1:9999&#34;},&#xA;&#x9;Auth: clickhouse.Auth{&#xA;&#x9;&#x9;Database: &#34;default&#34;,&#xA;&#x9;&#x9;Username: &#34;default&#34;,&#xA;&#x9;&#x9;Password: &#34;&#34;,&#xA;&#x9;},&#xA;&#x9;TLS: &amp;amp;tls.Config{&#xA;&#x9;&#x9;InsecureSkipVerify: true,&#xA;&#x9;},&#xA;&#x9;Settings: clickhouse.Settings{&#xA;&#x9;&#x9;&#34;max_execution_time&#34;: 60,&#xA;&#x9;},&#xA;&#x9;DialTimeout: 5 * time.Second,&#xA;&#x9;Compression: &amp;amp;clickhouse.Compression{&#xA;&#x9;&#x9;clickhouse.CompressionLZ4,&#xA;&#x9;},&#xA;&#x9;Debug: true,&#xA;})&#xA;conn.SetMaxIdleConns(5)&#xA;conn.SetMaxOpenConns(10)&#xA;conn.SetConnMaxLifetime(time.Hour)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;DSN&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;hosts - comma-separated list of single address hosts for load-balancing and failover&lt;/li&gt; &#xA; &lt;li&gt;username/password - auth credentials&lt;/li&gt; &#xA; &lt;li&gt;database - select the current default database&lt;/li&gt; &#xA; &lt;li&gt;dial_timeout - a duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix such as &#34;300ms&#34;, &#34;1s&#34;. Valid time units are &#34;ms&#34;, &#34;s&#34;, &#34;m&#34;.&lt;/li&gt; &#xA; &lt;li&gt;connection_open_strategy - random/in_order (default random). &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;round-robin - choose a round-robin server from the set&lt;/li&gt; &#xA;   &lt;li&gt;in_order - first live server is chosen in specified order&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;debug - enable debug output (boolean value)&lt;/li&gt; &#xA; &lt;li&gt;compress - enable lz4 compression (boolean value)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;SSL/TLS parameters:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;secure - establish secure connection (default is false)&lt;/li&gt; &#xA; &lt;li&gt;skip_verify - skip certificate verification (default is false)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;clickhouse://username:password@host1:9000,host2:9000/database?dial_timeout=200ms&amp;amp;max_execution_time=60&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Benchmark&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/benchmark/v1/read/main.go&#34;&gt;V1 (READ)&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/benchmark/v2/read/main.go&#34;&gt;V2 (READ) std&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/benchmark/v2/read-native/main.go&#34;&gt;V2 (READ) native&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.218s&lt;/td&gt; &#xA;   &lt;td&gt;924.390ms&lt;/td&gt; &#xA;   &lt;td&gt;675.721ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/benchmark/v1/write/main.go&#34;&gt;V1 (WRITE)&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/benchmark/v2/write/main.go&#34;&gt;V2 (WRITE) std&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/benchmark/v2/write-native/main.go&#34;&gt;V2 (WRITE) native&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/benchmark/v2/write-native-columnar/main.go&#34;&gt;V2 (WRITE) by column&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.899s&lt;/td&gt; &#xA;   &lt;td&gt;1.177s&lt;/td&gt; &#xA;   &lt;td&gt;699.203ms&lt;/td&gt; &#xA;   &lt;td&gt;661.973ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go get -u github.com/ClickHouse/clickhouse-go/v2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;h3&gt;native interface&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/native/batch/main.go&#34;&gt;batch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/native/write-async&#34;&gt;async insert&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/native/write-struct/main.go&#34;&gt;batch struct&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/native/write-columnar/main.go&#34;&gt;columnar&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/native/scan_struct/main.go&#34;&gt;scan struct&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/native/bind/main.go&#34;&gt;bind params&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;std &lt;code&gt;database/sql&lt;/code&gt; interface&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/std/batch/main.go&#34;&gt;batch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/std/write-async&#34;&gt;async insert&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/std/open_db/main.go&#34;&gt;open db&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ClickHouse/clickhouse-go/v2/examples/std/bind/main.go&#34;&gt;bind params&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;A Note on TLS/SSL&lt;/h4&gt; &#xA;&lt;p&gt;At a low level all driver connect methods (DSN/OpenDB/Open) will use the &lt;a href=&#34;https://pkg.go.dev/crypto/tls&#34;&gt;Go tls package&lt;/a&gt; to establish a secure connection. The driver knows to use TLS if the Options struct contains a non-nil tls.Config pointer.&lt;/p&gt; &#xA;&lt;p&gt;Setting secure in the DSN creates a minimal tls.Config struct with only the InsecureSkipVerify field set (either true or false). It is equivalent to this code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;conn := clickhouse.OpenDB(&amp;amp;clickhouse.Options{&#xA;&#x9;...&#xA;    TLS: &amp;amp;tls.Config{&#xA;            InsecureSkipVerify: false&#xA;&#x9;}&#xA;&#x9;...&#xA;    })&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This minimal tls.Config is normally all that is necessary to connect to the secure native port (normally 9440) on a ClickHouse server. If the ClickHouse server does not have a valid certificate (expired, wrong host name, not signed by a publicly recognized root Certificate Authority), InsecureSkipVerify can be to &lt;code&gt;true&lt;/code&gt;, but that is strongly discouraged.&lt;/p&gt; &#xA;&lt;p&gt;If additional TLS parameters are necessary the application code should set the desired fields in the tls.Config struct. That can include specific cipher suites, forcing a particular TLS version (like 1.2 or 1.3), adding an internal CA certificate chain, adding a client certificate (and private key) if required by the ClickHouse server, and most of the other options that come with a more specialized security setup.&lt;/p&gt; &#xA;&lt;h2&gt;Third-party alternatives&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Database drivers:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/mailru/go-clickhouse&#34;&gt;mailru/go-clickhouse&lt;/a&gt; (uses the HTTP protocol)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/uptrace/go-clickhouse&#34;&gt;uptrace/go-clickhouse&lt;/a&gt; (uses the native TCP protocol with &lt;code&gt;database/sql&lt;/code&gt;-like API)&lt;/li&gt; &#xA;   &lt;li&gt;Drivers with columnar interface: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/vahid-sohrabloo/chconn&#34;&gt;vahid-sohrabloo/chconn&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/go-faster/ch&#34;&gt;go-faster/ch&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Insert collectors:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/YuriyNasretdinov/kittenhouse&#34;&gt;KittenHouse&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/nikepan/clickhouse-bulk&#34;&gt;nikepan/clickhouse-bulk&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>confluentinc/confluent-kafka-go</title>
    <updated>2022-06-17T01:42:33Z</updated>
    <id>tag:github.com,2022-06-17:/confluentinc/confluent-kafka-go</id>
    <link href="https://github.com/confluentinc/confluent-kafka-go" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Confluent&#39;s Apache Kafka Golang client&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Confluent&#39;s Golang Client for Apache Kafka&lt;sup&gt;TM&lt;/sup&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;confluent-kafka-go&lt;/strong&gt; is Confluent&#39;s Golang client for &lt;a href=&#34;http://kafka.apache.org/&#34;&gt;Apache Kafka&lt;/a&gt; and the &lt;a href=&#34;https://www.confluent.io/product/compare/&#34;&gt;Confluent Platform&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;High performance&lt;/strong&gt; - confluent-kafka-go is a lightweight wrapper around &lt;a href=&#34;https://github.com/edenhill/librdkafka&#34;&gt;librdkafka&lt;/a&gt;, a finely tuned C client.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reliability&lt;/strong&gt; - There are a lot of details to get right when writing an Apache Kafka client. We get them right in one place (librdkafka) and leverage this work across all of our clients (also &lt;a href=&#34;https://github.com/confluentinc/confluent-kafka-python&#34;&gt;confluent-kafka-python&lt;/a&gt; and &lt;a href=&#34;https://github.com/confluentinc/confluent-kafka-dotnet&#34;&gt;confluent-kafka-dotnet&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supported&lt;/strong&gt; - Commercial support is offered by &lt;a href=&#34;https://confluent.io/&#34;&gt;Confluent&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Future proof&lt;/strong&gt; - Confluent, founded by the creators of Kafka, is building a &lt;a href=&#34;https://www.confluent.io/product/compare/&#34;&gt;streaming platform&lt;/a&gt; with Apache Kafka at its core. It&#39;s high priority for us that client features keep pace with core Apache Kafka and components of the &lt;a href=&#34;https://www.confluent.io/product/compare/&#34;&gt;Confluent Platform&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The Golang bindings provides a high-level Producer and Consumer with support for the balanced consumer groups of Apache Kafka 0.9 and above.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;http://docs.confluent.io/current/clients/confluent-kafka-go/index.html&#34;&gt;API documentation&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;For a step-by-step guide on using the client see &lt;a href=&#34;https://developer.confluent.io/get-started/go/&#34;&gt;Getting Started with Apache Kafka and Golang&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Examples&lt;/h1&gt; &#xA;&lt;p&gt;High-level balanced consumer&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;import (&#xA;&#x9;&#34;fmt&#34;&#xA;&#x9;&#34;github.com/confluentinc/confluent-kafka-go/kafka&#34;&#xA;)&#xA;&#xA;func main() {&#xA;&#xA;&#x9;c, err := kafka.NewConsumer(&amp;amp;kafka.ConfigMap{&#xA;&#x9;&#x9;&#34;bootstrap.servers&#34;: &#34;localhost&#34;,&#xA;&#x9;&#x9;&#34;group.id&#34;:          &#34;myGroup&#34;,&#xA;&#x9;&#x9;&#34;auto.offset.reset&#34;: &#34;earliest&#34;,&#xA;&#x9;})&#xA;&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;panic(err)&#xA;&#x9;}&#xA;&#xA;&#x9;c.SubscribeTopics([]string{&#34;myTopic&#34;, &#34;^aRegex.*[Tt]opic&#34;}, nil)&#xA;&#xA;&#x9;for {&#xA;&#x9;&#x9;msg, err := c.ReadMessage(-1)&#xA;&#x9;&#x9;if err == nil {&#xA;&#x9;&#x9;&#x9;fmt.Printf(&#34;Message on %s: %s\n&#34;, msg.TopicPartition, string(msg.Value))&#xA;&#x9;&#x9;} else {&#xA;&#x9;&#x9;&#x9;// The client will automatically try to recover from all errors.&#xA;&#x9;&#x9;&#x9;fmt.Printf(&#34;Consumer error: %v (%v)\n&#34;, err, msg)&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;&#xA;&#x9;c.Close()&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Producer&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;import (&#xA;&#x9;&#34;fmt&#34;&#xA;&#x9;&#34;github.com/confluentinc/confluent-kafka-go/kafka&#34;&#xA;)&#xA;&#xA;func main() {&#xA;&#xA;&#x9;p, err := kafka.NewProducer(&amp;amp;kafka.ConfigMap{&#34;bootstrap.servers&#34;: &#34;localhost&#34;})&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;panic(err)&#xA;&#x9;}&#xA;&#xA;&#x9;defer p.Close()&#xA;&#xA;&#x9;// Delivery report handler for produced messages&#xA;&#x9;go func() {&#xA;&#x9;&#x9;for e := range p.Events() {&#xA;&#x9;&#x9;&#x9;switch ev := e.(type) {&#xA;&#x9;&#x9;&#x9;case *kafka.Message:&#xA;&#x9;&#x9;&#x9;&#x9;if ev.TopicPartition.Error != nil {&#xA;&#x9;&#x9;&#x9;&#x9;&#x9;fmt.Printf(&#34;Delivery failed: %v\n&#34;, ev.TopicPartition)&#xA;&#x9;&#x9;&#x9;&#x9;} else {&#xA;&#x9;&#x9;&#x9;&#x9;&#x9;fmt.Printf(&#34;Delivered message to %v\n&#34;, ev.TopicPartition)&#xA;&#x9;&#x9;&#x9;&#x9;}&#xA;&#x9;&#x9;&#x9;}&#xA;&#x9;&#x9;}&#xA;&#x9;}()&#xA;&#xA;&#x9;// Produce messages to topic (asynchronously)&#xA;&#x9;topic := &#34;myTopic&#34;&#xA;&#x9;for _, word := range []string{&#34;Welcome&#34;, &#34;to&#34;, &#34;the&#34;, &#34;Confluent&#34;, &#34;Kafka&#34;, &#34;Golang&#34;, &#34;client&#34;} {&#xA;&#x9;&#x9;p.Produce(&amp;amp;kafka.Message{&#xA;&#x9;&#x9;&#x9;TopicPartition: kafka.TopicPartition{Topic: &amp;amp;topic, Partition: kafka.PartitionAny},&#xA;&#x9;&#x9;&#x9;Value:          []byte(word),&#xA;&#x9;&#x9;}, nil)&#xA;&#x9;}&#xA;&#xA;&#x9;// Wait for message deliveries before shutting down&#xA;&#x9;p.Flush(15 * 1000)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More elaborate examples are available in the &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-go/master/examples&#34;&gt;examples&lt;/a&gt; directory, including &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-go/master/examples/confluent_cloud_example&#34;&gt;how to configure&lt;/a&gt; the Go client for use with &lt;a href=&#34;https://www.confluent.io/confluent-cloud/&#34;&gt;Confluent Cloud&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;p&gt;Supports Go 1.11+ and librdkafka 1.6.0+.&lt;/p&gt; &#xA;&lt;h2&gt;Using Go Modules&lt;/h2&gt; &#xA;&lt;p&gt;Starting with Go 1.13, you can use &lt;a href=&#34;https://blog.golang.org/using-go-modules&#34;&gt;Go Modules&lt;/a&gt; to install confluent-kafka-go.&lt;/p&gt; &#xA;&lt;p&gt;Import the &lt;code&gt;kafka&lt;/code&gt; package from GitHub in your code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;import &#34;github.com/confluentinc/confluent-kafka-go/kafka&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Build your project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go build ./...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are building for Alpine Linux (musl), &lt;code&gt;-tags musl&lt;/code&gt; must be specified.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go build -tags musl ./...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A dependency to the latest stable version of confluent-kafka-go should be automatically added to your &lt;code&gt;go.mod&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;h2&gt;Install the client&lt;/h2&gt; &#xA;&lt;p&gt;Manual install:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go get -u github.com/confluentinc/confluent-kafka-go/kafka&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Golang import:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;import &#34;github.com/confluentinc/confluent-kafka-go/kafka&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;librdkafka&lt;/h2&gt; &#xA;&lt;p&gt;Prebuilt librdkafka binaries are included with the Go client and librdkafka does not need to be installed separately on the build or target system. The following platforms are supported by the prebuilt librdkafka binaries:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Mac OSX x64&lt;/li&gt; &#xA; &lt;li&gt;glibc-based Linux x64 (e.g., RedHat, Debian, CentOS, Ubuntu, etc) - without GSSAPI/Kerberos support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;musl-based Linux 64 (Alpine) - without GSSAPI/Kerberos support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When building your application for Alpine Linux (musl libc) you must pass &lt;code&gt;-tags musl&lt;/code&gt; to &lt;code&gt;go get&lt;/code&gt;, &lt;code&gt;go build&lt;/code&gt;, etc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;CGO_ENABLED&lt;/code&gt; must NOT be set to &lt;code&gt;0&lt;/code&gt; since the Go client is based on the C library librdkafka.&lt;/p&gt; &#xA;&lt;p&gt;If GSSAPI/Kerberos authentication support is required you will need to install librdkafka separately, see the &lt;strong&gt;Installing librdkafka&lt;/strong&gt; chapter below, and then build your Go application with &lt;code&gt;-tags dynamic&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installing librdkafka&lt;/h2&gt; &#xA;&lt;p&gt;If the bundled librdkafka build is not supported on your platform, or you need a librdkafka with GSSAPI/Kerberos support, you must install librdkafka manually on the build and target system using one of the following alternatives:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For Debian and Ubuntu based distros, install &lt;code&gt;librdkafka-dev&lt;/code&gt; from the standard repositories or using &lt;a href=&#34;http://docs.confluent.io/current/installation.html#installation-apt&#34;&gt;Confluent&#39;s Deb repository&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For Redhat based distros, install &lt;code&gt;librdkafka-devel&lt;/code&gt; using &lt;a href=&#34;http://docs.confluent.io/current/installation.html#rpm-packages-via-yum&#34;&gt;Confluent&#39;s YUM repository&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For MacOS X, install &lt;code&gt;librdkafka&lt;/code&gt; from Homebrew. You may also need to brew install pkg-config if you don&#39;t already have it: &lt;code&gt;brew install librdkafka pkg-config&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For Alpine: &lt;code&gt;apk add librdkafka-dev pkgconf&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;confluent-kafka-go is not supported on Windows.&lt;/li&gt; &#xA; &lt;li&gt;For source builds, see instructions below.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Build from source:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/edenhill/librdkafka.git&#xA;cd librdkafka&#xA;./configure&#xA;make&#xA;sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After installing librdkafka you will need to build your Go application with &lt;code&gt;-tags dynamic&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you use the &lt;code&gt;master&lt;/code&gt; branch of the Go client, then you need to use the &lt;code&gt;master&lt;/code&gt; branch of librdkafka.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;confluent-kafka-go requires librdkafka v1.6.0 or later.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h1&gt;API Strands&lt;/h1&gt; &#xA;&lt;p&gt;There are two main API strands: function and channel-based.&lt;/p&gt; &#xA;&lt;h2&gt;Function-Based Consumer&lt;/h2&gt; &#xA;&lt;p&gt;Messages, errors and events are polled through the &lt;code&gt;consumer.Poll()&lt;/code&gt; function.&lt;/p&gt; &#xA;&lt;p&gt;Pros:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;More direct mapping to underlying librdkafka functionality.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Cons:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Makes it harder to read from multiple channels, but a go-routine easily solves that (see Cons in channel-based consumer below about outdated events).&lt;/li&gt; &#xA; &lt;li&gt;Slower than the channel consumer.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-go/master/examples/consumer_example&#34;&gt;examples/consumer_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Channel-Based Consumer (deprecated)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Deprecated&lt;/em&gt;: The channel-based consumer is deprecated due to the channel issues mentioned below. Use the function-based consumer.&lt;/p&gt; &#xA;&lt;p&gt;Messages, errors and events are posted on the &lt;code&gt;consumer.Events()&lt;/code&gt; channel for the application to read.&lt;/p&gt; &#xA;&lt;p&gt;Pros:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Possibly more Golang:ish&lt;/li&gt; &#xA; &lt;li&gt;Makes reading from multiple channels easy&lt;/li&gt; &#xA; &lt;li&gt;Fast&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Cons:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Outdated events and messages may be consumed due to the buffering nature of channels. The extent is limited, but not remedied, by the Events channel buffer size (&lt;code&gt;go.events.channel.size&lt;/code&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-go/master/examples/consumer_channel_example&#34;&gt;examples/consumer_channel_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Channel-Based Producer&lt;/h2&gt; &#xA;&lt;p&gt;Application writes messages to the &lt;code&gt;producer.ProducerChannel()&lt;/code&gt;. Delivery reports are emitted on the &lt;code&gt;producer.Events()&lt;/code&gt; or specified private channel.&lt;/p&gt; &#xA;&lt;p&gt;Pros:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go:ish&lt;/li&gt; &#xA; &lt;li&gt;Proper channel backpressure if librdkafka internal queue is full.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Cons:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Double queueing: messages are first queued in the channel (size is configurable) and then inside librdkafka.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-go/master/examples/producer_channel_example&#34;&gt;examples/producer_channel_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Function-Based Producer&lt;/h2&gt; &#xA;&lt;p&gt;Application calls &lt;code&gt;producer.Produce()&lt;/code&gt; to produce messages. Delivery reports are emitted on the &lt;code&gt;producer.Events()&lt;/code&gt; or specified private channel.&lt;/p&gt; &#xA;&lt;p&gt;Pros:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go:ish&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Cons:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Produce()&lt;/code&gt; is a non-blocking call, if the internal librdkafka queue is full the call will fail.&lt;/li&gt; &#xA; &lt;li&gt;Somewhat slower than the channel producer.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-go/master/examples/producer_example&#34;&gt;examples/producer_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License v2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;KAFKA is a registered trademark of The Apache Software Foundation and has been licensed for use by confluent-kafka-go. confluent-kafka-go has no affiliation with and is not endorsed by The Apache Software Foundation.&lt;/p&gt; &#xA;&lt;h1&gt;Developer Notes&lt;/h1&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-go/master/kafka/README.md&#34;&gt;kafka/README&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Contributions to the code, examples, documentation, et.al, are very much appreciated.&lt;/p&gt; &#xA;&lt;p&gt;Make your changes, run &lt;code&gt;gofmt&lt;/code&gt;, tests, etc, push your branch, create a PR, and &lt;a href=&#34;http://clabot.confluent.io/cla&#34;&gt;sign the CLA&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Confluent Cloud&lt;/h1&gt; &#xA;&lt;p&gt;For a step-by-step guide on using the Golang client with Confluent Cloud see &lt;a href=&#34;https://developer.confluent.io/get-started/go/&#34;&gt;Getting Started with Apache Kafka and Golang&lt;/a&gt; on &lt;a href=&#34;https://developer.confluent.io/&#34;&gt;Confluent Developer&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>juicedata/juicefs</title>
    <updated>2022-06-17T01:42:33Z</updated>
    <id>tag:github.com,2022-06-17:/juicedata/juicefs</id>
    <link href="https://github.com/juicedata/juicefs" rel="alternate"></link>
    <summary type="html">&lt;p&gt;JuiceFS is a distributed POSIX file system built on top of Redis and S3.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/juicedata/juicefs&#34;&gt;&lt;img alt=&#34;JuiceFS Logo&#34; src=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-logo.png&#34; width=&#34;50%&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://travis-ci.com/juicedata/juicefs&#34;&gt;&lt;img alt=&#34;Build Status&#34; src=&#34;https://travis-ci.com/juicedata/juicefs.svg?token=jKSPwswpc2ph4uMtwpHa&amp;amp;branch=main&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/juicefs/shared_invite/zt-n9h5qdxh-YD7e0JxWdesSEa9vY_f_DA&#34;&gt;&lt;img alt=&#34;Join Slack&#34; src=&#34;https://badgen.net/badge/Slack/Join%20JuiceFS/0abd59?icon=slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/juicedata/juicefs&#34;&gt;&lt;img alt=&#34;Go Report&#34; src=&#34;https://goreportcard.com/badge/github.com/juicedata/juicefs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://juicefs.com/docs/community/introduction/&#34;&gt;&lt;img alt=&#34;English doc&#34; src=&#34;https://img.shields.io/badge/docs-Doc%20Center-brightgreen&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/README_CN.md&#34;&gt;&lt;img alt=&#34;中文手册&#34; src=&#34;https://img.shields.io/badge/docs-%E4%B8%AD%E6%96%87%E6%89%8B%E5%86%8C-brightgreen&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;JuiceFS&lt;/strong&gt; is a high-performance &lt;a href=&#34;https://en.wikipedia.org/wiki/POSIX&#34;&gt;POSIX&lt;/a&gt; file system released under Apache License 2.0, particularly designed for the cloud-native environment. The data, stored via JuiceFS, will be persisted in object storage (e.g. Amazon S3), and the corresponding metadata can be persisted in various database engines such as Redis, MySQL, and SQLite based on the scenarios and requirements.&lt;/p&gt; &#xA;&lt;p&gt;With JuiceFS, massive cloud storage can be directly connected to big data, machine learning, artificial intelligence, and various application platforms in production environments. Without modifying code, the massive cloud storage can be used as efficiently as local storage.&lt;/p&gt; &#xA;&lt;p&gt;📺 &lt;strong&gt;Video&lt;/strong&gt;: &lt;a href=&#34;https://www.youtube.com/watch?v=8RdZoBG-D6Y&#34;&gt;What is JuiceFS?&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;📖 &lt;strong&gt;Document&lt;/strong&gt;: &lt;a href=&#34;https://juicefs.com/docs/community/quick_start_guide&#34;&gt;Quick start guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Highlighted Features&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fully POSIX-compatible&lt;/strong&gt;: Use as a local file system, seamlessly docking with existing applications without breaking business workflow.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fully Hadoop-compatible&lt;/strong&gt;: JuiceFS&#39; &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/deployment/hadoop_java_sdk.md&#34;&gt;Hadoop Java SDK&lt;/a&gt; is compatible with Hadoop 2.x and Hadoop 3.x as well as a variety of components in the Hadoop ecosystems.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;S3-compatible&lt;/strong&gt;: JuiceFS&#39; &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/deployment/s3_gateway.md&#34;&gt;S3 Gateway&lt;/a&gt; provides an S3-compatible interface.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cloud Native&lt;/strong&gt;: A &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/deployment/how_to_use_on_kubernetes.md&#34;&gt;Kubernetes CSI driver&lt;/a&gt; is provided for easily using JuiceFS in Kubernetes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Shareable&lt;/strong&gt;: JuiceFS is a shared file storage that can be read and written by thousands of clients.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Strong Consistency&lt;/strong&gt;: The confirmed modification will be immediately visible on all the servers mounted with the same file system.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Outstanding Performance&lt;/strong&gt;: The latency can be as low as a few milliseconds, and the throughput can be expanded nearly unlimitedly (depending on the size of the object storage). &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/benchmark/benchmark.md&#34;&gt;Test results&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Supports data encryption in transit and at rest (please refer to &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/security/encrypt.md&#34;&gt;the guide&lt;/a&gt; for more information).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Global File Locks&lt;/strong&gt;: JuiceFS supports both BSD locks (flock) and POSIX record locks (fcntl).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Data Compression&lt;/strong&gt;: JuiceFS supports &lt;a href=&#34;https://lz4.github.io/lz4&#34;&gt;LZ4&lt;/a&gt; or &lt;a href=&#34;https://facebook.github.io/zstd&#34;&gt;Zstandard&lt;/a&gt; to compress all your data.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#architecture&#34;&gt;Architecture&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#advanced-topics&#34;&gt;Advanced Topics&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#posix-compatibility&#34;&gt;POSIX Compatibility&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#performance-benchmark&#34;&gt;Performance Benchmark&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#supported-object-storage&#34;&gt;Supported Object Storage&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#who-is-using&#34;&gt;Who is using&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#roadmap&#34;&gt;Roadmap&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#reporting-issues&#34;&gt;Reporting Issues&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#contributing&#34;&gt;Contributing&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#community&#34;&gt;Community&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#usage-tracking&#34;&gt;Usage Tracking&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#license&#34;&gt;License&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#credits&#34;&gt;Credits&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#faq&#34;&gt;FAQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;JuiceFS consists of three parts:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;JuiceFS Client&lt;/strong&gt;: Coordinates object storage and metadata storage engine as well as implementation of file system interfaces such as POSIX, Hadoop, Kubernetes, and S3 gateway.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Data Storage&lt;/strong&gt;: Stores data, with supports of a variety of data storage media, e.g., local disk, public or private cloud object storage, and HDFS.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Metadata Engine&lt;/strong&gt;: Stores the corresponding metadata that contains information of file name, file size, permission group, creation and modification time and directory structure, etc., with supports of different metadata engines, e.g., Redis, MySQL, SQLite and TiKV.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-arch-new.png&#34; alt=&#34;JuiceFS Architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;JuiceFS can store the metadata of file system on Redis, which is a fast, open-source, in-memory key-value data storage, particularly suitable for storing metadata; meanwhile, all the data will be stored in object storage through JuiceFS client. &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/introduction/architecture.md&#34;&gt;Learn more&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-storage-format-new.png&#34; alt=&#34;JuiceFS Storage Format&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Each file stored in JuiceFS is split into &lt;strong&gt;&#34;Chunk&#34;&lt;/strong&gt; s at a fixed size with the default upper limit of 64 MiB. Each Chunk is composed of one or more &lt;strong&gt;&#34;Slice&#34;&lt;/strong&gt;(s), and the length of the slice varies depending on how the file is written. Each slice is composed of size-fixed &lt;strong&gt;&#34;Block&#34;&lt;/strong&gt; s, which are 4 MiB by default. These blocks will be stored in object storage in the end; at the same time, the metadata information of the file and its Chunks, Slices, and Blocks will be stored in metadata engines via JuiceFS. &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/reference/how_juicefs_store_files.md&#34;&gt;Learn more&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/how-juicefs-stores-files-new.png&#34; alt=&#34;How JuiceFS stores your files&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;When using JuiceFS, files will eventually be split into Chunks, Slices and Blocks and stored in object storage. Therefore, the source files stored in JuiceFS cannot be found in the file browser of the object storage platform; instead, there are only a chunks directory and a bunch of digitally numbered directories and files in the bucket. Don&#39;t panic! This is just the secret of the high-performance operation of JuiceFS!&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Before you begin, make sure you have:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Redis database for metadata storage&lt;/li&gt; &#xA; &lt;li&gt;Object storage for storing data blocks&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juicefs.com/docs/community/installation&#34;&gt;JuiceFS Client&lt;/a&gt; downloaded and installed&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://juicefs.com/docs/community/quick_start_guide&#34;&gt;Quick Start Guide&lt;/a&gt; in the community doc (or doc in &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/getting-started/for_local.md&#34;&gt;this repo&lt;/a&gt;) to start using JuiceFS right away!&lt;/p&gt; &#xA;&lt;h3&gt;Command Reference&lt;/h3&gt; &#xA;&lt;p&gt;Check out all the command line options in &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/reference/command_reference.md&#34;&gt;command reference&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Kubernetes&lt;/h3&gt; &#xA;&lt;p&gt;It is also very easy to use JuiceFS on Kubernetes. Please find more information &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/deployment/how_to_use_on_kubernetes.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Hadoop Java SDK&lt;/h3&gt; &#xA;&lt;p&gt;If you wanna use JuiceFS in Hadoop, check &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/deployment/hadoop_java_sdk.md&#34;&gt;Hadoop Java SDK&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Advanced Topics&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/administration/metadata/redis_best_practices.md&#34;&gt;Redis Best Practices&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/reference/how_to_setup_object_storage.md&#34;&gt;How to Setup Object Storage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/administration/cache_management.md&#34;&gt;Cache Management&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/administration/fault_diagnosis_and_analysis.md&#34;&gt;Fault Diagnosis and Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/reference/fuse_mount_options.md&#34;&gt;FUSE Mount Options&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/juicefs_on_windows.md&#34;&gt;Using JuiceFS on Windows&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/deployment/s3_gateway.md&#34;&gt;S3 Gateway&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/README.md&#34;&gt;JuiceFS User Manual&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;POSIX Compatibility&lt;/h2&gt; &#xA;&lt;p&gt;JuiceFS has passed all of the compatibility tests (8813 in total) in the latest &lt;a href=&#34;https://github.com/pjd/pjdfstest&#34;&gt;pjdfstest&lt;/a&gt; .&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;All tests successful.&#xA;&#xA;Test Summary Report&#xA;-------------------&#xA;/root/soft/pjdfstest/tests/chown/00.t          (Wstat: 0 Tests: 1323 Failed: 0)&#xA;  TODO passed:   693, 697, 708-709, 714-715, 729, 733&#xA;Files=235, Tests=8813, 233 wallclock secs ( 2.77 usr  0.38 sys +  2.57 cusr  3.93 csys =  9.65 CPU)&#xA;Result: PASS&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Aside from the POSIX features covered by pjdfstest, JuiceFS also provides:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Close-to-open consistency. Once a file is written and closed, it is guaranteed to view the written data in the following open and read. Within the same mount point, all the written data can be read immediately.&lt;/li&gt; &#xA; &lt;li&gt;Rename and all other metadata operations are atomic, which are guaranteed by Redis transaction.&lt;/li&gt; &#xA; &lt;li&gt;Opened files remain accessible after unlink from same mount point.&lt;/li&gt; &#xA; &lt;li&gt;Mmap (tested with FSx).&lt;/li&gt; &#xA; &lt;li&gt;Fallocate with punch hole support.&lt;/li&gt; &#xA; &lt;li&gt;Extended attributes (xattr).&lt;/li&gt; &#xA; &lt;li&gt;BSD locks (flock).&lt;/li&gt; &#xA; &lt;li&gt;POSIX record locks (fcntl).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Performance Benchmark&lt;/h2&gt; &#xA;&lt;h3&gt;Basic benchmark&lt;/h3&gt; &#xA;&lt;p&gt;JuiceFS provides a subcommand that can run a few basic benchmarks to help you understand how it works in your environment:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-bench.png&#34; alt=&#34;JuiceFS Bench&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Throughput&lt;/h3&gt; &#xA;&lt;p&gt;A sequential read/write benchmark has also been performed on JuiceFS, &lt;a href=&#34;https://aws.amazon.com/efs&#34;&gt;EFS&lt;/a&gt; and &lt;a href=&#34;https://github.com/s3fs-fuse/s3fs-fuse&#34;&gt;S3FS&lt;/a&gt; by &lt;a href=&#34;https://github.com/axboe/fio&#34;&gt;fio&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/sequential-read-write-benchmark.svg?sanitize=true&#34; alt=&#34;Sequential Read Write Benchmark&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Above result figure shows that JuiceFS can provide 10X more throughput than the other two (see &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/benchmark/fio.md&#34;&gt;more details&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;Metadata IOPS&lt;/h3&gt; &#xA;&lt;p&gt;A simple mdtest benchmark has been performed on JuiceFS, &lt;a href=&#34;https://aws.amazon.com/efs&#34;&gt;EFS&lt;/a&gt; and &lt;a href=&#34;https://github.com/s3fs-fuse/s3fs-fuse&#34;&gt;S3FS&lt;/a&gt; by &lt;a href=&#34;https://github.com/hpc/ior&#34;&gt;mdtest&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/metadata-benchmark.svg?sanitize=true&#34; alt=&#34;Metadata Benchmark&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The result shows that JuiceFS can provide significantly more metadata IOPS than the other two (see &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/benchmark/mdtest.md&#34;&gt;more details&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;Analyze performance&lt;/h3&gt; &#xA;&lt;p&gt;There is a virtual file called &lt;code&gt;.accesslog&lt;/code&gt; in the root of JuiceFS to show all the details of file system operations and the time they take, for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat /jfs/.accesslog&#xA;2021.01.15 08:26:11.003330 [uid:0,gid:0,pid:4403] write (17669,8666,4993160): OK &amp;lt;0.000010&amp;gt;&#xA;2021.01.15 08:26:11.003473 [uid:0,gid:0,pid:4403] write (17675,198,997439): OK &amp;lt;0.000014&amp;gt;&#xA;2021.01.15 08:26:11.003616 [uid:0,gid:0,pid:4403] write (17666,390,951582): OK &amp;lt;0.000006&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The last number on each line is the time (in seconds) that the current operation takes. You can directly use this to debug and analyze performance issues, or try &lt;code&gt;./juicefs profile /jfs&lt;/code&gt; to monitor real time statistics. Please run &lt;code&gt;./juicefs profile -h&lt;/code&gt; or refer to &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/benchmark/operations_profiling.md&#34;&gt;here&lt;/a&gt; to learn more about this subcommand.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Object Storage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Amazon S3&lt;/li&gt; &#xA; &lt;li&gt;Google Cloud Storage&lt;/li&gt; &#xA; &lt;li&gt;Azure Blob Storage&lt;/li&gt; &#xA; &lt;li&gt;Alibaba Cloud Object Storage Service (OSS)&lt;/li&gt; &#xA; &lt;li&gt;Tencent Cloud Object Storage (COS)&lt;/li&gt; &#xA; &lt;li&gt;QingStor Object Storage&lt;/li&gt; &#xA; &lt;li&gt;Ceph RGW&lt;/li&gt; &#xA; &lt;li&gt;MinIO&lt;/li&gt; &#xA; &lt;li&gt;Local disk&lt;/li&gt; &#xA; &lt;li&gt;Redis&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;JuiceFS supports almost all object storage services. &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/reference/how_to_setup_object_storage.md#supported-object-storage&#34;&gt;Learn more&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Who is using&lt;/h2&gt; &#xA;&lt;p&gt;JuiceFS is still in beta quality, and the core storage format is not stabilized yet. Thus, please do a careful and thorough evaluation before using JuiceFS in a production environment. If you are interested, feel free to do tests and give us &lt;a href=&#34;https://github.com/juicedata/juicefs/discussions&#34;&gt;feedback&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You are also welcome to share your experience of using JuiceFS with us and others. Additionally, we have collected a summary list in &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/ADOPTERS.md&#34;&gt;ADOPTERS.md&lt;/a&gt;, which includes other open source projects used with JuiceFS.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Stabilize storage format&lt;/li&gt; &#xA; &lt;li&gt;Support FoundationDB as metadata engine&lt;/li&gt; &#xA; &lt;li&gt;User and group quotas&lt;/li&gt; &#xA; &lt;li&gt;Directory quotas&lt;/li&gt; &#xA; &lt;li&gt;Snapshot&lt;/li&gt; &#xA; &lt;li&gt;Write once read many (WORM)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Reporting Issues&lt;/h2&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/juicedata/juicefs/issues&#34;&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/#community&#34;&gt;contact&lt;/a&gt; the community for any questions.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Thank you for your contribution! Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;Welcome to join the &lt;a href=&#34;https://github.com/juicedata/juicefs/discussions&#34;&gt;Discussions&lt;/a&gt; and the &lt;a href=&#34;https://join.slack.com/t/juicefs/shared_invite/zt-n9h5qdxh-YD7e0JxWdesSEa9vY_f_DA&#34;&gt;Slack channel&lt;/a&gt; to connect with JuiceFS team members and other users.&lt;/p&gt; &#xA;&lt;h2&gt;Usage Tracking&lt;/h2&gt; &#xA;&lt;p&gt;JuiceFS collects &lt;strong&gt;anonymous&lt;/strong&gt; usage data by default to help us better understand how the community is using JuiceFS. Only core metrics (e.g. version number) will be reported, and user data and any other sensitive data will not be included. The related code can be viwed &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/pkg/usage/usage.go&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You could also disable reporting easily by command line option &lt;code&gt;--no-usage-report&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./juicefs mount --no-usage-report&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;JuiceFS is open-sourced under Apache License 2.0, see &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;The design of JuiceFS was inspired by &lt;a href=&#34;https://research.google/pubs/pub51&#34;&gt;Google File System&lt;/a&gt;, &lt;a href=&#34;https://hadoop.apache.org&#34;&gt;HDFS&lt;/a&gt; and &lt;a href=&#34;https://moosefs.com&#34;&gt;MooseFS&lt;/a&gt;. Thanks for their great work!&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;Why doesn&#39;t JuiceFS support XXX object storage?&lt;/h3&gt; &#xA;&lt;p&gt;JuiceFS supports many object storage. Please check out &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/reference/how_to_setup_object_storage.md#supported-object-storage&#34;&gt;this list&lt;/a&gt; first. If the object storage you want to use is compatible with S3, you could treat it as S3. Otherwise, try reporting issue.&lt;/p&gt; &#xA;&lt;h3&gt;Can I use Redis cluster?&lt;/h3&gt; &#xA;&lt;p&gt;The simple answer is no. JuiceFS uses &lt;a href=&#34;https://redis.io/topics/transactions&#34;&gt;Redis transaction&lt;/a&gt; to guarantee the atomicity of metadata operations, which is not well supported by cluster mode. For this, sentinal or other Redis HA solution are needed.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/administration/metadata/redis_best_practices.md&#34;&gt;&#34;Redis Best Practices&#34;&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h3&gt;What&#39;s the difference between JuiceFS and XXX?&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/comparison&#34;&gt;&#34;Comparison with Others&#34;&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;For more FAQs, please see the &lt;a href=&#34;https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/faq.md&#34;&gt;full list&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Stargazers over time&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://starchart.cc/juicedata/juicefs&#34;&gt;&lt;img src=&#34;https://starchart.cc/juicedata/juicefs.svg?sanitize=true&#34; alt=&#34;Stargazers over time&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>