<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-18T01:44:30Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>cube2222/octosql</title>
    <updated>2022-07-18T01:44:30Z</updated>
    <id>tag:github.com,2022-07-18:/cube2222/octosql</id>
    <link href="https://github.com/cube2222/octosql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OctoSQL is a query tool that allows you to join, analyse and transform data from multiple databases and file formats using SQL.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/images/octosql.svg?sanitize=true&#34; alt=&#34;OctoSQL&#34;&gt;OctoSQL&lt;/h1&gt; &#xA;&lt;p&gt;OctoSQL is predominantly a CLI tool which lets you query a plethora of databases and file formats using SQL through a unified interface, even do JOINs between them. (Ever needed to join a JSON file with a PostgreSQL table? OctoSQL can help you with that.)&lt;/p&gt; &#xA;&lt;p&gt;At the same time it&#39;s an easily extensible full-blown dataflow engine, and you can use it to add a SQL interface to your own applications.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/cube2222/octosql/actions/workflows/test.yml?query=branch%3Amain&#34;&gt;&lt;img src=&#34;https://shields.io/github/workflow/status/cube2222/octosql/Unit%20Tests/main&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/cube2222/octosql&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/cube2222/octosql&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://godoc.org/github.com/cube2222/octosql&#34;&gt;&lt;img src=&#34;https://godoc.org/github.com/cube2222/octosql?status.svg?sanitize=true&#34; alt=&#34;GoDoc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/LICENSE&#34;&gt;&lt;img src=&#34;https://shields.io/github/license/cube2222/octosql&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/cube2222/octosql/releases&#34;&gt;&lt;img src=&#34;https://shields.io/github/v/release/cube2222/octosql?display_name=tag&amp;amp;sort=semver&#34; alt=&#34;Latest Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/octosql/general?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/octosql/general.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/images/octosql-demo.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;octosql &#34;SELECT * FROM ./myfile.json&#34;&#xA;octosql &#34;SELECT * FROM ./myfile.json&#34; --describe  # Show the schema of the file.&#xA;octosql &#34;SELECT invoices.id, address, amount&#xA;         FROM invoices.csv JOIN db.customers ON invoices.customer_id = customers.id&#xA;         ORDER BY amount DESC&#34;&#xA;octosql &#34;SELECT customer_id, SUM(amount)&#xA;         FROM invoices.csv&#xA;         GROUP BY customer_id&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;OctoSQL supports a &lt;a href=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/#File-Access&#34;&gt;bunch of file formats&lt;/a&gt; out of the box, but you can additionally install plugins to add support for other databases.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;octosql &#34;SELECT * FROM plugins.available_plugins&#34;&#xA;octosql plugin install postgres&#xA;echo &#34;databases:&#xA;  - name: mydb&#xA;    type: postgres&#xA;    config:&#xA;      host: localhost&#xA;      port: 5443&#xA;      database: mydb&#xA;      user: postgres&#xA;      password: postgres&#34; &amp;gt; octosql.yml&#xA;octosql &#34;SELECT * FROM mydb.users&#34; --describe&#xA;octosql &#34;SELECT * FROM mydb.users&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can specify the output format using the &lt;code&gt;--output&lt;/code&gt; flag. Available values for it are &lt;code&gt;live_table&lt;/code&gt;, &lt;code&gt;batch_table&lt;/code&gt;, &lt;code&gt;csv&lt;/code&gt; and &lt;code&gt;stream_native&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The documentation about available aggregates and functions is contained within OctoSQL itself. It&#39;s in the &lt;code&gt;aggregates&lt;/code&gt;, &lt;code&gt;aggregate_signatures&lt;/code&gt;, &lt;code&gt;functions&lt;/code&gt; and &lt;code&gt;function_signatures&lt;/code&gt; tables in the &lt;code&gt;docs&lt;/code&gt; database.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;octosql &#34;SELECT * FROM docs.functions fs&#34;&#xA;+------------------+----------------------------------------+&#xA;|     fs.name      |             fs.description             |&#xA;+------------------+----------------------------------------+&#xA;| &#39;abs&#39;            | &#39;Returns absolute value                |&#xA;|                  | of argument.&#39;                          |&#xA;| &#39;ceil&#39;           | &#39;Returns ceiling of                    |&#xA;|                  | argument.&#39;                             |&#xA;| ...              | ...                                    |&#xA;+------------------+----------------------------------------+&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install OctoSQL using Homebrew on MacOS or Linux:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install cube2222/octosql/octosql&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After running it for the first time on MacOS you&#39;ll have to go into Preferences -&amp;gt; Security and Privacy -&amp;gt; Allow OctoSQL, as with any app that&#39;s not notarized.&lt;/p&gt; &#xA;&lt;p&gt;You can also download the binary for your operating system directly from the &lt;a href=&#34;https://github.com/cube2222/octosql/releases&#34;&gt;Releases page&lt;/a&gt;, or install using the go command line tool:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go install -u github.com/cube2222/octosql&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;File Access&lt;/h2&gt; &#xA;&lt;p&gt;Support for multiple file types is included by default in OctoSQL:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;JSON (in JSONLines format, one object per line)&lt;/li&gt; &#xA; &lt;li&gt;CSV&lt;/li&gt; &#xA; &lt;li&gt;TSV&lt;/li&gt; &#xA; &lt;li&gt;Parquet&lt;/li&gt; &#xA; &lt;li&gt;Lines (reading a file line by line)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If your file has a matching extension, you can use its path directly as a table:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;~&amp;gt; octosql &#34;SELECT * FROM my/file/path.json&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or, if the extension is not right, you can use this alternative notation, where the extension is used in place of the database name:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;~&amp;gt; octosql &#34;SELECT * FROM `json.my/file/path.whatever`&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also specify additional options using the following notation: &lt;code&gt;myfile.ext?key=value&amp;amp;key2=value2&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The following options are available:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CSV &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;header: true/false (default: true) - Whether the file has a header row.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;JSON &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;tail: true/false (default: false) - Whether to keep waiting for new content after reaching the end of the file.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Lines &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;tail: true/false (default: false) - Whether to keep waiting for new content after reaching the end of the file.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Reading from Standard Input&lt;/h3&gt; &#xA;&lt;p&gt;You can also pipe data in through stdin, and OctoSQL will expose it as the &lt;code&gt;stdin.&amp;lt;file_type&amp;gt;&lt;/code&gt; table. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;~&amp;gt; echo &#39;{&#34;hello&#34;: &#34;world&#34;}&#39; | octosql &#34;SELECT * FROM stdin.json&#34;&#xA;+---------+&#xA;|  hello  |&#xA;+---------+&#xA;| &#39;world&#39; |&#xA;+---------+&#xA;~&amp;gt; seq 100 | octosql &#34;SELECT SUM(int(text)) FROM stdin.lines&#34;&#xA;+------+&#xA;| sum  |&#xA;+------+&#xA;| 5050 |&#xA;+------+&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Plugins&lt;/h2&gt; &#xA;&lt;p&gt;To use databases which are not included in the core of OctoSQL - like PostgreSQL or MySQL - you need to install a plugin. Installing plugins is very easy. The following command installs the latest version of the PostgreSQL plugin:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;octosql plugin install postgres&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Plugins are grouped into repositories, and potentially have many versions available. The above uses the default &lt;strong&gt;core&lt;/strong&gt; repository and tries to install the latest version. So if 0.42.0 was the latest version, the above would be equivalent to:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;octosql plugin install core/postgres@0.42.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Browsing available and installed plugins is possible through OctoSQL itself, behind a SQL interface. The available tables are: &lt;code&gt;plugins.repositories&lt;/code&gt;, &lt;code&gt;plugins.available_plugins&lt;/code&gt;, &lt;code&gt;plugins.available_versions&lt;/code&gt;, &lt;code&gt;plugins.installed_plugins&lt;/code&gt;, &lt;code&gt;plugins.installed_versions&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;~&amp;gt; octosql &#34;SELECT name, description FROM plugins.available_plugins LIMIT 2&#34;&#xA;+------------------------+-------------------------------+&#xA;| available_plugins.name | available_plugins.description |&#xA;+------------------------+-------------------------------+&#xA;| &#39;postgres&#39;             | &#39;Adds support for             |&#xA;|                        | querying PostgreSQL           |&#xA;|                        | databases.&#39;                   |&#xA;| &#39;random_data&#39;          | &#39;Generates random data        |&#xA;|                        | for testing.&#39;                 |&#xA;+------------------------+-------------------------------+&#xA;~&amp;gt; octosql &#34;SELECT plugin_name, version FROM plugins.available_versions WHERE plugin_name=&#39;random_data&#39;&#34;&#xA;+--------------------------------+----------------------------+&#xA;| available_versions.plugin_name | available_versions.version |&#xA;+--------------------------------+----------------------------+&#xA;| &#39;random_data&#39;                  | &#39;0.1.0&#39;                    |&#xA;| &#39;random_data&#39;                  | &#39;0.1.1&#39;                    |&#xA;| &#39;random_data&#39;                  | &#39;0.2.0&#39;                    |&#xA;+--------------------------------+----------------------------+&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some plugins, like the &lt;code&gt;random_data&lt;/code&gt; plugin, can be used without any additional configuration:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;~&amp;gt; octosql plugin install random_data&#xA;Downloading core/random_data@0.2.0...&#xA;~&amp;gt; octosql &#34;SELECT * FROM random_data.users&#34; --describe&#xA;+---------------------------------+--------------------------+------------+&#xA;|              name               |           type           | time_field |&#xA;+---------------------------------+--------------------------+------------+&#xA;| &#39;users.avatar&#39;                  | &#39;String&#39;                 | false      |&#xA;| &#39;users.credit_card&#39;             | &#39;{cc_number: String}&#39;    | false      |&#xA;| &#39;users.date_of_birth&#39;           | &#39;String&#39;                 | false      |&#xA;| &#39;users.email&#39;                   | &#39;String&#39;                 | false      |&#xA;| &#39;users.first_name&#39;              | &#39;String&#39;                 | false      |&#xA;| &#39;users.last_name&#39;               | &#39;String&#39;                 | false      |&#xA;| ...                             | ...                      | ...        |&#xA;+---------------------------------+--------------------------+------------+&#xA;~&amp;gt; octosql &#34;SELECT first_name, last_name, date_of_birth FROM random_data.users LIMIT 3&#34;&#xA;+------------------+-----------------+---------------------+&#xA;| users.first_name | users.last_name | users.date_of_birth |&#xA;+------------------+-----------------+---------------------+&#xA;| &#39;Alethea&#39;        | &#39;Kuvalis&#39;       | &#39;1997-01-07&#39;        |&#xA;| &#39;Ambrose&#39;        | &#39;Spencer&#39;       | &#39;1979-04-18&#39;        |&#xA;| &#39;Antione&#39;        | &#39;Hodkiewicz&#39;    | &#39;1980-03-04&#39;        |&#xA;+------------------+-----------------+---------------------+&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Others, like the &lt;code&gt;postgres&lt;/code&gt; plugin, require additional configuration. The configuration file is located at &lt;code&gt;~/.octosql/octosql.yml&lt;/code&gt;. You can find the available configuration settings for a plugin in its own documentation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;~&amp;gt; octosql plugin install postgres&#xA;Downloading core/postgres@0.1.0...&#xA;echo &#34;databases:&#xA;  - name: mydb&#xA;    type: postgres&#xA;    config:&#xA;      host: localhost&#xA;      port: 5432&#xA;      database: postgres&#xA;      user: postgres&#xA;      password: mypassword&#34; &amp;gt; ~/.octosql/octosql.yml&#xA;~&amp;gt; octosql &#34;SELECT * FROM mydb.customers&#34; --describe&#xA;+--------------------------+-----------------+------------+&#xA;|           name           |      type       | time_field |&#xA;+--------------------------+-----------------+------------+&#xA;| &#39;customers.email&#39;        | &#39;String&#39;        | false      |&#xA;| &#39;customers.first_name&#39;   | &#39;String&#39;        | false      |&#xA;| &#39;customers.id&#39;           | &#39;Int&#39;           | false      |&#xA;| &#39;customers.last_name&#39;    | &#39;String&#39;        | false      |&#xA;| &#39;customers.phone_number&#39; | &#39;String | NULL&#39; | false      |&#xA;+--------------------------+-----------------+------------+&#xA;~&amp;gt; octosql &#34;SELECT COUNT(*) FROM mydb.customers&#34;&#xA;+-------+&#xA;| count |&#xA;+-------+&#xA;|   183 |&#xA;+-------+&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In order to create your own plugins, see examples of existing plugins:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cube2222/octosql-plugin-mysql&#34;&gt;MySQL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cube2222/octosql-plugin-postgres&#34;&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cube2222/octosql-plugin-random_data&#34;&gt;Random Data&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To test plugins while developing locally, put the plugin binary into &lt;code&gt;~/.octosql/plugins/core/octosql-plugin-&amp;lt;plugin name&amp;gt;/0.1.0/octosql-plugin-&amp;lt;plugin name&amp;gt;&lt;/code&gt;. That&#39;s the location where OctoSQL will be looking for it.&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;OctoSQL writes logs to &lt;code&gt;~/.octosql/logs.txt&lt;/code&gt;, which is the place to look for any errors or issues during execution. Only logs of the most recent execution are kept.&lt;/p&gt; &#xA;&lt;h2&gt;Advanced Features&lt;/h2&gt; &#xA;&lt;h3&gt;The Type System&lt;/h3&gt; &#xA;&lt;p&gt;OctoSQL is statically typed. That means that queries are verified, typechecked, and optimized based on the schemas of the tables and types of any values used in the query.&lt;/p&gt; &#xA;&lt;p&gt;Most of the type system is straight-forward and intuitive, similar to what you&#39;d find in other SQL dialects, even though the types have names which are closer to common programming languages, not SQL databases - in OctoSQL you&#39;ll find &lt;code&gt;String&lt;/code&gt;&#39;s, not &lt;code&gt;varchar&lt;/code&gt;&#39;s.&lt;/p&gt; &#xA;&lt;p&gt;However, OctoSQL also supports &lt;strong&gt;union types&lt;/strong&gt;, which means that a value might be one of multiple types. For example, you might have a dataset where a column is usually a Float, but occasionally also a String with the Float inside. Thus, the type of the column would be &lt;code&gt;Float | String&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Moreover, &lt;code&gt;NULL&lt;/code&gt; is its own type, which means that a nullable &lt;code&gt;Int&lt;/code&gt; column would be represented as &lt;code&gt;Int | NULL&lt;/code&gt; in OctoSQL.&lt;/p&gt; &#xA;&lt;p&gt;There&#39;s a few helper features to handle this union types in OctoSQL.&lt;/p&gt; &#xA;&lt;p&gt;First, whenever a type, i.e. &lt;code&gt;String | Int&lt;/code&gt;, is used in a place where a subtype, i.e. &lt;code&gt;Int&lt;/code&gt;, is expected, OctoSQL will add a dynamic runtime check which will fail execution only if a &lt;code&gt;String&lt;/code&gt; value actually ever reaches that place.&lt;/p&gt; &#xA;&lt;p&gt;Second, you can use type assertions to get a value only if it&#39;s of a certain type and otherwise evaluate to &lt;code&gt;NULL&lt;/code&gt;. The syntax for that is &lt;code&gt;value::type&lt;/code&gt;. So for example we might have a column &lt;code&gt;age&lt;/code&gt; of type &lt;code&gt;String | Int&lt;/code&gt; and would like to get its value only if it&#39;s an Int. We can write &lt;code&gt;age::Int&lt;/code&gt; to express that.&lt;/p&gt; &#xA;&lt;p&gt;Third, there&#39;s a bunch of conversion functions which can help you turn types into other types. For example, the &lt;code&gt;int&lt;/code&gt; function is able to turn values of many types, including strings, to integers. You could use it like this: &lt;code&gt;int(age_string)&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Fourth, and final, there&#39;s the &lt;code&gt;COALESCE&lt;/code&gt; operator which accepts an arbitrary number of arguments and returns the first non-null one. It works very well with what&#39;s described in the previous two paragraphs. This way, if you have an &lt;code&gt;age&lt;/code&gt; column of type &lt;code&gt;String | Int&lt;/code&gt; and would like to clean it up, you can write &lt;code&gt;COALESCE(age::int, int(age::string), 0)&lt;/code&gt;. This would return the value of &lt;code&gt;age&lt;/code&gt; as-is if it&#39;s an &lt;code&gt;Int&lt;/code&gt;, try to parse it if it&#39;s a &lt;code&gt;String&lt;/code&gt;, and just evaluate to &lt;code&gt;0&lt;/code&gt; if that fails.&lt;/p&gt; &#xA;&lt;p&gt;Additionally, you can work with objects and lists using the following syntax:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;List access: &lt;code&gt;list[index]&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Object field access: &lt;code&gt;object-&amp;gt;field&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Explaining Query Plans&lt;/h3&gt; &#xA;&lt;p&gt;You can use the &lt;code&gt;--explain&lt;/code&gt; flag to get a visual explanation of the query plan. Setting it to 1 gives you a query plan but without type and schema information, setting it to 2 includes those too. For the visualization to work you need to have the graphviz dot command installed.&lt;/p&gt; &#xA;&lt;p&gt;For example, running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;octosql &#34;SELECT email, COUNT(*) as invoice_count&#xA;         FROM invoices.csv JOIN mydb.customers ON invoices.customer_id = customers.id&#xA;         WHERE first_name &amp;lt;= &#39;D&#39;&#xA;         GROUP BY email&#xA;         ORDER BY invoice_count DESC&#34; --explain 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;will produce the following output: &lt;img src=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/images/octosql-explain.png&#34; alt=&#34;Explain&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here we can see that the &lt;code&gt;first_name &amp;lt;= &#39;D&#39;&lt;/code&gt; predicate has been pushed down to the &lt;code&gt;mydb.customers&lt;/code&gt; table query.&lt;/p&gt; &#xA;&lt;h3&gt;Dataflow&lt;/h3&gt; &#xA;&lt;p&gt;OctoSQL is a dataflow engine. In practice that means it can execute a query and then update it based on changes in the inputs. The way this works in practice is by using retractions, each record sent internally has a &lt;code&gt;retraction&lt;/code&gt; flag dictating whether it&#39;s an &lt;code&gt;undo&lt;/code&gt; or not.&lt;/p&gt; &#xA;&lt;p&gt;This also means that OctoSQL can work very well with endless streams of data, or display partial results before calculating the full query.&lt;/p&gt; &#xA;&lt;p&gt;In order to handle that well, OctoSQL contains the concept of record event times and watermarks. Each Record can have an Event Time (the time when it originally happened). Watermarks (special metadata records) are used to signal the timestamp that will be the lower bound for all future records. I.e. if you have a watermark of &lt;code&gt;2021-12-13T00:11:03Z&lt;/code&gt; then all future records will have an event time that is past that timestamp. This let&#39;s us understand which Records cannot be retracted anymore, and is very useful when grouping by time windows.&lt;/p&gt; &#xA;&lt;p&gt;OctoSQL is also internally consistent as defined by &lt;a href=&#34;https://www.scattered-thoughts.net/writing/internal-consistency-in-streaming-systems/&#34;&gt;this article&lt;/a&gt;. This means that the live output at any given time will be a correct output for a common time-prefix of all the inputs. If you&#39;re using the &lt;code&gt;stream-native&lt;/code&gt; output, this guarantee is satisfied whenever a watermark is emitted. (you can treat watermarks as atomic transactions as far as the output is concerned)&lt;/p&gt; &#xA;&lt;p&gt;That means, that if you have two input streams, and one input stream is a few minutes behind the other, so for example its watermark value is &lt;code&gt;2021-12-13T00:11:03Z&lt;/code&gt; and the watermark of the other one is &lt;code&gt;2021-12-13T00:11:07Z&lt;/code&gt;, then the output of OctoSQL at that time will be a correct output based on all events up to &lt;code&gt;2021-12-13T00:11:03Z&lt;/code&gt; from both streams. The records in the second stream between &lt;code&gt;2021-12-13T00:11:03Z&lt;/code&gt; and &lt;code&gt;2021-12-13T00:11:07Z&lt;/code&gt; will be buffered until the first stream catches up.&lt;/p&gt; &#xA;&lt;p&gt;For &lt;code&gt;GROUP BY&lt;/code&gt; queries you can specify when you want to udpate the output using the &lt;code&gt;TRIGGER&lt;/code&gt; clause: &lt;code&gt;SELECT ... FROM ... GROUP BY ... TRIGGER COUNTING 300, ON WATERMARK, ON END OF STREAM&lt;/code&gt;. You can use the Counting Trigger and/or the Watermark Trigger and/or the End Of Stream Trigger; it defaults to the End Of Stream trigger.&lt;/p&gt; &#xA;&lt;p&gt;The Watermark Trigger sends values for keys whenever the Watermark rises above the Event Time of the key. The Counting Trigger sends values every time a given number of records arrive for a key. The End Of Stream Trigger sends values for all keys when the stream is over.&lt;/p&gt; &#xA;&lt;p&gt;We can take a look at an example query which simulates a stream using a JSON file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;WITH&#xA;  with_watermark AS (SELECT *&#xA;                     FROM max_diff_watermark(source=&amp;gt;TABLE(clicks.json),&#xA;                                              max_diff=&amp;gt;INTERVAL 5 SECONDS,&#xA;                                              time_field=&amp;gt;DESCRIPTOR(time), resolution=&amp;gt;INTERVAL 10 SECONDS) c),&#xA;  with_tumble AS (SELECT *&#xA;                  FROM tumble(source=&amp;gt;TABLE(with_watermark),&#xA;                              window_length=&amp;gt;INTERVAL 1 MINUTE,&#xA;                              offset=&amp;gt;INTERVAL 0 SECONDS) c),&#xA;  counts_per_user AS (SELECT window_end, user_id, COUNT(*) as clicks&#xA;                      FROM with_tumble&#xA;                      GROUP BY window_end, user_id, TRIGGER ON WATERMARK, COUNTING 500)&#xA;SELECT window_end, user_id, clicks&#xA;FROM counts_per_user&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It uses &lt;a href=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/#table-valued-functions&#34;&gt;Table Valued Functions&lt;/a&gt; extensively.&lt;/p&gt; &#xA;&lt;p&gt;First we create a stream of clicks with Watermarks that lag the latest Event Time seen so far in a Record by 5 seconds. Then organize records into tumbling one-minute windows - each Record gets a new &lt;code&gt;window_end&lt;/code&gt; field that indicates the end of the window the Record belongs to and becomes its new Event Time. Finally, we group the clicks by user and time window, emitting the count every 500 Records per key, and after we get the Watermark for the window. As you can see on the demo below, for each window we&#39;ll get intermediate results and the full result when the Watermark arrives.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/images/octosql-demo-dataflow.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Table Valued Functions&lt;/h3&gt; &#xA;&lt;p&gt;OctoSQL supports Table Valued Functions, which are functions that return a stream of Records as their output. The following functions are available:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;range: constructs a sequence of integers &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;arguments &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;start: expression - required - inclusive start of range&lt;/li&gt; &#xA;     &lt;li&gt;end: expression - required - exclusive end of range&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;poll: polls a finite subquery periodically, emitting the current contents of the table &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;arguments &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;source: table - required - finite table to poll&lt;/li&gt; &#xA;     &lt;li&gt;poll_interval: expression - optional - interval between polls&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;tumble: assigns records to tumbling windows &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;arguments &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;source: table - required - source table&lt;/li&gt; &#xA;     &lt;li&gt;window_length: expression - required - length of the window as an interval&lt;/li&gt; &#xA;     &lt;li&gt;time_field: descriptor - optional - field to use as the Event Time for the windows&lt;/li&gt; &#xA;     &lt;li&gt;offset: expression - optional - offset of the window relative to the beginning of the epoch&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;max_diff_watermark: passes the Records forward as-is, while updating their Event Time field to be the field referenced by the &lt;code&gt;time_field&lt;/code&gt; argument, and sending Watermarks such that the Watermarks are &lt;code&gt;max_diff&lt;/code&gt; interval before the latest seen Record Event Time &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;arguments &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;source: table - required - source table&lt;/li&gt; &#xA;     &lt;li&gt;max_diff: expression - required - difference between the latest Event Time and the Watermark&lt;/li&gt; &#xA;     &lt;li&gt;time_field: descriptor - required - field to use as the Event Time&lt;/li&gt; &#xA;     &lt;li&gt;resolution: expression - optional - resolution of the Watermarks&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Table valued functions must be aliased when used:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM range(start=&amp;gt;1, end=&amp;gt;10) r&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can specify table arguments using the TABLE(...) operator and field descriptors using the DESCRIPTOR(...) operator. An example query using both of these types of arguments is shown in the &lt;a href=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/#dataflow&#34;&gt;Dataflow section&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The TABLE operator can be used to specify both a simple table name or another table valued function:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM poll(source=&amp;gt;TABLE(range(start=&amp;gt;1,end=&amp;gt;10) r)) r&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or even a whole subquery, but then you have to use another set of parentheses:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM poll(source=&amp;gt;TABLE((SELECT * FROM range(start=&amp;gt;1,end=&amp;gt;10) r) r)) r&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Join Types&lt;/h3&gt; &#xA;&lt;p&gt;OctoSQL supports two Join strategies: Stream Join and Lookup Join.&lt;/p&gt; &#xA;&lt;p&gt;One bit of nomenclature before moving forward: watermarked streams are streams that have an Event Time field, emit Watermarks, and are possibly infinite.&lt;/p&gt; &#xA;&lt;h4&gt;Stream Join&lt;/h4&gt; &#xA;&lt;p&gt;A Stream Join reads both input streams while storing all Records in memory, matching them by the key, and emitting them as they are processed.&lt;/p&gt; &#xA;&lt;p&gt;It supports watermarked streams on both sides and the output Watermark will be set to the minimum of both input stream Watermarks in that case. Records newer than the minimum of the input Watermarks will be buffered, not processed, thus guaranteeing &lt;a href=&#34;https://www.scattered-thoughts.net/writing/internal-consistency-in-streaming-systems/&#34;&gt;internal consistency&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Records with an event time of zero are never buffered.&lt;/p&gt; &#xA;&lt;p&gt;If you only have one watermarked input stream, then its watermarks will be used, and the other stream will be read fully before emitting any output Records.&lt;/p&gt; &#xA;&lt;p&gt;If none of the input streams is watermarked, then the Records will be processed without buffering.&lt;/p&gt; &#xA;&lt;p&gt;The Stream Join is the default join type, but can also be used by explicitly specifying the &lt;code&gt;STREAM JOIN&lt;/code&gt; operator.&lt;/p&gt; &#xA;&lt;h4&gt;Lookup Join&lt;/h4&gt; &#xA;&lt;p&gt;A Lookup Joins reads Records from the left input (which can be watermarked) and for each Record gets the relevant Records from the right side (which can&#39;t be watermarked). Thus, the right side will be evaluated once per left-side Record.&lt;/p&gt; &#xA;&lt;p&gt;This also gives OctoSQL more room for optimization, as it can push the Join predicate down to the right-side input, possibly reading only a small subset of the whole right-side input. This is very useful when the left-side input is very small, i.e., a CSV file with a few rows, the right-side input is huge, i.e., a PostgreSQL table with millions of rows, and you expect each left-side Record to be matched with just a few right-side Records. You can make sure this optimization succeeded by using the &lt;code&gt;--explain&lt;/code&gt; flag and checking whether the predicates are pushed under the right-side input datasource.&lt;/p&gt; &#xA;&lt;p&gt;The Lookup Join can be used by explicitly specifying the &lt;code&gt;LOOKUP JOIN&lt;/code&gt; operator.&lt;/p&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;The benchmarks were run on a 2021 MacBook Pro 16 / M1 Max / 32 GB / 1 TB. All binaries are native ARM binaries compiled for Apple Silicon.&lt;/p&gt; &#xA;&lt;p&gt;The benchmark script can be found &lt;a href=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/benchmarks/benchmarks.sh&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It runs the &lt;code&gt;SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi.csv GROUP BY passenger_count&lt;/code&gt; query against the well-known NYC Yellow Taxi Trip Dataset. Specifically, the CSV file from April 2021 is used. It&#39;s a 200MB CSV file with ~2 million rows, 18 columns, and mostly numerical values.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Command&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Version&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Mean [s]&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Relative&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;octosql &#34;SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi.csv GROUP BY passenger_count&#34;&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.8.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.980 ± 0.004&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;q -d &#39;,&#39; -H &#34;SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi.csv GROUP BY passenger_count&#34;&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3.1.6&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;16.042 ± 0.058&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;8.10&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;q -d &#39;,&#39; -H -C readwrite &#34;SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi.csv GROUP BY passenger_count&#34;&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3.1.6&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.691 ± 0.129&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.85&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;textql -header -sql &#34;SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi GROUP BY passenger_count&#34; taxi.csv&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;2.0.3&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;15.513 ± 0.047&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;7.83&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;datafusion-cli -f datafusion_commands.txt&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.9.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.432 ± 0.002&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.22&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;dsq taxi.csv &#34;SELECT passenger_count, COUNT(*), AVG(total_amount) FROM {} GROUP BY passenger_count&#34;&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.21.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;20.756 ± 0.272&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;10.48&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;dsq --cache taxi.csv &#34;SELECT passenger_count, COUNT(*), AVG(total_amount) FROM {} GROUP BY passenger_count&#34;&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.21.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.879 ± 0.022&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.44&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;spyql &#34;SELECT passenger_count, count_agg(*), avg_agg(total_amount) FROM csv GROUP BY passenger_count&#34; &amp;lt; taxi.csv&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.6.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;11.430 ± 0.099&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Here we can see that OctoSQL is fairly good performance wise.&lt;/p&gt; &#xA;&lt;p&gt;q and dsq with caching beat OctoSQL, but that&#39;s because caching means data loading from CSV is omitted, and the optimized SQLite format is used directly, so the CSV parsing bit is not really benchmarked for them.&lt;/p&gt; &#xA;&lt;p&gt;Non-cached q and textql, dsq are considerably slower, most probably because they have to parse the whole CSV file to put it into SQLite and only then query it. OctoSQL runs queries directly on the CSV file, so it&#39;s able to use its optimizer to avoid loading columns which aren&#39;t used in the query.&lt;/p&gt; &#xA;&lt;p&gt;DataFusion is faster than OctoSQL for CSV queries like this one.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;OctoSQL doesn&#39;t accept external contributions to its source code right now, but you can raise issues or develop external plugins for database types you&#39;d like OctoSQL to support. Create a Pull Request to add a plugin to the core plugins repository (which is contained in the plugin_repository.json file). You can find more details in the &lt;a href=&#34;https://raw.githubusercontent.com/cube2222/octosql/main/#plugins&#34;&gt;Plugins section&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>RedTeamPentesting/pretender</title>
    <updated>2022-07-18T01:44:30Z</updated>
    <id>tag:github.com,2022-07-18:/RedTeamPentesting/pretender</id>
    <link href="https://github.com/RedTeamPentesting/pretender" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Your MitM sidekick for relaying attacks featuring DHCPv6 DNS takeover as well as mDNS, LLMNR and NetBIOS-NS spoofing.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;h1 align=&#34;center&#34;&gt;&lt;b&gt;pretender&lt;/b&gt;&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;i&gt;Your MitM sidekick for relaying attacks featuring DHCPv6 DNS takeover&lt;br&gt;as well as mDNS, LLMNR and NetBIOS-NS spoofing&lt;/i&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/RedTeamPentesting/pretender/releases/latest&#34;&gt;&lt;img alt=&#34;Release&#34; src=&#34;https://img.shields.io/github/release/RedTeamPentesting/pretender.svg?style=for-the-badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/RedTeamPentesting/pretender/actions?workflow=Check&#34;&gt;&lt;img alt=&#34;GitHub Action: Check&#34; src=&#34;https://img.shields.io/github/workflow/status/RedTeamPentesting/pretender/Check/main?style=for-the-badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/RedTeamPentesting/pretender/main/LICENSE&#34;&gt;&lt;img alt=&#34;Software License&#34; src=&#34;https://img.shields.io/badge/license-MIT-brightgreen.svg?style=for-the-badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/RedTeamPentesting/pretender&#34;&gt;&lt;img alt=&#34;Go Report Card&#34; src=&#34;https://goreportcard.com/badge/github.com/RedTeamPentesting/pretender?style=for-the-badge&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;code&gt;pretender&lt;/code&gt; is a tool developed by RedTeam Pentesting to obtain machine-in-the-middle positions via spoofed local name resolution and DHCPv6 DNS takeover attacks. &lt;code&gt;pretender&lt;/code&gt; primarily targets Windows hosts, as it is intended to be used for relaying attacks but can be deployed on Linux, Windows and all other platforms Go supports. It can also answer with arbitrary IPs for situations where the relaying tool runs on a different host than &lt;code&gt;pretender&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Read our &lt;a href=&#34;https://blog.redteam-pentesting.de/2022/introducing-pretender/&#34;&gt;blog post&lt;/a&gt; for more information about DHCPv6 DNS takeover, local name resolution spoofing and relay attacks.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;To get a feel for the situation in the local network, &lt;code&gt;pretender&lt;/code&gt; can be started in &lt;code&gt;--dry&lt;/code&gt; mode where it only logs incoming queries and does not answer any of them:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pretender -i eth0 --dry&#xA;pretender -i eth0 --dry --no-ra # without router advertisements&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To perform local name resolution spoofing via mDNS, LLMNR and NetBIOS-NS as well as a DHCPv6 DNS takeover with router advertisements, simply run &lt;code&gt;pretender&lt;/code&gt; like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pretender -i eth0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can disable certain attacks with &lt;code&gt;--no-dhcp-dns&lt;/code&gt; (disabled DHCPv6, DNS and router advertisements), &lt;code&gt;--no-lnr&lt;/code&gt; (disabled mDNS, LLMNR and NetBIOS-NS), &lt;code&gt;--no-mdns&lt;/code&gt;, &lt;code&gt;--no-llmnr&lt;/code&gt;, &lt;code&gt;--no-netbios&lt;/code&gt; and &lt;code&gt;--no-ra&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If &lt;code&gt;ntlmrelayx.py&lt;/code&gt; runs on a different host (say &lt;code&gt;10.0.0.10&lt;/code&gt;/&lt;code&gt;fe80::5&lt;/code&gt;), run &lt;code&gt;pretender&lt;/code&gt; like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pretender -i eth0 -4 10.0.0.10 -6 fe80::5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Pretender can be setup to only respond to queries for certain domains (or all &lt;em&gt;but&lt;/em&gt; certain domains) and it can perform the spoofing attacks only for certain hosts (or all &lt;em&gt;but&lt;/em&gt; certain hosts). Referencing hosts by hostname relies on the name resolution of the host that runs &lt;code&gt;pretender&lt;/code&gt;. See the following example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pretender -i eth0 --spoof example.com --dont-spoof-for 10.0.0.3,host1.corp,fe80::f --ignore-nofqdn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information, run &lt;code&gt;pretender --help&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Tips&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make sure to enable IPv6 support in &lt;code&gt;ntlmrelayx.py&lt;/code&gt; with the &lt;code&gt;-6&lt;/code&gt; flag&lt;/li&gt; &#xA; &lt;li&gt;Pretender can be configured to stop after a certain time period for situations where it cannot be aborted manually (&lt;code&gt;--stop-after&lt;/code&gt; and &lt;code&gt;main.vendorStopAfter&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Host info lookup (which relies on the ARP table, IP neighbours and reverse lookups) can be disabled with &lt;code&gt;--no-host-info&lt;/code&gt; or &lt;code&gt;main.vendorNoHostInfo&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you are not sure which interface to choose (especially on Windows), list all interfaces with names and addresses using &lt;code&gt;--interfaces&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you want to exclude hosts from local name resolution spoofing, make sure to also exclude their IPv6 addresses or use &lt;code&gt;--no-ipv6-lnr&lt;/code&gt;/&lt;code&gt;main.vendorNoIPv6LNR&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;DHCPv6 messages usually contain a FQDN option (which can also sometimes contain a hostname which is not a FQDN). This option is used to filter out messages by hostname (&lt;code&gt;--spoof-for&lt;/code&gt;/&lt;code&gt;--dont-spoof-for&lt;/code&gt;). You can decide what to do with DHCPv6 messages without FQDN option by setting or omitting &lt;code&gt;--ignore-nofqdn&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Depending on the build configuration, either the operating system resolver (&lt;code&gt;CGO_ENABLED=1&lt;/code&gt;) or a Go implementation (&lt;code&gt;CGO_ENABLED=0&lt;/code&gt;) is used. This can be important for host info collection because the OS resolver may support local name resolution and the Go implementation does not, unless a stub resolver is used.&lt;/li&gt; &#xA; &lt;li&gt;The host info functionality is currently only available for Windows and Linux.&lt;/li&gt; &#xA; &lt;li&gt;A custom MAC address vendor list can be compiled into the binary by replacing the default list &lt;code&gt;hostinfo/mac-vendors.txt&lt;/code&gt;. Only lines with MAC prefixes in the following format are recognized: &lt;code&gt;FF:FF:FF&amp;lt;tab&amp;gt;VendorID&amp;lt;tab&amp;gt;Vendor&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Building and Vendoring&lt;/h2&gt; &#xA;&lt;p&gt;Pretender can be build as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Pretender can also be compiled with pre-configured settings. For this, the &lt;code&gt;ldflags&lt;/code&gt; have to be modified like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;-ldflags &#39;-X main.vendorInterface=eth1&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For example, Pretender can be built for Windows with a specific default interface, without colored output and with a relay IPv4 address configured:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;GOOS=windows go build -trimpath -ldflags &#39;-X &#34;main.vendorInterface=Ethernet 2&#34; -X main.vendorNoColor=true -X main.vendorRelayIPv4=10.0.0.10&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Full list of vendoring options (see &lt;code&gt;defaults.go&lt;/code&gt; or &lt;code&gt;pretender --help&lt;/code&gt; for detailed information):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;vendorInterface&#xA;vendorRelayIPv4&#xA;vendorRelayIPv6&#xA;vendorNoDHCPv6DNSTakeover&#xA;vendorNoDHCPv6&#xA;vendorNoDNS&#xA;vendorNoMDNS&#xA;vendorNoNetBIOS&#xA;vendorNoLLMNR&#xA;vendorNoLocalNameResolution&#xA;vendorNoRA&#xA;vendorNoIPv6LNR&#xA;vendorSpoof&#xA;vendorDontSpoof&#xA;vendorSpoofFor&#xA;vendorDontSpoofFor&#xA;vendorSpoofTypes&#xA;vendorIgnoreDHCPv6NoFQDN&#xA;vendorDryMode&#xA;vendorTTL&#xA;vendorLeaseLifetime&#xA;vendorRARouterLifetime&#xA;vendorRAPeriod&#xA;vendorStopAfter&#xA;vendorVerbose&#xA;vendorNoColor&#xA;vendorNoTimestamps&#xA;vendorLogFileName&#xA;vendorNoHostInfo&#xA;vendorHideIgnored&#xA;vendorRedirectStderr&#xA;vendorListInterfaces&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>docker/compose</title>
    <updated>2022-07-18T01:44:30Z</updated>
    <id>tag:github.com,2022-07-18:/docker/compose</id>
    <link href="https://github.com/docker/compose" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Define and run multi-container applications with Docker&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Docker Compose v2&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/docker/compose/actions&#34;&gt;&lt;img src=&#34;https://github.com/docker/compose/workflows/Continuous%20integration/badge.svg?sanitize=true&#34; alt=&#34;Actions Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/docker/compose/v2/logo.png?raw=true&#34; alt=&#34;Docker Compose&#34; title=&#34;Docker Compose Logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Docker Compose is a tool for running multi-container applications on Docker defined using the &lt;a href=&#34;https://compose-spec.io&#34;&gt;Compose file format&lt;/a&gt;. A Compose file is used to define how the one or more containers that make up your application are configured. Once you have a Compose file, you can create and start your application with a single command: &lt;code&gt;docker compose up&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;About update and backward compatibility&lt;/h1&gt; &#xA;&lt;p&gt;Docker Compose V2 is a major version bump release of Docker Compose. It has been completely rewritten from scratch in Golang (V1 was in Python). The installation instructions for Compose V2 differ from V1. V2 is not a standalone binary anymore, and installation scripts will have to be adjusted. Some commands are different.&lt;/p&gt; &#xA;&lt;p&gt;For a smooth transition from legacy docker-compose 1.xx, please consider installing &lt;a href=&#34;https://github.com/docker/compose-switch&#34;&gt;compose-switch&lt;/a&gt; to translate &lt;code&gt;docker-compose ...&lt;/code&gt; commands into Compose V2&#39;s &lt;code&gt;docker compose .... &lt;/code&gt;. Also check V2&#39;s &lt;code&gt;--compatibility&lt;/code&gt; flag.&lt;/p&gt; &#xA;&lt;h1&gt;Where to get Docker Compose&lt;/h1&gt; &#xA;&lt;h3&gt;Windows and macOS&lt;/h3&gt; &#xA;&lt;p&gt;Docker Compose is included in &lt;a href=&#34;https://www.docker.com/products/docker-desktop&#34;&gt;Docker Desktop&lt;/a&gt; for Windows and macOS.&lt;/p&gt; &#xA;&lt;h3&gt;Linux&lt;/h3&gt; &#xA;&lt;p&gt;You can download Docker Compose binaries from the &lt;a href=&#34;https://github.com/docker/compose/releases&#34;&gt;release page&lt;/a&gt; on this repository.&lt;/p&gt; &#xA;&lt;p&gt;Rename the relevant binary for your OS to &lt;code&gt;docker-compose&lt;/code&gt; and copy it to &lt;code&gt;$HOME/.docker/cli-plugins&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or copy it into one of these folders for installing it system-wide:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/usr/local/lib/docker/cli-plugins&lt;/code&gt; OR &lt;code&gt;/usr/local/libexec/docker/cli-plugins&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/usr/lib/docker/cli-plugins&lt;/code&gt; OR &lt;code&gt;/usr/libexec/docker/cli-plugins&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;(might require to make the downloaded file executable with &lt;code&gt;chmod +x&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Using Docker Compose is basically a three-step process:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Define your app&#39;s environment with a &lt;code&gt;Dockerfile&lt;/code&gt; so it can be reproduced anywhere.&lt;/li&gt; &#xA; &lt;li&gt;Define the services that make up your app in &lt;code&gt;docker-compose.yml&lt;/code&gt; so they can be run together in an isolated environment.&lt;/li&gt; &#xA; &lt;li&gt;Lastly, run &lt;code&gt;docker compose up&lt;/code&gt; and Compose will start and run your entire app.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;A Compose file looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;services:&#xA;  web:&#xA;    build: .&#xA;    ports:&#xA;      - &#34;5000:5000&#34;&#xA;    volumes:&#xA;      - .:/code&#xA;  redis:&#xA;    image: redis&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Want to help develop Docker Compose? Check out our &lt;a href=&#34;https://raw.githubusercontent.com/docker/compose/v2/CONTRIBUTING.md&#34;&gt;contributing documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you find an issue, please report it on the &lt;a href=&#34;https://github.com/docker/compose/issues/new/choose&#34;&gt;issue tracker&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>