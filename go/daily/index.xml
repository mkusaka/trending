<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-03T01:30:46Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>fruitbars/simple-one-api</title>
    <updated>2024-06-03T01:30:46Z</updated>
    <id>tag:github.com,2024-06-03:/fruitbars/simple-one-api</id>
    <link href="https://github.com/fruitbars/simple-one-api" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenAI 接口接入适配，支持千帆大模型平台、讯飞星火大模型、腾讯混元以及MiniMax、Deep-Seek，等兼容OpenAI接口，仅单可执行文件，配置超级简单，一键部署，开箱即用.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;simple-one-api:通过标准的 OpenAI API 格式访问的各种国产大模型，开箱即用&lt;/h1&gt; &#xA;&lt;h2&gt;简介&lt;/h2&gt; &#xA;&lt;p&gt;目前市面上免费的使用国产的免费大模型越来越多，one-api对于个人用起来还是有点麻烦，就想要一个不要统计、流量、计费等等的适配程序即可。&lt;/p&gt; &#xA;&lt;p&gt;还有一点是：即使有些厂商说兼容openai的接口，但是实际上还是存在些许差异的！！！&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;simple-one-api&lt;/strong&gt;主要是解决以上2点，旨在兼容多种大模型接口，并统一对外提供 OpenAI 接口。通过该项目，用户可以方便地集成和调用多种大模型，简化了不同平台接口差异带来的复杂性。&lt;/p&gt; &#xA;&lt;h3&gt;免费大模型列表&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;大模型&lt;/th&gt; &#xA;   &lt;th&gt;免费版本&lt;/th&gt; &#xA;   &lt;th&gt;控制台（api_key等）&lt;/th&gt; &#xA;   &lt;th&gt;文档地址&lt;/th&gt; &#xA;   &lt;th&gt;备注&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;讯飞星火大模型&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;spark-lite&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://console.xfyun.cn/services/cbm&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.xfyun.cn/doc/spark/Web.html&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;tokens：总量无限&lt;br&gt;QPS：2&lt;br&gt;有效期：不限&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;百度千帆大模型平台&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;yi_34b_chat&lt;/code&gt;, &lt;code&gt;ERNIE-Speed-8K&lt;/code&gt;, &lt;code&gt;ERNIE-Speed-128K&lt;/code&gt;, &lt;code&gt;ERNIE-Lite-8K&lt;/code&gt;, &lt;code&gt;ERNIE-Lite-8K-0922&lt;/code&gt;, &lt;code&gt;ERNIE-Tiny-8K&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://cloud.baidu.com/doc/WENXINWORKSHOP/s/klqx7b1xf&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Lite、Speed-8K：RPM = 300，TPM = 300000&lt;br&gt;Speed-128K：RPM = 60，TPM = 300000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;腾讯混元大模型&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;hunyuan-lite&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://console.cloud.tencent.com/cam/capi&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://cloud.tencent.com/document/api/1729/105701&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;限制并发数为 5 路&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;备注信息&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;讯飞星火大模型&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;tokens&lt;/strong&gt;: 总量无限&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;QPS&lt;/strong&gt;: 2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;有效期&lt;/strong&gt;: 不限&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;文档地址&lt;/strong&gt;：&lt;a href=&#34;https://www.xfyun.cn/doc/spark/Web.html&#34;&gt;https://www.xfyun.cn/doc/spark/Web.html&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;申请流程&lt;/strong&gt;：&lt;a href=&#34;https://raw.githubusercontent.com/fruitbars/simple-one-api/main/docs/%E8%AE%AF%E9%A3%9E%E6%98%9F%E7%81%ABspark-lite%E6%A8%A1%E5%9E%8B%E7%94%B3%E8%AF%B7%E6%B5%81%E7%A8%8B.md&#34;&gt;docs/讯飞星火spark-lite模型申请流程&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;百度千帆大模型平台&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Lite、Speed-8K&lt;/strong&gt;: RPM = 300，TPM = 300000&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Speed-128K&lt;/strong&gt;: RPM = 60，TPM = 300000]&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;文档地址&lt;/strong&gt;：&lt;a href=&#34;https://cloud.baidu.com/doc/WENXINWORKSHOP/s/klqx7b1xf&#34;&gt;https://cloud.baidu.com/doc/WENXINWORKSHOP/s/klqx7b1xf&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;申请流程&lt;/strong&gt;：&lt;a href=&#34;https://raw.githubusercontent.com/fruitbars/simple-one-api/main/docs/%E7%99%BE%E5%BA%A6%E5%8D%83%E5%B8%86speed%E5%92%8Clite%E6%A8%A1%E5%9E%8B%E7%94%B3%E8%AF%B7%E6%B5%81%E7%A8%8B.md&#34;&gt;docs/百度千帆speed和lite模型申请流程&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;腾讯混元大模型&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;限制并发数&lt;/strong&gt;: 5 路&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;文档地址&lt;/strong&gt;：&lt;a href=&#34;https://cloud.tencent.com/document/api/1729/105701&#34;&gt;https://cloud.tencent.com/document/api/1729/105701&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;申请流程&lt;/strong&gt;：&lt;a href=&#34;https://raw.githubusercontent.com/fruitbars/simple-one-api/main/docs/%E8%85%BE%E8%AE%AF%E6%B7%B7%E5%85%83hunyuan-lite%E6%A8%A1%E5%9E%8B%E7%94%B3%E8%AF%B7%E6%B5%81%E7%A8%8B.md&#34;&gt;docs/腾讯混元hunyuan-lite模型申请流程&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;功能&lt;/h2&gt; &#xA;&lt;h3&gt;文本生成&lt;/h3&gt; &#xA;&lt;p&gt;支持多种大模型：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://qianfan.cloud.baidu.com/&#34;&gt;百度智能云千帆大模型平台&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://xinghuo.xfyun.cn/sparkapi&#34;&gt;讯飞星火大模型&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://cloud.tencent.com/product/hunyuan&#34;&gt;腾讯混元大模型&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://platform.openai.com/docs/guides/gpt/chat-completions-api&#34;&gt;OpenAI ChatGPT 系列模型&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://platform.deepseek.com/api-docs/zh-cn/&#34;&gt;Deep-Seek&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://platform.minimaxi.com/document/guides/chat-model/pro&#34;&gt;MiniMax&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;如果兼容OpenAI的接口，那么直接就可以使用了。&lt;/p&gt; &#xA;&lt;h2&gt;安装&lt;/h2&gt; &#xA;&lt;h3&gt;源码安装&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;克隆本仓库：&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/fruitbars/simple-one-api.git&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;编译程序：&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;chmod +x build_windows.sh&#xA;chmod +x build_linux.sh&#xA;chmod +x build_macos.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;对于不同的平台可以执行不同的脚本&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./build_windows.sh           # 普通编译&#xA;./build_windows.sh --rebuild # 全量重新编译&#xA;&#xA;./build_linux.sh           # 普通编译&#xA;./build_linux.sh --rebuild # 全量重新编译&#xA;&#xA;./build_macos.sh           # 普通编译&#xA;./build_macos.sh --rebuild # 全量重新编译&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;配置你的模型服务和凭证：&lt;/p&gt; &lt;p&gt;在 &lt;code&gt;config.json&lt;/code&gt; 文件中添加你的模型服务和凭证信息，参考下文的配置文件说明。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;直接下载&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/fruitbars/simple-one-api/releases&#34;&gt;前往Releases页面&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;使用方法&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;启动服务：&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;直接启动&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./simple-one-api [config](可选项，默认为config.json)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;nohup启动&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;使用提供的&lt;code&gt;nohup_manage_simple_one_api.sh&lt;/code&gt;脚本&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;启动：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./nohup_manage_simple_one_api.sh start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;停止：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./nohup_manage_simple_one_api.sh stop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;重启：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./nohup_manage_simple_one_api.sh restart&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;使用systemd服务&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;也可以是使用准备好的脚本&lt;code&gt;install_simple_one_api_service.sh&lt;/code&gt; 需要修改下其中的工作目录&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;WORKING_DIRECTORY=&#34;/path/to/your/application&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;开启权限，安装&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chmod +x install_simple_one_api_service.sh&#xA;./install_simple_one_api_service.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;然后使用&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;启动：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl start simple-one-api&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;停止：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./nohup_manage_simple_one_api.sh stop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;重启：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./nohup_manage_simple_one_api.sh restart&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;2. 调用 API：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;现在，你可以通过 OpenAI 兼容的接口调用你配置的各大模型服务。服务地址: &lt;code&gt;http://host:port/v1&lt;/code&gt;,&lt;code&gt;api-key&lt;/code&gt;可以任意设置&lt;/p&gt; &#xA;&lt;p&gt;支持模型名称设置为&lt;code&gt;random&lt;/code&gt;，后台会自动找一个&lt;code&gt;&#34;enabled&#34;: true&lt;/code&gt;的模型来使用。&lt;/p&gt; &#xA;&lt;h2&gt;配置文件示例&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;load_balancing&#34;: &#34;first&#34;,&#xA;    &#34;xinghuo&#34;: [&#xA;      {&#xA;        &#34;models&#34;: [&#34;spark-lite&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;appid&#34;: &#34;xxx&#34;,&#xA;          &#34;api_key&#34;: &#34;xxx&#34;,&#xA;          &#34;api_secret&#34;: &#34;xxx&#34;&#xA;        }&#xA;      }&#xA;    ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;配置文件说明&lt;/h2&gt; &#xA;&lt;p&gt;配置文件采用 JSON 格式，以下是各字段的详细说明。&lt;/p&gt; &#xA;&lt;h3&gt;顶层字段说明&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;字段名&lt;/th&gt; &#xA;   &lt;th&gt;类型&lt;/th&gt; &#xA;   &lt;th&gt;说明&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;server_port&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;服务地址，例如：&#34;:9090&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;api_key&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;客户端需要传入的api_key，例如：&#34;sk-123456&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;load_balancing&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;负载均衡策略，示例值：&#34;first&#34;和&#34;random&#34;。first是取一个enabled，random是随机取一个enabled&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;services&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;对象&lt;/td&gt; &#xA;   &lt;td&gt;包含多个服务配置，每个服务对应一个大模型平台。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;code&gt;services.&amp;lt;service&amp;gt;&lt;/code&gt; 对象数组字段说明&lt;/h3&gt; &#xA;&lt;p&gt;每个服务包含一个或多个配置项。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;字段名&lt;/th&gt; &#xA;   &lt;th&gt;类型&lt;/th&gt; &#xA;   &lt;th&gt;说明&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;models&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串数组&lt;/td&gt; &#xA;   &lt;td&gt;支持的模型列表。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;enabled&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;布尔值&lt;/td&gt; &#xA;   &lt;td&gt;是否启用该配置。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;credentials&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;对象&lt;/td&gt; &#xA;   &lt;td&gt;凭证信息，根据不同服务可能包含不同字段。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;server_url&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;服务器 URL，有些服务需要此字段。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;code&gt;credentials&lt;/code&gt; 对象字段说明&lt;/h3&gt; &#xA;&lt;p&gt;根据不同服务，凭证信息包含不同的字段。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;服务&lt;/th&gt; &#xA;   &lt;th&gt;字段名&lt;/th&gt; &#xA;   &lt;th&gt;类型&lt;/th&gt; &#xA;   &lt;th&gt;说明&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;讯飞星火&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;appid&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;应用 ID。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;api_key&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;API 密钥。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;api_secret&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;API 秘密。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;百度千帆&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;api_key&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;API 密钥。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;secret_key&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;秘密密钥。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;腾讯混元&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;secret_id&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;秘密 ID。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;secret_key&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;秘密密钥。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenAI&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;api_key&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;API 密钥。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniMax&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;group_id&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;组 ID。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;api_key&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;字符串&lt;/td&gt; &#xA;   &lt;td&gt;API 密钥。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;示例配置文件&lt;/h3&gt; &#xA;&lt;p&gt;以下是一个完整的配置示例，涵盖了多个大模型平台和不同模型：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;server_port&#34;:&#34;:9090&#34;,&#xA;  &#34;load_balancing&#34;: &#34;first&#34;,&#xA;  &#34;services&#34;: {&#xA;    &#34;qianfan&#34;: [&#xA;      {&#xA;        &#34;models&#34;: [&#34;yi_34b_chat&#34;, &#34;ERNIE-Speed-8K&#34;, &#34;ERNIE-Speed-128K&#34;, &#34;ERNIE-Lite-8K&#34;, &#34;ERNIE-Lite-8K-0922&#34;, &#34;ERNIE-Tiny-8K&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;api_key&#34;: &#34;xxx&#34;,&#xA;          &#34;secret_key&#34;: &#34;xxx&#34;&#xA;        }&#xA;      }&#xA;    ],&#xA;    &#34;xinghuo&#34;: [&#xA;      {&#xA;        &#34;models&#34;: [&#34;spark-lite&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;appid&#34;: &#34;xxx&#34;,&#xA;          &#34;api_key&#34;: &#34;xxx&#34;,&#xA;          &#34;api_secret&#34;: &#34;xxx&#34;&#xA;        },&#xA;        &#34;server_url&#34;: &#34;ws://spark-api.xf-yun.com/v1.1/chat&#34;&#xA;      }&#xA;    ],&#xA;    &#34;hunyuan&#34;: [&#xA;      {&#xA;        &#34;models&#34;: [&#34;hunyuan-lite&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;secret_id&#34;: &#34;xxx&#34;,&#xA;          &#34;secret_key&#34;: &#34;xxx&#34;&#xA;        }&#xA;      }&#xA;    ],&#xA;    &#34;openai&#34;: [&#xA;      {&#xA;        &#34;models&#34;: [&#34;deepseek-chat&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;api_key&#34;: &#34;xxx&#34;&#xA;        },&#xA;        &#34;server_url&#34;: &#34;https://api.deepseek.com/v1&#34;&#xA;      }&#xA;    ],&#xA;    &#34;minimax&#34;: [&#xA;      {&#xA;        &#34;models&#34;: [&#34;abab6-chat&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;group_id&#34;: &#34;xxx&#34;,&#xA;          &#34;api_key&#34;: &#34;xxx&#34;&#xA;        },&#xA;        &#34;server_url&#34;: &#34;https://api.minimax.chat/v1/text/chatcompletion_pro&#34;&#xA;      }&#xA;    ]&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;如何设置一个对外的apikey？&lt;/h3&gt; &#xA;&lt;p&gt;可以通过&lt;code&gt;api_key&lt;/code&gt;字段来设置&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;api_key&#34;:&#34;123456&#34;,&#xA;    &#34;load_balancing&#34;: &#34;random&#34;,&#xA;    &#34;xinghuo&#34;: [&#xA;      {&#xA;        &#34;models&#34;: [&#34;spark-lite&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;appid&#34;: &#34;xxx&#34;,&#xA;          &#34;api_key&#34;: &#34;xxx&#34;,&#xA;          &#34;api_secret&#34;: &#34;xxx&#34;&#xA;        }&#xA;      }&#xA;    ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;单个模型如何配置多个credentials自动负载？&lt;/h3&gt; &#xA;&lt;p&gt;以客户端选择spark-lite为例，可以按照下面这样配置，会随机credentials&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;api_key&#34;:&#34;123456&#34;,&#xA;    &#34;load_balancing&#34;: &#34;random&#34;,&#xA;    &#34;xinghuo&#34;: [&#xA;      {&#xA;        &#34;models&#34;: [&#34;spark-lite&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;appid&#34;: &#34;xxx&#34;,&#xA;          &#34;api_key&#34;: &#34;xxx&#34;,&#xA;          &#34;api_secret&#34;: &#34;xxx&#34;&#xA;        }&#xA;      },&#xA;      {&#xA;        &#34;models&#34;: [&#34;spark-lite&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;appid&#34;: &#34;xxx&#34;,&#xA;          &#34;api_key&#34;: &#34;xxx&#34;,&#xA;          &#34;api_secret&#34;: &#34;xxx&#34;&#xA;        }&#xA;      }&#xA;    ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;在沉浸式翻译当中怎么使用？&lt;/h3&gt; &#xA;&lt;p&gt;参考&lt;a href=&#34;https://raw.githubusercontent.com/fruitbars/simple-one-api/main/%E5%9C%A8%E6%B2%89%E6%B5%B8%E5%BC%8F%E7%BF%BB%E8%AF%91%E4%B8%AD%E4%BD%BF%E7%94%A8simple-one-api.md&#34;&gt;docs/在沉浸式翻译中使用simple-one-api&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;如何让后台模型随机使用？&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;load_balancing&lt;/code&gt;就是为自动选择模型来配置的，支持&lt;code&gt;random&lt;/code&gt;，自动随机选一个&lt;code&gt;enabled&lt;/code&gt;为&lt;code&gt;true&lt;/code&gt;的模型&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;api_key&#34;:&#34;123456&#34;,&#xA;    &#34;load_balancing&#34;: &#34;random&#34;,&#xA;    &#34;xinghuo&#34;: [&#xA;      {&#xA;        &#34;models&#34;: [&#34;spark-lite&#34;],&#xA;        &#34;enabled&#34;: true,&#xA;        &#34;credentials&#34;: {&#xA;          &#34;appid&#34;: &#34;xxx&#34;,&#xA;          &#34;api_key&#34;: &#34;xxx&#34;,&#xA;          &#34;api_secret&#34;: &#34;xxx&#34;&#xA;        }&#xA;      }&#xA;    ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;贡献&lt;/h2&gt; &#xA;&lt;p&gt;我们欢迎任何形式的贡献。如果你有任何建议或发现了问题，请通过提交 issue 或 pull request 的方式与我们联系。&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>warpstreamlabs/bento</title>
    <updated>2024-06-03T01:30:46Z</updated>
    <id>tag:github.com,2024-06-03:/warpstreamlabs/bento</id>
    <link href="https://github.com/warpstreamlabs/bento" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://pkg.go.dev/github.com/warpstreamlabs/bento/v4/public&#34;&gt;&lt;img src=&#34;https://pkg.go.dev/badge/github.com/warpstreamlabs/bento/v4/public&#34; alt=&#34;godoc for warpstreamlabs/bento&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/warpstreamlabs/bento/actions/workflows/test.yml&#34;&gt;&lt;img src=&#34;https://github.com/warpstreamlabs/bento/actions/workflows/test.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://warpstreamlabs.github.io/bento/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Docs-Learn%20more-ffc7c7&#34; alt=&#34;Docs site&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://console.warpstream.com/socials/discord&#34;&gt;Discord&lt;/a&gt; &lt;a href=&#34;https://console.warpstream.com/socials/slack&#34;&gt;Slack&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Bento is a high performance and resilient stream processor, able to connect various &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/components/inputs/about&#34;&gt;sources&lt;/a&gt; and &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/components/outputs/about&#34;&gt;sinks&lt;/a&gt; in a range of brokering patterns and perform &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/components/processors/about&#34;&gt;hydration, enrichments, transformations and filters&lt;/a&gt; on payloads.&lt;/p&gt; &#xA;&lt;p&gt;It comes with a &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/guides/bloblang/about&#34;&gt;powerful mapping language&lt;/a&gt;, is easy to deploy and monitor, and ready to drop into your pipeline either as a static binary, docker image, or &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/guides/serverless/about&#34;&gt;serverless function&lt;/a&gt;, making it cloud native as heck.&lt;/p&gt; &#xA;&lt;p&gt;Bento is declarative, with stream pipelines defined in as few as a single config file, allowing you to specify connectors and a list of processing stages:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;input:&#xA;  gcp_pubsub:&#xA;    project: foo&#xA;    subscription: bar&#xA;&#xA;pipeline:&#xA;  processors:&#xA;    - mapping: |&#xA;        root.message = this&#xA;        root.meta.link_count = this.links.length()&#xA;        root.user.age = this.user.age.number()&#xA;&#xA;output:&#xA;  redis_streams:&#xA;    url: tcp://TODO:6379&#xA;    stream: baz&#xA;    max_in_flight: 20&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Delivery Guarantees&lt;/h3&gt; &#xA;&lt;p&gt;Delivery guarantees &lt;a href=&#34;https://youtu.be/QmpBOCvY8mY&#34;&gt;can be a dodgy subject&lt;/a&gt;. Bento processes and acknowledges messages using an in-process transaction model with no need for any disk persisted state, so when connecting to at-least-once sources and sinks it&#39;s able to guarantee at-least-once delivery even in the event of crashes, disk corruption, or other unexpected server faults.&lt;/p&gt; &#xA;&lt;p&gt;This behaviour is the default and free of caveats, which also makes deploying and scaling Bento much simpler.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Sources &amp;amp; Sinks&lt;/h2&gt; &#xA;&lt;p&gt;AWS (DynamoDB, Kinesis, S3, SQS, SNS), Azure (Blob storage, Queue storage, Table storage), GCP (Pub/Sub, Cloud storage, Big query), Kafka, NATS (JetStream, Streaming), NSQ, MQTT, AMQP 0.91 (RabbitMQ), AMQP 1, Redis (streams, list, pubsub, hashes), Cassandra, Elasticsearch, HDFS, HTTP (server and client, including websockets), MongoDB, SQL (MySQL, PostgreSQL, Clickhouse, MSSQL), and &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/about#components&#34;&gt;you know what just click here to see them all, they don&#39;t fit in a README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Connectors are being added constantly, if something you want is missing then &lt;a href=&#34;https://github.com/warpstreamlabs/bento/issues/new&#34;&gt;open an issue&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;If you want to dive fully into Bento then don&#39;t waste your time in this dump, check out the &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/about&#34;&gt;documentation site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For guidance on how to configure more advanced stream processing concepts such as stream joins, enrichment workflows, etc, check out the &lt;a href=&#34;https://warpstreamlabs.github.io/bento/cookbooks&#34;&gt;cookbooks section.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For guidance on building your own custom plugins in Go check out &lt;a href=&#34;https://pkg.go.dev/github.com/warpstreamlabs/bento/v4/public&#34;&gt;the public APIs.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re working on the release process, but you can either compile from source or pull the docker image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker pull public.ecr.aws/warpstream-labs/warpstream_bento:0.0.1-rc1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information check out the &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/guides/getting_started&#34;&gt;getting started guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Run&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bento -c ./config.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, with docker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Using a config file&#xA;docker run --rm -v /path/to/your/config.yaml:/bento.yaml public.ecr.aws/warpstream-labs/warpstream_bento&#xA;&#xA;# Using a series of -s flags&#xA;docker run --rm -p 4195:4195 public.ecr.aws/warpstream-labs/warpstream_bento \&#xA;  -s &#34;input.type=http_server&#34; \&#xA;  -s &#34;output.type=kafka&#34; \&#xA;  -s &#34;output.kafka.addresses=kafka-server:9092&#34; \&#xA;  -s &#34;output.kafka.topic=bento_topic&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Monitoring&lt;/h2&gt; &#xA;&lt;h3&gt;Health Checks&lt;/h3&gt; &#xA;&lt;p&gt;Bento serves two HTTP endpoints for health checks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/ping&lt;/code&gt; can be used as a liveness probe as it always returns a 200.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/ready&lt;/code&gt; can be used as a readiness probe as it serves a 200 only when both the input and output are connected, otherwise a 503 is returned.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Metrics&lt;/h3&gt; &#xA;&lt;p&gt;Bento &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/components/metrics/about&#34;&gt;exposes lots of metrics&lt;/a&gt; either to Statsd, Prometheus, a JSON HTTP endpoint, &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/components/metrics/about&#34;&gt;and more&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Tracing&lt;/h3&gt; &#xA;&lt;p&gt;Bento also &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/components/tracers/about&#34;&gt;emits open telemetry tracing events&lt;/a&gt;, which can be used to visualise the processors within a pipeline.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Bento provides lots of tools for making configuration discovery, debugging and organisation easy. You can &lt;a href=&#34;https://warpstreamlabs.github.io/bento/docs/configuration/about&#34;&gt;read about them here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Build&lt;/h2&gt; &#xA;&lt;p&gt;Build with Go (any &lt;a href=&#34;https://go.dev/dl/&#34;&gt;currently supported version&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone git@github.com:warpstreamlabs/bento&#xA;cd bento&#xA;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Lint&lt;/h2&gt; &#xA;&lt;p&gt;Bento uses &lt;a href=&#34;https://golangci-lint.run/&#34;&gt;golangci-lint&lt;/a&gt; for linting, which you can install with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then run it with &lt;code&gt;make lint&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Plugins&lt;/h2&gt; &#xA;&lt;p&gt;It&#39;s pretty easy to write your own custom plugins for Bento in Go, for information check out &lt;a href=&#34;https://pkg.go.dev/github.com/warpstreamlabs/bento/v4/public&#34;&gt;the API docs&lt;/a&gt;, and for inspiration there&#39;s an &lt;a href=&#34;https://github.com/warpstreamlabs/bento-plugin-example&#34;&gt;example repo&lt;/a&gt; demonstrating a variety of plugin implementations.&lt;/p&gt; &#xA;&lt;h2&gt;Extra Plugins&lt;/h2&gt; &#xA;&lt;p&gt;By default Bento does not build with components that require linking to external libraries, such as the &lt;code&gt;zmq4&lt;/code&gt; input and outputs. If you wish to build Bento locally with these dependencies then set the build tag &lt;code&gt;x_bento_extra&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# With go&#xA;go install -tags &#34;x_bento_extra&#34; github.com/warpstreamlabs/bento/v4/cmd/bento@latest&#xA;&#xA;# Using make&#xA;make TAGS=x_bento_extra&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that this tag may change or be broken out into granular tags for individual components outside of major version releases. If you attempt a build and these dependencies are not present you&#39;ll see error messages such as &lt;code&gt;ld: library not found for -lzmq&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Docker Builds&lt;/h2&gt; &#xA;&lt;p&gt;There&#39;s a multi-stage &lt;code&gt;Dockerfile&lt;/code&gt; for creating a Bento docker image which results in a minimal image from scratch. You can build it with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;make docker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then use the image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run --rm \&#xA;&#x9;-v /path/to/your/bento.yaml:/config.yaml \&#xA;&#x9;-v /tmp/data:/data \&#xA;&#x9;-p 4195:4195 \&#xA;&#x9;bento -c /config.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome, please &lt;a href=&#34;https://raw.githubusercontent.com/warpstreamlabs/bento/main/CONTRIBUTING.md&#34;&gt;read the guidelines&lt;/a&gt;, come and chat (links are on the &lt;a href=&#34;https://warpstreamlabs.github.io/bento/community&#34;&gt;community page&lt;/a&gt;), and watch your back.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>getseabird/seabird</title>
    <updated>2024-06-03T01:30:46Z</updated>
    <id>tag:github.com,2024-06-03:/getseabird/seabird</id>
    <link href="https://github.com/getseabird/seabird" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Native Kubernetes desktop client.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Seabird&lt;/h1&gt; &#xA;&lt;p&gt;Seabird is a native cross-platform Kubernetes desktop client that makes it super easy to explore your cluster&#39;s resources. We aim to visualize all common resource types in a simple, bloat-free user interface.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://getseabird.github.io/images/screenshot.png&#34; alt=&#34;Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;Downloads for all platforms are available under &lt;a href=&#34;https://github.com/getseabird/seabird/releases&#34;&gt;releases&lt;/a&gt;. On Linux, we recommend using the Flatpak package.&lt;/p&gt; &#xA;&lt;a href=&#34;https://flathub.org/apps/dev.skynomads.Seabird&#34;&gt; &lt;img width=&#34;140&#34; alt=&#34;Download on Flathub&#34; src=&#34;https://flathub.org/api/badge?locale=en&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Building From Source&lt;/h2&gt; &#xA;&lt;p&gt;Build dependencies&lt;/p&gt; &#xA;&lt;h4&gt;Fedora&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo dnf install gtk4-devel gtksourceview5-devel libadwaita-devel gobject-introspection-devel glib2-devel vte291-gtk4-devel golang&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Debian&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt install libgtk-4-dev libgtksourceview-5-dev libadwaita-1-dev libgirepository1.0-dev libglib2.0-dev-bin libvte-2.91-gtk4-dev golang-go&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run go generate to create the embedded resource file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go generate ./...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then build with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Reporting Issues&lt;/h2&gt; &#xA;&lt;p&gt;If you experience problems, please open an &lt;a href=&#34;https://raw.githubusercontent.com/getseabird/seabird/main/github.com/getseabird/seabird/issues&#34;&gt;issue&lt;/a&gt;. Try to include as much information as possible, such as version, operating system and reproduction steps.&lt;/p&gt; &#xA;&lt;p&gt;For feature suggestions, please create a &lt;a href=&#34;https://github.com/getseabird/seabird/discussions&#34;&gt;discussion&lt;/a&gt;. If you have a concrete vision for the feature, open an issue instead and use the proposal template.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Seabird is available under the terms of the Mozilla Public License v2, a copy of the license is distributed in the LICENSE file.&lt;/p&gt; &#xA;&lt;p&gt;Note: This is paid software with an unlimited free trial.&lt;/p&gt;</summary>
  </entry>
</feed>