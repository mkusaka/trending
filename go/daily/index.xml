<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-10T01:41:18Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>kubernetes/kube-state-metrics</title>
    <updated>2022-06-10T01:41:18Z</updated>
    <id>tag:github.com,2022-06-10:/kubernetes/kube-state-metrics</id>
    <link href="https://github.com/kubernetes/kube-state-metrics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Add-on agent to generate and expose cluster-level metrics.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Overview&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics/actions&#34;&gt;&lt;img src=&#34;https://github.com/kubernetes/kube-state-metrics/workflows/continuous-integration/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/kubernetes/kube-state-metrics&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/kubernetes/kube-state-metrics&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://godoc.org/github.com/kubernetes/kube-state-metrics&#34;&gt;&lt;img src=&#34;https://godoc.org/github.com/kubernetes/kube-state-metrics?status.svg?sanitize=true&#34; alt=&#34;GoDoc&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;kube-state-metrics (KSM) is a simple service that listens to the Kubernetes API server and generates metrics about the state of the objects. (See examples in the Metrics section below.) It is not focused on the health of the individual Kubernetes components, but rather on the health of the various objects inside, such as deployments, nodes and pods.&lt;/p&gt; &#xA;&lt;p&gt;kube-state-metrics is about generating metrics from Kubernetes API objects without modification. This ensures that features provided by kube-state-metrics have the same grade of stability as the Kubernetes API objects themselves. In turn, this means that kube-state-metrics in certain situations may not show the exact same values as kubectl, as kubectl applies certain heuristics to display comprehensible messages. kube-state-metrics exposes raw data unmodified from the Kubernetes API, this way users have all the data they require and perform heuristics as they see fit.&lt;/p&gt; &#xA;&lt;p&gt;The metrics are exported on the HTTP endpoint &lt;code&gt;/metrics&lt;/code&gt; on the listening port (default 8080). They are served as plaintext. They are designed to be consumed either by Prometheus itself or by a scraper that is compatible with scraping a Prometheus client endpoint. You can also open &lt;code&gt;/metrics&lt;/code&gt; in a browser to see the raw metrics. Note that the metrics exposed on the &lt;code&gt;/metrics&lt;/code&gt; endpoint reflect the current state of the Kubernetes cluster. When Kubernetes objects are deleted they are no longer visible on the &lt;code&gt;/metrics&lt;/code&gt; endpoint.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#versioning&#34;&gt;Versioning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#kubernetes-version&#34;&gt;Kubernetes Version&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#compatibility-matrix&#34;&gt;Compatibility matrix&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#resource-group-version-compatibility&#34;&gt;Resource group version compatibility&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#container-image&#34;&gt;Container Image&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#metrics-documentation&#34;&gt;Metrics Documentation&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#conflict-resolution-in-label-names&#34;&gt;Conflict resolution in label names&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#enabling-verticalpodautoscalers&#34;&gt;Enabling VerticalPodAutoscalers&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#kube-state-metrics-self-metrics&#34;&gt;Kube-state-metrics self metrics&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#resource-recommendation&#34;&gt;Resource recommendation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#latency&#34;&gt;Latency&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#a-note-on-costing&#34;&gt;A note on costing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#kube-state-metrics-vs-metrics-server&#34;&gt;kube-state-metrics vs. metrics-server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#scaling-kube-state-metrics&#34;&gt;Scaling kube-state-metrics&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#resource-recommendation&#34;&gt;Resource recommendation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#horizontal-sharding&#34;&gt;Horizontal sharding&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#automated-sharding&#34;&gt;Automated sharding&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#setup&#34;&gt;Setup&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#building-the-docker-container&#34;&gt;Building the Docker container&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#kubernetes-deployment&#34;&gt;Kubernetes Deployment&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#limited-privileges-environment&#34;&gt;Limited privileges environment&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#helm-chart&#34;&gt;Helm Chart&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#development&#34;&gt;Development&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/#developer-contributions&#34;&gt;Developer Contributions&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Kubernetes Version&lt;/h4&gt; &#xA;&lt;p&gt;kube-state-metrics uses &lt;a href=&#34;https://github.com/kubernetes/client-go&#34;&gt;&lt;code&gt;client-go&lt;/code&gt;&lt;/a&gt; to talk with Kubernetes clusters. The supported Kubernetes cluster version is determined by &lt;code&gt;client-go&lt;/code&gt;. The compatibility matrix for client-go and Kubernetes cluster can be found &lt;a href=&#34;https://github.com/kubernetes/client-go#compatibility-matrix&#34;&gt;here&lt;/a&gt;. All additional compatibility is only best effort, or happens to still/already be supported.&lt;/p&gt; &#xA;&lt;h4&gt;Compatibility matrix&lt;/h4&gt; &#xA;&lt;p&gt;At most, 5 kube-state-metrics and 5 &lt;a href=&#34;https://github.com/kubernetes/kubernetes/releases&#34;&gt;kubernetes releases&lt;/a&gt; will be recorded below.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;kube-state-metrics&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Kubernetes 1.20&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Kubernetes 1.21&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Kubernetes 1.22&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Kubernetes 1.23&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Kubernetes 1.24&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v2.2.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v2.3.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v2.4.2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-/✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-/✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v2.5.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-/✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-/✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;master&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-/✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-/✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✓&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;✓&lt;/code&gt; Fully supported version range.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-&lt;/code&gt; The Kubernetes cluster has features the client-go library can&#39;t use (additional API objects, deprecated APIs, etc).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The current kube-state-metrics &lt;code&gt;v2.0.0 +&lt;/code&gt; releases work on Kubernetes v1.17 &amp;amp; v1.18 excluding Ingress or CertificateSigningRequest resource metrics. If you require those metrics on an older Kubernetes version, use kube-state-metrics &lt;code&gt;v1.9.8&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Resource group version compatibility&lt;/h4&gt; &#xA;&lt;p&gt;Resources in Kubernetes can evolve, i.e., the group version for a resource may change from alpha to beta and finally GA in different Kubernetes versions. For now, kube-state-metrics will only use the oldest API available in the latest release.&lt;/p&gt; &#xA;&lt;h4&gt;Container Image&lt;/h4&gt; &#xA;&lt;p&gt;The latest container image can be found at:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.5.0&lt;/code&gt; (arch: &lt;code&gt;amd64&lt;/code&gt;, &lt;code&gt;arm&lt;/code&gt;, &lt;code&gt;arm64&lt;/code&gt;, &lt;code&gt;ppc64le&lt;/code&gt; and &lt;code&gt;s390x&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Metrics Documentation&lt;/h3&gt; &#xA;&lt;p&gt;Any resources and metrics based on alpha Kubernetes APIs are excluded from any stability guarantee, which may be changed at any given release.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/docs&#34;&gt;&lt;code&gt;docs&lt;/code&gt;&lt;/a&gt; directory for more information on the exposed metrics.&lt;/p&gt; &#xA;&lt;h4&gt;Conflict resolution in label names&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;*_labels&lt;/code&gt; family of metrics exposes Kubernetes labels as Prometheus labels. As &lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set&#34;&gt;Kubernetes&lt;/a&gt; is more liberal than &lt;a href=&#34;https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels&#34;&gt;Prometheus&lt;/a&gt; in terms of allowed characters in label names, we automatically convert unsupported characters to underscores. For example, &lt;code&gt;app.kubernetes.io/name&lt;/code&gt; becomes &lt;code&gt;label_app_kubernetes_io_name&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This conversion can create conflicts when multiple Kubernetes labels like &lt;code&gt;foo-bar&lt;/code&gt; and &lt;code&gt;foo_bar&lt;/code&gt; would be converted to the same Prometheus label &lt;code&gt;label_foo_bar&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Kube-state-metrics automatically adds a suffix &lt;code&gt;_conflictN&lt;/code&gt; to resolve this conflict, so it converts the above labels to &lt;code&gt;label_foo_bar_conflict1&lt;/code&gt; and &lt;code&gt;label_foo_bar_conflict2&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d like to have more control over how this conflict is resolved, you might want to consider addressing this issue on a different level of the stack, e.g. by standardizing Kubernetes labels using an &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/&#34;&gt;Admission Webhook&lt;/a&gt; that ensures that there are no possible conflicts.&lt;/p&gt; &#xA;&lt;h4&gt;Enabling VerticalPodAutoscalers&lt;/h4&gt; &#xA;&lt;p&gt;Please note that the collector for &lt;code&gt;verticalpodautoscalers&lt;/code&gt; is &lt;strong&gt;disabled&lt;/strong&gt; by default; Vertical Pod Autoscaler metrics will not be collected until the collector is enabled. This is because Vertical Pod Autoscalers are managed as custom resources.&lt;/p&gt; &#xA;&lt;p&gt;If you want to enable this collector, the &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/docs/verticalpodautoscaler-metrics.md#Configuration&#34;&gt;instructions&lt;/a&gt; are located in the &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/docs/verticalpodautoscaler-metrics.md&#34;&gt;Vertical Pod Autoscaler Metrics&lt;/a&gt; documentation.&lt;/p&gt; &#xA;&lt;h3&gt;Kube-state-metrics self metrics&lt;/h3&gt; &#xA;&lt;p&gt;kube-state-metrics exposes its own general process metrics under &lt;code&gt;--telemetry-host&lt;/code&gt; and &lt;code&gt;--telemetry-port&lt;/code&gt; (default 8081).&lt;/p&gt; &#xA;&lt;p&gt;kube-state-metrics also exposes list and watch success and error metrics. These can be used to calculate the error rate of list or watch resources. If you encounter those errors in the metrics, it is most likely a configuration or permission issue, and the next thing to investigate would be looking at the logs of kube-state-metrics.&lt;/p&gt; &#xA;&lt;p&gt;Example of the above mentioned metrics:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;kube_state_metrics_list_total{resource=&#34;*v1.Node&#34;,result=&#34;success&#34;} 1&#xA;kube_state_metrics_list_total{resource=&#34;*v1.Node&#34;,result=&#34;error&#34;} 52&#xA;kube_state_metrics_watch_total{resource=&#34;*v1beta1.Ingress&#34;,result=&#34;success&#34;} 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;kube-state-metrics also exposes some http request metrics, examples of those are:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;http_request_duration_seconds_bucket{handler=&#34;metrics&#34;,method=&#34;get&#34;,le=&#34;2.5&#34;} 30&#xA;http_request_duration_seconds_bucket{handler=&#34;metrics&#34;,method=&#34;get&#34;,le=&#34;5&#34;} 30&#xA;http_request_duration_seconds_bucket{handler=&#34;metrics&#34;,method=&#34;get&#34;,le=&#34;10&#34;} 30&#xA;http_request_duration_seconds_bucket{handler=&#34;metrics&#34;,method=&#34;get&#34;,le=&#34;+Inf&#34;} 30&#xA;http_request_duration_seconds_sum{handler=&#34;metrics&#34;,method=&#34;get&#34;} 0.021113919999999998&#xA;http_request_duration_seconds_count{handler=&#34;metrics&#34;,method=&#34;get&#34;} 30&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;kube-state-metrics also exposes build and configuration metrics:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;kube_state_metrics_build_info{branch=&#34;master&#34;,goversion=&#34;go1.15.3&#34;,revision=&#34;6c9d775d&#34;,version=&#34;v2.0.0-beta&#34;} 1&#xA;kube_state_metrics_shard_ordinal{shard_ordinal=&#34;0&#34;} 0&#xA;kube_state_metrics_total_shards 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;kube_state_metrics_build_info&lt;/code&gt; is used to expose version and other build information. For more usage about the info pattern, please check the blog post &lt;a href=&#34;https://www.robustperception.io/exposing-the-software-version-to-prometheus&#34;&gt;here&lt;/a&gt;. Sharding metrics expose &lt;code&gt;--shard&lt;/code&gt; and &lt;code&gt;--total-shards&lt;/code&gt; flags and can be used to validate run-time configuration, see &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/examples/prometheus-alerting-rules&#34;&gt;&lt;code&gt;/examples/prometheus-alerting-rules&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Scaling kube-state-metrics&lt;/h3&gt; &#xA;&lt;h4&gt;Resource recommendation&lt;/h4&gt; &#xA;&lt;p&gt;Resource usage for kube-state-metrics changes with the Kubernetes objects (Pods/Nodes/Deployments/Secrets etc.) size of the cluster. To some extent, the Kubernetes objects in a cluster are in direct proportion to the node number of the cluster.&lt;/p&gt; &#xA;&lt;p&gt;As a general rule, you should allocate:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;250MiB memory&lt;/li&gt; &#xA; &lt;li&gt;0.1 cores&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note that if CPU limits are set too low, kube-state-metrics&#39; internal queues will not be able to be worked off quickly enough, resulting in increased memory consumption as the queue length grows. If you experience problems resulting from high memory allocation or CPU throttling, try increasing the CPU limits.&lt;/p&gt; &#xA;&lt;h3&gt;Latency&lt;/h3&gt; &#xA;&lt;p&gt;In a 100 node cluster scaling test the latency numbers were as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;Perc50&#34;: 259615384 ns,&#xA;&#34;Perc90&#34;: 475000000 ns,&#xA;&#34;Perc99&#34;: 906666666 ns.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;A note on costing&lt;/h3&gt; &#xA;&lt;p&gt;By default, kube-state-metrics exposes several metrics for events across your cluster. If you have a large number of frequently-updating resources on your cluster, you may find that a lot of data is ingested into these metrics. This can incur high costs on some cloud providers. Please take a moment to &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/docs/cli-arguments.md&#34;&gt;configure what metrics you&#39;d like to expose&lt;/a&gt;, as well as consult the documentation for your Kubernetes environment in order to avoid unexpectedly high costs.&lt;/p&gt; &#xA;&lt;h3&gt;kube-state-metrics vs. metrics-server&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/kubernetes-incubator/metrics-server&#34;&gt;metrics-server&lt;/a&gt; is a project that has been inspired by &lt;a href=&#34;https://github.com/kubernetes-retired/heapster&#34;&gt;Heapster&lt;/a&gt; and is implemented to serve the goals of core metrics pipelines in &lt;a href=&#34;https://github.com/kubernetes/community/raw/master/contributors/design-proposals/instrumentation/monitoring_architecture.md&#34;&gt;Kubernetes monitoring architecture&lt;/a&gt;. It is a cluster level component which periodically scrapes metrics from all Kubernetes nodes served by Kubelet through Summary API. The metrics are aggregated, stored in memory and served in &lt;a href=&#34;https://git.k8s.io/metrics/pkg/apis/metrics/v1alpha1/types.go&#34;&gt;Metrics API format&lt;/a&gt;. The metrics-server stores the latest values only and is not responsible for forwarding metrics to third-party destinations.&lt;/p&gt; &#xA;&lt;p&gt;kube-state-metrics is focused on generating completely new metrics from Kubernetes&#39; object state (e.g. metrics based on deployments, replica sets, etc.). It holds an entire snapshot of Kubernetes state in memory and continuously generates new metrics based off of it. And just like the metrics-server it too is not responsible for exporting its metrics anywhere.&lt;/p&gt; &#xA;&lt;p&gt;Having kube-state-metrics as a separate project also enables access to these metrics from monitoring systems such as Prometheus.&lt;/p&gt; &#xA;&lt;h3&gt;Horizontal sharding&lt;/h3&gt; &#xA;&lt;p&gt;In order to shard kube-state-metrics horizontally, some automated sharding capabilities have been implemented. It is configured with the following flags:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--shard&lt;/code&gt; (zero indexed)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--total-shards&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Sharding is done by taking an md5 sum of the Kubernetes Object&#39;s UID and performing a modulo operation on it with the total number of shards. Each shard decides whether the object is handled by the respective instance of kube-state-metrics or not. Note that this means all instances of kube-state-metrics, even if sharded, will have the network traffic and the resource consumption for unmarshaling objects for all objects, not just the ones they are responsible for. To optimize this further, the Kubernetes API would need to support sharded list/watch capabilities. In the optimal case, memory consumption for each shard will be 1/n compared to an unsharded setup. Typically, kube-state-metrics needs to be memory and latency optimized in order for it to return its metrics rather quickly to Prometheus. One way to reduce the latency between kube-state-metrics and the kube-apiserver is to run KSM with the &lt;code&gt;--use-apiserver-cache&lt;/code&gt; flag. In addition to reducing the latency, this option will also lead to a reduction in the load on etcd.&lt;/p&gt; &#xA;&lt;p&gt;Sharding should be used carefully and additional monitoring should be set up in order to ensure that sharding is set up and functioning as expected (eg. instances for each shard out of the total shards are configured).&lt;/p&gt; &#xA;&lt;h4&gt;Automated sharding&lt;/h4&gt; &#xA;&lt;p&gt;Automatic sharding allows each shard to discover its nominal position when deployed in a StatefulSet which is useful for automatically configuring sharding. This is an experimental feature and may be broken or removed without notice.&lt;/p&gt; &#xA;&lt;p&gt;To enable automated sharding, kube-state-metrics must be run by a &lt;code&gt;StatefulSet&lt;/code&gt; and the pod name and namespace must be handed to the kube-state-metrics process via the &lt;code&gt;--pod&lt;/code&gt; and &lt;code&gt;--pod-namespace&lt;/code&gt; flags. Example manifests demonstrating the autosharding functionality can be found in &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/examples/autosharding&#34;&gt;&lt;code&gt;/examples/autosharding&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This way of deploying shards is useful when you want to manage KSM shards through a single Kubernetes resource (a single &lt;code&gt;StatefulSet&lt;/code&gt; in this case) instead of having one &lt;code&gt;Deployment&lt;/code&gt; per shard. The advantage can be especially significant when deploying a high number of shards.&lt;/p&gt; &#xA;&lt;p&gt;The downside of using an auto-sharded setup comes from the rollout strategy supported by &lt;code&gt;StatefulSet&lt;/code&gt;s. When managed by a &lt;code&gt;StatefulSet&lt;/code&gt;, pods are replaced one at a time with each pod first getting terminated and then recreated. Besides such rollouts being slower, they will also lead to short downtime for each shard. If a Prometheus scrape happens during a rollout, it can miss some of the metrics exported by kube-state-metrics.&lt;/p&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;p&gt;Install this project to your &lt;code&gt;$GOPATH&lt;/code&gt; using &lt;code&gt;go get&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;go get k8s.io/kube-state-metrics&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Building the Docker container&lt;/h4&gt; &#xA;&lt;p&gt;Simply run the following command in this root folder, which will create a self-contained, statically-linked binary and build a Docker image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make container&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Simply build and run kube-state-metrics inside a Kubernetes pod which has a service account token that has read-only access to the Kubernetes cluster.&lt;/p&gt; &#xA;&lt;h4&gt;For users of prometheus-operator/kube-prometheus stack&lt;/h4&gt; &#xA;&lt;p&gt;The (&lt;a href=&#34;https://github.com/prometheus-operator/kube-prometheus/&#34;&gt;&lt;code&gt;kube-prometheus&lt;/code&gt;&lt;/a&gt;) stack installs kube-state-metrics as one of its &lt;a href=&#34;https://github.com/prometheus-operator/kube-prometheus#kube-prometheus&#34;&gt;components&lt;/a&gt;; you do not need to install kube-state-metrics if you&#39;re using the kube-prometheus stack.&lt;/p&gt; &#xA;&lt;p&gt;If you want to revise the default configuration for kube-prometheus, for example to enable non-default metrics, have a look at &lt;a href=&#34;https://github.com/prometheus-operator/kube-prometheus#customizing-kube-prometheus&#34;&gt;Customizing Kube-Prometheus&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Kubernetes Deployment&lt;/h4&gt; &#xA;&lt;p&gt;To deploy this project, you can simply run &lt;code&gt;kubectl apply -f examples/standard&lt;/code&gt; and a Kubernetes service and deployment will be created. (Note: Adjust the apiVersion of some resource if your kubernetes cluster&#39;s version is not 1.8+, check the yaml file for more information).&lt;/p&gt; &#xA;&lt;p&gt;To have Prometheus discover kube-state-metrics instances it is advised to create a specific Prometheus scrape config for kube-state-metrics that picks up both metrics endpoints. Annotation based discovery is discouraged as only one of the endpoints would be able to be selected, plus kube-state-metrics in most cases has special authentication and authorization requirements as it essentially grants read access through the metrics endpoint to most information available to it.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Google Kubernetes Engine (GKE) Users - GKE has strict role permissions that will prevent the kube-state-metrics roles and role bindings from being created. To work around this, you can give your GCP identity the cluster-admin role by running the following one-liner:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$(gcloud info --format=&#39;value(config.account)&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that your GCP identity is case sensitive but &lt;code&gt;gcloud info&lt;/code&gt; as of Google Cloud SDK 221.0.0 is not. This means that if your IAM member contains capital letters, the above one-liner may not work for you. If you have 403 forbidden responses after running the above command and &lt;code&gt;kubectl apply -f examples/standard&lt;/code&gt;, check the IAM member associated with your account at &lt;a href=&#34;https://console.cloud.google.com/iam-admin/iam?project=PROJECT_ID&#34;&gt;https://console.cloud.google.com/iam-admin/iam?project=PROJECT_ID&lt;/a&gt;. If it contains capital letters, you may need to set the --user flag in the command above to the case-sensitive role listed at &lt;a href=&#34;https://console.cloud.google.com/iam-admin/iam?project=PROJECT_ID&#34;&gt;https://console.cloud.google.com/iam-admin/iam?project=PROJECT_ID&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;After running the above, if you see &lt;code&gt;Clusterrolebinding &#34;cluster-admin-binding&#34; created&lt;/code&gt;, then you are able to continue with the setup of this service.&lt;/p&gt; &#xA;&lt;h4&gt;Limited privileges environment&lt;/h4&gt; &#xA;&lt;p&gt;If you want to run kube-state-metrics in an environment where you don&#39;t have cluster-reader role, you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;create a serviceaccount&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1&#xA;kind: ServiceAccount&#xA;metadata:&#xA;  name: kube-state-metrics&#xA;  namespace: your-namespace-where-kube-state-metrics-will-deployed&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;give it &lt;code&gt;view&lt;/code&gt; privileges on specific namespaces (using roleBinding) (&lt;em&gt;note: you can add this roleBinding to all the NS you want your serviceaccount to access&lt;/em&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: rbac.authorization.k8s.io/v1&#xA;kind: RoleBinding&#xA;metadata:&#xA;  name: kube-state-metrics&#xA;  namespace: project1&#xA;roleRef:&#xA;  apiGroup: rbac.authorization.k8s.io&#xA;  kind: ClusterRole&#xA;  name: view&#xA;subjects:&#xA;  - kind: ServiceAccount&#xA;    name: kube-state-metrics&#xA;    namespace: your-namespace-where-kube-state-metrics-will-deployed&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;then specify a set of namespaces (using the &lt;code&gt;--namespaces&lt;/code&gt; option) and a set of kubernetes objects (using the &lt;code&gt;--resources&lt;/code&gt;) that your serviceaccount has access to in the &lt;code&gt;kube-state-metrics&lt;/code&gt; deployment configuration&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;spec:&#xA;  template:&#xA;    spec:&#xA;      containers:&#xA;      - name: kube-state-metrics&#xA;        args:&#xA;          - &#39;--resources=pods&#39;&#xA;          - &#39;--namespaces=project1&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For the full list of arguments available, see the documentation in &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/docs/cli-arguments.md&#34;&gt;docs/cli-arguments.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Helm Chart&lt;/h4&gt; &#xA;&lt;p&gt;Starting from the kube-state-metrics chart &lt;code&gt;v2.13.3&lt;/code&gt; (kube-state-metrics image &lt;code&gt;v1.9.8&lt;/code&gt;), the official &lt;a href=&#34;https://artifacthub.io/packages/helm/prometheus-community/kube-state-metrics/&#34;&gt;Helm chart&lt;/a&gt; is maintained in &lt;a href=&#34;https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-state-metrics&#34;&gt;prometheus-community/helm-charts&lt;/a&gt;. Starting from kube-state-metrics chart &lt;code&gt;v3.0.0&lt;/code&gt; only kube-state-metrics images of &lt;code&gt;v2.0.0 +&lt;/code&gt; are supported.&lt;/p&gt; &#xA;&lt;h4&gt;Development&lt;/h4&gt; &#xA;&lt;p&gt;When developing, test a metric dump against your local Kubernetes cluster by running:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Users can override the apiserver address in KUBE-CONFIG file with &lt;code&gt;--apiserver&lt;/code&gt; command line.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code&gt;go install&#xA;kube-state-metrics --port=8080 --telemetry-port=8081 --kubeconfig=&amp;lt;KUBE-CONFIG&amp;gt; --apiserver=&amp;lt;APISERVER&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then curl the metrics endpoint&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl localhost:8080/metrics&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the e2e tests locally see the documentation in &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/tests/README.md&#34;&gt;tests/README.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Developer Contributions&lt;/h4&gt; &#xA;&lt;p&gt;When developing, there are certain code patterns to follow to better your contributing experience and likelihood of e2e and other ci tests to pass. To learn more about them, see the documentation in &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/kube-state-metrics/master/docs/developer/guide.md&#34;&gt;docs/developer/guide.md&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>crossplane/crossplane</title>
    <updated>2022-06-10T01:41:18Z</updated>
    <id>tag:github.com,2022-06-10:/crossplane/crossplane</id>
    <link href="https://github.com/crossplane/crossplane" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cloud Native Control Planes&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/crossplane/crossplane/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt; &lt;a href=&#34;https://github.com/crossplane/crossplane/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/crossplane/crossplane/all.svg?style=flat-square&#34; alt=&#34;GitHub release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/crossplane/crossplane&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/crossplane/crossplane.svg?sanitize=true&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/crossplane/crossplane&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/crossplane/crossplane&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://slack.crossplane.io&#34;&gt;&lt;img src=&#34;https://slack.crossplane.io/badge.svg?sanitize=true&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/follow?screen_name=crossplane_io&amp;amp;user_id=788180534543339520&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/crossplane_io.svg?style=social&amp;amp;label=Follow&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/crossplane/crossplane/master/docs/media/banner.png&#34; alt=&#34;Crossplane&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Crossplane is a framework for building cloud native control planes without needing to write code. It has a highly extensible backend that enables you to build a control plane that can orchestrate applications and infrastructure no matter where they run, and a highly configurable frontend that puts you in control of the schema of the declarative API it offers.&lt;/p&gt; &#xA;&lt;p&gt;Crossplane is a &lt;a href=&#34;https://www.cncf.io/&#34;&gt;Cloud Native Compute Foundation&lt;/a&gt; project.&lt;/p&gt; &#xA;&lt;h2&gt;Releases&lt;/h2&gt; &#xA;&lt;p&gt;Currently maintained releases, as well as the next upcoming release are listed below. For more information take a look at the Crossplane &lt;a href=&#34;https://crossplane.io/docs/master/reference/release-cycle.html&#34;&gt;release cycle documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Release&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Release Date&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;EOL&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;v1.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Jan 4, 2022&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;July 2022&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;v1.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Mar 22, 2022&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Sept 2022&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;v1.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;May 17, 2022&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Dec 2022&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;You can subscribe to the &lt;a href=&#34;https://calendar.google.com/calendar/embed?src=c_2cdn0hs9e2m05rrv1233cjoj1k%40group.calendar.google.com&#34;&gt;community calendar&lt;/a&gt; to track all release dates, and find the most recent releases on the &lt;a href=&#34;https://github.com/crossplane/crossplane/releases&#34;&gt;releases&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;h2&gt;Get Involved&lt;/h2&gt; &#xA;&lt;p&gt;Crossplane is a community driven project; we welcome your contribution. To file a bug, suggest an improvement, or request a new feature please open an &lt;a href=&#34;https://github.com/crossplane/crossplane/issues&#34;&gt;issue against Crossplane&lt;/a&gt; or the relevant provider. Refer to our &lt;a href=&#34;https://raw.githubusercontent.com/crossplane/crossplane/master/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; for more information on how you can help.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Discuss Crossplane on &lt;a href=&#34;https://slack.crossplane.io&#34;&gt;Slack&lt;/a&gt; or our &lt;a href=&#34;https://groups.google.com/forum/#!forum/crossplane-dev&#34;&gt;developer mailing list&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Follow us on &lt;a href=&#34;https://twitter.com/crossplane_io&#34;&gt;Twitter&lt;/a&gt;, or contact us via &lt;a href=&#34;mailto:info@crossplane.io&#34;&gt;Email&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Join our regular community meetings.&lt;/li&gt; &#xA; &lt;li&gt;Provide feedback on our &lt;a href=&#34;https://github.com/orgs/crossplane/projects/12&#34;&gt;roadmap&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The Crossplane community meeting takes place every other &lt;a href=&#34;https://www.thetimezoneconverter.com/?t=10:00&amp;amp;tz=PT%20%28Pacific%20Time%29&#34;&gt;Thursday at 10:00am Pacific Time&lt;/a&gt;. Anyone who wants to discuss the direction of the project, design and implementation reviews, or raise general questions with the broader community is encouraged to join.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Meeting link: &lt;a href=&#34;https://zoom.us/j/425148449?pwd=NEk4N0tHWGpEazhuam1yR28yWHY5QT09&#34;&gt;https://zoom.us/j/425148449?pwd=NEk4N0tHWGpEazhuam1yR28yWHY5QT09&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1q_sp2jLQsDEOX7Yug6TPOv7Fwrys6EwcF5Itxjkno7Y/edit?usp=sharing&#34;&gt;Current agenda and past meeting notes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PL510POnNVaaYYYDSICFSNWFqNbx1EMr-M&#34;&gt;Past meeting recordings&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://calendar.google.com/calendar/embed?src=c_2cdn0hs9e2m05rrv1233cjoj1k%40group.calendar.google.com&#34;&gt;Community Calendar&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Crossplane is under the Apache 2.0 license.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://app.fossa.io/projects/git%2Bgithub.com%2Fcrossplane%2Fcrossplane?ref=badge_large&#34;&gt;&lt;img src=&#34;https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcrossplane%2Fcrossplane.svg?type=large&#34; alt=&#34;FOSSA Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- Named links --&gt;</summary>
  </entry>
  <entry>
    <title>knadh/dns.toys</title>
    <updated>2022-06-10T01:41:18Z</updated>
    <id>tag:github.com,2022-06-10:/knadh/dns.toys</id>
    <link href="https://github.com/knadh/dns.toys" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A DNS server that offers useful utilities and services over the DNS protocol.&lt;/p&gt;&lt;hr&gt;&lt;img width=&#34;150&#34; src=&#34;https://user-images.githubusercontent.com/547147/171995179-b9d2faae-d659-4260-99df-04c62c171f6f.png&#34;&gt; &#xA;&lt;p&gt;dns.toys is a DNS server that takes creative liberties with the DNS protocol to offer handy utilities and services that are easily accessible via the command line.&lt;/p&gt; &#xA;&lt;p&gt;For docs, visit &lt;a href=&#34;https://www.dns.toys&#34;&gt;&lt;strong&gt;www.dns.toys&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Sample commands&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dig help @dns.toys&#xA;&#xA;dig mumbai.time @dns.toys&#xA;&#xA;dig newyork.weather @dns.toys&#xA;&#xA;dig 42km-mi.unit @dns.toys&#xA;&#xA;dig 100USD-INR.fx @dns.toys&#xA;&#xA;dig ip @dns.toys&#xA;&#xA;dig 987654321.words @dns.toys&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running locally&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Clone the repo&lt;/li&gt; &#xA; &lt;li&gt;Copy &lt;code&gt;config.sample.toml&lt;/code&gt; to &lt;code&gt;config.toml&lt;/code&gt; and edit the config&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;make build&lt;/code&gt; to build the binary. Then run &lt;code&gt;./dnstoys.bin&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>