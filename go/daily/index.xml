<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-08-09T01:31:52Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>maximhq/bifrost</title>
    <updated>2025-08-09T01:31:52Z</updated>
    <id>tag:github.com,2025-08-09:/maximhq/bifrost</id>
    <link href="https://github.com/maximhq/bifrost" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Fastest LLM Gateway with built in OTel observability and MCP gateway&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.producthunt.com/products/maxim-ai?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-bifrost-2&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=1000604&amp;amp;theme=dark&amp;amp;t=1754378611200&#34; alt=&#34;Bifrost - The fastest LLM gateway in the market | Product Hunt&#34; style=&#34;width: 250px; height: 54px;&#34; width=&#34;250&#34; height=&#34;54&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;Bifrost&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://goreportcard.com/report/github.com/maximhq/bifrost/core&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/maximhq/bifrost/core&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The fastest way to build AI applications that never go down.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Bifrost is a high-performance AI gateway that connects you to 10+ providers (OpenAI, Anthropic, Bedrock, and more) through a single API. Get automatic failover, load balancing, and zero-downtime deployments in under 30 seconds.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/media/cover.png&#34; alt=&#34;Bifrost&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ğŸš€ &lt;strong&gt;Just launched:&lt;/strong&gt; Native MCP (Model Context Protocol) support for seamless tool integration&lt;br&gt; âš¡ &lt;strong&gt;Performance:&lt;/strong&gt; Adds only 11Âµs latency while handling 5,000+ RPS&lt;br&gt; ğŸ›¡ï¸ &lt;strong&gt;Reliability:&lt;/strong&gt; 100% uptime with automatic provider failover&lt;/p&gt; &#xA;&lt;h2&gt;âš¡ Quickstart (30 seconds)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Go from zero to production-ready AI gateway in under a minute.&lt;/strong&gt; Here&#39;s how:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What You Need&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Any AI provider API key (OpenAI, Anthropic, Bedrock, etc.)&lt;/li&gt; &#xA; &lt;li&gt;Node.js 18+ installed (or use Docker instead via &lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/quickstart/http-transport.md&#34;&gt;Docker installation&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;20 seconds of your time â°&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Using Bifrost HTTP Transport&lt;/h3&gt; &#xA;&lt;p&gt;ğŸ“– For detailed setup guides with multiple providers, advanced configuration, and language examples, see &lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/quickstart/http-transport.md&#34;&gt;Quick Start Documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Start Bifrost&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ğŸ”§ Run Bifrost binary&#xA;npx @maximhq/bifrost&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Open the built-in web interface and configure bifrost&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ğŸ–¥ï¸ Open the web interface in your browser&#xA;open http://localhost:8080&#xA;&#xA;# Or simply open http://localhost:8080 manually in your browser&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Test it works&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X POST http://localhost:8080/v1/chat/completions \&#xA;  -H &#34;Content-Type: application/json&#34; \&#xA;  -d &#39;{&#xA;    &#34;model&#34;: &#34;openai/gpt-4o-mini&#34;,&#xA;    &#34;messages&#34;: [&#xA;      {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Hello from Bifrost! ğŸŒˆ&#34;}&#xA;    ]&#xA;  }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ‰ Boom! You&#39;re done!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Your AI gateway is now running with a beautiful web interface. You can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ–¥ï¸ Configure everything visually&lt;/strong&gt; - No more JSON files!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ“Š Monitor requests in real-time&lt;/strong&gt; - See logs, analytics, and metrics&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ”„ Add providers and MCP clients on-the-fly&lt;/strong&gt; - Scale and failover without restarts&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸš€ Drop into existing code&lt;/strong&gt; - Zero changes to your OpenAI/Anthropic apps&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Want more?&lt;/strong&gt; See our &lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/quickstart/http-transport.md&#34;&gt;Complete Setup Guide&lt;/a&gt; for multi-provider configuration, failover strategies, and production deployment.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;ğŸ“‘ Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#bifrost&#34;&gt;Bifrost&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-quickstart-30-seconds&#34;&gt;âš¡ Quickstart (30 seconds)&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#using-bifrost-http-transport&#34;&gt;Using Bifrost HTTP Transport&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-table-of-contents&#34;&gt;ğŸ“‘ Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-features&#34;&gt;âœ¨ Features&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#%EF%B8%8F-repository-structure&#34;&gt;ğŸ—ï¸ Repository Structure&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-getting-started&#34;&gt;ğŸš€ Getting Started&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#1-as-a-go-package-core-integration&#34;&gt;1. As a Go Package (Core Integration)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#2-as-an-http-api-transport-layer&#34;&gt;2. As an HTTP API (Transport Layer)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#3-as-a-drop-in-replacement-zero-code-changes&#34;&gt;3. As a Drop-in Replacement (Zero Code Changes)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-performance&#34;&gt;ğŸ“Š Performance&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-key-performance-highlights&#34;&gt;ğŸ”‘ Key Performance Highlights&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-documentation&#34;&gt;ğŸ“š Documentation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-need-help&#34;&gt;ğŸ’¬ Need Help?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#%EF%B8%8F-development--build-requirements&#34;&gt;ğŸ› ï¸ Development &amp;amp; Build Requirements&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#cross-platform-compilation-with-cgo&#34;&gt;Cross-Platform Compilation with CGO&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#required-homebrew-packages&#34;&gt;Required Homebrew Packages&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#supported-target-platforms&#34;&gt;Supported Target Platforms&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#compiler-details&#34;&gt;Compiler Details&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#building-from-source&#34;&gt;Building from Source&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#prerequisites-for-building&#34;&gt;Prerequisites for Building&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-contributing&#34;&gt;ğŸ¤ Contributing&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/#-license&#34;&gt;ğŸ“„ License&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;âœ¨ Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ–¥ï¸ Built-in Web UI&lt;/strong&gt;: Visual configuration, real-time monitoring, and analytics dashboard - no config files needed&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸš€ Zero-Config Startup &amp;amp; Easy Integration&lt;/strong&gt;: Start immediately with dynamic provider configuration, or integrate existing SDKs by simply updating the &lt;code&gt;base_url&lt;/code&gt; - one line of code to get running&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ”„ Multi-Provider Support&lt;/strong&gt;: Integrate with OpenAI, Anthropic, Amazon Bedrock, Mistral, Ollama, and more through a single API&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ›¡ï¸ Fallback Mechanisms&lt;/strong&gt;: Automatically retry failed requests with alternative models or providers&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ”‘ Dynamic Key Management&lt;/strong&gt;: Rotate and manage API keys efficiently with weighted distribution&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;âš¡ Connection Pooling&lt;/strong&gt;: Optimize network resources for better performance&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ¯ Concurrency Control&lt;/strong&gt;: Manage rate limits and parallel requests effectively&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ”Œ Flexible Transports&lt;/strong&gt;: Multiple transports for easy integration into your infra&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ—ï¸ Plugin First Architecture&lt;/strong&gt;: No callback hell, simple addition/creation of custom plugins&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ› ï¸ MCP Integration&lt;/strong&gt;: Built-in Model Context Protocol (MCP) support for external tool integration and execution&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;âš™ï¸ Custom Configuration&lt;/strong&gt;: Offers granular control over pool sizes, network retry settings, fallback providers, and network proxy configurations&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ“Š Built-in Observability&lt;/strong&gt;: Native Prometheus metrics out of the box, no wrappers, no sidecars, just drop it in and scrape&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ”§ SDK Support&lt;/strong&gt;: Bifrost is available as a Go package, so you can use it directly in your own applications&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ğŸ—ï¸ Repository Structure&lt;/h2&gt; &#xA;&lt;p&gt;Bifrost is built with a modular architecture:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;bifrost/&#xA;â”œâ”€â”€ ci/                   # CI/CD pipeline scripts and npx configuration&#xA;â”‚&#xA;â”œâ”€â”€ core/                 # Core functionality and shared components&#xA;â”‚   â”œâ”€â”€ providers/        # Provider-specific implementations&#xA;â”‚   â”œâ”€â”€ schemas/          # Interfaces and structs used in bifrost&#xA;â”‚   â”œâ”€â”€ bifrost.go        # Main Bifrost implementation&#xA;â”‚&#xA;â”œâ”€â”€ docs/                 # Documentations for Bifrost&#39;s configurations and contribution guides&#xA;â”‚   â””â”€â”€ ...&#xA;â”‚&#xA;â”œâ”€â”€ tests/                # All test setups related to /core and /transports&#xA;â”‚   â””â”€â”€ ...&#xA;â”‚&#xA;â”œâ”€â”€ transports/           # Interface layers (HTTP, gRPC, etc.)&#xA;â”‚   â”œâ”€â”€ bifrost-http/     # HTTP transport implementation&#xA;â”‚   â””â”€â”€ ...&#xA;â”‚&#xA;â”œâ”€â”€ ui/                  # UI files for the web interface of the HTTP transport&#xA;â”‚   â””â”€â”€ ...&#xA;â”‚&#xA;â””â”€â”€ plugins/              # Plugin Implementations&#xA;    â”œâ”€â”€ maxim/&#xA;    â””â”€â”€ ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The system uses a provider-agnostic approach with well-defined interfaces to easily extend to new AI providers. All interfaces are defined in &lt;code&gt;core/schemas/&lt;/code&gt; and can be used as a reference for contributions.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ğŸš€ Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;There are three ways to use Bifrost - choose the one that fits your needs:&lt;/p&gt; &#xA;&lt;h3&gt;1. As a Go Package (Core Integration)&lt;/h3&gt; &#xA;&lt;p&gt;For direct integration into your Go applications. Provides maximum performance and control.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;ğŸ“– &lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/quickstart/go-package.md&#34;&gt;2-Minute Go Package Setup&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Quick example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go get github.com/maximhq/bifrost/core&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. As an HTTP API (Transport Layer)&lt;/h3&gt; &#xA;&lt;p&gt;For language-agnostic integration and microservices architecture.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;ğŸ“– &lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/quickstart/http-transport.md&#34;&gt;30-Second HTTP Transport Setup&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Quick example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npx @maximhq/bifrost&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. As a Drop-in Replacement (Zero Code Changes)&lt;/h3&gt; &#xA;&lt;p&gt;Replace existing OpenAI/Anthropic APIs without changing your application code.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;ğŸ“– &lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/http-transport/integrations/README.md&#34;&gt;1-Minute Drop-in Integration&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Quick example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;- base_url = &#34;https://api.openai.com&#34;&#xA;+ base_url = &#34;http://localhost:8080/openai&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ğŸ“Š Performance&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bifrost adds virtually zero overhead to your AI requests.&lt;/strong&gt; In our sustained 5,000 RPS benchmark (see full methodology in &lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/benchmarks.md&#34;&gt;docs/benchmarks.md&lt;/a&gt;), the gateway added only &lt;strong&gt;11 Âµs&lt;/strong&gt; of overhead per request â€“ that&#39;s &lt;strong&gt;less than 0.001%&lt;/strong&gt; of a typical GPT-4o response time.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Translation:&lt;/strong&gt; Your users won&#39;t notice Bifrost is there, but you&#39;ll sleep better knowing your AI never goes down.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Metric&lt;/th&gt; &#xA;   &lt;th&gt;t3.medium&lt;/th&gt; &#xA;   &lt;th&gt;t3.xlarge&lt;/th&gt; &#xA;   &lt;th&gt;Î”&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Added latency (Bifrost overhead)&lt;/td&gt; &#xA;   &lt;td&gt;59 Âµs&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;11 Âµs&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;-81 %&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Success rate @ 5 k RPS&lt;/td&gt; &#xA;   &lt;td&gt;100 %&lt;/td&gt; &#xA;   &lt;td&gt;100 %&lt;/td&gt; &#xA;   &lt;td&gt;No failed requests&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Avg. queue wait time&lt;/td&gt; &#xA;   &lt;td&gt;47 Âµs&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;1.67 Âµs&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;-96 %&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Avg. request latency (incl. provider)&lt;/td&gt; &#xA;   &lt;td&gt;2.12 s&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;1.61 s&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;-24 %&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;ğŸ”‘ Key Performance Highlights&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Perfect Success Rate&lt;/strong&gt; â€“ 100 % request success rate on both instance types even at 5 k RPS.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tiny Total Overhead&lt;/strong&gt; â€“ &amp;lt; 15 Âµs additional latency per request on average.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Efficient Queue Management&lt;/strong&gt; â€“ just &lt;strong&gt;1.67 Âµs&lt;/strong&gt; average wait time on the t3.xlarge test.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fast Key Selection&lt;/strong&gt; â€“ ~&lt;strong&gt;10 ns&lt;/strong&gt; to pick the right weighted API key.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Bifrost is deliberately configurable so you can dial the &lt;strong&gt;speed â†” memory&lt;/strong&gt; trade-off:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Config Knob&lt;/th&gt; &#xA;   &lt;th&gt;Effect&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;initial_pool_size&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;How many objects are pre-allocated. Higher = faster, more memory&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;buffer_size&lt;/code&gt; &amp;amp; &lt;code&gt;concurrency&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Queue depth and max parallel workers (can be set per provider)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Retry / Timeout&lt;/td&gt; &#xA;   &lt;td&gt;Tune aggressiveness for each provider to meet your SLOs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Choose higher settings (like the t3.xlarge profile above) for raw speed, or lower ones (t3.medium) for reduced memory footprint â€“ or find the sweet spot for your workload.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Need more numbers?&lt;/strong&gt; Dive into the &lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/benchmarks.md&#34;&gt;full benchmark report&lt;/a&gt; for breakdowns of every internal stage (JSON marshalling, HTTP call, parsing, etc.), hardware sizing guides and tuning tips.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Everything you need to master Bifrost, from 30-second setup to production-scale deployments.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;ğŸš€ I want to get started (2 minutes)&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/README.md&#34;&gt;ğŸ“– Documentation Hub&lt;/a&gt;&lt;/strong&gt; - Your complete roadmap to Bifrost&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/quickstart/go-package.md&#34;&gt;ğŸ”§ Go Package Setup&lt;/a&gt;&lt;/strong&gt; - Direct integration into your Go app&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/quickstart/http-transport.md&#34;&gt;ğŸŒ HTTP API Setup&lt;/a&gt;&lt;/strong&gt; - Language-agnostic service deployment&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/http-transport/integrations/README.md&#34;&gt;ğŸ”„ Drop-in Replacement&lt;/a&gt;&lt;/strong&gt; - Replace OpenAI/Anthropic with zero code changes&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;ğŸ¯ I want to understand what Bifrost can do&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/providers.md&#34;&gt;ğŸ”— Multi-Provider Support&lt;/a&gt;&lt;/strong&gt; - Connect to 10+ AI providers with one API&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/providers.md#fallback-mechanisms&#34;&gt;ğŸ›¡ï¸ Fallback &amp;amp; Reliability&lt;/a&gt;&lt;/strong&gt; - Never lose a request with automatic failover&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/http-transport/configuration/mcp.md&#34;&gt;ğŸ› ï¸ MCP Tool Integration&lt;/a&gt;&lt;/strong&gt; - Give your AI external capabilities&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/http-transport/configuration/plugins.md&#34;&gt;ğŸ”Œ Plugin Ecosystem&lt;/a&gt;&lt;/strong&gt; - Extend Bifrost with custom middleware&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/key-management.md&#34;&gt;ğŸ”‘ Key Management&lt;/a&gt;&lt;/strong&gt; - Rotate API keys without downtime&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/networking.md&#34;&gt;ğŸ“¡ Networking&lt;/a&gt;&lt;/strong&gt; - Proxies, timeouts, and connection tuning&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;âš™ï¸ I want to deploy this to production&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/architecture/README.md&#34;&gt;ğŸ—ï¸ System Architecture&lt;/a&gt;&lt;/strong&gt; - Understand how Bifrost works internally&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/benchmarks.md&#34;&gt;ğŸ“Š Performance Tuning&lt;/a&gt;&lt;/strong&gt; - Squeeze out every microsecond&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/http-transport/README.md&#34;&gt;ğŸš€ Production Deployment&lt;/a&gt;&lt;/strong&gt; - Scale to millions of requests&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/README.md&#34;&gt;ğŸ”§ Complete API Reference&lt;/a&gt;&lt;/strong&gt; - Every endpoint, parameter, and response&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/errors.md&#34;&gt;ğŸ› Error Handling&lt;/a&gt;&lt;/strong&gt; - Troubleshoot like a pro&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;ğŸ“± I&#39;m migrating from another tool&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/http-transport/integrations/migration-guide.md&#34;&gt;ğŸ”„ Migration Guides&lt;/a&gt;&lt;/strong&gt; - Step-by-step migration from OpenAI, Anthropic, LiteLLM&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/examples/&#34;&gt;ğŸ“ Real-World Examples&lt;/a&gt;&lt;/strong&gt; - Production-ready code samples&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/usage/errors.md&#34;&gt;â“ Common Questions&lt;/a&gt;&lt;/strong&gt; - Solutions to frequent issues&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ğŸ’¬ Need Help?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ”— &lt;a href=&#34;https://getmax.im/bifrost-discord&#34;&gt;Join our Discord&lt;/a&gt;&lt;/strong&gt; for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;â“ Quick setup assistance and troubleshooting&lt;/li&gt; &#xA; &lt;li&gt;ğŸ’¡ Best practices and configuration tips&lt;/li&gt; &#xA; &lt;li&gt;ğŸ¤ Community discussions and support&lt;/li&gt; &#xA; &lt;li&gt;ğŸš€ Real-time help with integrations&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ğŸ› ï¸ Development &amp;amp; Build Requirements&lt;/h2&gt; &#xA;&lt;h3&gt;Cross-Platform Compilation with CGO&lt;/h3&gt; &#xA;&lt;p&gt;Bifrost uses CGO for cross-platform compilation to ensure optimal performance across different architectures. To build Bifrost from source for all supported platforms, you&#39;ll need to install the following cross-compilation toolchains via Homebrew:&lt;/p&gt; &#xA;&lt;h4&gt;Required Homebrew Packages&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Install minimal cross-compilation toolchains for all target platforms&#xA;brew install FiloSottile/musl-cross/musl-cross mingw-w64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Supported Target Platforms&lt;/h4&gt; &#xA;&lt;p&gt;The build system supports the following platform/architecture combinations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;darwin/amd64&lt;/code&gt;, &lt;code&gt;darwin/arm64&lt;/code&gt; (native compilation)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: &lt;code&gt;linux/amd64&lt;/code&gt;, &lt;code&gt;linux/arm64&lt;/code&gt; (via musl-cross)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: &lt;code&gt;windows/amd64&lt;/code&gt; (via mingw-w64)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Compiler Details&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Platform&lt;/th&gt; &#xA;   &lt;th&gt;Architecture&lt;/th&gt; &#xA;   &lt;th&gt;C Compiler&lt;/th&gt; &#xA;   &lt;th&gt;C++ Compiler&lt;/th&gt; &#xA;   &lt;th&gt;Package Source&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Linux&lt;/td&gt; &#xA;   &lt;td&gt;amd64&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;x86_64-linux-musl-gcc&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;x86_64-linux-musl-g++&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;musl-cross&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Linux&lt;/td&gt; &#xA;   &lt;td&gt;arm64&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;aarch64-linux-musl-gcc&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;aarch64-linux-musl-g++&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;musl-cross&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Windows&lt;/td&gt; &#xA;   &lt;td&gt;amd64&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;x86_64-w64-mingw32-gcc&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;x86_64-w64-mingw32-g++&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;mingw-w64&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;macOS&lt;/td&gt; &#xA;   &lt;td&gt;amd64/arm64&lt;/td&gt; &#xA;   &lt;td&gt;Native system compiler&lt;/td&gt; &#xA;   &lt;td&gt;Native system compiler&lt;/td&gt; &#xA;   &lt;td&gt;Xcode Command Line Tools&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Building from Source&lt;/h4&gt; &#xA;&lt;p&gt;Once you have the required toolchains installed, you can build Bifrost using the provided build script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Build for all platforms&#xA;./ci/scripts/go-executable-build.sh bifrost-http ./dist/apps/bifrost &#34;&#34; ./transports/bifrost-http&#xA;&#xA;# The script will automatically detect and use the appropriate cross-compilers&#xA;# for each target platform&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The build script includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Static linking&lt;/strong&gt; for Linux builds (using musl libc for maximum compatibility)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CGO support&lt;/strong&gt; for all platforms to ensure optimal performance&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Automatic compiler detection&lt;/strong&gt; and validation before building&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Prerequisites for Building&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Go 1.21+&lt;/strong&gt; - Required for building the application&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cross-compilation toolchains&lt;/strong&gt; - Install via the Homebrew packages above&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Git&lt;/strong&gt; - For cloning and version management&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The build process uses fully static linking for Linux builds to ensure maximum compatibility across different distributions. Windows builds use mingw-w64 for cross-compilation from macOS/Linux environments.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; &#xA;&lt;p&gt;See our &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/docs/contributing/README.md&#34;&gt;Contributing Guide&lt;/a&gt;&lt;/strong&gt; for detailed information on how to contribute to Bifrost. We welcome contributions of all kindsâ€”whether it&#39;s bug fixes, features, documentation improvements, or new ideas. Feel free to open an issue, and once it&#39;s assigned, submit a Pull Request.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href=&#34;https://raw.githubusercontent.com/maximhq/bifrost/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; &#xA;&lt;p&gt;Built with â¤ï¸ by &lt;a href=&#34;https://github.com/maximhq&#34;&gt;Maxim&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>