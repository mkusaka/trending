<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-01T01:38:23Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>imusmanmalik/randomizer</title>
    <updated>2023-05-01T01:38:23Z</updated>
    <id>tag:github.com,2023-05-01:/imusmanmalik/randomizer</id>
    <link href="https://github.com/imusmanmalik/randomizer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GoLang library for generating cryptographically secure random numbers using the crypto/rand package&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;randomizer&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://coveralls.io/github/imusmanmalik/randomizer?branch=main&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/imusmanmalik/randomizer/badge.svg?branch=main&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/imusmanmalik/randomizer/actions/workflows/build.yaml&#34;&gt;&lt;img src=&#34;https://github.com/imusmanmalik/randomizer/actions/workflows/build.yaml/badge.svg?sanitize=true&#34; alt=&#34;CI Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/imusmanmalik/randomizer/actions/workflows/test.yaml&#34;&gt;&lt;img src=&#34;https://github.com/imusmanmalik/randomizer/actions/workflows/test.yaml/badge.svg?sanitize=true&#34; alt=&#34;CI Test&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/imusmanmalik/randomizer/actions/workflows/scan.yaml&#34;&gt;&lt;img src=&#34;https://github.com/imusmanmalik/randomizer/actions/workflows/scan.yaml/badge.svg?sanitize=true&#34; alt=&#34;CI Scan&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/imusmanmalik/randomizer/actions/workflows/release.yaml&#34;&gt;&lt;img src=&#34;https://github.com/imusmanmalik/randomizer/actions/workflows/release.yaml/badge.svg?sanitize=true&#34; alt=&#34;CI Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pkg.go.dev/github.com/imusmanmalik/randomizer&#34;&gt;&lt;img src=&#34;https://pkg.go.dev/badge/github.com/imusmanmalik/randomizer.svg?sanitize=true&#34; alt=&#34;Go Reference&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a GoLang library for generating cryptographically secure random numbers using the crypto/rand package. The library provides a simple API for generating random integers, bytes, and strings.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To install the library, use the go get command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;go get github.com/imusmanmalik/randomizer&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;To use the library, import it in your Go code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (&#xA;    &#34;fmt&#34;&#xA;    &#34;github.com/imusmanmalik/randomizer&#34;&#xA;)&#xA;&#xA;func main() {&#xA;    // Generate a random integer between 0 and 100&#xA;    n := yourpackage.RandomInt(100)&#xA;    fmt.Println(n)&#xA;&#xA;    // Generate a random byte slice with 16 bytes&#xA;    b := yourpackage.RandomBytes(16)&#xA;    fmt.Printf(&#34;%x\n&#34;, b)&#xA;&#xA;    // Generate a random string with 10 characters&#xA;    s := yourpackage.RandomString(10)&#xA;    fmt.Println(s)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Testing&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;go test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome! If you find a bug or have an idea for a new feature, please open an issue or submit a pull request on GitHub.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This library is licensed under Apache 2.0 License. See the &lt;a href=&#34;https://github.com/imusmanmalik/randomizer/raw/main/LICENSE&#34;&gt;LICENSE file&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;This library was inspired by the math/rand package in the Go standard library, and the github.com/Pallinder/go-randomdata library.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jo-m/trainbot</title>
    <updated>2023-05-01T01:38:23Z</updated>
    <id>tag:github.com,2023-05-01:/jo-m/trainbot</id>
    <link href="https://github.com/jo-m/trainbot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Trainbot watches a piece of train track, detects trains, and stitches together images of them. Computer vision exercise in Go.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Trainbot&lt;/h1&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/frontend/src/assets/logo-day.svg?sanitize=true&#34; height=&#34;100&#34; width=&#34;100&#34;&gt; &#xA;&lt;p&gt;Trainbot watches a piece of train track, detects passing trains, and stitches together images of them. Should work with any video4linux USB cam, or Raspberry Pi camera v3 modules.&lt;/p&gt; &#xA;&lt;p&gt;Frontend: &lt;a href=&#34;https://trains.jo-m.ch/&#34;&gt;https://trains.jo-m.ch/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/internal/pkg/stitch/testdata/set0/day.jpg&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/internal/pkg/stitch/testdata/set0/day.jpg&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/internal/pkg/stitch/testdata/set0/night.jpg&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/internal/pkg/stitch/testdata/set0/night.jpg&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/internal/pkg/stitch/testdata/set0/rain.jpg&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/internal/pkg/stitch/testdata/set0/rain.jpg&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/internal/pkg/stitch/testdata/set0/snow.jpg&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/internal/pkg/stitch/testdata/set0/snow.jpg&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/demo.gif&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/demo.gif&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;It also contains some packages which might be useful for other purposes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/pkg/pmatch&#34;&gt;pkg/pmatch&lt;/a&gt;: Image patch matching&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jo-m/trainbot/master/pkg/ransac&#34;&gt;pkg/ransac&lt;/a&gt;: RANSAC algorithm implementation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The binaries are currently built and tested on X86_64 and a Raspberry Pi 4 B.&lt;/p&gt; &#xA;&lt;h2&gt;Assumptions and notes on computer vision&lt;/h2&gt; &#xA;&lt;p&gt;The computer vision used in trainbot is fairly naive and simple. There is no camera calibration, image stabilization, undistortion, perspective mapping, or &#34;real&#34; object tracking. This allows us to stay away from complex dependencies like OpenCV, and keeps the computational requirements low. All processing happens on CPU.&lt;/p&gt; &#xA;&lt;p&gt;The assumptions are (there might be more implicit ones):&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Trains only appear in a (manually) pre-cropped region.&lt;/li&gt; &#xA; &lt;li&gt;The camera is stable and the image does not move around in any direction.&lt;/li&gt; &#xA; &lt;li&gt;There are no large fast brightness changes.&lt;/li&gt; &#xA; &lt;li&gt;Trains have a given min and max speed.&lt;/li&gt; &#xA; &lt;li&gt;We are looking at the tracks more or less perpendicularly in the chosen image crop region.&lt;/li&gt; &#xA; &lt;li&gt;Trains are coming from one direction at a time, crossings are not handled properly.&lt;/li&gt; &#xA; &lt;li&gt;Trains have a constant acceleration (might be 0) and do not stop and turn around while in front of the camera.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Build system&lt;/h2&gt; &#xA;&lt;p&gt;There is a helper &lt;code&gt;Makefile&lt;/code&gt; which calls the standard Go build tools and an arm64 cross build inside Docker.&lt;/p&gt; &#xA;&lt;h2&gt;V4L Settings&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# list&#xA;ffmpeg -f v4l2 -list_formats all -i /dev/video2&#xA;v4l2-ctl --all --device /dev/video2&#xA;&#xA;# exposure&#xA;v4l2-ctl -c exposure_auto=3 --device /dev/video2&#xA;&#xA;# autofocus&#xA;v4l2-ctl -c focus_auto=1 --device /dev/video2&#xA;&#xA;# fixed&#xA;v4l2-ctl -c focus_auto=0 --device /dev/video2&#xA;v4l2-ctl -c focus_absolute=0 --device /dev/video2&#xA;v4l2-ctl -c focus_absolute=1023 --device /dev/video2&#xA;&#xA;ffplay -f video4linux2 -framerate 30 -video_size 3264x2448 -pixel_format mjpeg /dev/video2&#xA;ffplay -f video4linux2 -framerate 30 -video_size 1920x1080 -pixel_format mjpeg /dev/video2&#xA;&#xA;ffmpeg -f v4l2 -framerate 30 -video_size 3264x2448 -pixel_format mjpeg -i /dev/video2 output.avi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;RasPi Cam v3 utils&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# setup&#xA;sudo apt-get install libcamera0 libcamera-apps-lite&#xA;sudo apt install -y vlc&#xA;&#xA;# grab frame&#xA;# https://www.raspberrypi.com/documentation/computers/camera_software.html#libcamera-and-libcamera-apps&#xA;libcamera-jpeg -o out.jpg -t 1 --width 4608 --height 2592 --rotation 180 --autofocus-mode=manual --lens-position=2&#xA;libcamera-jpeg -o out.jpg -t 1 --width 2304 --height 1296 --rotation 180 --autofocus-mode=manual --lens-position=4.5 --roi 0.25,0.5,0.5,0.5&#xA;&#xA;# record video&#xA;DATE=$(date +&#39;%F_%H-%M-%S&#39;); libcamera-vid -o $DATE.h264 --save-pts $DATE.txt --width 1080 --height 720 --rotation 180 --autofocus-mode=manual --lens-position=0 -t 0&#xA;&#xA;# stream through network&#xA;libcamera-vid -t 0 --inline --nopreview --width 4608 --height 2592 --rotation 180 --codec mjpeg --framerate 5 --listen -o tcp://0.0.0.0:8080 --autofocus-mode=manual --lens-position=0 --roi 0.25,0.5,0.5,0.5&#xA;# on localhost&#xA;ffplay http://pi4:8080/video.mjpeg&#xA;&#xA;# manually record video for test cases&#xA;libcamera-vid \&#xA;   --verbose=1 \&#xA;   --timeout=0 \&#xA;   --inline \&#xA;   --nopreview \&#xA;   --width 350 --height 280 \&#xA;   --roi 0.368924,0.532407,0.151910,0.216049 \&#xA;   --mode=2304:1296:12:P \&#xA;   --framerate 30 \&#xA;   --autofocus-mode=manual --lens-position=0.000000 \&#xA;   --rotation=180 \&#xA;   -o vid.h264 --save-pts vid-timestamps.txt&#xA;&#xA;mkvmerge -o test.mkv --timecodes 0:vid-timestamps.txt vid.h264&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;h3&gt;Raspberry Pi&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo usermod -a -G video pi&#xA;&#xA;# confighelper&#xA;./confighelper-arm64 --log-pretty --input=picam3 --listen-addr=0.0.0.0:8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The current production deployment is in a Tmux session...&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source ./env&#xA;&#xA;while true; do \&#xA;./trainbot-arm64 \&#xA;   --log-pretty --log-level=debug \&#xA;   --input picam3 \&#xA;   --camera-format-fourcc=MJPG \&#xA;   -X 850 -Y 690 -W 350 -H 280 \&#xA;   --px-per-m=42 \&#xA;   --enable-upload; \&#xA;done&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Download latest data from Raspberry Pi:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh &#34;$TRAINBOT_DEPLOY_TARGET_SSH_HOST&#34; sqlite3 data/db.sqlite3&#xA;.backup data/db.sqlite3.bak&#xA;# Ctrl+D&#xA;rsync --verbose --archive --rsh=ssh &#34;$TRAINBOT_DEPLOY_TARGET_SSH_HOST:data/&#34; data/&#xA;rm data/db.sqlite3-shm data/db.sqlite3-wal&#xA;mv data/db.sqlite3.bak data/db.sqlite3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Web frontend&lt;/h3&gt; &#xA;&lt;p&gt;Images and database are uploaded to a web server via FTP. The frontend served as a static HTML/JS bundle from the same server. All database access happens in the browser via sql.js.&lt;/p&gt; &#xA;&lt;h2&gt;Code notes&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Zerolog is used as logging framework&lt;/li&gt; &#xA; &lt;li&gt;&#34;Library&#34; code uses &lt;code&gt;panic()&lt;/code&gt;, &#34;application&#34; code use &lt;code&gt;log.Panic()...&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;TODOs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Also create GIFs&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Test in snow/bad weather&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Clean up and document build system&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Calculate length&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Write GIFs again&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Store metadata in db&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Sync pics and db up to bucket&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Static web frontend serving train sightings&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Github button link&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Filter view (longest, fastest, ...)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Fix stale relative timestamps&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Improve train detail view&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Store filter state in URL&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Show &#34;showing X of Y&#34; counter somewhere&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Auto dark mode&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Nicer dark mode colors&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Logo/Favicon&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Delete data after upload&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Clean up frontend db/blob path handling&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add favorites feature&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; (Maybe) Search in multiple horizontal slices for robustness&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Stats&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Correct for changing exposure, improve stitching seams&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add machine learning to classify trains (MobileNet, EfficientNet, &lt;a href=&#34;https://mediapipe-studio.webapps.google.com/demo/image_classifier&#34;&gt;https://mediapipe-studio.webapps.google.com/demo/image_classifier&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Create some screenshots&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Better deployment setup, remove hardcoded stuff, document deployment&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Deploy to Raspberry Pi via &lt;a href=&#34;https://gokrazy.org/&#34;&gt;gokrazy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add run/deploy instructions to README (including confighelper)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>