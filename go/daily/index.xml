<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-14T01:31:05Z</updated>
  <subtitle>Daily Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>philippta/flyscrape</title>
    <updated>2023-11-14T01:31:05Z</updated>
    <id>tag:github.com,2023-11-14:/philippta/flyscrape</id>
    <link href="https://github.com/philippta/flyscrape" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A standalone and scriptable web scraper in Go&lt;/p&gt;&lt;hr&gt;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;.github/assets/logo-alt.png&#34;&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;.github/assets/logo.png&#34;&gt; &#xA;  &lt;img width=&#34;200&#34; src=&#34;https://raw.githubusercontent.com/philippta/flyscrape/master/.github/assets/logo.png&#34;&gt; &#xA; &lt;/picture&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;flyscrape&lt;/b&gt; is a standalone and scriptable web scraper, combining the speed of Go with the flexibility of JavaScript. — Focus on data extraction rather than request juggling. &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/philippta/flyscrape/master/#installation&#34;&gt;Installation&lt;/a&gt; · &lt;a href=&#34;https://flyscrape.com/docs/&#34;&gt;Documentation&lt;/a&gt; · &lt;a href=&#34;https://github.com/philippta/flyscrape/releases&#34;&gt;Releases&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Highly Configurable:&lt;/strong&gt; 10 options to fine-tune your scraper.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Standalone:&lt;/strong&gt; flyscrape comes as a single binary executable.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Scriptable:&lt;/strong&gt; Use JavaScript to write your data extraction logic.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Simple API:&lt;/strong&gt; Extract data from HTML pages with a familiar API.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fast Iteration:&lt;/strong&gt; Use the development mode to get quick feedback.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Request Caching:&lt;/strong&gt; Re-run scripts on websites you already scraped.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Zero Dependencies:&lt;/strong&gt; No need to fill up your disk with npm packages.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Example script&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;export const config = {&#xA;    url: &#34;https://news.ycombinator.com/&#34;,&#xA;}&#xA;&#xA;export default function ({ doc, absoluteURL }) {&#xA;    const title = doc.find(&#34;title&#34;);&#xA;    const posts = doc.find(&#34;.athing&#34;);&#xA;&#xA;    return {&#xA;        title: title.text(),&#xA;        posts: posts.map((post) =&amp;gt; {&#xA;            const link = post.find(&#34;.titleline &amp;gt; a&#34;);&#xA;&#xA;            return {&#xA;                title: link.text(),&#xA;                url: link.attr(&#34;href&#34;),&#xA;            };&#xA;        }),&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ flyscrape run hackernews.js&#xA;[&#xA;  {&#xA;    &#34;url&#34;: &#34;https://news.ycombinator.com/&#34;,&#xA;    &#34;data&#34;: {&#xA;      &#34;title&#34;: &#34;Hacker News&#34;,&#xA;      &#34;posts&#34;: [&#xA;        {&#xA;          &#34;title&#34;: &#34;Show HN: flyscrape - An standalone and scriptable web scraper&#34;,&#xA;          &#34;url&#34;: &#34;https://flyscrape.com/&#34;&#xA;        },&#xA;        ...&#xA;      ]&#xA;    }&#xA;  }&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Check out the &lt;a href=&#34;https://raw.githubusercontent.com/philippta/flyscrape/master/examples&#34;&gt;examples folder&lt;/a&gt; for more detailed examples.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Pre-compiled binary&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;flyscrape&lt;/code&gt; is available for MacOS, Linux and Windows as a downloadable binary from the &lt;a href=&#34;https://github.com/philippta/flyscrape/releases&#34;&gt;releases page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Compile from source&lt;/h3&gt; &#xA;&lt;p&gt;To compile flyscrape from source, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install Go: Make sure you have Go installed on your system. If not, you can download it from &lt;a href=&#34;https://golang.org/&#34;&gt;https://golang.org/&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install flyscrape: Open a terminal and run the following command:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go install github.com/philippta/flyscrape/cmd/flyscrape@latest&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;flyscrape is a standalone and scriptable web scraper for efficiently extracting data from websites.&#xA;&#xA;Usage:&#xA;&#xA;    flyscrape &amp;lt;command&amp;gt; [arguments]&#xA;&#xA;Commands:&#xA;&#xA;    new    creates a sample scraping script&#xA;    run    runs a scraping script&#xA;    dev    watches and re-runs a scraping script&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Below is an example scraping script that showcases the capabilities of flyscrape. For a full documentation of all configuration options, visit the &lt;a href=&#34;https://raw.githubusercontent.com/philippta/flyscrape/master/docs/readme.md#configuration&#34;&gt;documentation page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;export const config = {&#xA;    url: &#34;https://example.com/&#34;, // Specify the URL to start scraping from.&#xA;    depth: 0,                    // Specify how deep links should be followed.  (default = 0, no follow)&#xA;    follow: [],                  // Speficy the css selectors to follow         (default = [&#34;a[href]&#34;])&#xA;    allowedDomains: [],          // Specify the allowed domains. [&#39;*&#39;] for all. (default = domain from url)&#xA;    blockedDomains: [],          // Specify the blocked domains.                (default = none)&#xA;    allowedURLs: [],             // Specify the allowed URLs as regex.          (default = all allowed)&#xA;    blockedURLs: [],             // Specify the blocked URLs as regex.          (default = none)&#xA;    rate: 100,                   // Specify the rate in requests per second.    (default = no rate limit)&#xA;    proxies: [],                 // Specify the HTTP(S) proxy URLs.             (default = no proxy)&#xA;    cache: &#34;file&#34;,               // Enable file-based request caching.          (default = no cache)&#xA;};&#xA;&#xA;export function setup() {&#xA;    // Optional setup function, called once before scraping starts.&#xA;    // Can be used for authentication.&#xA;}&#xA;&#xA;export default function ({ doc, url, absoluteURL }) {&#xA;    // doc              - Contains the parsed HTML document&#xA;    // url              - Contains the scraped URL&#xA;    // absoluteURL(...) - Transforms relative URLs into absolute URLs&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Query API&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// &amp;lt;div class=&#34;element&#34; foo=&#34;bar&#34;&amp;gt;Hey&amp;lt;/div&amp;gt;&#xA;const el = doc.find(&#34;.element&#34;)&#xA;el.text()                                 // &#34;Hey&#34;&#xA;el.html()                                 // `&amp;lt;div class=&#34;element&#34;&amp;gt;Hey&amp;lt;/div&amp;gt;`&#xA;el.attr(&#34;foo&#34;)                            // &#34;bar&#34;&#xA;el.hasAttr(&#34;foo&#34;)                         // true&#xA;el.hasClass(&#34;element&#34;)                    // true&#xA;&#xA;// &amp;lt;ul&amp;gt;&#xA;//   &amp;lt;li class=&#34;a&#34;&amp;gt;Item 1&amp;lt;/li&amp;gt;&#xA;//   &amp;lt;li&amp;gt;Item 2&amp;lt;/li&amp;gt;&#xA;//   &amp;lt;li&amp;gt;Item 3&amp;lt;/li&amp;gt;&#xA;// &amp;lt;/ul&amp;gt;&#xA;const list = doc.find(&#34;ul&#34;)&#xA;list.children()                           // [&amp;lt;li class=&#34;a&#34;&amp;gt;Item 1&amp;lt;/li&amp;gt;, &amp;lt;li&amp;gt;Item 2&amp;lt;/li&amp;gt;, &amp;lt;li&amp;gt;Item 3&amp;lt;/li&amp;gt;]&#xA;&#xA;const items = list.find(&#34;li&#34;)&#xA;items.length()                            // 3&#xA;items.first()                             // &amp;lt;li&amp;gt;Item 1&amp;lt;/li&amp;gt;&#xA;items.last()                              // &amp;lt;li&amp;gt;Item 3&amp;lt;/li&amp;gt;&#xA;items.get(1)                              // &amp;lt;li&amp;gt;Item 2&amp;lt;/li&amp;gt;&#xA;items.get(1).prev()                       // &amp;lt;li&amp;gt;Item 1&amp;lt;/li&amp;gt;&#xA;items.get(1).next()                       // &amp;lt;li&amp;gt;Item 3&amp;lt;/li&amp;gt;&#xA;items.get(1).parent()                     // &amp;lt;ul&amp;gt;...&amp;lt;/ul&amp;gt;&#xA;items.get(1).siblings()                   // [&amp;lt;li class=&#34;a&#34;&amp;gt;Item 1&amp;lt;/li&amp;gt;, &amp;lt;li&amp;gt;Item 2&amp;lt;/li&amp;gt;, &amp;lt;li&amp;gt;Item 3&amp;lt;/li&amp;gt;]&#xA;items.map(item =&amp;gt; item.text())            // [&#34;Item 1&#34;, &#34;Item 2&#34;, &#34;Item 3&#34;]&#xA;items.filter(item =&amp;gt; item.hasClass(&#34;a&#34;))  // [&amp;lt;li class=&#34;a&#34;&amp;gt;Item 1&amp;lt;/li&amp;gt;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Flyscrape API&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import { parse }&amp;nbsp;from &#34;flyscrape&#34;;&#xA;&#xA;const doc = parse(`&amp;lt;div class=&#34;foo&#34;&amp;gt;bar&amp;lt;/div&amp;gt;`);&#xA;const text = doc.find(&#34;.foo&#34;).text();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import http from &#34;flyscrape/http&#34;;&#xA;&#xA;const response = http.get(&#34;https://example.com&#34;)&#xA;&#xA;const response = http.postForm(&#34;https://example.com&#34;, {&#xA;    &#34;username&#34;: &#34;foo&#34;,&#xA;    &#34;password&#34;: &#34;bar&#34;,&#xA;})&#xA;&#xA;const response = http.postJSON(&#34;https://example.com&#34;, {&#xA;    &#34;username&#34;: &#34;foo&#34;,&#xA;    &#34;password&#34;: &#34;bar&#34;,&#xA;})&#xA;&#xA;// Contents of response&#xA;{&#xA;    body: &#34;&amp;lt;html&amp;gt;...&amp;lt;/html&amp;gt;&#34;,&#xA;    status: 200,&#xA;    headers: {&#xA;        &#34;Content-Type&#34;: &#34;text/html&#34;,&#xA;        // ...&#xA;    },&#xA;    error&#34;: &#34;&#34;,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Issues and Suggestions&lt;/h2&gt; &#xA;&lt;p&gt;If you encounter any issues or have suggestions for improvement, please &lt;a href=&#34;https://github.com/philippta/flyscrape/issues&#34;&gt;submit an issue&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>