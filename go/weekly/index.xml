<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-19T01:51:15Z</updated>
  <subtitle>Weekly Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>go-gorm/gorm</title>
    <updated>2023-11-19T01:51:15Z</updated>
    <id>tag:github.com,2023-11-19:/go-gorm/gorm</id>
    <link href="https://github.com/go-gorm/gorm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The fantastic ORM library for Golang, aims to be developer friendly&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GORM&lt;/h1&gt; &#xA;&lt;p&gt;The fantastic ORM library for Golang, aims to be developer friendly.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://goreportcard.com/report/github.com/go-gorm/gorm&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/go-gorm/gorm&#34; alt=&#34;go report card&#34; title=&#34;go report card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/go-gorm/gorm/actions&#34;&gt;&lt;img src=&#34;https://github.com/go-gorm/gorm/workflows/tests/badge.svg?branch=master&#34; alt=&#34;test status&#34; title=&#34;test status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-brightgreen.svg?sanitize=true&#34; alt=&#34;MIT license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pkg.go.dev/gorm.io/gorm?tab=doc&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/go.dev-reference-blue?logo=go&amp;amp;logoColor=white&#34; alt=&#34;Go.Dev reference&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Full-Featured ORM&lt;/li&gt; &#xA; &lt;li&gt;Associations (Has One, Has Many, Belongs To, Many To Many, Polymorphism, Single-table inheritance)&lt;/li&gt; &#xA; &lt;li&gt;Hooks (Before/After Create/Save/Update/Delete/Find)&lt;/li&gt; &#xA; &lt;li&gt;Eager loading with &lt;code&gt;Preload&lt;/code&gt;, &lt;code&gt;Joins&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Transactions, Nested Transactions, Save Point, RollbackTo to Saved Point&lt;/li&gt; &#xA; &lt;li&gt;Context, Prepared Statement Mode, DryRun Mode&lt;/li&gt; &#xA; &lt;li&gt;Batch Insert, FindInBatches, Find To Map&lt;/li&gt; &#xA; &lt;li&gt;SQL Builder, Upsert, Locking, Optimizer/Index/Comment Hints, NamedArg, Search/Update/Create with SQL Expr&lt;/li&gt; &#xA; &lt;li&gt;Composite Primary Key&lt;/li&gt; &#xA; &lt;li&gt;Auto Migrations&lt;/li&gt; &#xA; &lt;li&gt;Logger&lt;/li&gt; &#xA; &lt;li&gt;Extendable, flexible plugin API: Database Resolver (Multiple Databases, Read/Write Splitting) / Prometheus‚Ä¶&lt;/li&gt; &#xA; &lt;li&gt;Every feature comes with tests&lt;/li&gt; &#xA; &lt;li&gt;Developer Friendly&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GORM Guides &lt;a href=&#34;https://gorm.io&#34;&gt;https://gorm.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Gen Guides &lt;a href=&#34;https://gorm.io/gen/index.html&#34;&gt;https://gorm.io/gen/index.html&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gorm.io/contribute.html&#34;&gt;You can help to deliver a better GORM, check out things you can do&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/go-gorm/gorm/graphs/contributors&#34;&gt;Thank you&lt;/a&gt; for contributing to the GORM framework!&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;¬© Jinzhu, 2013~time.Now&lt;/p&gt; &#xA;&lt;p&gt;Released under the &lt;a href=&#34;https://github.com/go-gorm/gorm/raw/master/LICENSE&#34;&gt;MIT License&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>nlpodyssey/waveny</title>
    <updated>2023-11-19T01:51:15Z</updated>
    <id>tag:github.com,2023-11-19:/nlpodyssey/waveny</id>
    <link href="https://github.com/nlpodyssey/waveny" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Emulate guitar amps and pedals with deep learning, in Go.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Waveny&lt;/h1&gt; &#xA;&lt;p&gt;Waveny is a Go library and command-line utility designed for emulating guitar amplifiers and pedals through deep learning.&lt;/p&gt; &#xA;&lt;p&gt;The project takes inspiration from &lt;a href=&#34;https://www.neuralampmodeler.com&#34;&gt;Neural Amp Modeler&lt;/a&gt; (NAM) and has adapted significant components from related repositories into Go:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sdatkinson/neural-amp-modeler&#34;&gt;neural-amp-modeler&lt;/a&gt;: a Python project for model training and WAVE file processing (reamping), leveraging PyTorch and Lightning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sdatkinson/NeuralAmpModelerCore&#34;&gt;NeuralAmpModelerCore&lt;/a&gt;: the core DSP library, written in C++, suited to real-time plugin development.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development Status and Constraints&lt;/h2&gt; &#xA;&lt;p&gt;Waveny is in the early stages of development, and as such, the public APIs and functionalities are subject to change. The current codebase includes placeholders, indicating ongoing development, and minimal documentation.&lt;/p&gt; &#xA;&lt;p&gt;The project ambitiously applies digital signal processing in Go. The &lt;code&gt;live&lt;/code&gt; command aims to offer decent real-time processing on modern CPUs, but optimization is ongoing.&lt;/p&gt; &#xA;&lt;p&gt;Key technical constraints include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sole support for the WaveNet model.&lt;/li&gt; &#xA; &lt;li&gt;Support limited to a 48kHz sample rate.&lt;/li&gt; &#xA; &lt;li&gt;Requirement for WAVE files to be PCM 48kHz 24-bit mono, for training or reamping.&lt;/li&gt; &#xA; &lt;li&gt;Training on CPU only.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Future updates will address these limitations.&lt;/p&gt; &#xA;&lt;h2&gt;Utilization Guide&lt;/h2&gt; &#xA;&lt;h3&gt;Command Line Interface&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;waveny&lt;/code&gt; command-line interface offers several commands to interact with the deep learning models for guitar amp emulation.&lt;/p&gt; &#xA;&lt;p&gt;Build it with &lt;code&gt;go build ./cmd/waveny&lt;/code&gt;, or compile-and-run it with &lt;code&gt;go run ./cmd/waveny&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The single executable allows to run different sub-commands, in this form:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;waveny COMMAND [arguments...]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run &lt;code&gt;waveny help&lt;/code&gt; to see a list of available commands. Here is a recap:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;train&lt;/code&gt;: train a new WaveNet model using SpaGO, producing both SpaGO and &lt;code&gt;.nam&lt;/code&gt; models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;process-spago&lt;/code&gt;: process a WAVE file using a pre-trained WaveNet SpaGO model, loaded from a file in &#34;native&#34; format.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;process-rt&lt;/code&gt;: process a WAVE file using the custom Waveny real-time-capable WaveNet model, loaded from a &lt;code&gt;.nam&lt;/code&gt; model-data file.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;process-torch&lt;/code&gt;: process a WAVE file using a WaveNet SpaGO model, loaded and converted from a pre-trained NAM PyTorch/Lightning checkpoint file.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;live&lt;/code&gt;: process audio input in real-time using the custom Waveny WaveNet model, loaded from a &lt;code&gt;.nam&lt;/code&gt; model-data file. It uses PortAudio for I/O.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For detailed usage and arguments of each command, execute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;waveny COMMAND -h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The following sections illustrate several use cases.&lt;/p&gt; &#xA;&lt;h4&gt;Training&lt;/h4&gt; &#xA;&lt;p&gt;To train a new WaveNet model from scratch, we first need to prepare some files.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A clean/unprocessed audio file (WAVE PCM 48kHz 24-bit mono). You are free to create or record your own. However, &lt;a href=&#34;https://github.com/sdatkinson/neural-amp-modeler&#34;&gt;neural-amp-modeler&lt;/a&gt; Python project comes with a set of standardized files: see &lt;a href=&#34;https://github.com/sdatkinson/neural-amp-modeler/raw/v0.7.3/README.md#standardized-reamping-files&#34;&gt;this section&lt;/a&gt; from the README. We recommend to use v3.0.0.&lt;/li&gt; &#xA; &lt;li&gt;A &#34;reamped&#34; target audio file (same format as above), that is, the audio signal from the previous file processed through the real amp or pedal that you want to emulate.&lt;/li&gt; &#xA; &lt;li&gt;A JSON configuration that describes structure and shapes of the WaveNet model. A good starting point is this &lt;a href=&#34;https://github.com/sdatkinson/neural-amp-modeler/raw/v0.7.3/bin/train/inputs/models/wavenet.json&#34;&gt;wavenet.json&lt;/a&gt; file from NAM Python project.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Clean and reamped files must have the same size and be perfectly aligned. Their coupled audio content will be split into a training set and a validation set: the splitting points can be specified with dedicated command line arguments. If you are using NAM standardized reamping file &lt;a href=&#34;https://drive.google.com/file/d/1Pgf8PdE0rKB1TD4TRPKbpNo1ByR3IOm9/view?usp=drive_link&#34;&gt;v3_0_0.wav&lt;/a&gt;, then the default values are already a good fit.&lt;/p&gt; &#xA;&lt;p&gt;Please have a look at the output of &lt;code&gt;waveny train -h&lt;/code&gt; to learn about additional arguments.&lt;/p&gt; &#xA;&lt;p&gt;Here is a minimal example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;waveny train \&#xA;  -config path/to/wavenet.json \&#xA;  -input path/to/v3_0_0.wav \&#xA;  -target path/to/v3_0_0_reamped.wav \&#xA;  -out path/to/output-folder/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A new sub-folder, named with the current date and time, is created under the specified output directory. Here, at the end of each training epoch, two checkpoint files are created: a SpaGo binary model file, with extension &lt;code&gt;.spago&lt;/code&gt;, and an equivalent &lt;code&gt;.nam&lt;/code&gt; data-model file. The latter is a JSON file in the so-called &#34;exported&#34; NAM format, compatible with Neural Amp Modeler projects and plugins.&lt;/p&gt; &#xA;&lt;p&gt;Loss values are shown for each epoch, and they also become part of the checkpoint file names, for convenience.&lt;/p&gt; &#xA;&lt;p&gt;You can stop the training manually at any moment with Ctrl+C.&lt;/p&gt; &#xA;&lt;p&gt;When you are satisfied with the accuracy, pick the best pair of model files from the output folder, and see further steps described below.&lt;/p&gt; &#xA;&lt;h4&gt;Process an audio file with pre-trained models&lt;/h4&gt; &#xA;&lt;h5&gt;Loading a SpaGO model&lt;/h5&gt; &#xA;&lt;p&gt;If you trained your own model as described above, a &lt;code&gt;.spago&lt;/code&gt; checkpoint file is created at the end of each training epoch. You can now use a pre-trained &lt;code&gt;.spago&lt;/code&gt; model to process an audio file.&lt;/p&gt; &#xA;&lt;p&gt;Get or record a &#34;clean&#34; audio file (WAVE PCM 48kHz 24-bit mono), choose your preferred model, and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;waveny process-spago \&#xA;  -input path/to/input.wav \&#xA;  -output path/to/output.wav \&#xA;  -model path/to/model.spago&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command creates the output WAVE file, processing your input with the given amp/pedal emulation model.&lt;/p&gt; &#xA;&lt;h5&gt;Loading a PyTorch model, running with SpaGO&lt;/h5&gt; &#xA;&lt;p&gt;If you trained a WaveNet model with &lt;a href=&#34;https://github.com/sdatkinson/neural-amp-modeler&#34;&gt;neural-amp-modeler&lt;/a&gt; Python project, you can use another command to load a PyTorch/Lightning model/checkpoint file, convert it into a corresponding SpaGO model (on-the-fly, in memory), and process an input file just like we did above. In this case, you also need the accompanying WaveNet JSON model-configuration file. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;waveny process-torch \&#xA;  -input path/to/input.wav \&#xA;  -output path/to/output.wav \&#xA;  -config path/to/config_model.json \&#xA;  -model path/torch_model.ckpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Loading a &lt;code&gt;.nam&lt;/code&gt; model, running with Waveny custom implementation&lt;/h5&gt; &#xA;&lt;p&gt;There is yet another way to process an audio file. This time, we are going to provide a &lt;code&gt;.nam&lt;/code&gt; data-model file. This is NAM &#34;exported&#34; format, most commonly used to share NAM models, and intended to work with existing NAM audio plugins.&lt;/p&gt; &#xA;&lt;p&gt;If you trained your own model as described some sections above, a &lt;code&gt;.nam&lt;/code&gt; checkpoint file is created at the end of each training epoch.&lt;/p&gt; &#xA;&lt;p&gt;Furthermore, an amazing source for pre-trained models in this special format is &lt;a href=&#34;https://tonehunt.org&#34;&gt;ToneHunt&lt;/a&gt; website. Download your desired amp/pedal emulation model, and make sure it uses WaveNet architecture.&lt;/p&gt; &#xA;&lt;p&gt;Once you have a &lt;code&gt;.nam&lt;/code&gt; model file, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;waveny process-rt \&#xA;  -input path/to/input.wav \&#xA;  -output path/to/output.wav \&#xA;  -model path/to/model.nam&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &#34;rt&#34; suffix in the command name indicates that we are using a custom WaveNet DSP processor: this implementation is most suitable for real-time processing, a topic discussed in the next section.&lt;/p&gt; &#xA;&lt;h4&gt;Process audio in real-time&lt;/h4&gt; &#xA;&lt;p&gt;Pre-trained &lt;code&gt;.nam&lt;/code&gt; models can also be used for real-time processing. Plug in your musical instrument, and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;waveny live -model path/to/model.nam&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command uses Waveny custom WaveNet implementation to process audio input in real-time. I/O is possible thanks to &lt;a href=&#34;https://github.com/gordonklaus/portaudio&#34;&gt;PortAudio&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Library Integration&lt;/h3&gt; &#xA;&lt;p&gt;Integrate Waveny as a Go module in your projects with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;go get github.com/nlpodyssey/waveny&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;From now on, we will refer to the root package &lt;code&gt;github.com/nlpodyssey/waveny&lt;/code&gt; as simply &lt;code&gt;waveny&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Currently, the library only implements the WaveNet deep learning network. Under &lt;code&gt;waveny/models&lt;/code&gt; you will find two different model implementations.&lt;/p&gt; &#xA;&lt;p&gt;Package &lt;code&gt;waveny/models/spago/wavenet&lt;/code&gt; implements the model with &lt;a href=&#34;https://github.com/nlpodyssey/spago&#34;&gt;SpaGO&lt;/a&gt; machine learning library.&lt;/p&gt; &#xA;&lt;p&gt;A WaveNet SpaGO model can be trained from scratch - see &lt;code&gt;waveny/models/spago/wavenet/training&lt;/code&gt; subpackage. The training process produces SpaGO model files (&lt;code&gt;.spago&lt;/code&gt;), and equivalent models in NAM &#34;exported&#34; format (&lt;code&gt;.nam&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s also possible to load a PyTorch model file, pre-trained with &lt;a href=&#34;https://github.com/sdatkinson/neural-amp-modeler&#34;&gt;neural-amp-modeler&lt;/a&gt; Python project, and convert it into a SpaGO model - see &lt;code&gt;waveny/models/spago/wavenet/torchconv&lt;/code&gt; subpackage. It uses &lt;a href=&#34;https://github.com/nlpodyssey/gopickle&#34;&gt;GoPickle&lt;/a&gt; library to read torch models without the need to run Python.&lt;/p&gt; &#xA;&lt;p&gt;A pre-trained SpaGO model can be effectively used to process WAVE files (non-real-time reamping). It is less suitable for real-time processing, mostly due to memory allocations and usage of goroutines.&lt;/p&gt; &#xA;&lt;p&gt;For real-time use, we provide another custom implementation of WaveNet, in package &lt;code&gt;waveny/models/realtime/wavenet&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The real-time-capable model can load &lt;code&gt;.nam&lt;/code&gt; files (the ones trained with Waveny, or NAM WaveNet models from sources like &lt;a href=&#34;https://tonehunt.org&#34;&gt;ToneHunt&lt;/a&gt;). This implementation takes advantage of a self-contained package for handling matrices and vectors, implemented in &lt;code&gt;waveny/models/realtime/mat&lt;/code&gt;. Inspired by the original &lt;a href=&#34;https://github.com/sdatkinson/NeuralAmpModelerCore&#34;&gt;NeuralAmpModelerCore&lt;/a&gt; implementation, and the underlying &lt;a href=&#34;https://eigen.tuxfamily.org&#34;&gt;Eigen&lt;/a&gt; library, it allows to minimize the amount of memory allocations, permitting a predictable execution time, suitable for real-time processing.&lt;/p&gt; &#xA;&lt;p&gt;Package &lt;code&gt;waveny/liveplay&lt;/code&gt; implements real-time processing procedures, using &lt;a href=&#34;https://github.com/gordonklaus/portaudio&#34;&gt;PortAudio&lt;/a&gt; go bindings for I/O.&lt;/p&gt; &#xA;&lt;p&gt;Package &lt;code&gt;waveny/wave&lt;/code&gt; provides utilities for reading and writing WAVE files.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kubeshark/kubeshark</title>
    <updated>2023-11-19T01:51:15Z</updated>
    <id>tag:github.com,2023-11-19:/kubeshark/kubeshark</id>
    <link href="https://github.com/kubeshark/kubeshark" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The API traffic analyzer for Kubernetes providing real-time K8s protocol-level visibility, capturing and monitoring all traffic and payloads going in, out and across containers, pods, nodes and clusters. Inspired by Wireshark, purposely built for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/kubeshark/assets/master/svg/kubeshark-logo.svg?sanitize=true&#34; alt=&#34;Kubeshark: Traffic analyzer for Kubernetes.&#34; height=&#34;128px&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/kubeshark/kubeshark/releases/latest&#34;&gt; &lt;img alt=&#34;GitHub Latest Release&#34; src=&#34;https://img.shields.io/github/v/release/kubeshark/kubeshark?logo=GitHub&amp;amp;style=flat-square&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/kubeshark/worker&#34;&gt; &lt;img alt=&#34;Docker pulls&#34; src=&#34;https://img.shields.io/docker/pulls/kubeshark/worker?color=%23099cec&amp;amp;logo=Docker&amp;amp;style=flat-square&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/kubeshark/worker&#34;&gt; &lt;img alt=&#34;Image size&#34; src=&#34;https://img.shields.io/docker/image-size/kubeshark/kubeshark/latest?logo=Docker&amp;amp;style=flat-square&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://discord.gg/WkvRGMUcx7&#34;&gt; &lt;img alt=&#34;Discord&#34; src=&#34;https://img.shields.io/discord/1042559155224973352?logo=Discord&amp;amp;style=flat-square&amp;amp;label=discord&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/kubeshark/shared_invite/zt-1m90td3n7-VHxN_~V5kVp80SfQW3SfpA&#34;&gt; &lt;img alt=&#34;Slack&#34; src=&#34;https://img.shields.io/badge/slack-join_chat-green?logo=Slack&amp;amp;style=flat-square&amp;amp;label=slack&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt; &lt;span&gt;NEW: &lt;/span&gt; &lt;a href=&#34;https://github.com/kubeshark/kubeshark/releases/latest&#34;&gt;v51.0.0&lt;/a&gt; is out, with significantly improved performance and optimized resource utilization. &lt;/b&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Kubeshark&lt;/strong&gt; is an API Traffic Analyzer for &lt;a href=&#34;https://kubernetes.io/&#34;&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/a&gt; providing real-time, protocol-level visibility into Kubernetes‚Äô internal network, capturing and monitoring all traffic and payloads going in, out and across containers, pods, nodes and clusters.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/kubeshark/assets/raw/master/png/kubeshark-ui.png&#34; alt=&#34;Simple UI&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Think &lt;a href=&#34;https://en.wikipedia.org/wiki/Tcpdump&#34;&gt;TCPDump&lt;/a&gt; and &lt;a href=&#34;https://www.wireshark.org/&#34;&gt;Wireshark&lt;/a&gt; re-invented for Kubernetes&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Download &lt;strong&gt;Kubeshark&lt;/strong&gt;&#39;s binary distribution &lt;a href=&#34;https://github.com/kubeshark/kubeshark/releases/latest&#34;&gt;latest release&lt;/a&gt; and run following one of these examples:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubeshark tap&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubeshark tap -n sock-shop &#34;(catalo*|front-end*)&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Running any of the &lt;span&gt;‚òù&lt;/span&gt; above commands will open the &lt;a href=&#34;https://docs.kubeshark.co/en/ui&#34;&gt;Web UI&lt;/a&gt; in your browser which streams the traffic in your Kubernetes cluster in real-time.&lt;/p&gt; &#xA;&lt;h3&gt;Homebrew&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://brew.sh/&#34;&gt;Homebrew&lt;/a&gt; &lt;span&gt;üç∫&lt;/span&gt; users can add Kubeshark formulae with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;brew tap kubeshark/kubeshark&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and install Kubeshark CLI with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;brew install kubeshark&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Building From Source&lt;/h2&gt; &#xA;&lt;p&gt;Clone this repository and run &lt;code&gt;make&lt;/code&gt; command to build it. After the build is complete, the executable can be found at &lt;code&gt;./bin/kubeshark__&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;To learn more, read the &lt;a href=&#34;https://docs.kubeshark.co&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We &lt;span&gt;‚ù§Ô∏è&lt;/span&gt; pull requests! See &lt;a href=&#34;https://raw.githubusercontent.com/kubeshark/kubeshark/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for the contribution guide.&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;This project is for everyone. We ask that our users and contributors take a few minutes to review our &lt;a href=&#34;https://raw.githubusercontent.com/kubeshark/kubeshark/master/CODE_OF_CONDUCT.md&#34;&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>