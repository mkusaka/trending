<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-04T01:51:01Z</updated>
  <subtitle>Weekly Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>opencontainers/runc</title>
    <updated>2024-02-04T01:51:01Z</updated>
    <id>tag:github.com,2024-02-04:/opencontainers/runc</id>
    <link href="https://github.com/opencontainers/runc" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CLI tool for spawning and running containers according to the OCI specification&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;runc&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://goreportcard.com/report/github.com/opencontainers/runc&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/opencontainers/runc&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pkg.go.dev/github.com/opencontainers/runc&#34;&gt;&lt;img src=&#34;https://pkg.go.dev/badge/github.com/opencontainers/runc.svg?sanitize=true&#34; alt=&#34;Go Reference&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://bestpractices.coreinfrastructure.org/projects/588&#34;&gt;&lt;img src=&#34;https://bestpractices.coreinfrastructure.org/projects/588/badge&#34; alt=&#34;CII Best Practices&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/opencontainers/runc/actions?query=workflow%3Avalidate&#34;&gt;&lt;img src=&#34;https://github.com/opencontainers/runc/workflows/validate/badge.svg?sanitize=true&#34; alt=&#34;gha/validate&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/opencontainers/runc/actions?query=workflow%3Aci&#34;&gt;&lt;img src=&#34;https://github.com/opencontainers/runc/workflows/ci/badge.svg?sanitize=true&#34; alt=&#34;gha/ci&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cirrus-ci.com/github/opencontainers/runc&#34;&gt;&lt;img src=&#34;https://api.cirrus-ci.com/github/opencontainers/runc.svg?sanitize=true&#34; alt=&#34;CirrusCI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; is a CLI tool for spawning and running containers on Linux according to the OCI specification.&lt;/p&gt; &#xA;&lt;h2&gt;Releases&lt;/h2&gt; &#xA;&lt;p&gt;You can find official releases of &lt;code&gt;runc&lt;/code&gt; on the &lt;a href=&#34;https://github.com/opencontainers/runc/releases&#34;&gt;release&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;p&gt;All releases are signed by one of the keys listed in the &lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/runc.keyring&#34;&gt;&lt;code&gt;runc.keyring&lt;/code&gt; file in the root of this repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;The reporting process and disclosure communications are outlined &lt;a href=&#34;https://github.com/opencontainers/org/raw/master/SECURITY.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Security Audit&lt;/h3&gt; &#xA;&lt;p&gt;A third party security audit was performed by Cure53, you can see the full report &lt;a href=&#34;https://github.com/opencontainers/runc/raw/master/docs/Security-Audit.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; only supports Linux. It must be built with Go version 1.19 or higher.&lt;/p&gt; &#xA;&lt;p&gt;In order to enable seccomp support you will need to install &lt;code&gt;libseccomp&lt;/code&gt; on your platform.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;e.g. &lt;code&gt;libseccomp-devel&lt;/code&gt; for CentOS, or &lt;code&gt;libseccomp-dev&lt;/code&gt; for Ubuntu&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# create a &#39;github.com/opencontainers&#39; in your GOPATH/src&#xA;cd github.com/opencontainers&#xA;git clone https://github.com/opencontainers/runc&#xA;cd runc&#xA;&#xA;make&#xA;sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use &lt;code&gt;go get&lt;/code&gt; to install to your &lt;code&gt;GOPATH&lt;/code&gt;, assuming that you have a &lt;code&gt;github.com&lt;/code&gt; parent folder already created under &lt;code&gt;src&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go get github.com/opencontainers/runc&#xA;cd $GOPATH/src/github.com/opencontainers/runc&#xA;make&#xA;sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; will be installed to &lt;code&gt;/usr/local/sbin/runc&lt;/code&gt; on your system.&lt;/p&gt; &#xA;&lt;h4&gt;Build Tags&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; supports optional build tags for compiling support of various features, with some of them enabled by default (see &lt;code&gt;BUILDTAGS&lt;/code&gt; in top-level &lt;code&gt;Makefile&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;To change build tags from the default, set the &lt;code&gt;BUILDTAGS&lt;/code&gt; variable for make, e.g. to disable seccomp:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make BUILDTAGS=&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Build Tag&lt;/th&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th&gt;Enabled by Default&lt;/th&gt; &#xA;   &lt;th&gt;Dependencies&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;seccomp&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Syscall filtering using &lt;code&gt;libseccomp&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;yes&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;libseccomp&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;!runc_nodmz&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Reduce memory usage for CVE-2019-5736 protection by using a small C binary, &lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/contrib/cmd/memfd-bind/README.md&#34;&gt;see &lt;code&gt;memfd-bind&lt;/code&gt; for more details&lt;/a&gt;. &lt;code&gt;runc_nodmz&lt;/code&gt; disables this feature and causes runc to use a different protection mechanism which will further increases memory usage temporarily during container startup. This feature can also be disabled at runtime by setting the &lt;code&gt;RUNC_DMZ=legacy&lt;/code&gt; environment variable.&lt;/td&gt; &#xA;   &lt;td&gt;yes&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;runc_dmz_selinux_nocompat&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Disables a SELinux DMZ workaround (new distros should set this). See &lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/libcontainer/dmz/README.md&#34;&gt;dmz README&lt;/a&gt; for details.&lt;/td&gt; &#xA;   &lt;td&gt;no&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The following build tags were used earlier, but are now obsoleted:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;nokmem&lt;/strong&gt; (since runc v1.0.0-rc94 kernel memory settings are ignored)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;apparmor&lt;/strong&gt; (since runc v1.0.0-rc93 the feature is always enabled)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;selinux&lt;/strong&gt; (since runc v1.0.0-rc93 the feature is always enabled)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Running the test suite&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; currently supports running its test suite via Docker. To run the suite just type &lt;code&gt;make test&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are additional make targets for running the tests outside of a container but this is not recommended as the tests are written with the expectation that they can write and remove anywhere.&lt;/p&gt; &#xA;&lt;p&gt;You can run a specific test case by setting the &lt;code&gt;TESTFLAGS&lt;/code&gt; variable.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# make test TESTFLAGS=&#34;-run=SomeTestFunction&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can run a specific integration test by setting the &lt;code&gt;TESTPATH&lt;/code&gt; variable.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# make test TESTPATH=&#34;/checkpoint.bats&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can run a specific rootless integration test by setting the &lt;code&gt;ROOTLESS_TESTPATH&lt;/code&gt; variable.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# make test ROOTLESS_TESTPATH=&#34;/checkpoint.bats&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can run a test using your container engine&#39;s flags by setting &lt;code&gt;CONTAINER_ENGINE_BUILD_FLAGS&lt;/code&gt; and &lt;code&gt;CONTAINER_ENGINE_RUN_FLAGS&lt;/code&gt; variables.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# make test CONTAINER_ENGINE_BUILD_FLAGS=&#34;--build-arg http_proxy=http://yourproxy/&#34; CONTAINER_ENGINE_RUN_FLAGS=&#34;-e http_proxy=http://yourproxy/&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dependencies Management&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; uses &lt;a href=&#34;https://github.com/golang/go/wiki/Modules&#34;&gt;Go Modules&lt;/a&gt; for dependencies management. Please refer to &lt;a href=&#34;https://github.com/golang/go/wiki/Modules&#34;&gt;Go Modules&lt;/a&gt; for how to add or update new dependencies.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Update vendored dependencies&#xA;make vendor&#xA;# Verify all dependencies&#xA;make verify-dependencies&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using runc&lt;/h2&gt; &#xA;&lt;p&gt;Please note that runc is a low level tool not designed with an end user in mind. It is mostly employed by other higher level container software.&lt;/p&gt; &#xA;&lt;p&gt;Therefore, unless there is some specific use case that prevents the use of tools like Docker or Podman, it is not recommended to use runc directly.&lt;/p&gt; &#xA;&lt;p&gt;If you still want to use runc, here&#39;s how.&lt;/p&gt; &#xA;&lt;h3&gt;Creating an OCI Bundle&lt;/h3&gt; &#xA;&lt;p&gt;In order to use runc you must have your container in the format of an OCI bundle. If you have Docker installed you can use its &lt;code&gt;export&lt;/code&gt; method to acquire a root filesystem from an existing Docker container.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# create the top most bundle directory&#xA;mkdir /mycontainer&#xA;cd /mycontainer&#xA;&#xA;# create the rootfs directory&#xA;mkdir rootfs&#xA;&#xA;# export busybox via Docker into the rootfs directory&#xA;docker export $(docker create busybox) | tar -C rootfs -xvf -&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After a root filesystem is populated you just generate a spec in the format of a &lt;code&gt;config.json&lt;/code&gt; file inside your bundle. &lt;code&gt;runc&lt;/code&gt; provides a &lt;code&gt;spec&lt;/code&gt; command to generate a base template spec that you are then able to edit. To find features and documentation for fields in the spec please refer to the &lt;a href=&#34;https://github.com/opencontainers/runtime-spec&#34;&gt;specs&lt;/a&gt; repository.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;runc spec&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running Containers&lt;/h3&gt; &#xA;&lt;p&gt;Assuming you have an OCI bundle from the previous step you can execute the container in two different ways.&lt;/p&gt; &#xA;&lt;p&gt;The first way is to use the convenience command &lt;code&gt;run&lt;/code&gt; that will handle creating, starting, and deleting the container after it exits.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# run as root&#xA;cd /mycontainer&#xA;runc run mycontainerid&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you used the unmodified &lt;code&gt;runc spec&lt;/code&gt; template this should give you a &lt;code&gt;sh&lt;/code&gt; session inside the container.&lt;/p&gt; &#xA;&lt;p&gt;The second way to start a container is using the specs lifecycle operations. This gives you more power over how the container is created and managed while it is running. This will also launch the container in the background so you will have to edit the &lt;code&gt;config.json&lt;/code&gt; to remove the &lt;code&gt;terminal&lt;/code&gt; setting for the simple examples below (see more details about &lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/docs/terminals.md&#34;&gt;runc terminal handling&lt;/a&gt;). Your process field in the &lt;code&gt;config.json&lt;/code&gt; should look like this below with &lt;code&gt;&#34;terminal&#34;: false&lt;/code&gt; and &lt;code&gt;&#34;args&#34;: [&#34;sleep&#34;, &#34;5&#34;]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;        &#34;process&#34;: {&#xA;                &#34;terminal&#34;: false,&#xA;                &#34;user&#34;: {&#xA;                        &#34;uid&#34;: 0,&#xA;                        &#34;gid&#34;: 0&#xA;                },&#xA;                &#34;args&#34;: [&#xA;                        &#34;sleep&#34;, &#34;5&#34;&#xA;                ],&#xA;                &#34;env&#34;: [&#xA;                        &#34;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&#34;,&#xA;                        &#34;TERM=xterm&#34;&#xA;                ],&#xA;                &#34;cwd&#34;: &#34;/&#34;,&#xA;                &#34;capabilities&#34;: {&#xA;                        &#34;bounding&#34;: [&#xA;                                &#34;CAP_AUDIT_WRITE&#34;,&#xA;                                &#34;CAP_KILL&#34;,&#xA;                                &#34;CAP_NET_BIND_SERVICE&#34;&#xA;                        ],&#xA;                        &#34;effective&#34;: [&#xA;                                &#34;CAP_AUDIT_WRITE&#34;,&#xA;                                &#34;CAP_KILL&#34;,&#xA;                                &#34;CAP_NET_BIND_SERVICE&#34;&#xA;                        ],&#xA;                        &#34;inheritable&#34;: [&#xA;                                &#34;CAP_AUDIT_WRITE&#34;,&#xA;                                &#34;CAP_KILL&#34;,&#xA;                                &#34;CAP_NET_BIND_SERVICE&#34;&#xA;                        ],&#xA;                        &#34;permitted&#34;: [&#xA;                                &#34;CAP_AUDIT_WRITE&#34;,&#xA;                                &#34;CAP_KILL&#34;,&#xA;                                &#34;CAP_NET_BIND_SERVICE&#34;&#xA;                        ],&#xA;                        &#34;ambient&#34;: [&#xA;                                &#34;CAP_AUDIT_WRITE&#34;,&#xA;                                &#34;CAP_KILL&#34;,&#xA;                                &#34;CAP_NET_BIND_SERVICE&#34;&#xA;                        ]&#xA;                },&#xA;                &#34;rlimits&#34;: [&#xA;                        {&#xA;                                &#34;type&#34;: &#34;RLIMIT_NOFILE&#34;,&#xA;                                &#34;hard&#34;: 1024,&#xA;                                &#34;soft&#34;: 1024&#xA;                        }&#xA;                ],&#xA;                &#34;noNewPrivileges&#34;: true&#xA;        },&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now we can go through the lifecycle operations in your shell.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# run as root&#xA;cd /mycontainer&#xA;runc create mycontainerid&#xA;&#xA;# view the container is created and in the &#34;created&#34; state&#xA;runc list&#xA;&#xA;# start the process inside the container&#xA;runc start mycontainerid&#xA;&#xA;# after 5 seconds view that the container has exited and is now in the stopped state&#xA;runc list&#xA;&#xA;# now delete the container&#xA;runc delete mycontainerid&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This allows higher level systems to augment the containers creation logic with setup of various settings after the container is created and/or before it is deleted. For example, the container&#39;s network stack is commonly set up after &lt;code&gt;create&lt;/code&gt; but before &lt;code&gt;start&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Rootless containers&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; has the ability to run containers without root privileges. This is called &lt;code&gt;rootless&lt;/code&gt;. You need to pass some parameters to &lt;code&gt;runc&lt;/code&gt; in order to run rootless containers. See below and compare with the previous version.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In order to use this feature, &#34;User Namespaces&#34; must be compiled and enabled in your kernel. There are various ways to do this depending on your distribution:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Confirm &lt;code&gt;CONFIG_USER_NS=y&lt;/code&gt; is set in your kernel configuration (normally found in &lt;code&gt;/proc/config.gz&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Arch/Debian: &lt;code&gt;echo 1 &amp;gt; /proc/sys/kernel/unprivileged_userns_clone&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;RHEL/CentOS 7: &lt;code&gt;echo 28633 &amp;gt; /proc/sys/user/max_user_namespaces&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Run the following commands as an ordinary user:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Same as the first example&#xA;mkdir ~/mycontainer&#xA;cd ~/mycontainer&#xA;mkdir rootfs&#xA;docker export $(docker create busybox) | tar -C rootfs -xvf -&#xA;&#xA;# The --rootless parameter instructs runc spec to generate a configuration for a rootless container, which will allow you to run the container as a non-root user.&#xA;runc spec --rootless&#xA;&#xA;# The --root parameter tells runc where to store the container state. It must be writable by the user.&#xA;runc --root /tmp/runc run mycontainerid&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Supervisors&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; can be used with process supervisors and init systems to ensure that containers are restarted when they exit. An example systemd unit file looks something like this.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-systemd&#34;&gt;[Unit]&#xA;Description=Start My Container&#xA;&#xA;[Service]&#xA;Type=forking&#xA;ExecStart=/usr/local/sbin/runc run -d --pid-file /run/mycontainerid.pid mycontainerid&#xA;ExecStopPost=/usr/local/sbin/runc delete mycontainerid&#xA;WorkingDirectory=/mycontainer&#xA;PIDFile=/run/mycontainerid.pid&#xA;&#xA;[Install]&#xA;WantedBy=multi-user.target&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;More documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/docs/spec-conformance.md&#34;&gt;Spec conformance&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/docs/cgroup-v2.md&#34;&gt;cgroup v2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/docs/checkpoint-restore.md&#34;&gt;Checkpoint and restore&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/docs/systemd.md&#34;&gt;systemd cgroup driver&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/docs/terminals.md&#34;&gt;Terminals and standard IO&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/docs/experimental.md&#34;&gt;Experimental features&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code and docs are released under the &lt;a href=&#34;https://raw.githubusercontent.com/opencontainers/runc/main/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ollama/ollama</title>
    <updated>2024-02-04T01:51:01Z</updated>
    <id>tag:github.com,2024-02-04:/ollama/ollama</id>
    <link href="https://github.com/ollama/ollama" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Get up and running with Llama 2, Mistral, and other large language models locally.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img alt=&#34;ollama&#34; height=&#34;200px&#34; src=&#34;https://github.com/jmorganca/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;Ollama&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/ollama&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/ollama?style=flat&amp;amp;compact=true&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Get up and running with large language models locally.&lt;/p&gt; &#xA;&lt;h3&gt;macOS&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ollama.ai/download/Ollama-darwin.zip&#34;&gt;Download&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;p&gt;Coming soon! For now, you can install Ollama on Windows via WSL2.&lt;/p&gt; &#xA;&lt;h3&gt;Linux &amp;amp; WSL2&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl https://ollama.ai/install.sh | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jmorganca/ollama/raw/main/docs/linux.md&#34;&gt;Manual install instructions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;The official &lt;a href=&#34;https://hub.docker.com/r/ollama/ollama&#34;&gt;Ollama Docker image&lt;/a&gt; &lt;code&gt;ollama/ollama&lt;/code&gt; is available on Docker Hub.&lt;/p&gt; &#xA;&lt;h3&gt;Libraries&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ollama/ollama-python&#34;&gt;ollama-python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ollama/ollama-js&#34;&gt;ollama-js&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;To run and chat with &lt;a href=&#34;https://ollama.ai/library/llama2&#34;&gt;Llama 2&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama run llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Model library&lt;/h2&gt; &#xA;&lt;p&gt;Ollama supports a list of open-source models available on &lt;a href=&#34;https://ollama.ai/library&#34; title=&#34;ollama model library&#34;&gt;ollama.ai/library&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here are some example open-source models that can be downloaded:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Parameters&lt;/th&gt; &#xA;   &lt;th&gt;Size&lt;/th&gt; &#xA;   &lt;th&gt;Download&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 2&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llama2&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;4.1GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run mistral&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dolphin Phi&lt;/td&gt; &#xA;   &lt;td&gt;2.7B&lt;/td&gt; &#xA;   &lt;td&gt;1.6GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run dolphin-phi&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi-2&lt;/td&gt; &#xA;   &lt;td&gt;2.7B&lt;/td&gt; &#xA;   &lt;td&gt;1.7GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run phi&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Neural Chat&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;4.1GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run neural-chat&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Starling&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;4.1GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run starling-lm&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Code Llama&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run codellama&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 2 Uncensored&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llama2-uncensored&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 2 13B&lt;/td&gt; &#xA;   &lt;td&gt;13B&lt;/td&gt; &#xA;   &lt;td&gt;7.3GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llama2:13b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 2 70B&lt;/td&gt; &#xA;   &lt;td&gt;70B&lt;/td&gt; &#xA;   &lt;td&gt;39GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llama2:70b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Orca Mini&lt;/td&gt; &#xA;   &lt;td&gt;3B&lt;/td&gt; &#xA;   &lt;td&gt;1.9GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run orca-mini&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run vicuna&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaVA&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;4.5GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama run llava&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Customize a model&lt;/h2&gt; &#xA;&lt;h3&gt;Import from GGUF&lt;/h3&gt; &#xA;&lt;p&gt;Ollama supports importing GGUF models in the Modelfile:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a file named &lt;code&gt;Modelfile&lt;/code&gt;, with a &lt;code&gt;FROM&lt;/code&gt; instruction with the local filepath to the model you want to import.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;FROM ./vicuna-33b.Q4_0.gguf&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create the model in Ollama&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ollama create example -f Modelfile&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the model&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ollama run example&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Import from PyTorch or Safetensors&lt;/h3&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/ollama/ollama/main/docs/import.md&#34;&gt;guide&lt;/a&gt; on importing models for more information.&lt;/p&gt; &#xA;&lt;h3&gt;Customize a prompt&lt;/h3&gt; &#xA;&lt;p&gt;Models from the Ollama library can be customized with a prompt. For example, to customize the &lt;code&gt;llama2&lt;/code&gt; model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama pull llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create a &lt;code&gt;Modelfile&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;FROM llama2&#xA;&#xA;# set the temperature to 1 [higher is more creative, lower is more coherent]&#xA;PARAMETER temperature 1&#xA;&#xA;# set the system message&#xA;SYSTEM &#34;&#34;&#34;&#xA;You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.&#xA;&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, create and run the model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama create mario -f ./Modelfile&#xA;ollama run mario&#xA;&amp;gt;&amp;gt;&amp;gt; hi&#xA;Hello! It&#39;s your friend Mario.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more examples, see the &lt;a href=&#34;https://raw.githubusercontent.com/ollama/ollama/main/examples&#34;&gt;examples&lt;/a&gt; directory. For more information on working with a Modelfile, see the &lt;a href=&#34;https://raw.githubusercontent.com/ollama/ollama/main/docs/modelfile.md&#34;&gt;Modelfile&lt;/a&gt; documentation.&lt;/p&gt; &#xA;&lt;h2&gt;CLI Reference&lt;/h2&gt; &#xA;&lt;h3&gt;Create a model&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama create&lt;/code&gt; is used to create a model from a Modelfile.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama create mymodel -f ./Modelfile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pull a model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama pull llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;This command can also be used to update a local model. Only the diff will be pulled.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Remove a model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama rm llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Copy a model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama cp llama2 my-llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Multiline input&lt;/h3&gt; &#xA;&lt;p&gt;For multiline input, you can wrap text with &lt;code&gt;&#34;&#34;&#34;&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; &#34;&#34;&#34;Hello,&#xA;... world!&#xA;... &#34;&#34;&#34;&#xA;I&#39;m a basic program that prints the famous &#34;Hello, world!&#34; message to the console.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Multimodal models&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; What&#39;s in this image? /Users/jmorgan/Desktop/smile.png&#xA;The image features a yellow smiley face, which is likely the central focus of the picture.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pass in prompt as arguments&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ollama run llama2 &#34;Summarize this file: $(cat README.md)&#34;&#xA; Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;List models on your computer&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama list&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Start Ollama&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama serve&lt;/code&gt; is used when you want to start ollama without running the desktop application.&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;Install &lt;code&gt;cmake&lt;/code&gt; and &lt;code&gt;go&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install cmake go&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then generate dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;go generate ./...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then build the binary:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;go build .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More detailed instructions can be found in the &lt;a href=&#34;https://github.com/jmorganca/ollama/raw/main/docs/development.md&#34;&gt;developer guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Running local builds&lt;/h3&gt; &#xA;&lt;p&gt;Next, start the server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./ollama serve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, in a separate shell, run a model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./ollama run llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;REST API&lt;/h2&gt; &#xA;&lt;p&gt;Ollama has a REST API for running and managing models.&lt;/p&gt; &#xA;&lt;h3&gt;Generate a response&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl http://localhost:11434/api/generate -d &#39;{&#xA;  &#34;model&#34;: &#34;llama2&#34;,&#xA;  &#34;prompt&#34;:&#34;Why is the sky blue?&#34;&#xA;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Chat with a model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl http://localhost:11434/api/chat -d &#39;{&#xA;  &#34;model&#34;: &#34;mistral&#34;,&#xA;  &#34;messages&#34;: [&#xA;    { &#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;why is the sky blue?&#34; }&#xA;  ]&#xA;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/ollama/ollama/main/docs/api.md&#34;&gt;API documentation&lt;/a&gt; for all endpoints.&lt;/p&gt; &#xA;&lt;h2&gt;Community Integrations&lt;/h2&gt; &#xA;&lt;h3&gt;Web &amp;amp; Desktop&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bionic-gpt/bionic-gpt&#34;&gt;Bionic GPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rtcfirefly/ollama-ui&#34;&gt;HTML UI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ivanfioravanti/chatbot-ollama&#34;&gt;Chatbot UI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file&#34;&gt;Typescript UI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/richawo/minimal-llm-ui&#34;&gt;Minimalistic React UI for Ollama Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ollama-webui/ollama-webui&#34;&gt;Web UI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kevinhermawan/Ollamac&#34;&gt;Ollamac&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/enricoros/big-agi/raw/main/docs/config-ollama.md&#34;&gt;big-AGI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cheshire-cat-ai/core&#34;&gt;Cheshire Cat assistant framework&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/semperai/amica&#34;&gt;Amica&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BruceMacD/chatd&#34;&gt;chatd&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kghandour/Ollama-SwiftUI&#34;&gt;Ollama-SwiftUI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mindmac.app&#34;&gt;MindMac&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Terminal&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggozad/oterm&#34;&gt;oterm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/s-kostyaev/ellama&#34;&gt;Ellama Emacs client&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zweifisch/ollama&#34;&gt;Emacs client&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/David-Kunz/gen.nvim&#34;&gt;gen.nvim&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nomnivore/ollama.nvim&#34;&gt;ollama.nvim&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huynle/ogpt.nvim&#34;&gt;ogpt.nvim&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/karthink/gptel&#34;&gt;gptel Emacs client&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dustinblackman/oatmeal&#34;&gt;Oatmeal&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pgibler/cmdh&#34;&gt;cmdh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taketwo/llm-ollama&#34;&gt;llm-ollama&lt;/a&gt; for &lt;a href=&#34;https://llm.datasette.io/en/stable/&#34;&gt;Datasette&#39;s LLM CLI&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Database&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mindsdb/mindsdb/raw/staging/mindsdb/integrations/handlers/ollama_handler/README.md&#34;&gt;MindsDB&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Package managers&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://archlinux.org/packages/extra/x86_64/ollama/&#34;&gt;Pacman&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Libraries&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/docs/integrations/llms/ollama&#34;&gt;LangChain&lt;/a&gt; and &lt;a href=&#34;https://js.langchain.com/docs/modules/model_io/models/llms/integrations/ollama&#34;&gt;LangChain.js&lt;/a&gt; with &lt;a href=&#34;https://js.langchain.com/docs/use_cases/question_answering/local_retrieval_qa&#34;&gt;example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tmc/langchaingo/&#34;&gt;LangChainGo&lt;/a&gt; with &lt;a href=&#34;https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example&#34;&gt;example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpt-index.readthedocs.io/en/stable/examples/llm/ollama.html&#34;&gt;LlamaIndex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BerriAI/litellm&#34;&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/awaescher/OllamaSharp&#34;&gt;OllamaSharp for .NET&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gbaptista/ollama-ai&#34;&gt;Ollama for Ruby&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pepperoni21/ollama-rs&#34;&gt;Ollama-rs for Rust&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/amithkoujalgi/ollama4j&#34;&gt;Ollama4j for Java&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelfusion.dev/integration/model-provider/ollama&#34;&gt;ModelFusion Typescript Library&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kevinhermawan/OllamaKit&#34;&gt;OllamaKit for Swift&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/breitburg/dart-ollama&#34;&gt;Ollama for Dart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cloudstudio/ollama-laravel&#34;&gt;Ollama for Laravel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/davidmigloz/langchain_dart&#34;&gt;LangChainDart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama&#34;&gt;Semantic Kernel - Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepset-ai/haystack-integrations/raw/main/integrations/ollama.md&#34;&gt;Haystack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/JBGruber/rollama&#34;&gt;Ollama for R - rollama&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Mobile&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AugustDev/enchanted&#34;&gt;Enchanted&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mobile-Artificial-Intelligence/maid&#34;&gt;Maid&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Extensions &amp;amp; Plugins&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MassimilianoPasquini97/raycast_ollama&#34;&gt;Raycast extension&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mxyng/discollama&#34;&gt;Discollama&lt;/a&gt; (Discord bot inside the Ollama discord channel)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/continuedev/continue&#34;&gt;Continue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hinterdupfinger/obsidian-ollama&#34;&gt;Obsidian Ollama plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/omagdy7/ollama-logseq&#34;&gt;Logseq Ollama plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/samalba/dagger-chatbot&#34;&gt;Dagger Chatbot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mekb-turtle/discord-ai-bot&#34;&gt;Discord AI Bot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ruecat/ollama-telegram&#34;&gt;Ollama Telegram Bot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ej52/hass-ollama-conversation&#34;&gt;Hass Ollama Conversation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/abrenneke/rivet-plugin-ollama&#34;&gt;Rivet plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ex3ndr/llama-coder&#34;&gt;Llama Coder&lt;/a&gt; (Copilot alternative using Ollama)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/longy2k/obsidian-bmo-chatbot&#34;&gt;Obsidian BMO Chatbot plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openinterpreter.com/language-model-setup/local-models/ollama&#34;&gt;Open Interpreter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rjmacarthy/twinny&#34;&gt;twinny&lt;/a&gt; (Copilot and Copilot chat alternative using Ollama)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/RussellCanfield/wingman-ai&#34;&gt;Wingman-AI&lt;/a&gt; (Copilot code and chat alternative using Ollama and HuggingFace)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>pulumi/pulumi</title>
    <updated>2024-02-04T01:51:01Z</updated>
    <id>tag:github.com,2024-02-04:/pulumi/pulumi</id>
    <link href="https://github.com/pulumi/pulumi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Pulumi - Infrastructure as Code in any programming language. Build infrastructure intuitively on any cloud using familiar languages 🚀&lt;/p&gt;&lt;hr&gt;&lt;a href=&#34;https://www.pulumi.com?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=top-logo&#34; title=&#34;Pulumi - Modern Infrastructure as Code - AWS Azure Kubernetes Containers Serverless&#34;&gt; &lt;img src=&#34;https://www.pulumi.com/images/logo/logo-on-white-box.svg?&#34; width=&#34;350&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://slack.pulumi.com?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=slack-badge&#34;&gt;&lt;img src=&#34;http://www.pulumi.com/images/docs/badges/slack.svg?sanitize=true&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/discussions/pulumi/pulumi&#34; alt=&#34;GitHub Discussions&#34;&gt; &lt;a href=&#34;https://npmjs.com/package/@pulumi/pulumi&#34;&gt;&lt;img src=&#34;https://badge.fury.io/js/%40pulumi%2Fpulumi.svg?sanitize=true&#34; alt=&#34;NPM version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/pulumi&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/pulumi.svg?sanitize=true&#34; alt=&#34;Python version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://badge.fury.io/nu/pulumi&#34;&gt;&lt;img src=&#34;https://badge.fury.io/nu/pulumi.svg?sanitize=true&#34; alt=&#34;NuGet version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://godoc.org/github.com/pulumi/pulumi&#34;&gt;&lt;img src=&#34;https://godoc.org/github.com/pulumi/pulumi?status.svg?sanitize=true&#34; alt=&#34;GoDoc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/pulumi/pulumi/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/pulumi/pulumi&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitpod.io/#https://github.com/pulumi/pulumi&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&#34; alt=&#34;Gitpod ready-to-code&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;a href=&#34;https://www.pulumi.com/docs/get-started/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=get-started-button&#34; title=&#34;Get Started&#34;&gt; &lt;img src=&#34;https://www.pulumi.com/images/get-started.svg?&#34; align=&#34;right&#34; width=&#34;120&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pulumi&#39;s Infrastructure as Code SDK&lt;/strong&gt; is the easiest way to build and deploy infrastructure, of any architecture and on any cloud, using programming languages that you already know and love. Code and ship infrastructure faster with your favorite languages and tools, and embed IaC anywhere with &lt;a href=&#34;https://www.pulumi.com/docs/guides/automation-api/&#34;&gt;Automation API&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Simply write code in your favorite language and Pulumi automatically provisions and manages your resources on &lt;a href=&#34;https://www.pulumi.com/docs/reference/clouds/aws/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=aws-reference-link&#34;&gt;AWS&lt;/a&gt;, &lt;a href=&#34;https://www.pulumi.com/docs/reference/clouds/azure/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=azure-reference-link&#34;&gt;Azure&lt;/a&gt;, &lt;a href=&#34;https://www.pulumi.com/docs/reference/clouds/gcp/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=gcp-reference-link&#34;&gt;Google Cloud Platform&lt;/a&gt;, &lt;a href=&#34;https://www.pulumi.com/docs/reference/clouds/kubernetes/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=kuberneters-reference-link&#34;&gt;Kubernetes&lt;/a&gt;, and &lt;a href=&#34;https://www.pulumi.com/registry/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=providers-reference-link&#34;&gt;120+ providers&lt;/a&gt; using an &lt;a href=&#34;https://www.pulumi.com/what-is/what-is-infrastructure-as-code/&#34;&gt;infrastructure-as-code&lt;/a&gt; approach. Skip the YAML, and use standard language features like loops, functions, classes, and package management that you already know and love.&lt;/p&gt; &#xA;&lt;p&gt;For example, create three web servers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;const aws = require(&#34;@pulumi/aws&#34;);&#xA;const sg = new aws.ec2.SecurityGroup(&#34;web-sg&#34;, {&#xA;    ingress: [{ protocol: &#34;tcp&#34;, fromPort: 80, toPort: 80, cidrBlocks: [&#34;0.0.0.0/0&#34;] }],&#xA;});&#xA;for (let i = 0; i &amp;lt; 3; i++) {&#xA;    new aws.ec2.Instance(`web-${i}`, {&#xA;        ami: &#34;ami-7172b611&#34;,&#xA;        instanceType: &#34;t2.micro&#34;,&#xA;        vpcSecurityGroupIds: [sg.id],&#xA;        userData: `#!/bin/bash&#xA;            echo &#34;Hello, World!&#34; &amp;gt; index.html&#xA;            nohup python -m SimpleHTTPServer 80 &amp;amp;`,&#xA;    });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or a simple serverless timer that archives Hacker News every day at 8:30AM:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;const aws = require(&#34;@pulumi/aws&#34;);&#xA;&#xA;const snapshots = new aws.dynamodb.Table(&#34;snapshots&#34;, {&#xA;    attributes: [{ name: &#34;id&#34;, type: &#34;S&#34;, }],&#xA;    hashKey: &#34;id&#34;, billingMode: &#34;PAY_PER_REQUEST&#34;,&#xA;});&#xA;&#xA;aws.cloudwatch.onSchedule(&#34;daily-yc-snapshot&#34;, &#34;cron(30 8 * * ? *)&#34;, () =&amp;gt; {&#xA;    require(&#34;https&#34;).get(&#34;https://news.ycombinator.com&#34;, res =&amp;gt; {&#xA;        let content = &#34;&#34;;&#xA;        res.setEncoding(&#34;utf8&#34;);&#xA;        res.on(&#34;data&#34;, chunk =&amp;gt; content += chunk);&#xA;        res.on(&#34;end&#34;, () =&amp;gt; new aws.sdk.DynamoDB.DocumentClient().put({&#xA;            TableName: snapshots.name.get(),&#xA;            Item: { date: Date.now(), content },&#xA;        }).promise());&#xA;    }).end();&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Many examples are available spanning containers, serverless, and infrastructure in &lt;a href=&#34;https://github.com/pulumi/examples&#34;&gt;pulumi/examples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Pulumi is open source under the &lt;a href=&#34;https://github.com/pulumi/pulumi/raw/master/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;, supports many languages and clouds, and is easy to extend. This repo contains the &lt;code&gt;pulumi&lt;/code&gt; CLI, language SDKs, and core Pulumi engine, and individual libraries are in their own repos.&lt;/p&gt; &#xA;&lt;h2&gt;Welcome&lt;/h2&gt; &#xA;&lt;img align=&#34;right&#34; width=&#34;400&#34; src=&#34;https://www.pulumi.com/images/docs/quickstart/console.png&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.pulumi.com/docs/get-started/&#34;&gt;Get Started with Pulumi&lt;/a&gt;&lt;/strong&gt;: Deploy a simple application in AWS, Azure, Google Cloud, or Kubernetes using Pulumi.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.pulumi.com/learn/&#34;&gt;Learn&lt;/a&gt;&lt;/strong&gt;: Follow Pulumi learning pathways to learn best practices and architectural patterns through authentic examples.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/pulumi/examples&#34;&gt;Examples&lt;/a&gt;&lt;/strong&gt;: Browse several examples across many languages, clouds, and scenarios including containers, serverless, and infrastructure.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.pulumi.com/docs/&#34;&gt;Docs&lt;/a&gt;&lt;/strong&gt;: Learn about Pulumi concepts, follow user-guides, and consult the reference documentation.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.pulumi.com/registry/&#34;&gt;Registry&lt;/a&gt;&lt;/strong&gt;: Find the Pulumi Package with the resources you need. Install the package directly into your project, browse the API documentation, and start building.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/orgs/pulumi/projects/44&#34;&gt;Pulumi Roadmap&lt;/a&gt;&lt;/strong&gt;: Review the planned work for the upcoming quarter and a selected backlog of issues that are on our mind but not yet scheduled.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://slack.pulumi.com/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=welcome-slack&#34;&gt;Community Slack&lt;/a&gt;&lt;/strong&gt;: Join us in Pulumi Community Slack. All conversations and questions are welcome.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/pulumi/pulumi/discussions&#34;&gt;GitHub Discussions&lt;/a&gt;&lt;/strong&gt;: Ask questions or share what you&#39;re building with Pulumi.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;getting-started&#34;&gt;&lt;/a&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6f8KF6UGN7g&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pulumi/pulumi/master/youtube_preview_image.png&#34; alt=&#34;Watch the video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://www.pulumi.com/docs/quickstart/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=getting-started-quickstart&#34;&gt;Get Started&lt;/a&gt; guide to quickly get started with Pulumi on your platform and cloud of choice.&lt;/p&gt; &#xA;&lt;p&gt;Otherwise, the following steps demonstrate how to deploy your first Pulumi program, using AWS Serverless Lambdas, in minutes:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;To install the latest Pulumi release, run the following (see full &lt;a href=&#34;https://www.pulumi.com/docs/reference/install/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=getting-started-install&#34;&gt;installation instructions&lt;/a&gt; for additional installation options):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -fsSL https://get.pulumi.com/ | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Create a Project&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;After installing, you can get started with the &lt;code&gt;pulumi new&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mkdir pulumi-demo &amp;amp;&amp;amp; cd pulumi-demo&#xA;$ pulumi new hello-aws-javascript&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;new&lt;/code&gt; command offers templates for all languages and clouds. Run it without an argument and it&#39;ll prompt you with available projects. This command created an AWS Serverless Lambda project written in JavaScript.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deploy to the Cloud&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Run &lt;code&gt;pulumi up&lt;/code&gt; to get your code to the cloud:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pulumi up&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This makes all cloud resources needed to run your code. Simply make edits to your project, and subsequent &lt;code&gt;pulumi up&lt;/code&gt;s will compute the minimal diff to deploy your changes.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Use Your Program&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Now that your code is deployed, you can interact with it. In the above example, we can curl the endpoint:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl $(pulumi stack output url)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Access the Logs&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;If you&#39;re using containers or functions, Pulumi&#39;s unified logging command will show all of your logs:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pulumi logs -f&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Destroy your Resources&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;After you&#39;re done, you can remove all resources created by your program:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pulumi destroy -y&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;To learn more, head over to &lt;a href=&#34;https://pulumi.com/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=getting-started-learn-more-home&#34;&gt;pulumi.com&lt;/a&gt; for much more information, including &lt;a href=&#34;https://www.pulumi.com/docs/reference/tutorials/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=getting-started-learn-more-tutorials&#34;&gt;tutorials&lt;/a&gt;, &lt;a href=&#34;https://github.com/pulumi/examples&#34;&gt;examples&lt;/a&gt;, and details of the core Pulumi CLI and &lt;a href=&#34;https://www.pulumi.com/docs/reference/concepts/?utm_campaign=pulumi-pulumi-github-repo&amp;amp;utm_source=github.com&amp;amp;utm_medium=getting-started-learn-more-concepts&#34;&gt;programming model concepts&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;platform&#34;&gt;&lt;/a&gt;Platform&lt;/h2&gt; &#xA;&lt;h3&gt;Languages&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Language&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;   &lt;th&gt;Runtime&lt;/th&gt; &#xA;   &lt;th&gt;Versions&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://www.pulumi.com/logos/tech/logo-js.png&#34; height=&#34;38&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.pulumi.com/docs/intro/languages/javascript/&#34;&gt;JavaScript&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Stable&lt;/td&gt; &#xA;   &lt;td&gt;Node.js&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://nodejs.org/en/about/previous-releases&#34;&gt;Current, Active and Maintenance LTS versions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://www.pulumi.com/logos/tech/logo-ts.png&#34; height=&#34;38&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.pulumi.com/docs/intro/languages/javascript/&#34;&gt;TypeScript&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Stable&lt;/td&gt; &#xA;   &lt;td&gt;Node.js&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://nodejs.org/en/about/previous-releases&#34;&gt;Current, Active and Maintenance LTS versions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://www.pulumi.com/logos/tech/logo-python.svg?sanitize=true&#34; height=&#34;38&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.pulumi.com/docs/intro/languages/python/&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Stable&lt;/td&gt; &#xA;   &lt;td&gt;Python&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://devguide.python.org/versions/#versions&#34;&gt;Supported versions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://www.pulumi.com/logos/tech/logo-golang.png&#34; height=&#34;38&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.pulumi.com/docs/intro/languages/go/&#34;&gt;Go&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Stable&lt;/td&gt; &#xA;   &lt;td&gt;Go&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://go.dev/doc/devel/release#policy&#34;&gt;Supported versions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://www.pulumi.com/logos/tech/dotnet.svg?sanitize=true&#34; height=&#34;38&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.pulumi.com/docs/intro/languages/dotnet/&#34;&gt;.NET (C#/F#/VB.NET)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Stable&lt;/td&gt; &#xA;   &lt;td&gt;.NET&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://dotnet.microsoft.com/en-us/platform/support/policy/dotnet-core#lifecycle&#34;&gt;Supported versions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://www.pulumi.com/logos/tech/java.svg?sanitize=true&#34; height=&#34;38&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.pulumi.com/docs/intro/languages/java/&#34;&gt;Java&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Public Preview&lt;/td&gt; &#xA;   &lt;td&gt;JDK&lt;/td&gt; &#xA;   &lt;td&gt;11+&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://www.pulumi.com/logos/tech/yaml.svg?sanitize=true&#34; height=&#34;38&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.pulumi.com/docs/intro/languages/yaml/&#34;&gt;YAML&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Stable&lt;/td&gt; &#xA;   &lt;td&gt;n/a&lt;/td&gt; &#xA;   &lt;td&gt;n/a&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;EOL Releases&lt;/h3&gt; &#xA;&lt;p&gt;The Pulumi CLI v1 and v2 are no longer supported. If you are not yet running v3, please consider migrating to v3 to continue getting the latest and greatest Pulumi has to offer! &lt;span&gt;💪&lt;/span&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To migrate from v2 to v3, please see our &lt;a href=&#34;https://www.pulumi.com/docs/install/migrating-3.0/&#34;&gt;v3 Migration Guide&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Clouds&lt;/h3&gt; &#xA;&lt;p&gt;Visit the &lt;a href=&#34;https://www.pulumi.com/registry/&#34;&gt;Registry&lt;/a&gt; for the full list of supported cloud and infrastructure providers.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;https://github.com/pulumi/pulumi/raw/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for information on building Pulumi from source or contributing improvements.&lt;/p&gt;</summary>
  </entry>
</feed>