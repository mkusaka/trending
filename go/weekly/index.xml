<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Go Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-14T01:51:25Z</updated>
  <subtitle>Weekly Trending of Go in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>nilsherzig/LLocalSearch</title>
    <updated>2024-04-14T01:51:25Z</updated>
    <id>tag:github.com,2024-04-14:/nilsherzig/LLocalSearch</id>
    <link href="https://github.com/nilsherzig/LLocalSearch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LLocalSearch is a completely locally running search aggregator using LLM Agents. The user can ask a question and the system will use a chain of LLMs to find the answer. The user can see the progress of the agents and the final answer. No OpenAI or Google API keys are needed.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLocalSearch&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT] Discuss configurations and setups with other users at: &lt;a href=&#34;https://discord.gg/Cm77Eav5mX&#34;&gt;https://discord.gg/Cm77Eav5mX&lt;/a&gt;. Help / Support is handled exclusively on GitHub to allow people with similar issues to find solutions more easily.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;What it is&lt;/h2&gt; &#xA;&lt;p&gt;LLocalSearch is a completely locally running search aggregator using LLM Agents. The user can ask a question and the system will use a chain of LLMs to find the answer. The user can see the progress of the agents and the final answer. No OpenAI or Google API keys are needed.&lt;/p&gt; &#xA;&lt;h3&gt;Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/nilsherzig/LLocalSearch/assets/72463901/86ab3175-ac5a-48cf-bba6-73b4380d06d8&#34;&gt;https://github.com/nilsherzig/LLocalSearch/assets/72463901/86ab3175-ac5a-48cf-bba6-73b4380d06d8&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🕵️ Completely local (no need for API keys)&lt;/li&gt; &#xA; &lt;li&gt;💸 Runs on &#34;low end&#34; LLM Hardware (demo video uses a 7b model)&lt;/li&gt; &#xA; &lt;li&gt;🤓 Progress logs, allowing for a better understanding of the search process&lt;/li&gt; &#xA; &lt;li&gt;🤔 Follow-up questions&lt;/li&gt; &#xA; &lt;li&gt;📱 Mobile friendly interface&lt;/li&gt; &#xA; &lt;li&gt;🚀 Fast and easy to deploy with Docker Compose&lt;/li&gt; &#xA; &lt;li&gt;🌐 Web interface, allowing for easy access from any device&lt;/li&gt; &#xA; &lt;li&gt;💮 Handcrafted UI with light and dark mode&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Status&lt;/h2&gt; &#xA;&lt;p&gt;This project is still in its very early days. Expect some bugs.&lt;/p&gt; &#xA;&lt;h2&gt;How it works&lt;/h2&gt; &#xA;&lt;p&gt;Please read &lt;a href=&#34;https://github.com/nilsherzig/LLocalSearch/issues/17&#34;&gt;infra&lt;/a&gt; to get the most up-to-date idea.&lt;/p&gt; &#xA;&lt;h2&gt;Self-hosting &amp;amp; Development&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A running &lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama&lt;/a&gt; server, reachable from the container &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;GPU is not needed, but recommended&lt;/li&gt; &#xA;   &lt;li&gt;🔴 make sure that Ollama is not just listening on localhost but on all interfaces (or at least the docker network). You don&#39;t have to change anything if you&#39;re using ollama inside docker.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Docker Compose&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING] localhost / 127.0.0.1 inside the backend container (&lt;code&gt;OLLAMA_HOST&lt;/code&gt; var) is not the same as localhost on your host device.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Run the latest release&lt;/h3&gt; &#xA;&lt;p&gt;Recommended, if you don&#39;t intend to develop on this project.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/nilsherzig/LLocalSearch.git&#xA;cd ./LLocalSearch&#xA;# 🔴 check the env vars inside the compose file (and `env-example` file) and change them if needed&#xA;docker-compose up &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;🎉 You should now be able to open the web interface on &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;. Nothing else is exposed by default.&lt;/p&gt; &#xA;&lt;h3&gt;Run the current git version&lt;/h3&gt; &#xA;&lt;p&gt;Newer features, but potentially less stable.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/nilsherzig/LLocalsearch.git&#xA;# 1. make sure to check the env vars inside the `docker-compose.dev.yaml`.&#xA;# 2. Make sure you&#39;ve really checked the dev compose file not the normal one.&#xA;&#xA;# 3. build the containers and start the services&#xA;make dev &#xA;# Both front and backend will hot reload on code changes. &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you don&#39;t have &lt;code&gt;make&lt;/code&gt; installed, you can run the commands inside the Makefile manually.&lt;/p&gt; &#xA;&lt;p&gt;Now you should be able to access the frontend on &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;stars&lt;/h2&gt; &#xA;&lt;p&gt;Kinda looks like im botting haha&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#nilsherzig/LLocalSearch&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=nilsherzig/LLocalSearch&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>aurora-develop/aurora</title>
    <updated>2024-04-14T01:51:25Z</updated>
    <id>tag:github.com,2024-04-14:/aurora-develop/aurora</id>
    <link href="https://github.com/aurora-develop/aurora" rel="alternate"></link>
    <summary type="html">&lt;p&gt;free&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AURORA&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/aurora-develop/aurora/raw/main/README_EN.md&#34;&gt;README_EN&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;（带UI）免费的GPT3.5，支持使用3.5的access 调用&lt;/p&gt; &#xA;&lt;h1&gt;交流群&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://t.me/aurora_develop&#34;&gt;https://t.me/aurora_develop&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Web端&lt;/h1&gt; &#xA;&lt;p&gt;访问&lt;a href=&#34;http://%E4%BD%A0%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8ip:8080/web&#34;&gt;http://你的服务器ip:8080/web&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://jsd.cdn.zzko.cn/gh/xiaozhou26/tuph@main/images/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-04-07%20111706.png&#34; alt=&#34;web使用&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;注：仅ip属地支持免登录使用ChatGpt可以使用(也可以自定义Baseurl来绕过限制)&lt;/h3&gt; &#xA;&lt;h2&gt;Deploy&lt;/h2&gt; &#xA;&lt;h3&gt;Glitch部署&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/aurora-develop/aurora-glitch&#34;&gt;&lt;img src=&#34;https://cdn.glitch.com/2703baf2-b643-4da7-ab91-7ee2a2d00b5b%2Fremix-button.svg?sanitize=true&#34; alt=&#34;Deploy to Glitch&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Vercel部署&lt;/h3&gt; &#xA;&lt;p&gt;由于vercel的go不支持流式，如果在vercel部署请在STREAM_MODE中填False，不支持任何默认流式的客户端，支持沉浸式翻译。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Faurora-develop%2Faurora&amp;amp;env=STREAM_MODE&amp;amp;project-name=aurora&amp;amp;repository-name=aurora&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;Deploy with Vercel&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Render部署&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://render.com/deploy&#34;&gt;&lt;img src=&#34;https://render.com/images/deploy-to-render-button.svg?sanitize=true&#34; alt=&#34;Deploy&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Koyeb部署&lt;/h3&gt; &#xA;&lt;p&gt;地区选美国&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://app.koyeb.com/deploy?type=docker&amp;amp;name=aurora&amp;amp;ports=8080;http;/&amp;amp;image=ghcr.io/aurora-develop/aurora&#34;&gt;&lt;img src=&#34;https://www.koyeb.com/static/images/deploy/button.svg?sanitize=true&#34; alt=&#34;Deploy to Koyeb&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Railway部署&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://railway.app/template/jcl2Es?referralCode=XXqY_5&#34;&gt;&lt;img src=&#34;https://railway.app/button.svg?sanitize=true&#34; alt=&#34;Deploy on Railway&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Zeabur部署&lt;/h3&gt; &#xA;&lt;p&gt;进入修改镜像名称aurora+任何字母数字&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zeabur.com/templates/JF3EFW&#34;&gt;&lt;img src=&#34;https://zeabur.com/button.svg?sanitize=true&#34; alt=&#34;Deploy on Zeabur&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;编译部署&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/aurora-develop/aurora&#xA;cd aurora&#xA;go build -o aurora&#xA;chmod +x ./aurora&#xA;./aurora&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker部署&lt;/h3&gt; &#xA;&lt;h2&gt;Docker部署&lt;/h2&gt; &#xA;&lt;p&gt;您需要安装Docker和Docker Compose。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d \&#xA;  --name aurora \&#xA;  -p 8080:8080 \&#xA;  ghcr.io/aurora-develop/aurora:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Docker Compose部署&lt;/h2&gt; &#xA;&lt;p&gt;创建一个新的目录，例如aurora-app，并进入该目录：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir aurora&#xA;cd aurora&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;在此目录中下载库中的docker-compose.yml文件：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl --location &#39;http://你的服务器ip:8080/v1/chat/completions&#39; \&#xA;--header &#39;Content-Type: application/json&#39; \&#xA;--data &#39;{&#xA;     &#34;model&#34;: &#34;gpt-3.5-turbo&#34;,&#xA;     &#34;messages&#34;: [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Say this is a test!&#34;}],&#xA;     &#34;stream&#34;: true&#xA;   }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;高级设置&lt;/h2&gt; &#xA;&lt;p&gt;默认情况不需要设置，除非你有需求&lt;/p&gt; &#xA;&lt;h3&gt;环境变量&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;BASE_URL=&#34;https://chat.openai.com/backend-api&#34; 代理网关&#xA;Authorization=your_authorization  用户认证 key。&#xA;TLS_CERT=path_to_your_tls_cert 存储TLS（传输层安全协议）证书的路径。&#xA;TLS_KEY=path_to_your_tls_key 存储TLS（传输层安全协议）证书的路径。&#xA;PROXY_URL=your_proxy_url 添加代理池来。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;鸣谢&lt;/h2&gt; &#xA;&lt;p&gt;感谢各位大佬的pr支持，感谢。&lt;/p&gt; &#xA;&lt;h2&gt;参考项目&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/xqdoo00o/ChatGPT-to-API&#34;&gt;https://github.com/xqdoo00o/ChatGPT-to-API&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT License&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>plandex-ai/plandex</title>
    <updated>2024-04-14T01:51:25Z</updated>
    <id>tag:github.com,2024-04-14:/plandex-ai/plandex</id>
    <link href="https://github.com/plandex-ai/plandex" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An AI coding engine for complex tasks&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;a href=&#34;https://plandex.ai&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;images/plandex-logo-dark.png&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;images/plandex-logo-light.png&#34;&gt; &#xA;   &lt;img width=&#34;370&#34; src=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/images/plandex-logo-dark-bg.png&#34;&gt; &#xA;  &lt;/picture&gt;&lt;/a&gt; &lt;br&gt; &lt;/h1&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;strong&gt;🔮 An open source, terminal-based AI coding engine for complex tasks.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;!-- Badges --&gt; &lt;a href=&#34;https://github.com/plandex-ai/plandex/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt;  &lt;a href=&#34;https://github.com/plandex-ai/plandex/releases?q=cli&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/plandex-ai/plandex?filter=cli*&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/plandex-ai/plandex/releases?q=server&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/plandex-ai/plandex?filter=server*&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &#xA; &lt;!-- &lt;a href=&#34;https://github.com/your_username/your_project/issues&#34;&gt;&#xA;    &lt;img src=&#34;https://img.shields.io/github/issues-closed/your_username/your_project.svg&#34; alt=&#34;Issues Closed&#34; /&gt;&#xA;  &lt;/a&gt; --&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;!-- Call to Action Links --&gt; &lt;a href=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/#install&#34;&gt; &lt;b&gt;Install&lt;/b&gt; &lt;/a&gt; · &#xA; &lt;!-- &lt;a href=&#34;https://plandex.ai&#34;&gt;&#xA;    &lt;b&gt;Website&lt;/b&gt;&#xA;  &lt;/a&gt;&#xA;  · --&gt; &lt;a href=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/guides/USAGE.md&#34;&gt; &lt;b&gt;Usage&lt;/b&gt; &lt;/a&gt; · &lt;a href=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/guides/HOSTING.md&#34;&gt; &lt;b&gt;Self-Hosting&lt;/b&gt; &lt;/a&gt; · &lt;a href=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/guides/DEVELOPMENT.md&#34;&gt; &lt;b&gt;Development&lt;/b&gt; &lt;/a&gt; · &lt;a href=&#34;https://discord.gg/plandex-ai&#34;&gt; &lt;b&gt;Discord&lt;/b&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Plandex uses long-running agents to complete tasks that span multiple files and require many steps. It breaks up large tasks into smaller subtasks, then implements each one, continuing until it finishes the job. It helps you churn through your backlog, work with unfamiliar technologies, get unstuck, and spend less time on the boring stuff. &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;!-- Vimeo link is nicer on mobile than embedded video... downside is it navigates to vimeo in same tab (no way to add target=_blank) --&gt; &#xA;&lt;!-- https://github.com/plandex-ai/plandex/assets/545350/c2ee3bcd-1512-493f-bdd5-e3a4ca534a36 --&gt; &#xA;&lt;a href=&#34;https://player.vimeo.com/video/926634577&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/images/plandex-intro-vimeo.png&#34; alt=&#34;Plandex intro video&#34; width=&#34;100%&#34;&gt; &lt;/a&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;🌟&amp;nbsp; Build complex software with LLMs&lt;/h2&gt; &#xA;&lt;p&gt;⚡️ &amp;nbsp;Changes are accumulated in a protected sandbox so that you can review them before automatically applying them to your project files. Built-in version control allows you to easily go backwards and try a different approach. Branches allow you to try multiple approaches and compare the results.&lt;/p&gt; &#xA;&lt;p&gt;📑 &amp;nbsp;Manage context efficiently in the terminal. Easily add files or entire directories to context, and keep them updated automatically as you work so that models always have the latest state of your project.&lt;/p&gt; &#xA;&lt;p&gt;🧠 &amp;nbsp;Plandex relies on the OpenAI API and requires an &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; environment variable. Support for open source models, Google Gemini, and Anthropic Claude is coming soon. Use the &lt;code&gt;OPENAI_ENDPOINT&lt;/code&gt; environment variable for a custom OpenAI endpoint.&lt;/p&gt; &#xA;&lt;p&gt;✅ &amp;nbsp;Plandex supports Mac, Linux, FreeBSD, and Windows. It runs from a single binary with no dependencies.&lt;/p&gt; &#xA;&lt;h2&gt;Install&amp;nbsp;&amp;nbsp;📥&lt;/h2&gt; &#xA;&lt;h3&gt;Quick install&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -sL https://plandex.ai/install.sh | bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Manual install&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt; Grab the appropriate binary for your platform from the latest &lt;a href=&#34;https://github.com/plandex-ai/plandex/releases&#34;&gt;release&lt;/a&gt; and put it somewhere in your &lt;code&gt;PATH&lt;/code&gt;. &lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Build from source&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;pre&gt;&lt;code&gt;git clone https://github.com/plandex-ai/plandex.git&#xA;git clone https://github.com/plandex-ai/survey.git&#xA;cd plandex/app/cli&#xA;go build -ldflags &#34;-X plandex/version.Version=$(cat version.txt)&#34;&#xA;mv plandex /usr/local/bin # adapt as needed for your system&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Windows&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt; Windows is supported via &lt;a href=&#34;https://learn.microsoft.com/en-us/windows/wsl/about&#34;&gt;WSL&lt;/a&gt;. &lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Get started&amp;nbsp; 🚀&lt;/h2&gt; &#xA;&lt;p&gt;If you don&#39;t have an OpenAI account, first &lt;a href=&#34;https://platform.openai.com/signup&#34;&gt;sign up here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Then &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;generate an API key here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd your-project&#xA;export OPENAI_API_KEY=...&#xA;export OPENAI_ENDPOINT=... # optional e.g. https://&amp;lt;your-proxy&amp;gt;/v1&#xA;export OPENAI_ORG_ID=... # optional - set the OrgID if you have multiple OpenAI orgs&#xA;plandex new&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After any plandex command is run, commands that could make sense to run next will be suggested. You can learn to use Plandex quickly by jumping in and following these suggestions.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&amp;nbsp; 🛠️&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/guides/USAGE.md&#34;&gt;Here&#39;s a quick overview of the commands and functionality.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Help&amp;nbsp; ℹ️&lt;/h2&gt; &#xA;&lt;p&gt;To see all available commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;plandex help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For help on any command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;plandex [command] --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Why Plandex?&amp;nbsp; 🤔&lt;/h2&gt; &#xA;&lt;p&gt;🏗️&amp;nbsp; Go beyond autocomplete to build complex functionality with AI.&lt;br&gt; 🚫&amp;nbsp; Stop the mouse-centered, copy-pasting madness of coding with ChatGPT.&lt;br&gt; 📑&amp;nbsp; Manage context efficiently in the terminal.&lt;br&gt; ⚡️&amp;nbsp; Ensure AI models always have the latest versions of files in context.&lt;br&gt; 🪙&amp;nbsp; Retain granular control over what&#39;s in context and how many tokens you&#39;re using.&lt;br&gt; 🚧&amp;nbsp; Experiment, revise, and review in a protected sandbox before applying changes.&lt;br&gt; ⏪&amp;nbsp; Rewind and retry as needed.&lt;br&gt; 🌱&amp;nbsp; Explore multiple approaches with branches.&lt;br&gt; 🔀&amp;nbsp; Run tasks in the background or work on multiple tasks in parallel.&lt;br&gt; 🎛️&amp;nbsp; Try different models and model settings, then compare results.&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Plandex Cloud&amp;nbsp; ☁️&lt;/h2&gt; &#xA;&lt;p&gt;Plandex Cloud is the easiest and most reliable way to use Plandex. You&#39;ll be prompted to start an anonymous trial (no email required) when you create your first plan with &lt;code&gt;plandex new&lt;/code&gt;. Trial accounts are limited to 10 plans and 10 AI model replies per plan. You can upgrade to an unlimited account with your name and email.&lt;/p&gt; &#xA;&lt;p&gt;Plandex Cloud accounts are free for now. In the future, they will cost somewhere in the $10-20 per month range.&lt;/p&gt; &#xA;&lt;h2&gt;Self-hosting&amp;nbsp; 🏠&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/guides/HOSTING.md&#34;&gt;Read about self-hosting Plandex here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Limitations&amp;nbsp;and guidance ⚠️&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Plandex can provide a significant boost to your productivity, but as with any other AI tool, you shouldn&#39;t expect perfect results. Always review a plan carefully before applying changes, especially if security is involved. Plandex is designed to get you 80-90% of the way there rather than 100%.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Due to the reasoning limitations of LLMs, automatically applied file updates also aren&#39;t perfect. While these can be improved over time with better prompting strategies (contributions welcome) and better models, be prepared for occasional updates that aren&#39;t quite right. Use the &lt;code&gt;plandex changes&lt;/code&gt; command to review pending updates in a TUI. If a file update has mistakes, make those changes yourself with copy-and-paste and reject the file in the changes TUI.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The more direction and detail you provide, the better the results will be. Working with Plandex often involves giving it a prompt, seeing that the results are a bit off, then using &lt;code&gt;plandex rewind&lt;/code&gt; to go back and iterate on the prompt or add context before trying again. Branches are also useful for trying different approaches.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;While it can be tempting to just dump your entire project into context if it fits under the token limit, with current models you will tend to see better results (and pay less) by being more selective about what&#39;s loaded into context.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Security &amp;nbsp;🔐&lt;/h2&gt; &#xA;&lt;p&gt;Plandex Cloud follows best practices for network and data security. And whether cloud or self-hosted, Plandex protects model provider API keys (like your OpenAI API key). &lt;a href=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/guides/SECURITY.md&#34;&gt;Read more here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Privacy and data retention &amp;nbsp;🛡️&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/guides/PRIVACY.md&#34;&gt;Read about Plandex Cloud&#39;s privacy and data retention policies here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap &amp;nbsp;🗺️&lt;/h2&gt; &#xA;&lt;p&gt;🧠&amp;nbsp; Support for open source models, Google Gemini, and Anthropic Claude in addition to OpenAI&lt;br&gt; 🤝&amp;nbsp; Plan sharing and team collaboration&lt;br&gt; 🖼️&amp;nbsp; Support for GPT4-Vision and other multi-modal models—add images and screenshots to context&lt;br&gt; 🖥️&amp;nbsp; VSCode and JetBrains extensions&lt;br&gt; 📦&amp;nbsp; Community plugins and modules&lt;br&gt; 🔌&amp;nbsp; Github integration&lt;br&gt; 🌐&amp;nbsp; Web dashboard and GUI&lt;br&gt; 🔐&amp;nbsp; SOC2 compliance&lt;br&gt; 🛩️&amp;nbsp; Fine-tuned models&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;This list will grow and be prioritized based on your feedback.&lt;/p&gt; &#xA;&lt;h2&gt;Discussion and discord &amp;nbsp;💬&lt;/h2&gt; &#xA;&lt;p&gt;Speaking of feedback, feel free to give yours, ask questions, report a bug, or just hang out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/plandex-ai&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/plandex-ai/plandex/discussions&#34;&gt;Discussions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/plandex-ai/plandex/issues&#34;&gt;Issues&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributors &amp;nbsp;👥&lt;/h2&gt; &#xA;&lt;p&gt;⭐️&amp;nbsp;&amp;nbsp;Please star, fork, explore, and contribute to Plandex. There&#39;s a lot of work to do and so much that can be improved.&lt;/p&gt; &#xA;&lt;p&gt;Work on tests, evals, prompts, and bug fixes is especially appreciated.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/plandex-ai/plandex/main/guides/DEVELOPMENT.md&#34;&gt;Here&#39;s an overview on setting up a development environment.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Comparable tools ⚖️&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/paul-gauthier/aider&#34;&gt;Aider&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AbanteAI/mentat&#34;&gt;Mentat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Pythagora-io/gpt-pilot&#34;&gt;Pythagora Gpt-pilot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sourcegraph/cody&#34;&gt;Sourcegraph Cody&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/continuedev/continue&#34;&gt;Continue.dev&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sweepai/sweep&#34;&gt;Sweep.dev&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/getcursor/cursor&#34;&gt;Cursor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/features/copilot&#34;&gt;Github Copilot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://replit.com/ai&#34;&gt;Replit Ghostwriter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://chat.openai.com/g/g-n7Rs0IK86-grimoire&#34;&gt;Grimoire&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;About the developer&amp;nbsp; 👋&lt;/h2&gt; &#xA;&lt;p&gt;Hi, I&#39;m Dane. I&#39;ve been building and launching software products for 17 years. I went through YCombinator in winter 2018 with my devops security company, &lt;a href=&#34;https://envkey.com&#34;&gt;EnvKey&lt;/a&gt;, which I continue to run today. I&#39;m fascinated by LLMs and their potential to transform the practice of software development.&lt;/p&gt; &#xA;&lt;p&gt;I live with my wife and 4 year old daughter on the SF peninsula in California. I grew up in the Finger Lakes region of upstate New York. I like reading fiction, listening to podcasts, fitness, and surfing.&lt;/p&gt;</summary>
  </entry>
</feed>