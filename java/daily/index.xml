<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Java Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-24T01:39:40Z</updated>
  <subtitle>Daily Trending of Java in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ydzhao-reyes/weixin-tuisong</title>
    <updated>2022-08-24T01:39:40Z</updated>
    <id>tag:github.com,2022-08-24:/ydzhao-reyes/weixin-tuisong</id>
    <link href="https://github.com/ydzhao-reyes/weixin-tuisong" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;weixin-tuisong&lt;/h1&gt; &#xA;&lt;p&gt;ä¸ƒå¤•åˆ°å•¦ï¼Œåšä¸€ä¸ªç¨‹åºå‘˜ç»™å¥³æœ‹å‹çš„æµªæ¼«ç¤¼ç‰©å§ã€‚ ä¸€ä¸ªæ‘¸é±¼çš„ä¸‹åˆï¼Œç®€å•ä»‹ç»ä¸€ä¸‹æ€ä¹ˆåšçš„å§ï¼Œçº¯åç«¯javaï¼Œå†™çš„æ¯”è¾ƒéšæ„ï¼Œä»…ä»…è¾¾åˆ°äº†åŠŸèƒ½è¦æ±‚ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ‰€ç”¨çŸ¥è¯†ç‚¹&lt;/p&gt; &#xA;&lt;p&gt;1.springbootå®ç°javaåå°&lt;/p&gt; &#xA;&lt;p&gt;2.å¾®ä¿¡æµ‹è¯•è´¦å·çš„ç”³è¯·&lt;/p&gt; &#xA;&lt;p&gt;3.å¾®ä¿¡æ¨¡ç‰ˆæ¨é€çš„é…ç½®&lt;/p&gt; &#xA;&lt;p&gt;4.æ¥å…¥ç™¾åº¦å¤©æ°”api&lt;/p&gt; &#xA;&lt;p&gt;5.å½©è™¹å±apiæˆ–è€…è‡ªå·±å†™ä¸ªæƒ…è¯åº“&lt;/p&gt; &#xA;&lt;p&gt;6.æ¯æ—¥é‡‘å¥apiæˆ–è€…è‡ªå·±å†™ä¸ªé‡‘å¥åº“&lt;/p&gt; &#xA;&lt;p&gt;å…·ä½“æ•™ç¨‹å¯ä»¥æŸ¥çœ‹åšå®¢&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://t.csdn.cn/gzC6Z&#34;&gt;http://t.csdn.cn/gzC6Z&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;éœ€è¦ä¿®æ”¹æºç çš„åœ°æ–¹ æµ‹è¯•å…¬ä¼—å·çš„idå’Œå¯†é’¥ &lt;img src=&#34;https://user-images.githubusercontent.com/42952460/182985351-92f81810-59d0-44a9-8289-058a4b329e11.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ç™¾åº¦å¤©æ°”å¼€å‘è€…çš„akå’Œæ‰€åœ¨åœ°åŒºçš„ç¼–ç &lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/42952460/182985393-ff0db255-e5fd-4356-b0b6-59e5ad85687f.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;å½©è™¹å±apiçš„key&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/42952460/182987189-c3484b2a-4f10-40d7-a709-e9d88220214f.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>revanced/revanced-integrations</title>
    <updated>2022-08-24T01:39:40Z</updated>
    <id>tag:github.com,2022-08-24:/revanced/revanced-integrations</id>
    <link href="https://github.com/revanced/revanced-integrations" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ”© Integrations containing helper classes for ReVanced. Originally maintained by Vanced.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ReVanced Integrations&lt;/h1&gt; &#xA;&lt;h1&gt;How to use debugging:&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Usage on Windows: &lt;code&gt;adb logcat | findstr &#34;revanced&#34; &amp;gt; log.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Usage on Linux: &lt;code&gt;adb logcat | grep --line-buffered &#34;revanced&#34; &amp;gt; log.txt&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This will write the log to a file called log.txt which you can view then.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apache/hudi</title>
    <updated>2022-08-24T01:39:40Z</updated>
    <id>tag:github.com,2022-08-24:/apache/hudi</id>
    <link href="https://github.com/apache/hudi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Upserts, Deletes And Incremental Processing on Big Data.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache Hudi&lt;/h1&gt; &#xA;&lt;p&gt;Apache Hudi (pronounced Hoodie) stands for &lt;code&gt;Hadoop Upserts Deletes and Incrementals&lt;/code&gt;. Hudi manages the storage of large analytical datasets on DFS (Cloud stores, HDFS or any Hadoop FileSystem compatible storage).&lt;/p&gt; &#xA;&lt;img src=&#34;https://hudi.apache.org/assets/images/hudi-logo-medium.png&#34; alt=&#34;Hudi logo&#34; height=&#34;80px&#34; align=&#34;right&#34;&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hudi.apache.org/&#34;&gt;https://hudi.apache.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/hudi/actions/workflows/bot.yml&#34;&gt;&lt;img src=&#34;https://github.com/apache/hudi/actions/workflows/bot.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://dev.azure.com/apache-hudi-ci-org/apache-hudi-ci/_build/latest?definitionId=3&amp;amp;branchName=master&#34;&gt;&lt;img src=&#34;https://dev.azure.com/apache-hudi-ci-org/apache-hudi-ci/_apis/build/status/apachehudi-ci.hudi-mirror?branchName=master&#34; alt=&#34;Test&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-4EB1BA.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.apache.hudi%22&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/org.apache.hudi/hudi/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/commit-activity/m/apache/hudi&#34; alt=&#34;GitHub commit activity&#34;&gt; &lt;a href=&#34;https://join.slack.com/t/apache-hudi/shared_invite/enQtODYyNDAxNzc5MTg2LTE5OTBlYmVhYjM0N2ZhOTJjOWM4YzBmMWU2MjZjMGE4NDc5ZDFiOGQ2N2VkYTVkNzU3ZDQ4OTI1NmFmYWQ0NzE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/slack-%23hudi-72eff8?logo=slack&amp;amp;color=48c628&amp;amp;label=Join%20on%20Slack&#34; alt=&#34;Join on Slack&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/ApacheHudi&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Upsert support with fast, pluggable indexing&lt;/li&gt; &#xA; &lt;li&gt;Atomically publish data with rollback support&lt;/li&gt; &#xA; &lt;li&gt;Snapshot isolation between writer &amp;amp; queries&lt;/li&gt; &#xA; &lt;li&gt;Savepoints for data recovery&lt;/li&gt; &#xA; &lt;li&gt;Manages file sizes, layout using statistics&lt;/li&gt; &#xA; &lt;li&gt;Async compaction of row &amp;amp; columnar data&lt;/li&gt; &#xA; &lt;li&gt;Timeline metadata to track lineage&lt;/li&gt; &#xA; &lt;li&gt;Optimize data lake layout with clustering&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Hudi supports three types of queries:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Snapshot Query&lt;/strong&gt; - Provides snapshot queries on real-time data, using a combination of columnar &amp;amp; row-based storage (e.g &lt;a href=&#34;https://parquet.apache.org/&#34;&gt;Parquet&lt;/a&gt; + &lt;a href=&#34;https://avro.apache.org/docs/current/mr.html&#34;&gt;Avro&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Incremental Query&lt;/strong&gt; - Provides a change stream with records inserted or updated after a point in time.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Read Optimized Query&lt;/strong&gt; - Provides excellent snapshot query performance via purely columnar storage (e.g. &lt;a href=&#34;https://parquet.apache.org/&#34;&gt;Parquet&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Learn more about Hudi at &lt;a href=&#34;https://hudi.apache.org&#34;&gt;https://hudi.apache.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Building Apache Hudi from source&lt;/h2&gt; &#xA;&lt;p&gt;Prerequisites for building Apache Hudi:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Unix-like system (like Linux, Mac OS X)&lt;/li&gt; &#xA; &lt;li&gt;Java 8 (Java 9 or 10 may work)&lt;/li&gt; &#xA; &lt;li&gt;Git&lt;/li&gt; &#xA; &lt;li&gt;Maven (&amp;gt;=3.3.1)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Checkout code and build&#xA;git clone https://github.com/apache/hudi.git &amp;amp;&amp;amp; cd hudi&#xA;mvn clean package -DskipTests&#xA;&#xA;# Start command&#xA;spark-2.4.4-bin-hadoop2.7/bin/spark-shell \&#xA;  --jars `ls packaging/hudi-spark-bundle/target/hudi-spark-bundle_2.11-*.*.*-SNAPSHOT.jar` \&#xA;  --conf &#39;spark.serializer=org.apache.spark.serializer.KryoSerializer&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To build for integration tests that include &lt;code&gt;hudi-integ-test-bundle&lt;/code&gt;, use &lt;code&gt;-Dintegration-tests&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To build the Javadoc for all Java and Scala classes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Javadoc generated under target/site/apidocs&#xA;mvn clean javadoc:aggregate -Pjavadocs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Build with different Spark versions&lt;/h3&gt; &#xA;&lt;p&gt;The default Spark version supported is 2.4.4. Refer to the table below for building with different Spark and Scala versions.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Maven build options&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Expected Spark bundle jar name&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;(empty)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-spark-bundle_2.11 (legacy bundle name)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Spark 2.4.4 and Scala 2.11 (default options)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dspark2.4&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-spark2.4-bundle_2.11&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Spark 2.4.4 and Scala 2.11 (same as default)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dspark2.4 -Dscala-2.12&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-spark2.4-bundle_2.12&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Spark 2.4.4 and Scala 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dspark3.1 -Dscala-2.12&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-spark3.1-bundle_2.12&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Spark 3.1.x and Scala 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dspark3.2 -Dscala-2.12&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-spark3.2-bundle_2.12&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Spark 3.2.x and Scala 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dspark3&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-spark3-bundle_2.12 (legacy bundle name)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Spark 3.2.x and Scala 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dscala-2.12&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-spark-bundle_2.12 (legacy bundle name)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Spark 2.4.4 and Scala 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;For example,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Build against Spark 3.2.x&#xA;mvn clean package -DskipTests -Dspark3.2 -Dscala-2.12&#xA;&#xA;# Build against Spark 3.1.x&#xA;mvn clean package -DskipTests -Dspark3.1 -Dscala-2.12&#xA;&#xA;# Build against Spark 2.4.4 and Scala 2.12&#xA;mvn clean package -DskipTests -Dspark2.4 -Dscala-2.12&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;What about &#34;spark-avro&#34; module?&lt;/h4&gt; &#xA;&lt;p&gt;Starting from versions 0.11, Hudi no longer requires &lt;code&gt;spark-avro&lt;/code&gt; to be specified using &lt;code&gt;--packages&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Build with different Flink versions&lt;/h3&gt; &#xA;&lt;p&gt;The default Flink version supported is 1.14. Refer to the table below for building with different Flink and Scala versions.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Maven build options&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Expected Flink bundle jar name&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;(empty)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-flink1.14-bundle_2.11&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Flink 1.14 and Scala 2.11 (default options)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dflink1.14&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-flink1.14-bundle_2.11&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Flink 1.14 and Scala 2.11 (same as default)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dflink1.14 -Dscala-2.12&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-flink1.14-bundle_2.12&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Flink 1.14 and Scala 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dflink1.13&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-flink1.13-bundle_2.11&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Flink 1.13 and Scala 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;-Dflink1.13 -Dscala-2.12&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;hudi-flink1.13-bundle_2.12&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;For Flink 1.13 and Scala 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Running Tests&lt;/h2&gt; &#xA;&lt;p&gt;Unit tests can be run with maven profile &lt;code&gt;unit-tests&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mvn -Punit-tests test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Functional tests, which are tagged with &lt;code&gt;@Tag(&#34;functional&#34;)&lt;/code&gt;, can be run with maven profile &lt;code&gt;functional-tests&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mvn -Pfunctional-tests test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run tests with spark event logging enabled, define the Spark event log directory. This allows visualizing test DAG and stages using Spark History Server UI.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mvn -Punit-tests test -DSPARK_EVLOG_DIR=/path/for/spark/event/log&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;Please visit &lt;a href=&#34;https://hudi.apache.org/docs/quick-start-guide.html&#34;&gt;https://hudi.apache.org/docs/quick-start-guide.html&lt;/a&gt; to quickly explore Hudi&#39;s capabilities using spark-shell.&lt;/p&gt;</summary>
  </entry>
</feed>