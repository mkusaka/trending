<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Java Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-25T01:32:10Z</updated>
  <subtitle>Daily Trending of Java in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lakesoul-io/LakeSoul</title>
    <updated>2023-09-25T01:32:10Z</updated>
    <id>tag:github.com,2023-09-25:/lakesoul-io/LakeSoul</id>
    <link href="https://github.com/lakesoul-io/LakeSoul" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LakeSoul is an end-to-end, realtime and cloud native Lakehouse framework with fast data ingestion, concurrent update and incremental data analytics on cloud storages for both BI and AI applications.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://github.com/lakesoul-io/artwork/raw/main/horizontal/color/LakeSoul_Horizontal_Color.svg?sanitize=true&#34; alt=&#34;LakeSoul&#34; height=&#34;200&#34;&gt; &#xA;&lt;img src=&#34;https://github.com/lfai/artwork/raw/main/lfaidata-assets/lfaidata-project-badge/sandbox/color/lfaidata-project-badge-sandbox-color.svg?sanitize=true&#34; alt=&#34;LF AI &amp;amp; Data Sandbox Project&#34; height=&#34;180&#34;&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://bestpractices.coreinfrastructure.org/projects/7192/badge&#34; alt=&#34;OpenSSF Best Practices&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/lakesoul-io/LakeSoul/actions/workflows/maven-test.yml/badge.svg?sanitize=true&#34; alt=&#34;Maven Test&#34;&gt; &lt;img src=&#34;https://github.com/lakesoul-io/LakeSoul/actions/workflows/flink-cdc-test.yml/badge.svg?sanitize=true&#34; alt=&#34;Flink CDC Test&#34;&gt; &lt;img src=&#34;https://github.com/lakesoul-io/LakeSoul/actions/workflows/native-build.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lakesoul-io/LakeSoul/main/README-CN.md&#34;&gt;中文介绍&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul is a cloud-native Lakehouse framework that supports scalable metadata management, ACID transactions, efficient and flexible upsert operation, schema evolution, and unified streaming &amp;amp; batch processing.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul supports multiple computing engines to read and write lake warehouse table data, including Spark, Flink, Presto, and PyTorch, and supports multiple computing modes such as batch, stream, MPP, and AI. LakeSoul supports storage systems such as HDFS and S3.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lakesoul-io/LakeSoul/main/website/static/img/lakeSoulModel.png&#34; alt=&#34;LakeSoul Arch&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul was originally created by DMetaSoul company and was donated to Linux Foundation AI &amp;amp; Data as a sandbox project since May 2023.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul implements incremental upserts for both row and column and allows concurrent updates.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul uses LSM-Tree like structure to support updates on hash partitioning table with primary key, and achieves very high write throughput while providing optimized merge on read performance (refer to &lt;a href=&#34;https://lakesoul-io.github.io/blog/2023/04/21/lakesoul-2.2.0-release&#34;&gt;Performance Benchmarks&lt;/a&gt;). LakeSoul scales metadata management and achieves ACID control by using PostgreSQL.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul uses Rust to implement the native metadata layer and IO layer, and provides C/Java/Python interfaces to support the connecting of multiple computing frameworks such as big data and AI.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul supports concurrent batch or streaming read and write. Both read and write supports CDC semantics, and together with auto schema evolution and exacly-once guarantee, constructing realtime data warehouses is made easy.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul supports multi-workspace and RBAC. LakeSoul uses Postgres&#39;s RBAC and row-level security policies to implement permission isolation for metadata. Together with Hadoop users and groups, physical data isolation can be achieved. LakeSoul&#39;s permission isolation is effective for SQL/Java/Python jobs.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul supports automatic disaggregated compaction, automatic table life cycle maintenance, and automatic redundant data cleaning, reducing operation costs and improving usability.&lt;/p&gt; &#xA;&lt;p&gt;More detailed features please refer to our doc page: &lt;a href=&#34;https://lakesoul-io.github.io/docs/intro&#34;&gt;Documentations&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Quick Start&lt;/h1&gt; &#xA;&lt;p&gt;Follow the &lt;a href=&#34;https://lakesoul-io.github.io/docs/Getting%20Started/setup-local-env&#34;&gt;Quick Start&lt;/a&gt; to quickly set up a test env.&lt;/p&gt; &#xA;&lt;h1&gt;Tutorials&lt;/h1&gt; &#xA;&lt;p&gt;Please find tutorials in doc site:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/tree/main/python/examples&#34;&gt;Examples of Python Data Processing and AI Model Training on LakeSoul&lt;/a&gt; on how LakeSoul connecting AI to Lakehouse to build a unified and modern data infrastructure.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/flink-cdc-sink&#34;&gt;LakeSoul Flink CDC Whole Database Synchronization Tutorial&lt;/a&gt; on how to sync an entire MySQL database into LakeSoul in realtime, with auto table creation, auto DDL sync and exactly once guarantee.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Usage%20Docs/flink-lakesoul-connector&#34;&gt;Flink SQL Usage&lt;/a&gt; on using Flink SQL to read or write LakeSoul in both batch and streaming mode, with the supports of Flink Changelog Stream semantics and row-level upsert and delete.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/mutil-stream-merge&#34;&gt;Multi Stream Merge and Build Wide Table Tutorial&lt;/a&gt; on how to merge multiple stream with same primary key (and different other columns) concurrently without join.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/upsert-and-merge-udf&#34;&gt;Upsert Data and Merge UDF Tutorial&lt;/a&gt; on how to upsert data and Merge UDF to customize merge logic.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/snapshot-manage&#34;&gt;Snapshot API Usage&lt;/a&gt; on how to do snapshot read (time travel), snapshot rollback and cleanup.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/incremental-query&#34;&gt;Incremental Query Tutorial&lt;/a&gt; on how to do incremental query in Spark in batch or stream mode.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Usage Documentations&lt;/h1&gt; &#xA;&lt;p&gt;Please find usage documentations in doc site: &lt;a href=&#34;https://lakesoul-io.github.io/docs/Usage%20Docs/setup-meta-env&#34;&gt;Usage Doc&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lakesoul-io.github.io/zh-Hans/docs/Getting%20Started/setup-local-env&#34;&gt;快速开始&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/flink-cdc-sink&#34;&gt;教程&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lakesoul-io.github.io/zh-Hans/docs/Usage%20Docs/setup-meta-env&#34;&gt;使用文档&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Feature Roadmap&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Data Science and AI &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Native Python Reader (without PySpark)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; PyTorch Dataset and distributed training&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Meta Management (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/23&#34;&gt;#23&lt;/a&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multiple Level Partitioning: Multiple range partition and at most one hash partition&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Concurrent write with auto conflict resolution&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; MVCC with read isolation&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Write transaction (two-stage commit) through Postgres Transaction&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Schema Evolution: Column add/delete supported&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Table operations &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; LSM-Tree style upsert for hash partitioned table&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Merge on read for hash partition with upsert delta file&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Copy on write update for non hash partitioned table&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Automatic Disaggregated Compaction Service&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Data Warehousing &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CDC stream ingestion with auto ddl sync&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Incremental and Snapshot Query &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Snapshot Query (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/103&#34;&gt;#103&lt;/a&gt;)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Incremental Query (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/103&#34;&gt;#103&lt;/a&gt;)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Incremental Streaming Source (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/130&#34;&gt;#130&lt;/a&gt;)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Flink Stream/Batch Source&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multi Workspaces and RBAC&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Spark Integration &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Table/Dataframe API&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; SQL support with catalog except upsert&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Query optimization &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Shuffle/Join elimination for operations on primary key&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Merge UDF (Merge operator)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Merge Into SQL support &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Merge Into SQL with match on Primary Key (Merge on read)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Merge Into SQL with match on non-pk&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Merge Into SQL with match condition and complex expression (Merge on read when match on PK) (depends on &lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/66&#34;&gt;#66&lt;/a&gt;)&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Flink Integration and CDC Ingestion (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/57&#34;&gt;#57&lt;/a&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Table API &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Batch/Stream Sink&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Batch/Stream source&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Stream Source/Sink for ChangeLog Stream Semantics&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Exactly Once Source and Sink&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Flink CDC &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Auto Schema Change (DDL) Sync&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Auto Table Creation (depends on #78)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support sink multiple source tables with different schemas (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/84&#34;&gt;#84&lt;/a&gt;)&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Hive Integration &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Export to Hive partition after compaction&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Apache Kyuubi (Hive JDBC) Integration&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Realtime Data Warehousing &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CDC ingestion&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Time Travel (Snapshot read)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Snapshot rollback&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Automatic global compaction service&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; MPP Engine Integration (depends on &lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/66&#34;&gt;#66&lt;/a&gt;) &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Presto&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Trino&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Cloud and Native IO (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/66&#34;&gt;#66&lt;/a&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Object storage IO optimization&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Native merge on read&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Multi-layer storage classes support with data tiering&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Community guidelines&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lakesoul-io/LakeSoul/main/community-guideline.md&#34;&gt;Community guidelines&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Feedback and Contribution&lt;/h1&gt; &#xA;&lt;p&gt;Please feel free to open an issue or dicussion if you have any questions.&lt;/p&gt; &#xA;&lt;p&gt;Join our &lt;a href=&#34;https://discord.gg/WJrHKq4BPf&#34;&gt;Discord&lt;/a&gt; server for discussions.&lt;/p&gt; &#xA;&lt;h1&gt;Contact Us&lt;/h1&gt; &#xA;&lt;p&gt;Email us at &lt;a href=&#34;mailto:lakesoul-technical-discuss@lists.lfaidata.foundation&#34;&gt;lakesoul-technical-discuss@lists.lfaidata.foundation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Opensource License&lt;/h1&gt; &#xA;&lt;p&gt;LakeSoul is opensourced under Apache License v2.0.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jsorrell/CarpetSkyAdditions</title>
    <updated>2023-09-25T01:32:10Z</updated>
    <id>tag:github.com,2023-09-25:/jsorrell/CarpetSkyAdditions</id>
    <link href="https://github.com/jsorrell/CarpetSkyAdditions" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Empty world generation with new ways to obtain resources&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Carpet Sky Additions&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jsorrell/CarpetSkyAdditions/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/jsorrell/CarpetSkyAdditions/total?label=Github%20downloads&amp;amp;logo=github&#34; alt=&#34;GitHub downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.curseforge.com/minecraft/mc-mods/carpet-sky-additions&#34;&gt;&lt;img src=&#34;http://cf.way2muchnoise.eu/full_633402_downloads.svg?sanitize=true&#34; alt=&#34;CurseForge downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://modrinth.com/mod/carpet-sky-additions&#34;&gt;&lt;img src=&#34;https://img.shields.io/modrinth/dt/3oX3JnAP?label=Modrinth%20Downloads&#34; alt=&#34;Modrinth downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jsorrell/CarpetSkyAdditions/main/README.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/lang-en-red.svg?sanitize=true&#34; alt=&#34;en&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/jsorrell/CarpetSkyAdditions/main/docs/zh_cn/README.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/lang-zh--cn-yellow.svg?sanitize=true&#34; alt=&#34;zh_cn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Carpet Sky Additions is a module for &lt;a href=&#34;https://github.com/gnembon/fabric-carpet&#34;&gt;fabric-carpet&lt;/a&gt; originally based on &lt;a href=&#34;https://github.com/skyrising/skyblock&#34;&gt;skyrising/skyblock&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This mod aims to provide an expert-level SkyBlock style gameplay that depends on players&#39; knowledge of Minecraft mechanics. In some cases, outside tools such as &lt;a href=&#34;https://www.chunkbase.com/&#34;&gt;Chunkbase&lt;/a&gt; or &lt;a href=&#34;https://www.curseforge.com/minecraft/mc-mods/minihud&#34;&gt;MiniHUD&lt;/a&gt; will be helpful. Usage of these is encouraged. Sometimes extended grinding or AFKing will be required for progression. Unless SkyBlock world generation is chosen or features are specifically enabled, the mod will do nothing. This means SkyBlock and Non-SkyBlock worlds can be switched between easily without restarting the client.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.curseforge.com/minecraft/modpacks/vanilla-sky&#34;&gt;&lt;img src=&#34;http://cf.way2muchnoise.eu/title/624853.svg?sanitize=true&#34; alt=&#34;Vanilla Sky: Everything from Nothing&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The easiest way to use this mod is to install the modpack called &lt;em&gt;&lt;strong&gt;Vanilla Sky: Everything from Nothing&lt;/strong&gt;&lt;/em&gt; which is available on CurseForge.&lt;/p&gt; &#xA;&lt;p&gt;To create a new SkyBlock world, choose &lt;code&gt;World Type: SkyBlock&lt;/code&gt; and enable the datapack &lt;code&gt;&#34;carpetskyadditions/skyblock&#34;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you want a harder challenge, &lt;em&gt;&lt;strong&gt;also&lt;/strong&gt;&lt;/em&gt; enable the datapack &lt;code&gt;&#34;carpetskyadditions/skyblock_acacia&#34;&lt;/code&gt; to start with an Acacia tree instead of an Oak tree.&lt;/p&gt; &#xA;&lt;p&gt;For custom or server installations, follow the &lt;a href=&#34;https://raw.githubusercontent.com/jsorrell/CarpetSkyAdditions/main/docs/en_us/installation.md&#34;&gt;Detailed Installation Instructions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt;SkyBlock Generation&lt;/h3&gt; &#xA;&lt;p&gt;A SkyBlock world generates exactly like a Default generation world, but with every block removed. Biomes and Structure Bounding Boxes are kept in place. This means Husks will still spawn in Deserts and Blazes will spawn in Nether Fortresses, for example. Even with almost every block removed, you have access to most things in the game.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jsorrell/CarpetSkyAdditions/main/docs/en_us/generation.md&#34;&gt;More Generation Details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Gameplay Changes&lt;/h3&gt; &#xA;&lt;p&gt;SkyBlock generation does, however, leave a few unobtainable resources. In addition to adding SkyBlock generation, this mod also fills in the gaps, making as minimal and Minecrafty changes as possible.&lt;/p&gt; &#xA;&lt;p&gt;The biggest progress-blocker is Lava, which is unobtainable by default. This prevents going to the Nether or End or getting Cobblestone. This mod fixes that problem by providing a way to get Lava.&lt;/p&gt; &#xA;&lt;p&gt;Sand is also very limited in a default SkyBlock world, but the mod allows for more to be created.&lt;/p&gt; &#xA;&lt;p&gt;Most other resources provided by this mod are cosmetic and don&#39;t make major changes to progression, such as Dead Bushes and Ender Dragon Heads.&lt;/p&gt; &#xA;&lt;p&gt;When possible, changes were added to a datapack instead of being programmed into the mod for ease of user customization. The datapack is built into the mod.&lt;/p&gt; &#xA;&lt;p&gt;SkyBlock advancements were also added to guide progression and document the mod&#39;s changes to vanilla.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;When installed with default settings, all blocks, items, mobs, and advancements obtainable in Default generation are obtainable in SkyBlock generation.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jsorrell/CarpetSkyAdditions/main/docs/en_us/features.md&#34;&gt;List of Mod Features&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jsorrell/CarpetSkyAdditions/main/docs/en_us/datapack.md&#34;&gt;List of Datapack Features&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Commands&lt;/h3&gt; &#xA;&lt;p&gt;This mod provides a command for generating islands, which simplifies having multiple players on the same server with different starting islands.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jsorrell/CarpetSkyAdditions/main/docs/en_us/commands.md&#34;&gt;List of Mod Commands&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Progression Walkthrough&lt;/h3&gt; &#xA;&lt;p&gt;If you get stuck, a general progression walkthrough is available &lt;a href=&#34;https://raw.githubusercontent.com/jsorrell/CarpetSkyAdditions/main/docs/en_us/progression.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Translations&lt;/h2&gt; &#xA;&lt;p&gt;The mod and the datapack are available for translation using &lt;a href=&#34;https://crowdin.com/project/carpetskyadditions&#34;&gt;CrowdIn&lt;/a&gt;. If you are able to add translations, your help would be much appreciated.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/skyrising/skyblock&#34;&gt;@skyrising&lt;/a&gt; for the initial mod idea&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/DeadlyMC/Skyblock-datapack&#34;&gt;@DeadlyMC&lt;/a&gt; for the initial ideas for the datapack&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/gnembon/fabric-carpet&#34;&gt;@gnembon&lt;/a&gt; for &lt;code&gt;fabric-carpet&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;All the translators on CrowdIn&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt;</summary>
  </entry>
</feed>