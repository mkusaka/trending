<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Java Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-27T01:32:34Z</updated>
  <subtitle>Daily Trending of Java in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Ishan-sinha/DSA-for-SDE-interview</title>
    <updated>2024-01-27T01:32:34Z</updated>
    <id>tag:github.com,2024-01-27:/Ishan-sinha/DSA-for-SDE-interview</id>
    <link href="https://github.com/Ishan-sinha/DSA-for-SDE-interview" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository is aimed to contain all the questions required for SDE interview preparation from data structures and algorithms.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Data Structures and Algorithms for SDE role preparation&lt;/h1&gt; &#xA;&lt;h2&gt;Data Structures&lt;/h2&gt; &#xA;&lt;h3&gt;Linked List&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;em&gt;Linked List&lt;/em&gt; is a linear collection of data elements, called nodes, each pointing to the next node by means of a pointer. It is a data structure consisting of a group of nodes which together represent a sequence.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Singly-linked list&lt;/strong&gt;: linked list in which each node points to the next node and the last node points to null&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Doubly-linked list&lt;/strong&gt;: linked list in which each node has two pointers, p and n, such that p points to the previous node and n points to the next node; the last node&#39;s n pointer points to null&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Circular-linked list&lt;/strong&gt;: linked list in which each node points to the next node and the last node points back to the first node&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Access: &lt;code&gt;O(n)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Search: &lt;code&gt;O(n)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Insert: &lt;code&gt;O(1)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Remove: &lt;code&gt;O(1)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Stack&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;em&gt;Stack&lt;/em&gt; is a collection of elements, with two principle operations: &lt;em&gt;push&lt;/em&gt;, which adds to the collection, and &lt;em&gt;pop&lt;/em&gt;, which removes the most recently added element&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Last in, first out data structure (LIFO)&lt;/strong&gt;: the most recently added object is the first to be removed&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Access: &lt;code&gt;O(n)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Search: &lt;code&gt;O(n)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Insert: &lt;code&gt;O(1)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Remove: &lt;code&gt;O(1)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Queue&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;em&gt;Queue&lt;/em&gt; is a collection of elements, supporting two principle operations: &lt;em&gt;enqueue&lt;/em&gt;, which inserts an element into the queue, and &lt;em&gt;dequeue&lt;/em&gt;, which removes an element from the queue&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;First in, first out data structure (FIFO)&lt;/strong&gt;: the oldest added object is the first to be removed&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Access: &lt;code&gt;O(n)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Search: &lt;code&gt;O(n)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Insert: &lt;code&gt;O(1)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Remove: &lt;code&gt;O(1)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Tree&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;em&gt;Tree&lt;/em&gt; is an undirected, connected, acyclic graph&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Binary Tree&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;em&gt;Binary Tree&lt;/em&gt; is a tree data structure in which each node has at most two children, which are referred to as the &lt;em&gt;left child&lt;/em&gt; and &lt;em&gt;right child&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Full Tree&lt;/strong&gt;: a tree in which every node has either 0 or 2 children&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Perfect Binary Tree&lt;/strong&gt;: a binary tree in which all interior nodes have two children and all leave have the same depth&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Complete Tree&lt;/strong&gt;: a binary tree in which every level &lt;em&gt;except possibly the last&lt;/em&gt; is full and all nodes in the last level are as far left as possible&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Binary Search Tree&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A binary search tree, sometimes called BST, is a type of binary tree which maintains the property that the value in each node must be greater than or equal to any value stored in the left sub-tree, and less than or equal to any value stored in the right sub-tree&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Access: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Search: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Insert: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Remove: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/BST.png?raw=true&#34; alt=&#34;Binary Search Tree&#34; width=&#34;400&#34; height=&#34;500&#34;&gt; &#xA;&lt;h3&gt;Trie&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A trie, sometimes called a radix or prefix tree, is a kind of search tree that is used to store a dynamic set or associative array where the keys are usually Strings. No node in the tree stores the key associated with that node; instead, its position in the tree defines the key with which it is associated. All the descendants of a node have a common prefix of the String associated with that node, and the root is associated with the empty String.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/trie.png?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Trie&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Fenwick Tree&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A Fenwick tree, sometimes called a binary indexed tree, is a tree in concept, but in practice is implemented as an implicit data structure using an array. Given an index in the array representing a vertex, the index of a vertex&#39;s parent or child is calculated through bitwise operations on the binary representation of its index. Each element of the array contains the pre-calculated sum of a range of values, and by combining that sum with additional ranges encountered during an upward traversal to the root, the prefix sum is calculated&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Range Sum: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Update: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/fenwickTree.png?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Fenwick Tree&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Segment Tree&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A Segment tree, is a tree data structure for storing intervals, or segments. It allows querying which of the stored segments contain a given point&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Range Query: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Update: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/segmentTree.png?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Segment Tree&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Heap&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;em&gt;Heap&lt;/em&gt; is a specialized tree based structure data structure that satisfies the &lt;em&gt;heap&lt;/em&gt; property: if A is a parent node of B, then the key (the value) of node A is ordered with respect to the key of node B with the same ordering applying across the entire heap. A heap can be classified further as either a &#34;max heap&#34; or a &#34;min heap&#34;. In a max heap, the keys of parent nodes are always greater than or equal to those of the children and the highest key is in the root node. In a min heap, the keys of parent nodes are less than or equal to those of the children and the lowest key is in the root node&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Access Max / Min: &lt;code&gt;O(1)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Insert: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Remove Max / Min: &lt;code&gt;O(log(n))&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/heap.png?raw=true&#34; alt=&#34;Max Heap&#34; width=&#34;400&#34; height=&#34;500&#34;&gt; &#xA;&lt;h3&gt;Hashing&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Hashing&lt;/em&gt; is used to map data of an arbitrary size to data of a fixed size. The values returned by a hash function are called hash values, hash codes, or simply hashes. If two keys map to the same value, a collision occurs&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Hash Map&lt;/strong&gt;: a &lt;em&gt;hash map&lt;/em&gt; is a structure that can map keys to values. A hash map uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found.&lt;/li&gt; &#xA; &lt;li&gt;Collision Resolution&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Separate Chaining&lt;/strong&gt;: in &lt;em&gt;separate chaining&lt;/em&gt;, each bucket is independent, and contains a list of entries for each index. The time for hash map operations is the time to find the bucket (constant time), plus the time to iterate through the list&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Open Addressing&lt;/strong&gt;: in &lt;em&gt;open addressing&lt;/em&gt;, when a new entry is inserted, the buckets are examined, starting with the hashed-to-slot and proceeding in some sequence, until an unoccupied slot is found. The name open addressing refers to the fact that the location of an item is not always determined by its hash value&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/hash.png?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Hashing&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Graph&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;em&gt;Graph&lt;/em&gt; is an ordered pair of G = (V, E) comprising a set V of vertices or nodes together with a set E of edges or arcs, which are 2-element subsets of V (i.e. an edge is associated with two vertices, and that association takes the form of the unordered pair comprising those two vertices)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Undirected Graph&lt;/strong&gt;: a graph in which the adjacency relation is symmetric. So if there exists an edge from node u to node v (u -&amp;gt; v), then it is also the case that there exists an edge from node v to node u (v -&amp;gt; u)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Directed Graph&lt;/strong&gt;: a graph in which the adjacency relation is not symmetric. So if there exists an edge from node u to node v (u -&amp;gt; v), this does &lt;em&gt;not&lt;/em&gt; imply that there exists an edge from node v to node u (v -&amp;gt; u)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/graph.png?raw=true&#34; alt=&#34;Graph&#34; width=&#34;400&#34; height=&#34;500&#34;&gt; &#xA;&lt;h2&gt;Algorithms&lt;/h2&gt; &#xA;&lt;h3&gt;Sorting&lt;/h3&gt; &#xA;&lt;h4&gt;Quicksort&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Stable: &lt;code&gt;No&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Best Case: &lt;code&gt;O(nlog(n))&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Worst Case: &lt;code&gt;O(n^2)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Average Case: &lt;code&gt;O(nlog(n))&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/quicksort.gif?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Quicksort&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Mergesort&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Mergesort&lt;/em&gt; is also a divide and conquer algorithm. It continuously divides an array into two halves, recurses on both the left subarray and right subarray and then merges the two sorted halves&lt;/li&gt; &#xA; &lt;li&gt;Stable: &lt;code&gt;Yes&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Best Case: &lt;code&gt;O(nlog(n))&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Worst Case: &lt;code&gt;O(nlog(n))&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Average Case: &lt;code&gt;O(nlog(n))&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/mergesort.gif?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Mergesort&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Bucket Sort&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Bucket Sort&lt;/em&gt; is a sorting algorithm that works by distributing the elements of an array into a number of buckets. Each bucket is then sorted individually, either using a different sorting algorithm, or by recursively applying the bucket sorting algorithm&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Best Case: &lt;code&gt;Ω(n + k)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Worst Case: &lt;code&gt;O(n^2)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Average Case:&lt;code&gt;Θ(n + k)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/bucketsort.png?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Bucket Sort&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Radix Sort&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Radix Sort&lt;/em&gt; is a sorting algorithm that like bucket sort, distributes elements of an array into a number of buckets. However, radix sort differs from bucket sort by &#39;re-bucketing&#39; the array after the initial pass as opposed to sorting each bucket and merging&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Best Case: &lt;code&gt;Ω(nk)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Worst Case: &lt;code&gt;O(nk)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Average Case: &lt;code&gt;Θ(nk)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Graph Algorithms&lt;/h3&gt; &#xA;&lt;h4&gt;Depth First Search&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Depth First Search&lt;/em&gt; is a graph traversal algorithm which explores as far as possible along each branch before backtracking&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &lt;code&gt;O(|V| + |E|)&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/dfsbfs.gif?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;DFS / BFS Traversal&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Breadth First Search&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Breadth First Search&lt;/em&gt; is a graph traversal algorithm which explores the neighbor nodes first, before moving to the next level neighbors&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &lt;code&gt;O(|V| + |E|)&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/dfsbfs.gif?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;DFS / BFS Traversal&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Topological Sort&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Topological Sort&lt;/em&gt; is the linear ordering of a directed graph&#39;s nodes such that for every edge from node u to node v, u comes before v in the ordering&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &lt;code&gt;O(|V| + |E|)&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Dijkstra&#39;s Algorithm&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Dijkstra&#39;s Algorithm&lt;/em&gt; is an algorithm for finding the shortest path between nodes in a graph&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &lt;code&gt;O(|V|^2)&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/dijkstra.gif?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Dijkstra&#39;s&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Bellman-Ford Algorithm&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Bellman-Ford Algorithm&lt;/em&gt; is an algorithm that computes the shortest paths from a single source node to all other nodes in a weighted graph&lt;/li&gt; &#xA; &lt;li&gt;Although it is slower than Dijkstra&#39;s, it is more versatile, as it is capable of handling graphs in which some of the edge weights are negative numbers&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Best Case: &lt;code&gt;O(|E|)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Worst Case: &lt;code&gt;O(|V||E|)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/bellman-ford.gif?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Bellman-Ford&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Floyd-Warshall Algorithm&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Floyd-Warshall Algorithm&lt;/em&gt; is an algorithm for finding the shortest paths in a weighted graph with positive or negative edge weights, but no negative cycles&lt;/li&gt; &#xA; &lt;li&gt;A single execution of the algorithm will find the lengths (summed weights) of the shortest paths between &lt;em&gt;all&lt;/em&gt; pairs of nodes&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Best Case: &lt;code&gt;O(|V|^3)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Worst Case: &lt;code&gt;O(|V|^3)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Average Case: &lt;code&gt;O(|V|^3)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Prim&#39;s Algorithm&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Prim&#39;s Algorithm&lt;/em&gt; is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph. In other words, Prim&#39;s find a subset of edges that forms a tree that includes every node in the graph&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &lt;code&gt;O(|V|^2)&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/prim.gif?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Prim&#39;s Algorithm&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Kruskal&#39;s Algorithm&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Kruskal&#39;s Algorithm&lt;/em&gt; is also a greedy algorithm that finds a minimum spanning tree in a graph. However, in Kruskal&#39;s, the graph does not have to be connected&lt;/li&gt; &#xA; &lt;li&gt;Time Complexity: &lt;code&gt;O(|E|log|V|)&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/kruskal.gif?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Kruskal&#39;s Algorithm&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Greedy Algorithms&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Greedy Algorithms&lt;/em&gt; are algorithms that make locally optimal choices at each step in the hope of eventually reaching the globally optimal solution&lt;/li&gt; &#xA; &lt;li&gt;Problems must exhibit two properties in order to implement a Greedy solution:&lt;/li&gt; &#xA; &lt;li&gt;Optimal Substructure &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An optimal solution to the problem contains optimal solutions to the given problem&#39;s subproblems&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;The Greedy Property &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An optimal solution is reached by &#34;greedily&#34; choosing the locally optimal choice without ever reconsidering previous choices&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Example - Coin Change &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Given a target amount V cents and a list of denominations of n coins, i.e. we have coinValue[i] (in cents) for coin types i from [0...n - 1], what is the minimum number of coins that we must use to represent amount V? Assume that we have an unlimited supply of coins of any type&lt;/li&gt; &#xA;   &lt;li&gt;Coins - Penny (1 cent), Nickel (5 cents), Dime (10 cents), Quarter (25 cents)&lt;/li&gt; &#xA;   &lt;li&gt;Assume V = 41. We can use the Greedy algorithm of continuously selecting the largest coin denomination less than or equal to V, subtract that coin&#39;s value from V, and repeat.&lt;/li&gt; &#xA;   &lt;li&gt;V = 41 | 0 coins used&lt;/li&gt; &#xA;   &lt;li&gt;V = 16 | 1 coin used (41 - 25 = 16)&lt;/li&gt; &#xA;   &lt;li&gt;V = 6 | 2 coins used (16 - 10 = 6)&lt;/li&gt; &#xA;   &lt;li&gt;V = 1 | 3 coins used (6 - 5 = 1)&lt;/li&gt; &#xA;   &lt;li&gt;V = 0 | 4 coins used (1 - 1 = 0)&lt;/li&gt; &#xA;   &lt;li&gt;Using this algorithm, we arrive at a total of 4 coins which is optimal&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Bitmasks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bitmasking is a technique used to perform operations at the bit level. Leveraging bitmasks often leads to faster runtime complexity and helps limit memory usage&lt;/li&gt; &#xA; &lt;li&gt;Test kth bit: &lt;code&gt;s &amp;amp; (1 &amp;lt;&amp;lt; k);&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Set kth bit: &lt;code&gt;s |= (1 &amp;lt;&amp;lt; k);&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Turn off kth bit: &lt;code&gt;s &amp;amp;= ~(1 &amp;lt;&amp;lt; k);&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Toggle kth bit: &lt;code&gt;s ^= (1 &amp;lt;&amp;lt; k);&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Multiple by 2&lt;sup&gt;n&lt;/sup&gt;: &lt;code&gt;s &amp;lt;&amp;lt; n;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Divide by 2&lt;sup&gt;n&lt;/sup&gt;: &lt;code&gt;s &amp;gt;&amp;gt; n;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Intersection: &lt;code&gt;s &amp;amp; t;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Union: &lt;code&gt;s | t;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Set Subtraction: &lt;code&gt;s &amp;amp; ~t;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Extract lowest set bit: &lt;code&gt;s &amp;amp; (-s);&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Extract lowest unset bit: &lt;code&gt;~s &amp;amp; (s + 1);&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Swap Values: &lt;code&gt;x ^= y; y ^= x; x ^= y;&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Runtime Analysis&lt;/h2&gt; &#xA;&lt;h4&gt;Big O Notation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Big O Notation&lt;/em&gt; is used to describe the upper bound of a particular algorithm. Big O is used to describe worst case scenarios&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/bigO.png?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Theta Notation&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Little O Notation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Little O Notation&lt;/em&gt; is also used to describe an upper bound of a particular algorithm; however, Little O provides a bound that is not asymptotically tight&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Big Ω Omega Notation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Big Omega Notation&lt;/em&gt; is used to provide an asymptotic lower bound on a particular algorithm&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/bigOmega.png?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Theta Notation&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Little ω Omega Notation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Little Omega Notation&lt;/em&gt; is used to provide a lower bound on a particular algorithm that is not asymptotically tight&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Theta Θ Notation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Theta Notation&lt;/em&gt; is used to provide a bound on a particular algorithm such that it can be &#34;sandwiched&#34; between two constants (one for an upper limit and one for a lower limit) for sufficiently large values&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ishan-sinha/DSA-for-SDE-interview/master/images/theta.png?raw=true&#34; alt=&#34;Alt text&#34; title=&#34;Theta Notation&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>