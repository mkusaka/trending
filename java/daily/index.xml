<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Java Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-09T01:30:33Z</updated>
  <subtitle>Daily Trending of Java in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>confluentinc/kafka-rest</title>
    <updated>2024-02-09T01:30:33Z</updated>
    <id>tag:github.com,2024-02-09:/confluentinc/kafka-rest</id>
    <link href="https://github.com/confluentinc/kafka-rest" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Confluent REST Proxy for Kafka&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kafka REST Proxy&lt;/h1&gt; &#xA;&lt;p&gt;The Kafka REST Proxy provides a RESTful interface to a Kafka cluster. It makes it easy to produce and consume data, view the state of the cluster, and perform administrative actions without using the native Kafka protocol or clients. Examples of use cases include reporting data to Kafka from any front-end app built in any language, ingesting data into a stream processing framework that doesn&#39;t yet support Kafka, and scripting administrative actions.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can download prebuilt versions of the Kafka REST Proxy as part of the &lt;a href=&#34;https://www.confluent.io/product/confluent-platform/&#34;&gt;Confluent Platform&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can read our full &lt;a href=&#34;http://docs.confluent.io/current/installation.html#installation&#34;&gt;installation instructions&lt;/a&gt; and the complete &lt;a href=&#34;http://docs.confluent.io/current/kafka-rest/docs/&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To install from source, follow the instructions in the Development section below.&lt;/p&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;p&gt;The Kafka REST Proxy includes a built-in Jetty server and can be deployed after being configured to connect to an existing Kafka cluster.&lt;/p&gt; &#xA;&lt;p&gt;Running &lt;code&gt;mvn clean package&lt;/code&gt; runs all 3 of its assembly targets.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;code&gt;development&lt;/code&gt; target assembles all necessary dependencies in a &lt;code&gt;kafka-rest/target&lt;/code&gt; subfolder without packaging them in a distributable format. The wrapper scripts &lt;code&gt;bin/kafka-rest-start&lt;/code&gt; and &lt;code&gt;bin/kafka-rest-stop&lt;/code&gt; can then be used to start and stop the service.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;package&lt;/code&gt; target is meant to be used in shared dependency environments and omits some dependencies expected to be provided externally. It assembles the other dependencies in a &lt;code&gt;kafka-rest/target&lt;/code&gt; subfolder as well as in distributable archives. The wrapper scripts &lt;code&gt;bin/kafka-rest-start&lt;/code&gt; and &lt;code&gt;bin/kafka-rest-stop&lt;/code&gt; can then be used to start and stop the service.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;standalone&lt;/code&gt; target packages all necessary dependencies as a distributable JAR that can be run as standard (&lt;code&gt;java -jar $base-dir/kafka-rest/target/kafka-rest-X.Y.Z-standalone.jar&lt;/code&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart (v3 API)&lt;/h2&gt; &#xA;&lt;p&gt;The following assumes you have Kafka and an instance of the REST Proxy running using the default settings and some topics already created.&lt;/p&gt; &#xA;&lt;p&gt;The v3 API is the latest version of the API. The cluster ID is a path parameter to enable a REST Proxy to work with multiple Kafka clusters. API responses often contain links to related resources, such as the list of a topic&#39;s partitions. The content type is always &lt;code&gt;application/json&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Get the local cluster information&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl http://localhost:8082/v3/clusters&#xA;&#xA;Response:&#xA;  {&#34;kind&#34;:&#34;KafkaClusterList&#34;,&#xA;   &#34;metadata&#34;:{&#34;self&#34;:&#34;http://localhost:8082/v3/clusters&#34;,&#34;next&#34;:null},&#xA;   &#34;data&#34;:[&#xA;    {&#34;kind&#34;:&#34;KafkaCluster&#34;,&#xA;     &#34;metadata&#34;:{&#34;self&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;     &#34;resource_name&#34;:&#34;crn:///kafka=xFhUvurESIeeCI87SXWR-Q&#34;},&#xA;     &#34;cluster_id&#34;:&#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;     &#34;controller&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/brokers/0&#34;},&#xA;     &#34;acls&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/acls&#34;},&#xA;     &#34;brokers&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/brokers&#34;},&#xA;     &#34;broker_configs&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/broker-configs&#34;},&#xA;     &#34;consumer_groups&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/consumer-groups&#34;},&#xA;     &#34;topics&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics&#34;},&#xA;     &#34;partition_reassignments&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/-/partitions/-/reassignment&#34;}&#xA;    }&#xA;   ]&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The cluster ID in the output is &lt;code&gt;xFhUvurESIeeCI87SXWR-Q&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Get a list of topics&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics&#xA;&#xA;Response:&#xA;  {&#34;kind&#34;:&#34;KafkaTopicList&#34;,&#xA;   &#34;metadata&#34;:{&#34;self&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics&#34;,&#34;next&#34;:null},&#xA;   &#34;data&#34;:[&#xA;    {&#34;kind&#34;:&#34;KafkaTopic&#34;,&#xA;     &#34;metadata&#34;:{&#34;self&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest&#34;,&#xA;     &#34;resource_name&#34;:&#34;crn:///kafka=xFhUvurESIeeCI87SXWR-Q/topic=jsontest&#34;},&#xA;     &#34;cluster_id&#34;:&#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;     &#34;topic_name&#34;:&#34;jsontest&#34;,&#xA;     &#34;is_internal&#34;:false,&#xA;     &#34;replication_factor&#34;:1,&#xA;     &#34;partitions_count&#34;:1,&#xA;     &#34;partitions&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/partitions&#34;},&#xA;     &#34;configs&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/configs&#34;},&#xA;     &#34;partition_reassignments&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/partitions/-/reassignment&#34;}&#xA;    }&#xA;   ]&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Create a topic&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X POST -H &#34;Content-Type:application/json&#34; -d &#39;{&#34;topic_name&#34;:&#34;jsontest&#34;}&#39; \&#xA;       http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics&#xA;&#xA;Response:&#xA;  {&#34;kind&#34;:&#34;KafkaTopic&#34;,&#xA;   &#34;metadata&#34;:{&#34;self&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest&#34;,&#xA;   &#34;resource_name&#34;:&#34;crn:///kafka=xFhUvurESIeeCI87SXWR-Q/topic=jsontest&#34;},&#xA;   &#34;cluster_id&#34;:&#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;   &#34;topic_name&#34;:&#34;jsontest&#34;,&#xA;   &#34;is_internal&#34;:false,&#xA;   &#34;replication_factor&#34;:1,&#xA;   &#34;partitions_count&#34;:1,&#xA;   &#34;partitions&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/partitions&#34;},&#xA;   &#34;configs&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/configs&#34;},&#xA;   &#34;partition_reassignments&#34;:{&#34;related&#34;:&#34;http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/partitions/-/reassignment&#34;}&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Produce records with JSON data&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X POST -H &#34;Content-Type: application/json&#34; \&#xA;       -d &#39;{&#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;data&#34;:{&#34;name&#34;:&#34;testUser&#34;}}}&#39; \&#xA;       http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/records&#xA;&#xA;Response:&#xA;  {&#34;error_code&#34;:200,&#xA;   &#34;cluster_id&#34;:&#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;   &#34;topic_name&#34;:&#34;jsontest&#34;,&#xA;   &#34;partition_id&#34;:0,&#xA;   &#34;offset&#34;:0,&#xA;   &#34;timestamp&#34;:&#34;2023-03-09T14:07:23.592Z&#34;,&#xA;   &#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;size&#34;:19}&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the response, the &lt;code&gt;error_code&lt;/code&gt; of 200 is an HTTP status code (OK) which indicates the operation was successful. Because you can use this API to stream multiple records into a topic as part of the same request, each record produced has its own error code. To send multiple records, simply concatentate the records like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X POST -H &#34;Content-Type: application/json&#34; \&#xA;       -d &#39;{&#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;data&#34;:&#34;ONE&#34;}} {&#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;data&#34;:&#34;TWO&#34;}}&#39; \&#xA;       http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/records&#xA;&#xA;Response:&#xA;  {&#34;error_code&#34;:200,&#xA;   &#34;cluster_id&#34;:&#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;   &#34;topic_name&#34;:&#34;jsontest&#34;,&#xA;   &#34;partition_id&#34;:0,&#xA;   &#34;offset&#34;:1,&#xA;   &#34;timestamp&#34;:&#34;2023-03-09T14:07:23.592Z&#34;,&#xA;   &#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;size&#34;:5}&#xA;  }&#xA;  {&#34;error_code&#34;:200,&#xA;   &#34;cluster_id&#34;:&#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;   &#34;topic_name&#34;:&#34;jsontest&#34;,&#xA;   &#34;partition_id&#34;:0,&#xA;   &#34;offset&#34;:2,&#xA;   &#34;timestamp&#34;:&#34;2023-03-09T14:07:23.592Z&#34;,&#xA;   &#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;size&#34;:5}&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Produce records with string data&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X POST -H &#34;Content-Type: application/json&#34; \&#xA;       -d &#39;{&#34;value&#34;:{&#34;type&#34;:&#34;STRING&#34;,&#34;data&#34;:&#34;REST&#34;}}&#39; \&#xA;       http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/records&#xA;&#xA;Response:&#xA;  {&#34;error_code&#34;:200,&#xA;   &#34;cluster_id&#34;:&#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;   &#34;topic_name&#34;:&#34;jsontest&#34;,&#xA;   &#34;partition_id&#34;:0,&#xA;   &#34;offset&#34;:2,&#xA;   &#34;timestamp&#34;:&#34;2023-03-09T14:07:23.592Z&#34;,&#xA;   &#34;value&#34;:{&#34;type&#34;:&#34;STRING&#34;,&#34;size&#34;:4}&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The data is treated as a string in UTF-8 encoding and follows JSON rules for escaping special characters.&lt;/p&gt; &#xA;&lt;h3&gt;Produce records in a batch&lt;/h3&gt; &#xA;&lt;p&gt;As an alternative to streaming mode, you can produce multiple records in a batch. This is not streaming, but it is easier to use with HTTP libraries that expect a straightforward request-response behavior.&lt;/p&gt; &#xA;&lt;p&gt;Each entry in the batch has a unique identifier (a string of up to 80 characters) which can be used to correlate the responses. The identifiers of the entries in a batch must be unique.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X POST -H &#34;Content-Type: application/json&#34; \&#xA;       -d &#39;{&#34;entries&#34;:[{&#34;id&#34;:&#34;first&#34;,&#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;data&#34;:&#34;ONE&#34;}}, {&#34;id&#34;:&#34;second&#34;,&#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;data&#34;:&#34;TWO&#34;}}]}&#39; \&#xA;       http://localhost:8082/v3/clusters/xFhUvurESIeeCI87SXWR-Q/topics/jsontest/records:batch&#xA;&#xA;Response:&#xA;  {&#34;successes&#34;:[&#xA;    {&#34;id&#34;:&#34;first&#34;,&#xA;     &#34;cluster_id&#34;:&#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;     &#34;topic_name&#34;:&#34;jsontest&#34;,&#xA;     &#34;partition_id&#34;:0,&#xA;     &#34;offset&#34;:3,&#xA;     &#34;timestamp&#34;:&#34;2023-03-09T14:07:23.592Z&#34;,&#xA;     &#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;size&#34;:5}&#xA;    },&#xA;    {&#34;id&#34;:&#34;second&#34;,&#xA;     &#34;cluster_id&#34;:&#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;     &#34;topic_name&#34;:&#34;jsontest&#34;,&#xA;     &#34;partition_id&#34;:0,&#xA;     &#34;offset&#34;:4,&#xA;     &#34;timestamp&#34;:&#34;2023-03-09T14:07:23.592Z&#34;,&#xA;     &#34;value&#34;:{&#34;type&#34;:&#34;JSON&#34;,&#34;size&#34;:5}&#xA;    }&#xA;   ],&#xA;   &#34;failures&#34;:[]&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Successes and failures are returned in the response in separate arrays like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;successes&#34;: [&#xA;    {&#xA;      &#34;id&#34;: &#34;1&#34;,&#xA;      &#34;cluster_id&#34;: &#34;xFhUvurESIeeCI87SXWR-Q&#34;,&#xA;      &#34;topic_name&#34;: &#34;jsontest&#34;,&#xA;      &#34;partition_id&#34;: 0,&#xA;      &#34;offset&#34;: 5,&#xA;      &#34;timestamp&#34;: &#34;2023-03-09T14:07:23.592Z&#34;,&#xA;      &#34;value&#34;: {&#xA;        &#34;type&#34;: &#34;STRING&#34;,&#xA;        &#34;size&#34;: 7&#xA;      }&#xA;    }&#xA;  ],&#xA;  &#34;failures&#34;: [&#xA;    {&#xA;      &#34;id&#34;: &#34;2&#34;,&#xA;      &#34;error_code&#34;: 400,&#xA;      &#34;message&#34;: &#34;Bad Request: data=\&#34;Message$\&#34; is not a valid base64 string.&#34;&#xA;    }&#xA;  ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quickstart (v2 API)&lt;/h2&gt; &#xA;&lt;p&gt;The earlier v2 API is a bit more concise.&lt;/p&gt; &#xA;&lt;h3&gt;Get a list of topics&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl http://localhost:8082/topics&#xA;  &#xA;Response:&#xA;  [&#34;__consumer_offsets&#34;,&#34;jsontest&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Get info about one topic&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl http://localhost:8082/topics/jsontest&#xA;&#xA;Response:&#xA;  {&#34;name&#34;:&#34;jsontest&#34;,&#xA;   &#34;configs&#34;:{},&#xA;   &#34;partitions&#34;:[&#xA;    {&#34;partition&#34;:0,&#xA;     &#34;leader&#34;:0,&#xA;     &#34;replicas&#34;:[&#xA;      {&#34;broker&#34;:0,&#xA;       &#34;leader&#34;:true,&#xA;       &#34;in_sync&#34;:true&#xA;      }&#xA;     ]&#xA;    }&#xA;   ]&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Produce records with JSON data&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X POST -H &#34;Content-Type: application/vnd.kafka.json.v2+json&#34; \&#xA;       -d &#39;{&#34;records&#34;:[{&#34;value&#34;:{&#34;name&#34;: &#34;testUser&#34;}}]}&#39; \&#xA;       http://localhost:8082/topics/jsontest&#xA;&#xA;Response:&#xA;  {&#34;offsets&#34;:[&#xA;    {&#34;partition&#34;:0,&#xA;     &#34;offset&#34;:0,&#xA;     &#34;error_code&#34;:null,&#xA;     &#34;error&#34;:null&#xA;    }&#xA;   ],&#xA;   &#34;key_schema_id&#34;:null,&#xA;   &#34;value_schema_id&#34;:null&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Consume JSON data&lt;/h3&gt; &#xA;&lt;p&gt;First, create a consumer for JSON data, starting at the beginning of the topic. The consumer group is called &lt;code&gt;my_json_consumer&lt;/code&gt; and the instance is &lt;code&gt;my_consumer_instance&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X POST -H &#34;Content-Type: application/vnd.kafka.v2+json&#34; -H &#34;Accept: application/vnd.kafka.v2+json&#34; \&#xA;       -d &#39;{&#34;name&#34;: &#34;my_consumer_instance&#34;, &#34;format&#34;: &#34;json&#34;, &#34;auto.offset.reset&#34;: &#34;earliest&#34;}&#39; \&#xA;       http://localhost:8082/consumers/my_json_consumer&#xA;&#xA;Response:&#xA;  {&#34;instance_id&#34;:&#34;my_consumer_instance&#34;,&#xA;   &#34;base_uri&#34;:&#34;http://localhost:8082/consumers/my_json_consumer/instances/my_consumer_instance&#34;&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Subscribe the consumer to a topic.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X POST -H &#34;Content-Type: application/vnd.kafka.v2+json&#34; \&#xA;       -d &#39;{&#34;topics&#34;:[&#34;jsontest&#34;]}&#39; \&#xA;      http://localhost:8082/consumers/my_json_consumer/instances/my_consumer_instance/subscription&#xA;&#xA;Response:&#xA;  # No content in response&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then consume some data from a topic using the base URL in the first response.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X GET -H &#34;Accept: application/vnd.kafka.json.v2+json&#34; \&#xA;       http://localhost:8082/consumers/my_json_consumer/instances/my_consumer_instance/records&#xA;&#xA;Response:&#xA;  [&#xA;   {&#34;key&#34;:null,&#xA;    &#34;value&#34;:{&#34;name&#34;:&#34;testUser&#34;},&#xA;    &#34;partition&#34;:0,&#xA;    &#34;offset&#34;:0,&#xA;    &#34;topic&#34;:&#34;jsontest&#34;&#xA;   }&#xA;  ]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, close the consumer with a DELETE to make it leave the group and clean up its resources.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -X DELETE -H &#34;Accept: application/vnd.kafka.v2+json&#34; \&#xA;       http://localhost:8082/consumers/my_json_consumer/instances/my_consumer_instance&#xA;&#xA;Response:&#xA;  # No content in response&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;To build a development version, you may need development versions of &lt;a href=&#34;https://github.com/confluentinc/common&#34;&gt;common&lt;/a&gt;, &lt;a href=&#34;https://github.com/confluentinc/rest-utils&#34;&gt;rest-utils&lt;/a&gt;, and &lt;a href=&#34;https://github.com/confluentinc/schema-registry&#34;&gt;schema-registry&lt;/a&gt;. After installing these, you can build the Kafka REST Proxy with Maven. All the standard lifecycle phases work.&lt;/p&gt; &#xA;&lt;p&gt;You can avoid building development versions of dependencies by building on the latest (or earlier) release tag, or &lt;code&gt;&amp;lt;release&amp;gt;-post&lt;/code&gt; branch, which will reference dependencies available pre-built from the &lt;a href=&#34;http://packages.confluent.io/maven/&#34;&gt;public repository&lt;/a&gt;. For example, branch &lt;code&gt;7.3.0-post&lt;/code&gt; can be used as a base for patches for this version.&lt;/p&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Source Code: &lt;a href=&#34;https://github.com/confluentinc/kafka-rest&#34;&gt;https://github.com/confluentinc/kafka-rest&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Issue Tracker: &lt;a href=&#34;https://github.com/confluentinc/kafka-rest/issues&#34;&gt;https://github.com/confluentinc/kafka-rest/issues&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/kafka-rest/master/LICENSE&#34;&gt;Confluent Community License&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>