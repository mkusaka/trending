<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Java Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-05T01:38:20Z</updated>
  <subtitle>Daily Trending of Java in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>epcdiy/timemachineplus</title>
    <updated>2023-07-05T01:38:20Z</updated>
    <id>tag:github.com,2023-07-05:/epcdiy/timemachineplus</id>
    <link href="https://github.com/epcdiy/timemachineplus" rel="alternate"></link>
    <summary type="html">&lt;p&gt;è‹¹æœtimemachineå¤åˆ»ï¼Œè¶…è¶Šï¼Œå¯æ”¯æŒæœ¬åœ°ç£ç›˜æ•°æ®å’Œå±€åŸŸç½‘æ‹‰å–å¤‡ä»½å…¶ä»–ç”µè„‘ï¼Œæ”¯æŒå¤šå¤‡ä»½ç¡¬ç›˜åˆ†å¸ƒå¼å­˜å‚¨ï¼Œjavaå¼€å‘ï¼Œå…¨å¹³å°æ”¯æŒ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;timemachineplus&lt;/h1&gt; &#xA;&lt;p&gt;è‹¹æœtimemachineå¤åˆ»ï¼Œè¶…è¶Šï¼Œå¯æ”¯æŒæœ¬åœ°ç£ç›˜æ•°æ®å’Œå±€åŸŸç½‘æ‹‰å–å¤‡ä»½å…¶ä»–ç”µè„‘ï¼Œæ”¯æŒå¤šå¤‡ä»½ç¡¬ç›˜åˆ†å¸ƒå¼å­˜å‚¨ï¼Œjavaå¼€å‘ï¼Œå…¨å¹³å°æ”¯æŒ&lt;/p&gt; &#xA;&lt;p&gt;è®¸å¯è¯ï¼š&lt;br&gt; æœ¬æºä»£ç è®¸å¯è¯åŸºäº GPL v3. å…·ä½“è§LICENSEæ–‡ä»¶&lt;a href=&#34;https://raw.githubusercontent.com/epcdiy/timemachineplus/main/LICENSE&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;è½¯ä»¶çš„ä»‹ç»è¯·å‚è€ƒæˆ‘Bç«™è§†é¢‘ï¼š&lt;br&gt; &lt;a href=&#34;https://www.bilibili.com/video/BV1Ls4y1c7Wd/&#34;&gt;https://www.bilibili.com/video/BV1Ls4y1c7Wd/&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>HamaWhiteGG/langchain-java</title>
    <updated>2023-07-05T01:38:20Z</updated>
    <id>tag:github.com,2023-07-05:/HamaWhiteGG/langchain-java</id>
    <link href="https://github.com/HamaWhiteGG/langchain-java" rel="alternate"></link>
    <summary type="html">&lt;p&gt;It&#39;s the Java implementation of LangChain, for building applications with LLMs through composability.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸ¦œï¸ LangChain Java&lt;/h1&gt; &#xA;&lt;p&gt;âš¡ Building applications with LLMs through composability âš¡&lt;/p&gt; &#xA;&lt;h2&gt;1. What is this?&lt;/h2&gt; &#xA;&lt;p&gt;This is the Java language implementation of LangChain.&lt;/p&gt; &#xA;&lt;p&gt;Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. But using these LLMs in isolation is often not enough to create a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.&lt;/p&gt; &#xA;&lt;p&gt;This library is aimed at assisting in the development of those types of applications.&lt;/p&gt; &#xA;&lt;p&gt;Looking for the Python version? Check out &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;2. Quickstart Guide&lt;/h2&gt; &#xA;&lt;p&gt;This tutorial gives you a quick walkthrough about building an end-to-end language model application with LangChain.&lt;/p&gt; &#xA;&lt;p&gt;View the &lt;a href=&#34;https://python.langchain.com/en/latest/getting_started/getting_started.html#&#34;&gt;Quickstart Guide&lt;/a&gt; on the LangChain official website.&lt;/p&gt; &#xA;&lt;h3&gt;2.1 Maven Repository&lt;/h3&gt; &#xA;&lt;p&gt;Prerequisites for building:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Java 17 or later&lt;/li&gt; &#xA; &lt;li&gt;Unix-like environment (we use Linux, Mac OS X)&lt;/li&gt; &#xA; &lt;li&gt;Maven (we recommend version 3.8.6 and require at least 3.5.4)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;&#xA;    &amp;lt;groupId&amp;gt;io.github.hamawhitegg&amp;lt;/groupId&amp;gt;&#xA;    &amp;lt;artifactId&amp;gt;langchain-core&amp;lt;/artifactId&amp;gt;&#xA;    &amp;lt;version&amp;gt;0.1.7&amp;lt;/version&amp;gt;&#xA;&amp;lt;/dependency&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2.2 Environment Setup&lt;/h3&gt; &#xA;&lt;p&gt;Using LangChain will usually require integrations with one or more model providers, data stores, apis, etc. For this example, we will be using OpenAIâ€™s APIs.&lt;/p&gt; &#xA;&lt;p&gt;We will then need to set the environment variable.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export OPENAI_API_KEY=xxx&#xA;&#xA;# If a proxy is needed, set the OPENAI_PROXY environment variable.&#xA;export OPENAI_PROXY=http://host:port&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to set the API key and proxy dynamically, you can use the openaiApiKey and openaiProxy parameter when initiating OpenAI class.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;var llm = OpenAI.builder()&#xA;        .openaiApiKey(&#34;xxx&#34;)&#xA;        .openaiProxy(&#34;http://host:port&#34;)&#xA;        .build()&#xA;        .init();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The following test code can be used to view the &lt;a href=&#34;https://raw.githubusercontent.com/HamaWhiteGG/langchain-java/main/langchain-core/src/test/java/com/hw/langchain/QuickStart.java&#34;&gt;QuickStart.java&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;2.3 LLMs: Get predictions from a language model&lt;/h3&gt; &#xA;&lt;p&gt;The most basic building block of LangChain is calling an LLM on some input. Letâ€™s walk through a simple example of how to do this. For this purpose, letâ€™s pretend we are building a service that generates a company name based on what the company makes.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;var llm = OpenAI.builder()&#xA;        .temperature(0.9f)&#xA;        .build()&#xA;        .init();&#xA;&#xA;String text = &#34;What would be a good company name for a company that makes colorful socks?&#34;;&#xA;System.out.println(llm.call(text));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Feetful of Fun&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2.4 Prompt Templates: Manage prompts for LLMs&lt;/h3&gt; &#xA;&lt;p&gt;Calling an LLM is a great first step, but itâ€™s just the beginning. Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you are probably taking user input and constructing a prompt, and then sending that to the LLM.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;var prompt = new PromptTemplate(List.of(&#34;product&#34;),&#xA;        &#34;What is a good name for a company that makes {product}?&#34;);&#xA;&#xA;System.out.println(prompt.format(Map.of(&#34;product&#34;, &#34;colorful socks&#34;)));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;What is a good name for a company that makes colorful socks?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2.5 Chains: Combine LLMs and prompts in multi-step workflows&lt;/h3&gt; &#xA;&lt;p&gt;Up until now, weâ€™ve worked with the PromptTemplate and LLM primitives by themselves. But of course, a real application is not just one primitive, but rather a combination of them.&lt;/p&gt; &#xA;&lt;p&gt;A chain in LangChain is made up of links, which can be either primitives like LLMs or other chains.&lt;/p&gt; &#xA;&lt;h4&gt;2.5.1 LLM Chain&lt;/h4&gt; &#xA;&lt;p&gt;The most core type of chain is an LLMChain, which consists of a PromptTemplate and an LLM.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;var llm = OpenAI.builder()&#xA;        .temperature(0.9f)&#xA;        .build()&#xA;        .init();&#xA;&#xA;var prompt = new PromptTemplate(List.of(&#34;product&#34;),&#xA;        &#34;What is a good name for a company that makes {product}?&#34;);&#xA;&#xA;var chain = new LLMChain(llm, prompt);&#xA;System.out.println(chain.run(&#34;colorful socks&#34;));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;\n\nSocktastic!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2.5.2 SQL Chain&lt;/h4&gt; &#xA;&lt;p&gt;This example demonstrates the use of the SQLDatabaseChain for answering questions over a database.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;var database = SQLDatabase.fromUri(&#34;jdbc:mysql://127.0.0.1:3306/demo&#34;, &#34;xxx&#34;, &#34;xxx&#34;);&#xA;&#xA;var llm = OpenAI.builder()&#xA;        .temperature(0)&#xA;        .build()&#xA;        .init();&#xA;&#xA;var chain = SQLDatabaseChain.fromLLM(llm, database);&#xA;System.out.println(chain.run(&#34;How many students are there?&#34;));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;There are 6 students.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2.6 Agents: Dynamically Call Chains Based on User Input&lt;/h3&gt; &#xA;&lt;p&gt;Agents no longer do: they use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.&lt;/p&gt; &#xA;&lt;p&gt;When used correctly agents can be extremely powerful. In this tutorial, we show you how to easily use agents through the simplest, highest level API.&lt;/p&gt; &#xA;&lt;p&gt;Set the appropriate environment variables.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export SERPAPI_API_KEY=xxx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now we can get started!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;var llm = OpenAI.builder()&#xA;        .temperature(0)&#xA;        .build()&#xA;        .init();&#xA;&#xA;// load some tools to use.&#xA;var tools = loadTools(List.of(&#34;serpapi&#34;, &#34;llm-math&#34;), llm);&#xA;&#xA;// initialize an agent with the tools, the language model, and the type of agent&#xA;var agent = initializeAgent(tools, llm, AgentType.ZERO_SHOT_REACT_DESCRIPTION);&#xA;&#xA;// let&#39;s test it out!&#xA;String text =&#xA;        &#34;What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?&#34;;&#xA;System.out.println(agent.run(text));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;I need to find the temperature first, then use the calculator to raise it to the .023 power.&#xA;&#xA;Action: Search&#xA;Action Input: &#34;High temperature in SF yesterday&#34;&#xA;Observation: San Francisco Weather History for the Previous 24 Hours ; 60 Â°F Â· 60 Â°F Â· 61 Â°F ...&#xA;&#xA;Thought: I now have the temperature, so I can use the calculator to raise it to the .023 power.&#xA;Action: Calculator&#xA;Action Input: 60^.023&#xA;Observation: Answer: 1.09874643447&#xA;&#xA;Thought: I now know the final answer&#xA;Final Answer: 1.09874643447&#xA;&#xA;1.09874643447&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2.7 Memory: Add State to Chains and Agents&lt;/h3&gt; &#xA;&lt;p&gt;So far, all the chains and agents weâ€™ve gone through have been stateless. But often, you may want a chain or agent to have some concept of &#34;memory&#34; so that it may remember information about its previous interactions. The clearest and simple example of this is when designing a chatBot - you want it to remember previous messages so it can use context from that to have a better conversation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;var llm = OpenAI.builder()&#xA;        .temperature(0)&#xA;        .build()&#xA;        .init();&#xA;&#xA;var conversation = new ConversationChain(llm);&#xA;&#xA;var output = conversation.predict(Map.of(&#34;input&#34;, &#34;Hi there!&#34;));&#xA;System.out.println(&#34;Finished chain.\n&#39;&#34; + output + &#34;&#39;&#34;);&#xA;&#xA;output = conversation.predict(Map.of(&#34;input&#34;, &#34;I&#39;m doing well! Just having a conversation with an AI.&#34;));&#xA;System.out.println(&#34;Finished chain.\n&#39;&#34; + output + &#34;&#39;&#34;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.&#xA;&#xA;Current conversation:&#xA;&#xA;Human: Hi there!&#xA;AI:&#xA;Finished chain.&#xA;&#39; Hi there! It&#39;s nice to meet you. How can I help you today?&#39;&#xA;&#xA;The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.&#xA;&#xA;Current conversation:&#xA;Human: Hi there!&#xA;AI:  Hi there! It&#39;s nice to meet you. How can I help you today?&#xA;Human: I&#39;m doing well! Just having a conversation with an AI.&#xA;AI:&#xA;Finished chain.&#xA;&#39; That&#39;s great! It&#39;s always nice to have a conversation with someone new. What would you like to talk about?&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;3. Run Test Cases from Source&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/HamaWhiteGG/langchain-java.git&#xA;cd langchain-java&#xA;&#xA;# export JAVA_HOME=JDK17_INSTALL_HOME &amp;amp;&amp;amp; mvn clean test&#xA;mvn clean test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;4. Apply Spotless&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd langchain-java&#xA;&#xA;# export JAVA_HOME=JDK17_INSTALL_HOME &amp;amp;&amp;amp; mvn spotless:apply&#xA;mvn spotless:apply&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;5. Support&lt;/h2&gt; &#xA;&lt;p&gt;Donâ€™t hesitate to ask!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/HamaWhiteGG/langchain-java/issues&#34;&gt;Open an issue&lt;/a&gt; if you find a bug in Flink.&lt;/p&gt; &#xA;&lt;h2&gt;6. Fork and Contribute&lt;/h2&gt; &#xA;&lt;p&gt;This is an active open-source project. We are always open to people who want to use the system or contribute to it.&lt;/p&gt; &#xA;&lt;p&gt;Contact me if you are looking for implementation tasks that fit your skills.&lt;/p&gt;</summary>
  </entry>
</feed>