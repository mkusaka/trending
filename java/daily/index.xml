<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Java Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-04-15T01:31:56Z</updated>
  <subtitle>Daily Trending of Java in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Audiveris/audiveris</title>
    <updated>2025-04-15T01:31:56Z</updated>
    <id>tag:github.com,2025-04-15:/Audiveris/audiveris</id>
    <link href="https://github.com/Audiveris/audiveris" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Latest generation of Audiveris OMR engine&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/Audiveris/docs/raw/master/images/SplashLogo.png&#34; alt=&#34;&#34;&gt; Logo crafted by &lt;a href=&#34;https://www.facebook.com/katkastreetart/&#34;&gt;Katka&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Audiveris - Open-source Optical Music Recognition&lt;/h1&gt; &#xA;&lt;p&gt;The goal of an OMR application is to allow the end-user to transcribe a score image into its symbolic counterpart. This opens the door to its further use by many kinds of digital processing such as playback, music edition, searching, republishing, etc.&lt;/p&gt; &#xA;&lt;p&gt;The Audiveris application is built around the tight integration of two main components: an OMR engine and an OMR editor.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The OMR engine combines many techniques, depending on the type of entities to be recognized -- &lt;em&gt;ad-hoc&lt;/em&gt; methods for lines, image morphological closing for beams, external OCR for texts, template matching for heads, neural network for all other fixed-size shapes.&lt;br&gt; Significant progresses have been made, especially regarding poor-quality scores, but experience tells us that a 100% recognition ratio is simply out of reach in many cases.&lt;/li&gt; &#xA; &lt;li&gt;The OMR editor thus comes into play to overcome engine weaknesses in convenient ways. The user can preselect processing switches to adapt the OMR engine before launching the transcription of the current score. Then the remaining mistakes can generally be quickly fixed via the manual editing of a few music symbols.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Key characteristics&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Good recognition efficiency on real-world quality scores (as those seen on the &lt;a href=&#34;https://imslp.org/&#34;&gt;IMSLP&lt;/a&gt; site)&lt;/li&gt; &#xA; &lt;li&gt;Effective support for large scores (with up to hundreds of pages)&lt;/li&gt; &#xA; &lt;li&gt;Convenient user-oriented interface to detect and correct most OMR errors&lt;/li&gt; &#xA; &lt;li&gt;Available on Windows, Linux and macOS&lt;/li&gt; &#xA; &lt;li&gt;Open source&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The core of engine music information (OMR data) is fully documented and made publicly available, either directly via XML-based &lt;code&gt;.omr&lt;/code&gt; project files or via the Java API of this software.&lt;br&gt; Audiveris comes with an integrated exporter to write (a subset of) this OMR data into &lt;a href=&#34;http://www.musicxml.com/&#34;&gt;MusicXML&lt;/a&gt; 4.0 format. In the future, other exporters are expected to build upon OMR data to support other target formats.&lt;/p&gt; &#xA;&lt;h2&gt;Stable releases&lt;/h2&gt; &#xA;&lt;p&gt;On a rather regular basis, typically every 6 to 12 months, a new release is made available on the dedicated &lt;a href=&#34;https://github.com/Audiveris/audiveris/releases&#34;&gt;Audiveris Releases&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;p&gt;The goal of a release is to provide significant improvements, well tested and integrated, resulting in a software as easy as possible to install and use.&lt;/p&gt; &#xA;&lt;p&gt;Since the release 5.5, an installer is provided for each of the main OSes (&lt;strong&gt;Windows&lt;/strong&gt;, &lt;strong&gt;Linux&lt;/strong&gt; and &lt;strong&gt;macOS&lt;/strong&gt;) and comes with a pre-installed Java Runtime Environment (JRE). You can download any installer file from the &lt;strong&gt;Assets&lt;/strong&gt; section, at the end of the chosen release:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;OS name&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Installer file extension&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Windows&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;.msi&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Linux&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;.deb&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;macOS&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;.dmg&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Additionally for &lt;strong&gt;Linux&lt;/strong&gt;, a &lt;em&gt;flatpak&lt;/em&gt; package, also with a suitable JRE included, can be installed from the &lt;a href=&#34;https://flathub.org/apps/org.audiveris.audiveris&#34;&gt;Flathub&lt;/a&gt; site.&lt;/p&gt; &#xA;&lt;p&gt;See installers details in the handbook &lt;a href=&#34;https://audiveris.github.io/audiveris/_pages/tutorials/install/binaries/&#34;&gt;installation&lt;/a&gt; section.&lt;/p&gt; &#xA;&lt;h2&gt;Development versions&lt;/h2&gt; &#xA;&lt;p&gt;The Audiveris project is developed on GitHub, the site you are reading.&lt;br&gt; Any one can clone, build and run this software. The needed tools are &lt;code&gt;git&lt;/code&gt;, &lt;code&gt;gradle&lt;/code&gt; and a Java Development Kit (&lt;code&gt;jdk&lt;/code&gt;), as described in the handbook &lt;a href=&#34;https://audiveris.github.io/audiveris/_pages/tutorials/install/sources/&#34;&gt;sources section&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There are two main branches in the Audiveris project:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;the &lt;code&gt;master&lt;/code&gt; branch is the GitHub default branch; we use it for releases, and only for them;&lt;br&gt; To build from this branch, you will need a &lt;code&gt;jdk&lt;/code&gt; for Java version &lt;strong&gt;21&lt;/strong&gt; or higher.&lt;/li&gt; &#xA; &lt;li&gt;the &lt;code&gt;development&lt;/code&gt; branch is the one where all developments continuously take place; Periodically, when a release is to be made, we merge the development branch into the master branch;&lt;br&gt; As of this writing, the source code on development branch requires a &lt;code&gt;jdk&lt;/code&gt; for Java version &lt;strong&gt;21&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See details in the &lt;a href=&#34;https://github.com/Audiveris/audiveris/wiki/Git-Workflow&#34;&gt;Wiki article&lt;/a&gt; dedicated to the chosen development workflow.&lt;/p&gt; &#xA;&lt;h2&gt;Further Information&lt;/h2&gt; &#xA;&lt;p&gt;Users and developers are advised to read the Audiveris &lt;a href=&#34;https://audiveris.github.io/audiveris/&#34;&gt;User Handbook&lt;/a&gt;, and the more general &lt;a href=&#34;https://github.com/Audiveris/audiveris/wiki&#34;&gt;Wiki&lt;/a&gt; set of articles.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>AugmentOS-Community/AugmentOS</title>
    <updated>2025-04-15T01:31:56Z</updated>
    <id>tag:github.com,2025-04-15:/AugmentOS-Community/AugmentOS</id>
    <link href="https://github.com/AugmentOS-Community/AugmentOS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Smart glasses OS, with dozens of built-in apps. Users get AI assistant, notifications, translation, screen mirror, captions, and more. Devs get to write 1 app that runs on any pair of smart glases.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/TeamOpenSmartGlasses/Convoscope&#34; alt=&#34;Contributors&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/TeamOpenSmartGlasses/Convoscope&#34; alt=&#34;License&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/TeamOpenSmartGlasses/Convoscope?style=social&#34; alt=&#34;GitHub Stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/TeamOpenSmartGlasses/Convoscope&#34; alt=&#34;GitHub Release Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/last-commit/TeamOpenSmartGlasses/Convoscope&#34; alt=&#34;Last Updated&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;AugmentOS - smart glasses OS and super app.&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;The open source operating system for your smart glasses. Access the best apps and AI agents on your smart glasses and build new apps and agents:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AugmentOS-Community/AugmentOS/main/images/glasses_banner_TOSG_AugmentOS_Cayden_low_res.jpg&#34; alt=&#34;AugmentOS Smart Glasses&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;AI Assistant&lt;/li&gt; &#xA; &lt;li&gt;Live Captions&lt;/li&gt; &#xA; &lt;li&gt;Merge (Proactive AI)&lt;/li&gt; &#xA; &lt;li&gt;Translation&lt;/li&gt; &#xA; &lt;li&gt;Language Learning&lt;/li&gt; &#xA; &lt;li&gt;ADHD Tools&lt;/li&gt; &#xA; &lt;li&gt;Screen Mirror (Teleprompter, Karaoke/Lyrics, video captions, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;AugmentOS is the &lt;em&gt;the&lt;/em&gt; way to build apps for smart glasses. The &lt;a href=&#34;https://console.augmentos.org&#34;&gt;AugmentOS SDK&lt;/a&gt; enables:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Your app to immediately runs on any pair of smart glasses.&lt;/li&gt; &#xA; &lt;li&gt;Simple + fast dev - focus on building a great experience.&lt;/li&gt; &#xA; &lt;li&gt;Continuously access smart glasses I/O.&lt;/li&gt; &#xA; &lt;li&gt;Run always - run your app for days straight, guaranteed.&lt;/li&gt; &#xA; &lt;li&gt;Get seen - get your app in front of everyone using smart glasses.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;AugmentOS enables you to run multiple apps &lt;em&gt;at the same time&lt;/em&gt; so you can truly take advantage of AI-first wearables apps. Apps that run proactively based on context. That&#39;s the power of a smart glasses operating system.&lt;/p&gt; &#xA;&lt;h2&gt;Apps&lt;/h2&gt; &#xA;&lt;p&gt;Some of the apps running on AugmentOS...&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;strong&gt;&#34;Mira&#34; AI Assistant&lt;/strong&gt; &lt;/summary&gt; &#xA; &lt;p&gt;Smart and fast AI assistant with access to Google search. Say &#34;Hey Mira&#34; and then ask a question/say a command.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&#34;hey Mira, how long is a direct flight from Toronto to Hong Kong?&#34;&lt;/li&gt; &#xA;  &lt;li&gt;&#34;hey Mira, what&#39;s the weather like this weekend in Cambridge?&#34;&lt;/li&gt; &#xA;  &lt;li&gt;&#34;hey Mira, how much does YC invest in each company and what do they take?&#34;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;strong&gt; Screen Mirror &lt;/strong&gt; &lt;/summary&gt; &#xA; &lt;p&gt;Mirror anything on your screen to your smart glasses. We use a lightweight, novel approach, which makes it very fast and makes text easy to read.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;strong&gt;Mentra Merge: Proactive AI Agents&lt;/strong&gt; &lt;/summary&gt; &#xA; &lt;p&gt;Convoscope is a suite of proactive AI agents to augment conversations. Imagine a council of superintelligent assistants listening in to your conversation and helping you solve problems, have new ideas, and better connect with those you&#39;re speaking with&lt;/p&gt; &#xA; &lt;a href=&#34;https://www.youtube.com/watch?v=3n6DzuYQ_v8&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/AugmentOS-Community/AugmentOS/main/images/convoscope_play_video.jpg&#34; alt=&#34;Convoscope Proactive Agents Vision video&#34; width=&#34;340&#34;&gt; &lt;/a&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Someone mention a company you&#39;ve never heard of? A proactice AI agent instantly shows you info on that company&lt;/li&gt; &#xA;  &lt;li&gt;Your friend is suggesting you have a BBQ tomrrow. A proactive AI agent searches tomorrow&#39;s forecast and overlays the rainy forecast on your vision&lt;/li&gt; &#xA;  &lt;li&gt;Groupthink happening? A devil&#39;s advocate agent presents an alternative viewpiont to stimulate thought&lt;/li&gt; &#xA;  &lt;li&gt;Someone makes a shaky claim? A fact checker agent provides a source to back it up or show it&#39;s false&lt;/li&gt; &#xA;  &lt;li&gt;Can&#39;t remember the website your coworker reccomended? Proactive agents review your past conversations and pull up the url.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;strong&gt;Mentra Link: Language Learning&lt;/strong&gt; &lt;/summary&gt; &#xA; &lt;p&gt;Learn a new language 10x faster with smart glasses. Partial translation, AI foreign language conversations, word/phrase suggestions, immersive AR language annotations, and more.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://mentra.glass/&#34;&gt;Mentra Link&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;Artificial Immersion demo video: &lt;a href=&#34;https://www.youtube.com/watch?v=UFBEG1s27uU&#34;&gt;https://www.youtube.com/watch?v=UFBEG1s27uU&lt;/a&gt;&lt;br&gt; TEDxMIT Talk on &#34;Can Smart Glasses Revolutionize How We Learn Languages?&#34; by Cayden Pierce: &lt;a href=&#34;https://www.youtube.com/watch?v=7XuBVY3nVbA&#34;&gt;https://www.youtube.com/watch?v=7XuBVY3nVbA&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/AugmentOS-Community/AugmentOS/main/images/LLSG_demo_picture.png&#34; alt=&#34;Mentra Link Language Learning&#34; width=&#34;340&#34;&gt; &lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;strong&gt;Live Captions&lt;/strong&gt; &lt;/summary&gt; &#xA; &lt;p&gt;See live captions of everything that is said. 100s of languages supported with high accuracy and low latency.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;strong&gt;ADHD Glasses&lt;/strong&gt; &lt;/summary&gt; &#xA; &lt;p&gt;A 10 minute short term memory buffer to help get back on track during conversations after a zone-out.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;strong&gt;Live Language Translation&lt;/strong&gt; &lt;/summary&gt; &#xA; &lt;p&gt;Live translate languages - when someone speaks a foreign language, instantly see it translated on your vision. Supports 100s of language.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h4&gt;More Coming&lt;/h4&gt; &#xA;&lt;p&gt;The community is working on many more apps - fully open source - join us and help build! &lt;a href=&#34;https://docs.google.com/document/d/1XK4TE6hDRa2ut0WBpMQGcNLS6icWj6DJCLP49Fldz2E/edit?usp=sharing&#34;&gt;Check out our roadmap here!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Dev Guide + Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Developer Console: &lt;a href=&#34;https://console.AugmentOS.org&#34;&gt;https://console.AugmentOS.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;SDK Documentation: &lt;a href=&#34;https://docs.AugmentOS.org&#34;&gt;https://docs.AugmentOS.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;AugmentOS Example App: &lt;a href=&#34;https://github.com/AugmentOS-Community/AugmentOS-Cloud-Example-App&#34;&gt;https://github.com/AugmentOS-Community/AugmentOS-Cloud-Example-App&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Required Hardware&lt;/h2&gt; &#xA;&lt;h3&gt;Glasses&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://augmentos.org/glasses&#34;&gt;Supported glasses list&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Smart Phones&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://AugmentOS.org/install&#34;&gt;Install Now&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Authors / Team&lt;/h2&gt; &#xA;&lt;p&gt;AugmentOS is made by a decentralized community of contributors, and managed by &lt;a href=&#34;https://mentra.glass&#34;&gt;Mentra&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Lead Dev Team&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cayden Pierce&lt;/li&gt; &#xA; &lt;li&gt;Alex Israelov&lt;/li&gt; &#xA; &lt;li&gt;Nicolo Micheletti&lt;/li&gt; &#xA; &lt;li&gt;Isaiah Ballah&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Contributions welcome! Our team is growing and we have a lot to do! Join our Discord and reach out!&lt;/p&gt; &#xA;&lt;h2&gt;AugmentOS Community&lt;/h2&gt; &#xA;&lt;p&gt;The AugmentOS Community is a team building open-source smart glasses tech towards an open, self-empowered, intercognitive, augmented future. Our industry partners include companies like Vuzix, Activelook, TCL, and others. To get involved, check out &lt;a href=&#34;https://augmentos.org&#34;&gt;our website&lt;/a&gt; and join our &lt;a href=&#34;https://discord.gg/bAKsjh8CtE&#34;&gt;Discord server&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT License Copyright 2025 AugmentOS Community&lt;/p&gt;</summary>
  </entry>
</feed>