<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Java Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-15T01:33:28Z</updated>
  <subtitle>Daily Trending of Java in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>provectus/kafka-ui</title>
    <updated>2022-12-15T01:33:28Z</updated>
    <id>tag:github.com,2022-12-15:/provectus/kafka-ui</id>
    <link href="https://github.com/provectus/kafka-ui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open-Source Web UI for Apache Kafka Management&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;&lt;img src=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/images/kafka-ui-logo.png&#34; alt=&#34;UI for Apache Kafka logo&#34;&gt; UI for Apache Kafka&amp;nbsp;&lt;/h2&gt; &#xA;&lt;h4&gt;Versatile, fast and lightweight web UI for managing Apache Kafka® clusters. Built by developers, for developers.&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/provectus/kafka-ui/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/images/free-open-source.svg?sanitize=true&#34; alt=&#34;UI for Apache Kafka Price Free&#34;&gt; &lt;a href=&#34;https://github.com/provectus/kafka-ui/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/provectus/kafka-ui&#34; alt=&#34;Release version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/4DWzD7pGE5&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/897805035122077716&#34; alt=&#34;Chat with us&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;DISCLAIMER&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;UI for Apache Kafka is a free tool built and supported by the open-source community. Curated by Provectus, it will remain free and open-source, without any paid features or subscription plans to be added in the future. Looking for the help of Kafka experts? Provectus can help you design, build, deploy, and manage Apache Kafka clusters and streaming applications. Discover &lt;a href=&#34;https://provectus.com/professional-services-apache-kafka/&#34;&gt;Professional Services for Apache Kafka&lt;/a&gt;, to unlock the full potential of Kafka in your enterprise! &lt;/em&gt;&lt;/p&gt; &#xA;&lt;h4&gt;UI for Apache Kafka is a free, open-source web UI to monitor and manage Apache Kafka clusters.&lt;/h4&gt; &#xA;&lt;p&gt;UI for Apache Kafka is a simple tool that makes your data flows observable, helps find and troubleshoot issues faster and deliver optimal performance. Its lightweight dashboard makes it easy to track key metrics of your Kafka clusters - Brokers, Topics, Partitions, Production, and Consumption.&lt;/p&gt; &#xA;&lt;p&gt;Set up UI for Apache Kafka with just a couple of easy commands to visualize your Kafka data in a comprehensible way. You can run the tool locally or in the cloud.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/images/Interface.gif&#34; alt=&#34;Interface&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-Cluster Management&lt;/strong&gt; — monitor and manage all your clusters in one place&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Performance Monitoring with Metrics Dashboard&lt;/strong&gt; — track key Kafka metrics with a lightweight dashboard&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;View Kafka Brokers&lt;/strong&gt; — view topic and partition assignments, controller status&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;View Kafka Topics&lt;/strong&gt; — view partition count, replication status, and custom configuration&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;View Consumer Groups&lt;/strong&gt; — view per-partition parked offsets, combined and per-partition lag&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Browse Messages&lt;/strong&gt; — browse messages with JSON, plain text, and Avro encoding&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Dynamic Topic Configuration&lt;/strong&gt; — create and configure new topics with dynamic configuration&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Configurable Authentification&lt;/strong&gt; — secure your installation with optional Github/Gitlab/Google OAuth 2.0&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Custom serialization/deserialization plugins&lt;/strong&gt; - use a ready-to-go serde for your data like AWS Glue or Smile, or code your own!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;The Interface&lt;/h1&gt; &#xA;&lt;p&gt;UI for Apache Kafka wraps major functions of Apache Kafka with an intuitive user interface.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/images/Interface.gif&#34; alt=&#34;Interface&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Topics&lt;/h2&gt; &#xA;&lt;p&gt;UI for Apache Kafka makes it easy for you to create topics in your browser by several clicks, pasting your own parameters, and viewing topics in the list.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/images/Create_topic_kafka-ui.gif&#34; alt=&#34;Create Topic&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s possible to jump from connectors view to corresponding topics and from a topic to consumers (back and forth) for more convenient navigation. connectors, overview topic settings.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/images/Connector_Topic_Consumer.gif&#34; alt=&#34;Connector_Topic_Consumer&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Messages&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s say we want to produce messages for our topic. With the UI for Apache Kafka we can send or write data/messages to the Kafka topics without effort by specifying parameters, and viewing messages in the list.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/images/Create_message_kafka-ui.gif&#34; alt=&#34;Produce Message&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Schema registry&lt;/h2&gt; &#xA;&lt;p&gt;There are 3 supported types of schemas: Avro®, JSON Schema, and Protobuf schemas.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/images/Create_schema.gif&#34; alt=&#34;Create Schema Registry&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Before producing avro-encoded messages, you have to add an avro schema for the topic in Schema Registry. Now all these steps are easy to do with a few clicks in a user-friendly interface.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/images/Schema_Topic.gif&#34; alt=&#34;Avro Schema Topic&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;p&gt;To run UI for Apache Kafka, you can use a pre-built Docker image or build it locally.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;We have plenty of &lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/compose/DOCKER_COMPOSE.md&#34;&gt;docker-compose files&lt;/a&gt; as examples. They&#39;re built for various configuration stacks.&lt;/p&gt; &#xA;&lt;h1&gt;Guides&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/guides/SSO.md&#34;&gt;SSO configuration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/guides/AWS_IAM.md&#34;&gt;AWS IAM configuration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/compose/DOCKER_COMPOSE.md&#34;&gt;Docker-compose files&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/guides/SECURE_BROKER.md&#34;&gt;Connection to a secure broker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/guides/Serialization.md&#34;&gt;Configure seriliazation/deserialization plugins or code your own&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Configuration File&lt;/h3&gt; &#xA;&lt;p&gt;Example of how to configure clusters in the &lt;a href=&#34;https://github.com/provectus/kafka-ui/raw/master/kafka-ui-api/src/main/resources/application-local.yml&#34;&gt;application-local.yml&lt;/a&gt; configuration file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;kafka:&#xA;  clusters:&#xA;    -&#xA;      name: local&#xA;      bootstrapServers: localhost:29091&#xA;      schemaRegistry: http://localhost:8085&#xA;      schemaRegistryAuth:&#xA;        username: username&#xA;        password: password&#xA;#     schemaNameTemplate: &#34;%s-value&#34;&#xA;      metrics:&#xA;        port: 9997&#xA;        type: JMX&#xA;    -&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;name&lt;/code&gt;: cluster name&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;bootstrapServers&lt;/code&gt;: where to connect&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;schemaRegistry&lt;/code&gt;: schemaRegistry&#39;s address&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;schemaRegistryAuth.username&lt;/code&gt;: schemaRegistry&#39;s basic authentication username&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;schemaRegistryAuth.password&lt;/code&gt;: schemaRegistry&#39;s basic authentication password&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;schemaNameTemplate&lt;/code&gt;: how keys are saved to schemaRegistry&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;metrics.port&lt;/code&gt;: open JMX port of a broker&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;metrics.type&lt;/code&gt;: Type of metrics, either JMX or PROMETHEUS. Defaulted to JMX.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;readOnly&lt;/code&gt;: enable read only mode&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Configure as many clusters as you need by adding their configs below separated with &lt;code&gt;-&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Running a Docker Image&lt;/h2&gt; &#xA;&lt;p&gt;The official Docker image for UI for Apache Kafka is hosted here: &lt;a href=&#34;https://hub.docker.com/r/provectuslabs/kafka-ui&#34;&gt;hub.docker.com/r/provectuslabs/kafka-ui&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Launch Docker container in the background:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;&#xA;docker run -p 8080:8080 \&#xA;&#x9;-e KAFKA_CLUSTERS_0_NAME=local \&#xA;&#x9;-e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092 \&#xA;&#x9;-d provectuslabs/kafka-ui:latest&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then access the web UI at &lt;a href=&#34;http://localhost:8080&#34;&gt;http://localhost:8080&lt;/a&gt;. Further configuration with environment variables - &lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/#env_variables&#34;&gt;see environment variables&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Docker Compose&lt;/h3&gt; &#xA;&lt;p&gt;If you prefer to use &lt;code&gt;docker-compose&lt;/code&gt; please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/docker-compose.md&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Helm chart&lt;/h3&gt; &#xA;&lt;p&gt;Helm chart could be found under &lt;a href=&#34;https://github.com/provectus/kafka-ui/tree/master/charts/kafka-ui&#34;&gt;charts/kafka-ui&lt;/a&gt; directory&lt;/p&gt; &#xA;&lt;p&gt;Quick-start instruction &lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/helm_chart.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Building With Docker&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;Check &lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/project/contributing/prerequisites.md&#34;&gt;prerequisites.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Building and Running&lt;/h3&gt; &#xA;&lt;p&gt;Check &lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/project/contributing/building.md&#34;&gt;building.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Building Without Docker&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/project/contributing/prerequisites.md&#34;&gt;Prerequisites&lt;/a&gt; will mostly remain the same with the exception of docker.&lt;/p&gt; &#xA;&lt;h3&gt;Running without Building&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/project/contributing/building-and-running-without-docker.md#run_without_docker_quickly&#34;&gt;How to run quickly without building&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Building and Running&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/provectus/kafka-ui/master/documentation/project/contributing/building-and-running-without-docker.md#build_and_run_without_docker&#34;&gt;How to build and run&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Liveliness and readiness probes&lt;/h2&gt; &#xA;&lt;p&gt;Liveliness and readiness endpoint is at &lt;code&gt;/actuator/health&lt;/code&gt;. Info endpoint (build info) is located at &lt;code&gt;/actuator/info&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;env_variables&#34;&gt;&lt;/a&gt; Environment Variables&lt;/h2&gt; &#xA;&lt;p&gt;Alternatively, each variable of the .yml file can be set with an environment variable. For example, if you want to use an environment variable to set the &lt;code&gt;name&lt;/code&gt; parameter, you can write it like this: &lt;code&gt;KAFKA_CLUSTERS_2_NAME&lt;/code&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;SERVER_SERVLET_CONTEXT_PATH&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;URI basePath&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;LOGGING_LEVEL_ROOT&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Setting log level (trace, debug, info, warn, error). Default: info&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;LOGGING_LEVEL_COM_PROVECTUS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Setting log level (trace, debug, info, warn, error). Default: debug&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;SERVER_PORT&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Port for the embedded server. Default: &lt;code&gt;8080&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_ADMIN-CLIENT-TIMEOUT&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Kafka API timeout in ms. Default: &lt;code&gt;30000&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_NAME&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Cluster name&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Address where to connect&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KSQLDBSERVER&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;KSQL DB server address&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KSQLDBSERVERAUTH_USERNAME&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;KSQL DB server&#39;s basic authentication username&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KSQLDBSERVERAUTH_PASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;KSQL DB server&#39;s basic authentication password&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KSQLDBSERVERSSL_KEYSTORELOCATION&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Path to the JKS keystore to communicate to KSQL DB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KSQLDBSERVERSSL_KEYSTOREPASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Password of the JKS keystore for KSQL DB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KSQLDBSERVERSSL_TRUSTSTORELOCATION&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Path to the JKS truststore to communicate to KSQL DB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KSQLDBSERVERSSL_TRUSTSTOREPASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Password of the JKS truststore for KSQL DB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Security protocol to connect to the brokers. For SSL connection use &#34;SSL&#34;, for plaintext connection don&#39;t set this environment variable&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_SCHEMAREGISTRY&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;SchemaRegistry&#39;s address&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_SCHEMAREGISTRYAUTH_USERNAME&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;SchemaRegistry&#39;s basic authentication username&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_SCHEMAREGISTRYAUTH_PASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;SchemaRegistry&#39;s basic authentication password&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_SCHEMAREGISTRYSSL_KEYSTORELOCATION&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Path to the JKS keystore to communicate to SchemaRegistry&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_SCHEMAREGISTRYSSL_KEYSTOREPASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Password of the JKS keystore for SchemaRegistry&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_SCHEMAREGISTRYSSL_TRUSTSTORELOCATION&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Path to the JKS truststore to communicate to SchemaRegistry&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_SCHEMAREGISTRYSSL_TRUSTSTOREPASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Password of the JKS truststore for SchemaRegistry&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_SCHEMANAMETEMPLATE&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;How keys are saved to schemaRegistry&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_METRICS_PORT&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Open metrics port of a broker&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_METRICS_TYPE&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Type of metrics retriever to use. Valid values are JMX (default) or PROMETHEUS. If Prometheus, then metrics are read from prometheus-jmx-exporter instead of jmx&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_READONLY&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Enable read-only mode. Default: false&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_DISABLELOGDIRSCOLLECTION&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Disable collecting segments information. It should be true for confluent cloud. Default: false&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Given name for the Kafka Connect cluster&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Address of the Kafka Connect service endpoint&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KAFKACONNECT_0_USERNAME&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Kafka Connect cluster&#39;s basic authentication username&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KAFKACONNECT_0_PASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Kafka Connect cluster&#39;s basic authentication password&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KAFKACONNECT_0_KEYSTORELOCATION&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Path to the JKS keystore to communicate to Kafka Connect&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KAFKACONNECT_0_KEYSTOREPASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Password of the JKS keystore for Kafka Connect&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KAFKACONNECT_0_TRUSTSTORELOCATION&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Path to the JKS truststore to communicate to Kafka Connect&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_KAFKACONNECT_0_TRUSTSTOREPASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Password of the JKS truststore for Kafka Connect&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_METRICS_SSL&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Enable SSL for Metrics? &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt;. For advanced setup, see &lt;code&gt;kafka-ui-jmx-secured.yml&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_METRICS_USERNAME&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Username for Metrics authentication&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_METRICS_PASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Password for Metrics authentication&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;KAFKA_CLUSTERS_0_POLLING_THROTTLE_RATE&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Max traffic rate (bytes/sec) that kafka-ui allowed to reach when polling messages from the cluster. Default: 0 (not limited)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;TOPIC_RECREATE_DELAY_SECONDS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Time delay between topic deletion and topic creation attempts for topic recreate functionality. Default: 1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;TOPIC_RECREATE_MAXRETRIES&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Number of attempts of topic creation after topic deletion for topic recreate functionality. Default: 15&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>spring-projects/spring-batch</title>
    <updated>2022-12-15T01:33:28Z</updated>
    <id>tag:github.com,2022-12-15:/spring-projects/spring-batch</id>
    <link href="https://github.com/spring-projects/spring-batch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Spring Batch is a framework for writing offline and batch applications using Spring and Java&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Spring Batch &lt;a href=&#34;https://build.spring.io/browse/BATCH-MCI&#34;&gt;&lt;img src=&#34;https://build.spring.io/plugins/servlet/wittified/build-status/BATCH-MCI&#34; alt=&#34;build status&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Spring Batch is a lightweight, comprehensive batch framework designed to enable the development of robust batch applications vital for the daily operations of enterprise systems. Spring Batch builds upon the productivity, POJO-based development approach, and general ease of use capabilities people have come to know from the &lt;a href=&#34;https://github.com/spring-projects/spring-framework&#34;&gt;Spring Framework&lt;/a&gt;, while making it easy for developers to access and leverage more advanced enterprise services when necessary.&lt;/p&gt; &#xA;&lt;p&gt;If you are looking for a runtime orchestration tool for your Batch applications, or need a management console to view current and historic executions, take a look at &lt;a href=&#34;https://cloud.spring.io/spring-cloud-dataflow/&#34;&gt;Spring Cloud Data Flow&lt;/a&gt;. It is an orchestration tool for deploying and executing data integration based microservices including Spring Batch applications.&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;Please see our &lt;a href=&#34;https://github.com/spring-projects/.github/raw/main/CODE_OF_CONDUCT.md&#34;&gt;code of conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Reporting Security Vulnerabilities&lt;/h2&gt; &#xA;&lt;p&gt;Please see our &lt;a href=&#34;https://github.com/spring-projects/spring-batch/security/policy&#34;&gt;Security policy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Building from Source&lt;/h1&gt; &#xA;&lt;p&gt;Clone the git repository using the URL on the Github home page:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone git@github.com:spring-projects/spring-batch.git&#xA;$ cd spring-batch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Command Line&lt;/h2&gt; &#xA;&lt;p&gt;Maven is the build tool used for Spring Batch. You can build the project with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./mvnw package&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to perform a full build with all integration tests, then run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./mvnw verify&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please note that some integration tests are based on Docker, so please make sure to have Docker up and running before running a full build.&lt;/p&gt; &#xA;&lt;p&gt;To generate the reference documentation, run the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./mvnw javadoc:aggregate&#xA;$ cd spring-batch-docs&#xA;$ ../mvnw site&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The reference documentation can be found in &lt;code&gt;spring-batch-docs/target&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Spring Tool Suite (STS)&lt;/h2&gt; &#xA;&lt;p&gt;In STS (or any Eclipse distro or other IDE with Maven support), import the module directories as existing projects. They should compile and the tests should run with no additional steps.&lt;/p&gt; &#xA;&lt;h2&gt;Using Docker&lt;/h2&gt; &#xA;&lt;p&gt;If you want to build the project in a Docker container, you can proceed as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$&amp;gt; docker run -it --mount type=bind,source=&#34;$(pwd)&#34;,target=/spring-batch maven:3-openjdk-17 bash&#xA;#&amp;gt; cd spring-batch&#xA;#&amp;gt; ./mvnw package&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will mount the source code that you cloned previously on the host inside the container. If you want to work on a copy of the source code inside the container (no side effects on the host), you can proceed as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$&amp;gt; docker run -it maven:3-openjdk-17 bash&#xA;#&amp;gt; git clone https://github.com/spring-projects/spring-batch.git&#xA;#&amp;gt; cd spring-batch&#xA;#&amp;gt; ./mvnw package&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Getting Started Using Spring Boot&lt;/h1&gt; &#xA;&lt;p&gt;This is the quickest way to get started with a new Spring Batch project. You find the Getting Started Guide for Spring Batch on Spring.io: &lt;a href=&#34;https://spring.io/guides/gs/batch-processing/&#34;&gt;Creating a Batch Service&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Getting Started Using Spring Tool Suite (STS)&lt;/h1&gt; &#xA;&lt;p&gt;It requires an internet connection for download, and access to a Maven repository (remote or local).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download STS version 3.4.* (or better) from the &lt;a href=&#34;https://spring.io/tools&#34;&gt;Spring website&lt;/a&gt;. STS is a free Eclipse bundle with many features useful for Spring developers.&lt;/li&gt; &#xA; &lt;li&gt;Go to &lt;code&gt;File-&amp;gt;New-&amp;gt;Spring Template Project&lt;/code&gt; from the menu bar (in the Spring perspective).&lt;/li&gt; &#xA; &lt;li&gt;The wizard has a drop down with a list of template projects. One of them is a &#34;Simple Spring Batch Project&#34;. Select it and follow the wizard.&lt;/li&gt; &#xA; &lt;li&gt;A project is created with all dependencies and a simple input/output job configuration. It can be run using a unit test, or on the command line (see instructions in the pom.xml).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Getting Help&lt;/h1&gt; &#xA;&lt;p&gt;Read the main project &lt;a href=&#34;https://projects.spring.io/spring-batch/&#34;&gt;website&lt;/a&gt; and the &lt;a href=&#34;https://docs.spring.io/spring-batch/docs/current/reference/&#34;&gt;User Guide&lt;/a&gt;. Look at the source code and the Javadocs. For more detailed questions, use &lt;a href=&#34;https://stackoverflow.com/questions/tagged/spring-batch&#34;&gt;StackOverflow&lt;/a&gt;. If you are new to Spring as well as to Spring Batch, look for information about &lt;a href=&#34;https://spring.io/projects&#34;&gt;Spring projects&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Contributing to Spring Batch&lt;/h1&gt; &#xA;&lt;p&gt;Here are some ways for you to get involved in the community:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Get involved with the Spring Batch community on &lt;a href=&#34;https://twitter.com/springbatch&#34;&gt;Twitter&lt;/a&gt; and &lt;a href=&#34;https://stackoverflow.com/questions/tagged/spring-batch&#34;&gt;StackOverflow&lt;/a&gt; by responding to questions and joining the debate.&lt;/li&gt; &#xA; &lt;li&gt;Create &lt;a href=&#34;https://github.com/spring-projects/spring-batch/issues&#34;&gt;issues&lt;/a&gt; for bugs and new features and comment and vote on the ones that you are interested in.&lt;/li&gt; &#xA; &lt;li&gt;Github is for social coding: if you want to write code, we encourage contributions through pull requests from &lt;a href=&#34;https://help.github.com/forking/&#34;&gt;forks of this repository&lt;/a&gt;. If you want to contribute code this way, please familiarize yourself with the process outlined for contributing to Spring projects here: &lt;a href=&#34;https://github.com/spring-projects/spring-batch/raw/main/CONTRIBUTING.md&#34;&gt;Contributor Guidelines&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Watch for upcoming articles on Spring by &lt;a href=&#34;feed://assets.spring.io/drupal/node/feed.xml&#34;&gt;subscribing&lt;/a&gt; to &lt;a href=&#34;https://spring.io&#34;&gt;spring.io&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Before we accept a non-trivial patch or pull request we will need you to sign the &lt;a href=&#34;https://support.springsource.com/spring_committer_signup&#34;&gt;contributor&#39;s agreement&lt;/a&gt;. Signing the contributor&#39;s agreement does not grant anyone commit rights to the main repository, but it does mean that we can accept your contributions, and you will get an author credit if we do. Active contributors might be asked to join the core team, and given the ability to merge pull requests.&lt;/p&gt;</summary>
  </entry>
</feed>