<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Java Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-31T01:33:01Z</updated>
  <subtitle>Daily Trending of Java in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>apache/incubator-amoro</title>
    <updated>2024-03-31T01:33:01Z</updated>
    <id>tag:github.com,2024-03-31:/apache/incubator-amoro</id>
    <link href="https://github.com/apache/incubator-amoro" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache Amoro (incubating) is a Lakehouse management system built on open data lake formats.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://amoro.netease.com/img/amoro-logo.svg?sanitize=true&#34; alt=&#34;Amoro logo&#34; height=&#34;120px&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-4EB1BA.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/NetEase/amoro/actions/workflows/core-hadoop3-ci.yml&#34;&gt; &lt;img src=&#34;https://github.com/NetEase/amoro/actions/workflows/core-hadoop3-ci.yml/badge.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/NetEase/amoro/actions/workflows/core-hadoop2-ci.yml&#34;&gt; &lt;img src=&#34;https://github.com/NetEase/amoro/actions/workflows/core-hadoop2-ci.yml/badge.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/NetEase/amoro/actions/workflows/trino-ci.yml&#34;&gt; &lt;img src=&#34;https://github.com/NetEase/amoro/actions/workflows/trino-ci.yml/badge.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;Amoro(former name was Arctic) is a Lakehouse management system built on open data lake formats. Working with compute engines including Flink, Spark, and Trino, Amoro brings pluggable and self-managed features for Lakehouse to provide out-of-the-box data warehouse experience, and helps data platforms or products easily build infra-decoupled, stream-and-batch-fused and lake-native architecture.&lt;/p&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;Here is the architecture diagram of Amoro:&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://amoro.netease.com//img/home-content.png&#34; alt=&#34;Amoro architecture&#34; height=&#34;360px&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;AMS: Amoro Management Service provides Lakehouse management features, like self-optimizing, data expiration, etc. It also provides a unified catalog service for all compute engines, which can also be combined with existing metadata services.&lt;/li&gt; &#xA; &lt;li&gt;Plugins: Amoro provides a wide selection of external plugins to meet different scenarios. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Optimizers: The self-optimizing execution engine plugin asynchronously performs merging, sorting, deduplication, layout optimization, and other operations on all type table format tables.&lt;/li&gt; &#xA;   &lt;li&gt;Terminal: SQL command-line tools, provide various implementations like local Spark and Kyuubi.&lt;/li&gt; &#xA;   &lt;li&gt;LogStore: Provide millisecond to second level SLAs for real-time data processing based on message queues like Kafka and Pulsar.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Supported table formats&lt;/h2&gt; &#xA;&lt;p&gt;Amoro can manage tables of different table formats, similar to how MySQL/ClickHouse can choose different storage engines. Amoro meets diverse user needs by using different table formats. Currently, Amoro supports four table formats:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Iceberg format: Users can directly entrust their Iceberg tables to Amoro for maintenance, so that users can not only use all the functions of Iceberg tables, but also enjoy the performance and stability improvements brought by Amoro.&lt;/li&gt; &#xA; &lt;li&gt;Mixed-Iceberg format: Amoro provides a set of more optimized formats for streaming update scenarios on top of the Iceberg format. If users have high performance requirements for streaming updates or have demands for CDC incremental data reading functions, they can choose to use the Mixed-Iceberg format.&lt;/li&gt; &#xA; &lt;li&gt;Mixed-Hive format: Many users do not want to affect the business originally built on Hive while using data lakes. Therefore, Amoro provides the Mixed-Hive format, which can upgrade Hive tables to Mixed-Hive format only through metadata migration, and the original Hive tables can still be used normally. This ensures business stability and benefits from the advantages of data lake computing.&lt;/li&gt; &#xA; &lt;li&gt;Paimon format: Amoro supports displaying metadata information in the Paimon format, including Schema, Options, Files, Snapshots, DDLs, and Compaction information.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Supported engines&lt;/h2&gt; &#xA;&lt;h3&gt;Iceberg format&lt;/h3&gt; &#xA;&lt;p&gt;Iceberg format tables use the engine integration method provided by the Iceberg community. For details, please refer to: &lt;a href=&#34;https://iceberg.apache.org/docs/latest/&#34;&gt;Iceberg Docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Mixed format&lt;/h3&gt; &#xA;&lt;p&gt;Amoro support multiple processing engines for Mixed format as below:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Processing Engine&lt;/th&gt; &#xA;   &lt;th&gt;Version&lt;/th&gt; &#xA;   &lt;th&gt;Batch Read&lt;/th&gt; &#xA;   &lt;th&gt;Batch Write&lt;/th&gt; &#xA;   &lt;th&gt;Batch Overwrite&lt;/th&gt; &#xA;   &lt;th&gt;Streaming Read&lt;/th&gt; &#xA;   &lt;th&gt;Streaming Write&lt;/th&gt; &#xA;   &lt;th&gt;Create Table&lt;/th&gt; &#xA;   &lt;th&gt;Alter Table&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Flink&lt;/td&gt; &#xA;   &lt;td&gt;1.15.x, 1.16.x, 1.17.x&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Spark&lt;/td&gt; &#xA;   &lt;td&gt;3.1, 3.2, 3.3&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Hive&lt;/td&gt; &#xA;   &lt;td&gt;2.x, 3.x&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Trino&lt;/td&gt; &#xA;   &lt;td&gt;406&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✖&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Self-optimizing - Continuously optimizing tables, including compacting small files, change files, regularly delete expired files to keep high query performance and reducing storage costs.&lt;/li&gt; &#xA; &lt;li&gt;Multiple Formats - Support different table formats such as Iceberg, Mixed-Iceberg and Mixed-Hive to meet different scenario requirements and provide them with unified management capabilities.&lt;/li&gt; &#xA; &lt;li&gt;Catalog Service - Provide a unified catalog service for all compute engines, which can also used with existing metadata store service such as Hive Metastore and AWS Glue.&lt;/li&gt; &#xA; &lt;li&gt;Rich Plugins - Provide various plugins to integrate with other systems, like continuously optimizing with Flink and data analysis with Spark and Kyuubi.&lt;/li&gt; &#xA; &lt;li&gt;Management Tools - Provide a variety of management tools, including WEB UI and standard SQL command line, to help you get started faster and integrate with other systems more easily.&lt;/li&gt; &#xA; &lt;li&gt;Infrastructure Independent - Can be easily deployed and used in private environments, cloud environments, hybrid cloud environments, and multi-cloud environments.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Modules&lt;/h2&gt; &#xA;&lt;p&gt;Amoro contains modules as below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;amoro-core&lt;/code&gt; contains core abstractions and common implementation for other modules&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;amoro-ams&lt;/code&gt; is amoro management service module &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;ams-api&lt;/code&gt; contains ams thrift api and common interfaces&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;ams-dashboard&lt;/code&gt; is the dashboard frontend for ams&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;ams-server&lt;/code&gt; is the backend server for ams&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;ams-optimizer&lt;/code&gt; provides default optimizer implementation&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;amoro-mixed-format&lt;/code&gt; provides Mixed format implementation &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;amoro-hive&lt;/code&gt; integrates with Apache Hive and implements Mixed Hive format&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;amoro-flink&lt;/code&gt; provides Flink connectors for Mixed format tables (use amoro-flink-runtime for a shaded version)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;amoro-spark&lt;/code&gt; provides Spark connectors for Mixed format tables (use amoro-spark-runtime for a shaded version)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;amoro-trino&lt;/code&gt; provides Trino connectors for Mixed format tables&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;Amoro is built using Maven with Java 1.8 and Java 17(only for &lt;code&gt;mixed-format/trino&lt;/code&gt; module).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To build Trino module need config &lt;code&gt;toolchains.xml&lt;/code&gt; in &lt;code&gt;${user.home}/.m2/&lt;/code&gt; dir, the content is&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&amp;gt;&#xA;&amp;lt;toolchains&amp;gt;&#xA;    &amp;lt;toolchain&amp;gt;&#xA;        &amp;lt;type&amp;gt;jdk&amp;lt;/type&amp;gt;&#xA;        &amp;lt;provides&amp;gt;&#xA;            &amp;lt;version&amp;gt;17&amp;lt;/version&amp;gt;&#xA;            &amp;lt;vendor&amp;gt;sun&amp;lt;/vendor&amp;gt;&#xA;        &amp;lt;/provides&amp;gt;&#xA;        &amp;lt;configuration&amp;gt;&#xA;            &amp;lt;jdkHome&amp;gt;${YourJDK17Home}&amp;lt;/jdkHome&amp;gt;&#xA;        &amp;lt;/configuration&amp;gt;&#xA;    &amp;lt;/toolchain&amp;gt;&#xA;&amp;lt;/toolchains&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To invoke a build and run tests: &lt;code&gt;mvn package -P toolchain&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;To skip tests: &lt;code&gt;mvn -DskipTests package -P toolchain&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;To package without trino module and JAVA 17 dependency: &lt;code&gt;mvn clean package -DskipTests -pl &#39;!mixed-format/trino&#39;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;To build with hadoop 2.x(the default is 3.x) &lt;code&gt;mvn clean package -DskipTests -Dhadoop=v2&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;To indicate Flink version for optimizer (the default is 1.18.1): &lt;code&gt;mvn clean package -Dflink-optimizer.flink-version=1.15.4&lt;/code&gt;. If the version of Flink is below 1.15.0, you also need to add the &lt;code&gt;-Pflink-pre-1.15&lt;/code&gt; parameter: &lt;code&gt;mvn clean package -Pflink-pre-1.15 -Dflink-optimizer.flink-version=1.14.6&lt;/code&gt;. &lt;code&gt;mvn clean package -Pflink-pre-1.15 -Dflink-optimizer.flink-version=1.14.6 -DskipTests&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Spotless is skipped by default in &lt;code&gt;trino&lt;/code&gt; module. So if you want to perform checkstyle when building &lt;code&gt;trino&lt;/code&gt; module, you must be in a Java 17 environment.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To invoke a build include &lt;code&gt;mixed-format/trino&lt;/code&gt; module in Java 17 environment: &lt;code&gt;mvn clean package -DskipTests -P trino-spotless&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;To only build &lt;code&gt;mixed-format/trino&lt;/code&gt; and its dependent modules in Java 17 environment: &lt;code&gt;mvn clean package -DskipTests -P trino-spotless -pl &#39;mixed-format/trino&#39; -am&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;https://amoro.netease.com/quick-demo/&#34;&gt;https://amoro.netease.com/quick-demo/&lt;/a&gt; to quickly explore what amoro can do.&lt;/p&gt; &#xA;&lt;h2&gt;Join Community&lt;/h2&gt; &#xA;&lt;p&gt;If you are interested in Lakehouse, Data Lake Format, welcome to join our community, we welcome any organizations, teams and individuals to grow together, and sincerely hope to help users better use Data Lake Format through open source.&lt;/p&gt; &#xA;&lt;p&gt;Join the Amoro WeChat Group: Add &#34; &lt;code&gt;kllnn999&lt;/code&gt; &#34; as a friend on WeChat and specify &#34;Amoro lover&#34;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;This project exists thanks to all the people who contribute.&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/NetEase/amoro/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=NetEase/amoro&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;Made with &lt;a href=&#34;https://contrib.rocks&#34;&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#NetEase/amoro&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=NetEase/amoro&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apache/paimon</title>
    <updated>2024-03-31T01:33:01Z</updated>
    <id>tag:github.com,2024-03-31:/apache/paimon</id>
    <link href="https://github.com/apache/paimon" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache Paimon is a lake format that enables building a Realtime Lakehouse Architecture with Flink and Spark for both streaming and batch operations.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://paimon.apache.org/assets/paimon_blue.svg?sanitize=true&#34; alt=&#34;Paimon&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-4EB1BA.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://the-asf.slack.com/archives/C053Q2NCW8G&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/slack-join-orange.svg?sanitize=true&#34; alt=&#34;Get on Slack&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Apache Paimon is a lake format that enables building a Realtime Lakehouse Architecture with Flink and Spark for both streaming and batch operations. Paimon innovatively combines lake format and LSM structure, bringing realtime streaming updates into the lake architecture.&lt;/p&gt; &#xA;&lt;p&gt;Background and documentation are available at &lt;a href=&#34;https://paimon.apache.org&#34;&gt;https://paimon.apache.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Paimon&lt;/code&gt;&#39;s former name was &lt;code&gt;Flink Table Store&lt;/code&gt;, developed from the Flink community. The architecture refers to some design concepts of Iceberg. Thanks to Apache Flink and Apache Iceberg.&lt;/p&gt; &#xA;&lt;h2&gt;Collaboration&lt;/h2&gt; &#xA;&lt;p&gt;Paimon tracks issues in GitHub and prefers to receive contributions as pull requests.&lt;/p&gt; &#xA;&lt;h2&gt;Mailing Lists&lt;/h2&gt; &#xA;&lt;table class=&#34;table table-striped&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;th class=&#34;text-center&#34;&gt;Name&lt;/th&gt; &#xA;   &lt;th class=&#34;text-center&#34;&gt;Subscribe&lt;/th&gt; &#xA;   &lt;th class=&#34;text-center&#34;&gt;Digest&lt;/th&gt; &#xA;   &lt;th class=&#34;text-center&#34;&gt;Unsubscribe&lt;/th&gt; &#xA;   &lt;th class=&#34;text-center&#34;&gt;Post&lt;/th&gt; &#xA;   &lt;th class=&#34;text-center&#34;&gt;Archive&lt;/th&gt; &#xA;  &lt;/tr&gt;&#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;strong&gt;user&lt;/strong&gt;@paimon.apache.org&lt;br&gt; &lt;small&gt;User support and questions mailing list&lt;/small&gt; &lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt;&lt;i class=&#34;fa fa-pencil-square-o&#34;&gt;&lt;/i&gt; &lt;a href=&#34;mailto:user-subscribe@paimon.apache.org&#34;&gt;Subscribe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt;&lt;i class=&#34;fa fa-pencil-square-o&#34;&gt;&lt;/i&gt; &lt;a href=&#34;mailto:user-digest-subscribe@paimon.apache.org&#34;&gt;Subscribe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt;&lt;i class=&#34;fa fa-pencil-square-o&#34;&gt;&lt;/i&gt; &lt;a href=&#34;mailto:user-unsubscribe@paimon.apache.org&#34;&gt;Unsubscribe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt;&lt;i class=&#34;fa fa-pencil-square-o&#34;&gt;&lt;/i&gt; &lt;a href=&#34;mailto:user@paimon.apache.org&#34;&gt;Post&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt; &lt;a href=&#34;https://lists.apache.org/list.html?user@paimon.apache.org&#34;&gt;Archives&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;strong&gt;dev&lt;/strong&gt;@paimon.apache.org&lt;br&gt; &lt;small&gt;Development related discussions&lt;/small&gt; &lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt;&lt;i class=&#34;fa fa-pencil-square-o&#34;&gt;&lt;/i&gt; &lt;a href=&#34;mailto:dev-subscribe@paimon.apache.org&#34;&gt;Subscribe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt;&lt;i class=&#34;fa fa-pencil-square-o&#34;&gt;&lt;/i&gt; &lt;a href=&#34;mailto:dev-digest-subscribe@paimon.apache.org&#34;&gt;Subscribe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt;&lt;i class=&#34;fa fa-pencil-square-o&#34;&gt;&lt;/i&gt; &lt;a href=&#34;mailto:dev-unsubscribe@paimon.apache.org&#34;&gt;Unsubscribe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt;&lt;i class=&#34;fa fa-pencil-square-o&#34;&gt;&lt;/i&gt; &lt;a href=&#34;mailto:dev@paimon.apache.org&#34;&gt;Post&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td class=&#34;text-center&#34;&gt; &lt;a href=&#34;https://lists.apache.org/list.html?dev@paimon.apache.org&#34;&gt;Archives&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;b style=&#34;color:red&#34;&gt;Please make sure you are subscribed to the mailing list you are posting to!&lt;/b&gt; If you are not subscribed to the mailing list, your message will either be rejected (dev@ list) or you won&#39;t receive the response (user@ list).&lt;/p&gt; &#xA;&lt;h2&gt;Slack&lt;/h2&gt; &#xA;&lt;p&gt;You can join the Paimon community on Slack. Paimon channel is in ASF Slack workspace.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Anyone with an @apache.org email address can become a full member of the ASF Slack workspace. Search &lt;a href=&#34;https://the-asf.slack.com/archives/C053Q2NCW8G&#34;&gt;Paimon channel&lt;/a&gt; and join it.&lt;/li&gt; &#xA; &lt;li&gt;If you don&#39;t have an @apache.org email address, you can email to &lt;code&gt;user@paimon.apache.org&lt;/code&gt; to apply for an &lt;a href=&#34;https://infra.apache.org/slack.html&#34;&gt;ASF Slack invitation&lt;/a&gt;. Then join &lt;a href=&#34;https://the-asf.slack.com/archives/C053Q2NCW8G&#34;&gt;Paimon channel&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;JDK 8/11 is required for building the project. Maven version &amp;gt;=3.3.1.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run the &lt;code&gt;mvn clean install -DskipTests&lt;/code&gt; command to build the project.&lt;/li&gt; &#xA; &lt;li&gt;Run the &lt;code&gt;mvn spotless:apply&lt;/code&gt; to format the project (both Java and Scala).&lt;/li&gt; &#xA; &lt;li&gt;IDE: Mark &lt;code&gt;paimon-common/target/generated-sources/antlr4&lt;/code&gt; as Sources Root.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to Contribute&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://paimon.apache.org/docs/master/project/contributing/&#34;&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code in this repository is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/apache/paimon/master/LICENSE&#34;&gt;Apache Software License 2&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>