<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Java Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-08T01:53:53Z</updated>
  <subtitle>Weekly Trending of Java in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>kestra-io/kestra</title>
    <updated>2023-10-08T01:53:53Z</updated>
    <id>tag:github.com,2023-10-08:/kestra-io/kestra</id>
    <link href="https://github.com/kestra-io/kestra" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Infinitely scalable, event-driven, language-agnostic orchestration and scheduling platform to manage millions of workflows declaratively in code.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.kestra.io&#34;&gt; &lt;img src=&#34;https://kestra.io/banner.png&#34; alt=&#34;Kestra workflow orchestrator&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34; style=&#34;border-bottom: none&#34;&gt; Event-Driven Declarative Orchestrator &lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/kestra-io/kestra/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/tag-pre/kestra-io/kestra.svg?color=blueviolet&#34; alt=&#34;Last Version&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/kestra-io/kestra/raw/develop/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/kestra-io/kestra?color=blueviolet&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/kestra-io/kestra/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/kestra-io/kestra?color=blueviolet&amp;amp;logo=github&#34; alt=&#34;Github star&#34;&gt;&lt;/a&gt; &#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://kestra.io&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Website-kestra.io-192A4E?color=blueviolet&#34; alt=&#34;Kestra infinitely scalable orchestration and scheduling platform&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://kestra.io/slack&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Slack-Join%20Community-blueviolet?logo=slack&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://twitter.com/kestra_io&#34;&gt;&lt;img height=&#34;25&#34; src=&#34;https://kestra.io/twitter.svg?sanitize=true&#34; alt=&#34;twitter&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://www.linkedin.com/company/kestra/&#34;&gt;&lt;img height=&#34;25&#34; src=&#34;https://kestra.io/linkedin.svg?sanitize=true&#34; alt=&#34;linkedin&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://www.youtube.com/@kestra-io&#34;&gt;&lt;img height=&#34;25&#34; src=&#34;https://kestra.io/youtube.svg?sanitize=true&#34; alt=&#34;youtube&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=h-P0eK2xN58&amp;amp;ab_channel=Kestra&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://kestra.io/startvideo.png&#34; alt=&#34;Get started in 4 minutes with Kestra&#34; width=&#34;640px&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; style=&#34;color:grey;&#34;&gt;&lt;i&gt;&#34;Click on the image to get started in 4 minutes with Kestra.&#34;&lt;/i&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Live Demo&lt;/h2&gt; &#xA;&lt;p&gt;Try Kestra using our &lt;a href=&#34;https://demo.kestra.io&#34;&gt;live demo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;What is Kestra&lt;/h2&gt; &#xA;&lt;p&gt;Kestra is a universal open-source orchestrator that makes both &lt;strong&gt;scheduled&lt;/strong&gt; and &lt;strong&gt;event-driven&lt;/strong&gt; workflows easy. By bringing &lt;strong&gt;Infrastructure as Code&lt;/strong&gt; best practices to data, process, and microservice orchestration, you can build reliable workflows and manage them with confidence.&lt;/p&gt; &#xA;&lt;p&gt;In just a few lines of code, you can &lt;a href=&#34;https://kestra.io/docs/getting-started&#34;&gt;create a flow&lt;/a&gt; directly from the UI. Thanks to the declarative YAML interface for defining orchestration logic, business stakeholders can participate in the workflow creation process.&lt;/p&gt; &#xA;&lt;p&gt;Kestra offers a versatile set of &lt;strong&gt;language-agnostic&lt;/strong&gt; developer tools while simultaneously providing an intuitive user interface tailored for business professionals. The YAML definition gets automatically adjusted any time you make changes to a workflow from the UI or via an API call. Therefore, the orchestration logic is always managed &lt;strong&gt;declaratively in code&lt;/strong&gt;, even if some workflow components are modified in other ways (UI, CI/CD, Terraform, API calls).&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://kestra.io/adding-tasks.gif&#34; alt=&#34;Adding new tasks in the UI&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Key concepts&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;Flow&lt;/code&gt; is the main component in Kestra. It&#39;s a container for your tasks and orchestration logic.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Namespace&lt;/code&gt; is used to provide logical isolation, e.g., to separate development and production environments. Namespaces are like folders on your file system ‚Äî they organize flows into logical categories and can be nested to provide a hierarchical structure.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Tasks&lt;/code&gt; are atomic actions in a flow. By default, all tasks in the list will be executed sequentially, with additional customization options, a.o. to run tasks in parallel or allow a failure of specific tasks when needed.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Triggers&lt;/code&gt; define when a flow should run. In Kestra, flows are triggered based on events. Examples of such events include: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;a regular time-based&amp;nbsp;&lt;strong&gt;schedule&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;an&amp;nbsp;&lt;strong&gt;API&lt;/strong&gt;&amp;nbsp;call (&lt;em&gt;webhook trigger&lt;/em&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;ad-hoc execution from the&amp;nbsp;&lt;strong&gt;UI&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;a &lt;strong&gt;flow trigger&lt;/strong&gt; - flows can be triggered from other flows using a &lt;a href=&#34;https://kestra.io/docs/developer-guide/triggers/flow&#34;&gt;flow trigger&lt;/a&gt; or a &lt;a href=&#34;https://kestra.io/docs/flow-examples/subflow&#34;&gt;subflow&lt;/a&gt;, enabling highly modular workflows.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;custom&amp;nbsp;events&lt;/strong&gt;, including a new file arrival (&lt;em&gt;file detection event&lt;/em&gt;), a new message in a message bus, query completion, and more.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Inputs&lt;/code&gt; allow you to pass runtime-specific variables to a flow. They are strongly typed, and allow additional &lt;a href=&#34;https://kestra.io/docs/developer-guide/inputs#input-validation&#34;&gt;validation rules&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Extensible platform via plugins&lt;/h2&gt; &#xA;&lt;p&gt;Most tasks in Kestra are available as &lt;a href=&#34;https://kestra.io/plugins&#34;&gt;plugins&lt;/a&gt;, but many type of tasks are available in the core library, including a.o. script tasks supporting various programming languages (e.g., Python, Node, Bash) and the ability to orchestrate your business logic packaged into Docker container images.&lt;/p&gt; &#xA;&lt;p&gt;To create your own plugins, check the &lt;a href=&#34;https://kestra.io/docs/plugin-developer-guide&#34;&gt;plugin developer guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Rich orchestration capabilities&lt;/h2&gt; &#xA;&lt;p&gt;Kestra provides a variety of tasks to handle both simple and complex business logic, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;subflows&lt;/li&gt; &#xA; &lt;li&gt;retries&lt;/li&gt; &#xA; &lt;li&gt;timeout&lt;/li&gt; &#xA; &lt;li&gt;error handling&lt;/li&gt; &#xA; &lt;li&gt;conditional branching&lt;/li&gt; &#xA; &lt;li&gt;dynamic tasks&lt;/li&gt; &#xA; &lt;li&gt;sequential and parallel tasks&lt;/li&gt; &#xA; &lt;li&gt;skipping tasks or triggers when needed by setting the flag &lt;code&gt;disabled&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;configuring dependencies between tasks, flows and triggers&lt;/li&gt; &#xA; &lt;li&gt;advanced scheduling and trigger conditions&lt;/li&gt; &#xA; &lt;li&gt;backfills&lt;/li&gt; &#xA; &lt;li&gt;blueprints&lt;/li&gt; &#xA; &lt;li&gt;documenting your flows, tasks and triggers by adding a markdown description to any component&lt;/li&gt; &#xA; &lt;li&gt;adding labels to add additional metadata to your flows such as the flow owner or team:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;id: getting_started&#xA;namespace: dev&#xA;&#xA;description: |&#xA;  # Getting Started&#xA;  Let&#39;s `write` some **markdown** - [first flow](https://t.ly/Vemr0) üöÄ&#xA;&#xA;labels:&#xA;  owner: rick.astley&#xA;  project: never-gonna-give-you-up&#xA;&#xA;tasks:&#xA;  - id: hello&#xA;    type: io.kestra.core.tasks.log.Log&#xA;    message: Hello world!&#xA;    description: a *very* important task&#xA;    disabled: false&#xA;    timeout: PT10M&#xA;    retry:&#xA;      type: constant # type: string&#xA;      interval: PT15M # type: Duration&#xA;      maxDuration: PT1H # type: Duration&#xA;      maxAttempt: 5 # type: int&#xA;      warningOnRetry: true # type: boolean, default is false&#xA;&#xA;- id: parallel&#xA;    type: io.kestra.core.tasks.flows.Parallel&#xA;    concurrent: 3&#xA;    tasks:&#xA;      - id: task1&#xA;        type: io.kestra.plugin.scripts.shell.Commands&#xA;        commands:&#xA;          - &#39;echo &#34;running {{task.id}}&#34;&#39;&#xA;          - &#39;sleep 2&#39;&#xA;      - id: task2&#xA;        type: io.kestra.plugin.scripts.shell.Commands&#xA;        commands:&#xA;          - &#39;echo &#34;running {{task.id}}&#34;&#39;&#xA;          - &#39;sleep 1&#39;&#xA;      - id: task3&#xA;        type: io.kestra.plugin.scripts.shell.Commands&#xA;        commands:&#xA;          - &#39;echo &#34;running {{task.id}}&#34;&#39;&#xA;          - &#39;sleep 3&#39;&#xA;&#xA;triggers:&#xA;  - id: schedule&#xA;    type: io.kestra.core.models.triggers.types.Schedule&#xA;    cron: &#34;*/15 * * * *&#34;&#xA;    backfill:&#xA;      start: 2023-10-05T14:00:00Z&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Built-in code editor&lt;/h2&gt; &#xA;&lt;p&gt;You can write workflows directly from the UI. When writing your workflows, the UI provides:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;autocompletion&lt;/li&gt; &#xA; &lt;li&gt;syntax validation&lt;/li&gt; &#xA; &lt;li&gt;embedded plugin documentation&lt;/li&gt; &#xA; &lt;li&gt;example flows provided as blueprints&lt;/li&gt; &#xA; &lt;li&gt;topology view (view of your dependencies in a Directed Acyclic Graph) that get updated live as you modify and add new tasks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Follow the steps below to start local development.&lt;/p&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;Make sure that Docker is installed and running on your system. The default installation requires the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/install/&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.docker.com/compose/install/&#34;&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Launch Kestra&lt;/h3&gt; &#xA;&lt;p&gt;Download the Docker Compose file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -o docker-compose.yml https://raw.githubusercontent.com/kestra-io/kestra/develop/docker-compose.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can use &lt;code&gt;wget https://raw.githubusercontent.com/kestra-io/kestra/develop/docker-compose.yml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Start Kestra:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser and create your first flow.&lt;/p&gt; &#xA;&lt;h3&gt;Hello-World flow&lt;/h3&gt; &#xA;&lt;p&gt;Here is a simple example logging hello world message to the terminal:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;id: getting_started&#xA;namespace: dev&#xA;tasks:&#xA;  - id: hello_world&#xA;    type: io.kestra.core.tasks.log.Log&#xA;    message: Hello World!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Follow the &lt;a href=&#34;https://kestra.io/docs/getting-started/&#34;&gt;getting started tutorial&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Read the &lt;a href=&#34;https://kestra.io/docs/&#34;&gt;documentation&lt;/a&gt; to understand how to: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://kestra.io/docs/developer-guide/&#34;&gt;Develop your flows&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://kestra.io/docs/administrator-guide/&#34;&gt;Deploy Kestra&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Use our &lt;a href=&#34;https://kestra.io/docs/terraform/&#34;&gt;Terraform provider&lt;/a&gt; to deploy your flows&lt;/li&gt; &#xA;   &lt;li&gt;Develop your &lt;a href=&#34;https://kestra.io/docs/plugin-developer-guide/&#34;&gt;own plugins&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Plugins&lt;/h2&gt; &#xA;&lt;p&gt;Kestra is built on a &lt;a href=&#34;https://kestra.io/plugins/&#34;&gt;plugin system&lt;/a&gt;. You can find your plugin to interact with your provider; alternatively, you can follow &lt;a href=&#34;https://kestra.io/docs/plugin-developer-guide/&#34;&gt;these steps&lt;/a&gt; to develop your own plugin.&lt;/p&gt; &#xA;&lt;p&gt;For a full list of plugins, check the &lt;a href=&#34;https://kestra.io/plugins/&#34;&gt;plugins page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Here are some examples of the available plugins:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-airbyte#cloudjobs&#34;&gt;Airbyte Cloud&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-airbyte#connections&#34;&gt;Airbyte OSS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-aws#athena&#34;&gt;Amazon Athena&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-aws#cli&#34;&gt;Amazon CLI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-aws#dynamodb&#34;&gt;Amazon DynamoDb&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-redshift&#34;&gt;Amazon Redshift&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-aws#s3&#34;&gt;Amazon S3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-aws#sns&#34;&gt;Amazon SNS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-aws#sqs&#34;&gt;Amazon SQS&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-amqp&#34;&gt;AMQP&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-serdes#avro&#34;&gt;Apache Avro&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-cassandra&#34;&gt;Apache Cassandra&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-kafka&#34;&gt;Apache Kafka&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-pinot&#34;&gt;Apache Pinot&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-serdes#parquet&#34;&gt;Apache Parquet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-pulsar&#34;&gt;Apache Pulsar&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-spark&#34;&gt;Apache Spark&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-tika&#34;&gt;Apache Tika&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-azure/#batchjob&#34;&gt;Azure Batch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-azure/#storage-blob&#34;&gt;Azure Blob Storage&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-azure/#storagetable&#34;&gt;Azure Blob Table&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-serdes#csv&#34;&gt;CSV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-clickhouse&#34;&gt;ClickHouse&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-compress&#34;&gt;Compression&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-couchbase&#34;&gt;Couchbase&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-databricks&#34;&gt;Databricks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-dbt#cloud&#34;&gt;dbt cloud&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-dbt#cli&#34;&gt;dbt core&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-debezium-sqlserver&#34;&gt;Debezium Microsoft SQL Server&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-debezium-mysql&#34;&gt;Debezium MYSQL&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-debezium-postgres&#34;&gt;Debezium Postgres&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-duckdb&#34;&gt;DuckDb&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-elasticsearch&#34;&gt;ElasticSearch&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-notifications#mail&#34;&gt;Email&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-fivetran&#34;&gt;Fivetran&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-fs#ftp&#34;&gt;FTP&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-fs#ftps&#34;&gt;FTPS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-git&#34;&gt;Git&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-gcp#bigquery&#34;&gt;Google Big Query&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-gcp#pubsub&#34;&gt;Google Pub/Sub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-gcp#gcs&#34;&gt;Google Cloud Storage&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-gcp#dataproc&#34;&gt;Google DataProc&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-gcp#firestore&#34;&gt;Google Firestore&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-gcp#cli&#34;&gt;Google Cli&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-gcp#vertexai/&#34;&gt;Google Vertex AI&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-gcp#gke&#34;&gt;Google Kubernetes Engines&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-googleworkspace#drive&#34;&gt;Google Drive&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-googleworkspace#sheets&#34;&gt;Google Sheets&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-script-groovy&#34;&gt;Groovy&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-fs#http&#34;&gt;Http&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-serdes#json&#34;&gt;JSON&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-script-julia&#34;&gt;Julia&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-script-jython&#34;&gt;Jython&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-kubernetes&#34;&gt;Kubernetes&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-sqlserver&#34;&gt;Microsoft SQL Server&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-notifications#teams&#34;&gt;Microsoft Teams&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-mongodb&#34;&gt;MongoDb&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-mqtt&#34;&gt;MQTT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-mysql&#34;&gt;MySQL&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-script-nashorn&#34;&gt;Nashorn&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-nats&#34;&gt;NATS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-neo4j&#34;&gt;Neo4j&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-script-node&#34;&gt;Node&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-openai&#34;&gt;OpenAI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-crypto#openpgp&#34;&gt;Open PGP&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-oracle&#34;&gt;Oracle&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-postgres&#34;&gt;PostgreSQL&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-powerbi&#34;&gt;Power BI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-script-powershell&#34;&gt;PowerShell&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-script-python&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-rockset&#34;&gt;Rockset&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-script-powershell&#34;&gt;RScript&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-fs#sftp&#34;&gt;SFTP&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-servicenow&#34;&gt;ServiceNow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-singer&#34;&gt;Singer&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-script-shell&#34;&gt;Shell&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-notifications#slack&#34;&gt;Slack&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-snowflake&#34;&gt;Snowflake&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-soda&#34;&gt;Soda&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-fs#ssh&#34;&gt;SSH&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-notifications#telegram&#34;&gt;Telegram&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-trino&#34;&gt;Trino&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-serdes#xml&#34;&gt;XML&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kestra.io/plugins/plugin-jdbc-vertica&#34;&gt;Vertica&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;This list is growing quickly and we welcome contributions.&lt;/p&gt; &#xA;&lt;h2&gt;Community Support&lt;/h2&gt; &#xA;&lt;p&gt;If you need help or have any questions, reach out using one of the following channels:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kestra.io/slack&#34;&gt;Slack&lt;/a&gt; - join the community and get the latest updates.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kestra-io/kestra/discussions&#34;&gt;GitHub discussions&lt;/a&gt; - useful to start a conversation that is not a bug or feature request.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/kestra_io&#34;&gt;Twitter&lt;/a&gt; - to follow up with the latest updates.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://github.com/kestra-io/kestra/issues&#34;&gt;open issues&lt;/a&gt; for a list of proposed features (and known issues) or look at the &lt;a href=&#34;https://github.com/orgs/kestra-io/projects/2&#34;&gt;project board&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We love contributions, big or small. Check out &lt;a href=&#34;https://github.com/kestra-io/kestra/raw/develop/.github/CONTRIBUTING.md&#34;&gt;our contributor guide&lt;/a&gt; for details on how to contribute to Kestra.&lt;/p&gt; &#xA;&lt;p&gt;See our &lt;a href=&#34;https://kestra.io/docs/plugin-developer-guide/&#34;&gt;Plugin Developer Guide&lt;/a&gt; for details on developing and publishing Kestra plugins.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Apache 2.0 ¬© &lt;a href=&#34;https://kestra.io&#34;&gt;Kestra Technologies&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lakesoul-io/LakeSoul</title>
    <updated>2023-10-08T01:53:53Z</updated>
    <id>tag:github.com,2023-10-08:/lakesoul-io/LakeSoul</id>
    <link href="https://github.com/lakesoul-io/LakeSoul" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LakeSoul is an end-to-end, realtime and cloud native Lakehouse framework with fast data ingestion, concurrent update and incremental data analytics on cloud storages for both BI and AI applications.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://github.com/lakesoul-io/artwork/raw/main/horizontal/color/LakeSoul_Horizontal_Color.svg?sanitize=true&#34; alt=&#34;LakeSoul&#34; height=&#34;200&#34;&gt; &#xA;&lt;img src=&#34;https://github.com/lfai/artwork/raw/main/lfaidata-assets/lfaidata-project-badge/sandbox/color/lfaidata-project-badge-sandbox-color.svg?sanitize=true&#34; alt=&#34;LF AI &amp;amp; Data Sandbox Project&#34; height=&#34;180&#34;&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://bestpractices.coreinfrastructure.org/projects/7192/badge&#34; alt=&#34;OpenSSF Best Practices&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/lakesoul-io/LakeSoul/actions/workflows/maven-test.yml/badge.svg?sanitize=true&#34; alt=&#34;Maven Test&#34;&gt; &lt;img src=&#34;https://github.com/lakesoul-io/LakeSoul/actions/workflows/flink-cdc-test.yml/badge.svg?sanitize=true&#34; alt=&#34;Flink CDC Test&#34;&gt; &lt;img src=&#34;https://github.com/lakesoul-io/LakeSoul/actions/workflows/native-build.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lakesoul-io/LakeSoul/main/README-CN.md&#34;&gt;‰∏≠Êñá‰ªãÁªç&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul is a cloud-native Lakehouse framework that supports scalable metadata management, ACID transactions, efficient and flexible upsert operation, schema evolution, and unified streaming &amp;amp; batch processing.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul supports multiple computing engines to read and write lake warehouse table data, including Spark, Flink, Presto, and PyTorch, and supports multiple computing modes such as batch, stream, MPP, and AI. LakeSoul supports storage systems such as HDFS and S3.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lakesoul-io/LakeSoul/main/website/static/img/lakeSoulModel.png&#34; alt=&#34;LakeSoul Arch&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul was originally created by DMetaSoul company and was donated to Linux Foundation AI &amp;amp; Data as a sandbox project since May 2023.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul implements incremental upserts for both row and column and allows concurrent updates.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul uses LSM-Tree like structure to support updates on hash partitioning table with primary key, and achieves very high write throughput while providing optimized merge on read performance (refer to &lt;a href=&#34;https://lakesoul-io.github.io/blog/2023/04/21/lakesoul-2.2.0-release&#34;&gt;Performance Benchmarks&lt;/a&gt;). LakeSoul scales metadata management and achieves ACID control by using PostgreSQL.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul uses Rust to implement the native metadata layer and IO layer, and provides C/Java/Python interfaces to support the connecting of multiple computing frameworks such as big data and AI.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul supports concurrent batch or streaming read and write. Both read and write supports CDC semantics, and together with auto schema evolution and exacly-once guarantee, constructing realtime data warehouses is made easy.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul supports multi-workspace and RBAC. LakeSoul uses Postgres&#39;s RBAC and row-level security policies to implement permission isolation for metadata. Together with Hadoop users and groups, physical data isolation can be achieved. LakeSoul&#39;s permission isolation is effective for SQL/Java/Python jobs.&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul supports automatic disaggregated compaction, automatic table life cycle maintenance, and automatic redundant data cleaning, reducing operation costs and improving usability.&lt;/p&gt; &#xA;&lt;p&gt;More detailed features please refer to our doc page: &lt;a href=&#34;https://lakesoul-io.github.io/docs/intro&#34;&gt;Documentations&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Quick Start&lt;/h1&gt; &#xA;&lt;p&gt;Follow the &lt;a href=&#34;https://lakesoul-io.github.io/docs/Getting%20Started/setup-local-env&#34;&gt;Quick Start&lt;/a&gt; to quickly set up a test env.&lt;/p&gt; &#xA;&lt;h1&gt;Tutorials&lt;/h1&gt; &#xA;&lt;p&gt;Please find tutorials in doc site:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/tree/main/python/examples&#34;&gt;Examples of Python Data Processing and AI Model Training on LakeSoul&lt;/a&gt; on how LakeSoul connecting AI to Lakehouse to build a unified and modern data infrastructure.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/flink-cdc-sink&#34;&gt;LakeSoul Flink CDC Whole Database Synchronization Tutorial&lt;/a&gt; on how to sync an entire MySQL database into LakeSoul in realtime, with auto table creation, auto DDL sync and exactly once guarantee.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Usage%20Docs/flink-lakesoul-connector&#34;&gt;Flink SQL Usage&lt;/a&gt; on using Flink SQL to read or write LakeSoul in both batch and streaming mode, with the supports of Flink Changelog Stream semantics and row-level upsert and delete.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/mutil-stream-merge&#34;&gt;Multi Stream Merge and Build Wide Table Tutorial&lt;/a&gt; on how to merge multiple stream with same primary key (and different other columns) concurrently without join.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/upsert-and-merge-udf&#34;&gt;Upsert Data and Merge UDF Tutorial&lt;/a&gt; on how to upsert data and Merge UDF to customize merge logic.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/snapshot-manage&#34;&gt;Snapshot API Usage&lt;/a&gt; on how to do snapshot read (time travel), snapshot rollback and cleanup.&lt;/li&gt; &#xA; &lt;li&gt;Checkout &lt;a href=&#34;https://lakesoul-io.github.io/docs/Tutorials/incremental-query&#34;&gt;Incremental Query Tutorial&lt;/a&gt; on how to do incremental query in Spark in batch or stream mode.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Usage Documentations&lt;/h1&gt; &#xA;&lt;p&gt;Please find usage documentations in doc site: &lt;a href=&#34;https://lakesoul-io.github.io/docs/Usage%20Docs/setup-meta-env&#34;&gt;Usage Doc&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lakesoul-io.github.io/zh-Hans/docs/Getting%20Started/setup-local-env&#34;&gt;Âø´ÈÄüÂºÄÂßã&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/flink-cdc-sink&#34;&gt;ÊïôÁ®ã&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lakesoul-io.github.io/zh-Hans/docs/Usage%20Docs/setup-meta-env&#34;&gt;‰ΩøÁî®ÊñáÊ°£&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Feature Roadmap&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Data Science and AI &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Native Python Reader (without PySpark)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; PyTorch Dataset and distributed training&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Meta Management (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/23&#34;&gt;#23&lt;/a&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multiple Level Partitioning: Multiple range partition and at most one hash partition&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Concurrent write with auto conflict resolution&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; MVCC with read isolation&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Write transaction (two-stage commit) through Postgres Transaction&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Schema Evolution: Column add/delete supported&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Table operations &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; LSM-Tree style upsert for hash partitioned table&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Merge on read for hash partition with upsert delta file&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Copy on write update for non hash partitioned table&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Automatic Disaggregated Compaction Service&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Data Warehousing &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CDC stream ingestion with auto ddl sync&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Incremental and Snapshot Query &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Snapshot Query (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/103&#34;&gt;#103&lt;/a&gt;)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Incremental Query (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/103&#34;&gt;#103&lt;/a&gt;)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Incremental Streaming Source (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/130&#34;&gt;#130&lt;/a&gt;)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Flink Stream/Batch Source&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multi Workspaces and RBAC&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Spark Integration &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Table/Dataframe API&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; SQL support with catalog except upsert&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Query optimization &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Shuffle/Join elimination for operations on primary key&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Merge UDF (Merge operator)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Merge Into SQL support &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Merge Into SQL with match on Primary Key (Merge on read)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Merge Into SQL with match on non-pk&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Merge Into SQL with match condition and complex expression (Merge on read when match on PK) (depends on &lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/66&#34;&gt;#66&lt;/a&gt;)&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Flink Integration and CDC Ingestion (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/57&#34;&gt;#57&lt;/a&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Table API &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Batch/Stream Sink&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Batch/Stream source&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Stream Source/Sink for ChangeLog Stream Semantics&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Exactly Once Source and Sink&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Flink CDC &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Auto Schema Change (DDL) Sync&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Auto Table Creation (depends on #78)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support sink multiple source tables with different schemas (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/84&#34;&gt;#84&lt;/a&gt;)&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Hive Integration &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Export to Hive partition after compaction&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Apache Kyuubi (Hive JDBC) Integration&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Realtime Data Warehousing &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CDC ingestion&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Time Travel (Snapshot read)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Snapshot rollback&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Automatic global compaction service&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; MPP Engine Integration (depends on &lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/66&#34;&gt;#66&lt;/a&gt;) &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Presto&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Trino&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Cloud and Native IO (&lt;a href=&#34;https://github.com/lakesoul-io/LakeSoul/issues/66&#34;&gt;#66&lt;/a&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Object storage IO optimization&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Native merge on read&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Multi-layer storage classes support with data tiering&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Community guidelines&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lakesoul-io/LakeSoul/main/community-guideline.md&#34;&gt;Community guidelines&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Feedback and Contribution&lt;/h1&gt; &#xA;&lt;p&gt;Please feel free to open an issue or dicussion if you have any questions.&lt;/p&gt; &#xA;&lt;p&gt;Join our &lt;a href=&#34;https://discord.gg/WJrHKq4BPf&#34;&gt;Discord&lt;/a&gt; server for discussions.&lt;/p&gt; &#xA;&lt;h1&gt;Contact Us&lt;/h1&gt; &#xA;&lt;p&gt;Email us at &lt;a href=&#34;mailto:lakesoul-technical-discuss@lists.lfaidata.foundation&#34;&gt;lakesoul-technical-discuss@lists.lfaidata.foundation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Opensource License&lt;/h1&gt; &#xA;&lt;p&gt;LakeSoul is opensourced under Apache License v2.0.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>vespa-engine/vespa</title>
    <updated>2023-10-08T01:53:53Z</updated>
    <id>tag:github.com,2023-10-08:/vespa-engine/vespa</id>
    <link href="https://github.com/vespa-engine/vespa" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The open big data serving engine. https://vespa.ai&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://vespa.ai&#34;&gt;&lt;img src=&#34;https://vespa.ai/assets/vespa-logo-color.png&#34; alt=&#34;#Vespa&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The open big data serving engine - Store, search, organize and make machine-learned inferences over big data at serving time.&lt;/p&gt; &#xA;&lt;p&gt;This is the primary repository for Vespa where all development is happening. New production releases from this repository&#39;s master branch are made each weekday from Monday through Thursday.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Home page: &lt;a href=&#34;https://vespa.ai&#34;&gt;https://vespa.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Documentation: &lt;a href=&#34;https://docs.vespa.ai&#34;&gt;https://docs.vespa.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Continuous build: &lt;a href=&#34;https://factory.vespa.oath.cloud&#34;&gt;https://factory.vespa.oath.cloud&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run applications in the cloud for free: &lt;a href=&#34;https://cloud.vespa.ai&#34;&gt;https://cloud.vespa.ai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Vespa build status: &lt;a href=&#34;https://cd.screwdriver.cd/pipelines/6386&#34;&gt;&lt;img src=&#34;https://api.screwdriver.cd/v4/pipelines/6386/build-vespa/badge&#34; alt=&#34;Vespa Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/#background&#34;&gt;Background&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/#install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/#usage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/#contribute&#34;&gt;Contribute&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/#building&#34;&gt;Building&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Background&lt;/h2&gt; &#xA;&lt;p&gt;Use cases such as search, recommendation and personalization need to select a subset of data in a large corpus, evaluate machine-learned models over the selected data, organize and aggregate it and return it, typically in less than 100 milliseconds, all while the data corpus is continuously changing.&lt;/p&gt; &#xA;&lt;p&gt;This is hard to do, especially with large data sets that needs to be distributed over multiple nodes and evaluated in parallel. Vespa is a platform which performs these operations for you with high availability and performance. It has been in development for many years and is used on a number of large internet services and apps which serve hundreds of thousands of queries from Vespa per second.&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;Run your own Vespa instance: &lt;a href=&#34;https://docs.vespa.ai/en/getting-started.html&#34;&gt;https://docs.vespa.ai/en/getting-started.html&lt;/a&gt; Or deploy your Vespa applications to the cloud service: &lt;a href=&#34;https://cloud.vespa.ai&#34;&gt;https://cloud.vespa.ai&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The application created in the getting started guide is fully functional and production ready, but you may want to &lt;a href=&#34;https://docs.vespa.ai/en/multinode-systems.html&#34;&gt;add more nodes&lt;/a&gt; for redundancy.&lt;/li&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://docs.vespa.ai/en/developer-guide.html&#34;&gt;developing applications&lt;/a&gt; on adding your own Java components to your Vespa application.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.vespa.ai/en/api.html&#34;&gt;Vespa APIs&lt;/a&gt; is useful to understand how to interface with Vespa&lt;/li&gt; &#xA; &lt;li&gt;Explore the &lt;a href=&#34;https://github.com/vespa-engine/sample-apps/tree/master&#34;&gt;sample applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Follow the &lt;a href=&#34;https://blog.vespa.ai/&#34;&gt;Vespa Blog&lt;/a&gt; for feature updates / use cases&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Full documentation is at &lt;a href=&#34;https://docs.vespa.ai&#34;&gt;https://docs.vespa.ai&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions! See &lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; to learn how to contribute.&lt;/p&gt; &#xA;&lt;p&gt;If you want to contribute to the documentation, see &lt;a href=&#34;https://github.com/vespa-engine/documentation&#34;&gt;https://github.com/vespa-engine/documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;You do not need to build Vespa to use it, but if you want to contribute you need to be able to build the code. This section explains how to build and test Vespa. To understand where to make changes, see &lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/Code-map.md&#34;&gt;Code-map.md&lt;/a&gt;. Some suggested improvements with pointers to code are in &lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/TODO.md&#34;&gt;TODO.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Development environment&lt;/h3&gt; &#xA;&lt;p&gt;C++ and Java building is supported on CentOS Stream 8. The Java source can also be built on any platform having Java 17 and Maven installed. Use the following guide to set up a complete development environment using Docker for building Vespa, running unit tests and running system tests: &lt;a href=&#34;https://github.com/vespa-engine/docker-image-dev#vespa-development-on-centos-stream-8&#34;&gt;Vespa development on CentOS Stream 8&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Build Java modules&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;export MAVEN_OPTS=&#34;-Xms128m -Xmx1024m&#34;&#xA;./bootstrap.sh java&#xA;mvn install --threads 1C&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use this if you only need to build the Java modules, otherwise follow the complete development guide above.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Code licensed under the Apache 2.0 license. See &lt;a href=&#34;https://raw.githubusercontent.com/vespa-engine/vespa/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for terms.&lt;/p&gt;</summary>
  </entry>
</feed>