<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub CSS Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-02T01:53:26Z</updated>
  <subtitle>Weekly Trending of CSS in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>oldinaction/ChatGPT-MP</title>
    <updated>2023-07-02T01:53:26Z</updated>
    <id>tag:github.com,2023-07-02:/oldinaction/ChatGPT-MP</id>
    <link href="https://github.com/oldinaction/ChatGPT-MP" rel="alternate"></link>
    <summary type="html">&lt;p&gt;（**承接各类小程序开发**）基于ChatGPT实现的微信小程序，适配H5和WEB端。包含前后端，支持打字效果输出流式输出，支持AI聊天次数限制，支持分享增加次数等功能。&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;ChatGPT-MP(基于ChatGPT实现的微信小程序，适配H5和WEB端)&lt;/h2&gt; &#xA;&lt;p&gt;包含前后台，支持打字效果输出流式输出，支持AI聊天次数限制，支持分享增加次数等功能。&lt;strong&gt;开源版禁止商用，仅供学习交流，禁止倒卖。&lt;/strong&gt; 感谢Star！&lt;/p&gt; &#xA;&lt;p&gt;技术栈：JDK8 + SpringBoot + Vue2 + Uniapp + Mysql&lt;/p&gt; &#xA;&lt;p&gt;Github地址：&lt;a href=&#34;https://github.com/oldinaction/ChatGPT-MP&#34;&gt;https://github.com/oldinaction/ChatGPT-MP&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Gitee地址(国内访问更快)：&lt;a href=&#34;https://gitee.com/smalle/ChatGPT-MP&#34;&gt;https://gitee.com/smalle/ChatGPT-MP&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;小程序演示地址&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn7.aezo.cn/common/qrcode/one_qrcode.jpg&#34; alt=&#34;One能抽屉&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;包含功能&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ChatGPT聊天&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 用户聊天次数限制&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 分享得聊天次数&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 每日领取免费次数&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 查看及清除聊天历史&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 显示连接情况&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 清除聊天历史&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 开通会员&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 购买次数包&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 联系客服领取次数&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 看广告得次数&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 后台管理系统，暂时为升级版功能，之后会择机开源&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 敏感词检测及设置&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 适配H5和WEB端&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 登录方式支持：小程序登录/微信公众号登录/手机号注册登录/邮箱注册登录&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 提示词功能(角色扮演)，内置近300种提示词，包含小红书文案书写、周报生成、异性对话生成器等&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; AI生成图片、语音转换等功能开发中......&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;小程序/H5样式预览&lt;/h2&gt; &#xA;&lt;p&gt;小程序样式&lt;/p&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;img src=&#34;images/MP-我的菜单.PNG&#34; width=&#34;210&#34; height=&#34;454&#34;&gt; &#xA; &lt;img src=&#34;images/MP-聊天.PNG&#34; width=&#34;210&#34; height=&#34;454&#34;&gt; &#xA; &lt;img src=&#34;images/MP-聊天历史.PNG&#34; width=&#34;210&#34; height=&#34;454&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;提示词功能&lt;/p&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;img src=&#34;images/MP-提示词.PNG&#34; width=&#34;210&#34; height=&#34;454&#34;&gt; &#xA; &lt;img src=&#34;images/MP-提示词分类.PNG&#34; width=&#34;210&#34; height=&#34;454&#34;&gt; &#xA; &lt;img src=&#34;images/MP-提示词使用.PNG&#34; width=&#34;210&#34; height=&#34;454&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;登录注册界面等样式&lt;/p&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;img src=&#34;images/H5-登录注册.PNG&#34; width=&#34;210&#34; height=&#34;454&#34;&gt; &#xA; &lt;img src=&#34;images/H5-开通会员.PNG&#34; width=&#34;210&#34; height=&#34;454&#34;&gt; &#xA; &lt;img src=&#34;images/H5-支付.PNG&#34; width=&#34;210&#34; height=&#34;454&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;后端管理样式预览&lt;/h2&gt; &#xA;&lt;img src=&#34;images/用户管理.png&#34;&gt; &#xA;&lt;img src=&#34;images/用户次数管理.png&#34;&gt; &#xA;&lt;img src=&#34;images/敏感词管理.png&#34;&gt; &#xA;&lt;img src=&#34;images/数据统计.png&#34;&gt; &#xA;&lt;h2&gt;开源版部署&lt;/h2&gt; &#xA;&lt;h3&gt;后端&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;创建Mysql数据库aezo-chat-gpt, 执行脚本文件 aezo-chat-gpt-api/doc/aezo-chat-gpt.sql&lt;/li&gt; &#xA; &lt;li&gt;使用IDEA打开aezo-chat-gpt-api项目&lt;/li&gt; &#xA; &lt;li&gt;修改application.yml中的小程序id和秘钥、OpenAI地址和KEY&lt;/li&gt; &#xA; &lt;li&gt;启动项目&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;再加一点点说明：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;此项目开源后，收到了不少Star(感谢~)&lt;/p&gt; &#xA;&lt;p&gt;其中不少同学非技术出身，很多都卡在后端项目启动这一步，我就将项目编译打包后的Jar一并上传了，之后只需安装好JDK并修改少许配置即可启动，省去了编译环节&lt;/p&gt; &#xA;&lt;p&gt;Jar包启动方式如下：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;安装JDK(略)，网上教程较多&lt;/li&gt; &#xA; &lt;li&gt;下载dist.zip压缩包后进行解压&lt;/li&gt; &#xA; &lt;li&gt;修改此目录中的 application-dev.yml 文件(记事本文本编辑器即可打开，配置项已备注清楚)&lt;/li&gt; &#xA; &lt;li&gt;启动：Windows执行&lt;code&gt;start.bat&lt;/code&gt;文件，Linux执行&lt;code&gt;start.sh&lt;/code&gt;文件&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;前端小程序&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;使用HBuilder打开aezo-chat-gpt-m项目&lt;/li&gt; &#xA; &lt;li&gt;修改common/config.js中的API地址&lt;/li&gt; &#xA; &lt;li&gt;运行项目到微信小程序&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;版本功能比对&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;功能&lt;/th&gt; &#xA;   &lt;th&gt;开源版&lt;/th&gt; &#xA;   &lt;th&gt;升级版&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGPT聊天&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;用户聊天次数限制&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;分享得聊天次数&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;每日领取免费次数&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;查看聊天历史&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;显示连接情况&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;清除聊天历史&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;开通会员&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;购买次数包&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;联系客服领取次数&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;看广告得次数&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;敏感词过滤&lt;/td&gt; &#xA;   &lt;td&gt;❌&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;提示词功能(角色扮演)&lt;/td&gt; &#xA;   &lt;td&gt;❌&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;H5/WEB端适配&lt;/td&gt; &#xA;   &lt;td&gt;❌&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;登录注册方式&lt;/td&gt; &#xA;   &lt;td&gt;小程序登录&lt;/td&gt; &#xA;   &lt;td&gt;小程序登录/微信公众号登录/手机号注册登录/邮箱注册登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;后台管理&lt;/td&gt; &#xA;   &lt;td&gt;❌&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;详细部署及使用文档&lt;/td&gt; &#xA;   &lt;td&gt;❌&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;售后服务&lt;/td&gt; &#xA;   &lt;td&gt;❌&lt;/td&gt; &#xA;   &lt;td&gt;交流学习群&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ekey.oneneng.top/buy/1&#34;&gt;需要升级版，戳这里&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;交流学习&lt;/h2&gt; &#xA;&lt;p&gt;有问题可进群交流，为了防止各种广告，需小额打赏1元以上~(你的心意就是我最大的动力)，添加请注明来意！&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;点击查看联系方式（需小额打赏，添加注明OneChat）&lt;/summary&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/oldinaction/ChatGPT-MP/master/images/wechat-1.jpg&#34; width=&#34;210&#34; height=&#34;280&#34; alt=&#34;微信：moonstarwall&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;鸣谢&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;基于ChatGPT Java客户端&lt;a href=&#34;https://github.com/Grt1228/chatgpt-java&#34;&gt;chatgpt-java&lt;/a&gt;实现接口调用&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ParisNeo/Gpt4All-webui</title>
    <updated>2023-07-02T01:53:26Z</updated>
    <id>tag:github.com,2023-07-02:/ParisNeo/Gpt4All-webui</id>
    <link href="https://github.com/ParisNeo/Gpt4All-webui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A web user interface for GPT4All&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gpt4All Web UI&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/license/nomic-ai/GPT4All-ui&#34; alt=&#34;GitHub license&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues/nomic-ai/GPT4All-ui&#34; alt=&#34;GitHub issues&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/nomic-ai/GPT4All-ui&#34; alt=&#34;GitHub stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/nomic-ai/GPT4All-ui&#34; alt=&#34;GitHub forks&#34;&gt; &lt;a href=&#34;https://discord.gg/4rR282WJb6&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1092918764925882418?color=7289da&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=ffffff&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/SpaceNerduino&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/SpaceNerduino?style=social&#34; alt=&#34;Follow me on Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/user/Parisneo&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Follow%20Me%20on-YouTube-red?style=flat&amp;amp;logo=youtube&#34; alt=&#34;Follow Me on YouTube&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a Flask web application that provides a chat UI for interacting with &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llamacpp&lt;/a&gt;, gpt-j, gpt-q as well as Hugging face based language models uch as &lt;a href=&#34;https://github.com/nomic-ai/gpt4all&#34;&gt;GPT4all&lt;/a&gt;, vicuna etc...&lt;/p&gt; &#xA;&lt;p&gt;Follow us on our &lt;a href=&#34;https://discord.gg/4rR282WJb6&#34;&gt;Discord Server&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Watch Install Video (Outdated, please use &#34;New UI video&#34;) &lt;a href=&#34;https://youtu.be/6kKv6ESnwMk&#34;&gt;Old Install Video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Watch Usage Videos &lt;a href=&#34;https://youtu.be/DCBefhJUUh4&#34;&gt;Usage Video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Watch Settings Video &lt;a href=&#34;https://youtu.be/7KwR2vdt1t4&#34;&gt;Settings Video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Watch New UI Video &lt;a href=&#34;https://youtu.be/M7NFajCyZKs&#34;&gt;New UI + Install&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.gyazo.com/ef94a5ac9169467a1aec228ef8c36c66.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;GPT4All is an exceptional language model, designed and developed by Nomic-AI, a proficient company dedicated to natural language processing. The app uses Nomic-AI&#39;s advanced library to communicate with the cutting-edge GPT4All model, which operates locally on the user&#39;s PC, ensuring seamless and efficient communication.&lt;/p&gt; &#xA;&lt;p&gt;If you are interested in learning more about this groundbreaking project, visit their &lt;a href=&#34;https://github.com/nomic-ai/gpt4all&#34;&gt;Github Repository&lt;/a&gt;, where you can find comprehensive information regarding the app&#39;s functionalities and technical details. Moreover, you can delve deeper into the training process and database by going through their detailed Technical report, available for download at &lt;a href=&#34;https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf&#34;&gt;Technical report&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;One of the app&#39;s impressive features is that it allows users to send messages to the chatbot and receive instantaneous responses in real time, ensuring a seamless user experience. Additionally, the app facilitates the exportation of the entire chat history in either text or JSON format, providing greater flexibility to the users.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s worth noting that the model has recently been launched, and it&#39;s expected to evolve across time, enabling it to become even better in the future. This web UI is designed to provide the community with easy and fully localized access to a chatbot that will continue to improve and adapt across time.&lt;/p&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Chat with locally hosted AI inside a web browser&lt;/li&gt; &#xA; &lt;li&gt;Create, edit, and share your AI&#39;s personality&lt;/li&gt; &#xA; &lt;li&gt;Audio in and audio out with many options for language and voices (only Chrome web browser is supported at this time)&lt;/li&gt; &#xA; &lt;li&gt;History of discussion with resume functionality&lt;/li&gt; &#xA; &lt;li&gt;Add new discussion, rename discussion, remove discussion&lt;/li&gt; &#xA; &lt;li&gt;Export database to json format&lt;/li&gt; &#xA; &lt;li&gt;Export discussion to text format&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Installation and running&lt;/h1&gt; &#xA;&lt;p&gt;Make sure that your CPU supports &lt;code&gt;AVX2&lt;/code&gt; instruction set. Without it, this application won&#39;t run out of the box (for the pyllamacpp backend). To check your CPU features, please visit the website of your CPU manufacturer for more information and look for &lt;code&gt;Instruction set extension: AVX2&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;Default model &lt;code&gt;gpt4all-lora-quantized-ggml.bin&lt;/code&gt; is roughly 4GB in size.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Windows 10 and 11&lt;/h2&gt; &#xA;&lt;h3&gt;Automatic install&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;It is mandatory to have python &lt;a href=&#34;https://www.python.org/downloads/release/python-31010/&#34;&gt;3.10&lt;/a&gt; (The official one, not the one from Microsoft Store) and &lt;a href=&#34;https://git-scm.com/download/win&#34;&gt;git&lt;/a&gt; installed.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nomic-ai/gpt4all-ui/releases&#34;&gt;Go to the latest release section&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Download the &lt;code&gt;webui.bat&lt;/code&gt; if you are on windows or &lt;code&gt;webui.sh&lt;/code&gt; if you are on linux/mac. Put this file in a folder for example &lt;code&gt;/gpt4all-ui/&lt;/code&gt;, because when you run it, all the necessary files will be downloaded into that folder.&lt;/li&gt; &#xA; &lt;li&gt;Run the script and wait. It should install everything and start the chatbot. Chatbot will be avaliable from web browser &lt;code&gt;http://localhost:9600&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; During installtion, it may ask you to download a model. Feel free to accept or to download your own models depending on the backends you are using.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Once installed, you can run the app by using &lt;code&gt;webui.bat&lt;/code&gt; or &lt;code&gt;webui.sh&lt;/code&gt;. The script will check for any new updates&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ParisNeo/Gpt4All-webui/main/docs/usage/AdvancedInstallInstructions.md&#34;&gt;If you want to use a more advanced install procedure, please click here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Docker Compose&lt;/h2&gt; &#xA;&lt;p&gt;Make sure to put models the inside the &lt;code&gt;models&lt;/code&gt; directory. After that, you can simply use docker-compose or podman-compose to build and start the application:&lt;/p&gt; &#xA;&lt;p&gt;Build&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose -f docker-compose.yml build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Start&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose -f docker-compose.yml up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Stop &lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;C&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Start detached (runs in background)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose -f docker-compose.yml up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Stop detached (one that runs in background)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose stop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After that, you can open the application in your browser on &lt;a href=&#34;http://localhost:9600&#34;&gt;http://localhost:9600&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now you&#39;re ready to work!&lt;/p&gt; &#xA;&lt;h1&gt;Supported backends&lt;/h1&gt; &#xA;&lt;p&gt;Two backends are now supported:&lt;/p&gt; &#xA;&lt;p&gt;1- &lt;a href=&#34;https://github.com/abdeladim-s/pyllamacpp&#34;&gt;The llama_cpp backend by Abdeladim&lt;/a&gt; 2- &lt;a href=&#34;https://github.com/abdeladim-s/pygptj&#34;&gt;The GPT-j backend by Abdeladim&lt;/a&gt; 3- &lt;a href=&#34;https://github.com/marella/gpt4all-j&#34;&gt;The GPT-j backend by marella&lt;/a&gt; 4- Hugging face&#39;s Transformers (under construction)&lt;/p&gt; &#xA;&lt;h1&gt;Supported models&lt;/h1&gt; &#xA;&lt;p&gt;You can also refuse to download the model during the install procedure and download it manually.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For now, we support ggml models that work &#34;out-of-the-box&#34; (tested on Windows 11 and Ubuntu 22.04.2), such as:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;LLama_cpp models&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/ParisNeo/GPT4All/resolve/main/gpt4all-lora-quantized-ggml.bin&#34;&gt;GPT4ALL 7B&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/ParisNeo/GPT4All&#34;&gt;repository&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/ParisNeo/GPT4All/resolve/main/gpt4all-lora-unfiltered-quantized.new.bin&#34;&gt;GPT4ALL 7B unfiltered&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/ParisNeo/GPT4All&#34;&gt;repository&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit/resolve/main/ggml-vicuna-7b-4bit-rev1.bin&#34;&gt;Vicuna 7B rev 1&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit&#34;&gt;repository&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-4bit/resolve/main/ggml-vicuna-13b-4bit-rev1.bin&#34;&gt;Vicuna 13B rev 1&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-4bit&#34;&gt;repository&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin&#34;&gt;ggml-gpt4all-j-v1.3-groovy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://gpt4all.io/models/ggml-gpt4all-j-v1.2-jazzy.bin&#34;&gt;ggml-gpt4all-j-v1.2-jazzy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin&#34;&gt;ggml-gpt4all-l13b-snoozy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://gpt4all.io/models/ggml-gpt4all-j-v1.1-breezy.bin&#34;&gt;ggml-gpt4all-j-v1.1-breezy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://gpt4all.io/models/ggml-gpt4all-j.bin&#34;&gt;ggml-gpt4all-j&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://gpt4all.io/models/ggml-vicuna-7b-1.1-q4_2.bin&#34;&gt;ggml-vicuna-7b-1.1-q4_2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://gpt4all.io/models/ggml-vicuna-13b-1.1-q4_2.bin&#34;&gt;ggml-vicuna-13b-1.1-q4_2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/TheBloke/wizard-vicuna-13B-GGML/resolve/main/wizard-vicuna-13B.ggml.q4_2.bin&#34;&gt;wizard-vicuna-13B.ggml.q4_2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGML/resolve/main/WizardLM-7B-uncensored.ggml.q4_0.bin&#34;&gt;WizardLM-7B-uncensored.ggml.q4_0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/TheBloke/wizardLM-7B-GGML/resolve/main/wizardLM-7B.ggml.q4_2.bin&#34;&gt;wizardLM-7B.ggml.q4_2.bin&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We also support GPT-j models out of the box&lt;/p&gt; &#xA;&lt;h2&gt;GPT-j models&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpt4all.io/models/ggml-gpt4all-j.bin&#34;&gt;GPT-j 7B&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;These models don&#39;t work &#34;out-of-the-box&#34; and need to be converted to the right ggml type:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;LLAMACPP models&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit/resolve/main/ggml-vicuna-7b-4bit.bin&#34;&gt;Vicuna 7B&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/resolve/main/ggml-vicuna-13b-1.1-q4_0.bin&#34;&gt;Vicuna 13B q4 v0&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/resolve/main/ggml-vicuna-13b-1.1-q4_1.bin&#34;&gt;Vicuna 13B q4 v1&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml/resolve/main/ggml-alpaca-7b-q4.bin&#34;&gt;ALPACA 7B&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml/&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Just download the model into the &lt;code&gt;models/&amp;lt;backend name&amp;gt;&lt;/code&gt; folder and start using the tool.&lt;/p&gt; &#xA;&lt;h1&gt;Personalities&lt;/h1&gt; &#xA;&lt;p&gt;You can find hundreds of personalities in my personal &lt;a href=&#34;https://github.com/ParisNeo/PyAIPersonality&#34;&gt;Personalities repository&lt;/a&gt;. This new personalities format can be used for any third party applications, it builds a simple structure and format to define personalities. This format is evolutive and new fields and assets will be added in the future like personality voice or 3d animated character with prebaked motions that should allow AI to be more alive. The format is baked to support old versions while adding new capabilities for new versions making it ideal as a personality defintition format.&lt;/p&gt; &#xA;&lt;h3&gt;How to Install Personalities from the Zoo&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Navigate to the root directory of your repository.&lt;/li&gt; &#xA; &lt;li&gt;Run either &lt;code&gt;installations/add_personality.bat&lt;/code&gt; or &lt;code&gt;installations/add_personality.sh&lt;/code&gt;, depending on your operating system.&lt;/li&gt; &#xA; &lt;li&gt;Select the desired language, category, and personality from the provided options.&lt;/li&gt; &#xA; &lt;li&gt;The selected personality will be added to the list of available options.&lt;/li&gt; &#xA; &lt;li&gt;Choose the current personality: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Option 1: Use the UI by going to &#34;Settings&#34; and selecting &#34;Personalities&#34;.&lt;/li&gt; &#xA;   &lt;li&gt;Option 2: Update the configuration file &lt;code&gt;configs/default_local.yaml&lt;/code&gt; with the appropriate language, category, and personality name.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: Ensure that you have the necessary permissions and dependencies installed before performing the above steps.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;Please don&#39;t forget to take time and give a Star if you like the project. This helps the visibility of the project.&#xA;# Build custom personalities and share them&#xA;&#xA;To build a new personality, create a new file with the name of the personality inside the `personalities` folder. You can look at `gpt4all` personality as an example. Then you can fill the fields with the description, conditionning, etc. of your personality. Add a logo to your personality (avatar). Then save the file. I personally use stable diffusion to generate the avatars.&#xA;&#xA;&#xA;&#xA;You can launch the application using the personality in two ways:&#xA;- Change it permanently by putting the name of the personality inside your configuration file&#xA;- Use the `--personality` or `-p` option to give the personality name to be used&#xA;&#xA;If you deem your personality worthy of sharing, you can share the it by adding it to the [GPT4all personalities](https://github.com/ParisNeo/GPT4All_Personalities) repository. Just fork the repo, add your file, and do a pull request.&#xA;&#xA;# Advanced Usage&#xA;&#xA;If you want more control on your launch, you can activate your environment:&#xA;&#xA;On Windows:&#xA;```cmd&#xA;env/Scripts/activate.bat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On Linux/MacOs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;source venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you are ready to customize your Bot.&lt;/p&gt; &#xA;&lt;p&gt;To run the Flask server, execute the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python app.py [--config CONFIG] [--personality PERSONALITY] [--port PORT] [--host HOST] [--temp TEMP] [--n_threads N_THREADS] [--n_predict N_PREDICT] [--top_k TOP_K] [--top_p TOP_P] [--repeat_penalty REPEAT_PENALTY] [--repeat_last_n REPEAT_LAST_N] [--ctx_size CTX_SIZE]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On Linux/MacOS more details can be found &lt;a href=&#34;https://raw.githubusercontent.com/ParisNeo/Gpt4All-webui/main/docs/usage/Linux_Osx_Usage.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Options&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--config&lt;/code&gt;: the configuration file to be used. It contains default configurations. The script parameters will override the configurations inside the configuration file. It must be placed in configs folder (default: default.yaml)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--personality&lt;/code&gt;: the personality file name. It contains the definition of the pezrsonality of the chatbot and should be placed in personalities folder. The default personality is &lt;code&gt;gpt4all_chatbot.yaml&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--model&lt;/code&gt;: the name of the model to be used. The model should be placed in models folder (default: gpt4all-lora-quantized.bin)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--seed&lt;/code&gt;: the random seed for reproductibility. If fixed, it is possible to reproduce the outputs exactly (default: random)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: the port on which to run the server (default: 9600)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--host&lt;/code&gt;: the host address at which to run the server (default: localhost). To expose application to local network, set this to 0.0.0.0.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--temp&lt;/code&gt;: the sampling temperature for the model (default: 0.1)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--n_threads&lt;/code&gt;: the number of threads to be used (default:8)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--n-predict&lt;/code&gt;: the number of tokens to predict at a time (default: 128)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--top-k&lt;/code&gt;: the number of top-k candidates to consider for sampling (default: 40)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--top-p&lt;/code&gt;: the cumulative probability threshold for top-p sampling (default: 0.90)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--repeat-penalty&lt;/code&gt;: the penalty to apply for repeated n-grams (default: 1.3)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--repeat-last-n&lt;/code&gt;: the number of tokens to use for detecting repeated n-grams (default: 64)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--ctx-size&lt;/code&gt;: the maximum context size to use for generating responses (default: 2048)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note: All options are optional and have default values.&lt;/p&gt; &#xA;&lt;p&gt;Once the server is running, open your web browser and navigate to &lt;a href=&#34;http://localhost:9600&#34;&gt;http://localhost:9600&lt;/a&gt; (or &lt;a href=&#34;http://your-host-name:your-port-number&#34;&gt;http://your-host-name:your-port-number&lt;/a&gt; if you have selected different values for those) to access the chatbot UI. To use the app, open a web browser and navigate to this URL.&lt;/p&gt; &#xA;&lt;p&gt;Make sure to adjust the default values and descriptions of the options to match your specific application.&lt;/p&gt; &#xA;&lt;h1&gt;Contribute&lt;/h1&gt; &#xA;&lt;p&gt;This is an open-source project by the community and for the community. Our chatbot is a UI wrapper for Nomic AI&#39;s model, which enables natural language processing and machine learning capabilities.&lt;/p&gt; &#xA;&lt;p&gt;We welcome contributions from anyone who is interested in improving our chatbot. Whether you want to report a bug, suggest a feature, or submit a pull request, we encourage you to get involved and help us make our chatbot even better.&lt;/p&gt; &#xA;&lt;p&gt;Before contributing, please take a moment to review our &lt;a href=&#34;https://raw.githubusercontent.com/ParisNeo/Gpt4All-webui/main/CODE_OF_CONDUCT.md&#34;&gt;code of conduct&lt;/a&gt;. We expect all contributors to abide by this code of conduct, which outlines our expectations for respectful communication, collaborative development, and innovative contributions.&lt;/p&gt; &#xA;&lt;h3&gt;Reporting Bugs&lt;/h3&gt; &#xA;&lt;p&gt;If you find a bug or other issue with our chatbot, please report it by &lt;a href=&#34;https://github.com/nomic-ai/gpt4all-ui/issues/new&#34;&gt;opening an issue&lt;/a&gt;. Be sure to provide as much detail as possible, including steps to reproduce the issue and any relevant error messages.&lt;/p&gt; &#xA;&lt;h3&gt;Suggesting Features&lt;/h3&gt; &#xA;&lt;p&gt;If you have an idea for a new feature or improvement to our chatbot, we encourage you to &lt;a href=&#34;https://github.com/nomic-ai/gpt4all-ui/issues/new&#34;&gt;open an issue&lt;/a&gt; to discuss it. We welcome feedback and ideas from the community and will consider all suggestions that align with our project goals.&lt;/p&gt; &#xA;&lt;h3&gt;Contributing Code&lt;/h3&gt; &#xA;&lt;p&gt;If you want to contribute code to our chatbot, please follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork the repository and create a new branch for your changes.&lt;/li&gt; &#xA; &lt;li&gt;Make your changes and ensure that they follow our coding conventions.&lt;/li&gt; &#xA; &lt;li&gt;Test your changes to ensure that they work as expected.&lt;/li&gt; &#xA; &lt;li&gt;Submit a pull request with a clear description of your changes and the problem they solve.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;We will review your pull request as soon as possible and provide feedback on any necessary changes. We appreciate your contributions and look forward to working with you!&lt;/p&gt; &#xA;&lt;p&gt;Please note that all contributions are subject to review and approval by our project maintainers. We reserve the right to reject any contribution that does not align with our project goals or standards.&lt;/p&gt; &#xA;&lt;h1&gt;Future Plans&lt;/h1&gt; &#xA;&lt;p&gt;Here are some of the future plans for this project:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Enhanced control of chatbot parameters:&lt;/strong&gt; We plan to improve the UI of the chatbot to allow users to control the parameters of the chatbot such as temperature and other variables. This will give users more control over the chatbot&#39;s responses, and allow for a more customized experience.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Extension system for plugins:&lt;/strong&gt; We are also working on an extension system that will allow developers to create plugins for the chatbot. These plugins will be able to add new features and capabilities to the chatbot, and allow for greater customization of the chatbot&#39;s behavior.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Enhanced UI with themes and skins:&lt;/strong&gt; Additionally, we plan to enhance the UI of the chatbot to allow for themes and skins. This will allow users to personalize the appearance of the chatbot and make it more visually appealing.&lt;/p&gt; &#xA;&lt;p&gt;We are excited about these future plans for the project and look forward to implementing them in the near future. Stay tuned for updates!&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;This project is licensed under the Apache 2.0 License. See the &lt;a href=&#34;https://github.com/nomic-ai/GPT4All-ui/raw/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>IBM/plex</title>
    <updated>2023-07-02T01:53:26Z</updated>
    <id>tag:github.com,2023-07-02:/IBM/plex</id>
    <link href="https://github.com/IBM/plex" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The package of IBM’s typeface, IBM Plex.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;IBM Plex® typeface&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.ibm.com/plex/&#34;&gt; &lt;img alt=&#34;Plex&#34; src=&#34;https://i.imgur.com/yB9xz60.jpg&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;Meet the IBM Plex® typeface, our new corporate typeface family. It’s global, it’s versatile and it’s distinctly IBM.&lt;/p&gt; &#xA;&lt;p&gt;We designed the IBM Plex typeface carefully to both meet our needs as a global tech company and express who we are as IBMers. It took two years and a lot of work to get here, but today we have a signature typeface we’re proud and excited to share with the world. Discover more about our development of the &lt;a href=&#34;https://www.ibm.com/plex/&#34;&gt;IBM Plex typeface&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The IBM Plex typeface is an open-source project available for download and various uses following the Open Font License (OFL). The IBM Plex family comes in Sans, Serif, Mono, and Sans Condensed, all with roman and true italics. Plex has been designed to work well in user interface (UI) environments and other mediums. This project provides all source files and multiple formats to support most typographical situations. Currently, IBM Plex Sans supports Extended Latin, Arabic, Cyrillic, Devanagari, Greek, Hebrew, Japanese, Korean and Thai. Traditional and Simpliﬁed Chinese versions will be available in Q1 2024, and IBM Plex Math in Q2 2024.&lt;/p&gt; &#xA;&lt;p&gt;Thanks for trying the IBM Plex typeface! We hope you like it.&lt;/p&gt; &#xA;&lt;h2&gt;Add the IBM Plex typeface to your device&lt;/h2&gt; &#xA;&lt;p&gt;Please download the latest zip files from our &lt;a href=&#34;https://github.com/IBM/plex/releases&#34;&gt;releases page&lt;/a&gt; for installation.&lt;/p&gt; &#xA;&lt;h2&gt;Web usage&lt;/h2&gt; &#xA;&lt;p&gt;This project contains the following for web development:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;IBM Plex .woff2 and .woff files split into performant subsets of glyphs&lt;/li&gt; &#xA; &lt;li&gt;Cascading style sheet (CSS) code to reference any weight, variant and split&lt;/li&gt; &#xA; &lt;li&gt;Sassy CSS (SCSS) code partials down to each weight, variant and split&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We also include whole .woff2, .woff, and .eot files. However, we recommend using the prescribed split strategy for performance.&lt;/p&gt; &#xA;&lt;p&gt;Installation with &lt;a href=&#34;https://nodejs.org/en/&#34;&gt;Node.js®&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm install @ibm/plex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Manually installing the files for web development can be done by downloading the latest web zip from our &lt;a href=&#34;https://github.com/IBM/plex/releases&#34;&gt;releases page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Developers using the CSS files should keep the directory structure as is, so the font files will be found. If you’re importing the SCSS files, you can set the path of the font files beforehand by declaring this variable:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scss&#34;&gt;$font-prefix: &#39;./custom/path/to/font/files&#39;;&#xA;@import &#39;node_modules/@ibm/plex/scss/ibm-plex.scss&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If your app, for example, React, can’t import the font because it’s outside the ‘src’ directory, then edit the imported ‘ibm-plex.scss’ file and change the relative path prefix there as follows: &lt;code&gt;$font-prefix: &#39;&#39; !default;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Below are the &lt;code&gt;font-family&lt;/code&gt; rules for the family:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;font-family: &#39;IBM Plex Mono&#39;, &#39;Menlo&#39;, &#39;DejaVu Sans Mono&#39;,&#xA;  &#39;Bitstream Vera Sans Mono&#39;, Courier, monospace;&#xA;font-family: &#39;IBM Plex Sans&#39;, &#39;Helvetica Neue&#39;, Arial, sans-serif;&#xA;font-family: &#39;IBM Plex Sans Condensed&#39;, &#39;Helvetica Neue&#39;, Arial, sans-serif;&#xA;font-family: &#39;IBM Plex Serif&#39;, &#39;Georgia&#39;, Times, serif;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Building the fonts from source&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;p&gt;To build binary font files from .vfb sources you need &lt;a href=&#34;https://www.fontlab.com&#34;&gt;FontLab Studio 5&lt;/a&gt;. A Python script called &lt;code&gt;IBM Plex export FDK files.py&lt;/code&gt; is necessary to export the proper files from FontLab. To run this script you’ll need the &lt;a href=&#34;https://github.com/robofab-developers/robofab&#34;&gt;RoboFab&lt;/a&gt; library. Also, you’ll need to have the &lt;a href=&#34;http://www.adobe.com/devnet/opentype/afdko.html&#34;&gt;Adobe Font Development Kit for OpenType&lt;/a&gt; (AFDKO) installed.&lt;/p&gt; &#xA;&lt;h3&gt;Building one font&lt;/h3&gt; &#xA;&lt;p&gt;From FontLab, run &lt;code&gt;IBM Plex export FDK files.py&lt;/code&gt; and choose a directory with IBM Plex .vfb source files. The script will create a new directory called &lt;code&gt;fdk&lt;/code&gt; in which subdirectories are created for every font. The script will export files necessary for AFDKO in those subdirectories.&lt;/p&gt; &#xA;&lt;p&gt;Subsequently, OpenType Fonts (OTFs) or TrueType Fonts (TTFs) can be generated from the command line using &lt;code&gt;makeotf&lt;/code&gt;, which is part of the AFDKO toolset. Information and usage instructions can be found by executing &lt;code&gt;makeotf -h&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>