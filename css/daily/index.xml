<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub CSS Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-25T01:32:42Z</updated>
  <subtitle>Daily Trending of CSS in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>nomic-ai/gpt4all-ui</title>
    <updated>2023-04-25T01:32:42Z</updated>
    <id>tag:github.com,2023-04-25:/nomic-ai/gpt4all-ui</id>
    <link href="https://github.com/nomic-ai/gpt4all-ui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;gpt4all chatbot ui&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gpt4All Web UI&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/license/nomic-ai/GPT4All-ui&#34; alt=&#34;GitHub license&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues/nomic-ai/GPT4All-ui&#34; alt=&#34;GitHub issues&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/nomic-ai/GPT4All-ui&#34; alt=&#34;GitHub stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/nomic-ai/GPT4All-ui&#34; alt=&#34;GitHub forks&#34;&gt; &lt;a href=&#34;https://discord.gg/4rR282WJb6&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1092918764925882418?color=7289da&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=ffffff&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a Flask web application that provides a chat UI for interacting with &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llamacpp&lt;/a&gt; based chatbots such as &lt;a href=&#34;https://github.com/nomic-ai/gpt4all&#34;&gt;GPT4all&lt;/a&gt;, vicuna etc...&lt;/p&gt; &#xA;&lt;p&gt;Follow us on our &lt;a href=&#34;https://discord.gg/4rR282WJb6&#34;&gt;Discord Server&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Watch Install Video (Outdated, please use &#34;New UI video&#34;) &lt;a href=&#34;https://youtu.be/6kKv6ESnwMk&#34;&gt;Old Install Video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Watch Usage Videos &lt;a href=&#34;https://youtu.be/DCBefhJUUh4&#34;&gt;Usage Video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Watch Settings Video &lt;a href=&#34;https://youtu.be/7KwR2vdt1t4&#34;&gt;Settings Video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Watch New UI Video &lt;a href=&#34;https://youtu.be/M7NFajCyZKs&#34;&gt;New UI + Install&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.gyazo.com/ef94a5ac9169467a1aec228ef8c36c66.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;GPT4All is an exceptional language model, designed and developed by Nomic-AI, a proficient company dedicated to natural language processing. The app uses Nomic-AI&#39;s advanced library to communicate with the cutting-edge GPT4All model, which operates locally on the user&#39;s PC, ensuring seamless and efficient communication.&lt;/p&gt; &#xA;&lt;p&gt;If you are interested in learning more about this groundbreaking project, visit their &lt;a href=&#34;https://github.com/nomic-ai/gpt4all&#34;&gt;Github Repository&lt;/a&gt;, where you can find comprehensive information regarding the app&#39;s functionalities and technical details. Moreover, you can delve deeper into the training process and database by going through their detailed Technical report, available for download at &lt;a href=&#34;https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf&#34;&gt;Technical report&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;One of the app&#39;s impressive features is that it allows users to send messages to the chatbot and receive instantaneous responses in real time, ensuring a seamless user experience. Additionally, the app facilitates the exportation of the entire chat history in either text or JSON format, providing greater flexibility to the users.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s worth noting that the model has recently been launched, and it&#39;s expected to evolve across time, enabling it to become even better in the future. This web UI is designed to provide the community with easy and fully localized access to a chatbot that will continue to improve and adapt across time.&lt;/p&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Chat with locally hosted AI inside a web browser&lt;/li&gt; &#xA; &lt;li&gt;Create, edit, and share your AI&#39;s personality&lt;/li&gt; &#xA; &lt;li&gt;Audio in and audio out with many options for language and voices (only Chrome web browser is supported at this time)&lt;/li&gt; &#xA; &lt;li&gt;History of discussion with resume functionality&lt;/li&gt; &#xA; &lt;li&gt;Add new discussion, rename discussion, remove discussion&lt;/li&gt; &#xA; &lt;li&gt;Export database to json format&lt;/li&gt; &#xA; &lt;li&gt;Export discussion to text format&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Installation and running&lt;/h1&gt; &#xA;&lt;p&gt;Make sure that your CPU supports &lt;code&gt;AVX2&lt;/code&gt; instruction set. Without it, this application won&#39;t run out of the box. To check your CPU features, please visit the website of your CPU manufacturer for more information and look for &lt;code&gt;Instruction set extension: AVX2&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;Default model &lt;code&gt;gpt4all-lora-quantized-ggml.bin&lt;/code&gt; is roughly 4GB in size.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Windows 10 and 11&lt;/h2&gt; &#xA;&lt;h3&gt;Automatic install&lt;/h3&gt; &#xA;&lt;p&gt;It is advised to have python 3.10 (The official one, not the one from Microsoft Store) and git installed. Although it should work with any python from 3.7, it is advised to use 3.10 to have the full support as some extensions like the future stable diffusion extension will force you to have 3.10.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nomic-ai/gpt4all-ui/releases&#34;&gt;Go to the latest release section&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Download the &lt;code&gt;webui.bat&lt;/code&gt; if you are on windows or &lt;code&gt;webui.sh&lt;/code&gt; if you are on linux/mac. but the download in a folder you name for example gpt4all-ui&lt;/li&gt; &#xA; &lt;li&gt;Run the script and wait. It should install everything and start the chatbot&lt;/li&gt; &#xA; &lt;li&gt;Before running, it may ask you to download a model. Feel free to accept or to download your own models depending on the backends you are using.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Once installed, you should see a new folder called GPT4All. From now on, you can run the app by using webui.bat or webui.sh. The script will check for any new updates&lt;/p&gt; &#xA;&lt;h3&gt;Manual Simple install:&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download this repository .zip:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/80409979/232210909-0ce3dc80-ed34-4b32-b828-e124e3df3ff1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Extract contents into a folder.&lt;/li&gt; &#xA; &lt;li&gt;Install/run application by double clicking on &lt;code&gt;webui.bat&lt;/code&gt; file from Windows Explorer as normal user.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Manual Advanced mode:&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://git-scm.com/download/win&#34;&gt;git&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Open Terminal/PowerShell and navigate to a folder you want to clone this repository.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/nomic-ai/gpt4all-ui.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Install/run application by double clicking on &lt;code&gt;webui.bat&lt;/code&gt; file from Windows explorer as normal user.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Linux&lt;/h2&gt; &#xA;&lt;h3&gt;Automatic install&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Make sure you have installed &lt;code&gt;curl&lt;/code&gt;. It is needed for the one-liner to work.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;code&gt;Debian-based:&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt install curl &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;Red Hat-based:&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo dnf install curl &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;Arch-based:&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo pacman -S curl &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Open terminal/console copy and paste this command and press enter:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir -p ~/gpt4all-ui &amp;amp;&amp;amp; curl -L https://raw.githubusercontent.com/nomic-ai/gpt4all-ui/main/webui.sh -o ~/gpt4all-ui/webui.sh &amp;amp;&amp;amp; chmod +x ~/gpt4all-ui/webui.sh &amp;amp;&amp;amp; cd ~/gpt4all-ui &amp;amp;&amp;amp; ./webui.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This command creates new directory &lt;code&gt;/gpt4all-ui/&lt;/code&gt; in your /home/ direcory, downloads a file &lt;a href=&#34;https://raw.githubusercontent.com/nomic-ai/gpt4all-ui/main/webui.sh&#34;&gt;webui.sh&lt;/a&gt;, makes file executable and executes webui.sh that downloads and installs everything that is needed.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Follow instructions on screen until it launches webui.&lt;/li&gt; &#xA; &lt;li&gt;To relaunch application:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash webui.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Manual Simple install:&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download this repository .zip:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/80409979/232210909-0ce3dc80-ed34-4b32-b828-e124e3df3ff1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Extract contents into a folder.&lt;/li&gt; &#xA; &lt;li&gt;Install/run application from terminal/console:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash webui.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Manual Advanced mode:&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open terminal/console and install dependencies:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;code&gt;Debian-based:&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt install curl git python3 python3-venv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;Red Hat-based:&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo dnf install curl git python3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;Arch-based:&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo pacman -S curl git python3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Clone repository:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/nomic-ai/gpt4all-ui.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd gpt4all-ui&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install/run application:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bash ./webui.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;MacOS&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open terminal/console and install &lt;code&gt;brew&lt;/code&gt;:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ /bin/bash -c &#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install dependencies:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install git python3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Clone repository:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/nomic-ai/gpt4all-ui.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd gpt4all-ui&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Install/run application:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bash ./webui.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On Linux/MacOS, if you have issues, refer to the details presented &lt;a href=&#34;https://raw.githubusercontent.com/nomic-ai/gpt4all-ui/main/docs/Linux_Osx_Install.md&#34;&gt;here&lt;/a&gt; These scripts will create a Python virtual environment and install the required dependencies. It will also download the models and install them.&lt;/p&gt; &#xA;&lt;h2&gt;Docker Compose&lt;/h2&gt; &#xA;&lt;p&gt;Make sure to put models the inside the &lt;code&gt;models&lt;/code&gt; directory. After that, you can simply use docker-compose or podman-compose to build and start the application:&lt;/p&gt; &#xA;&lt;p&gt;Build&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose -f docker-compose.yml build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Start&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose -f docker-compose.yml up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Stop &lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;C&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Start detached (runs in background)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose -f docker-compose.yml up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Stop detached (one that runs in background)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose stop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After that, you can open the application in your browser on &lt;a href=&#34;http://localhost:9600&#34;&gt;http://localhost:9600&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now you&#39;re ready to work!&lt;/p&gt; &#xA;&lt;h1&gt;Supported backends&lt;/h1&gt; &#xA;&lt;p&gt;Two backends are now supported: 1 - &lt;a href=&#34;https://github.com/nomic-ai/pygpt4all&#34;&gt;The llama_cpp backend&lt;/a&gt; 2 - &lt;a href=&#34;https://github.com/marella/gpt4all-j&#34;&gt;The GPT-j backend&lt;/a&gt; 3 - Hugging face&#39;s Transformers (under construction)&lt;/p&gt; &#xA;&lt;h1&gt;Supported models&lt;/h1&gt; &#xA;&lt;p&gt;You can also refuse to download the model during the install procedure and download it manually.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For now, we support ggml models that work &#34;out-of-the-box&#34; (tested on Windows 11 and Ubuntu 22.04.2), such as:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;LLama_cpp models&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/ParisNeo/GPT4All/resolve/main/gpt4all-lora-quantized-ggml.bin&#34;&gt;GPT4ALL 7B&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/ParisNeo/GPT4All&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/ParisNeo/GPT4All/blob/main/gpt4all-lora-unfiltered-quantized.new.bin&#34;&gt;GPT4ALL 7B unfiltered&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/ParisNeo/GPT4All&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit/resolve/main/ggml-vicuna-7b-4bit-rev1.bin&#34;&gt;Vicuna 7B rev 1&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-4bit/resolve/main/ggml-vicuna-13b-4bit-rev1.bin&#34;&gt;Vicuna 13B rev 1&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-4bit&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;GPT-j models&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpt4all.io/models/ggml-gpt4all-j.bin&#34;&gt;GPT-j 7B&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;These models don&#39;t work &#34;out-of-the-box&#34; and need to be converted to the right ggml type:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;LLAMACPP models&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit/resolve/main/ggml-vicuna-7b-4bit.bin&#34;&gt;Vicuna 7B&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/resolve/main/ggml-vicuna-13b-1.1-q4_0.bin&#34;&gt;Vicuna 13B q4 v0&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/resolve/main/ggml-vicuna-13b-1.1-q4_1.bin&#34;&gt;Vicuna 13B q4 v1&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml/resolve/main/ggml-alpaca-7b-q4.bin&#34;&gt;ALPACA 7B&lt;/a&gt; or visit &lt;a href=&#34;https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml/&#34;&gt;repository&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Just download the model into the &lt;code&gt;models&lt;/code&gt; folder and start using the tool.&lt;/p&gt; &#xA;&lt;h1&gt;Build custom personalities and share them&lt;/h1&gt; &#xA;&lt;p&gt;To build a new personality, create a new file with the name of the personality inside the &lt;code&gt;personalities&lt;/code&gt; folder. You can look at &lt;code&gt;gpt4all_chatbot.yaml&lt;/code&gt; file as an example. Then you can fill the fields with the description, conditionning, etc. of your personality. Then save the file.&lt;/p&gt; &#xA;&lt;p&gt;You can launch the application using the personality in two ways:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Change it permanently by putting the name of the personality inside your configuration file&lt;/li&gt; &#xA; &lt;li&gt;Use the &lt;code&gt;--personality&lt;/code&gt; or &lt;code&gt;-p&lt;/code&gt; option to give the personality name to be used&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you deem your personality worthy of sharing, you can share the it by adding it to the &lt;a href=&#34;https://github.com/ParisNeo/GPT4All_Personalities&#34;&gt;GPT4all personalities&lt;/a&gt; repository. Just fork the repo, add your file, and do a pull request.&lt;/p&gt; &#xA;&lt;h1&gt;Advanced Usage&lt;/h1&gt; &#xA;&lt;p&gt;If you want more control on your launch, you can activate your environment:&lt;/p&gt; &#xA;&lt;p&gt;On Windows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;env/Scripts/activate.bat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On Linux/MacOs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;source venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you are ready to customize your Bot.&lt;/p&gt; &#xA;&lt;p&gt;To run the Flask server, execute the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python app.py [--config CONFIG] [--personality PERSONALITY] [--port PORT] [--host HOST] [--temp TEMP] [--n_threads N_THREADS] [--n_predict N_PREDICT] [--top_k TOP_K] [--top_p TOP_P] [--repeat_penalty REPEAT_PENALTY] [--repeat_last_n REPEAT_LAST_N] [--ctx_size CTX_SIZE]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On Linux/MacOS more details can be found &lt;a href=&#34;https://raw.githubusercontent.com/nomic-ai/gpt4all-ui/main/docs/Linux_Osx_Usage.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Options&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--config&lt;/code&gt;: the configuration file to be used. It contains default configurations. The script parameters will override the configurations inside the configuration file. It must be placed in configs folder (default: default.yaml)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--personality&lt;/code&gt;: the personality file name. It contains the definition of the pezrsonality of the chatbot and should be placed in personalities folder. The default personality is &lt;code&gt;gpt4all_chatbot.yaml&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--model&lt;/code&gt;: the name of the model to be used. The model should be placed in models folder (default: gpt4all-lora-quantized.bin)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--seed&lt;/code&gt;: the random seed for reproductibility. If fixed, it is possible to reproduce the outputs exactly (default: random)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: the port on which to run the server (default: 9600)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--host&lt;/code&gt;: the host address at which to run the server (default: localhost). To expose application to local network, set this to 0.0.0.0.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--temp&lt;/code&gt;: the sampling temperature for the model (default: 0.1)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--n_threads&lt;/code&gt;: the number of threads to be used (default:8)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--n-predict&lt;/code&gt;: the number of tokens to predict at a time (default: 128)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--top-k&lt;/code&gt;: the number of top-k candidates to consider for sampling (default: 40)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--top-p&lt;/code&gt;: the cumulative probability threshold for top-p sampling (default: 0.90)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--repeat-penalty&lt;/code&gt;: the penalty to apply for repeated n-grams (default: 1.3)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--repeat-last-n&lt;/code&gt;: the number of tokens to use for detecting repeated n-grams (default: 64)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--ctx-size&lt;/code&gt;: the maximum context size to use for generating responses (default: 2048)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note: All options are optional and have default values.&lt;/p&gt; &#xA;&lt;p&gt;Once the server is running, open your web browser and navigate to &lt;a href=&#34;http://localhost:9600&#34;&gt;http://localhost:9600&lt;/a&gt; (or &lt;a href=&#34;http://your&#34;&gt;http://your&lt;/a&gt; host name:your port number if you have selected different values for those) to access the chatbot UI. To use the app, open a web browser and navigate to this URL.&lt;/p&gt; &#xA;&lt;p&gt;Make sure to adjust the default values and descriptions of the options to match your specific application.&lt;/p&gt; &#xA;&lt;h1&gt;Contribute&lt;/h1&gt; &#xA;&lt;p&gt;This is an open-source project by the community and for the community. Our chatbot is a UI wrapper for Nomic AI&#39;s model, which enables natural language processing and machine learning capabilities.&lt;/p&gt; &#xA;&lt;p&gt;We welcome contributions from anyone who is interested in improving our chatbot. Whether you want to report a bug, suggest a feature, or submit a pull request, we encourage you to get involved and help us make our chatbot even better.&lt;/p&gt; &#xA;&lt;p&gt;Before contributing, please take a moment to review our &lt;a href=&#34;https://raw.githubusercontent.com/nomic-ai/gpt4all-ui/main/CODE_OF_CONDUCT.md&#34;&gt;code of conduct&lt;/a&gt;. We expect all contributors to abide by this code of conduct, which outlines our expectations for respectful communication, collaborative development, and innovative contributions.&lt;/p&gt; &#xA;&lt;h3&gt;Reporting Bugs&lt;/h3&gt; &#xA;&lt;p&gt;If you find a bug or other issue with our chatbot, please report it by &lt;a href=&#34;https://github.com/your-username/your-chatbot/issues/new&#34;&gt;opening an issue&lt;/a&gt;. Be sure to provide as much detail as possible, including steps to reproduce the issue and any relevant error messages.&lt;/p&gt; &#xA;&lt;h3&gt;Suggesting Features&lt;/h3&gt; &#xA;&lt;p&gt;If you have an idea for a new feature or improvement to our chatbot, we encourage you to &lt;a href=&#34;https://github.com/your-username/your-chatbot/issues/new&#34;&gt;open an issue&lt;/a&gt; to discuss it. We welcome feedback and ideas from the community and will consider all suggestions that align with our project goals.&lt;/p&gt; &#xA;&lt;h3&gt;Contributing Code&lt;/h3&gt; &#xA;&lt;p&gt;If you want to contribute code to our chatbot, please follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork the repository and create a new branch for your changes.&lt;/li&gt; &#xA; &lt;li&gt;Make your changes and ensure that they follow our coding conventions.&lt;/li&gt; &#xA; &lt;li&gt;Test your changes to ensure that they work as expected.&lt;/li&gt; &#xA; &lt;li&gt;Submit a pull request with a clear description of your changes and the problem they solve.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;We will review your pull request as soon as possible and provide feedback on any necessary changes. We appreciate your contributions and look forward to working with you!&lt;/p&gt; &#xA;&lt;p&gt;Please note that all contributions are subject to review and approval by our project maintainers. We reserve the right to reject any contribution that does not align with our project goals or standards.&lt;/p&gt; &#xA;&lt;h1&gt;Future Plans&lt;/h1&gt; &#xA;&lt;p&gt;Here are some of the future plans for this project:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Enhanced control of chatbot parameters:&lt;/strong&gt; We plan to improve the UI of the chatbot to allow users to control the parameters of the chatbot such as temperature and other variables. This will give users more control over the chatbot&#39;s responses, and allow for a more customized experience.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Extension system for plugins:&lt;/strong&gt; We are also working on an extension system that will allow developers to create plugins for the chatbot. These plugins will be able to add new features and capabilities to the chatbot, and allow for greater customization of the chatbot&#39;s behavior.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Enhanced UI with themes and skins:&lt;/strong&gt; Additionally, we plan to enhance the UI of the chatbot to allow for themes and skins. This will allow users to personalize the appearance of the chatbot and make it more visually appealing.&lt;/p&gt; &#xA;&lt;p&gt;We are excited about these future plans for the project and look forward to implementing them in the near future. Stay tuned for updates!&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;This project is licensed under the Apache 2.0 License. See the &lt;a href=&#34;https://github.com/nomic-ai/GPT4All-ui/raw/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>KiritoCheng/openai-public</title>
    <updated>2023-04-25T01:32:42Z</updated>
    <id>tag:github.com,2023-04-25:/KiritoCheng/openai-public</id>
    <link href="https://github.com/KiritoCheng/openai-public" rel="alternate"></link>
    <summary type="html">&lt;p&gt;openai-public&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;openai-public&lt;/h1&gt; &#xA;&lt;p&gt;项目示例：&lt;a href=&#34;https://kiritosa.com/ai/&#34;&gt;https://kiritosa.com/ai/&lt;/a&gt;&lt;br&gt; 搭配openai3.5接口写出的聊天AI页，后端项目请前往&lt;a href=&#34;https://github.com/KiritoCheng/openai-server&#34;&gt;openai-server&lt;/a&gt;仓库查看。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/19926113/231107329-c43a1592-aef5-412d-a42b-2c49342b8921.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>