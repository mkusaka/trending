<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-26T02:26:06Z</updated>
  <subtitle>Weekly Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>wangshusen/DeepLearning</title>
    <updated>2022-06-26T02:26:06Z</updated>
    <id>tag:github.com,2022-06-26:/wangshusen/DeepLearning</id>
    <link href="https://github.com/wangshusen/DeepLearning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CS583: Deep Learning&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Machine learning basics.&lt;/strong&gt; This part briefly introduces the fundamental ML problems-- regression, classification, dimensionality reduction, and clustering-- and the traditional ML models and numerical algorithms for solving the problems.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;ML basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/1_ML_Basics.pdf&#34;&gt;slides-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/1_Models.pdf&#34;&gt;slides-2&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Regression [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/2_Regression_1.pdf&#34;&gt;slides-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/2_Regression_2.pdf&#34;&gt;slides-2&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Classification.&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;Logistic regression [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Classification_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/Logistic/paper/logistic.pdf&#34;&gt;lecture note&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;SVM [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Classification_2.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;Softmax classifier [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Classification_3.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;KNN classifier [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Classification_4.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Regularizations [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Optimization.pdf&#34;&gt;slides-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Regularizations.pdf&#34;&gt;slides-2&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Clustering [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Clustering.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Dimensionality reduction [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/5_DR_1.pdf&#34;&gt;slides-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/5_DR_2.pdf&#34;&gt;slides-2&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/SVD/svd.pdf&#34;&gt;lecture note&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Scientific computing libraries. [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/5_DR_3.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Neural network basics.&lt;/strong&gt; This part covers the multilayer perceptron, backpropagation, and deep learning libraries, with focus on Keras.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Multilayer perceptron and backpropagation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/6_NeuralNet_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/BP/bp.pdf&#34;&gt;lecture note&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Keras [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/6_NeuralNet_2.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Further reading:&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;[&lt;a href=&#34;https://adl1995.github.io/an-overview-of-activation-functions-used-in-neural-networks.html&#34;&gt;activation functions&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;[&lt;a href=&#34;https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&#34;&gt;parameter initialization&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;[&lt;a href=&#34;http://ruder.io/optimizing-gradient-descent/&#34;&gt;optimization algorithms&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Convolutional neural networks (CNNs).&lt;/strong&gt; This part is focused on CNNs and its application to computer vision problems.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;CNN basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_1.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Tricks for improving test accuracy [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_2.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Feature scaling and batch normalization [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_3.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Advanced topics on CNNs [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_4.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Popular CNN architectures [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_5.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Further reading:&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;[style transfer (Section 8.1, Chollet&#39;s book)]&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;[visualize CNN (Section 5.4, Chollet&#39;s book)]&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Recurrent neural networks (RNNs).&lt;/strong&gt; This part introduces RNNs and its applications in natural language processing (NLP).&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Categorical feature processing [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_0.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/NWcShtqr8kc&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Text processing and word embedding [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/6_2_2CPB97s&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;RNN basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/Cc4ENs6BHQw&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;LSTM [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&#34;&gt;reference&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/vTouAvxlphc&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Making RNNs more effective [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_4.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/pzWHk_M23a0&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Text generation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_5.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/10cjvcrU_ZU&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Machine translation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_6.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/gxXJ58LR684&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Attention [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_8.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/B3uws4cLcFw&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/XhWdv7ghmQQ&#34;&gt;video (Chinese)&lt;/a&gt;] [&lt;a href=&#34;https://distill.pub/2016/augmented-rnns/&#34;&gt;reference&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Self-attention [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_9.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/06r6kp7ujCA&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/Vr4UNt7X6Gw&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Image caption generation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_7.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/&#34;&gt;reference&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transformer Models.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Transformer (1/2): attention without RNN [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/10_Transformer_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/FC8PziPmxnQ&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/aButdUV0dxI&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Transformer (2/2): from shallow to deep [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/10_Transformer_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/J4H6A4-dvhE&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/aJRsr39F4dI&#34;&gt;video (Chinese)&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/pdf/1706.03762.pdf&#34;&gt;reference&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;BERT: pre-training Transformer [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/10_BERT.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/EOmd5sUUA_A&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/UlC6AjQWao8&#34;&gt;video (Chinese)&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/pdf/1810.04805.pdf&#34;&gt;reference&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Vision Transformer (ViT) [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/10_ViT.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/HZ4j_U3FC94&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/BbzOZ9THriY&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Autoencoders.&lt;/strong&gt; This part introduces autoencoders for dimensionality reduction and image generation.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Autoencoder for dimensionality reduction [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/8_AE_1.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Variational Autoencoders (VAEs) for image generation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/8_AE_2.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Generative Adversarial Networks (GANs).&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;DC-GAN [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/12_GAN.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deep Reinforcement Learning.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Reinforcement learning basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/DRL/DRL.pdf&#34;&gt;lecture note&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/vmkRMvhCW5c&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Value-based learning [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/jflq6vNcZyA&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Policy-based learning [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/qI0vyfR2_Rc&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Actor-critic methods [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_4.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/xjd7Jq9wPQY&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;AlphaGo and Monte Carlo tree search [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_5.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/zHojAp5vkRE&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Parallel Computing.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Basics and MapReduce [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/14_Parallel_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/Parallel/Parallel.pdf&#34;&gt;lecture note&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/gVcnOe6_c6Q&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Parameter server and decentralized network [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/14_Parallel_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/Aga2Lxp3G7M&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;TensorFlow&#39;s mirrored strategy and ring all-reduce [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/14_Parallel_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/rj-hjS5L8Bw&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Federated learning [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/14_Parallel_4.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/STxtRucv_zo&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Adversarial Robustness.&lt;/strong&gt; This part introduces how to attack neural networks using adversarial examples and how to defend from the attack.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Data evasion attack and defense [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/11_Evasion.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/Adversarial/DataAttacks.pdf&#34;&gt;lecture note&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Data poisoning attack [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/11_Poisoning.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/_K0nZcqdu5w&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Further reading: [&lt;a href=&#34;https://adversarial-ml-tutorial.org/&#34;&gt;Adversarial Robustness - Theory and Practice&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Meta Learning.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Few-shot learning: basic concepts [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/16_Meta_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/hE7eGew4eeg&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/UkQ2FVpDxHg&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Siamese network [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/16_Meta_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/4S-XDefSjTM&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/Er8xH_k0Vj4&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Pretraining + fine tuning [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/16_Meta_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/U6uFOIURcD0&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/3zSYMuDm6RU&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Neural Architecture Search (NAS).&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/15_NAS_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/voWgnMpFaW8&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;RNN + Reinforcement Learning: [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/15_NAS_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/AmitvRzmvv0&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Differentiable NAS: [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/15_NAS_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/D9m9-CXw_HY&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>rstudio/cheatsheets</title>
    <updated>2022-06-26T02:26:06Z</updated>
    <id>tag:github.com,2022-06-26:/rstudio/cheatsheets</id>
    <link href="https://github.com/rstudio/cheatsheets" rel="alternate"></link>
    <summary type="html">&lt;p&gt;RStudio Cheat Sheets&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;RStudio Cheatsheets&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/rstudio-ide.png&#34; width=&#34;364&#34; height=&#34;288&#34; align=&#34;right&#34;&gt; &#xA;&lt;p&gt;The cheatsheets make it easy to learn about and use some of our favorite packages. They are published in their respective PDF versions here: &lt;a href=&#34;https://www.rstudio.com/resources/cheatsheets/&#34;&gt;https://www.rstudio.com/resources/cheatsheets/&lt;/a&gt;, some are also available in the RStudio IDE under Help &amp;gt; Cheat Sheets.&lt;/p&gt; &#xA;&lt;p&gt;This repository contains the source files of the current, archived and translated versions.&lt;/p&gt; &#xA;&lt;p&gt;The cheatsheets use the creative commons copyright. Please see the LICENSE document for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Translations&lt;/h2&gt; &#xA;&lt;p&gt;If you wish to contribute to this effort by translating a cheatsheet, please feel free to use the source Keynote file. To submit a translation, please use a Pull Request via GitHub. See the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/main/.github/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Tips for making a new RStudio cheatsheet&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;RStudio cheatsheets are not meant to be text or documentation!&lt;/strong&gt; They are scannable visual aids that use layout and visual mnemonics to help people zoom to the functions they need. Think of cheatsheets as a quick reference, with the emphasis on quick. Here&#39;s an analogy:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;A cheatsheet is more like a well-organized computer menu bar that leads you to a command than like a manual that documents each command.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Everything about your cheatsheet should be designed to lead users to essential information &lt;em&gt;quickly&lt;/em&gt;. If you are summarizing the documentation manual, you are doing it wrong! Here are some tips to help you do it right:&lt;/p&gt; &#xA;&lt;h3&gt;Getting Started&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;RStudio cheatsheets are hosted at &lt;a href=&#34;https://github.com/rstudio/cheatsheets&#34;&gt;https://github.com/rstudio/cheatsheets&lt;/a&gt;. You can submit new cheatsheets to the repository with a pull request. See the &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/main/.github/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt; for more information.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The files &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/main/keynotes/0-template.key&#34;&gt;keynotes/0-template.key&lt;/a&gt; and &lt;a href=&#34;https://github.com/rstudio/cheatsheets/raw/main/powerpoints/0-template.pptx&#34;&gt;powerpoints/0-template.ppt&lt;/a&gt; are official templates that contain some helpful tips.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You may find it easiest to create a new cheatsheet by duplicating the most recent Keynote / Powerpoint cheatsheet and then heavily editing itâ€”that&#39;s what I do!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Process&lt;/h3&gt; &#xA;&lt;p&gt;Budget more time than you expect to make the sheets. So far, I&#39;ve found this process to be the least time consuming:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Identify which functions to include&lt;/strong&gt; by reading the package web page and vignettes. I try to limit my cheatsheets to the essentials.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Organize the functions&lt;/strong&gt; into meaningful, self-explanatory groups. Each group should address a common problem or task.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Think about how to visualize the purpose of each function.&lt;/strong&gt; Visual mnemonics are easier to scan than text, which all looks the same.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Think about&lt;/strong&gt; what &lt;strong&gt;key mental models&lt;/strong&gt;, definitions, or explanations the cheatsheet should contain in addition to the functions. Ideally, use these to explain the visualizations.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Sketch out several possible layouts&lt;/strong&gt; for the sheet. Take care to put the more basic and/or pre-requisite content above and to the left of other content. Try to keep related content on the same side of the page. often your final layout will itself be a &#34;mental map&#34; for the topic of the cheatsheet.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Type out all of the explanations and function descriptions&lt;/strong&gt; that you plan to include. Lay them out. Use placeholders for the visuals. Verify that everything fits. White space is very important. Use it to make the sheet scannable and to isolate content groups. Retain white space, even if it means smaller text.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Make the visuals.&lt;/strong&gt; They take the longest, so I save them for last or make them as I do step 6.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tweak until happy.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Visual Design&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Use the existing theme&lt;/strong&gt; that you see in the cheatsheets. It is cohesive and black and white printer friendly.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Choose a highlight color&lt;/strong&gt; to use throughout your cheatsheet, and repeat this highlight color in the background of the top right corner. Ideally you could find a color that is different enough from the other cheatsheets that you can quickly tell yours apart when flipping through a booklet of cheatsheets.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Use a second color sparingly or not at all&lt;/strong&gt; to draw attention to where it is needed and to differentiate different groupings of content.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Include lots of white space.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Visually differentiate groups of content.&lt;/strong&gt; Backgrounds, boxes, side bars, and headers are helpful here. It is very useful for the user to know immediately where one group of content begins and where one ends. Our &#34;gradation headers&#34; fail here, so think of better solutions if possible.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Align things&lt;/strong&gt; to guides, i.e. align things across the page. It helps define the white space and makes the cheat more orderly and professional.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Make the text no smaller than ~10pt.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;If the letters are white on a colored background&lt;/strong&gt;, make the font thicker - semibold or bold.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Save bold text&lt;/strong&gt; for simple, important statements, or to draw scanning eyes to important words, such as words that identify the topic discussed. Don&#39;t make an entire paragraph bold text.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Content&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Include a hex sticker, IDE screenshot, or other branding material&lt;/strong&gt;. The cheatsheets have a second function as marketing material.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Include a &lt;a href=&#34;https://creativecommons.org/&#34;&gt;Creative Commons Copyright&lt;/a&gt;&lt;/strong&gt; to make the sheet easy to share. You&#39;ll find one baked into every cheatsheet and the template.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Be very concise&lt;/strong&gt; - rely on diagrams where possible.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pay attention to the details!&lt;/strong&gt; Your readers sure will... so be correct.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;If in doubt, leave it out.&lt;/strong&gt; There is a documentation manual after all.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Code comments inform, but fail&lt;/strong&gt; to draw the readers attention. It is better to use arrows, speech bubbles, etc. for important information. If it is not important information, leave it out.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simple working examples are more helpful than documentation details.&lt;/strong&gt; They meet the user at his or her pain points, demonstrating code, and reminding users how to run it, with the least context shifting.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Add some concise text to &lt;strong&gt;help the user make sense of your sections and diagrams&lt;/strong&gt;. Images are best, but readers need to be able to interpret them.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Summary&lt;/h3&gt; &#xA;&lt;p&gt;Your cheatsheet has two goals. First, to help users find essential information quickly, and second, to prevent confusion while doing the above. Your best strategy will be to limit the amount of information you put into the cheatsheet and to lay that information out intuitively and visually. This approach will make your cheatsheet equally useful as a teaching tool, programming tool, or marketing tool.&lt;/p&gt; &#xA;&lt;p&gt;Cheatsheets fall squarely on the &lt;em&gt;human-facing side of software design&lt;/em&gt;. They focus on human attention. What does that mean? When you write documentation, your job is to fill in all of the relevant detailsâ€”that&#39;s a software facing job, you need to know the software to do it. You assume that interested humans will find their way to your details on their own (and understand them when they do!). When you make a cheatsheet, your job flips. You assume that the relevant details already exist in the documentation. Your job is to help interested humans find them and understand them. Your job is to guide the human&#39;s attention. Don&#39;t just write, design.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>posquit0/Awesome-CV</title>
    <updated>2022-06-26T02:26:06Z</updated>
    <id>tag:github.com,2022-06-26:/posquit0/Awesome-CV</id>
    <link href="https://github.com/posquit0/Awesome-CV" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ðŸ“„ Awesome CV is LaTeX template for your outstanding job application&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/posquit0/Awesome-CV&#34; title=&#34;AwesomeCV Documentation&#34;&gt; &lt;img alt=&#34;AwesomeCV&#34; src=&#34;https://github.com/posquit0/Awesome-CV/raw/master/icon.png&#34; width=&#34;200px&#34; height=&#34;200px&#34;&gt; &lt;/a&gt; &lt;br&gt; Awesome CV &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; LaTeX template for your outstanding job application &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.paypal.me/posquit0&#34;&gt; &lt;img alt=&#34;Donate&#34; src=&#34;https://img.shields.io/badge/Donate-PayPal-blue.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/posquit0/Awesome-CV/actions/workflows/main.yml&#34;&gt; &lt;img alt=&#34;GitHub Actions&#34; src=&#34;https://github.com/posquit0/Awesome-CV/actions/workflows/main.yml/badge.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf&#34;&gt; &lt;img alt=&#34;Example Resume&#34; src=&#34;https://img.shields.io/badge/resume-pdf-green.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/cv.pdf&#34;&gt; &lt;img alt=&#34;Example CV&#34; src=&#34;https://img.shields.io/badge/cv-pdf-green.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf&#34;&gt; &lt;img alt=&#34;Example Coverletter&#34; src=&#34;https://img.shields.io/badge/coverletter-pdf-green.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;What is Awesome CV?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Awesome CV&lt;/strong&gt; is LaTeX template for a &lt;strong&gt;CV(Curriculum Vitae)&lt;/strong&gt;, &lt;strong&gt;RÃ©sumÃ©&lt;/strong&gt; or &lt;strong&gt;Cover Letter&lt;/strong&gt; inspired by &lt;a href=&#34;https://www.sharelatex.com/templates/cv-or-resume/fancy-cv&#34;&gt;Fancy CV&lt;/a&gt;. It is easy to customize your own template, especially since it is really written by a clean, semantic markup.&lt;/p&gt; &#xA;&lt;h2&gt;Donate&lt;/h2&gt; &#xA;&lt;p&gt;Please help keep this project alive! Donations are welcome and will go towards further development of this project.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PayPal: paypal.me/posquit0&#xA;BTC: 1Je3DxJVM2a9nTVPNo55SfQwpmxA6N2KKb&#xA;BCH: 1Mg1wG7PwHGrHYSWS67TsGSjo5GHEVbF16&#xA;ETH: 0x77ED9B4659F80205E9B9C9FB1E26EDB9904AFCC7&#xA;QTUM: QZT7D6m3QtTTqp7s4ZWAwLtGDsoHMMaM8E&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;Thank you for your support!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Preview&lt;/h2&gt; &#xA;&lt;h4&gt;RÃ©sumÃ©&lt;/h4&gt; &#xA;&lt;p&gt;You can see &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Page. 1&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Page. 2&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume-0.png&#34; alt=&#34;RÃ©sumÃ©&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume-1.png&#34; alt=&#34;RÃ©sumÃ©&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Cover Letter&lt;/h4&gt; &#xA;&lt;p&gt;You can see &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Without Sections&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;With Sections&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter-0.png&#34; alt=&#34;Cover Letter(Traditional)&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter-1.png&#34; alt=&#34;Cover Letter(Awesome)&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.overleaf.com/latex/templates/awesome-cv/tvmzpvdjfqxp&#34;&gt;&lt;strong&gt;Edit RÃ©sumÃ© on OverLeaf.com&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.overleaf.com/latex/templates/awesome-cv-cover-letter/pfzzjspkthbk&#34;&gt;&lt;strong&gt;Edit Cover Letter on OverLeaf.com&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note:&lt;/em&gt; Above services do not guarantee up-to-date source code of Awesome CV&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How to Use&lt;/h2&gt; &#xA;&lt;h4&gt;Requirements&lt;/h4&gt; &#xA;&lt;p&gt;A full TeX distribution is assumed. &lt;a href=&#34;http://tex.stackexchange.com/q/55437&#34;&gt;Various distributions for different operating systems (Windows, Mac, *nix) are available&lt;/a&gt; but TeX Live is recommended. You can &lt;a href=&#34;https://tex.stackexchange.com/q/1092&#34;&gt;install TeX from upstream&lt;/a&gt; (recommended; most up-to-date) or use &lt;code&gt;sudo apt-get install texlive-full&lt;/code&gt; if you really want that. (It&#39;s generally a few years behind.)&lt;/p&gt; &#xA;&lt;p&gt;If you don&#39;t want to install the dependencies on your system, this can also be obtained via &lt;a href=&#34;https://docker.com&#34;&gt;Docker&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Usage&lt;/h4&gt; &#xA;&lt;p&gt;At a command prompt, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ xelatex {your-cv}.tex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or using docker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run --rm --user $(id -u):$(id -g) -i -w &#34;/doc&#34; -v &#34;$PWD&#34;:/doc thomasweise/texlive make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In either case, this should result in the creation of &lt;code&gt;{your-cv}.pdf&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Credit&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.latex-project.org&#34;&gt;&lt;strong&gt;LaTeX&lt;/strong&gt;&lt;/a&gt; is a fantastic typesetting program that a lot of people use these days, especially the math and computer science people in academia.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/furl/latex-fontawesome&#34;&gt;&lt;strong&gt;LaTeX FontAwesome&lt;/strong&gt;&lt;/a&gt; is bindings for FontAwesome icons to be used in XeLaTeX.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/google/roboto&#34;&gt;&lt;strong&gt;Roboto&lt;/strong&gt;&lt;/a&gt; is the default font on Android and ChromeOS, and the recommended font for Googleâ€™s visual language, Material Design.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/adobe-fonts/source-sans-pro&#34;&gt;&lt;strong&gt;Source Sans Pro&lt;/strong&gt;&lt;/a&gt; is a set of OpenType fonts that have been designed to work well in user interface (UI) environments.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;You are free to take my &lt;code&gt;.tex&lt;/code&gt; file and modify it to create your own resume. Please don&#39;t use my resume for anything else without my permission, though!&lt;/p&gt; &#xA;&lt;p&gt;If you have any questions, feel free to join me at &lt;a href=&#34;irc://irc.freenode.net/posquit0&#34;&gt;&lt;code&gt;#posquit0&lt;/code&gt; on Freenode&lt;/a&gt; and ask away. Click &lt;a href=&#34;https://kiwiirc.com/client/irc.freenode.net/posquit0&#34;&gt;here&lt;/a&gt; to connect.&lt;/p&gt; &#xA;&lt;p&gt;Good luck!&lt;/p&gt; &#xA;&lt;h2&gt;Maintainers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/posquit0&#34;&gt;posquit0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/OJFord&#34;&gt;OJFord&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;See Also&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/posquit0/hugo-awesome-identity&#34;&gt;Awesome Identity&lt;/a&gt; - A single-page Hugo theme to introduce yourself.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>