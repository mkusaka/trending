<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-12T02:06:46Z</updated>
  <subtitle>Weekly Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Mixtape-Sessions/Causal-Inference-1</title>
    <updated>2023-02-12T02:06:46Z</updated>
    <id>tag:github.com,2023-02-12:/Mixtape-Sessions/Causal-Inference-1</id>
    <link href="https://github.com/Mixtape-Sessions/Causal-Inference-1" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Causal Inference 1 Mixtape Session taught by Scott Cunningham&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Mixtape-Sessions/Causal-Inference-1/main/img/banner.png&#34; alt=&#34;Mixtape Sessions Banner&#34; width=&#34;100%&#34;&gt; &#xA;&lt;br&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Mixtape-Sessions/Causal-Inference-1/main/img/readme_about.png&#34; alt=&#34;About&#34; width=&#34;100%&#34;&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Causal Inference Part I kickstarts a new 4-day series on design-based causal inference series. It covers the foundations of causal inference grounded in a counterfactual theory of causality built on the Neyman-Rubin model of potential outcomes. It will also cover randomization inference, independence, matching, regression discontinuity and instrumental variables. We will review the theory behind each of these designs in detail with the aim being comprehension, competency and confidence. Each day is 8 hours with 15 minute breaks on the hour plus an hour for lunch. To help accomplish this, we will hold ongoing discussions via Discourse, work through assignments and exercises together, and have detailed walk-throughs of code in R and Stata. This is the prequel to the Part II course that covers difference-in-differences and synthetic control. &lt;br&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Mixtape-Sessions/Causal-Inference-1/main/img/readme_schedule.png&#34; alt=&#34;Schedule&#34; width=&#34;100%&#34;&gt; &#xA;&lt;br&gt; &#xA;&lt;details open&gt;&#xA; &lt;summary&gt;&lt;b&gt;Potential Outcomes&lt;/b&gt;&lt;/summary&gt;&#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;b&gt;About&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;The modern theory of causality is based on a seemingly simple idea called the &#34;counterfactual&#34;. The counterfactual is an unusual features of the arsenal of modern statistics because it is more or less storytelling about alternative worlds that may or may not exist, but could have existed had one single decision gone a different way. Out of this idea grew what a model, complete with its own language, on top of which the field of causal inference is based, and the purpose of this lecture is to learn that language. The language is called potential outcomes and it forms the basis for many causal objects we tend to be interested in, such as the average treatment effect. I also cover randomization, selection bias and randomization inference.&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Slides&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Mixtape-Sessions/Causal-Inference-1/main/Slides/auxiliary/01-Foundations.pdf&#34;&gt;Foundations of causality&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Code&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Mixtape-Sessions/Causal-Inference-1/tree/main/Lab/Doctor-PO&#34;&gt;Doctor PO&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Mixtape-Sessions/Causal-Inference-1/tree/main/Lab/Thornton&#34;&gt;Replication of Thornton (2008)&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://mixtape.shinyapps.io/Randomization-Inference/&#34;&gt;Shiny App for Randomization Inference&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Readings&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;Mixtape chapter 3: &lt;a href=&#34;https://mixtape.scunning.com/potential-outcomes.html&#34;&gt;Directed Acyclical Graphs&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;Mixtape chapter 4: &lt;a href=&#34;https://mixtape.scunning.com/potential-outcomes.html&#34;&gt;Potential Outcomes Causal Model&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt;&#xA;&lt;br&gt; &#xA;&lt;details open&gt;&#xA; &lt;summary&gt;&lt;b&gt;Known and Quantified Confounder Methods&lt;/b&gt;&lt;/summary&gt;&#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;b&gt;About&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;In observational studies, researchers typically are not able to assume that a treatment is randomly assigned as in an experiment. However, this randomization becomes more plausible in some cases after conditioning on a set of covariates. For example, it is not likely that attending college is random since individuals will sort to college based on a bunch of personal characteristics and social setting. However, comparing two individuals who have much of the same characteristics and come from similar backgrounds, it becomes more likely that whether these two individuals attend college differ. This is often called &lt;em&gt;selection on observables&lt;/em&gt; and this section covers how to try to &#34;match&#34; two individuals based on their characteristics when you believe this assumption.&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Slides&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Mixtape-Sessions/Causal-Inference-1/main/Slides/auxiliary/02-Matching_and_Weighting.pdf&#34;&gt;Matching Methods&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Code&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;[Titanic exercise using stratification weighting] (see lab section under Titanic)&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Mixtape-Sessions/Causal-Inference-1/tree/main/Lab/Thornton&#34;&gt;Replication of Lalonde (1986) and Dehejia and Wahba (2002)&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Readings&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;Mixtape chapter 5: &lt;a href=&#34;https://mixtape.scunning.com/matching-and-subclassification.html&#34;&gt;Matching and Subclassification&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt;&#xA;&lt;br&gt; &#xA;&lt;details open&gt;&#xA; &lt;summary&gt;&lt;b&gt;Instrumental Variables&lt;/b&gt;&lt;/summary&gt;&#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;b&gt;About&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;In settings where we are not willing to assume &lt;em&gt;selection on observables&lt;/em&gt;, researchers often turn to an instrumental variables (IV) strategy to estimate a causal effect. In short, IVs are a sort of &#34;external shock&#34; to the equilibrium we&#39;re thinking about. This chapter shows how to leverage these &#34;external shocks&#34; to identify causal effects.&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Slides&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Mixtape-Sessions/Causal-Inference-1/main/Slides/auxiliary/03-IV.pdf&#34;&gt;Instrumental Variables&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Code&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Mixtape-Sessions/Causal-Inference-1/tree/main/Lab/IV&#34;&gt;Replication of Graddy (1995) and Card (1995)&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Readings&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;Mixtape chapter 7: &lt;a href=&#34;https://mixtape.scunning.com/instrumental-variables.html&#34;&gt;Instrumental Variables&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt;&#xA;&lt;br&gt; &#xA;&lt;details open&gt;&#xA; &lt;summary&gt;&lt;b&gt;Regression Discontinuity Design&lt;/b&gt;&lt;/summary&gt;&#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;b&gt;About&lt;/b&gt; One of the most desired quasi-experimental designs -- desired because it is viewed as highly credible despite being based on observational data -- is the regression discontinuity design. Here I will discuss the sharp RDD in great detail, going through identification, estimation, specification tests and tips, as well as a replication.&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Slides&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Mixtape-Sessions/Causal-Inference-1/main/Slides/auxiliary/04-RDD.pdf&#34;&gt;Regression Discontinuity Designs&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Code&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Mixtape-Sessions/Causal-Inference-1/tree/main/Lab/Hansen&#34;&gt;Replication of Hansen (2015)&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://mixtape.shinyapps.io/RD-Bandwidth/&#34;&gt;Shiny App for RD Optimal Bandwidth&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt;Readings&lt;/b&gt;&lt;/p&gt; &#xA; &lt;p&gt;Mixtape chapter 6: &lt;a href=&#34;https://mixtape.scunning.com/regression-discontinuity.html&#34;&gt;Regression discontinuity&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt;&#xA;&lt;br&gt;</summary>
  </entry>
  <entry>
    <title>gphanikumar/id2090a3</title>
    <updated>2023-02-12T02:06:46Z</updated>
    <id>tag:github.com,2023-02-12:/gphanikumar/id2090a3</id>
    <link href="https://github.com/gphanikumar/id2090a3" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Third Assignment on LaTeX and Git usage&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;id2090a3&lt;/h1&gt; &#xA;&lt;p&gt;Third Assignment on LaTeX and Git usage. Instructions are given over email and on moodle.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>AllenDowney/ThinkDataStructures</title>
    <updated>2023-02-12T02:06:46Z</updated>
    <id>tag:github.com,2023-02-12:/AllenDowney/ThinkDataStructures</id>
    <link href="https://github.com/AllenDowney/ThinkDataStructures" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LaTeX source and supporting code for Think Data Structures: Algorithms and Information Retrieval in Java&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ThinkDataStructures&lt;/h1&gt; &#xA;&lt;p&gt;LaTeX source and supporting code for &lt;em&gt;Think Data Structures: Algorithms and Information Retrieval in Java&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Data structures and algorithms are among the most important inventions of the last 50 years, and they are fundamental tools software engineers need to know. But in my opinion, most of the books on these topics are too theoretical, too big, and too bottom-up:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Too theoretical: Mathematical analysis of algorithms is based on simplifying assumptions that limit its usefulness in practice. Many presentations of this topic gloss over the simplifications and focus on the math. In this book I present the most practical subset of this material and eliminate the rest.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Too big: Most books on these topics are at least 500 pages, and some are more than 1000. By focusing on the topics I think are most useful for software engineers, I kept this book under 250 pages.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Too bottom-up: Many data structures books focus on how data structures work (the implementations), with less about how to use them (the interfaces). In this book, I go ``top down&#39;&#39;, starting with the interfaces. Readers learn to use the structures in the Java Collections Framework before getting into the details of how they work.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Finally, many present this material out of context and without motivation: it&#39;s just one damn data structure after another!&lt;/p&gt; &#xA;&lt;p&gt;I try to alleviate the boredom by organizing the topics around an application -- web search -- that uses data structures extensively, and is an interesting and important topic in its own right.&lt;/p&gt; &#xA;&lt;p&gt;This application also motivates some topics that are not usually covered in an introductory data structures class, including persistent data structures, with Redis, and streaming algorithms.&lt;/p&gt; &#xA;&lt;p&gt;I have made difficult decisions about what to leave out, but I have made some compromises. I include a few topics that most readers will never use, but that they might be expected to know, possibly in a technical interview. For these topics, I present both the conventional wisdom as well as my reasons to be skeptical.&lt;/p&gt; &#xA;&lt;p&gt;This book also presents basic aspects of software engineering practice, including version control and unit testing. Each chapter ends with an exercise that allows readers to apply what they have learned. Each exercise includes automated tests that check the solution. And for most exercises, I present my solution at the beginning of the next chapter.&lt;/p&gt; &#xA;&lt;p&gt;This book is intended for college students in computer science and related fields, as well as professional software engineers, people training in software engineering, and people preparing for technical interviews.&lt;/p&gt; &#xA;&lt;p&gt;I assume that the reader knows Java at an intermediate level, but I explain some Java features along the way, and provide pointers to supplementary material.&lt;/p&gt; &#xA;&lt;p&gt;People who have read &lt;em&gt;Think Java&lt;/em&gt; or &lt;em&gt;Head First Java&lt;/em&gt; are prepared for this book.&lt;/p&gt;</summary>
  </entry>
</feed>