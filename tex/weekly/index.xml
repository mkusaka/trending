<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-28T02:10:59Z</updated>
  <subtitle>Weekly Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dreamos82/Osdev-Notes</title>
    <updated>2023-05-28T02:10:59Z</updated>
    <id>tag:github.com,2023-05-28:/dreamos82/Osdev-Notes</id>
    <link href="https://github.com/dreamos82/Osdev-Notes" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Personal Notes about OSDev!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Osdev Notes&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discordapp.com/channels/578193015433330698/578193713340219392&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/578193015433330698.svg?style=flat&#34; alt=&#34;Discord Chat&#34;&gt;&lt;/a&gt; &lt;span class=&#34;badge-buymeacoffee&#34;&gt; &lt;a href=&#34;https://buymeacoffee.com/dreamos82&#34; title=&#34;Donate to this project using Buy Me A Coffee&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/buy%20me%20a%20coffee-donate-yellow.svg?sanitize=true&#34; alt=&#34;Buy Me A Coffee donate button&#34;&gt;&lt;/a&gt; &lt;/span&gt; &lt;img src=&#34;https://tokei.rs/b1/github/dreamos82/osdev-notes&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository is a collection of notes about operating systems development. Written by the authors while writing (and re-writing) our own operating systems. The notes are organised like a book, with the intent of guiding the reader through the various stages of building an operating system kernel from scratch.&lt;/p&gt; &#xA;&lt;p&gt;Currently these notes are a work in progress, but many chapters are functionally complete and available to read below. We&#39;ll keep updating old chapters and adding new ones over time so be sure to check back occasionally.&lt;/p&gt; &#xA;&lt;p&gt;We hope you enjoy, and find something interesting here!&lt;/p&gt; &#xA;&lt;h2&gt;Current Chapters:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/00_Introduction/01_README.md&#34;&gt;Part 0: Introduction&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/00_Introduction/02_AssumedKnowledge.md&#34;&gt;Assumed Knowledge&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/00_Introduction/03_AboutTheAuthors.md&#34;&gt;About The Authors&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/01_Build_Process/01_README.md&#34;&gt;Part 1: Building &amp;amp; Boot Protocols&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/01_Build_Process/02_Overview.md&#34;&gt;Building a Kernel&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/01_Build_Process/03_Boot_Protocols.md&#34;&gt;Bootloaders and Boot Protocols&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/01_Build_Process/04_Gnu_Makefiles.md&#34;&gt;Makefiles&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/01_Build_Process/05_Linker_Scripts.md&#34;&gt;Linker Scripts&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/01_Build_Process/06_Generating_Iso.md&#34;&gt;Generating a Bootable Iso&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/01_README.md&#34;&gt;Part 2: Architecture and Basic Drivers&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/02_Hello_World.md&#34;&gt;Hello World&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/03_HigherHalf.md&#34;&gt;A Higher Higher Kernel&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/04_GDT.md&#34;&gt;Global Descriptor Table&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/05_InterruptHandling.md&#34;&gt;Interrupts&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/06_ACPITables.md&#34;&gt;ACPI Tables&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/07_APIC.md&#34;&gt;APIC&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/08_Timers.md&#34;&gt;Timers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/PS2_Keyboard/01_README.md&#34;&gt;Adding Keyboard support&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Architecture/PS2_Keyboard/02_Interrupt_Handling.md&#34;&gt;Handling the keyboard interrupt&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/02_Interrupt_Handling/PS2_Keyboard/03_Driver_Implementation.md&#34;&gt;Keyboard Driver Implementation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/03_Video_Output/01_README.md&#34;&gt;Part 3: Video Output&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/03_Video_Output/01_Framebuffer.md&#34;&gt;The Framebuffer&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/03_Video_Output/02_DrawingTextOnFB.md&#34;&gt;Drawing Text on Framebuffer&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/04_Memory_Management/01_README.md&#34;&gt;Part 4: Memory Management&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/04_Memory_Management/02_Physical_Memory.md&#34;&gt;Physical Memory&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/04_Memory_Management/03_Paging.md&#34;&gt;Paging&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/04_Memory_Management/04_Virtual_Memory_Manager.md&#34;&gt;Virtual Memory Manager&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/04_Memory_Management/05_Heap_Allocation.md&#34;&gt;Heap Allocation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/04_Memory_Management/06_Memory_Protection.md&#34;&gt;Memory Protection&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/05_Scheduling/01_README.md&#34;&gt;Part 5: Scheduling&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/05_Scheduling/02_Scheduler.md&#34;&gt;The Scheduler&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/05_Scheduling/03_Processes_And_Threads.md&#34;&gt;Processes and Threads&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/05_Scheduling/04_Locks.md&#34;&gt;Locks&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/06_Userspace/01_README.md&#34;&gt;Part 6: Getting to Userspace&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/06_Userspace/02_Switching_Modes.md&#34;&gt;Switching Modes&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/06_Userspace/03_Handling_Interrupts.md&#34;&gt;Updated Interrupt Handling&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/06_Userspace/04_System_Calls.md&#34;&gt;System Calls&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/06_Userspace/05_Example_ABI.md&#34;&gt;Example Syscall ABI&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/07_IPC/01_README.md&#34;&gt;Part 7: Inter-Process Communication&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/07_IPC/02_Shared_Memory.md&#34;&gt;Shared Memory&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/07_IPC/03_Message_Passing.md&#34;&gt;Message Passing&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/08_VirtualFileSystem/01_README.md&#34;&gt;Part 8: File System&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/08_VirtualFileSystem/02_VirtualFileSystem.md&#34;&gt;The Virtual File System&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/09_Loading_Elf/01_README.md&#34;&gt;Part 9: Loading &amp;amp; Executing ELFs&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/09_Loading_Elf/02_Elf_Theory.md&#34;&gt;Theory&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/09_Loading_Elf/03_Loading_And_Running.md&#34;&gt;Loading and Running&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/10_Going_Beyond/01_README.md&#34;&gt;Part 10: Going Beyond&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/99_Appendices/0_README.md&#34;&gt;Extras: Appendices&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/99_Appendices/A_Troubleshooting.md&#34;&gt;General Troubleshooting&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/99_Appendices/B_Tips_And_Tricks.md&#34;&gt;Tips and Tricks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/99_Appendices/C_Language_Info.md&#34;&gt;C Language&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/99_Appendices/D_Nasm.md&#34;&gt;Working With NASM&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Useful Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dreamos82/Dreamos64&#34;&gt;DreamOs64&lt;/a&gt;: 64-bit OS written from scratch by &lt;a href=&#34;https://github.com/dreamos82&#34;&gt;Ivan G&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DeanoBurrito/northport&#34;&gt;Northport&lt;/a&gt;: Another 64-bit OS with SMP, and riscv support! by &lt;a href=&#34;https://github.com/DeanoBurrito/&#34;&gt;Dean T&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dreamos82/Dreamos&#34;&gt;DreamOs&lt;/a&gt;: 32-bit OS written from scratch. This project is discontinued, but it still worth mentioning. Also by &lt;a href=&#34;https://github.com/dreamos82&#34;&gt;Ivan G&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dreamos82&#34;&gt;Ivan G&lt;/a&gt; (dreamos82) - Author and creator of these notes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DeanoBurrito/&#34;&gt;Dean T&lt;/a&gt; (DeanoBurrito) - Author.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The contents (code, text and other assets) of this repository are licensed under the Creative Commons Attribution-NonCommercial 4.0 Public License, see the &lt;a href=&#34;https://raw.githubusercontent.com/dreamos82/Osdev-Notes/master/LICENSE.md&#34;&gt;LICENSE&lt;/a&gt; file for the full text.&lt;/p&gt; &#xA;&lt;p&gt;While not legal advice, this license can be summed up as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You are free to share (copy and redistribute) this material in any medium or format.&lt;/li&gt; &#xA; &lt;li&gt;Adapt (remix, transform and build upon) the material.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Under the following restrictions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You must give appropriate credit, provide a link to the license, and indicate if changes were made.&lt;/li&gt; &#xA; &lt;li&gt;You cannot use the material for commercial uses.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note that no warranties of any kind are provided.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc/4.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;https://i.creativecommons.org/l/by-nc/4.0/88x31.png&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hendricius/the-sourdough-framework</title>
    <updated>2023-05-28T02:10:59Z</updated>
    <id>tag:github.com,2023-05-28:/hendricius/the-sourdough-framework</id>
    <link href="https://github.com/hendricius/the-sourdough-framework" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open source book dedicated to helping you to make the best possible sourdough bread at home.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Sourdough Framework&lt;/h1&gt; &#xA;&lt;p&gt;The sourdough framework is an open-source book dedicated to helping you to make the best possible sourdough bread at home.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hendricius/the-sourdough-framework/main/book/images/cover-page.jpg&#34; alt=&#34;The book cover&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Rather than providing recipes this book intends to provide a framework that enables you to bake bread in your respective environment. Every flour, every sourdough, and every home setup is different. This makes following recipes without background information so hard and a fail-prone endeavor. This book intends to close that gap.&lt;/p&gt; &#xA;&lt;h2&gt;Background&lt;/h2&gt; &#xA;&lt;p&gt;4 years after launching the repositories &lt;a href=&#34;https://github.com/hendricius/the-bread-code&#34;&gt;the-bread-code&lt;/a&gt; and &lt;a href=&#34;https://github.com/hendricius/pizza-dough&#34;&gt;pizza-dough&lt;/a&gt; I created this project to merge the knowledge together. This project intends to go one step deeper into the workings of natural fermentation. At the same time as many scientific references as possible are provided.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hendricius/the-sourdough-framework/main/book/images/whole-wheat-crumb.jpg&#34; alt=&#34;A whole wheat sourdough bread&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🍞 Baking the book (Docker)&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then you can check out the file &lt;code&gt;book/book.pdf&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to 🍞 bake all the versions including ebook formats (.pdf, .epub, .mobi, .azw3) run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;make bake&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can check the files in the folder &lt;code&gt;book/release/&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🍞 Baking the book locally (LaTeX)&lt;/h2&gt; &#xA;&lt;p&gt;Make sure you have &lt;code&gt;biber&lt;/code&gt; installed. Refer to your system&#39;s installation instructions for LaTeX.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;cd book/&#xA;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to 🍞 bake all the versions including ebook formats (.pdf, .epub, .mobi, .azw3) run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;cd book/&#xA;make bake&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can check the files in the folder &lt;code&gt;book/release/&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Compiled versions&lt;/h2&gt; &#xA;&lt;p&gt;The below versions are automatically built on every push to the &lt;code&gt;main&lt;/code&gt; branch.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.the-bread-code.io/book.pdf&#34;&gt;Download compiled .pdf version&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.the-bread-code.io/book.epub&#34;&gt;Download compiled .epub version&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.the-bread-code.io/book.mobi&#34;&gt;Download compiled .mobi version&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.the-bread-code.io/book.azw3&#34;&gt;Download compiled .azw3 version&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;There&#39;s an additional enhanced accessibility version using a sans serif font:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.the-bread-code.io/book-sans-serif.pdf&#34;&gt;Download compiled .pdf version&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.the-bread-code.io/book-sans-serif.epub&#34;&gt;Download compiled .epub version&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.the-bread-code.io/book-sans-serif.mobi&#34;&gt;Download compiled .mobi version&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.the-bread-code.io/book-sans-serif.azw3&#34;&gt;Download compiled .azw3 version&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;Did you find a typo, or feel the wording could be improved? Feel free to open up a pull request at any time.&lt;/p&gt; &#xA;&lt;p&gt;I believe that the knowledge this book provides is essential to everyone. That&#39;s why I decided to open source my knowledge hoping that it will reach more people all over the world without budget constraints.&lt;/p&gt; &#xA;&lt;p&gt;If you would like to contribute with a small donation you can do so via my &lt;a href=&#34;https://breadco.de/book&#34;&gt;ko-fi page.&lt;/a&gt; Your donation will tremendously help me to cover costs related to running the-bread-code. It futhermore allows me to dedidcate time to continously update and improve this book.&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/c/thebreadcode&#34;&gt;My YouTube channel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://breadco.de/discord&#34;&gt;Ask a question on Discord&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>chaofengc/Awesome-Image-Quality-Assessment</title>
    <updated>2023-05-28T02:10:59Z</updated>
    <id>tag:github.com,2023-05-28:/chaofengc/Awesome-Image-Quality-Assessment</id>
    <link href="https://github.com/chaofengc/Awesome-Image-Quality-Assessment" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A comprehensive collection of IQA papers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome Image Quality Assessment (IQA)&lt;/h1&gt; &#xA;&lt;p&gt;A comprehensive collection of IQA papers, datasets and codes. We also provide PyTorch implementations of mainstream metrics in &lt;a href=&#34;https://github.com/chaofengc/IQA-PyTorch&#34;&gt;IQA-PyTorch&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/chaofengc/IQA-PyTorch&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Toolbox-IQA--PyTorch-critical&#34; alt=&#34;toolbox&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/pyiqa/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/pyiqa&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://visitor-badge.laobi.icu/badge?page_id=chaofengc/Awesome-Image-Quality-Assessment&#34; alt=&#34;visitors&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/#awesome-image-quality-assessment-iqa&#34;&gt;Awesome Image Quality Assessment (IQA)&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/#papers&#34;&gt;Papers&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/#no-reference-nr&#34;&gt;No Reference (NR)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/#full-reference-fr&#34;&gt;Full Reference (FR)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/#image-aesthetic-assessment&#34;&gt;Image Aesthetic Assessment&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/#others&#34;&gt;Others&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/#datasets&#34;&gt;Datasets&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/#iqa-datasets&#34;&gt;IQA datasets&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/#perceptual-similarity-datasets&#34;&gt;Perceptual similarity datasets&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Related Resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bcmi/Awesome-Aesthetic-Evaluation-and-Cropping&#34;&gt;Awesome Image Aesthetic Assessment and Cropping&lt;/a&gt;. A curated list of resources including papers, datasets, and relevant links to aesthetic evaluation and cropping.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Papers&lt;/h2&gt; &#xA;&lt;h3&gt;No Reference (NR)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[CVPR2023]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2304.00451&#34;&gt;Re-IQA: Unsupervised Learning for Image Quality Assessment in the Wild&lt;/a&gt;, Saha et al. &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L791-L796&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[CVPR2023]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2303.14968&#34;&gt;Blind Image Quality Assessment via Vision-Language Correspondence: A Multitask Learning Perspective&lt;/a&gt;, Zhang et al. &lt;a href=&#34;https://github.com/zwx8981/LIQE&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L770-L775&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[CVPR2023]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2303.00521&#34;&gt;Quality-aware Pre-trained Models for Blind Image Quality Assessment&lt;/a&gt;, Zhao et al. &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L763-L768&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[AAAI2023]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2207.12396&#34;&gt;Exploring CLIP for Assessing the Look and Feel of Images&lt;/a&gt;, Wang et al. &lt;a href=&#34;https://github.com/IceClear/CLIP-IQA&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L745-L750&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[AAAI2023]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2304.04952&#34;&gt;Data-Efficient Image Quality Assessment with Attention-Panel Decoder&lt;/a&gt;, Qin et al. &lt;a href=&#34;https://github.com/narthchin/DEIQT&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L745-L750&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[TPAMI2022]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2102.09717&#34;&gt;Continual Learning for Blind Image Quality Assessment &lt;/a&gt;, Zhang et al. &lt;a href=&#34;https://github.com/zwx8981/BIQA_CL&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L738-L743&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[TIP2022]&lt;/code&gt; &lt;a href=&#34;https://ieeexplore.ieee.org/document/9694502&#34;&gt;VCRNet: Visual Compensation Restoration Network for No-Reference Image Quality Assessment&lt;/a&gt;, Pan et al. &lt;a href=&#34;https://github.com/NUIST-Videocoding/VCRNet&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L752-L761&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[TMM2022]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2103.07666&#34;&gt;GraphIQA: Learning Distortion Graph Representations for Blind Image Quality Assessment&lt;/a&gt;, Sun et al. &lt;a href=&#34;https://github.com/geekyutao/GraphIQA&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L701-L707&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[CVPR2021]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2105.06747&#34;&gt;Troubleshooting Blind Image Quality Models in the Wild&lt;/a&gt;, Wang et al. &lt;a href=&#34;https://github.com/wangzhihua520/troubleshooting_BIQA&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L716-L722&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Paper Link&lt;/th&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Published&lt;/th&gt; &#xA;   &lt;th&gt;Code&lt;/th&gt; &#xA;   &lt;th&gt;Keywords&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.08958&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MANIQA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVPRW2022&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/IIGROUP/MANIQA&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Transformer, multi-dimension attention, dual branch&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.06858&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TReS&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;WACV2022&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/isalirezag/TReS&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Transformer, relative ranking, self-consistency&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bmvc2021-virtualconference.com/assets/papers/0868.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;KonIQ++&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;BMVC2021&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/SSL92/koniqplusplus&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Multi-task with distortion prediction&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.05997&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MUSIQ&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;ICCV2021&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-research/google-research/tree/master/musiq&#34;&gt;Official&lt;/a&gt; / &lt;a href=&#34;https://github.com/anse3832/MUSIQ&#34;&gt;Pytorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Multi-scale, transformer, Aspect Ratio Preserved (ARP) resizing&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.07948&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CKDN&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;ICCV2021&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/researchmm/CKDN&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Degraded reference, Conditional knowledge distillation (related to HIQA)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/papers/Su_Blindly_Assess_Image_Quality_in_the_Wild_Guided_by_a_CVPR_2020_paper.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HyperIQA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/SSL92/hyperIQA&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Content-aware hyper network&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2004.05508&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Meta-IQA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/zhuhancheng/MetaIQA&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Meta-learning&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.08932&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GIQA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;ECCV2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/cientgu/GIQA&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Generated image&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1809.07517&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PI&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;2018 PIRM Challenge&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/roimehrez/PIRM2018&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1/2 * (NIQE + (10 - NRQM)).&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1804.01681&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HIQA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2018&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kwanyeelin.github.io/projects/HIQA/HIQA.html&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Hallucinated reference&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1805.08493v1.pdf&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;BPSQM&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2018&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Pixel-wise quality map&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1707.08347&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;RankIQA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;ICCV2017&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/xialeiliu/RankIQA&#34;&gt;Github&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Pretrain on synthetically ranked data&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_cvpr_2014/papers/Kang_Convolutional_Neural_Networks_2014_CVPR_paper.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CNNIQA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2014&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lidq92/CNNIQA&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;First CNN-based NR-IQA&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.13983&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;UNIQUE&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2021&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/zwx8981/UNIQUE&#34;&gt;Github&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Combine synthetic and authentic image pairs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1907.02665.pdf&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;DBCNN&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TCSVT2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/zwx8981/DBCNN-PyTorch&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Two branches for synthetic and authentic distortions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.jdl.link/doc/2011/20191226_08489929.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;SFA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TMM2019&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lidq92/SFA&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Aggregate ResNet50 features of multiple cropped patches&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1tMjcllKP8SzTn-dWVmogxaCLpzL1L7nO/view&#34;&gt;pdf&lt;/a&gt;/&lt;a href=&#34;https://arxiv.org/abs/1708.08190&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PQR&lt;/td&gt; &#xA;   &lt;td&gt;NR/Aesthetic&lt;/td&gt; &#xA;   &lt;td&gt;TIP2019&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/HuiZeng/Unified_IAA&#34;&gt;Official1&lt;/a&gt;/&lt;a href=&#34;https://github.com/HuiZeng/BIQA_Toolbox&#34;&gt;Official2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Unify different type of aesthetic labels&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1612.01697&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;WaDIQaM (deepIQA)&lt;/td&gt; &#xA;   &lt;td&gt;NR/FR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2018&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lidq92/WaDIQaM&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Weighted average of patch qualities, shared FR/NR models&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/ielx7/83/8347140/08352823.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;NIMA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2018&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/kentsyx/Neural-IMage-Assessment&#34;&gt;PyTorch&lt;/a&gt;/&lt;a href=&#34;https://github.com/idealo/image-quality-assessment&#34;&gt;Tensorflow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Squared EMD loss&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ece.uwaterloo.ca/~z70wang/publications/TIP_E2E_BIQA.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MEON&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2017&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Multi-task: distortion learning and quality prediction&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1904.06505&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;dipIQ&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2017&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ece.uwaterloo.ca/~k29ma/codes/dipIQ.rar&#34;&gt;download&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Similar to RankIQA&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1612.05890&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;NRQM (Ma)&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVIU2017&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://sites.google.com/site/chaoma99/sr-metric&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional, Super resolution&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1609.04757&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;FRIQUEE&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;JoV2017&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/utlive/FRIQUEE&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Authentically Distorted, Bag of Features&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/7501619&#34;&gt;IEEE&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HOSA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2016&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/7501619&#34;&gt;Matlab download&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/publications/2015/zhang2015feature.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ILNIQE&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2015&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www4.comp.polyu.edu.hk/~cslzhang/IQA/ILNIQE/ILNIQE.htm&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/publications/2012/TIP%20BRISQUE.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;BRISQUE&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2012&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/utlive/BRISQUE&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/publications/2012/saad_2012_tip.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;BLIINDS-II&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2012&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/utlive/BLIINDS2&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.359.7510&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CORNIA&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2012&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/HuiZeng/BIQA_Toolbox&#34;&gt;Matlab download&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Codebook Representation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/publications/2013/mittal2013.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;NIQE&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;SPL2012&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/utlive/niqe&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.imaging.utk.edu/research/wcho/references/2011%20TIP%20BLINDS2.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;DIIVINE&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2011&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/utlive/DIIVINE&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- | []() | | NR | | []() |  --&gt; &#xA;&lt;h3&gt;Full Reference (FR)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;[ECCV2022]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2211.052152207.13686&#34;&gt;Shift-tolerant Perceptual Similarity Metric&lt;/a&gt;, Ghildyal et al. &lt;a href=&#34;https://github.com/abhijay9/ShiftTolerant-LPIPS&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L731-L736&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;[BMVC2022]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2211.05215&#34;&gt;Content-Diverse Comparisons improve IQA&lt;/a&gt;, Thong et al. &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L724-L729&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;[ACM MM2022]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2207.08689&#34;&gt;Quality Assessment of Image Super-Resolution: Balancing Deterministic and Statistical Fidelity&lt;/a&gt;, Zhou et al. &lt;a href=&#34;https://github.com/weizhou-geek/SRIF&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L709-L714&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Paper Link&lt;/th&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Published&lt;/th&gt; &#xA;   &lt;th&gt;Code&lt;/th&gt; &#xA;   &lt;th&gt;Keywords&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.10485&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;AHIQ&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2022 NTIRE workshop&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/IIGROUP/AHIQ&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Attention, Transformer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.08763&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;JSPL&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2022&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/happycaoyue/JSPL&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;semi-supervised and positive-unlabeled (PU) learning&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.13123&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CVRKD&lt;/td&gt; &#xA;   &lt;td&gt;NAR&lt;/td&gt; &#xA;   &lt;td&gt;AAAI2022&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/guanghaoyin/CVRKD-IQA&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Non-Aligned content reference, knowledge distillation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.14730&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;IQT&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;CVPRW2021&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/anse3832/IQT&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Transformer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2110.08521&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A-DISTS&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;ACMM2021&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/dingkeyan93/A-DISTS&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2004.07728&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;DISTS&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;TPAMI2021&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/dingkeyan93/DISTS&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1801.03924&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;LPIPS&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2018&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://richzhang.github.io/PerceptualSimilarity/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Perceptual similarity, Pairwise Preference&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1806.02067&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PieAPP&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2018&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://civc.ucsb.edu/graphics/Papers/CVPR2018_PieAPP/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Perceptual similarity, Pairwise Preference&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1612.01697&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;WaDIQaM&lt;/td&gt; &#xA;   &lt;td&gt;NR/FR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2018&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lidq92/WaDIQaM&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1902.05316&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;JND-SalCAR&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;TCSVT2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;JND (Just-Noticeable-Difference)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://nottingham-repository.worktribe.com/preview/1589753/Visual%20IEEE-TIP-2019.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;QADS&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2019&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.vista.ac.cn/super-resolution/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Super-resolution&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://sse.tongji.edu.cn/linzhang/IQA/FSIM/Files/Fsim%20a%20feature%20similarity%20index%20for%20image%20quality%20assessment.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;FSIM&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2011&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://sse.tongji.edu.cn/linzhang/IQA/FSIM/FSIM.htm&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/publications/2004/hrs_ieeetip_2004_imginfo.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;VIF/IFC&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2006&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/research/Quality/VIF.htm&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ece.uwaterloo.ca/~z70wang/publications/msssim.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MS-SSIM&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ece.uwaterloo.ca/~z70wang/research/ssim/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;SSIM&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2004&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ece.uwaterloo.ca/~z70wang/research/ssim/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PSNR&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Traditional&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- | []() | | FR | | []() |  --&gt; &#xA;&lt;h3&gt;Image Aesthetic Assessment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;[CVPR2023]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2303.14302&#34;&gt;VILA: Learning Image Aesthetics from User Comments with Vision-Language Pretraining&lt;/a&gt;, Ke et al. &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L784-L789&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;[CVPR2023]&lt;/code&gt; &lt;a href=&#34;https://arxiv.org/abs/2303.14968&#34;&gt;Towards Artistic Image Aesthetics Assessment: a Large-scale Dataset and a New Method&lt;/a&gt;, Yi et al. &lt;a href=&#34;https://github.com/Dreemurr-T/BAID&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/chaofengc/Awesome-Image-Quality-Assessment/main/iqa_ref.bib#L777-L782&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Others&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Published&lt;/th&gt; &#xA;   &lt;th&gt;Code&lt;/th&gt; &#xA;   &lt;th&gt;Keywords&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2008.03889&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;NiNLoss&lt;/td&gt; &#xA;   &lt;td&gt;ACMM2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lidq92/LinearityIQA&#34;&gt;Official&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Norm-in-Norm Loss&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;h3&gt;IQA datasets&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Paper Link&lt;/th&gt; &#xA;   &lt;th&gt;Dataset Name&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Published&lt;/th&gt; &#xA;   &lt;th&gt;Website&lt;/th&gt; &#xA;   &lt;th&gt;Images&lt;/th&gt; &#xA;   &lt;th&gt;Annotations&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1912.10088&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PaQ-2-PiQ&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/baidut/PaQ-2-PiQ&#34;&gt;Official github&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;40k, 120k patches&lt;/td&gt; &#xA;   &lt;td&gt;4M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/html/Fang_Perceptual_Quality_Assessment_of_Smartphone_Photography_CVPR_2020_paper.html&#34;&gt;CVF&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;SPAQ&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/h4nwei/SPAQ&#34;&gt;Offical github&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;11k (smartphone)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1910.06180&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;KonIQ-10k&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://database.mmsp-kn.de/koniq-10k-database.html&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;10k from &lt;a href=&#34;http://projects.dfki.uni-kl.de/yfcc100m/&#34;&gt;YFCC100M&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.2M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1511.02919&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CLIVE&lt;/td&gt; &#xA;   &lt;td&gt;NR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2016&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/research/ChallengeDB/index.html&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1200&lt;/td&gt; &#xA;   &lt;td&gt;350k&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://refbase.cvc.uab.es/files/MMP2012a.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;AVA&lt;/td&gt; &#xA;   &lt;td&gt;NR / Aesthentic&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2012&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mtobeiyf/ava_downloader&#34;&gt;Github&lt;/a&gt;/&lt;a href=&#34;http://www.lucamarchesotti.com/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;250k (60 categories)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.12142&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PIPAL&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;ECCV2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.jasongt.com/projectpages/pipal.html&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;250&lt;/td&gt; &#xA;   &lt;td&gt;1.13M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2001.08113&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;KADIS-700k&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;arXiv&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://database.mmsp-kn.de/kadid-10k-database.html&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;140k pristine / 700k distorted&lt;/td&gt; &#xA;   &lt;td&gt;30 ratings (DCRs) per image.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8743252&#34;&gt;IEEE&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;KADID-10k&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;QoMEX2019&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://database.mmsp-kn.de/kadid-10k-database.html&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;81&lt;/td&gt; &#xA;   &lt;td&gt;10k distortions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ece.uwaterloo.ca/~k29ma/papers/17_TIP_EXPLORATION.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Waterloo-Exp&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2017&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ece.uwaterloo.ca/~k29ma/exploration/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;4744&lt;/td&gt; &#xA;   &lt;td&gt;94k distortions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://daneshyari.com/article/preview/533080.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MDID&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;PR2017&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;20&lt;/td&gt; &#xA;   &lt;td&gt;1600 distortions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.ponomarenko.info/papers/euvip_tid2013.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TID2013&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;SP2015&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.ponomarenko.info/tid2013.htm&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;25&lt;/td&gt; &#xA;   &lt;td&gt;3000 distortions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.298.9133&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;LIVEMD&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;ACSSC2012&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/research/Quality/live_multidistortedimage.html&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;15 pristine images&lt;/td&gt; &#xA;   &lt;td&gt;two successive distortions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Damon-Chandler/publication/220050520_Most_apparent_distortion_Full-reference_image_quality_assessment_and_the_role_of_strategy/links/5629cd1c08ae518e347e1445/Most-apparent-distortion-Full-reference-image-quality-assessment-and-the-role-of-strategy.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CSIQ&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;Journal of Electronic Imaging 2010&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;30&lt;/td&gt; &#xA;   &lt;td&gt;866 distortions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.ponomarenko.info/papers/mre2009tid.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TID2008&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;2009&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.ponomarenko.info/tid2008.htm&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;25&lt;/td&gt; &#xA;   &lt;td&gt;1700 distortions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/publications/2006/hrs-transIP-06.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;LIVE IQA&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;TIP2006&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://live.ece.utexas.edu/research/Quality/subjective.htm&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;29 images, 780 synthetic distortions&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://hal.univ-nantes.fr/hal-00580755/&#34;&gt;link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;IVC&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;2005&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;10&lt;/td&gt; &#xA;   &lt;td&gt;185 distortions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Perceptual similarity datasets&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Paper Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset Name&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Published&lt;/th&gt; &#xA;   &lt;th&gt;Website&lt;/th&gt; &#xA;   &lt;th&gt;Images&lt;/th&gt; &#xA;   &lt;th&gt;Annotations&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1801.03924&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;BAPPS(LPIPS)&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2018&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://richzhang.github.io/PerceptualSimilarity/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;187.7k&lt;/td&gt; &#xA;   &lt;td&gt;484k&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1806.02067&#34;&gt;arXiv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PieAPP&lt;/td&gt; &#xA;   &lt;td&gt;FR&lt;/td&gt; &#xA;   &lt;td&gt;CVPR2018&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://civc.ucsb.edu/graphics/Papers/CVPR2018_PieAPP/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;200 images&lt;/td&gt; &#xA;   &lt;td&gt;2.3M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>