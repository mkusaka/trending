<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-24T02:24:30Z</updated>
  <subtitle>Weekly Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>storopoli/Bayesian-Statistics</title>
    <updated>2022-07-24T02:24:30Z</updated>
    <id>tag:github.com,2022-07-24:/storopoli/Bayesian-Statistics</id>
    <link href="https://github.com/storopoli/Bayesian-Statistics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository holds slides and code for a full Bayesian statistics graduate course.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Bayesian Statistics&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-CC%20BY--SA%204.0-lightgrey.svg?sanitize=true&#34; alt=&#34;CC BY-SA 4.0&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/storopoli/Bayesian-Statistics/main/slides/images/bayes-meme.jpg&#34; alt=&#34;Bayesian for Everyone!&#34; width=&#34;500&#34;&gt; &#xA; &lt;p class=&#34;caption&#34;&gt; Bayesian for Everyone! &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;This repository holds slides and code for a full Bayesian statistics graduate course.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bayesian statistics&lt;/strong&gt; is an approach to inferential statistics based on Bayes&#39; theorem, where available knowledge about parameters in a statistical model is updated with the information in observed data. The background knowledge is expressed as a prior distribution and combined with observational data in the form of a likelihood function to determine the posterior distribution. The posterior can also be used for making predictions about future events.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bayesian statistics&lt;/strong&gt; is a departure from classical inferential statistics that prohibits probability statements about parameters and is based on asymptotically sampling infinite samples from a theoretical population and finding parameter values that maximize the likelihood function. Mostly notorious is null-hypothesis significance testing (NHST) based on &lt;em&gt;p&lt;/em&gt;-values. Bayesian statistics &lt;strong&gt;incorporate uncertainty&lt;/strong&gt; (and prior knowledge) by allowing probability statements about parameters, and the process of parameter value inference is a direct result of the &lt;strong&gt;Bayes&#39; theorem&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Content&lt;/h2&gt; &#xA;&lt;p&gt;The whole content is a set of several slides found at &lt;a href=&#34;https://raw.githubusercontent.com/storopoli/Bayesian-Statistics/main/slides/slides.pdf&#34;&gt;&lt;code&gt;slides/slides.pdf&lt;/code&gt;&lt;/a&gt; (342 slides). Here is a brief table of contents:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;What is Bayesian Statistics?&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Common Probability Distributions&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Priors&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Predictive Checks&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bayesian Linear Regression&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bayesian Logistic Regression&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bayesian Ordinal Regression&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bayesian Regression with Count Data: Poisson Regression&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Robust Bayesian Regression&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Hierarchical Models&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Markov Chain Monte Carlo (MCMC) and Model Metrics&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Model Comparison: Cross-Validation and Other Metrics&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Probabilistic Programming Languages (PPLs)&lt;/h2&gt; &#xA;&lt;p&gt;Along with slides for the content, this repository also holds &lt;code&gt;Stan&lt;/code&gt; code and also &lt;code&gt;Turing.jl&lt;/code&gt; code for all models. &lt;code&gt;Stan&lt;/code&gt; and &lt;code&gt;Turing.jl&lt;/code&gt; represents, respectively, the present and future of &lt;a href=&#34;https://en.wikipedia.org/wiki/Probabilistic_programming&#34;&gt;probabilistic programming&lt;/a&gt; languages.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;Stan&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mc-stan.org&#34;&gt;&lt;strong&gt;&lt;code&gt;Stan&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; (Carpenter et al., 2017) &lt;code&gt;Stan&lt;/code&gt; is a state-of-the-art platform for statistical modeling and high-performance statistical computation. Thousands of users rely on &lt;code&gt;Stan&lt;/code&gt; for statistical modeling, data analysis, and prediction in the social, biological, and physical sciences, engineering, and business.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Stan&lt;/code&gt; models are specified in its own language (similar to C++) and compiled into an executable binary that can generate Bayesian statistical inferences using a high-performance Markov Chain Montecarlo (MCMC).&lt;/p&gt; &#xA;&lt;p&gt;You can find &lt;code&gt;Stan&lt;/code&gt; models for all the content discussed in the slides at &lt;a href=&#34;https://raw.githubusercontent.com/storopoli/Bayesian-Statistics/main/stan/&#34;&gt;&lt;code&gt;stan/&lt;/code&gt;&lt;/a&gt; folder. These were tested with &lt;code&gt;Stan&lt;/code&gt; version 2.30.0 and &lt;code&gt;CmdStanR&lt;/code&gt; version 0.5.2.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;Turing.jl&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://turing.ml/&#34;&gt;&lt;strong&gt;&lt;code&gt;Turing.jl&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; (Ge, Xu &amp;amp; Ghahramani, 2018) is an ecosystem of &lt;a href=&#34;https://www.julialang.org&#34;&gt;&lt;strong&gt;Julia&lt;/strong&gt;&lt;/a&gt; packages for Bayesian Inference using &lt;a href=&#34;https://en.wikipedia.org/wiki/Probabilistic_programming&#34;&gt;probabilistic programming&lt;/a&gt;. Models specified using &lt;code&gt;Turing.jl&lt;/code&gt; are easy to read and write â€” models work the way you write them. Like everything in Julia, &lt;code&gt;Turing.jl&lt;/code&gt; is &lt;a href=&#34;https://arxiv.org/abs/2002.02702&#34;&gt;fast&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can find &lt;code&gt;Turing.jl&lt;/code&gt; models for all the content discussed in the slides at &lt;a href=&#34;https://raw.githubusercontent.com/storopoli/Bayesian-Statistics/main/turing/&#34;&gt;&lt;code&gt;turing/&lt;/code&gt;&lt;/a&gt; folder. These were tested with &lt;code&gt;Turing.jl&lt;/code&gt; version 0.21.9 and Julia 1.7.3.&lt;/p&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;kidiq&lt;/code&gt; (linear regression): data from a survey of adult American women and their children (a subsample from the National Longitudinal Survey of Youth). Source: Gelman and Hill (2007).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;wells&lt;/code&gt; (logistic regression): a survey of 3200 residents in a small area of Bangladesh suffering from arsenic contamination of groundwater. Respondents with elevated arsenic levels in their wells had been encouraged to switch their water source to a safe public or private well in the nearby area and the survey was conducted several years later to learn which of the affected residents had switched wells. Souce: Gelman and Hill (2007).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;esoph&lt;/code&gt; (ordinal regression): data from a case-control study of (o)esophageal cancer in Ille-et-Vilaine, France. Source: Breslow and Day (1980).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;roaches&lt;/code&gt; (Poisson regression): data on the efficacy of a pest management system at reducing the number of roaches in urban apartments. Source: Gelman and Hill (2007).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;duncan&lt;/code&gt; (robust regression): data from occupation&#39;s prestige filled with outliers. Source: Duncan (1961).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cheese&lt;/code&gt; (hierarchical models): data from cheese ratings. A group of 10 rural and 10 urban raters rated 4 types of different cheeses (A, B, C and D) in two samples. Source: Boatwright, McCulloch and Rossi (1999).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Author&lt;/h2&gt; &#xA;&lt;p&gt;Jose Storopoli, PhD - &lt;a href=&#34;http://lattes.cnpq.br/2281909649311607&#34;&gt;&lt;em&gt;Lattes&lt;/em&gt; CV&lt;/a&gt; - &lt;a href=&#34;https://orcid.org/0000-0002-0559-5176&#34;&gt;ORCID&lt;/a&gt; - &lt;a href=&#34;https://storopoli.io&#34;&gt;https://storopoli.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How to use the content?&lt;/h2&gt; &#xA;&lt;p&gt;The content is licensed under a very permissive Creative Commons license (CC BY-SA). You are mostly welcome to contribute with &lt;a href=&#34;https://www.github.com/storopoli/Bayesian-Statistics/issues&#34;&gt;issues&lt;/a&gt; and &lt;a href=&#34;https://github.com/storopoli/Bayesian-Statistics/pulls&#34;&gt;pull requests&lt;/a&gt;. My hope is to have &lt;strong&gt;more people into Bayesian statistics&lt;/strong&gt;. The content is aimed towards PhD candidates in applied sciences. I chose to provide an &lt;strong&gt;intuitive approach&lt;/strong&gt; along with some rigorous mathematical formulations. I&#39;ve made it to be how I would have liked to be introduced to Bayesian statistics.&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;p&gt;The references are divided in &lt;strong&gt;books&lt;/strong&gt;, &lt;strong&gt;papers&lt;/strong&gt;, &lt;strong&gt;software&lt;/strong&gt;, and &lt;strong&gt;datasets&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Books&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp;amp; Rubin, D. B. (2013). &lt;em&gt;Bayesian Data Analysis&lt;/em&gt;. Chapman and Hall/CRC.&lt;/li&gt; &#xA; &lt;li&gt;McElreath, R. (2020). &lt;em&gt;Statistical rethinking: A Bayesian course with examples in R and Stan&lt;/em&gt;. CRC press.&lt;/li&gt; &#xA; &lt;li&gt;Gelman, A., Hill, J., &amp;amp; Vehtari, A. (2020). &lt;em&gt;Regression and other stories&lt;/em&gt;. Cambridge University Press.&lt;/li&gt; &#xA; &lt;li&gt;Brooks, S., Gelman, A., Jones, G., &amp;amp; Meng, X.-L. (2011). &lt;em&gt;Handbook of Markov Chain Monte Carlo&lt;/em&gt;. CRC Press. &lt;a href=&#34;http://books.google.com?id=qfRsAIKZ4rIC&#34;&gt;http://books.google.com?id=qfRsAIKZ4rIC&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Geyer, C. J. (2011). Introduction to markov chain monte carlo. In S. Brooks, A. Gelman, G. L. Jones, &amp;amp; X.-L. Meng (Eds.), &lt;em&gt;Handbook of markov chain monte carlo&lt;/em&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Papers&lt;/h3&gt; &#xA;&lt;p&gt;The papers section of the references are divided into &lt;strong&gt;required&lt;/strong&gt; and &lt;strong&gt;complementary&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Required&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;van de Schoot, R., Depaoli, S., King, R., Kramer, B., MÃ¤rtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., &amp;amp; Yau, C. (2021). Bayesian statistics and modelling. &lt;em&gt;Nature Reviews Methods Primers&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(1, 1), 1â€“26. &lt;a href=&#34;https://doi.org/%5B10.1038/s43586-020-00001-2%5D(https://doi.org/10.1038/s43586-020-00001-2)&#34;&gt;https://doi.org/[10.1038/s43586-020-00001-2](https://doi.org/10.1038/s43586-020-00001-2)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Gabry, J., Simpson, D., Vehtari, A., Betancourt, M., &amp;amp; Gelman, A. (2019). Visualization in Bayesian workflow. &lt;em&gt;Journal of the Royal Statistical Society: Series A (Statistics in Society)&lt;/em&gt;, &lt;em&gt;182&lt;/em&gt;(2), 389â€“402. &lt;a href=&#34;https://doi.org/%5B10.1111/rssa.12378%5D(https://doi.org/10.1111/rssa.12378)&#34;&gt;https://doi.org/[10.1111/rssa.12378](https://doi.org/10.1111/rssa.12378)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Gelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., BÃ¼rkner, P.-C., &amp;amp; Modrâ€™ak, M. (2020, November 3). &lt;em&gt;Bayesian Workflow&lt;/em&gt;. &lt;a href=&#34;http://arxiv.org/abs/2011.01808&#34;&gt;http://arxiv.org/abs/2011.01808&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., Cesarini, D., Chambers, C. D., Clyde, M., Cook, T. D., De Boeck, P., Dienes, Z., Dreber, A., Easwaran, K., Efferson, C., â€¦ Johnson, V. E. (2018). Redefine statistical significance. &lt;em&gt;Nature Human Behaviour&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;(1), 6â€“10. &lt;a href=&#34;https://doi.org/%5B10.1038/s41562-017-0189-z%5D(https://doi.org/10.1038/s41562-017-0189-z)&#34;&gt;https://doi.org/[10.1038/s41562-017-0189-z](https://doi.org/10.1038/s41562-017-0189-z)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Etz, A. (2018). Introduction to the Concept of Likelihood and Its Applications. &lt;em&gt;Advances in Methods and Practices in Psychological Science&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(1), 60â€“69. &lt;a href=&#34;https://doi.org/%5B10.1177/2515245917744314%5D(https://doi.org/10.1177/2515245917744314)&#34;&gt;https://doi.org/[10.1177/2515245917744314](https://doi.org/10.1177/2515245917744314)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Etz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., &amp;amp; Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 219â€“234. &lt;a href=&#34;https://doi.org/%5B10.3758/s13423-017-1317-5%5D(https://doi.org/10.3758/s13423-017-1317-5)&#34;&gt;https://doi.org/[10.3758/s13423-017-1317-5](https://doi.org/10.3758/s13423-017-1317-5)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;McShane, B. B., Gal, D., Gelman, A., Robert, C., &amp;amp; Tackett, J. L. (2019). Abandon Statistical Significance. &lt;em&gt;American Statistician&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;, 235â€“245. &lt;a href=&#34;https://doi.org/%5B10.1080/00031305.2018.1527253%5D(https://doi.org/10.1080/00031305.2018.1527253)&#34;&gt;https://doi.org/[10.1080/00031305.2018.1527253](https://doi.org/10.1080/00031305.2018.1527253)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Amrhein, V., Greenland, S., &amp;amp; McShane, B. (2019). Scientists rise up against statistical significance. &lt;em&gt;Nature&lt;/em&gt;, &lt;em&gt;567&lt;/em&gt;(7748), 305â€“307. &lt;a href=&#34;https://doi.org/%5B10.1038/d41586-019-00857-9%5D(https://doi.org/10.1038/d41586-019-00857-9)&#34;&gt;https://doi.org/[10.1038/d41586-019-00857-9](https://doi.org/10.1038/d41586-019-00857-9)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;van Ravenzwaaij, D., Cassey, P., &amp;amp; Brown, S. D. (2018). A simple introduction to Markov Chain Monteâ€“Carlo sampling. &lt;em&gt;Psychonomic Bulletin and Review&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 143â€“154. &lt;a href=&#34;https://doi.org/%5B10.3758/s13423-016-1015-8%5D(https://doi.org/10.3758/s13423-016-1015-8)&#34;&gt;https://doi.org/[10.3758/s13423-016-1015-8](https://doi.org/10.3758/s13423-016-1015-8)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Vandekerckhove, J., Matzke, D., Wagenmakers, E.-J., &amp;amp; others. (2015). Model comparison and the principle of parsimony. In J. R. Busemeyer, Z. Wang, J. T. Townsend, &amp;amp; A. Eidels (Eds.), &lt;em&gt;Oxford handbook of computational and mathematical psychology&lt;/em&gt; (pp. 300â€“319). Oxford University Press Oxford.&lt;/li&gt; &#xA; &lt;li&gt;van de Schoot, R., Kaplan, D., Denissen, J., Asendorpf, J. B., Neyer, F. J., &amp;amp; van Aken, M. A. G. (2014). A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research. &lt;em&gt;Child Development&lt;/em&gt;, &lt;em&gt;85&lt;/em&gt;(3), 842â€“860. &lt;a href=&#34;https://doi.org/%5B10.1111/cdev.12169%5D(https://doi.org/10.1111/cdev.12169)&#34;&gt;https://doi.org/[10.1111/cdev.12169](https://doi.org/10.1111/cdev.12169)&lt;/a&gt; &lt;span class=&#34;csl-block&#34;&gt;_eprint: &lt;a href=&#34;https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/cdev.12169&#34;&gt;https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/cdev.12169&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;Wagenmakers, E.-J. (2007). A practical solution to the pervasive problems of p values. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;14&lt;/em&gt;(5), 779â€“804. &lt;a href=&#34;https://doi.org/%5B10.3758/BF03194105%5D(https://doi.org/10.3758/BF03194105)&#34;&gt;https://doi.org/[10.3758/BF03194105](https://doi.org/10.3758/BF03194105)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Vandekerckhove, J., Matzke, D., Wagenmakers, E.-J., &amp;amp; others. (2015). Model comparison and the principle of parsimony. In J. R. Busemeyer, Z. Wang, J. T. Townsend, &amp;amp; A. Eidels (Eds.), Oxford handbook of computational and mathematical psychology (pp. 300â€“319). Oxford University Press Oxford.&lt;/li&gt; &#xA; &lt;li&gt;Vehtari, A., Gelman, A., &amp;amp; Gabry, J. (2015). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. &lt;a href=&#34;https://doi.org/10.1007/s11222-016-9696-4&#34;&gt;https://doi.org/10.1007/s11222-016-9696-4&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Complementary&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cohen, J. (1994). The earth is round (p &amp;lt; .05). &lt;em&gt;American Psychologist&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(12), 997â€“1003. &lt;a href=&#34;https://doi.org/%5B10.1037/0003-066X.49.12.997%5D(https://doi.org/10.1037/0003-066X.49.12.997)&#34;&gt;https://doi.org/[10.1037/0003-066X.49.12.997](https://doi.org/10.1037/0003-066X.49.12.997)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Dienes, Z. (2011). Bayesian Versus Orthodox Statistics: Which Side Are You On? &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt;, &lt;em&gt;6&lt;/em&gt;(3), 274â€“290. &lt;a href=&#34;https://doi.org/%5B10.1177/1745691611406920%5D(https://doi.org/10.1177/1745691611406920)&#34;&gt;https://doi.org/[10.1177/1745691611406920](https://doi.org/10.1177/1745691611406920)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Etz, A., &amp;amp; Vandekerckhove, J. (2018). Introduction to Bayesian Inference for Psychology. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 5â€“34. &lt;a href=&#34;https://doi.org/%5B10.3758/s13423-017-1262-3%5D(https://doi.org/10.3758/s13423-017-1262-3)&#34;&gt;https://doi.org/[10.3758/s13423-017-1262-3](https://doi.org/10.3758/s13423-017-1262-3)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Jâ€™unior, C. A. M. (2020). Quanto vale o valor-p? &lt;em&gt;Arquivos de CiÃªncias Do Esporte&lt;/em&gt;, &lt;em&gt;7&lt;/em&gt;(2).&lt;/li&gt; &#xA; &lt;li&gt;Kerr, N. L. (1998). HARKing: Hypothesizing after the results are known. &lt;em&gt;Personality and Social Psychology Review&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;(3), 196â€“217. &lt;a href=&#34;https://doi.org/%5B10.1207/s15327957pspr0203%5C_4%5D(https://doi.org/10.1207/s15327957pspr0203_4)&#34;&gt;https://doi.org/[10.1207/s15327957pspr0203\_4](https://doi.org/10.1207/s15327957pspr0203_4)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kruschke, J. K., &amp;amp; Vanpaemel, W. (2015). Bayesian estimation in hierarchical models. In J. R. Busemeyer, Z. Wang, J. T. Townsend, &amp;amp; A. Eidels (Eds.), &lt;em&gt;The Oxford handbook of computational and mathematical psychology&lt;/em&gt; (pp. 279â€“299). Oxford University Press Oxford, UK.&lt;/li&gt; &#xA; &lt;li&gt;Kruschke, J. K., &amp;amp; Liddell, T. M. (2018). Bayesian data analysis for newcomers. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 155â€“177. &lt;a href=&#34;https://doi.org/%5B10.3758/s13423-017-1272-1%5D(https://doi.org/10.3758/s13423-017-1272-1)&#34;&gt;https://doi.org/[10.3758/s13423-017-1272-1](https://doi.org/10.3758/s13423-017-1272-1)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kruschke, J. K., &amp;amp; Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 178â€“206. &lt;a href=&#34;https://doi.org/%5B10.3758/s13423-016-1221-4%5D(https://doi.org/10.3758/s13423-016-1221-4)&#34;&gt;https://doi.org/[10.3758/s13423-016-1221-4](https://doi.org/10.3758/s13423-016-1221-4)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Lakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., Baguley, T., Becker, R. B., Benning, S. D., Bradford, D. E., Buchanan, E. M., Caldwell, A. R., Van Calster, B., Carlsson, R., Chen, S. C., Chung, B., Colling, L. J., Collins, G. S., Crook, Z., â€¦ Zwaan, R. A. (2018). Justify your alpha. &lt;em&gt;Nature Human Behaviour&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;(3), 168â€“171. &lt;a href=&#34;https://doi.org/%5B10.1038/s41562-018-0311-x%5D(https://doi.org/10.1038/s41562-018-0311-x)&#34;&gt;https://doi.org/[10.1038/s41562-018-0311-x](https://doi.org/10.1038/s41562-018-0311-x)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Morey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., &amp;amp; Wagenmakers, E.-J. (2016). &lt;span class=&#34;nocase&#34;&gt;The fallacy of placing confidence in confidence intervals&lt;/span&gt;. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;23&lt;/em&gt;(1), 103â€“123. &lt;a href=&#34;https://doi.org/%5B10.3758/s13423-015-0947-8%5D(https://doi.org/10.3758/s13423-015-0947-8)&#34;&gt;https://doi.org/[10.3758/s13423-015-0947-8](https://doi.org/10.3758/s13423-015-0947-8)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Murphy, K. R., &amp;amp; Aguinis, H. (2019). HARKing: How Badly Can Cherry-Picking and Question Trolling Produce Bias in Published Results? &lt;em&gt;Journal of Business and Psychology&lt;/em&gt;, &lt;em&gt;34&lt;/em&gt;(1). &lt;a href=&#34;https://doi.org/%5B10.1007/s10869-017-9524-7%5D(https://doi.org/10.1007/s10869-017-9524-7)&#34;&gt;https://doi.org/[10.1007/s10869-017-9524-7](https://doi.org/10.1007/s10869-017-9524-7)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Stark, P. B., &amp;amp; Saltelli, A. (2018). Cargo-cult statistics and scientific crisis. &lt;em&gt;Significance&lt;/em&gt;, &lt;em&gt;15&lt;/em&gt;(4), 40â€“43. &lt;a href=&#34;https://doi.org/%5B10.1111/j.1740-9713.2018.01174.x%5D(https://doi.org/10.1111/j.1740-9713.2018.01174.x)&#34;&gt;https://doi.org/[10.1111/j.1740-9713.2018.01174.x](https://doi.org/10.1111/j.1740-9713.2018.01174.x)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Software&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Carpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M., Guo, J., Li, P., &amp;amp; Riddell, A. (2017). Stan : A Probabilistic Programming Language. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;76&lt;/em&gt;(1). &lt;a href=&#34;https://doi.org/%5B10.18637/jss.v076.i01%5D(https://doi.org/10.18637/jss.v076.i01)&#34;&gt;https://doi.org/[10.18637/jss.v076.i01](https://doi.org/10.18637/jss.v076.i01)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Ge, H., Xu, K., &amp;amp; Ghahramani, Z. (2018). Turing: A Language for Flexible Probabilistic Inference. International Conference on Artificial Intelligence and Statistics, 1682â€“1690. &lt;a href=&#34;http://proceedings.mlr.press/v84/ge18b.html&#34;&gt;http://proceedings.mlr.press/v84/ge18b.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Tarek, M., Xu, K., Trapp, M., Ge, H., &amp;amp; Ghahramani, Z. (2020). DynamicPPL: Stan-like Speed for Dynamic Probabilistic Models. ArXiv:2002.02702 [Cs, Stat]. &lt;a href=&#34;http://arxiv.org/abs/2002.02702&#34;&gt;http://arxiv.org/abs/2002.02702&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Xu, K., Ge, H., Tebbutt, W., Tarek, M., Trapp, M., &amp;amp; Ghahramani, Z. (2020). AdvancedHMC.jl: A robust, modular and efficient implementation of advanced HMC algorithms. Symposium on Advances in Approximate Bayesian Inference, 1â€“10. &lt;a href=&#34;http://proceedings.mlr.press/v118/xu20a.html&#34;&gt;http://proceedings.mlr.press/v118/xu20a.html&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Datasets&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Boatwright, P., McCulloch, R., &amp;amp; Rossi, P. (1999). Account-level modeling for trade promotion: An application of a constrained parameter hierarchical model. &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt;, 94(448), 1063â€“1073.&lt;/li&gt; &#xA; &lt;li&gt;Breslow, N. E. &amp;amp; Day, N. E. (1980). &lt;strong&gt;Statistical Methods in Cancer Research. Volume 1: The Analysis of Case-Control Studies&lt;/strong&gt;. IARC Lyon / Oxford University Press.&lt;/li&gt; &#xA; &lt;li&gt;Duncan, O. D. (1961). A socioeconomic index for all occupations. Class: Critical Concepts, 1, 388â€“426.&lt;/li&gt; &#xA; &lt;li&gt;Gelman, A., &amp;amp; Hill, J. (2007). &lt;strong&gt;Data analysis using regression and multilevel/hierarchical models&lt;/strong&gt;. Cambridge university press.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to cite&lt;/h2&gt; &#xA;&lt;p&gt;To cite this course, please use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Storopoli (2022). Bayesian Statistics: a graduate course. https://github.com/storopoli/Bayesian-Statistics.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or in BibTeX format (LaTeX):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{storopoli2022bayesian,&#xA;  author = {Storopoli, Jose},&#xA;  title = {Bayesian Statistics: a graduate course},&#xA;  url = {https://github.com/storopoli/Bayesian-Statistics},&#xA;  year = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This content is licensed under &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 Internacional&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;&lt;img src=&#34;https://licensebuttons.net/l/by-sa/4.0/88x31.png&#34; alt=&#34;CC BY-SA 4.0&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hmemcpy/milewski-ctfp-pdf</title>
    <updated>2022-07-24T02:24:30Z</updated>
    <id>tag:github.com,2022-07-24:/hmemcpy/milewski-ctfp-pdf</id>
    <link href="https://github.com/hmemcpy/milewski-ctfp-pdf" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bartosz Milewski&#39;s &#39;Category Theory for Programmers&#39; unofficial PDF and LaTeX source&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Category Theory for Programmers&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/601206/43392303-f770d7be-93fb-11e8-8db8-b7e915b435ba.png&#34; alt=&#34;image&#34;&gt; &lt;b&gt;Direct link: &lt;a href=&#34;https://github.com/hmemcpy/milewski-ctfp-pdf/releases/download/v1.3.0/category-theory-for-programmers.pdf&#34;&gt;category-theory-for-programmers.pdf&lt;/a&gt;&lt;/b&gt;&lt;br&gt; (Latest release: v1.3.0, August 2019. See &lt;a href=&#34;https://github.com/hmemcpy/milewski-ctfp-pdf/releases&#34;&gt;releases&lt;/a&gt; for additional formats and languages.)&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/hmemcpy/milewski-ctfp-pdf&#34;&gt;&lt;img src=&#34;https://travis-ci.org/hmemcpy/milewski-ctfp-pdf.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://s3.amazonaws.com/milewski-ctfp-pdf/category-theory-for-programmers.pdf&#34;&gt;(latest CI build)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/601206/47271389-8eea0900-d581-11e8-8e81-5b932e336336.png&#34; alt=&#34;Buy Category Theory for Programmers&#34; width=&#34;410&#34;&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://www.blurb.com/b/9621951-category-theory-for-programmers-new-edition-hardco&#34;&gt;Available in full-color hardcover print&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; Publish date: 12 August, 2019. Based off release tag &lt;a href=&#34;https://github.com/hmemcpy/milewski-ctfp-pdf/releases/tag/v1.3.0&#34;&gt;v1.3.0&lt;/a&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/hmemcpy/milewski-ctfp-pdf/master/errata-1.3.0.md&#34;&gt;errata-1.3.0&lt;/a&gt; for changes and fixes since print.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.blurb.com/b/9603882-category-theory-for-programmers-scala-edition-pape&#34;&gt;Scala Edition is now available in paperback&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; Publish date: 12 August, 2019. Based off release tag &lt;a href=&#34;https://github.com/hmemcpy/milewski-ctfp-pdf/releases/tag/v1.3.0&#34;&gt;v1.3.0&lt;/a&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/hmemcpy/milewski-ctfp-pdf/master/errata-scala.md&#34;&gt;errata-scala&lt;/a&gt; for changes and fixes since print.&lt;/p&gt; &#xA;&lt;p&gt;This is an &lt;em&gt;unofficial&lt;/em&gt; PDF version of &#34;Category Theory for Programmers&#34; by Bartosz Milewski, converted from his &lt;a href=&#34;https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/&#34;&gt;blogpost series&lt;/a&gt; (with permission!)&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;The best way to build the book is using the &lt;a href=&#34;https://nixos.org/nix/&#34;&gt;Nix&lt;/a&gt; package manager. After &lt;a href=&#34;https://nixos.org/download.html&#34;&gt;installing Nix&lt;/a&gt;, if you&#39;re using a non-NixOS operating system, you need to install &lt;code&gt;nixFlakes&lt;/code&gt; in your environment following the steps below (&lt;a href=&#34;https://nixos.wiki/wiki/Flakes#Non-NixOS&#34;&gt;source&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ nix-env -iA nixpkgs.nixFlakes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Edit either &lt;code&gt;~/.config/nix/nix.conf&lt;/code&gt; or &lt;code&gt;/etc/nix/nix.conf&lt;/code&gt; and add:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;experimental-features = nix-command flakes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is needed to expose the Nix 2.0 CLI and flakes support that are hidden behind feature-flags.&lt;/p&gt; &#xA;&lt;p&gt;Also, if the Nix installation is in multi-user mode, donâ€™t forget to restart the nix-daemon.&lt;/p&gt; &#xA;&lt;p&gt;Afterwards, type &lt;code&gt;nix flake show&lt;/code&gt; in the root directory of the project to see all the available versions of this book. Then type &lt;code&gt;nix build .#&amp;lt;edition&amp;gt;&lt;/code&gt; to build the edition you want (Haskell, Scala, OCaml, Reason and their printed versions). For example, to build the Scala edition you&#39;ll have to type &lt;code&gt;nix build .#ctfp-scala&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Upon successful compilation, the PDF file will be placed in the &lt;code&gt;result&lt;/code&gt; directory inside the root directory &lt;code&gt;milewski-ctfp-pdf&lt;/code&gt; of the repository.&lt;/p&gt; &#xA;&lt;p&gt;The file &lt;code&gt;preamble.tex&lt;/code&gt; contains all the configuration and style declarations.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;PDF LaTeX source and the tools to create it are based on the work by Andres Raba et al., available here: &lt;a href=&#34;https://github.com/sarabander/sicp-pdf&#34;&gt;https://github.com/sarabander/sicp-pdf&lt;/a&gt;.&lt;br&gt; The book content is taken, with permission, from Bartosz Milewski&#39;s blogpost series, and adapted to the LaTeX format.&lt;/p&gt; &#xA;&lt;p&gt;Thanks to the following people for contributing corrections/conversions and misc:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Oleg Rakitskiy&lt;/li&gt; &#xA; &lt;li&gt;Jared Weakly&lt;/li&gt; &#xA; &lt;li&gt;Paolo G. Giarrusso&lt;/li&gt; &#xA; &lt;li&gt;Adi Shavit&lt;/li&gt; &#xA; &lt;li&gt;Mico Loretan&lt;/li&gt; &#xA; &lt;li&gt;Marcello Seri&lt;/li&gt; &#xA; &lt;li&gt;Erwin Maruli Tua Pakpahan&lt;/li&gt; &#xA; &lt;li&gt;Markus Hauck&lt;/li&gt; &#xA; &lt;li&gt;Yevheniy Zelenskyy&lt;/li&gt; &#xA; &lt;li&gt;Ross Kirsling&lt;/li&gt; &#xA; &lt;li&gt;...and many others!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The original blog post acknowledgments by Bartosz are consolidated in the &lt;em&gt;Acknowledgments&lt;/em&gt; page at the end of the book.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note from Bartosz&lt;/strong&gt;: I really appreciate all your contributions. You made this book much better than I could have imagined. Thank you!&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The PDF book, &lt;code&gt;.tex&lt;/code&gt; files, and associated images and figures in directories &lt;code&gt;src/fig&lt;/code&gt; and &lt;code&gt;src/content&lt;/code&gt; are licensed under Creative Commons Attribution-ShareAlike 4.0 International License (&lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;cc by-sa&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;The script files &lt;code&gt;scraper.py&lt;/code&gt; and others are licensed under GNU General Public License version 3 (for details, see &lt;a href=&#34;https://github.com/hmemcpy/milewski-ctfp-pdf/raw/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt;).&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>sb2nov/resume</title>
    <updated>2022-07-24T02:24:30Z</updated>
    <id>tag:github.com,2022-07-24:/sb2nov/resume</id>
    <link href="https://github.com/sb2nov/resume" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Software developer resume in Latex&lt;/p&gt;&lt;hr&gt;&lt;p&gt;A single-page, one-column resume for software developers. It uses the base latex templates and fonts to provide ease of use and installation when trying to update the resume. The different sections are clearly documented and custom commands are used to provide consistent formatting. The three main sections in the resume are education, experience, and projects.&lt;/p&gt; &#xA;&lt;h3&gt;Motivation&lt;/h3&gt; &#xA;&lt;p&gt;I created this template as managing a resume on Google Docs was hard and changing any formatting was too difficult since it had to be applied in multiple places.&lt;/p&gt; &#xA;&lt;p&gt;Most currently available templates either focus on two columns, or are multiple pages long that didn&#39;t work well for career fairs or online applications.&lt;/p&gt; &#xA;&lt;h3&gt;Quick start&lt;/h3&gt; &#xA;&lt;p&gt;Get started quickly using &lt;a href=&#34;https://www.overleaf.com/latex/templates/software-engineer-resume/gqxmqsvsbdjf&#34;&gt;Overleaf&lt;/a&gt; template.&lt;/p&gt; &#xA;&lt;h3&gt;Build using Docker&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker build -t latex .&#xA;docker run --rm -i -v &#34;$PWD&#34;:/data latex pdflatex sourabh_bajaj_resume.tex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Preview&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sb2nov/resume/master/resume_preview.png&#34; alt=&#34;Resume Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;Format is MIT but all the data is owned by Sourabh Bajaj.&lt;/p&gt;</summary>
  </entry>
</feed>