<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-03-23T01:52:28Z</updated>
  <subtitle>Weekly Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>microsoft/promptpex</title>
    <updated>2025-03-23T01:52:28Z</updated>
    <id>tag:github.com,2025-03-23:/microsoft/promptpex</id>
    <link href="https://github.com/microsoft/promptpex" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Prompt Exploration&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PromptPex&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Prompts&lt;/strong&gt; are an important part of any software project that incorporates the power of AI models. As a result, tools to help developers create and maintain effective prompts are increasingly important.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.sigplan.org/2024/10/22/prompts-are-programs/&#34;&gt;Prompts Are Programs - ACM Blog Post&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;PromptPex&lt;/strong&gt; is a tool for exploring and testing AI model prompts. PromptPex is intended to be used by developers who have prompts as part of their code base. PromptPex treats a prompt as a function and automatically generates test inputs to the function to support unit testing.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/2503.05070&#34;&gt;PromptPex technical paper&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;PromptPex provides the following capabilities:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It will &lt;strong&gt;automatically extract output rules&lt;/strong&gt; that are expressed in natural language in the prompt. An example of a rule might be &#34;The output should be formatted as JSON&#34;.&lt;/li&gt; &#xA; &lt;li&gt;From the rules, it will &lt;strong&gt;generate unit test cases&lt;/strong&gt; specifically designed to determine if the prompt, for a given model, correctly follows the rule.&lt;/li&gt; &#xA; &lt;li&gt;Given a set of rules and tests, PromptPex will &lt;strong&gt;evaluate the performance of the prompt on any given model&lt;/strong&gt;. For example, a user can determine if a set of unit tests succeeds on gpt-4o-mini but fails on phi3.&lt;/li&gt; &#xA; &lt;li&gt;PromptPex uses an LLM to automatically determine whether model outputs meet the specified requirements.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Glossary&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;Prompt Under Test (PUT) - like Program Under Test; the prompt&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Model Under Test (MUT) - Model which we are testing against with specific temperature, etc example: gpt-4o-mini&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Model Used by PromptPex (MPP) - gpt-4o&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Input Specification (IS) - Extracting input constraints of PUT using MPP (input_spec)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Output Rules (OR) - Extracting output constraints of PUT using MPP (rules_global)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Inverse Output Rules (IOR) - Inverse of the generated Output Rules&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Output Rules Groundedness (ORG) - Checks if OR is grounded in PUT using MPP (check_rule_grounded)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Prompt Under Test Intent (PUTI) - Extracting the exact task from PUT using MMP (extract_intent)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;PromptPex Tests (PPT) - Test cases generated for PUT with MPP using IS and OR (test)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Baseline Tests (BT) - Zero shot test cases generated for PUT with MPP (baseline_test)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Test Validity (TV) - Checking if PPT and BT meets the constraints in IS using MPP (check_violation_with_input_spec)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Spec Agreement (SA) - Result generated for PPT and BT on PUTI + OR with MPP (evaluate_test_coverage)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Test Output (TO) - Result generated for PPT and BT on PUT with each MUT (the template is PUT)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Test Non-Compliance&amp;nbsp;(TNC) - Checking if TO meets the constraints in PUT using MPP (check_violation_with_system_prompt)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD&#xA;    PUT([&#34;Prompt Under Test (PUT)&#34;])&#xA;    IS[&#34;Input Specification (IS)&#34;]&#xA;    OR[&#34;Output Rules (OR)&#34;]&#xA;    IOR[&#34;Inverse Output Rules (IOR)&#34;]&#xA;    PPT[&#34;PromptPex Tests (PPT)&#34;]&#xA;    TO[&#34;Test Output (TO) for MUT&#34;]&#xA;&#xA;    PUT --&amp;gt; IS&#xA;&#xA;    PUT --&amp;gt; OR&#xA;    OR --&amp;gt; IOR&#xA;&#xA;    PUT --&amp;gt; PPT&#xA;    IS --&amp;gt; PPT&#xA;    OR --&amp;gt; PPT&#xA;    IOR --&amp;gt; PPT&#xA;&#xA;    PPT --&amp;gt; TO&#xA;    PUT --&amp;gt; TO&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;Here is an example of PromptPex in practice.&lt;/p&gt; &#xA;&lt;p&gt;Prompt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;In this task, you will be presented with a sentence and a word contained in that sentence. You have to determine the part of speech&#xA;for a given word and return just the tag for the word&#39;s part of speech. Return only the part of speech tag.&#xA;If the word cannot be tagged with the listed tags, return Unknown. If you are unable to tag the word, return CantAnswer.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Input Specification:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;1. The input consists of a sentence combined with a specific word from that sentence.&#xA;2. The sentence must contain natural language text.&#xA;3. The word must be a single word from the provided sentence.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Extracted rules:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;1. The output must return only the part of speech tag without any additional text or formatting.&#xA;2. If the given word can be identified with one of the listed part of speech tags, the output must include only the specific tag for that word from the provided alphabetical list.&#xA;3. If the given word cannot be tagged with any of the listed part of speech tags, the output should be the word &#34;Unknown&#34;.&#xA;4. If tagging the given word is not possible for any reason, the output should be the word &#34;CantAnswer&#34;.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Tests generated from the rules:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;1. sentence: &#39;An aura of mystery surrounded them.&#39;, word: &#39;aura&#39;&#xA;2. sentence: &#39;The researchers documented carefully.&#39;, word: &#39;carefully&#39;&#xA;(Note this tests the Unknown corner case)&#xA;3. sentence: &#39;This is such a unique perspective.&#39;, word: &#39;such&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;PromptPex uses &lt;a href=&#34;https://microsoft.github.io/genaiscript&#34;&gt;GenAIScript&lt;/a&gt; to execute.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://nodejs.org/&#34;&gt;Node.js v20+&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Configure your LLM credentials in &lt;code&gt;.env&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npx --yes genaiscript configure&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Launch promptpex remotely&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npx --yes genaiscript serve --remote microsoft/promptpex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Configure the eval, rules, baseline aliases&lt;/h3&gt; &#xA;&lt;p&gt;PromptPex defines the following model aliases for the different phases of the test generation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;rules&lt;/code&gt;: rule, inverse rules, test generation&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;eval&lt;/code&gt;: rule and test quality evaluations&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;baseline&lt;/code&gt;: baseline test generation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you are using a specific set of models, you can use a &lt;code&gt;.env&lt;/code&gt; file to override the eval/rules/baseline aliases&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;GENAISCRIPT_MODEL_EVAL=&#34;azure:gpt-4o_2024-08-06&#34;&#xA;GENAISCRIPT_MODEL_RULES=&#34;azure:gpt-4o_2024-08-06&#34;&#xA;GENAISCRIPT_MODEL_BASELINE=&#34;azure:gpt-4o_2024-08-06&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Test and Eval Workflow&lt;/h2&gt; &#xA;&lt;p&gt;The diagram below shows the flow of test generation in PromptPex, starting from the PUT (database shape).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD&#xA;    PUT[(&#34;Prompt Under Test (PUT)&#34;)]&#xA;    IS([&#34;Input Specification (IS)&#34;])&#xA;    OR([&#34;Output Rules (OR)&#34;])&#xA;    IOR([&#34;Inverse Output Rules (IOR)&#34;])&#xA;    ORG[&#34;Output Rules Groundedness (ORG)&#34;]&#xA;    PUTI([&#34;Prompt Under Test Intent (PUTI)&#34;])&#xA;    PPT{{&#34;PromptPex Tests (PPT)&#34;}}&#xA;    SA[&#34;Spec Agreement (SA)&#34;]&#xA;    SAE[&#34;Spec Agreement Evaluation (SAE)&#34;]&#xA;    TO[&#34;Test Output (TO) for MUT&#34;]&#xA;    TNC[&#34;Test Non-Compliance (TNC)&#34;]&#xA;    TV[&#34;Test Validity (TV)&#34;]&#xA;    BT{{&#34;Baseline Tests (BT)&#34;}}&#xA;&#xA;    PUT ==&amp;gt; IS&#xA;&#xA;    PUT ==&amp;gt; OR&#xA;    OR ==&amp;gt; IOR&#xA;&#xA;    OR --&amp;gt; ORG&#xA;    PUT --&amp;gt; ORG&#xA;&#xA;    PUT --&amp;gt; PUTI&#xA;&#xA;    PUT --&amp;gt; PPT&#xA;    IS ==&amp;gt; PPT&#xA;    OR ==&amp;gt; PPT&#xA;    IOR ==&amp;gt; PPT&#xA;&#xA;    PPT --&amp;gt; TV&#xA;    IS --&amp;gt; TV&#xA;&#xA;    PPT --&amp;gt; SA&#xA;    PUTI --&amp;gt; SA&#xA;    OR --&amp;gt; SA&#xA;&#xA;    SA --&amp;gt; SAE&#xA;    PUT --&amp;gt; SAE&#xA;&#xA;&#xA;    PPT --&amp;gt; TO&#xA;    PUT --&amp;gt; TO&#xA;&#xA;    TO --&amp;gt; TNC&#xA;    PUT --&amp;gt; TNC&#xA;&#xA;    PUT --&amp;gt; BT&#xA;    BT --&amp;gt; TNC&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Every node is created by a LLM call (aside from the PUT).&lt;/li&gt; &#xA; &lt;li&gt;Rounded nodes can be edited by the user.&lt;/li&gt; &#xA; &lt;li&gt;Square nodes are evaluations.&lt;/li&gt; &#xA; &lt;li&gt;Diamond nodes are outputs.&lt;/li&gt; &#xA; &lt;li&gt;Lines represent data dependencies.&lt;/li&gt; &#xA; &lt;li&gt;Bolded lines are the minimum path to generate tests.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Intended Uses&lt;/h2&gt; &#xA;&lt;p&gt;PromptPex is shared for research purposes only. It is not meant to be used in practice. PromptPex was not extensively tested for its capabilities and properties, including its accuracy and reliability in practical use cases, security and privacy.&lt;/p&gt; &#xA;&lt;h2&gt;Developer Guide&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Use CodeSpaces / dev container to get a fully configured environment, including access to LLMs through GitHub Marketplace Models.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/codespaces/new?hide_repo_select=true&amp;amp;ref=main&amp;amp;repo=microsoft/promptpex&#34;&gt;&lt;img src=&#34;https://github.com/codespaces/badge.svg?sanitize=true&#34; alt=&#34;Open in GitHub Codespaces&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://nodejs.org/&#34;&gt;Node.js v20+&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install dependencies&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Web interface&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Launch web interface&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run serve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Open localhost&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Typecheck scripts&lt;/h3&gt; &#xA;&lt;p&gt;Use Visual Studio Code to get builtin typechecking from TypeScript or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Create a commit&lt;/h3&gt; &#xA;&lt;p&gt;For convinience,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run gcm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Debug&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Open a &lt;code&gt;JavaScript Debug Terminal&lt;/code&gt; in Visual Studio Code&lt;/li&gt; &#xA; &lt;li&gt;Put a breakpoint in your script&lt;/li&gt; &#xA; &lt;li&gt;Launch the script&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Upgrade dependencies&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run upgrade&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Diagnostics mode&lt;/h3&gt; &#xA;&lt;p&gt;Set the &lt;code&gt;DEBUG&lt;/code&gt; or &lt;code&gt;GENAISCRIPT_DEBUG&lt;/code&gt; environment variable to enable dianostics modes.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export GENAISCRIPT_DEBUG=1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Responsible AI Transparency Note&lt;/h2&gt; &#xA;&lt;p&gt;Please reference &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/promptpex/main/RESPONSIBLE_AI_TRANSPARENCY_NOTE.md&#34;&gt;RESPONSIBLE_AI_TRANSPARENCY_NOTE.md&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
</feed>