<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-24T02:00:42Z</updated>
  <subtitle>Weekly Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>unaguil/metodos_numericos</title>
    <updated>2023-12-24T02:00:42Z</updated>
    <id>tag:github.com,2023-12-24:/unaguil/metodos_numericos</id>
    <link href="https://github.com/unaguil/metodos_numericos" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Ejercicios de la asignatura de métodos numéricos I de la UNED&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction</title>
    <updated>2023-12-24T02:00:42Z</updated>
    <id>tag:github.com,2023-12-24:/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction</id>
    <link href="https://github.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A selection of state-of-the-art research materials on trajectory prediction&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome Interaction-Aware Behavior and Trajectory Prediction&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://awesome.re/badge.svg?sanitize=true&#34; alt=&#34;Awesome&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Version-2.0-ff69b4.svg?sanitize=true&#34; alt=&#34;Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/LastUpdated-2023.09-lightgrey.svg?sanitize=true&#34; alt=&#34;LastUpdated&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Topic-trajectory--prediction-yellow.svg?logo=github&#34; alt=&#34;Topic&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a checklist of state-of-the-art research materials (datasets, blogs, papers and public codes) related to trajectory prediction. Wish it could be helpful for both academia and industry. (Still updating)&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Maintainers&lt;/strong&gt;: &lt;a href=&#34;https://jiachenli94.github.io&#34;&gt;&lt;strong&gt;Jiachen Li&lt;/strong&gt;&lt;/a&gt; (Stanford University); &lt;a href=&#34;https://www.linkedin.com/in/hengboma/&#34;&gt;&lt;strong&gt;Hengbo Ma&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/jinningli/&#34;&gt;&lt;strong&gt;Jinning Li&lt;/strong&gt;&lt;/a&gt; (University of California, Berkeley)&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Emails&lt;/strong&gt;: &lt;a href=&#34;mailto:jiachen_li@stanford.edu&#34;&gt;jiachen_li@stanford.edu&lt;/a&gt;; {hengbo_ma, jinning_li}@berkeley.edu&lt;/p&gt; &#xA;&lt;p&gt;Please feel free to pull request to add new resources or send emails to us for questions, discussion and collaborations.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;a href=&#34;https://github.com/jiachenli94/Awesome-Decision-Making-Reinforcement-Learning&#34;&gt;&lt;strong&gt;Here&lt;/strong&gt;&lt;/a&gt; is also a collection of materials for reinforcement learning, decision making and motion planning.&lt;/p&gt; &#xA;&lt;p&gt;Please consider citing our work if you found this repo useful:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{li2020evolvegraph,&#xA;  title={EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning},&#xA;  author={Li, Jiachen and Yang, Fan and Tomizuka, Masayoshi and Choi, Chiho},&#xA;  booktitle={2020 Advances in Neural Information Processing Systems (NeurIPS)},&#xA;  year={2020}&#xA;}&#xA;&#xA;@inproceedings{li2019conditional,&#xA;  title={Conditional Generative Neural System for Probabilistic Trajectory Prediction},&#xA;  author={Li, Jiachen and Ma, Hengbo and Tomizuka, Masayoshi},&#xA;  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},&#xA;  pages={6150--6156},&#xA;  year={2019},&#xA;  organization={IEEE}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Table of Contents&lt;/h3&gt; &#xA;&lt;!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#datasets&#34;&gt;&lt;strong&gt;Datasets&lt;/strong&gt;&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#vehicles-and-traffic&#34;&gt;Vehicles and Traffic&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#pedestrians&#34;&gt;Pedestrians&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#sport-players&#34;&gt;Sport Players&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#literature-and-codes&#34;&gt;&lt;strong&gt;Literature and Codes&lt;/strong&gt;&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#survey-papers&#34;&gt;Survey Papers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#physics-systems-with-interaction&#34;&gt;Physics Systems with Interaction&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#intelligent-vehicles-and-pedestrians&#34;&gt;Intelligent Vehicles and Pedestrians&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#mobile-robots&#34;&gt;Mobile Robots&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#sport-players&#34;&gt;Sport Players&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#benchmark-and-evaluation-metrics&#34;&gt;Benchmark and Evaluation Metrics&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiachenli94/Awesome-Interaction-Aware-Trajectory-Prediction/master/#others&#34;&gt;Others&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;!-- /TOC --&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Datasets&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Vehicles and Traffic&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Dataset&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Agents&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Scenarios&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Sensors&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://waymo.com/open/&#34;&gt;Waymo Open Dataset&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban / highway&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;LiDAR / camera / Radar&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.argoverse.org/&#34;&gt;Argoverse&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban / highway&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;LiDAR / camera / Radar&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.nuscenes.org/&#34;&gt;nuScenes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera / LiDAR / Radar&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.highd-dataset.com/&#34;&gt;highD&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;highway&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.ind-dataset.com/&#34;&gt;inD&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;highway&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.round-dataset.com/&#34;&gt;roundD&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;highway&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://bdd-data.berkeley.edu/&#34;&gt;BDD100k&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;highway / urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.cvlibs.net/datasets/kitti/&#34;&gt;KITTI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;highway / rural areas&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera / LiDAR&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://ops.fhwa.dot.gov/trafficanalysistools/ngsim.htm&#34;&gt;NGSIM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;highway&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.interaction-dataset.com/&#34;&gt;INTERACTION&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;roundabout / intersection&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.gavrila.net/Datasets/Daimler_Pedestrian_Benchmark_D/Tsinghua-Daimler_Cyclist_Detec/tsinghua-daimler_cyclist_detec.html&#34;&gt;Cyclists&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;cyclists&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://apolloscape.auto/?source=post_page---------------------------&#34;&gt;Apolloscapes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/udacity/self-driving-car/tree/master/datasets&#34;&gt;Udacity&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.cityscapes-dataset.com/&#34;&gt;Cityscapes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://cvgl.stanford.edu/projects/uav_data/&#34;&gt;Stanford Drone&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.argoverse.org/&#34;&gt;Argoverse&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera / LiDAR&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://gamma.umd.edu/researchdirections/autonomousdriving/trafdataset&#34;&gt;TRAF&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / buses / cyclists / bikes / people / animals&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.5724486&#34;&gt;Aschaffenburg Pose Dataset&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Pedestrians&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Dataset&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Agents&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Scenarios&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Sensors&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://graphics.cs.ucy.ac.cy/research/downloads/crowd-data&#34;&gt;UCY&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;zara / students&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://icu.ee.ethz.ch/research/datsets.html&#34;&gt;ETH (ICCV09)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.viratdata.org/&#34;&gt;VIRAT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people / vehicles&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.cvlibs.net/datasets/kitti/&#34;&gt;KITTI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;highway / rural areas&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera / LiDAR&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://irc.atr.jp/crest2010_HRI/ATC_dataset/&#34;&gt;ATC&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;shopping center&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Range sensor&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.gavrila.net/Datasets/Daimler_Pedestrian_Benchmark_D/daimler_pedestrian_benchmark_d.html&#34;&gt;Daimler&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;from moving vehicle&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.ee.cuhk.edu.hk/~xgwang/grandcentral.html&#34;&gt;Central Station&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;inside station&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.robots.ox.ac.uk/ActiveVision/Research/Projects/2009bbenfold_headpose/project.html#datasets&#34;&gt;Town Center&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban street&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://homepages.inf.ed.ac.uk/rbf/FORUMTRACKING/&#34;&gt;Edinburgh&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.cityscapes-dataset.com/login/&#34;&gt;Cityscapes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.argoverse.org/&#34;&gt;Argoverse&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera / LiDAR&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://cvgl.stanford.edu/projects/uav_data/&#34;&gt;Stanford Drone&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;vehicles / cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://trajnet.stanford.edu/&#34;&gt;TrajNet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://data.nvision2.eecs.yorku.ca/PIE_dataset/&#34;&gt;PIE&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://next.cs.cmu.edu/multiverse/index.html&#34;&gt;ForkingPaths&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban / simulation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.aicrowd.com/challenges/trajnet-a-trajectory-forecasting-challenge&#34;&gt;TrajNet++&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.5724486&#34;&gt;Aschaffenburg Pose Dataset&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;cyclists / people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;urban&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Sport Players&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Dataset&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Agents&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Scenarios&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Sensors&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://datahub.io/collections/football&#34;&gt;Football&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;football field&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/linouk23/NBA-Player-Movements&#34;&gt;NBA SportVU&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;basketball Hall&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/a-vhadgar/Big-Data-Bowl&#34;&gt;NFL&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;people&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;American football&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;camera&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Literature and Codes&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Survey Papers&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Machine Learning for Autonomous Vehicle’s Trajectory Prediction: A comprehensive survey, Challenges, and Future Research Directions, arXiv preprint arXiv:2307.07527, 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2307.07527.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Incorporating Driving Knowledge in Deep Learning Based Vehicle Trajectory Prediction: A Survey, IEEE T-IV, 2023. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10100881&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review, IEEE T-ITS, 2023. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10181234&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Survey on Trajectory-Prediction Methods for Autonomous Driving, IEEE T-IV 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9756903&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Survey of Vehicle Trajectory Prediction Based on Deep Learning Models, International Conference on Sustainable Expert Systems, ICSES 2022. [&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-981-19-7874-6_48&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Scenario Understanding and Motion Prediction for Autonomous Vehicles – Review and Comparison, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9733973&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-modal Fusion Technology based on Vehicle Information: A Survey, arXiv preprint arXiv:2211.06080, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2211.06080.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Deep Reinforcement Learning for Autonomous Driving: A Survey, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9351818&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social Interactions for Autonomous Driving: A Review and Perspective, arXiv preprint arXiv:2208.07541, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2208.07541.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generative Adversarial Networks for Spatio-temporal Data: A Survey, ACM T-IST, 2022. [&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/3474838&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Behavioral Intention Prediction in Driving Scenes: A Survey, arXiv preprint arXiv:2211.00385, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2211.00385.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Survey on Motion Prediction of Pedestrians and Vehicles for Autonomous Driving, IEEE Access, 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9559998&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Review of Pedestrian Trajectory Prediction Methods: Comparing Deep Learning and Knowledge-based Approaches, arXiv preprint arXiv:2111.06740, 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2111.06740.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Survey on Trajectory Data Management, Analytics, and Learning, CSUR 2021. [&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/3440207&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian Behavior Prediction for Automated Driving: Requirements, Metrics, and Relevant Features, IEEE T-ITS, 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9660784&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Review of Deep Learning-Based Methods for Pedestrian Trajectory Prediction, Sensors, 2021. [&lt;a href=&#34;https://www.mdpi.com/1424-8220/21/22/7543/pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Survey on Deep-Learning Approaches for Vehicle Trajectory Prediction in Autonomous Driving, ROBIO 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2110.10436.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Henry1iu/TNT-Trajectory-Predition&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Survey of Deep Learning Techniques for Autonomous Driving, Journal of Field Robotics, 2020. [&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/epdf/10.1002/rob.21918?saml_referrer&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human Motion Trajectory Prediction: A Survey, International Journal of Robotics Research, 2020. [&lt;a href=&#34;http://sage.cnpereading.com/paragraph/download/?doi=10.1177/0278364920917446&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Autonomous Driving with Deep Learning: A Survey of State-of-Art Technologies, arXiv preprint arXiv:2006.06091, 2020. [&lt;a href=&#34;https://arxiv.org/ftp/arxiv/papers/2006/2006.06091.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Survey on Visual Traffic Simulation: Models, Evaluations, and Applications in Autonomous Driving, Computer Graphics Forum 2020. [&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/epdf/10.1111/cgf.13803?saml_referrer&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Deep Learning-Based Vehicle Behavior Prediction for Autonomous Driving Applications: A Review, IEEE T-ITS 2020. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9158529&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Survey of Deep Reinforcement Learning for Motion Planning of Autonomous Vehicles, IEEE T-ITS 2020. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9210154&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicle Trajectory Similarity: Models, Methods, and Applications, ACM Computing Surveys (CSUR 2020). [&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/3406096&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Modeling and Prediction of Human Driver Behavior: A Survey, 2020. [&lt;a href=&#34;https://arxiv.org/abs/2006.08832&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A literature review on the prediction of pedestrian behavior in urban scenarios, ITSC 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8569415&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Survey on Vision-Based Path Prediction. [&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-319-91131-1_4&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Autonomous vehicles that interact with pedestrians: A survey of theory and practice. [&lt;a href=&#34;https://arxiv.org/abs/1805.11773&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory data mining: an overview. [&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=2743025&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A survey on motion prediction and risk assessment for intelligent vehicles. [&lt;a href=&#34;https://robomechjournal.springeropen.com/articles/10.1186/s40648-014-0001-z&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Physics Systems with Interaction&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Learning Physical Dynamics with Subequivariant Graph Neural Networks, NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.06876&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/hanjq17/SGNN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning, NeurIPS 2020. [&lt;a href=&#34;https://arxiv.org/abs/2003.13924&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Interaction Templates for Multi-Robot Systems, IROS 2019. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/8737744/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Factorised Neural Relational Inference for Multi-Interaction Systems, ICML workshop 2019. [&lt;a href=&#34;https://arxiv.org/abs/1905.08721v1&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ekwebb/fNRI&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Physics-as-Inverse-Graphics: Joint Unsupervised Learning of Objects and Physics from Video, 2019. [&lt;a href=&#34;https://arxiv.org/pdf/1905.11169v1.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Neural Relational Inference for Interacting Systems, ICML 2018. [&lt;a href=&#34;https://arxiv.org/abs/1802.04687v2&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ethanfetaya/NRI&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Unsupervised Learning of Latent Physical Properties Using Perception-Prediction Networks, UAI 2018. [&lt;a href=&#34;http://arxiv.org/abs/1807.09244v2&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Relational inductive biases, deep learning, and graph networks, 2018. [&lt;a href=&#34;https://arxiv.org/abs/1806.01261v3&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions, ICLR 2018. [&lt;a href=&#34;http://arxiv.org/abs/1802.10353v1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Graph networks as learnable physics engines for inference and control, ICML 2018. [&lt;a href=&#34;http://arxiv.org/abs/1806.01242v1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Flexible Neural Representation for Physics Prediction, 2018. [&lt;a href=&#34;http://arxiv.org/abs/1806.08047v2&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A simple neural network module for relational reasoning, 2017. [&lt;a href=&#34;http://arxiv.org/abs/1706.01427v1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;VAIN: Attentional Multi-agent Predictive Modeling, NeurIPS 2017. [&lt;a href=&#34;https://arxiv.org/pdf/1706.06122.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Visual Interaction Networks, 2017. [&lt;a href=&#34;http://arxiv.org/abs/1706.01433v1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Compositional Object-Based Approach to Learning Physical Dynamics, ICLR 2017. [&lt;a href=&#34;http://arxiv.org/abs/1612.00341v2&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Interaction Networks for Learning about Objects, Relations and Physics, 2016. [&lt;a href=&#34;https://arxiv.org/abs/1612.00222&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/higgsfield/interaction_network_pytorch&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Intelligent Vehicles &amp;amp; Traffic &amp;amp; Pedestrians&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MotionDiffuser: Controllable Multi-Agent Motion Prediction using Diffusion, CVPR 2023. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_MotionDiffuser_Controllable_Multi-Agent_Motion_Prediction_Using_Diffusion_CVPR_2023_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Uncovering the Missing Pattern: Unified Framework Towards Trajectory Imputation and Prediction, CVPR 2023. [&lt;a href=&#34;http://xxx.itp.ac.cn/pdf/2303.16005.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Unsupervised Sampling Promoting for Stochastic Human Trajectory Prediction, CVPR 2023. [&lt;a href=&#34;https://chengy12.github.io/files/Bosampler.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/viewsetting/Unsupervised_sampling_promoting&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Planning-oriented Autonomous Driving, CVPR 2023. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Planning-Oriented_Autonomous_Driving_CVPR_2023_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/OpenDriveLab/UniAD&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint Multi-Agent Trajectory Prediction, CVPR 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2303.00575.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Stimulus Verification is a Universal and Effective Sampler in Multi-modal Human Trajectory Prediction, CVPR 2023. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Stimulus_Verification_Is_a_Universal_and_Effective_Sampler_in_Multi-Modal_CVPR_2023_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Query-Centric Trajectory Prediction, CVPR 2023. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Query-Centric_Trajectory_Prediction_CVPR_2023_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ZikangZhou/QCNet&#34;&gt;code&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/pdf/2306.10508.pdf&#34;&gt;QCNeXt&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;FEND: A Future Enhanced Distribution-Aware Contrastive Learning Framework for Long-tail Trajectory Prediction, CVPR 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2303.16574.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory Diffusion, CVPR 2023. [&lt;a href=&#34;https://nv-tlabs.github.io/trace-pace/docs/trace_and_pace.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://nv-tlabs.github.io/trace-pace/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;FJMP: Factorized Joint Multi-Agent Motion Prediction over Learned Directed Acyclic Interaction Graphs, CVPR 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2211.16197.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://rluke22.github.io/FJMP/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Leapfrog Diffusion Model for Stochastic Trajectory Prediction, CVPR 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2303.10895.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MediaBrain-SJTU/LED&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries, CVPR 2023. [&lt;a href=&#34;http://xxx.itp.ac.cn/pdf/2208.01582.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://tsinghua-mars-lab.github.io/ViP3D/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;EqMotion: Equivariant Multi-Agent Motion Prediction with Invariant Interaction Reasoning, CVPR 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2303.10876.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MediaBrain-SJTU/EqMotion&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;V2X-Seq: A Large-Scale Sequential Dataset for Vehicle-Infrastructure Cooperative Perception and Forecasting, CVPR 2023. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_V2X-Seq_A_Large-Scale_Sequential_Dataset_for_Vehicle-Infrastructure_Cooperative_Perception_and_CVPR_2023_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/AIR-THU/DAIR-V2X-Seq&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Weakly Supervised Class-agnostic Motion Prediction for Autonomous Driving, CVPR 2023. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Weakly_Supervised_Class-Agnostic_Motion_Prediction_for_Autonomous_Driving_CVPR_2023_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Decompose More and Aggregate Better: Two Closer Looks at Frequency Representation Learning for Human Motion Prediction, CVPR 2023. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_Decompose_More_and_Aggregate_Better_Two_Closer_Looks_at_Frequency_CVPR_2023_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;HumanMAC: Masked Motion Completion for Human Motion Prediction, ICCV 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03665&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LinghaoChan/HumanMAC&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction, ICCV 2023. [&lt;a href=&#34;https://arxiv.org/abs/2211.14304&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/BarqueroGerman/BeLFusion&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory Forecasting, ICCV 2023. [&lt;a href=&#34;https://arxiv.org/abs/2307.09306&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/InhwanBae/EigenTrajectory&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;ADAPT: Efficient Multi-Agent Trajectory Prediction with Adaptation, ICCV 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2307.14187.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://kuis-ai.github.io/adapt/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;PowerBEV: A Powerful Yet Lightweight Framework for Instance Prediction in Bird’s-Eye View, IJCAI 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2306.10761.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/EdwardLeeLPZ/PowerBEV&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human Joint Kinematics Diffusion-Refinement for Stochastic Motion Prediction, AAAI 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2210.05976.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-stream Representation Learning for Pedestrian Trajectory Prediction, AAAI 2023. [&lt;a href=&#34;https://ojs.aaai.org/index.php/AAAI/article/view/25389&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Continuous Trajectory Generation Based on Two-Stage GAN, AAAI 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2301.07103.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/WenMellors/TS-TrajGen&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Set of Control Points Conditioned Pedestrian Trajectory Prediction, AAAI 2023. [&lt;a href=&#34;https://assets.underline.io/lecture/67747/paper/82988b653861eb7a0d5cdc91c4b26f8c.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/InhwanBae/GraphTERN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Leveraging Future Relationship Reasoning for Vehicle Trajectory Prediction, ICLR 2023. [&lt;a href=&#34;https://openreview.net/forum?id=CGBCTp2M6lA&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;TrafficGen: Learning to Generate Diverse and Realistic Traffic Scenarios, ICRA 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2210.06609.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/metadriverse/trafficgen&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GANet: Goal Area Network for Motion Forecasting, ICRA 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2209.09723.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/kingwmk/GANet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;TOFG: A Unified and Fine-Grained Environment Representation in Autonomous Driving, ICRA 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2305.20068.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous Driving, CoRL 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2206.14116.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/AutoVision-cloud/SSL-Lanes&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;LimSim: A Long-term Interactive Multi-scenario Traffic Simulator, ITSC 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2307.06648.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/PJLab-ADG/LimSim&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MVHGN: Multi-View Adaptive Hierarchical Spatial Graph Convolution Network Based Trajectory Prediction for Heterogeneous Traffic-Agents, TITS. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10056303&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Adaptive and Simultaneous Trajectory Prediction for Heterogeneous Agents via Transferable Hierarchical Transformer Network, TITS. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10149109&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SSAGCN: Social Soft Attention Graph Convolution Network for Pedestrian Trajectory Prediction, TNNLS. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10063206&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/WW-Tong/ssagcn_for_path_prediction&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Disentangling Crowd Interactions for Pedestrians Trajectory Prediction, RAL. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10083225&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;VNAGT: Variational Non-Autoregressive Graph Transformer Network for Multi-Agent Trajectory Prediction, IEEE Transactions on Vehicular Technology. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10121688&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Spatial-Temporal-Spectral LSTM: A Transferable Model for Pedestrian Trajectory Prediction, TIV. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10149368&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Holistic Transformer: A Joint Neural Network for Trajectory Prediction and Decision-Making of Autonomous Vehicles, PR. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0031320323002935&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Tri-HGNN: Learning triple policies fused hierarchical graph neural networks for pedestrian trajectory prediction, PR. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0031320323004703&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multimodal Vehicular Trajectory Prediction With Inverse Reinforcement Learning and Risk Aversion at Urban Unsignalized Intersections, TITS. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10164651&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory prediction for autonomous driving based on multiscale spatial‐temporal graph, IET Intelligent Transport Systems. [&lt;a href=&#34;https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/itr2.12265&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social Self-Attention Generative Adversarial Networks for Human Trajectory Prediction, IEEE Transactions on Artificial Intelligence. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10197467&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;CSIR: Cascaded Sliding CVAEs With Iterative Socially-Aware Rethinking for Trajectory Prediction, TITS. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10215313&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multimodal Manoeuvre and Trajectory Prediction for Automated Driving on Highways Using Transformer Networks, RAL. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10207845&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A physics-informed Transformer model for vehicle trajectory prediction on highways, Transportation Research Part C: Emerging Technologies. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0968090X23002619&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Gengmaosi/PIT-IDM&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MacFormer: Map-Agent Coupled Transformer for Real-time and Robust Trajectory Prediction, RAL. [&lt;a href=&#34;https://arxiv.org/pdf/2308.10280.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MRGTraj: A Novel Non-Autoregressive Approach for Human Trajectory Prediction, TCSVT. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10226250&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wisionpeng/MRGTraj&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Planning-inspired Hierarchical Trajectory Prediction via Lateral-Longitudinal Decomposition for Autonomous Driving, TIV. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=10226224&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Traj-MAE: Masked Autoencoders for Trajectory Prediction, arXiv preprint arXiv:2303.06697, 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2303.06697.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Uncertainty-Aware Pedestrian Trajectory Prediction via Distributional Diffusion, arXiv preprint arXiv:2303.08367, 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2303.08367.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Diffusion Model for GPS Trajectory Generation, arXiv preprint arXiv:2304.11582, 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2304.11582.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multiverse Transformer: 1st Place Solution for Waymo Open Sim Agents Challenge 2023, CVPR 2023 Workshop on Autonomous Driving. [&lt;a href=&#34;https://arxiv.org/pdf/2306.11868.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://multiverse-transformer.github.io/sim-agents/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Joint-Multipath++ for Simulation Agents: 2nd Place Solution for Waymo Open Sim Agents Challenge 2023, CVPR 2023 Workshop on Autonomous Driving. [&lt;a href=&#34;https://storage.googleapis.com/waymo-uploads/files/research/2023%20Technical%20Reports/SA_hm_jointMP.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangwenxi-handsome/Joint-Multipathpp&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MTR++: Multi-Agent Motion Prediction with Symmetric Scene Modeling and Guided Intention Querying, 1st Place Solution for Waymo Open Motion Prediction Challenge 2023, CVPR 2023 Workshop on Autonomous Driving. [&lt;a href=&#34;https://arxiv.org/pdf/2306.17770.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sshaoshuai/MTR&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GameFormer: Game-theoretic Modeling and Learning of Transformer-based Interactive Prediction and Planning for Autonomous Driving, arXiv preprint arXiv:2303.05760, 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2303.05760.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MCZhi/GameFormer&#34;&gt;code&lt;/a&gt;] [&lt;a href=&#34;https://mczhi.github.io/GameFormer/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GameFormer Planner: A Learning-enabled Interactive Prediction and Planning Framework for Autonomous Vehicles, the nuPlan Planning Challenge at the CVPR 2023 End-to-End Autonomous Driving Workshop. [&lt;a href=&#34;https://opendrivelab.com/e2ead/AD23Challenge/Track_4_AID.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MCZhi/GameFormer-Planner/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;trajdata: A Unified Interface to Multiple Human Trajectory Datasets, arXiv preprint arXiv:2307.13924, 2023. [&lt;a href=&#34;https://arxiv.org/pdf/2307.13924.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/NVlabs/trajdata&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Remember Intentions: Retrospective-Memory-based Trajectory Prediction, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.11474.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MediaBrain-SJTU/MemoNet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;STCrowd: A Multimodal Dataset for Pedestrian Perception in Crowded Scenes, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2204.01026.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/4DVLab/STCrowd.git&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicle trajectory prediction works, but not everywhere, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2112.03909.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://s-attack.github.io/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.13777.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gutianpei/MID&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Non-Probability Sampling Network for Stochastic Human Trajectory Prediction, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.13471.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/inhwanbae/NPSN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;On Adversarial Robustness of Trajectory Prediction for Autonomous Vehicles, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2201.05057.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zqzqz/AdvTrajectoryPrediction&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Adaptive Trajectory Prediction via Transferable GNN, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.05046.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2111.14820.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/vita-epfl/causalmotion&#34;&gt;code&lt;/a&gt;, &lt;a href=&#34;https://github.com/sherwinbahmani/ynet_adaptive&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;How many Observations are Enough? Knowledge Distillation for Trajectory Forecasting, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.04781.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning from All Vehicles, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.11934.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/dotchen/LAV&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Forecasting from LiDAR via Future Object Detection, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.16297.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/neeharperi/FutureDet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;End-to-End Trajectory Distribution Prediction Based on Occupancy Grid Maps, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.16910.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Kguo-cs/TDOR&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;M2I: From Factored Marginal Trajectory Prediction to Interactive Prediction, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2202.11884.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://tsinghua-mars-lab.github.io/M2I/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GroupNet: Multiscale Hypergraph Neural Networks for Trajectory Prediction with Relational Reasoning, CVPR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2204.08770.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MediaBrain-SJTU/GroupNet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Whose Track Is It Anyway? Improving Robustness to Tracking Errors with Affinity-Based Prediction, CVPR 2022. [&lt;a href=&#34;https://xinshuoweng.com/papers/Affinipred/camera_ready.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;ScePT: Scene-consistent, Policy-based Trajectory Predictions for Planning, CVPR 2022. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_ScePT_Scene-Consistent_Policy-Based_Trajectory_Predictions_for_Planning_CVPR_2022_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/NVlabs/ScePT&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Graph-based Spatial Transformer with Memory Replay for Multi-future Pedestrian Trajectory Prediction, CVPR 2022. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Graph-Based_Spatial_Transformer_With_Memory_Replay_for_Multi-Future_Pedestrian_Trajectory_CVPR_2022_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Jacobieee/ST-MR&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MUSE-VAE: Multi-Scale VAE for Environment-Aware Long Term Trajectory Prediction, CVPR 2022. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_MUSE-VAE_Multi-Scale_VAE_for_Environment-Aware_Long_Term_Trajectory_Prediction_CVPR_2022_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;LTP: Lane-based Trajectory Prediction for Autonomous Driving, CVPR 2022. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_LTP_Lane-Based_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2022_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;ATPFL: Automatic Trajectory Prediction Model Design under Federated Learning Framework, CVPR 2022. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ATPFL_Automatic_Trajectory_Prediction_Model_Design_Under_Federated_Learning_Framework_CVPR_2022_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human Trajectory Prediction with Momentary Observation, CVPR 2022. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Human_Trajectory_Prediction_With_Momentary_Observation_CVPR_2022_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;HiVT: Hierarchical Vector Transformer for Multi-Agent Motion Prediction, CVPR 2022. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ZikangZhou/HiVT&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning Pedestrian Group Representations for Multi-modal Trajectory Prediction, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2207.09953.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/InhwanBae/GPGraph&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.03057.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/abduallahmohamed/Social-Implicit&#34;&gt;code&lt;/a&gt;] [&lt;a href=&#34;https://www.abduallahmohamed.com/social-implicit-amdamv-adefde-demo&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Hierarchical Latent Structure for Multi-Modal Vehicle Trajectory Forecasting, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2207.04624.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/d1024choi/HLSTrajForecast&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SocialVAE: Human Trajectory Prediction using Timewise Latents, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.08207.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/xupei0610/SocialVAE&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;View Vertically: A Hierarchical Network for Trajectory Prediction via Fourier Spectrums, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2110.07288.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/cocoon2wong/Vertical&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Entry-Flipped Transformer for Inference and Prediction of Participant Behavior, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2207.06235.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;D2-TPred: Discontinuous Dependency for Trajectory Prediction under Traffic Lights, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2207.10398.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/VTP-TL/D2-TPred&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human Trajectory Prediction via Neural Social Physics, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2207.10435.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/realcrane/Human-Trajectory-Prediction-via-Neural-Social-Physics&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social-SSL: Self-Supervised Cross-Sequence Representation Learning Based on Transformers for Multi-Agent Trajectory Prediction, ECCV 2022. [&lt;a href=&#34;https://basiclab.lab.nycu.edu.tw/assets/Social-SSL.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Sigta678/Social-SSL&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Aware of the History: Trajectory Forecasting with the Local Behavior Data, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2207.09646.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Kay1794/Aware-of-the-history&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Action-based Contrastive Learning for Trajectory Prediction, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2207.08664.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;AdvDO: Realistic Adversarial Attacks for Trajectory Prediction, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2209.08744.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;ST-P3: End-to-end Vision-based Autonomous Driving via Spatial-Temporal Feature Learning, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2207.07601.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/OpenPerceptionX/ST-P3&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social ODE: Multi-Agent Trajectory Forecasting with Neural Ordinary Differential Equations, ECCV 2022. [&lt;a href=&#34;https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136820211.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Forecasting Human Trajectory from Scene History, NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2210.08732.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MaKaRuiNah/SHENet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline, NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2206.08129&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/OpenPerceptionX/TCP&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Motion Transformer with Global Intention Localization and Local Movement Refinement, NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2209.13508.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://vas.mpi-inf.mpg.de/motion-transformer-with-global-intention-localization-and-local-movement-refinement/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Interaction Modeling with Multiplex Attention, NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2208.10660.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/fanyun-sun/IMMA&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Deep Interactive Motion Prediction and Planning: Playing Games with Motion Prediction Models, Conference on Learning for Dynamics and Control (L4DC). [&lt;a href=&#34;https://arxiv.org/pdf/2204.02392.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://sites.google.com/view/deep-interactive-predict-plan&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social Interpretable Tree for Pedestrian Trajectory Prediction, AAAI 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2205.13296.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/lssiair/SIT&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Complementary Attention Gated Network for Pedestrian Trajectory Prediction, AAAI 2022. [&lt;a href=&#34;https://www.aaai.org/AAAI22Papers/AAAI-1963.DuanJ.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jinghaiD/CAGN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Scene Transformer: A unified architecture for predicting future trajectories of multiple agents, ICLR 2022. [&lt;a href=&#34;https://openreview.net/pdf?id=Wm3EA5OlHsG&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;You Mostly Walk Alone: Analyzing Feature Attribution in Trajectory Prediction, ICLR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2110.05304.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Latent Variable Sequential Set Transformers For Joint Multi-Agent Motion Prediction, ICLR 2022. [&lt;a href=&#34;https://openreview.net/pdf?id=Dup_dDqkZC5&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://fgolemo.github.io/autobots/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling, ICLR 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2110.06607&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Path-Aware Graph Attention for HD Maps in Motion Prediction, ICRA 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2202.13772.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Prediction with Linguistic Representations, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9811928&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Leveraging Smooth Attention Prior for Multi-Agent Trajectory Prediction, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9811718&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://sites.google.com/view/smoothness-attention&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;KEMP: Keyframe-Based Hierarchical End-to-End Deep Model for Long-Term Trajectory Prediction, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9812337&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Domain Generalization for Vision-based Driving Trajectory Generation, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9812070&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://sites.google.com/view/dg-traj-gen&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Deep Concept Graph Network for Interaction-Aware Trajectory Prediction, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9811567&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Conditioned Human Trajectory Prediction using Iterative Attention Blocks, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9812404&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;StopNet: Scalable Trajectory and Occupancy Prediction for Urban Autonomous Driving, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9811830&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Meta-path Analysis on Spatio-Temporal Graphs for Pedestrian Trajectory Prediction, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9811632&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://sites.google.com/illinois.edu/mesrnn/home&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Propagating State Uncertainty Through Trajectory Forecasting, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9811776&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/StanfordASL/PSU-TF&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;HYPER: Learned Hybrid Trajectory Prediction via Factored Inference and Adaptive Sampling, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9812254&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for Group-Aware Dense Crowd Trajectory Forecasting, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9811585&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Crossmodal Transformer Based Generative Framework for Pedestrian Trajectory Prediction, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9812226&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Prediction for Autonomous Driving with Topometric Map, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9811712&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Jiaolong/trajectory-prediction&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;CRAT-Pred: Vehicle Trajectory Prediction with Crystal Graph Convolutional Neural Networks and Multi-Head Self-Attention, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9811637&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/schmidt-ju/crat-pred&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MultiPath++: Efficient Information Fusion and Trajectory Aggregation for Behavior Prediction, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9812107&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-modal Motion Prediction with Transformer-based Neural Network for Autonomous Driving, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9812060/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GOHOME: Graph-Oriented Heatmap Output for future Motion Estimation, ICRA 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2109.01827.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;TridentNetV2: Lightweight Graphical Global Plan Representations for Dynamic Trajectory Generation, ICRA 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9811591&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Heterogeneous-Agent Trajectory Forecasting Incorporating Class Uncertainty, IROS 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2104.12446.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/TRI-ML/HAICU&#34;&gt;code&lt;/a&gt;] [&lt;a href=&#34;https://github.com/nvr-avg/trajdata&#34;&gt;trajdata&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Prediction with Graph-based Dual-scale Context Fusion, IROS 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2111.01592.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/HKUST-Aerial-Robotics/DSP&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Robust Trajectory Prediction against Adversarial Attacks, CoRL 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2208.00094.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://robustav.github.io/RobustTraj/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Planning with Diffusion for Flexible Behavior Synthesis, ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.09991&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://diffusion-planning.github.io/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Synchronous Bi-Directional Pedestrian Trajectory Prediction with Error Compensation, ACCV 2022. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ACCV2022/papers/Xie_Synchronous_Bi-Directional_Pedestrian_Trajectory_Prediction_with_Error_Compensation_ACCV_2022_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;AI-TP: Attention-based Interaction-aware Trajectory Prediction for Autonomous Driving, IEEE T-IV, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9723649&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/KP-Zhang/AI-TP&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MDST-DGCN: A Multilevel Dynamic Spatiotemporal Directed Graph Convolutional Network for Pedestrian Trajectory Prediction, Computational Intelligence and Neuroscience. [&lt;a href=&#34;https://downloads.hindawi.com/journals/cin/2022/4192367.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Graph-Based Spatial-Temporal Convolutional Network for Vehicle Trajectory Prediction in Autonomous Driving, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9737058&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-Agent Trajectory Prediction with Heterogeneous Edge-Enhanced Graph Attention Network, IEEE T-ITS, 2022. [&lt;a href=&#34;https://dspace.lib.cranfield.ac.uk/bitstream/handle/1826/17541/Multi-agent_trajectory_prediction-2022.pdf?sequence=1&amp;amp;isAllowed=y&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Fully Convolutional Encoder-Decoder With an Attention Mechanism for Practical Pedestrian Trajectory Prediction, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9768201&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;STGM: Vehicle Trajectory Prediction Based on Generative Model for Spatial-Temporal Features, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9743363&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Prediction for Autonomous Driving Using Spatial-Temporal Graph Attention Transformer, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9768029&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Intention-Aware Vehicle Trajectory Prediction Based on Spatial-Temporal Dynamic Attention Network for Internet of Vehicles, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9767719&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://xbchen82.github.io/resource/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Forecasting Based on Prior-Aware Directed Graph Convolutional Neural Network, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9686621&amp;amp;tag=1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;DeepTrack: Lightweight Deep Learning for Vehicle Trajectory Prediction in Highways, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9770480&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Interactive Trajectory Prediction Using a Driving Risk Map-Integrated Deep Learning Method for Surrounding Vehicles on Highways, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9745461&amp;amp;tag=1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicle Trajectory Prediction in Connected Environments via Heterogeneous Context-Aware Graph Convolutional Networks, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9781338&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Prediction Neural Network and Model Interpretation Based on Temporal Pattern Attention, IEEE T-ITS, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9945660&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning Sparse Interaction Graphs of Partially Detected Pedestrians for Trajectory Prediction, IEEE RA-L, 2022. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9664278&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/tedhuang96/gst&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GAMMA: A General Agent Motion Prediction Model for Autonomous Driving, RAL. [&lt;a href=&#34;https://arxiv.org/pdf/1906.01566.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/AdaCompNUS/gamma&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Stepwise Goal-Driven Networks for Trajectory Prediction, RAL. [&lt;a href=&#34;https://arxiv.org/pdf/2103.14107v3.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ChuhuaW/SGNet.pytorch&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GA-STT: Human Trajectory Prediction with Group Aware Spatial-Temporal Transformer, RAL. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9779572&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Long-term 4D trajectory prediction using generative adversarial networks, Transportation Research Part C: Emerging Technologies. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0968090X22000031&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A context-aware pedestrian trajectory prediction framework for automated vehicles, Transportation Research Part C: Emerging Technologies. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0968090X21004423&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Explainable multimodal trajectory prediction using attention models, Transportation Research Part C: Emerging Technologies. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0968090X22002509&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;CSCNet: Contextual semantic consistency network for trajectory prediction in crowded spaces, PR. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0031320322000334&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;CSR: Cascade Conditional Variational AutoEncoder with Social-aware Regression for Pedestrian Trajectory Prediction, PR. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0031320322005106&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Step Attention: Sequential Pedestrian Trajectory Prediction, IEEE Sensors Journal. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9732437&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicle Trajectory Prediction Method Coupled With Ego Vehicle Motion Trend Under Dual Attention Mechanism, IEEE Transactions on Instrumentation and Measurement. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9749176&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Spatio-temporal Interaction Aware and Trajectory Distribution Aware Graph Convolution Network for Pedestrian Multimodal Trajectory Prediction, IEEE Transactions on Instrumentation and Measurement. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9997233&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Deep encoder–decoder-NN: A deep learning-based autonomous vehicle trajectory prediction and correction model, Physica A: Statistical Mechanics and its Applications. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0378437122000139&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;PTPGC: Pedestrian trajectory prediction by graph attention network with ConvLSTM, Robotics and Autonomous Systems. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0921889021002165&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GCHGAT: pedestrian trajectory prediction using group constrained hierarchical graph attention networks, Applied Intelligence. [&lt;a href=&#34;https://link.springer.com/article/10.1007/s10489-021-02997-w&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicles Trajectory Prediction Using Recurrent VAE Network, IEEE Access. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9740177&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/midemig/traj_pred_vae&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SEEM: A Sequence Entropy Energy-Based Model for Pedestrian Trajectory All-Then-One Prediction, TPAMI. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9699076&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;PTP-STGCN: Pedestrian Trajectory Prediction Based on a Spatio-temporal Graph Convolutional Neural Network, Applied Intelligence. [&lt;a href=&#34;https://link.springer.com/article/10.1007/s10489-022-03524-1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory distributions: A new description of movement for trajectory prediction, Computational Visual Media. [&lt;a href=&#34;https://link.springer.com/content/pdf/10.1007/s41095-021-0236-6.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory prediction for autonomous driving based on multiscale spatial-temporal graph, IET Intelligent Transport Systems. [&lt;a href=&#34;https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/itr2.12265&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Continual learning-based trajectory prediction with memory augmented networks, Knowledge-Based Systems. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0950705122011157&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Atten-GAN: Pedestrian Trajectory Prediction with GAN Based on Attention Mechanism, Cognitive Computation. [&lt;a href=&#34;https://link.springer.com/article/10.1007/s12559-022-10029-z#Abs1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;EvoSTGAT: Evolving spatiotemporal graph attention networks for pedestrian trajectory prediction, Neurocomputing. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0925231222003460?ref=pdf_download&amp;amp;fr=RR-2&amp;amp;rr=7da0ead45e800fcc&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Raising context awareness in motion forecasting, CVPR Workshops 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2109.08048.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/valeoai/CAB&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Goal-driven Self-Attentive Recurrent Networks for Trajectory Prediction, CVPR Workshops 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2204.11561.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/luigifilippochiara/Goal-SAR&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Importance Is in Your Attention: Agent Importance Prediction for Autonomous Driving, CVPR Workshops 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2204.09121.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MPA: MultiPath++ Based Architecture for Motion Prediction, CVPR Workshops 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2206.10041.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/stepankonev/waymo-motion-prediction-challenge-2022-multipath-plus-plus&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;TPAD: Identifying Effective Trajectory Predictions Under the Guidance of Trajectory Anomaly Detection Model, arXiv:2201.02941, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2201.02941v1.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Wayformer: Motion Forecasting via Simple &amp;amp; Efficient Attention Networks, arXiv preprint arXiv:2207.05844, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2207.05844.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;PreTR: Spatio-Temporal Non-Autoregressive Trajectory Prediction Transformer, arXiv preprint arXiv:2203.09293, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.09293.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;LatentFormer: Multi-Agent Transformer-Based Interaction Modeling and Trajectory Prediction, arXiv preprint arXiv:2203.01880, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2203.01880.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Diverse Multiple Trajectory Prediction Using a Two-stage Prediction Network Trained with Lane Loss, arXiv preprint arXiv:2206.08641, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2206.08641.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Semi-supervised Semantics-guided Adversarial Training for Trajectory Prediction, arXiv preprint arXiv:2205.14230, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2205.14230.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Heterogeneous Trajectory Forecasting via Risk and Scene Graph Learning, arXiv preprint arXiv:2211.00848, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2211.00848.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GATraj: A Graph- and Attention-based Multi-Agent Trajectory Prediction Model, arXiv preprint arXiv:2209.07857, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2209.07857.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mengmengliu1998/GATraj&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Dynamic-Group-Aware Networks for Multi-Agent Trajectory Prediction with Relational Reasoning, arXiv preprint arXiv:2206.13114, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2206.13114.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Collaborative Uncertainty Benefits Multi-Agent Multi-Modal Trajectory Forecasting, arXiv preprint arXiv:2207.05195, 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.05195&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MediaBrain-SJTU/Collaborative-Uncertainty&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Guided Conditional Diffusion for Controllable Traffic Simulation, arXiv preprint arXiv:2210.17366, 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2210.17366.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://aiasd.github.io/ctg.github.io/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;PhysDiff: Physics-Guided Human Motion Diffusion Model, arXiv preprint arXiv:2212.02500, 2022. [&lt;a href=&#34;http://xxx.itp.ac.cn/pdf/2212.02500.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MPA: MultiPath++ Based Architecture for Motion Prediction, CVPR Workshop on Autonomous Driving 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.10041&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/stepankonev/waymo-motion-prediction-challenge-2022-multipath-plus-plus&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Collaborative Uncertainty in Multi-Agent Trajectory Forecasting, NeurIPS 2021. [&lt;a href=&#34;https://proceedings.neurips.cc/paper/2021/file/31ca0ca71184bbdb3de7b20a51e88e90-Paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GRIN: Generative Relation and Intention Network for Multi-agent Trajectory Prediction, NeurIPS 2021. [&lt;a href=&#34;https://proceedings.neurips.cc/paper/2021/file/e3670ce0c315396e4836d7024abcf3dd-Paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/longyuanli/GRIN_NeurIPS21&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;LibCity: An Open Library for Traffic Prediction, SIGSPATIAL 2021. [&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/3474717.3483923&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LibCity/Bigscity-LibCity&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Predicting Vehicles Trajectories in Urban Scenarios with Transformer Networks and Augmented Information, IEEE Intelligent Vehicles Symposium (IV 2021). [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9575242&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social-STAGE: Spatio-Temporal Multi-Modal Future Trajectory Forecast, ICRA 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2011.04853.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;AVGCN: Trajectory Prediction using Graph Convolutional Networks Guided by Human Attention, ICRA 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2101.05682.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Exploring Dynamic Context for Multi-path Trajectory Prediction, ICRA 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9562034&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wtliao/DCENet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian Trajectory Prediction using Context-Augmented Transformer Networks, ICRA 2021. [&lt;a href=&#34;https://www.researchgate.net/publication/346614349_Pedestrian_Trajectory_Prediction_using_Context-Augmented_Transformer_Networks&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/KhaledSaleh/Context-Transformer-PedTraj&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Spectral Temporal Graph Neural Network for Trajectory Prediction, ICRA 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2106.02930.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Congestion-aware Multi-agent Trajectory Prediction for Collision Avoidance, ICRA 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9560994&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/xuxie1031/CollisionFreeMultiAgentTrajectoryPrediciton&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Anticipatory Navigation in Crowds by Probabilistic Prediction of Pedestrian Future Movements, ICRA 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9561022&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;AgentFormer: Agent-Aware Transformers for Socio-Temporal Multi-Agent Forecasting, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Yuan_AgentFormer_Agent-Aware_Transformers_for_Socio-Temporal_Multi-Agent_Forecasting_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Khrylx/AgentFormer&#34;&gt;code&lt;/a&gt;] [&lt;a href=&#34;https://ye-yuan.com/agentformer/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Likelihood-Based Diverse Sampling for Trajectory Forecasting, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Jason_Likelihood-Based_Diverse_Sampling_for_Trajectory_Forecasting_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/JasonMa2016/LDS&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MG-GAN: A Multi-Generator Model Preventing Out-of-Distribution Samples in Pedestrian Trajectory Prediction, ICCV 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2108.09274.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/selflein/MG-GAN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Spatial-Temporal Consistency Network for Low-Latency Trajectory Forecasting, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Spatial-Temporal_Consistency_Network_for_Low-Latency_Trajectory_Forecasting_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Three Steps to Multimodal Trajectory Prediction: Modality Clustering, Classification and Synthesis, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Sun_Three_Steps_to_Multimodal_Trajectory_Prediction_Modality_Clustering_Classification_and_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;From Goals, Waypoints &amp;amp; Paths To Long Term Human Trajectory Forecasting, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Mangalam_From_Goals_Waypoints__Paths_to_Long_Term_Human_Trajectory_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://karttikeya.github.io/publication/ynet/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Where are you heading? Dynamic Trajectory Prediction with Expert Goal Examples, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Where_Are_You_Heading_Dynamic_Trajectory_Prediction_With_Expert_Goal_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/JoeHEZHAO/expert_traj&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;DenseTNT: End-to-end Trajectory Prediction from Dense Goal Sets, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_DenseTNT_End-to-End_Trajectory_Prediction_From_Dense_Goal_Sets_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Safety-aware Motion Prediction with Unseen Vehicles for Autonomous Driving, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Ren_Safety-Aware_Motion_Prediction_With_Unseen_Vehicles_for_Autonomous_Driving_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/xrenaa/Safety-Aware-Motion-Prediction&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;LOKI: Long Term and Key Intentions for Trajectory Prediction, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Girase_LOKI_Long_Term_and_Key_Intentions_for_Trajectory_Prediction_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://usa.honda-ri.com/loki&#34;&gt;dataset&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human Trajectory Prediction via Counterfactual Analysis, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Human_Trajectory_Prediction_via_Counterfactual_Analysis_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/CHENGY12/CausalHTP&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Personalized Trajectory Prediction via Distribution Discrimination, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Personalized_Trajectory_Prediction_via_Distribution_Discrimination_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/CHENGY12/DisDis&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Unlimited Neighborhood Interaction for Heterogeneous Trajectory Prediction, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Zheng_Unlimited_Neighborhood_Interaction_for_Heterogeneous_Trajectory_Prediction_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zhengfang1997/Unlimited-Neighborhood-Interaction-for-Heterogeneous-Trajectory-Prediction&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social NCE: Contrastive Learning of Socially-aware Motion Representations, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Social_NCE_Contrastive_Learning_of_Socially-Aware_Motion_Representations_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/vita-epfl/social-nce&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting, ICCV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/papers/Li_RAIN_Reinforced_Hybrid_Attention_Inference_Network_for_Motion_Forecasting_ICCV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Temporal Pyramid Network for Pedestrian Trajectory Prediction with Multi-Supervision, AAAI 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2012.01884.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SCAN: A Spatial Context Attentive Network for Joint Multi-Agent Intent Prediction, AAAI 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2102.00109.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Disentangled Multi-Relational Graph Convolutional Network for Pedestrian Trajectory Prediction, AAAI 2021. [&lt;a href=&#34;https://www.aaai.org/AAAI21Papers/AAAI-1677.BaeI.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/InhwanBae/DMRGCN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MotionRNN: A Flexible Model for Video Prediction with Spacetime-Varying Motions, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_MotionRNN_A_Flexible_Model_for_Video_Prediction_With_Spacetime-Varying_Motions_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multimodal Motion Prediction with Stacked Transformers, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Multimodal_Motion_Prediction_With_Stacked_Transformers_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/decisionforce/mmTransformer&#34;&gt;code&lt;/a&gt;] [&lt;a href=&#34;https://decisionforce.github.io/mmTransformer/?utm_source=catalyzex.com&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SGCN: Sparse Graph Convolution Network for Pedestrian Trajectory Prediction, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_SGCN_Sparse_Graph_Convolution_Network_for_Pedestrian_Trajectory_Prediction_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/shuaishiliu/SGCN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;LaPred: Lane-Aware Prediction of Multi-Modal Future Trajectories of Dynamic Agents, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_LaPred_Lane-Aware_Prediction_of_Multi-Modal_Future_Trajectories_of_Dynamic_Agents_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Divide-and-Conquer for Lane-Aware Diverse Trajectory Prediction, CVPR 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2104.08277.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Euro-PVI: Pedestrian Vehicle Interactions in Dense Urban Centers, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Bhattacharyya_Euro-PVI_Pedestrian_Vehicle_Interactions_in_Dense_Urban_Centers_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/euro-pvi-dataset&#34;&gt;dataset&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Prediction with Latent Belief Energy-Based Model, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Pang_Trajectory_Prediction_With_Latent_Belief_Energy-Based_Model_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/bpucla/lbebm&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Shared Cross-Modal Trajectory Prediction for Autonomous Driving, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Choi_Shared_Cross-Modal_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian and Ego-vehicle Trajectory Prediction from Monocular camera, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Neumann_Pedestrian_and_Ego-Vehicle_Trajectory_Prediction_From_Monocular_camera_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://gitlab.com/lukeN86/pedFutureTracking&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Interpretable Social Anchors for Human Trajectory Forecasting in Crowds, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Kothari_Interpretable_Social_Anchors_for_Human_Trajectory_Forecasting_in_Crowds_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Introvert: Human Trajectory Prediction via Conditional 3D Attention, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Shafiee_Introvert_Human_Trajectory_Prediction_via_Conditional_3D_Attention_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MP3: A Unified Model to Map, Perceive, Predict and Plan, CVPR 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2101.06806.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;TrafficSim: Learning to Simulate Realistic Multi-Agent Behaviors, CVPR 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Suo_TrafficSim_Learning_To_Simulate_Realistic_Multi-Agent_Behaviors_CVPR_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multimodal Transformer Network for Pedestrian Trajectory Prediction, IJCAI 2021. [&lt;a href=&#34;https://www.ijcai.org/proceedings/2021/0174.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ericyinyzy/MTN_trajectory&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Decoder Fusion RNN: Context and Interaction Aware Decoders for Trajectory Prediction, IROS 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2108.05814.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Joint Intention and Trajectory Prediction Based on Transformer, IROS 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9636241&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Maneuver-based Trajectory Prediction for Self-driving Cars Using Spatio-temporal Convolutional Networks, IROS 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9636875&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multiple Contextual Cues Integrated Trajectory Prediction for Autonomous Driving, IROS 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9476975&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;MultiXNet: Multiclass Multistage Multimodal Motion Prediction, IEEE Intelligent Vehicles Symposium (IV 2021). [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9575718&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Prediction for Autonomous Driving based on Multi-Head Attention with Joint Agent-Map Representation, IEEE Intelligent Vehicles Symposium (IV 2021). [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9576054&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social-IWSTCNN: A Social Interaction-Weighted Spatio-Temporal Convolutional Neural Network for Pedestrian Trajectory Prediction in Urban Traffic Scenarios, IV 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9575958&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generating Scenarios with Diverse Pedestrian Behaviors for Autonomous Vehicle Testing, Conference on Robot Learning (CoRL 2021). [&lt;a href=&#34;https://openreview.net/pdf?id=HTfApPeT4DZ&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MariaPriisalu/spl&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multimodal Trajectory Prediction Conditioned on Lane-Graph Traversals, CoRL 2021. [&lt;a href=&#34;https://proceedings.mlr.press/v164/deo22a.html&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/nachiket92/PGP&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning to Predict Vehicle Trajectories with Model-based Planning, CoRL 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2103.04027.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pose Based Trajectory Forecast of Vulnerable Road Users Using Recurrent Neural Networks, International Conference on Pattern Recognition (ICPR 2021). [&lt;a href=&#34;https://link.springer.com/content/pdf/10.1007/978-3-030-68763-2_5.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GraphTCN: Spatio-Temporal Interaction Modeling for Human Trajectory Prediction, WACV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/WACV2021/papers/Wang_GraphTCN_Spatio-Temporal_Interaction_Modeling_for_Human_Trajectory_Prediction_WACV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Goal-driven Long-Term Trajectory Prediction, WACV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/WACV2021/papers/Tran_Goal-Driven_Long-Term_Trajectory_Prediction_WACV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multimodal Trajectory Predictions for Autonomous Driving without a Detailed Prior Map, WACV 2021. [&lt;a href=&#34;https://openaccess.thecvf.com/content/WACV2021/papers/Kawasaki_Multimodal_Trajectory_Predictions_for_Autonomous_Driving_Without_a_Detailed_Prior_WACV_2021_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Self-Growing Spatial Graph Network for Context-Aware Pedestrian Trajectory Prediction, IEEE International Conference on Image Processing (ICIP 2021). [&lt;a href=&#34;https://arxiv.org/pdf/2012.06320v2.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/serenetech90/AOL_ovsc&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;S2TNet: Spatio-Temporal Transformer Networks for Trajectory Prediction in Autonomous Driving, Asian Conference on Machine Learning 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2206.10902.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/chenghuang66/s2tnet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning Structured Representations of Spatial and Interactive Dynamics for Trajectory Prediction in Crowded Scenes, IEEE Robotics and Automation Letters 2021 [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9309332&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/tdavchev/structured-trajectory-prediction&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Prediction using Equivariant Continuous Convolution, ICLR 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2010.11344.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Rose-STL-Lab/ECCO&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;TridentNet: A Conditional Generative Model for Dynamic Trajectory Generation, International Conference on Intelligent Autonomous Systems 2021. [&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-030-95892-3_31#Abs1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;HOME: Heatmap Output for future Motion Estimation, ITSC 2021. [&lt;a href=&#34;https://arxiv.org/pdf/2105.10968.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Graph and Recurrent Neural Network-based Vehicle Trajectory Prediction For Highway Driving, ITSC 2021. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9564929&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SCSG Attention: A Self-Centered Star Graph with Attention for Pedestrian Trajectory Prediction, International Conference on Database Systems for Advanced Applications (DASFAA 2021). [&lt;a href=&#34;https://link.springer.com/content/pdf/10.1007/978-3-030-73194-6_29.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Leveraging Trajectory Prediction for Pedestrian Video Anomaly Detection, IEEE Symposium Series on Computational Intelligence (SSCI 2021). [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9660004&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/akanuasiegbu/Leveraging-Trajectory-Prediction-for-Pedestrian-Video-Anomaly-Detection&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Are socially-aware trajectory prediction models really socially-aware?, Transportation Research: Part C. [&lt;a href=&#34;https://arxiv.org/pdf/2108.10879.pdf&#34;&gt;paper&lt;/a&gt;, &lt;a href=&#34;https://iccv21-adv-workshop.github.io/short_paper/s-attack-arow2021.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://s-attack.github.io/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Injecting knowledge in data-driven vehicle trajectory predictors, Transportation Research: Part C. [&lt;a href=&#34;https://reader.elsevier.com/reader/sd/pii/S0968090X21000425?token=F03D20769BFB255F56662C10348A81F3D07A42C6B4AB9BA19E3F7B2A5F1DA7D99B96B783616BDA86C12866AFCF4C5671&amp;amp;originRegion=eu-west-1&amp;amp;originCreation=20220506090622&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/vita-epfl/RRB&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Decoding pedestrian and automated vehicle interactions using immersive virtual reality and interpretable deep learning, Transportation Research: Part C. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0968090X2030855X&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human Trajectory Forecasting in Crowds: A Deep Learning Perspective, IEEE Transactions on Intelligent Transportation Systems. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9408398&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/vita-epfl/trajnetplusplusbaselines&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;NetTraj: A Network-Based Vehicle Trajectory Prediction Model With Directional Representation and Spatiotemporal Attention Mechanisms, TITS. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9629362&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Spatio-Temporal Graph Dual-Attention Network for Multi-Agent Prediction and Tracking, TITS. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9491972&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Hierarchical Framework for Interactive Behaviour Prediction of Heterogeneous Traffic Participants Based on Graph Neural Network, TITS. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9468360&amp;amp;tag=1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;TrajGAIL: Generating urban vehicle trajectories using generative adversarial imitation learning, Transportation Research Part C. [&lt;a href=&#34;https://reader.elsevier.com/reader/sd/pii/S0968090X21001121?token=3DEACAF2AD919E99B3331E74F747B61A0EAC2741E79B6F99F4F806155EB394F163D74F2F83806358BBD65911E107EF01&amp;amp;originRegion=us-east-1&amp;amp;originCreation=20220416040814&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/benchoi93/TrajGAIL&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicle Trajectory Prediction Using Generative Adversarial Network With Temporal Logic Syntax Tree Features, IEEE ROBOTICS AND AUTOMATION LETTERS. [&lt;a href=&#34;https://www.gilitschenski.org/igor/publications/202104-ral-logic_gan/ral21-logic_gan.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicle Trajectory Prediction Using LSTMs with Spatial-Temporal Attention Mechanisms, IEEE Intelligent Transportation Systems Magazine. [&lt;a href=&#34;http://urdata.net/files/2020_VTP.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/leilin-research/VTP&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Long Short-Term Memory-Based Human-Driven Vehicle Longitudinal Trajectory Prediction in a Connected and Autonomous Vehicle Environment, Transportation Research Record. [&lt;a href=&#34;http://sage.cnpereading.com/paragraph/download/?doi=10.1177/0361198121993471&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Temporal Pyramid Network with Spatial-Temporal Attention for Pedestrian Trajectory Prediction, IEEE Transactions on Network Science and Engineering. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9373939&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;An efficient Spatial–Temporal model based on gated linear units for trajectory prediction, Neurocomputing. [&lt;a href=&#34;https://reader.elsevier.com/reader/sd/pii/S0925231221018907?token=C894F657732BB6078B77AEC9BD3858338C1A7F1254CCC0BBC34ADA1421A95CF9A4F68BDCA8812457DE27FB37EEB8F198&amp;amp;originRegion=us-east-1&amp;amp;originCreation=20220420144432&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SRAI-LSTM: A Social Relation Attention-based Interaction-aware LSTM for human trajectory prediction, Neurocomputing. [&lt;a href=&#34;https://reader.elsevier.com/reader/sd/pii/S0925231221018014?token=BB22DAAC41E3BF453C326A9D72A0CC900C2DFFD0D8AE07B7DEED51C7F2250B9CB40CC89B6812CA20DBFA6A7EDD32AAD6&amp;amp;originRegion=us-east-1&amp;amp;originCreation=20220512100647&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;AST-GNN: An attention-based spatio-temporal graph neural network for Interaction-aware pedestrian trajectory prediction, Neurocomputing. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S092523122100388X&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-PPTP: Multiple Probabilistic Pedestrian Trajectory Prediction in the Complex Junction Scene, IEEE Transactions on Intelligent Transportation Systems. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9619864&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Novel Graph-Based Trajectory Predictor With Pseudo-Oracle, TNNLS. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9447207&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Large Scale GPS Trajectory Generation Using Map Based on Two Stage GAN, Journal of Data Science. [&lt;a href=&#34;https://www.jds-online.com/files/JDS202001-08.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/XingruiWang/Two-Stage-Gan-in-trajectory-generation&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pose and Semantic Map Based Probabilistic Forecast of Vulnerable Road Users’ Trajectories, IEEE Transactions on Intelligent Vehicles. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9707640&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;STI-GAN: Multimodal Pedestrian Trajectory Prediction Using Spatiotemporal Interactions and a Generative Adversarial Network, IEEE Access. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9387292&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Holistic LSTM for Pedestrian Trajectory Prediction, TIP. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9361440&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian trajectory prediction with convolutional neural networks, PR. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0031320321004325&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;LSTM based trajectory prediction model for cyclist utilizing multiple interactions with environment, PR. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0031320320306038&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human trajectory prediction and generation using LSTM models and GANs, PR. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S003132032100323X&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicle trajectory prediction and generation using LSTM models and GANs, Plos one. [&lt;a href=&#34;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253868&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;BiTraP: Bi-Directional Pedestrian Trajectory Prediction With Multi-Modal Goal Estimation, RAL. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9345445&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/umautobots/bidireaction-trajectory-prediction&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Kinematic Model for Trajectory Prediction in General Highway Scenarios, RAL. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9472993&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/umautobots/kinematic_highway&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory Prediction in Autonomous Driving With a Lane Heading Auxiliary Loss, RAL. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9387075&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicle Trajectory Prediction Using Generative Adversarial Network With Temporal Logic Syntax Tree Features, RAL. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9366373&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Tra2Tra: Trajectory-to-Trajectory Prediction With a Global Social Spatial-Temporal Attentive Neural Network, RAL. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9347678&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social graph convolutional LSTM for pedestrian trajectory prediction, IET Intelligent Transport Systems. [&lt;a href=&#34;https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/itr2.12033&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;HSTA: A Hierarchical Spatio-Temporal Attention Model for Trajectory Prediction, IEEE Transactions on Vehicular Technology (TVT). [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9548801&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Environment-Attention Network for Vehicle Trajectory Prediction, TVT. [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9534487&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Where Are They Going? Predicting Human Behaviors in Crowded Scenes, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM). [&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/3449359&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-Agent Trajectory Prediction with Spatio-Temporal Sequence Fusion, IEEE Transactions on Multimedia (TMM). [&lt;a href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=9580659&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning, NeurIPS 2020. [&lt;a href=&#34;https://arxiv.org/abs/2003.13924&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;V2VNet- Vehicle-to-Vehicle Communication for Joint Perception and Prediction, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2008.07519&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SMART- Simultaneous Multi-Agent Recurrent Trajectory Prediction, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2007.13078&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SimAug- Learning Robust Representations from Simulation for Trajectory Prediction, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2004.02022&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning Lane Graph Representations for Motion Forecasting, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2007.13732&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Implicit Latent Variable Model for Scene-Consistent Motion Forecasting, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2007.12036&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Diverse and Admissible Trajectory Forecasting through Multimodal Context Understanding, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2003.03212&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Semantic Synthesis of Pedestrian Locomotion, ACCV 2020. [&lt;a href=&#34;https://openaccess.thecvf.com/content/ACCV2020/html/Priisalu_Semantic_Synthesis_of_Pedestrian_Locomotion_ACCV_2020_paper.html&#34;&gt;Paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Kernel Trajectory Maps for Multi-Modal Probabilistic Motion Prediction, CoRL 2019. [&lt;a href=&#34;https://arxiv.org/abs/1907.05127&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wzhi/KernelTrajectoryMaps&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social-WaGDAT: Interaction-aware Trajectory Prediction via Wasserstein Graph Double-Attention Network, 2020. [&lt;a href=&#34;https://arxiv.org/abs/2002.06241&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social NCE: Contrastive Learning of Socially-aware Motion Representations. [&lt;a href=&#34;https://arxiv.org/abs/2012.11717&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/vita-epfl/social-nce&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pose Based Trajectory Forecast of Vulnerable Road Users Using Recurrent Neural Networks, ICPR International Workshops and Challenges 2020. [&lt;a href=&#34;https://www.springerprofessional.de/pose-based-trajectory-forecast-of-vulnerable-road-users-using-re/18885576&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning, NeurIPS 2020. [&lt;a href=&#34;https://arxiv.org/abs/2003.13924&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Spatio-Temporal Graph Transformer Networks for Pedestrian Trajectory Prediction, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2005.08514&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;It is not the Journey but the Destination- Endpoint Conditioned Trajectory Prediction, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2004.02025&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;How Can I See My Future? FvTraj: Using First-person View for Pedestrian Trajectory Prediction, ECCV 2020. [&lt;a href=&#34;http://graphics.cs.uh.edu/wp-content/papers/2020/2020-ECCV-PedestrianTrajPrediction.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Dynamic and Static Context-aware LSTM for Multi-agent Motion Prediction, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2008.00777&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human Trajectory Forecasting in Crowds: A Deep Learning Perspective, 2020. [&lt;a href=&#34;https://arxiv.org/pdf/2007.03639.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/vita-epfl/trajnetplusplusbaselines&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SimAug: Learning Robust Representations from 3D Simulation for Pedestrian Trajectory Prediction in Unseen cameras, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/pdf/2004.02022&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/JunweiLiang/Multiverse&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;DAG-Net: Double Attentive Graph Neural Network for Trajectory Forecasting, ICPR 2020. [&lt;a href=&#34;https://arxiv.org/abs/2005.12661&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/alexmonti19/dagnet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Disentangling Human Dynamics for Pedestrian Locomotion Forecasting with Noisy Supervision, WACV 2020. [&lt;a href=&#34;https://arxiv.org/abs/1911.01138&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social-WaGDAT: Interaction-aware Trajectory Prediction via Wasserstein Graph Double-Attention Network, 2020. [&lt;a href=&#34;https://arxiv.org/abs/2002.06241&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction, CVPR 2020. [&lt;a href=&#34;https://arxiv.org/pdf/2002.11927.pdf&#34;&gt;Paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/abduallahmohamed/Social-STGCNN/&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;The Garden of Forking Paths: Towards Multi-Future Trajectory Prediction, CVPR 2020. [&lt;a href=&#34;https://arxiv.org/pdf/1912.06445.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://next.cs.cmu.edu/multiverse/index.html&#34;&gt;code/dataset&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Disentangling Human Dynamics for Pedestrian Locomotion Forecasting with Noisy Supervision, WACV 2020. [&lt;a href=&#34;https://arxiv.org/abs/1911.01138&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pose Based Trajectory Forecast of Vulnerable Road Users, SSCI 2019. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/9003023&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;The Trajectron: Probabilistic Multi-Agent Trajectory Modeling With Dynamic Spatiotemporal Graphs, ICCV 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_ICCV_2019/papers/Ivanovic_The_Trajectron_Probabilistic_Multi-Agent_Trajectory_Modeling_With_Dynamic_Spatiotemporal_Graphs_ICCV_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/StanfordASL/Trajectron&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;STGAT: Modeling Spatial-Temporal Interactions for Human Trajectory Prediction, ICCV 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_STGAT_Modeling_Spatial-Temporal_Interactions_for_Human_Trajectory_Prediction_ICCV_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/huang-xx/STGAT&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Instance-Level Future Motion Estimation in a Single Image Based on Ordinal Regression, ICCV 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_ICCV_2019/papers/Kim_Instance-Level_Future_Motion_Estimation_in_a_Single_Image_Based_on_ICCV_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social and Scene-Aware Trajectory Prediction in Crowded Spaces, ICCV workshop 2019. [&lt;a href=&#34;https://arxiv.org/pdf/1909.08840.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Oghma/sns-lstm/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Stochastic Sampling Simulation for Pedestrian Trajectory Prediction, IROS 2019. [&lt;a href=&#34;https://arxiv.org/abs/1903.01860&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Long-Term Prediction of Motion Trajectories Using Path Homology Clusters, IROS 2019. [&lt;a href=&#34;http://www.csc.kth.se/~fpokorny/static/publications/carvalho2019a.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;StarNet: Pedestrian Trajectory Prediction Using Deep Neural Network in Star Topology, IROS 2019. [&lt;a href=&#34;https://arxiv.org/pdf/1906.01797.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning Generative Socially-Aware Models of Pedestrian Motion, IROS 2019. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/8760356/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Situation-Aware Pedestrian Trajectory Prediction with Spatio-Temporal Attention Model, CVWW 2019. [&lt;a href=&#34;https://arxiv.org/pdf/1902.05437.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Path predictions using object attributes and semantic environment, VISIGRAPP 2019. [&lt;a href=&#34;http://mprg.jp/data/MPRG/C_group/C20190225_minoura.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Probabilistic Path Planning using Obstacle Trajectory Prediction, CoDS-COMAD 2019. [&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=3297006&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human Trajectory Prediction using Adversarial Loss, hEART 2019. [&lt;a href=&#34;http://www.strc.ch/2019/Kothari_Alahi.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/vita-epfl/AdversarialLoss-SGAN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social Ways: Learning Multi-Modal Distributions of Pedestrian Trajectories with GANs, CVPR 2019. [&lt;a href=&#34;https://sites.google.com/view/ieeecvf-cvpr2019-precognition&#34;&gt;&lt;em&gt;Precognition Workshop&lt;/em&gt;&lt;/a&gt;], [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPRW_2019/papers/Precognition/Amirian_Social_Ways_Learning_Multi-Modal_Distributions_of_Pedestrian_Trajectories_With_GANs_CVPRW_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/amiryanj/socialways&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Peeking into the Future: Predicting Future Person Activities and Locations in Videos, CVPR 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPR_2019/papers/Liang_Peeking_Into_the_Future_Predicting_Future_Person_Activities_and_Locations_CVPR_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/google/next-prediction&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning to Infer Relations for Future Trajectory Forecast, CVPR 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPRW_2019/papers/Precognition/Choi_Learning_to_Infer_Relations_for_Future_Trajectory_Forecast_CVPRW_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;TraPHic: Trajectory Prediction in Dense and Heterogeneous Traffic Using Weighted Interactions, CVPR 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPR_2019/papers/Chandra_TraPHic_Trajectory_Prediction_in_Dense_and_Heterogeneous_Traffic_Using_Weighted_CVPR_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Which Way Are You Going? Imitative Decision Learning for Path Forecasting in Dynamic Scenes, CVPR 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Which_Way_Are_You_Going_Imitative_Decision_Learning_for_Path_CVPR_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Overcoming Limitations of Mixture Density Networks: A Sampling and Fitting Framework for Multimodal Future Prediction, CVPR 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPR_2019/papers/Makansi_Overcoming_Limitations_of_Mixture_Density_Networks_A_Sampling_and_Fitting_CVPR_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/lmb-freiburg/Multimodal-Future-Prediction&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Sophie: An attentive gan for predicting paths compliant to social and physical constraints, CVPR 2019. [&lt;a href=&#34;https://arxiv.org/abs/1806.01482&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/hindupuravinash/the-gan-zoo/raw/master/README.md&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian path, pose, and intention prediction through gaussian process dynamical models and pedestrian activity recognition, 2019. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8370119/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multimodal Interaction-aware Motion Prediction for Autonomous Street Crossing, 2019. [&lt;a href=&#34;https://arxiv.org/abs/1808.06887&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;The simpler the better: Constant velocity for pedestrian motion prediction, 2019. [&lt;a href=&#34;https://arxiv.org/abs/1903.07933&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian trajectory prediction in extremely crowded scenarios, 2019. [&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/30862018&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Srlstm: State refinement for lstm towards pedestrian trajectory prediction, 2019. [&lt;a href=&#34;https://arxiv.org/abs/1903.02793&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Location-velocity attention for pedestrian trajectory prediction, WACV 2019. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8659060&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian Trajectory Prediction in Extremely Crowded Scenarios, Sensors, 2019. [&lt;a href=&#34;https://www.mdpi.com/1424-8220/19/5/1223/pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Forecasting Trajectory and Behavior of Road-Agents Using Spectral Clustering in Graph-LSTMs, 2019. [&lt;a href=&#34;https://arxiv.org/pdf/1912.01118.pdf&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://gamma.umd.edu/researchdirections/autonomousdriving/spectralcows/&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Joint Prediction for Kinematic Trajectories in Vehicle-Pedestrian-Mixed Scenes, ICCV 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_ICCV_2019/papers/Bi_Joint_Prediction_for_Kinematic_Trajectories_in_Vehicle-Pedestrian-Mixed_Scenes_ICCV_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Analyzing the Variety Loss in the Context of Probabilistic Trajectory Prediction, ICCV 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_ICCV_2019/papers/Thiede_Analyzing_the_Variety_Loss_in_the_Context_of_Probabilistic_Trajectory_ICCV_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Looking to Relations for Future Trajectory Forecast, ICCV 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_ICCV_2019/papers/Choi_Looking_to_Relations_for_Future_Trajectory_Forecast_ICCV_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Jointly Learnable Behavior and Trajectory Planning for Self-Driving Vehicles, IROS 2019. [&lt;a href=&#34;https://arxiv.org/abs/1910.04586&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Sharing Is Caring: Socially-Compliant Autonomous Intersection Negotiation, IROS 2019. [&lt;a href=&#34;https://pdfs.semanticscholar.org/f4b2/021353bba52224eb33923b3b98956e2c9821.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;INFER: INtermediate Representations for FuturE PRediction, IROS 2019. [&lt;a href=&#34;https://arxiv.org/abs/1903.10641&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/talsperre/INFER&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Deep Predictive Autonomous Driving Using Multi-Agent Joint Trajectory Prediction and Traffic Rules, IROS 2019. [&lt;a href=&#34;http://rllab.snu.ac.kr/publications/papers/2019_iros_predstl.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;NeuroTrajectory: A Neuroevolutionary Approach to Local State Trajectory Learning for Autonomous Vehicles, IROS 2019. [&lt;a href=&#34;https://arxiv.org/abs/1906.10971&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Urban Street Trajectory Prediction with Multi-Class LSTM Networks, IROS 2019. [N/A]&lt;/li&gt; &#xA; &lt;li&gt;Spatiotemporal Learning of Directional Uncertainty in Urban Environments with Kernel Recurrent Mixture Density Networks, IROS 2019. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8772158&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Conditional generative neural system for probabilistic trajectory prediction, IROS 2019. [&lt;a href=&#34;https://arxiv.org/abs/1905.01631&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Interaction-aware multi-agent tracking and probabilistic behavior prediction via adversarial learning, ICRA 2019. [&lt;a href=&#34;https://arxiv.org/abs/1904.02390&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generic Tracking and Probabilistic Prediction Framework and Its Application in Autonomous Driving, IEEE Trans. Intell. Transport. Systems, 2019. [&lt;a href=&#34;https://www.researchgate.net/publication/334560415_Generic_Tracking_and_Probabilistic_Prediction_Framework_and_Its_Application_in_Autonomous_Driving&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Coordination and trajectory prediction for vehicle interactions via bayesian generative modeling, IV 2019. [&lt;a href=&#34;https://arxiv.org/abs/1905.00587&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Wasserstein generative learning with kinematic constraints for probabilistic interactive driving behavior prediction, IV 2019. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8813783&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GRIP: Graph-based Interaction-aware Trajectory Prediction, ITSC 2019. [&lt;a href=&#34;https://arxiv.org/abs/1907.07792&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;AGen: Adaptable Generative Prediction Networks for Autonomous Driving, IV 2019. [&lt;a href=&#34;http://www.cs.cmu.edu/~cliu6/files/iv19-1.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;TraPHic: Trajectory Prediction in Dense and Heterogeneous Traffic Using Weighted Interactions, CVPR 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPR_2019/papers/Chandra_TraPHic_Trajectory_Prediction_in_Dense_and_Heterogeneous_Traffic_Using_Weighted_CVPR_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/rohanchandra30/TrackNPred&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-Step Prediction of Occupancy Grid Maps with Recurrent Neural Networks, CVPR 2019. [&lt;a href=&#34;https://arxiv.org/pdf/1812.09395.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Argoverse: 3D Tracking and Forecasting With Rich Maps, CVPR 2019 [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPR_2019/papers/Chang_Argoverse_3D_Tracking_and_Forecasting_With_Rich_Maps_CVPR_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Robust Aleatoric Modeling for Future Vehicle Localization, CVPR 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPRW_2019/papers/Precognition/Hudnell_Robust_Aleatoric_Modeling_for_Future_Vehicle_Localization_CVPRW_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian occupancy prediction for autonomous vehicles, IRC 2019. [paper]&lt;/li&gt; &#xA; &lt;li&gt;Context-based path prediction for targets with switching dynamics, 2019.[&lt;a href=&#34;https://link.springer.com/article/10.1007/s11263-018-1104-4&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Deep Imitative Models for Flexible Inference, Planning, and Control, 2019. [&lt;a href=&#34;https://arxiv.org/abs/1810.06544&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Infer: Intermediate representations for future prediction, 2019. [&lt;a href=&#34;https://arxiv.org/abs/1903.10641&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/talsperre/INFER&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-agent tensor fusion for contextual trajectory prediction, 2019. [&lt;a href=&#34;https://arxiv.org/abs/1904.04776&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Context-Aware Pedestrian Motion Prediction In Urban Intersections, 2018. [&lt;a href=&#34;https://arxiv.org/abs/1806.09453&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generic probabilistic interactive situation recognition and prediction: From virtual to real, ITSC 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/8569780&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generic vehicle tracking framework capable of handling occlusions based on modified mixture particle filter, IV 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/8500626&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-Modal Trajectory Prediction of Surrounding Vehicles with Maneuver based LSTMs, 2018. [&lt;a href=&#34;https://arxiv.org/abs/1805.05499&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Sequence-to-sequence prediction of vehicle trajectory via lstm encoder-decoder architecture, 2018. [&lt;a href=&#34;https://arxiv.org/abs/1802.06338&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;R2P2: A ReparameteRized Pushforward Policy for diverse, precise generative path forecasting, ECCV 2018. [&lt;a href=&#34;https://www.cs.cmu.edu/~nrhineha/R2P2.html&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Predicting trajectories of vehicles using large-scale motion priors, IV 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8500604&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Vehicle trajectory prediction by integrating physics-and maneuver based approaches using interactive multiple models, 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8186191&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Motion Prediction of Traffic Actors for Autonomous Driving using Deep Convolutional Networks, 2018. [&lt;a href=&#34;https://arxiv.org/abs/1808.05819v1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generative multi-agent behavioral cloning, 2018. [&lt;a href=&#34;https://www.semanticscholar.org/paper/Generative-Multi-Agent-Behavioral-Cloning-Zhan-Zheng/ccc196ada6ec9cad1e418d7321b0cd6813d9b261&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Deep Sequence Learning with Auxiliary Information for Traffic Prediction, KDD 2018. [&lt;a href=&#34;https://arxiv.org/pdf/1806.07380.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/JingqingZ/BaiduTraffic&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A data-driven model for interaction-aware pedestrian motion prediction in object cluttered environments, ICRA 2018. [&lt;a href=&#34;https://arxiv.org/abs/1709.08528&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Move, Attend and Predict: An attention-based neural model for people’s movement prediction, Pattern Recognition Letters 2018. [&lt;a href=&#34;https://reader.elsevier.com/reader/sd/pii/S016786551830182X?token=1EF2B664B70D2B0C3ECDD07B6D8B664F5113AEA7533CE5F0B564EF9F4EE90D3CC228CDEB348F79FEB4E8CDCD74D4BA31&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GD-GAN: Generative Adversarial Networks for Trajectory Prediction and Group Detection in Crowds, ACCV 2018, [&lt;a href=&#34;https://arxiv.org/pdf/1812.07667.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://www.youtube.com/watch?v=7cCIC_JIfms&#34;&gt;demo&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Ss-lstm: a hierarchical lstm model for pedestrian trajectory prediction, WACV 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8354239&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social Attention: Modeling Attention in Human Crowds, ICRA 2018. [&lt;a href=&#34;https://arxiv.org/abs/1710.04689&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/TNTant/social_lstm&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian prediction by planning using deep neural networks, ICRA 2018. [&lt;a href=&#34;https://arxiv.org/abs/1706.05904&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Joint long-term prediction of human motion using a planning-based social force approach, ICRA 2018. [&lt;a href=&#34;https://iliad-project.eu/publications/2018-2/joint-long-term-prediction-of-human-motion-using-a-planning-based-social-force-approach/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human motion prediction under social grouping constraints, IROS 2018. [&lt;a href=&#34;http://iliad-project.eu/publications/2018-2/human-motion-prediction-under-social-grouping-constraints/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Future Person Localization in First-Person Videos, CVPR 2018. [&lt;a href=&#34;http://openaccess.thecvf.com/content_cvpr_2018/papers/Yagi_Future_Person_Localization_CVPR_2018_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks, CVPR 2018. [&lt;a href=&#34;https://arxiv.org/abs/1803.10892&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/agrimgupta92/sgan&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Group LSTM: Group Trajectory Prediction in Crowded Scenarios, ECCV 2018. [&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-030-11015-4_18&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Mx-lstm: mixing tracklets and vislets to jointly forecast trajectories and head poses, CVPR 2018. [&lt;a href=&#34;https://arxiv.org/abs/1805.00652&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Intent prediction of pedestrians via motion trajectories using stacked recurrent neural networks, 2018. [&lt;a href=&#34;http://ieeexplore.ieee.org/document/8481390/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Transferable pedestrian motion prediction models at intersections, 2018. [&lt;a href=&#34;https://arxiv.org/abs/1804.00495&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Probabilistic map-based pedestrian motion prediction taking traffic participants into consideration, 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8500562&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Computationally Efficient Model for Pedestrian Motion Prediction, ECC 2018. [&lt;a href=&#34;https://arxiv.org/abs/1803.04702&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Context-aware trajectory prediction, ICPR 2018. [&lt;a href=&#34;https://arxiv.org/abs/1705.02503&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Set-based prediction of pedestrians in urban environments considering formalized traffic rules, ITSC 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8569434&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Building prior knowledge: A markov based pedestrian prediction model using urban environmental data, ICARCV 2018. [&lt;a href=&#34;https://arxiv.org/abs/1809.06045&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Depth Information Guided Crowd Counting for Complex Crowd Scenes, 2018. [&lt;a href=&#34;https://arxiv.org/abs/1803.02256&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Tracking by Prediction: A Deep Generative Model for Mutli-Person Localisation and Tracking, WACV 2018. [&lt;a href=&#34;https://arxiv.org/abs/1803.03347&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;“Seeing is Believing”: Pedestrian Trajectory Forecasting Using Visual Frustum of Attention, WACV 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8354238&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Long-Term On-Board Prediction of People in Traffic Scenes under Uncertainty, CVPR 2018. [&lt;a href=&#34;http://openaccess.thecvf.com/content_cvpr_2018/papers/Bhattacharyya_Long-Term_On-Board_Prediction_CVPR_2018_paper.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/apratimbhattacharyya18/onboard_long_term_prediction&#34;&gt;code+data&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Encoding Crowd Interaction with Deep Neural Network for Pedestrian Trajectory Prediction, CVPR 2018. [&lt;a href=&#34;http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Encoding_Crowd_Interaction_CVPR_2018_paper.pdf&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/ShanghaiTechCVDL/CIDNN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction, 2017. [&lt;a href=&#34;https://link.springer.com/article/10.1007/s10514-017-9619-z&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Probabilistic long-term prediction for autonomous vehicles, IV 2017. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/7995726&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Probabilistic vehicle trajectory prediction over occupancy grid map via recurrent neural network, ITSC 2017. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/6632960&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Desire: Distant future prediction in dynamic scenes with interacting agents, CVPR 2017. [&lt;a href=&#34;https://arxiv.org/abs/1704.04394&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/yadrimz/DESIRE&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Imitating driver behavior with generative adversarial networks, 2017. [&lt;a href=&#34;https://arxiv.org/abs/1701.06699&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/sisl/gail-driver&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Infogail: Interpretable imitation learning from visual demonstrations, 2017. [&lt;a href=&#34;https://arxiv.org/abs/1703.08840&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/YunzhuLi/InfoGAIL&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Long-term planning by short-term prediction, 2017. [&lt;a href=&#34;https://arxiv.org/abs/1602.01580&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Long-term path prediction in urban scenarios using circular distributions, 2017. [&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0262885617301853&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Deep learning driven visual path prediction from a single image, 2016. [&lt;a href=&#34;https://arxiv.org/abs/1601.07265&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Walking Ahead: The Headed Social Force Model, 2017. [&lt;a href=&#34;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169734&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Real-time certified probabilistic pedestrian forecasting, 2017. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7959047&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A multiple-predictor approach to human motion prediction, ICRA 2017. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7989265&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Forecasting interactive dynamics of pedestrians with fictitious play, CVPR 2017. [&lt;a href=&#34;https://arxiv.org/abs/1604.01431&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Forecast the plausible paths in crowd scenes, IJCAI 2017. [&lt;a href=&#34;https://www.ijcai.org/proceedings/2017/386&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Bi-prediction: pedestrian trajectory prediction based on bidirectional lstm classification, DICTA 2017. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8227412/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Aggressive, Tense or Shy? Identifying Personality Traits from Crowd Videos, IJCAI 2017. [&lt;a href=&#34;https://www.ijcai.org/proceedings/2017/17&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Natural vision based method for predicting pedestrian behaviour in urban environments, ITSC 2017. [&lt;a href=&#34;http://ieeexplore.ieee.org/document/8317848/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Human Trajectory Prediction using Spatially aware Deep Attention Models, 2017. [&lt;a href=&#34;https://arxiv.org/pdf/1705.09436.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Soft + Hardwired Attention: An LSTM Framework for Human Trajectory Prediction and Abnormal Event Detection, 2017. [&lt;a href=&#34;https://arxiv.org/pdf/1702.05552.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Forecasting Interactive Dynamics of Pedestrians with Fictitious Play, CVPR 2017. [&lt;a href=&#34;http://openaccess.thecvf.com/content_cvpr_2017/papers/Ma_Forecasting_Interactive_Dynamics_CVPR_2017_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social LSTM: Human trajectory prediction in crowded spaces, CVPR 2016. [&lt;a href=&#34;http://openaccess.thecvf.com/content_cvpr_2016/html/Alahi_Social_LSTM_Human_CVPR_2016_paper.html&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/vita-epfl/trajnetplusplusbaselines&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Comparison and evaluation of pedestrian motion models for vehicle safety systems, ITSC 2016. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7795912&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Age and Group-driven Pedestrian Behaviour: from Observations to Simulations, 2016. [&lt;a href=&#34;https://collective-dynamics.eu/index.php/cod/article/view/A3&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Structural-RNN: Deep learning on spatio-temporal graphs, CVPR 2016. [&lt;a href=&#34;https://arxiv.org/abs/1511.05298&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/asheshjain399/RNNexp&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Intent-aware long-term prediction of pedestrian motion, ICRA 2016. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7487409&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Context-based detection of pedestrian crossing intention for autonomous driving in urban environments, IROS 2016. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/7759351/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Novel planning-based algorithms for human motion prediction, ICRA 2016. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7487505&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning social etiquette: Human trajectory understanding in crowded scenes, ECCV 2016. [&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-319-46484-8_33&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/SajjadMzf/Pedestrian_Datasets_VIS&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;GLMP-realtime pedestrian path prediction using global and local movement patterns, ICRA 2016. [&lt;a href=&#34;http://ieeexplore.ieee.org/document/7487768/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Knowledge transfer for scene-specific motion prediction, ECCV 2016. [&lt;a href=&#34;https://arxiv.org/abs/1603.06987&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;STF-RNN: Space Time Features-based Recurrent Neural Network for predicting People Next Location, SSCI 2016. [&lt;a href=&#34;https://github.com/mhjabreel/STF-RNN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Goal-directed pedestrian prediction, ICCV 2015. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7406377&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory analysis and prediction for improved pedestrian safety: Integrated framework and evaluations, 2015. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7225707&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Predicting and recognizing human interactions in public spaces, 2015. [&lt;a href=&#34;https://link.springer.com/article/10.1007/s11554-014-0428-8&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning collective crowd behaviors with dynamic pedestrian-agents, 2015. [&lt;a href=&#34;https://link.springer.com/article/10.1007/s11263-014-0735-3&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Modeling spatial-temporal dynamics of human movements for predicting future trajectories, AAAI 2015. [&lt;a href=&#34;https://aaai.org/ocs/index.php/WS/AAAIW15/paper/view/10126&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Unsupervised robot learning to predict person motion, ICRA 2015. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7139254&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A controlled interactive multiple model filter for combined pedestrian intention recognition and path prediction, ITSC 2015. [&lt;a href=&#34;http://ieeexplore.ieee.org/abstract/document/7313129/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Real-Time Predictive Modeling and Robust Avoidance of Pedestrians with Uncertain, Changing Intentions, 2014. [&lt;a href=&#34;https://arxiv.org/abs/1405.5581&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Behavior estimation for a complete framework for human motion prediction in crowded environments, ICRA 2014. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/6907734&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian’s trajectory forecast in public traffic with artificial neural network, ICPR 2014. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/6977417&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Will the pedestrian cross? A study on pedestrian path prediction, 2014. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/6632960&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;BRVO: Predicting pedestrian trajectories using velocity-space reasoning, 2014. [&lt;a href=&#34;https://journals.sagepub.com/doi/abs/10.1177/0278364914555543&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Context-based pedestrian path prediction, ECCV 2014. [&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-319-10599-4_40&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pedestrian path prediction using body language traits, 2014. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/6856498/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Online maneuver recognition and multimodal trajectory prediction for intersection assistance using non-parametric regression, 2014. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/6856480&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning intentions for improved human motion prediction, 2013. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/6766565&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Understanding interactions between traffic participants based on learned behaviors, 2016. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7535554&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Visual path prediction in complex scenes with crowded moving objects, CVPR 2016. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/7780661/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A game-theoretic approach to replanning-aware interactive scene prediction and planning, 2016. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7353203&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Intention-aware online pomdp planning for autonomous driving in a crowd, ICRA 2015. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7139219&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Online maneuver recognition and multimodal trajectory prediction for intersection assistance using non-parametric regression, 2014. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/6856480&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Patch to the future: Unsupervised visual prediction, CVPR 2014. [&lt;a href=&#34;http://ieeexplore.ieee.org/abstract/document/6909818/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Mobile agent trajectory prediction using bayesian nonparametric reachability trees, 2011. [&lt;a href=&#34;https://dspace.mit.edu/handle/1721.1/114899&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Mobile Robots&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Anticipatory Navigation in Crowds by Probabilistic Prediction of Pedestrian Future Movements, ICRA 2021. [&lt;a href=&#34;https://arxiv.org/abs/2011.06235&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Social NCE: Contrastive Learning of Socially-aware Motion Representations. [&lt;a href=&#34;https://arxiv.org/abs/2012.11717&#34;&gt;paper&lt;/a&gt;], [&lt;a href=&#34;https://github.com/vita-epfl/social-nce&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multimodal probabilistic model-based planning for human-robot interaction, ICRA 2018. [&lt;a href=&#34;https://arxiv.org/abs/1710.09483&#34;&gt;paper&lt;/a&gt;][&lt;a href=&#34;https://github.com/StanfordASL/TrafficWeavingCVAE&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Decentralized Non-communicating Multiagent Collision Avoidance with Deep Reinforcement Learning, ICRA 2017. [&lt;a href=&#34;https://arxiv.org/abs/1609.07845&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Augmented dictionary learning for motion prediction, ICRA 2016. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7487407&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Predicting future agent motions for dynamic environments, ICMLA 2016. [&lt;a href=&#34;https://www.semanticscholar.org/paper/Predicting-Future-Agent-Motions-for-Dynamic-Previtali-Bordallo/2df8179ac7b819bad556b6d185fc2030c40f98fa&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Bayesian intention inference for trajectory prediction with an unknown goal destination, IROS 2015. [&lt;a href=&#34;http://ieeexplore.ieee.org/abstract/document/7354203/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning to predict trajectories of cooperatively navigating agents, ICRA 2014. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/6907442&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Sport Players&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning, NeurIPS 2020. [&lt;a href=&#34;https://arxiv.org/abs/2003.13924&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Imitative Non-Autoregressive Modeling for Trajectory Forecasting and Imputation, CVPR 2020. [&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/html/Qi_Imitative_Non-Autoregressive_Modeling_for_Trajectory_Forecasting_and_Imputation_CVPR_2020_paper.html&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;DAG-Net: Double Attentive Graph Neural Network for Trajectory Forecasting, ICPR 2020. [&lt;a href=&#34;https://arxiv.org/abs/2005.12661&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/alexmonti19/dagnet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Diverse Generation for Multi-Agent Sports Games, CVPR 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPR_2019/html/Yeh_Diverse_Generation_for_Multi-Agent_Sports_Games_CVPR_2019_paper.html&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Stochastic Prediction of Multi-Agent Interactions from Partial Observations, ICLR 2019. [&lt;a href=&#34;http://arxiv.org/abs/1902.09641v1&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generating Multi-Agent Trajectories using Programmatic Weak Supervision, ICLR 2019. [&lt;a href=&#34;http://arxiv.org/abs/1803.07612v6&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generative Multi-Agent Behavioral Cloning, ICML 2018. [&lt;a href=&#34;http://www.stephanzheng.com/pdf/Zhan_Zheng_Lucey_Yue_Generative_Multi_Agent_Behavioral_Cloning.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Where Will They Go? Predicting Fine-Grained Adversarial Multi-Agent Motion using Conditional Variational Autoencoders, ECCV 2018. [&lt;a href=&#34;http://openaccess.thecvf.com/content_ECCV_2018/papers/Panna_Felsen_Where_Will_They_ECCV_2018_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Coordinated Multi-Agent Imitation Learning, ICML 2017. [&lt;a href=&#34;http://arxiv.org/abs/1703.03121v2&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generating long-term trajectories using deep hierarchical networks, 2017. [&lt;a href=&#34;https://arxiv.org/abs/1706.07138&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning Fine-Grained Spatial Models for Dynamic Sports Play Prediction, ICDM 2014. [&lt;a href=&#34;http://www.yisongyue.com/publications/icdm2014_bball_predict.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Generative Modeling of Multimodal Multi-Human Behavior, 2018. [&lt;a href=&#34;https://arxiv.org/pdf/1803.02015.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;What will Happen Next? Forecasting Player Moves in Sports Videos, ICCV 2017, [&lt;a href=&#34;http://openaccess.thecvf.com/content_ICCV_2017/papers/Felsen_What_Will_Happen_ICCV_2017_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Benchmark and Evaluation Metrics&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation, ECCV 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.03057&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/abduallahmohamed/Social-Implicit&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;OpenTraj: Assessing Prediction Complexity in Human Trajectories Datasets, ACCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2010.00890&#34;&gt;paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/crowdbotp/OpenTraj&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Testing the Safety of Self-driving Vehicles by Simulating Perception and Prediction, ECCV 2020. [&lt;a href=&#34;https://arxiv.org/abs/2008.06020&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;PIE: A Large-Scale Dataset and Models for Pedestrian Intention Estimation and Trajectory Prediction, ICCV 2019. [&lt;a href=&#34;http://openaccess.thecvf.com/content_ICCV_2019/papers/Rasouli_PIE_A_Large-Scale_Dataset_and_Models_for_Pedestrian_Intention_Estimation_ICCV_2019_paper.pdf&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Towards a fatality-aware benchmark of probabilistic reaction prediction in highly interactive driving scenarios, ITSC 2018. [&lt;a href=&#34;https://arxiv.org/abs/1809.03478&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;How good is my prediction? Finding a similarity measure for trajectory prediction evaluation, ITSC 2017. [&lt;a href=&#34;http://ieeexplore.ieee.org/document/8317825/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajnet: Towards a benchmark for human trajectory prediction. [&lt;a href=&#34;http://trajnet.epfl.ch/&#34;&gt;website&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Others&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pose Based Start Intention Detection of Cyclists, ITSC 2019. [&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/8917215&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Cyclist trajectory prediction using bidirectional recurrent neural networks, AI 2018. [&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-030-03991-2_28&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Road infrastructure indicators for trajectory prediction, 2018. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/8500678&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Using road topology to improve cyclist path prediction, 2017. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7995734/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Trajectory prediction of cyclists using a physical model and an artificial neural network, 2016. [&lt;a href=&#34;https://ieeexplore.ieee.org/document/7535484/&#34;&gt;paper&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>