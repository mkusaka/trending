<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-05T02:27:57Z</updated>
  <subtitle>Weekly Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>yenchenlin/awesome-NeRF</title>
    <updated>2022-06-05T02:27:57Z</updated>
    <id>tag:github.com,2022-06-05:/yenchenlin/awesome-NeRF</id>
    <link href="https://github.com/yenchenlin/awesome-NeRF" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A curated list of awesome neural radiance fields papers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome Neural Radiance Fields &lt;a href=&#34;https://github.com/sindresorhus/awesome&#34;&gt;&lt;img src=&#34;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true&#34; alt=&#34;Awesome&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;A curated list of awesome neural radiance fields papers, inspired by &lt;a href=&#34;https://github.com/jbhuang0604/awesome-computer-vision&#34;&gt;awesome-computer-vision&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/how-to-PR.md&#34;&gt;How to submit a pull request?&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/#survey&#34;&gt;Survey&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/#papers&#34;&gt;Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/#talks&#34;&gt;Talks&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Survey&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2101.05204&#34;&gt;Neural Volume Rendering: NeRF And Beyond&lt;/a&gt;, Dellaert and Yen-Chen, Arxiv 2020 | &lt;a href=&#34;https://dellaert.github.io/NeRF/&#34;&gt;blog&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/nerf-survey.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Papers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.matthewtancik.com/nerf&#34;&gt;NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis&lt;/a&gt;, Mildenhall et al., ECCV 2020 | &lt;a href=&#34;https://github.com/bmild/nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L168-L173&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Mildenhall20eccv_nerf--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Faster Inference&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lingjie0206.github.io/papers/NSVF/&#34;&gt;Neural Sparse Voxel Fields&lt;/a&gt;, Liu et al., NeurIPS 2020 | &lt;a href=&#34;https://github.com/facebookresearch/NSVF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L135-L141&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Liu20neurips_sparse_nerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.computationalimaging.org/publications/automatic-integration/&#34;&gt;AutoInt: Automatic Integration for Fast Neural Volume Rendering&lt;/a&gt;, Lindell et al., CVPR 2021 | &lt;a href=&#34;https://github.com/computational-imaging/automatic-integration&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L127-L133&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Lindell20arxiv_AutoInt--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.12490&#34;&gt;DeRF: Decomposed Radiance Fields&lt;/a&gt;, Rebain et al. Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L222-L228&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Rebain20arxiv_derf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://depthoraclenerf.github.io/&#34;&gt;DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks&lt;/a&gt;, Neff et al., CGF 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/donerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--neff2021donerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.10380&#34;&gt;FastNeRF: High-Fidelity Neural Rendering at 200FPS&lt;/a&gt;, Garbin et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/fastnerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Garbin21arxiv_FastNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.13744&#34;&gt;KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs &lt;/a&gt;, Reiser et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/creiser/kilonerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/kilonerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--reiser2021kilonerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://alexyu.net/plenoctrees/&#34;&gt;PlenOctrees for Real-time Rendering of Neural Radiance Fields&lt;/a&gt;, Yu et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/sxyu/volrend&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/plenoctrees.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--yu2021plenoctrees--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.01954&#34;&gt;Mixture of Volumetric Primitives for Efficient Neural Rendering&lt;/a&gt;, Lombardi et al., SIGGRAPH 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/mixture.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vsitzmann.github.io/lfns/&#34;&gt;Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering&lt;/a&gt;, Sitzmann et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/lfn.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Faster Training&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2107.02791.pdf&#34;&gt;Depth-supervised NeRF: Fewer Views and Faster Training for Free&lt;/a&gt;, Deng et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/dunbar12138/DSNeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/dsnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2111.11215.pdf&#34;&gt;Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction&lt;/a&gt;, Sun et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/sunset1995/DirectVoxGO&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/DirectVoxGO.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--sun2021direct--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Unconstrained Images&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nerf-w.github.io/&#34;&gt;NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections&lt;/a&gt;, Martin-Brualla et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L152-L158&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--MartinBrualla20arxiv_nerfw--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rover-xingyu.github.io/Ha-NeRF/&#34;&gt;Ha-NeRF&lt;span&gt;ğŸ˜†&lt;/span&gt;: Hallucinated Neural Radiance Fields in the Wild&lt;/a&gt;, Chen et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/rover-xingyu/Ha-NeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/Ha-NeRF.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--chen2021hallucinated--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Deformable&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nerfies.github.io/&#34;&gt;Deformable Neural Radiance Fields&lt;/a&gt;, Park et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/google/nerfies&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L206-L212&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Park20arxiv_nerfies--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.albertpumarola.com/research/D-NeRF/index.html&#34;&gt;D-NeRF: Neural Radiance Fields for Dynamic Scenes&lt;/a&gt;, Pumarola et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L214-L220&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Pumarola20arxiv_D_NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gafniguy.github.io/4D-Facial-Avatars/&#34;&gt;Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction&lt;/a&gt;, Gafni et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L87-L93&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Gafni20arxiv_DNRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/&#34;&gt;Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Deforming Scene from Monocular Video&lt;/a&gt;, Tretschk et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/facebookresearch/nonrigid_nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L283-L289&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Tretschk20arxiv_NR-NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://volumetric-avatars.github.io/&#34;&gt;PVA: Pixel-aligned Volumetric Avatars&lt;/a&gt;, Raj et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/pva.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nogu-atsu/NARF&#34;&gt;Neural Articulated Radiance Field&lt;/a&gt;, Noguchi et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/narf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.00181&#34;&gt;CLA-NeRF: Category-Level Articulated Neural Radiance Field&lt;/a&gt;, Tseng et al., ICRA 2022 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/cla-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zju3dv.github.io/animatable_nerf/&#34;&gt;Animatable Neural Radiance Fields for Human Body Modeling&lt;/a&gt;, Peng et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/animatable_nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Peng21arxiv_animatable_nerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hypernerf.github.io/&#34;&gt;A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields&lt;/a&gt;, Park et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/hypernerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.13629&#34;&gt;Animatable Neural Radiance Fields from Monocular RGB Videos&lt;/a&gt;, Chen et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/JanaldoChen/Anim-NeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/anim_nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vcai.mpi-inf.mpg.de/projects/NeuralActor/&#34;&gt;Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control&lt;/a&gt;, Liu et al., SIGGRAPH Asia 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/neuralactor.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Video&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.cs.cornell.edu/~zl548/NSFF/&#34;&gt;Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes&lt;/a&gt;, Li et al., CVPR 2021 | &lt;a href=&#34;https://github.com/zhengqili/Neural-Scene-Flow-Fields&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L119-L125&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Li20arxiv_nsff--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://video-nerf.github.io/&#34;&gt;Space-time Neural Irradiance Fields for Free-Viewpoint Video&lt;/a&gt;, Xian et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L299-L305&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Xian20arxiv_stnif--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yilundu.github.io/nerflow/&#34;&gt;Neural Radiance Flow for 4D View Synthesis and Video Processing&lt;/a&gt;, Du et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L79-L85&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Du20arxiv_nerflow--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zju3dv.github.io/neuralbody/&#34;&gt;Neural Body: Implicit Neural Representations with Structured Latent Codes for Novel View Synthesis of Dynamic Humans&lt;/a&gt;, Peng et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/neuralbody.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Peng20arxiv_neuralbody--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://neural-3d-video.github.io/&#34;&gt;Neural 3D Video Synthesis&lt;/a&gt;, Li et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/3d-video.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://free-view-video.github.io/&#34;&gt;Dynamic View Synthesis from Dynamic Monocular Video&lt;/a&gt;, Gao et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/dvs_dmv.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Generalization&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.02442&#34;&gt;GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis&lt;/a&gt;, Schwarz et al., NeurIPS 2020 | &lt;a href=&#34;https://github.com/autonomousvision/graf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L237-L243&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Schwarz20neurips_graf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.04595&#34;&gt;GRF: Learning a General Radiance Field for 3D Scene Representation and Rendering&lt;/a&gt;, Trevithick and Yang, Arxiv 2020 | &lt;a href=&#34;https://github.com/alextrevithick/GRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L291-L297&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Trevithick20arxiv_GRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.02190&#34;&gt;pixelNeRF: Neural Radiance Fields from One or Few Images&lt;/a&gt;, Yu et al., CVPR 2021 | &lt;a href=&#34;https://github.com/sxyu/pixel-nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L329-L335&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Yu20arxiv_pixelNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.02189&#34;&gt;Learned Initializations for Optimizing Coordinate-Based Neural Representations&lt;/a&gt;, Tancik et al., CVPR 2021 | &lt;a href=&#34;https://github.com/tancik/learnit&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L268-L274&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Tancik20arxiv_meta--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://marcoamonteiro.github.io/pi-GAN-website/&#34;&gt;pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis&lt;/a&gt;, Chan et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L24-L30&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Chan20arxiv_piGAN--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://portrait-nerf.github.io/&#34;&gt;Portrait Neural Radiance Fields from a Single Image&lt;/a&gt;, Gao et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L95-L101&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Gao20arxiv_pNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2102.08860.pdf&#34;&gt;ShaRF: Shape-conditioned Radiance Fields from a Single View&lt;/a&gt;, Rematas et al., ICML 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/sharf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ibrnet.github.io/static/paper.pdf&#34;&gt;IBRNet: Learning Multi-View Image-Based Rendering&lt;/a&gt;, Wang et al., CVPR 2021 | &lt;a href=&#34;https://github.com/googleinterns/IBRNet&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/ibr.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2103.17269.pdf&#34;&gt;CAMPARI: Camera-Aware Decomposed Generative Neural Radiance Fields&lt;/a&gt;, Niemeyer &amp;amp; Geiger, Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/CAMPARI.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2104.00587.pdf&#34;&gt;NeRF-VAE: A Geometry Aware 3D Scene Generative Model&lt;/a&gt;, Kosiorek et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nerf-vae.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://apple.github.io/ml-gsn/&#34;&gt;Unconstrained Scene Generation with Locally Conditioned Radiance Fields&lt;/a&gt;, DeVries et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/gsn.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://apchenstu.github.io/mvsnerf/&#34;&gt;MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo&lt;/a&gt;, Chen et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/apchenstu/mvsnerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/mvsnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://virtualhumans.mpi-inf.mpg.de/srf/&#34;&gt;Stereo Radiance Fields (SRF): Learning View Synthesis from Sparse Views of Novel Scenes&lt;/a&gt;, Chibane et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/srf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://liuyuan-pal.github.io/NeuRay/&#34;&gt;Neural Rays for Occlusion-aware Image-based Rendering&lt;/a&gt;, Liu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/neuray.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ajayj.com/dietnerf&#34;&gt;Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis&lt;/a&gt;, Matthew Tancik et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/DietNeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vincentfung13.github.io/projects/mine/&#34;&gt;MINE: Towards Continuous Depth MPI with NeRF for Novel View Synthesis&lt;/a&gt;, Jiaxin Li et al., ICCV 2021 | &lt;a href=&#34;https://github.com/vincentfung13/MINE&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/MINE.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://imaging.cs.cmu.edu/torf/&#34;&gt;TÃ¶RF: Time-of-Flight Radiance Fields for Dynamic Scene View Synthesis&lt;/a&gt;, Benjamin Attal et al., NeurIPS 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/turf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sites.google.com/view/wbjang/home/codenerf&#34;&gt;CodeNeRF: Disentangled Neural Radiance Fields for Object Categories&lt;/a&gt;, Jang et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/CodeNeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://jiataogu.me/style_nerf/&#34;&gt;StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis&lt;/a&gt;, Gu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/stylenerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bmild.github.io/rawnerf/&#34;&gt;NeRF in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images&lt;/a&gt;, Ben Mildenhall et al, arXiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/rawnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Pose Estimation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://yenchenlin.me/inerf/&#34;&gt;iNeRF: Inverting Neural Radiance Fields for Pose Estimation&lt;/a&gt;, Yen-Chen et al. IROS 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L321-L327&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--YenChen20arxiv_iNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lemonatsu.github.io/ANeRF-Surface-free-Pose-Refinement/&#34;&gt;A-NeRF: Surface-free Human 3D Pose Refinement via Neural Rendering&lt;/a&gt;, Su et al. Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/a-nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Su21arxiv_A_NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nerfmm.active.vision/&#34;&gt;NeRF--: Neural Radiance Fields Without Known Camera Parameters&lt;/a&gt;, Wang et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/ActiveVisionLab/nerfmm&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nerf--.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Wang21arxiv_nerfmm--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://edgarsucar.github.io/iMAP/&#34;&gt;iMAP: Implicit Mapping and Positioning in Real-Time&lt;/a&gt;, Sucar et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/imap.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pengsongyou.github.io/nice-slam&#34;&gt;NICE-SLAM: Neural Implicit Scalable Encoding for SLAM&lt;/a&gt;, Zhu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nice-slam.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.15606&#34;&gt;GNeRF: GAN-based Neural Radiance Field without Posed Camera&lt;/a&gt;, Meng et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/gnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/&#34;&gt;BARF: Bundle-Adjusting Neural Radiance Fields&lt;/a&gt;, Lin et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/barf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://postech-cvlab.github.io/SCNeRF/&#34;&gt;Self-Calibrating Neural Radiance Fields&lt;/a&gt;, Jeong et al., ICCV 2021 | &lt;a href=&#34;https://github.com/POSTECH-CVLab/SCNeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/SCNeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Lighting&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://markboss.me/publication/2021-nerd/&#34;&gt;NeRD: Neural Reflectance Decomposition from Image Collections&lt;/a&gt;, Boss et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L9-L15&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Boss20arxiv_NeRD--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~pratul/nerv/&#34;&gt;NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis&lt;/a&gt;, Srinivasan et al. CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L260-L266&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Srinivasan20arxiv_NeRV--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nex-mpi.github.io/&#34;&gt;NeX: Real-time View Synthesis with Neural Basis Expansion&lt;/a&gt;, Wizadwongsa et al. Arxiv 2021 | &lt;a href=&#34;https://github.com/nex-mpi/nex-code&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nex.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://people.csail.mit.edu/xiuming/projects/nerfactor/&#34;&gt;NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination&lt;/a&gt;, Zhang et al. Arxiv 2021 | &lt;a href=&#34;https://github.com/google/nerfactor&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nerfactor.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Compositionality&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.07492&#34;&gt;NeRF++: Analyzing and Improving Neural Radiance Fields&lt;/a&gt;, Zhang et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/Kai-46/nerfplusplus&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L345-L351&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Zhang20arxiv_nerf++--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.12100&#34;&gt;GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields&lt;/a&gt;, Niemeyer et al., CVPR 2021, &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L175-L181&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Niemeyer20arxiv_GIRAFFE--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shellguo.com/osf/&#34;&gt;Object-Centric Neural Scene Rendering&lt;/a&gt;, Guo et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L111-L117&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Guo20arxiv_OSF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ziyanw1.github.io/hybrid_nerf/&#34;&gt;Learning Compositional Radiance Fields of Dynamic Human Heads&lt;/a&gt;, Wang et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/hybrid-nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Wang20arxiv_hybrid_NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://light.princeton.edu/neural-scene-graphs/&#34;&gt;Neural Scene Graphs for Dynamic Scenes&lt;/a&gt;, Ost et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L353-L358&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Ost20arxiv_NeuralSceneGraphs--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kovenyu.com/uorf/&#34;&gt;Unsupervised Discovery of Object Radiance Fields&lt;/a&gt;, Yu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/uorf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zju3dv.github.io/object_nerf/&#34;&gt;Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering&lt;/a&gt;, Yang et al., ICCV 2021 | &lt;a href=&#34;https://github.com/zju3dv/object_nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/object-nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--yang2021objectnerf--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Scene Labelling and Understanding&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shuaifengzhi.com/Semantic-NeRF/&#34;&gt;In-Place Scene Labelling and Understanding with Implicit Scene Representation&lt;/a&gt;, Zhi et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/semantic-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Editing&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://editnerf.csail.mit.edu/&#34;&gt;Editing Conditional Radiance Fields&lt;/a&gt;, Liu et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/stevliu/editnerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/editnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jiakai-zhang.github.io/st-nerf/&#34;&gt;Editable Free-viewpoint Video Using a Layered Neural Representation&lt;/a&gt;, Zhang et al., SIGGRAPH 2021 | &lt;a href=&#34;https://github.com/DarlingHang/st-nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/st-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Object Category Modeling&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fig-nerf.github.io/&#34;&gt;FiG-NeRF: Figure Ground Neural Radiance Fields for 3D Object Category Modelling&lt;/a&gt;, Xie et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/fig-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/blog/nvidia-research-nerf-tex-neural-reflectance-field-textures/&#34;&gt;NeRF-Tex: Neural Reflectance Field Textures&lt;/a&gt;, Baatz et al., EGSR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nerf-tex.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Multi-scale&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jonbarron.info/mipnerf/&#34;&gt;Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields&lt;/a&gt;, Barron et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/google/mipnerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/mip-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Model Reconstruction&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.10078&#34;&gt;UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction&lt;/a&gt;, Oechsle et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/unisurf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.10689&#34;&gt;NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction&lt;/a&gt;, Wang et al., NeurIPS 2021 | &lt;a href=&#34;https://github.com/Totoro97/NeuS&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/neus.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.12052&#34;&gt;Volume Rendering of Neural Implicit Surfaces&lt;/a&gt;, Yariv et al., NeurIPS 2021 | &lt;a href=&#34;https://github.com/ventusff/neurecon&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/volsdf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Depth Estimation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://weiyithu.github.io/NerfingMVS/&#34;&gt;NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-view Stereo&lt;/a&gt;, Wei et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/NerfingMVS.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Talks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=LCTYRqW-ne8&amp;amp;t=10190s&#34;&gt;NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis&lt;/a&gt;, Ben Mildenhall&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nRyOzHpcr4Q&amp;amp;feature=emb_logo&amp;amp;ab_channel=cvprtum&#34;&gt;Understanding and Extending Neural Radiance Fields&lt;/a&gt;, Barron et al.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/Rd0nBO6--bM?t=1992&#34;&gt;Towards Photorealism (2nd half)&lt;/a&gt;, Vladlen Koltun&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=dPWLybp4LL0&#34;&gt;Neural Radiance Fields for View Synthesis&lt;/a&gt;, Matthew Tancik&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Implementations&lt;/h2&gt; &#xA;&lt;h4&gt;Tensorflow&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bmild/nerf&#34;&gt;NeRF&lt;/a&gt;, Mildenhall et al., 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L168-L173&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;PyTorch&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yenchenlin/nerf-pytorch&#34;&gt;NeRF-PyTorch&lt;/a&gt;, Yen-Chen Lin, 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/pytorch-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kwea123/nerf_pl&#34;&gt;NeRF-PyTorch-Lighting&lt;/a&gt;, &lt;a href=&#34;https://github.com/kwea123&#34;&gt;@kwea123&lt;/a&gt;, 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kwea123/nerf_pl/tree/nerfw&#34;&gt;NeRF-W&lt;/a&gt;, &lt;a href=&#34;https://github.com/kwea123&#34;&gt;@kwea123&lt;/a&gt;, 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/pytorch3d/tree/master/projects/nerf&#34;&gt;NeRF-PyTorch3D&lt;/a&gt;, &lt;a href=&#34;https://github.com/facebookresearch&#34;&gt;@facebookresearch&lt;/a&gt;, 2020&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Jax&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/google-research/google-research/tree/master/jaxnerf&#34;&gt;JaxNeRF&lt;/a&gt;, Deng et al., 2020 | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/NeRF-and-Beyond.bib#L55-L60&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/google/mipnerf&#34;&gt;Mip-NeRF&lt;/a&gt;, &lt;a href=&#34;https://github.com/google&#34;&gt;@google&lt;/a&gt;, 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/mipnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lib-pku/libpku</title>
    <updated>2022-06-05T02:27:57Z</updated>
    <id>tag:github.com,2022-06-05:/lib-pku/libpku</id>
    <link href="https://github.com/lib-pku/libpku" rel="alternate"></link>
    <summary type="html">&lt;p&gt;è´µæ ¡è¯¾ç¨‹èµ„æ–™æ°‘é—´æ•´ç†&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;libpku - è´µæ ¡è¯¾ç¨‹èµ„æ–™æ°‘é—´æ•´ç†&lt;/h1&gt; &#xA;&lt;h2&gt;Preface&lt;/h2&gt; &#xA;&lt;p&gt;ï¼ˆå¼•ç”¨è‡ª &lt;a href=&#34;https://github.com/QSCTech/zju-icicles&#34;&gt;QSCTech/zju-icicles&lt;/a&gt; ï¼‰&lt;/p&gt; &#xA;&lt;p&gt;æ¥åˆ°ä¸€æ‰€å¤§å­¦ï¼Œä»ç¬¬ä¸€æ¬¡æ¥è§¦è®¸å¤šè¯¾ï¼Œç›´åˆ°ä¸€é—¨ä¸€é—¨å®Œæˆï¼Œè¿™ä¸ªè¿‡ç¨‹ä¸­æˆ‘ä»¬æ—¶å¸¸æ”¶é›†èµ·è®¸å¤šèµ„æ–™å’Œæƒ…æŠ¥ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æœ‰äº›æ˜¯éœ€è¦åœ¨ç½‘ä¸Šæœç´¢çš„ç”µå­ä¹¦ï¼Œæ¯æ¬¡è§åˆ°ä¸€é—¨æ–°è¯¾ç¨‹ï¼ŒGoogle ä¸€ä¸‹æ•™æåç§°ï¼Œæœ‰çš„å¯ä»¥ç«‹å³æ‰¾åˆ°ï¼Œæœ‰çš„å´æ˜¯è¦èŠ±è´¹è®¸å¤šçœ¼åŠ›ï¼›æœ‰äº›æ˜¯å†å¹´è¯•å·æˆ–è€… A4 çº¸ï¼Œå‰äººç²¾å¿ƒæ”¶é›†åˆ¶ä½œï¼ŒæŠ±ç€èƒ½å¯¹ä»–äººæœ‰ç”¨çš„æƒ³æ³•å…¬å¼€ï¼Œå´éœ€è¦åœ¨å„ä¸ªç¾¤æˆ–è€…ç§ä¸‹ä¸­æ‘¸ç´¢ä»¥è‡³äºä»å­¦é•¿æ‰‹ä¸­ä»£ä»£ç›¸ä¼ ï¼›æœ‰äº›æ˜¯ä¸Šå®Œä¸€é—¨è¯¾æ‰æç„¶é¢†æ‚Ÿçš„æŠ€å·§ï¼ŒåŸæ¥è¿™é—¨è¯¾é‡ç‚¹å¦‚æ­¤ï¼Œå½“åˆæœ¬å¯ä»¥æ›´è½»æ¾åœ°å®Œæˆå¾—æ›´å¥½â€¦â€¦&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘ä¹Ÿæ›¾å¾ˆåŠªåŠ›åœ°æ”¶é›†å„ç§è¯¾ç¨‹èµ„æ–™ï¼Œä½†åˆ°æœ€åï¼ŒæŸäº›é‡è¦ä¿¡æ¯çš„å¾—åˆ°å´å¾€å¾€ä¾ç„¶æ˜¯çº¯å±å¶ç„¶ã€‚è¿™ç§çŠ¶æ€æ—¶å¸¸ä»¤æˆ‘æ„Ÿåˆ°åæ€•ä¸ä¸å®‰ã€‚æˆ‘ä¹Ÿæ›¾åœ¨è¯¾ç¨‹ç»“æŸåç»ˆäºæœ‰äº†äº›è®¸æ–¹æ³•ä¸æ€»ç»“ï¼Œä½†è¿™äº›æƒ³æ³•æ— å¤„è¯‰è¯´ï¼Œæœ€ç»ˆåªèƒ½æŠŠèŠ±è´¹æ—¶é—´ä¸ç²¾åŠ›æ‰æ¢æ¥çš„ç»éªŒè€—æ•£åœ¨äº†æ¼«æ¼«çš„é—å¿˜ä¹‹ä¸­ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘ä¸ºè¿™ä¸€å¹´ä¸€å¹´ï¼Œè¿™ä¹ˆå¤šäººå­¤å†›å¥‹æˆ˜çš„é‡å¤åŠ³åŠ¨æ„Ÿåˆ°ä¸å¹³ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘å¸Œæœ›èƒ½å¤Ÿå°†è¿™äº›éšæ™¦çš„ã€ä¸ç¡®å®šçš„ã€å£å£ç›¸ä¼ çš„èµ„æ–™å’Œç»éªŒï¼Œå˜ä¸ºå…¬å¼€çš„ã€æ˜“äºè·å–çš„å’Œå¤§å®¶èƒ½å¤Ÿå…±åŒå®Œå–„ã€ç§¯ç´¯çš„å…±äº«èµ„æ–™ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;æˆ‘å¸Œæœ›åªè¦æ˜¯å‰äººèµ°è¿‡çš„å¼¯è·¯ï¼Œåäººå°±ä¸å¿…å†èµ°ã€‚&lt;/strong&gt; è¿™æ˜¯æˆ‘çš„ä¿¡å¿µï¼Œä¹Ÿæ˜¯æˆ‘å»ºç«‹è¿™ä¸ªé¡¹ç›®çš„åŸå› ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;ä½¿ç”¨æ–¹æ³•ï¼šè®¿é—® &lt;a href=&#34;https://lib-pku.github.io/&#34;&gt;https://lib-pku.github.io/&lt;/a&gt; ï¼Œç‚¹å‡»èµ„æ–™é“¾æ¥å³å¯ä¸‹è½½ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://minhaskamal.github.io/DownGit/#/home&#34;&gt;https://minhaskamal.github.io/DownGit/#/home&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;æ¬¢è¿è´¡çŒ®ï¼&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;æ¬¢è¿è´¡çŒ®ï¼&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;æ¬¢è¿è´¡çŒ®ï¼&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;â€”â€”å› ä¸ºå¾ˆé‡è¦æ‰€ä»¥è¯´äº†ä¸‰é&lt;/p&gt; &#xA;&lt;p&gt;Issueã€PRã€çº é”™ã€èµ„æ–™ã€é€‰è¯¾/è€ƒè¯•æ”»ç•¥ï¼Œå®Œå…¨æ¬¢è¿ï¼&lt;/p&gt; &#xA;&lt;p&gt;æ¥è‡ªå¤§å®¶çš„å…³æ³¨ã€ç»´æŠ¤å’Œè´¡çŒ®ï¼Œæ‰æ˜¯è®©è¿™ä¸ªæ”»ç•¥ç»§ç»­å­˜åœ¨çš„åŠ¨åŠ›~&lt;/p&gt; &#xA;&lt;p&gt;å¯¹äºè¯¾ç¨‹çš„è¯„ä»·å¯å†™åœ¨å¯¹åº”è¯¾ç¨‹æ–‡ä»¶å¤¹çš„ &lt;code&gt;README.md&lt;/code&gt; ä¸­ã€‚å¦‚æœæƒ³ä¸Šä¼ è¯¾ä»¶ï¼ˆè¯·ç¡®ä¿æ— ç‰ˆæƒé—®é¢˜ï¼‰ï¼Œæ¨èä½¿ç”¨ PDF æ ¼å¼ï¼Œé¿å…ç³»ç»Ÿå·®ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ç”±äºæœ¬é¡¹ç›®ä½“ç§¯å¾ˆå¤§ï¼Œæ•…æ¨èé‡‡ç”¨åœ¨ &lt;strong&gt;GitHub Web ç«¯ç›´æ¥ä¸Šä¼ &lt;/strong&gt; çš„æ–¹å¼ï¼Œå…·ä½“æ“ä½œå¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;é¦–å…ˆ Fork æœ¬é¡¹ç›®&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;ä¸Šä¼ æ–‡ä»¶åˆ°å·²æœ‰æ–‡ä»¶å¤¹ï¼šæ‰“å¼€å¯¹åº”æ–‡ä»¶å¤¹ï¼Œç‚¹å‡»ç»¿è‰² Download æŒ‰é’®æ—çš„ uploadï¼Œä¸Šä¼ ä½ çš„æ–‡ä»¶ã€‚&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;ä¸Šä¼ æ–‡ä»¶åˆ°æ–°æ–‡ä»¶å¤¹ï¼šæ‰“å¼€ä»»æ„æ–‡ä»¶å¤¹ï¼Œç‚¹å‡»ç»¿è‰² Download æŒ‰é’®æ—çš„ uploadï¼Œ&lt;strong&gt;æŠŠæµè§ˆå™¨åœ°å€æ ä¸­æ–‡ä»¶å¤¹åç§°æ”¹ä¸ºä½ æƒ³è¦æ–°å»ºçš„æ–‡ä»¶å¤¹åç§°ï¼Œç„¶åå›è½¦&lt;/strong&gt;ï¼Œä¸Šä¼ ä½ çš„æ–‡ä»¶ã€‚&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æäº¤ PRï¼šFork æœ¬é¡¹ç›®ï¼Œç„¶ååœ¨ GitHub ç½‘é¡µç«¯ç‚¹å‡» Upload File ä¸Šä¼ æ–‡ä»¶ï¼Œå‘èµ· PR å³å¯ã€‚ç•™æ„ä¸€ä¸‹é¡¹ç›®çš„æ–‡ä»¶ç»„ç»‡å–”ã€‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;æˆ–è€…ä¹Ÿå¯ä»¥ç›´æ¥é™„åŠ åœ¨ &lt;strong&gt;Issue&lt;/strong&gt; ä¸­ï¼Œç”±ç»´æŠ¤è€…è¿›è¡Œæ·»åŠ ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ–è€…ä¹Ÿå¯ä»¥å‘é€é‚®ä»¶è‡³ &lt;strong&gt;&lt;a href=&#34;mailto:libpku@protonmail.com&#34;&gt;libpku@protonmail.com&lt;/a&gt;&lt;/strong&gt; ï¼Œç”±ç»´æŠ¤è€…è¿›è¡Œæ·»åŠ ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;è¿™ä¸æ˜¯åŒ—äº¬å¤§å­¦å›¾ä¹¦é¦†ã€‚ æˆ‘ä»¬ä¹Ÿä¸å¯¹é¡¹ç›®ä¸­ä¿¡æ¯çš„å‡†ç¡®æ€§æˆ–çœŸå®æ€§åšä»»ä½•æ‰¿è¯ºã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;å¦‚æœæœ‰ä¾µæƒæƒ…å†µï¼Œéº»çƒ¦æ‚¨å‘é€å¿…è¦çš„ä¿¡æ¯è‡³ &lt;a href=&#34;mailto:libpku@protonmail.com&#34;&gt;libpku@protonmail.com&lt;/a&gt; ï¼Œå¸¦æ¥ä¸ä¾¿è¿˜è¯·æ‚¨è°…è§£ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;èµ„æ–™æ¥è‡ªç½‘ç»œï¼Œç›¸å…³æƒåˆ©ç”±åŸä½œè€…æ‰€æœ‰ï¼Œè¿™ä¸ª repo ä»…ç”¨äºæ”¶é›†ç°æœ‰èµ„æ–™ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å½“ç„¶ï¼Œæˆ‘ä»¬ä¸ä¼šä¸ºæ”¶é›†åˆ°çš„èµ„æ–™æ”¶è´¹ï¼Œæˆ–æ˜¯å°è¯•æ”¶å–æèµ ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åªæ˜¯å°è¯•ä¸ºåæ¥çš„åŒå­¦èŠ‚çœä¸€äº›æ—¶é—´ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;Related Works&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/QSCTech/zju-icicles&#34;&gt;æµ™æ±Ÿå¤§å­¦è¯¾ç¨‹æ”»ç•¥å…±äº«è®¡åˆ’&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/martinwu42/project-hover&#34;&gt;æ°”å«èˆ¹è®¡åˆ’â€”â€”å…è´¹ã€å»ä¸­å¿ƒåŒ–çš„åŒ—äº¬å¤§å­¦å¾€å¹´é¢˜èµ„æ–™åº“&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/EECS-PKU-XSB/Shared-learning-materials&#34;&gt;åŒ—äº¬å¤§å­¦ä¿¡ç§‘å­¦ç”Ÿä¼šå­¦æœ¯éƒ¨èµ„æ–™åº“&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tongtzeho/PKUCourse&#34;&gt;åŒ—å¤§è®¡ç®—æœºè¯¾ç¨‹å¤§ä½œä¸š&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PKUanonym/REKCARC-TSC-UHT&#34;&gt;æ¸…åå¤§å­¦è®¡ç®—æœºç³»è¯¾ç¨‹æ”»ç•¥&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zjdx1998/seucourseshare&#34;&gt;ä¸œå—å¤§å­¦è¯¾ç¨‹å…±äº«è®¡åˆ’&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/USTC-Resource/USTC-Course&#34;&gt;ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦è®¡ç®—æœºå­¦é™¢è¯¾ç¨‹èµ„æº&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CoolPhilChen/SJTU-Courses/&#34;&gt;ä¸Šæµ·äº¤é€šå¤§å­¦è¯¾ç¨‹èµ„æ–™åˆ†äº«&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sysuexam/SYSU-Exam&#34;&gt;ä¸­å±±å¤§å­¦è¯¾ç¨‹èµ„æ–™åˆ†äº«&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/idealclover/NJU-Review-Materials&#34;&gt;å—äº¬å¤§å­¦è¯¾ç¨‹å¤ä¹ èµ„æ–™&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CooperNiu/ZZU-Courses-Resource&#34;&gt;éƒ‘å·å¤§å­¦è¯¾ç¨‹å¤ä¹ èµ„æ–™&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/brenner8023/gdut-course&#34;&gt;å¹¿ä¸œå·¥ä¸šå¤§å­¦è®¡ç®—æœºå­¦é™¢è¯¾ç¨‹æ”»ç•¥&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;(more to be added....)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ElegantLaTeX/ElegantBook</title>
    <updated>2022-06-05T02:27:57Z</updated>
    <id>tag:github.com,2022-06-05:/ElegantLaTeX/ElegantBook</id>
    <link href="https://github.com/ElegantLaTeX/ElegantBook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Elegant LaTeX Template for Books&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://elegantlatex.org/&#34;&gt;Homepage&lt;/a&gt; | &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantBook&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://ctan.org/pkg/elegantbook&#34;&gt;CTAN&lt;/a&gt; | &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantBook/releases&#34;&gt;Download&lt;/a&gt; | &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantBook/wiki&#34;&gt;Wiki&lt;/a&gt; | &lt;a href=&#34;https://weibo.com/elegantlatex&#34;&gt;Weibo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/ctan/l/elegantbook.svg?sanitize=true&#34; alt=&#34;License&#34;&gt; &lt;img src=&#34;https://img.shields.io/ctan/v/elegantbook.svg?sanitize=true&#34; alt=&#34;CTAN Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/release/ElegantLaTeX/ElegantBook.svg?sanitize=true&#34; alt=&#34;Github Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/repo-size/ElegantLaTeX/ElegantBook.svg?sanitize=true&#34; alt=&#34;Repo Size&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;ElegantBook: An Elegant LaTeX Template for Books&lt;/h1&gt; &#xA;&lt;p&gt;ElegantBook is designed for writing books, created by &lt;a href=&#34;https://ddswhu.me/&#34;&gt;Dongsheng Deng&lt;/a&gt; and &lt;a href=&#34;https://liam.page/&#34;&gt;Liam Huang&lt;/a&gt;. Just enjoy it! If you have any questions, suggestions or bug reports, you can create issues or contact us at &lt;a href=&#34;mailto:elegantlatex2e@gmail.com&#34;&gt;elegantlatex2e@gmail.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Important Notes&lt;/h2&gt; &#xA;&lt;p&gt;For some reasons, &lt;strong&gt;unauthorized&lt;/strong&gt; pull requests are &lt;strong&gt;UNACCEPTABLE&lt;/strong&gt; since May 20, 2019. For those who want to help revise the templates, submit issues or clone to your own repository to modify under the LPPL-1.3c.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;Thank &lt;a href=&#34;https://github.com/sikouhjw&#34;&gt;sikouhjw&lt;/a&gt; and &lt;a href=&#34;https://github.com/syvshc&#34;&gt;syvshc&lt;/a&gt; for their quick response to Github issues and continuously support work for ElegantLaTeX.&lt;/p&gt; &#xA;&lt;p&gt;Thank ChinaTeX and &lt;a href=&#34;http://www.latexstudio.net/&#34;&gt;LaTeX Studio&lt;/a&gt; for their promotion.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This work is released under the LaTeX Project Public License, v1.3c or later.&lt;/p&gt; &#xA;&lt;h2&gt;Derivative Works&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/XiangyunHuang/ElegantBookdown&#34;&gt;ElegantBookdown&lt;/a&gt;ï¼š&lt;a href=&#34;https://github.com/XiangyunHuang&#34;&gt;XiangyunHuang&lt;/a&gt; developed a Bookdown template based on ElegantBook.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pzhaonet/bookdownplus&#34;&gt;bookdownplus&lt;/a&gt;: maintained by &lt;a href=&#34;https://github.com/pzhaonet&#34;&gt;pzhaonet&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/annProg/PanBook&#34;&gt;PanBook&lt;/a&gt;ï¼ša markdown-based writing workflow Developed by &lt;a href=&#34;https://github.com/annProg&#34;&gt;annProg&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>