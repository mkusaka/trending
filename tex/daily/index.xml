<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-22T01:37:15Z</updated>
  <subtitle>Daily Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>IAAR-Shanghai/SurveyX</title>
    <updated>2025-06-22T01:37:15Z</updated>
    <id>tag:github.com,2025-06-22:/IAAR-Shanghai/SurveyX</id>
    <link href="https://github.com/IAAR-Shanghai/SurveyX" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Academic Survey Paper Generation.&lt;/p&gt;&lt;hr&gt;&lt;h2 align=&#34;center&#34;&gt;SurveyX: Academic Survey Automation via Large Language Models&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;i&gt; ‚ú®Welcome to SurveyX! If you want to experience the full features, please log in to our website. This open-source code only provides offline processing capabilities.‚ú® &lt;/i&gt; &lt;br&gt; &lt;a href=&#34;https://arxiv.org/abs/2502.14776&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/arXiv-Paper-red.svg?logo=arxiv&#34; alt=&#34;arxiv paper&#34;&gt; &lt;/a&gt; &lt;a href=&#34;http://www.surveyx.cn&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/SurveyX-Web-blue?style=flat&#34; alt=&#34;surveyx.cn&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://huggingface.co/papers/2502.14776&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Huggingface-%F0%9F%A4%97-yellow?style=flat&#34; alt=&#34;huggingface paper&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/IAAR-Shanghai/SurveyX&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/IAAR-Shanghai/SurveyX?style=flat&amp;amp;logo=github&amp;amp;color=yellow&#34; alt=&#34;github stars&#34;&gt; &lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/last-commit/IAAR-Shanghai/SurveyX?display_timestamp=author&amp;amp;style=flat&amp;amp;color=green&#34; alt=&#34;last commit&#34;&gt;  &lt;br&gt; &lt;a href=&#34;https://github.com/IAAR-Shanghai/SurveyX/raw/main/assets/user_groups_123.jpg&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Wechat-Group-07c160?style=flat&amp;amp;logo=wechat&#34; alt=&#34;Wechat Group&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;strong&gt;&lt;a&gt;If you find our work helpful, don&#39;t forget to give us a star! ‚≠êÔ∏è&lt;/a&gt;&lt;/strong&gt; &#xA; &lt;br&gt; üëâ &#xA; &lt;strong&gt;&lt;a href=&#34;https://surveyx.cn/&#34;&gt;Visit SurveyX&lt;/a&gt;&lt;/strong&gt; üëà &#xA;&lt;/div&gt; &#xA;&lt;p&gt;[English | &lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/README_zh.md&#34;&gt;‰∏≠Êñá&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;h2&gt;ü§îWhat is SurveyX?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/assets/SurveyX.png&#34; alt=&#34;surveyx_frame&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SurveyX&lt;/strong&gt; is an advanced academic survey automation system that leverages the power of Large Language Models (LLMs) to generate high-quality, domain-specific academic papers and surveys. By simply providing a paper title and keywords for literature retrieval, users can request comprehensive academic papers or surveys tailored to specific topics.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üÜö Full Version vs. Offline Open Source Version&lt;/h2&gt; &#xA;&lt;p&gt;The open-source code in this repository only provides offline processing capabilities. If you want to experience the full features, please log in to &lt;a href=&#34;https://www.surveyx.cn&#34;&gt;our website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Missing features in the open-source version:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Real-time online search:&lt;/strong&gt; You can only generate surveys based on your own uploaded &lt;code&gt;.md&lt;/code&gt; format references. The open-source version lacks access to our paper database, web crawler system, keyword expansion algorithms, and dual-layer semantic filtering for literature acquisition.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multimodal document parsing:&lt;/strong&gt; The generated survey will not include image understanding or illustrations from the references.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üõ†Ô∏è How to Use the Offline Open Source Version (This repo)&lt;/h2&gt; &#xA;&lt;h3&gt;1. Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.10+ (Anaconda recommended)&lt;/li&gt; &#xA; &lt;li&gt;All Python dependencies in &lt;code&gt;requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;LaTeX environment (for PDF compilation):&lt;/li&gt; &#xA; &lt;li&gt;You need to convert all your reference documents to Markdown (&lt;code&gt;.md&lt;/code&gt;) format and put them together in a single folder before running the pipeline.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt update &amp;amp;&amp;amp; sudo apt install texlive-full&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Installation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/IAAR-Shanghai/SurveyX.git&#xA;cd SurveyX&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install Python dependencies:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. LLM Configuration&lt;/h3&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;src/configs/config.py&lt;/code&gt; to provide your LLM API URL, token, and model information before running the pipeline.&lt;/p&gt; &#xA;&lt;p&gt;Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;REMOTE_URL = &#34;https://api.openai.com/v1/chat/completions&#34;&#xA;TOKEN = &#34;sk-xxxx...&#34;&#xA;DEFAULT_EMBED_ONLINE_MODEL = &#34;BAAI/bge-base-en-v1.5&#34;&#xA;EMBED_REMOTE_URL = &#34;https://api.siliconflow.cn/v1/embeddings&#34;&#xA;EMBED_TOKEN = &#34;your embed token here&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;4. Workflow&lt;/h3&gt; &#xA;&lt;p&gt;Each run creates a unique result folder under &lt;code&gt;outputs/&lt;/code&gt;, named by the task id &lt;code&gt;outputs/&amp;lt;task_id&amp;gt;&lt;/code&gt; (e.g., &lt;code&gt;outputs/2025-06-18-0935_keyword/&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Run the full pipeline:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python tasks/offline_run.py --title &#34;Your Survey Title&#34; --key_words &#34;keyword1, keyword2, ...&#34; --ref_path &#34;path/to/your/reference/dir&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or run step by step:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export task_id=&#34;your_task_id&#34;&#xA;python tasks/workflow/03_gen_outlines.py --task_id $task_id&#xA;python tasks/workflow/04_gen_content.py --task_id $task_id&#xA;python tasks/workflow/05_post_refine.py --task_id $task_id&#xA;python tasks/workflow/06_gen_latex.py --task_id $task_id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Your local reference documents &lt;strong&gt;must be in Markdown (&lt;code&gt;.md&lt;/code&gt;) format&lt;/strong&gt; and placed in a single directory.&lt;/p&gt; &#xA;&lt;h3&gt;5. Output&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All results are saved under &lt;code&gt;outputs/&amp;lt;task_id&amp;gt;/&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;survey.pdf&lt;/code&gt;: Final compiled survey&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;outlines.json&lt;/code&gt;: Generated outline&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;latex/&lt;/code&gt;: LaTeX sources&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;tmp/&lt;/code&gt;: Intermediate files&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Example Papers&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Keywords&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/A_Survey_of_NoSQL_Database_Systems_for_Flexible_and_Scalable_Data_Management.pdf&#34;&gt;A Survey of NoSQL Database Systems for Flexible and Scalable Data Management&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;NoSQL, Database Systems, Flexibility, Scalability, Data Management&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/Vector_Databases_and_Their_Role_in_Modern_Data_Management_and_Retrieval_A_Survey.pdf&#34;&gt;Vector Databases and Their Role in Modern Data Management and Retrieval A Survey&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vector Databases, Data Management, Data Retrieval, Modern Applications&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/Graph_Databases_A_Survey_on_Models.pdf&#34;&gt;Graph Databases A Survey on Models, Data Modeling, and Applications&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Graph Databases, Data Modeling&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/A_Survey_on_Large_Language_Model_Integration_with_Databases_for_Enhanced_Data_Management_and_Survey_Analysis.pdf&#34;&gt;A Survey on Large Language Model Integration with Databases for Enhanced Data Management and Survey Analysis&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Large Language Models, Database Integration, Data Management, Survey Analysis, Enhanced Processing&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/A_Survey_of_Temporal_Databases_Real.pdf&#34;&gt;A Survey of Temporal Databases Real-Time Databases and Data Management Systems&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Temporal Databases, Real-Time Databases, Data Management&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/Transformer.pdf&#34;&gt;From BERT to GPT-4: A Survey of Architectural Innovations in Pre-trained Language Models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Transformer, BERT, GPT-3, self-attention, masked language modeling, cross-lingual transfer, model scaling&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/low.pdf&#34;&gt;Unsupervised Cross-Lingual Word Embedding Alignment: Techniques and Applications&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;low-resource NLP, few-shot learning, data augmentation, unsupervised alignment, synthetic corpora, NLLB, zero-shot transfer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/multimodal.pdf&#34;&gt;Vision-Language Pre-training: Architectures, Benchmarks, and Emerging Trends&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;multimodal learning, CLIP, Whisper, cross-modal retrieval, modality fusion, video-language models, contrastive learning&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/model.pdf&#34;&gt;Efficient NLP at Scale: A Review of Model Compression Techniques&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;model compression, knowledge distillation, pruning, quantization, TinyBERT, edge computing, latency-accuracy tradeoff&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/domain.pdf&#34;&gt;Domain-Specific NLP: Adapting Models for Healthcare, Law, and Finance&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;domain adaptation, BioBERT, legal NLP, clinical text analysis, privacy-preserving NLP, terminology extraction, few-shot domain transfer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/attn.pdf&#34;&gt;Attention Heads of Large Language Models: A Survey&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;attention head, attention mechanism, large language model, LLM,transformer architecture, neural networks, natural language processing&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/ctg.pdf&#34;&gt;Controllable Text Generation for Large Language Models: A Survey&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;controlled text generation, text generation, large language model, LLM,natural language processing&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/eval.pdf&#34;&gt;A survey on evaluation of large language models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;evaluation of large language models,large language models assessment, natural language processing, AI model evaluation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/infor.pdf&#34;&gt;Large language models for generative information extraction: a survey&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;information extraction, large language models, LLM,natural language processing, generative AI, text mining&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/inter.pdf&#34;&gt;Internal consistency and self feedback of LLM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Internal consistency, self feedback, large language model, LLM,natural language processing, model evaluation, AI reliability&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/multi-agent.pdf&#34;&gt;Review of Multi Agent Offline Reinforcement Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;multi agent, offline policy, reinforcement learning,decentralized learning, cooperative agents, policy optimization&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computation_and_Language/reason.pdf&#34;&gt;Reasoning of large language model: A survey&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;reasoning of large language models, large language models, LLM,natural language processing, AI reasoning, transformer models&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computational_Complexity/P_vs_.pdf&#34;&gt;Hierarchy Theorems in Computational Complexity: From Time-Space Tradeoffs to Oracle Separations&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;P vs NP, NP-completeness, polynomial hierarchy, space complexity, oracle separation, Cook-Levin theorem&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computational_Complexity/BQP.pdf&#34;&gt;Classical Simulation of Quantum Circuits: Complexity Barriers and Implications&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;BQP, quantum supremacy, Shor&#39;s algorithm, post-quantum cryptography, QMA, hidden subgroup problem&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computational_Complexity/fixed.pdf&#34;&gt;Kernelization: Theory, Techniques, and Limits&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;fixed-parameter tractable (FPT), kernelization, treewidth, W-hierarchy, ETH (Exponential Time Hypothesis), parameterized reduction&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computational_Complexity/PCP.pdf&#34;&gt;Optimal Inapproximability Thresholds for Combinatorial Optimization Problems&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PCP theorem, approximation ratio, Unique Games Conjecture, APX-hardness, gap-preserving reduction, LP relaxation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Computational_Complexity/SETH.pdf&#34;&gt;Hardness in P: When Polynomial Time is Not Enough&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;SETH (Strong Exponential Time Hypothesis), 3SUM conjecture, all-pairs shortest paths (APSP), orthogonal vectors problem, fine-grained reduction, dynamic lower bounds&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/CAP.pdf&#34;&gt;Consistency Models in Distributed Databases: From ACID to NewSQL&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CAP theorem, ACID vs BASE, Paxos/Raft, Spanner, NewSQL, sharding, linearizability&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/CAP.pdf&#34;&gt;Cloud-Native Databases: Architectures, Challenges, and Future Directions&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;cloud databases, AWS Aurora, Snowflake, storage-compute separation, auto-scaling, pay-per-query, multi-tenancy&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/graph.pdf&#34;&gt;Graph Database Systems: Storage Engines and Query Optimization Techniques&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;graph traversal, Neo4j, SPARQL, property graph, subgraph matching, RDF triplestore, Gremlin&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/time.pdf&#34;&gt;Real-Time Aggregation in TSDBs: Techniques for High-Cardinality Data&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;time-series data, InfluxDB, Prometheus, downsampling, time windowing, high-cardinality indexing, stream processing&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/auto.pdf&#34;&gt;Self-Driving Databases: A Survey of AI-Powered Autonomous Management&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;autonomous databases, learned indexes, query optimization, Oracle AutoML, workload forecasting, anomaly detection&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Database/mmd.pdf&#34;&gt;Multi-Model Databases: Integrating Relational, Document, and Graph Paradigms&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;multi-model database, MongoDB, ArangoDB, JSONB, unified query language, schema flexibility, polystore&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Networking_and_Internet_Architecture/vector.pdf&#34;&gt;Vector Databases for AI: Efficient Similarity Search and Retrieval-Augmented Generation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;vector database, FAISS, Milvus, ANN search, embedding indexing, RAG (Retrieval-Augmented Generation), HNSW&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Networking_and_Internet_Architecture/open.pdf&#34;&gt;Software-Defined Networking: Evolution, Challenges, and Future Scalability&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;OpenFlow, control plane/data plane separation, NFV orchestration, network slicing, P4 language, OpenDaylight, scalability bottlenecks&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Networking_and_Internet_Architecture/network.pdf&#34;&gt;Beyond 5G: Architectural Innovations for Terahertz Communication and Network Slicing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;network slicing, MEC (Multi-access Edge Computing), beamforming, mmWave, URLLC (Ultra-Reliable Low-Latency Communication), O-RAN, energy efficiency&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Networking_and_Internet_Architecture/LPWAN.pdf&#34;&gt;IoT Network Protocols: A Comparative Study of LoRaWAN, NB-IoT, and Thread&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;LPWAN, LoRa, ZigBee 3.0, 6LoWPAN, TDMA scheduling, RPL routing, device density management&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Networking_and_Internet_Architecture/CDN.pdf&#34;&gt;Edge Caching in Content Delivery Networks: Algorithms and Economic Incentives&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CDN, Akamai, cache replacement policies, DASH (Dynamic Adaptive Streaming), QoE optimization, edge server placement, bandwidth cost reduction&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Other/battery.pdf&#34;&gt;A survey on flow batteries&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;battery electrolyte formulation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IAAR-Shanghai/SurveyX/main/examples/Other/flow_battery.pdf&#34;&gt;Research on battery electrolyte formulation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;flow batteries&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üìÉCiting SurveyX&lt;/h2&gt; &#xA;&lt;p&gt;Please cite us if you find this project helpful for your project/paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;@misc{liang2025surveyxacademicsurveyautomation,&#xA;      title={SurveyX: Academic Survey Automation via Large Language Models}, &#xA;      author={Xun Liang and Jiawei Yang and Yezhaohui Wang and Chen Tang and Zifan Zheng and Shichao Song and Zehao Lin and Yebin Yang and Simin Niu and Hanyu Wang and Bo Tang and Feiyu Xiong and Keming Mao and Zhiyu li},&#xA;      year={2025},&#xA;      eprint={2502.14776},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CL},&#xA;      url={https://arxiv.org/abs/2502.14776}, &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr style=&#34;border: 1px solid #ecf0f1;&#34;&gt; &#xA;&lt;h2&gt;Open Source Version Notice&lt;/h2&gt; &#xA;&lt;p&gt;This open source version of Surveyx is a simplified edition. It relies entirely on user-provided local reference documents and does not include advanced features such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Keyword expansion and filtering algorithms&lt;/li&gt; &#xA; &lt;li&gt;Multimodal image parsing or figure extraction&lt;/li&gt; &#xA; &lt;li&gt;Online reference search or automatic data fetching&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These advanced modules are only available in the full version of Surveyx, which is hosted by MemTensor (Shanghai) Technology Co., Ltd. If you would like to experience the complete features, please visit our official website: &lt;a href=&#34;https://surveyx.cn&#34;&gt;surveyx.cn&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For questions or issues, please open an issue on the repository.&lt;/p&gt; &#xA;&lt;h2&gt;‚ö†Ô∏è Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;SurveyX uses advanced language models to assist with the generation of academic papers. However, it is important to note that the generated content is a tool for research assistance. Users should verify the accuracy of the generated papers, as SurveyX cannot guarantee full compliance with academic standards.&lt;/p&gt;</summary>
  </entry>
</feed>