<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-02T01:38:05Z</updated>
  <subtitle>Daily Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mikeizbicki/cmc-csci145-math166</title>
    <updated>2022-09-02T01:38:05Z</updated>
    <id>tag:github.com,2022-09-02:/mikeizbicki/cmc-csci145-math166</id>
    <link href="https://github.com/mikeizbicki/cmc-csci145-math166" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Data Mining&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CSCI145 / MATH166: Data Mining&lt;/h1&gt; &#xA;&lt;!--&#xA;FIXME:&#xA;Include these links in the right topic folders:&#xA;&#xA;1. Why I don&#39;t like notebooks https://www.youtube.com/watch?v=7jiPeIFXb6U&#xA;&#xA;1. NeurIPS keynote on software engineering in data mining: https://nips.cc/virtual/2020/public/invited_16166.html&#xA;&#xA;1 Tutorial on fairness: https://www.youtube.com/watch?v=jIXIuYdnyyk&#xA;&#xA;1. AUC/ROC curves https://www.youtube.com/watch?v=4jRBRDbJemM&#xA;&#xA;1. A cool fasttext application: https://mixedname.com/english_klingon_feminine_names&#xA;&#xA;1. cross-lingual embeddings: https://ruder.io/cross-lingual-embeddings/&#xA;--&gt; &#xA;&lt;center&gt; &#xA; &lt;img width=&#34;400px&#34; src=&#34;https://raw.githubusercontent.com/mikeizbicki/cmc-csci145-math166/2022fall/machine_learning_2x.png&#34;&gt; &#xA;&lt;/center&gt; &#xA;&lt;p&gt;Important links:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/5026/what-is-the-difference-between-data-mining-statistics-machine-learning-and-ai&#34;&gt;Data Mining vs Machine Learning vs Artificial Intelligence vs Statistics&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.levels.fyi/comp.html?track=Data%20Scientist&#34;&gt;What do data scientists get payed?&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;About the Instructor&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Name&lt;/td&gt; &#xA;   &lt;td&gt;Mike Izbicki (call me Mike)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Email&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;mailto:mizbicki@cmc.edu&#34;&gt;mizbicki@cmc.edu&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Office&lt;/td&gt; &#xA;   &lt;td&gt;Adams 216&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Office Hours&lt;/td&gt; &#xA;   &lt;td&gt;See &lt;a href=&#34;https://github.com/mikeizbicki/cmc-csci145-math166/issues/69&#34;&gt;Issue #69&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Zoom&lt;/td&gt; &#xA;   &lt;td&gt;See &lt;a href=&#34;https://github.com/mikeizbicki/cmc-csci145-math166/issues/70&#34;&gt;Issue #70&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Webpage&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://izbicki.me&#34;&gt;https://izbicki.me&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Research&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning (see &lt;a href=&#34;https://izbicki.me/research.html&#34;&gt;izbicki.me/research.html&lt;/a&gt; for some past projects)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Fun facts:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;grew up in San Clemente (~1 hr south of Claremont)&lt;/li&gt; &#xA; &lt;li&gt;7 years in the navy &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;nuclear submarine officer, personally converted &amp;gt;10g of uranium into pure energy&lt;/li&gt; &#xA;   &lt;li&gt;worked at National Security Agency (NSA)&lt;/li&gt; &#xA;   &lt;li&gt;left Navy as a &lt;a href=&#34;https://www.nytimes.com/2011/02/23/nyregion/23objector.html&#34;&gt;conscientious objector&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;phd/postdoc at UC Riverside&lt;/li&gt; &#xA; &lt;li&gt;taught in &lt;a href=&#34;https://pust.co&#34;&gt;DPRK (i.e. North Korea)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;About the Course&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;General Information:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;This is the theory course for CMC&#39;s Data Science major&lt;/li&gt; &#xA; &lt;li&gt;Prepare you for industry or graduate school &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Especially for machine learning technical interviews&lt;/li&gt; &#xA;   &lt;li&gt;No SQL in this course =&amp;gt; that&#39;s CSCI133 Big Data&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning Objectives:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/mikeizbicki/cmc-csci145-math166/2022fall/intro.ipnyb&#34;&gt;Jupyter notebook&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Exposure to &lt;em&gt;research-level&lt;/em&gt; data mining&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt; &lt;p&gt;Understand the latest algorithms... but algorithms get outdated fast.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;The real goal is to teach you how to read research-level papers and math so that you can understand future techniques by yourself&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Major concepts&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Techniques &#xA;    &lt;ol&gt; &#xA;     &lt;li&gt;Eigen-methods for data mining&lt;/li&gt; &#xA;     &lt;li&gt;Logistic regression&lt;/li&gt; &#xA;     &lt;li&gt;Kernel methods&lt;/li&gt; &#xA;     &lt;li&gt;Neural networks&lt;/li&gt; &#xA;     &lt;li&gt;word2vec&lt;/li&gt; &#xA;     &lt;li&gt;Small amount of deep learning (transformers, CNNs, etc.)&lt;/li&gt; &#xA;    &lt;/ol&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Math &#xA;    &lt;ol&gt; &#xA;     &lt;li&gt;Bias/variance trade-off&lt;/li&gt; &#xA;     &lt;li&gt;VC Dimension theorem (fundamental theorem of statistical learning)&lt;/li&gt; &#xA;     &lt;li&gt;Regularization (L1, L2, elastic net, weight decay, early stopping, etc.)&lt;/li&gt; &#xA;     &lt;li&gt;Optimization algorithms (gradient descent, stochastic gradient descent, ADAM, etc.)&lt;/li&gt; &#xA;    &lt;/ol&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Programming: &#xA;    &lt;ol&gt; &#xA;     &lt;li&gt;Writing code that is easy to deploy&lt;/li&gt; &#xA;    &lt;/ol&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Focus on text/web/social media examples&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ethical implications of data mining&lt;/p&gt; &lt;p&gt;Pet peeve: You can&#39;t fully understand the ethics if you don&#39;t understand the technical details&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Apply data mining libraries (PyTorch, scikit-learn, GenSim, spaCy, etc.)&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Teaching you how to use these libraries is NOT the primary goal of the course&lt;/li&gt; &#xA;   &lt;li&gt;In-person class time will focus on the math, and I&#39;m expecting you can figure out how to use the libraries on your own&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Prerequisite knowledge:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;!-- FIXME --&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;linear algebra &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;eigenvectors&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;computation &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;big-o analysis&lt;/li&gt; &#xA;   &lt;li&gt;git&lt;/li&gt; &#xA;   &lt;li&gt;download/use python libraries&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;statistics &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;super basic probability&lt;/li&gt; &#xA;   &lt;li&gt;exposure to linear/logistic regression helpful but not required&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Textbook:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;I will provide all the reference material for this class. You don&#39;t have to buy anything.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;Learning from Data&lt;/em&gt; by Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin&lt;/p&gt; &lt;p&gt;I am providing you all a free copy. It is yours to keep forever if you&#39;d like (or you can return it to me at the end of the semester and I&#39;ll pass it on to future students). Feel free to highlight/take notes/etc in it as if it were your own book, because it is.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;Understanding Machine Learning: From Theory to Algorithms&lt;/em&gt; by Shai Shalev-Shwartz and Shai Ben-David&lt;/p&gt; &lt;p&gt;Freely available &lt;a href=&#34;https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/&#34;&gt;from Shalev-Shwartz&#39;s website&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Lots of research papers / lecture notes&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;!--&#xA;1. Christopher Bishop&#39;s *Pattern Recognition and Machine Learning*.  [Download a free pdf copy from Microsoft Research.](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/)&#xA;1. Peterson&#39;s *The Matrix Cookbook* is a handy reference for multivariable calculus, and [you can download a free copy here](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf).&#xA;1. Other articles as posted in the schedule below.&#xA;1. Other popular (and freely available) data mining books include [Data Mining: Concepts and Techniques](http://myweb.sabanciuniv.edu/rdehkharghani/files/2016/02/The-Morgan-Kaufmann-Series-in-Data-Management-Systems-Jiawei-Han-Micheline-Kamber-Jian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-Morgan-Kaufmann-2011.pdf) by Jiawei Han, Micheline Kamber and Jian Pei and [Data Mining](http://www.charuaggarwal.net/Data-Mining.htm) by Charu C. Aggarwal.  We probably won&#39;t use these books at all though.&#xA;--&gt; &#xA;&lt;p&gt;&lt;strong&gt;Grades:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Category&lt;/th&gt; &#xA;   &lt;th&gt;Percent&lt;/th&gt; &#xA;   &lt;th&gt;Approximate Date&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Projects&lt;/td&gt; &#xA;   &lt;td&gt;30&lt;/td&gt; &#xA;   &lt;td&gt;Every 2-3 weeks&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Quizzes&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Midterm 1 (Pagerank)&lt;/td&gt; &#xA;   &lt;td&gt;15&lt;/td&gt; &#xA;   &lt;td&gt;Week 03&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Midterm 2 (Learning from Data)&lt;/td&gt; &#xA;   &lt;td&gt;15&lt;/td&gt; &#xA;   &lt;td&gt;Week 08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Midterm 3 (Text mining)&lt;/td&gt; &#xA;   &lt;td&gt;15&lt;/td&gt; &#xA;   &lt;td&gt;Week 13&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Final&lt;/td&gt; &#xA;   &lt;td&gt;25&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Projects:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;4-7 projects&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;All of them must be completed on the lambda server (i.e. using ssh+bash+vim)&lt;/p&gt; &lt;p&gt;Lambda server has 80 CPUs + 8 GPUs&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;I&#39;m expecting almost everyone will get full credit, and these will act as a &#34;grade boost&#34;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;!--&#xA;| Project: Search Engine I          | 5         | Week 2              |&#xA;| Project: Statistical Learning I   | 5         |                     |&#xA;| Project: Statistical Learning II  | 5         |                     |&#xA;| Project: Transfer Learning        |           |                     | https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html&#xA;| Project: Twitter                  | 5         |                     |&#xA;| Project: Search Engine II         | 5         |                     |&#xA;--&gt; &#xA;&lt;p&gt;Quizzes:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;There will be 1 quiz per midterm testing definition memorization.&lt;/li&gt; &#xA; &lt;li&gt;I will give you the quiz before you take it.&lt;/li&gt; &#xA; &lt;li&gt;They are not worth any points, but &lt;strong&gt;you must get 100% on the quiz or you will fail the class&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Unlimited retakes, but each retake results in a -1% off your final grade.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Midterms:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;No programming, only math&lt;/li&gt; &#xA; &lt;li&gt;Take home, unlimited time, open note&lt;/li&gt; &#xA; &lt;li&gt;Very hard exams. (Historically, average in the 70s. No curve.)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Final:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Oral exam&lt;/li&gt; &#xA; &lt;li&gt;The purpose is to help prepare you for interviews.&lt;/li&gt; &#xA; &lt;li&gt;The last week of class will be dedicated to prep.&lt;/li&gt; &#xA; &lt;li&gt;The final grade can replace your lowest midterm grade, if that would improve your overall grade in the class.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This is a &lt;strong&gt;hard&lt;/strong&gt; class.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;The material is intrinsically hard&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Very few people find linear algebra, statistics and programming to ALL be easy subjects, and this class combines them all&lt;/li&gt; &#xA;   &lt;li&gt;There&#39;s a reason people who understand this material get paid big salaries at FAANG&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You will have to read the required references.&lt;/p&gt; &lt;p&gt;Not all the material will be covered in lectures, and that&#39;s intentional to force you to get practice reading research-level data mining text.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Comments from previous students:&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt; &#xA;    &lt;blockquote&gt; &#xA;     &lt;p&gt;Holy fucking shit this was a hard class. I had no idea there was so much god damned fucking math involved in a CS class. You should warn students about that.&lt;/p&gt; &#xA;    &lt;/blockquote&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &#xA;    &lt;blockquote&gt; &#xA;     &lt;p&gt;I spent 20+ hours per week on this class, and still only got a B. The class is too hard and you should make it easier.&lt;/p&gt; &#xA;    &lt;/blockquote&gt; &lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;p&gt;Unfortunately, I can&#39;t remove the math from this class, and I can&#39;t make the class easier. Otherwise, you wouldn&#39;t be learning the material needed to pass a technical interview / get a good job / go to grad school.&lt;/p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mikeizbicki/cmc-csci145-math166/2022fall/math.webp&#34;&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; In all of my other courses, I include required reading/watching tasks to learn about CS/DS culture. This course doesn&#39;t have these tasks because there is already a LOT of textbook reading that you will have to complete.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;Late Work Policy:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You lose 20% on projects for each day late. It is still typically better to submit a correct assignment late than an incorrect one on time.&lt;/p&gt; &#xA;&lt;p&gt;If you collaborate with other students, you get an automatic 2 day extension on any project.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Collaboration Policy:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You are encouraged to discuss all labs and projects with other students, subject to the following constraints:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;you must be the person typing in all code for your assignments, and&lt;/li&gt; &#xA; &lt;li&gt;you must not copy another student&#39;s code.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You may use any online resources you like as references.&lt;/p&gt; &#xA;&lt;p&gt;Basically, I&#39;m trusting you all to be adults. You are ultimately responsible for ensuring you learn the material! So do what will help you learn best.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;WARNING:&lt;/strong&gt; All material in this class is cumulative. If you work &#34;too closely&#34; with another student on an assignment, you won&#39;t understand how to complete subsequent assignments, and you will quickly fall behind. You should view collaboration as a way to improve your understanding, not as a way to do less work.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!--&#xA;## Schedule&#xA;&#xA;| Homework              | Topic                                         |&#xA;| --------------------- | --------------------------------------------- |&#xA;| 1                     | Review                                        |&#xA;| 2                     | Pagerank: math                                |&#xA;| 3                     | Pagerank: implementation                      |&#xA;| 4                     | SLT: math                                     |&#xA;| 5                     | SLT: implementation (theoretical)             |&#xA;| 6                     | SLT: implementation (practical)               |&#xA;| 7                     | SGD: math                                     |&#xA;| 8                     | SGD: implementation                           |&#xA;| 9                     | Word2Vec                                      |&#xA;| 11                    | Sentiment Analysis                            |&#xA;&#xA;| Week | Date        | Topic                                                                |&#xA;| ---- | ----------- | -------------------------------------------------------------------- |&#xA;| 1    | Mon, Aug 24 | Course intro                                                         |&#xA;| 1    | Wed, Aug 26 | Computational Linear Algebra                                         |&#xA;| 2    | Mon, Aug 31 | Pagerank                                                             |&#xA;| 2    | Wed, Sep 2  | Pagerank                                                             |&#xA;| 3    | Mon, Sep 7  | Statistical Learning Theory                                          |&#xA;| 3    | Wed, Sep 9  | Statistical Learning Theory                                          |&#xA;| 4    | Mon, Sep 14 | Statistical Learning Theory                                          |&#xA;| 4    | Wed, Sep 16 | Statistical Learning Theory                                          |&#xA;| 5    | Mon, Sep 21 | Logistic Regression                                                  |&#xA;| 5    | Wed, Sep 23 | Logistic Regression                                                  |&#xA;| 6    | Mon, Sep 28 | Kernels / neural networks / k-nearest neighbor / decision trees      |&#xA;| 6    | Wed, Sep 30 | Kernels / neural networks / k-nearest neighbor / decision trees      |&#xA;| 7    | Mon, Oct 5  | Stochastic gradient descent                                          |&#xA;| 7    | Wed, Oct 7  | Stochastic gradient descent                                          |&#xA;| 8    | Mon, Oct 12 | Regularization                                                       |&#xA;| 8    | Wed, Oct 14 | Regularization                                                       |&#xA;| 9    | Mon, Oct 19 | Hashing trick / random projections                                   |&#xA;| 9    | Wed, Oct 21 | Hashing trick / random projections                                   |&#xA;| 10   | Mon, Oct 26 | Word2Vec                                                             |&#xA;| 10   | Wed, Oct 28 | Word2Vec                                                             |&#xA;| 11   | Mon, Nov 2  | Word2Vec: FastText                                                   |&#xA;| 11   | Wed, Nov 4  | Word2Vec: translation  |&#xA;| 12   | Mon, Nov 9  | Word2Vec: bias                                                       |&#xA;| 12   | Wed, Nov 11 | Word2Vec: history                                                    |&#xA;| 13   | Mon, Nov 16 | Other Applications                                                   |&#xA;| 13   | Wed, Nov 18 | Other Applications                                                   |&#xA;| 14   | Mon, Nov 23 | Other Applications                                                   |&#xA;--&gt; &#xA;&lt;!--&#xA;| Week | Date | Topic | Assignment |&#xA;| ---- | --- | --- | --- |&#xA;| 1  | Tues, 3 Sept  | &lt;p&gt;Introduction&lt;/p&gt; Examples:&lt;ol&gt;&lt;li&gt;[/r/dataisbeautiful](https://www.reddit.com/r/dataisbeautiful/top/)&lt;li&gt;okcupid [pictures](https://theblog.okcupid.com/dont-be-ugly-by-accident-b378f261dea4), [messages](https://theblog.okcupid.com/exactly-what-to-say-in-a-first-message-2bf680806c72), and [lies](https://theblog.okcupid.com/the-big-lies-people-tell-in-online-dating-a9e3990d6ae2)&lt;li&gt;[NLP analysis of net neutrality comments](https://medium.com/hackernoon/more-than-a-million-pro-repeal-net-neutrality-comments-were-likely-faked-e9f0e3ed36a6)&lt;li&gt;[sattelite images of cars affect stock prices](https://theoutline.com/post/1169/jc-penney-satellite-imaging?zd=1&amp;zi=qmayberw)&lt;li&gt;[digitalnk: gender and North Korean posters](https://digitalnk.com/blog/2017/09/30/gender-distribution-in-north-korean-posters/); [posters](https://www.businessinsider.com/kim-jong-il-kim-jong-un-north-korea-propoganda-2011-12)&lt;/ol&gt;Ethics:&lt;ol&gt;&lt;li&gt;[Target and pregnancy](https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html?pagewanted=1&amp;_r=1&amp;hp)&lt;li&gt;[Data mining algorithms determine prison time](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)&lt;li&gt;[Google Gorilla mistake](https://twitter.com/jackyalcine/status/615329515909156865)&lt;/ol&gt; | HW 0 |&#xA;| 1  | Thur, 5 Sept  | Bishop 1.2: Probability Theory Review | |&#xA;| 2  | Tues, 10 Sept | Bishop 1.3-1.6: Introduction to Machine Learning | |&#xA;| 2  | Thur, 12 Sept | Bishop 1.3-1.6: Introduction to Machine Learning | Project (proposal)&lt;br/&gt;HW 1 |&#xA;| 3  | Tues, 17 Sept | **NO CLASS** (Mike at [ECML-PKDD](http://ecmlpkdd2019.org/)) | |&#xA;| 3  | Thur, 19 Sept | **NO CLASS** (Mike at [ECML-PKDD](http://ecmlpkdd2019.org/)) |  |&#xA;| 4  | Tues, 24 Sept | Bishop 3.1: Regression: Linear Regression | |&#xA;| 4  | Thur, 26 Sept | Bishop 3.2: Regression: The Bias-Variance Trade-off | Quiz 1 |&#xA;| 5  | Tues, 1 Oct   | Bishop 4.1: Classification: Discriminant Functions | |&#xA;| 5  | Thur, 3 Oct   | Bishop 4.2: Classification: Generative Models | |&#xA;| 6  | Tues, 8 Oct   | Bishop 4.3: Classification: Discriminative Models | HW 2 |&#xA;| 6  | Thur, 10 Oct  | [Leon Bottou&#39;s SGD paper](https://datajobs.com/data-science-repo/Stochastic-Gradient-Descent-[Leon-Bottou].pdf) | |&#xA;| 7  | Tues, 15 Oct  | Text Processing: [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model#Example_usage:_spam_filtering), [tf-idf](https://skymind.ai/wiki/bagofwords-tf-idf), [n-grams](https://en.wikipedia.org/wiki/N-gram),[hashing trick](https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087), [zipf&#39;s law](https://en.wikipedia.org/wiki/Zipf%27s_law) &lt;br/&gt;Python NLP libraries: [TextBlob](https://textblob.readthedocs.io/en/dev/), [spacy](https://spacy.io/), [neuralcoref](https://github.com/huggingface/neuralcoref), [NLTK](https://www.nltk.org/), [textstat](https://pypi.org/project/textstat/) | Quiz 2&lt;br/&gt;Project (checkup) |&#xA;| 7  | Thur, 17 Oct  | Text Processing: word2vec [high level overview](https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/), [details with math](http://arxiv.org/pdf/1402.3722v1.pdf) | |&#xA;| 8  | Tues, 22 Oct  | **NO CLASS** (Fall Break) | |&#xA;| 8  | Thur, 24 Oct  | Text Processing: more word2vec | |&#xA;| 9  | Tues, 29 Oct  | Text Processing: [translating with word2vec](https://arxiv.org/abs/1309.4168), [doc2vec](https://arxiv.org/abs/1405.4053), [fastText](https://fasttext.cc) | HW 3 |&#xA;| 9  | Thur, 31 Oct  | more word2vec examples: [gender bias](http://wordbias.umiacs.umd.edu/), [racial bias](https://www.pnas.org/content/115/16/E3635/tab-figures-data), [histwords](https://nlp.stanford.edu/projects/histwords/), [temporal word analogies](https://www.aclweb.org/anthology/P17-2071/) [political words](https://arxiv.org/abs/1711.05603)&lt;br/&gt;exploiting Twitter metadata: [trump tweets](http://varianceexplained.org/r/trump-tweets/) |  |&#xA;| 10 | Tues, 5 Nov   | **NO CLASS** (Mike at [CIKM 2019](http://www.cikm2019.net/)) | |&#xA;| 10 | Thur, 7 Nov   | **NO CLASS** (Mike at [CIKM 2019](http://www.cikm2019.net/)) |  |&#xA;| 11 | Tues, 12 Nov  | Linear algebra review | |&#xA;| 11 | Thur, 14 Nov  | Bishop 12.1: The multivariate gaussian / PCA&lt;br&gt;[Lecture Notes from Berkeley](https://people.eecs.berkeley.edu/~jrs/189/lec/08.pdf) | ~~HW 4~~ |&#xA;| 12 | Tues, 19 Nov  | Bishop 12.1: The multivariate gaussian / PCA | |&#xA;| 12 | Thur, 21 Nov  | Bishop 12.1: The multivariate gaussian / PCA&lt;br/&gt;&lt;a href=&#39;https://colah.github.io/posts/2014-10-Visualizing-MNIST/&#39;&gt;Colah&#39;s Visualizing MNIST&lt;/a&gt; | |&#xA;| 13 | Tues, 26 Nov  | Bishop 9.2: Mixtures of Gaussians / k-means clustering&lt;br/&gt;Scikit learn &lt;a href=&#39;https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html&#39;&gt;1&lt;/a&gt;, &lt;a href=&#39;https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html#sphx-glr-auto-examples-cluster-plot-kmeans-assumptions-py&#39;&gt;2&lt;/a&gt;, &lt;a href=&#39;https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_covariances.html#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&#39;&gt;3&lt;/a&gt;, &lt;a href=&#39;https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm.html#sphx-glr-auto-examples-mixture-plot-gmm-py&#39;&gt;4&lt;/a&gt;, &lt;a href=&#39;https://www.naftaliharris.com/blog/visualizing-k-means-clustering/&#39;&gt;visualizing k-means&lt;/a&gt; | ~~Quiz 3~~ |&#xA;| 13 | Thur, 28 Nov  | **NO CLASS** (Thanksgiving) |  |&#xA;| 14 | Tues, 3 Dec   | Bishop 7.1: SVMs&lt;br/&gt;[youtube](https://www.youtube.com/watch?v=3liCbRZPrZA), [youtube](https://www.youtube.com/watch?v=ndNE8he7Nnk), [scikit-learn](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html) | HW 5 |&#xA;| 14 | Thur, 5 Dec   | Bishop 6.1,6.2: Kernel methods | |&#xA;| 15 | Tues, 10 Dec  | Bishop 5.1: Neural networks | |&#xA;| 15 | Thur, 12 Dec  | Project Presentations | |&#xA;--&gt; &#xA;&lt;!--&#xA;Bishop 5.1: Feed Forward Neural Networks | HW 4 |&#xA;Bishop 6.1,6.2: Kernel Methods | Quiz 3 |&#xA;Bishop 6.4.1-6.4.3: Gaussian Processes |  |&#xA;Bishop 7.1: Support Vector Machines | |&#xA;Bishop 9.1: K-Means Clustering | HW 5 |&#xA;**NO CLASS** (Thanksgiving) |  |&#xA;Bishop 9.2: Mixtures of Gaussians |  |&#xA;Hierarchical clustering | |&#xA;Bishop 12.1: Principle Component Analysis |  |&#xA;The hashing trick (revisited) | Quiz 4 |&#xA;--&gt; &#xA;&lt;!--&#xA;Possible topics:&#xA;1. Leon Bottou&#39;s large scale learning with stochastic gradient descent / stochastic gradient descent tricks&#xA;1. Fully understanding the hashing trick&#xA;1. Feature hashing for large scale multitask learning&#xA;1. Random Projections and the Johnson-Lindenstrauss Lemma&#xA;--&gt; &#xA;&lt;!--&#xA;## Ethics&#xA;&#xA;* Microsoft Tay&#xA;&#xA;* Target: https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/&#xA;&#xA;* Crime recidivism: https://advances.sciencemag.org/content/4/1/eaao5580.full https://www.heinz.cmu.edu/media/2017/january/automate-fairness-machine-learning-discrimination https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing&#xA;&#xA;* Self driving cars: https://www.nytimes.com/2018/03/19/technology/uber-driverless-fatality.html&#xA;&#xA;* Images: https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai&#xA;&#xA;* https://freedom-to-tinker.com/2019/08/23/deconstructing-googles-excuses-on-tracking-protection/&#xA;&#xA;* Border security:&#xA;https://www.reddit.com/r/legaladvice/comments/cyr3g3/i_am_an_american_citizen_yesterday_at_lax_i_was/&#xA;https://www.reddit.com/r/privacy/comments/cwxp0q/harvard_student_denied_entry_into_us_due_to/&#xA;--&gt; &#xA;&lt;!--&#xA;## Collaboration Policy&#xA;&#xA;You are encouraged to discuss all labs, homeworks, and online quizzes with other students,&#xA;subject to the following constraints:&#xA;&#xA;1. you must be the person typing in all code for your assignments, and&#xA;1. you may not look at another student&#39;s assignment.&#xA;&#xA;You may use any online resources you like as references.&#xA;--&gt; &#xA;&lt;!--&#xA;## Self Grading&#xA;&#xA;[An outlook on self-assessment of homework assignments in higher mathematics education](https://link.springer.com/article/10.1186/s40594-018-0146-z)&#xA;&#xA;Also *Your* Job to Learn! Helping Students Reflect on their Learning Progress&#xA;&#xA;Should you Allow your Students to Grade their own Homework?&#xA;&#xA;Peer and Self Assessment in Massive Online Classes&#xA;--&gt; &#xA;&lt;h2&gt;Accommodations for Disabilities&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;ve tried to design the course to be as accessible as possible for all students. If you need any further accommodations---even if you don&#39;t have an officially recognized disability---please ask.&lt;/p&gt; &#xA;&lt;p&gt;I want you to succeed and I&#39;ll make every effort to ensure that you can.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>begemotv2718/matan</title>
    <updated>2022-09-02T01:38:05Z</updated>
    <id>tag:github.com,2022-09-02:/begemotv2718/matan</id>
    <link href="https://github.com/begemotv2718/matan" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Этот микропроект -- попытка написать учебник по матану немного с другой стороны, не начиная с понятия предела, непрерывной функции, дифференцирования функции, а сразу, начиная от представления функций бесконечными рядами. При этом мы ограничиваемся, конечно, только аналитическими функциями, но с ними проще начинать жить и именно они составляют основную часть функций, встречающихся на практике. Под конец можно будет поговорить о кусочно аналитических функциях, чем и исчерпать почти все, что можно встретить в непатологических ситуациях.&lt;/p&gt;</summary>
  </entry>
</feed>