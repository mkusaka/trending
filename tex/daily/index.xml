<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-07T01:42:03Z</updated>
  <subtitle>Daily Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>sczhou/Awesome-Face-Restoration</title>
    <updated>2022-10-07T01:42:03Z</updated>
    <id>tag:github.com,2022-10-07:/sczhou/Awesome-Face-Restoration</id>
    <link href="https://github.com/sczhou/Awesome-Face-Restoration" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A curated list of face restoration &amp; enhancement papers and resources&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome Face Restoration &amp;amp; Enhancement&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/sindresorhus/awesome&#34;&gt;&lt;img src=&#34;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true&#34; alt=&#34;Awesome&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/Collection-Keep%20Updating-green&#34; alt=&#34;collection&#34;&gt; &lt;img src=&#34;https://visitor-badge.laobi.icu/badge?page_id=sczhou/Awesome-Face-Restoration&#34; alt=&#34;visitors&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A curated list of awesome face restoration &amp;amp; enhancement papers and resources &lt;span&gt;üê≥&lt;/span&gt;, inspired by &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF&#34;&gt;awesome-NeRF&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Welcome to add papers and other resources related to this topic &lt;a href=&#34;https://github.com/sczhou/Awesome-Face-Restoration/raw/master/how-to-PR.md&#34;&gt;[submit a pull request]&lt;/a&gt; &lt;span&gt;ü§ó&lt;/span&gt;&lt;/h4&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/#papers&#34;&gt;Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/#survey&#34;&gt;Survey&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/#datasets&#34;&gt;Datasets&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Papers&lt;/h2&gt; &#xA;&lt;h4&gt;Generative Prior - VQGAN&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[NeurIPS 2022]&lt;/code&gt; CodeFormer: Towards Robust Blind Face Restoration with Codebook Lookup Transformer, Zhou et al. &lt;a href=&#34;https://arxiv.org/abs/2206.11253&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://shangchenzhou.com/projects/CodeFormer/&#34;&gt;Project&lt;/a&gt; | &lt;a href=&#34;https://github.com/sczhou/CodeFormer&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/sczhou/CodeFormer&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L1-L6&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[ECCV 2022]&lt;/code&gt; VQFR: Blind Face Restoration with Vector-Quantized Dictionary and Parallel Decoder, Gu et al. &lt;a href=&#34;https://arxiv.org/abs/2205.06803&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://ycgu.site/projects/vqfr/&#34;&gt;Project&lt;/a&gt; | &lt;a href=&#34;https://github.com/sczhou/CodeFormer&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L8-L13&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[CVPR 2022]&lt;/code&gt; RestoreFormer: High-Quality Blind Face Restoration from Undegraded Key-Value Pairs, Wang et al. &lt;a href=&#34;https://arxiv.org/abs/2201.06374&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://github.com/wzhouxiff/RestoreFormer&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L15-L20&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Generative Prior - StyleGAN2&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[CVPR 2021]&lt;/code&gt; GFPGAN: Towards Real-World Blind Face Restoration with Generative Facial Prior, Wang et al. &lt;a href=&#34;https://arxiv.org/abs/2101.04061&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://xinntao.github.io/projects/gfpgan&#34;&gt;Project&lt;/a&gt; | &lt;a href=&#34;https://github.com/TencentARC/GFPGAN&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/Xintao/GFPGAN&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L43-L48&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[CVPR 2021]&lt;/code&gt; GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution, Chan et al. &lt;a href=&#34;https://arxiv.org/abs/2012.00739&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://mmlab-ntu.github.io/project/glean/&#34;&gt;Project&lt;/a&gt; | &lt;a href=&#34;https://github.com/open-mmlab/mmediting&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L36-L41&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;[CVPR 2021]&lt;/code&gt; GPEN: GAN Prior Embedded Network for Blind Face Restoration in the Wild, Yang et al. &lt;a href=&#34;https://arxiv.org/abs/2105.06070&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://github.com/yangxy/GPEN&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L50-L55&#34;&gt;Bibtex&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;GAN Inversion&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;[CVPR 2020]&lt;/code&gt; PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models, Menon et al. &lt;a href=&#34;https://arxiv.org/abs/2003.03808&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://github.com/adamian98/pulse&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L64-L69&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Dictionary Learning&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;[ECCV 2020]&lt;/code&gt; DFDNet: Blind Face Restoration via Deep Multi-scale Component Dictionaries, Li et al. &lt;a href=&#34;https://arxiv.org/abs/2008.00418&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://github.com/csxmli2016/DFDNet&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L22-L27&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Reference/Exemplar Prior&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;[CVPR 2020]&lt;/code&gt; ASFFNet: Enhanced Blind Face Restoration With Multi-Exemplar Images and Adaptive Spatial Feature Fusion, Li et al. &lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Enhanced_Blind_Face_Restoration_With_Multi-Exemplar_Images_and_Adaptive_Spatial_CVPR_2020_paper.pdf&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://github.com/csxmli2016/ASFFNet&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L57-L62&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Geometry Facial Prior&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;[CVPR 2021]&lt;/code&gt; PSFRGAN: Progressive Semantic-Aware Style Transformation for Blind Face Restoration, Chen et al. &lt;a href=&#34;https://arxiv.org/abs/2009.08709&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://github.com/chaofengc/PSFRGAN&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L29-L34&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;3D Face Shape Prior&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;[CVPR 2022]&lt;/code&gt; SGPN: Blind Face Restoration via Integrating Face Shape and Generative Priors, Zhu et al. &lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Blind_Face_Restoration_via_Integrating_Face_Shape_and_Generative_Priors_CVPR_2022_paper.pdf&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L71-L76&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Personalized Restoration&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;[ArXiv 2022]&lt;/code&gt; MyStyle: A Personalized Generative Prior, Nitzan et al. &lt;a href=&#34;https://arxiv.org/abs/2203.17272&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://github.com/google/mystyle&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://mystyle-personalized-prior.github.io/&#34;&gt;Project&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/sczhou/Awesome-Face-Restoration/master/facebib.bib#L78-L83&#34;&gt;Bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Survey&lt;/h2&gt; &#xA;&lt;p&gt;(TBD)&lt;/p&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;h4&gt;High-Resolution&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Dataset&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Resolution&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/NVlabs/ffhq-dataset&#34;&gt;FFHQ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1024 x 1024&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;7,0000 high-quality face images (usually used for training)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/nperraud/download-celebA-HQ&#34;&gt;CelebA-HQ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1024 x 1024&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3,0000 high-quality face images (usually used for evaluation)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/switchablenorms/CelebAMask-HQ&#34;&gt;CelebAMask-HQ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;512 x 512&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3,0000 face images with 19 facial classes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/csxmli2016/DMDNet&#34;&gt;CelebRef-HQ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;512 x 512&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;high-quality face images with multiple same-identity references&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Low-Resolution&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Dataset&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html&#34;&gt;CelebA&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;a large-scale face attributes dataset with more than 200K celebrity images&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://shangchenzhou.com/projects/CodeFormer/&#34;&gt;WIDER-Test&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;970 real-world severely degraded face images from the &lt;a href=&#34;http://shuoyang1213.me/WIDERFACE/&#34;&gt;WIDER Face dataset&lt;/a&gt; (for test)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://xinntao.github.io/projects/gfpgan&#34;&gt;LFW-Test&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1711 real-world degraded faces collected from the &lt;a href=&#34;https://vis-www.cs.umass.edu/lfw/&#34;&gt;LFW dataset&lt;/a&gt; (for test)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://xinntao.github.io/projects/gfpgan&#34;&gt;WebPhoto-Test&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;407 real-world degraded faces collected from the Internet (for test)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://xinntao.github.io/projects/gfpgan&#34;&gt;CelebChild-Test&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;180 real-world degraded child faces collected from the Internet (for test)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Other Face Dataset&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Dataset&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ziqihuangg/CelebA-Dialog&#34;&gt;CelebA-Dialog&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;a large-scale visual-language face dataset with fine-grained labels and captions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ZhangYuanhan-AI/CelebA-Spoof&#34;&gt;CelebA-Spoof&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;a large-scale face anti-spoofing dataset with rich attributes and spoof types&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/csjliang/PPR10K&#34;&gt;PPR10K&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;a large-scale portrait photo retouching dataset&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>