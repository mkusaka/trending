<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-18T01:42:54Z</updated>
  <subtitle>Daily Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Seasawher/graduate_exam</title>
    <updated>2023-11-18T01:42:54Z</updated>
    <id>tag:github.com,2023-11-18:/Seasawher/graduate_exam</id>
    <link href="https://github.com/Seasawher/graduate_exam" rel="alternate"></link>
    <summary type="html">&lt;p&gt;京都大学数学系の院試の問題と解答です&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;graduate_exam&lt;/h1&gt; &#xA;&lt;h2&gt;はじめに&lt;/h2&gt; &#xA;&lt;p&gt;京都大学数学系の院試の過去問の解答です．平成19年から令和2年までの基礎問題と，代数の問題をおもにカバーしています．&lt;/p&gt; &#xA;&lt;p&gt;下記リンクにあるPDFが解答の本体です．&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Seasawher/graduate_exam/master/graduate_exam.pdf&#34;&gt;graduate_exam.pdf&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;code&gt;source&lt;/code&gt;というディレクトリにたくさんファイルがありますが，これは &lt;code&gt;graduate_exam.pdf&lt;/code&gt; を生成するためのTeXのソースコードなので，無視して構いません．&lt;/p&gt; &#xA;&lt;h2&gt;サポート&lt;/h2&gt; &#xA;&lt;p&gt;誤植の訂正などはいたしません．&lt;/p&gt; &#xA;&lt;h2&gt;謝辞&lt;/h2&gt; &#xA;&lt;p&gt;この解答を作るにあたって，協力してくださった方々に感謝します．&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;すむーずぷりんちゃん @mat_der_D　&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;には H31年度基礎 問4 を解いていただきました．以下の方も協力してくださいました．&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;キヅ &lt;a href=&#34;https://twitter.com/28Vittorio&#34;&gt;@28Vittorio&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ひろ &lt;a href=&#34;https://twitter.com/azureh97&#34;&gt;@azureh97&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;また，ナカトウ氏による解答も大変参考にさせていただきました．&lt;/p&gt; &#xA;&lt;p&gt;最後に，私が難しい問題に悩んでいるときにいつも適切なアドバイスをくれたM君にこの場を借りて謝意を表します．&lt;/p&gt; &#xA;&lt;h2&gt;お願い&lt;/h2&gt; &#xA;&lt;p&gt;私が院試を受験したころは，ネット上で入手できる解答例は断片的なものが大半で，「1問 550円」などと有料で販売されていたりしました．&lt;/p&gt; &#xA;&lt;p&gt;その状況に危機感を持ち，悪しき有料過去問をすべて駆逐するために作成したのがこの解答です．過去問解答は無料で誰でも入手できなければならないと思います．一緒に院試対策に取り組んだキヅさんも&lt;a href=&#34;http://s2s.undefin.net/wiki/?plugin=attach&amp;amp;pcmd=open&amp;amp;file=%E9%99%A2%E8%A9%A6%28%E5%B9%BE%E4%BD%95%29.pdf&amp;amp;refer=%E6%9C%A8%E6%B4%A5&#34;&gt;幾何の専門問題の解答を作成してくださった&lt;/a&gt;ので，私の年以降は無料の解答が一気に充実するようになりました．&lt;/p&gt; &#xA;&lt;p&gt;皆さんも，有料の解答をみかけても購入されないようお願いします．また，解答例を探している方を見かけたら，この解答をはじめとした無料の解答の存在を教えてあげてください．よろしくお願いします．&lt;/p&gt; &#xA;&lt;h2&gt;ライセンス&lt;/h2&gt; &#xA;&lt;p&gt;ライセンスは&lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/deed.ja&#34;&gt;CC BY-SA 4.0&lt;/a&gt;です．&lt;/p&gt; &#xA;&lt;p&gt;ただし問題文の著作権は，問題を作成された先生方にあります．&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>collaborativebioinformatics/DMDL_manuscript</title>
    <updated>2023-11-18T01:42:54Z</updated>
    <id>tag:github.com,2023-11-18:/collaborativebioinformatics/DMDL_manuscript</id>
    <link href="https://github.com/collaborativebioinformatics/DMDL_manuscript" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;hr&gt; &#xA;&lt;p&gt;title: &#39;The fourth annual Carnegie Mellon Libraries hackathon for biomedical data management, knowledge graphs, and deep learning&#39; tags:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;BioHackathon&lt;/li&gt; &#xA; &lt;li&gt;Biomedical data&lt;/li&gt; &#xA; &lt;li&gt;Large language models&lt;/li&gt; &#xA; &lt;li&gt;Knowledge graphs&lt;/li&gt; &#xA; &lt;li&gt;Deep learning&lt;/li&gt; &#xA; &lt;li&gt;FAIR data authors:&lt;/li&gt; &#xA; &lt;li&gt;name: Jędrzej Kubica orcid: 0000-0001-7037-3900 affiliation: 1&lt;/li&gt; &#xA; &lt;li&gt;name: Rachit Kumar orcid: 0000-0002-7736-3307 affiliation: 2,3&lt;/li&gt; &#xA; &lt;li&gt;name: Glenda Hui-En Tan orcid: 0009-0008-5892-9302 affiliation: 4&lt;/li&gt; &#xA; &lt;li&gt;name: Van Q. Truong orcid: 0000-0002-5485-1818 affiliation: 5,6&lt;/li&gt; &#xA; &lt;li&gt;name: Nicholas P. Cooley orcid: 0000-0002-6029-304X affiliation: 7&lt;/li&gt; &#xA; &lt;li&gt;name: Minhyek Jeon orcid: 0000-0001-5208-5921 affiliation: 8&lt;/li&gt; &#xA; &lt;li&gt;name: Chiao-Feng Lin orcid: 0000-0002-6177-8807 affiliation: 9&lt;/li&gt; &#xA; &lt;li&gt;name: Minh Tran orcid: 0009-0006-0010-9331 affiliation: 10&lt;/li&gt; &#xA; &lt;li&gt;name: Amrita Roy Choudhury orcid: 0000-0003-2795-7219 affiliation: 11&lt;/li&gt; &#xA; &lt;li&gt;name: Xinrong Du orcid: 0009-0004-6548-3688 affiliation: 12&lt;/li&gt; &#xA; &lt;li&gt;name: David Enoma orcid: 0000-0001-7300-8474 affiliation: 13&lt;/li&gt; &#xA; &lt;li&gt;name: Shashank Katiyar orcid: 0009-0004-2265-2883 affiliation: 14&lt;/li&gt; &#xA; &lt;li&gt;name: Andrew Lutsky orcid: 0000-0003-3168-7450 affiliation: 15&lt;/li&gt; &#xA; &lt;li&gt;name: Rajarshi Mondal affiliation: 16&lt;/li&gt; &#xA; &lt;li&gt;name: Aniket Naik orcid: 0009-0000-5853-3043 affiliation: 17&lt;/li&gt; &#xA; &lt;li&gt;name: Soham Shirolkar orcid: ​​0009-0004-4798-899X affiliation: 18&lt;/li&gt; &#xA; &lt;li&gt;name: Thomas Yu Chow Tam orcid: 0000-0002-1779-9512 affiliation: 19&lt;/li&gt; &#xA; &lt;li&gt;name: Qixin Amy Zhou orcid: 0009-0002-4297-3305 affiliation: 20&lt;/li&gt; &#xA; &lt;li&gt;name: Kristen Scotti orcid: 0000-0002-9529-5213 affiliation: 21&lt;/li&gt; &#xA; &lt;li&gt;name: Ben Busby orcid: 0000-0001-5267-4988 affiliation: 22&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;affiliations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;name: Laboratory of Functional and Structural Genomics, Centre of New Technologies, University of Warsaw, Warsaw, Poland index: 1&lt;/li&gt; &#xA; &lt;li&gt;name: Genomics and Computational Biology, Perelman School of Medicine at the University of Pennsylvania index: 2&lt;/li&gt; &#xA; &lt;li&gt;name: Medical Scientist Training Program, Perelman School of Medicine at the University of Pennsylvania index: 3&lt;/li&gt; &#xA; &lt;li&gt;name: Carnegie Mellon University index: 4&lt;/li&gt; &#xA; &lt;li&gt;name: Genomics and Computational Biology Graduate Group, University of Pennsylvania Perelman School of Medicine, 3700 Hamilton Walk, Philadelphia, PA, 19104, USA index: 5&lt;/li&gt; &#xA; &lt;li&gt;name: Institute for Biomedical Informatics, University of Pennsylvania Perelman School of Medicine, 3700 Hamilton Walk, Philadelphia, PA, 19104, USA index: 6&lt;/li&gt; &#xA; &lt;li&gt;name: No affiliation index: 7&lt;/li&gt; &#xA; &lt;li&gt;name: Computational Biology Department, Carnegie Mellon University index: 8&lt;/li&gt; &#xA; &lt;li&gt;name: No affiliation index: 9&lt;/li&gt; &#xA; &lt;li&gt;name: School of Computer Science, Carnegie Mellon University index: 10&lt;/li&gt; &#xA; &lt;li&gt;name: No affiliation index: 11&lt;/li&gt; &#xA; &lt;li&gt;name: Computational Biology Department, Carnegie Mellon University index: 12&lt;/li&gt; &#xA; &lt;li&gt;name: Cumming School of Medicine, University of Calgary,&amp;nbsp;3330 Hospital Dr NW, Calgary, AB T2N 4N1, Canada index: 13&lt;/li&gt; &#xA; &lt;li&gt;name: Computational Biology Department, Carnegie Mellon University index: 14&lt;/li&gt; &#xA; &lt;li&gt;name: No affiliation index: 15&lt;/li&gt; &#xA; &lt;li&gt;name: No affiliation index: 16&lt;/li&gt; &#xA; &lt;li&gt;name: Mellon College of Science, Carnegie Mellon University index: 17&lt;/li&gt; &#xA; &lt;li&gt;name: University of South Florida index: 18&lt;/li&gt; &#xA; &lt;li&gt;name: Carnegie Mellon University, Pittsburgh, PA 15213 index: 19&lt;/li&gt; &#xA; &lt;li&gt;name: No affiliation index: 20&lt;/li&gt; &#xA; &lt;li&gt;name: Carnegie Mellon University Libraries, Pittsburgh, PA 15213 index: 21&lt;/li&gt; &#xA; &lt;li&gt;name: DNAnexus, 1975 West El Camino Real Suite 101 Mountain View, CA 94040 index: 22&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;date: 22 November 2023 bibliography: paper.bib authors_short: Kubica J., Kumar R., Hui-En Tan G., Truong Q. V. \emph{et al.} group: Virus Susceptibility, Graph Based Tuning, VCFs to Knowledge Graphs, Knowledge Graphs Based Validation git_url: &lt;a href=&#34;https://github.com/collaborativebioinformatics/DMDL_manuscript&#34;&gt;https://github.com/collaborativebioinformatics/DMDL_manuscript&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h1&gt;Introduction&lt;/h1&gt; &#xA;&lt;p&gt;In October 2023, a group of 44 scientists hailing from several U.S. states, Canada, Poland, and Switzerland came together for a hybrid in-person and virtual hackathon. The event was jointly hosted by Carnegie Mellon University Libraries and DNAnexus, a California-based cloud computing and bioinformatics company. This collaborative effort revolved around the theme of “Data Management and Graph Extraction for Large Transformer Models in the Biomedical Space.” In the spirit of fostering collaboration, participants organized themselves into five teams, which ultimately resulted in the successful completion of four hackathon projects. These projects encompassed a wide range of topics, from detecting features contributing to virus susceptibility to validating models using knowledge graphs. Repositories for the hackathon projects are available at &lt;a href=&#34;https://github.com/collaborativebioinformatics&#34;&gt;https://github.com/collaborativebioinformatics&lt;/a&gt;. We hope that the insights and experiences shared by these teams, as detailed in the following manuscript, will prove valuable to the broader scientific community.&lt;/p&gt; &#xA;&lt;h2&gt;Code Availability:&lt;/h2&gt; &#xA;&lt;p&gt;Virus Susceptibility: &lt;a href=&#34;https://github.com/collaborativebioinformatics/virussusceptibility&#34;&gt;https://github.com/collaborativebioinformatics/virussusceptibility&lt;/a&gt; Graph Based Tuning: &lt;a href=&#34;https://github.com/collaborativebioinformatics/graphbasedtuning&#34;&gt;https://github.com/collaborativebioinformatics/graphbasedtuning&lt;/a&gt; VCFs to Knowledge Graphs: &lt;a href=&#34;https://github.com/collaborativebioinformatics/vcfs2kgs&#34;&gt;https://github.com/collaborativebioinformatics/vcfs2kgs&lt;/a&gt; Knowledge Graph Based Validation: &lt;a href=&#34;https://github.com/collaborativebioinformatics/kgbasedvalidation&#34;&gt;https://github.com/collaborativebioinformatics/kgbasedvalidation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Virus Susceptibility&lt;/h2&gt; &#xA;&lt;p&gt;The COVID-19 pandemic has generated a substantial body of scientific literature, prompting innovative approaches to address complex questions surrounding the disease [@wang_text_2021]. The Virus Susceptibility team employed vector comparison inferences to identify correlations between COVID-19 susceptibility and chronic diseases (e.g., cancer, hypertension, or diabetes). To enhance our search capabilities for relevant articles, we constructed vector databases using the CORD-19 dataset [@wang_cord-19_2020], These databases brought significant improvements in performance, scalability, and flexibility in searching for relevant articles using certain queries [@noauthor_httpswwwpineconeiolearnvector-database_nodate; @noauthor_httpslearnmicrosoftcomen-ussemantic-kernelmemoriesvector-db_nodate]. We tested our pipeline on both a subset of the CORD-19 dataset as well as on the entire dataset. Furthermore, we extended our efforts by creating a custom vector database using 40 articles within the CORD-19 dataset. These articles were processed using SPECTER, and we conducted subsequent tests to evaluate the retrieval capabilities of the corresponding articles..&lt;/p&gt; &#xA;&lt;h2&gt;Graph-Based Tuning&lt;/h2&gt; &#xA;&lt;p&gt;As large language models (LLMs) continue to improve in speed and accuracy, their applications in the biomedical field are becoming increasingly valuable. For instance, LLMs can be used in drug treatment recommendations for various diseases where time and precision are paramount [@thirunavukarasu_large_2023]. Additionally, empirical evidence shows that LLMs consistently outperform smaller language models in various complex and contextual tasks [@wei_emergent_2022]. However, for LLMs to provide accurate drug treatment recommendations, they must be trained on factually correct and updated training data, which often does not occur. Furthermore, it is also crucial for LLMs to answer queries based on given context [@chang_survey_2023], especially when taking into consideration scientific articles on precision medicine that often contain critical subtleties. Knowledge Graphs (KGs) have emerged as state-of-the-art methods for capturing relationships between data points, offering a means to supply LLMs with contextually relevant knowledge [@yasunaga_qa-gnn_2022]. Hence, an LLM fine-tuned on a KG can be given the ability to answer complex biomedical queries, addressing the above issues. Therefore, we believe that fine-tuning an LLM with knowledge graphs related to biomedicine can improve its ability in recommending drug treatment. In our experiments, we fine-tuned the Llama 2 model [@touvron_llama_2023] and benchmarked it against ChatGPT and the original Llama 2 models using medical queries. Our fine-tuned LLAMA2Glendalorian model is deployed on HuggingFace (llama-2-7b-glendalorian)[https://huggingface.co/tminh/llama-2-7b-glendalorian].&lt;/p&gt; &#xA;&lt;h2&gt;VCFs to Knowledge Graphs&lt;/h2&gt; &#xA;&lt;p&gt;As the field of medical knowledge continues to expand, clinicians are faced with the challenge of effectively integrating this wealth of information into the context of individual patient care. To fully harness the growing medical knowledge base for the benefit of patients, it is imperative that we find ways to represent existing biomedical knowledge alongside individual patient data. Previous efforts to integrate such knowledge have generally been limited to patients who have known mutations within a selected subset of genes [@zhao_po2rdf_2022]. Typically, the entire genetic profile of a patient is not taken into consideration, thereby limiting our ability to uncover novel therapeutic avenues. For example, if a patient carries a mutation in the EGFR gene, even though their tumor type doesn’t typically exhibit EGFR mutations, conventional clinical practice may overlook sequencing the EGFR gene to detect this mutation. Consequently, treatment options may not include drugs that have proven effective for patients with known EGFR mutations.&lt;/p&gt; &#xA;&lt;p&gt;In this component of the hackathon, we aimed to develop a proof-of-concept pipeline that is able to generate a clinical-genomic knowledge graph from cohort-based, large-scale genomics data (i.e., a VCF file or other genomic data storage format) and existing knowledge (e.g., clinical knowledge-bases or variant annotations). Enriching the graph in this way to make use of cohort-level information as well as more generalized knowledge from existing practice is the next step to ensuring precision medicine – that is, improving care for individual patients based on lessons that have been learned from previous patients.&lt;/p&gt; &#xA;&lt;p&gt;For this proof-of-concept, we utilized the publicly-available TCGA COAD-CPTAC dataset previously described in Vasaikar et. al., 2019 [@vasaikar_proteogenomic_2019] which contains 110 patient samples with associated clinical data; 106 of the patient samples include corresponding sequencing data. This dataset was chosen due to its robust clinical-genomic links and its public availability.&lt;/p&gt; &#xA;&lt;h2&gt;Knowledge Graph Based Validation&lt;/h2&gt; &#xA;&lt;p&gt;At their core, knowledge graphs consist of nodes representing concepts and edges relating those concepts. An illustrative example of this is a knowledge graph mapping genes to their known disease associations. However, constructing knowledge graphs often involves aggregating information from a variety of sources, and verifying the accuracy of relationships within these graphs against continually evolving knowledge can pose challenges.&lt;/p&gt; &#xA;&lt;p&gt;In the Knowledge Graph Based Validation project, we aimed to explore the applicability of large language models (LLMs) beyond general domains. Specifically, we sought to assess these capabilities of LLMs in three key areas: 1) understanding biomedical domain knowledge from research publications, 2) constructing knowledge graphs in formats such as Resource Description Format (RDF), and 3) comparing and validating inputs and relationships within knowledge graphs. To achieve this, we leveraged existing research publications such as PubMed to validate and identify relationships within these knowledge graphs using LLMs. Specifically, we sought to test whether large language models (LLMs) such as Vicuna, LLama2, or GPT-4 might offer a viable path to validating relationships within knowledge graphs. Our approach is novel in that we devised and implemented a structured way to pass in existing knowledge from the literature into LLMs, obtain parsed relationships, and compare these relationships to existing knowledge graphs and the relationships thereof to validate them.&lt;/p&gt; &#xA;&lt;h1&gt;Flow diagrams&lt;/h1&gt; &#xA;&lt;h2&gt;Virus Susceptibility&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/virus_susceptibility_workflow.png&#34; alt=&#34;Figure 1. Virus Susceptibility workflow.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 1.&lt;/strong&gt; Virus Susceptibility workflow.&lt;/p&gt; &#xA;&lt;h2&gt;Graph Based Tuning&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/graph_based_tuning_workflow.png&#34; alt=&#34;Figure 2.Graph Based Tuning workflow.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 2.&lt;/strong&gt; Graph Based Tuning workflow.&lt;/p&gt; &#xA;&lt;h2&gt;VCFs to Knowledge Graphs&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/vcfs_to_knowledge_graphs_workflow.png&#34; alt=&#34;Figure 3. VCFs to Knowledge Graphs workflow.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 3.&lt;/strong&gt; VCFs to Knowledge Graphs workflow.&lt;/p&gt; &#xA;&lt;h2&gt;Knowledge Graph Based Validation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/knowledge_graphs_based_validation_workflow.png&#34; alt=&#34;Figure 4. Knowledge Graph Based Validation workflow.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 4.&lt;/strong&gt; Knowledge Graph Based Validation workflow.&lt;/p&gt; &#xA;&lt;h1&gt;Methods&lt;/h1&gt; &#xA;&lt;h2&gt;Virus Susceptibility&lt;/h2&gt; &#xA;&lt;p&gt;The Jupyter notebooks used in this work are located in the scripts/ directory on the project GitHub page (&lt;a href=&#34;https://github.com/collaborativebioinformatics/virussusceptibility&#34;&gt;https://github.com/collaborativebioinformatics/virussusceptibility&lt;/a&gt;). The CORD-19 dataset [@wang_cord-19_2020] contains metadata and embeddings that are generated from Covid-19-related articles. We retrieved the embeddings with references to the original articles from the dataset. The embeddings were generated with SPECTER (Scientific Paper Embeddings using Citation-informed TransformERs) [@cohan_specter_2020], which is a pre-trained language model that can be used to generate high-quality article representations. The training of the model and its implementation details can be found in the original article [@cohan_specter_2020]. We created a vector database with &#39;insert&#39;, &#39;query&#39;, and &#39;retrieve&#39; methods [@noauthor_httpswwwlinkedincompulsevector-databases-demystified-part-2-building-your-own-adie-kaye_nodate]. Then, we inserted the CORD-19 embedding into the vector database. We downloaded SPECTER from GitHub (&lt;a href=&#34;https://github.com/allenai/specter&#34;&gt;https://github.com/allenai/specter&lt;/a&gt;) and used it to create an embedding for an example query (specifically, &#34;What combinations of features predispose cohorts to virus susceptibility?&#34;). Next, we compared the embedding of the example query with all of the embeddings in the dataset and ranked the comparisons according to cosine similarity. Thus, the highest-ranked paper retrieved should be the closest contextual match to the example query (i.e., the highest ranked paper should have the highest measure of cosine similarity). Remark: Cosine similarity turned out to be unsuitable for high-dimensional vector comparison. For this reason we reduced the dimensionality of vectors with random projection [@noauthor_httppeopleeedukeedulcarinp93pdf_nodate; @noauthor_httpstowardsdatasciencecomrandom-projection--python-705883a19e48_nodate]; specifically, Gaussian random projection [@noauthor_httpsscikit-learnorgstablemodulesgeneratesklearnrandom_projectiongaussianrandomprojectionhtml_nodate]. Then, we used cosine similarity to search for articles that showed the highest relevance with respect to the query. As a proof of principle, we created a dataset of ten articles and embedded the articles SPECTER [@cohan_specter_2020]. The embeddings were subsequently inserted into a vector database. Lastly, we tested the retrieval of the most relevant articles. The corresponding workflow is provided on the project GitHub page (&lt;a href=&#34;https://github.com/collaborativebioinformatics/virussusceptibility/scripts/query_custom_dataset.ipynb&#34;&gt;https://github.com/collaborativebioinformatics/virussusceptibility/scripts/query_custom_dataset.ipynb&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;Graph Based Tuning&lt;/h2&gt; &#xA;&lt;p&gt;Firstly, 38,617 drug-relationship-target triples were downloaded from the Therapeutic Target Database [@zhou_ttd_2023]. A knowledge graph was generated from 20 sample triples and is shown in &lt;strong&gt;Figure 5&lt;/strong&gt;. Then, we developed an algorithm to preprocess such triplets into a prompt-response format for LLAMA2 (see “inputdata.txt”). For instance, a sample prompt would be “[INST] Tell me more about the drug with ID D07OAC. [/INST]” and its corresponding response would be “Drug D07OAC is an inhibitor to target protein S5A2_HUMAN.”&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/kg_20_triplets.png&#34; alt=&#34;Figure 5. Knowledge graph generated from 20 sample triples.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 5.&lt;/strong&gt; Knowledge graph generated from 20 sample triples.&lt;/p&gt; &#xA;&lt;p&gt;Traditional fine-tuning approaches generally require retraining the last layers of the LLM, which is computationally-expensive. To overcome this, we leveraged QLora [@dettmers_qlora_2023], an efficient parameter tuning method that uses Low Rank Adaptation and Double Quantization to reduce training and inference costs. The Llama 2-7b [@touvron_llama_2023] model was fine-tuned on the preprocessed data for three epochs. Training was done on a NVIDIA Tesla A100 and training time was approximately three hours. Our fine-tuned model LLAMA2Glendalorian has been deployed on HuggingFace (&lt;a href=&#34;https://huggingface.co/tminh/llama-2-7b-glendalorian&#34;&gt;https://huggingface.co/tminh/llama-2-7b-glendalorian&lt;/a&gt;). Finally, our fine-tuned model was benchmarked against ChatGPT [@noauthor_openai_nodate] and the original Llama 2 model using the prompt “What can the drug with ID D0Y6UB do?”. The results are shown in the results section.&lt;/p&gt; &#xA;&lt;h2&gt;VCFs to Knowledge Graphs&lt;/h2&gt; &#xA;&lt;p&gt;We first acquired data from the TCGA COAD-CPTAC dataset, mentioned above and previously described in Vasaikar et. al., 2019 [@vasaikar_proteogenomic_2019]. This dataset consists of a MAF file (pre-converted from a VCF file) that provides data about subjects, the genetic variants they carry, and various annotations for those variants including: what genes they mapped to, the functional impact of those variants, and ClinVar annotations for variants that had a known clinical impact.&lt;/p&gt; &#xA;&lt;p&gt;To ensure data harmonization, especially when dealing with the potential integration of data across cohorts (although not implemented in this instance, but is feasible within this framework), we obtained MONDO concepts for various diseases from the MONDO database. Similarly, we acquired HUGO concepts for each gene. This approach enabled us to establish a unified representation for genes and diseases across various cohorts, addressing potential heterogeneity issues that are most likely to emerge across nodes in the graph between cohorts and where harmonization is critical.&lt;/p&gt; &#xA;&lt;p&gt;To reduce the number of variants included within the dataset as a proof-of-concept, we filtered the genes contained within the graph to only include those with ClinVar-annotated variants across the entire cohort. However, the same framework can be applied without this filtering step to substantially enrich the graph and enable possible link prediction and inference tasks (of which genes may be associated with disease, for example). The code to implement this is included in the repository (&lt;a href=&#34;https://github.com/collaborativebioinformatics/vcfs2kgs&#34;&gt;https://github.com/collaborativebioinformatics/vcfs2kgs&lt;/a&gt;) as a Python notebook &lt;code&gt;tcga_rdf.ipynb&lt;/code&gt; that can be run directly so long as the data is downloaded and provided, and a BioPortal API key is acquired (which can be done for free).&lt;/p&gt; &#xA;&lt;h2&gt;Knowledge Graph Based Validation&lt;/h2&gt; &#xA;&lt;p&gt;We accomplished evaluation of the LLMs by constructing an induced subset of an existing knowledge base known as DisGeNet, which is structured in a relational form as a knowledge graph. The induced subset consisted of three single nucleotide polymorphisms (SNP, aka variants) and the diseases associated with those variants, and it comprised the set of SNPs for which we tested this approach.&lt;/p&gt; &#xA;&lt;p&gt;For each SNP, we acquired a body of literature from PubMed by using the SNP name as a keyword for a PubMed search. The abstracts from the papers obtained were provided for each SNP to the model and the model was prompted to construct subject-predicate-object triplets from these abstracts. We evaluated this approach on multiple open-source or publicly available LLMs, including Vicuna-7b, Vicuna-13b, llama2-7b, codellama2-7b, and GPT-4. We used three overarching prompts for each of these models:&lt;/p&gt; &#xA;&lt;p&gt;Prompt 1: “User: Create subject predicate subject logic triplets using some motor vehicles and output it as a subject predicate subject logic triplet. An example subject predicate subject triplet could be Biliary Atresia - results in - biliary obstruction. Create 10 of these triplets.”&lt;/p&gt; &#xA;&lt;p&gt;Prompt 2: “User: Create subject predicate subject logic triplets using some genes and their disease associations and output it as a subject predicate subject logic triplet. An example subject predicate subject triplet could be Biliary Atresia - results in - biliary obstruction. Create 10 of these triplets.”&lt;/p&gt; &#xA;&lt;p&gt;Prompt 3: “Create subject predicate subject logic triplets using singlue nucleotide polymorphism rs rs113993960 and their disease associations and output it as a subject predicate subject logic triplet. An example subject predicate subject triplet could be Biliary Atresia - results in - biliary obstruction. Create10 of these triplets.” [sic]&lt;/p&gt; &#xA;&lt;p&gt;We then compared the results of these models to the DisGeNet associations. The code for all of these can be found in the repository (&lt;a href=&#34;https://github.com/collaborativebioinformatics/kgbasedvalidation/&#34;&gt;https://github.com/collaborativebioinformatics/kgbasedvalidation/&lt;/a&gt;) with documentation in the repository describing the required dependencies and installation instructions.&lt;/p&gt; &#xA;&lt;h1&gt;Discussion and/or Conclusion&lt;/h1&gt; &#xA;&lt;h2&gt;Virus Susceptibility&lt;/h2&gt; &#xA;&lt;p&gt;Building and querying the vector database that was previously created using the embeddings from the CORD-19 dataset didn&#39;t show the expected result (articles related to the topic of the query). This highlights a possibility for improvement in data and code reproducibility. Building our own custom vector database from the CORD-19 articles and querying it yields articles relevant to the query. For example, the query, “hypertension” Example results for a query “hypertension” shows provided search results that included an article related to cardiovascular diseases. This result can be found on the GitHub page. Querying the vector database with the embedded query takes only ~190 ms.&lt;/p&gt; &#xA;&lt;h2&gt;Graph Based Tuning&lt;/h2&gt; &#xA;&lt;p&gt;The results show that neither ChatGPT nor the original Llama model 2 were able to relate specific drug (ID: D0Y6UB) to the target protein (see &lt;strong&gt;Figures 6 and 7&lt;/strong&gt;), whereas our LLAMA2Glendalorian model suggested a putative target protein (POL_HV1B1) for the drug with the corresponding binding relationship (see &lt;strong&gt;Figure 8&lt;/strong&gt;). In most of our experiments, the improvement from the 13B models over the 7B models indicates that use of larger models – or leveraging smaller models – is warranted for questions in the biomedical domain that were appropriate for deep learning models, such as those involving many-to-many comparisons and finding contextualized etiologies.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/chat_gpt_response.png&#34; alt=&#34;Figure 6. Response from ChatGPT to the benchmark prompt.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 6.&lt;/strong&gt; Response from ChatGPT to the benchmark prompt.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/llama2_response.png.png&#34; alt=&#34;Figure 7. Response from the Llama 2 model to the benchmark prompt.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 7.&lt;/strong&gt; Response from the Llama 2 model to the benchmark prompt.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/llama2glendalorian_response.png&#34; alt=&#34;Figure 8. Response from the LLAMA2Glendalorian model to the benchmark prompt.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 8.&lt;/strong&gt; Response from the LLAMA2Glendalorian model to the benchmark prompt.&lt;/p&gt; &#xA;&lt;h2&gt;VCFs to Knowledge Graphs&lt;/h2&gt; &#xA;&lt;p&gt;The underlying relationships within the graph were constructed based on cohort-specific relationships (for example, whether patients have colon adenocarcinoma or not) as well as information acquired from existing clinical knowledge bases. A schema of the ideal graph construction has been provided (see &lt;strong&gt;Figure 9&lt;/strong&gt;), with dashed edges representing planned but not implemented (due to time constraints) relationships. Concepts contained within the graph constructed using this framework from the CPTAC dataset are described in &lt;strong&gt;Table 1&lt;/strong&gt; below and embedded within &lt;strong&gt;Figure 9&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/ideal_graph_construction.png&#34; alt=&#34;Figure 9. A schema of an ideal graph construction.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 9.&lt;/strong&gt; A schema of an ideal graph construction.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Table 1.&lt;/strong&gt; Concepts for the graph construction.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Concept&lt;/th&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Number&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Node Type&lt;/td&gt; &#xA;   &lt;td&gt;Sample&lt;/td&gt; &#xA;   &lt;td&gt;93&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Node Type&lt;/td&gt; &#xA;   &lt;td&gt;Gene&lt;/td&gt; &#xA;   &lt;td&gt;3302&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Node Type&lt;/td&gt; &#xA;   &lt;td&gt;Cancer Type&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Edge Type&lt;/td&gt; &#xA;   &lt;td&gt;isCancerTypeOf (connects Sample -&amp;gt; Cancer Type)&lt;/td&gt; &#xA;   &lt;td&gt;93&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Edge Type&lt;/td&gt; &#xA;   &lt;td&gt;hasHugoSymbol (connects Sample -&amp;gt; Gene)&lt;/td&gt; &#xA;   &lt;td&gt;15285&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Knowledge Graph Based Validation&lt;/h2&gt; &#xA;&lt;p&gt;The single nucleotide polymorphisms/variants that we evaluated are shown in &lt;strong&gt;Table 2&lt;/strong&gt;. These pairs were collected using the DisGeNET database, as described above. Some examples of the responses from the models tested are provided below in &lt;strong&gt;Figure 10&lt;/strong&gt;. Notably, many of the prompts including the abstracts exceeded the recommended context window for some of these models, and we note that prompts approaching the context window recommendation or exceeding it tended to lead to substantially worse performance.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Table 2.&lt;/strong&gt; Evaluated SNPs.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;SNP&lt;/th&gt; &#xA;   &lt;th&gt;Diseases&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs113993960&lt;/td&gt; &#xA;   &lt;td&gt;BRONCHIECTASIS&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs113993960&lt;/td&gt; &#xA;   &lt;td&gt;Stenosis of duodenum&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs113993960&lt;/td&gt; &#xA;   &lt;td&gt;Congenital bilateral aplasia of vas deferens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs113993960&lt;/td&gt; &#xA;   &lt;td&gt;Hereditary pancreatitis&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs113993960&lt;/td&gt; &#xA;   &lt;td&gt;Recurrent pancreatitis&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs113993960&lt;/td&gt; &#xA;   &lt;td&gt;Cystic Fibrosis&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs199473282&lt;/td&gt; &#xA;   &lt;td&gt;LONG QT SYNDROME 3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs199473282&lt;/td&gt; &#xA;   &lt;td&gt;Brugada Syndrome (disorder)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs199473282&lt;/td&gt; &#xA;   &lt;td&gt;Brugada Syndrome 1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs199473282&lt;/td&gt; &#xA;   &lt;td&gt;Long QT Syndrome&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs199473282&lt;/td&gt; &#xA;   &lt;td&gt;Hereditary bundle branch system defect&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Plaque, Amyloid&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Familial Amyloid Polyneuropathy, Type V&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Corneal dystrophy&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Corneal deposit&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Corneal Dystrophy, Lattice Type IIIA&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Dystrophy, granular&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Reis-Bucklers&#39; corneal dystrophy&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Corneal guttata&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Lattice corneal dystrophy Type I&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Amyloidosis&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Neoplasms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Granular Dystrophy, Corneal&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Thiel-Behnke corneal dystrophy&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Stromal Dystrophies, Corneal&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;rs121909211&lt;/td&gt; &#xA;   &lt;td&gt;Avellino corneal dystrophy&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/collaborativebioinformatics/DMDL_manuscript/main/figures/outputs_from_tested_llms.png&#34; alt=&#34;Figure 10. Outputs from the tested LLMs.&#34;&gt;&lt;br&gt; &lt;strong&gt;Figure 10.&lt;/strong&gt; Outputs from the tested LLMs.&lt;/p&gt; &#xA;&lt;h1&gt;Conclusion and Future Directions&lt;/h1&gt; &#xA;&lt;p&gt;The advent of large language models (LLMs) has provided a unique opportunity in the biomedical domain. LLMs have shown the capability in outputting code or file formats given natural language prompts, synthesizing data, and extracting relevant information from corpus.&lt;/p&gt; &#xA;&lt;h2&gt;Future Directions for the Teams Involved in this Hackathon&lt;/h2&gt; &#xA;&lt;h2&gt;Virus Susceptibility&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;•&#x9;Create a vector database of 1M CORD-19 articles&#xA;•&#x9;Develop a more efficient method to generate queries for the vector database&#xA;•&#x9;Use the vector database to ask complex scientific questions:&#xA;•&#x9;&#34;What combinations of features predispose cohorts to viral infections?&#34;&#xA;•&#x9;&#34;Which combinations differentially predispose individuals to chronic disease post infection?”&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Graph Based Tuning&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;•&#x9;Fine-tune LLMs onto additional biomedical KGs:&#xA;•&#x9;DrugBank/ROBOKOP &#xA;•&#x9;Protein-protein interactions&#xA;•&#x9;Drug-drug interactions&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;VCFs to Knowledge Graphs&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;•&#x9;Construct sample-sample edges from a genetic relatedness matrix, automatically identifying duplicates and related individuals across cohorts&#xA;•&#x9;Create disease-disease edges based on co-occurrence and different levels of granularity&#xA;•&#x9;Include gene-disease edges from DisGeNet&#xA;•&#x9;Include additional node attributes, e.g.:&#xA;•&#x9;Sample level: original cohort, sex, age &#xA;•&#x9;Gene level: gene type (protein-coding, noncoding, pseudogene)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Knowledge Graph Based Validation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;•&#x9;Compress prompts by summarizing abstracts further to reach context windows&#xA;•&#x9;Create an end to end pipeline using DisGeNET&#xA;•&#x9;Implement dynamic parameter tuning and queryable database formatting&#xA;•&#x9;Implement data structures for comparing SPO objects:&#xA;•&#x9;Q/A implement comparison of data structures&#xA;•&#x9;Implement key word predicates to limit the scope of keywords&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you or your colleagues are interested in collaborating on these or similar projects in a hackathon or professional setting, please contact &lt;a href=&#34;mailto:ben.busby@gmail.com&#34;&gt;ben.busby@gmail.com&lt;/a&gt;. If you have technical questions or issues, please put an issue into one of the github repositories listed below.&lt;/p&gt; &#xA;&lt;h1&gt;Data and software availability&lt;/h1&gt; &#xA;&lt;p&gt;All code is provided in the following GitHub repositories, which may include additional links to data repositories and Jupyter Notebooks. • &lt;a href=&#34;https://github.com/collaborativebioinformatics/virustrajectory&#34;&gt;https://github.com/collaborativebioinformatics/virustrajectory&lt;/a&gt; • &lt;a href=&#34;https://github.com/collaborativebioinformatics/graphbasedtuning&#34;&gt;https://github.com/collaborativebioinformatics/graphbasedtuning&lt;/a&gt; • &lt;a href=&#34;https://github.com/collaborativebioinformatics/vcfs2kgs&#34;&gt;https://github.com/collaborativebioinformatics/vcfs2kgs&lt;/a&gt; • &lt;a href=&#34;https://github.com/collaborativebioinformatics/kgbasedvalidation&#34;&gt;https://github.com/collaborativebioinformatics/kgbasedvalidation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Acknowledgements&lt;/h1&gt; &#xA;&lt;h2&gt;Carnegie Mellon Libraries&lt;/h2&gt; &#xA;&lt;p&gt;For providing space – in both Pittsburgh, PA and Palo Alto, CA – as well as refreshments and other logistical support. The authors would especially like to thank Tom Hughes and Melanie Gainey (palo alto coordinator)______???&lt;/p&gt; &#xA;&lt;h2&gt;DNAnexus&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to DNAnexus for providing compute for the hackathon, as well as the time of BB and CL.&lt;/p&gt; &#xA;&lt;h2&gt;Grant funding&lt;/h2&gt; &#xA;&lt;p&gt;Van Q. Truong is supported by the Microsoft Research PhD Fellowship and ACM SIGHPC Computational and Data Science Fellowship.&lt;/p&gt; &#xA;&lt;h1&gt;References&lt;/h1&gt;</summary>
  </entry>
  <entry>
    <title>cran/RFlocalfdr</title>
    <updated>2023-11-18T01:42:54Z</updated>
    <id>tag:github.com,2023-11-18:/cran/RFlocalfdr</id>
    <link href="https://github.com/cran/RFlocalfdr" rel="alternate"></link>
    <summary type="html">&lt;p&gt;❗ This is a read-only mirror of the CRAN R package repository. RFlocalfdr — Significance Level for Random Forest Impurity Importance Scores&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RFlocalfdr&lt;/h1&gt; &#xA;&lt;p&gt;Provides a method for setting the significance level of the MDI (mean decrease in impurity) importances from a random forest model. Based on an empirical Bayes model. See &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2022.04.06.487300v2&#34;&gt;https://www.biorxiv.org/content/10.1101/2022.04.06.487300v2&lt;/a&gt; Thresholding Gini Variable Importance with a single trained Random Forest: An Empirical Bayes Approach (Robert Dunne, Roc Reguant, Priya Ramarao-Milne, Piotr Szul, Letitia Sng, Mischa Lundberg, Natalie A. Twine, Denis C. Bauer) for full details.&lt;/p&gt; &#xA;&lt;p&gt;Until I figure out how to manage the cran repository:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;the data sets are not available in the cran version&lt;/li&gt; &#xA; &lt;li&gt;many of the examples are enclosed in &#34;dontrun&#34; environments&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install devtools from CRAN&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;RFlocalfdr&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Or from GitHub:&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&#34;parsifal9/RFlocalfdr&#34;, build_vignettes = TRUE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;library(RFlocalfdr)&#xA;vignette(&#34;simulated&#34;,package=&#34;RFlocalfdr&#34;)&#xA;vignette(&#34;Smoking&#34;,package=&#34;RFlocalfdr&#34;)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;GNU General Public License&lt;/p&gt;</summary>
  </entry>
</feed>