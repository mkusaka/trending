<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-05-31T01:55:20Z</updated>
  <subtitle>Daily Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>billryan/resume</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/billryan/resume</id>
    <link href="https://github.com/billryan/resume" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An elegant \LaTeX\ résumé template. 大陆镜像 https://gods.coding.net/p/resume/git&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Résumé&lt;/h1&gt; &#xA;&lt;p&gt;Hit branch &lt;a href=&#34;https://github.com/billryan/resume/tree/zh_CN&#34;&gt;zh_CN&lt;/a&gt; if you want a Simplified Chinese résumé.&lt;/p&gt; &#xA;&lt;p&gt;中文用户请前往 &lt;a href=&#34;https://github.com/billryan/resume/tree/zh_CN&#34;&gt;zh_CN&lt;/a&gt; 分支。&lt;/p&gt; &#xA;&lt;p&gt;An elegant \LaTeX\ résumé template, compiled with \XeLaTeX. Inspired by&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zachscrivena/simple-resume-cv&#34;&gt;zachscrivena/simple-resume-cv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ctan.org/pkg/res&#34;&gt;res&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.jianxu.net/en/files/JianXu_CV.pdf&#34;&gt;JianXu&#39;s CV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.stat.berkeley.edu/~paciorek/computingTips/Latex_template_creating_CV_.html&#34;&gt;paciorek&#39;s CV/Resume template&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.sharelatex.com/blog/2011/03/27/how-to-write-a-latex-class-file-and-design-your-own-cv.html&#34;&gt;How to write a LaTeX class file and design your own CV (Part 1) - ShareLaTeX&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Easy to further customize or extend&lt;/li&gt; &#xA; &lt;li&gt;Full support for unicode characters (e.g. CJK) with \XeLaTeX\&lt;/li&gt; &#xA; &lt;li&gt;Perfect Simplified Chinese fonts supported with Adobefonts&lt;/li&gt; &#xA; &lt;li&gt;FontAwesome 4.6.3 support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fork this repository&lt;/li&gt; &#xA; &lt;li&gt;Add information about you directly in GitHub&lt;/li&gt; &#xA; &lt;li&gt;Compile TeX file to PDF with &lt;a href=&#34;https://latexonline.cc/&#34;&gt;LaTeX.Online&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Can also use Overleaf for online compilation with &lt;a href=&#34;https://www.overleaf.com/latex/templates/bill-ryans-elegant-latex-resume/xcqmhktmzmsw&#34;&gt;template&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Sample Output&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/25968335/131621921-65ab1862-1f56-47ef-9d58-8d5149bec841.png&#34; alt=&#34;English&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25968335/131621960-1cafb3c2-114b-4e90-8b04-bd9b949a6e9d.png&#34; alt=&#34;English with photo&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25968335/131621980-c004f2a6-4199-4676-8a97-5d2cb165402f.png&#34; alt=&#34;简体中文&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/billryan/resume/files/3463503/resume.pdf&#34;&gt;English PDF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/billryan/resume/files/3463501/resume_photo.pdf&#34;&gt;English with photo PDF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/billryan/resume/files/3463502/resume-zh_CN.pdf&#34;&gt;简体中文 PDF&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Edit in Overleaf online Web &lt;a href=&#34;https://www.overleaf.com/latex/templates/bill-ryans-elegant-latex-resume/xcqmhktmzmsw&#34;&gt;template&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Compile tex on your Computer&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If you only need a résumé in English or have installed Adobe Simplified Chinese on your OS, &lt;strong&gt;It would be better to clone only the master branch,&lt;/strong&gt; since the Simplified Chinese fonts files are too large.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/billryan/resume.git --branch master --depth 1 --single-branch &amp;lt;folder&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://opensource.org/licenses/MIT&#34;&gt;The MIT License (MIT)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Copyrighted fonts are not subjected to this License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mszep/pandoc_resume</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/mszep/pandoc_resume</id>
    <link href="https://github.com/mszep/pandoc_resume" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Markdown Resume&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Markdown Resume&lt;/h1&gt; &#xA;&lt;h3&gt;Instructions&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/mszep/pandoc_resume&#xA;cd pandoc_resume&#xA;vim markdown/resume.md   # insert your own resume info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Local&lt;/h4&gt; &#xA;&lt;p&gt;Make everything&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Make specifics&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make pdf&#xA;make html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Dockerized&lt;/h4&gt; &#xA;&lt;p&gt;Make everything&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;p&gt;If not using &lt;code&gt;docker&lt;/code&gt; then you will need the following dependencies.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ConTeXt 0.6x&lt;/li&gt; &#xA; &lt;li&gt;pandoc 2.x &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;1.x is deprecated&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Last tested on the above versions and that&#39;s not to say the later versions won&#39;t work. Please try to use the latest versions when possible.&lt;/p&gt; &#xA;&lt;h4&gt;Debian / Ubuntu&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt install pandoc context&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Fedora&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo dnf install pandoc texlive-collection-context&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Arch&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo pacman -S pandoc texlive-core&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;OSX&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install pandoc&#xA;brew install --cask mactex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Make sure to add the directory &lt;code&gt;/Library/TeX/texbin/&lt;/code&gt; to your path or &lt;code&gt;context&lt;/code&gt; and &lt;code&gt;mtxrun&lt;/code&gt; will not be found.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export PATH=$PATH:/Library/TeX/texbin/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Troubleshooting&lt;/h3&gt; &#xA;&lt;h4&gt;Get versions&lt;/h4&gt; &#xA;&lt;p&gt;Check if the dependencies are up to date.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;context --version&#xA;pandoc --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Cannot process lua&lt;/h4&gt; &#xA;&lt;p&gt;Currently pandoc 1.x may be within your distro&#39;s repos and the latest version should be used. See the &lt;a href=&#34;https://github.com/jgm/pandoc/releases&#34;&gt;pandoc releases&lt;/a&gt; for your distro.&lt;/p&gt; &#xA;&lt;p&gt;e.g. for Debian / Ubuntu&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;wget https://github.com/jgm/pandoc/releases/download/2.2.1/pandoc-2.2.1-1-amd64.deb&#xA;sudo dpkg -i pandoc-2.2.1-1-amd64.deb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Context executable cannot be found&lt;/h4&gt; &#xA;&lt;p&gt;Some users have reported problems where their system does not properly find the ConTeXt executable, leading to errors like &lt;code&gt;Cannot find context.lua&lt;/code&gt; or similar. It has been found that running &lt;code&gt;mtxrun --generate&lt;/code&gt;, (&lt;a href=&#34;https://tex.stackexchange.com/questions/53892/texlive-2011-context-problem&#34;&gt;suggested on texlive-2011-context-problem&lt;/a&gt;), can fix the issue.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lervag/vimtex</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/lervag/vimtex</id>
    <link href="https://github.com/lervag/vimtex" rel="alternate"></link>
    <summary type="html">&lt;p&gt;VimTeX: A modern Vim and neovim filetype plugin for LaTeX files.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VimTeX&lt;/h1&gt; &#xA;&lt;p&gt;VimTeX is a modern &lt;a href=&#34;http://www.vim.org/&#34;&gt;Vim&lt;/a&gt; and &lt;a href=&#34;https://neovim.io/&#34;&gt;Neovim&lt;/a&gt; filetype and syntax plugin for LaTeX files.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/vimtex-chat/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/vimtex-chat/community.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://github.com/lervag/vimtex/workflows/CI%20tests/badge.svg?sanitize=true&#34; alt=&#34;CI tests&#34;&gt; &lt;a href=&#34;https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=5N4MFVXN7U8NW&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Donate-PayPal-green.svg?sanitize=true&#34; alt=&#34;Donate&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt; &#xA;&lt;!-- DON&#39;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#configuration&#34;&gt;Configuration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#quick-start&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#screenshots-and-gifs&#34;&gt;Screenshots and GIFs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#other-relevant-plugins&#34;&gt;Other relevant plugins&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#linting-and-syntax-checking&#34;&gt;Linting and syntax checking&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#snippets-and-templates&#34;&gt;Snippets and templates&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#tag-navigation&#34;&gt;Tag navigation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#alternatives&#34;&gt;Alternatives&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#vimtex-on-the-web&#34;&gt;VimTeX on the Web&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;VimTeX requires Vim version 8.0.1453 or Neovim version 0.4.3. The requirements were updated in July 2020 after the release of VimTeX 1.0. If you are stuck on older versions of Vim or Neovim, then you should not use the most recent version of VimTeX, but instead remain at the v1.0 tag.&lt;/p&gt; &#xA;&lt;p&gt;Some features require external tools. For example, the default compiler backend relies on &lt;a href=&#34;http://users.phys.psu.edu/~collins/software/latexmk-jcc/&#34;&gt;latexmk&lt;/a&gt;. Users are encouraged to read the requirements section in the &lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/doc/vimtex.txt&#34;&gt;documentation&lt;/a&gt; (&lt;code&gt;:h vimtex-requirements&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;If you use &lt;a href=&#34;https://github.com/junegunn/vim-plug&#34;&gt;vim-plug&lt;/a&gt;, then add the following line to your &lt;code&gt;vimrc&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;Plug &#39;lervag/vimtex&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or use some other plugin manager:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gmarik/vundle&#34;&gt;vundle&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Shougo/neobundle.vim&#34;&gt;neobundle&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tpope/vim-pathogen&#34;&gt;pathogen&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you use the new package feature in Vim, please note the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make sure to read and understand the package feature: &lt;code&gt;:help package&lt;/code&gt;!&lt;/li&gt; &#xA; &lt;li&gt;Use the &lt;code&gt;/pack/foo/start&lt;/code&gt; subdirectory to make sure the filetype plugin is automatically loaded for the &lt;code&gt;tex&lt;/code&gt; filetypes.&lt;/li&gt; &#xA; &lt;li&gt;Helptags are not generated automatically. Run &lt;code&gt;:helptags&lt;/code&gt; to generate them.&lt;/li&gt; &#xA; &lt;li&gt;Please note that by default Vim puts custom &lt;code&gt;/start/&lt;/code&gt; plugin directories at the end of the &lt;code&gt;&amp;amp;runtimepath&lt;/code&gt;. This means the built in filetype plugin is loaded, which prevents VimTeX from loading. See &lt;a href=&#34;https://github.com/lervag/vimtex/issues/1413&#34;&gt;#1413&lt;/a&gt; for two suggested solutions to this. To see which scripts are loaded and in which order, use &lt;code&gt;:scriptnames&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For more information on how to use the Vim native package solution, see &lt;a href=&#34;https://vi.stackexchange.com/questions/9522/what-is-the-vim8-package-feature-and-how-should-i-use-it&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://shapeshed.com/vim-packages/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;After installing VimTeX, you should edit your &lt;code&gt;.vimrc&lt;/code&gt; file or &lt;code&gt;init.vim&lt;/code&gt; file to configure VimTeX to your liking. Users should read the documentation to learn the various configuration possibilities, but the below is a simple overview of some of the main aspects.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;&#34; This is necessary for VimTeX to load properly. The &#34;indent&#34; is optional.&#xA;&#34; Note that most plugin managers will do this automatically.&#xA;filetype plugin indent on&#xA;&#xA;&#34; This enables Vim&#39;s and neovim&#39;s syntax-related features. Without this, some&#xA;&#34; VimTeX features will not work (see &#34;:help vimtex-requirements&#34; for more&#xA;&#34; info).&#xA;syntax enable&#xA;&#xA;&#34; Viewer options: One may configure the viewer either by specifying a built-in&#xA;&#34; viewer method:&#xA;let g:vimtex_view_method = &#39;zathura&#39;&#xA;&#xA;&#34; Or with a generic interface:&#xA;let g:vimtex_view_general_viewer = &#39;okular&#39;&#xA;let g:vimtex_view_general_options = &#39;--unique file:@pdf\#src:@line@tex&#39;&#xA;&#xA;&#34; VimTeX uses latexmk as the default compiler backend. If you use it, which is&#xA;&#34; strongly recommended, you probably don&#39;t need to configure anything. If you&#xA;&#34; want another compiler backend, you can change it as follows. The list of&#xA;&#34; supported backends and further explanation is provided in the documentation,&#xA;&#34; see &#34;:help vimtex-compiler&#34;.&#xA;let g:vimtex_compiler_method = &#39;latexrun&#39;&#xA;&#xA;&#34; Most VimTeX mappings rely on localleader and this can be changed with the&#xA;&#34; following line. The default is usually fine and is the symbol &#34;\&#34;.&#xA;let maplocalleader = &#34;,&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If the compiler or the viewer doesn&#39;t start properly, one may type &lt;code&gt;&amp;lt;localleader&amp;gt;li&lt;/code&gt; to view the system commands that were executed to start them. To inspect the compiler output, use &lt;code&gt;&amp;lt;localleader&amp;gt;lo&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;The following video shows how to use VimTeX&#39;s main features (credits: &lt;a href=&#34;https://github.com/DustyTopology&#34;&gt;@DustyTopology&lt;/a&gt; from &lt;a href=&#34;https://github.com/lervag/vimtex/issues/1946#issuecomment-846345095&#34;&gt;#1946&lt;/a&gt;). The example LaTeX file used in the video is available under &lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/test/example-quick-start/main.tex&#34;&gt;&lt;code&gt;test/example-quick-start/main.tex&lt;/code&gt;&lt;/a&gt; and it may be instructive to copy the file and play with it to learn some of these basic functions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/66584581/119213849-1b7d4080-ba77-11eb-8a31-7ff7b9a4a020.mp4&#34;&gt;https://user-images.githubusercontent.com/66584581/119213849-1b7d4080-ba77-11eb-8a31-7ff7b9a4a020.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Both new and experienced users are also encouraged to read the third-party article &lt;a href=&#34;https://ejmastnak.github.io/tutorials/vim-latex/vimtex.html&#34;&gt;Getting started with the VimTeX plugin&lt;/a&gt;. The article covers VimTeX&#39;s core features and contains plenty of examples and high-resolution animations intended to help new users ease into working with the plugin.&lt;/p&gt; &#xA;&lt;p&gt;Users are of course &lt;em&gt;strongly&lt;/em&gt; encouraged to read the documentation, at least the introduction, to learn about the different features and possibilities provided by VimTeX (see &lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/doc/vimtex.txt&#34;&gt;&lt;code&gt;:h vimtex&lt;/code&gt;&lt;/a&gt;). Advanced users and potential developers may also be interested in reading the supplementary documents:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/DOCUMENTATION.md&#34;&gt;DOCUMENTATION.md&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Screenshots and GIFs&lt;/h2&gt; &#xA;&lt;p&gt;Here is an example of the syntax highlighting provided by VimTeX. The conceal feature is active on the right-hand side split. The example is made by @DustyTopology with the &lt;a href=&#34;https://github.com/arzg/vim-colors-xcode&#34;&gt;vim-colors-xcode&lt;/a&gt; colorscheme with some minor adjustments &lt;a href=&#34;https://github.com/lervag/vimtex/issues/1946#issuecomment-843674951&#34;&gt;described here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/lervag/vimtex-media/raw/main/img/syntax.png&#34; alt=&#34;Syntax example&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Additionally, you can find animated demonstrations of VimTeX&#39;s core motions, text-editing commands, and text objects in the file &lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/VISUALS.md&#34;&gt;VISUALS.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;Below is a list of features offered by VimTeX. The features are accessible as both commands and mappings. The mappings generally start with &lt;code&gt;&amp;lt;localleader&amp;gt;l&lt;/code&gt;, but if desired one can disable default mappings to define custom mappings. Nearly all features are enabled by default, but each feature may be disabled if desired. The two exceptions are code folding and formating, which are disabled by default and must be manually enabled.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Document compilation with &lt;a href=&#34;http://users.phys.psu.edu/~collins/software/latexmk-jcc/&#34;&gt;latexmk&lt;/a&gt;, &lt;a href=&#34;https://github.com/aclements/latexrun&#34;&gt;latexrun&lt;/a&gt;, &lt;a href=&#34;https://tectonic-typesetting.github.io&#34;&gt;tectonic&lt;/a&gt;, or &lt;a href=&#34;https://github.com/cereda/arara&#34;&gt;arara&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;LaTeX log parsing for quickfix entries using &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;internal method&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/stefanhepp/pplatex&#34;&gt;pplatex&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Compilation of selected part of document&lt;/li&gt; &#xA; &lt;li&gt;Support for several PDF viewers with forward search &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://www.mupdf.com/&#34;&gt;MuPDF&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://okular.kde.org/&#34;&gt;Okular&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://launchpad.net/qpdfview&#34;&gt;qpdfview&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://skim-app.sourceforge.net/&#34;&gt;Skim&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://www.sumatrapdfreader.org/free-pdf-reader.html&#34;&gt;SumatraPDF&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://pwmt.org/projects/zathura/&#34;&gt;Zathura&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Other viewers are supported through a general interface&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Completion of &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;citations&lt;/li&gt; &#xA;   &lt;li&gt;labels&lt;/li&gt; &#xA;   &lt;li&gt;commands&lt;/li&gt; &#xA;   &lt;li&gt;file names for figures, input/include, includepdf, includestandalone&lt;/li&gt; &#xA;   &lt;li&gt;glossary entries&lt;/li&gt; &#xA;   &lt;li&gt;package and documentclass names based on available &lt;code&gt;.sty&lt;/code&gt; and &lt;code&gt;.cls&lt;/code&gt; files&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Document navigation through &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;table of contents&lt;/li&gt; &#xA;   &lt;li&gt;table of labels&lt;/li&gt; &#xA;   &lt;li&gt;proper settings for &lt;code&gt;&#39;include&#39;&lt;/code&gt;, &lt;code&gt;&#39;includexpr&#39;&lt;/code&gt;, &lt;code&gt;&#39;suffixesadd&#39;&lt;/code&gt; and &lt;code&gt;&#39;define&#39;&lt;/code&gt;, which among other things &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;allow &lt;code&gt;:h include-search&lt;/code&gt; and &lt;code&gt;:h definition-search&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;give enhanced &lt;code&gt;gf&lt;/code&gt; command&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Easy access to (online) documentation of packages&lt;/li&gt; &#xA; &lt;li&gt;Word count (through &lt;code&gt;texcount&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Motions &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Move between section boundaries with &lt;code&gt;[[&lt;/code&gt;, &lt;code&gt;[]&lt;/code&gt;, &lt;code&gt;][&lt;/code&gt;, and &lt;code&gt;]]&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Move between environment boundaries with &lt;code&gt;[m&lt;/code&gt;, &lt;code&gt;[M&lt;/code&gt;, &lt;code&gt;]m&lt;/code&gt;, and &lt;code&gt;]M&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Move between math environment boundaries with &lt;code&gt;[n&lt;/code&gt;, &lt;code&gt;[N&lt;/code&gt;, &lt;code&gt;]n&lt;/code&gt;, and &lt;code&gt;]N&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Move between frame environment boundaries with &lt;code&gt;[r&lt;/code&gt;, &lt;code&gt;[R&lt;/code&gt;, &lt;code&gt;]r&lt;/code&gt;, and &lt;code&gt;]R&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Move between comment boundaries with &lt;code&gt;[*&lt;/code&gt; and &lt;code&gt;]*&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Move between matching delimiters with &lt;code&gt;%&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Text objects &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;ic ac&lt;/code&gt; Commands&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;id ad&lt;/code&gt; Delimiters&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;ie ae&lt;/code&gt; LaTeX environments&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;i$ a$&lt;/code&gt; Math environments&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;iP aP&lt;/code&gt; Sections&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;im am&lt;/code&gt; Items&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Other mappings &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Delete the surrounding command, environment or delimiter with &lt;code&gt;dsc&lt;/code&gt;/&lt;code&gt;dse&lt;/code&gt;/&lt;code&gt;ds$&lt;/code&gt;/&lt;code&gt;dsd&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Change the surrounding command, environment or delimiter with &lt;code&gt;csc&lt;/code&gt;/&lt;code&gt;cse&lt;/code&gt;/&lt;code&gt;cs$&lt;/code&gt;/&lt;code&gt;csd&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Toggle starred command or environment with &lt;code&gt;tsc&lt;/code&gt;/&lt;code&gt;tse&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Toggle inline and displaymath with &lt;code&gt;ts$&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Toggle between e.g. &lt;code&gt;()&lt;/code&gt; and &lt;code&gt;\left(\right)&lt;/code&gt; with &lt;code&gt;tsd&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Toggle (inline) fractions with &lt;code&gt;tsf&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Close the current environment/delimiter in insert mode with &lt;code&gt;]]&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Add &lt;code&gt;\left ... \right)&lt;/code&gt; modifiers to surrounding delimiters with &lt;code&gt;&amp;lt;F8&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Insert new command with &lt;code&gt;&amp;lt;F7&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Convenient insert mode mappings for faster typing of e.g. maths&lt;/li&gt; &#xA;   &lt;li&gt;Context menu on citations (e.g. &lt;code&gt;\cite{...}&lt;/code&gt;) mapped to &lt;code&gt;&amp;lt;cr&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Improved folding (&lt;code&gt;:h &#39;foldexpr&#39;&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Improved indentation (&lt;code&gt;:h &#39;indentexpr&#39;&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Syntax highlighting &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A consistent core syntax specification&lt;/li&gt; &#xA;   &lt;li&gt;General syntax highlighting for several popular LaTeX packages&lt;/li&gt; &#xA;   &lt;li&gt;Nested syntax highlighting for several popular LaTeX packages&lt;/li&gt; &#xA;   &lt;li&gt;Highlight matching delimiters&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Support for multi-file project packages &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://ctan.uib.no/macros/latex/contrib/import/import.pdf&#34;&gt;import&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://ctan.uib.no/macros/latex/contrib/subfiles/subfiles.pdf&#34;&gt;subfiles&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For orientation, you can watch concise demonstrations of many of the motions, text objects, and text-editing features provided by VimTeX in the file &lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/VISUALS.md&#34;&gt;VISUALS.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See the documentation for a thorough introduction to VimTeX (e.g. &lt;code&gt;:h vimtex&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;Other relevant plugins&lt;/h2&gt; &#xA;&lt;p&gt;Even though VimTeX provides a lot of nice features for working with LaTeX documents, there are several features that are better served by other, dedicated plugins. For a more detailed listing of these, please see &lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/doc/vimtex.txt#L508&#34;&gt;&lt;code&gt;:help vimtex-and-friends&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Linting and syntax checking&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/w0rp/ale&#34;&gt;ale&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/neomake/neomake&#34;&gt;neomake&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vim-syntastic/syntastic&#34;&gt;syntastic&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Snippets and templates&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/SirVer/ultisnips&#34;&gt;UltiSnips&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Shougo/neosnippet.vim&#34;&gt;neosnippet&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Tag navigation&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ludovicchabant/vim-gutentags&#34;&gt;vim-gutentags&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Alternatives&lt;/h2&gt; &#xA;&lt;p&gt;The following are some alternative LaTeX plugins for Vim:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;http://vim-latex.sourceforge.net&#34;&gt;LaTeX-Suite&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The main difference between VimTeX and LaTeX-Suite (aka vim-latex) is probably that VimTeX does not try to implement a full fledged IDE for LaTeX inside Vim. E.g.:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;VimTeX does not provide a full snippet feature, because this is better handled by &lt;a href=&#34;https://github.com/SirVer/ultisnips&#34;&gt;UltiSnips&lt;/a&gt; or &lt;a href=&#34;https://github.com/Shougo/neosnippet.vim&#34;&gt;neosnippet&lt;/a&gt; or similar snippet engines.&lt;/li&gt; &#xA;   &lt;li&gt;VimTeX builds upon Vim principles: It provides text objects for environments, inline math, it provides motions for sections and paragraphs&lt;/li&gt; &#xA;   &lt;li&gt;VimTeX uses &lt;code&gt;latexmk&lt;/code&gt;, &lt;code&gt;latexrun&lt;/code&gt;, &lt;code&gt;tectonic&lt;/code&gt; or &lt;code&gt;arara&lt;/code&gt; for compilation with a callback feature to get instant feedback on compilation errors&lt;/li&gt; &#xA;   &lt;li&gt;VimTeX is very modular: if you don&#39;t like a feature, you can turn it off.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/jakewvincent/texmagic.nvim&#34;&gt;TexMagic.nvim&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&#34;A simple, lightweight Neovim plugin that facilitates LaTeX build engine selection via magic comments. It is designed with the TexLab LSP server&#39;s build functionality in mind, which at the time of this plugin&#39;s inception had to be specified in init.lua/init.vim and could not be set on a by-project basis.&#34;&lt;/p&gt; &lt;p&gt;This plugin should be combined with the TexLab LSP server, and it only works on neovim.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/LaTeX-Box-Team/LaTeX-Box&#34;&gt;LaTeX-Box&lt;/a&gt;&lt;/p&gt; &lt;p&gt;VimTeX currently has most of the features of LaTeX-Box, as well as some additional ones. See &lt;a href=&#34;https://raw.githubusercontent.com/lervag/vimtex/master/#features&#34;&gt;here&lt;/a&gt; for a relatively complete list of features.&lt;/p&gt; &lt;p&gt;One particular feature that LaTeX-Box has but VimTeX misses, is the ability to do single-shot compilation &lt;em&gt;with callback&lt;/em&gt;. This functionality was removed because it adds a lot of complexity for relatively little gain (IMHO).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;http://atp-vim.sourceforge.net&#34;&gt;AutomaticTexPlugin&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/xuhdev/vim-latex-live-preview&#34;&gt;vim-latex-live-preview&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For more alternatives and more information and discussions regarding LaTeX plugins for Vim, see:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://vi.stackexchange.com/questions/2047/what-are-the-differences-between-latex-plugins&#34;&gt;What are the differences between LaTeX plugins&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tex.stackexchange.com/questions/339/latex-editors-ides&#34;&gt;List of LaTeX editors (not only Vim)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;VimTeX on the Web&lt;/h2&gt; &#xA;&lt;p&gt;VimTeX users may be interested in reading &lt;a href=&#34;https://github.com/ejmastnak&#34;&gt;@ejmastnak&lt;/a&gt;&#39;s series on &lt;a href=&#34;https://ejmastnak.github.io/tutorials/vim-latex/intro.html&#34;&gt;Efficient LaTeX Using (Neo)Vim&lt;/a&gt;, which covers all the fundamentals of setting up a VimTeX-based LaTeX workflow, including usage of the VimTeX plugin, compilation, setting up forward and inverse search with a PDF reader, and Vimscript tools for user-specific customization.&lt;/p&gt; &#xA;&lt;p&gt;If you know of (or create) other up-to-date, high-quality guides to VimTeX&#39;s features on third-party websites, feel free to submit a pull request updating this section.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>posquit0/Awesome-CV</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/posquit0/Awesome-CV</id>
    <link href="https://github.com/posquit0/Awesome-CV" rel="alternate"></link>
    <summary type="html">&lt;p&gt;📄 Awesome CV is LaTeX template for your outstanding job application&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/posquit0/Awesome-CV&#34; title=&#34;AwesomeCV Documentation&#34;&gt; &lt;img alt=&#34;AwesomeCV&#34; src=&#34;https://github.com/posquit0/Awesome-CV/raw/master/icon.png&#34; width=&#34;200px&#34; height=&#34;200px&#34;&gt; &lt;/a&gt; &lt;br&gt; Awesome CV &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; LaTeX template for your outstanding job application &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.paypal.me/posquit0&#34;&gt; &lt;img alt=&#34;Donate&#34; src=&#34;https://img.shields.io/badge/Donate-PayPal-blue.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/posquit0/Awesome-CV/actions/workflows/main.yml&#34;&gt; &lt;img alt=&#34;GitHub Actions&#34; src=&#34;https://github.com/posquit0/Awesome-CV/actions/workflows/main.yml/badge.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf&#34;&gt; &lt;img alt=&#34;Example Resume&#34; src=&#34;https://img.shields.io/badge/resume-pdf-green.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/cv.pdf&#34;&gt; &lt;img alt=&#34;Example CV&#34; src=&#34;https://img.shields.io/badge/cv-pdf-green.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf&#34;&gt; &lt;img alt=&#34;Example Coverletter&#34; src=&#34;https://img.shields.io/badge/coverletter-pdf-green.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;What is Awesome CV?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Awesome CV&lt;/strong&gt; is LaTeX template for a &lt;strong&gt;CV(Curriculum Vitae)&lt;/strong&gt;, &lt;strong&gt;Résumé&lt;/strong&gt; or &lt;strong&gt;Cover Letter&lt;/strong&gt; inspired by &lt;a href=&#34;https://www.sharelatex.com/templates/cv-or-resume/fancy-cv&#34;&gt;Fancy CV&lt;/a&gt;. It is easy to customize your own template, especially since it is really written by a clean, semantic markup.&lt;/p&gt; &#xA;&lt;h2&gt;Donate&lt;/h2&gt; &#xA;&lt;p&gt;Please help keep this project alive! Donations are welcome and will go towards further development of this project.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PayPal: paypal.me/posquit0&#xA;BTC: 1Je3DxJVM2a9nTVPNo55SfQwpmxA6N2KKb&#xA;BCH: 1Mg1wG7PwHGrHYSWS67TsGSjo5GHEVbF16&#xA;ETH: 0x77ED9B4659F80205E9B9C9FB1E26EDB9904AFCC7&#xA;QTUM: QZT7D6m3QtTTqp7s4ZWAwLtGDsoHMMaM8E&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;Thank you for your support!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Preview&lt;/h2&gt; &#xA;&lt;h4&gt;Résumé&lt;/h4&gt; &#xA;&lt;p&gt;You can see &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Page. 1&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Page. 2&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume-0.png&#34; alt=&#34;Résumé&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume-1.png&#34; alt=&#34;Résumé&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Cover Letter&lt;/h4&gt; &#xA;&lt;p&gt;You can see &lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Without Sections&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;With Sections&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter-0.png&#34; alt=&#34;Cover Letter(Traditional)&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter-1.png&#34; alt=&#34;Cover Letter(Awesome)&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.overleaf.com/latex/templates/awesome-cv/tvmzpvdjfqxp&#34;&gt;&lt;strong&gt;Edit Résumé on OverLeaf.com&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.overleaf.com/latex/templates/awesome-cv-cover-letter/pfzzjspkthbk&#34;&gt;&lt;strong&gt;Edit Cover Letter on OverLeaf.com&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note:&lt;/em&gt; Above services do not guarantee up-to-date source code of Awesome CV&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How to Use&lt;/h2&gt; &#xA;&lt;h4&gt;Requirements&lt;/h4&gt; &#xA;&lt;p&gt;A full TeX distribution is assumed. &lt;a href=&#34;http://tex.stackexchange.com/q/55437&#34;&gt;Various distributions for different operating systems (Windows, Mac, *nix) are available&lt;/a&gt; but TeX Live is recommended. You can &lt;a href=&#34;https://tex.stackexchange.com/q/1092&#34;&gt;install TeX from upstream&lt;/a&gt; (recommended; most up-to-date) or use &lt;code&gt;sudo apt-get install texlive-full&lt;/code&gt; if you really want that. (It&#39;s generally a few years behind.)&lt;/p&gt; &#xA;&lt;p&gt;If you don&#39;t want to install the dependencies on your system, this can also be obtained via &lt;a href=&#34;https://docker.com&#34;&gt;Docker&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Usage&lt;/h4&gt; &#xA;&lt;p&gt;At a command prompt, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ xelatex {your-cv}.tex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or using docker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run --rm --user $(id -u):$(id -g) -i -w &#34;/doc&#34; -v &#34;$PWD&#34;:/doc thomasweise/texlive make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In either case, this should result in the creation of &lt;code&gt;{your-cv}.pdf&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Credit&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.latex-project.org&#34;&gt;&lt;strong&gt;LaTeX&lt;/strong&gt;&lt;/a&gt; is a fantastic typesetting program that a lot of people use these days, especially the math and computer science people in academia.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/furl/latex-fontawesome&#34;&gt;&lt;strong&gt;LaTeX FontAwesome&lt;/strong&gt;&lt;/a&gt; is bindings for FontAwesome icons to be used in XeLaTeX.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/google/roboto&#34;&gt;&lt;strong&gt;Roboto&lt;/strong&gt;&lt;/a&gt; is the default font on Android and ChromeOS, and the recommended font for Google’s visual language, Material Design.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/adobe-fonts/source-sans-pro&#34;&gt;&lt;strong&gt;Source Sans Pro&lt;/strong&gt;&lt;/a&gt; is a set of OpenType fonts that have been designed to work well in user interface (UI) environments.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;You are free to take my &lt;code&gt;.tex&lt;/code&gt; file and modify it to create your own resume. Please don&#39;t use my resume for anything else without my permission, though!&lt;/p&gt; &#xA;&lt;p&gt;If you have any questions, feel free to join me at &lt;a href=&#34;irc://irc.freenode.net/posquit0&#34;&gt;&lt;code&gt;#posquit0&lt;/code&gt; on Freenode&lt;/a&gt; and ask away. Click &lt;a href=&#34;https://kiwiirc.com/client/irc.freenode.net/posquit0&#34;&gt;here&lt;/a&gt; to connect.&lt;/p&gt; &#xA;&lt;p&gt;Good luck!&lt;/p&gt; &#xA;&lt;h2&gt;Maintainers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/posquit0&#34;&gt;posquit0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/OJFord&#34;&gt;OJFord&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;See Also&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/posquit0/hugo-awesome-identity&#34;&gt;Awesome Identity&lt;/a&gt; - A single-page Hugo theme to introduce yourself.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Grokitach/Stalker_GAMMA</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/Grokitach/Stalker_GAMMA</id>
    <link href="https://github.com/Grokitach/Stalker_GAMMA" rel="alternate"></link>
    <summary type="html">&lt;p&gt;S.T.A.L.K.E.R. Anomaly G.A.M.M.A. modpack definition files.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stalker GAMMA&lt;/h1&gt; &#xA;&lt;p&gt;S.T.A.L.K.E.R. Anomaly G.A.M.M.A. modpack definition files.&lt;/p&gt; &#xA;&lt;h2&gt;Get the client to use this repository&lt;/h2&gt; &#xA;&lt;p&gt;G.A.M.M.A. stands for Grok&#39;s Automated Modular Modpack for Anomaly.&lt;/p&gt; &#xA;&lt;p&gt;To get the latest Stalker GAMMA client and install intructions, head to the associated discord server:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/KT2bEHZQbh&#34;&gt;https://discord.gg/KT2bEHZQbh&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;G.A.M.M.A. aims at providing a balanced survival, scavenging, cooking, crafting and repairing focused experience with a long progression and smooth gameplay.&lt;/p&gt; &#xA;&lt;p&gt;For people accustomed to Skyrim modding, G.A.M.M.A. is basically Wabbajack remade from scratch in PowerShell + a modlist of 200+ addons and its own developed modular add-ons for STALKER Anomaly.&lt;/p&gt; &#xA;&lt;p&gt;This modpack is 100% copyright free since it doesn&#39;t redistribute any copyrighted content developed by other modders. Indeed, G.A.M.M.A. downloads every add-on directly from moddb or github, and installs them automatically and in the correct order in a Mod Organizer 2 (MO2) instance. You will thus directly support modders by installing G.A.M.M.A.&lt;/p&gt; &#xA;&lt;p&gt;G.A.M.M.A. is easy to use, since by simply executing 3 scripts and following basic instructions, you&#39;ll find on your desktop the G.A.M.M.A. icon which will launch a MO2 instance directly linked to your STALKER Anomaly folder. From there, you will find every add-on installed and be able to deactivate the ones you don&#39;t like, or add new add-ons. This is especially easy since all add-ons used in G.A.M.M.A. are separated by their type, i.e. Audio, Gameplay, Gunplay, etc.&lt;/p&gt; &#xA;&lt;p&gt;This modpack also features its own new modular set of add-ons including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A new UI.&lt;/li&gt; &#xA; &lt;li&gt;A rebalanced survival experience focused on crafting, repairing and cooking.&lt;/li&gt; &#xA; &lt;li&gt;A new economy where traders will only sell you supplies, and where good ammunition will only be available to trustful stalkers.&lt;/li&gt; &#xA; &lt;li&gt;New starting loadouts focused on providing pistols, SMGs or WW2 guns to have a smoother start with calibers for which you can buy ammo. It also gives you the basic tools to wander the Zone, which is nice for Ironman runs.&lt;/li&gt; &#xA; &lt;li&gt;Rebalanced close quarter combat to make knives more useful and to free even more inventory slots, yup you can equip 2 pistols and 2 main weapons and still profit from your best knife with a reworked quick melee motion and system.&lt;/li&gt; &#xA; &lt;li&gt;Rebalanced actor damage.&lt;/li&gt; &#xA; &lt;li&gt;Rebalanced sleep.&lt;/li&gt; &#xA; &lt;li&gt;Rebalanced Skill System from Haruka.&lt;/li&gt; &#xA; &lt;li&gt;Overhauled radiations effects and dynamic radiation areas.&lt;/li&gt; &#xA; &lt;li&gt;Many fixes for some major addons including the Boomsticks and Sharpsticks gunpack.&lt;/li&gt; &#xA; &lt;li&gt;And more!&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>lib-pku/libpku</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/lib-pku/libpku</id>
    <link href="https://github.com/lib-pku/libpku" rel="alternate"></link>
    <summary type="html">&lt;p&gt;贵校课程资料民间整理&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;libpku - 贵校课程资料民间整理&lt;/h1&gt; &#xA;&lt;h2&gt;Preface&lt;/h2&gt; &#xA;&lt;p&gt;（引用自 &lt;a href=&#34;https://github.com/QSCTech/zju-icicles&#34;&gt;QSCTech/zju-icicles&lt;/a&gt; ）&lt;/p&gt; &#xA;&lt;p&gt;来到一所大学，从第一次接触许多课，直到一门一门完成，这个过程中我们时常收集起许多资料和情报。&lt;/p&gt; &#xA;&lt;p&gt;有些是需要在网上搜索的电子书，每次见到一门新课程，Google 一下教材名称，有的可以立即找到，有的却是要花费许多眼力；有些是历年试卷或者 A4 纸，前人精心收集制作，抱着能对他人有用的想法公开，却需要在各个群或者私下中摸索以至于从学长手中代代相传；有些是上完一门课才恍然领悟的技巧，原来这门课重点如此，当初本可以更轻松地完成得更好……&lt;/p&gt; &#xA;&lt;p&gt;我也曾很努力地收集各种课程资料，但到最后，某些重要信息的得到却往往依然是纯属偶然。这种状态时常令我感到后怕与不安。我也曾在课程结束后终于有了些许方法与总结，但这些想法无处诉说，最终只能把花费时间与精力才换来的经验耗散在了漫漫的遗忘之中。&lt;/p&gt; &#xA;&lt;p&gt;我为这一年一年，这么多人孤军奋战的重复劳动感到不平。&lt;/p&gt; &#xA;&lt;p&gt;我希望能够将这些隐晦的、不确定的、口口相传的资料和经验，变为公开的、易于获取的和大家能够共同完善、积累的共享资料。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;我希望只要是前人走过的弯路，后人就不必再走。&lt;/strong&gt; 这是我的信念，也是我建立这个项目的原因。&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;使用方法：访问 &lt;a href=&#34;https://lib-pku.github.io/&#34;&gt;https://lib-pku.github.io/&lt;/a&gt; ，点击资料链接即可下载。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://minhaskamal.github.io/DownGit/#/home&#34;&gt;https://minhaskamal.github.io/DownGit/#/home&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;欢迎贡献！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;欢迎贡献！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;欢迎贡献！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;——因为很重要所以说了三遍&lt;/p&gt; &#xA;&lt;p&gt;Issue、PR、纠错、资料、选课/考试攻略，完全欢迎！&lt;/p&gt; &#xA;&lt;p&gt;来自大家的关注、维护和贡献，才是让这个攻略继续存在的动力~&lt;/p&gt; &#xA;&lt;p&gt;对于课程的评价可写在对应课程文件夹的 &lt;code&gt;README.md&lt;/code&gt; 中。如果想上传课件（请确保无版权问题），推荐使用 PDF 格式，避免系统差。&lt;/p&gt; &#xA;&lt;p&gt;由于本项目体积很大，故推荐采用在 &lt;strong&gt;GitHub Web 端直接上传&lt;/strong&gt; 的方式，具体操作如下：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;首先 Fork 本项目&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;上传文件到已有文件夹：打开对应文件夹，点击绿色 Download 按钮旁的 upload，上传你的文件。&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;上传文件到新文件夹：打开任意文件夹，点击绿色 Download 按钮旁的 upload，&lt;strong&gt;把浏览器地址栏中文件夹名称改为你想要新建的文件夹名称，然后回车&lt;/strong&gt;，上传你的文件。&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;提交 PR：Fork 本项目，然后在 GitHub 网页端点击 Upload File 上传文件，发起 PR 即可。留意一下项目的文件组织喔。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;或者也可以直接附加在 &lt;strong&gt;Issue&lt;/strong&gt; 中，由维护者进行添加。&lt;/p&gt; &#xA;&lt;p&gt;或者也可以发送邮件至 &lt;strong&gt;&lt;a href=&#34;mailto:libpku@protonmail.com&#34;&gt;libpku@protonmail.com&lt;/a&gt;&lt;/strong&gt; ，由维护者进行添加。&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;这不是北京大学图书馆。 我们也不对项目中信息的准确性或真实性做任何承诺。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;如果有侵权情况，麻烦您发送必要的信息至 &lt;a href=&#34;mailto:libpku@protonmail.com&#34;&gt;libpku@protonmail.com&lt;/a&gt; ，带来不便还请您谅解。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;资料来自网络，相关权利由原作者所有，这个 repo 仅用于收集现有资料。&lt;/p&gt; &#xA;&lt;p&gt;当然，我们不会为收集到的资料收费，或是尝试收取捐赠。&lt;/p&gt; &#xA;&lt;p&gt;我们只是尝试为后来的同学节省一些时间。&lt;/p&gt; &#xA;&lt;h2&gt;Related Works&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/QSCTech/zju-icicles&#34;&gt;浙江大学课程攻略共享计划&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/martinwu42/project-hover&#34;&gt;气垫船计划——免费、去中心化的北京大学往年题资料库&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/EECS-PKU-XSB/Shared-learning-materials&#34;&gt;北京大学信科学生会学术部资料库&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tongtzeho/PKUCourse&#34;&gt;北大计算机课程大作业&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PKUanonym/REKCARC-TSC-UHT&#34;&gt;清华大学计算机系课程攻略&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zjdx1998/seucourseshare&#34;&gt;东南大学课程共享计划&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/USTC-Resource/USTC-Course&#34;&gt;中国科学技术大学计算机学院课程资源&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CoolPhilChen/SJTU-Courses/&#34;&gt;上海交通大学课程资料分享&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sysuexam/SYSU-Exam&#34;&gt;中山大学课程资料分享&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/idealclover/NJU-Review-Materials&#34;&gt;南京大学课程复习资料&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CooperNiu/ZZU-Courses-Resource&#34;&gt;郑州大学课程复习资料&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/brenner8023/gdut-course&#34;&gt;广东工业大学计算机学院课程攻略&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;(more to be added....)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>AllenDowney/ThinkPython2</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/AllenDowney/ThinkPython2</id>
    <link href="https://github.com/AllenDowney/ThinkPython2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LaTeX source and supporting code for Think Python, 2nd edition, by Allen Downey.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ThinkPython&lt;/h1&gt; &#xA;&lt;p&gt;LaTeX source, code examples, and exercise solutions for Think Python, 2nd edition, by Allen Downey.&lt;/p&gt; &#xA;&lt;p&gt;You can download this book in PDF from &lt;a href=&#34;http://greenteapress.com/wp/think-python-2e/&#34;&gt;Green Tea Press&lt;/a&gt; or buy it in paper and other formats from &lt;a href=&#34;http://shop.oreilly.com/product/0636920045267.do&#34;&gt;O&#39;Reilly Media&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To build the book from source you will need a LaTeX installion. I recommend the TeX Live distribution with the following packages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;texlive-latex-base&lt;/li&gt; &#xA; &lt;li&gt;texlive-latex-extra&lt;/li&gt; &#xA; &lt;li&gt;texlive-fonts-recommended&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>jeffrey-xiao/papers</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/jeffrey-xiao/papers</id>
    <link href="https://github.com/jeffrey-xiao/papers" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;papers&lt;/h1&gt; &#xA;&lt;p&gt;A collection of academic papers, articles, and other resources that I plan to read or have read. The content has a focus on distributed systems.&lt;/p&gt; &#xA;&lt;p&gt;I have also included my notes on select resources to summarize important takeaways and to help me better understand the material.&lt;/p&gt; &#xA;&lt;h2&gt;Blog Posts and Online Articles&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jepsen.io/consistency&#34;&gt;Consistency Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jepsen.io/analyses&#34;&gt;Jepsen Analyses&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aphyr.com/posts/313-strong-consistency-models&#34;&gt;Strong Consistency Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://christophermeiklejohn.com/distributed/systems/2013/07/12/readings-in-distributed-systems.html&#34;&gt;Readings in Distributed Systems&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying&#34;&gt;The Log: What every software engineering should know about real-time data&#39;s unifying abstraction&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Consensus&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/unreliable-failure-detectors-for-reliable-distributed-systems.pdf&#34;&gt;Unreliable Failure Detectors for Reliable Distributed Systems&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Chandra, Tushar Deepak, and Sam Toueg. 1996. “Unreliable Failure Detectors for Reliable Distributed Systems.” &lt;em&gt;Journal of the ACM (JACM)&lt;/em&gt; 43 (2). ACM: 225–67.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/impossibility-of-distributed-consensus-with-one-faulty-process.pdf&#34;&gt;Impossibility of Distributed Consensus with One Faulty Process&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Fischer, Michael J, Nancy A Lynch, and Michael S Paterson. 1982. “Impossibility of Distributed Consensus with One Faulty Process.” MASSACHUSETTS INST OF TECH CAMBRIDGE LAB FOR COMPUTER SCIENCE.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/viewstamped-replication-a-new-primary-copy-method-to-support-highly-available-distributed-systems.pdf&#34;&gt;Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Oki, Brian M, and Barbara H Liskov. 1988. “Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.” In &lt;em&gt;Proceedings of the Seventh Annual Acm Symposium on Principles of Distributed Computing&lt;/em&gt;, 8–17. ACM.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/viewstamped-replication-revisited.pdf&#34;&gt;Viewstamped Replication Revisited&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Liskov, Barbara, and James Cowling. 2012. “Viewstamped Replication Revisited.”&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/the-part-time-parliament.pdf&#34;&gt;The Part Time Parliament&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Lamport, Leslie, and others. 1998. “The Part-Time Parliament.” &lt;em&gt;ACM Transactions on Computer Systems&lt;/em&gt; 16 (2): 133–69.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/paxos-made-simple.pdf&#34;&gt;Paxos Made Simple&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Lamport, Leslie, and others. 2001. “Paxos Made Simple.” &lt;em&gt;ACM Sigact News&lt;/em&gt; 32 (4): 18–25.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/paxos-made-live-an-engineering-perspective.pdf&#34;&gt;Paxos Made Live - An Engineering Perspective&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Chandra, Tushar D, Robert Griesemer, and Joshua Redstone. 2007. “Paxos Made Live: An Engineering Perspective.” In &lt;em&gt;Proceedings of the Twenty-Sixth Annual Acm Symposium on Principles of Distributed Computing&lt;/em&gt;, 398–407. ACM.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/flexible-paxos-quorum-intersection-revisited.pdf&#34;&gt;Flexible Paxos: Quorum Intersection Revisited&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Howard, Heidi, Dahlia Malkhi, and Alexander Spiegelman. 2016. “Flexible Paxos: Quorum Intersection Revisited.” &lt;em&gt;arXiv Preprint arXiv:1608.06696&lt;/em&gt;.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/zab-high-performance-broadcast-for-primary-backup-systems.pdf&#34;&gt;Zab: High-Performance Broadcast for Primary-Backup Systems&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Junqueira, Flavio P, Benjamin C Reed, and Marco Serafini. 2011. “Zab: High-Performance Broadcast for Primary-Backup Systems.” In &lt;em&gt;2011 Ieee/Ifip 41st International Conference on Dependable Systems &amp;amp; Networks (Dsn)&lt;/em&gt;, 245–56. IEEE.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/zookeepers-atomic-broadcast-protocol-theory-and-practice.pdf&#34;&gt;ZooKeeper&#39;s Atomic Broadcast Protocol: Theory and Practice&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Medeiros, André. 2012. “ZooKeeper’s Atomic Broadcast Protocol: Theory and Practice.” &lt;em&gt;Aalto University School of Science&lt;/em&gt; 20.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/viva-la-difference-paxos-vs-viewstamped-replication-vs-zab&#34;&gt;Vive la Différence: Paxos vs. Viewstamped Replication vs. Zab&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Van Renesse, Robbert, Nicolas Schiper, and Fred B Schneider. 2015. “Vive La Différence: Paxos Vs. Viewstamped Replication Vs. Zab.” &lt;em&gt;IEEE Transactions on Dependable and Secure Computing&lt;/em&gt; 12 (4). IEEE: 472–84.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/in-search-of-an-understandable-consensus-algorithm.pdf&#34;&gt;In Search of an Understandable Consensus Algorithm&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Ongaro, Diego, and John Ousterhout. 2014. “In Search of an Understandable Consensus Algorithm.” In &lt;em&gt;2014 {Usenix} Annual Technical Conference ({Usenix}{ATC} 14)&lt;/em&gt;, 305–19.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/consensus-bridging-theory-and-practice.pdf&#34;&gt;Consensus: Bridging Theory and Practice&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Ongaro, Diego. 2014. “Consensus: Bridging Theory and Practice.” PhD thesis, Stanford University.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/consensus/raft-refloated-do-we-have-consensus.pdf&#34;&gt;Raft Refloated: Do We Have Consensus?&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Howard, Heidi, Malte Schwarzkopf, Anil Madhavapeddy, and Jon Crowcroft. 2015. “Raft Refloated: Do We Have Consensus?” &lt;em&gt;Operating Systems Review&lt;/em&gt; 49 (1): 12–21.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Causality&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/causality/time-clocks-and-the-ordering-of-events-in-a-distributed-system.pdf&#34;&gt;Time, Clocks, and the Ordering of Events in a Distributed System&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Lamport, Leslie. 1978. “Time, Clocks, and the Ordering of Events in a Distributed System.” &lt;em&gt;Communications of the ACM&lt;/em&gt; 21 (7). ACM: 558–65.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/causality/timestamps-in-message-passing-systems-that-preserve-the-partial-ordering.pdf&#34;&gt;Timestamps in Message-Passing Systems That Preserve the Partial Ordering&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Fidge, Colin J. 1987. &lt;em&gt;Timestamps in Message-Passing Systems That Preserve the Partial Ordering&lt;/em&gt;. Australian National University. Department of Computer Science.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/causality/virtual-time-and-global-states-of-distributed-systems.pdf&#34;&gt;Virtual Time and Global States of Distributed Systems&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Mattern, Friedemann, and others. 1988. &lt;em&gt;Virtual Time and Global States of Distributed Systems&lt;/em&gt;. Citeseer.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/causality/logical-physical-clocks-and-consistent-snapshots-in-globally-distributed-databases.pdf&#34;&gt;Logical Physical Clocks and Consistent Snapshots in Globally Distributed Databases&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Demirbas, Murat, Marcelo Leone, Bharadwaj Avva, Deepak Madeppa, and Sandeep Kulkarni. 2014. “Logical Physical Clocks and Consistent Snapshots in Globally Distributed Databases.”&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/causality/the-bloom-clock.pdf&#34;&gt;The Bloom Clock&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Ramabaja, Lum. 2019. “The Bloom Clock.” &lt;em&gt;CoRR&lt;/em&gt; abs/1905.13064. &lt;a href=&#34;http://arxiv.org/abs/1905.13064&#34;&gt;http://arxiv.org/abs/1905.13064&lt;/a&gt;.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Consistency&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/brewers-conjecture-and-the-feasibility-of-consistent-available-partition-tolerant-web-services.pdf&#34;&gt;Brewer&#39;s Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant Web Services&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Gilbert, Seth, and Nancy Lynch. 2002. “Brewer’s Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant Web Services.” &lt;em&gt;Acm Sigact News&lt;/em&gt; 33 (2). ACM: 51–59.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Data Structures&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/fast-set-operations-using-treaps.pdf&#34;&gt;Fast set operations using treaps&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Blelloch, Guy E, and Margaret Reid-Miller. 1998. “Fast Set Operations Using Treaps.” In &lt;em&gt;SPAA&lt;/em&gt;, 98:16–26.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/a-skip-list-cookbook.pdf&#34;&gt;A Skip List Cookbook&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Pugh, William. 1998. “A Skip List Cookbook.”&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/skip-lists-a-probabilistic-alternative-to-balanced-trees.pdf&#34;&gt;Skip Lists: A Probabilistic Alternative to Balanced Trees&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Pugh, William. 1990. “Skip Lists: A Probabilistic Alternative to Balanced Trees.” &lt;em&gt;Communications of the ACM&lt;/em&gt; 33 (6).&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/less-hashing-same-performance-building-a-better-bloom-filter.pdf&#34;&gt;Less hashing, same performance: Building a better Bloom filter&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Kirsch, Adam, and Michael Mitzenmacher. 2006. “Less Hashing, Same Performance: Building a Better Bloom Filter.” In &lt;em&gt;European Symposium on Algorithms&lt;/em&gt;, 456–67. Springer.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/advanced-bloom-filter-based-algorithms-for-efficient-approximate-data-de-duplication-in-streams.pdf&#34;&gt;Advanced bloom filter based algorithms for efficient approximate data de-duplication in streams&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Bera, Suman K, Sourav Dutta, Ankur Narang, and Souvik Bhattacherjee. 2012. “Advanced Bloom Filter Based Algorithms for Efficient Approximate Data de-Duplication in Streams.” &lt;em&gt;arXiv Preprint arXiv:1212.3964&lt;/em&gt;.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/cuckoo-filter-practically-better-than-bloom.pdf&#34;&gt;Cuckoo filter: Practically better than bloom&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Fan, Bin, Dave G Andersen, Michael Kaminsky, and Michael D Mitzenmacher. 2014. “Cuckoo Filter: Practically Better Than Bloom.” In &lt;em&gt;Proceedings of the 10th Acm International on Conference on Emerging Networking Experiments and Technologies&lt;/em&gt;, 75–88. ACM.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/dont-thrash-how-to-cache-your-hash-on-flash.pdf&#34;&gt;Don&#39;t thrash: how to cache your hash on flash&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Bender, Michael A, Martin Farach-Colton, Rob Johnson, Russell Kraner, Bradley C Kuszmaul, Dzejla Medjedovic, Pablo Montes, Pradeep Shetty, Richard P Spillane, and Erez Zadok. 2012. “Don’t Thrash: How to Cache Your Hash on Flash.” &lt;em&gt;Proceedings of the VLDB Endowment&lt;/em&gt; 5 (11). VLDB Endowment: 1627–37.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/an-improved-data-stream-summary-the-count-min-sketch-and-its-applications.pdf&#34;&gt;An improved data stream summary: the count-min sketch and its applications&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Cormode, Graham, and Shan Muthukrishnan. 2005. “An Improved Data Stream Summary: The Count-Min Sketch and Its Applications.” &lt;em&gt;Journal of Algorithms&lt;/em&gt; 55 (1). Elsevier: 58–75.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/a-general-purpose-counting-filter-making-every-bit-count.pdf&#34;&gt;A general-purpose counting filter: Making every bit count&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Pandey, Prashant, Michael A Bender, Rob Johnson, and Rob Patro. 2017. “A General-Purpose Counting Filter: Making Every Bit Count.” In &lt;em&gt;Proceedings of the 2017 Acm International Conference on Management of Data&lt;/em&gt;, 775–87. ACM.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/hyperloglog-the-analysis-of-a-near-optimal-cardinality-estimation-algorithm.pdf&#34;&gt;HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Flajolet, Philippe, Éric Fusy, Olivier Gandouet, and Frédéric Meunier. 2007. “Hyperloglog: The Analysis of a Near-Optimal Cardinality Estimation Algorithm.” In &lt;em&gt;Discrete Mathematics and Theoretical Computer Science&lt;/em&gt;, 137–56. Discrete Mathematics; Theoretical Computer Science.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/hyperloglog-in-practice-algorithmic-engineering-of-a-state-of-the-art-cardinality-estimation-algorithm.pdf&#34;&gt;HyperLogLog in practice: algorithmic engineering of a state of the art cardinality estimation algorithm&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Heule, Stefan, Marc Nunkesser, and Alexander Hall. 2013. “HyperLogLog in Practice: Algorithmic Engineering of a State of the Art Cardinality Estimation Algorithm.” In &lt;em&gt;Proceedings of the 16th International Conference on Extending Database Technology&lt;/em&gt;, 683–92. ACM.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/lsm-tree.pdf&#34;&gt;LSM Tree&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;O’Neil, Patrick, Edward Cheng, Dieter Gawlick, and Elizabeth O’Neil. 1996. “The Log-Structured Merge-Tree (Lsm-Tree).” &lt;em&gt;Acta Informatica&lt;/em&gt; 33 (4). Springer: 351–85.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/blsm-a-general-purpose-lsm-tree.pdf&#34;&gt;bLSM: A General Purpose LSM Tree&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Sears, Russell, and Raghu Ramakrishnan. 2012. “BLSM: A General Purpose Log Structured Merge Tree.” In &lt;em&gt;Proceedings of the 2012 Acm Sigmod International Conference on Management of Data&lt;/em&gt;, 217–28. ACM.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/a-comprehensive-study-of-convergent-and-commutative-replicated-data-types.pdf&#34;&gt;A Comprehensive Study of Convergent and Commutative Replicated Data Types&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Shapiro, Marc, Nuno Preguiça, Carlos Baquero, and Marek Zawirski. 2011. “A Comprehensive Study of Convergent and Commutative Replicated Data Types.” PhD thesis, Inria–Centre Paris-Rocquencourt; INRIA.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/data-structures/efficient-synchronization-of-state-based-crdts.pdf&#34;&gt;Efficient Synchronization of State-based CRDTs&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Enes, Vitor, Paulo Sérgio Almeida, Carlos Baquero, and João Leitão. 2018. “Efficient Synchronization of State-Based Crdts.” &lt;em&gt;arXiv Preprint arXiv:1803.02750&lt;/em&gt;.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;P2P&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/p2p/chord-a-scalable-peer-to-peer-lookup-service-for-internet-applications.pdf&#34;&gt;Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Stoica, Ion, Robert Morris, David Liben-Nowell, David R Karger, M Frans Kaashoek, Frank Dabek, and Hari Balakrishnan. 2003. “Chord: A Scalable Peer-to-Peer Lookup Protocol for Internet Applications.” &lt;em&gt;IEEE/ACM Transactions on Networking (TON)&lt;/em&gt; 11 (1). IEEE Press: 17–32.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/p2p/kademlia-a-peer-to-peer-information-system-based-on-the-xor-metric.pdf&#34;&gt;Kademlia: A Peer-to-peer Information System Based on the XOR Metric&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Maymounkov, Petar, and David Mazieres. 2002. “Kademlia: A Peer-to-Peer Information System Based on the Xor Metric.” In &lt;em&gt;International Workshop on Peer-to-Peer Systems&lt;/em&gt;, 53–65. Springer.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Systems&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/systems/dynamo-amazons-highly-available-key-value-store.pdf&#34;&gt;Dynamo: Amazon&#39;s Highly Available Key-value Store&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;DeCandia, Giuseppe, Deniz Hastorun, Madan Jampani, Gunavardhan Kakulapati, Avinash Lakshman, Alex Pilchin, Swaminathan Sivasubramanian, Peter Vosshall, and Werner Vogels. 2007. “Dynamo: Amazon’s Highly Available Key-Value Store.” In &lt;em&gt;ACM Sigops Operating Systems Review&lt;/em&gt;, 41:205–20. 6. ACM.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/systems/bigtable-a-distributed-storage-system-for-structured-data.pdf&#34;&gt;Bigtable: A Distributed Storage System for Structured Data&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Chang, Fay, Jeffrey Dean, Sanjay Ghemawat, Wilson C Hsieh, Deborah A Wallach, Mike Burrows, Tushar Chandra, Andrew Fikes, and Robert E Gruber. 2008. “Bigtable: A Distributed Storage System for Structured Data.” &lt;em&gt;ACM Transactions on Computer Systems (TOCS)&lt;/em&gt; 26 (2). ACM: 4.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/systems/cassandra-a-decentralized-structured-storage-system.pdf&#34;&gt;Cassandra - A Decentralized Structured Storage System&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Lakshman, Avinash, and Prashant Malik. 2010. “Cassandra: A Decentralized Structured Storage System.” &lt;em&gt;ACM SIGOPS Operating Systems Review&lt;/em&gt; 44 (2). ACM: 35–40.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/systems/kafka-a-distributed-messaging-system-for-log-processing.pdf&#34;&gt;Kafka: A Distributed Messaging System for Log Processing&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Kreps, Jay, Neha Narkhede, Jun Rao, and others. 2011. “Kafka: A Distributed Messaging System for Log Processing.” In &lt;em&gt;Proceedings of the Netdb&lt;/em&gt;, 1–7.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/systems/spanner-googles-globally-distributed-database.pdf&#34;&gt;Spanner: Google&#39;s Globally-Distributed Database&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Corbett, James C., Jeffrey Dean, Michael Epstein, Andrew Fikes, Christopher Frost, JJ Furman, Sanjay Ghemawat, et al. 2012. “Spanner: Google’s Globally-Distributed Database.” In &lt;em&gt;OSDI&lt;/em&gt;.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/systems/spanner-becoming-a-sql-system.pdf&#34;&gt;Spanner: Becoming a SQL System&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Bacon, David F., Nathan Bales, Nico Bruno, Brian F. Cooper, Adam Dickinson, Andrew Fikes, Campbell Fraser, et al. 2017. “Spanner: Becoming a Sql System.” In &lt;em&gt;Proc. SIGMOD 2017&lt;/em&gt;, 331–43.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/testing/an-analysis-of-network-partitioning-failures-in-cloud-systems.pdf&#34;&gt;An Analysis of Network-Partitioning Failures in Cloud Systems&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Alquraan, Ahmed, Hatem Takruri, Mohammed Alfatafta, and Samer Al-Kiswany. 2018. “An Analysis of Network-Partitioning Failures in Cloud Systems.” In &lt;em&gt;13th Usenix Symposium on Operating Systems Design and Implementation Osdi 18)&lt;/em&gt;, 51–68.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/testing/why-is-random-testing-effective-for-partition-tolerance-bugs.pdf&#34;&gt;Why Is Random Testing Effective for Partition Tolerance Bugs?&lt;/a&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Majumdar, Rupak, and Filip Niksic. 2017. “Why Is Random Testing Effective for Partition Tolerance Bugs?” &lt;em&gt;Proceedings of the ACM on Programming Languages&lt;/em&gt; 2 (POPL). ACM: 46.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Textbooks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Operating Systems: Principles and Practice &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/textbooks/operating-systems-principles-and-practice-vol-1-kernels-and-processes.pdf&#34;&gt;Volume 1: Kernels and Processes&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/textbooks/operating-systems-principles-and-practice-vol-2-concurrency.pdf&#34;&gt;Volume 2: Concurrency&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/textbooks/operating-systems-principles-and-practice-vol-3-memory-management.pdf&#34;&gt;Volume 3: Memory Management&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/textbooks/operating-systems-principles-and-practice-vol-4-persistent-storage.pdf&#34;&gt;Volume 4: Persistent Storage&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/textbooks/designing-data-intensive-applications.pdf&#34;&gt;Designing Data-Intensive Applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/textbooks/distributed-systems.pdf&#34;&gt;Distributed Systems&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://book.mixu.net/distsys&#34;&gt;Distributed Systems for Fun and Profit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.the-paper-trail.org/post/2014-08-09-distributed-systems-theory-for-the-distributed-systems-engineer&#34;&gt;Distributed Systems Theory for the Distributed Systems Engineer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jeffrey-xiao/papers/master/textbooks/readings-in-database-systems.pdf&#34;&gt;Readings in Database Systems&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ElegantLaTeX/ElegantPaper</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/ElegantLaTeX/ElegantPaper</id>
    <link href="https://github.com/ElegantLaTeX/ElegantPaper" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Elegant LaTeX Template for Working Papers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ElegantPaper&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://elegantlatex.org/&#34;&gt;Homepage&lt;/a&gt; | &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantPaper&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://ctan.org/pkg/elegantpaper&#34;&gt;CTAN&lt;/a&gt; | &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantPaper/releases&#34;&gt;Download&lt;/a&gt; | &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantPaper/wiki&#34;&gt;Wiki&lt;/a&gt; | &lt;a href=&#34;https://weibo.com/elegantlatex&#34;&gt;Weibo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/ctan/l/elegantpaper.svg?sanitize=true&#34; alt=&#34;License&#34;&gt; &lt;img src=&#34;https://img.shields.io/ctan/v/elegantpaper.svg?sanitize=true&#34; alt=&#34;CTAN Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/release/ElegantLaTeX/ElegantPaper.svg?sanitize=true&#34; alt=&#34;Github Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/repo-size/ElegantLaTeX/ElegantPaper.svg?sanitize=true&#34; alt=&#34;Repo Size&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ElegantPaper is designed for writing a working paper, especially for economics students. This template is based on the standard LaTeX article class. The goal of this template is to make the writing process easier and more comfortable. You can get rid of all the worries about the format. Just enjoy it! If you have any questions, suggestions or bug reports, you can create issues or email us at &lt;a href=&#34;mailto:elegantlatex2e@gmail.com&#34;&gt;elegantlatex2e@gmail.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;此模板基于 LaTeX 的 article 类，专为工作论文写作而设计。设计这个模板的初衷是让作者不用关心工作论文的格式，专心写作，从而有更加舒适，简便的写作体验。如果你有其他问题、建议或者报告 bug，可以提交 issues 或者给我们发邮件：&lt;a href=&#34;mailto:elegantlatex2e@gmail.com&#34;&gt;elegantlatex2e@gmail.com&lt;/a&gt;。用户 QQ 交流群（Q 群：692108391），欢迎加入。&lt;/p&gt; &#xA;&lt;p&gt;The official user guide is &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantPaper/releases&#34;&gt;here&lt;/a&gt;, or you can refer to the &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantPaper/wiki&#34;&gt;wiki&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;模板使用说明请参见&lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantPaper/releases&#34;&gt;模板文档&lt;/a&gt;，或者 &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantPaper/wiki&#34;&gt;wiki&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This work is released under the LaTeX Project Public License, v1.3c or later.&lt;/p&gt; &#xA;&lt;p&gt;本模板发布遵循 LaTeX 项目公共许可证 1.3c 或更高版本。&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>yenchenlin/awesome-NeRF</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/yenchenlin/awesome-NeRF</id>
    <link href="https://github.com/yenchenlin/awesome-NeRF" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A curated list of awesome neural radiance fields papers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome Neural Radiance Fields &lt;a href=&#34;https://github.com/sindresorhus/awesome&#34;&gt;&lt;img src=&#34;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true&#34; alt=&#34;Awesome&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;A curated list of awesome neural radiance fields papers, inspired by &lt;a href=&#34;https://github.com/jbhuang0604/awesome-computer-vision&#34;&gt;awesome-computer-vision&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/how-to-PR.md&#34;&gt;How to submit a pull request?&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/#survey&#34;&gt;Survey&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/#papers&#34;&gt;Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/#talks&#34;&gt;Talks&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Survey&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2101.05204&#34;&gt;Neural Volume Rendering: NeRF And Beyond&lt;/a&gt;, Dellaert and Yen-Chen, Arxiv 2020 | &lt;a href=&#34;https://dellaert.github.io/NeRF/&#34;&gt;blog&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/nerf-survey.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Papers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.matthewtancik.com/nerf&#34;&gt;NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis&lt;/a&gt;, Mildenhall et al., ECCV 2020 | &lt;a href=&#34;https://github.com/bmild/nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L168-L173&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Mildenhall20eccv_nerf--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Faster Inference&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lingjie0206.github.io/papers/NSVF/&#34;&gt;Neural Sparse Voxel Fields&lt;/a&gt;, Liu et al., NeurIPS 2020 | &lt;a href=&#34;https://github.com/facebookresearch/NSVF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L135-L141&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Liu20neurips_sparse_nerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.computationalimaging.org/publications/automatic-integration/&#34;&gt;AutoInt: Automatic Integration for Fast Neural Volume Rendering&lt;/a&gt;, Lindell et al., CVPR 2021 | &lt;a href=&#34;https://github.com/computational-imaging/automatic-integration&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L127-L133&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Lindell20arxiv_AutoInt--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.12490&#34;&gt;DeRF: Decomposed Radiance Fields&lt;/a&gt;, Rebain et al. Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L222-L228&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Rebain20arxiv_derf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://depthoraclenerf.github.io/&#34;&gt;DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks&lt;/a&gt;, Neff et al., CGF 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/donerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--neff2021donerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.10380&#34;&gt;FastNeRF: High-Fidelity Neural Rendering at 200FPS&lt;/a&gt;, Garbin et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/fastnerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Garbin21arxiv_FastNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.13744&#34;&gt;KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs &lt;/a&gt;, Reiser et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/creiser/kilonerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/kilonerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--reiser2021kilonerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://alexyu.net/plenoctrees/&#34;&gt;PlenOctrees for Real-time Rendering of Neural Radiance Fields&lt;/a&gt;, Yu et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/sxyu/volrend&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/plenoctrees.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--yu2021plenoctrees--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.01954&#34;&gt;Mixture of Volumetric Primitives for Efficient Neural Rendering&lt;/a&gt;, Lombardi et al., SIGGRAPH 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/mixture.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vsitzmann.github.io/lfns/&#34;&gt;Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering&lt;/a&gt;, Sitzmann et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/lfn.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Faster Training&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2107.02791.pdf&#34;&gt;Depth-supervised NeRF: Fewer Views and Faster Training for Free&lt;/a&gt;, Deng et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/dunbar12138/DSNeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/dsnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2111.11215.pdf&#34;&gt;Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction&lt;/a&gt;, Sun et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/sunset1995/DirectVoxGO&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/DirectVoxGO.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--sun2021direct--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Unconstrained Images&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nerf-w.github.io/&#34;&gt;NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections&lt;/a&gt;, Martin-Brualla et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L152-L158&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--MartinBrualla20arxiv_nerfw--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rover-xingyu.github.io/Ha-NeRF/&#34;&gt;Ha-NeRF&lt;span&gt;😆&lt;/span&gt;: Hallucinated Neural Radiance Fields in the Wild&lt;/a&gt;, Chen et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/rover-xingyu/Ha-NeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/Ha-NeRF.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--chen2021hallucinated--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Deformable&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nerfies.github.io/&#34;&gt;Deformable Neural Radiance Fields&lt;/a&gt;, Park et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/google/nerfies&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L206-L212&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Park20arxiv_nerfies--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.albertpumarola.com/research/D-NeRF/index.html&#34;&gt;D-NeRF: Neural Radiance Fields for Dynamic Scenes&lt;/a&gt;, Pumarola et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L214-L220&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Pumarola20arxiv_D_NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gafniguy.github.io/4D-Facial-Avatars/&#34;&gt;Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction&lt;/a&gt;, Gafni et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L87-L93&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Gafni20arxiv_DNRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/&#34;&gt;Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Deforming Scene from Monocular Video&lt;/a&gt;, Tretschk et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/facebookresearch/nonrigid_nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L283-L289&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Tretschk20arxiv_NR-NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://volumetric-avatars.github.io/&#34;&gt;PVA: Pixel-aligned Volumetric Avatars&lt;/a&gt;, Raj et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/pva.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nogu-atsu/NARF&#34;&gt;Neural Articulated Radiance Field&lt;/a&gt;, Noguchi et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/narf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.00181&#34;&gt;CLA-NeRF: Category-Level Articulated Neural Radiance Field&lt;/a&gt;, Tseng et al., ICRA 2022 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/cla-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zju3dv.github.io/animatable_nerf/&#34;&gt;Animatable Neural Radiance Fields for Human Body Modeling&lt;/a&gt;, Peng et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/animatable_nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Peng21arxiv_animatable_nerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hypernerf.github.io/&#34;&gt;A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields&lt;/a&gt;, Park et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/hypernerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.13629&#34;&gt;Animatable Neural Radiance Fields from Monocular RGB Videos&lt;/a&gt;, Chen et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/JanaldoChen/Anim-NeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/anim_nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vcai.mpi-inf.mpg.de/projects/NeuralActor/&#34;&gt;Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control&lt;/a&gt;, Liu et al., SIGGRAPH Asia 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/neuralactor.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Video&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.cs.cornell.edu/~zl548/NSFF/&#34;&gt;Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes&lt;/a&gt;, Li et al., CVPR 2021 | &lt;a href=&#34;https://github.com/zhengqili/Neural-Scene-Flow-Fields&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L119-L125&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Li20arxiv_nsff--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://video-nerf.github.io/&#34;&gt;Space-time Neural Irradiance Fields for Free-Viewpoint Video&lt;/a&gt;, Xian et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L299-L305&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Xian20arxiv_stnif--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yilundu.github.io/nerflow/&#34;&gt;Neural Radiance Flow for 4D View Synthesis and Video Processing&lt;/a&gt;, Du et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L79-L85&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Du20arxiv_nerflow--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zju3dv.github.io/neuralbody/&#34;&gt;Neural Body: Implicit Neural Representations with Structured Latent Codes for Novel View Synthesis of Dynamic Humans&lt;/a&gt;, Peng et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/neuralbody.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Peng20arxiv_neuralbody--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://neural-3d-video.github.io/&#34;&gt;Neural 3D Video Synthesis&lt;/a&gt;, Li et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/3d-video.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://free-view-video.github.io/&#34;&gt;Dynamic View Synthesis from Dynamic Monocular Video&lt;/a&gt;, Gao et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/dvs_dmv.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Generalization&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.02442&#34;&gt;GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis&lt;/a&gt;, Schwarz et al., NeurIPS 2020 | &lt;a href=&#34;https://github.com/autonomousvision/graf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L237-L243&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Schwarz20neurips_graf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.04595&#34;&gt;GRF: Learning a General Radiance Field for 3D Scene Representation and Rendering&lt;/a&gt;, Trevithick and Yang, Arxiv 2020 | &lt;a href=&#34;https://github.com/alextrevithick/GRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L291-L297&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Trevithick20arxiv_GRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.02190&#34;&gt;pixelNeRF: Neural Radiance Fields from One or Few Images&lt;/a&gt;, Yu et al., CVPR 2021 | &lt;a href=&#34;https://github.com/sxyu/pixel-nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L329-L335&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Yu20arxiv_pixelNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.02189&#34;&gt;Learned Initializations for Optimizing Coordinate-Based Neural Representations&lt;/a&gt;, Tancik et al., CVPR 2021 | &lt;a href=&#34;https://github.com/tancik/learnit&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L268-L274&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Tancik20arxiv_meta--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://marcoamonteiro.github.io/pi-GAN-website/&#34;&gt;pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis&lt;/a&gt;, Chan et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L24-L30&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Chan20arxiv_piGAN--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://portrait-nerf.github.io/&#34;&gt;Portrait Neural Radiance Fields from a Single Image&lt;/a&gt;, Gao et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L95-L101&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Gao20arxiv_pNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2102.08860.pdf&#34;&gt;ShaRF: Shape-conditioned Radiance Fields from a Single View&lt;/a&gt;, Rematas et al., ICML 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/sharf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ibrnet.github.io/static/paper.pdf&#34;&gt;IBRNet: Learning Multi-View Image-Based Rendering&lt;/a&gt;, Wang et al., CVPR 2021 | &lt;a href=&#34;https://github.com/googleinterns/IBRNet&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/ibr.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2103.17269.pdf&#34;&gt;CAMPARI: Camera-Aware Decomposed Generative Neural Radiance Fields&lt;/a&gt;, Niemeyer &amp;amp; Geiger, Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/CAMPARI.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2104.00587.pdf&#34;&gt;NeRF-VAE: A Geometry Aware 3D Scene Generative Model&lt;/a&gt;, Kosiorek et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nerf-vae.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://apple.github.io/ml-gsn/&#34;&gt;Unconstrained Scene Generation with Locally Conditioned Radiance Fields&lt;/a&gt;, DeVries et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/gsn.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://apchenstu.github.io/mvsnerf/&#34;&gt;MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo&lt;/a&gt;, Chen et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/apchenstu/mvsnerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/mvsnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://virtualhumans.mpi-inf.mpg.de/srf/&#34;&gt;Stereo Radiance Fields (SRF): Learning View Synthesis from Sparse Views of Novel Scenes&lt;/a&gt;, Chibane et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/srf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://liuyuan-pal.github.io/NeuRay/&#34;&gt;Neural Rays for Occlusion-aware Image-based Rendering&lt;/a&gt;, Liu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/neuray.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ajayj.com/dietnerf&#34;&gt;Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis&lt;/a&gt;, Matthew Tancik et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/DietNeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vincentfung13.github.io/projects/mine/&#34;&gt;MINE: Towards Continuous Depth MPI with NeRF for Novel View Synthesis&lt;/a&gt;, Jiaxin Li et al., ICCV 2021 | &lt;a href=&#34;https://github.com/vincentfung13/MINE&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/MINE.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://imaging.cs.cmu.edu/torf/&#34;&gt;TöRF: Time-of-Flight Radiance Fields for Dynamic Scene View Synthesis&lt;/a&gt;, Benjamin Attal et al., NeurIPS 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/turf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sites.google.com/view/wbjang/home/codenerf&#34;&gt;CodeNeRF: Disentangled Neural Radiance Fields for Object Categories&lt;/a&gt;, Jang et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/CodeNeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://jiataogu.me/style_nerf/&#34;&gt;StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis&lt;/a&gt;, Gu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/stylenerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bmild.github.io/rawnerf/&#34;&gt;NeRF in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images&lt;/a&gt;, Ben Mildenhall et al, arXiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/rawnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Pose Estimation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://yenchenlin.me/inerf/&#34;&gt;iNeRF: Inverting Neural Radiance Fields for Pose Estimation&lt;/a&gt;, Yen-Chen et al. IROS 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L321-L327&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--YenChen20arxiv_iNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lemonatsu.github.io/ANeRF-Surface-free-Pose-Refinement/&#34;&gt;A-NeRF: Surface-free Human 3D Pose Refinement via Neural Rendering&lt;/a&gt;, Su et al. Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/a-nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Su21arxiv_A_NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nerfmm.active.vision/&#34;&gt;NeRF--: Neural Radiance Fields Without Known Camera Parameters&lt;/a&gt;, Wang et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/ActiveVisionLab/nerfmm&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nerf--.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Wang21arxiv_nerfmm--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://edgarsucar.github.io/iMAP/&#34;&gt;iMAP: Implicit Mapping and Positioning in Real-Time&lt;/a&gt;, Sucar et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/imap.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pengsongyou.github.io/nice-slam&#34;&gt;NICE-SLAM: Neural Implicit Scalable Encoding for SLAM&lt;/a&gt;, Zhu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nice-slam.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.15606&#34;&gt;GNeRF: GAN-based Neural Radiance Field without Posed Camera&lt;/a&gt;, Meng et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/gnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/&#34;&gt;BARF: Bundle-Adjusting Neural Radiance Fields&lt;/a&gt;, Lin et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/barf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://postech-cvlab.github.io/SCNeRF/&#34;&gt;Self-Calibrating Neural Radiance Fields&lt;/a&gt;, Park et al., ICCV 2021 | &lt;a href=&#34;https://github.com/POSTECH-CVLab/SCNeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/SCNeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Lighting&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://markboss.me/publication/2021-nerd/&#34;&gt;NeRD: Neural Reflectance Decomposition from Image Collections&lt;/a&gt;, Boss et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L9-L15&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Boss20arxiv_NeRD--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~pratul/nerv/&#34;&gt;NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis&lt;/a&gt;, Srinivasan et al. CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L260-L266&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Srinivasan20arxiv_NeRV--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nex-mpi.github.io/&#34;&gt;NeX: Real-time View Synthesis with Neural Basis Expansion&lt;/a&gt;, Wizadwongsa et al. Arxiv 2021 | &lt;a href=&#34;https://github.com/nex-mpi/nex-code&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nex.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://people.csail.mit.edu/xiuming/projects/nerfactor/&#34;&gt;NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination&lt;/a&gt;, Zhang et al. Arxiv 2021 | &lt;a href=&#34;https://github.com/google/nerfactor&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nerfactor.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Compositionality&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.07492&#34;&gt;NeRF++: Analyzing and Improving Neural Radiance Fields&lt;/a&gt;, Zhang et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/Kai-46/nerfplusplus&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L345-L351&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Zhang20arxiv_nerf++--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.12100&#34;&gt;GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields&lt;/a&gt;, Niemeyer et al., CVPR 2021, &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L175-L181&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Niemeyer20arxiv_GIRAFFE--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shellguo.com/osf/&#34;&gt;Object-Centric Neural Scene Rendering&lt;/a&gt;, Guo et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L111-L117&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Guo20arxiv_OSF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ziyanw1.github.io/hybrid_nerf/&#34;&gt;Learning Compositional Radiance Fields of Dynamic Human Heads&lt;/a&gt;, Wang et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/hybrid-nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Wang20arxiv_hybrid_NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://light.princeton.edu/neural-scene-graphs/&#34;&gt;Neural Scene Graphs for Dynamic Scenes&lt;/a&gt;, Ost et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L353-L358&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Ost20arxiv_NeuralSceneGraphs--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kovenyu.com/uorf/&#34;&gt;Unsupervised Discovery of Object Radiance Fields&lt;/a&gt;, Yu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/uorf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zju3dv.github.io/object_nerf/&#34;&gt;Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering&lt;/a&gt;, Yang et al., ICCV 2021 | &lt;a href=&#34;https://github.com/zju3dv/object_nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/object-nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--yang2021objectnerf--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Scene Labelling and Understanding&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shuaifengzhi.com/Semantic-NeRF/&#34;&gt;In-Place Scene Labelling and Understanding with Implicit Scene Representation&lt;/a&gt;, Zhi et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/semantic-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Editing&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://editnerf.csail.mit.edu/&#34;&gt;Editing Conditional Radiance Fields&lt;/a&gt;, Liu et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/stevliu/editnerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/editnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jiakai-zhang.github.io/st-nerf/&#34;&gt;Editable Free-viewpoint Video Using a Layered Neural Representation&lt;/a&gt;, Zhang et al., SIGGRAPH 2021 | &lt;a href=&#34;https://github.com/DarlingHang/st-nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/st-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Object Category Modeling&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fig-nerf.github.io/&#34;&gt;FiG-NeRF: Figure Ground Neural Radiance Fields for 3D Object Category Modelling&lt;/a&gt;, Xie et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/fig-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/blog/nvidia-research-nerf-tex-neural-reflectance-field-textures/&#34;&gt;NeRF-Tex: Neural Reflectance Field Textures&lt;/a&gt;, Baatz et al., EGSR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/nerf-tex.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Multi-scale&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jonbarron.info/mipnerf/&#34;&gt;Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields&lt;/a&gt;, Barron et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/google/mipnerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/mip-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Model Reconstruction&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.10078&#34;&gt;UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction&lt;/a&gt;, Oechsle et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/unisurf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.10689&#34;&gt;NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction&lt;/a&gt;, Wang et al., NeurIPS 2021 | &lt;a href=&#34;https://github.com/Totoro97/NeuS&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/neus.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.12052&#34;&gt;Volume Rendering of Neural Implicit Surfaces&lt;/a&gt;, Yariv et al., NeurIPS 2021 | &lt;a href=&#34;https://github.com/ventusff/neurecon&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/volsdf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Depth Estimation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://weiyithu.github.io/NerfingMVS/&#34;&gt;NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-view Stereo&lt;/a&gt;, Wei et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/NerfingMVS.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Talks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=LCTYRqW-ne8&amp;amp;t=10190s&#34;&gt;NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis&lt;/a&gt;, Ben Mildenhall&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nRyOzHpcr4Q&amp;amp;feature=emb_logo&amp;amp;ab_channel=cvprtum&#34;&gt;Understanding and Extending Neural Radiance Fields&lt;/a&gt;, Barron et al.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/Rd0nBO6--bM?t=1992&#34;&gt;Towards Photorealism (2nd half)&lt;/a&gt;, Vladlen Koltun&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=dPWLybp4LL0&#34;&gt;Neural Radiance Fields for View Synthesis&lt;/a&gt;, Matthew Tancik&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Implementations&lt;/h2&gt; &#xA;&lt;h4&gt;Tensorflow&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bmild/nerf&#34;&gt;NeRF&lt;/a&gt;, Mildenhall et al., 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib#L168-L173&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;PyTorch&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yenchenlin/nerf-pytorch&#34;&gt;NeRF-PyTorch&lt;/a&gt;, Yen-Chen Lin, 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/pytorch-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kwea123/nerf_pl&#34;&gt;NeRF-PyTorch-Lighting&lt;/a&gt;, &lt;a href=&#34;https://github.com/kwea123&#34;&gt;@kwea123&lt;/a&gt;, 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kwea123/nerf_pl/tree/nerfw&#34;&gt;NeRF-W&lt;/a&gt;, &lt;a href=&#34;https://github.com/kwea123&#34;&gt;@kwea123&lt;/a&gt;, 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/pytorch3d/tree/master/projects/nerf&#34;&gt;NeRF-PyTorch3D&lt;/a&gt;, &lt;a href=&#34;https://github.com/facebookresearch&#34;&gt;@facebookresearch&lt;/a&gt;, 2020&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Jax&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/google-research/google-research/tree/master/jaxnerf&#34;&gt;JaxNeRF&lt;/a&gt;, Deng et al., 2020 | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/NeRF-and-Beyond.bib#L55-L60&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/google/mipnerf&#34;&gt;Mip-NeRF&lt;/a&gt;, &lt;a href=&#34;https://github.com/google&#34;&gt;@google&lt;/a&gt;, 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/citations/mipnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jamesfang8499/physics3</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/jamesfang8499/physics3</id>
    <link href="https://github.com/jamesfang8499/physics3" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;高中物理甲种本（第三册）重排本&lt;/h1&gt; &#xA;&lt;p&gt;本项目是对高中物理甲种本（第三册）的致敬。虽然该书年代久远（1983—1985年出版，后在上世纪90年代以《高中物理读本》为名再版过），但是内容体系安排比如今的高中教材完整且合理。&lt;/p&gt; &#xA;&lt;p&gt;本重排本是根据网络上找到的此书扫描版电子文档，使用LaTeX制作而成的重排本电子文档（PDF格式）。书中的矢量图片采用电子版教材中的矢量图，或采用Tikz及Tkz-euclide制作而来。其余的点阵图则是来自于扫描版电子文档（限于作者的能力和精力，无法将所有内容均以矢量图全部重绘）。文档当中的电路图基于circuitikz绘制，请使用TeXLive2020以后的版本编译。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;注意：本项目的内容勿用于商业目的。电子版的原教材，可通过如下网址下载：&lt;a href=&#34;https://pan.baidu.com/s/1k2LGR&#34;&gt;https://pan.baidu.com/s/1k2LGR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;补充：高级中学物理（甲种本）第三册教学参考书，包含了各章的教学内容、教学建议、实验指导、习题解答、参考资料等。相关代码在3-ref文件夹中。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;目录&lt;/h1&gt; &#xA;&lt;h2&gt;第一章 磁场&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;磁场&lt;/li&gt; &#xA; &lt;li&gt;磁场的方向磁力线&lt;/li&gt; &#xA; &lt;li&gt;磁现象的电本质磁性材料&lt;/li&gt; &#xA; &lt;li&gt;磁感应强度&lt;/li&gt; &#xA; &lt;li&gt;磁通量&lt;/li&gt; &#xA; &lt;li&gt;直线电流的磁场&lt;/li&gt; &#xA; &lt;li&gt;磁场对电流的作用力&lt;/li&gt; &#xA; &lt;li&gt;电流天平&lt;/li&gt; &#xA; &lt;li&gt;电流表的工作原理&lt;/li&gt; &#xA; &lt;li&gt;磁场对运动电荷的作用力&lt;/li&gt; &#xA; &lt;li&gt;带电粒子在磁场中的运动&lt;/li&gt; &#xA; &lt;li&gt;荷质比的测定质谱仪&lt;/li&gt; &#xA; &lt;li&gt;回旋加速器&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第二章 电磁感应&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;电磁感应现象&lt;/li&gt; &#xA; &lt;li&gt;感生电流的方向楞次定律&lt;/li&gt; &#xA; &lt;li&gt;楞次定律的应用&lt;/li&gt; &#xA; &lt;li&gt;法拉第电磁感应定律&lt;/li&gt; &#xA; &lt;li&gt;电磁感应现象中能量的转化&lt;/li&gt; &#xA; &lt;li&gt;直流电动机的反电动势&lt;/li&gt; &#xA; &lt;li&gt;自感&lt;/li&gt; &#xA; &lt;li&gt;自感现象的应用&lt;/li&gt; &#xA; &lt;li&gt;涡流&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第三章 交流电&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;交流电的产生&lt;/li&gt; &#xA; &lt;li&gt;交流电的变化规律&lt;/li&gt; &#xA; &lt;li&gt;表征交流电的物理量&lt;/li&gt; &#xA; &lt;li&gt;纯电阻电路&lt;/li&gt; &#xA; &lt;li&gt;纯电感电路&lt;/li&gt; &#xA; &lt;li&gt;纯电容电路&lt;/li&gt; &#xA; &lt;li&gt;电感和电容对交流电相位的影响&lt;/li&gt; &#xA; &lt;li&gt;交流电的功率&lt;/li&gt; &#xA; &lt;li&gt;变压器&lt;/li&gt; &#xA; &lt;li&gt;电能的输送&lt;/li&gt; &#xA; &lt;li&gt;交流电的整流&lt;/li&gt; &#xA; &lt;li&gt;滤波&lt;/li&gt; &#xA; &lt;li&gt;三相交流电&lt;/li&gt; &#xA; &lt;li&gt;三相电路的连接&lt;/li&gt; &#xA; &lt;li&gt;感应电动机&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第四章 电磁振荡和电磁波&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;电磁振荡&lt;/li&gt; &#xA; &lt;li&gt;电磁振荡的周期和频率&lt;/li&gt; &#xA; &lt;li&gt;电磁场&lt;/li&gt; &#xA; &lt;li&gt;电磁波&lt;/li&gt; &#xA; &lt;li&gt;赫兹实验&lt;/li&gt; &#xA; &lt;li&gt;电磁波的发送（一） 开放电路&lt;/li&gt; &#xA; &lt;li&gt;电磁波的发送（二） 调制&lt;/li&gt; &#xA; &lt;li&gt;电磁波的接收（一） 电谐振&lt;/li&gt; &#xA; &lt;li&gt;电磁波的接收（二） 检波&lt;/li&gt; &#xA; &lt;li&gt;传真电视雷达&lt;/li&gt; &#xA; &lt;li&gt;电磁波的传播&lt;/li&gt; &#xA; &lt;li&gt;电子技术一瞥&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第五章 光的反射和折射&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;光的直线传播&lt;/li&gt; &#xA; &lt;li&gt;光的速度&lt;/li&gt; &#xA; &lt;li&gt;光的反射平面镜&lt;/li&gt; &#xA; &lt;li&gt;球面镜&lt;/li&gt; &#xA; &lt;li&gt;光的折射&lt;/li&gt; &#xA; &lt;li&gt;折射率&lt;/li&gt; &#xA; &lt;li&gt;全反射&lt;/li&gt; &#xA; &lt;li&gt;棱镜&lt;/li&gt; &#xA; &lt;li&gt;透镜&lt;/li&gt; &#xA; &lt;li&gt;透镜成像&lt;/li&gt; &#xA; &lt;li&gt;透镜成像作图法&lt;/li&gt; &#xA; &lt;li&gt;透镜成像公式&lt;/li&gt; &#xA; &lt;li&gt;眼睛&lt;/li&gt; &#xA; &lt;li&gt;显微镜和望远镜&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第六章 光的波动性&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;光的微粒说和波动说&lt;/li&gt; &#xA; &lt;li&gt;光的干涉&lt;/li&gt; &#xA; &lt;li&gt;薄膜干涉及其应用&lt;/li&gt; &#xA; &lt;li&gt;光的衍射&lt;/li&gt; &#xA; &lt;li&gt;光的偏振&lt;/li&gt; &#xA; &lt;li&gt;光的电磁说&lt;/li&gt; &#xA; &lt;li&gt;电磁波谱&lt;/li&gt; &#xA; &lt;li&gt;光谱&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第七章 光的粒子性&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;光电效应&lt;/li&gt; &#xA; &lt;li&gt;爱因斯坦对光电效应的解释&lt;/li&gt; &#xA; &lt;li&gt;光电效应的应用&lt;/li&gt; &#xA; &lt;li&gt;光的波粒二象性&lt;/li&gt; &#xA; &lt;li&gt;物质波&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第八章 原子结构&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;电子的发现&lt;/li&gt; &#xA; &lt;li&gt;原子的核式结构的发现&lt;/li&gt; &#xA; &lt;li&gt;玻尔的原子理论&lt;/li&gt; &#xA; &lt;li&gt;玻尔原子理论对氢光谱的解释&lt;/li&gt; &#xA; &lt;li&gt;玻尔原子理论的困难和量子力学&lt;/li&gt; &#xA; &lt;li&gt;原子的受激辐射激光&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第九章 原子核&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;天然放射现象&lt;/li&gt; &#xA; &lt;li&gt;探测放射线的方法&lt;/li&gt; &#xA; &lt;li&gt;原子核的人工转变原子核的组成&lt;/li&gt; &#xA; &lt;li&gt;放射性同位素及其应用&lt;/li&gt; &#xA; &lt;li&gt;原子核的结合能&lt;/li&gt; &#xA; &lt;li&gt;重核的裂变&lt;/li&gt; &#xA; &lt;li&gt;轻核的聚变&lt;/li&gt; &#xA; &lt;li&gt;基本粒子&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第十章 学生实验&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;观察磁铁对电流的作用&lt;/li&gt; &#xA; &lt;li&gt;研究电磁感应现象&lt;/li&gt; &#xA; &lt;li&gt;用示波器观察交流电的波形&lt;/li&gt; &#xA; &lt;li&gt;用示波器观察交流电的整流和滤波&lt;/li&gt; &#xA; &lt;li&gt;研究变压器的作用&lt;/li&gt; &#xA; &lt;li&gt;安装简单的收音机&lt;/li&gt; &#xA; &lt;li&gt;测定玻璃的折射率&lt;/li&gt; &#xA; &lt;li&gt;测定凸透镜的焦距&lt;/li&gt; &#xA; &lt;li&gt;组成显微镜模型&lt;/li&gt; &#xA; &lt;li&gt;利用双缝干涉测定光波的波长&lt;/li&gt; &#xA; &lt;li&gt;观察光的衍射现象&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;附录A 课外实验活动&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;自制指南针&lt;/li&gt; &#xA; &lt;li&gt;验证环形电流的磁场&lt;/li&gt; &#xA; &lt;li&gt;验证通电螺线管的南北极&lt;/li&gt; &#xA; &lt;li&gt;观察磁化现象&lt;/li&gt; &#xA; &lt;li&gt;判断指南针的偏转方向&lt;/li&gt; &#xA; &lt;li&gt;自制测电笔&lt;/li&gt; &#xA; &lt;li&gt;测定水的折射率&lt;/li&gt; &#xA; &lt;li&gt;测定凹透镜的焦距&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;附录B 常用电磁学量的国际制单位&lt;/h2&gt; &#xA;&lt;h2&gt;附录C 常用的物理恒量&lt;/h2&gt; &#xA;&lt;h2&gt;附录D 用于构成十进倍数和分数单位的词头&lt;/h2&gt;</summary>
  </entry>
  <entry>
    <title>wangshusen/DeepLearning</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/wangshusen/DeepLearning</id>
    <link href="https://github.com/wangshusen/DeepLearning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CS583: Deep Learning&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Machine learning basics.&lt;/strong&gt; This part briefly introduces the fundamental ML problems-- regression, classification, dimensionality reduction, and clustering-- and the traditional ML models and numerical algorithms for solving the problems.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;ML basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/1_ML_Basics.pdf&#34;&gt;slides-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/1_Models.pdf&#34;&gt;slides-2&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Regression [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/2_Regression_1.pdf&#34;&gt;slides-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/2_Regression_2.pdf&#34;&gt;slides-2&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Classification.&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;Logistic regression [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Classification_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/Logistic/paper/logistic.pdf&#34;&gt;lecture note&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;SVM [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Classification_2.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;Softmax classifier [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Classification_3.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;KNN classifier [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Classification_4.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Regularizations [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Optimization.pdf&#34;&gt;slides-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Regularizations.pdf&#34;&gt;slides-2&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Clustering [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/3_Clustering.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Dimensionality reduction [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/5_DR_1.pdf&#34;&gt;slides-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/5_DR_2.pdf&#34;&gt;slides-2&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/SVD/svd.pdf&#34;&gt;lecture note&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Scientific computing libraries. [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/5_DR_3.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Neural network basics.&lt;/strong&gt; This part covers the multilayer perceptron, backpropagation, and deep learning libraries, with focus on Keras.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Multilayer perceptron and backpropagation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/6_NeuralNet_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/BP/bp.pdf&#34;&gt;lecture note&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Keras [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/6_NeuralNet_2.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Further reading:&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;[&lt;a href=&#34;https://adl1995.github.io/an-overview-of-activation-functions-used-in-neural-networks.html&#34;&gt;activation functions&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;[&lt;a href=&#34;https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&#34;&gt;parameter initialization&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;[&lt;a href=&#34;http://ruder.io/optimizing-gradient-descent/&#34;&gt;optimization algorithms&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Convolutional neural networks (CNNs).&lt;/strong&gt; This part is focused on CNNs and its application to computer vision problems.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;CNN basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_1.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Tricks for improving test accuracy [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_2.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Feature scaling and batch normalization [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_3.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Advanced topics on CNNs [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_4.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Popular CNN architectures [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/7_CNN_5.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Further reading:&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;[style transfer (Section 8.1, Chollet&#39;s book)]&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;[visualize CNN (Section 5.4, Chollet&#39;s book)]&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Recurrent neural networks (RNNs).&lt;/strong&gt; This part introduces RNNs and its applications in natural language processing (NLP).&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Categorical feature processing [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_0.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/NWcShtqr8kc&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Text processing and word embedding [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/6_2_2CPB97s&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;RNN basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/Cc4ENs6BHQw&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;LSTM [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&#34;&gt;reference&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/vTouAvxlphc&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Making RNNs more effective [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_4.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/pzWHk_M23a0&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Text generation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_5.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/10cjvcrU_ZU&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Machine translation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_6.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/gxXJ58LR684&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Attention [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_8.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/B3uws4cLcFw&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/XhWdv7ghmQQ&#34;&gt;video (Chinese)&lt;/a&gt;] [&lt;a href=&#34;https://distill.pub/2016/augmented-rnns/&#34;&gt;reference&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Self-attention [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_9.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/06r6kp7ujCA&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/Vr4UNt7X6Gw&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Image caption generation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/9_RNN_7.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/&#34;&gt;reference&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transformer Models.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Transformer (1/2): attention without RNN [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/10_Transformer_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/FC8PziPmxnQ&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/aButdUV0dxI&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Transformer (2/2): from shallow to deep [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/10_Transformer_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/J4H6A4-dvhE&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/aJRsr39F4dI&#34;&gt;video (Chinese)&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/pdf/1706.03762.pdf&#34;&gt;reference&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;BERT: pre-training Transformer [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/10_BERT.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/EOmd5sUUA_A&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/UlC6AjQWao8&#34;&gt;video (Chinese)&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/pdf/1810.04805.pdf&#34;&gt;reference&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Vision Transformer (ViT) [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/10_ViT.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/HZ4j_U3FC94&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/BbzOZ9THriY&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Autoencoders.&lt;/strong&gt; This part introduces autoencoders for dimensionality reduction and image generation.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Autoencoder for dimensionality reduction [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/8_AE_1.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Variational Autoencoders (VAEs) for image generation [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/8_AE_2.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Generative Adversarial Networks (GANs).&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;DC-GAN [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/12_GAN.pdf&#34;&gt;slides&lt;/a&gt;].&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deep Reinforcement Learning.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Reinforcement learning basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/DRL/DRL.pdf&#34;&gt;lecture note&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/vmkRMvhCW5c&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Value-based learning [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/jflq6vNcZyA&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Policy-based learning [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/qI0vyfR2_Rc&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Actor-critic methods [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_4.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/xjd7Jq9wPQY&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;AlphaGo and Monte Carlo tree search [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/13_RL_5.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/zHojAp5vkRE&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Parallel Computing.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Basics and MapReduce [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/14_Parallel_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/Parallel/Parallel.pdf&#34;&gt;lecture note&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/gVcnOe6_c6Q&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Parameter server and decentralized network [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/14_Parallel_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/Aga2Lxp3G7M&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;TensorFlow&#39;s mirrored strategy and ring all-reduce [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/14_Parallel_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/rj-hjS5L8Bw&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Federated learning [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/14_Parallel_4.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/STxtRucv_zo&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Adversarial Robustness.&lt;/strong&gt; This part introduces how to attack neural networks using adversarial examples and how to defend from the attack.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Data evasion attack and defense [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/11_Evasion.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/LectureNotes/Adversarial/DataAttacks.pdf&#34;&gt;lecture note&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Data poisoning attack [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/11_Poisoning.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/_K0nZcqdu5w&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Further reading: [&lt;a href=&#34;https://adversarial-ml-tutorial.org/&#34;&gt;Adversarial Robustness - Theory and Practice&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Meta Learning.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Few-shot learning: basic concepts [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/16_Meta_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/hE7eGew4eeg&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/UkQ2FVpDxHg&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Siamese network [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/16_Meta_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/4S-XDefSjTM&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/Er8xH_k0Vj4&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Pretraining + fine tuning [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/16_Meta_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/U6uFOIURcD0&#34;&gt;video (English)&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/3zSYMuDm6RU&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Neural Architecture Search (NAS).&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Basics [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/15_NAS_1.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/voWgnMpFaW8&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;RNN + Reinforcement Learning: [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/15_NAS_2.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/AmitvRzmvv0&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Differentiable NAS: [&lt;a href=&#34;https://github.com/wangshusen/DeepLearning/raw/master/Slides/15_NAS_3.pdf&#34;&gt;slides&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/D9m9-CXw_HY&#34;&gt;video (Chinese)&lt;/a&gt;].&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>latex3/latex2e</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/latex3/latex2e</id>
    <link href="https://github.com/latex3/latex2e" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The LaTeX2e kernel&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The LaTeX2e Kernel Code Repository&lt;/h1&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Important notice:&lt;/strong&gt; This repository holds the unpackaged sources of LaTeX2e as well as code under development in various branches. For this reason it is only of interest to a small number of developers in this form and building a working version from the sources is a non-trivial exercise.&lt;/p&gt; &#xA; &lt;p&gt;The normal way to obtain LaTeX is therefore not to get it from this repository, but through the packaged version available from &lt;a href=&#34;https://ctan.org&#34;&gt;https://ctan.org&lt;/a&gt; and automatically distributed as part of major TeX distributions such as TeXLive, MacTeX or MiKTeX.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;This repository hosts development of the core LaTeX distribution, which comprises:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The LaTeX kernel itself (&lt;code&gt;base&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;LaTeX team documentation (&lt;code&gt;doc&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Bundles which must be available (&lt;code&gt;required&lt;/code&gt;). These are &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Essential tools (&lt;code&gt;tools&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Core graphics and color support (&lt;code&gt;graphics&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Key mathematics support (&lt;code&gt;amsmath&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;First aid for LaTeX (&lt;code&gt;firstaid&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;LaTeX laboratory (&lt;code&gt;latex-lab&lt;/code&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The main public Git repository is hosted on &lt;a href=&#34;https://github.com/latex3/latex2e&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note that Babel moved to its own repository in 2019: &lt;a href=&#34;https://github.com/latex3/babel&#34;&gt;GitHub&lt;/a&gt;; any issues related to Babel should be reported there.&lt;/p&gt; &#xA;&lt;p&gt;From 2020 onwards LaTeX includes the L3 programming layer as part of the format. The code for this layer is hosted in its own repository: &lt;a href=&#34;https://github.com/latex3/latex3&#34;&gt;GitHub&lt;/a&gt;; any issues directly related to commands from that layer should preferably be reported there.&lt;/p&gt; &#xA;&lt;h2&gt;LaTeX Version number&lt;/h2&gt; &#xA;&lt;p&gt;The LaTeX version is defined in the file &lt;code&gt;ltvers.dtx&lt;/code&gt; in the two commands &lt;code&gt;\fmtversion&lt;/code&gt; (the main version) and &lt;code&gt;\patch@level&lt;/code&gt; (the patch level). A negative patch level indicates a pretest version.&lt;/p&gt; &#xA;&lt;p&gt;Each component of the core distribution contains a &lt;code&gt;README&lt;/code&gt; file which is tagged with the appropriate release string prior to upload to CTAN.&lt;/p&gt; &#xA;&lt;h2&gt;Issues&lt;/h2&gt; &#xA;&lt;p&gt;Only issues &lt;em&gt;specifically related to these components&lt;/em&gt; should be logged &lt;a href=&#34;https://github.com/latex3/latex2e/issues&#34;&gt;with the team on GitHub&lt;/a&gt;. The LaTeX ecosystem is large, and there are &lt;em&gt;many&lt;/em&gt; (thousands) of additional packages not maintained by us: issues related to the use of those need to be reported to the relevant maintainers because we are usually unable to help in that case.&lt;/p&gt; &#xA;&lt;p&gt;To help you making the right decision where to report an issue we ask to start your minimal example file showing the problem &lt;em&gt;always&lt;/em&gt; with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;\RequirePackage{latexbug}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Please look at the report generated from &lt;code&gt;latexbug&lt;/code&gt; and if it indicates that you are using packages not maintained by the LaTeX Project check if your problem is still present after removing them. If so contact the maintainers of these third-party packages and file a bug report with them.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;More details on creating issue reports for the core LaTeX distribution are given in our &lt;a href=&#34;https://raw.githubusercontent.com/latex3/latex2e/develop/CONTRIBUTING.md&#34;&gt;CONTRIBUTING guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;We are unable to provide advice/support here: community sites such as &lt;a href=&#34;http://tex.stackexchange.com&#34;&gt;TeX-LaTeX StackExchange&lt;/a&gt; and &lt;a href=&#34;http://latex-community.org&#34;&gt;The LaTeX Community&lt;/a&gt; are available for general help. See also &lt;a href=&#34;https://www.latex-project.org/help&#34;&gt;the help pages on our website&lt;/a&gt; for further suggestions.&lt;/p&gt; &#xA;&lt;h2&gt;Code fixes&lt;/h2&gt; &#xA;&lt;p&gt;Changes to the core LaTeX distribution have to be approached bearing in mind the importance of maintaining stability. This means that all changes have to be carefully weighed up, balancing the issues addressed by a change with the effects on existing documents. We strongly suggest raising suggestions on the &lt;a href=&#34;https://listserv.uni-heidelberg.de/cgi-bin/wa?A0=latex-l&#34;&gt;LaTeX-L mailing list&lt;/a&gt; early.&lt;/p&gt; &#xA;&lt;p&gt;You can subscribe to the LaTeX-L mailing list by sending mail to&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;listserv@urz.uni-heidelberg.de&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;with the body containing&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;subscribe LATEX-L &amp;lt;Your-First-Name&amp;gt; &amp;lt;Your-Second-Name&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Development team&lt;/h2&gt; &#xA;&lt;p&gt;The LaTeX kernel is developed by &lt;a href=&#34;https://latex-project.org&#34;&gt;The LaTeX Project&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Copyright&lt;/h2&gt; &#xA;&lt;p&gt;This README file is&lt;/p&gt; &#xA;&lt;p&gt;Copyright (C) 2019-2021 The LaTeX Project&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>corona-warn-app/cwa-documentation</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/corona-warn-app/cwa-documentation</id>
    <link href="https://github.com/corona-warn-app/cwa-documentation" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Project overview, general documentation, and white papers.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.coronawarn.app/en/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/images/CWA_title.png&#34; width=&#34;400&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/#about-this-project&#34;&gt;About this Project&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/#who-we-are&#34;&gt;Who We Are&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/#credits&#34;&gt;Credits&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/#data-privacy&#34;&gt;Data Privacy&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/#code-of-conduct&#34;&gt;Code of Conduct&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/#working-language&#34;&gt;Working Language&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/#our-documentation&#34;&gt;Our Documentation&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/#licensing&#34;&gt;Licensing&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/#how-to-contribute&#34;&gt;How to Contribute&lt;/a&gt; • &lt;a href=&#34;https://www.coronawarn.app/en/&#34;&gt;Website&lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Corona-Warn-App: Documentation&lt;/h1&gt; &#xA;&lt;p&gt;NOTE: This README is also available &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/translations/README.de.md&#34;&gt;in German&lt;/a&gt;. Thank you for understanding that the German version might not always be up-to-date with the English one.&lt;/p&gt; &#xA;&lt;p&gt;HINWEIS: Diese README ist ebenfalls &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/translations/README.de.md&#34;&gt;auf Deutsch&lt;/a&gt; verfügbar. Bitte haben Sie Verständnis, dass die deutsche Version nicht immer auf dem gleichen Stand wie die englische Version ist.&lt;/p&gt; &#xA;&lt;h2&gt;About this Project&lt;/h2&gt; &#xA;&lt;p&gt;We are developing the official COVID-19 exposure notification app for Germany, called &#34;&lt;a href=&#34;https://www.coronawarn.app/en/&#34;&gt;Corona-Warn-App&lt;/a&gt;&#34;. This project has the goal to develop an app based on technology with a decentralized approach - heavily inspired by the &lt;a href=&#34;https://github.com/DP-3T/documents&#34;&gt;DP-3T&lt;/a&gt; (Decentralized Privacy-Preserving Proximity Tracing, see &lt;a href=&#34;https://github.com/DP-3T/documents/tree/master/public_engagement/cartoon&#34;&gt;this comic&lt;/a&gt; for concept explanation) and &lt;a href=&#34;https://tcn-coalition.org/&#34;&gt;TCN&lt;/a&gt; protocols and based on the &lt;a href=&#34;https://www.apple.com/covid19/contacttracing/&#34;&gt;Privacy-Preserving Contact Tracing specifications&lt;/a&gt; by Apple and Google. Like DP-3T and the TCN Protocol, the apps and backend infrastructure will be entirely open source - licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;! The apps (for iOS and Android) will collect pseudonymous data from nearby mobile phones using Bluetooth technology. The data will be stored locally on each device preventing access and control over data by authorities or anyone else. We will meet the applicable data protection standards and guarantee a high level of IT security. By doing so, we are addressing people&#39;s privacy concerns and thereby aiming to increase the adoption of the app.&lt;/p&gt; &#xA;&lt;h2&gt;Who We Are&lt;/h2&gt; &#xA;&lt;p&gt;The German government has commissioned SAP and Deutsche Telekom to develop the Corona-Warn-App for Germany as open source software. Deutsche Telekom is providing the network and mobile technology and will operate and run the backend for the app in a safe, scalable and stable manner. SAP is responsible for the app development, its framework and the underlying platform. Therefore, development teams of SAP and Deutsche Telekom are contributing to this project. At the same time our commitment to open source means that we are enabling -in fact encouraging- all interested parties to contribute and become part of its developer community.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;d like to thank all the partners who have been involved in this enormous project from the beginning. The project would not be where it is today without all the exploration and great work that had already been done around the &lt;a href=&#34;https://github.com/pepp-pt/pepp-pt-documentation&#34;&gt;PEPP-PT&lt;/a&gt; approach by partners on a European and national level. We will build on top of some of these components and appreciate how everyone is dedicated to making this new approach successful. Moreover, we would like to thank GitHub for their great support.&lt;/p&gt; &#xA;&lt;h2&gt;Data Privacy&lt;/h2&gt; &#xA;&lt;p&gt;In this project we are strictly observing the principles of the General Data Protection Regulation (GDPR) to protect the users’ privacy. We are processing necessary data only - exclusively for the purpose to let users know if they have come into close contact with other infected users, without revealing each other&#39;s identity. The compliance with these regulations is safeguarded by several procedures, e.g. by implementing technical and organizational measures adhering diligently to the high standards of the GDPR. Of course, the app will provide users with a comprehensive privacy statement to be as transparent and clear as possible. As we are developing the app as an open source project, the community can review it. We appreciate your feedback!&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://www.contributor-covenant.org/&#34;&gt;Contributor Covenant&lt;/a&gt; in version 2.0 as our code of conduct. Please see the details in our &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/CODE_OF_CONDUCT.md&#34;&gt;CODE_OF_CONDUCT.md&lt;/a&gt;. All contributors must abide by the code of conduct.&lt;/p&gt; &#xA;&lt;h2&gt;Working Language&lt;/h2&gt; &#xA;&lt;p&gt;We are building this application for Germany. We want to be as open and transparent as possible, also to interested parties in the global developer community who do not speak German. Consequently, all content will be made available primarily in &lt;em&gt;English&lt;/em&gt;. We also ask all interested people to use English as language to create issues, in their code (comments, documentation etc.) and when you send requests to us. The application itself, documentation and all end-user facing content has - of course - been made available in German. Apart from the initial release in English and German, other languages have been added over time including Bulgarian, Polish, Romanian and Turkish. See the &lt;a href=&#34;https://www.coronawarn.app/en/faq/#available_languages&#34;&gt;FAQ available languages&lt;/a&gt; entry for more details. We also try to make developer documentation available in German, but please understand that focusing on the &lt;em&gt;Lingua Franca&lt;/em&gt; of the global developer community makes the development of this application as efficient as possible.&lt;/p&gt; &#xA;&lt;h2&gt;Our Documentation&lt;/h2&gt; &#xA;&lt;p&gt;This repository contains the developer documentation and related content.&lt;/p&gt; &#xA;&lt;h3&gt;Project Scope&lt;/h3&gt; &#xA;&lt;p&gt;The project scope has been agreed on jointly by Deutsche Telekom AG and SAP SE as contractors and the German Federal Government and the Robert-Koch-Institut as clients. The project scope might change over time as new requirements need to be included or existing ones change. We appreciate feedback to all elements of this project scope document. However, additional features or any other content changes beyond fixes to grammatical issues or typos need to be aligned on by these partners before they can be included in the document. Thank you for your understanding!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/scoping_document.md&#34;&gt;Corona-Warn-App - Scoping Document&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/ui_screens.md&#34;&gt;Corona-Warn-App - User Interface Screens&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Technical Documentation&lt;/h3&gt; &#xA;&lt;p&gt;The technical documents are intended for a technical audience and represent the most recent state of the architecture. The solution architecture and concepts might change over time as external dependencies (e.g. the framework provided by Apple/Google) are still changing and new requirements need to be included or existing ones change. We appreciate feedback to all elements of these technical documents.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/solution_architecture.md&#34;&gt;Corona-Warn-App - Solution Architecture&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-server/raw/main/docs/ARCHITECTURE.md&#34;&gt;Corona-Warn-App Server Architecture&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-verification-server/raw/master/docs/architecture-overview.md&#34;&gt;Corona-Warn-App Verification Server Software Design&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-verification-portal/raw/master/docs/architecture-overview.md&#34;&gt;Corona-Warn-App Verification Portal Server Software Design&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-testresult-server/raw/master/docs/architecture-overview.md&#34;&gt;Corona-Warn-App Test Result Server Software Design&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-app-android/raw/main/docs/architecture-overview.md&#34;&gt;Corona-Warn-App Mobile Client (Android) Architecture&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-app-ios/raw/main/docs/architecture-overview.md&#34;&gt;Corona-Warn-App Mobile Client (iOS) Architecture&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/pruefsteine.md&#34;&gt;Criteria for the Evaluation of Contact Tracing Apps&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/overview-security.md&#34;&gt;Corona-Warn-App Security Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/backend-infrastructure-architecture.pdf&#34;&gt;Corona-Warn-App Backend Infrastructure Architecture Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/solution_architecture.md#mobile-applications&#34;&gt;How does the Corona-Warn-App identify an increased risk?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/transmission_risk.pdf&#34;&gt;Epidemiological Motivation of the Transmission Risk Level (PDF)&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/transmission_risk.Rmd&#34;&gt;(Rmd file)&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/transmission_risk_references.bib&#34;&gt;(bib references)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung.pdf&#34;&gt;Corona-Warn-App Data Privacy Impact Assessment/DPIA (PDF, German)&lt;/a&gt;, &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage1a.pdf&#34;&gt;DPIA Annex 1a&lt;/a&gt;, &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage1b.pdf&#34;&gt;DPIA Annex 1b&lt;/a&gt;, &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage1c.pdf&#34;&gt;DPIA Annex 1c&lt;/a&gt;, &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage2.pdf&#34;&gt;DPIA Annex 2&lt;/a&gt;, &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage3.pdf&#34;&gt;DPIA Annex 3&lt;/a&gt;, &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage4.pdf&#34;&gt;DPIA Annex 4&lt;/a&gt;, &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage5.pdf&#34;&gt;DPIA Annex 5&lt;/a&gt;, &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage6.pdf&#34;&gt;DPIA Annex 6&lt;/a&gt;, &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage7.pdf&#34;&gt;DPIA Annex 7&lt;/a&gt; and &lt;a href=&#34;https://www.coronawarn.app/assets/documents/cwa-datenschutz-folgenabschaetzung-anlage8.pdf&#34;&gt;DPIA Annex 8&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/2020_06_24_Corona_API_measurements.pdf&#34;&gt;Exposure Notification API Testing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/event_registration.md&#34;&gt;Event Registration&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To be published:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;System Operation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Glossary&lt;/h3&gt; &#xA;&lt;p&gt;For an easier understanding of the used acronyms and special terms in our documents please see our &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/glossary.md&#34;&gt;glossary&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Repositories&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Repository&lt;/th&gt; &#xA;   &lt;th&gt;Description &amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-app-android&#34;&gt;cwa-app-android&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Native Android app using the Apple/Google exposure notification API. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-app-ccl&#34;&gt;cwa-app-ccl&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Common Covid Logic (CCL) for Android and iOS.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-app-ios&#34;&gt;cwa-app-ios&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Native iOS app using the Apple/Google exposure notification API. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-dcc-server&#34;&gt;cwa-dcc-server&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Backend implementation of the process to issue EU Digital Covid Certificate CovidCertificate.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-documentation&#34;&gt;cwa-documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Project overview, general documentation and white papers. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-event-landingpage&#34;&gt;cwa-event-landingpage&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Landing page for CWA which opens if the user does not have the app installed. &amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-event-qr-code&#34;&gt;cwa-event-qr-code&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Utility to generate QR codes for Event Registration. &amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-hotline&#34;&gt;cwa-hotline&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Contains all issues reg. the hotlines of the CWA.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&amp;nbsp;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-kotlin-jfn&#34;&gt;cwa-kotlin-jfn&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;JsonFunctions Engine - DCC Logic.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-log-upload&#34;&gt;cwa-log-upload&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Counterpart of the log upload in the app. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-map-backend&#34;&gt;cwa-map-backend&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Backend of map.schnelltestportal.de.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-map-public-frontend&#34;&gt;cwa-map-public-frontend&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Public frontend of map.schnelltestportal.de.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-ppa-server&#34;&gt;cwa-ppa-server&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Backend implementation for the privacy-preserving analytics server. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-quick-test-backend&#34;&gt;cwa-quick-test-backend&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Backend implementation of the rapid antigen test portal and API for participating partners.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-quick-test-frontend&#34;&gt;cwa-quick-test-frontend&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Frontend implementation of the rapid antigen test portal for participating partners. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-quicktest-onboarding&#34;&gt;cwa-quicktest-onboarding&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Documentation about onboarding procedure for rapid antigen test partners.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-server&#34;&gt;cwa-server&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Backend implementation for the Apple/Google exposure notification API. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-testresult-server&#34;&gt;cwa-testresult-server&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Receives PCR test results from connected laboratories. &amp;nbsp;&amp;nbsp; &amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-verification-iam&#34;&gt;cwa-verification-iam&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The identity and access management to interact with the verification server. &amp;nbsp;&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-verification-portal&#34;&gt;cwa-verification-portal&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The portal to interact with the verification server. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-verification-server&#34;&gt;cwa-verification-server&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Backend implementation of the verification process. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-website&#34;&gt;cwa-website&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The official website for the Corona-Warn-App. &amp;nbsp;&amp;nbsp; &amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/cwa-wishlist&#34;&gt;cwa-wishlist&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Community feature requests. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/corona-warn-app/dcc-rule-translation&#34;&gt;dcc-rule-translation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Translations of Booster Notification Rules.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Licensing&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (c) 2020-2022 Deutsche Telekom AG and SAP SE or an SAP affiliate company.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the &lt;strong&gt;Apache License, Version 2.0&lt;/strong&gt; (the &#34;License&#34;); you may not use this file except in compliance with the License.&lt;/p&gt; &#xA;&lt;p&gt;You may obtain a copy of the License at &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for the specific language governing permissions and limitations under the License.&lt;/p&gt; &#xA;&lt;!-- The website of the Bundesregierung has implemented additional security which causes a 503 error (service unavailable) when any link on their site is tested automatically. --&gt; &#xA;&lt;!-- markdown-link-check-disable --&gt; &#xA;&lt;p&gt;The &#34;Corona-Warn-App&#34; logo is a registered trademark of The Press and Information Office of the Federal Government. For more information please see &lt;a href=&#34;https://www.bundesregierung.de/breg-en/federal-government/federal-press-office&#34;&gt;bundesregierung.de&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!-- markdown-link-check-enable --&gt; &#xA;&lt;h2&gt;How to Contribute&lt;/h2&gt; &#xA;&lt;p&gt;Please see our &lt;a href=&#34;https://raw.githubusercontent.com/corona-warn-app/cwa-documentation/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for details on how to contribute, our team setup, the project structure and additional details which you need to know to work with us.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>tuhdo/os01</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/tuhdo/os01</id>
    <link href="https://github.com/tuhdo/os01" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bootstrap yourself to write an OS from scratch. A book for self-learner.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://www.paypal.com/cgi-bin/webscr?cmd=_donations&amp;amp;business=tuhdo1710%40gmail%2ecom&amp;amp;lc=VN&amp;amp;item_number=tuhdo&amp;amp;currency_code=USD&amp;amp;bn=PP%2dDonationsBF%3aDonate%2dPayPal%2dgreen%2esvg%3aNonHosted&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Donate-PayPal-green.svg?sanitize=true&#34; alt=&#34;Donate&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://tuhdo.github.io/os01/&#34;&gt;Operating Systems: From 0 to 1&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;This book helps you gain the foundational knowledge required to write an operating system from scratch. Hence the title, 0 to 1.&lt;/p&gt; &#xA;&lt;p&gt;After completing this book, at the very least you will learn:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;How to write an operating system from scratch by reading hardware datasheets. In the real world, it works like that. You won&#39;t be able to consult Google for a quick answer.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;A big picture of how each layer of a computer is related to the other, from hardware to software.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Write code independently. It&#39;s pointless to copy and paste code. Real learning happens when you solve problems on your own. Some examples are given to kick start, but most problems are yours to conquer. However, the solutions are available online for you to examine after giving it a good try.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Linux as a development environment and how to use common tools for low-level programming.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;x86 assembly in-depth.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;How a program is structured so that an operating system can run.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;How to debug a program running directly on hardware with gdb and QEMU.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Linking and loading on bare metal x86_64, with pure C. No standard library. No runtime overhead.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tuhdo/os01/raw/master/Operating_Systems_From_0_to_1.pdf&#34;&gt;Download the book&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;The pedagogy of the book&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;You give a poor man a fish and you feed him for a day. You teach him to fish and you give him an occupation that will feed him for a lifetime.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;This has been the guiding principle of the book when I was writing it. The book does not try to teach you everything, but enough to enable you to learn by yourself. The book itself, at this point, is quite &#34;complete&#34;: once you master part 1 and part 2 (which consist of 8 chapters), you can drop the book and learn by yourself. At this point, smart readers should be able to continue on their own. For example, they can continue their journeys on &lt;a href=&#34;http://wiki.osdev.org/Main_Page&#34;&gt;OSDev wiki&lt;/a&gt;; in fact, after you study everything in part 1 and part 2, you only meet the &lt;a href=&#34;http://wiki.osdev.org/Required_Knowledge&#34;&gt;minimum requirement&lt;/a&gt; by OSDev Wiki (well, not quite, the book actually goes deeper for the suggested topics). Or, if you consider developing an OS for fun is impractical, you can continue with a Linux-specific book, such as this free book &lt;a href=&#34;https://0xax.gitbooks.io/linux-insides/content/&#34;&gt;Linux Insides&lt;/a&gt;, or other popular Linux kernel books. The book tries hard to provide you a strong foundation, and that&#39;s why part 1 and part 2 were released first.&lt;/p&gt; &#xA;&lt;p&gt;The book teaches you core concepts, such as x86 Assembly, ELF, linking and debugging on bare metal, etc., but more importantly, where such information come from. For example, instead of just teaching x86 Assembly, it also teaches how to use reference manuals from Intel. Learning to read the official manuals is important because only the hardware manufacturers themselves understand how their hardware work. If you only learn from the secondary resources because it is easier, you will never gain a complete understanding of the hardware you are programming for. Have you ever read a book on Assembly, and wondered where all the information came from? How does the author know everything he says is correct? And how one seems to magically know so much about hardware programming? This book gives pointers to such questions.&lt;/p&gt; &#xA;&lt;p&gt;As an example, you should skim through chapter 4, &#34;x86 Assembly and C&#34;, to see how it makes use of the Intel manual, Volume 2. And in the process, it guides you how to use the official manuals.&lt;/p&gt; &#xA;&lt;p&gt;Part 3 is planned as a series of specifications that a reader will implement to complete each operating system component. It does not contain code aside from a few examples. Part 3 is just there to shorten the reader&#39;s time when reading the official manuals by giving hints where to read, explaining difficult concepts and how to use the manuals to debug. In short, the implementation is up to the reader to work on his or her own; the chapters are just like university assignments.&lt;/p&gt; &#xA;&lt;h1&gt;Prerequisites&lt;/h1&gt; &#xA;&lt;p&gt;Know some circuit concepts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Basic Concepts of Electricity: atoms, electrons, protons, neutrons, current flow.&lt;/li&gt; &#xA; &lt;li&gt;Ohm&#39;s law&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;However, if you know absolutely nothing about electricity, you can quickly learn it here: &lt;a href=&#34;http://www.allaboutcircuits.com/textbook/&#34;&gt;http://www.allaboutcircuits.com/textbook/&lt;/a&gt;, by reading chapter 1 and chapter 2.&lt;/p&gt; &#xA;&lt;p&gt;C programming. In particular:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Variable and function declarations/definitions&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;While and for loops&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Pointers and function pointers&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fundamental algorithms and data structures in C&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Linux basics:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Know how to navigate directory with the command line&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Know how to invoke a command with options&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Know how to pipe output to another program&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Touch typing. Since we are going to use Linux, touch typing helps. I know typing speed does not relate to problem-solving, but at least your typing speed should be fast enough not to let it get it the way and degrade the learning experience.&lt;/p&gt; &#xA;&lt;p&gt;In general, I assume that the reader has basic C programming knowledge, and can use an IDE to build and run a program.&lt;/p&gt; &#xA;&lt;h1&gt;Status:&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Part 1&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Chapter 1: Complete&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 2: Complete&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 3: Almost. Currently, the book relies on the Intel Manual for fully explaining x86 execution environment.&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 4: Complete&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 5: Complete&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 6: Complete&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Part 2&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Chapter 7: Complete&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 8: Complete&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Part 3&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Chapter 9: Incomplete&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 10: Incomplete&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 11: Incomplete&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 12: Incomplete&lt;/li&gt; &#xA;   &lt;li&gt;Chapter 13: Incomplete&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;... and future chapters not included yet ...&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In the future, I hope to expand part 3 to cover more than the first 2 parts. But for the time being, I will try to finish the above chapters first.&lt;/p&gt; &#xA;&lt;h1&gt;Sample OS&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tuhdo/sample-os&#34;&gt;This repository&lt;/a&gt; is the sample OS of the book that is intended as a reference material for part 3. It covers 10 chapters of the &#34;System Programming Guide&#34; (Intel Manual Volume 3), along with a simple keyboard and video driver for input and output. However, at the moment, only the following features are implemented:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Protected mode.&lt;/li&gt; &#xA; &lt;li&gt;Creating and managing processes with TSS (Task State Structure).&lt;/li&gt; &#xA; &lt;li&gt;Interrupts&lt;/li&gt; &#xA; &lt;li&gt;LAPIC.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Paging and I/O are not yet implemented. I will try to implement it as the book progresses.&lt;/p&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;If you find any grammatical issues, please report it using Github Issues. Or, if some sentence or paragraph is difficult to understand, feel free to open an issue with the following title format: &lt;code&gt;[page number][type] Descriptive Title&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For example: &lt;code&gt;[pg.9][grammar] Incorrect verb usage&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;type&lt;/code&gt; can be one of the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Typo&lt;/code&gt;: indicates typing mistake.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Grammar&lt;/code&gt;: indicates incorrect grammar usage.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Style&lt;/code&gt;: indicates a style improvement.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Content&lt;/code&gt;: indicates problems with the content.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Even better, you can make a pull request with the provided book source. The main content of the book is in the file &#34;Operating Systems: From 0 to 1.lyx&#34;. You can edit the .txt file, then I will integrate the changes manually. It is a workaround for now since Lyx can cause a huge diff which makes it impossible to review changes.&lt;/p&gt; &#xA;&lt;p&gt;The book is in development, so please bear with me if the English irritates you. I really appreciate it.&lt;/p&gt; &#xA;&lt;p&gt;Finally, if you like the project and if it is possible, please donate to help this project and keep it going.&lt;/p&gt; &#xA;&lt;h1&gt;Got questions?&lt;/h1&gt; &#xA;&lt;p&gt;If you have any question related to the material or the development of the book, feel free to &lt;a href=&#34;https://github.com/tuhdo/os01/issues/new&#34;&gt;open a Github issue&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jamesfang8499/physics2</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/jamesfang8499/physics2</id>
    <link href="https://github.com/jamesfang8499/physics2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;高中物理甲种本（第二册）重排本&lt;/h1&gt; &#xA;&lt;p&gt;本项目是对高中物理甲种本（第二册）的致敬。虽然该书年代久远（1983—1985年出版，后在上世纪90年代以《高中物理读本》为名再版过），但是内容体系安排比如今的高中教材完整且合理。&lt;/p&gt; &#xA;&lt;p&gt;本重排本是根据网络上找到的此书扫描版电子文档，使用LaTeX制作而成的重排本电子文档（PDF格式）。书中的矢量图片采用电子版教材中的矢量图，或采用Tikz及Tkz-euclide制作而来。其余的点阵图则是来自于扫描版电子文档（限于作者的能力和精力，无法将所有内容均以矢量图全部重绘）。文档当中的电路图基于circuitikz绘制，请使用TeXLive2020以后的版本编译。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;注意：本项目的内容勿用于商业目的。电子版的原教材，可通过如下网址下载：&lt;a href=&#34;https://pan.baidu.com/s/1k2LGR&#34;&gt;https://pan.baidu.com/s/1k2LGR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;补充：高级中学物理（甲种本）第二册教学参考书，包含了各章的教学内容、教学建议、实验指导、习题解答、参考资料等。相关代码在2-ref文件夹中。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;目录&lt;/h1&gt; &#xA;&lt;h2&gt;说明&lt;/h2&gt; &#xA;&lt;h2&gt;第一章 分子运动论基础&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;分子运动论的建立&lt;/li&gt; &#xA; &lt;li&gt;物体是由分子组成的&lt;/li&gt; &#xA; &lt;li&gt;布朗运动&lt;/li&gt; &#xA; &lt;li&gt;分子间的相互作用力&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第二章 内能，能的转化和守恒定律&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;物体的内能&lt;/li&gt; &#xA; &lt;li&gt;改变内能的两种方式&lt;/li&gt; &#xA; &lt;li&gt;热功当量&lt;/li&gt; &#xA; &lt;li&gt;能的转化和守恒定律&lt;/li&gt; &#xA; &lt;li&gt;能的转化和守恒定律的建立及其意义&lt;/li&gt; &#xA; &lt;li&gt;能源的利用和开发&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第三章 气体的性质&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;气体的状态和状态参量&lt;/li&gt; &#xA; &lt;li&gt;气体的等温变化玻意耳-马略特定律&lt;/li&gt; &#xA; &lt;li&gt;气体的等容变化查理定律&lt;/li&gt; &#xA; &lt;li&gt;热力学温标&lt;/li&gt; &#xA; &lt;li&gt;理想气体的状态方程&lt;/li&gt; &#xA; &lt;li&gt;克拉珀龙方程&lt;/li&gt; &#xA; &lt;li&gt;气体分子运动的特点&lt;/li&gt; &#xA; &lt;li&gt;气体实验定律的微观解释&lt;/li&gt; &#xA; &lt;li&gt;理想气体的内能&lt;/li&gt; &#xA; &lt;li&gt;理想气体的内能变化&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第四章 固体和液体的性质&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;晶体和非晶体&lt;/li&gt; &#xA; &lt;li&gt;空间点阵&lt;/li&gt; &#xA; &lt;li&gt;液体的微观结构&lt;/li&gt; &#xA; &lt;li&gt;液体的表面现象&lt;/li&gt; &#xA; &lt;li&gt;浸润和不浸润&lt;/li&gt; &#xA; &lt;li&gt;毛细现象&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第五章 物态变化&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;熔解和凝固&lt;/li&gt; &#xA; &lt;li&gt;熔解热&lt;/li&gt; &#xA; &lt;li&gt;蒸发&lt;/li&gt; &#xA; &lt;li&gt;饱和汽与饱和汽压&lt;/li&gt; &#xA; &lt;li&gt;沸腾&lt;/li&gt; &#xA; &lt;li&gt;汽化热&lt;/li&gt; &#xA; &lt;li&gt;气体的液化&lt;/li&gt; &#xA; &lt;li&gt;空气的湿度&lt;/li&gt; &#xA; &lt;li&gt;露点湿度计&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第六章 电场&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;两种电荷电荷守恒定律&lt;/li&gt; &#xA; &lt;li&gt;库仑定律&lt;/li&gt; &#xA; &lt;li&gt;电场电场强度&lt;/li&gt; &#xA; &lt;li&gt;电力线&lt;/li&gt; &#xA; &lt;li&gt;电场中的导体&lt;/li&gt; &#xA; &lt;li&gt;电势能&lt;/li&gt; &#xA; &lt;li&gt;电势&lt;/li&gt; &#xA; &lt;li&gt;等势面&lt;/li&gt; &#xA; &lt;li&gt;电势差&lt;/li&gt; &#xA; &lt;li&gt;电势差跟电场强度的关系&lt;/li&gt; &#xA; &lt;li&gt;带电粒子在电场中的运动&lt;/li&gt; &#xA; &lt;li&gt;基本电荷的测定：密立根实验&lt;/li&gt; &#xA; &lt;li&gt;电容器电容&lt;/li&gt; &#xA; &lt;li&gt;电容器的连接&lt;/li&gt; &#xA; &lt;li&gt;静电的防止和应用&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第七章 稳恒电流&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;电流&lt;/li&gt; &#xA; &lt;li&gt;欧姆定律&lt;/li&gt; &#xA; &lt;li&gt;电阻定律电阻率&lt;/li&gt; &#xA; &lt;li&gt;电功和电功率&lt;/li&gt; &#xA; &lt;li&gt;焦耳定律&lt;/li&gt; &#xA; &lt;li&gt;串联电路&lt;/li&gt; &#xA; &lt;li&gt;并联电路&lt;/li&gt; &#xA; &lt;li&gt;分压和分流在伏特表和安培表中的应用&lt;/li&gt; &#xA; &lt;li&gt;电路的分析和计算&lt;/li&gt; &#xA; &lt;li&gt;电动势闭合电路的欧姆定律&lt;/li&gt; &#xA; &lt;li&gt;路端电压&lt;/li&gt; &#xA; &lt;li&gt;电池组&lt;/li&gt; &#xA; &lt;li&gt;电阻的测量&lt;/li&gt; &#xA; &lt;li&gt;惠斯通电桥&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;第八章 物质的导电性&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;金属的导电性&lt;/li&gt; &#xA; &lt;li&gt;液体的导电性&lt;/li&gt; &#xA; &lt;li&gt;法拉第电解定律&lt;/li&gt; &#xA; &lt;li&gt;电子电量的确定&lt;/li&gt; &#xA; &lt;li&gt;气体的导电性&lt;/li&gt; &#xA; &lt;li&gt;几种自激放电现象&lt;/li&gt; &#xA; &lt;li&gt;气体电光源&lt;/li&gt; &#xA; &lt;li&gt;真空中的电流&lt;/li&gt; &#xA; &lt;li&gt;示波管&lt;/li&gt; &#xA; &lt;li&gt;半导体的导电性&lt;/li&gt; &#xA; &lt;li&gt;N 型半导体和P 型半导体&lt;/li&gt; &#xA; &lt;li&gt;PN 结晶体二极管&lt;/li&gt; &#xA; &lt;li&gt;晶体三极管&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;学生实验&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;验证玻意耳-马略特定律&lt;/li&gt; &#xA; &lt;li&gt;验证气体状态方程&lt;/li&gt; &#xA; &lt;li&gt;测定冰的熔解热&lt;/li&gt; &#xA; &lt;li&gt;测定空气的相对湿度&lt;/li&gt; &#xA; &lt;li&gt;电场中等势线的描绘&lt;/li&gt; &#xA; &lt;li&gt;利用电容器放电测电容&lt;/li&gt; &#xA; &lt;li&gt;测定金属的电阻率&lt;/li&gt; &#xA; &lt;li&gt;把电流表改装为伏特表&lt;/li&gt; &#xA; &lt;li&gt;用安培表和伏特表测定电池的电动势和内电阻&lt;/li&gt; &#xA; &lt;li&gt;练习使用万用电表&lt;/li&gt; &#xA; &lt;li&gt;用惠斯通电桥测电阻&lt;/li&gt; &#xA; &lt;li&gt;测定铜的电化当量&lt;/li&gt; &#xA; &lt;li&gt;练习使用示波器&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;课外实验活动&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;观察扩散现象&lt;/li&gt; &#xA; &lt;li&gt;自制冰淇淋&lt;/li&gt; &#xA; &lt;li&gt;人造云雾&lt;/li&gt; &#xA; &lt;li&gt;测定水的汽化热&lt;/li&gt; &#xA; &lt;li&gt;估计水升高的温度&lt;/li&gt; &#xA; &lt;li&gt;用自制的验电器做静电实验&lt;/li&gt; &#xA; &lt;li&gt;自制电池&lt;/li&gt; &#xA; &lt;li&gt;研究电灯泡的电阻&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;常用的热学量和电学量的国际单位制单位&lt;/h2&gt;</summary>
  </entry>
  <entry>
    <title>sailist/LaTeXdoc</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/sailist/LaTeXdoc</id>
    <link href="https://github.com/sailist/LaTeXdoc" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LaTeX document written by LaTeX, used for quick learning and inspecting&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LaTeXdoc&lt;/h1&gt; &#xA;&lt;p&gt;for LaTeX command quick learning and search.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Download: &lt;a href=&#34;https://github.com/sailist/LaTeXdoc/releases/download/0.7/LaTeX.pdf&#34;&gt;ver-0.7&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;Compile&lt;/h1&gt; &#xA;&lt;p&gt;clone repo to local dist&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone --depth=1 https://github.com/sailist/LaTeXdoc&#xA;cd LaTeXdoc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;then run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-LaTeX&#34;&gt;xelatex  -synctex=1 -interaction=nonstopmode -file-line-error -output-directory=./out --shell-escape LaTeXTutorial.tex&#xA;&#xA;bibtex out/LaTeXTutorial.aux&#xA;&#xA;xelatex  -synctex=1 -interaction=nonstopmode -file-line-error -output-directory=./out --shell-escape LaTeXTutorial.tex&#xA;&#xA;xelatex  -synctex=1 -interaction=nonstopmode -file-line-error -output-directory=./out --shell-escape LaTeXTutorial.tex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;preview&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sailist/LaTeXdoc/master/preview/1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sailist/LaTeXdoc/master/preview/2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sailist/LaTeXdoc/master/preview/3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Related work&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sailist/LatexTool&#34;&gt;https://github.com/sailist/LatexTool&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>riscv/riscv-isa-manual</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/riscv/riscv-isa-manual</id>
    <link href="https://github.com/riscv/riscv-isa-manual" rel="alternate"></link>
    <summary type="html">&lt;p&gt;RISC-V Instruction Set Manual&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RISC-V Instruction Set Manual &lt;a href=&#34;https://app.travis-ci.com/riscv/riscv-isa-manual&#34;&gt;&lt;img src=&#34;https://app.travis-ci.com/riscv/riscv-isa-manual.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the LaTeX source for the draft RISC-V Instruction Set Manual. The preface of each document indicates the version of each standard that has been formally ratified by RISC-V International.&lt;/p&gt; &#xA;&lt;p&gt;This work is licensed under a Creative Commons Attribution 4.0 International License. See the LICENSE file for details.&lt;/p&gt; &#xA;&lt;p&gt;The Manual is split up into the following volumes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Volume I: User-Level ISA&lt;/li&gt; &#xA; &lt;li&gt;Volume II: Privileged Architecture&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Official versions&lt;/strong&gt; of the specifications are available at &lt;a href=&#34;https://riscv.org/specifications/&#34;&gt;https://riscv.org/specifications/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Compiled versions of the most recent drafts&lt;/strong&gt; of the specifications are available at &lt;a href=&#34;https://github.com/riscv/riscv-isa-manual/releases/latest&#34;&gt;https://github.com/riscv/riscv-isa-manual/releases/latest&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Older official versions&lt;/strong&gt; of the specifications are available at &lt;a href=&#34;https://github.com/riscv/riscv-isa-manual/releases/tag/archive&#34;&gt;https://github.com/riscv/riscv-isa-manual/releases/tag/archive&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The canonical list of &lt;strong&gt;open-source RISC-V implementations&#39; marchid CSR values&lt;/strong&gt; is available at &lt;a href=&#34;https://github.com/riscv/riscv-isa-manual/raw/master/marchid.md&#34;&gt;https://github.com/riscv/riscv-isa-manual/blob/master/marchid.md&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>blockchainsllc/DAO</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/blockchainsllc/DAO</id>
    <link href="https://github.com/blockchainsllc/DAO" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Standard DAO Framework, including Whitepaper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Decentralized Autonomous Organization (DAO) Framework&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/slockit/DAO&#34;&gt;&lt;img src=&#34;https://travis-ci.org/slockit/DAO.png&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is it?&lt;/h2&gt; &#xA;&lt;p&gt;Note: this is currently not maintained - do not use it as is.&lt;/p&gt; &#xA;&lt;p&gt;A Standard Decentralized Autonomous Organization (DAO) framework written in Solidity to run on the Ethereum blockchain.&lt;/p&gt; &#xA;&lt;p&gt;Feel free to reuse this framework to create your own Decentralized Autonomous Organization.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt; &lt;em&gt;&#34;Decentralized autonomous organization to automate governance&#34; -&lt;/em&gt; &lt;a href=&#34;https://download.slock.it/public/DAO/WhitePaper.pdf&#34;&gt;White Paper&lt;/a&gt; - &lt;a href=&#34;https://blog.slock.it/a-primer-to-the-decentralized-autonomous-organization-dao-69fb125bd3cd&#34;&gt;Primer&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;The future remains a work in progress. Our vision exists in a world where laws vary widely. It is important to remember that anyone who uses the generic DAO framework including the DAO refered to as &#39;The DAO&#39; or any other DAO will do so at their own risk. One can only speculate about the legal status of DAOs worldwide. Whatever one’s personal beliefs may be, people must draw their own conclusions, relying on legal advice where appropriate. The authors are not a law firm and are not in the business of offering legal advice.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;If you create a DAO it will be your DAO, and you will be responsible for its operation.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Our Standard DAO Framework allows people to create Decentralized Autonomous Organizations (DAOs) governed by the code in this repository written immutably to the blockchain.&lt;/p&gt; &#xA;&lt;p&gt;We are making the Standard DAO Framework we developed free and open source, so it can be reused by anyone wishing to put together a transparent organization where governance and decision making systems are immutably programmed in the Ethereum blockchain. This code been reviewed by hundreds of pairs of eyes from our community and by one of the most respected auditing companies in the world, Deja Vu.&lt;/p&gt; &#xA;&lt;p&gt;This DAO model is open source under the LGPL, so it can be reused by anyone wishing to put together a transparent organization where governance and decision making system are immutably programmed in the Blockchain.&lt;/p&gt; &#xA;&lt;p&gt;Note: Although the word &#34;contract&#34; is used in the DAO’s framework code, the term is a programming convention and is not being used as a legal term of art. The term is a programming convention, not a representation that the code is in and of itself a legally binding and enforceable contract. If you have questions about legal enforceability, consult with legal counsel.&lt;/p&gt; &#xA;&lt;h2&gt;Solidity files&lt;/h2&gt; &#xA;&lt;h3&gt;DAO.sol:&lt;/h3&gt; &#xA;&lt;p&gt;Standard smart contract for any generated Decentralized Autonomous Organization (DAO) to automate organizational governance and decision-making.&lt;/p&gt; &#xA;&lt;h3&gt;Token.sol:&lt;/h3&gt; &#xA;&lt;p&gt;Defines the functions to check token balances, send tokens, send tokens on behalf of a 3rd party and its corresponding approval process.&lt;/p&gt; &#xA;&lt;h3&gt;TokenCreation.sol:&lt;/h3&gt; &#xA;&lt;p&gt;Token Creation contract, used by the DAO generated by the framework to sell its tokens and initialize its ether.&lt;/p&gt; &#xA;&lt;h3&gt;SampleOffer.sol&lt;/h3&gt; &#xA;&lt;p&gt;Sample Proposal from a Contractor to the DAO generated by the framework. Feel free to use as a template for your own proposal.&lt;/p&gt; &#xA;&lt;h3&gt;ManagedAccount.sol&lt;/h3&gt; &#xA;&lt;p&gt;Basic account, used by the DAO contract generated by the framework to separately manage both the rewards and the extraBalance accounts.&lt;/p&gt; &#xA;&lt;h3&gt;DAOTokenCreationProxyTransferer.sol&lt;/h3&gt; &#xA;&lt;p&gt;This contract is used as a fall back in case an exchange doesn&#39;t implement the &#34;add data to a transaction&#34; feature in a timely manner, preventing it from calling createTokenProxy().&lt;/p&gt; &#xA;&lt;h2&gt;Licensing&lt;/h2&gt; &#xA;&lt;p&gt;The DAO framework is free software: you can redistribute it and/or modify it under the terms of the GNU lesser General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.&lt;/p&gt; &#xA;&lt;p&gt;The DAO framework is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU lesser General Public License for more details.&lt;/p&gt; &#xA;&lt;p&gt;A copy of the GNU lesser General Public License is included along with the DAO framework. See LICENSE.&lt;/p&gt; &#xA;&lt;h2&gt;Additional Disclaimers&lt;/h2&gt; &#xA;&lt;p&gt;NEITHER THE SOFTWARE NOR ITS CREATORS PROVIDE LEGAL ADVICE AND THIS CODE WAS NOT CREATED TO PROVIDE LEGAL ADVICE OR AS A SUBSTITUTE FOR LEGAL ADVICE. BY USING THIS CODE YOU ALSO AGREE:&lt;/p&gt; &#xA;&lt;p&gt;a. The creators of the Software and its contributors are not your lawyers.&lt;/p&gt; &#xA;&lt;p&gt;b. The Software is not a lawyer.&lt;/p&gt; &#xA;&lt;p&gt;c. Your use of the Software does not, in and of itself, create a legally binding contract in any jurisdiction and does not establish a lawyer-client relationship. Your communication with a non-lawyer will not be subject to the attorney-client privilege and (depending on your jurisdiction) may not be entitled to protection as confidential communication.&lt;/p&gt; &#xA;&lt;p&gt;d. The dissemination, distribution, or usage of this software shall not constitute the provision of legal advice within your jurisdiction. Unless you are legally authorized and licensed to do so, you will not use the Software to provide or assist in the provision of legal advice.&lt;/p&gt; &#xA;&lt;p&gt;e. You acknowledge and understand that each jurisdiction has its own particular rules regarding the practice of law. IF YOU USE THIS SOFTWARE TO PROVIDE LEGAL ADVICE YOU MAY BE SUBJECT TO CIVIL AND CRIMINAL LIABILITY. PRACTICING LAW WITHOUT A LICENSE IS A VIOLATION OF CRIMINAL LAW IN SOME JURISDICTIONS. CONSULT A LAWYER LICENSED IN YOUR JURISDICTION IF YOU HAVE ANY QUESTIONS ABOUT WHAT DOES OR DOES NOT CONSTITUTE THE PRACTICE OF LAW.&lt;/p&gt; &#xA;&lt;p&gt;f. The providers of this software neither warrant nor guarantee this software shall meet the requirements of any particular legal system to form a legally binding contract, nor it it their intention to directly or indirectly facilitate or encourage the unauthorized practice of law.&lt;/p&gt; &#xA;&lt;p&gt;g. You agree that in order for you to form a legally binding contract that you shall seek legal advice from an appropriately qualified and experienced lawyer within your jurisdiction.&lt;/p&gt; &#xA;&lt;p&gt;h. Issuance of DAO tokens may constitute the sale of securities in certain jurisdictions. Seek appropriate legal advice before deploying DAO code.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>deedy/Deedy-Resume</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/deedy/Deedy-Resume</id>
    <link href="https://github.com/deedy/Deedy-Resume" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A one page , two asymmetric column resume template in XeTeX that caters to an undergraduate Computer Science student&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deedy-Resume&lt;/h1&gt; &#xA;&lt;p&gt;A &lt;strong&gt;one-page&lt;/strong&gt;, &lt;strong&gt;two asymmetric column&lt;/strong&gt; resume template in &lt;strong&gt;XeTeX&lt;/strong&gt; that caters particularly to an &lt;strong&gt;undergraduate Computer Science&lt;/strong&gt; student. As of &lt;strong&gt;v1.2&lt;/strong&gt;, there is an option to choose from two templates:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;MacFonts&lt;/strong&gt; - uses fonts native to OSX - &lt;em&gt;Helvetica&lt;/em&gt;, &lt;em&gt;Helvetica Neue&lt;/em&gt; (and it&#39;s Light and Ultralight versions) and the CJK fonts &lt;em&gt;Heiti SC&lt;/em&gt;, and &lt;em&gt;Heiti TC&lt;/em&gt;. The EULA of these fonts prevents distribution on Open Source.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;OpenFonts&lt;/strong&gt; - uses free, open-source fonts that resemble the above - &lt;em&gt;Lato&lt;/em&gt; (and its various variants) and &lt;em&gt;Raleway&lt;/em&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;It is licensed under the Apache License 2.0.&lt;/p&gt; &#xA;&lt;h2&gt;Motivation&lt;/h2&gt; &#xA;&lt;p&gt;Common LaTeX resume-builders such as &lt;a href=&#34;http://www.latextemplates.com/template/moderncv-cv-and-cover-letter&#34;&gt;&lt;strong&gt;moderncv&lt;/strong&gt;&lt;/a&gt; and the &lt;a href=&#34;https://github.com/afriggeri/cv&#34;&gt;&lt;strong&gt;friggeri-cv&lt;/strong&gt;&lt;/a&gt; look great if you&#39;re looking for a multi-page resume with numerous citations, but usually imperfect for making a thorough, single-page one. A lot of companies today search resumes based on &lt;a href=&#34;http://www.businessinsider.com/most-big-companies-have-a-tracking-system-that-scans-your-resume-for-keywords-2012-1&#34;&gt;keywords&lt;/a&gt; but at the same time require/prefer a one-page resume, especially for undergraduates.&lt;/p&gt; &#xA;&lt;p&gt;This template attempts to &lt;strong&gt;look clean&lt;/strong&gt;, highlight &lt;strong&gt;details&lt;/strong&gt;, be a &lt;strong&gt;single page&lt;/strong&gt;, and allow useful &lt;strong&gt;LaTeX templating&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Preview&lt;/h2&gt; &#xA;&lt;h3&gt;OpenFonts&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/OpenFonts/sample-image.png&#34; alt=&#34;alt tag&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;MacFonts&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/MacFonts/sample-image.png&#34; alt=&#34;alt tag&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Compiles only with &lt;strong&gt;XeTeX&lt;/strong&gt; and required &lt;strong&gt;BibTex&lt;/strong&gt; for compiling publications and the .bib filetype.&lt;/li&gt; &#xA; &lt;li&gt;Uses fonts that are usually only available to &lt;strong&gt;Mac&lt;/strong&gt; users such as Helvetica Neue Light.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Availability&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;MacFonts version - &lt;a href=&#34;http://debarghyadas.com/resume/debarghya-das-resume.pdf&#34;&gt;as an online preview&lt;/a&gt; and &lt;a href=&#34;https://github.com/deedydas/Deedy-Resume/raw/master/MacFonts/deedy_resume.pdf&#34;&gt;as a direct download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;OpenFonts version - &lt;a href=&#34;https://github.com/deedydas/Deedy-Resume/raw/master/OpenFonts/deedy_resume-openfont.pdf&#34;&gt;as a direct download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Overleaf&lt;/strong&gt;.com (formerly &lt;strong&gt;WriteLatex&lt;/strong&gt;.com) (v1 fonts/colors changed) - &lt;a href=&#34;https://www.writelatex.com/templates/deedy-resume/sqdbztjjghvz#.U2H9Kq1dV18&#34;&gt;compilable online&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ShareLatex&lt;/strong&gt;.com (v1 fonts changes) - &lt;a href=&#34;https://www.sharelatex.com/templates/cv-or-resume/deedy-resume&#34;&gt;compilable online&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;h3&gt;v1.2&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Added publications in place of societies.&lt;/li&gt; &#xA; &lt;li&gt;Collapsed a portion of education.&lt;/li&gt; &#xA; &lt;li&gt;Fixed a bug with alignment of overflowing long last updated dates on the top right.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;v1.1&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fixed several compilation bugs with \renewcommand&lt;/li&gt; &#xA; &lt;li&gt;Got Open-source fonts (Windows/Linux support)&lt;/li&gt; &#xA; &lt;li&gt;Added Last Updated&lt;/li&gt; &#xA; &lt;li&gt;Moved Title styling into .sty&lt;/li&gt; &#xA; &lt;li&gt;Commented .sty file.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Merge OpenFont and MacFonts as a single sty with options.&lt;/li&gt; &#xA; &lt;li&gt;Figure out a smoother way for the document to flow onto the next page.&lt;/li&gt; &#xA; &lt;li&gt;Add styling information for a &#34;Projects/Hacks&#34; section.&lt;/li&gt; &#xA; &lt;li&gt;Add location/address information&lt;/li&gt; &#xA; &lt;li&gt;Fix the hacky &#39;References&#39; omission outside the .cls file in the MacFonts version.&lt;/li&gt; &#xA; &lt;li&gt;Add various styling and section options and allow for multiple pages smoothly.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Known Issues:&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Overflows onto second page if any column&#39;s contents are more than the vertical limit&lt;/li&gt; &#xA; &lt;li&gt;Hacky space on the first bullet point on the second column.&lt;/li&gt; &#xA; &lt;li&gt;Hacky redefinition of \refname to omit &#39;References&#39; text for publications in the MacFonts version.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;Copyright 2014 Debarghya Das&#xA;&#xA;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);&#xA;you may not use this file except in compliance with the License.&#xA;You may obtain a copy of the License at&#xA;&#xA;   http://www.apache.org/licenses/LICENSE-2.0&#xA;&#xA;Unless required by applicable law or agreed to in writing, software&#xA;distributed under the License is distributed on an &#34;AS IS&#34; BASIS,&#xA;WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&#xA;See the License for the specific language governing permissions and&#xA;limitations under the License.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>ElegantLaTeX/ElegantBook</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/ElegantLaTeX/ElegantBook</id>
    <link href="https://github.com/ElegantLaTeX/ElegantBook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Elegant LaTeX Template for Books&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://elegantlatex.org/&#34;&gt;Homepage&lt;/a&gt; | &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantBook&#34;&gt;Github&lt;/a&gt; | &lt;a href=&#34;https://ctan.org/pkg/elegantbook&#34;&gt;CTAN&lt;/a&gt; | &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantBook/releases&#34;&gt;Download&lt;/a&gt; | &lt;a href=&#34;https://github.com/ElegantLaTeX/ElegantBook/wiki&#34;&gt;Wiki&lt;/a&gt; | &lt;a href=&#34;https://weibo.com/elegantlatex&#34;&gt;Weibo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/ctan/l/elegantbook.svg?sanitize=true&#34; alt=&#34;License&#34;&gt; &lt;img src=&#34;https://img.shields.io/ctan/v/elegantbook.svg?sanitize=true&#34; alt=&#34;CTAN Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/release/ElegantLaTeX/ElegantBook.svg?sanitize=true&#34; alt=&#34;Github Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/repo-size/ElegantLaTeX/ElegantBook.svg?sanitize=true&#34; alt=&#34;Repo Size&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;ElegantBook: An Elegant LaTeX Template for Books&lt;/h1&gt; &#xA;&lt;p&gt;ElegantBook is designed for writing books, created by &lt;a href=&#34;https://ddswhu.me/&#34;&gt;Dongsheng Deng&lt;/a&gt; and &lt;a href=&#34;https://liam.page/&#34;&gt;Liam Huang&lt;/a&gt;. Just enjoy it! If you have any questions, suggestions or bug reports, you can create issues or contact us at &lt;a href=&#34;mailto:elegantlatex2e@gmail.com&#34;&gt;elegantlatex2e@gmail.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Important Notes&lt;/h2&gt; &#xA;&lt;p&gt;For some reasons, &lt;strong&gt;unauthorized&lt;/strong&gt; pull requests are &lt;strong&gt;UNACCEPTABLE&lt;/strong&gt; since May 20, 2019. For those who want to help revise the templates, submit issues or clone to your own repository to modify under the LPPL-1.3c.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;Thank &lt;a href=&#34;https://github.com/sikouhjw&#34;&gt;sikouhjw&lt;/a&gt; and &lt;a href=&#34;https://github.com/syvshc&#34;&gt;syvshc&lt;/a&gt; for their quick response to Github issues and continuously support work for ElegantLaTeX.&lt;/p&gt; &#xA;&lt;p&gt;Thank ChinaTeX and &lt;a href=&#34;http://www.latexstudio.net/&#34;&gt;LaTeX Studio&lt;/a&gt; for their promotion.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This work is released under the LaTeX Project Public License, v1.3c or later.&lt;/p&gt; &#xA;&lt;h2&gt;Derivative Works&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/XiangyunHuang/ElegantBookdown&#34;&gt;ElegantBookdown&lt;/a&gt;：&lt;a href=&#34;https://github.com/XiangyunHuang&#34;&gt;XiangyunHuang&lt;/a&gt; developed a Bookdown template based on ElegantBook.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pzhaonet/bookdownplus&#34;&gt;bookdownplus&lt;/a&gt;: maintained by &lt;a href=&#34;https://github.com/pzhaonet&#34;&gt;pzhaonet&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/annProg/PanBook&#34;&gt;PanBook&lt;/a&gt;：a markdown-based writing workflow Developed by &lt;a href=&#34;https://github.com/annProg&#34;&gt;annProg&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>dart-lang/language</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/dart-lang/language</id>
    <link href="https://github.com/dart-lang/language" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Design of the Dart language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dart language evolution&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/dart-lang/language/actions?query=workflow%3ACI+branch%3Amaster&#34;&gt;&lt;img src=&#34;https://github.com/dart-lang/language/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository is a place for the &lt;a href=&#34;https://www.dartlang.org&#34;&gt;Dart&lt;/a&gt; language team to work on language changes and features, and to solicit and accept feedback and requests.&lt;/p&gt; &#xA;&lt;p&gt;Issues and feature requests relevant to the language and the specification may be filed &lt;a href=&#34;https://github.com/dart-lang/language/issues&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Dart language team&lt;/h1&gt; &#xA;&lt;p&gt;As of June 2020, the Dart language team consists of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Leaf Petersen (&lt;a href=&#34;https://github.com/leafpetersen&#34;&gt;@leafpetersen&lt;/a&gt;), language engineer&lt;/li&gt; &#xA; &lt;li&gt;Lasse R.H. Nielsen (&lt;a href=&#34;https://github.com/lrhn&#34;&gt;@lrhn&lt;/a&gt;), language engineer&lt;/li&gt; &#xA; &lt;li&gt;Bob Nystrom (&lt;a href=&#34;https://github.com/munificent&#34;&gt;@munificent&lt;/a&gt;), language engineer&lt;/li&gt; &#xA; &lt;li&gt;Erik Ernst (&lt;a href=&#34;https://github.com/eernstg&#34;&gt;@eernstg&lt;/a&gt;), language engineer, &lt;a href=&#34;https://dart.dev/guides/language/spec&#34;&gt;specification&lt;/a&gt; maintainer&lt;/li&gt; &#xA; &lt;li&gt;Nate Bosch (&lt;a href=&#34;https://github.com/natebosch&#34;&gt;@natebosch&lt;/a&gt;), language engineer&lt;/li&gt; &#xA; &lt;li&gt;Jake MacDonald (&lt;a href=&#34;https://github.com/jakemac53&#34;&gt;@jakemac53&lt;/a&gt;), language engineer&lt;/li&gt; &#xA; &lt;li&gt;Paul Berry (&lt;a href=&#34;https://github.com/stereotype441&#34;&gt;@stereotype441&lt;/a&gt;), language engineer&lt;/li&gt; &#xA; &lt;li&gt;Michael Thomsen (&lt;a href=&#34;https://github.com/mit-mit&#34;&gt;@mit-mit&lt;/a&gt;), product manager&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Organization&lt;/h1&gt; &#xA;&lt;p&gt;We follow &lt;a href=&#34;https://github.com/dart-lang/language/raw/master/doc/life_of_a_language_feature.md&#34;&gt;this process&lt;/a&gt; for planning and rolling out language changes.&lt;/p&gt; &#xA;&lt;p&gt;Features currently being worked on are listed in the &lt;a href=&#34;https://github.com/dart-lang/language/projects/1&#34;&gt;language funnel&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Anyone can participate in the discussion about language changes by participating on the dart language mailing list, by replying to issues in this repository, and by uploading documents, tests or other resources.&lt;/p&gt; &#xA;&lt;p&gt;When commenting on issues in this repository, keep in mind:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;span&gt;👍&lt;/span&gt; reactions are more useful than comments to show support.&lt;/li&gt; &#xA; &lt;li&gt;Motivating examples help us understand why you want new features more than pointers to other languages which have them. We love hearing feedback about your experiences with other languages, but we also want to know why they are right for Dart in particular.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License &amp;amp; patents&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/dart-lang/language/raw/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; and &lt;a href=&#34;https://github.com/dart-lang/language/raw/master/PATENTS&#34;&gt;PATENTS&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>vdumoulin/conv_arithmetic</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/vdumoulin/conv_arithmetic</id>
    <link href="https://github.com/vdumoulin/conv_arithmetic" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A technical report on convolution arithmetic in the context of deep learning&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Convolution arithmetic&lt;/h1&gt; &#xA;&lt;p&gt;A technical report on convolution arithmetic in the context of deep learning.&lt;/p&gt; &#xA;&lt;p&gt;The code and the images of this tutorial are free to use as regulated by the licence and subject to proper attribution:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[1] Vincent Dumoulin, Francesco Visin - &lt;a href=&#34;https://arxiv.org/abs/1603.07285&#34;&gt;A guide to convolution arithmetic for deep learning&lt;/a&gt; (&lt;a href=&#34;https://gist.github.com/fvisin/165ca9935392fa9600a6c94664a01214&#34;&gt;BibTeX&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Convolution animations&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;N.B.: Blue maps are inputs, and cyan maps are outputs.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%; table-layout:fixed;&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/arbitrary_padding_no_strides.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/full_padding_no_strides.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;No padding, no strides&lt;/td&gt; &#xA;   &lt;td&gt;Arbitrary padding, no strides&lt;/td&gt; &#xA;   &lt;td&gt;Half padding, no strides&lt;/td&gt; &#xA;   &lt;td&gt;Full padding, no strides&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_strides.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides_odd.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;No padding, strides&lt;/td&gt; &#xA;   &lt;td&gt;Padding, strides&lt;/td&gt; &#xA;   &lt;td&gt;Padding, strides (odd)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Transposed convolution animations&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;N.B.: Blue maps are inputs, and cyan maps are outputs.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%; table-layout:fixed;&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides_transposed.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/arbitrary_padding_no_strides_transposed.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides_transposed.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/full_padding_no_strides_transposed.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;No padding, no strides, transposed&lt;/td&gt; &#xA;   &lt;td&gt;Arbitrary padding, no strides, transposed&lt;/td&gt; &#xA;   &lt;td&gt;Half padding, no strides, transposed&lt;/td&gt; &#xA;   &lt;td&gt;Full padding, no strides, transposed&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_strides_transposed.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides_transposed.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides_odd_transposed.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;No padding, strides, transposed&lt;/td&gt; &#xA;   &lt;td&gt;Padding, strides, transposed&lt;/td&gt; &#xA;   &lt;td&gt;Padding, strides, transposed (odd)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Dilated convolution animations&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;N.B.: Blue maps are inputs, and cyan maps are outputs.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:25%&#34; ; table-layout:fixed;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;150px&#34; src=&#34;https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/dilation.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;No padding, no stride, dilation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Generating the Makefile&lt;/h2&gt; &#xA;&lt;p&gt;From the repository&#39;s root directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./bin/generate_makefile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Generating the animations&lt;/h2&gt; &#xA;&lt;p&gt;From the repository&#39;s root directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ make all_animations&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The animations will be output to the &lt;code&gt;gif&lt;/code&gt; directory. Individual animation steps will be output in PDF format to the &lt;code&gt;pdf&lt;/code&gt; directory and in PNG format to the &lt;code&gt;png&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h2&gt;Compiling the document&lt;/h2&gt; &#xA;&lt;p&gt;From the repository&#39;s root directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ make&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>sysprog21/lkmpg</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/sysprog21/lkmpg</id>
    <link href="https://github.com/sysprog21/lkmpg" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Linux Kernel Module Programming Guide (updated for 5.x kernels)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Linux Kernel Module Programming Guide&lt;/h1&gt; &#xA;&lt;p&gt;This project keeps the Linux Kernel Module Programming Guide up to date, with &lt;a href=&#34;https://raw.githubusercontent.com/sysprog21/lkmpg/master/examples/&#34;&gt;working examples&lt;/a&gt; for recent 5.x kernel versions. The guide has been around since 2001 and most copies of it on the web only describe old 2.6.x kernels.&lt;/p&gt; &#xA;&lt;p&gt;The book can be freely accessed via &lt;a href=&#34;https://sysprog21.github.io/lkmpg/&#34;&gt;https://sysprog21.github.io/lkmpg/&lt;/a&gt; or &lt;a href=&#34;https://github.com/sysprog21/lkmpg/releases&#34;&gt;latest PDF file&lt;/a&gt;. The original guide may be found at &lt;a href=&#34;http://www.tldp.org/LDP/lkmpg/&#34;&gt;Linux Documentation Project&lt;/a&gt;. You may check other &lt;a href=&#34;https://ebookfoundation.github.io/free-programming-books/books/free-programming-books.html&#34;&gt;freely available programming books&lt;/a&gt; listed by The &lt;a href=&#34;https://ebookfoundation.org/&#34;&gt;Free Ebook Foundation&lt;/a&gt; or &lt;a href=&#34;https://onlinebooks.library.upenn.edu/webbin/book/browse?type=lcsubc&amp;amp;key=Linux&#34;&gt;Linux online books&lt;/a&gt; collected by &lt;a href=&#34;https://onlinebooks.library.upenn.edu/&#34;&gt;The Online Books Page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Summary&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Get the latest source code from the &lt;a href=&#34;https://github.com/sysprog21/lkmpg&#34;&gt;GitHub page&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Install the prerequisites.&lt;/li&gt; &#xA; &lt;li&gt;Generate PDF and/or HTML documents.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 1: Get the latest source code&lt;/h3&gt; &#xA;&lt;p&gt;Make sure you can run &lt;code&gt;git&lt;/code&gt; with an Internet connection.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git clone https://github.com/sysprog21/lkmpg.git &amp;amp;&amp;amp; cd lkmpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 2: Install the prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;To generate the book from source, &lt;a href=&#34;https://www.tug.org/texlive/&#34;&gt;TeXLive&lt;/a&gt; (&lt;a href=&#34;https://www.tug.org/mactex/&#34;&gt;MacTeX&lt;/a&gt;) is required.&lt;/p&gt; &#xA;&lt;p&gt;For Ubuntu Linux, macOS, and other Unix-like systems, run the following command(s):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Debian / Ubuntu&#xA;$ sudo apt install make texlive-full&#xA;&#xA;# Arch / Manjaro&#xA;$ sudo pacman -S make texlive-most texlive-bin&#xA;&#xA;# macOS&#xA;$ brew install --cask mactex&#xA;$ sudo tlmgr update --self&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that &lt;code&gt;latexmk&lt;/code&gt; is required to generated PDF, and it probably has been installed on your OS already. If not, please follow the &lt;a href=&#34;https://mg.readthedocs.io/latexmk.html#installation&#34;&gt;installation guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Alternatively, using &lt;a href=&#34;https://docs.docker.com/&#34;&gt;Docker&lt;/a&gt; is recommended, as it guarantees the same dependencies with our GitHub Actions workflow. After install &lt;a href=&#34;https://docs.docker.com/engine/install/&#34;&gt;docker engine&lt;/a&gt; on your machine, pull the docker image &lt;a href=&#34;https://hub.docker.com/r/twtug/lkmpg&#34;&gt;twtug/lkmpg&lt;/a&gt; and run in isolated containers.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# pull docker image and run it as container&#xA;$ docker pull twtug/lkmpg&#xA;$ docker run --rm -it -v $(pwd):/workdir twtug/lkmpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/containerd/nerdctl&#34;&gt;nerdctl&lt;/a&gt; is a Docker-compatible command line tool for &lt;a href=&#34;https://containerd.io/&#34;&gt;containerd&lt;/a&gt;, and you can replace the above &lt;code&gt;docker&lt;/code&gt; commands with &lt;code&gt;nerdctl&lt;/code&gt; counterparts.&lt;/p&gt; &#xA;&lt;h3&gt;Step 3: Generate PDF and/or HTML documents&lt;/h3&gt; &#xA;&lt;p&gt;Now we could build document with following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ make all              # Generate PDF document&#xA;$ make html             # Convert TeX to HTML&#xA;$ make clean            # Delete generated files&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The Linux Kernel Module Programming Guide is a free book; you may reproduce and/or modify it under the terms of the &lt;a href=&#34;https://opensource.org/licenses/OSL-3.0&#34;&gt;Open Software License&lt;/a&gt;. Use of this work is governed by a copyleft license that can be found in the &lt;code&gt;LICENSE&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;The complementary sample code is licensed under GNU GPL version 2, as same as Linux kernel.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>LTH-Co-op/dscs-edaa40-edaa75</title>
    <updated>2022-05-31T01:55:20Z</updated>
    <id>tag:github.com,2022-05-31:/LTH-Co-op/dscs-edaa40-edaa75</id>
    <link href="https://github.com/LTH-Co-op/dscs-edaa40-edaa75" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Diskreta strukturer i datavetenskap&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Info&lt;/h1&gt; &#xA;&lt;p&gt;Planen är att vi gör lösningar till extentor på ett snyggt sätt för alla områden så man senare kan skriva ut. Vi ska inte ha massa kopior av frågor. Vi ska även ha viktiga slides som en PDF.&lt;/p&gt; &#xA;&lt;h1&gt;Områden&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; DNF&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Trees&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Graphs&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Relations&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>