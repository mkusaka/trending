<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-09T01:38:12Z</updated>
  <subtitle>Daily Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ysymyth/awesome-language-agents</title>
    <updated>2023-09-09T01:38:12Z</updated>
    <id>tag:github.com,2023-09-09:/ysymyth/awesome-language-agents</id>
    <link href="https://github.com/ysymyth/awesome-language-agents" rel="alternate"></link>
    <summary type="html">&lt;p&gt;List of language agents based on paper &#34;Cognitive Architectures for Language Agents&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üê®CoALA: Awesome Language Agents&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://awesome.re&#34;&gt;&lt;img src=&#34;https://awesome.re/badge.svg?sanitize=true&#34; alt=&#34;Awesome&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/ysymyth/awesome-language-agents/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ysymyth/awesome-language-agents/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen&#34; alt=&#34;PR Welcome&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ysymyth/awesome-language-agents/main/CoALA.png&#34; alt=&#34;teaser&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A compilation of language agents using the &lt;strong&gt;Cognitive Architectures for Language Agents (üê®CoALA)&lt;/strong&gt; framework.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CoLLA Paper (16 pages of main content): &lt;a href=&#34;https://arxiv.org/abs/2309.02427&#34;&gt;https://arxiv.org/abs/2309.02427&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CoLLA Tweet (6 threads): &lt;a href=&#34;https://twitter.com/ShunyuYao12/status/1699396834983362690&#34;&gt;https://twitter.com/ShunyuYao12/status/1699396834983362690&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CoLLA BibTex file with 300+ related citations: &lt;a href=&#34;https://raw.githubusercontent.com/ysymyth/awesome-language-agents/main/CoALA.bib&#34;&gt;CoALA.bib&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CoLLA BibTex citation if you find our work/resources useful:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{sumers2023cognitive,&#xA;      title={Cognitive Architectures for Language Agents}, &#xA;      author={Theodore Sumers and Shunyu Yao and Karthik Narasimhan and Thomas L. Griffiths},&#xA;      year={2023},&#xA;      eprint={2309.02427},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.AI}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üê®CoALA Overview&lt;/h2&gt; &#xA;&lt;p&gt;CoLLA neatly specifies a langauge agent starting with its &lt;strong&gt;action space&lt;/strong&gt;, which has 2 parts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;External actions to interact with external environments (&lt;strong&gt;grounding&lt;/strong&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Internal actions to interact with internal memories (&lt;strong&gt;reasoning&lt;/strong&gt;, &lt;strong&gt;retrieval&lt;/strong&gt;, &lt;strong&gt;learning&lt;/strong&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A language agent has a short-term working memory and several (optional) long-term memories (episodic for experience, semantic for knowledge, procedural for code/LLM)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Reasoning&lt;/strong&gt; = update working memory (with LLM)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Retrieval&lt;/strong&gt; = read long-term memory&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Learning&lt;/strong&gt; = write long-term memory &lt;img src=&#34;https://raw.githubusercontent.com/ysymyth/awesome-language-agents/main/action_space.png&#34; alt=&#34;action_space&#34;&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Then how does a language agent choose which action to take? Its actions are structured into &lt;strong&gt;decision making&lt;/strong&gt; cycles, and each cycle has two stages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Planning&lt;/strong&gt;: The agent applies reasoning/retrieval actions to (iteratively) propose and evaluate actions, then select a learning/grounding action.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Execution&lt;/strong&gt;: The selected learning/grounding action is executed to affect the internal memory or external world. &lt;img src=&#34;https://raw.githubusercontent.com/ysymyth/awesome-language-agents/main/decision_making.png&#34; alt=&#34;decision_making&#34;&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To understand more, read Section 4 of our &lt;a href=&#34;https://arxiv.org/abs/2309.02427&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Papers&lt;/h2&gt; &#xA;&lt;p&gt;Note: Below is only a subset of papers scraped from &lt;a href=&#34;https://raw.githubusercontent.com/ysymyth/awesome-language-agents/main/CoALA.bib&#34;&gt;CoALA.bib&lt;/a&gt;, with potentially incorrect action space labels. Date is based on arxiv v1. They do not represent all language agent work, and we plan to add more work soon (pull requests welcome), and have labels for highly cited work.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;(2021-10) &lt;a href=&#34;http://arxiv.org/abs/2110.01691&#34;&gt;AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2021-10) &lt;a href=&#34;http://arxiv.org/abs/2110.10661&#34;&gt;SILG: The Multi-environment Symbolic Interactive Language Grounding Benchmark&lt;/a&gt; (environment)&lt;/li&gt; &#xA; &lt;li&gt;(2022-01) &lt;a href=&#34;http://arxiv.org/abs/2201.07207&#34;&gt;Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2022-03) &lt;a href=&#34;http://arxiv.org/abs/2203.06566&#34;&gt;PromptChainer: Chaining Large Language Model Prompts through Visual Programming&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2022-03) &lt;a href=&#34;http://arxiv.org/abs/2203.07540&#34;&gt;ScienceWorld: Is your Agent Smarter than a 5th Grader?&lt;/a&gt; (environment)&lt;/li&gt; &#xA; &lt;li&gt;(2022-04) &lt;a href=&#34;http://arxiv.org/abs/2204.01691&#34;&gt;Do As I Can, Not As I Say: Grounding Language in Robotic Affordances&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2022-04) &lt;a href=&#34;http://arxiv.org/abs/2204.00598&#34;&gt;Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2022-07) &lt;a href=&#34;http://arxiv.org/abs/2207.01206&#34;&gt;WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents&lt;/a&gt; (environment)&lt;/li&gt; &#xA; &lt;li&gt;(2022-09) &lt;a href=&#34;http://arxiv.org/abs/2209.11302&#34;&gt;ProgPrompt: Generating Situated Robot Task Plans using Large Language Models&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2022-10) &lt;a href=&#34;http://arxiv.org/abs/2210.02406&#34;&gt;Decomposed Prompting: A Modular Approach for Solving Complex Tasks&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2022-10) &lt;a href=&#34;http://arxiv.org/abs/2210.05359&#34;&gt;Mind&#39;s Eye: Grounded Language Model Reasoning through Simulation&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2022-10) &lt;a href=&#34;http://arxiv.org/abs/2210.03629&#34;&gt;ReAct: Synergizing Reasoning and Acting in Language Models&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2022-11) &lt;a href=&#34;http://arxiv.org/abs/2211.01910&#34;&gt;Large Language Models Are Human-Level Prompt Engineers&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-02) &lt;a href=&#34;http://arxiv.org/abs/2302.02676v6&#34;&gt;Chain of Hindsight Aligns Language Models with Feedback&lt;/a&gt; (learning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-02) &lt;a href=&#34;http://arxiv.org/abs/2302.01560&#34;&gt;Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-02) &lt;a href=&#34;http://arxiv.org/abs/2302.04761&#34;&gt;Toolformer: Language Models Can Teach Themselves to Use Tools&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2023-03) &lt;a href=&#34;http://arxiv.org/abs/2303.04129&#34;&gt;Foundation Models for Decision Making: Problems, Methods, and Opportunities&lt;/a&gt; (survey)&lt;/li&gt; &#xA; &lt;li&gt;(2023-03) &lt;a href=&#34;http://arxiv.org/abs/2303.17580&#34;&gt;HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2023-03) &lt;a href=&#34;http://arxiv.org/abs/2303.03378&#34;&gt;PaLM-E: An Embodied Multimodal Language Model&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2023-03) &lt;a href=&#34;http://arxiv.org/abs/2303.11366&#34;&gt;Reflexion: Language Agents with Verbal Reinforcement Learning&lt;/a&gt; (grounding, reasoning, learning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-03) &lt;a href=&#34;http://arxiv.org/abs/2303.17651&#34;&gt;Self-Refine: Iterative Refinement with Self-Feedback&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-03) &lt;a href=&#34;http://arxiv.org/abs/2303.06689&#34;&gt;Self-planning Code Generation with Large Language Models&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-04) &lt;a href=&#34;http://arxiv.org/abs/2304.05332&#34;&gt;Emergent autonomous scientific research capabilities of large language models&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-04) &lt;a href=&#34;http://arxiv.org/abs/2304.11477&#34;&gt;LLM+P: Empowering Large Language Models with Optimal Planning Proficiency&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-04) &lt;a href=&#34;http://arxiv.org/abs/2304.01904&#34;&gt;REFINER: Reasoning Feedback on Intermediate Representations&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-04) &lt;a href=&#34;http://arxiv.org/abs/2304.05128&#34;&gt;Teaching Large Language Models to Self-Debug&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.12487&#34;&gt;Augmenting Autotelic Agents with Large Language Models&lt;/a&gt; (grounding, reasoning, retrieval, learning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.14323&#34;&gt;ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.00633&#34;&gt;Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.19118&#34;&gt;Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.14325&#34;&gt;Improving Factuality and Reasoning in Language Models through Multiagent Debate&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.04091&#34;&gt;Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.18323&#34;&gt;ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.17390&#34;&gt;SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.10601&#34;&gt;Tree of Thoughts: Deliberate Problem Solving with Large Language Models&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-05) &lt;a href=&#34;http://arxiv.org/abs/2305.16291&#34;&gt;Voyager: An Open-Ended Embodied Agent with Large Language Models&lt;/a&gt; (grounding, reasoning, retrieval, learning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-06) &lt;a href=&#34;http://arxiv.org/abs/2306.14898&#34;&gt;InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-06) &lt;a href=&#34;http://arxiv.org/abs/2306.06070&#34;&gt;Mind2Web: Towards a Generalist Agent for the Web&lt;/a&gt; (environment)&lt;/li&gt; &#xA; &lt;li&gt;(2023-06) &lt;a href=&#34;http://arxiv.org/abs/2306.06624&#34;&gt;RestGPT: Connecting Large Language Models with Real-World RESTful APIs&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-06) &lt;a href=&#34;http://arxiv.org/abs/2306.05301&#34;&gt;ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-07) &lt;a href=&#34;http://arxiv.org/abs/2307.12856&#34;&gt;A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-07) &lt;a href=&#34;http://arxiv.org/abs/2307.15818&#34;&gt;RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2023-07) &lt;a href=&#34;http://arxiv.org/abs/2307.04738&#34;&gt;RoCo: Dialectic Multi-Robot Collaboration with Large Language Models&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2023-07) &lt;a href=&#34;http://arxiv.org/abs/2307.01928&#34;&gt;Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2023-07) &lt;a href=&#34;http://arxiv.org/abs/2307.14984&#34;&gt;S$^3$: Social-network Simulation System with Large Language Model-Empowered Agents&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-07) &lt;a href=&#34;http://arxiv.org/abs/2307.16789&#34;&gt;ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs&lt;/a&gt; (grounding, reasoning, retrieval)&lt;/li&gt; &#xA; &lt;li&gt;(2023-07) &lt;a href=&#34;http://arxiv.org/abs/2307.15810&#34;&gt;Understanding the Benefits and Challenges of Using Large Language Model-based Conversational Agents for Mental Well-being Support&lt;/a&gt; (grounding)&lt;/li&gt; &#xA; &lt;li&gt;(2023-07) &lt;a href=&#34;http://arxiv.org/abs/2307.05300&#34;&gt;Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-07) &lt;a href=&#34;http://arxiv.org/abs/2307.13854&#34;&gt;WebArena: A Realistic Web Environment for Building Autonomous Agents&lt;/a&gt; (environment)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.03688&#34;&gt;AgentBench: Evaluating LLMs as Agents&lt;/a&gt; (environment)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.10848&#34;&gt;AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents&lt;/a&gt; (environment)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.08155&#34;&gt;AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.12503&#34;&gt;CGMI: Configurable General Multi-Agent Interaction Framework&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.07201&#34;&gt;ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.04371&#34;&gt;Cumulative Reasoning with Large Language Models&lt;/a&gt; (reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.10435&#34;&gt;GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.04030&#34;&gt;Gentopia: A Collaborative Platform for Tool-Augmented LLMs&lt;/a&gt; (environment)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.00352&#34;&gt;MetaGPT: Meta Programming for Multi-Agent Collaborative Framework&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.11339&#34;&gt;ProAgent: Building Proactive Cooperative AI with Large Language Models&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.02151&#34;&gt;Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization&lt;/a&gt; (grounding, reasoning, learning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.03022&#34;&gt;SAPIEN: Affective Virtual Agents Powered by Large Language Models&lt;/a&gt; (grounding, reasoning)&lt;/li&gt; &#xA; &lt;li&gt;(2023-08) &lt;a href=&#34;http://arxiv.org/abs/2308.09830&#34;&gt;Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis&lt;/a&gt; (grounding, reasoning, retrieval, learning)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;(more to be added soon. pull request welcome.)&lt;/p&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/&#34;&gt;LLM Powered Autonomous Agents (Lil‚ÄôLog)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AGI-Edgerunners/LLM-Agents-Papers&#34;&gt;LLM-Agents-Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zjunlp/LLMAgentPapers&#34;&gt;LLMAgentPapers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;(more to be added soon. pull request welcome.)&lt;/p&gt;</summary>
  </entry>
</feed>