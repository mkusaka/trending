<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-12T01:42:06Z</updated>
  <subtitle>Daily Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ml874/Data-Engineering-on-GCP-Cheatsheet</title>
    <updated>2022-10-12T01:42:06Z</updated>
    <id>tag:github.com,2022-10-12:/ml874/Data-Engineering-on-GCP-Cheatsheet</id>
    <link href="https://github.com/ml874/Data-Engineering-on-GCP-Cheatsheet" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Data Engineering on GCP Cheatsheet&lt;/h1&gt; &#xA;&lt;p&gt;This cheatsheet is currently a 9-page reference Data Engineering on the Google Cloud Platform. It covers the data engineering lifecycle, machine learning, Google case studies, and GCP&#39;s storage, compute, and big data products.&lt;/p&gt; &#xA;&lt;p&gt;I compiled this sheet while studying for Google&#39;s Data Engineering Exam- this cheatsheet is not guaranteed to help you pass.&lt;/p&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ml874/Data-Engineering-on-GCP-Cheatsheet/master/Screenshots/screenshot1.png?raw=true&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This work is licensed under a &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/a&gt;. &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png&#34;&gt;&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-08-10&lt;/strong&gt;: Added Google Data Engineering Cheatsheet&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to suggest comments, updates, and potential improvements!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Maverick Lin&lt;/strong&gt;: Reach out to me via &lt;a href=&#34;https://www.quora.com/profile/Maverick-Lin&#34;&gt;Quora&lt;/a&gt; or through my &lt;a href=&#34;http://mavericklin.com/&#34;&gt;website&lt;/a&gt;. Cheers.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Just-A-Visitor/Algorithmic-Pseudocode</title>
    <updated>2022-10-12T01:42:06Z</updated>
    <id>tag:github.com,2022-10-12:/Just-A-Visitor/Algorithmic-Pseudocode</id>
    <link href="https://github.com/Just-A-Visitor/Algorithmic-Pseudocode" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository contains the pseudocode(pdf) of various algorithms and data structures necessary for Interview Preparation and Competitive Coding&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;200&#34; height=&#34;200&#34; src=&#34;https://raw.githubusercontent.com/Just-A-Visitor/Algorithmic-Pseudocode/master/Images/Icon.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/algorithmic-pseudocode/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/algorithmic-pseudocode/community.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://just-a-visitor.github.io/&#34;&gt;&lt;img src=&#34;https://img.shields.io/website-up-down-green-red/http/shields.io.svg?sanitize=true&#34; alt=&#34;Website shields.io&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A strange game. The only winning move is not to play&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Introduction&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the pseudo-code of various algorithms and data structures necessary for &lt;strong&gt;Interview Preparation&lt;/strong&gt; and &lt;strong&gt;Competitive Coding&lt;/strong&gt;. The pseudocodes are written such that they can be easily adapted to any language. Let us remove the clutter of language and focus on the core concepts of the question!&lt;/p&gt; &#xA;&lt;h1&gt;Sample GIF&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Just-A-Visitor/Algorithmic-Pseudocode/master/Images/Sample.gif&#34; alt=&#34;Images&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Contribution&lt;/h1&gt; &#xA;&lt;p&gt;Read this section carefully if you are planning on contributing to this repository.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The What&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;In the &lt;code&gt;Pseudocode&lt;/code&gt; folder, you can find a lot of algorithms. If you&#39;ve come across any interesting algorithms that changed the way you think about any topic, please consider contributing it to this repo.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;There are a lot of pseudocodes with no explanation. If you want to write a detailed explanation on the workings and intuition of these algorithms, please raise an issue and start working on it after it is approved). I would prefer if the explanation is in &lt;code&gt;pdf&lt;/code&gt; format. However, markdown format is equally acceptable.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you are familiar with &lt;code&gt;tikz&lt;/code&gt;, &lt;code&gt;pgf&lt;/code&gt; or &lt;code&gt;beamer&lt;/code&gt;, consider making some animations/graphs/diagrams/plots to explain the various algorithms.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you want to contribute anything other than pseudocodes, feel free to explore the repository and pick up a code and explain its logic and working (either in &lt;code&gt;pdf&lt;/code&gt; or &lt;code&gt;Markdown&lt;/code&gt; format). If you don&#39;t see your desired code, feel free to add it. However, remember that this repository is not a code dump and you should only add new codes if you have written a good post explaining the intricacies of the algorithm.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Why&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;You&#39;ll understand the algorithm in depth once you start working on its pseudocode because now you need to explain your code to people who code in a variety of languages.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Your work might help other people preparing for interviews/competitive programming get acquainted with the core concepts of the algorithms rather than being confused by the clutter of the programming language.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Lastly, you&#39;ll get to learn &lt;strong&gt;LaTeX&lt;/strong&gt; which is a great experience in itself.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;The How&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;If this is your first time contributing to a public repository, please refer to this &lt;a href=&#34;https://akrabat.com/the-beginners-guide-to-contributing-to-a-github-project/&#34;&gt;link&lt;/a&gt;. For more clarity, you can refer to this &lt;a href=&#34;https://github.com/MarcDiethelm/contributing&#34;&gt;link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you are not familiar with &lt;strong&gt;TeX&lt;/strong&gt; or TypeSetting in general, please refer to this &lt;a href=&#34;https://www.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes&#34;&gt;link&lt;/a&gt;. You don&#39;t need to install anything to contribute to this repository. Just make sure that you have an &lt;strong&gt;Overleaf&lt;/strong&gt; account and you are good to go.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create an &lt;em&gt;issue&lt;/em&gt; if you&#39;ve decided to work on an algorithm and get it approved before the coding phase. &lt;strong&gt;Please do not start working on the issue before commenting on that particular thread.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure to follow the coding standards. Put the source code in a file called &lt;code&gt;SourceCode.tex&lt;/code&gt;. (Notice the Capitalisation).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you want to code a different implementation than what is already present (for example, &lt;em&gt;iterative&lt;/em&gt; instead of &lt;em&gt;recursive&lt;/em&gt;, constant space instead of linear space, etc), please create a new sub-folder inside the root directory.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Don&#39;t include a lot of comments in the pseudocode (it just means that the code is not self-expressive). However, if the algorithm is highly non-trivial and you would like to include some explanation, please do so before or after the pseudocode. Refer to this &lt;a href=&#34;https://raw.githubusercontent.com/Just-A-Visitor/Algorithmic-Pseudocode/master/Pseudocode/Heaps/Median%20in%20a%20Stream%20of%20Integers/Median%20in%20Stream.pdf&#34;&gt;link&lt;/a&gt; for example.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Do &lt;strong&gt;not&lt;/strong&gt; create a &lt;strong&gt;ReadMe&lt;/strong&gt; file inside the newly created folder. If you want to submit the code with which you tested your pseudocode, you can add it in the &lt;strong&gt;Validation Codes&lt;/strong&gt; folder following the same hierarchy.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you borrow the code from any online/offline source, please remember to cite it.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Finally, &lt;strong&gt;please do not include a &lt;code&gt;pdf&lt;/code&gt; file of the final source code&lt;/strong&gt; (This is to avoid untracked binary in the repo&#39;s history). The pdf files would be generated after everything has been finalized.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make a pull request. Sit back and relax while your pull request gets merged.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stuck?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you need any clarifications or are stuck on something for a long time, feel free to ping us. &lt;a href=&#34;https://gitter.im/algorithmic-pseudocode/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/algorithmic-pseudocode/community.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Credits&lt;/h1&gt; &#xA;&lt;p&gt;Icon made by &lt;a href=&#34;https://www.flaticon.com/authors/freepik&#34;&gt;Freepik&lt;/a&gt; from &lt;a href=&#34;https://www.flaticon.com&#34;&gt;Flaticon&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>markvdw/mml-autumn-2022</title>
    <updated>2022-10-12T01:42:06Z</updated>
    <id>tag:github.com,2022-10-12:/markvdw/mml-autumn-2022</id>
    <link href="https://github.com/markvdw/mml-autumn-2022" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Materials for Autumn 2022 Mathematics for Machine Learning course.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Mathematics for Machine Learning&lt;/h1&gt; &#xA;&lt;p&gt;Autumn 2022 Lecturers: &lt;a href=&#34;https://mvdw.uk&#34;&gt;Mark van der Wilk&lt;/a&gt;, &lt;a href=&#34;http://yingzhenli.net/home/en/&#34;&gt;Yingzhen Li&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Lecture materials for the Imperial College London course &#34;Mathematics for Machine Learning&#34;. Some material is based on an earlier version of the course by &lt;a href=&#34;https://www.deisenroth.cc/&#34;&gt;Marc Deisenroth&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome any suggestions and fixes from students. For those who make contributions, there will be cake.&lt;/p&gt; &#xA;&lt;p&gt;If you want to make a contribution, please fork the repo, and make a pull request.&lt;/p&gt; &#xA;&lt;h2&gt;Syllabus&lt;/h2&gt; &#xA;&lt;p&gt;Below is a syllabus of the course, together with a rough plan for the term. This is subject to change.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pre-course exercises &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Basic probability, events, mutual exclusivity, independence, RVs&lt;/li&gt; &#xA;   &lt;li&gt;Probability densities, multivariate ones, multivariate integrals&lt;/li&gt; &#xA;   &lt;li&gt;Simple maximum likelihood&lt;/li&gt; &#xA;   &lt;li&gt;Statistical terminology (estimator, statistic, ...)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Lecture 1: A (Hopefully (Reasonably)) Familiar Collection of Maths (MvdW) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Introduction (MvdW) &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;What is this course about?&lt;/li&gt; &#xA;     &lt;li&gt;Who is it for?&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Setting the scene for Probability &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Understanding the world using probability, models (shaking desk)&lt;/li&gt; &#xA;     &lt;li&gt;Notation of vector probability density (vectors as grouping of variables)&lt;/li&gt; &#xA;     &lt;li&gt;Maximum Likelihood (Recap from P&amp;amp;S)&lt;/li&gt; &#xA;     &lt;li&gt;Linear Regression from loss func and as MaxLik&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Multivariate differentiation &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Differentiation, by scalars and vectors&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Multivariate calculus (revision)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Lecture 2: Differentiation &amp;amp; Autodiff (MvdW) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Differentiation of vectors, general array differentiation&lt;/li&gt; &#xA;   &lt;li&gt;Index notation for multivariate calculus&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Lecture 3: Automatic differentiation (MvdW) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Computational Graph&lt;/li&gt; &#xA;   &lt;li&gt;Forward-mode autodiff&lt;/li&gt; &#xA;   &lt;li&gt;Backward-mode autodiff&lt;/li&gt; &#xA;   &lt;li&gt;Computational complexity guarantees (&lt;a href=&#34;https://timvieira.github.io/blog/post/2016/09/25/evaluating-fx-is-as-fast-as-fx/&#34;&gt;see this&lt;/a&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Lecture 4: Gradient Descent (YL)&lt;/li&gt; &#xA; &lt;li&gt;Lecture 5: Gradient descent applications: Linear &amp;amp; Logistic Regression (YL)&lt;/li&gt; &#xA; &lt;li&gt;Lecture 6 &amp;amp; 7: Multivariate Probability (YL)&lt;/li&gt; &#xA; &lt;li&gt;Lecture 8 &amp;amp; 9: Validation &amp;amp; Cross-validation (MvdW) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Overfitting&lt;/li&gt; &#xA;   &lt;li&gt;Estimating on the training set: Danger, underestimates error!&lt;/li&gt; &#xA;   &lt;li&gt;Unbiased estimate (recap from P&amp;amp;S)&lt;/li&gt; &#xA;   &lt;li&gt;High-probability bounds on generalisation error&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Lecture 10 and 11: Bayesian inference (MvdWL) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Principle of Bayesian inference&lt;/li&gt; &#xA;   &lt;li&gt;Gaussian conditioning from completing the square&lt;/li&gt; &#xA;   &lt;li&gt;Gaussian conditioning from a big joint distribution&lt;/li&gt; &#xA;   &lt;li&gt;Bayesian Linear Regression&lt;/li&gt; &#xA;   &lt;li&gt;Exercises: Simple Bayesian inference (coins), derive BLR.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Lecture 12: Bias-variance trade-off (YL)&lt;/li&gt; &#xA; &lt;li&gt;Lecture 13 &amp;amp; 14: Dimensionality Reduction &amp;amp; PCA (YL 2L)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>