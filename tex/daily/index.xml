<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TeX Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-15T01:37:45Z</updated>
  <subtitle>Daily Trending of TeX in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>RylanSchaeffer/Stanford-LaTeX-Poster-Template</title>
    <updated>2022-12-15T01:37:45Z</updated>
    <id>tag:github.com,2022-12-15:/RylanSchaeffer/Stanford-LaTeX-Poster-Template</id>
    <link href="https://github.com/RylanSchaeffer/Stanford-LaTeX-Poster-Template" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stanford LaTeX Poster Template&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/RylanSchaeffer/Stanford-LaTeX-Poster-Template/master/poster_pic.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;There are four color demos under &lt;code&gt;demos&lt;/code&gt;: Palo Alto Green, Cardinal Red, White and Cool Gray. To change the color, go to &lt;code&gt;beamerthemestanford.sty&lt;/code&gt; and change the &lt;code&gt;headline&lt;/code&gt; color:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;White Text, Palo Alto Green Banner: &lt;code&gt;\setbeamercolor{headline}{bg=paloaltogreen,fg=white}&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Cardinal Red Text, White Banner: &lt;code&gt;\setbeamercolor{headline}{bg=white,fg=cardinalred}&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;White Text, Cardinal Red Banner: &lt;code&gt;\setbeamercolor{headline}{bg=cardinalred,fg=white}&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;White Text, Cool Gray Banner: &lt;code&gt;\setbeamercolor{headline}{bg=coolgray,fg=white}&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are more than welcome! If you have a way to improve this poster, please pay it forward by opening a pull request and I&#39;ll add your improvement(s) :)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>openai/spinningup-workshop</title>
    <updated>2022-12-15T01:37:45Z</updated>
    <id>tag:github.com,2022-12-15:/openai/spinningup-workshop</id>
    <link href="https://github.com/openai/spinningup-workshop" rel="alternate"></link>
    <summary type="html">&lt;p&gt;For educational materials related to the spinning up workshops.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Spinning Up Workshop Materials&lt;/h1&gt; &#xA;&lt;h2&gt;Morning talks schedule:&lt;/h2&gt; &#xA;&lt;p&gt;9-10am: &lt;a href=&#34;https://github.com/openai/spinningup-workshop/raw/master/rl_intro/rl_intro.pdf&#34;&gt;Intro to RL, Part 1&lt;/a&gt;, presented by Joshua Achiam&lt;/p&gt; &#xA;&lt;p&gt;10:15-11am: &lt;a href=&#34;https://github.com/openai/spinningup-workshop/raw/master/rl_intro/rl_intro.pdf&#34;&gt;Intro to RL, Part 2&lt;/a&gt;, presented by Joshua Achiam&lt;/p&gt; &#xA;&lt;p&gt;11-11:30am: &lt;a href=&#34;https://github.com/openai/spinningup-workshop/tree/master/research_talks&#34;&gt;Learning Dexterity&lt;/a&gt;, presented by Matthias Plappert&lt;/p&gt; &#xA;&lt;p&gt;11:30am-12pm: Intro to AI Safety, presented by Dario Amodei&lt;/p&gt; &#xA;&lt;h2&gt;Breakout sessions:&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/openai/spinningup-workshop/raw/master/tensorflow_review/tf_review_session.pdf&#34;&gt;Intro to Tensorflow&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/openai/spinningup-workshop/tree/master/writing_dqn_together&#34;&gt;Writing DQN Together&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/openai/spinningup-workshop/raw/master/rl_intro/rl_intro_part2.pdf&#34;&gt;Advanced RL Q&amp;amp;A&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Project recommendations:&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://docs.google.com/document/d/1pmqV-dAFSRDVYct9m6smP702f9cUIsPYTyamPLUcQZs/edit#&#34;&gt;this list&lt;/a&gt; of recommended projects if you need something to hack on!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>awesome-NeRF/awesome-NeRF</title>
    <updated>2022-12-15T01:37:45Z</updated>
    <id>tag:github.com,2022-12-15:/awesome-NeRF/awesome-NeRF</id>
    <link href="https://github.com/awesome-NeRF/awesome-NeRF" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A curated list of awesome neural radiance fields papers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome Neural Radiance Fields &lt;a href=&#34;https://github.com/sindresorhus/awesome&#34;&gt;&lt;img src=&#34;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true&#34; alt=&#34;Awesome&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;A curated list of awesome neural radiance fields papers, inspired by &lt;a href=&#34;https://github.com/jbhuang0604/awesome-computer-vision&#34;&gt;awesome-computer-vision&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/how-to-PR.md&#34;&gt;How to submit a pull request?&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://github.com/awesome-NeRF/awesome-NeRF/issues/108#issuecomment-1350732470&#34;&gt;Want to help maintain the list?&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/#survey&#34;&gt;Survey&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/#papers&#34;&gt;Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/#talks&#34;&gt;Talks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/#implementations&#34;&gt;Implementations&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Survey&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2101.05204&#34;&gt;Neural Volume Rendering: NeRF And Beyond&lt;/a&gt;, Dellaert and Yen-Chen, Arxiv 2020 | &lt;a href=&#34;https://dellaert.github.io/NeRF/&#34;&gt;blog&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/yenchenlin/awesome-NeRF/main/NeRF-and-Beyond.bib&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/nerf-survey.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Papers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.matthewtancik.com/nerf&#34;&gt;NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis&lt;/a&gt;, Mildenhall et al., ECCV 2020 | &lt;a href=&#34;https://github.com/bmild/nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L168-L173&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Mildenhall20eccv_nerf--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Faster Inference&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lingjie0206.github.io/papers/NSVF/&#34;&gt;Neural Sparse Voxel Fields&lt;/a&gt;, Liu et al., NeurIPS 2020 | &lt;a href=&#34;https://github.com/facebookresearch/NSVF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L135-L141&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Liu20neurips_sparse_nerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.computationalimaging.org/publications/automatic-integration/&#34;&gt;AutoInt: Automatic Integration for Fast Neural Volume Rendering&lt;/a&gt;, Lindell et al., CVPR 2021 | &lt;a href=&#34;https://github.com/computational-imaging/automatic-integration&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L127-L133&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Lindell20arxiv_AutoInt--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.12490&#34;&gt;DeRF: Decomposed Radiance Fields&lt;/a&gt;, Rebain et al. Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L222-L228&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Rebain20arxiv_derf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://depthoraclenerf.github.io/&#34;&gt;DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks&lt;/a&gt;, Neff et al., CGF 2021 | &lt;a href=&#34;https://github.com/facebookresearch/DONERF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/donerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--neff2021donerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.10380&#34;&gt;FastNeRF: High-Fidelity Neural Rendering at 200FPS&lt;/a&gt;, Garbin et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/fastnerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Garbin21arxiv_FastNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.13744&#34;&gt;KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs &lt;/a&gt;, Reiser et al., ICCV 2021 | &lt;a href=&#34;https://github.com/creiser/kilonerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/kilonerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--reiser2021kilonerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://alexyu.net/plenoctrees/&#34;&gt;PlenOctrees for Real-time Rendering of Neural Radiance Fields&lt;/a&gt;, Yu et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/sxyu/volrend&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/plenoctrees.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--yu2021plenoctrees--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.01954&#34;&gt;Mixture of Volumetric Primitives for Efficient Neural Rendering&lt;/a&gt;, Lombardi et al., SIGGRAPH 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/mixture.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vsitzmann.github.io/lfns/&#34;&gt;Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering&lt;/a&gt;, Sitzmann et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/vsitzmann/light-field-networks&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/lfn.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Faster Training&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2107.02791.pdf&#34;&gt;Depth-supervised NeRF: Fewer Views and Faster Training for Free&lt;/a&gt;, Deng et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/dunbar12138/DSNeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/dsnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2111.11215.pdf&#34;&gt;Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction&lt;/a&gt;, Sun et al., CVPR 2022 | &lt;a href=&#34;https://github.com/sunset1995/DirectVoxGO&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/DirectVoxGO.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--sun2021direct--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Unconstrained Images&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nerf-w.github.io/&#34;&gt;NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections&lt;/a&gt;, Martin-Brualla et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L152-L158&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--MartinBrualla20arxiv_nerfw--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rover-xingyu.github.io/Ha-NeRF/&#34;&gt;Ha-NeRF&lt;span&gt;😆&lt;/span&gt;: Hallucinated Neural Radiance Fields in the Wild&lt;/a&gt;, Chen et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/rover-xingyu/Ha-NeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/Ha-NeRF.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--chen2021hallucinated--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Deformable&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nerfies.github.io/&#34;&gt;Deformable Neural Radiance Fields&lt;/a&gt;, Park et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/google/nerfies&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L206-L212&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Park20arxiv_nerfies--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.albertpumarola.com/research/D-NeRF/index.html&#34;&gt;D-NeRF: Neural Radiance Fields for Dynamic Scenes&lt;/a&gt;, Pumarola et al., CVPR 2021 | &lt;a href=&#34;https://github.com/albertpumarola/D-NeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L214-L220&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Pumarola20arxiv_D_NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gafniguy.github.io/4D-Facial-Avatars/&#34;&gt;Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction&lt;/a&gt;, Gafni et al., CVPR 2021 | &lt;a href=&#34;https://github.com/gafniguy/4D-Facial-Avatars&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L87-L93&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Gafni20arxiv_DNRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/&#34;&gt;Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Deforming Scene from Monocular Video&lt;/a&gt;, Tretschk et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/facebookresearch/nonrigid_nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L283-L289&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Tretschk20arxiv_NR-NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://volumetric-avatars.github.io/&#34;&gt;PVA: Pixel-aligned Volumetric Avatars&lt;/a&gt;, Raj et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/pva.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nogu-atsu/NARF&#34;&gt;Neural Articulated Radiance Field&lt;/a&gt;, Noguchi et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/nogu-atsu/NARF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/narf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.00181&#34;&gt;CLA-NeRF: Category-Level Articulated Neural Radiance Field&lt;/a&gt;, Tseng et al., ICRA 2022 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/cla-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zju3dv.github.io/animatable_nerf/&#34;&gt;Animatable Neural Radiance Fields for Modeling Dynamic Human Bodies&lt;/a&gt;, Peng et al., ICCV 2021 | &lt;a href=&#34;https://github.com/zju3dv/animatable_nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/animatable_nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Peng21arxiv_animatable_nerf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hypernerf.github.io/&#34;&gt;A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields&lt;/a&gt;, Park et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/google/hypernerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/hypernerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.13629&#34;&gt;Animatable Neural Radiance Fields from Monocular RGB Videos&lt;/a&gt;, Chen et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/JanaldoChen/Anim-NeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/anim_nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vcai.mpi-inf.mpg.de/projects/NeuralActor/&#34;&gt;Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control&lt;/a&gt;, Liu et al., SIGGRAPH Asia 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/neuralactor.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Video&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.cs.cornell.edu/~zl548/NSFF/&#34;&gt;Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes&lt;/a&gt;, Li et al., CVPR 2021 | &lt;a href=&#34;https://github.com/zhengqili/Neural-Scene-Flow-Fields&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L119-L125&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Li20arxiv_nsff--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://video-nerf.github.io/&#34;&gt;Space-time Neural Irradiance Fields for Free-Viewpoint Video&lt;/a&gt;, Xian et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L299-L305&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Xian20arxiv_stnif--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yilundu.github.io/nerflow/&#34;&gt;Neural Radiance Flow for 4D View Synthesis and Video Processing&lt;/a&gt;, Du et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L79-L85&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Du20arxiv_nerflow--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zju3dv.github.io/neuralbody/&#34;&gt;Neural Body: Implicit Neural Representations with Structured Latent Codes for Novel View Synthesis of Dynamic Humans&lt;/a&gt;, Peng et al., CVPR 2021 | &lt;a href=&#34;https://github.com/zju3dv/neuralbody&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/neuralbody.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Peng20arxiv_neuralbody--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://neural-3d-video.github.io/&#34;&gt;Neural 3D Video Synthesis from Multi-view Video&lt;/a&gt;, Li et al., CVPR 2022 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/3d-video.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://free-view-video.github.io/&#34;&gt;Dynamic View Synthesis from Dynamic Monocular Video&lt;/a&gt;, Gao et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/dvs_dmv.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://waymo.com/research/block-nerf/&#34;&gt;Block-NeRF: Scalable Large Scene Neural View Synthesis&lt;/a&gt;, Tancik et al., Arxiv 2022 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/Block-NeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Generalization&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.02442&#34;&gt;GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis&lt;/a&gt;, Schwarz et al., NeurIPS 2020 | &lt;a href=&#34;https://github.com/autonomousvision/graf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L237-L243&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Schwarz20neurips_graf--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.04595&#34;&gt;GRF: Learning a General Radiance Field for 3D Scene Representation and Rendering&lt;/a&gt;, Trevithick and Yang, Arxiv 2020 | &lt;a href=&#34;https://github.com/alextrevithick/GRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L291-L297&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Trevithick20arxiv_GRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.02190&#34;&gt;pixelNeRF: Neural Radiance Fields from One or Few Images&lt;/a&gt;, Yu et al., CVPR 2021 | &lt;a href=&#34;https://github.com/sxyu/pixel-nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L329-L335&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Yu20arxiv_pixelNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.02189&#34;&gt;Learned Initializations for Optimizing Coordinate-Based Neural Representations&lt;/a&gt;, Tancik et al., CVPR 2021 | &lt;a href=&#34;https://github.com/tancik/learnit&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L268-L274&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Tancik20arxiv_meta--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://marcoamonteiro.github.io/pi-GAN-website/&#34;&gt;pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis&lt;/a&gt;, Chan et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L24-L30&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Chan20arxiv_piGAN--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://portrait-nerf.github.io/&#34;&gt;Portrait Neural Radiance Fields from a Single Image&lt;/a&gt;, Gao et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L95-L101&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Gao20arxiv_pNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2102.08860.pdf&#34;&gt;ShaRF: Shape-conditioned Radiance Fields from a Single View&lt;/a&gt;, Rematas et al., ICML 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/sharf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ibrnet.github.io/static/paper.pdf&#34;&gt;IBRNet: Learning Multi-View Image-Based Rendering&lt;/a&gt;, Wang et al., CVPR 2021 | &lt;a href=&#34;https://github.com/googleinterns/IBRNet&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/ibr.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2103.17269.pdf&#34;&gt;CAMPARI: Camera-Aware Decomposed Generative Neural Radiance Fields&lt;/a&gt;, Niemeyer &amp;amp; Geiger, Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/CAMPARI.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2104.00587.pdf&#34;&gt;NeRF-VAE: A Geometry Aware 3D Scene Generative Model&lt;/a&gt;, Kosiorek et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/nerf-vae.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://apple.github.io/ml-gsn/&#34;&gt;Unconstrained Scene Generation with Locally Conditioned Radiance Fields&lt;/a&gt;, DeVries et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/gsn.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://apchenstu.github.io/mvsnerf/&#34;&gt;MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo&lt;/a&gt;, Chen et al., ICCV 2021 | &lt;a href=&#34;https://github.com/apchenstu/mvsnerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/mvsnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://virtualhumans.mpi-inf.mpg.de/srf/&#34;&gt;Stereo Radiance Fields (SRF): Learning View Synthesis from Sparse Views of Novel Scenes&lt;/a&gt;, Chibane et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/srf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://liuyuan-pal.github.io/NeuRay/&#34;&gt;Neural Rays for Occlusion-aware Image-based Rendering&lt;/a&gt;, Liu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/neuray.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ajayj.com/dietnerf&#34;&gt;Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis&lt;/a&gt;, Matthew Tancik et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/DietNeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vincentfung13.github.io/projects/mine/&#34;&gt;MINE: Towards Continuous Depth MPI with NeRF for Novel View Synthesis&lt;/a&gt;, Jiaxin Li et al., ICCV 2021 | &lt;a href=&#34;https://github.com/vincentfung13/MINE&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/MINE.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://imaging.cs.cmu.edu/torf/&#34;&gt;TöRF: Time-of-Flight Radiance Fields for Dynamic Scene View Synthesis&lt;/a&gt;, Benjamin Attal et al., NeurIPS 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/turf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sites.google.com/view/wbjang/home/codenerf&#34;&gt;CodeNeRF: Disentangled Neural Radiance Fields for Object Categories&lt;/a&gt;, Jang et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/CodeNeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://jiataogu.me/style_nerf/&#34;&gt;StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis&lt;/a&gt;, Gu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/stylenerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bmild.github.io/rawnerf/&#34;&gt;NeRF in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images&lt;/a&gt;, Ben Mildenhall et al, arXiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/rawnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Pose Estimation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://yenchenlin.me/inerf/&#34;&gt;iNeRF: Inverting Neural Radiance Fields for Pose Estimation&lt;/a&gt;, Yen-Chen et al. IROS 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L321-L327&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--YenChen20arxiv_iNeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lemonatsu.github.io/ANeRF-Surface-free-Pose-Refinement/&#34;&gt;A-NeRF: Surface-free Human 3D Pose Refinement via Neural Rendering&lt;/a&gt;, Su et al. Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/a-nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Su21arxiv_A_NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nerfmm.active.vision/&#34;&gt;NeRF--: Neural Radiance Fields Without Known Camera Parameters&lt;/a&gt;, Wang et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/ActiveVisionLab/nerfmm&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/nerf--.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Wang21arxiv_nerfmm--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://edgarsucar.github.io/iMAP/&#34;&gt;iMAP: Implicit Mapping and Positioning in Real-Time&lt;/a&gt;, Sucar et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/imap.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pengsongyou.github.io/nice-slam&#34;&gt;NICE-SLAM: Neural Implicit Scalable Encoding for SLAM&lt;/a&gt;, Zhu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/nice-slam.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.15606&#34;&gt;GNeRF: GAN-based Neural Radiance Field without Posed Camera&lt;/a&gt;, Meng et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/gnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/&#34;&gt;BARF: Bundle-Adjusting Neural Radiance Fields&lt;/a&gt;, Lin et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/barf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://postech-cvlab.github.io/SCNeRF/&#34;&gt;Self-Calibrating Neural Radiance Fields&lt;/a&gt;, Jeong et al., ICCV 2021 | &lt;a href=&#34;https://github.com/POSTECH-CVLab/SCNeRF&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/citations/SCNeRF.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Lighting&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://markboss.me/publication/2021-nerd/&#34;&gt;NeRD: Neural Reflectance Decomposition from Image Collections&lt;/a&gt;, Boss et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L9-L15&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Boss20arxiv_NeRD--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~pratul/nerv/&#34;&gt;NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis&lt;/a&gt;, Srinivasan et al. CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L260-L266&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Srinivasan20arxiv_NeRV--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nex-mpi.github.io/&#34;&gt;NeX: Real-time View Synthesis with Neural Basis Expansion&lt;/a&gt;, Wizadwongsa et al. Arxiv 2021 | &lt;a href=&#34;https://github.com/nex-mpi/nex-code&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/nex.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://people.csail.mit.edu/xiuming/projects/nerfactor/&#34;&gt;NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination&lt;/a&gt;, Zhang et al. Arxiv 2021 | &lt;a href=&#34;https://github.com/google/nerfactor&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/nerfactor.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Compositionality&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.07492&#34;&gt;NeRF++: Analyzing and Improving Neural Radiance Fields&lt;/a&gt;, Zhang et al., Arxiv 2020 | &lt;a href=&#34;https://github.com/Kai-46/nerfplusplus&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L345-L351&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Zhang20arxiv_nerf++--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.12100&#34;&gt;GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields&lt;/a&gt;, Niemeyer et al., CVPR 2021, &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L175-L181&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Niemeyer20arxiv_GIRAFFE--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shellguo.com/osf/&#34;&gt;Object-Centric Neural Scene Rendering&lt;/a&gt;, Guo et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L111-L117&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Guo20arxiv_OSF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ziyanw1.github.io/hybrid_nerf/&#34;&gt;Learning Compositional Radiance Fields of Dynamic Human Heads&lt;/a&gt;, Wang et al., Arxiv 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/hybrid-nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Wang20arxiv_hybrid_NeRF--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://light.princeton.edu/neural-scene-graphs/&#34;&gt;Neural Scene Graphs for Dynamic Scenes&lt;/a&gt;, Ost et al., CVPR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L353-L358&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--Ost20arxiv_NeuralSceneGraphs--&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kovenyu.com/uorf/&#34;&gt;Unsupervised Discovery of Object Radiance Fields&lt;/a&gt;, Yu et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/uorf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zju3dv.github.io/object_nerf/&#34;&gt;Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering&lt;/a&gt;, Yang et al., ICCV 2021 | &lt;a href=&#34;https://github.com/zju3dv/object_nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/object-nerf.txt&#34;&gt;bibtex&lt;/a&gt; &#xA;  &lt;!--yang2021objectnerf--&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Scene Labelling and Understanding&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shuaifengzhi.com/Semantic-NeRF/&#34;&gt;In-Place Scene Labelling and Understanding with Implicit Scene Representation&lt;/a&gt;, Zhi et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/semantic-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Editing&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://editnerf.csail.mit.edu/&#34;&gt;Editing Conditional Radiance Fields&lt;/a&gt;, Liu et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/stevliu/editnerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/editnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jiakai-zhang.github.io/st-nerf/&#34;&gt;Editable Free-viewpoint Video Using a Layered Neural Representation&lt;/a&gt;, Zhang et al., SIGGRAPH 2021 | &lt;a href=&#34;https://github.com/DarlingHang/st-nerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/st-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Object Category Modeling&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fig-nerf.github.io/&#34;&gt;FiG-NeRF: Figure Ground Neural Radiance Fields for 3D Object Category Modelling&lt;/a&gt;, Xie et al., Arxiv 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/fig-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/blog/nvidia-research-nerf-tex-neural-reflectance-field-textures/&#34;&gt;NeRF-Tex: Neural Reflectance Field Textures&lt;/a&gt;, Baatz et al., EGSR 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/nerf-tex.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Multi-scale&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jonbarron.info/mipnerf/&#34;&gt;Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields&lt;/a&gt;, Barron et al., Arxiv 2021 | &lt;a href=&#34;https://github.com/google/mipnerf&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/mip-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Model Reconstruction&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.10078&#34;&gt;UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction&lt;/a&gt;, Oechsle et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/unisurf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.10689&#34;&gt;NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction&lt;/a&gt;, Wang et al., NeurIPS 2021 | &lt;a href=&#34;https://github.com/Totoro97/NeuS&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/neus.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.12052&#34;&gt;Volume Rendering of Neural Implicit Surfaces&lt;/a&gt;, Yariv et al., NeurIPS 2021 | &lt;a href=&#34;https://github.com/ventusff/neurecon&#34;&gt;github&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/volsdf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Depth Estimation&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://weiyithu.github.io/NerfingMVS/&#34;&gt;NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-view Stereo&lt;/a&gt;, Wei et al., ICCV 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/NerfingMVS.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Robotics&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://3d-representation-learning.github.io/nerf-dy/&#34;&gt;3D Neural Scene Representations for Visuomotor Control&lt;/a&gt;, Li et al., CoRL 2021 Oral | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/nerf-dy.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2110.00168&#34;&gt;Vision-Only Robot Navigation in a Neural Radiance World&lt;/a&gt;, Adamkiewicz et al., RA-L 2022 Vol.7 No.2 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/vision-only.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Talks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=LCTYRqW-ne8&amp;amp;t=10190s&#34;&gt;NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis&lt;/a&gt;, Ben Mildenhall&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nRyOzHpcr4Q&amp;amp;feature=emb_logo&amp;amp;ab_channel=cvprtum&#34;&gt;Understanding and Extending Neural Radiance Fields&lt;/a&gt;, Barron et al.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/Rd0nBO6--bM?t=1992&#34;&gt;Towards Photorealism (2nd half)&lt;/a&gt;, Vladlen Koltun&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=dPWLybp4LL0&#34;&gt;Neural Radiance Fields for View Synthesis&lt;/a&gt;, Matthew Tancik&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Implementations&lt;/h2&gt; &#xA;&lt;h4&gt;Tensorflow&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bmild/nerf&#34;&gt;NeRF&lt;/a&gt;, Mildenhall et al., 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/NeRF-and-Beyond.bib#L168-L173&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;PyTorch&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yenchenlin/nerf-pytorch&#34;&gt;NeRF-PyTorch&lt;/a&gt;, Yen-Chen Lin, 2020 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/pytorch-nerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kwea123/nerf_pl&#34;&gt;NeRF-PyTorch-Lighting&lt;/a&gt;, &lt;a href=&#34;https://github.com/kwea123&#34;&gt;@kwea123&lt;/a&gt;, 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kwea123/nerf_pl/tree/nerfw&#34;&gt;NeRF-W&lt;/a&gt;, &lt;a href=&#34;https://github.com/kwea123&#34;&gt;@kwea123&lt;/a&gt;, 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/pytorch3d/tree/master/projects/nerf&#34;&gt;NeRF-PyTorch3D&lt;/a&gt;, &lt;a href=&#34;https://github.com/facebookresearch&#34;&gt;@facebookresearch&lt;/a&gt;, 2020&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Jax&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/google-research/google-research/tree/master/jaxnerf&#34;&gt;JaxNeRF&lt;/a&gt;, Deng et al., 2020 | &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF/raw/main/NeRF-and-Beyond.bib#L55-L60&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/google/mipnerf&#34;&gt;Mip-NeRF&lt;/a&gt;, &lt;a href=&#34;https://github.com/google&#34;&gt;@google&lt;/a&gt;, 2021 | &lt;a href=&#34;https://raw.githubusercontent.com/awesome-NeRF/awesome-NeRF/main/citations/mipnerf.txt&#34;&gt;bibtex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Libraries&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/google-research/visu3d&#34;&gt;Visu3d&lt;/a&gt;, &lt;a href=&#34;https://github.com/google-research&#34;&gt;@google&lt;/a&gt;, 2022&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
</feed>