<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-15T01:35:56Z</updated>
  <subtitle>Daily Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>squarecat/doc-buddy</title>
    <updated>2023-05-15T01:35:56Z</updated>
    <id>tag:github.com,2023-05-15:/squarecat/doc-buddy</id>
    <link href="https://github.com/squarecat/doc-buddy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GPT chatbot that will learn documents and instruction manuals uploaded to it&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Documentation Buddy&lt;/h1&gt; &#xA;&lt;p&gt;Documentation Buddy is a Telegram chatbot powered by GPT and OpenAI. You can upload PDF and other documents, the bot will learn from them and you can ask it questions.&lt;/p&gt; &#xA;&lt;p&gt;Useful in a variety of situations where you have too much information to learn and need a quick reference guide!&lt;/p&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Your own OpenAI account and API Key&lt;/li&gt; &#xA; &lt;li&gt;A Pinecone account and API Key (for embeddings)&lt;/li&gt; &#xA; &lt;li&gt;Somewhere s3-like to save files (for re-indexing if needed)&lt;/li&gt; &#xA; &lt;li&gt;A Telegram key from BotFather&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Optional Requirements:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you don&#39;t use the DigitalOcean one-click deploy then you will also need to run OpenAIs embeddings project separately. You can get it from &lt;a href=&#34;https://github.com/openai/chatgpt-retrieval-plugin&#34;&gt;here&lt;/a&gt;. If you do this then set the env variable &lt;code&gt;EMBEDDINGS_URL&lt;/code&gt; to match. If you use the Deploy to DigitalOcean button below then this will be deployed for you as the &lt;code&gt;memory&lt;/code&gt; component.&lt;/li&gt; &#xA; &lt;li&gt;A DigitalOcean account if you want to deploy directly to DigitalOceans App Platform. If you don&#39;t already have one, you can sign up &lt;a href=&#34;https://www.digitalocean.com/?refcode=1f67a87765d4&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a new Telegram bot with BotFather. Step-by-step guide &lt;a href=&#34;https://core.telegram.org/bots/features#creating-a-new-bot&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You will get a token from BotFather that looks like this: &lt;code&gt;4839574812:AAFD39kkdpWt3ywyRZergyOLMaJhac60qc&lt;/code&gt;. You will use this for the &lt;code&gt;TELEGRAM_TOKEN&lt;/code&gt; env variable later.&lt;/li&gt; &#xA; &lt;li&gt;Create a &lt;a href=&#34;https://www.pinecone.io/&#34;&gt;Pinecone&lt;/a&gt; account. This is used to store the embeddings data of the uploaded documents.&lt;/li&gt; &#xA; &lt;li&gt;Get a Pinecone API key from the settings pages. You will use this for the &lt;code&gt;PINECONE_API_KEY&lt;/code&gt; env variable. The index will be created automatically later so you don&#39;t need to do anything else.&lt;/li&gt; &#xA; &lt;li&gt;Create a Digital Ocean Space (or other s3 like storage). This is used to store the documents uploaded in case they need to be reindexed later.&lt;/li&gt; &#xA; &lt;li&gt;Click the button below to deploy directly as a Digital Ocean App. This is a simple step-by-step process that takes &amp;lt;5 minutes.&lt;/li&gt; &#xA; &lt;li&gt;On the Environment Variables page of the Digital Ocean App creation process, replace the default values with the values you&#39;ve generated.&lt;/li&gt; &#xA; &lt;li&gt;The app should start automatically and connect to the Telegram API&lt;/li&gt; &#xA; &lt;li&gt;Open a chat in Telegram with the bot you created, and try chatting to it!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Deploying the App&lt;/h2&gt; &#xA;&lt;p&gt;Click this button to deploy the app to the DigitalOcean App Platform. If you are not logged in, you will be prompted to log in with your DigitalOcean account.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cloud.digitalocean.com/apps/new?repo=https://github.com/squarecat/doc-buddy/tree/main&amp;amp;refcode=1f67a87765d4&#34;&gt;&lt;img src=&#34;https://www.deploytodo.com/do-btn-blue.svg?sanitize=true&#34; alt=&#34;Deploy to DigitalOcean&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;When you get to the &#34;Review&#34; section of the deploy, make sure to set the plan to &lt;code&gt;Basic&lt;/code&gt; as it will default to &lt;code&gt;Pro&lt;/code&gt;. The chat component should run fine on a $5/mo sized instance, and the memory component will probably be fine at $5 also, but much faster at $10/mo.&lt;/p&gt; &#xA;&lt;h2&gt;Environment Variables&lt;/h2&gt; &#xA;&lt;p&gt;You&#39;ll need to add these to the DigitalOcean app env variables.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Key&lt;/th&gt; &#xA;   &lt;th&gt;Default&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OPEN_AI_MODEL&lt;/td&gt; &#xA;   &lt;td&gt;&#34;gpt-3.5-turbo&#34;&lt;/td&gt; &#xA;   &lt;td&gt;The AI model that the assistant will use to reply. GPT-3.5-Turbo will be good enough for most cases&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OPEN_AI_KEY&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Your OpenAI API Key&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TELEGRAM_TOKEN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The token you get from BotFather&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;EMBEDDINGS_BEARER_TOKEN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Set this to a randomly generated string&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;STORAGE_NAME&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The name of the s3 storage bucket eg. &#34;doc-buddy&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;STORAGE_URL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The url of the s3 bucket eg. &lt;a href=&#34;https://sfo3.digitaloceanspaces.com/&#34;&gt;https://sfo3.digitaloceanspaces.com/&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;STORAGE_KEY&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The API key of the s3 bucket&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;STORAGE_SECRET&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The Secret key of the s3 bucket&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DATASTORE&lt;/td&gt; &#xA;   &lt;td&gt;pinecone&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PINECONE_API_KEY&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Your Pinecone API key&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PINECONE_ENVIRONMENT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The envrinment of your Pinecone index eg. &#34;northamerica-northeast1-gcp&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PINECONE_INDEX&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The name of your Pinecone index eg. &#34;doc-buddy-memory&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Usage - uploading documentation&lt;/h2&gt; &#xA;&lt;p&gt;Simply upload a doc to the Telegram chat and doc buddy will learn the contents of that document.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/squarecat/doc-buddy/main/imgs/upload-file.png&#34; alt=&#34;Example file upload&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Customizing the assistant&lt;/h2&gt; &#xA;&lt;p&gt;You can edit the prompt that is given to the assistant in the &lt;code&gt;prompt.md&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;h2&gt;Sponsor&lt;/h2&gt; &#xA;&lt;p&gt;Sponsored by &lt;a href=&#34;https://tryellie.com&#34;&gt;Ellie - Your AI Email assistant&lt;/a&gt;. Ellie learns from your writing style and crafts replies as if they were written by you!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://tryellie.com?ref=doc-buddy&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/squarecat/doc-buddy/main/imgs/ellie.png&#34; alt=&#34;Ellie example&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.digitalocean.com/?refcode=1f67a87765d4&amp;amp;utm_campaign=Referral_Invite&amp;amp;utm_medium=Referral_Program&amp;amp;utm_source=badge&#34;&gt;&lt;img src=&#34;https://web-platforms.sfo2.digitaloceanspaces.com/WWW/Badge%203.svg?sanitize=true&#34; alt=&#34;DigitalOcean Referral Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>sunner/ChatALL</title>
    <updated>2023-05-15T01:35:56Z</updated>
    <id>tag:github.com,2023-05-15:/sunner/ChatALL</id>
    <link href="https://github.com/sunner/ChatALL" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Concurrently chat with ChatGPT, Bing Chat, bard, Alpaca, Vincuna, Claude, ChatGLM, MOSS, iFlytek Spark, ERNIE and more, discover the best answers&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sunner/ChatALL/main/README_ZH-CN.md&#34;&gt;简体中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/sunner/ChatALL/main/src/assets/logo-cover.png&#34; width=&#34;256&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;Chat with ALL AI Bots Concurrently, Discover the Best&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sunner/ChatALL/main/screenshots/screenshot-2.png?raw=true&#34; alt=&#34;Screenshot&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sunner/ChatALL/main/screenshots/screenshot-1.png?raw=true&#34; alt=&#34;Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;Large Language Models (LLMs) based AI bots are amazing. However, their behavior can be random and different bots excel at different tasks. If you want the best experience, don&#39;t try them one by one. ChatALL (Chinese name: 齐叨) can send prompt to severl AI bots concurrently, help you to discover the best results.&lt;/p&gt; &#xA;&lt;h3&gt;Supported bots&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;AI Bots&lt;/th&gt; &#xA;   &lt;th&gt;Web Access&lt;/th&gt; &#xA;   &lt;th&gt;API&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat.openai.com&#34;&gt;ChatGPT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bing.com/new&#34;&gt;Bing Chat&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;No API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://yiyan.baidu.com/&#34;&gt;Baidu ERNIE&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://bard.google.com/&#34;&gt;Bard&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;No API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://poe.com/&#34;&gt;Poe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Coming soon&lt;/td&gt; &#xA;   &lt;td&gt;Coming soon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://moss.fastnlp.top/&#34;&gt;MOSS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;No API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://tongyi.aliyun.com/&#34;&gt;Tongyi Qianwen&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Coming soon&lt;/td&gt; &#xA;   &lt;td&gt;Coming soon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ai.dedao.cn/&#34;&gt;Dedao Learning Assistant&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Coming soon&lt;/td&gt; &#xA;   &lt;td&gt;No API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://xinghuo.xfyun.cn/&#34;&gt;iFLYTEK SPARK&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Coming soon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://crfm.stanford.edu/2023/03/13/alpaca.html&#34;&gt;Alpaca&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;No API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://lmsys.org/blog/2023-03-30-vicuna/&#34;&gt;Vicuna&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;No API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chatglm.cn/blog&#34;&gt;ChatGLM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;No API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.anthropic.com/index/introducing-claude&#34;&gt;Claude&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;No API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gradio.app/&#34;&gt;Gradio&lt;/a&gt; for self-deployed models&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;No API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;And more...&lt;/p&gt; &#xA;&lt;h3&gt;Other features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Quick-prompt mode: send the next prompt without waiting for the previous request to complete&lt;/li&gt; &#xA; &lt;li&gt;Store chat history locally, protect your privacy&lt;/li&gt; &#xA; &lt;li&gt;Highlight the response you like, delete the bad&lt;/li&gt; &#xA; &lt;li&gt;Automatically keep ChatGPT session alive&lt;/li&gt; &#xA; &lt;li&gt;Enable/disable any bots at any time&lt;/li&gt; &#xA; &lt;li&gt;Switch between one, two, or three-column view&lt;/li&gt; &#xA; &lt;li&gt;Supports multiple languages (en, zh)&lt;/li&gt; &#xA; &lt;li&gt;[TODO] Best recommendations&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;ChatALL is a client, not a proxy. Therefore, you must:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Have working accounts and/or API tokens for the bots.&lt;/li&gt; &#xA; &lt;li&gt;Have reliable network connections to the bots.&lt;/li&gt; &#xA; &lt;li&gt;If you are using a VPN, it must be set as system/global proxy.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Download / Install&lt;/h2&gt; &#xA;&lt;p&gt;Download from &lt;a href=&#34;https://github.com/sunner/ChatALL/releases&#34;&gt;https://github.com/sunner/ChatALL/releases&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;On Windows&lt;/h3&gt; &#xA;&lt;p&gt;Just download the *-win.exe file and proceed with the setup.&lt;/p&gt; &#xA;&lt;h3&gt;On macOS&lt;/h3&gt; &#xA;&lt;p&gt;For Apple Silicon Mac (M1, M2 CPU), download the *-mac-arm64.dmg file.&lt;/p&gt; &#xA;&lt;p&gt;For other Macs, download *-mac-x64.dmg file.&lt;/p&gt; &#xA;&lt;h3&gt;On Linux&lt;/h3&gt; &#xA;&lt;p&gt;Download the .AppImage file, make it executable, and enjoy the click-to-run experience.&lt;/p&gt; &#xA;&lt;h2&gt;For developers&lt;/h2&gt; &#xA;&lt;h3&gt;Contribute a Bot&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/sunner/ChatALL/wiki/%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84-AI-%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA&#34;&gt;The guide&lt;/a&gt; may help you.&lt;/p&gt; &#xA;&lt;h3&gt;Run&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install&#xA;npm run electron:serve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Build&lt;/h3&gt; &#xA;&lt;p&gt;Build for your current platform:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run electron:build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Build for all platforms:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run electron:build -- -wml --x64 --arm64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;h3&gt;Contributors&lt;/h3&gt; &#xA;&lt;a href=&#34;https://github.com/sunner/ChatALL/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=sunner/ChatALL&#34;&gt; &lt;/a&gt; &#xA;&lt;h3&gt;Others&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GPT-4 contributed much of the code&lt;/li&gt; &#xA; &lt;li&gt;ChatGPT, Bing Chat and Google provide many solutons (ranked in order)&lt;/li&gt; &#xA; &lt;li&gt;Inspired by &lt;a href=&#34;https://github.com/chathub-dev/chathub&#34;&gt;ChatHub&lt;/a&gt;. Respect!&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>haibbo/cf-openai-azure-proxy</title>
    <updated>2023-05-15T01:35:56Z</updated>
    <id>tag:github.com,2023-05-15:/haibbo/cf-openai-azure-proxy</id>
    <link href="https://github.com/haibbo/cf-openai-azure-proxy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Cloudflare worker script to proxy OpenAI‘s request to Azure OpenAI Service&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;cf-openai-azure-proxy&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/haibbo/cf-openai-azure-proxy/main/README_en.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/haibbo/cf-openai-azure-proxy/main/README.md&#34;&gt;中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;大多数 OpenAI 客户端不支持 Azure OpenAI Service，但Azure OpenAI Service的申请和绑卡都非常简单，并且还提供了免费的额度。此脚本使用免费的 Cloudflare Worker 作为代理，使得支持 OpenAI 的客户端可以直接使用 Azure OpenAI Service。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;项目说明:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;我没有服务器可以使用吗? &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;这段脚本跑在Cloudflare Worker, 不需要服务器, 不需要绑卡, 每天10W次请求 免费&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;我没有自己的域名可以使用吗? &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;也可以, 参考: &lt;a href=&#34;https://github.com/haibbo/cf-openai-azure-proxy/issues/3&#34;&gt;https://github.com/haibbo/cf-openai-azure-proxy/issues/3&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;实现打印机模式： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Azure OpenAI Service&#39;s 回复是一段一段回复的&lt;/li&gt; &#xA;   &lt;li&gt;返回给客户端的时候， 本项目拆出一条条的消息, 依次给， 达到打印机模式&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;项目也支持 Docker 部署（基于 wrangler）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;部署&lt;/h3&gt; &#xA;&lt;p&gt;代理 OpenAI 的请求到 Azure OpenAI Serivce，代码部署步骤：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;注册并登录到 Cloudflare 账户&lt;/li&gt; &#xA; &lt;li&gt;创建一个新的 Cloudflare Worker&lt;/li&gt; &#xA; &lt;li&gt;将 &lt;a href=&#34;https://raw.githubusercontent.com/haibbo/cf-openai-azure-proxy/main/cf-openai-azure-proxy.js&#34;&gt;cf-openai-azure-proxy.js&lt;/a&gt; 复制并粘贴到 Cloudflare Worker 编辑器中&lt;/li&gt; &#xA; &lt;li&gt;通过修改或环境变量调整 resourceName 和 deployment mapper 的值&lt;/li&gt; &#xA; &lt;li&gt;保存并部署 Cloudflare Worker&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/haibbo/cf-openai-azure-proxy/issues/3&#34;&gt;https://github.com/haibbo/cf-openai-azure-proxy/issues/3&lt;/a&gt; &lt;strong&gt;可选&lt;/strong&gt;绑定自定义域名: 在 Worker 详情页 -&amp;gt; Trigger -&amp;gt; Custom Domains 中为这个 Worker 添加一个自定义域名&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;使用说明&lt;/h3&gt; &#xA;&lt;p&gt;先得到 resourceName 和 deployment mapper, 登录到Azure的后台:&lt;/p&gt; &#xA;&lt;img width=&#34;777&#34; src=&#34;https://user-images.githubusercontent.com/1295315/233124125-1ea95665-ffab-4b5c-a7ba-26f31f1bb0b3.png&#34; alt=&#34;env&#34;&gt; &#xA;&lt;h4&gt;这里有两种做法:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;直接修改他们的值, 如:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// The name of your Azure OpenAI Resource.&#xA;const resourceName=&#34;codegpt&#34;&#xA;&#xA;// deployment model mapper&#xA;const mapper = {&#xA;     &#39;gpt-3.5-turbo&#39;: &#39;gpt3&#39;,&#xA;     &#39;gpt-4&#39;: &#39;gpt4&#39; &#xA;   };&#xA;其他的map规则直接按这样的格式续写即可&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;或者通过 cloudflare worker 控制台, 进入 Workers script &amp;gt; Settings &amp;gt; Add variable under Environment Variables.&lt;/p&gt; &lt;img width=&#34;777&#34; src=&#34;https://user-images.githubusercontent.com/1295315/233384224-aa6581f0-26a4-49cf-ae25-4dfb466143da.png&#34; alt=&#34;env&#34;&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;客户端&lt;/h3&gt; &#xA;&lt;p&gt;以 OpenCat 为例: 自定义 API 域名填写 第六步绑定的域名:&lt;/p&gt; &#xA;&lt;img width=&#34;339&#34; src=&#34;https://user-images.githubusercontent.com/1295315/229820705-ab2ad1d1-8795-4670-97b4-16a0f9fdebba.png&#34; alt=&#34;opencat&#34;&gt; &#xA;&lt;p&gt;我已经尝试了多种客户端, 如果遇到其他客户端有问题, 欢迎创建issue.&lt;/p&gt;</summary>
  </entry>
</feed>