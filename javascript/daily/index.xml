<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-01T01:34:14Z</updated>
  <subtitle>Daily Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>justimyhxu/GRM</title>
    <updated>2024-04-01T01:34:14Z</updated>
    <id>tag:github.com,2024-04-01:/justimyhxu/GRM</id>
    <link href="https://github.com/justimyhxu/GRM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation&lt;/strong&gt; &lt;br&gt; Yinghao Xu*, Zifan Shi*, Wang Yifan, Hansheng Chen, Ceyuan Yang, Sida Peng, Yujun Shen, Gordon Wetzstein&lt;br&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;[&lt;a href=&#34;https://arxiv.org/abs/2403.14621&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://justimyhxu.github.io/projects/grm&#34;&gt;Project Page&lt;/a&gt;] [&lt;a href=&#34;https://github.com/justimyhxu/GRM/assets/29980330/0cf713aa-ba87-4a15-a8ee-1b0da643cb3c&#34;&gt;Blender Demo&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/spaces/GRM-demo/GRM&#34;&gt;HF Demo&lt;/a&gt;][&lt;a href=&#34;https://huggingface.co/justimyhxu/GRM/tree/main&#34;&gt;Weights&lt;/a&gt;]&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/justimyhxu/GRM/assets/29980330/32f41f04-5ebe-4aa4-b1b7-bf4f78e5f197&#34;&gt;https://github.com/justimyhxu/GRM/assets/29980330/32f41f04-5ebe-4aa4-b1b7-bf4f78e5f197&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Todo List&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release gradio demo code.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release inference code.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release pretrained models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Release training code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;GRM Demo&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/GRM-demo/GRM&#34;&gt;Huggingface Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://replicate.com/camenduru/grm&#34;&gt;Replicate Demo&lt;/a&gt;. Thanks &lt;a href=&#34;https://github.com/camenduru&#34;&gt;@camenduru&lt;/a&gt; for the &lt;a href=&#34;https://github.com/camenduru/GRM-jupyter&#34;&gt;jupyter code&lt;/a&gt;!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;64-bit Python 3.10 and PyTorch 2.0.1 or higher.&lt;/li&gt; &#xA; &lt;li&gt;CUDA 11.8&lt;/li&gt; &#xA; &lt;li&gt;Users can use the following commands to install the packages&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n grm python=3.10&#xA;conda activate grm &#xA;pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118&#xA;cd third_party/diff-gaussian-rasterization &amp;amp;&amp;amp;  pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Pretrained weights&lt;/h2&gt; &#xA;&lt;p&gt;Pretrained weights can be downloaded from &lt;a href=&#34;https://huggingface.co/justimyhxu/GRM/tree/main&#34;&gt;Hugging Face&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Example&#xA;mkdir checkpoints &amp;amp;&amp;amp; cd checkpoints&#xA;wget https://huggingface.co/justimyhxu/GRM/blob/main/grm_u.pth &amp;amp;&amp;amp; cd ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that we provide three checkpoints for use. We use the OpenCV coordinate system.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Checkpoint&lt;/th&gt; &#xA;   &lt;th&gt;Training settings&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/justimyhxu/GRM/blob/main/grm_u.pth&#34;&gt;grm_u.pth&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The elevations are all 20 degrees and the azimuths uniformly cover all the 360-degree information.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/justimyhxu/GRM/blob/main/grm_r.pth&#34;&gt;grm_r.pth&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The azimuths roughly cover the 360-degree information.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/justimyhxu/GRM/blob/main/grm_zero123plus.pth&#34;&gt;grm_zero123plus.pth&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Three views are with 30-degree elevations and the azimuths are evenly distributed at intervals of 120 degrees. Another view has the elevation of -20 degrees and the azimuth is 60 degrees different from one of the three.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Besides, you need to download checkpoints for &lt;a href=&#34;https://huggingface.co/stabilityai/sv3d/tree/main&#34;&gt;SV3D&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd checkpoints&#xA;wget https://huggingface.co/stabilityai/sv3d/blob/main/sv3d_p.safetensors &amp;amp;&amp;amp; cd ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# text-to-3D&#xA;python test.py --prompt &#39;a car made out of cheese&#39;&#xA;# image-to-3D with zero123plus-v1.1&#xA;python test.py --image_path examples/dragon2.png --model zero123plus-v1.1&#xA;# image-to-3D with zero123plus-v1.2&#xA;python test.py --image_path examples/dragon2.png --model zero123plus-v1.2&#xA;# image-to-3D with SV3D&#xA;python test.py --image_path examples/dragon2.png --model sv3d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add &lt;code&gt;--fuse_mesh True&lt;/code&gt; if you would like to get the textured mesh. Add &lt;code&gt;--optimize_texture True&lt;/code&gt; if you would like to optimize texture on extracted textured mesh.&lt;/p&gt; &#xA;&lt;h2&gt;Gradio Demo&lt;/h2&gt; &#xA;&lt;p&gt;We provide an offline gradio demo, which can be run with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;h3&gt;Blender Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/justimyhxu/GRM/assets/29980330/0cf713aa-ba87-4a15-a8ee-1b0da643cb3c&#34;&gt;https://github.com/justimyhxu/GRM/assets/29980330/0cf713aa-ba87-4a15-a8ee-1b0da643cb3c&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Sparse-view Reconstruction&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/justimyhxu/GRM/assets/29980330/d436bca9-ddf9-4507-aed3-828fd6508ec3&#34;&gt;https://github.com/justimyhxu/GRM/assets/29980330/d436bca9-ddf9-4507-aed3-828fd6508ec3&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;We thank all of the following amazing codes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;gaussian-splatting&lt;/a&gt;, and &lt;a href=&#34;https://github.com/ashawkey/diff-gaussian-rasterization&#34;&gt;diff-gaussian-rasterization&lt;/a&gt; for depth rendering&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Kai-46/ARF-svox2&#34;&gt;ARF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/SUDO-AI-3D/zero123plus&#34;&gt;zero123++&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://instant-3d.github.io/&#34;&gt;Instant3D&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Stability-AI/generative-models&#34;&gt;SV3D&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/heheyas/V3D&#34;&gt;V3D&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/nvdiffrast&#34;&gt;nvdiffrast&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Lakonik/MVEdit&#34;&gt;MVEdit&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{xu2024grm,&#xA;     author    = {Xu, Yinghao and Shi, Zifan and Yifan, Wang and Peng, Sida and Yang, Ceyuan and Shen, Yujun and Wetzstein Gordon},&#xA;     title     = {GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation},&#xA;     journal   = {arxiv: 2403.14621},&#xA;     year      = {2024},&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>eduardoleao052/js-torch</title>
    <updated>2024-04-01T01:34:14Z</updated>
    <id>tag:github.com,2024-04-01:/eduardoleao052/js-torch</id>
    <link href="https://github.com/eduardoleao052/js-torch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A JavaScript library like PyTorch, built from scratch.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/eduardoleao052/js-torch/main/assets/logo.png&#34; alt=&#34;js-torch&#34; height=&#34;135&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/eduardoleao052/js-torch/actions/workflows/test.yml/badge.svg&#34; alt=&#34;Unit Tests&#34;&gt; &lt;img src=&#34;https://github.com/eduardoleao052/js-torch/actions/workflows/test.yml/badge.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/eduardoleao052/js-torch/pulse&#34; alt=&#34;Activity&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/commit-activity/m/eduardoleao052/js-torch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/eduardoleao052/js-torch/graphs/contributors&#34; alt=&#34;Contributors&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/contributors/eduardoleao052/js-torch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/eduardoleao052/js-torch&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/language-JavaScript-yellow&#34;&gt; &lt;/a&gt; &lt;a href=&#34;mailto:eduardoleao052@usp.br&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/-Email-red?style=flat-square&amp;amp;logo=gmail&amp;amp;logoColor=white&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/in/eduardoleao052/&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/-Linkedin-blue?style=flat-square&amp;amp;logo=linkedin&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1&gt;PyTorch in JavaScript&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;JS-Torch is a Deep Learning &lt;strong&gt;JavaScript library&lt;/strong&gt; built from scratch, to closely follow PyTorch&#39;s syntax.&lt;/li&gt; &#xA; &lt;li&gt;It contains a fully functional &lt;a href=&#34;https://raw.githubusercontent.com/eduardoleao052/js-torch/main/src/tensor.js&#34;&gt;Tensor&lt;/a&gt; object, which can track gradients, Deep Learning &lt;a href=&#34;https://raw.githubusercontent.com/eduardoleao052/js-torch/main/src/layers.js&#34;&gt;Layers&lt;/a&gt; and functions, and an &lt;strong&gt;Automatic Differentiation&lt;/strong&gt; engine.&lt;/li&gt; &#xA; &lt;li&gt;Feel free to try out a &lt;a href=&#34;https://eduardoleao052.github.io/js-torch/assets/demo/demo.html&#34; target=&#34;blank&#34;&gt;Web Demo&lt;/a&gt;!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; Implemented Tensor &lt;b&gt;Operations&lt;/b&gt;: &lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L346-L401&#34;&gt;Add&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L404-L438&#34;&gt;Subtract&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L441-L496&#34;&gt;Multiply&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L498-L557&#34;&gt;Divide&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L560-L621&#34;&gt;Matrix Multiply&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L625-L663&#34;&gt;Power&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L666-L704&#34;&gt;Square Root&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#706-L744&#34;&gt;Exponentiate&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L746-L785&#34;&gt;Log&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L790-L842&#34;&gt;Sum&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L844-L894&#34;&gt;Mean&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L896-L949&#34;&gt;Variance&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L953-L1008&#34;&gt;Transpose&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L1010-L1060&#34;&gt;At&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L1062-L1095&#34;&gt;MaskedFill&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/07c1286867b952f32c0e904033214253e8812090/src/tensor.js#L1097-L1129&#34;&gt;Reshape&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; Implemented Deep Learning &lt;b&gt;Layers&lt;/b&gt;: &lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L60-L88&#34;&gt;nn.Linear&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L90-L163&#34;&gt;nn.MultiHeadSelfAttention&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L165-L194&#34;&gt;nn.FullyConnected&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L196-L226&#34;&gt;nn.Block&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L231-L260&#34;&gt;nn.Embedding&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L262-L291&#34;&gt;nn.PositionalEmbedding&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L296-L325&#34;&gt;nn.ReLU&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L327-L346&#34;&gt;nn.Softmax&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L351-L376&#34;&gt;nn.Dropout&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L378-L397&#34;&gt;nn.LayerNorm&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/eduardoleao052/js-torch/raw/a158c91db9775a88fae6ed2d0f76d6d8ee6f9d23/src/layers.js#L400-L441&#34;&gt;nn.CrossEntropyLoss&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;1. Project Structure&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;assets/&lt;/code&gt; : Folder to store images and the Demo. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;assets/demo/&lt;/code&gt; : JS-Torch&#39;s &lt;a href=&#34;https://eduardoleao052.github.io/js-torch/assets/demo/demo.html&#34;&gt;Web Demo&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;src/&lt;/code&gt; : Framework with JavaScript files. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;src/tensor.js&lt;/code&gt;: File with the &lt;code&gt;Tensor&lt;/code&gt; class and all of the tensor &lt;code&gt;Operations&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;src/utils.js&lt;/code&gt;: File with operations and helper functions.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;src/layers.js&lt;/code&gt;: Submodule of the framework. Contains full layers.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;src/optim.js&lt;/code&gt;: Submodule of the framework. Contains Adam Optimizer.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;tests/&lt;/code&gt;: Folder with unit tests. Contains &lt;code&gt;test.js&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;2. Running it Yourself&lt;/h2&gt; &#xA;&lt;h3&gt;Simple Autograd Example:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const torch = require(&#34;js-pytorch&#34;);&#xA;&#xA;// Instantiate Tensors:&#xA;let x = torch.randn([8,4,5]);&#xA;let w = torch.randn([8,5,4], requires_grad = true);&#xA;let b = torch.tensor([0.2, 0.5, 0.1, 0.0], requires_grad = true);&#xA;&#xA;// Make calculations:&#xA;let out = torch.matmul(x, w);&#xA;out = torch.add(out, b);&#xA;&#xA;// Compute gradients on whole graph:&#xA;out.backward();&#xA;&#xA;// Get gradients from specific Tensors:&#xA;console.log(w.grad);&#xA;console.log(b.grad);&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Complex Autograd Example (Transformer):&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const torch = require(&#34;js-pytorch&#34;);&#xA;const nn = torch.nn;&#xA;&#xA;class Transformer extends nn.Module {&#xA;    constructor(vocab_size, hidden_size, n_timesteps, n_heads, p) {&#xA;        super();&#xA;        // Instantiate Transformer&#39;s Layers:&#xA;        this.embed = new nn.Embedding(vocab_size, hidden_size);&#xA;        this.pos_embed = new nn.PositionalEmbedding(n_timesteps, hidden_size);&#xA;        this.b1 = new nn.Block(hidden_size, hidden_size, n_heads, n_timesteps, dropout_p=p);&#xA;        this.b2 = new nn.Block(hidden_size, hidden_size, n_heads, n_timesteps, dropout_p=p);&#xA;        this.ln = new nn.LayerNorm(hidden_size);&#xA;        this.linear = new nn.Linear(hidden_size, vocab_size);&#xA;    };&#xA;&#xA;    forward(x) {&#xA;        let z;&#xA;        z = torch.add(this.embed.forward(x), this.pos_embed.forward(x));&#xA;        z = this.b1.forward(z);&#xA;        z = this.b2.forward(z);&#xA;        z = this.ln.forward(z);&#xA;        z = this.linear.forward(z);&#xA;        return z;&#xA;    };&#xA;};&#xA;&#xA;// Instantiate your custom nn.Module:&#xA;const model = new Transformer(vocab_size, hidden_size, n_timesteps, n_heads, dropout_p);&#xA;&#xA;// Define loss function and optimizer:&#xA;const loss_func = new nn.CrossEntropyLoss();&#xA;const optimizer = new optim.Adam(model.parameters(), lr=5e-3, reg=0);&#xA;&#xA;// Instantiate sample input and output:&#xA;let x = torch.randint(0,vocab_size,[batch_size,n_timesteps,1]);&#xA;let y = torch.randint(0,vocab_size,[batch_size,n_timesteps]);&#xA;let loss;&#xA;&#xA;// Training Loop:&#xA;for(let i=0 ; i &amp;lt; 40 ; i++) {&#xA;    // Forward pass through the Transformer:&#xA;    let z = model.forward(x);&#xA;&#xA;    // Get loss:&#xA;    loss = loss_func.forward(z, y);&#xA;&#xA;    // Backpropagate the loss using torch.tensor&#39;s backward() method:&#xA;    loss.backward();&#xA;&#xA;    // Update the weights:&#xA;    optimizer.step();&#xA;    &#xA;    // Reset the gradients to zero after each training step:&#xA;    optimizer.zero_grad();&#xA;    &#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can install the package locally with: &lt;code&gt;npm install js-pytorch&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;3. Results&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The models implemented in the &lt;a href=&#34;https://raw.githubusercontent.com/eduardoleao052/js-torch/main/tests/test.js&#34;&gt;unit tests&lt;/a&gt; all converged to &lt;strong&gt;near-zero losses&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;This package is not as optimized as PyTorch yet, but I tried making it more interpretable. Efficiency improvements are incoming!&lt;/li&gt; &#xA; &lt;li&gt;Hope you enjoy!&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>anticensority/runet-censorship-bypass</title>
    <updated>2024-04-01T01:34:14Z</updated>
    <id>tag:github.com,2024-04-01:/anticensority/runet-censorship-bypass</id>
    <link href="https://github.com/anticensority/runet-censorship-bypass" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Chromium extension for bypassing censorship in Russia&lt;/p&gt;&lt;hr&gt;&lt;p&gt;If you &lt;strong&gt;unstar&lt;/strong&gt;, please, &lt;a href=&#34;https://github.com/anticensority/runet-censorship-bypass/issues&#34;&gt;leave us a note&lt;/a&gt; why you do so.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/anticensority/runet-censorship-bypass/wiki/%D0%9F%D0%BE%D0%B4%D0%B4%D0%B5%D1%80%D0%B6%D0%B0%D1%82%D1%8C&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%D0%9F%D0%BE%D0%B4%D0%B4%D0%B5%D1%80%D0%B6%D0%B0%D1%82%D1%8C-%E2%9D%A4-green.svg?sanitize=true&#34; alt=&#34;–ü–æ–¥–¥–µ—Ä–∂–∞—Ç—å&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/anticensority/runet-censorship-bypass/development/#backers&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/backers/badge.svg?sanitize=true&#34; alt=&#34;Backers on Open Collective&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/anticensority/runet-censorship-bypass/development/#sponsors&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsors/badge.svg?sanitize=true&#34; alt=&#34;Sponsors on Open Collective&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Russian Anticensorship on PAC-Scripts&lt;/h1&gt; &#xA;&lt;p&gt;This repo contains an extension for Chromium and FireFox that helps to bypass censorship in Russia: &lt;a href=&#34;https://chrome.google.com/webstore/detail/npgcnondjocldhldegnakemclmfkngch&#34;&gt;WebStore&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/anticensority/runet-censorship-bypass/development/extensions/chromium/runet-censorship-bypass&#34;&gt;Sources&lt;/a&gt;.&lt;br&gt; This extension uses pac scripts, one of which (anticensority) is generated by this &lt;a href=&#34;https://github.com/anticensority/pac-script-generator&#34;&gt;pac-generator&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Install / –£—Å—Ç–∞–Ω–æ–≤–∫–∞&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://chrome.google.com/webstore/detail/%D0%BE%D0%B1%D1%85%D0%BE%D0%B4-%D0%B1%D0%BB%D0%BE%D0%BA%D0%B8%D1%80%D0%BE%D0%B2%D0%BE%D0%BA-%D1%80%D1%83%D0%BD%D0%B5%D1%82%D0%B0/npgcnondjocldhldegnakemclmfkngch&#34;&gt;Chrome Web Store&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://chrome.google.com/webstore/detail/%D0%BE%D0%B1%D1%85%D0%BE%D0%B4-%D0%B1%D0%BB%D0%BE%D0%BA%D0%B8%D1%80%D0%BE%D0%B2%D0%BE%D0%BA-%D1%80%D1%83%D0%BD%D0%B5%D1%82%D0%B0-%D0%BC/gnknjnebjldmkpmlhjipalimhjofpgho&#34;&gt;Chrome Web Store (MINI)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoftedge.microsoft.com/addons/detail/%D0%BE%D0%B1%D1%85%D0%BE%D0%B4-%D0%B1%D0%BB%D0%BE%D0%BA%D0%B8%D1%80%D0%BE%D0%B2%D0%BE%D0%BA-%D1%80%D1%83%D0%BD%D0%B5%D1%82%D0%B0/ajgpnodjpffiagcfmifildjpoaeiobfh&#34;&gt;Microsoft Edge Add-ons&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoftedge.microsoft.com/addons/detail/%D0%BE%D0%B1%D1%85%D0%BE%D0%B4-%D0%B1%D0%BB%D0%BE%D0%BA%D0%B8%D1%80%D0%BE%D0%B2%D0%BE%D0%BA-%D1%80%D1%83%D0%BD%D0%B5%D1%82%D0%B0-%D0%BC/cjppllmpmkpjfchbaoebeneghcbmlibj&#34;&gt;Microsoft Edge Add-ons (MINI)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://addons.mozilla.org/ru/firefox/addon/%D0%BE%D0%B1%D1%85%D0%BE%D0%B4-%D0%B1%D0%BB%D0%BE%D0%BA%D0%B8%D1%80%D0%BE%D0%B2%D0%BE%D0%BA-%D1%80%D1%83%D0%BD%D0%B5%D1%82%D0%B0/&#34;&gt;FireFox Add-ons (Beta)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Opera: —Å–Ω–∞—á–∞–ª–∞ &lt;a href=&#34;https://addons.opera.com/ru/extensions/details/install-chrome-extensions/&#34;&gt;—É—Å—Ç–∞–Ω–æ–≤—â–∏–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π –∏–∑ WebStore&lt;/a&gt; (–æ—Ç –∫–æ–º–∞–Ω–¥—ã Opera), –∑–∞—Ç–µ–º —Å–º. –ø—É–Ω–∫—Ç—ã 1 –∏ 2 –≤—ã—à–µ.&lt;/li&gt; &#xA; &lt;li&gt;–ü–∞–∫–µ—Ç—ã –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π (offline) —É—Å—Ç–∞–Ω–æ–≤–∫–∏: &lt;a href=&#34;https://github.com/anticensority/runet-censorship-bypass/releases&#34;&gt;https://github.com/anticensority/runet-censorship-bypass/releases&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;–ò–∑-–∑–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ –∞–¥—Ä–µ—Å–æ–≤ Google —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –º–æ–∂–µ—Ç –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –∏–∑ WebStore. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –∏ —Å–ø–æ—Å–æ–±—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–º. &lt;a href=&#34;https://github.com/anticensority/runet-censorship-bypass/wiki/%D0%90%D0%B2%D1%82%D0%BE%D0%BD%D0%BE%D0%BC%D0%BD%D0%B0%D1%8F-%D1%83%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BA%D0%B0-%D1%80%D0%B0%D1%81%D1%88%D0%B8%D1%80%D0%B5%D0%BD%D0%B8%D1%8F&#34;&gt;https://github.com/anticensority/runet-censorship-bypass/wiki/–ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è-—É—Å—Ç–∞–Ω–æ–≤–∫–∞-—Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Why I do This&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/anticensority/runet-censorship-bypass/wiki/%D0%9F%D0%BE%D1%87%D0%B5%D0%BC%D1%83-%D0%BC%D1%8B-%D1%8D%D1%82%D0%BE-%D0%B4%D0%B5%D0%BB%D0%B0%D0%B5%D0%BC%3F-%D0%90%D1%80%D0%B3%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B-%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2-%D1%86%D0%B5%D0%BD%D0%B7%D1%83%D1%80%D1%8B&#34;&gt;my arguments against censorship (ru)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Looking at how Russian government &lt;a href=&#34;https://therussianreader.wordpress.com/2015/11/22/russian-truckers-strike-dagestan/&#34;&gt;distorts TV&lt;/a&gt; and blocks &lt;a href=&#34;https://www.reuters.com/article/us-russia-internet-idUSBREA2C21L20140313&#34;&gt;critics of Putin&lt;/a&gt;, I decided to write an anticensorship extension for Chromium before they strike me first.&lt;/p&gt; &#xA;&lt;h2&gt;How it Works&lt;/h2&gt; &#xA;&lt;ol start=&#34;0&#34;&gt; &#xA; &lt;li&gt;PAC script is a JavaScript file, triggered on every URL request, which says browser which proxy to use if any for this particular URL.&lt;/li&gt; &#xA; &lt;li&gt;The Chrome Extension sets PAC script in browser settings and keeps it synced with PAC script on the server (offering Antizapret (hosted on a dedicated server) or Anticensority (hosted on GitHub)).&lt;/li&gt; &#xA; &lt;li&gt;On every request PAC script checks if host is blocked or if its IP is blocked.&lt;/li&gt; &#xA; &lt;li&gt;If address is blocked PAC script returns proxy server to the browser. Antizapret PAC-script uses its own proxy servers and Anticensority PAC-script uses local Tor.&lt;/li&gt; &#xA; &lt;li&gt;PAC scripts on servers are updated periodically from &lt;a href=&#34;https://github.com/zapret-info/z-i&#34;&gt;https://github.com/zapret-info/z-i&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;This project exists thanks to all the people who contribute. &lt;a href=&#34;https://github.com/anticensority/runet-censorship-bypass/graphs/contributors&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/contributors.svg?width=890&amp;amp;button=false?force&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Backers&lt;/h2&gt; &#xA;&lt;p&gt;Thank you to all our backers! üôè [&lt;a href=&#34;https://opencollective.com/anticensority#backer&#34;&gt;Become a backer&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opencollective.com/anticensority#backers&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/backers.svg?width=890&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;p&gt;Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [&lt;a href=&#34;https://opencollective.com/anticensority#sponsor&#34;&gt;Become a sponsor&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opencollective.com/anticensority/sponsor/0/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/0/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/anticensority/sponsor/1/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/1/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/anticensority/sponsor/2/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/2/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/anticensority/sponsor/3/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/3/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/anticensority/sponsor/4/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/4/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/anticensority/sponsor/5/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/5/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/anticensority/sponsor/6/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/6/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/anticensority/sponsor/7/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/7/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/anticensority/sponsor/8/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/8/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/anticensority/sponsor/9/website&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://opencollective.com/anticensority/sponsor/9/avatar.svg?sanitize=true&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>