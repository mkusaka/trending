<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-02T01:30:07Z</updated>
  <subtitle>Daily Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>langchain-ai/langserve</title>
    <updated>2023-11-02T01:30:07Z</updated>
    <id>tag:github.com,2023-11-02:/langchain-ai/langserve</id>
    <link href="https://github.com/langchain-ai/langserve" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LangServe ü¶úÔ∏èüèì&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LangServe ü¶úÔ∏èüèì&lt;/h1&gt; &#xA;&lt;p&gt;üö© We will be releasing a hosted version of LangServe for one-click deployments of LangChain applications. &lt;a href=&#34;https://airtable.com/app0hN6sd93QcKubv/shrAjst60xXa6quV2&#34;&gt;Sign up here&lt;/a&gt; to get on the waitlist.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;LangServe&lt;/code&gt; helps developers deploy &lt;code&gt;LangChain&lt;/code&gt; &lt;a href=&#34;https://python.langchain.com/docs/expression_language/&#34;&gt;runnables and chains&lt;/a&gt; as a REST API.&lt;/p&gt; &#xA;&lt;p&gt;This library is integrated with &lt;a href=&#34;https://fastapi.tiangolo.com/&#34;&gt;FastAPI&lt;/a&gt; and uses &lt;a href=&#34;https://docs.pydantic.dev/latest/&#34;&gt;pydantic&lt;/a&gt; for data validation.&lt;/p&gt; &#xA;&lt;p&gt;In addition, it provides a client that can be used to call into runnables deployed on a server. A javascript client is available in &lt;a href=&#34;https://js.langchain.com/docs/api/runnables_remote/classes/RemoteRunnable&#34;&gt;LangChainJS&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Input and Output schemas automatically inferred from your LangChain object, and enforced on every API call, with rich error messages&lt;/li&gt; &#xA; &lt;li&gt;API docs page with JSONSchema and Swagger (insert example link)&lt;/li&gt; &#xA; &lt;li&gt;Efficient &lt;code&gt;/invoke&lt;/code&gt;, &lt;code&gt;/batch&lt;/code&gt; and &lt;code&gt;/stream&lt;/code&gt; endpoints with support for many concurrent requests on a single server&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/stream_log&lt;/code&gt; endpoint for streaming all (or some) intermediate steps from your chain/agent&lt;/li&gt; &#xA; &lt;li&gt;Playground page at &lt;code&gt;/playground&lt;/code&gt; with streaming output and intermediate steps&lt;/li&gt; &#xA; &lt;li&gt;Built-in (optional) tracing to &lt;a href=&#34;https://www.langchain.com/langsmith&#34;&gt;LangSmith&lt;/a&gt;, just add your API key (see &lt;a href=&#34;https://docs.smith.langchain.com/&#34;&gt;Instructions&lt;/a&gt;])&lt;/li&gt; &#xA; &lt;li&gt;All built with battle-tested open-source Python libraries like FastAPI, Pydantic, uvloop and asyncio.&lt;/li&gt; &#xA; &lt;li&gt;Use the client SDK to call a LangServe server as if it was a Runnable running locally (or call the HTTP API directly)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/langchain-ai/langchain/raw/master/templates/README.md&#34;&gt;LangServe Hub&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Limitations&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Client callbacks are not yet supported for events that originate on the server&lt;/li&gt; &#xA; &lt;li&gt;Does not work with &lt;a href=&#34;https://github.com/tiangolo/fastapi/issues/10360&#34;&gt;pydantic v2 yet&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Hosted LangServe&lt;/h2&gt; &#xA;&lt;p&gt;We will be releasing a hosted version of LangServe for one-click deployments of LangChain applications. &lt;a href=&#34;https://airtable.com/app0hN6sd93QcKubv/shrAjst60xXa6quV2&#34;&gt;Sign up here&lt;/a&gt; to get on the waitlist.&lt;/p&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Vulnerability in Versions 0.0.13 - 0.0.15 -- playground endpoint allows accessing arbitrary files on server. &lt;a href=&#34;https://github.com/langchain-ai/langserve/pull/98&#34;&gt;Resolved in 0.0.16&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LangChain CLI üõ†Ô∏è&lt;/h2&gt; &#xA;&lt;p&gt;Use the &lt;code&gt;LangChain&lt;/code&gt; CLI to bootstrap a &lt;code&gt;LangServe&lt;/code&gt; project quickly.&lt;/p&gt; &#xA;&lt;p&gt;To use the langchain CLI make sure that you have a recent version of &lt;code&gt;langchain-cli&lt;/code&gt; installed. You can install it with &lt;code&gt;pip install -U &#34;langchain-cli[serve]&#34;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;langchain app new ../path/to/directory&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;Get your LangServe instance started quickly with &lt;a href=&#34;https://github.com/langchain-ai/langchain/raw/master/templates/README.md&#34;&gt;LangChain Templates&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For more examples, see the templates &lt;a href=&#34;https://github.com/langchain-ai/langchain/raw/master/templates/docs/INDEX.md&#34;&gt;index&lt;/a&gt; or the &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/langserve/main/examples&#34;&gt;examples&lt;/a&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;Server&lt;/h3&gt; &#xA;&lt;p&gt;Here&#39;s a server that deploys an OpenAI chat model, an Anthropic chat model, and a chain that uses the Anthropic model to tell a joke about a topic.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python&#xA;from fastapi import FastAPI&#xA;from langchain.prompts import ChatPromptTemplate&#xA;from langchain.chat_models import ChatAnthropic, ChatOpenAI&#xA;from langserve import add_routes&#xA;&#xA;&#xA;app = FastAPI(&#xA;  title=&#34;LangChain Server&#34;,&#xA;  version=&#34;1.0&#34;,&#xA;  description=&#34;A simple api server using Langchain&#39;s Runnable interfaces&#34;,&#xA;)&#xA;&#xA;add_routes(&#xA;    app,&#xA;    ChatOpenAI(),&#xA;    path=&#34;/openai&#34;,&#xA;)&#xA;&#xA;add_routes(&#xA;    app,&#xA;    ChatAnthropic(),&#xA;    path=&#34;/anthropic&#34;,&#xA;)&#xA;&#xA;model = ChatAnthropic()&#xA;prompt = ChatPromptTemplate.from_template(&#34;tell me a joke about {topic}&#34;)&#xA;add_routes(&#xA;    app,&#xA;    prompt | model,&#xA;    path=&#34;/chain&#34;,&#xA;)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    import uvicorn&#xA;&#xA;    uvicorn.run(app, host=&#34;localhost&#34;, port=8000)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docs&lt;/h3&gt; &#xA;&lt;p&gt;If you&#39;ve deployed the server above, you can view the generated OpenAPI docs using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl localhost:8000/docs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;make sure to &lt;strong&gt;add&lt;/strong&gt; the &lt;code&gt;/docs&lt;/code&gt; suffix.&lt;/p&gt; &#xA;&lt;p&gt;Below will return a 404 until you define a &lt;code&gt;@app.get(&#34;/&#34;)&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;localhost:8000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Client&lt;/h3&gt; &#xA;&lt;p&gt;Python SDK&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;from langchain.schema import SystemMessage, HumanMessage&#xA;from langchain.prompts import ChatPromptTemplate&#xA;from langchain.schema.runnable import RunnableMap&#xA;from langserve import RemoteRunnable&#xA;&#xA;openai = RemoteRunnable(&#34;http://localhost:8000/openai/&#34;)&#xA;anthropic = RemoteRunnable(&#34;http://localhost:8000/anthropic/&#34;)&#xA;joke_chain = RemoteRunnable(&#34;http://localhost:8000/chain/&#34;)&#xA;&#xA;joke_chain.invoke({&#34;topic&#34;: &#34;parrots&#34;})&#xA;&#xA;# or async&#xA;await joke_chain.ainvoke({&#34;topic&#34;: &#34;parrots&#34;})&#xA;&#xA;prompt = [&#xA;    SystemMessage(content=&#39;Act like either a cat or a parrot.&#39;),&#xA;    HumanMessage(content=&#39;Hello!&#39;)&#xA;]&#xA;&#xA;# Supports astream&#xA;async for msg in anthropic.astream(prompt):&#xA;    print(msg, end=&#34;&#34;, flush=True)&#xA;&#xA;prompt = ChatPromptTemplate.from_messages(&#xA;    [(&#34;system&#34;, &#34;Tell me a long story about {topic}&#34;)]&#xA;)&#xA;&#xA;# Can define custom chains&#xA;chain = prompt | RunnableMap({&#xA;    &#34;openai&#34;: openai,&#xA;    &#34;anthropic&#34;: anthropic,&#xA;})&#xA;&#xA;chain.batch([{ &#34;topic&#34;: &#34;parrots&#34; }, { &#34;topic&#34;: &#34;cats&#34; }])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In TypeScript (requires LangChain.js version 0.0.166 or later):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { RemoteRunnable } from &#34;langchain/runnables/remote&#34;;&#xA;&#xA;const chain = new RemoteRunnable({&#xA;  url: `http://localhost:8000/chain/invoke/`,&#xA;});&#xA;const result = await chain.invoke({&#xA;  topic: &#34;cats&#34;,&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Python using &lt;code&gt;requests&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import requests&#xA;response = requests.post(&#xA;    &#34;http://localhost:8000/chain/invoke/&#34;,&#xA;    json={&#39;input&#39;: {&#39;topic&#39;: &#39;cats&#39;}}&#xA;)&#xA;response.json()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use &lt;code&gt;curl&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl --location --request POST &#39;http://localhost:8000/chain/invoke/&#39; \&#xA;    --header &#39;Content-Type: application/json&#39; \&#xA;    --data-raw &#39;{&#xA;        &#34;input&#34;: {&#xA;            &#34;topic&#34;: &#34;cats&#34;&#xA;        }&#xA;    }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Endpoints&lt;/h2&gt; &#xA;&lt;p&gt;The following code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;...&#xA;add_routes(&#xA;  app,&#xA;  runnable,&#xA;  path=&#34;/my_runnable&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;adds of these endpoints to the server:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;POST /my_runnable/invoke&lt;/code&gt; - invoke the runnable on a single input&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;POST /my_runnable/batch&lt;/code&gt; - invoke the runnable on a batch of inputs&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;POST /my_runnable/stream&lt;/code&gt; - invoke on a single input and stream the output&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;POST /my_runnable/stream_log&lt;/code&gt; - invoke on a single input and stream the output, including output of intermediate steps as it&#39;s generated&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;GET /my_runnable/input_schema&lt;/code&gt; - json schema for input to the runnable&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;GET /my_runnable/output_schema&lt;/code&gt; - json schema for output of the runnable&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;GET /my_runnable/config_schema&lt;/code&gt; - json schema for config of the runnable&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Playground&lt;/h2&gt; &#xA;&lt;p&gt;You can find a playground page for your runnable at &lt;code&gt;/my_runnable/playground&lt;/code&gt;. This exposes a simple UI to &lt;a href=&#34;https://python.langchain.com/docs/expression_language/how_to/configure&#34;&gt;configure&lt;/a&gt; and invoke your runnable with streaming output and intermediate steps.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/langchain-ai/langserve/assets/3205522/5ca56e29-f1bb-40f4-84b5-15916384a276&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;For both client and server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install &#34;langserve[all]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or &lt;code&gt;pip install &#34;langserve[client]&#34;&lt;/code&gt; for client code, and &lt;code&gt;pip install &#34;langserve[server]&#34;&lt;/code&gt; for server code.&lt;/p&gt; &#xA;&lt;h2&gt;Legacy Chains&lt;/h2&gt; &#xA;&lt;p&gt;LangServe works with both Runnables (constructed via &lt;a href=&#34;https://python.langchain.com/docs/expression_language/&#34;&gt;LangChain Expression Language&lt;/a&gt;) and legacy chains (inheriting from &lt;code&gt;Chain&lt;/code&gt;). However, some of the input schemas for legacy chains may be incomplete/incorrect, leading to errors. This can be fixed by updating the &lt;code&gt;input_schema&lt;/code&gt; property of those chains in LangChain. If you encounter any errors, please open an issue on THIS repo, and we will work to address it.&lt;/p&gt; &#xA;&lt;h2&gt;Handling Authentication&lt;/h2&gt; &#xA;&lt;p&gt;If you need to add authentication to your server, please reference FastAPI&#39;s &lt;a href=&#34;https://fastapi.tiangolo.com/tutorial/security/&#34;&gt;security documentation&lt;/a&gt; and &lt;a href=&#34;https://fastapi.tiangolo.com/tutorial/middleware/&#34;&gt;middleware documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;h3&gt;Deploy to GCP&lt;/h3&gt; &#xA;&lt;p&gt;You can deploy to GCP Cloud Run using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gcloud run deploy [your-service-name] --source . --port 8001 --allow-unauthenticated --region us-central1 --set-env-vars=OPENAI_API_KEY=your_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Advanced&lt;/h2&gt; &#xA;&lt;h3&gt;Files&lt;/h3&gt; &#xA;&lt;p&gt;LLM applications often deal with files. There are different architectures that can be made to implement file processing; at a high level:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The file may be uploaded to the server via a dedicated endpoint and processed using a separate endpoint&lt;/li&gt; &#xA; &lt;li&gt;The file may be uploaded by either value (bytes of file) or reference (e.g., s3 url to file content)&lt;/li&gt; &#xA; &lt;li&gt;The processing endpoint may be blocking or non-blocking&lt;/li&gt; &#xA; &lt;li&gt;If significant processing is required, the processing may be offloaded to a dedicated process pool&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You should determine what is the appropriate architecture for your application.&lt;/p&gt; &#xA;&lt;p&gt;Currently, to upload files by value to a runnable, use base64 encoding for the file (&lt;code&gt;multipart/form-data&lt;/code&gt; is not supported yet).&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s an &lt;a href=&#34;https://github.com/langchain-ai/langserve/tree/main/examples/file_processing&#34;&gt;example&lt;/a&gt; that shows how to use base64 encoding to send a file to a remote runnable.&lt;/p&gt; &#xA;&lt;p&gt;Remember, you can always upload files by reference (e.g., s3 url) or upload them as multipart/form-data to a dedicated endpoint.&lt;/p&gt; &#xA;&lt;h3&gt;Custom Input and Output Types&lt;/h3&gt; &#xA;&lt;p&gt;Input and Output types are defined on all runnables.&lt;/p&gt; &#xA;&lt;p&gt;You can access them via the &lt;code&gt;input_schema&lt;/code&gt; and &lt;code&gt;output_schema&lt;/code&gt; properties.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;LangServe&lt;/code&gt; uses these types for validation and documentation.&lt;/p&gt; &#xA;&lt;p&gt;If you want to override the default inferred types, you can use the &lt;code&gt;with_types&lt;/code&gt; method.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s a toy example to illustrate the idea:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from typing import Any&#xA;&#xA;from fastapi import FastAPI&#xA;from langchain.schema.runnable import RunnableLambda&#xA;&#xA;app = FastAPI()&#xA;&#xA;&#xA;def func(x: Any) -&amp;gt; int:&#xA;    &#34;&#34;&#34;Mistyped function that should accept an int but accepts anything.&#34;&#34;&#34;&#xA;    return x + 1&#xA;&#xA;&#xA;runnable = RunnableLambda(func).with_types(&#xA;    input_schema=int,&#xA;)&#xA;&#xA;add_routes(app, runnable)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Custom User Types&lt;/h3&gt; &#xA;&lt;p&gt;Inherit from &lt;code&gt;CustomUserType&lt;/code&gt; if you want the data to de-serialize into a pydantic model rather than the equivalent dict representation.&lt;/p&gt; &#xA;&lt;p&gt;At the moment, this type only works &lt;em&gt;server&lt;/em&gt; side and is used to specify desired &lt;em&gt;decoding&lt;/em&gt; behavior. If inheriting from this type the server will keep the decoded type as a pydantic model instead of converting it into a dict.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fastapi import FastAPI&#xA;from langchain.schema.runnable import RunnableLambda&#xA;&#xA;from langserve import add_routes&#xA;from langserve.schema import CustomUserType&#xA;&#xA;app = FastAPI()&#xA;&#xA;&#xA;class Foo(CustomUserType):&#xA;    bar: int&#xA;&#xA;&#xA;def func(foo: Foo) -&amp;gt; int:&#xA;    &#34;&#34;&#34;Sample function that expects a Foo type which is a pydantic model&#34;&#34;&#34;&#xA;    assert isinstance(foo, Foo)&#xA;    return foo.bar&#xA;&#xA;# Note that the input and output type are automatically inferred!&#xA;# You do not need to specify them.&#xA;# runnable = RunnableLambda(func).with_types( # &amp;lt;-- Not needed in this case&#xA;#     input_schema=Foo,&#xA;#     output_schema=int,&#xA;# &#xA;add_routes(app, RunnableLambda(func), path=&#34;/foo&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Playground Widgets&lt;/h3&gt; &#xA;&lt;p&gt;The playground allows you to define custom widgets for your runnable from the backend.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A widget is specified at the field level and shipped as part of the JSON schema of the input type&lt;/li&gt; &#xA; &lt;li&gt;A widget must contain a key called &lt;code&gt;type&lt;/code&gt; with the value being one of a well known list of widgets&lt;/li&gt; &#xA; &lt;li&gt;Other widget keys will be associated with values that describe paths in a JSON object&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;General schema:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;type JsonPath = number | string | (number | string)[];&#xA;type NameSpacedPath = { title: string; path: JsonPath }; // Using title to mimick json schema, but can use namespace&#xA;type OneOfPath = { oneOf: JsonPath[] };&#xA;&#xA;type Widget = {&#xA;    type: string // Some well known type (e.g., base64file, chat etc.)&#xA;    [key: string]: JsonPath | NameSpacedPath | OneOfPath;&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;File Upload Widget&lt;/h4&gt; &#xA;&lt;p&gt;Allows creation of a file upload input in the UI playground for files that are uploaded as base64 encoded strings. Here&#39;s the full &lt;a href=&#34;https://github.com/langchain-ai/langserve/tree/main/examples/file_processing&#34;&gt;example&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Snippet:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pydantic import Field&#xA;&#xA;from langserve import CustomUserType&#xA;&#xA;&#xA;# ATTENTION: Inherit from CustomUserType instead of BaseModel otherwise&#xA;#            the server will decode it into a dict instead of a pydantic model.&#xA;class FileProcessingRequest(CustomUserType):&#xA;    &#34;&#34;&#34;Request including a base64 encoded file.&#34;&#34;&#34;&#xA;&#xA;    # The extra field is used to specify a widget for the playground UI.&#xA;    file: str = Field(..., extra={&#34;widget&#34;: {&#34;type&#34;: &#34;base64file&#34;}})&#xA;    num_chars: int = 100&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>browserless/browserless</title>
    <updated>2023-11-02T01:30:07Z</updated>
    <id>tag:github.com,2023-11-02:/browserless/browserless</id>
    <link href="https://github.com/browserless/browserless" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The browserless service in Docker. Run on our cloud or bring your own.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/browserless/browserless/main/assets/logo.png&#34; alt=&#34;browserless.io logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/browserless/chrome&#34; alt=&#34;Docker Pulls&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/package-json/v/browserless/chrome&#34; alt=&#34;GitHub package.json version (subfolder of monorepo)&#34;&gt; &lt;img src=&#34;https://github.com/browserless/chrome/actions/workflows/docker-chromium.yml/badge.svg?sanitize=true&#34; alt=&#34;Chrome CI&#34;&gt; &lt;img src=&#34;https://github.com/browserless/chrome/actions/workflows/docker-firefox.yml/badge.svg?sanitize=true&#34; alt=&#34;Firefox CI&#34;&gt; &lt;img src=&#34;https://github.com/browserless/chrome/actions/workflows/docker-webkit.yml/badge.svg?sanitize=true&#34; alt=&#34;Webkit CI&#34;&gt; &lt;img src=&#34;https://github.com/browserless/chrome/actions/workflows/docker-multi.yml/badge.svg?sanitize=true&#34; alt=&#34;Multi CI&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/browserless/chrome/tree/v1&#34;&gt;Looking for v1.x.x of browserless? Check it out here&lt;/a&gt;. NOTE: Version 1 is the version we currently still have running on browserless&#39; hosted services.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;browserless is a web-based service that allows for remote clients to connect and execute headless work; all inside of docker. It supports new libraries like Puppeteer and Playwright, aiming to replace antiquated or in-house systems. We also bundle numerous handy REST-based APIs for doing more common actions like data collection, PDF generation and more.&lt;/p&gt; &#xA;&lt;p&gt;We also take care of other common issues such as missing system-fonts, missing external libraries, and performance improvements. We even handle edge-cases like downloading files, managing sessions, and have a full documentation site built into the project which includes Open API docs.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;ve been struggling to get a browser up and running docker, or scaling out your headless workloads, then browserless was built for you.&lt;/p&gt; &#xA;&lt;h1&gt;Table of Contents&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/browserless/browserless/main/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/browserless/browserless/main/#how-it-works&#34;&gt;How it works&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/browserless/browserless/main/#docker&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/browserless/browserless/main/#hosting-providers&#34;&gt;Hosting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/browserless/browserless/main/#puppeteer&#34;&gt;Puppeteer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/browserless/browserless/main/#playwright&#34;&gt;Playwright&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/browserless/browserless/main/#licensing&#34;&gt;Licensing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/browserless/chrome/raw/master/CHANGELOG.md&#34;&gt;Changelog&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;External links&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.browserless.io/docs/start&#34;&gt;Full documentation site&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://chrome.browserless.io/&#34;&gt;Live Debugger (using browserless.io)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/browserless/chrome/pkgs/container/basic&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://join.slack.com/t/browserless/shared_invite/enQtMzA3OTMwNjA3MzY1LTRmMWU5NjQ0MTQ2YTE2YmU3MzdjNmVlMmU4MThjM2UxODNmNzNlZjVkY2U2NjdkMzYyNTgyZTBiMmE3Nzg0MzY&#34;&gt;Slack&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Parallelism and request-queueing are built-in + configurable.&lt;/li&gt; &#xA; &lt;li&gt;Fonts and emoji&#39;s working out-of-the-box.&lt;/li&gt; &#xA; &lt;li&gt;Debug Viewer for actively viewing/debugging running sessions.&lt;/li&gt; &#xA; &lt;li&gt;An interactive puppeteer debugger, so you can see what the headless browser is doing and use its DevTools.&lt;/li&gt; &#xA; &lt;li&gt;Works with most headless libraries.&lt;/li&gt; &#xA; &lt;li&gt;Configurable session timers and health-checks to keep things running smoothly.&lt;/li&gt; &#xA; &lt;li&gt;Error tolerant: if Chrome dies it won&#39;t.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/browserless/browserless/main/#building-for-arm64-apple-m1-machines&#34;&gt;Support for running and development on Apple&#39;s M1 machines&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;How it works&lt;/h1&gt; &#xA;&lt;p&gt;browserless listens for both incoming websocket requests, generally issued by most libraries, as well as pre-build REST APIs to do common functions (PDF generation, images and so on). When a websocket connects to browserless it starts Chrome and proxies your request into it. Once the session is done then it closes and awaits for more connections. Some libraries use Chrome&#39;s HTTP endpoints, like &lt;code&gt;/json&lt;/code&gt; to inspect debug-able targets, which browserless also supports.&lt;/p&gt; &#xA;&lt;p&gt;You still execute the script itself which gives you total control over what library you want to choose and when to do upgrades. This also comes with the benefit of keep your code proprietary and able to run on numerous platforms. We simply take care of all the browser-aspects and offer a management layer on top of the browser.&lt;/p&gt; &#xA;&lt;h1&gt;Docker&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;See more options on our &lt;a href=&#34;https://www.browserless.io/docs/docker-quickstart&#34;&gt;full documentation site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;docker run -p 3000:3000 ghcr.io/browserless/chrome&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Visit &lt;code&gt;http://localhost:3000/docs&lt;/code&gt; to see the documentation site.&lt;/li&gt; &#xA; &lt;li&gt;See more at our &lt;a href=&#34;https://github.com/browserless/chrome/pkgs/container/basic&#34;&gt;docker package&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Hosting Providers&lt;/h1&gt; &#xA;&lt;p&gt;We offer a first-class hosted product located &lt;a href=&#34;https://browserless.io&#34;&gt;here&lt;/a&gt;. Alternatively you can host this image on just about any major platform that offers hosting for docker. Our hosted service takes care of all the machine provisioning, notifications, dashboards and monitoring plus more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Easily upgrade and toggle between versions at the press of a button. No managing repositories and other code artifacts.&lt;/li&gt; &#xA; &lt;li&gt;Never need to update or pull anything from docker. There&#39;s literally zero software to install to get started.&lt;/li&gt; &#xA; &lt;li&gt;Scale your consumption up or down with different plans. We support up to thousands of concurrent sessions at a given time.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you&#39;re interested in using this image for commercial aspects, then please read the below section on licensing.&lt;/p&gt; &#xA;&lt;h1&gt;Puppeteer&lt;/h1&gt; &#xA;&lt;p&gt;Puppeteer allows you to specify a remote location for chrome via the &lt;code&gt;browserWSEndpoint&lt;/code&gt; option. Setting this for browserless is a single line of code change.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Before&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const browser = await puppeteer.launch();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;After&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const browser = await puppeteer.connect({ browserWSEndpoint: &#39;ws://localhost:3000&#39; });&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Playwright&lt;/h1&gt; &#xA;&lt;p&gt;We support running with playwright via their remote connection method on the &lt;code&gt;chromium&lt;/code&gt; interface. Since playwright is very similar to puppeteer, even launch arguments and other things &#34;just work&#34;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Before&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const browser = await pw.chromium.launch();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;After&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const browser = await pw.chromium.connect(&#39;ws://localhost:3000/playwright/chromium&#39;);&#xA;&#xA;// OR&#xA;const browser = await pw.chromium.connectOverCDP(&#39;ws://localhost:3000&#39;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After that, the rest of your code remains the same with no other changes required.&lt;/p&gt; &#xA;&lt;h1&gt;Usage with other libraries&lt;/h1&gt; &#xA;&lt;p&gt;Most libraries allow you to specify a remote instance of Chrome to interact with. They are either looking for a websocket endpoint, a host and port, or some address. Browserless supports these by default, however if you&#39;re having issues please make an issue in this project and we&#39;ll try and work with the library authors to get them integrated with browserless. Please note that in V2 we no longer support selenium or webdriver integrations.&lt;/p&gt; &#xA;&lt;p&gt;You can find a much larger list of supported libraries &lt;a href=&#34;https://www.browserless.io/docs/puppeteer-library&#34;&gt;on our documentation site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Motivations&lt;/h1&gt; &#xA;&lt;p&gt;Running Chrome on lambda or on your own is a fantastic idea but in practice is quite challenging in production. You&#39;re met with pretty tough cloud limits, possibly building Chrome yourself, and then dealing with odd invocation issues should everything else go ok. A lot of issues in various repositories are due to just challenges of getting Chrome running smoothly in AWS (see &lt;a href=&#34;https://github.com/GoogleChrome/puppeteer/issues?q=is%3Aissue+is%3Aopen+sort%3Acomments-desc&#34;&gt;here&lt;/a&gt;). You can see for yourself by going to nearly any library and sorting issues by most commented.&lt;/p&gt; &#xA;&lt;p&gt;Getting Chrome running well in docker is also a challenge as there&#39;s quiet a few packages you need in order to get Chrome running. Once that&#39;s done then there&#39;s still missing fonts, getting libraries to work with it, and having limitations on service reliability. This is also ignoring CVEs, access-controls, and scaling strategies.&lt;/p&gt; &#xA;&lt;p&gt;All of these issues prompted us to build a first-class image and workflow for interacting with Chrome in a more streamlined way. With browserless you never have to worry about fonts, extra packages, library support, security, or anything else. It just works reliably like any other modern web service. On top of that it comes with a prescribed approach on how you interact with Chrome, which is through socket connections (similar to a database or any other external appliance). What this means is that you get the ability to drive Chrome remotely without having to do updates/releases to the thing that runs Chrome since it&#39;s divorced from your application.&lt;/p&gt; &#xA;&lt;h1&gt;Licensing&lt;/h1&gt; &#xA;&lt;p&gt;SPDX-License-Identifier: SSPL-1.0 OR Browserless Commercial License.&lt;/p&gt; &#xA;&lt;p&gt;If you want to use browserless to build commercial sites, applications, or in a continuous-integration system that&#39;s closed-source then you&#39;ll need to purchase a commercial license. This allows you to keep your software proprietary whilst still using browserless. &lt;a href=&#34;https://www.browserless.io/contact&#34;&gt;You can purchase a commercial license here&lt;/a&gt;. A commercial license grants you:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Priority support on issues and features.&lt;/li&gt; &#xA; &lt;li&gt;On-premise running as well as running on public cloud providers for commercial/CI purposes for proprietary systems.&lt;/li&gt; &#xA; &lt;li&gt;Ability to modify the source (forking) for your own purposes.&lt;/li&gt; &#xA; &lt;li&gt;A new admin user-interface.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Not only does it grant you a license to run such a critical piece of infrastructure, but you are also supporting further innovation in this space and our ability to contribute to it.&lt;/p&gt; &#xA;&lt;p&gt;If you are creating an open source application under a license compatible with the Server Side License 1.0, you may use browserless under those terms.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>xnl-h4ck3r/XnlReveal</title>
    <updated>2023-11-02T01:30:07Z</updated>
    <id>tag:github.com,2023-11-02:/xnl-h4ck3r/XnlReveal</id>
    <link href="https://github.com/xnl-h4ck3r/XnlReveal" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Chrome/Firefox browser extension to show alerts for relfected query params, show hidden elements and enable disabled elements.&lt;/p&gt;&lt;hr&gt;&lt;center&gt;&#xA; &lt;img src=&#34;https://github.com/xnl-h4ck3r/XnlReveal/raw/main/images/title.png&#34;&gt;&#xA;&lt;/center&gt; &#xA;&lt;h2&gt;About - v1.0&lt;/h2&gt; &#xA;&lt;p&gt;This is a &lt;strong&gt;Chrome/Firefox Extension&lt;/strong&gt; that can do the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Show an alert for any query parameters that are reflected.&lt;/li&gt; &#xA; &lt;li&gt;Show the Wayback Archive endpoints for the path visited.&lt;/li&gt; &#xA; &lt;li&gt;Show any hidden elements on the page.&lt;/li&gt; &#xA; &lt;li&gt;Enable any disabled elements on the page.&lt;/li&gt; &#xA; &lt;li&gt;Provide a context menu to: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Open a new tab to show Wayback endpoints for the current domain&lt;/li&gt; &#xA;   &lt;li&gt;Show any hidden elements on the page (even if the extension isn&#39;t enabled to do automatically).&lt;/li&gt; &#xA;   &lt;li&gt;Enable any disabled element on the page (even if the extension isn&#39;t enabled to do automatically).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The first point was inspired by a comment by &lt;a href=&#34;https://x.com/renniepak&#34;&gt;@renniepak&lt;/a&gt; on Episode 42 of the &lt;a href=&#34;https://www.criticalthinkingpodcast.io/episode-42-renniepak-interview-intigriti-lhe-recap/&#34;&gt;Critical Thinking - Bug Bounty Podcast&lt;/a&gt; where he mentioned he had his own browser extension that let him know about any reflections.&lt;/p&gt; &#xA;&lt;p&gt;The third and fourth points were inspired by this &lt;a href=&#34;https://x.com/ctbbpodcast/status/1717151268622233614?s=20&#34;&gt;Tweet by Critical Thinking - Bug Bounty Podcast&lt;/a&gt; and I initially created as browser bookmarks.&lt;/p&gt; &#xA;&lt;h2&gt;Installing&lt;/h2&gt; &#xA;&lt;p&gt;Clone this repo to your machine and then follow the instructions below, depending on whether you want install on a Chrome or Firefox browser:&lt;/p&gt; &#xA;&lt;h3&gt;Chrome&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Open the Extension Manager in Chrome by following: Kebab menu(three vertical dots) -&amp;gt; Extensions -&amp;gt; Manage Extensions&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If the developer mode is not turned on, turn it on by clicking the toggle in the top right corner.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Now click on &lt;strong&gt;Load unpacked&lt;/strong&gt; button on the top left&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Go the directory where you have &lt;code&gt;XnlReveal&lt;/code&gt; folder and select it.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The extension is now loaded. You can click on the extension icon in the toolbar, and then the pin icon to pin &lt;code&gt;Xnl Reveal&lt;/code&gt; to your toolbar.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Firefox&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;IMPORTANT: With Firefox extensions, you will need to load it each time you open Firefox&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Go to &lt;code&gt;about:debugging&lt;/code&gt; in a new browser tab.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Click on the &lt;strong&gt;This Firefox&lt;/strong&gt; heading on the left of the page.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Click the &lt;strong&gt;Load Temporary Add-on...&lt;/strong&gt; button under the &lt;strong&gt;Temporary Extensions&lt;/strong&gt; heading.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to the &lt;code&gt;Firefox&lt;/code&gt; folder from the downloaded repo and select any file, and then click &lt;strong&gt;Open&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The extension is now loaded. You can click on the extension icon in the toolbar, then click the Settings cog icon, and select &lt;strong&gt;Pin to Toolbar&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Settings&lt;/h2&gt; &#xA;&lt;h3&gt;Options Page&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chrome&lt;/strong&gt;: If you right click the &lt;code&gt;Xnl Reveal&lt;/code&gt; logo in the toolbar and select &lt;strong&gt;Options&lt;/strong&gt;, you will be taken to the Options page.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Firefox&lt;/strong&gt;: If you right click the &lt;code&gt;Xnl Reveal&lt;/code&gt; logo in the toolbar and select &lt;strong&gt;Manage Extension&lt;/strong&gt;, then click the &lt;strong&gt;Options&lt;/strong&gt; tab to see the Options page.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;center&gt;&#xA; &lt;img src=&#34;https://github.com/xnl-h4ck3r/XnlReveal/raw/main/images/options.png&#34;&gt;&#xA;&lt;/center&gt; &#xA;&lt;p&gt;You have the following options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Canary token&lt;/code&gt; - When requests are made to test for reflection of query parameters, this is the value of the parameter that is used and checked for.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Check delay&lt;/code&gt; - When a page is loaded, depending on settings, the extension will try to show hidden elements and enable disabled elements. However, sometimes parts of the page are loaded dynamically and they aren&#39;t in the original response. THe extension will try to show and enable again after this delay (in seconds) after the page has initially loaded.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Only write JS Wayback endpoints&lt;/code&gt; - If the setting to write Wayback archive endpoints has been selected, then if this option is checked, only endpoints for JS files will be written to the browser console.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Save&lt;/code&gt; - If any options are changed, click this button to save them for future use.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Clear Saved URLs/Params&lt;/code&gt; - If the extension is looking for reflected query parameters, then you don&#39;t want to keep getting alerted for the same URL/Parameter combinations, so those that have been reported are stored to prevent this. However, if you want to remove the memory of those, you can click this button to remove them. Similarly, we don&#39;t want to keep passing the same requests to the Wayback archive, so those are also stored, but can be cleared if this button is pressed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Popup Menu&lt;/h3&gt; &#xA;&lt;p&gt;If you click the &lt;code&gt;Xnl Reveal&lt;/code&gt; logo in the toolbar, you will see a popup menu.&lt;/p&gt; &#xA;&lt;center&gt;&#xA; &lt;img src=&#34;https://github.com/xnl-h4ck3r/XnlReveal/raw/main/images/popup.png&#34;&gt;&#xA;&lt;/center&gt; &#xA;&lt;p&gt;You have the following settings:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;ENABLE REVEAL&lt;/code&gt; - If this is not checked then the extension will do nothing. If checked then it will take certain actions on web pages visited, depending on the other options set.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Show query param reflection alerts&lt;/code&gt; - If this is checked, then when a web page is visited that has any query parameters, a background request is made for each parameter, replacing each n turn with the &lt;strong&gt;Canary token&lt;/strong&gt; from the Options page. If the token is found for any of the parameters the response then an alert box is shown giving you the URL and all the parameters on that page that were reflected. These are also written to the browser console.&lt;br&gt; &lt;strong&gt;NOTE: If there are many parameters, it can take some time to send all the requests and wait for the responses. A red status bar is displayed at the top of the page to let you know to wait. Also, if the page is dynamic, then these may not be found in the initial response and reported.&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Write Wayback endpoints to console&lt;/code&gt; - If this is checked, then for each location/path visited in the browser, endpoints will be retrieved from the Wayback archive and written to the console. Once a location/path has been sent to the Wayback API it will not be sent again, unless the &lt;code&gt;Clear Saved URLs/Params&lt;/code&gt; has been clicked.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Show hidden elements&lt;/code&gt; - If this is checked, then any elements (excluding &lt;code&gt;img&lt;/code&gt;,&lt;code&gt;span&lt;/code&gt; and &lt;code&gt;div&lt;/code&gt;) that are hidden will be shown. They will be shown with a red border and a label in red that gives some detail. Sometimes, if the page is dynamic, the elements may not be shown. You can always click the &lt;strong&gt;Run Now&lt;/strong&gt; button to change the current loaded page.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Enable disabled elements&lt;/code&gt; - If this is checked, then any elements (excluding &lt;code&gt;img&lt;/code&gt;,&lt;code&gt;span&lt;/code&gt; and &lt;code&gt;div&lt;/code&gt;) that are hidden will be shown. They will be shown with a red border and a label in red that gives some detail. Sometimes, if the page is dynamic, the elements may not be shown. You can always click the &lt;strong&gt;Run Now&lt;/strong&gt; button to change the current loaded page.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Context Menu&lt;/h2&gt; &#xA;&lt;p&gt;If you right click on a webpage, you will get the browser context menu:&lt;/p&gt; &#xA;&lt;center&gt;&#xA; &lt;img src=&#34;https://github.com/xnl-h4ck3r/XnlReveal/raw/main/images/context.png&#34;&gt;&#xA;&lt;/center&gt; &#xA;&lt;p&gt;These options are available even if the &lt;code&gt;ENABLE REVEAL&lt;/code&gt; option in the &lt;strong&gt;Popup Menu&lt;/strong&gt; is not selected. There are 3 options you can choose from:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Get wayback endpoints&lt;/code&gt; - If this is clicked, a new tab will be opened that will contain Wayback archive endpoints for the domain of the window it is clicked on. This isn&#39;t affected by any other settings and can be run even if the extension isn;t enabled.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Show hidden elements&lt;/code&gt; - This is the same as clicking the &lt;strong&gt;Run Now&lt;/strong&gt; button for &lt;code&gt;Show hidden elements&lt;/code&gt; on the &lt;strong&gt;Popup Menu&lt;/strong&gt;, but the extension doesn&#39;t need to be enabled.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Enable disabled elements&lt;/code&gt; - This is the same as clicking the &lt;strong&gt;Run Now&lt;/strong&gt; button for &lt;code&gt;Enable disabled elements&lt;/code&gt; on the &lt;strong&gt;Popup Menu&lt;/strong&gt;, but the extension doesn&#39;t need to be enabled.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Important&lt;/h2&gt; &#xA;&lt;p&gt;This browser extension isn&#39;t going to be perfect!&lt;br&gt; Sometimes the change of code can break a page. If you get a problem, unselected a certain setting in the popup menu will reload the page and it may be okay again, and you&#39;ll just not be able to check.&lt;br&gt; There may also be some Errors that are shown in the &lt;strong&gt;Manage extension&lt;/strong&gt; page in certain situations. If you manually run an option from the context menu and nothing happens, you may need to refresh the page you are trying to run the option on and try again.&lt;/p&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Provide a regex or whitelist of domains that the extension will only be enabled for. Then you can browse anything, but it will only do processing for targets you are interested in.&lt;/li&gt; &#xA; &lt;li&gt;Look at registering the extension so you don&#39;t need to reload each time in Firefox.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Issues&lt;/h2&gt; &#xA;&lt;p&gt;If you come across any problems at all, or have ideas for improvements, please feel free to raise an issue on Github. If there is a problem, it will be useful if you can provide the exact URL you were on, and any console errors. &lt;br&gt;&lt;br&gt; Good luck and good hunting! If you really love the tool (or any others), or they helped you find an awesome bounty, consider &lt;a href=&#34;https://ko-fi.com/xnlh4ck3r&#34;&gt;BUYING ME A COFFEE!&lt;/a&gt; ‚òï (I could use the caffeine!)&lt;/p&gt; &#xA;&lt;p&gt;ü§ò /XNL-h4ck3r&lt;/p&gt;</summary>
  </entry>
</feed>