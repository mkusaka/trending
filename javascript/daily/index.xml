<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-01T01:38:40Z</updated>
  <subtitle>Daily Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>slarkvan/Block-Pornographic-Replies</title>
    <updated>2023-07-01T01:38:40Z</updated>
    <id>tag:github.com,2023-07-01:/slarkvan/Block-Pornographic-Replies</id>
    <link href="https://github.com/slarkvan/Block-Pornographic-Replies" rel="alternate"></link>
    <summary type="html">&lt;p&gt;屏蔽推特回复下的黄推。Block pornographic replies below the tweet.&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;背景&lt;/h3&gt; &#xA;&lt;p&gt;实在受不了推文下无休无止的回复引流的黄推了，musk 管不了的，我来管&lt;/p&gt; &#xA;&lt;h3&gt;设计宗旨&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;隐私优先。本插件纯客户端代码，无服务端 api 或前端监控等设计&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;使用方式&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;进入 &lt;a href=&#34;chrome://extensions/&#34;&gt;chrome://extensions/&lt;/a&gt;，打开「开发者模式」&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;把代码包下载解压拖到里面即可&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;效果&lt;/h3&gt; &#xA;&lt;p&gt;目前一定得&lt;strong&gt;自己装了插件才有用。且只针对推文回复下的黄推&lt;/strong&gt;。插件有 2 种功能。&lt;/p&gt; &#xA;&lt;p&gt;1.标记推文回复下的黄推引流，并在自身浏览时隐藏&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/slarkvan/Block-Pornographic-Replies/main/misc/demo.png&#34; alt=&#34;Image&#34; width=&#34;300&#34; height=&#34;400&#34;&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;一键批量屏蔽&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/slarkvan/Block-Pornographic-Replies/main/misc/how-to-block.png&#34; alt=&#34;Image&#34; width=&#34;600&#34; height=&#34;209&#34;&gt; &#xA;&lt;p&gt;具体可以拿&lt;strong&gt;立党&lt;/strong&gt;的推文 &lt;a href=&#34;https://twitter.com/lidangzzz/status/1674346633335648256&#34;&gt;https://twitter.com/lidangzzz/status/1674346633335648256&lt;/a&gt; 检测下&lt;/p&gt; &#xA;&lt;h3&gt;说明&lt;/h3&gt; &#xA;&lt;p&gt;原理采用的是内置的「关键词匹配」检测是否是黄推，然后进行浏览器样式上的隐藏(非推特的 Block 功能)，准确率大约 90%。会有少少部分的错判和漏判。可以通过点击「移出列表」按钮加入白名单&lt;/p&gt; &#xA;&lt;h3&gt;后续计划&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 增加 on/off 配置&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 增加一键 block 功能&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 适配 firefox 浏览器&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 进入 Store&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 其他&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;欢迎 PR&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;想 PR 前，可以现在 discuss or issue 大概说下要做的内容&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jgraph/drawio-desktop</title>
    <updated>2023-07-01T01:38:40Z</updated>
    <id>tag:github.com,2023-07-01:/jgraph/drawio-desktop</id>
    <link href="https://github.com/jgraph/drawio-desktop" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official electron build of draw.io&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;drawio-desktop&lt;/strong&gt; is a diagramming and whiteboarding desktop app based on &lt;a href=&#34;https://electronjs.org/&#34;&gt;Electron&lt;/a&gt; that wraps the &lt;a href=&#34;https://github.com/jgraph/drawio&#34;&gt;core draw.io editor&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Download built binaries from the &lt;a href=&#34;https://github.com/jgraph/drawio-desktop/releases&#34;&gt;releases section&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Can I use this app for free?&lt;/strong&gt; Yes, under the apache 2.0 license. If you don&#39;t change the code and accept it is provided &#34;as-is&#34;, you can use it for any purpose.&lt;/p&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;draw.io Desktop is designed to be completely isolated from the Internet, apart from the update process. This checks github.com at startup for a newer version and downloads it from an AWS S3 bucket owned by Github. All JavaScript files are self-contained, the Content Security Policy forbids running remotely loaded JavaScript.&lt;/p&gt; &#xA;&lt;p&gt;No diagram data is ever sent externally, nor do we send any analytics about app usage externally. This means certain functionality for which we do not have a JavaScript implementation do not work in the Desktop build, namely .vsd and Gliffy import.&lt;/p&gt; &#xA;&lt;h2&gt;Developing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;draw.io&lt;/strong&gt; is a git submodule of &lt;strong&gt;drawio-desktop&lt;/strong&gt;. To get both you need to clone recursively:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;git clone --recursive https://github.com/jgraph/drawio-desktop.git&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;To run this:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;npm install&lt;/code&gt; (in the root directory of this repo)&lt;/li&gt; &#xA; &lt;li&gt;export DRAWIO_ENV=dev if you want to develop/debug in dev mode.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;npm start&lt;/code&gt; &lt;em&gt;in the root directory of this repo&lt;/em&gt; runs the app. For debugging, use &lt;code&gt;npm start --enable-logging&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: If a symlink is used to refer to drawio repo (instead of the submodule), then symlink the &lt;code&gt;node_modules&lt;/code&gt; directory inside &lt;code&gt;drawio/src/main/webapp&lt;/code&gt; also.&lt;/p&gt; &#xA;&lt;p&gt;To release:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Update the draw.io sub-module and push the change. Add version tag before pushing to origin.&lt;/li&gt; &#xA; &lt;li&gt;Wait for the builds to complete (&lt;a href=&#34;https://travis-ci.org/jgraph/drawio-desktop&#34;&gt;https://travis-ci.org/jgraph/drawio-desktop&lt;/a&gt; and &lt;a href=&#34;https://ci.appveyor.com/project/davidjgraph/drawio-desktop&#34;&gt;https://ci.appveyor.com/project/davidjgraph/drawio-desktop&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;https://github.com/jgraph/drawio-desktop/releases&#34;&gt;https://github.com/jgraph/drawio-desktop/releases&lt;/a&gt;, edit the preview release.&lt;/li&gt; &#xA; &lt;li&gt;Download the windows exe and windows portable, sign them using &lt;code&gt;signtool sign /a /tr http://rfc3161timestamp.globalsign.com/advanced /td SHA256 c:/path/to/your/file.exe&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Re-upload signed file as &lt;code&gt;draw.io-windows-installer-x.y.z.exe&lt;/code&gt; and &lt;code&gt;draw.io-windows-no-installer-x.y.z.exe&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Add release notes&lt;/li&gt; &#xA; &lt;li&gt;Publish release&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: In Windows release, when using both x64 and is32 as arch, the result is one big file with both archs. This is why we split them.&lt;/p&gt; &#xA;&lt;p&gt;Local Storage and Session Storage is stored in the AppData folder:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;macOS: &lt;code&gt;~/Library/Application Support/draw.io&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Windows: &lt;code&gt;C:\Users\&amp;lt;USER-NAME&amp;gt;\AppData\Roaming\draw.io\&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Open-source, not open-contribution&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.sqlite.org/copyright.html&#34;&gt;Similar to SQLite&lt;/a&gt;, draw.io is open source but closed to contributions.&lt;/p&gt; &#xA;&lt;p&gt;The level of complexity of this project means that even simple changes can break a &lt;em&gt;lot&lt;/em&gt; of other moving parts. The amount of testing required is far more than it first seems. If we were to receive a PR, we&#39;d have to basically throw it away and write it how we want it to be implemented.&lt;/p&gt; &#xA;&lt;p&gt;We are grateful for community involvement, bug reports, &amp;amp; feature requests. We do not wish to come off as anything but welcoming, however, we&#39;ve made the decision to keep this project closed to contributions for the long term viability of the project.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>painebenjamin/app.enfugue.ai</title>
    <updated>2023-07-01T01:38:40Z</updated>
    <id>tag:github.com,2023-07-01:/painebenjamin/app.enfugue.ai</id>
    <link href="https://github.com/painebenjamin/app.enfugue.ai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ENFUGUE is a feature-rich self-hosted Stable Diffusion webapp&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/github-header.png?raw=true&#34; alt=&#34;ENFUGUE&#34;&gt; &lt;/p&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt; Enfugue is a feature-rich self-hosted Stable Diffusion web application. &lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;em&gt;Forever open source, forever free.&lt;/em&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;400&#34; src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/screencap.png?raw=true&#34; alt=&#34;The ENFUGUE interface zoomed out&#34;&gt; &lt;img width=&#34;400&#34; src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/screencap-zoomed-in.png?raw=true&#34; alt=&#34;The ENFUGUE interface zoomed in&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Feature Summary&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🚀 &lt;strong&gt;One Click Install:&lt;/strong&gt; Enfugue is available as a simple &lt;code&gt;.exe&lt;/code&gt; to make it as easy as possible to get busy making images, not configuring environments.&lt;/li&gt; &#xA; &lt;li&gt;🤝 &lt;strong&gt;Plays Nice with Others:&lt;/strong&gt; If you want more control in managing your environment, simply install &lt;code&gt;enfugue&lt;/code&gt; via &lt;code&gt;pip&lt;/code&gt; into your existing stable diffusion workflow. Worried about a whole webapp clogging up your installation? Don&#39;t be, Enfugue is only &lt;code&gt;1 MB&lt;/code&gt; in size on it&#39;s own.&lt;/li&gt; &#xA; &lt;li&gt;👥 &lt;strong&gt;Owners and Users:&lt;/strong&gt; Optional authentication and authorization keeps your installation settings locked down.&lt;/li&gt; &#xA; &lt;li&gt;🗃 &lt;strong&gt;Easy Model Management:&lt;/strong&gt; In-app CivitAI browser makes community checkpoints, LoRA, and Textual Inversions one click away. Drop any other models directly into the app to keep files organized.&lt;/li&gt; &#xA; &lt;li&gt;🧷 &lt;strong&gt;Safety&#39;s On:&lt;/strong&gt; Safety checker is on by default, and can be disabled by owners right in the UI.&lt;/li&gt; &#xA; &lt;li&gt;⚡ &lt;strong&gt;Turbocharged:&lt;/strong&gt; Have a powerful NVidia GPU? TensorRT support is built-in; speed up inference by up to 100% using state-of-the-art AI technology from NVidia.&lt;/li&gt; &#xA; &lt;li&gt;♻️ &lt;strong&gt;Waste Not, Want Not:&lt;/strong&gt; AI can take a lot of resources, and Enfugue takes care to only use what it needs. It will free your GPU for desktop applications or gaming as soon as it&#39;s no longer needed, and clean up unneeded files as it goes.&lt;/li&gt; &#xA; &lt;li&gt;🧈 &lt;strong&gt;Unified Pipeline:&lt;/strong&gt; Never choose between &lt;code&gt;txt2img&lt;/code&gt;, &lt;code&gt;img2img&lt;/code&gt;, &lt;code&gt;inpainting&lt;/code&gt;, or any upscaling pipeline again, with or without multi-diffusion. Just ask what you want, and Enfugue will take care of the rest.&lt;/li&gt; &#xA; &lt;li&gt;🕹️ &lt;strong&gt;Take Control:&lt;/strong&gt; Region prompting and Controlnet are standard.&lt;/li&gt; &#xA; &lt;li&gt;🔌 &lt;strong&gt;Plug Away:&lt;/strong&gt; All features are available via JSON API, or can be added to your Python scripts using our &lt;code&gt;diffusers&lt;/code&gt; extensions.&lt;/li&gt; &#xA; &lt;li&gt;👁️ &lt;strong&gt;Eye Queue:&lt;/strong&gt; Have things to do? Send an unlimited* number of invocations at once, let Enfugue take care of making sure they all get done.&lt;/li&gt; &#xA; &lt;li&gt;☁️ &lt;strong&gt;Your Own Cloud:&lt;/strong&gt; All of the best features you would expect from a SaaS application, with the security of knowing nothing ever leaves your computer. Results are kept by the app until you no longer need them, and your browser keeps a lengthy history of workspaces so you can always revisit where you left off.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;em&gt;* configurable in-app, defaults to five queued invocations&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Installation and Running&lt;/h1&gt; &#xA;&lt;h2&gt;As Easy as Possible: Self-Contained Executable&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Navigate to &lt;a href=&#34;https://github.com/painebenjamin/app.enfugue.ai/releases&#34;&gt;the Releases page&lt;/a&gt; and download the latest release as a &lt;code&gt;.zip&lt;/code&gt; (Windows) or &lt;code&gt;.tar.gz&lt;/code&gt; (Linux).&lt;/li&gt; &#xA; &lt;li&gt;Extract the archive anywhere. See the releases page for details on extraction.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the archive folder and run the executable file - &lt;code&gt;enfugue-server.exe&lt;/code&gt; for Windows, or &lt;code&gt;enfugue.sh&lt;/code&gt; for Linux.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;On windows, you will now see the Enfugue icon in the bottom-right-hand corner of your screen. Click on this to exit the server when you wish. To enable TensorRT for Windows follow the steps under &lt;strong&gt;Windows TensorRT Support&lt;/strong&gt; below.&lt;/p&gt; &#xA;&lt;h2&gt;Advanced: Creating your Own Environment and Running from Command Line&lt;/h2&gt; &#xA;&lt;p&gt;This instruction assumes you are using a variant of &lt;a href=&#34;https://docs.conda.io/projects/conda/en/stable/&#34;&gt;Conda&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download a copy of &lt;a href=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/environment.yaml&#34;&gt;environment.yaml&lt;/a&gt; somewhere to your computer.&lt;/li&gt; &#xA; &lt;li&gt;Run the command &lt;code&gt;conda env create -f environment.yaml&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run the command &lt;code&gt;conda activate enfugue&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run the comand &lt;code&gt;pip install enfugue&lt;/code&gt;. If you are on Linux and want to install TensorRT support as well, use &lt;code&gt;pip install enfugue[tensorrt]&lt;/code&gt;. If you are on Windows, this will not work, you will need to install the python packages from source as detailed below.&lt;/li&gt; &#xA; &lt;li&gt;Run the command &lt;code&gt;enfugue run&lt;/code&gt; to run the server. Issue a keyboard interrupt (Ctrl+C) to stop it.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;À la Carte&lt;/h2&gt; &#xA;&lt;p&gt;You can install &lt;code&gt;enfugue&lt;/code&gt; into any other latent diffusion environment using &lt;code&gt;pip install enfugue&lt;/code&gt;. If you are on Linux and want to install TensorRT support as well, use &lt;code&gt;pip install enfugue[tensorrt]&lt;/code&gt;. If you are on Windows, this will not work, you will need to install the python packages from source as detailed below.&lt;/p&gt; &#xA;&lt;h2&gt;Windows TensorRT Support&lt;/h2&gt; &#xA;&lt;p&gt;In order to use TensorRT on Windows, some additional steps must be taken. This is temporary (hopefully) as TensorRT support for Windows is very new.&lt;/p&gt; &#xA;&lt;p&gt;You will be asked to add a number of directories to your PATH. On windows, the easiest way to reach it is:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open the start menu and begin typing &#34;Environment&#34;. You will see an option that says &#34;Edit the system environment variables,&#34; click this.&lt;/li&gt; &#xA; &lt;li&gt;In the bottom-right-hand corner of the System Properties window, click &#34;Environment Variables.&#34;&lt;/li&gt; &#xA; &lt;li&gt;Under your user, click the &#34;Path&#34; variable and then click &#34;Edit&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Add a new entry pointing to the requested path.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/github-windows-env.png?raw=true&#34; alt=&#34;Windows Configuration for Enabling TensorRT&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Before downloading anything, you will need to make an account with NVidia and &lt;a href=&#34;https://developer.nvidia.com/developer-program&#34;&gt;Join the Nvidia Developer Program&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Once that is complete, download the following packages and install them anywhere to your system.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-11-7-1-download-archive?target_os=Windows&amp;amp;target_arch=x86_64&amp;amp;target_version=10&amp;amp;target_type=exe_local&#34;&gt;Install CUDA&lt;/a&gt;, add &lt;code&gt;/bin&lt;/code&gt; to PATH&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/rdp/cudnn-download&#34;&gt;Install CUDNN&lt;/a&gt;, add &lt;code&gt;/lib&lt;/code&gt; to PATH&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/nvidia-tensorrt-8x-download&#34;&gt;Install TensorRT&lt;/a&gt;, add &lt;code&gt;/lib&lt;/code&gt; to PATH. If you are creating your own environment, you should also use &lt;code&gt;pip&lt;/code&gt; to install &lt;code&gt;python/tensorrt-8.*-cp310-none-win_amd64.whl&lt;/code&gt; from this directory.&lt;/li&gt; &#xA; &lt;li&gt;If you are creating your own environment, now run &lt;code&gt;pip install pibble[tensorrt]&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Many configuration options are available, but none are required. If you want to specify things such as the host and port that the server listens on, please review the documentation for this on &lt;a href=&#34;https://github.com/painebenjamin/app.enfugue.ai/wiki/Configuration-for-Advanced-Users&#34;&gt;the wiki&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;App Quickstart Guide&lt;/h1&gt; &#xA;&lt;p&gt;Once the Enfugue server is running on your computer, you can start using the app. Simply open any browser (Chromium-based browsers are recommended for all features, but Firefox is also supported) and navigate to &lt;code&gt;https://app.enfugue.ai:45554&lt;/code&gt;, or for short, &lt;code&gt;my.enfugue.ai&lt;/code&gt; (this redirects you to the first address.) If you specified your own configuration, then the server will instead be listening on your configured address. You&#39;ll be greeted by your application home screen and some initial documentation - please read it in it&#39;s entirety.&lt;/p&gt; &#xA;&lt;h2&gt;Windows&lt;/h2&gt; &#xA;&lt;p&gt;The Enfugue interface uses a custom frontend framework which features a windows-like interface. Many interface elements will spawn windows; these can be moved around, minimized, maximized, resized and closed as you would expect if you&#39;ve ever worked in a window-focused interface.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/windows.png?raw=true&#34; alt=&#34;Windows in ENFUGUE&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Components&lt;/h2&gt; &#xA;&lt;p&gt;The User Interface is broken up into a small handful of components:&lt;/p&gt; &#xA;&lt;h3&gt;The Sidebar&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/sidebar.png?raw=true&#34; alt=&#34;The ENFUGUE interface sidebar&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;The sidebar is where all of your settings are for the current image you are creating. Most import is the &lt;code&gt;prompt&lt;/code&gt; field, which must be filled with what you want the image to contain before invoking the engine. All other settings are optional; click on any of the headers to expand them and view the settings beneath. Hold your mouse over the relevant input sections to see details about what it does, or visit &lt;a href=&#34;https://github.com/painebenjamin/app.enfugue.ai/edit/main/README.md&#34;&gt;the Wiki&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The button at the button, labeled &lt;code&gt;ENFUGUE&lt;/code&gt;, to send your current invocation settings to the engine and start the image creation process.&lt;/p&gt; &#xA;&lt;h3&gt;The Canvas&lt;/h3&gt; &#xA;&lt;p&gt;The main feature that sets Enfugue apart from other Stable Diffusion interfaces is the Canvas.&lt;/p&gt; &#xA;&lt;p&gt;With nothing on it, the canvas shows you a preview of the shape of your inference, with convenient 8-pixel and 64-pixel demarcations provided.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/canvas.png?raw=true&#34; alt=&#34;The ENFUGUE interface canvas with nothing in it&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;While making images, the canvas will be replaced with in-progress samples, and then by the final images when complete. When making multiple samples at once, you can choose between the samples here.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/samples.png?raw=true&#34; alt=&#34;The ENFUGUE interface canvas showing in-progress samples&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;You can move the entire canvas (pan) by placing your cursor over it then holding down the &lt;strong&gt;middle-mouse&lt;/strong&gt; button, or alternatively &lt;strong&gt;Ctrl+Left-Mouse-Button&lt;/strong&gt;, and move the canvas around.&lt;/p&gt; &#xA;&lt;p&gt;Zoom in and out using the scroll wheel or scroll gestures. You can also click the &lt;code&gt;+&lt;/code&gt; and &lt;code&gt;-&lt;/code&gt; icons in the bottom-right-hand corner. Click &#39;RESET&#39; at any time to bring the canvas back.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/zoom-and-pan.png?raw=true&#34; alt=&#34;The ENFUGUE interface zoomed in and panned to the side.&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;To take better control of the image, there are different &lt;strong&gt;nodes&lt;/strong&gt; available that can be placed on the canvas. See the &lt;strong&gt;toolbar&lt;/strong&gt; section below for descriptions of the nodes that can be added. Nodes can be moved, removed, and resized just like windows, within the confines of the canvas.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/canvas-nodes.png?raw=true&#34; alt=&#34;The ENFUGUE interface canvas with multiple nodes&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Nodes on the canvas often feature additional buttons on their headers. Place your cursor over each to see what they do. Some nodes hide their headers when your cursor is not in them so you can better see the contents underneath.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/scribble.png?raw=true&#34; width=&#34;300&#34; alt=&#34;A scribble node on the ENFUGUE interface.&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/scribble-result.png?raw=true&#34; width=&#34;300&#34; alt=&#34;The result of a scribble on the ENFUGUE interface.&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Additionally, some nodes feature the ability to draw black and white images using simple tools. These nodes all feature an array of buttons at the top to control various things about the brush you are drawing with. There are some additional controls available when drawing:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Use the Scroll Wheel or Scroll Gestures to increase/decrease the size of the brush.&lt;/li&gt; &#xA; &lt;li&gt;Hold &lt;code&gt;Control&lt;/code&gt; when scrolling up/down to stop this behavior and instead perform the previous behavior of zooming in and out.&lt;/li&gt; &#xA; &lt;li&gt;Left-click to draw, or hold &lt;code&gt;Alt&lt;/code&gt; and left-click to erase.&lt;/li&gt; &#xA; &lt;li&gt;After releasing left-click, if you then draw somewhere else while holding &lt;code&gt;shift&lt;/code&gt;, a line will be drawn between the last point and the new point using the current brush.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;The Toolbar&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/toolbar.png?raw=true&#34; alt=&#34;The ENFUGUE interface toolbar&#34;&gt; &lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Image&lt;/strong&gt;: Upload an image from your computer and place it on the canvas. Paste an image in the window to quickly make an image node without having to save it.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Scribble&lt;/strong&gt;: Draw the shape you&#39;re looking for.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Prompt&lt;/strong&gt;: Denote a section of the image as a different prompt with it&#39;s own settings.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;The Menu Bar&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/menu.png?raw=true&#34; alt=&#34;The ENFUGUE menu bar&#34;&gt; &lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;File&lt;/strong&gt;: Save, load, and reset settings, including the entire content of the canvas, uploaded images and all. Also review your history here.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Models&lt;/strong&gt;: Manage models - download fine-tuned models from CivitAI and create configurations of models and prompts.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;System&lt;/strong&gt;: Manage your installation. Find here the settings window to enable or disable authentication, enable or disable the safety checker, and manage queue sizes. If authentication is enabled, you will also manager users and passwords here.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Help&lt;/strong&gt;: View information about Enfugue, and find links to resources such as this page.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;The Header&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/header.png?raw=true&#34; alt=&#34;The ENFUGUE header&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;The header contains useful information about your GPU, as well as two important icons. The &lt;strong&gt;Download&lt;/strong&gt; icon shows you the progress of any active downloads, and the &lt;strong&gt;Status&lt;/strong&gt; icon shows you the current engine status - Green (ready), Yellow (busy) or Gray (Idle). Whenever the status indicator shows any state other than &lt;strong&gt;Idle&lt;/strong&gt;, you can click on it to terminate the engine, stopping any active diffusion process.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/terminate.png?raw=true&#34; alt=&#34;A window in the ENFUGUE interface offering to terminate any active invocations.&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;The Model Picker&lt;/h3&gt; &#xA;&lt;p&gt;A special callout should be made to the Model Picker, the input in the top-left-hand corner of the Canvas:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/assets/57536852/122837ea-52d7-45db-b1fe-47b655515efa&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is essential to unlock the best results from enfugue. After downloading a model from Civit AI, uploading it through the menu at &lt;code&gt;System&lt;/code&gt; -&amp;gt; &lt;code&gt;Installation&lt;/code&gt;, or manually playing them into the correct directory (&lt;code&gt;~/.cache/enfugue/checkpoint&lt;/code&gt;, &lt;code&gt;~/.cache/enfugue/lora&lt;/code&gt;, etc, by default, or as configured by the user during initialization or using the &lt;code&gt;system &amp;gt; Installation Manager&lt;/code&gt; menu item,) use the &lt;strong&gt;Model Manager&lt;/strong&gt; from the &lt;code&gt;Models&lt;/code&gt; menu to create a pre-configured set of model, LoRA, inversions, and default/trigger prompts.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/assets/57536852/78c7c05f-4af5-47a0-ab2b-da80ae38e035&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Tensor RT&lt;/h2&gt; &#xA;&lt;p&gt;TensorRT is a technology created by Nvidia that transforms an AI model into one that takes advantage of hardware acceleration available on NVidia GPUs.&lt;/p&gt; &#xA;&lt;p&gt;As there are numerous varying architectures used by NVidia that support this technology, these engines must be compiled by an architecture compatible with your actual hardware, rather than distributed by AI model providers. The compilation time for each model varies, but generally takes between 15 and 30 minutes each. You can expect between 50% and 100% faster inference speeds during the engine&#39;s respective step(s).&lt;/p&gt; &#xA;&lt;p&gt;This is &lt;strong&gt;only&lt;/strong&gt; available for modern 30xx and 40xx Nvidia GPU&#39;s.&lt;/p&gt; &#xA;&lt;p&gt;After selecting a model, you will see a small icon next to the model name with a number. This is the number of TensorRT engines that are prepared. Each engine is used in a different portion of the inference process. Click the icon to see a small window that allows you to begin the engine build process. You will receive a notification in this window (and any others) when the build is complete, and the engine will automatically be used when it is able to be used. Build all engines to ensure you are using the fastest possible inference method for all image generation techniques.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/tensorrt-build.png?raw=true&#34; alt=&#34;A window in the ENFUGUE interface offering to build TensorRT engines.&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;This is experimental.&lt;/em&gt; Engine builds can fail for a variety of reasons, some of which are not immediately apparent. There is a hard cap of one hour of unresponsiveness from the build process before it will be canceled.&lt;/p&gt; &#xA;&lt;h2&gt;Authentication&lt;/h2&gt; &#xA;&lt;p&gt;When enabled, authentication will be required when using Enfugue. This enables system administrators to create a two-tiered hierarchy of users and administrators, where users are not permitted to modify models or the installation itself; they are only allowed to use the pre-configured setup. The primary impetus behind this was to create the ability for parents to curate an environment for children to safely experiment with generative AI.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/painebenjamin/app.enfugue.ai/raw/main/docs/settings.png?raw=true&#34; alt=&#34;A window in the ENFUGUE interface offering multiple settings options&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Once enabled in the settings menu, you will be taken to a login screen. The default user and password are both &lt;code&gt;enfugue&lt;/code&gt;, all lowercase. You can change any other user&#39;s password as an administrator.&lt;/p&gt; &#xA;&lt;p&gt;If you ever forget your password, you can reset the root password by creating a file named &lt;code&gt;password_reset.txt&lt;/code&gt; in the enfugue cache directory with the desired new password, then restart the server. The cache directory is located at &lt;code&gt;~/.cache/enfugue/&lt;/code&gt;, where &lt;code&gt;~&lt;/code&gt; is your home directory or user directory, depending on platform.&lt;/p&gt; &#xA;&lt;h2&gt;Tips&lt;/h2&gt; &#xA;&lt;p&gt;Here are a few quick tips to getting great results:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The base Stable Diffusion model can create some pretty good images, but it&#39;s with the fine-tuned models from the larger AI community that you will see the best images. Open up the CivitAI browser and download the latest and greatest models to give them a try.&lt;/li&gt; &#xA; &lt;li&gt;The very first invocation with a new model will always take quite a bit longer than subsequent ones, as Enfugue moves files and downloads any other necessary files.&lt;/li&gt; &#xA; &lt;li&gt;Upscaling can take an image from mediocre to great with surprising frequency. Try out the AI upscale methods and upscale diffusion to take your image generation to the next level.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Troubleshooting&lt;/h1&gt; &#xA;&lt;p&gt;Here are a few steps to take if you&#39;re having trouble getting Enfugue to work for you:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Ensure your Firewall is not blocking port inbound port &lt;code&gt;45554&lt;/code&gt;. This would be uncommon, but possible in strict environments. See &lt;a href=&#34;https://learn.microsoft.com/en-us/windows/security/operating-system-security/network-security/windows-firewall/create-an-inbound-port-rule&#34;&gt;here&lt;/a&gt; for details on how to create an Inbound Port rule.&lt;/li&gt; &#xA; &lt;li&gt;Instead of typing in &lt;code&gt;my.enfugue.ai&lt;/code&gt;, go directly to &lt;code&gt;https://app.enfugue.ai:45554/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Clear you cache and cookies, then try reload the app.&lt;/li&gt; &#xA; &lt;li&gt;Report your issue &lt;a href=&#34;https://github.com/painebenjamin/app.enfugue.ai/issues&#34;&gt;in the issues tab&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If all else fails, you can always try deleting the &lt;code&gt;enfugue&lt;/code&gt; folder and &lt;code&gt;enfugue.db&lt;/code&gt; file in your &lt;code&gt;~/.cache&lt;/code&gt; directory to re-initialize the application.&lt;/p&gt; &#xA;&lt;h1&gt;FAQ&lt;/h1&gt; &#xA;&lt;h2&gt;What is &#34;Full FP32&#34;, &#34;Pruned PickleTensor&#34;, etc.?&lt;/h2&gt; &#xA;&lt;p&gt;These flags are the precision level and format of the model. In order to use all of Enfugue&#39;s features, Enfugue will change these formats and precisions as necessary, so in theory any of them will work the same as the other. In practice, if one is available, pick &lt;code&gt;Pruned&lt;/code&gt; and &lt;code&gt;FP16/Half&lt;/code&gt; for the fastest download and processes.&lt;/p&gt; &#xA;&lt;h2&gt;What are the best settings for the best images?&lt;/h2&gt; &#xA;&lt;p&gt;There is still much to be learned about generative AI in general, and Stable Diffusion in specific. A great starting point has been preconfigured in Enfugue, but there will be no one-size-fits-all set of parameters that works for every kind of image you want to generate. The best way to learn is simply to play with the values and see what the effect is on the final image.&lt;/p&gt; &#xA;&lt;h2&gt;Where can I learn more?&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/painebenjamin/app.enfugue.ai/wiki&#34;&gt;The Wiki&lt;/a&gt; (in progress)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/painebenjamin/app.enfugue.ai/discussions&#34;&gt;The Discussion Boards&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Additional resources will be made available as they are needed, so don&#39;t hesitate to ask for what you think will work best for you.&lt;/p&gt; &#xA;&lt;h1&gt;For Developers&lt;/h1&gt; &#xA;&lt;h2&gt;The Enfugue Diffusion Pipeline&lt;/h2&gt; &#xA;&lt;p&gt;Enfugue uses an extension of &lt;code&gt;transformers.StableDiffusionPipeline&lt;/code&gt; that provides a number of additional arguments over the typical signature, weaving between &lt;code&gt;txt2img&lt;/code&gt;, &lt;code&gt;img2img&lt;/code&gt;, &lt;code&gt;inpaint&lt;/code&gt; and &lt;code&gt;controlnet&lt;/code&gt; as necessary. It also has TensorRT support for all models in the pipeline. Start &lt;a href=&#34;https://github.com/painebenjamin/app.enfugue.ai/tree/main/src/python/enfugue&#34;&gt;here&lt;/a&gt; for documentation on how it is used.&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;For anyone interested in building from source themselves, simply check out this repository and issue a &lt;code&gt;make&lt;/code&gt; command to build the associated binary release. See below for all make targets.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Build Step&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Depends On&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;clean&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This target removes build artifacts.&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;typecheck&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This step runs &lt;code&gt;mypy&lt;/code&gt; against each source file. See &lt;a href=&#34;https://mypy-lang.org/&#34;&gt;mypy-lang.org&lt;/a&gt; for details on python static typing. Mypy is ran with the &lt;code&gt;--strict&lt;/code&gt; flag, meaning all constraints are opted in.&lt;/td&gt; &#xA;   &lt;td&gt;Python source files&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;importcheck&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This step runs &lt;code&gt;importcheck&lt;/code&gt; against each source file. See &lt;a href=&#34;https://github.com/python-coincidence/importcheck&#34;&gt;github&lt;/a&gt; for details on importcheck; simply put, it will produce an error if an imported module is not used.&lt;/td&gt; &#xA;   &lt;td&gt;Python source files&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;unittest&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This step runs &lt;code&gt;doctest&lt;/code&gt; against each source file. See &lt;a href=&#34;https://docs.python.org/3/library/doctest.html&#34;&gt;the Python Documentation&lt;/a&gt; for details on doctest. This will run all tests placed in docstrings, you will see these as python commands in the documentation, prepended by &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Python source files&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;test&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This step runs &lt;code&gt;enfugue.test.run&lt;/code&gt;. This will run the &lt;code&gt;main&lt;/code&gt; method in &lt;code&gt;&amp;lt;n&amp;gt;*.py&lt;/code&gt; files places in the &lt;code&gt;test&lt;/code&gt; directory.&lt;/td&gt; &#xA;   &lt;td&gt;Python source files, python test files&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;vendor&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This step fetches vendor resources by running all scripts under the &lt;code&gt;vendor/&lt;/code&gt; directory.&lt;/td&gt; &#xA;   &lt;td&gt;Script files&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;js&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This step compresses and mangles the &lt;code&gt;.mjs&lt;/code&gt; files using &lt;code&gt;terser&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;src/js/*.mjs&lt;/code&gt; files&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;css&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This step minifies all &lt;code&gt;css&lt;/code&gt; files using &lt;code&gt;cssminify&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;src/css/*.css&lt;/code&gt; files&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;html&lt;/strong&gt;, &lt;strong&gt;img&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;These step simply copy the relevant static directories (&lt;code&gt;/html&lt;/code&gt;, &lt;code&gt;/img&lt;/code&gt;) to the build directory.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;src/html/*.html&lt;/code&gt; files, &lt;code&gt;src/img/*.*&lt;/code&gt; files&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;sdist&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This step compiles the source distribution into an installable &lt;code&gt;.tar.gz&lt;/code&gt; file, suitable for passing to &lt;code&gt;pip install&lt;/code&gt;. Contains all the results of the previous steps&lt;/td&gt; &#xA;   &lt;td&gt;Python source files, passing &lt;code&gt;typecheck&lt;/code&gt;, &lt;code&gt;importcheck&lt;/code&gt;, &lt;code&gt;unittest&lt;/code&gt;, and &lt;code&gt;test&lt;/code&gt;, running &lt;code&gt;vendor&lt;/code&gt;, compiling &lt;code&gt;js&lt;/code&gt;, &lt;code&gt;css&lt;/code&gt;, &lt;code&gt;html&lt;/code&gt;, and &lt;code&gt;img&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;dist&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This step compiles the relevant executable artifact (and zips/tars it).&lt;/td&gt; &#xA;   &lt;td&gt;sdist&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Running directly from Source&lt;/h2&gt; &#xA;&lt;p&gt;To run directly from source (in development mode,) use the &lt;code&gt;scripts/run-dev.sh&lt;/code&gt; script. This works on Windows (in Cygwin) and on Linux.&lt;/p&gt;</summary>
  </entry>
</feed>