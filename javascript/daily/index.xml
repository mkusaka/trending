<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-25T01:36:53Z</updated>
  <subtitle>Daily Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>vanjs-org/van</title>
    <updated>2023-05-25T01:36:53Z</updated>
    <id>tag:github.com,2023-05-25:/vanjs-org/van</id>
    <link href="https://github.com/vanjs-org/van" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üç¶VanJS (Vanilla JavaScript): World&#39;s smallest reactive UI framework&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üç¶ &lt;strong&gt;VanJS&lt;/strong&gt;: The Smallest Reactive UI Framework in the World&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;VanJS&lt;/strong&gt; (abbr. &lt;strong&gt;Van&lt;/strong&gt;illa &lt;strong&gt;J&lt;/strong&gt;ava&lt;strong&gt;S&lt;/strong&gt;cript) is an &lt;em&gt;&lt;strong&gt;ultra-lightweight&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;zero-dependency&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;unopinionated&lt;/strong&gt;&lt;/em&gt; Reactive UI framework based on pure vanilla JavaScript and DOM. Programming with &lt;strong&gt;VanJS&lt;/strong&gt; feels a lot like React. Check-out the &lt;code&gt;Hello World&lt;/code&gt; code below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// Reusable components can be just pure vanilla JavaScript functions.&#xA;// Here we capitalize the first letter to follow React conventions.&#xA;const Hello = () =&amp;gt; div(&#xA;  p(&#34;üëãHello&#34;),&#xA;  ul(&#xA;    li(&#34;üó∫Ô∏èWorld&#34;),&#xA;    li(a({href: &#34;https://vanjs.org/&#34;}, &#34;üç¶VanJS&#34;)),&#xA;  ),&#xA;)&#xA;&#xA;van.add(document.body, Hello())&#xA;// Alternatively, you can write:&#xA;// document.body.appendChild(Hello())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://jsfiddle.net/gh/get/library/pure/vanjs-org/vanjs-org.github.io/tree/master/jsfiddle/home/hello&#34;&gt;Try on jsfiddle&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can convert any HTML snippet into &lt;strong&gt;VanJS&lt;/strong&gt; code with our online &lt;a href=&#34;https://vanjs.org/convert&#34;&gt;converter&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;VanJS&lt;/strong&gt; helps you manage state and UI binding as well, with a more natural API:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const Counter = () =&amp;gt; {&#xA;  const counter = van.state(0)&#xA;  return div(&#xA;    &#34;‚ù§Ô∏è &#34;, counter, &#34; &#34;,&#xA;    button({onclick: () =&amp;gt; ++counter.val}, &#34;üëç&#34;),&#xA;    button({onclick: () =&amp;gt; --counter.val}, &#34;üëé&#34;),&#xA;  )&#xA;}&#xA;&#xA;van.add(document.body, Counter())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://jsfiddle.net/gh/get/library/pure/vanjs-org/vanjs-org.github.io/tree/master/jsfiddle/home/counter&#34;&gt;Try on jsfiddle&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Why VanJS?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;VanJS&lt;/strong&gt; has the vision to be the &lt;a href=&#34;https://vanjs.org/about#story&#34;&gt;scripting language&lt;/a&gt; for UI, just like &lt;code&gt;bash&lt;/code&gt; is the scripting language for terminal. &lt;strong&gt;VanJS&lt;/strong&gt; empowers frontend engineers, backend engineers, system engineers, data scientists, and anyone else to build comprehensive user interfaces. You can code with &lt;strong&gt;VanJS&lt;/strong&gt; anywhere, any time, and on any device ‚Äì &lt;em&gt;even on your smartphone!&lt;/em&gt; üëèüëèüëè&lt;/p&gt; &#xA;&lt;h3&gt;Reactive Programming without React/JSX&lt;/h3&gt; &#xA;&lt;p&gt;Declarative DOM tree composition, reusable components, reactive state binding - &lt;strong&gt;VanJS&lt;/strong&gt; offers every good aspect that React does, but without the need of React, JSX, transpiling, virtual DOM, or any hidden logic. Everything is built with simple JavaScript functions and DOM.&lt;/p&gt; &#xA;&lt;h3&gt;Grab &#39;n Go&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;No installation&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;no configuration&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;no 3rd-party dependencies&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;no transpiling&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;no IDE setups&lt;/strong&gt;&lt;/em&gt;. Adding a line to your script or HTML file is all you need to start coding. &lt;strong&gt;VanJS&lt;/strong&gt; allows you to focus on the business logic of your application, rather than getting bogged down in frameworks and tools.&lt;/p&gt; &#xA;&lt;h3&gt;Ultra-Lightweight&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;VanJS&lt;/strong&gt; is a very thin layer on top of Vanilla JavaScript and DOM, barely enough to make the DOM manipulation and state binding as ergonomic as (if not more than) React, and it delegates most of work to standard browser APIs implemented in native code. As a result, the bundled size of &lt;strong&gt;VanJS&lt;/strong&gt; is just 1.2kB, which is &lt;strong&gt;more than 100 times&lt;/strong&gt; smaller than most popular UI frameworks:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/vanjs-org/van/main/doc/size_comp.png&#34; alt=&#34;Size comparison&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;em&gt;Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.&lt;/em&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;em&gt;-- Antoine de Saint-Exup√©ry, Airman&#39;s Odyssey&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;TypeScript Support&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;VanJS&lt;/strong&gt; provides first-class support for TypeScript. Simply download the corresponding &lt;code&gt;.d.ts&lt;/code&gt; file along with your &lt;code&gt;.js&lt;/code&gt; file, and you&#39;ll be able to take advantage of type-checking, IntelliSense, large-scale refactoring provided by your preferred development environment. Refer to the &lt;a href=&#34;https://vanjs.org/start#download-table&#34;&gt;Download Table&lt;/a&gt; to find the right &lt;code&gt;.d.ts&lt;/code&gt; file to work with.&lt;/p&gt; &#xA;&lt;h3&gt;Easy to Learn&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;VanJS&lt;/strong&gt; puts heavy emphasis on the simplicity of the framework. There are only 4 exported functions in the API and feels a lot like React. Because of that, the &lt;a href=&#34;https://vanjs.org/tutorial&#34;&gt;walkthrough tutorial&lt;/a&gt; is the same as the full API referrence, and can be learned within 1 hour for most developers.&lt;/p&gt; &#xA;&lt;h2&gt;Want to Learn More?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download and &lt;a href=&#34;https://vanjs.org/start&#34;&gt;Get Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Learn from the &lt;a href=&#34;https://vanjs.org/tutorial&#34;&gt;Tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Learn by &lt;a href=&#34;https://vanjs.org/demo&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Convert HTML snippet to &lt;strong&gt;VanJS&lt;/strong&gt; code with our online &lt;a href=&#34;https://vanjs.org/convert&#34;&gt;HTML to &lt;strong&gt;VanJS&lt;/strong&gt; Converter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Want server-side rendering? Check out &lt;a href=&#34;https://github.com/vanjs-org/mini-van&#34;&gt;Mini-Van&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;For questions, feedback or general discussions, visit our &lt;a href=&#34;https://github.com/vanjs-org/van/discussions&#34;&gt;Discussions&lt;/a&gt; page&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support &amp;amp; Feedback&lt;/h2&gt; &#xA;&lt;p&gt;üôè &lt;strong&gt;VanJS&lt;/strong&gt; aims to build a better world by reducing the entry barrier for UI programming, with no intention or plan on commercialization whatsoever. If you find &lt;strong&gt;VanJS&lt;/strong&gt; interesting, or could be useful for you some day, please consider starring the project. It takes just a few seconds but your support means the world to us and helps spread &lt;strong&gt;VanJS&lt;/strong&gt; to a wider audience.&lt;/p&gt; &#xA;&lt;p&gt;We&#39;re looking for the 1.0 milestone (commitment to API stability) soon, your precious feedback will be greatly appreciated. You can submit your feedback in our &lt;a href=&#34;https://github.com/vanjs-org/van/discussions&#34;&gt;Discussions&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;p&gt;Contact us: &lt;a href=&#34;mailto:tao@vanjs.org&#34;&gt;tao@vanjs.org&lt;/a&gt; / &lt;a href=&#34;https://www.linkedin.com/in/tao-xin-64234920/&#34;&gt;Tao Xin&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Ordered chronologically by first contribution:&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tao-VanJS&#34;&gt;Tao Xin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ryanolsonx&#34;&gt;Ryan Olson&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tamo&#34;&gt;Tamotsu Takahashi&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>mlc-ai/web-llm</title>
    <updated>2023-05-25T01:36:53Z</updated>
    <id>tag:github.com,2023-05-25:/mlc-ai/web-llm</id>
    <link href="https://github.com/mlc-ai/web-llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bringing large-language models and chat to web browsers. Everything runs inside the browser with no server support.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Web LLM&lt;/h1&gt; &#xA;&lt;p&gt;This project brings language model chats directly onto web browsers. &lt;strong&gt;Everything runs inside the browser with no server support and accelerated with WebGPU.&lt;/strong&gt; We can bring a lot of fun opportunities to build AI assistants for everyone and enable privacy while enjoying GPU acceleration.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://mlc.ai/web-llm/&#34;&gt;Check out our demo webpage to try out!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You might also be interested in &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm&#34;&gt;MLC LLM&lt;/a&gt;, our companion project that runs LLMs natively on iphone and other native local environments.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/web-llm/main/site/img/fig/demo.gif&#34;&gt; &#xA;&lt;p&gt;We have been seeing amazing progress in generative AI and LLM recently. Thanks to the open-source efforts like LLaMA, Alpaca, Vicuna, and Dolly, we can now see an exciting future of building our own open-source language models and personal AI assistant.&lt;/p&gt; &#xA;&lt;p&gt;These models are usually big and compute-heavy. To build a chat service, we will need a large cluster to run an inference server, while clients send requests to servers and retrieve the inference output. We also usually have to run on a specific type of GPUs where popular deep-learning frameworks are readily available.&lt;/p&gt; &#xA;&lt;p&gt;This project is our step to bring more diversity to the ecosystem. Specifically, can we simply bake LLMs directly into the client side and directly run them inside a browser? If that can be realized, we could offer support for client personal AI models with the benefit of cost reduction, enhancement for personalization, and privacy protection. The client side is getting pretty powerful.&lt;/p&gt; &#xA;&lt;p&gt;Won‚Äôt it be even more amazing if we can simply open up a browser and directly bring AI natively to your browser tab? There is some level of readiness in the ecosystem. WebGPU has just shipped and enables native GPU executions on the browser.&lt;/p&gt; &#xA;&lt;p&gt;Still, there are big hurdles to cross, to name a few:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We need to bring the models somewhere without the relevant GPU-accelerated Python frameworks.&lt;/li&gt; &#xA; &lt;li&gt;Most of the AI frameworks rely heavily on optimized computed libraries that are maintained by hardware vendors. We need to start from scratch.&lt;/li&gt; &#xA; &lt;li&gt;Careful planning of memory usage, and aggressive compression of weights so that we can fit the models into memory.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We also do not want to only do it for just one model. Instead, we would like to present a repeatable and hackable workflow that enables anyone to easily develop and optimize these models in a productive Python-first approach, and deploy them universally, including on the web.&lt;/p&gt; &#xA;&lt;p&gt;Besides supporting WebGPU, this project also provides the harness for other kinds of GPU backends that TVM supports (such as CUDA, OpenCL, and Vulkan) and really enables accessible deployment of LLM models.&lt;/p&gt; &#xA;&lt;h2&gt;Instructions for local deployment&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install TVM Unity. Open &lt;a href=&#34;https://mlc.ai/wheels&#34;&gt;mlc.ai wheels&lt;/a&gt; for more version.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install all the prerequisite for web deployment:&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://emscripten.org&#34;&gt;emscripten&lt;/a&gt;. It is an LLVM-based compiler which compiles C/C++ source code to WebAssembly. &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Follow the &lt;a href=&#34;https://emscripten.org/docs/getting_started/downloads.html#installation-instructions-using-the-emsdk-recommended&#34;&gt;installation instruction&lt;/a&gt; to install the latest emsdk.&lt;/li&gt; &#xA;     &lt;li&gt;Source &lt;code&gt;emsdk_env.sh&lt;/code&gt; by &lt;code&gt;source path/to/emsdk_env.sh&lt;/code&gt;, so that &lt;code&gt;emcc&lt;/code&gt; is reachable from PATH and the command &lt;code&gt;emcc&lt;/code&gt; works.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.rust-lang.org/tools/install&#34;&gt;Rust&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rustwasm.github.io/wasm-pack/installer/&#34;&gt;&lt;code&gt;wasm-pack&lt;/code&gt;&lt;/a&gt;. It helps build Rust-generated WebAssembly, which used for tokenizer in our case here.&lt;/li&gt; &#xA;   &lt;li&gt;Install jekyll by following the &lt;a href=&#34;https://jekyllrb.com/docs/installation/&#34;&gt;official guides&lt;/a&gt;. It is the package we use for website.&lt;/li&gt; &#xA;   &lt;li&gt;Install jekyll-remote-theme by command. Try &lt;a href=&#34;https://gems.ruby-china.com/&#34;&gt;gem mirror&lt;/a&gt; if install blocked. &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;gem install jekyll-remote-theme&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Install &lt;a href=&#34;https://www.google.com/chrome/&#34;&gt;Chrome&lt;/a&gt; with version at least 113. WebGPU has shipped to Chrome in version 113.&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;p&gt;We can verify the success installation by trying out &lt;code&gt;emcc&lt;/code&gt;, &lt;code&gt;jekyll&lt;/code&gt; and &lt;code&gt;wasm-pack&lt;/code&gt; in terminal respectively.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Import, optimize and build the LLM model:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Get Model Weight&lt;/p&gt; &lt;p&gt;Currently we support LLaMA and Vicuna and RedPajama. To get the Vicuna model weights, follow the instructions below:&lt;/p&gt; &#xA;    &lt;ol&gt; &#xA;     &lt;li&gt; &lt;p&gt;Get the original LLaMA weights in the huggingface format by following the instructions &lt;a href=&#34;https://huggingface.co/docs/transformers/main/model_doc/llama&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;Use instructions &lt;a href=&#34;https://github.com/lm-sys/FastChat#vicuna-weights&#34;&gt;here&lt;/a&gt; to get vicuna weights&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;Create a soft link to the model path under mlc-llm/dist/models.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir -p mlc-llm/dist/models&#xA;ln -s your_model_path mlc-llm/dist/models/model_name&#xA;&#xA;# For example:&#xA;# ln -s path/to/vicuna-v1-7b mlc-llm/dist/models/vicuna-v1-7b&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you want to use your own mlc-llm branch, set &lt;code&gt;MLC_LLM_HOME&lt;/code&gt; to that path and link weights under &lt;code&gt;$MLC_LLM_HOME/dist/models/model_name&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ol&gt; &lt;p&gt;You can download the RedPajama weights from the HuggingFace repo &lt;a href=&#34;https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Optimize and build the models to WebGPU backend and export the executable to disk in the WebAssembly file format.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;./build.sh --model=vicuna-v1-7b --quantization q4f32_0&#xA;./build.sh --model=RedPajama-INCITE-Chat-3B-v1 --quantization q4f32_0&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note: build.py for Vicuna-v1-7B requires 16GB of memory for Mac, and about 30GB CPU memory for other OS. We are continuously optimizing for reducing build memory requirement to enable more people to try out locally.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Deploy the model on web with WebGPU runtime&lt;/p&gt; &lt;p&gt;Prepare all the necessary dependencies for web build:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;./scripts/prep_deps.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The last thing to do is setting up the site with:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;./scripts/local_deploy_site.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With the site set up, you can go to &lt;code&gt;localhost:8888/web-llm/&lt;/code&gt; in Chrome to try out the demo on your local machine. You will need around 6GB GPU memory to run the Vicuna model, or 3GB GPU memory to run the RedPajama model. You can use&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --enable-dawn-features=disable_robustness&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;to launch Chrome from the command line to turn off the robustness check from Chrome and enable better performance.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;How&lt;/h2&gt; &#xA;&lt;p&gt;The key technology here is machine learning compilation (MLC). Our solution builds on the shoulders of the open source ecosystem, including Hugging Face, model variants from LLaMA and Vicuna, wasm and WebGPU. The main flow builds on Apache TVM Unity, an exciting ongoing development in the &lt;a href=&#34;https://github.com/apache/tvm/&#34;&gt;Apache TVM Community&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We bake a language model&#39;s IRModule in TVM with native dynamic shape support, avoiding the need of padding to max length and reducing both computation amount and memory usage.&lt;/li&gt; &#xA; &lt;li&gt;Each function in TVM‚Äôs IRModule can be further transformed and generate runnable code that can be deployed universally on any environment that is supported by minimum tvm runtime (JavaScript being one of them).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.04296&#34;&gt;TensorIR&lt;/a&gt; is the key technique used to generate optimized programs. We provide productive solutions by quickly transforming TensorIR programs based on the combination of expert knowledge and automated scheduler.&lt;/li&gt; &#xA; &lt;li&gt;Heuristics are used when optimizing light-weight operators in order to reduce the engineering pressure.&lt;/li&gt; &#xA; &lt;li&gt;We utilize int4 quantization techniques to compress the model weights so that they can fit into memory.&lt;/li&gt; &#xA; &lt;li&gt;We build static memory planning optimizations to reuse memory across multiple layers.&lt;/li&gt; &#xA; &lt;li&gt;We use &lt;a href=&#34;https://emscripten.org/&#34;&gt;Emscripten&lt;/a&gt; and TypeScript to build a TVM web runtime that can deploy generated modules.&lt;/li&gt; &#xA; &lt;li&gt;We also leveraged a wasm port of SentencePiece tokenizer.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/web-llm/main/site/img/fig/web-llm.svg?sanitize=true&#34; alt=&#34;web-llm&#34;&gt; &#xA;&lt;p&gt;All parts of this workflow are done in Python, with the exception of course, of the last part that builds a 600 loc JavaScript app that connects things together. This is also a fun process of interactive development, bringing new models.&lt;/p&gt; &#xA;&lt;p&gt;All these are made possible by the open-source ecosystem that we leverage. Specifically, we make heavy use of &lt;a href=&#34;https://discuss.tvm.apache.org/t/establish-tvm-unity-connection-a-technical-strategy/13344&#34;&gt;TVM unity&lt;/a&gt;, an exciting latest development in the TVM project that enables such Python-first interactive MLC development experiences that allows us to easily compose new optimizations, all in Python, and incrementally bring our app to the web.&lt;/p&gt; &#xA;&lt;p&gt;TVM unity also provides an easy way to compose new solutions in the ecosystem. We will continue to bring further optimizations such as fused quantization kernels, and bring them to more platforms.&lt;/p&gt; &#xA;&lt;p&gt;One key characteristic of LLM models is the dynamic nature of the model. As the decoding and prefill process depends on computations that grow with the size of tokens, we leverage the first-class dynamic shape support in TVM unity that represents sequence dimensions through symbolic integers. This allows us to plan ahead to statically allocate all the memory needed for the sequence window of interest without padding.&lt;/p&gt; &#xA;&lt;p&gt;We also leveraged the integration of tensor expressions to quickly express partial-tensor computations such as rotary embedding directly without materializing them into full-tensor matrix computations.&lt;/p&gt; &#xA;&lt;h2&gt;Comparison to Native GPU Runtime, Limitations and Opportunities&lt;/h2&gt; &#xA;&lt;p&gt;Besides the WebGPU runtime, we also provide options for native deployment with local GPU runtime. So they can be used both as a tool to deploy on native environment as well as a reference point to compare native GPU driver performance and WebGPU.&lt;/p&gt; &#xA;&lt;p&gt;WebGPU works by translating WGSL shaders to native shaders. We observed that there are opportunities to reach zero gap between the WebGPU runtime and native environment.&lt;/p&gt; &#xA;&lt;p&gt;Some of the current gaps are caused by Chrome&#39;s WebGPU implementation inserts bound clips for all array index access, such that &lt;code&gt;a[i]&lt;/code&gt; becomes &lt;code&gt;a[min(i, a.size)]&lt;/code&gt;. This can be optimized out as the WebGPU support continues to mature.&lt;/p&gt; &#xA;&lt;p&gt;You can get around this by using a special flag to launch Chrome (thanks to Dawn developers for providing the pointers), by exiting Chrome completely, then in command line, type:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;/path/to/Chrome --enable-dawn-features=disable_robustness&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then you will find that the execution speed is as fast as native GPU environment. We anticipate this problem will get resolved as WebGPU matures. WebGPU just shipped and we are excited to see opportunities it can unblock. There are also a lot of exciting upcoming features we can leverage to further improve things such as fp16 extensions.&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mlc.ai/web-llm/&#34;&gt;Demo page&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you want to run LLM on native runtime, check out &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm&#34;&gt;MLC-LLM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;You might also be interested in &lt;a href=&#34;https://github.com/mlc-ai/web-stable-diffusion/&#34;&gt;Web Stable Diffusion&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This project is initiated by members from CMU catalyst, UW SAMPL, SJTU, OctoML and the MLC community. We would love to continue developing and supporting the open-source ML community.&lt;/p&gt; &#xA;&lt;a href=&#34;https://www.scs.cmu.edu&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/web-llm/main/site/img/logo/cmuscs.png&#34; alt=&#34;CMU School of Computer Science&#34; height=&#34;60&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://catalyst.cs.cmu.edu&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/web-llm/main/site/img/logo/catalyst.svg?sanitize=true&#34; alt=&#34;Catalyst&#34; height=&#34;60&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://mlc.ai&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/web-llm/main/site/img/logo/mlc-logo-with-text-landscape.svg?sanitize=true&#34; alt=&#34;MLC&#34; height=&#34;60&#34;&gt; &lt;/a&gt; &#xA;&lt;br&gt; &#xA;&lt;a href=&#34;https://octoml.ai&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/web-llm/main/site/img/logo/octoml.png&#34; alt=&#34;OctoML&#34; height=&#34;60&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://www.cs.washington.edu/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/web-llm/main/site/img/logo/uw.jpg&#34; alt=&#34;UW&#34; height=&#34;60&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://en.sjtu.edu.cn/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/web-llm/main/site/img/logo/sjtu.png&#34; alt=&#34;SJTU&#34; height=&#34;60&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;This project is only possible thanks to the shoulders open-source ecosystems that we stand on. We want to thank the Apache TVM community and developers of the TVM Unity effort. The open-source ML community members made these models publicly available. PyTorch and Hugging Face communities that make these models accessible. We would like to thank the teams behind vicuna, SentencePiece, LLaMA, Alpaca. We also would like to thank the WebAssembly, Emscripten, and WebGPU communities. Finally, thanks to Dawn and WebGPU developers.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Spyware007/Animating-Buttons</title>
    <updated>2023-05-25T01:36:53Z</updated>
    <id>tag:github.com,2023-05-25:/Spyware007/Animating-Buttons</id>
    <link href="https://github.com/Spyware007/Animating-Buttons" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Explore Amazing Buttons animation for your next project. ü§©An initiative by GDSC-DYPCOE for Hactoberfest. üöÄ&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img width=&#34;300&#34; alt=&#34;Screenshot 2022-10-15 at 1 19 54 PM&#34; src=&#34;https://user-images.githubusercontent.com/89961974/195978518-289c02ba-5643-4424-ab5e-d7947a09140c.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div id=&#34;top&#34;&gt; &#xA; &lt;h1&gt;‚úÖ Animation Buttons&lt;/h1&gt; &#xA; &lt;p&gt;Welcome to the Animating Buttons repository! üéâ&lt;/p&gt; &#xA; &lt;p&gt;This project aims to provide a collection of animated buttons that you can use to enhance your web development projects. Whether you&#39;re a beginner or an experienced developer, these buttons will add a touch of interactivity and flair to your websites.&lt;/p&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt;‚ú®‚ú®HacktoberFest 2022‚ú®‚ú®&lt;/h1&gt; &#xA; &lt;img width=&#34;1440&#34; alt=&#34;Screenshot 2022-10-15 at 1 19 54 PM&#34; src=&#34;https://user-images.githubusercontent.com/89961974/195976027-407986aa-6865-4462-859d-b5e4d2deeb64.png&#34;&gt; &#xA; &lt;h2&gt;What can You Contribute ‚ö†Ô∏è&lt;/h2&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;You can contribute any animated buttons. ü§©&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;You can update or refine an existing animated button or even add your own new buttons in this repo. üöÄ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Make sure you follow the below steps before making your contributions‚ùó‚ùó‚ùó&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Spyware007/Animating-Buttons/main/#top&#34;&gt; Back to top&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h3&gt;Firstly&lt;/h3&gt; &#xA; &lt;h3&gt;üì¢ Register &lt;a href=&#34;https://hacktoberfest.com/&#34;&gt;here&lt;/a&gt; for Hacktoberfest and make 4Ô∏è‚É£ PRs this month to grab free SWAGS üî•&lt;/h3&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Fork this repo &#xA;   &lt;!-- Place this tag where you want the button to render. --&gt; &lt;a class=&#34;github-button&#34; href=&#34;https://github.com/Spyware007/Animating-Buttons/fork&#34; data-color-scheme=&#34;no-preference: light_high_contrast; light: light_high_contrast; dark: dark;&#34; data-icon=&#34;octicon-repo-forked&#34; data-size=&#34;large&#34; data-show-count=&#34;true&#34; aria-label=&#34;Fork Princeton21/Data-Structures-and-Algorithms on GitHub&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Clone on your local machine&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-terminal&#34;&gt;git clone https://github.com/**username**/Animating-Buttons.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Navigate to project directory.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-terminal&#34;&gt;cd Animating-Buttons&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-terminal&#34;&gt;npm i&#xA;npm start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Create a new Branch&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code&gt;git checkout -b my-new-branch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;üöÄüöÄ &lt;strong&gt;Go to &lt;a href=&#34;https://github.com/Spyware007/Animating-Buttons/raw/main/src/components/Main/Main.jsx&#34;&gt;public/Buttons&lt;/a&gt; folder and add a new folder with your GitHub username including your button code (index.html + style.css files)&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;Then go to &lt;a href=&#34;https://github.com/Spyware007/Animating-Buttons/raw/main/src/Data.js&#34;&gt;src/Data.js&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Add your folder name (github_username, github_username_1,etc) code in &lt;a href=&#34;https://github.com/Spyware007/Animating-Buttons/raw/main/src/Data.js&#34;&gt;src/Data.js&lt;/a&gt; file.&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Spyware007/Animating-Buttons/main/#top&#34;&gt; Back to top&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h1&gt;Note:&lt;/h1&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;Make sure to align your button centered horizontally as well as vertically.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Don&#39;t forget to replace &#39;your_github_username&#39; with GitHub Username.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;If you are adding more than one buttons then give proper names such as Spyware007_1,Spyware007_2, your_github_username_1,etc&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Stage your changes.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code&gt;git add .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Commit your changes.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code&gt;git commit -m &#34;Relevant message&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Then push&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code&gt;git push origin my-new-branch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Finally, create a new pull request from your forked repository&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;hr&gt; &#xA; &lt;hr&gt; &#xA; &lt;h3&gt;PLEASE NOTE&lt;/h3&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Make sure you commit your changes in a new branch‚ùó‚ùó&lt;/li&gt; &#xA;  &lt;li&gt;Make sure that your file name and your commit message are relevant.&lt;/li&gt; &#xA;  &lt;li&gt;Also, make sure you comment your code wherever necessary.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;hr&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Spyware007/Animating-Buttons/main/#top&#34;&gt; Back to top&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h1&gt;Our Beloved Contributors üòç&lt;/h1&gt; &#xA; &lt;hr&gt; &#xA; &lt;a href=&#34;https://github.com/Spyware007/Animating-Buttons/graphs/contributors&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://contrib.rocks/image?max=100&amp;amp;repo=Spyware007/Animating-Buttons&#34;&gt; &lt;/a&gt; &#xA; &lt;hr&gt; &#xA; &lt;p&gt;A big thank you to all our contributors who have made this project better with their valuable contributions! We appreciate your efforts and dedication.&lt;/p&gt; &#xA; &lt;p&gt;Don&#39;t forget to ‚≠ê this repository to show your support!&lt;/p&gt; &#xA; &lt;hr&gt; &#xA; &lt;h3 align=&#34;center&#34;&gt; DON&#39;T FORGET TO ‚≠ê THIS REPOSITORY !! &lt;/h3&gt; &#xA; &lt;h3&gt;You can follow me &lt;a href=&#34;https://github.com/Spyware007&#34;&gt;here&lt;/a&gt; ‚ù§&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Spyware007/Animating-Buttons/main/#top&#34;&gt; Back to top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
</feed>