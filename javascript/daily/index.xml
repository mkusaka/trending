<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-03-11T01:31:58Z</updated>
  <subtitle>Daily Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mendableai/firecrawl-mcp-server</title>
    <updated>2025-03-11T01:31:58Z</updated>
    <id>tag:github.com,2025-03-11:/mendableai/firecrawl-mcp-server</id>
    <link href="https://github.com/mendableai/firecrawl-mcp-server" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official Firecrawl MCP Server - Adds powerful web scraping to Cursor, Claude and any other LLM clients.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Firecrawl MCP Server&lt;/h1&gt; &#xA;&lt;p&gt;A Model Context Protocol (MCP) server implementation that integrates with &lt;a href=&#34;https://github.com/mendableai/firecrawl&#34;&gt;Firecrawl&lt;/a&gt; for web scraping capabilities.&lt;/p&gt; &#xA;&lt;p&gt;Big thanks to &lt;a href=&#34;https://github.com/vrknetha&#34;&gt;@vrknetha&lt;/a&gt;, &lt;a href=&#34;https://caw.tech&#34;&gt;@cawstudios&lt;/a&gt; for the initial implementation!&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scrape, crawl, search, extract, deep research and batch scrape support&lt;/li&gt; &#xA; &lt;li&gt;Web scraping with JS rendering&lt;/li&gt; &#xA; &lt;li&gt;URL discovery and crawling&lt;/li&gt; &#xA; &lt;li&gt;Web search with content extraction&lt;/li&gt; &#xA; &lt;li&gt;Automatic retries with exponential backoff&lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Efficient batch processing with built-in rate limiting&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Credit usage monitoring for cloud API&lt;/li&gt; &#xA; &lt;li&gt;Comprehensive logging system&lt;/li&gt; &#xA; &lt;li&gt;Support for cloud and self-hosted FireCrawl instances&lt;/li&gt; &#xA; &lt;li&gt;Mobile/Desktop viewport support&lt;/li&gt; &#xA; &lt;li&gt;Smart content filtering with tag inclusion/exclusion&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Running with npx&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;env FIRECRAWL_API_KEY=fc-YOUR_API_KEY npx -y firecrawl-mcp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Manual Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install -g firecrawl-mcp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running on Cursor&lt;/h3&gt; &#xA;&lt;p&gt;Configuring Cursor üñ•Ô∏è Note: Requires Cursor version 0.45.6+&lt;/p&gt; &#xA;&lt;p&gt;To configure FireCrawl MCP in Cursor:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open Cursor Settings&lt;/li&gt; &#xA; &lt;li&gt;Go to Features &amp;gt; MCP Servers&lt;/li&gt; &#xA; &lt;li&gt;Click &#34;+ Add New MCP Server&#34;&lt;/li&gt; &#xA; &lt;li&gt;Enter the following: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Name: &#34;firecrawl-mcp&#34; (or your preferred name)&lt;/li&gt; &#xA;   &lt;li&gt;Type: &#34;command&#34;&lt;/li&gt; &#xA;   &lt;li&gt;Command: &lt;code&gt;env FIRECRAWL_API_KEY=your-api-key npx -y firecrawl-mcp&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;If you are using Windows and are running into issues, try &lt;code&gt;cmd /c &#34;set FIRECRAWL_API_KEY=your-api-key &amp;amp;&amp;amp; npx -y firecrawl-mcp&#34;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Replace &lt;code&gt;your-api-key&lt;/code&gt; with your FireCrawl API key.&lt;/p&gt; &#xA;&lt;p&gt;After adding, refresh the MCP server list to see the new tools. The Composer Agent will automatically use FireCrawl MCP when appropriate, but you can explicitly request it by describing your web scraping needs. Access the Composer via Command+L (Mac), select &#34;Agent&#34; next to the submit button, and enter your query.&lt;/p&gt; &#xA;&lt;h3&gt;Running on Windsurf&lt;/h3&gt; &#xA;&lt;p&gt;Add this to your &lt;code&gt;./codeium/windsurf/model_config.json&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;mcpServers&#34;: {&#xA;    &#34;mcp-server-firecrawl&#34;: {&#xA;      &#34;command&#34;: &#34;npx&#34;,&#xA;      &#34;args&#34;: [&#34;-y&#34;, &#34;firecrawl-mcp&#34;],&#xA;      &#34;env&#34;: {&#xA;        &#34;FIRECRAWL_API_KEY&#34;: &#34;YOUR_API_KEY_HERE&#34;&#xA;      }&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Installing via Smithery (Legacy)&lt;/h3&gt; &#xA;&lt;p&gt;To install FireCrawl for Claude Desktop automatically via &lt;a href=&#34;https://smithery.ai/server/@mendableai/mcp-server-firecrawl&#34;&gt;Smithery&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npx -y @smithery/cli install @mendableai/mcp-server-firecrawl --client claude&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;h3&gt;Environment Variables&lt;/h3&gt; &#xA;&lt;h4&gt;Required for Cloud API&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;FIRECRAWL_API_KEY&lt;/code&gt;: Your FireCrawl API key &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Required when using cloud API (default)&lt;/li&gt; &#xA;   &lt;li&gt;Optional when using self-hosted instance with &lt;code&gt;FIRECRAWL_API_URL&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;FIRECRAWL_API_URL&lt;/code&gt; (Optional): Custom API endpoint for self-hosted instances &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: &lt;code&gt;https://firecrawl.your-domain.com&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;If not provided, the cloud API will be used (requires API key)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Optional Configuration&lt;/h4&gt; &#xA;&lt;h5&gt;Retry Configuration&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;FIRECRAWL_RETRY_MAX_ATTEMPTS&lt;/code&gt;: Maximum number of retry attempts (default: 3)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;FIRECRAWL_RETRY_INITIAL_DELAY&lt;/code&gt;: Initial delay in milliseconds before first retry (default: 1000)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;FIRECRAWL_RETRY_MAX_DELAY&lt;/code&gt;: Maximum delay in milliseconds between retries (default: 10000)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;FIRECRAWL_RETRY_BACKOFF_FACTOR&lt;/code&gt;: Exponential backoff multiplier (default: 2)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;Credit Usage Monitoring&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;FIRECRAWL_CREDIT_WARNING_THRESHOLD&lt;/code&gt;: Credit usage warning threshold (default: 1000)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;FIRECRAWL_CREDIT_CRITICAL_THRESHOLD&lt;/code&gt;: Credit usage critical threshold (default: 100)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Configuration Examples&lt;/h3&gt; &#xA;&lt;p&gt;For cloud API usage with custom retry and credit monitoring:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Required for cloud API&#xA;export FIRECRAWL_API_KEY=your-api-key&#xA;&#xA;# Optional retry configuration&#xA;export FIRECRAWL_RETRY_MAX_ATTEMPTS=5        # Increase max retry attempts&#xA;export FIRECRAWL_RETRY_INITIAL_DELAY=2000    # Start with 2s delay&#xA;export FIRECRAWL_RETRY_MAX_DELAY=30000       # Maximum 30s delay&#xA;export FIRECRAWL_RETRY_BACKOFF_FACTOR=3      # More aggressive backoff&#xA;&#xA;# Optional credit monitoring&#xA;export FIRECRAWL_CREDIT_WARNING_THRESHOLD=2000    # Warning at 2000 credits&#xA;export FIRECRAWL_CREDIT_CRITICAL_THRESHOLD=500    # Critical at 500 credits&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For self-hosted instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Required for self-hosted&#xA;export FIRECRAWL_API_URL=https://firecrawl.your-domain.com&#xA;&#xA;# Optional authentication for self-hosted&#xA;export FIRECRAWL_API_KEY=your-api-key  # If your instance requires auth&#xA;&#xA;# Custom retry configuration&#xA;export FIRECRAWL_RETRY_MAX_ATTEMPTS=10&#xA;export FIRECRAWL_RETRY_INITIAL_DELAY=500     # Start with faster retries&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage with Claude Desktop&lt;/h3&gt; &#xA;&lt;p&gt;Add this to your &lt;code&gt;claude_desktop_config.json&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;mcpServers&#34;: {&#xA;    &#34;mcp-server-firecrawl&#34;: {&#xA;      &#34;command&#34;: &#34;npx&#34;,&#xA;      &#34;args&#34;: [&#34;-y&#34;, &#34;firecrawl-mcp&#34;],&#xA;      &#34;env&#34;: {&#xA;        &#34;FIRECRAWL_API_KEY&#34;: &#34;YOUR_API_KEY_HERE&#34;,&#xA;&#xA;        &#34;FIRECRAWL_RETRY_MAX_ATTEMPTS&#34;: &#34;5&#34;,&#xA;        &#34;FIRECRAWL_RETRY_INITIAL_DELAY&#34;: &#34;2000&#34;,&#xA;        &#34;FIRECRAWL_RETRY_MAX_DELAY&#34;: &#34;30000&#34;,&#xA;        &#34;FIRECRAWL_RETRY_BACKOFF_FACTOR&#34;: &#34;3&#34;,&#xA;&#xA;        &#34;FIRECRAWL_CREDIT_WARNING_THRESHOLD&#34;: &#34;2000&#34;,&#xA;        &#34;FIRECRAWL_CREDIT_CRITICAL_THRESHOLD&#34;: &#34;500&#34;&#xA;      }&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;System Configuration&lt;/h3&gt; &#xA;&lt;p&gt;The server includes several configurable parameters that can be set via environment variables. Here are the default values if not configured:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;const CONFIG = {&#xA;  retry: {&#xA;    maxAttempts: 3, // Number of retry attempts for rate-limited requests&#xA;    initialDelay: 1000, // Initial delay before first retry (in milliseconds)&#xA;    maxDelay: 10000, // Maximum delay between retries (in milliseconds)&#xA;    backoffFactor: 2, // Multiplier for exponential backoff&#xA;  },&#xA;  credit: {&#xA;    warningThreshold: 1000, // Warn when credit usage reaches this level&#xA;    criticalThreshold: 100, // Critical alert when credit usage reaches this level&#xA;  },&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;These configurations control:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Retry Behavior&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Automatically retries failed requests due to rate limits&lt;/li&gt; &#xA;   &lt;li&gt;Uses exponential backoff to avoid overwhelming the API&lt;/li&gt; &#xA;   &lt;li&gt;Example: With default settings, retries will be attempted at: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;1st retry: 1 second delay&lt;/li&gt; &#xA;     &lt;li&gt;2nd retry: 2 seconds delay&lt;/li&gt; &#xA;     &lt;li&gt;3rd retry: 4 seconds delay (capped at maxDelay)&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Credit Usage Monitoring&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Tracks API credit consumption for cloud API usage&lt;/li&gt; &#xA;   &lt;li&gt;Provides warnings at specified thresholds&lt;/li&gt; &#xA;   &lt;li&gt;Helps prevent unexpected service interruption&lt;/li&gt; &#xA;   &lt;li&gt;Example: With default settings: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Warning at 1000 credits remaining&lt;/li&gt; &#xA;     &lt;li&gt;Critical alert at 100 credits remaining&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Rate Limiting and Batch Processing&lt;/h3&gt; &#xA;&lt;p&gt;The server utilizes FireCrawl&#39;s built-in rate limiting and batch processing capabilities:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Automatic rate limit handling with exponential backoff&lt;/li&gt; &#xA; &lt;li&gt;Efficient parallel processing for batch operations&lt;/li&gt; &#xA; &lt;li&gt;Smart request queuing and throttling&lt;/li&gt; &#xA; &lt;li&gt;Automatic retries for transient errors&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Available Tools&lt;/h2&gt; &#xA;&lt;h3&gt;1. Scrape Tool (&lt;code&gt;firecrawl_scrape&lt;/code&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;Scrape content from a single URL with advanced options.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;name&#34;: &#34;firecrawl_scrape&#34;,&#xA;  &#34;arguments&#34;: {&#xA;    &#34;url&#34;: &#34;https://example.com&#34;,&#xA;    &#34;formats&#34;: [&#34;markdown&#34;],&#xA;    &#34;onlyMainContent&#34;: true,&#xA;    &#34;waitFor&#34;: 1000,&#xA;    &#34;timeout&#34;: 30000,&#xA;    &#34;mobile&#34;: false,&#xA;    &#34;includeTags&#34;: [&#34;article&#34;, &#34;main&#34;],&#xA;    &#34;excludeTags&#34;: [&#34;nav&#34;, &#34;footer&#34;],&#xA;    &#34;skipTlsVerification&#34;: false&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Batch Scrape Tool (&lt;code&gt;firecrawl_batch_scrape&lt;/code&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;Scrape multiple URLs efficiently with built-in rate limiting and parallel processing.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;name&#34;: &#34;firecrawl_batch_scrape&#34;,&#xA;  &#34;arguments&#34;: {&#xA;    &#34;urls&#34;: [&#34;https://example1.com&#34;, &#34;https://example2.com&#34;],&#xA;    &#34;options&#34;: {&#xA;      &#34;formats&#34;: [&#34;markdown&#34;],&#xA;      &#34;onlyMainContent&#34;: true&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Response includes operation ID for status checking:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;content&#34;: [&#xA;    {&#xA;      &#34;type&#34;: &#34;text&#34;,&#xA;      &#34;text&#34;: &#34;Batch operation queued with ID: batch_1. Use firecrawl_check_batch_status to check progress.&#34;&#xA;    }&#xA;  ],&#xA;  &#34;isError&#34;: false&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Check Batch Status (&lt;code&gt;firecrawl_check_batch_status&lt;/code&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;Check the status of a batch operation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;name&#34;: &#34;firecrawl_check_batch_status&#34;,&#xA;  &#34;arguments&#34;: {&#xA;    &#34;id&#34;: &#34;batch_1&#34;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;4. Search Tool (&lt;code&gt;firecrawl_search&lt;/code&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;Search the web and optionally extract content from search results.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;name&#34;: &#34;firecrawl_search&#34;,&#xA;  &#34;arguments&#34;: {&#xA;    &#34;query&#34;: &#34;your search query&#34;,&#xA;    &#34;limit&#34;: 5,&#xA;    &#34;lang&#34;: &#34;en&#34;,&#xA;    &#34;country&#34;: &#34;us&#34;,&#xA;    &#34;scrapeOptions&#34;: {&#xA;      &#34;formats&#34;: [&#34;markdown&#34;],&#xA;      &#34;onlyMainContent&#34;: true&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;5. Crawl Tool (&lt;code&gt;firecrawl_crawl&lt;/code&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;Start an asynchronous crawl with advanced options.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;name&#34;: &#34;firecrawl_crawl&#34;,&#xA;  &#34;arguments&#34;: {&#xA;    &#34;url&#34;: &#34;https://example.com&#34;,&#xA;    &#34;maxDepth&#34;: 2,&#xA;    &#34;limit&#34;: 100,&#xA;    &#34;allowExternalLinks&#34;: false,&#xA;    &#34;deduplicateSimilarURLs&#34;: true&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;6. Extract Tool (&lt;code&gt;firecrawl_extract&lt;/code&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;Extract structured information from web pages using LLM capabilities. Supports both cloud AI and self-hosted LLM extraction.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;name&#34;: &#34;firecrawl_extract&#34;,&#xA;  &#34;arguments&#34;: {&#xA;    &#34;urls&#34;: [&#34;https://example.com/page1&#34;, &#34;https://example.com/page2&#34;],&#xA;    &#34;prompt&#34;: &#34;Extract product information including name, price, and description&#34;,&#xA;    &#34;systemPrompt&#34;: &#34;You are a helpful assistant that extracts product information&#34;,&#xA;    &#34;schema&#34;: {&#xA;      &#34;type&#34;: &#34;object&#34;,&#xA;      &#34;properties&#34;: {&#xA;        &#34;name&#34;: { &#34;type&#34;: &#34;string&#34; },&#xA;        &#34;price&#34;: { &#34;type&#34;: &#34;number&#34; },&#xA;        &#34;description&#34;: { &#34;type&#34;: &#34;string&#34; }&#xA;      },&#xA;      &#34;required&#34;: [&#34;name&#34;, &#34;price&#34;]&#xA;    },&#xA;    &#34;allowExternalLinks&#34;: false,&#xA;    &#34;enableWebSearch&#34;: false,&#xA;    &#34;includeSubdomains&#34;: false&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example response:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;content&#34;: [&#xA;    {&#xA;      &#34;type&#34;: &#34;text&#34;,&#xA;      &#34;text&#34;: {&#xA;        &#34;name&#34;: &#34;Example Product&#34;,&#xA;        &#34;price&#34;: 99.99,&#xA;        &#34;description&#34;: &#34;This is an example product description&#34;&#xA;      }&#xA;    }&#xA;  ],&#xA;  &#34;isError&#34;: false&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Extract Tool Options:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;urls&lt;/code&gt;: Array of URLs to extract information from&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;prompt&lt;/code&gt;: Custom prompt for the LLM extraction&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;systemPrompt&lt;/code&gt;: System prompt to guide the LLM&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;schema&lt;/code&gt;: JSON schema for structured data extraction&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;allowExternalLinks&lt;/code&gt;: Allow extraction from external links&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;enableWebSearch&lt;/code&gt;: Enable web search for additional context&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;includeSubdomains&lt;/code&gt;: Include subdomains in extraction&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When using a self-hosted instance, the extraction will use your configured LLM. For cloud API, it uses FireCrawl&#39;s managed LLM service.&lt;/p&gt; &#xA;&lt;h2&gt;Logging System&lt;/h2&gt; &#xA;&lt;p&gt;The server includes comprehensive logging:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Operation status and progress&lt;/li&gt; &#xA; &lt;li&gt;Performance metrics&lt;/li&gt; &#xA; &lt;li&gt;Credit usage monitoring&lt;/li&gt; &#xA; &lt;li&gt;Rate limit tracking&lt;/li&gt; &#xA; &lt;li&gt;Error conditions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example log messages:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INFO] FireCrawl MCP Server initialized successfully&#xA;[INFO] Starting scrape for URL: https://example.com&#xA;[INFO] Batch operation queued with ID: batch_1&#xA;[WARNING] Credit usage has reached warning threshold&#xA;[ERROR] Rate limit exceeded, retrying in 2s...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Error Handling&lt;/h2&gt; &#xA;&lt;p&gt;The server provides robust error handling:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Automatic retries for transient errors&lt;/li&gt; &#xA; &lt;li&gt;Rate limit handling with backoff&lt;/li&gt; &#xA; &lt;li&gt;Detailed error messages&lt;/li&gt; &#xA; &lt;li&gt;Credit usage warnings&lt;/li&gt; &#xA; &lt;li&gt;Network resilience&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example error response:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;content&#34;: [&#xA;    {&#xA;      &#34;type&#34;: &#34;text&#34;,&#xA;      &#34;text&#34;: &#34;Error: Rate limit exceeded. Retrying in 2 seconds...&#34;&#xA;    }&#xA;  ],&#xA;  &#34;isError&#34;: true&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Install dependencies&#xA;npm install&#xA;&#xA;# Build&#xA;npm run build&#xA;&#xA;# Run tests&#xA;npm test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Contributing&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork the repository&lt;/li&gt; &#xA; &lt;li&gt;Create your feature branch&lt;/li&gt; &#xA; &lt;li&gt;Run tests: &lt;code&gt;npm test&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Submit a pull request&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT License - see LICENSE file for details&lt;/p&gt;</summary>
  </entry>
</feed>