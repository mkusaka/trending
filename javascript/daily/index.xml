<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-04-19T01:31:48Z</updated>
  <subtitle>Daily Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>gradio-app/fastrtc</title>
    <updated>2025-04-19T01:31:48Z</updated>
    <id>tag:github.com,2025-04-19:/gradio-app/fastrtc</id>
    <link href="https://github.com/gradio-app/fastrtc" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The python library for real-time communication&lt;/p&gt;&lt;hr&gt;&lt;div style=&#34;text-align: center; margin-bottom: 1rem; display: flex; justify-content: center; align-items: center;&#34;&gt; &#xA; &lt;h1 style=&#34;color: white; margin: 0;&#34;&gt;FastRTC&lt;/h1&gt; &#xA; &lt;img src=&#34;https://huggingface.co/datasets/freddyaboulton/bucket/resolve/main/fastrtc_logo_small.png&#34; alt=&#34;FastRTC Logo&#34; style=&#34;margin-right: 10px;&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div style=&#34;display: flex; flex-direction: row; justify-content: center&#34;&gt; &#xA; &lt;img style=&#34;display: block; padding-right: 5px; height: 20px;&#34; alt=&#34;Static Badge&#34; src=&#34;https://img.shields.io/pypi/v/fastrtc&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/gradio-app/fastrtc&#34; target=&#34;_blank&#34;&gt;&lt;img alt=&#34;Static Badge&#34; src=&#34;https://img.shields.io/badge/github-white?logo=github&amp;amp;logoColor=black&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3 style=&#34;text-align: center&#34;&gt; The Real-Time Communication Library for Python. &lt;/h3&gt; &#xA;&lt;p&gt;Turn any python function into a real-time audio and video stream over WebRTC or WebSockets.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install fastrtc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to use built-in pause detection (see &lt;a href=&#34;https://fastrtc.org/userguide/audio/#reply-on-pause&#34;&gt;ReplyOnPause&lt;/a&gt;), and text to speech (see &lt;a href=&#34;https://fastrtc.org/userguide/audio/#text-to-speech&#34;&gt;Text To Speech&lt;/a&gt;), install the &lt;code&gt;vad&lt;/code&gt; and &lt;code&gt;tts&lt;/code&gt; extras:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install &#34;fastrtc[vad, tts]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ—£ï¸ Automatic Voice Detection and Turn Taking built-in, only worry about the logic for responding to the user.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ’» Automatic UI - Use the &lt;code&gt;.ui.launch()&lt;/code&gt; method to launch the webRTC-enabled built-in Gradio UI.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”Œ Automatic WebRTC Support - Use the &lt;code&gt;.mount(app)&lt;/code&gt; method to mount the stream on a FastAPI app and get a webRTC endpoint for your own frontend!&lt;/li&gt; &#xA; &lt;li&gt;âš¡ï¸ Websocket Support - Use the &lt;code&gt;.mount(app)&lt;/code&gt; method to mount the stream on a FastAPI app and get a websocket endpoint for your own frontend!&lt;/li&gt; &#xA; &lt;li&gt;ğŸ“ Automatic Telephone Support - Use the &lt;code&gt;fastphone()&lt;/code&gt; method of the stream to launch the application and get a free temporary phone number!&lt;/li&gt; &#xA; &lt;li&gt;ğŸ¤– Completely customizable backend - A &lt;code&gt;Stream&lt;/code&gt; can easily be mounted on a FastAPI app so you can easily extend it to fit your production application. See the &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/talk-to-claude&#34;&gt;Talk To Claude&lt;/a&gt; demo for an example on how to serve a custom JS frontend.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Docs&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://fastrtc.org&#34;&gt;https://fastrtc.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://fastrtc.org/cookbook/&#34;&gt;Cookbook&lt;/a&gt; for examples of how to use the library.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸ—£ï¸ğŸ‘€ Gemini Audio Video Chat&lt;/h3&gt; &lt;p&gt;Stream BOTH your webcam video and audio feeds to Google Gemini. You can also upload images to augment your conversation!&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/9636dc97-4fee-46bb-abb8-b92e69c08c71&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/freddyaboulton/gemini-audio-video-chat&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/freddyaboulton/gemini-audio-video-chat/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸ—£ï¸ Google Gemini Real Time Voice API&lt;/h3&gt; &lt;p&gt;Talk to Gemini in real time using Google&#39;s voice API.&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/ea6d18cb-8589-422b-9bba-56332d9f61de&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/talk-to-gemini&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/talk-to-gemini/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸ—£ï¸ OpenAI Real Time Voice API&lt;/h3&gt; &lt;p&gt;Talk to ChatGPT in real time using OpenAI&#39;s voice API.&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/178bdadc-f17b-461a-8d26-e915c632ff80&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/talk-to-openai&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/talk-to-openai/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸ¤– Hello Computer&lt;/h3&gt; &lt;p&gt;Say computer before asking your question!&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/afb2a3ef-c1ab-4cfb-872d-578f895a10d5&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/hello-computer&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/hello-computer/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸ¤– Llama Code Editor&lt;/h3&gt; &lt;p&gt;Create and edit HTML pages with just your voice! Powered by SambaNova systems.&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/98523cf3-dac8-4127-9649-d91a997e3ef5&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/llama-code-editor&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/llama-code-editor/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸ—£ï¸ Talk to Claude&lt;/h3&gt; &lt;p&gt;Use the Anthropic and Play.Ht APIs to have an audio conversation with Claude.&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/fb6ef07f-3ccd-444a-997b-9bc9bdc035d3&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/talk-to-claude&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/talk-to-claude/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸµ Whisper Transcription&lt;/h3&gt; &lt;p&gt;Have whisper transcribe your speech in real time!&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/87603053-acdc-4c8a-810f-f618c49caafb&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/whisper-realtime&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/whisper-realtime/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸ“· Yolov10 Object Detection&lt;/h3&gt; &lt;p&gt;Run the Yolov10 model on a user webcam stream in real time!&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/f82feb74-a071-4e81-9110-a01989447ceb&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/object-detection&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/fastrtc/object-detection/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸ—£ï¸ Kyutai Moshi&lt;/h3&gt; &lt;p&gt;Kyutai&#39;s moshi is a novel speech-to-speech model for modeling human conversations.&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/becc7a13-9e89-4a19-9df2-5fb1467a0137&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/freddyaboulton/talk-to-moshi&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/freddyaboulton/talk-to-moshi/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;h3&gt;ğŸ—£ï¸ Hello Llama: Stop Word Detection&lt;/h3&gt; &lt;p&gt;A code editor built with Llama 3.3 70b that is triggered by the phrase &#34;Hello Llama&#34;. Build a Siri-like coding assistant in 100 lines of code!&lt;/p&gt; &#xA;    &lt;video width=&#34;100%&#34; src=&#34;https://github.com/user-attachments/assets/3e10cb15-ff1b-4b17-b141-ff0ad852e613&#34; controls&gt;&lt;/video&gt; &lt;p&gt; &lt;a href=&#34;https://huggingface.co/spaces/freddyaboulton/hey-llama-code-editor&#34;&gt;Demo&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/freddyaboulton/hey-llama-code-editor/blob/main/app.py&#34;&gt;Code&lt;/a&gt; &lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;This is an shortened version of the official &lt;a href=&#34;https://freddyaboulton.github.io/gradio-webrtc/user-guide/&#34;&gt;usage guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;.ui.launch()&lt;/code&gt;: Launch a built-in UI for easily testing and sharing your stream. Built with &lt;a href=&#34;https://www.gradio.app/&#34;&gt;Gradio&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;.fastphone()&lt;/code&gt;: Get a free temporary phone number to call into your stream. Hugging Face token required.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;.mount(app)&lt;/code&gt;: Mount the stream on a &lt;a href=&#34;https://fastapi.tiangolo.com/&#34;&gt;FastAPI&lt;/a&gt; app. Perfect for integrating with your already existing production system.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;h3&gt;Echo Audio&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fastrtc import Stream, ReplyOnPause&#xA;import numpy as np&#xA;&#xA;def echo(audio: tuple[int, np.ndarray]):&#xA;    # The function will be passed the audio until the user pauses&#xA;    # Implement any iterator that yields audio&#xA;    # See &#34;LLM Voice Chat&#34; for a more complete example&#xA;    yield audio&#xA;&#xA;stream = Stream(&#xA;    handler=ReplyOnPause(echo),&#xA;    modality=&#34;audio&#34;, &#xA;    mode=&#34;send-receive&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;LLM Voice Chat&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from fastrtc import (&#xA;    ReplyOnPause, AdditionalOutputs, Stream,&#xA;    audio_to_bytes, aggregate_bytes_to_16bit&#xA;)&#xA;import gradio as gr&#xA;from groq import Groq&#xA;import anthropic&#xA;from elevenlabs import ElevenLabs&#xA;&#xA;groq_client = Groq()&#xA;claude_client = anthropic.Anthropic()&#xA;tts_client = ElevenLabs()&#xA;&#xA;&#xA;# See &#34;Talk to Claude&#34; in Cookbook for an example of how to keep &#xA;# track of the chat history.&#xA;def response(&#xA;    audio: tuple[int, np.ndarray],&#xA;):&#xA;    prompt = groq_client.audio.transcriptions.create(&#xA;        file=(&#34;audio-file.mp3&#34;, audio_to_bytes(audio)),&#xA;        model=&#34;whisper-large-v3-turbo&#34;,&#xA;        response_format=&#34;verbose_json&#34;,&#xA;    ).text&#xA;    response = claude_client.messages.create(&#xA;        model=&#34;claude-3-5-haiku-20241022&#34;,&#xA;        max_tokens=512,&#xA;        messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: prompt}],&#xA;    )&#xA;    response_text = &#34; &#34;.join(&#xA;        block.text&#xA;        for block in response.content&#xA;        if getattr(block, &#34;type&#34;, None) == &#34;text&#34;&#xA;    )&#xA;    iterator = tts_client.text_to_speech.convert_as_stream(&#xA;        text=response_text,&#xA;        voice_id=&#34;JBFqnCBsd6RMkjVDRZzb&#34;,&#xA;        model_id=&#34;eleven_multilingual_v2&#34;,&#xA;        output_format=&#34;pcm_24000&#34;&#xA;        &#xA;    )&#xA;    for chunk in aggregate_bytes_to_16bit(iterator):&#xA;        audio_array = np.frombuffer(chunk, dtype=np.int16).reshape(1, -1)&#xA;        yield (24000, audio_array)&#xA;&#xA;stream = Stream(&#xA;    modality=&#34;audio&#34;,&#xA;    mode=&#34;send-receive&#34;,&#xA;    handler=ReplyOnPause(response),&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Webcam Stream&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fastrtc import Stream&#xA;import numpy as np&#xA;&#xA;&#xA;def flip_vertically(image):&#xA;    return np.flip(image, axis=0)&#xA;&#xA;&#xA;stream = Stream(&#xA;    handler=flip_vertically,&#xA;    modality=&#34;video&#34;,&#xA;    mode=&#34;send-receive&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Object Detection&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fastrtc import Stream&#xA;import gradio as gr&#xA;import cv2&#xA;from huggingface_hub import hf_hub_download&#xA;from .inference import YOLOv10&#xA;&#xA;model_file = hf_hub_download(&#xA;    repo_id=&#34;onnx-community/yolov10n&#34;, filename=&#34;onnx/model.onnx&#34;&#xA;)&#xA;&#xA;# git clone https://huggingface.co/spaces/fastrtc/object-detection&#xA;# for YOLOv10 implementation&#xA;model = YOLOv10(model_file)&#xA;&#xA;def detection(image, conf_threshold=0.3):&#xA;    image = cv2.resize(image, (model.input_width, model.input_height))&#xA;    new_image = model.detect_objects(image, conf_threshold)&#xA;    return cv2.resize(new_image, (500, 500))&#xA;&#xA;stream = Stream(&#xA;    handler=detection,&#xA;    modality=&#34;video&#34;, &#xA;    mode=&#34;send-receive&#34;,&#xA;    additional_inputs=[&#xA;        gr.Slider(minimum=0, maximum=1, step=0.01, value=0.3)&#xA;    ]&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running the Stream&lt;/h2&gt; &#xA;&lt;p&gt;Run:&lt;/p&gt; &#xA;&lt;h3&gt;Gradio&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;stream.ui.launch()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Telephone (Audio Only)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;```py&#xA;stream.fastphone()&#xA;```&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;FastAPI&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;app = FastAPI()&#xA;stream.mount(app)&#xA;&#xA;# Optional: Add routes&#xA;@app.get(&#34;/&#34;)&#xA;async def _():&#xA;    return HTMLResponse(content=open(&#34;index.html&#34;).read())&#xA;&#xA;# uvicorn app:app --host 0.0.0.0 --port 8000&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>hexgrad/kokoro</title>
    <updated>2025-04-19T01:31:48Z</updated>
    <id>tag:github.com,2025-04-19:/hexgrad/kokoro</id>
    <link href="https://github.com/hexgrad/kokoro" rel="alternate"></link>
    <summary type="html">&lt;p&gt;https://hf.co/hexgrad/Kokoro-82M&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;kokoro&lt;/h1&gt; &#xA;&lt;p&gt;An inference library for &lt;a href=&#34;https://huggingface.co/hexgrad/Kokoro-82M&#34;&gt;Kokoro-82M&lt;/a&gt;. You can &lt;a href=&#34;https://pypi.org/project/kokoro/&#34;&gt;&lt;code&gt;pip install kokoro&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Kokoro&lt;/strong&gt; is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, Kokoro can be deployed anywhere from production environments to personal projects.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;You can run this basic cell on &lt;a href=&#34;https://colab.research.google.com/&#34;&gt;Google Colab&lt;/a&gt;. &lt;a href=&#34;https://huggingface.co/hexgrad/Kokoro-82M/blob/main/SAMPLES.md&#34;&gt;Listen to samples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;!pip install -q kokoro&amp;gt;=0.9.4 soundfile&#xA;!apt-get -qq -y install espeak-ng &amp;gt; /dev/null 2&amp;gt;&amp;amp;1&#xA;from kokoro import KPipeline&#xA;from IPython.display import display, Audio&#xA;import soundfile as sf&#xA;import torch&#xA;pipeline = KPipeline(lang_code=&#39;a&#39;)&#xA;text = &#39;&#39;&#39;&#xA;[Kokoro](/kËˆOkÉ™É¹O/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, [Kokoro](/kËˆOkÉ™É¹O/) can be deployed anywhere from production environments to personal projects.&#xA;&#39;&#39;&#39;&#xA;generator = pipeline(text, voice=&#39;af_heart&#39;)&#xA;for i, (gs, ps, audio) in enumerate(generator):&#xA;    print(i, gs, ps)&#xA;    display(Audio(data=audio, rate=24000, autoplay=i==0))&#xA;    sf.write(f&#39;{i}.wav&#39;, audio, 24000)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Under the hood, &lt;code&gt;kokoro&lt;/code&gt; uses &lt;a href=&#34;https://pypi.org/project/misaki/&#34;&gt;&lt;code&gt;misaki&lt;/code&gt;&lt;/a&gt;, a G2P library at &lt;a href=&#34;https://github.com/hexgrad/misaki&#34;&gt;https://github.com/hexgrad/misaki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Advanced Usage&lt;/h3&gt; &#xA;&lt;p&gt;You can run this advanced cell on &lt;a href=&#34;https://colab.research.google.com/&#34;&gt;Google Colab&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# 1ï¸âƒ£ Install kokoro&#xA;!pip install -q kokoro&amp;gt;=0.9.4 soundfile&#xA;# 2ï¸âƒ£ Install espeak, used for English OOD fallback and some non-English languages&#xA;!apt-get -qq -y install espeak-ng &amp;gt; /dev/null 2&amp;gt;&amp;amp;1&#xA;&#xA;# 3ï¸âƒ£ Initalize a pipeline&#xA;from kokoro import KPipeline&#xA;from IPython.display import display, Audio&#xA;import soundfile as sf&#xA;import torch&#xA;# ğŸ‡ºğŸ‡¸ &#39;a&#39; =&amp;gt; American English, ğŸ‡¬ğŸ‡§ &#39;b&#39; =&amp;gt; British English&#xA;# ğŸ‡ªğŸ‡¸ &#39;e&#39; =&amp;gt; Spanish es&#xA;# ğŸ‡«ğŸ‡· &#39;f&#39; =&amp;gt; French fr-fr&#xA;# ğŸ‡®ğŸ‡³ &#39;h&#39; =&amp;gt; Hindi hi&#xA;# ğŸ‡®ğŸ‡¹ &#39;i&#39; =&amp;gt; Italian it&#xA;# ğŸ‡¯ğŸ‡µ &#39;j&#39; =&amp;gt; Japanese: pip install misaki[ja]&#xA;# ğŸ‡§ğŸ‡· &#39;p&#39; =&amp;gt; Brazilian Portuguese pt-br&#xA;# ğŸ‡¨ğŸ‡³ &#39;z&#39; =&amp;gt; Mandarin Chinese: pip install misaki[zh]&#xA;pipeline = KPipeline(lang_code=&#39;a&#39;) # &amp;lt;= make sure lang_code matches voice, reference above.&#xA;&#xA;# This text is for demonstration purposes only, unseen during training&#xA;text = &#39;&#39;&#39;&#xA;The sky above the port was the color of television, tuned to a dead channel.&#xA;&#34;It&#39;s not like I&#39;m using,&#34; Case heard someone say, as he shouldered his way through the crowd around the door of the Chat. &#34;It&#39;s like my body&#39;s developed this massive drug deficiency.&#34;&#xA;It was a Sprawl voice and a Sprawl joke. The Chatsubo was a bar for professional expatriates; you could drink there for a week and never hear two words in Japanese.&#xA;&#xA;These were to have an enormous impact, not only because they were associated with Constantine, but also because, as in so many other areas, the decisions taken by Constantine (or in his name) were to have great significance for centuries to come. One of the main issues was the shape that Christian churches were to take, since there was not, apparently, a tradition of monumental church buildings when Constantine decided to help the Christian church build a series of truly spectacular structures. The main form that these churches took was that of the basilica, a multipurpose rectangular structure, based ultimately on the earlier Greek stoa, which could be found in most of the great cities of the empire. Christianity, unlike classical polytheism, needed a large interior space for the celebration of its religious services, and the basilica aptly filled that need. We naturally do not know the degree to which the emperor was involved in the design of new churches, but it is tempting to connect this with the secular basilica that Constantine completed in the Roman forum (the so-called Basilica of Maxentius) and the one he probably built in Trier, in connection with his residence in the city at a time when he was still caesar.&#xA;&#xA;[Kokoro](/kËˆOkÉ™É¹O/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, [Kokoro](/kËˆOkÉ™É¹O/) can be deployed anywhere from production environments to personal projects.&#xA;&#39;&#39;&#39;&#xA;# text = &#39;ã€Œã‚‚ã—ãŠã‚ŒãŒãŸã å¶ç„¶ã€ãã—ã¦ã“ã†ã—ã‚ˆã†ã¨ã„ã†ã¤ã‚‚ã‚Šã§ãªãã“ã“ã«ç«‹ã£ã¦ã„ã‚‹ã®ãªã‚‰ã€ã¡ã‚‡ã£ã¨ã°ã‹ã‚Šçµ¶æœ›ã™ã‚‹ã¨ã“ã‚ã ãªã€ã¨ã€ãã‚“ãªã“ã¨ãŒå½¼ã®é ­ã«æ€ã„æµ®ã‹ã‚“ã ã€‚&#39;&#xA;# text = &#39;ä¸­åœ‹äººæ°‘ä¸ä¿¡é‚ªä¹Ÿä¸æ€•é‚ªï¼Œä¸æƒ¹äº‹ä¹Ÿä¸æ€•äº‹ï¼Œä»»ä½•å¤–åœ‹ä¸è¦æŒ‡æœ›æˆ‘å€‘æœƒæ‹¿è‡ªå·±çš„æ ¸å¿ƒåˆ©ç›Šåšäº¤æ˜“ï¼Œä¸è¦æŒ‡æœ›æˆ‘å€‘æœƒåä¸‹æå®³æˆ‘åœ‹ä¸»æ¬Šã€å®‰å…¨ã€ç™¼å±•åˆ©ç›Šçš„è‹¦æœï¼&#39;&#xA;# text = &#39;Los partidos polÃ­ticos tradicionales compiten con los populismos y los movimientos asamblearios.&#39;&#xA;# text = &#39;Le dromadaire resplendissant dÃ©ambulait tranquillement dans les mÃ©andres en mastiquant de petites feuilles vernissÃ©es.&#39;&#xA;# text = &#39;à¤Ÿà¥à¤°à¤¾à¤‚à¤¸à¤ªà¥‹à¤°à¥à¤Ÿà¤°à¥‹à¤‚ à¤•à¥€ à¤¹à¤¡à¤¼à¤¤à¤¾à¤² à¤²à¤—à¤¾à¤¤à¤¾à¤° à¤ªà¤¾à¤‚à¤šà¤µà¥‡à¤‚ à¤¦à¤¿à¤¨ à¤œà¤¾à¤°à¥€, à¤¦à¤¿à¤¸à¤‚à¤¬à¤° à¤¸à¥‡ à¤‡à¤²à¥‡à¤•à¥à¤Ÿà¥à¤°à¥‰à¤¨à¤¿à¤• à¤Ÿà¥‹à¤² à¤•à¤²à¥‡à¤•à¥à¤¶à¤¨à¤² à¤¸à¤¿à¤¸à¥à¤Ÿà¤®&#39;&#xA;# text = &#34;Allora cominciava l&#39;insonnia, o un dormiveglia peggiore dell&#39;insonnia, che talvolta assumeva i caratteri dell&#39;incubo.&#34;&#xA;# text = &#39;Elabora relatÃ³rios de acompanhamento cronolÃ³gico para as diferentes unidades do Departamento que propÃµem contratos.&#39;&#xA;&#xA;# 4ï¸âƒ£ Generate, display, and save audio files in a loop.&#xA;generator = pipeline(&#xA;    text, voice=&#39;af_heart&#39;, # &amp;lt;= change voice here&#xA;    speed=1, split_pattern=r&#39;\n+&#39;&#xA;)&#xA;# Alternatively, load voice tensor directly:&#xA;# voice_tensor = torch.load(&#39;path/to/voice.pt&#39;, weights_only=True)&#xA;# generator = pipeline(&#xA;#     text, voice=voice_tensor,&#xA;#     speed=1, split_pattern=r&#39;\n+&#39;&#xA;# )&#xA;&#xA;for i, (gs, ps, audio) in enumerate(generator):&#xA;    print(i)  # i =&amp;gt; index&#xA;    print(gs) # gs =&amp;gt; graphemes/text&#xA;    print(ps) # ps =&amp;gt; phonemes&#xA;    display(Audio(data=audio, rate=24000, autoplay=i==0))&#xA;    sf.write(f&#39;{i}.wav&#39;, audio, 24000) # save each audio file&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Windows Installation&lt;/h3&gt; &#xA;&lt;p&gt;To install espeak-ng on Windows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;https://github.com/espeak-ng/espeak-ng/releases&#34;&gt;espeak-ng releases&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Click on &lt;strong&gt;Latest release&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Download the appropriate &lt;code&gt;*.msi&lt;/code&gt; file (e.g. &lt;strong&gt;espeak-ng-20191129-b702b03-x64.msi&lt;/strong&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Run the downloaded installer&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For advanced configuration and usage on Windows, see the &lt;a href=&#34;https://github.com/espeak-ng/espeak-ng/raw/master/docs/guide.md&#34;&gt;official espeak-ng Windows guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;MacOS Apple Silicon GPU Acceleration&lt;/h3&gt; &#xA;&lt;p&gt;On Mac M1/M2/M3/M4 devices, you can explicitly specify the environment variable &lt;code&gt;PYTORCH_ENABLE_MPS_FALLBACK=1&lt;/code&gt; to enable GPU acceleration.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;PYTORCH_ENABLE_MPS_FALLBACK=1 python run-your-kokoro-script.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Conda Environment&lt;/h3&gt; &#xA;&lt;p&gt;Use the following conda &lt;code&gt;environment.yml&lt;/code&gt; if you&#39;re facing any dependency issues.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;name: kokoro&#xA;channels:&#xA;  - defaults&#xA;dependencies:&#xA;  - python==3.9       &#xA;  - libstdcxx~=12.4.0 # Needed to load espeak correctly. Try removing this if you&#39;re facing issues with Espeak fallback. &#xA;  - pip:&#xA;      - kokoro&amp;gt;=0.3.1&#xA;      - soundfile&#xA;      - misaki[en]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Acknowledgements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ› ï¸ &lt;a href=&#34;https://huggingface.co/yl4579&#34;&gt;@yl4579&lt;/a&gt; for architecting StyleTTS 2.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ† &lt;a href=&#34;https://huggingface.co/Pendrokar&#34;&gt;@Pendrokar&lt;/a&gt; for adding Kokoro as a contender in the TTS Spaces Arena.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ“Š Thank you to everyone who contributed synthetic training data.&lt;/li&gt; &#xA; &lt;li&gt;â¤ï¸ Special thanks to all compute sponsors.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‘¾ Discord server: &lt;a href=&#34;https://discord.gg/QuGxSWBfQy&#34;&gt;https://discord.gg/QuGxSWBfQy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸª½ Kokoro is a Japanese word that translates to &#34;heart&#34; or &#34;spirit&#34;. Kokoro is also a &lt;a href=&#34;https://terminator.fandom.com/wiki/Kokoro&#34;&gt;character in the Terminator franchise&lt;/a&gt; along with &lt;a href=&#34;https://github.com/hexgrad/misaki?tab=readme-ov-file#acknowledgements&#34;&gt;Misaki&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://static0.gamerantimages.com/wordpress/wp-content/uploads/2024/08/terminator-zero-41-1.jpg&#34; width=&#34;400&#34; alt=&#34;kokoro&#34;&gt;</summary>
  </entry>
</feed>