<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-25T01:30:16Z</updated>
  <subtitle>Daily Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>XPandora/PhysGaussian</title>
    <updated>2023-11-25T01:30:16Z</updated>
    <id>tag:github.com,2023-11-25:/XPandora/PhysGaussian</id>
    <link href="https://github.com/XPandora/PhysGaussian" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics&lt;/h1&gt; &#xA;&lt;p&gt;The code is coming soon.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>radian-software/riju</title>
    <updated>2023-11-25T01:30:16Z</updated>
    <id>tag:github.com,2023-11-25:/radian-software/riju</id>
    <link href="https://github.com/radian-software/riju" rel="alternate"></link>
    <summary type="html">&lt;p&gt;âš¡ Extremely fast online playground for every programming language.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Riju&lt;/h1&gt; &#xA;&lt;p&gt;Riju is a very fast online playground for every programming language. In less than a second, you can start playing with a Python interpreter or compiling &lt;a href=&#34;https://en.wikipedia.org/wiki/INTERCAL&#34;&gt;INTERCAL&lt;/a&gt; code.&lt;/p&gt; &#xA;&lt;p&gt;Check it out at &lt;a href=&#34;https://riju.codes&#34;&gt;https://riju.codes&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt;Service uptime available at &lt;a href=&#34;https://radian.statuspage.io/&#34;&gt;https://radian.statuspage.io/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Is it free?&lt;/h2&gt; &#xA;&lt;p&gt;Riju will always be free for everyone. I pay for the hosting costs out of the business account of Radian LLC, which is funded by donations and my personal savings. If you would like to help keep Riju online and see more projects like it, there are a few donation methods available in the &#34;Sponsor this project&#34; sidebar on GitHub.&lt;/p&gt; &#xA;&lt;p&gt;All financial records for Radian LLC are made &lt;a href=&#34;https://github.com/radian-software/financials&#34;&gt;publicly available&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Is it safe?&lt;/h2&gt; &#xA;&lt;p&gt;Riju does not collect your personal information.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Your code is deleted from the server as soon as you close Riju.&lt;/li&gt; &#xA; &lt;li&gt;Your terminal input and output is never saved or logged anywhere.&lt;/li&gt; &#xA; &lt;li&gt;Riju uses &lt;a href=&#34;https://usefathom.com/&#34;&gt;Fathom Analytics&lt;/a&gt; to measure traffic. Fathom collects very limited data and does not sell it to third parties, unlike Google Analytics.&lt;/li&gt; &#xA; &lt;li&gt;Riju does not serve advertisements or share data with any third party aside from Fathom Analytics.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All of the above notwithstanding, any service that allows people to run code online is inherently risky. For this reason, I can&#39;t make any guarantees about the security or privacy of your data.&lt;/p&gt; &#xA;&lt;p&gt;See also &lt;a href=&#34;https://raw.githubusercontent.com/radian-software/riju/main/SECURITY.md&#34;&gt;Reporting a security issue&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Are there rules?&lt;/h2&gt; &#xA;&lt;p&gt;Yes, there is one rule and it is &#34;please be nice&#34;. Examples of not being nice include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Trying to consume as many resources as possible.&lt;/em&gt; All this will do is prevent others from using Riju, which isn&#39;t nice.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Mining cryptocurrency.&lt;/em&gt; Since hosting Riju comes out of &lt;del&gt;my paycheck&lt;/del&gt; community donations, this is exactly equivalent to stealing, which isn&#39;t nice.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Can I help? / Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Absolutely, please see &lt;a href=&#34;https://raw.githubusercontent.com/radian-software/riju/main/CONTRIBUTING.md&#34;&gt;Contributing guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Similar projects&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tio.run/&#34;&gt;TryItOnline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ryugod.com/&#34;&gt;RyuGod&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A big thank you to &lt;a href=&#34;https://github.com/Salakar&#34;&gt;Mike Diarmid&lt;/a&gt; of &lt;a href=&#34;https://github.com/invertase&#34;&gt;Invertase&lt;/a&gt; for being an early sponsor of the project and helping out with hosting costs! Thanks to Mike&#39;s generous support I have the runway to get Riju stable enough for everyone to use.&lt;/li&gt; &#xA; &lt;li&gt;Thank you to the maintainers of &lt;a href=&#34;https://github.com/microsoft/monaco-editor&#34;&gt;Monaco&lt;/a&gt;, &lt;a href=&#34;https://github.com/microsoft/node-pty&#34;&gt;node-pty&lt;/a&gt;, and &lt;a href=&#34;https://github.com/xtermjs/xterm.js/&#34;&gt;Xterm.js&lt;/a&gt;! Without any one of these open-source libraries, version 1.0 of Riju could not have come to life!&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>conanak99/sample-gpt-local</title>
    <updated>2023-11-25T01:30:16Z</updated>
    <id>tag:github.com,2023-11-25:/conanak99/sample-gpt-local</id>
    <link href="https://github.com/conanak99/sample-gpt-local" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Running the Chat Application&lt;/h1&gt; &#xA;&lt;p&gt;This guide will help you run the chat application contained in the &lt;code&gt;index.html&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Ensure you have the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A modern web browser (Chrome, Firefox, Safari, etc.)&lt;/li&gt; &#xA; &lt;li&gt;A local web server (like Python&#39;s SimpleHTTPServer, Node&#39;s http-server, etc.). Or you can use Live Server feature from VSCode&lt;/li&gt; &#xA; &lt;li&gt;An API key from OpenAI for API access. Or a laptop/PC with &amp;gt;8GB RAM&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Start the app using OpenAI API&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Set up the API key&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Open the &lt;code&gt;index.html&lt;/code&gt; file and locate the following line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;const chatGPTKey = &#39;sk-&#39;; // Paste the API key here&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Replace &lt;code&gt;&#39;sk-*****&#39;&lt;/code&gt; with your actual OpenAI GPT-3 API key.&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;&lt;strong&gt;Start the local server&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Navigate to the directory containing &lt;code&gt;index.html&lt;/code&gt; and start your local server. For example, if you&#39;re using Python&#39;s SimpleHTTPServer, you can start it with the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m SimpleHTTPServer&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you&#39;re using Node&#39;s http-server, you can start it with the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;http-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;&lt;strong&gt;Access the application&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Open your web browser and navigate to localhost on the port your server is running. For example, if your server is running on port 8000, you would navigate to &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;&lt;strong&gt;Interact with the chat application&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You should now see the chat interface in your browser. You can type messages into the input field and press &#34;Send&#34; to interact with the chatbot.&lt;/p&gt; &#xA;&lt;p&gt;Please note that this is a simple setup meant for local development and testing. It is not suitable for a production environment.&lt;/p&gt; &#xA;&lt;h2&gt;Start the app using Local API&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Download model&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Create a folder named &lt;code&gt;models&lt;/code&gt;, then download &lt;code&gt;mistral-7b-openorca.Q4_0.gguf&lt;/code&gt; from here &lt;a href=&#34;https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca&#34;&gt;https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca&lt;/a&gt; and put into the &lt;code&gt;models&lt;/code&gt; folder&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;&lt;strong&gt;Install llama_cpp Python&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Follow the guide here to install llama_cpp Python &lt;a href=&#34;https://github.com/abetlen/llama-cpp-python&#34;&gt;https://github.com/abetlen/llama-cpp-python&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;&lt;strong&gt;Run local OpenAI server&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Run the following script to run an OpenAI API server locally. The server should run at port 8000&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 -m llama_cpp.server --model &#34;./models/mistral-7b-openorca.Q4_0.gguf&#34; --chat_format chatml --n_gpu_layers 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;&lt;strong&gt;Update chat application code&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Open the &lt;code&gt;index.html&lt;/code&gt; file and locate the following line&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;  // Real GPT&#xA;  // const OPEN_AI_ENDPOINT = &#39;https://api.openai.com/v1&#39; // Comment this line&#xA;&#xA;  // Security, do not deploy this in production&#xA;  const chatGPTKey = &#39;sk-*****&#39;; // Create an API key from here&#xA;&#xA;  // Local GPT&#xA;  const OPEN_AI_ENDPOINT = &#39;http://localhost:8000/v1&#39; // Uncomment this line&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the application again. It should use localhost for local API inteference.&lt;/p&gt;</summary>
  </entry>
</feed>