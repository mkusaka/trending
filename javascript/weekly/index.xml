<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-02T01:57:08Z</updated>
  <subtitle>Weekly Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dirk1983/chatgpt</title>
    <updated>2023-04-02T01:57:08Z</updated>
    <id>tag:github.com,2023-04-02:/dirk1983/chatgpt</id>
    <link href="https://github.com/dirk1983/chatgpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;本项目是最易部署的ChatGPT环境，想做点事情的创业者欢迎加群参与讨论！PHP版调用OpenAI最新接口和模型gpt-3.5-turbo进行问答的Demo，采用Stream流模式通信，一边生成一边输出，响应速度超过官网。前端采用JS的EventSource，支持Markdown格式解析，代码有着色处理。页面UI简洁，支持上下文连续会话。源码只有两三个文件，没用任何框架，支持所有PHP版本。只需要修改stream.php中的API_KEY即可使用，也可让浏览者使用自定义API_KEY。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;chatgpt&lt;/h1&gt; &#xA;&lt;h2&gt;GPT-4已经发布，快进群参与讨论吧…… 免费加群，即将达到500人上限，欲加从速。群里已有人拿到GPT-4接口访问权限，目前暂不支持输入图片，并且模型价格较贵。&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;2023-03-16更新版本日志：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;支持表格和公式的显示&lt;/li&gt; &#xA; &lt;li&gt;优化了代码显示逻辑&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;2023-03-11更新版本日志：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;支持多行输入，文本框高度自动调节&lt;/li&gt; &#xA; &lt;li&gt;AI回答途中可以随时打断&lt;/li&gt; &#xA; &lt;li&gt;增加了API_KEY被封禁和未提供API_KEY错误的提示&lt;/li&gt; &#xA; &lt;li&gt;增加了一些预设话术&lt;/li&gt; &#xA; &lt;li&gt;对手机浏览器进行了适配优化&lt;/li&gt; &#xA; &lt;li&gt;修复了AI回复内容包含某些代码时，显示效果异常的bug&lt;/li&gt; &#xA; &lt;li&gt;增加了代码复制按钮&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;PHP版调用OpenAI的API接口进行问答的Demo，代码已更新为调用最新的gpt-3.5-turbo模型。 采用Stream流模式通信，一边生成一边输出，响应速度超过官网。前端采用JS的EventSource，还将Markdown格式文本进行了排版，对代码进行了着色处理。服务器记录所有访问者的对话日志。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;很多人想要Demo网站中自己输入API-KEY的功能，已经把代码加上了，取消index.php的注释就行了。为了美观可以把上面的“连续对话”部分注释掉，要不然手机访问不是很友好。&lt;/p&gt; &#xA;&lt;p&gt;在国内访问OpenAI的新接口会提示超时，如果你本地有HTTP-PROXY，可以把stream.php里面注释掉的“curl_setopt($ch, CURLOPT_PROXY, &#34; &lt;a href=&#34;http://127.0.0.1:1081&#34;&gt;http://127.0.0.1:1081&lt;/a&gt; &#34;);”修改一下，这样就可以通过你本地的代理访问openai的接口。&lt;/p&gt; &#xA;&lt;p&gt;如果你自己没代理，可以使用热心网友提供的反代地址，把“curl_setopt($ch, CURLOPT_URL, &#39; &lt;a href=&#34;https://api.openai.com/v1/chat/completions&#34;&gt;https://api.openai.com/v1/chat/completions&lt;/a&gt; &#39;);”这行里面的网址改成&#39; &lt;a href=&#34;https://openai.1rmb.tk/v1/chat/completions&#34;&gt;https://openai.1rmb.tk/v1/chat/completions&lt;/a&gt; &#39;，不确定那个什么时候会失效，也可以进群再找其他群友求一个。不过反代的方式访问速度比较慢，最好还是自己买个海外服务器吧，每个月不到20元的有的是。&lt;/p&gt; &#xA;&lt;p&gt;如果你实在不会买海外服务器，那你有自己的域名吗？有的话还可以用cf worker自建反代，具体可以参考这篇文章：&lt;a href=&#34;https://github.com/noobnooc/noobnooc/discussions/9&#34;&gt;https://github.com/noobnooc/noobnooc/discussions/9&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;测试网址：&lt;a href=&#34;http://mm1.ltd&#34;&gt;http://mm1.ltd&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/5563148/224522389-f60e3047-c0e6-49cd-bee7-80feaf2c86a4.png&#34; alt=&#34;微信截图_20230312112146&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;核心代码只有几个文件，没有用任何框架，修改调试很方便，只需要修改stream.php中的API_KEY即可使用。&lt;/p&gt; &#xA;&lt;p&gt;index.php前面的代码还可以实现区分内外网IP，内网直接访问，外网通过BASIC认证后可访问。可以根据需要删掉注释并进行修改。&lt;/p&gt; &#xA;&lt;p&gt;部署好了可以放在公司内网，让同事们一起体验chatGPT的强大功能。也可以发到朋友圈分享，互联网技术大牛的形象直接拉满。&lt;/p&gt; &#xA;&lt;p&gt;FAQ：&lt;/p&gt; &#xA;&lt;p&gt;之前OpenAI官方API提供的最先进的模型是text-davinci-003，比官网的ChatGPT稍弱一些。最近OpenAI终于放出了gpt-3.5-turbo模型，理论上和官网的ChatGPT几乎没区别了。只是由于接口限制，问题和答案最多4096个tokens，实测1个汉字算2个tokens。&lt;/p&gt; &#xA;&lt;p&gt;github上也有一些大神提供了基于官方web版chatgpt的代码（ &lt;a href=&#34;https://github.com/acheong08/ChatGPT&#34;&gt;https://github.com/acheong08/ChatGPT&lt;/a&gt; ）。原理就是把服务器模拟成一个客户端来和openai交互，用户所有请求通过服务器中转到openai。这个模式需要服务器IP是chatgpt支持的区域，并且稳定性差一些，问多了一段时间内可能会一直失败。好处是不限制问题和答案长度，不需要扣费。不过最新的模型放出来之后，这种方案就更加鸡肋了，好在之前没投入太多精力研究……&lt;/p&gt; &#xA;&lt;p&gt;有网友提出想使用docker方式运行本项目，其实随便找一个nginx+php环境的docker，把path指向本项目所在的目录就行了。这里提供热心网友提供的docker镜像：gindex/nginx-php。使用方式如下：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker pull gindex/nginx-php&#xA;docker run -itd -v /root/chatgpt(本地目录):/usr/share/nginx/html --name nginx-php -p 8080(主机端口):80 --restart=always gindex/nginx-php&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;还有另一位热心网友基于本项目在github上的docker版chatgpt，网址：&lt;a href=&#34;https://github.com/hsmbs/chatgpt-php&#34;&gt;https://github.com/hsmbs/chatgpt-php&lt;/a&gt; ，也可以用。&lt;/p&gt; &#xA;&lt;p&gt;喜欢使用独立Windows桌面应用的朋友可以下载Release里面的exe文件运行，其实就是一个指向我演示网站的浏览器套个壳。&lt;/p&gt; &#xA;&lt;p&gt;OpenAI官网的模型和接口调用介绍：&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://platform.openai.com/docs/models/moderation&#34;&gt;https://platform.openai.com/docs/models/moderation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat/create&#34;&gt;https://platform.openai.com/docs/api-reference/chat/create&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://platform.openai.com/docs/guides/chat/introduction&#34;&gt;https://platform.openai.com/docs/guides/chat/introduction&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://platform.openai.com/docs/api-reference/models/list&#34;&gt;https://platform.openai.com/docs/api-reference/models/list&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;对chatgpt感兴趣的同学们欢迎加群讨论。群里有很多大神，有问题可以互相帮助。如果需要在本项目基础上进行二次开发或者其他商务合作，可以加我微信沟通。&lt;/p&gt; &#xA;&lt;p&gt;由于群里人数已超过200，无法直接扫码进群，想进群的朋友可以加热心网友小号，由他帮忙拉进群。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/5563148/223048985-4cac05cb-acf0-4f04-aad5-1c3dcec609d0.png&#34; alt=&#34;微信截图_20230306154434&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;有热心网友建议我放个打赏码，各位如果真的想表达感谢，小额即可。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/5563148/222968018-9def451a-bbce-4a7e-bde6-edecc7ced40f.jpg&#34; alt=&#34;打赏码&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;最后，我还做了个在微信个人订阅号中通过调用OpenAI最新接口和gpt-3.5-turbo模型实现ChatGPT聊天机器人的功能，已开源，需要的朋友也可以拿去。 &lt;a href=&#34;https://github.com/dirk1983/chatgpt-wechat-personal&#34;&gt;https://github.com/dirk1983/chatgpt-wechat-personal&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>zahidkhawaja/langchain-chat-nextjs</title>
    <updated>2023-04-02T01:57:08Z</updated>
    <id>tag:github.com,2023-04-02:/zahidkhawaja/langchain-chat-nextjs</id>
    <link href="https://github.com/zahidkhawaja/langchain-chat-nextjs" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Next.js frontend for LangChain Chat.&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;LangChain Chat - Next.js&lt;/h2&gt; &#xA;&lt;h2&gt;Getting started 🚀&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repo!&lt;/li&gt; &#xA; &lt;li&gt;Install dependencies: &lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run the development server: &lt;code&gt;npm run dev&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Open &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; with your browser to see the result.&lt;/p&gt; &#xA;&lt;p&gt;You can start editing the page by modifying &lt;code&gt;pages/index.js&lt;/code&gt;. The page auto-updates as you edit the file.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://nextjs.org/docs/api-routes/introduction&#34;&gt;API routes&lt;/a&gt; can be accessed on &lt;a href=&#34;http://localhost:3000/api/chat&#34;&gt;http://localhost:3000/api/chat&lt;/a&gt;. This endpoint can be edited in &lt;code&gt;pages/api/chat.js&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;pages/api&lt;/code&gt; directory is mapped to &lt;code&gt;/api/*&lt;/code&gt;. Files in this directory are treated as &lt;a href=&#34;https://nextjs.org/docs/api-routes/introduction&#34;&gt;API routes&lt;/a&gt; instead of React pages.&lt;/p&gt; &#xA;&lt;h2&gt;Learn More&lt;/h2&gt; &#xA;&lt;p&gt;To learn more about Next.js, take a look at the following resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nextjs.org/docs&#34;&gt;Next.js Documentation&lt;/a&gt; - learn about Next.js features and API.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nextjs.org/learn&#34;&gt;Learn Next.js&lt;/a&gt; - an interactive Next.js tutorial.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🦜🔗 Powered by LangChain&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/hwchase17/langchain/&#34;&gt;LangChain&lt;/a&gt; backend implementation can be found &lt;a href=&#34;https://github.com/hwchase17/chat-langchain&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Read more on the &lt;a href=&#34;https://blog.langchain.dev/langchain-chat/&#34;&gt;LangChain blog&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Deployed at &lt;a href=&#34;https://chat.langchain.dev/&#34;&gt;chat.langchain.dev&lt;/a&gt;. Feel free to reach out to &lt;a href=&#34;https://twitter.com/chillzaza_&#34;&gt;Zahid&lt;/a&gt; if you need anything!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>easychen/openai-api-proxy</title>
    <updated>2023-04-02T01:57:08Z</updated>
    <id>tag:github.com,2023-04-02:/easychen/openai-api-proxy</id>
    <link href="https://github.com/easychen/openai-api-proxy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;一行Docker命令部署的 OpenAI/GPT API代理，支持SSE流式返回、按句子流式文本安全、腾讯云函数 。Simple proxy for OpenAi api via a one-line docker command&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;openai-api-proxy&lt;/h1&gt; &#xA;&lt;p&gt;可以部署到docker和云函数的OpenAI API代理 Simple proxy for OpenAi api via a one-line docker command&lt;/p&gt; &#xA;&lt;p&gt;🎉 已经支持SSE，可以实时返回内容 💪 &lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-api-proxy/master/stream-moderation.mp4&#34;&gt;支持流式内容文本安全&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-api-proxy/master/FUNC.md&#34;&gt;腾讯云函数部署教程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-api-proxy/master/README.CN.md&#34;&gt;简体中文使用说明&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/easychen/openai-gpt-dev-notes-for-cn-developer&#34;&gt;《如何快速开发一个OpenAI/GPT应用：国内开发者笔记》&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;以下英文由GPT翻译。The following English was translated by GPT.&lt;/p&gt; &#xA;&lt;p&gt;⚠️ This is the server-side of the proxy, not the client-side. It needs to be deployed to a network environment that can access the openai api.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Supports SSE streaming output&lt;/li&gt; &#xA; &lt;li&gt;Built-in text moderation (requires Tencent Cloud KEY configuration)&lt;/li&gt; &#xA; &lt;li&gt;💪 SSE streaming output supports text moderation, that&#39;s how powerful it is.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;NodeJS Deployment&lt;/h2&gt; &#xA;&lt;p&gt;You can deploy ./app.js to any environment that supports nodejs 14+, such as cloud functions and edge computing platforms.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Copy app.js and package.json to the directory&lt;/li&gt; &#xA; &lt;li&gt;Install dependencies with yarn install&lt;/li&gt; &#xA; &lt;li&gt;Start the service with node app.js&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Docker Deployment&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -p 9000:9000 easychen/ai.level06.com:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The proxy address is http://${IP}:9000&lt;/p&gt; &#xA;&lt;h3&gt;Available Environment Variables&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;PORT: Service port&lt;/li&gt; &#xA; &lt;li&gt;PROXY_KEY: Proxy access key, used to restrict access&lt;/li&gt; &#xA; &lt;li&gt;TIMEOUT: Request timeout, default 30 seconds&lt;/li&gt; &#xA; &lt;li&gt;TENCENT_CLOUD_SID: Tencent Cloud secret_id&lt;/li&gt; &#xA; &lt;li&gt;TENCENT_CLOUD_SKEY: Tencent Cloud secret_key&lt;/li&gt; &#xA; &lt;li&gt;TENCENT_CLOUD_AP: Tencent Cloud region (e.g. ap-singapore Singapore)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;API Usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Change the domain/IP (with port number) of the openai request address in the original project (e.g. &lt;a href=&#34;https://api.openai.com&#34;&gt;https://api.openai.com&lt;/a&gt;) to the domain/IP of this proxy.&lt;/li&gt; &#xA; &lt;li&gt;If PROXY_KEY is set, add &lt;code&gt;:&amp;lt;PROXY_KEY&amp;gt;&lt;/code&gt; after the openai key. If not set, no modification is required.&lt;/li&gt; &#xA; &lt;li&gt;moderation: true enables moderation, false disables moderation&lt;/li&gt; &#xA; &lt;li&gt;moderation_level: high interrupts all sentences whose moderation result is not Pass, low only interrupts sentences whose moderation result is Block.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Notes&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Only supports GET and POST methods, not file-related interfaces.&lt;/li&gt; &#xA; &lt;li&gt;&lt;del&gt;SSE is not currently supported, so stream-related options need to be turned off&lt;/del&gt; Now supported.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Client-side Usage Example&lt;/h2&gt; &#xA;&lt;p&gt;Using &lt;code&gt;https://www.npmjs.com/package/chatgpt&lt;/code&gt; as an example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;chatApi= new gpt.ChatGPTAPI({&#xA;    apiKey: &#39;sk.....:&amp;lt;proxy_key_here&amp;gt;&#39;,&#xA;    apiBaseUrl: &#34;http://localhost:9001/v1&#34;, // Replace with proxy domain/IP&#xA;});&#xA;   &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;SSE reference to &lt;a href=&#34;https://github.com/transitive-bullshit/chatgpt-api/raw/main/src/fetch-sse.ts&#34;&gt;chatgpt-api project related code&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
</feed>