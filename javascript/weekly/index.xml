<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-12T01:57:31Z</updated>
  <subtitle>Weekly Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>vincelwt/chatgpt-mac</title>
    <updated>2023-02-12T01:57:31Z</updated>
    <id>tag:github.com,2023-02-12:/vincelwt/chatgpt-mac</id>
    <link href="https://github.com/vincelwt/chatgpt-mac" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGPT for Mac, living in your menubar.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT for desktop&lt;/h1&gt; &#xA;&lt;p&gt;This is a simple app that makes ChatGPT live in your menubar.&lt;/p&gt; &#xA;&lt;p&gt;You can use Cmd+Shift+G (Mac) or Ctrl+Shift+G (Win) to quickly open it from anywhere.&lt;/p&gt; &#xA;&lt;p&gt;Download:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vincelwt/chatgpt-mac/releases/download/v0.0.5/ChatGPT-0.0.5-arm64.dmg&#34;&gt;Mac Arm64 .dmg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vincelwt/chatgpt-mac/releases/download/v0.0.5/ChatGPT-0.0.5-x64.dmg&#34;&gt;Mac Intel .dmg&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;No Windows binaries currently offered. Clone the repo, npm install electron-forge and run.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/vincelwt/chatgpt-mac/main/images/screenshot.jpeg&#34; width=&#34;500&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Credit&lt;/h2&gt; &#xA;&lt;p&gt;All credit and copyrights goes to OpenAI.&lt;/p&gt; &#xA;&lt;h2&gt;Author&lt;/h2&gt; &#xA;&lt;p&gt;You can find me on Twitter &lt;a href=&#34;https://twitter.com/vincelwt&#34;&gt;@vincelwt&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>waylaidwanderer/node-chatgpt-api</title>
    <updated>2023-02-12T01:57:31Z</updated>
    <id>tag:github.com,2023-02-12:/waylaidwanderer/node-chatgpt-api</id>
    <link href="https://github.com/waylaidwanderer/node-chatgpt-api" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A ChatGPT implementation with support for Bing&#39;s GPT-4 version of ChatGPT, plus the official ChatGPT model via OpenAI&#39;s API. Available as a Node.js module, REST API server, and CLI app.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;CLI demo&#34; src=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/demos/cli.svg?v=1&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Updates&lt;/h2&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;strong&gt;2023-02-11&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;p&gt;With the help of @PawanOsman, we&#39;ve figured out a way to continue using the ChatGPT raw models directly. In an attempt to prevent the models from being disabled again, we&#39;ve decided to provide a reverse proxy (i.e. a private API server) with a completions endpoint that&#39;s compatible with the OpenAI API. I&#39;ve updated &lt;code&gt;ChatGPTClient&lt;/code&gt; to support using a reverse proxy URL endpoint instead of the default OpenAI API endpoint. See &lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#using-a-reverse-proxy&#34;&gt;Using a Reverse Proxy&lt;/a&gt; for more information.&lt;/p&gt; &#xA; &lt;p&gt;Please note that if you choose to go this route, you are exposing your API key or session token to a third-party server. If you are concerned about this, you may choose to use the official OpenAI API instead, with the &lt;code&gt;text-davinci-003&lt;/code&gt; model.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;2023-02-10&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;p&gt;&lt;del&gt;I&#39;ve found a new working model for &lt;code&gt;text-chat-davinci-002&lt;/code&gt;, &lt;code&gt;text-chat-davinci-002-sh-alpha-aoruigiofdj83&lt;/code&gt;. This is the raw model that the ChatGPT Plus &#34;Turbo&#34; version uses. Responses are blazing fast. I&#39;ve updated the library to use this model.&lt;/del&gt;&lt;/p&gt; &#xA; &lt;p&gt;Bad timing; &lt;code&gt;text-chat-davinci-002-sh-alpha-aoruigiofdj83&lt;/code&gt; was removed shortly after, possibly due to a new model somewhere out there?&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;2023-02-09&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;p&gt;Experience the power of Bing&#39;s GPT-4 version of ChatGPT with &lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/src/BingAIClient.js&#34;&gt;&lt;code&gt;BingAIClient&lt;/code&gt;&lt;/a&gt; (experimental). &lt;strong&gt;The &lt;del&gt;API server and&lt;/del&gt; CLI still need to be updated to support this&lt;/strong&gt;, but you can &lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#module&#34;&gt;use the client&lt;/a&gt; directly right now. &lt;em&gt;Please note that if your account is still wait-listed, you will not be able to use this client.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;2023-02-08&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;p&gt;Even though &lt;code&gt;text-chat-davinci-002-20221122&lt;/code&gt; is back up again, it seems like it&#39;s constantly overloaded and returns a 429 error. It&#39;s likely that OpenAI only dedicated a small amount of resources to this model to prevent it being widely used by the public. Additionally, I&#39;ve heard that newer versions are now access-locked to OpenAI employees and partners, so it&#39;s unlikely that we&#39;ll be able to find any workarounds until the model is officially released.&lt;/p&gt; &#xA; &lt;p&gt;You may use the &lt;code&gt;text-davinci-003&lt;/code&gt; model instead as a drop-in replacement. Keep in mind that &lt;code&gt;text-davinci-003&lt;/code&gt; is not as good as &lt;code&gt;text-chat-davinci-002&lt;/code&gt; (which is trained via RHLF and fine-tuned to be a conversational AI), though results are still pretty good in most cases. &lt;strong&gt;Please note that using &lt;code&gt;text-davinci-003&lt;/code&gt; will cost you credits ($).&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;I will be re-adding support for the browser-based ChatGPT for the API server and CLI. Please star and watch this repository for updates.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;2023-02-07&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;p&gt;The roller coaster has reached the next stop. &lt;code&gt;text-chat-davinci-002-20221122&lt;/code&gt; is back up again.&lt;/p&gt; &#xA; &lt;p&gt;&lt;del&gt;Trying to use &lt;code&gt;text-chat-davinci-002-20221122&lt;/code&gt; with the OpenAI API now returns a 404 error. You may use the &lt;code&gt;text-davinci-003&lt;/code&gt; model instead as a drop-in replacement. Keep in mind that &lt;code&gt;text-davinci-003&lt;/code&gt; is not as good as &lt;code&gt;text-chat-davinci-002&lt;/code&gt; (which is trained via RHLF and fine-tuned to be a conversational AI), though results are still very good. &lt;strong&gt;Please note that using &lt;code&gt;text-davinci-003&lt;/code&gt; will cost you credits ($).&lt;/strong&gt;&lt;/del&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;del&gt;Please hold for further updates as we investigate further workarounds.&lt;/del&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;2023-02-02&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;p&gt;&lt;del&gt;Trying to use &lt;code&gt;text-chat-davinci-002-20230126&lt;/code&gt; with the OpenAI API now returns a 404 error. Someone has already found the new model name, but they are unwilling to share at this time. I will update this repository once I find the new model. If you have any leads, please open an issue or a pull request.&lt;/del&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;del&gt;In the meantime, I&#39;ve added support for models like &lt;code&gt;text-davinci-003&lt;/code&gt;, which you can use as a drop-in replacement. Keep in mind that &lt;code&gt;text-davinci-003&lt;/code&gt; is not as good as &lt;code&gt;text-chat-davinci-002&lt;/code&gt; (which is trained via RHLF and fine-tuned to be a conversational AI), though results are still very good. &lt;strong&gt;Please note that using &lt;code&gt;text-davinci-003&lt;/code&gt; will cost you credits ($).&lt;/strong&gt;&lt;/del&gt;&lt;/p&gt; &#xA; &lt;p&gt;Discord user @pig#8932 has found a working &lt;code&gt;text-chat-davinci-002&lt;/code&gt; model, &lt;code&gt;text-chat-davinci-002-20221122&lt;/code&gt;. I&#39;ve updated the library to use this model.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h1&gt;ChatGPT API&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;A ChatGPT implementation with support for Bing&#39;s GPT-4 version of ChatGPT, plus the official ChatGPT model via OpenAI&#39;s API. Available as a Node.js module, REST API server, and CLI app.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.npmjs.com/package/@waylaidwanderer/chatgpt-api&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/@waylaidwanderer/chatgpt-api.svg?sanitize=true&#34; alt=&#34;NPM&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmjs.com/package/@waylaidwanderer/chatgpt-api&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/dt/@waylaidwanderer/chatgpt-api&#34; alt=&#34;npm&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/waylaidwanderer/node-chatgpt-api/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue&#34; alt=&#34;MIT License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/waylaidwanderer/node-chatgpt-api/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/waylaidwanderer/node-chatgpt-api&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is an implementation of &lt;a href=&#34;https://chat.openai.com/chat&#34;&gt;ChatGPT&lt;/a&gt;, with support for Bing&#39;s GPT-4 version of ChatGPT, plus the official ChatGPT raw model, &lt;code&gt;text-chat-davinci-002&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;About Bing&#39;s GPT-4 version of ChatGPT&lt;/h4&gt; &#xA;&lt;p&gt;An experimental client for Bing&#39;s GPT-4 version of ChatGPT is available in &lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/src/BingAIClient.js&#34;&gt;&lt;code&gt;BingAIClient&lt;/code&gt;&lt;/a&gt;. It works much like ChatGPT, but it&#39;s powered by GPT-4 instead of GPT-3. For more information on its capabilities and limitations, see &lt;a href=&#34;https://www.reddit.com/r/ChatGPT/comments/10xjda1/comment/j7snwxx/?utm_source=reddit&amp;amp;utm_medium=web2x&amp;amp;context=3&#34;&gt;this Reddit comment&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;About &lt;code&gt;text-chat-davinci-002&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;p&gt;The model name &lt;code&gt;text-chat-davinci-002-20230126&lt;/code&gt; was briefly leaked while I was inspecting the network requests made by the official ChatGPT website, and I discovered that it works with the &lt;a href=&#34;https://beta.openai.com/docs/api-reference/completions&#34;&gt;OpenAI API&lt;/a&gt;. Since then, that model and others have been disabled, but I&#39;m keeping this repo updated with the newer versions of &lt;code&gt;text-chat-davinci-002&lt;/code&gt; as we find them. &lt;strong&gt;Usage of this model currently does not cost any credits.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;As far as I&#39;m aware, I was the first one who discovered this, and usage of the model has since been implemented in libraries like &lt;a href=&#34;https://github.com/acheong08/ChatGPT&#34;&gt;acheong08/ChatGPT&lt;/a&gt; and &lt;a href=&#34;https://github.com/transitive-bullshit/chatgpt-api&#34;&gt;transitive-bullshit/chatgpt-api&lt;/a&gt; as we collaborated and shared knowledge.&lt;/p&gt; &#xA;&lt;p&gt;By itself, the model does not have any conversational support, so &lt;code&gt;ChatGPTClient&lt;/code&gt; uses a cache to store conversations and pass them to the model as context. This allows you to have persistent conversations with ChatGPT in a nearly identical way to the official website.&lt;/p&gt; &#xA;&lt;h1&gt;Table of Contents&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#prerequisites&#34;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#module&#34;&gt;Module&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#api-server&#34;&gt;API Server&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#cli&#34;&gt;CLI&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#using-a-reverse-proxy&#34;&gt;Using a Reverse Proxy&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#caveats&#34;&gt;Caveats&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Experimental support for Bing&#39;s version of ChatGPT, powered by GPT-4.&lt;/li&gt; &#xA; &lt;li&gt;Support for the official ChatGPT raw model, &lt;code&gt;text-chat-davinci-002&lt;/code&gt;, via OpenAI&#39;s API.&lt;/li&gt; &#xA; &lt;li&gt;Includes an API server (with Docker support) you can run to use ChatGPT in non-Node.js applications.&lt;/li&gt; &#xA; &lt;li&gt;Includes a &lt;code&gt;ChatGPTClient&lt;/code&gt; and &lt;code&gt;BingAIClient&lt;/code&gt; class that you can use in your own Node.js applications.&lt;/li&gt; &#xA; &lt;li&gt;Includes a CLI interface where you can chat with ChatGPT.&lt;/li&gt; &#xA; &lt;li&gt;(&lt;code&gt;ChatGPTClient&lt;/code&gt;) Replicates chat threads from the official ChatGPT website (with conversation IDs and message IDs), with persistent conversations using &lt;a href=&#34;https://www.npmjs.com/package/keyv&#34;&gt;Keyv&lt;/a&gt;. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Conversations are stored in memory by default, but you can optionally &lt;a href=&#34;https://www.npmjs.com/package/keyv#usage&#34;&gt;install a storage adapter&lt;/a&gt; to persist conversations to a database.&lt;/li&gt; &#xA;   &lt;li&gt;The &lt;code&gt;keyv-file&lt;/code&gt; adapter is also included in this package, and can be used to store conversations in a JSON file if you&#39;re using the API server or CLI (see &lt;code&gt;settings.example.js&lt;/code&gt;).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;(&lt;code&gt;ChatGPTClient&lt;/code&gt;) Supports configurable prompt prefixes, and custom names for the user and ChatGPT. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;In essence, this allows you to turn ChatGPT into a different character.&lt;/li&gt; &#xA;   &lt;li&gt;This is currently only configurable on a global level, but I plan to add support for per-conversation customization.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Node.js &amp;gt;= 16.0.0&lt;/li&gt; &#xA; &lt;li&gt;npm&lt;/li&gt; &#xA; &lt;li&gt;Docker (optional, for API server)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI API key&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Module&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm i @waylaidwanderer/chatgpt-api&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;strong&gt;BingAIClient&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;import { BingAIClient } from &#39;@waylaidwanderer/chatgpt-api&#39;;&#xA;&#xA;const bingAIClient = new BingAIClient({&#xA;  userToken: &#39;&#39;, // &#34;_U&#34; cookie from bing.com&#xA;  debug: false,&#xA;});&#xA;&#xA;let response = await bingAIClient.sendMessage(&#39;Write a short poem about cats&#39;, {&#xA;  onProgress: (token) =&amp;gt; {&#xA;    process.stdout.write(token);&#xA;  },&#xA;});&#xA;console.log(response);&#xA;&#xA;response = await bingAIClient.sendMessage(&#39;Now write it in French&#39;, {&#xA;  conversationSignature: response.conversationSignature,&#xA;  conversationId: response.conversationId,&#xA;  clientId: response.clientId,&#xA;  invocationId: response.invocationId,&#xA;  onProgress: (token) =&amp;gt; {&#xA;    process.stdout.write(token);&#xA;  },&#xA;});&#xA;console.log(response);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;ChatGPTClient&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;import { ChatGPTClient } from &#39;@waylaidwanderer/chatgpt-api&#39;;&#xA;&#xA;const clientOptions = {&#xA;  // (Optional) Support for a reverse proxy for the completions endpoint (private API server).&#xA;  // Warning: This will expose your `openaiApiKey` to a third-party. Consider the risks before using this.&#xA;  // reverseProxyUrl: &#39;https://chatgpt.pawan.krd/api/completions&#39;,&#xA;  // (Optional) Parameters as described in https://platform.openai.com/docs/api-reference/completions&#xA;  modelOptions: {&#xA;    // You can override the model name and any other parameters here.&#xA;    // model: &#39;text-chat-davinci-002-20221122&#39;,&#xA;  },&#xA;  // (Optional) Set custom instructions instead of &#34;You are ChatGPT...&#34;.&#xA;  // promptPrefix: &#39;You are Bob, a cowboy in Western times...&#39;,&#xA;  // (Optional) Set a custom name for the user&#xA;  // userLabel: &#39;User&#39;,&#xA;  // (Optional) Set a custom name for ChatGPT&#xA;  // chatGptLabel: &#39;ChatGPT&#39;,&#xA;  // (Optional) Set to true to enable `console.debug()` logging&#xA;  debug: false,&#xA;};&#xA;&#xA;const cacheOptions = {&#xA;  // Options for the Keyv cache, see https://www.npmjs.com/package/keyv&#xA;  // This is used for storing conversations, and supports additional drivers (conversations are stored in memory by default)&#xA;  // For example, to use a JSON file (`npm i keyv-file`) as a database:&#xA;  // store: new KeyvFile({ filename: &#39;cache.json&#39; }),&#xA;};&#xA;&#xA;const chatGptClient = new ChatGPTClient(&#39;OPENAI_API_KEY&#39;, clientOptions, cacheOptions);&#xA;&#xA;const response = await chatGptClient.sendMessage(&#39;Hello!&#39;);&#xA;console.log(response); // { response: &#39;Hi! How can I help you today?&#39;, conversationId: &#39;...&#39;, messageId: &#39;...&#39; }&#xA;&#xA;const response2 = await chatGptClient.sendMessage(&#39;Write a poem about cats.&#39;, { conversationId: response.conversationId, parentMessageId: response.messageId });&#xA;console.log(response2.response); // Cats are the best pets in the world.&#xA;&#xA;const response3 = await chatGptClient.sendMessage(&#39;Now write it in French.&#39;, {&#xA;  conversationId: response2.conversationId,&#xA;  parentMessageId: response2.messageId,&#xA;  // If you want streamed responses, you can set the `onProgress` callback to receive the response as it&#39;s generated.&#xA;  // You will receive one token at a time, so you will need to concatenate them yourself.&#xA;  onProgress: (token) =&amp;gt; console.log(token),&#xA;});&#xA;console.log(response3.response); // Les chats sont les meilleurs animaux de compagnie du monde.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;API Server&lt;/h3&gt; &#xA;&lt;h4 id=&#34;api-server-setup&#34;&gt;Setup&lt;/h4&gt; &#xA;&lt;p&gt;You can install the package using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm i -g @waylaidwanderer/chatgpt-api&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;then run it using &lt;code&gt;chatgpt-api&lt;/code&gt;. This takes an optional &lt;code&gt;--settings=&amp;lt;path_to_settings.js&amp;gt;&lt;/code&gt; parameter, or looks for &lt;code&gt;settings.js&lt;/code&gt; in the current directory if not set, with the following contents:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;module.exports = {&#xA;    // Your OpenAI API key (for `ChatGPTClient`)&#xA;    openaiApiKey: process.env.OPENAI_API_KEY || &#39;&#39;,&#xA;    chatGptClient: {&#xA;        // (Optional) Support for a reverse proxy for the completions endpoint (private API server).&#xA;        // Warning: This will expose your `openaiApiKey` to a third-party. Consider the risks before using this.&#xA;        // reverseProxyUrl: &#39;https://chatgpt.pawan.krd/api/completions&#39;,&#xA;        // (Optional) Parameters as described in https://platform.openai.com/docs/api-reference/completions&#xA;        modelOptions: {&#xA;            // You can override the model name and any other parameters here.&#xA;            // model: &#39;text-chat-davinci-002-20221122&#39;,&#xA;        },&#xA;        // (Optional) Set custom instructions instead of &#34;You are ChatGPT...&#34;.&#xA;        // promptPrefix: &#39;You are Bob, a cowboy in Western times...&#39;,&#xA;        // (Optional) Set a custom name for the user&#xA;        // userLabel: &#39;User&#39;,&#xA;        // (Optional) Set a custom name for ChatGPT&#xA;        // chatGptLabel: &#39;ChatGPT&#39;,&#xA;        // (Optional) Set to true to enable `console.debug()` logging&#xA;        debug: false,&#xA;    },&#xA;    // Options for the Keyv cache, see https://www.npmjs.com/package/keyv.&#xA;    // This is used for storing conversations, and supports additional drivers (conversations are stored in memory by default).&#xA;    // Does not apply when using `BingAIClient`.&#xA;    cacheOptions: {},&#xA;    // Options for the Bing client&#xA;    bingAiClient: {&#xA;        // The &#34;_U&#34; cookie value from bing.com&#xA;        userToken: &#39;&#39;,&#xA;        // (Optional) Set to true to enable `console.debug()` logging&#xA;        debug: false,&#xA;    },&#xA;    // Options for the API server&#xA;    apiOptions: {&#xA;        port: process.env.API_PORT || 3000,&#xA;        host: process.env.API_HOST || &#39;localhost&#39;,&#xA;        // (Optional) Set to true to enable `console.debug()` logging&#xA;        debug: false,&#xA;        // (Optional) Set to &#34;bing&#34; to use `BingAIClient` instead of `ChatGPTClient`.&#xA;        // clientToUse: &#39;bing&#39;,&#xA;    },&#xA;    // If set, `ChatGPTClient` will use `keyv-file` to store conversations to this JSON file instead of in memory.&#xA;    // However, `cacheOptions.store` will override this if set&#xA;    storageFilePath: process.env.STORAGE_FILE_PATH || &#39;./cache.json&#39;,&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can install and run the package directly.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository: &lt;code&gt;git clone https://github.com/waylaidwanderer/node-chatgpt-api&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install dependencies with &lt;code&gt;npm install&lt;/code&gt; (if not using Docker)&lt;/li&gt; &#xA; &lt;li&gt;Rename &lt;code&gt;settings.example.js&lt;/code&gt; to &lt;code&gt;settings.js&lt;/code&gt; in the root directory and change the settings where required.&lt;/li&gt; &#xA; &lt;li&gt;Start the server: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;using &lt;code&gt;npm start&lt;/code&gt; or &lt;code&gt;npm run server&lt;/code&gt; (if not using Docker)&lt;/li&gt; &#xA;   &lt;li&gt;using &lt;code&gt;docker-compose up&lt;/code&gt; (requires Docker)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Usage&lt;/h4&gt; &#xA;&lt;p&gt;To start a conversation with ChatGPT, send a POST request to the server&#39;s &lt;code&gt;/conversation&lt;/code&gt; endpoint with a JSON body in the following format. Optional parameters are only necessary for conversations that span multiple requests:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JSON&#34;&gt;{&#xA;    &#34;message&#34;: &#34;Hello, how are you today?&#34;,&#xA;    &#34;conversationId&#34;: &#34;your-conversation-id (optional)&#34;,&#xA;    &#34;parentMessageId&#34;: &#34;your-parent-message-id (optional, for `ChatGPTClient` only)&#34;,&#xA;    &#34;conversationSignature&#34;: &#34;your-conversation-signature (optional, for `BingAIClient` only)&#34;,&#xA;    &#34;clientId&#34;: &#34;your-client-id (optional, for `BingAIClient` only)&#34;,&#xA;    &#34;invocationId&#34;: &#34;your-invocation-id (optional, for `BingAIClient` only)&#34;,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The server will return a JSON object containing ChatGPT&#39;s response:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;// HTTP/1.1 200 OK&#xA;{&#xA;    &#34;response&#34;: &#34;I&#39;m doing well, thank you! How are you?&#34;,&#xA;    &#34;conversationId&#34;: &#34;your-conversation-id&#34;,&#xA;    &#34;messageId&#34;: &#34;response-message-id (for `ChatGPTClient` only)&#34;,&#xA;    &#34;conversationSignature&#34;: &#34;your-conversation-signature (for `BingAIClient` only)&#34;,&#xA;    &#34;clientId&#34;: &#34;your-client-id (for `BingAIClient` only)&#34;,&#xA;    &#34;invocationId&#34;: &#34;your-invocation-id (for `BingAIClient` only - pass this new value back into subsequent requests as-is)&#34;,&#xA;    &#34;details&#34;: &#34;additional details about the AI&#39;s response (for `BingAIClient` only)&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the request is unsuccessful, the server will return a JSON object with an error message.&lt;/p&gt; &#xA;&lt;p&gt;If the request object is missing a required property (e.g. &lt;code&gt;message&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;// HTTP/1.1 400 Bad Request&#xA;{&#xA;    &#34;error&#34;: &#34;The message parameter is required.&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If there was an error sending the message to ChatGPT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;// HTTP/1.1 503 Service Unavailable&#xA;{&#xA;    &#34;error&#34;: &#34;There was an error communicating with ChatGPT.&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can set &lt;code&gt;&#34;stream&#34;: true&lt;/code&gt; in the request body to receive a stream of tokens as they are generated.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JSON&#34;&gt;{&#xA;    &#34;message&#34;: &#34;Write a poem about cats.&#34;,&#xA;    &#34;conversationId&#34;: &#34;your-conversation-id (optional)&#34;,&#xA;    &#34;parentMessageId&#34;: &#34;your-parent-message-id (optional)&#34;,&#xA;    &#34;stream&#34;: true&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/demos/use-api-server-streaming.js&#34;&gt;demos/use-api-server-streaming.js&lt;/a&gt; for an example of how to receive the response as it&#39;s generated. You will receive one token at a time, so you will need to concatenate them yourself.&lt;/p&gt; &#xA;&lt;p&gt;Successful output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;{ data: &#39;&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: 3000 }&#xA;{ data: &#39;Hello&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;{ data: &#39;!&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;{ data: &#39; How&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;{ data: &#39; can&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;{ data: &#39; I&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;{ data: &#39; help&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;{ data: &#39; you&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;{ data: &#39; today&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;{ data: &#39;?&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;{ data: &#39;[DONE]&#39;, event: &#39;&#39;, id: &#39;&#39;, retry: undefined }&#xA;// Hello! How can I help you today?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Error output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;const message = {&#xA;  data: &#39;{&#34;code&#34;:503,&#34;error&#34;:&#34;There was an error communicating with ChatGPT.&#34;}&#39;,&#xA;  event: &#39;error&#39;,&#xA;  id: &#39;&#39;,&#xA;  retry: undefined&#xA;};&#xA;&#xA;if (message.event === &#39;error&#39;) {&#xA;  console.error(JSON.parse(message.data).error); // There was an error communicating with ChatGPT.&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;CLI&lt;/h3&gt; &#xA;&lt;h4&gt;Setup&lt;/h4&gt; &#xA;&lt;p&gt;Follow the same &lt;a href=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/#api-server-setup&#34;&gt;setup instructions&lt;/a&gt; for the API server, creating &lt;code&gt;settings.js&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Usage&lt;/h4&gt; &#xA;&lt;p&gt;If installed globally:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chatgpt-cli&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If installed locally:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run cli&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ChatGPT&#39;s responses are automatically copied to your clipboard, so you can paste them into other applications.&lt;/p&gt; &#xA;&lt;h2&gt;Using a Reverse Proxy&lt;/h2&gt; &#xA;&lt;p&gt;As shown in the examples above, you can set &lt;code&gt;reverseProxyUrl&lt;/code&gt; in &lt;code&gt;ChatGPTClient&lt;/code&gt;&#39;s options to use a private API instead of the official ChatGPT API. For now, this is the only way to use the ChatGPT raw models directly.&lt;/p&gt; &#xA;&lt;p&gt;Depending on whose private API you use, there are some things you have to do differently to make it work with &lt;code&gt;ChatGPTClient&lt;/code&gt;, and some things may not work as expected. Instructions and any caveats are provided below.&lt;/p&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;strong&gt;https://chatgpt.pawan.krd/api/completions&lt;/strong&gt; (@PawanOsmon)&lt;/summary&gt; &#xA; &lt;h4&gt;Instructions&lt;/h4&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Set &lt;code&gt;reverseProxyUrl&lt;/code&gt; to &lt;code&gt;https://chatgpt.pawan.krd/api/completions&lt;/code&gt; in &lt;code&gt;settings.js&lt;/code&gt; or &lt;code&gt;ChatGPTClient&lt;/code&gt;&#39;s options.&lt;/li&gt; &#xA;  &lt;li&gt;Set the OpenAI API key to your ChatGPT session&#39;s access token instead of your actual OpenAI API key. &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;You can find your ChatGPT session&#39;s access token by logging in to &lt;a href=&#34;https://chat.openai.com/&#34;&gt;ChatGPT&lt;/a&gt; and then going to &lt;a href=&#34;https://chat.openai.com/api/auth/session&#34;&gt;https://chat.openai.com/api/auth/session&lt;/a&gt; (look for the &lt;code&gt;accessToken&lt;/code&gt; property).&lt;/li&gt; &#xA;    &lt;li&gt;&lt;strong&gt;Fetching or refreshing your ChatGPT session&#39;s access token is not currently supported by this library.&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;Set the &lt;code&gt;model&lt;/code&gt; to &lt;code&gt;text-davinci-002-render&lt;/code&gt;, &lt;code&gt;text-davinci-002-render-paid&lt;/code&gt;, or any other ChatGPT models that your account has access to. Models &lt;strong&gt;must&lt;/strong&gt; be a ChatGPT model name, not the raw model name, and you cannot use a model that your account does not have access to. &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;You can check which ones you have access to by opening DevTools and going to the Network tab. Refresh the page and look at the response body for &lt;a href=&#34;https://chat.openai.com/backend-api/models&#34;&gt;https://chat.openai.com/backend-api/models&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;h4&gt;Caveats&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Custom stop sequences (&lt;code&gt;stop&lt;/code&gt;) are not supported. You must handle that yourself or modify your &lt;code&gt;promptPrefix&lt;/code&gt; to work around it.&lt;/li&gt; &#xA;  &lt;li&gt;Frequency and presence penalties don&#39;t appear to do anything.&lt;/li&gt; &#xA;  &lt;li&gt;Temperature doesn&#39;t work as expected. Setting it to 0-1 appears to have an effect, but setting it above 1 doesn&#39;t seem to do anything.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Caveats&lt;/h2&gt; &#xA;&lt;p&gt;Since &lt;code&gt;text-chat-davinci-002&lt;/code&gt; is ChatGPT&#39;s raw model, I had to do my best to replicate the way the official ChatGPT website uses it. After extensive testing and comparing responses, I believe that the model used by ChatGPT has some additional fine-tuning. This means my implementation or the raw model may not behave exactly the same in some ways:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Conversations are not tied to any user IDs, so if that&#39;s important to you, you should implement your own user ID system.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ChatGPT&#39;s model parameters (temperature, frequency penalty, etc.) are unknown, so I set some defaults that I thought would be reasonable.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Conversations are limited to roughly the last 3000 tokens, so earlier messages may be forgotten during longer conversations.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This works in a similar way to ChatGPT, except I&#39;m pretty sure they have some additional way of retrieving context from earlier messages when needed (which can probably be achieved with embeddings, but I consider that out-of-scope for now).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;It is well known that, as part of the fine-tuning, ChatGPT had the following preamble:&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;&#34;You are ChatGPT, a large language model trained by OpenAI. You answer as concisely as possible for each response (e.g. don’t be verbose). It is very important that you answer as concisely as possible, so please remember this. If you are generating a list, do not have too many items. Keep the number of items short. Knowledge cutoff: 2021-09 Current date: 2023-01-31&#34;&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;p&gt;As OpenAI updates ChatGPT, this preamble may also change. The default prompt prefix in my implementation attempts to replicate a similar behavior to the current ChatGPT model.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;d like to contribute to this project, please create a pull request with a detailed description of your changes.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the MIT License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OpenZeppelin/openzeppelin-contracts</title>
    <updated>2023-02-12T01:57:31Z</updated>
    <id>tag:github.com,2023-02-12:/OpenZeppelin/openzeppelin-contracts</id>
    <link href="https://github.com/OpenZeppelin/openzeppelin-contracts" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenZeppelin Contracts is a library for secure smart contract development.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/logo.svg?sanitize=true&#34; alt=&#34;OpenZeppelin&#34; height=&#34;40px&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.npmjs.org/package/@openzeppelin/contracts&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/@openzeppelin/contracts.svg?sanitize=true&#34; alt=&#34;NPM Package&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts/graph/badge.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.gitpoap.io/gh/OpenZeppelin/openzeppelin-contracts&#34;&gt;&lt;img src=&#34;https://public-api.gitpoap.io/v1/repo/OpenZeppelin/openzeppelin-contracts/badge&#34; alt=&#34;GitPOAPs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.openzeppelin.com/contracts&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-%F0%9F%93%84-yellow&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.openzeppelin.com/contracts&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/forum-%F0%9F%92%AC-yellow&#34; alt=&#34;Forum&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A library for secure smart contract development.&lt;/strong&gt; Build on a solid foundation of community-vetted code.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Implementations of standards like &lt;a href=&#34;https://docs.openzeppelin.com/contracts/erc20&#34;&gt;ERC20&lt;/a&gt; and &lt;a href=&#34;https://docs.openzeppelin.com/contracts/erc721&#34;&gt;ERC721&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Flexible &lt;a href=&#34;https://docs.openzeppelin.com/contracts/access-control&#34;&gt;role-based permissioning&lt;/a&gt; scheme.&lt;/li&gt; &#xA; &lt;li&gt;Reusable &lt;a href=&#34;https://docs.openzeppelin.com/contracts/utilities&#34;&gt;Solidity components&lt;/a&gt; to build custom contracts and complex decentralized systems.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;span&gt;🧙&lt;/span&gt; &lt;strong&gt;Not sure how to get started?&lt;/strong&gt; Check out &lt;a href=&#34;https://wizard.openzeppelin.com/&#34;&gt;Contracts Wizard&lt;/a&gt; — an interactive smart contract generator.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;🏗&lt;/span&gt; &lt;strong&gt;Want to scale your decentralized application?&lt;/strong&gt; Check out &lt;a href=&#34;https://openzeppelin.com/defender&#34;&gt;OpenZeppelin Defender&lt;/a&gt; — a secure platform for automating and monitoring your operations.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ npm install @openzeppelin/contracts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;OpenZeppelin Contracts features a &lt;a href=&#34;https://docs.openzeppelin.com/contracts/releases-stability#api-stability&#34;&gt;stable API&lt;/a&gt;, which means that your contracts won&#39;t break unexpectedly when upgrading to a newer minor version.&lt;/p&gt; &#xA;&lt;p&gt;An alternative to npm is to use the GitHub repository (&lt;code&gt;openzeppelin/openzeppelin-contracts&lt;/code&gt;) to retrieve the contracts. When doing this, make sure to specify the tag for a release such as &lt;code&gt;v4.5.0&lt;/code&gt;, instead of using the &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Once installed, you can use the contracts in the library by importing them:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-solidity&#34;&gt;pragma solidity ^0.8.0;&#xA;&#xA;import &#34;@openzeppelin/contracts/token/ERC721/ERC721.sol&#34;;&#xA;&#xA;contract MyCollectible is ERC721 {&#xA;    constructor() ERC721(&#34;MyCollectible&#34;, &#34;MCO&#34;) {&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;If you&#39;re new to smart contract development, head to &lt;a href=&#34;https://docs.openzeppelin.com/learn/developing-smart-contracts&#34;&gt;Developing Smart Contracts&lt;/a&gt; to learn about creating a new project and compiling your contracts.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;To keep your system secure, you should &lt;strong&gt;always&lt;/strong&gt; use the installed code as-is, and neither copy-paste it from online sources nor modify it yourself. The library is designed so that only the contracts and functions you use are deployed, so you don&#39;t need to worry about it needlessly increasing gas costs.&lt;/p&gt; &#xA;&lt;h2&gt;Learn More&lt;/h2&gt; &#xA;&lt;p&gt;The guides in the &lt;a href=&#34;https://docs.openzeppelin.com/contracts&#34;&gt;documentation site&lt;/a&gt; will teach about different concepts, and how to use the related contracts that OpenZeppelin Contracts provides:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openzeppelin.com/contracts/access-control&#34;&gt;Access Control&lt;/a&gt;: decide who can perform each of the actions on your system.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openzeppelin.com/contracts/tokens&#34;&gt;Tokens&lt;/a&gt;: create tradeable assets or collectives, and distribute them via &lt;a href=&#34;https://docs.openzeppelin.com/contracts/crowdsales&#34;&gt;Crowdsales&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openzeppelin.com/contracts/utilities&#34;&gt;Utilities&lt;/a&gt;: generic useful tools including non-overflowing math, signature verification, and trustless paying systems.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://docs.openzeppelin.com/contracts/api/token/ERC20&#34;&gt;full API&lt;/a&gt; is also thoroughly documented, and serves as a great reference when developing your smart contract application. You can also ask for help or follow Contracts&#39;s development in the &lt;a href=&#34;https://forum.openzeppelin.com&#34;&gt;community forum&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Finally, you may want to take a look at the &lt;a href=&#34;https://blog.openzeppelin.com/guides&#34;&gt;guides on our blog&lt;/a&gt;, which cover several common use cases and good practices. The following articles provide great background reading, though please note that some of the referenced tools have changed, as the tooling in the ecosystem continues to rapidly evolve.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.openzeppelin.com/the-hitchhikers-guide-to-smart-contracts-in-ethereum-848f08001f05&#34;&gt;The Hitchhiker’s Guide to Smart Contracts in Ethereum&lt;/a&gt; will help you get an overview of the various tools available for smart contract development, and help you set up your environment.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.openzeppelin.com/a-gentle-introduction-to-ethereum-programming-part-1-783cc7796094&#34;&gt;A Gentle Introduction to Ethereum Programming, Part 1&lt;/a&gt; provides very useful information on an introductory level, including many basic concepts from the Ethereum platform.&lt;/li&gt; &#xA; &lt;li&gt;For a more in-depth dive, you may read the guide &lt;a href=&#34;https://blog.openzeppelin.com/designing-the-architecture-for-your-ethereum-application-9cec086f8317&#34;&gt;Designing the Architecture for Your Ethereum Application&lt;/a&gt;, which discusses how to better structure your application and its relationship to the real world.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;This project is maintained by &lt;a href=&#34;https://openzeppelin.com&#34;&gt;OpenZeppelin&lt;/a&gt; with the goal of providing a secure and reliable library of smart contract components for the ecosystem. We address security through risk management in various areas such as engineering and open source best practices, scoping and API design, multi-layered review processes, and incident response preparedness.&lt;/p&gt; &#xA;&lt;p&gt;The security policy is detailed in &lt;a href=&#34;https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/SECURITY.md&#34;&gt;&lt;code&gt;SECURITY.md&lt;/code&gt;&lt;/a&gt;, and specifies how you can report security vulnerabilities, which versions will receive security patches, and how to stay informed about them. We run a &lt;a href=&#34;https://immunefi.com/bounty/openzeppelin&#34;&gt;bug bounty program on Immunefi&lt;/a&gt; to reward the responsible disclosure of vulnerabilities.&lt;/p&gt; &#xA;&lt;p&gt;The engineering guidelines we follow to promote project quality can be found in &lt;a href=&#34;https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/GUIDELINES.md&#34;&gt;&lt;code&gt;GUIDELINES.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Past audits can be found in &lt;a href=&#34;https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/audits&#34;&gt;&lt;code&gt;audits/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Smart contracts are a nascent techology and carry a high level of technical risk and uncertainty. Although OpenZeppelin is well known for its security audits, using OpenZeppelin Contracts is not a substitute for a security audit.&lt;/p&gt; &#xA;&lt;p&gt;OpenZeppelin Contracts is made available under the MIT License, which disclaims all warranties in relation to the project and which limits the liability of those that contribute and maintain the project, including OpenZeppelin. As set out further in the Terms, you acknowledge that you are solely responsible for any use of OpenZeppelin Contracts and you assume all risks associated with any such use.&lt;/p&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;p&gt;OpenZeppelin Contracts exists thanks to its contributors. There are many ways you can participate and help build high quality software. Check out the &lt;a href=&#34;https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/CONTRIBUTING.md&#34;&gt;contribution guide&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;OpenZeppelin Contracts is released under the &lt;a href=&#34;https://raw.githubusercontent.com/OpenZeppelin/openzeppelin-contracts/master/LICENSE&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Legal&lt;/h2&gt; &#xA;&lt;p&gt;Your use of this Project is governed by the terms found at &lt;a href=&#34;http://www.openzeppelin.com/tos&#34;&gt;www.openzeppelin.com/tos&lt;/a&gt; (the &#34;Terms&#34;).&lt;/p&gt;</summary>
  </entry>
</feed>