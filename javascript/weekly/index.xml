<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub JavaScript Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-30T01:58:26Z</updated>
  <subtitle>Weekly Trending of JavaScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>anc95/ChatGPT-CodeReview</title>
    <updated>2023-04-30T01:58:26Z</updated>
    <id>tag:github.com,2023-04-30:/anc95/ChatGPT-CodeReview</id>
    <link href="https://github.com/anc95/ChatGPT-CodeReview" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ¥ A code review bot powered by ChatGPT&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CodeReview BOT&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;A code review robot powered by ChatGPT&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Translation Versions: &lt;a href=&#34;https://raw.githubusercontent.com/anc95/ChatGPT-CodeReview/main/README.md&#34;&gt;ENGLISH&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/anc95/ChatGPT-CodeReview/main/README.zh-CN.md&#34;&gt;ä¸­æ–‡ç®€ä½“&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/anc95/ChatGPT-CodeReview/main/README.zh-TW.md&#34;&gt;ä¸­æ–‡ç¹é«”&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/anc95/ChatGPT-CodeReview/main/README.ko.md&#34;&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/anc95/ChatGPT-CodeReview/main/README.ja.md&#34;&gt;æ—¥æœ¬èª&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Bot Usage&lt;/h2&gt; &#xA;&lt;p&gt;â—ï¸âš ï¸ &lt;code&gt;Due to cost considerations, BOT is only used for testing purposes and is currently deployed on AWS Lambda with ratelimit restrictions. Therefore, unstable situations are completely normal. It is recommended to deploy an app by yourself.&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Install&lt;/h3&gt; &#xA;&lt;p&gt;Install: &lt;a href=&#34;https://github.com/apps/cr-gpt&#34;&gt;apps/cr-gpt&lt;/a&gt;;&lt;/p&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to the repo homepage which you want integrate this bot&lt;/li&gt; &#xA; &lt;li&gt;click &lt;code&gt;settings&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;click &lt;code&gt;actions&lt;/code&gt; under &lt;code&gt;secrets and variables&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Change to &lt;code&gt;Variables&lt;/code&gt; tab, create a new variable &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; with the value of your open api key (For Github Action integration, set it in secrets) &lt;img width=&#34;1465&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/13167934/218533628-3974b70f-c423-44b0-b096-d1ec2ace85ea.png&#34;&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Start using&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The robot will automatically do the code review when you create a new Pull request, the review information will show in the pr timeline / file changes part.&lt;/li&gt; &#xA; &lt;li&gt;After &lt;code&gt;git push&lt;/code&gt; update the pull request, cr bot will re-review the changed files&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;example:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/anc95/ChatGPT-CodeReview/pull/21&#34;&gt;ChatGPT-CodeReview/pull/21&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img width=&#34;1052&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/13167934/218999459-812206e1-d8d2-4900-8ce8-19b5b6e1f5cb.png&#34;&gt; &#xA;&lt;h2&gt;Using Github Actions&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/marketplace/actions/chatgpt-codereviewer&#34;&gt;actions/chatgpt-codereviewer&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;add the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; to your github actions secrets&lt;/li&gt; &#xA; &lt;li&gt;create &lt;code&gt;.github/workflows/cr.yml&lt;/code&gt; add bellow content&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;name: Code Review&#xA;&#xA;permissions:&#xA;  contents: read&#xA;  pull-requests: write&#xA;&#xA;on:&#xA;  pull_request:&#xA;    types: [opened, reopened, synchronize]&#xA;&#xA;jobs:&#xA;  test:&#xA;    if: ${{ contains(github.event.*.labels.*.name, &#39;gpt review&#39;) }} # Optional; to run only when a label is attached&#xA;    runs-on: ubuntu-latest&#xA;    steps:&#xA;      - uses: anc95/ChatGPT-CodeReview@main&#xA;        env:&#xA;          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}&#xA;          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}&#xA;          # Optional&#xA;          LANGUAGE: Chinese&#xA;          MODEL:&#xA;          top_p: 1&#xA;          temperature: 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Self-hosting&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;clone code&lt;/li&gt; &#xA; &lt;li&gt;copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt;, and fill the env variables&lt;/li&gt; &#xA; &lt;li&gt;install deps and run&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm i&#xA;npm -i g pm2&#xA;npm run build&#xA;pm2 start pm2.config.cjs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://probot.github.io/docs/development/&#34;&gt;probot&lt;/a&gt; for more detail&lt;/p&gt; &#xA;&lt;h2&gt;Dev&lt;/h2&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Install dependencies&#xA;npm install&#xA;&#xA;# Run the bot&#xA;npm start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 1. Build container&#xA;docker build -t cr-bot .&#xA;&#xA;# 2. Start container&#xA;docker run -e APP_ID=&amp;lt;app-id&amp;gt; -e PRIVATE_KEY=&amp;lt;pem-value&amp;gt; cr-bot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you have suggestions for how cr-bot could be improved, or want to report a bug, open an issue! We&#39;d love all and any contributions.&lt;/p&gt; &#xA;&lt;p&gt;For more, check out the &lt;a href=&#34;https://raw.githubusercontent.com/anc95/ChatGPT-CodeReview/main/CONTRIBUTING.md&#34;&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Credit&lt;/h2&gt; &#xA;&lt;p&gt;this project is inpired by &lt;a href=&#34;https://github.com/sturdy-dev/codereview.gpt&#34;&gt;codereview.gpt&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/anc95/ChatGPT-CodeReview/main/LICENSE&#34;&gt;ISC&lt;/a&gt; Â© 2023 anc95&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>xcanwin/KeepChatGPT</title>
    <updated>2023-04-30T01:58:26Z</updated>
    <id>tag:github.com,2023-04-30:/xcanwin/KeepChatGPT</id>
    <link href="https://github.com/xcanwin/KeepChatGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGPTç•…èŠæ’ä»¶ã€‚è§£å†³æ‰€æœ‰æŠ¥é”™ï¼Œè®©æˆ‘ä»¬çš„AIä½“éªŒæ— æ¯”é¡ºç•…ã€ä¸æ»‘ã€é«˜æ•ˆã€‚æŒç»­æ›´æ–°çš„å¢å¼ºåŠŸèƒ½ï¼Œå¦‚å–æ¶ˆå®¡è®¡ç­‰ã€‚è§£å†³çš„æŠ¥é”™å¦‚ä¸‹: (1) NetworkError when attempting to fetch resource. (2) Something went wrong. If this issue persists please contact us through our help center at help.openai.com. (3) Conversation not found. (4) This content may violate our content policy.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/xcanwin/KeepChatGPT/main/assets/KeepChatGPT.png&#34; width=&#34;600&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ç®€ä»‹&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;éç›ˆåˆ©å¼€æºé¡¹ç›®ä¾é å¤§å®¶æ— ä»·çš„æ”¯æŒï¼Œæ¬¢è¿å„ä½ä¼™ä¼´åœ¨ &lt;a href=&#34;https://github.com/xcanwin/KeepChatGPT/&#34;&gt;GitHub&lt;/a&gt; å’Œ &lt;a href=&#34;https://greasyfork.org/zh-CN/scripts/462804-keepchatgpt&#34;&gt;GreasyFork&lt;/a&gt; ç•™ä¸‹å¾®å¾®çš„â­ï¸starå’ŒğŸ‘ğŸ»æ­£é¢çš„ä½“éªŒåé¦ˆ&lt;/li&gt; &#xA; &lt;li&gt;è¿™æ˜¯ä¸€æ¬¾&lt;code&gt;ChatGPT&lt;/code&gt;ç•…èŠæ’ä»¶ã€‚è§£å†³æ‰€æœ‰æŠ¥é”™ï¼Œè®©æˆ‘ä»¬çš„AIä½“éªŒæ— æ¯”é¡ºç•…ã€ä¸æ»‘ã€é«˜æ•ˆã€‚æŒç»­æ›´æ–°çš„å¢å¼ºåŠŸèƒ½ï¼Œå¦‚å–æ¶ˆå®¡è®¡ç­‰ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;è¯¦ç»†ä»‹ç»&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xcanwin/KeepChatGPT/raw/main/README_CN.md&#34;&gt;ä¸­æ–‡æ–‡æ¡£&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xcanwin/KeepChatGPT/raw/main/README_EN.md&#34;&gt;English README&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;è§£å†³&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;è§£å†³ä»¥ä¸‹å¸¸è§é”™è¯¯&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;NetworkError when attempting to fetch resource.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Something went wrong. If this issue persists please contact us through our help center at help.openai.com.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Conversation not found&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;This content may violate our content policy. If you believe this to be in error, please submit your feedback â€” your input will aid our research in this area.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>0hq/WebGPT</title>
    <updated>2023-04-30T01:58:26Z</updated>
    <id>tag:github.com,2023-04-30:/0hq/WebGPT</id>
    <link href="https://github.com/0hq/WebGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Run GPT model on the browser with WebGPU. An implementation of GPT inference in less than ~2000 lines of vanilla Javascript.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WebGPT&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/0hq/WebGPT/main/other/misc/header.png&#34; alt=&#34;webGPT&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;After six years of development, WebGPU is about to launch across most major web browsers. This is massive: web applications now have near-native access to the GPU, with the added capacity of compute shaders.&lt;/p&gt; &#xA;&lt;p&gt;WebGPT is a vanilla JS and HTML implementation of a transformer model, intended as a proof-of-concept as well as educational resource. WebGPT has been tested to be working with models up to 500 M parameters, though could likely support far more with further testing/optimization.&lt;/p&gt; &#xA;&lt;p&gt;At the moment, WebGPT averages ~50ms per token on GPT-2 124M running on a 2020 M1 Mac with Chrome Canary. This could be 500% faster, if not more, with better optimization of the kernels, buffers, the WebGPU interface. WebGPU should also receive significant speed increases as it matures.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/30643741/233488471-0cd93d38-af27-4648-bbf6-46aa033e44a1.mp4&#34;&gt;https://user-images.githubusercontent.com/30643741/233488471-0cd93d38-af27-4648-bbf6-46aa033e44a1.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Running WebGPT&lt;/h2&gt; &#xA;&lt;p&gt;Running WebGPT is remarkably simple, as it&#39;s just a set of HTML + JS files. Since WebGPU is still in the process of being released, you&#39;ll need to open with a compatible browser. WebGPU is currently available on Chrome v113 but the most straightforward way to ensure proper functionality is to install &lt;a href=&#34;https://www.google.com/chrome/canary/&#34;&gt;Chrome Canary&lt;/a&gt; and enable &#34;Unsafe WebGPU&#34; at &lt;code&gt;chrome://flags/#enable-unsafe-webgpu&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;I&#39;ve included two different models: a toy GPT-Shakespeare model (which is severly undertrained haha) and GPT-2 117M. See main.js for more information on how to run these models. If you want to import custom models, take a look at misc/conversion_scripts.&lt;/p&gt; &#xA;&lt;p&gt;If you want to try out WebGPT, visit the demo website here &lt;a href=&#34;https://www.kmeans.org&#34;&gt;KMeans.org&lt;/a&gt;. I&#39;d generally reccomend cloning the repo and running locally, just because loading the weights remotely is significantly slower. Note: You&#39;ll need to use Git LFS to download the model files, after cloning the repository.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/0hq/WebGPT/main/other/misc/files.png&#34; alt=&#34;file sizes&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap / Fixing Stupid Decisions&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Embeddings / de-embeddings on GPU.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Initializing pipelines on every step is incredibly inefficient.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Key-value caching.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Reuse buffers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Kernel shared memory for matmul!&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Destroy buffers after use!&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Investigate why attention cache isn&#39;t giving proper speed-ups.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Make simple instructional version without special stuff.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Optimize workgroup sizes, specifically for single row/col operations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Optimize all other kernels.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Convert into a package.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Compute pass splitting for larger models &lt;em&gt;(maxStorageBufferBindingSize)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Write better comments + make Youtube explainer.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;When I started this project I had no idea how transformers worked or how to implement them (or GPUs or matmul kernels or WebGPU or tokenization for that matter), so Andrej Karpathy&#39;s series on neural networks and building GPT from scratch were invaluable: &lt;a href=&#34;https://www.youtube.com/@AndrejKarpathy&#34;&gt;Andrej&#39;s Youtube&lt;/a&gt;. I&#39;ve also used some code as well from the nanoGPT repository: &lt;a href=&#34;https://github.com/karpathy/nanoGPT&#34;&gt;nanoGPT&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;I copied from LatitudeGames&#39; implementation of OpenAI&#39;s GPT-3 tokenizer in Javascript: &lt;a href=&#34;https://github.com/latitudegames/GPT-3-Encoder&#34;&gt;GPT-3-Encoder&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Note: I&#39;m looking for work!&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;m currently in the process of switching into the AI field. I&#39;m specifically looking for opportunites at larger research labs in a variety of jobs, with the goal of breaking into the space and finding an area in which to specialize. If you&#39;re interested, check out my personal website: &lt;a href=&#34;https://depue.design/&#34;&gt;Personal Website&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>