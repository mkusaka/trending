<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Lua Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-19T01:41:10Z</updated>
  <subtitle>Daily Trending of Lua in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>nomnivore/ollama.nvim</title>
    <updated>2024-01-19T01:41:10Z</updated>
    <id>tag:github.com,2024-01-19:/nomnivore/ollama.nvim</id>
    <link href="https://github.com/nomnivore/ollama.nvim" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A plugin for managing and integrating your ollama workflows in neovim.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ollama.nvim&lt;/h1&gt; &#xA;&lt;p&gt;A plugin for managing and integrating your &lt;a href=&#34;https://ollama.ai&#34;&gt;ollama&lt;/a&gt; workflows in neovim.&lt;/p&gt; &#xA;&lt;p&gt;Designed to be flexible in configuration and extensible with custom functionality.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Connects over HTTP, run your ollama server anywhere&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Query and select from available models&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Prompt the LLM with context from your buffer&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Display, replace, or write your own actions for the response&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Specify additional parameters for a prompt (temperature, top_k, etc)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Planned / Ideas (implemented depending on interest)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Download and manage models&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Clone or create models from &lt;a href=&#34;https://github.com/jmorganca/ollama/raw/main/docs/modelfile.md&#34;&gt;Modelfiles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Chat&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama.nvim&lt;/code&gt; provides the following commands, which map to methods exposed by the plugin:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Ollama&lt;/code&gt;: Prompt the user to select a prompt to run.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OllamaModel&lt;/code&gt;: Prompt the user to select a model to use as session default.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OllamaServe&lt;/code&gt;: Start the ollama server.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OllamaServeStop&lt;/code&gt;: Stop the ollama server.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama.nvim&lt;/code&gt; uses &lt;code&gt;curl&lt;/code&gt; to communicate with your ollama server over HTTP. Please ensure that &lt;code&gt;curl&lt;/code&gt; is installed on your system.&lt;/p&gt; &#xA;&lt;p&gt;Install using &lt;a href=&#34;https://github.com/folke/lazy.nvim&#34;&gt;lazy.nvim&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;return {&#xA;  &#34;nomnivore/ollama.nvim&#34;,&#xA;  dependencies = {&#xA;    &#34;nvim-lua/plenary.nvim&#34;,&#xA;  },&#xA;&#xA;  -- All the user commands added by the plugin&#xA;  cmd = { &#34;Ollama&#34;, &#34;OllamaModel&#34;, &#34;OllamaServe&#34;, &#34;OllamaServeStop&#34; },&#xA;&#xA;  keys = {&#xA;    -- Sample keybind for prompt menu. Note that the &amp;lt;c-u&amp;gt; is important for selections to work properly.&#xA;    {&#xA;      &#34;&amp;lt;leader&amp;gt;oo&#34;,&#xA;      &#34;:&amp;lt;c-u&amp;gt;lua require(&#39;ollama&#39;).prompt()&amp;lt;cr&amp;gt;&#34;,&#xA;      desc = &#34;ollama prompt&#34;,&#xA;      mode = { &#34;n&#34;, &#34;v&#34; },&#xA;    },&#xA;&#xA;    -- Sample keybind for direct prompting. Note that the &amp;lt;c-u&amp;gt; is important for selections to work properly.&#xA;    {&#xA;      &#34;&amp;lt;leader&amp;gt;oG&#34;,&#xA;      &#34;:&amp;lt;c-u&amp;gt;lua require(&#39;ollama&#39;).prompt(&#39;Generate_Code&#39;)&amp;lt;cr&amp;gt;&#34;,&#xA;      desc = &#34;ollama Generate Code&#34;,&#xA;      mode = { &#34;n&#34;, &#34;v&#34; },&#xA;    },&#xA;  },&#xA;&#xA;  ---@type Ollama.Config&#xA;  opts = {&#xA;    -- your configuration overrides&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To get a fuzzy-finding Telescope prompt selector you can optionally install &lt;a href=&#34;https://github.com/stevearc/dressing.nvim&#34;&gt;&lt;code&gt;stevearc/dressing.nvim&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;h3&gt;Default Options&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;opts = {&#xA;  model = &#34;mistral&#34;,&#xA;  url = &#34;http://127.0.0.1:11434&#34;,&#xA;  serve = {&#xA;    on_start = false,&#xA;    command = &#34;ollama&#34;,&#xA;    args = { &#34;serve&#34; },&#xA;    stop_command = &#34;pkill&#34;,&#xA;    stop_args = { &#34;-SIGTERM&#34;, &#34;ollama&#34; },&#xA;  },&#xA;  -- View the actual default prompts in ./lua/ollama/prompts.lua&#xA;  prompts = {&#xA;    Sample_Prompt = {&#xA;      prompt = &#34;This is a sample prompt that receives $input and $sel(ection), among others.&#34;,&#xA;      input_label = &#34;&amp;gt; &#34;,&#xA;      model = &#34;mistral&#34;,&#xA;      action = &#34;display&#34;,&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;Due to &lt;code&gt;ollama.nvim&lt;/code&gt;&#39;s flexible configuration, docker support is included with minimal extra effort.&lt;/p&gt; &#xA;&lt;p&gt;If your container is running on a &lt;strong&gt;separate machine&lt;/strong&gt;, you just need to configure the &lt;code&gt;url&lt;/code&gt; option to point to your server.&lt;/p&gt; &#xA;&lt;p&gt;For &lt;strong&gt;local containers&lt;/strong&gt;, you can configure the &lt;code&gt;serve&lt;/code&gt; options to use the &lt;code&gt;docker&lt;/code&gt; cli to create and destroy a container. Here&#39;s an example configuration that uses the official &lt;code&gt;ollama&lt;/code&gt; docker image to create an ephemeral container with a shared volume:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;opts = {&#xA;  -- $ docker run -d --rm --gpus=all -v &amp;lt;volume&amp;gt;:/root/.ollama -p 11434:11434 --name ollama ollama/ollama&#xA;  url = &#34;http://127.0.0.1:11434&#34;,&#xA;  serve = {&#xA;    command = &#34;docker&#34;,&#xA;    args = {&#xA;      &#34;run&#34;,&#xA;      &#34;-d&#34;,&#xA;      &#34;--rm&#34;,&#xA;      &#34;--gpus=all&#34;,&#xA;      &#34;-v&#34;,&#xA;      &#34;ollama:/root/.ollama&#34;,&#xA;      &#34;-p&#34;,&#xA;      &#34;11434:11434&#34;,&#xA;      &#34;--name&#34;,&#xA;      &#34;ollama&#34;,&#xA;      &#34;ollama/ollama&#34;,&#xA;    },&#xA;    stop_command = &#34;docker&#34;,&#xA;    stop_args = { &#34;stop&#34;, &#34;ollama&#34; },&#xA;  },&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Writing your own prompts&lt;/h3&gt; &#xA;&lt;p&gt;By default, &lt;code&gt;ollama.nvim&lt;/code&gt; comes with a few prompts that are useful for most workflows. However, you can also write your own prompts directly in your config, as shown above.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;prompts&lt;/code&gt; is a dictionary of prompt names to prompt configurations. The prompt name is used in prompt selection menus where you can select which prompt to run, where &#34;Sample_Prompt&#34; is shown as &#34;Sample Prompt&#34;.&lt;/p&gt; &#xA;&lt;p&gt;This dictionary accepts the following keys:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Key&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;prompt&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;string&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The prompt to send to the LLM. Can contain special tokens that are substituted with context before sending. See &lt;a href=&#34;https://raw.githubusercontent.com/nomnivore/ollama.nvim/main/#tokens&#34;&gt;Tokens&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;model&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;string&lt;/code&gt; (Optional)&lt;/td&gt; &#xA;   &lt;td&gt;The model to use for the prompt. Defaults to the global &lt;code&gt;opts.model&lt;/code&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;input_label&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;string&lt;/code&gt; (Optional)&lt;/td&gt; &#xA;   &lt;td&gt;The label to use for the input prompt. Defaults to &lt;code&gt;&#34;&amp;gt; &#34;&lt;/code&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;action&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;string&lt;/code&gt; or &lt;code&gt;table&lt;/code&gt; (Optional)&lt;/td&gt; &#xA;   &lt;td&gt;The action to take with the response from the LLM. See &lt;a href=&#34;https://raw.githubusercontent.com/nomnivore/ollama.nvim/main/#actions&#34;&gt;Actions&lt;/a&gt;. Defaults to &#34;display&#34;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;extract&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;string&lt;/code&gt; (Optional)&lt;/td&gt; &#xA;   &lt;td&gt;A Lua match pattern to extract from the response. Used only by certain actions. See &lt;a href=&#34;https://raw.githubusercontent.com/nomnivore/ollama.nvim/main/#extracting&#34;&gt;Extracting&lt;/a&gt;. Set to &lt;code&gt;false&lt;/code&gt; if you want to disable this step.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;options&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;table&lt;/code&gt; (Optional)&lt;/td&gt; &#xA;   &lt;td&gt;Additional model parameter overrides, such as temperature, listed in the documentation for the &lt;a href=&#34;https://github.com/jmorganca/ollama/raw/main/docs/modelfile.md#valid-parameters-and-values&#34;&gt;Ollama Modelfile&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;system&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;string&lt;/code&gt; (Optional)&lt;/td&gt; &#xA;   &lt;td&gt;The system prompt to be used in the Modelfile template, if applicable. (overrides what&#39;s in the Modelfile)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;format&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;string&lt;/code&gt; (Optional)&lt;/td&gt; &#xA;   &lt;td&gt;The format to return a response in. Currently the only accepted value is &#34;json&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;If you&#39;d like to disable a prompt (such as one of the default ones), set the value of the prompt to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;prompts = {&#xA;  Sample_Prompt = false&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Extracting&lt;/h3&gt; &#xA;&lt;p&gt;When using certain actions (or custom ones you write), you may want to operate on a specific part of the response. To do this, you can use the &lt;code&gt;extract&lt;/code&gt; key in your prompt configuration.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;extract = &#34;```$ftype\n(.-)```&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama.nvim&lt;/code&gt; will parse the &lt;code&gt;extract&lt;/code&gt; string the same way as a prompt, substituting tokens (see below). The parsed extract pattern will then be sent to the action associated with the prompt.&lt;/p&gt; &#xA;&lt;h3&gt;Tokens&lt;/h3&gt; &#xA;&lt;p&gt;Before sending the prompt, &lt;code&gt;ollama.nvim&lt;/code&gt; will replace certain special tokens in the prompt string with context in the following ways:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Token&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$input&lt;/td&gt; &#xA;   &lt;td&gt;Prompt the user for input.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$sel&lt;/td&gt; &#xA;   &lt;td&gt;The current or previous selection.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$ftype&lt;/td&gt; &#xA;   &lt;td&gt;The filetype of the current buffer.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$fname&lt;/td&gt; &#xA;   &lt;td&gt;The filename of the current buffer.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$buf&lt;/td&gt; &#xA;   &lt;td&gt;The full contents of the current buffer.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$line&lt;/td&gt; &#xA;   &lt;td&gt;The current line in the buffer.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$lnum&lt;/td&gt; &#xA;   &lt;td&gt;The current line number in the buffer.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Actions&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama.nvim&lt;/code&gt; provides the following built-in actions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;display&lt;/code&gt;: Stream and display the response in a floating window.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;replace&lt;/code&gt;: Replace the current selection with the response. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Uses the &lt;code&gt;extract&lt;/code&gt; pattern to extract the response.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;insert&lt;/code&gt;: Insert the response at the current cursor line &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Uses the &lt;code&gt;extract&lt;/code&gt; pattern to extract the response.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;display_replace&lt;/code&gt;: Stream and display the response in a floating window, then replace the current selection with the response. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Uses the &lt;code&gt;extract&lt;/code&gt; pattern to extract the response.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;display_insert&lt;/code&gt;: Stream and display the response in a floating window, then insert the response at the current cursor line. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Uses the &lt;code&gt;extract&lt;/code&gt; pattern to extract the response.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Sometimes, you may need functionality that is not provided by the built-in actions. In this case, you can write your own Custom Actions with the following interface:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;---@type Ollama.PromptAction&#xA;action = {&#xA;  fn = function(prompt)&#xA;    -- This function is called when the prompt is selected&#xA;    -- just before sending the prompt to the LLM.&#xA;    -- Useful for setting up UI or other state.&#xA;&#xA;    -- Return a function that will be used as a callback&#xA;    -- when a response is received.&#xA;    ---@type Ollama.PromptActionResponseCallback&#xA;    return function(body, job)&#xA;      -- body is a table of the json response&#xA;      -- body.response is the response text received&#xA;&#xA;      -- job is the plenary.job object when opts.stream = true&#xA;      -- job is nil otherwise&#xA;    end&#xA;&#xA;  end,&#xA;&#xA;  opts = { stream = true } -- optional, default is false&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Instead of returning a callback function, you can also return &lt;code&gt;false&lt;/code&gt; or &lt;code&gt;nil&lt;/code&gt; to indicate that the prompt should be cancelled and not be sent to the LLM. This can be useful for actions that require a selection or for other criteria not being met.&lt;/p&gt; &#xA;&lt;p&gt;Actions can also be written without the table keys, like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;action = {&#xA;  function(prompt)&#xA;    -- ...&#xA;    return function(body, job)&#xA;      -- ...&#xA;    end&#xA;  end,&#xA;  { stream = true }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Actions Factory&lt;/h4&gt; &#xA;&lt;p&gt;The built-in actions are implemented using a factory function that takes a table of options and returns a prompt action. You can use this factory to quickly make small adjustments to the built-in actions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;action = require(&#34;ollama.actions.factory&#34;).create_action({ display = true, replace = true, show_prompt = false })&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The following options are available:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Option&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;display&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;boolean&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;whether to display the response (default: &lt;code&gt;true&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;insert&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;boolean&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;whether to insert the response at the cursor (default: &lt;code&gt;false&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;replace&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;boolean&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;whether to replace the selection with the response. Precedes &lt;code&gt;insert&lt;/code&gt; (default: &lt;code&gt;false&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;show_prompt&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;boolean&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;whether to prepend the display buffer with the parsed prompt (default: &lt;code&gt;false&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;window&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;float&#34;|&#34;split&#34;|&#34;vsplit&#34;&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;type of window to display the response in (default: &lt;code&gt;&#34;float&#34;&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Status&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama.nvim&lt;/code&gt; module exposes a &lt;code&gt;.status()&lt;/code&gt; method for checking the status of the ollama server. This is used to see if any jobs are currently running. It returns the type &lt;code&gt;Ollama.StatusEnum&lt;/code&gt; which is one of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;&#34;IDLE&#34;&lt;/code&gt;: No jobs are running&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;&#34;WORKING&#34;&lt;/code&gt;: One or more jobs are running&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can use this to display a prompt running status in your statusline. Here are a few example recipes for &lt;a href=&#34;https://github.com/nvim-lualine/lualine.nvim&#34;&gt;lualine&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;h4&gt;Assuming you already have lualine set up in your config, and that you are using a package manager that can merge configs&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;{&#xA;  &#34;nvim-lualine/lualine.nvim&#34;,&#xA;  optional = true,&#xA;&#xA;  opts = function(_, opts)&#xA;    table.insert(opts.sections.lualine_x, {&#xA;      function()&#xA;        local status = require(&#34;ollama&#34;).status()&#xA;&#xA;        if status == &#34;IDLE&#34; then&#xA;          return &#34;󱙺&#34; -- nf-md-robot-outline&#xA;        elseif status == &#34;WORKING&#34; then&#xA;          return &#34;󰚩&#34; -- nf-md-robot&#xA;        end&#xA;      end,&#xA;      cond = function()&#xA;        return package.loaded[&#34;ollama&#34;] and require(&#34;ollama&#34;).status() ~= nil&#xA;      end,&#xA;    })&#xA;  end,&#xA;},&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Alternatively, Assuming you want all of the statusline config entries in one file.&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;-- assuming the following plugin is installed&#xA;{&#xA;  &#34;nvim-lualine/lualine.nvim&#34;,&#xA;},&#xA;&#xA;-- Define a function to check that ollama is installed and working&#xA;local function get_condition()&#xA;    return package.loaded[&#34;ollama&#34;] and require(&#34;ollama&#34;).status ~= nil&#xA;end&#xA;&#xA;&#xA;-- Define a function to check the status and return the corresponding icon&#xA;local function get_status_icon()&#xA;  local status = require(&#34;ollama&#34;).status()&#xA;&#xA;  if status == &#34;IDLE&#34; then&#xA;    return &#34;OLLAMA IDLE&#34;&#xA;  elseif status == &#34;WORKING&#34; then&#xA;    return &#34;OLLAMA BUSY&#34;&#xA;  end&#xA;end&#xA;&#xA;-- Load and configure &#39;lualine&#39;&#xA;require(&#34;lualine&#34;).setup({&#xA;&#x9;sections = {&#xA;&#x9;&#x9;lualine_a = {},&#xA;&#x9;&#x9;lualine_b = { &#34;branch&#34;, &#34;diff&#34;, &#34;diagnostics&#34; },&#xA;&#x9;&#x9;lualine_c = { { &#34;filename&#34;, path = 1 } },&#xA;&#x9;&#x9;lualine_x = { get_status_icon, get_condition },&#xA;&#x9;&#x9;lualine_y = { &#34;progress&#34; },&#xA;&#x9;&#x9;lualine_z = { &#34;location&#34; },&#xA;&#x9;},&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jmorganca/ollama&#34;&gt;ollama&lt;/a&gt; for running LLMs locally&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/David-Kunz/gen.nvim&#34;&gt;gen.nvim&lt;/a&gt; for inspiration&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Pixel-Scripts/px_weapon-crafting</title>
    <updated>2024-01-19T01:41:10Z</updated>
    <id>tag:github.com,2024-01-19:/Pixel-Scripts/px_weapon-crafting</id>
    <link href="https://github.com/Pixel-Scripts/px_weapon-crafting" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PX WEAPON CRAFTING&lt;/h1&gt; &#xA;&lt;p&gt;Simple weapon crafting system with XP system and job control&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img align=&#34;right&#34; src=&#34;https://cdn.discordapp.com/attachments/869944683235794954/1196241862055432262/PX_1920-100.jpg?ex=65b6ea0d&amp;amp;is=65a4750d&amp;amp;hm=117ae31ad94ded1e2e76c3c84dbaded7f7c2c796a0ff92f9bc679fb8993b6d08&amp;amp;&#34; alt=&#34;px-development&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;strong&gt;Frameworks&lt;/strong&gt;&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ESX&lt;br&gt;&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;EnableDebug: A boolean flag indicating whether debugging is enabled for the crafting system&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;XpSystem: A boolean flag indicating activate the experience system for crafting weapons&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;ExperiancePerCraft: The amount of experience gained per craft in the crafting system&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;Weapon: A set of definitions for different weapons in the game, each with details such as weapon code, name, job requirements, required experience, an allowed job list, and items required for crafting. For example, the sniper rifle requires the police job, 10 experience points, and 2 iron and 5 copper for crafting&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;PositionCrafting: A list of locations in the game where you can craft, defined by coordinates and direction&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;🧷 Discord&lt;/strong&gt; &lt;a href=&#34;https://discord.gg/KeZSH27fGe&#34;&gt;Pixel Scripts&lt;/a&gt; &lt;br&gt; &lt;strong&gt;💻 Preview&lt;/strong&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=qLC1rGdf22g&#34;&gt;Video&lt;/a&gt; &lt;br&gt; &lt;strong&gt;📖 Documentation&lt;/strong&gt; &lt;a href=&#34;https://app.gitbook.com/o/maLkzzf71CV0QY3XJcJC/s/ryJXOX2xIE06Mha4iYtD/~/changes/18/&#34;&gt;View&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>marilari88/neotest-vitest</title>
    <updated>2024-01-19T01:41:10Z</updated>
    <id>tag:github.com,2024-01-19:/marilari88/neotest-vitest</id>
    <link href="https://github.com/marilari88/neotest-vitest" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Vitest adapter for Neovim Neotest plugin&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;neotest-vitest&lt;/h1&gt; &#xA;&lt;p&gt;This plugin provides a &lt;a href=&#34;https://vitest.dev/&#34;&gt;Vitest&lt;/a&gt; adapter for the &lt;a href=&#34;https://github.com/rcarriga/neotest&#34;&gt;Neotest&lt;/a&gt; framework.&lt;/p&gt; &#xA;&lt;p&gt;Credits to &lt;a href=&#34;https://github.com/haydenmeade/neotest-jest&#34;&gt;neotest-jest&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Known issues&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;test.each is currently not well supported (WIP)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to install it&lt;/h2&gt; &#xA;&lt;h3&gt;Lazy&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;{&#xA;  &#34;nvim-neotest/neotest&#34;,&#xA;  dependencies = {&#xA;    ...,&#xA;    &#34;marilari88/neotest-vitest&#34;,&#xA;  },&#xA;  config = function()&#xA;    require(&#34;neotest&#34;).setup({&#xA;          ...,&#xA;&#x9;  adapters = {&#xA;            require(&#34;neotest-vitest&#34;),&#xA;            }&#xA;      })&#xA;  end,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Packer&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;use({&#xA;  &#34;nvim-neotest/neotest&#34;,&#xA;  requires = {&#xA;    ...,&#xA;    &#34;marilari88/neotest-vitest&#34;,&#xA;  }&#xA;  config = function()&#xA;    require(&#34;neotest&#34;).setup({&#xA;      ...,&#xA;      adapters = {&#xA;        require(&#34;neotest-vitest&#34;)&#xA;        }&#xA;    })&#xA;  end&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Make sure you have Treesitter installed with the right language parser installed&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;:TSInstall javascript&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/32909388/185812063-d05d9cc7-b9aa-43ed-915b-cf156e3f0c52.gif&#34; alt=&#34;usage preview&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;See neotest&#39;s documentation for more information on how to run tests.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;🎁&lt;/span&gt; Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please raise a PR if you are interested in adding new functionality or fixing any bugs. When submitting a bug, please include an example spec that can be tested.&lt;/p&gt; &#xA;&lt;p&gt;To trigger the tests for the adapter, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./scripts/test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Bug Reports&lt;/h2&gt; &#xA;&lt;p&gt;Please file any bug reports and I &lt;em&gt;might&lt;/em&gt; take a look if time permits otherwise please submit a PR, this plugin is intended to be by the community for the community.&lt;/p&gt;</summary>
  </entry>
</feed>