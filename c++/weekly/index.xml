<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-30T01:51:58Z</updated>
  <subtitle>Weekly Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>google/mediapipe</title>
    <updated>2023-04-30T01:51:58Z</updated>
    <id>tag:github.com,2023-04-30:/google/mediapipe</id>
    <link href="https://github.com/google/mediapipe" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cross-platform, customizable ML solutions for live and streaming media.&lt;/p&gt;&lt;hr&gt;&lt;hr&gt; &#xA;&lt;h2&gt;layout: default title: Home nav_order: 1&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://mediapipe.dev/images/mediapipe_small.png&#34; alt=&#34;MediaPipe&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;Attention:&lt;/strong&gt; &lt;em&gt;Thanks for your interest in MediaPipe! We have moved to &lt;a href=&#34;https://developers.google.com/mediapipe&#34;&gt;https://developers.google.com/mediapipe&lt;/a&gt; as the primary developer documentation site for MediaPipe as of April 3, 2023.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;This notice and web page will be removed on June 1, 2023.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Live ML anywhere&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://google.github.io/mediapipe/&#34;&gt;MediaPipe&lt;/a&gt; offers cross-platform, customizable ML solutions for live and streaming media.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/accelerated_small.png&#34; alt=&#34;accelerated.png&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/cross_platform_small.png&#34; alt=&#34;cross_platform.png&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;em&gt;&lt;strong&gt;End-to-End acceleration&lt;/strong&gt;&lt;/em&gt;: &lt;em&gt;Built-in fast ML inference and processing accelerated even on common hardware&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;em&gt;&lt;strong&gt;Build once, deploy anywhere&lt;/strong&gt;&lt;/em&gt;: &lt;em&gt;Unified solution works across Android, iOS, desktop/cloud, web and IoT&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/ready_to_use_small.png&#34; alt=&#34;ready_to_use.png&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/open_source_small.png&#34; alt=&#34;open_source.png&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;em&gt;&lt;strong&gt;Ready-to-use solutions&lt;/strong&gt;&lt;/em&gt;: &lt;em&gt;Cutting-edge ML solutions demonstrating full power of the framework&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;em&gt;&lt;strong&gt;Free and open source&lt;/strong&gt;&lt;/em&gt;: &lt;em&gt;Framework and solutions both under Apache 2.0, fully extensible and customizable&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ML solutions in MediaPipe&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Face Detection&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Face Mesh&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Iris&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Hands&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pose&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Holistic&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/face_detection&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/face_detection_android_gpu_small.gif&#34; alt=&#34;face_detection&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/face_mesh&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/face_mesh_android_gpu_small.gif&#34; alt=&#34;face_mesh&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/iris&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/iris_tracking_android_gpu_small.gif&#34; alt=&#34;iris&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/hands&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/hand_tracking_android_gpu_small.gif&#34; alt=&#34;hand&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/pose&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/pose_tracking_android_gpu_small.gif&#34; alt=&#34;pose&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/holistic&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/holistic_tracking_android_gpu_small.gif&#34; alt=&#34;hair_segmentation&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Hair Segmentation&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Object Detection&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Box Tracking&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Instant Motion Tracking&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Objectron&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;KNIFT&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/hair_segmentation&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/hair_segmentation_android_gpu_small.gif&#34; alt=&#34;hair_segmentation&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/object_detection&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/object_detection_android_gpu_small.gif&#34; alt=&#34;object_detection&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/box_tracking&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/object_tracking_android_gpu_small.gif&#34; alt=&#34;box_tracking&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/instant_motion_tracking&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/instant_motion_tracking_android_small.gif&#34; alt=&#34;instant_motion_tracking&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/objectron&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/objectron_chair_android_gpu_small.gif&#34; alt=&#34;objectron&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/knift&#34;&gt;&lt;img src=&#34;https://mediapipe.dev/images/mobile/template_matching_android_cpu_small.gif&#34; alt=&#34;knift&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- []() in the first cell is needed to preserve table formatting in GitHub Pages. --&gt; &#xA;&lt;!-- Whenever this table is updated, paste a copy to solutions/solutions.md. --&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/getting_started/android&#34;&gt;Android&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/getting_started/ios&#34;&gt;iOS&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/getting_started/cpp&#34;&gt;C++&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/getting_started/python&#34;&gt;Python&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/getting_started/javascript&#34;&gt;JS&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/google/mediapipe/tree/master/mediapipe/examples/coral/README.md&#34;&gt;Coral&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/face_detection&#34;&gt;Face Detection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/face_mesh&#34;&gt;Face Mesh&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/iris&#34;&gt;Iris&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/hands&#34;&gt;Hands&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/pose&#34;&gt;Pose&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/holistic&#34;&gt;Holistic&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/selfie_segmentation&#34;&gt;Selfie Segmentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/hair_segmentation&#34;&gt;Hair Segmentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/object_detection&#34;&gt;Object Detection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/box_tracking&#34;&gt;Box Tracking&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/instant_motion_tracking&#34;&gt;Instant Motion Tracking&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/objectron&#34;&gt;Objectron&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/knift&#34;&gt;KNIFT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/autoflip&#34;&gt;AutoFlip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/media_sequence&#34;&gt;MediaSequence&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://google.github.io/mediapipe/solutions/youtube_8m&#34;&gt;YouTube 8M&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;See also &lt;a href=&#34;https://google.github.io/mediapipe/solutions/models&#34;&gt;MediaPipe Models and Model Cards&lt;/a&gt; for ML models released in MediaPipe.&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;To start using MediaPipe &lt;a href=&#34;https://google.github.io/mediapipe/solutions/solutions&#34;&gt;solutions&lt;/a&gt; with only a few lines code, see example code and demos in &lt;a href=&#34;https://google.github.io/mediapipe/getting_started/python&#34;&gt;MediaPipe in Python&lt;/a&gt; and &lt;a href=&#34;https://google.github.io/mediapipe/getting_started/javascript&#34;&gt;MediaPipe in JavaScript&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To use MediaPipe in C++, Android and iOS, which allow further customization of the &lt;a href=&#34;https://google.github.io/mediapipe/solutions/solutions&#34;&gt;solutions&lt;/a&gt; as well as building your own, learn how to &lt;a href=&#34;https://google.github.io/mediapipe/getting_started/install&#34;&gt;install&lt;/a&gt; MediaPipe and start building example applications in &lt;a href=&#34;https://google.github.io/mediapipe/getting_started/cpp&#34;&gt;C++&lt;/a&gt;, &lt;a href=&#34;https://google.github.io/mediapipe/getting_started/android&#34;&gt;Android&lt;/a&gt; and &lt;a href=&#34;https://google.github.io/mediapipe/getting_started/ios&#34;&gt;iOS&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The source code is hosted in the &lt;a href=&#34;https://github.com/google/mediapipe&#34;&gt;MediaPipe Github repository&lt;/a&gt;, and you can run code search using &lt;a href=&#34;https://cs.opensource.google/mediapipe/mediapipe&#34;&gt;Google Open Source Code Search&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Publications&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2021/07/bringing-artworks-to-life-with-ar.html&#34;&gt;Bringing artworks to life with AR&lt;/a&gt; in Google Developers Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2021/05/control-your-mirru-prosthesis-with-mediapipe-hand-tracking.html&#34;&gt;Prosthesis control via Mirru App using MediaPipe hand tracking&lt;/a&gt; in Google Developers Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2021/04/signall-sdk-sign-language-interface-using-mediapipe-now-available.html&#34;&gt;SignAll SDK: Sign language interface using MediaPipe is now available for developers&lt;/a&gt; in Google Developers Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html&#34;&gt;MediaPipe Holistic - Simultaneous Face, Hand and Pose Prediction, on Device&lt;/a&gt; in Google AI Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.googleblog.com/2020/10/background-features-in-google-meet.html&#34;&gt;Background Features in Google Meet, Powered by Web ML&lt;/a&gt; in Google AI Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2020/09/mediapipe-3d-face-transform.html&#34;&gt;MediaPipe 3D Face Transform&lt;/a&gt; in Google Developers Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2020/08/instant-motion-tracking-with-mediapipe.html&#34;&gt;Instant Motion Tracking With MediaPipe&lt;/a&gt; in Google Developers Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.googleblog.com/2020/08/on-device-real-time-body-pose-tracking.html&#34;&gt;BlazePose - On-device Real-time Body Pose Tracking&lt;/a&gt; in Google AI Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.googleblog.com/2020/08/mediapipe-iris-real-time-iris-tracking.html&#34;&gt;MediaPipe Iris: Real-time Eye Tracking and Depth Estimation&lt;/a&gt; in Google AI Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2020/04/mediapipe-knift-template-based-feature-matching.html&#34;&gt;MediaPipe KNIFT: Template-based feature matching&lt;/a&gt; in Google Developers Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2020/03/alfred-camera-smart-camera-features-using-mediapipe.html&#34;&gt;Alfred Camera: Smart camera features using MediaPipe&lt;/a&gt; in Google Developers Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.googleblog.com/2020/03/real-time-3d-object-detection-on-mobile.html&#34;&gt;Real-Time 3D Object Detection on Mobile Devices with MediaPipe&lt;/a&gt; in Google AI Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.googleblog.com/2020/02/autoflip-open-source-framework-for.html&#34;&gt;AutoFlip: An Open Source Framework for Intelligent Video Reframing&lt;/a&gt; in Google AI Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2020/01/mediapipe-on-web.html&#34;&gt;MediaPipe on the Web&lt;/a&gt; in Google Developers Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2019/12/object-detection-and-tracking-using-mediapipe.html&#34;&gt;Object Detection and Tracking using MediaPipe&lt;/a&gt; in Google Developers Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html&#34;&gt;On-Device, Real-Time Hand Tracking with MediaPipe&lt;/a&gt; in Google AI Blog&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1906.08172&#34;&gt;MediaPipe: A Framework for Building Perception Pipelines&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Videos&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/c/MediaPipe&#34;&gt;YouTube Channel&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Events&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mediapipe.page.link/seattle2020&#34;&gt;MediaPipe Seattle Meetup, Google Building Waterside, 13 Feb 2020&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aisea20.xnextcon.com/&#34;&gt;AI Nextcon 2020, 12-16 Feb 2020, Seattle&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/Madrid-AI-Developers-Group/events/266329088/&#34;&gt;MediaPipe Madrid Meetup, 16 Dec 2019&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/London-AI-Tech-Talk/events/266329038&#34;&gt;MediaPipe London Meetup, Google 123 Building, 12 Dec 2019&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mlconference.ai/machine-learning-advanced-development/mediapipe-building-real-time-cross-platform-mobile-web-edge-desktop-video-audio-ml-pipelines/&#34;&gt;ML Conference, Berlin, 11 Dec 2019&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/Berlin-AI-Tech-Talk/events/266328794/&#34;&gt;MediaPipe Berlin Meetup, Google Berlin, 11 Dec 2019&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://research.google.com/youtube8m/workshop2019/index.html&#34;&gt;The 3rd Workshop on YouTube-8M Large Scale Video Understanding Workshop, Seoul, Korea ICCV 2019&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aidevworld.com&#34;&gt;AI DevWorld 2019, 10 Oct 2019, San Jose, CA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://2019.ieeeicip.org/?action=page4&amp;amp;id=14#Google&#34;&gt;Google Industry Workshop at ICIP 2019, 24 Sept 2019, Taipei, Taiwan&lt;/a&gt; (&lt;a href=&#34;https://docs.google.com/presentation/d/e/2PACX-1vRIBBbO_LO9v2YmvbHHEt1cwyqH6EjDxiILjuT0foXy1E7g6uyh4CesB2DkkEwlRDO9_lWfuKMZx98T/pub?start=false&amp;amp;loop=false&amp;amp;delayms=3000&amp;amp;slide=id.g556cc1a659_0_5&#34;&gt;presentation&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sites.google.com/corp/view/perception-cv4arvr/mediapipe&#34;&gt;Open sourced at CVPR 2019, 17~20 June, Long Beach, CA&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mediapipe.page.link/awesome-mediapipe&#34;&gt;Awesome MediaPipe&lt;/a&gt; - A curated list of awesome MediaPipe related frameworks, libraries and software&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mediapipe.page.link/joinslack&#34;&gt;Slack community&lt;/a&gt; for MediaPipe users&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/mediapipe&#34;&gt;Discuss&lt;/a&gt; - General community discussion around MediaPipe&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Alpha disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;MediaPipe is currently in alpha at v0.7. We may be still making breaking API changes and expect to get to stable APIs by v1.0.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions. Please follow these &lt;a href=&#34;https://github.com/google/mediapipe/raw/master/CONTRIBUTING.md&#34;&gt;guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We use GitHub issues for tracking requests and bugs. Please post questions to the MediaPipe Stack Overflow with a &lt;code&gt;mediapipe&lt;/code&gt; tag.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>tesseract-ocr/tesseract</title>
    <updated>2023-04-30T01:51:58Z</updated>
    <id>tag:github.com,2023-04-30:/tesseract-ocr/tesseract</id>
    <link href="https://github.com/tesseract-ocr/tesseract" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tesseract Open Source OCR Engine (main repository)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tesseract OCR&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ci.appveyor.com/project/zdenop/tesseract/&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/miah0ikfsf0j3819/branch/master?svg=true&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/actions/workflows/sw.yml&#34;&gt;&lt;img src=&#34;https://github.com/tesseract-ocr/tesseract/workflows/sw/badge.svg?sanitize=true&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://scan.coverity.com/projects/tesseract-ocr&#34;&gt;&lt;img src=&#34;https://scan.coverity.com/projects/tesseract-ocr/badge.svg?sanitize=true&#34; alt=&#34;Coverity Scan Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/security/code-scanning&#34;&gt;&lt;img src=&#34;https://github.com/tesseract-ocr/tesseract/workflows/CodeQL/badge.svg?sanitize=true&#34; alt=&#34;CodeQL&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;amp;can=2&amp;amp;q=proj:tesseract-ocr&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/oss--fuzz-fuzzing-brightgreen&#34; alt=&#34;OSS-Fuzz&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache--2.0-blue.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/releases/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/download-all%20releases-brightgreen.svg?sanitize=true&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#tesseract-ocr&#34;&gt;Tesseract OCR&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#about&#34;&gt;About&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#brief-history&#34;&gt;Brief history&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#installing-tesseract&#34;&gt;Installing Tesseract&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#running-tesseract&#34;&gt;Running Tesseract&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#for-developers&#34;&gt;For developers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#support&#34;&gt;Support&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#dependencies&#34;&gt;Dependencies&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#latest-version-of-readme&#34;&gt;Latest Version of README&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;This package contains an &lt;strong&gt;OCR engine&lt;/strong&gt; - &lt;code&gt;libtesseract&lt;/code&gt; and a &lt;strong&gt;command line program&lt;/strong&gt; - &lt;code&gt;tesseract&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Tesseract 4 adds a new neural net (LSTM) based &lt;a href=&#34;https://en.wikipedia.org/wiki/Optical_character_recognition&#34;&gt;OCR engine&lt;/a&gt; which is focused on line recognition, but also still supports the legacy Tesseract OCR engine of Tesseract 3 which works by recognizing character patterns. Compatibility with Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0). It also needs &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/Data-Files.html&#34;&gt;traineddata&lt;/a&gt; files which support the legacy engine, for example those from the &lt;a href=&#34;https://github.com/tesseract-ocr/tessdata&#34;&gt;tessdata&lt;/a&gt; repository.&lt;/p&gt; &#xA;&lt;p&gt;Stefan Weil is the current lead developer. Ray Smith was the lead developer until 2018. The maintainer is Zdenko Podobny. For a list of contributors see &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/raw/main/AUTHORS&#34;&gt;AUTHORS&lt;/a&gt; and GitHub&#39;s log of &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/graphs/contributors&#34;&gt;contributors&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Tesseract has &lt;strong&gt;unicode (UTF-8) support&lt;/strong&gt;, and can &lt;strong&gt;recognize &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html&#34;&gt;more than 100 languages&lt;/a&gt;&lt;/strong&gt; &#34;out of the box&#34;.&lt;/p&gt; &#xA;&lt;p&gt;Tesseract supports &lt;strong&gt;&lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/InputFormats&#34;&gt;various image formats&lt;/a&gt;&lt;/strong&gt; including PNG, JPEG and TIFF.&lt;/p&gt; &#xA;&lt;p&gt;Tesseract supports &lt;strong&gt;various output formats&lt;/strong&gt;: plain text, hOCR (HTML), PDF, invisible-text-only PDF, TSV and ALTO (the last one - since version 4.1.0).&lt;/p&gt; &#xA;&lt;p&gt;You should note that in many cases, in order to get better OCR results, you&#39;ll need to &lt;strong&gt;&lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html&#34;&gt;improve the quality&lt;/a&gt; of the image&lt;/strong&gt; you are giving Tesseract.&lt;/p&gt; &#xA;&lt;p&gt;This project &lt;strong&gt;does not include a GUI application&lt;/strong&gt;. If you need one, please see the &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/User-Projects-%E2%80%93-3rdParty.html&#34;&gt;3rdParty&lt;/a&gt; documentation.&lt;/p&gt; &#xA;&lt;p&gt;Tesseract &lt;strong&gt;can be trained to recognize other languages&lt;/strong&gt;. See &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/Training-Tesseract.html&#34;&gt;Tesseract Training&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Brief history&lt;/h2&gt; &#xA;&lt;p&gt;Tesseract was originally developed at Hewlett-Packard Laboratories Bristol UK and at Hewlett-Packard Co, Greeley Colorado USA between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some C++izing in 1998. In 2005 Tesseract was open sourced by HP. From 2006 until November 2018 it was developed by Google.&lt;/p&gt; &#xA;&lt;p&gt;Major version 5 is the current stable version and started with release &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/releases/tag/5.0.0&#34;&gt;5.0.0&lt;/a&gt; on November 30, 2021. Newer minor versions and bugfix versions are available from &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/releases/&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Latest source code is available from &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/tree/main&#34;&gt;main branch on GitHub&lt;/a&gt;. Open issues can be found in &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/issues&#34;&gt;issue tracker&lt;/a&gt;, and &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/Planning.html&#34;&gt;planning documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;strong&gt;&lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/ReleaseNotes.html&#34;&gt;Release Notes&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/raw/main/ChangeLog&#34;&gt;Change Log&lt;/a&gt;&lt;/strong&gt; for more details of the releases.&lt;/p&gt; &#xA;&lt;h2&gt;Installing Tesseract&lt;/h2&gt; &#xA;&lt;p&gt;You can either &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/Installation.html&#34;&gt;Install Tesseract via pre-built binary package&lt;/a&gt; or &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/Compiling.html&#34;&gt;build it from source&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;A C++ compiler with good C++17 support is required for building Tesseract from source.&lt;/p&gt; &#xA;&lt;h2&gt;Running Tesseract&lt;/h2&gt; &#xA;&lt;p&gt;Basic &lt;strong&gt;&lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html&#34;&gt;command line usage&lt;/a&gt;&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;tesseract imagename outputbase [-l lang] [--oem ocrenginemode] [--psm pagesegmode] [configfiles...]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information about the various command line options use &lt;code&gt;tesseract --help&lt;/code&gt; or &lt;code&gt;man tesseract&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Examples can be found in the &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html#simplest-invocation-to-ocr-an-image&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;For developers&lt;/h2&gt; &#xA;&lt;p&gt;Developers can use &lt;code&gt;libtesseract&lt;/code&gt; &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/raw/main/include/tesseract/capi.h&#34;&gt;C&lt;/a&gt; or &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/raw/main/include/tesseract/baseapi.h&#34;&gt;C++&lt;/a&gt; API to build their own application. If you need bindings to &lt;code&gt;libtesseract&lt;/code&gt; for other programming languages, please see the &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/AddOns.html#tesseract-wrappers&#34;&gt;wrapper&lt;/a&gt; section in the AddOns documentation.&lt;/p&gt; &#xA;&lt;p&gt;Documentation of Tesseract generated from source code by doxygen can be found on &lt;a href=&#34;https://tesseract-ocr.github.io/&#34;&gt;tesseract-ocr.github.io&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;Before you submit an issue, please review &lt;strong&gt;&lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/raw/main/CONTRIBUTING.md&#34;&gt;the guidelines for this repository&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For support, first read the &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/&#34;&gt;documentation&lt;/a&gt;, particularly the &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/FAQ.html&#34;&gt;FAQ&lt;/a&gt; to see if your problem is addressed there. If not, search the &lt;a href=&#34;https://groups.google.com/g/tesseract-ocr&#34;&gt;Tesseract user forum&lt;/a&gt;, the &lt;a href=&#34;https://groups.google.com/g/tesseract-dev&#34;&gt;Tesseract developer forum&lt;/a&gt; and &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/issues&#34;&gt;past issues&lt;/a&gt;, and if you still can&#39;t find what you need, ask for support in the mailing-lists.&lt;/p&gt; &#xA;&lt;p&gt;Mailing-lists:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/g/tesseract-ocr&#34;&gt;tesseract-ocr&lt;/a&gt; - For tesseract users.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/g/tesseract-dev&#34;&gt;tesseract-dev&lt;/a&gt; - For tesseract developers.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please report an issue only for a &lt;strong&gt;bug&lt;/strong&gt;, not for asking questions.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;The code in this repository is licensed under the Apache License, Version 2.0 (the &#34;License&#34;);&#xA;you may not use this file except in compliance with the License.&#xA;You may obtain a copy of the License at&#xA;&#xA;   http://www.apache.org/licenses/LICENSE-2.0&#xA;&#xA;Unless required by applicable law or agreed to in writing, software&#xA;distributed under the License is distributed on an &#34;AS IS&#34; BASIS,&#xA;WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&#xA;See the License for the specific language governing permissions and&#xA;limitations under the License.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This software depends on other packages that may be licensed under different open source licenses.&lt;/p&gt; &#xA;&lt;p&gt;Tesseract uses &lt;a href=&#34;http://leptonica.com/&#34;&gt;Leptonica library&lt;/a&gt; which essentially uses a &lt;a href=&#34;http://leptonica.com/about-the-license.html&#34;&gt;BSD 2-clause license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;Tesseract uses &lt;a href=&#34;https://github.com/DanBloomberg/leptonica&#34;&gt;Leptonica library&lt;/a&gt; for opening input images (e.g. not documents like pdf). It is suggested to use leptonica with built-in support for &lt;a href=&#34;https://zlib.net&#34;&gt;zlib&lt;/a&gt;, &lt;a href=&#34;https://sourceforge.net/projects/libpng&#34;&gt;png&lt;/a&gt; and &lt;a href=&#34;http://www.simplesystems.org/libtiff&#34;&gt;tiff&lt;/a&gt; (for multipage tiff).&lt;/p&gt; &#xA;&lt;h2&gt;Latest Version of README&lt;/h2&gt; &#xA;&lt;p&gt;For the latest online version of the README.md see:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/raw/main/README.md&#34;&gt;https://github.com/tesseract-ocr/tesseract/blob/main/README.md&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rizinorg/cutter</title>
    <updated>2023-04-30T01:51:58Z</updated>
    <id>tag:github.com,2023-04-30:/rizinorg/cutter</id>
    <link href="https://github.com/rizinorg/cutter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Free and Open Source Reverse Engineering Platform powered by rizin&lt;/p&gt;&lt;hr&gt;&lt;img width=&#34;150&#34; height=&#34;150&#34; align=&#34;left&#34; style=&#34;float: left; margin: 0 10px 0 0;&#34; alt=&#34;Cutter logo&#34; src=&#34;https://raw.githubusercontent.com/rizinorg/cutter/dev/src/img/cutter.svg?sanitize=true&#34;&gt; &#xA;&lt;h1&gt;Cutter&lt;/h1&gt; &#xA;&lt;p&gt;Cutter is a free and open-source reverse engineering platform powered by &lt;a href=&#34;https://github.com/rizinorg/rizin&#34;&gt;rizin&lt;/a&gt;. It aims at being an advanced and customizable reverse engineering platform while keeping the user experience in mind. Cutter is created by reverse engineers for reverse engineers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/rizinorg/cutter/actions?query=workflow%3A%22Cutter+CI%22&#34;&gt;&lt;img src=&#34;https://github.com/rizinorg/cutter/workflows/Cutter%20CI/badge.svg?sanitize=true&#34; alt=&#34;Cutter CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ci.appveyor.com/project/rizinorg/cutter/branch/dev&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/tn7kttv55b8wf799/branch/dev?svg=true&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rizinorg/cutter/dev/docs/source/images/screenshot.png&#34; alt=&#34;Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Learn more at &lt;a href=&#34;https://cutter.re&#34;&gt;cutter.re&lt;/a&gt;.&lt;/h2&gt; &#xA;&lt;h2&gt;Getting Cutter&lt;/h2&gt; &#xA;&lt;h3&gt;Download&lt;/h3&gt; &#xA;&lt;p&gt;Cutter release binaries for all major platforms (Linux, macOS, Windows) can be downloaded from &lt;a href=&#34;https://github.com/rizinorg/cutter/releases&#34;&gt;GitHub Releases&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux&lt;/strong&gt;: If your distribution provides it, check for &lt;code&gt;cutter&lt;/code&gt; package in your package manager (or &lt;code&gt;cutter-re&lt;/code&gt;). If not available there, we have setup repositories in &lt;a href=&#34;https://openbuildservice.org/&#34;&gt;OBS&lt;/a&gt; for some common distributions. Look at &lt;a href=&#34;https://software.opensuse.org/download/package?package=cutter-re&amp;amp;project=home%3ARizinOrg&#34;&gt;https://software.opensuse.org/package/cutter-re&lt;/a&gt; and follow the instructions there. Otherwise download the &lt;code&gt;.AppImage&lt;/code&gt; file from our release, make it executable and run as below or use &lt;a href=&#34;https://github.com/TheAssassin/AppImageLauncher&#34;&gt;AppImageLauncher&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;code&gt;chmod +x Cutter*.AppImage; ./Cutter*.AppImage&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;macOS&lt;/strong&gt;: Download the &lt;code&gt;.dmg&lt;/code&gt; file or use &lt;a href=&#34;https://github.com/Homebrew/homebrew-cask&#34;&gt;Homebrew Cask&lt;/a&gt;:&lt;/p&gt; &lt;p&gt;&lt;code&gt;brew install --cask cutter&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;: Download the &lt;code&gt;.zip&lt;/code&gt; archive, or use either &lt;a href=&#34;https://chocolatey.org&#34;&gt;Chocolatey&lt;/a&gt; or &lt;a href=&#34;https://scoop.sh/&#34;&gt;Scoop&lt;/a&gt;:&lt;/p&gt; &lt;p&gt;&lt;code&gt;choco install cutter&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;scoop bucket add extras&lt;/code&gt; followed by &lt;code&gt;scoop install cutter&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Build from sources&lt;/h3&gt; &#xA;&lt;p&gt;To build Cutter from sources, please check the &lt;a href=&#34;https://cutter.re/docs/building.html&#34;&gt;Building Docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Docker image&lt;/h3&gt; &#xA;&lt;p&gt;To deploy &lt;em&gt;cutter&lt;/em&gt; using a pre-built &lt;code&gt;Dockerfile&lt;/code&gt;, it&#39;s possible to use the &lt;a href=&#34;https://raw.githubusercontent.com/rizinorg/cutter/dev/docker&#34;&gt;provided configuration&lt;/a&gt;. The corresponding &lt;code&gt;README.md&lt;/code&gt; file also contains instructions on how to get started using the docker image with minimal effort.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://cutter.re/docs/user-docs.html&#34;&gt;User Guide&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://cutter.re/docs/contributing.html&#34;&gt;Contribution Guidelines&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://cutter.re/docs/contributing/code.html&#34;&gt;Developers Docs&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;Plugins&lt;/h2&gt; &#xA;&lt;p&gt;Cutter supports both Python and Native C++ plugins.&lt;/p&gt; &#xA;&lt;p&gt;Our community has built many plugins and useful scripts for Cutter such as the native integration of &lt;a href=&#34;https://github.com/rizinorg/rz-ghidra&#34;&gt;Ghidra decompiler&lt;/a&gt; or the plugin to visualize DynamoRIO code coverage. You can find a list of cutter plugins linked below. Feel free to extend it with your own plugins and scripts for Cutter.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/rizinorg/cutter-plugins&#34;&gt;Official &amp;amp; Community Plugins&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://cutter.re/docs/plugins.html&#34;&gt;Plugins Development Guide&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting Help&lt;/h2&gt; &#xA;&lt;p&gt;Please use the following channels to ask for help from Cutter developers and community:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Telegram:&lt;/strong&gt; &lt;a href=&#34;https://t.me/cutter_re&#34;&gt;https://t.me/cutter_re&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Mattermost:&lt;/strong&gt; &lt;a href=&#34;https://im.rizin.re&#34;&gt;https://im.rizin.re&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;IRC:&lt;/strong&gt; #cutter on &lt;a href=&#34;https://web.libera.chat/&#34;&gt;https://web.libera.chat/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Twitter:&lt;/strong&gt; &lt;a href=&#34;https://twitter.com/cutter_re&#34;&gt;@cutter_re&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>