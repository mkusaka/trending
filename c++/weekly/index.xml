<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-12-08T01:37:33Z</updated>
  <subtitle>Weekly Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>XRPLF/rippled</title>
    <updated>2024-12-08T01:37:33Z</updated>
    <id>tag:github.com,2024-12-08:/XRPLF/rippled</id>
    <link href="https://github.com/XRPLF/rippled" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Decentralized cryptocurrency blockchain daemon implementing the XRP Ledger protocol in C++&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The XRP Ledger&lt;/h1&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://xrpl.org/&#34;&gt;XRP Ledger&lt;/a&gt; is a decentralized cryptographic ledger powered by a network of peer-to-peer nodes. The XRP Ledger uses a novel Byzantine Fault Tolerant consensus algorithm to settle and record transactions in a secure distributed database without a central operator.&lt;/p&gt; &#xA;&lt;h2&gt;XRP&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://xrpl.org/xrp.html&#34;&gt;XRP&lt;/a&gt; is a public, counterparty-free asset native to the XRP Ledger, and is designed to bridge the many different currencies in use worldwide. XRP is traded on the open-market and is available for anyone to access. The XRP Ledger was created in 2012 with a finite supply of 100 billion units of XRP.&lt;/p&gt; &#xA;&lt;h2&gt;rippled&lt;/h2&gt; &#xA;&lt;p&gt;The server software that powers the XRP Ledger is called &lt;code&gt;rippled&lt;/code&gt; and is available in this repository under the permissive &lt;a href=&#34;https://raw.githubusercontent.com/XRPLF/rippled/develop/LICENSE.md&#34;&gt;ISC open-source license&lt;/a&gt;. The &lt;code&gt;rippled&lt;/code&gt; server software is written primarily in C++ and runs on a variety of platforms. The &lt;code&gt;rippled&lt;/code&gt; server software can run in several modes depending on its &lt;a href=&#34;https://xrpl.org/rippled-server-modes.html&#34;&gt;configuration&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you are interested in running an &lt;strong&gt;API Server&lt;/strong&gt; (including a &lt;strong&gt;Full History Server&lt;/strong&gt;), take a look at &lt;a href=&#34;https://github.com/XRPLF/clio&#34;&gt;Clio&lt;/a&gt;. (rippled Reporting Mode has been replaced by Clio.)&lt;/p&gt; &#xA;&lt;h3&gt;Build from Source&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/XRPLF/rippled/develop/BUILD.md&#34;&gt;Read the build instructions in &lt;code&gt;BUILD.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you encounter any issues, please &lt;a href=&#34;https://github.com/XRPLF/rippled/issues&#34;&gt;open an issue&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Key Features of the XRP Ledger&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://xrpl.org/xrp-ledger-overview.html#censorship-resistant-transaction-processing&#34;&gt;Censorship-Resistant Transaction Processing&lt;/a&gt;:&lt;/strong&gt; No single party decides which transactions succeed or fail, and no one can &#34;roll back&#34; a transaction after it completes. As long as those who choose to participate in the network keep it healthy, they can settle transactions in seconds.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://xrpl.org/xrp-ledger-overview.html#fast-efficient-consensus-algorithm&#34;&gt;Fast, Efficient Consensus Algorithm&lt;/a&gt;:&lt;/strong&gt; The XRP Ledger&#39;s consensus algorithm settles transactions in 4 to 5 seconds, processing at a throughput of up to 1500 transactions per second. These properties put XRP at least an order of magnitude ahead of other top digital assets.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://xrpl.org/xrp-ledger-overview.html#finite-xrp-supply&#34;&gt;Finite XRP Supply&lt;/a&gt;:&lt;/strong&gt; When the XRP Ledger began, 100 billion XRP were created, and no more XRP will ever be created. The available supply of XRP decreases slowly over time as small amounts are destroyed to pay transaction costs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://xrpl.org/xrp-ledger-overview.html#responsible-software-governance&#34;&gt;Responsible Software Governance&lt;/a&gt;:&lt;/strong&gt; A team of full-time, world-class developers at Ripple maintain and continually improve the XRP Ledger&#39;s underlying software with contributions from the open-source community. Ripple acts as a steward for the technology and an advocate for its interests, and builds constructive relationships with governments and financial institutions worldwide.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://xrpl.org/xrp-ledger-overview.html#secure-adaptable-cryptography&#34;&gt;Secure, Adaptable Cryptography&lt;/a&gt;:&lt;/strong&gt; The XRP Ledger relies on industry standard digital signature systems like ECDSA (the same scheme used by Bitcoin) but also supports modern, efficient algorithms like Ed25519. The extensible nature of the XRP Ledger&#39;s software makes it possible to add and disable algorithms as the state of the art in cryptography advances.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://xrpl.org/xrp-ledger-overview.html#modern-features-for-smart-contracts&#34;&gt;Modern Features for Smart Contracts&lt;/a&gt;:&lt;/strong&gt; Features like Escrow, Checks, and Payment Channels support cutting-edge financial applications including the &lt;a href=&#34;https://interledger.org/&#34;&gt;Interledger Protocol&lt;/a&gt;. This toolbox of advanced features comes with safety features like a process for amending the network and separate checks against invariant constraints.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://xrpl.org/xrp-ledger-overview.html#on-ledger-decentralized-exchange&#34;&gt;On-Ledger Decentralized Exchange&lt;/a&gt;:&lt;/strong&gt; In addition to all the features that make XRP useful on its own, the XRP Ledger also has a fully-functional accounting system for tracking and trading obligations denominated in any way users want, and an exchange built into the protocol. The XRP Ledger can settle long, cross-currency payment paths and exchanges of multiple currencies in atomic transactions, bridging gaps of trust with XRP.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Source Code&lt;/h2&gt; &#xA;&lt;p&gt;Here are some good places to start learning the source code:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Read the markdown files in the source tree: &lt;code&gt;src/ripple/**/*.md&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Read &lt;a href=&#34;https://raw.githubusercontent.com/XRPLF/rippled/develop/Builds/levelization&#34;&gt;the levelization document&lt;/a&gt; to get an idea of the internal dependency graph.&lt;/li&gt; &#xA; &lt;li&gt;In the big picture, the &lt;code&gt;main&lt;/code&gt; function constructs an &lt;code&gt;ApplicationImp&lt;/code&gt; object, which implements the &lt;code&gt;Application&lt;/code&gt; virtual interface. Almost every component in the application takes an &lt;code&gt;Application&amp;amp;&lt;/code&gt; parameter in its constructor, typically named &lt;code&gt;app&lt;/code&gt; and stored as a member variable &lt;code&gt;app_&lt;/code&gt;. This allows most components to depend on any other component.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Repository Contents&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Folder&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Contents&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;./bin&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Scripts and data files for Ripple integrators.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;./Builds&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Platform-specific guides for building &lt;code&gt;rippled&lt;/code&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;./docs&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Source documentation files and doxygen config.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;./cfg&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Example configuration files.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;code&gt;./src&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Source code.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Some of the directories under &lt;code&gt;src&lt;/code&gt; are external repositories included using git-subtree. See those directories&#39; README files for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Additional Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xrpl.org/&#34;&gt;XRP Ledger Dev Portal&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xrpl.org/install-rippled.html&#34;&gt;Setup and Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xrplf.github.io/rippled/&#34;&gt;Source Documentation (Doxygen)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;See Also&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/XRPLF/clio&#34;&gt;Clio API Server for the XRP Ledger&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/g/ripple-server&#34;&gt;Mailing List for Release Announcements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLJQ55Tj1hIVZtJ_JdTvSum2qMTsedWkNi&#34;&gt;Learn more about the XRP Ledger (YouTube)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>trustwallet/wallet-core</title>
    <updated>2024-12-08T01:37:33Z</updated>
    <id>tag:github.com,2024-12-08:/trustwallet/wallet-core</id>
    <link href="https://github.com/trustwallet/wallet-core" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cross-platform, cross-blockchain wallet library.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://raw.githubusercontent.com/trustwallet/wallet-core/master/docs/banner.png&#34; align=&#34;center&#34; title=&#34;Trust logo&#34;&gt; &#xA;&lt;p&gt;Trust Wallet Core is an open-source, cross-platform, mobile-focused library implementing low-level cryptographic wallet functionality for a high number of blockchains. It is a core part of the popular &lt;a href=&#34;https://trustwallet.com&#34;&gt;Trust Wallet&lt;/a&gt;, and some other projects. Most of the code is C++ with a set of strict C interfaces, and idiomatic interfaces for supported languages: Swift for iOS and Java (Kotlin) for Android.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/ios-ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/ios-ci.yml/badge.svg?sanitize=true&#34; alt=&#34;iOS CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/android-ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/android-ci.yml/badge.svg?sanitize=true&#34; alt=&#34;Android CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/linux-ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/linux-ci.yml/badge.svg?sanitize=true&#34; alt=&#34;Linux CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/linux-ci-rust.yml&#34;&gt;&lt;img src=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/linux-ci-rust.yml/badge.svg?sanitize=true&#34; alt=&#34;Rust CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/wasm-ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/wasm-ci.yml/badge.svg?sanitize=true&#34; alt=&#34;Wasm CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/kotlin-ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/kotlin-ci.yml/badge.svg?sanitize=true&#34; alt=&#34;Kotlin CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/docker.yml&#34;&gt;&lt;img src=&#34;https://github.com/trustwallet/wallet-core/actions/workflows/docker.yml/badge.svg?sanitize=true&#34; alt=&#34;Docker CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sonarcloud.io/summary/new_code?id=TrustWallet_wallet-core&#34;&gt;&lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=TrustWallet_wallet-core&amp;amp;metric=alert_status&#34; alt=&#34;Quality Gate Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitpod.io/#https://github.com/trustwallet/wallet-core&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&#34; alt=&#34;Gitpod Ready-to-Code&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/license/TrustWallet/wallet-core.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/trustwallet/wallet-core&#34; alt=&#34;GitHub release (latest by date)&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/SPM-ready-blue&#34; alt=&#34;SPM&#34;&gt; &lt;img src=&#34;https://img.shields.io/cocoapods/v/TrustWalletCore.svg?sanitize=true&#34; alt=&#34;Cocoapods&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p&gt;For comprehensive documentation, see &lt;a href=&#34;https://developer.trustwallet.com/wallet-core&#34;&gt;developer.trustwallet.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Audit Reports&lt;/h1&gt; &#xA;&lt;p&gt;Security Audit reports can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/trustwallet/wallet-core/master/audit&#34;&gt;audit&lt;/a&gt; directory.&lt;/p&gt; &#xA;&lt;h1&gt;Supported Blockchains&lt;/h1&gt; &#xA;&lt;p&gt;Wallet Core supports more than &lt;strong&gt;130&lt;/strong&gt; blockchains: Bitcoin, Ethereum, BNB, Cosmos, Solana, and most major blockchain platforms. The full list is &lt;a href=&#34;https://raw.githubusercontent.com/trustwallet/wallet-core/master/docs/registry.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Building&lt;/h1&gt; &#xA;&lt;p&gt;For build instructions, see &lt;a href=&#34;https://developer.trustwallet.com/wallet-core/building&#34;&gt;developer.trustwallet.com/wallet-core/building&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Using from your project&lt;/h1&gt; &#xA;&lt;p&gt;If you want to use wallet core in your project follow these instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Android&lt;/h2&gt; &#xA;&lt;p&gt;Android releases are hosted on &lt;a href=&#34;https://github.com/trustwallet/wallet-core/packages/700258&#34;&gt;GitHub packages&lt;/a&gt;, you need to add GitHub access token to install it. Please check out &lt;a href=&#34;https://developer.trustwallet.com/wallet-core/integration-guide/android-guide#adding-library-dependency&#34;&gt;this installation guide&lt;/a&gt; or &lt;code&gt;build.gradle&lt;/code&gt; from our &lt;a href=&#34;https://github.com/trustwallet/wallet-core/raw/master/samples/android/build.gradle&#34;&gt;android sample&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Don&#39;t forget replacing the version in the code with latest: &lt;img src=&#34;https://img.shields.io/github/v/release/trustwallet/wallet-core&#34; alt=&#34;GitHub release (latest by date)&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;iOS&lt;/h2&gt; &#xA;&lt;p&gt;We currently support Swift Package Manager and CocoaPods (will discontinue in the future).&lt;/p&gt; &#xA;&lt;h3&gt;SPM&lt;/h3&gt; &#xA;&lt;p&gt;Download latest &lt;code&gt;Package.swift&lt;/code&gt; from &lt;a href=&#34;https://github.com/trustwallet/wallet-core/releases&#34;&gt;GitHub Releases&lt;/a&gt; and put it in a local &lt;code&gt;WalletCore&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;p&gt;Add this line to the &lt;code&gt;dependencies&lt;/code&gt; parameter in your &lt;code&gt;Package.swift&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;.package(name: &#34;WalletCore&#34;, path: &#34;../WalletCore&#34;),&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or add remote url + &lt;code&gt;master&lt;/code&gt; branch, it points to recent (not always latest) binary release.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;.package(name: &#34;WalletCore&#34;, url: &#34;https://github.com/trustwallet/wallet-core&#34;, .branchItem(&#34;master&#34;)),&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then add libraries to target&#39;s &lt;code&gt;dependencies&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;.product(name: &#34;WalletCore&#34;, package: &#34;WalletCore&#34;),&#xA;.product(name: &#34;SwiftProtobuf&#34;, package: &#34;WalletCore&#34;),&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;CocoaPods&lt;/h3&gt; &#xA;&lt;p&gt;Add this line to your Podfile and run &lt;code&gt;pod install&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;pod &#39;TrustWalletCore&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;NPM (beta)&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;npm install @trustwallet/wallet-core&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Go (beta)&lt;/h2&gt; &#xA;&lt;p&gt;Please check out the &lt;a href=&#34;https://github.com/trustwallet/wallet-core/tree/master/samples/go&#34;&gt;Go integration sample&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Kotlin Multipleplatform (beta)&lt;/h2&gt; &#xA;&lt;p&gt;Please check out the &lt;a href=&#34;https://github.com/trustwallet/wallet-core/tree/master/samples/kmp&#34;&gt;Kotlin Multiplatform sample&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Projects&lt;/h1&gt; &#xA;&lt;p&gt;Projects using Trust Wallet Core. Add yours too!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://trustwallet.com&#34;&gt;&lt;img src=&#34;https://trustwallet.com/icon.svg?sanitize=true&#34; alt=&#34;Trust Wallet&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://coinpaprika.com/&#34;&gt;Coinpaprika&lt;/a&gt; | &lt;a href=&#34;https://crypto.com&#34;&gt;crypto.com&lt;/a&gt; | &lt;a href=&#34;https://frontier.xyz/&#34;&gt;Frontier&lt;/a&gt; | &lt;a href=&#34;https://tokenary.io/&#34;&gt;Tokenary&lt;/a&gt; | &lt;a href=&#34;https://planetmemes.com/&#34;&gt;MemesWallet&lt;/a&gt; | &lt;a href=&#34;https://xportal.com/&#34;&gt;xPortal&lt;/a&gt; | &lt;a href=&#34;https://slingshot.finance/&#34;&gt;Slingshot&lt;/a&gt; | &lt;a href=&#34;https://play.google.com/store/apps/details?id=org.ecoinwallet&amp;amp;pcampaignid=web_share&#34;&gt;ECOIN Wallet&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Community&lt;/h1&gt; &#xA;&lt;p&gt;There are a few community-maintained projects that extend Wallet Core to some additional platforms and languages. Note this is not an endorsement, please do your own research before using them:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Flutter binding &lt;a href=&#34;https://github.com/weishirongzhen/flutter_trust_wallet_core&#34;&gt;https://github.com/weishirongzhen/flutter_trust_wallet_core&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Python binding &lt;a href=&#34;https://github.com/phuang/wallet-core-python&#34;&gt;https://github.com/phuang/wallet-core-python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Wallet Core on Windows &lt;a href=&#34;https://github.com/kaetemi/wallet-core-windows&#34;&gt;https://github.com/kaetemi/wallet-core-windows&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;The best way to submit feedback and report bugs related to WalletCore is to &lt;a href=&#34;https://github.com/trustwallet/wallet-core/issues/new&#34;&gt;open a GitHub issue&lt;/a&gt;. If the bug is not related to WalletCore but to the TrustWallet app, please &lt;a href=&#34;https://support.trustwallet.com/en/support/tickets/new&#34;&gt;create a Customer Support ticket&lt;/a&gt;. If you want to contribute code please see &lt;a href=&#34;https://developer.trustwallet.com/wallet-core/contributing&#34;&gt;Contributing&lt;/a&gt;. If you want to add support for a new blockchain also see &lt;a href=&#34;https://developer.trustwallet.com/wallet-core/newblockchain&#34;&gt;Adding Support for a New Blockchain&lt;/a&gt;, make sure you have read the &lt;a href=&#34;https://developer.trustwallet.com/wallet-core/newblockchain#requirements&#34;&gt;requirements&lt;/a&gt; section.&lt;/p&gt; &#xA;&lt;p&gt;Thanks to all the people who contribute. &lt;a href=&#34;https://github.com/trustwallet/wallet-core/graphs/contributors&#34;&gt;&lt;img src=&#34;https://opencollective.com/wallet-core/contributors.svg?width=890&amp;amp;button=false&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Disclaimer&lt;/h1&gt; &#xA;&lt;p&gt;The Wallet Core project is led and managed by Trust Wallet with a large contributor community and actively used in several projects. Our goal at Wallet Core is to give other wallets an easy way to add chain support.&lt;/p&gt; &#xA;&lt;p&gt;Trust Wallet products leverage wallet core, however, they may or may not leverage all the capabilities, features, and assets available in wallet core due to their own product requirements.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;Trust Wallet Core is available under the Apache 2.0 license. See the &lt;a href=&#34;https://raw.githubusercontent.com/trustwallet/wallet-core/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for more info.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/BitNet</title>
    <updated>2024-12-08T01:37:33Z</updated>
    <id>tag:github.com,2024-12-08:/microsoft/BitNet</id>
    <link href="https://github.com/microsoft/BitNet" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official inference framework for 1-bit LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitnet.cpp&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/version-1.0-blue&#34; alt=&#34;version&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support &lt;strong&gt;fast&lt;/strong&gt; and &lt;strong&gt;lossless&lt;/strong&gt; inference of 1.58-bit models on CPU (with NPU and GPU support coming next).&lt;/p&gt; &#xA;&lt;p&gt;The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of &lt;strong&gt;1.37x&lt;/strong&gt; to &lt;strong&gt;5.07x&lt;/strong&gt; on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by &lt;strong&gt;55.4%&lt;/strong&gt; to &lt;strong&gt;70.0%&lt;/strong&gt;, further boosting overall efficiency. On x86 CPUs, speedups range from &lt;strong&gt;2.37x&lt;/strong&gt; to &lt;strong&gt;6.17x&lt;/strong&gt; with energy reductions between &lt;strong&gt;71.9%&lt;/strong&gt; to &lt;strong&gt;82.2%&lt;/strong&gt;. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the &lt;a href=&#34;https://arxiv.org/abs/2410.16144&#34;&gt;technical report&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/BitNet/main/assets/m2_performance.jpg&#34; alt=&#34;m2_performance&#34; width=&#34;800&#34;&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/BitNet/main/assets/intel_performance.jpg&#34; alt=&#34;m2_performance&#34; width=&#34;800&#34;&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&#34;&gt;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s New:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;11/08/2024 &lt;a href=&#34;https://arxiv.org/abs/2411.04965&#34;&gt;BitNet a4.8: 4-bit Activations for 1-bit LLMs&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/NEW-red&#34; alt=&#34;NEW&#34;&gt;&lt;/li&gt; &#xA; &lt;li&gt;10/21/2024 &lt;a href=&#34;https://arxiv.org/abs/2410.16144&#34;&gt;1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;10/17/2024 bitnet.cpp 1.0 released.&lt;/li&gt; &#xA; &lt;li&gt;03/21/2024 &lt;a href=&#34;https://github.com/microsoft/unilm/raw/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf&#34;&gt;The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;02/27/2024 &lt;a href=&#34;https://arxiv.org/abs/2402.17764&#34;&gt;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;10/17/2023 &lt;a href=&#34;https://arxiv.org/abs/2310.11453&#34;&gt;BitNet: Scaling 1-bit Transformers for Large Language Models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;This project is based on the &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp&#39;s kernels are built on top of the Lookup Table methodologies pioneered in &lt;a href=&#34;https://github.com/microsoft/T-MAC/&#34;&gt;T-MAC&lt;/a&gt;. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Models&lt;/h2&gt; &#xA;&lt;p&gt;❗️&lt;strong&gt;We use existing 1-bit LLMs available on &lt;a href=&#34;https://huggingface.co/&#34;&gt;Hugging Face&lt;/a&gt; to demonstrate the inference capabilities of bitnet.cpp. These models are neither trained nor released by Microsoft. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt;  &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th rowspan=&#34;2&#34;&gt;Model&lt;/th&gt; &#xA;   &lt;th rowspan=&#34;2&#34;&gt;Parameters&lt;/th&gt; &#xA;   &lt;th rowspan=&#34;2&#34;&gt;CPU&lt;/th&gt; &#xA;   &lt;th colspan=&#34;3&#34;&gt;Kernel&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;I2_S&lt;/th&gt; &#xA;   &lt;th&gt;TL1&lt;/th&gt; &#xA;   &lt;th&gt;TL2&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;&lt;a href=&#34;https://huggingface.co/1bitLLM/bitnet_b1_58-large&#34;&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;0.7B&lt;/td&gt; &#xA;   &lt;td&gt;x86&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✘&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ARM&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✘&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;&lt;a href=&#34;https://huggingface.co/1bitLLM/bitnet_b1_58-3B&#34;&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;3.3B&lt;/td&gt; &#xA;   &lt;td&gt;x86&lt;/td&gt; &#xA;   &lt;td&gt;✘&lt;/td&gt; &#xA;   &lt;td&gt;✘&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ARM&lt;/td&gt; &#xA;   &lt;td&gt;✘&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✘&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;&lt;a href=&#34;https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens&#34;&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;8.0B&lt;/td&gt; &#xA;   &lt;td&gt;x86&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✘&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ARM&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;✘&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;python&amp;gt;=3.9&lt;/li&gt; &#xA; &lt;li&gt;cmake&amp;gt;=3.22&lt;/li&gt; &#xA; &lt;li&gt;clang&amp;gt;=18 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;For Windows users, install &lt;a href=&#34;https://visualstudio.microsoft.com/downloads/&#34;&gt;Visual Studio 2022&lt;/a&gt;. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Desktop-development with C++&lt;/li&gt; &#xA;     &lt;li&gt;C++-CMake Tools for Windows&lt;/li&gt; &#xA;     &lt;li&gt;Git for Windows&lt;/li&gt; &#xA;     &lt;li&gt;C++-Clang Compiler for Windows&lt;/li&gt; &#xA;     &lt;li&gt;MS-Build Support for LLVM-Toolset (clang)&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;For Debian/Ubuntu users, you can download with &lt;a href=&#34;https://apt.llvm.org/&#34;&gt;Automatic installation script&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;bash -c &#34;$(wget -O - https://apt.llvm.org/llvm.sh)&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;conda (highly recommend)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Build from source&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone --recursive https://github.com/microsoft/BitNet.git&#xA;cd BitNet&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install the dependencies&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# (Recommended) Create a new conda environment&#xA;conda create -n bitnet-cpp python=3.9&#xA;conda activate bitnet-cpp&#xA;&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Build the project&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Download the model from Hugging Face, convert it to quantized gguf format, and build the project&#xA;python setup_env.py --hf-repo HF1BitLLM/Llama3-8B-1.58-100B-tokens -q i2_s&#xA;&#xA;# Or you can manually download the model and run with local path&#xA;huggingface-cli download HF1BitLLM/Llama3-8B-1.58-100B-tokens --local-dir models/Llama3-8B-1.58-100B-tokens&#xA;python setup_env.py -md models/Llama3-8B-1.58-100B-tokens -q i2_s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&#xA;usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]&#xA;                    [--use-pretuned]&#xA;&#xA;Setup the environment for running inference&#xA;&#xA;optional arguments:&#xA;  -h, --help            show this help message and exit&#xA;  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens}&#xA;                        Model used for inference&#xA;  --model-dir MODEL_DIR, -md MODEL_DIR&#xA;                        Directory to save/load the model&#xA;  --log-dir LOG_DIR, -ld LOG_DIR&#xA;                        Directory to save the logging info&#xA;  --quant-type {i2_s,tl1}, -q {i2_s,tl1}&#xA;                        Quantization type&#xA;  --quant-embd          Quantize the embeddings to f16&#xA;  --use-pretuned, -p    Use the pretuned kernel parameters&#xA;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Basic usage&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Run inference with the quantized model&#xA;python run_inference.py -m models/Llama3-8B-1.58-100B-tokens/ggml-model-i2_s.gguf -p &#34;Daniel went back to the the the garden. Mary travelled to the kitchen. Sandra journeyed to the kitchen. Sandra went to the hallway. John went to the bedroom. Mary went back to the garden. Where is Mary?\nAnswer:&#34; -n 6 -temp 0&#xA;&#xA;# Output:&#xA;# Daniel went back to the the the garden. Mary travelled to the kitchen. Sandra journeyed to the kitchen. Sandra went to the hallway. John went to the bedroom. Mary went back to the garden. Where is Mary?&#xA;# Answer: Mary is in the garden.&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&#xA;usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE]&#xA;&#xA;Run inference&#xA;&#xA;optional arguments:&#xA;  -h, --help            show this help message and exit&#xA;  -m MODEL, --model MODEL&#xA;                        Path to model file&#xA;  -n N_PREDICT, --n-predict N_PREDICT&#xA;                        Number of tokens to predict when generating text&#xA;  -p PROMPT, --prompt PROMPT&#xA;                        Prompt to generate text from&#xA;  -t THREADS, --threads THREADS&#xA;                        Number of threads to use&#xA;  -c CTX_SIZE, --ctx-size CTX_SIZE&#xA;                        Size of the prompt context&#xA;  -temp TEMPERATURE, --temperature TEMPERATURE&#xA;                        Temperature, a hyperparameter that controls the randomness of the generated text&#xA;&lt;/pre&gt; &#xA;&lt;h3&gt;Benchmark&lt;/h3&gt; &#xA;&lt;p&gt;We provide scripts to run the inference benchmark providing a model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  &#xA;   &#xA;Setup the environment for running the inference  &#xA;   &#xA;required arguments:  &#xA;  -m MODEL, --model MODEL  &#xA;                        Path to the model file. &#xA;   &#xA;optional arguments:  &#xA;  -h, --help  &#xA;                        Show this help message and exit. &#xA;  -n N_TOKEN, --n-token N_TOKEN  &#xA;                        Number of generated tokens. &#xA;  -p N_PROMPT, --n-prompt N_PROMPT  &#xA;                        Prompt to generate text from. &#xA;  -t THREADS, --threads THREADS  &#xA;                        Number of threads to use. &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here&#39;s a brief explanation of each argument:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;: The path to the model file. This is a required argument that must be provided when running the script.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-n&lt;/code&gt;, &lt;code&gt;--n-token&lt;/code&gt;: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--n-prompt&lt;/code&gt;: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-t&lt;/code&gt;, &lt;code&gt;--threads&lt;/code&gt;: The number of threads to use for running the inference. It is an optional argument with a default value of 2.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;: Show the help message and exit. Use this argument to display usage information.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command would run the inference benchmark using the model located at &lt;code&gt;/path/to/model&lt;/code&gt;, generating 200 tokens from a 256 token prompt, utilizing 4 threads.&lt;/p&gt; &#xA;&lt;p&gt;For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M&#xA;&#xA;# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate&#xA;python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>