<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-02T01:45:02Z</updated>
  <subtitle>Weekly Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>autowarefoundation/autoware.universe</title>
    <updated>2024-06-02T01:45:02Z</updated>
    <id>tag:github.com,2024-06-02:/autowarefoundation/autoware.universe</id>
    <link href="https://github.com/autowarefoundation/autoware.universe" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Autoware Universe&lt;/h1&gt; &#xA;&lt;h2&gt;Welcome to Autoware Universe&lt;/h2&gt; &#xA;&lt;p&gt;Autoware Universe serves as a foundational pillar within the Autoware ecosystem, playing a critical role in enhancing the core functionalities of autonomous driving technologies. This repository is a pivotal element of the Autoware Core/Universe concept, managing a wide array of packages that significantly extend the capabilities of autonomous vehicles.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/autowarefoundation/autoware.universe/main/docs/assets/images/autoware_universe_front.png&#34; alt=&#34;autoware_universe_front&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To dive into the vast world of Autoware and understand how Autoware Universe fits into the bigger picture, we recommend starting with the &lt;a href=&#34;https://autowarefoundation.github.io/autoware-documentation/&#34;&gt;Autoware Documentation&lt;/a&gt;. This resource provides a thorough overview of the Autoware ecosystem, guiding you through its components, functionalities, and how to get started with development.&lt;/p&gt; &#xA;&lt;h3&gt;Explore Autoware Universe documentation&lt;/h3&gt; &#xA;&lt;p&gt;For those looking to explore the specifics of Autoware Universe components, the &lt;a href=&#34;https://autowarefoundation.github.io/autoware.universe/&#34;&gt;Autoware Universe Documentation&lt;/a&gt;, deployed with MKDocs, offers detailed insights.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cameron314/concurrentqueue</title>
    <updated>2024-06-02T01:45:02Z</updated>
    <id>tag:github.com,2024-06-02:/cameron314/concurrentqueue</id>
    <link href="https://github.com/cameron314/concurrentqueue" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A fast multi-producer, multi-consumer lock-free concurrent queue for C++11&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;moodycamel::ConcurrentQueue&#xA; &lt;t&gt;&lt;/t&gt;&lt;/h1&gt; &#xA;&lt;p&gt;An industrial-strength lock-free queue for C++.&lt;/p&gt; &#xA;&lt;p&gt;Note: If all you need is a single-producer, single-consumer queue, I have &lt;a href=&#34;https://github.com/cameron314/readerwriterqueue&#34;&gt;one of those too&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Knock-your-socks-off &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++#benchmarks&#34;&gt;blazing fast performance&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Single-header implementation. Just drop it in your project.&lt;/li&gt; &#xA; &lt;li&gt;Fully thread-safe lock-free queue. Use concurrently from any number of threads.&lt;/li&gt; &#xA; &lt;li&gt;C++11 implementation -- elements are moved (instead of copied) where possible.&lt;/li&gt; &#xA; &lt;li&gt;Templated, obviating the need to deal exclusively with pointers -- memory is managed for you.&lt;/li&gt; &#xA; &lt;li&gt;No artificial limitations on element types or maximum count.&lt;/li&gt; &#xA; &lt;li&gt;Memory can be allocated once up-front, or dynamically as needed.&lt;/li&gt; &#xA; &lt;li&gt;Fully portable (no assembly; all is done through standard C++11 primitives).&lt;/li&gt; &#xA; &lt;li&gt;Supports super-fast bulk operations.&lt;/li&gt; &#xA; &lt;li&gt;Includes a low-overhead blocking version (BlockingConcurrentQueue).&lt;/li&gt; &#xA; &lt;li&gt;Exception safe.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Reasons to use&lt;/h2&gt; &#xA;&lt;p&gt;There are not that many full-fledged lock-free queues for C++. Boost has one, but it&#39;s limited to objects with trivial assignment operators and trivial destructors, for example. Intel&#39;s TBB queue isn&#39;t lock-free, and requires trivial constructors too. There&#39;re many academic papers that implement lock-free queues in C++, but usable source code is hard to find, and tests even more so.&lt;/p&gt; &#xA;&lt;p&gt;This queue not only has less limitations than others (for the most part), but &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++#benchmarks&#34;&gt;it&#39;s also faster&lt;/a&gt;. It&#39;s been fairly well-tested, and offers advanced features like &lt;strong&gt;bulk enqueueing/dequeueing&lt;/strong&gt; (which, with my new design, is much faster than one element at a time, approaching and even surpassing the speed of a non-concurrent queue even under heavy contention).&lt;/p&gt; &#xA;&lt;p&gt;In short, there was a lock-free queue shaped hole in the C++ open-source universe, and I set out to fill it with the fastest, most complete, and well-tested design and implementation I could. The result is &lt;code&gt;moodycamel::ConcurrentQueue&lt;/code&gt; :-)&lt;/p&gt; &#xA;&lt;h2&gt;Reasons &lt;em&gt;not&lt;/em&gt; to use&lt;/h2&gt; &#xA;&lt;p&gt;The fastest synchronization of all is the kind that never takes place. Fundamentally, concurrent data structures require some synchronization, and that takes time. Every effort was made, of course, to minimize the overhead, but if you can avoid sharing data between threads, do so!&lt;/p&gt; &#xA;&lt;p&gt;Why use concurrent data structures at all, then? Because they&#39;re gosh darn convenient! (And, indeed, sometimes sharing data concurrently is unavoidable.)&lt;/p&gt; &#xA;&lt;p&gt;My queue is &lt;strong&gt;not linearizable&lt;/strong&gt; (see the next section on high-level design). The foundations of its design assume that producers are independent; if this is not the case, and your producers co-ordinate amongst themselves in some fashion, be aware that the elements won&#39;t necessarily come out of the queue in the same order they were put in &lt;em&gt;relative to the ordering formed by that co-ordination&lt;/em&gt; (but they will still come out in the order they were put in by any &lt;em&gt;individual&lt;/em&gt; producer). If this affects your use case, you may be better off with another implementation; either way, it&#39;s an important limitation to be aware of.&lt;/p&gt; &#xA;&lt;p&gt;My queue is also &lt;strong&gt;not NUMA aware&lt;/strong&gt;, and does a lot of memory re-use internally, meaning it probably doesn&#39;t scale particularly well on NUMA architectures; however, I don&#39;t know of any other lock-free queue that &lt;em&gt;is&lt;/em&gt; NUMA aware (except for &lt;a href=&#34;http://webee.technion.ac.il/~idish/ftp/spaa049-gidron.pdf&#34;&gt;SALSA&lt;/a&gt;, which is very cool, but has no publicly available implementation that I know of).&lt;/p&gt; &#xA;&lt;p&gt;Finally, the queue is &lt;strong&gt;not sequentially consistent&lt;/strong&gt;; there &lt;em&gt;is&lt;/em&gt; a happens-before relationship between when an element is put in the queue and when it comes out, but other things (such as pumping the queue until it&#39;s empty) require more thought to get right in all eventualities, because explicit memory ordering may have to be done to get the desired effect. In other words, it can sometimes be difficult to use the queue correctly. This is why it&#39;s a good idea to follow the &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/samples.md&#34;&gt;samples&lt;/a&gt; where possible. On the other hand, the upside of this lack of sequential consistency is better performance.&lt;/p&gt; &#xA;&lt;h2&gt;High-level design&lt;/h2&gt; &#xA;&lt;p&gt;Elements are stored internally using contiguous blocks instead of linked lists for better performance. The queue is made up of a collection of sub-queues, one for each producer. When a consumer wants to dequeue an element, it checks all the sub-queues until it finds one that&#39;s not empty. All of this is largely transparent to the user of the queue, however -- it mostly just works&lt;sup&gt;TM&lt;/sup&gt;.&lt;/p&gt; &#xA;&lt;p&gt;One particular consequence of this design, however, (which seems to be non-intuitive) is that if two producers enqueue at the same time, there is no defined ordering between the elements when they&#39;re later dequeued. Normally this is fine, because even with a fully linearizable queue there&#39;d be a race between the producer threads and so you couldn&#39;t rely on the ordering anyway. However, if for some reason you do extra explicit synchronization between the two producer threads yourself, thus defining a total order between enqueue operations, you might expect that the elements would come out in the same total order, which is a guarantee my queue does not offer. At that point, though, there semantically aren&#39;t really two separate producers, but rather one that happens to be spread across multiple threads. In this case, you can still establish a total ordering with my queue by creating a single producer token, and using that from both threads to enqueue (taking care to synchronize access to the token, of course, but there was already extra synchronization involved anyway).&lt;/p&gt; &#xA;&lt;p&gt;I&#39;ve written a more detailed &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++&#34;&gt;overview of the internal design&lt;/a&gt;, as well as &lt;a href=&#34;http://moodycamel.com/blog/2014/detailed-design-of-a-lock-free-queue&#34;&gt;the full nitty-gritty details of the design&lt;/a&gt;, on my blog. Finally, the &lt;a href=&#34;https://github.com/cameron314/concurrentqueue&#34;&gt;source&lt;/a&gt; itself is available for perusal for those interested in its implementation.&lt;/p&gt; &#xA;&lt;h2&gt;Basic use&lt;/h2&gt; &#xA;&lt;p&gt;The entire queue&#39;s implementation is contained in &lt;strong&gt;one header&lt;/strong&gt;, &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/concurrentqueue.h&#34;&gt;&lt;code&gt;concurrentqueue.h&lt;/code&gt;&lt;/a&gt;. Simply download and include that to use the queue. The blocking version is in a separate header, &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/blockingconcurrentqueue.h&#34;&gt;&lt;code&gt;blockingconcurrentqueue.h&lt;/code&gt;&lt;/a&gt;, that depends on &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/concurrentqueue.h&#34;&gt;&lt;code&gt;concurrentqueue.h&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/lightweightsemaphore.h&#34;&gt;&lt;code&gt;lightweightsemaphore.h&lt;/code&gt;&lt;/a&gt;. The implementation makes use of certain key C++11 features, so it requires a relatively recent compiler (e.g. VS2012+ or g++ 4.8; note that g++ 4.6 has a known bug with &lt;code&gt;std::atomic&lt;/code&gt; and is thus not supported). The algorithm implementations themselves are platform independent.&lt;/p&gt; &#xA;&lt;p&gt;Use it like you would any other templated queue, with the exception that you can use it from many threads at once :-)&lt;/p&gt; &#xA;&lt;p&gt;Simple example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;#include &#34;concurrentqueue.h&#34;&#xA;&#xA;moodycamel::ConcurrentQueue&amp;lt;int&amp;gt; q;&#xA;q.enqueue(25);&#xA;&#xA;int item;&#xA;bool found = q.try_dequeue(item);&#xA;assert(found &amp;amp;&amp;amp; item == 25);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Description of basic methods:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;ConcurrentQueue(size_t initialSizeEstimate)&lt;/code&gt; Constructor which optionally accepts an estimate of the number of elements the queue will hold&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;enqueue(T&amp;amp;&amp;amp; item)&lt;/code&gt; Enqueues one item, allocating extra space if necessary&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;try_enqueue(T&amp;amp;&amp;amp; item)&lt;/code&gt; Enqueues one item, but only if enough memory is already allocated&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;try_dequeue(T&amp;amp; item)&lt;/code&gt; Dequeues one item, returning true if an item was found or false if the queue appeared empty&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note that it is up to the user to ensure that the queue object is completely constructed before being used by any other threads (this includes making the memory effects of construction visible, possibly via a memory barrier). Similarly, it&#39;s important that all threads have finished using the queue (and the memory effects have fully propagated) before it is destructed.&lt;/p&gt; &#xA;&lt;p&gt;There&#39;s usually two versions of each method, one &#34;explicit&#34; version that takes a user-allocated per-producer or per-consumer token, and one &#34;implicit&#34; version that works without tokens. Using the explicit methods is almost always faster (though not necessarily by a huge factor). Apart from performance, the primary distinction between them is their sub-queue allocation behaviour for enqueue operations: Using the implicit enqueue methods causes an automatically-allocated thread-local producer sub-queue to be allocated. Explicit producers, on the other hand, are tied directly to their tokens&#39; lifetimes (but are recycled internally).&lt;/p&gt; &#xA;&lt;p&gt;In order to avoid the number of sub-queues growing without bound, implicit producers are marked for reuse once their thread exits. However, this is not supported on all platforms. If using the queue from short-lived threads, it is recommended to use explicit producer tokens instead.&lt;/p&gt; &#xA;&lt;p&gt;Full API (pseudocode):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Allocates more memory if necessary&#xA;enqueue(item) : bool&#xA;enqueue(prod_token, item) : bool&#xA;enqueue_bulk(item_first, count) : bool&#xA;enqueue_bulk(prod_token, item_first, count) : bool&#xA;&#xA;# Fails if not enough memory to enqueue&#xA;try_enqueue(item) : bool&#xA;try_enqueue(prod_token, item) : bool&#xA;try_enqueue_bulk(item_first, count) : bool&#xA;try_enqueue_bulk(prod_token, item_first, count) : bool&#xA;&#xA;# Attempts to dequeue from the queue (never allocates)&#xA;try_dequeue(item&amp;amp;) : bool&#xA;try_dequeue(cons_token, item&amp;amp;) : bool&#xA;try_dequeue_bulk(item_first, max) : size_t&#xA;try_dequeue_bulk(cons_token, item_first, max) : size_t&#xA;&#xA;# If you happen to know which producer you want to dequeue from&#xA;try_dequeue_from_producer(prod_token, item&amp;amp;) : bool&#xA;try_dequeue_bulk_from_producer(prod_token, item_first, max) : size_t&#xA;&#xA;# A not-necessarily-accurate count of the total number of elements&#xA;size_approx() : size_t&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Blocking version&lt;/h2&gt; &#xA;&lt;p&gt;As mentioned above, a full blocking wrapper of the queue is provided that adds &lt;code&gt;wait_dequeue&lt;/code&gt; and &lt;code&gt;wait_dequeue_bulk&lt;/code&gt; methods in addition to the regular interface. This wrapper is extremely low-overhead, but slightly less fast than the non-blocking queue (due to the necessary bookkeeping involving a lightweight semaphore).&lt;/p&gt; &#xA;&lt;p&gt;There are also timed versions that allow a timeout to be specified (either in microseconds or with a &lt;code&gt;std::chrono&lt;/code&gt; object).&lt;/p&gt; &#xA;&lt;p&gt;The only major caveat with the blocking version is that you must be careful not to destroy the queue while somebody is waiting on it. This generally means you need to know for certain that another element is going to come along before you call one of the blocking methods. (To be fair, the non-blocking version cannot be destroyed while in use either, but it can be easier to coordinate the cleanup.)&lt;/p&gt; &#xA;&lt;p&gt;Blocking example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;#include &#34;blockingconcurrentqueue.h&#34;&#xA;&#xA;moodycamel::BlockingConcurrentQueue&amp;lt;int&amp;gt; q;&#xA;std::thread producer([&amp;amp;]() {&#xA;    for (int i = 0; i != 100; ++i) {&#xA;        std::this_thread::sleep_for(std::chrono::milliseconds(i % 10));&#xA;        q.enqueue(i);&#xA;    }&#xA;});&#xA;std::thread consumer([&amp;amp;]() {&#xA;    for (int i = 0; i != 100; ++i) {&#xA;        int item;&#xA;        q.wait_dequeue(item);&#xA;        assert(item == i);&#xA;        &#xA;        if (q.wait_dequeue_timed(item, std::chrono::milliseconds(5))) {&#xA;            ++i;&#xA;            assert(item == i);&#xA;        }&#xA;    }&#xA;});&#xA;producer.join();&#xA;consumer.join();&#xA;&#xA;assert(q.size_approx() == 0);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Advanced features&lt;/h2&gt; &#xA;&lt;h4&gt;Tokens&lt;/h4&gt; &#xA;&lt;p&gt;The queue can take advantage of extra per-producer and per-consumer storage if it&#39;s available to speed up its operations. This takes the form of &#34;tokens&#34;: You can create a consumer token and/or a producer token for each thread or task (tokens themselves are not thread-safe), and use the methods that accept a token as their first parameter:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;moodycamel::ConcurrentQueue&amp;lt;int&amp;gt; q;&#xA;&#xA;moodycamel::ProducerToken ptok(q);&#xA;q.enqueue(ptok, 17);&#xA;&#xA;moodycamel::ConsumerToken ctok(q);&#xA;int item;&#xA;q.try_dequeue(ctok, item);&#xA;assert(item == 17);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you happen to know which producer you want to consume from (e.g. in a single-producer, multi-consumer scenario), you can use the &lt;code&gt;try_dequeue_from_producer&lt;/code&gt; methods, which accept a producer token instead of a consumer token, and cut some overhead.&lt;/p&gt; &#xA;&lt;p&gt;Note that tokens work with the blocking version of the queue too.&lt;/p&gt; &#xA;&lt;p&gt;When producing or consuming many elements, the most efficient way is to:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Use the bulk methods of the queue with tokens&lt;/li&gt; &#xA; &lt;li&gt;Failing that, use the bulk methods without tokens&lt;/li&gt; &#xA; &lt;li&gt;Failing that, use the single-item methods with tokens&lt;/li&gt; &#xA; &lt;li&gt;Failing that, use the single-item methods without tokens&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Having said that, don&#39;t create tokens willy-nilly -- ideally there would be one token (of each kind) per thread. The queue will work with what it is given, but it performs best when used with tokens.&lt;/p&gt; &#xA;&lt;p&gt;Note that tokens aren&#39;t actually tied to any given thread; it&#39;s not technically required that they be local to the thread, only that they be used by a single producer/consumer at a time.&lt;/p&gt; &#xA;&lt;h4&gt;Bulk operations&lt;/h4&gt; &#xA;&lt;p&gt;Thanks to the &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++&#34;&gt;novel design&lt;/a&gt; of the queue, it&#39;s just as easy to enqueue/dequeue multiple items as it is to do one at a time. This means that overhead can be cut drastically for bulk operations. Example syntax:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;moodycamel::ConcurrentQueue&amp;lt;int&amp;gt; q;&#xA;&#xA;int items[] = { 1, 2, 3, 4, 5 };&#xA;q.enqueue_bulk(items, 5);&#xA;&#xA;int results[5];     // Could also be any iterator&#xA;size_t count = q.try_dequeue_bulk(results, 5);&#xA;for (size_t i = 0; i != count; ++i) {&#xA;    assert(results[i] == items[i]);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Preallocation (correctly using &lt;code&gt;try_enqueue&lt;/code&gt;)&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;try_enqueue&lt;/code&gt;, unlike just plain &lt;code&gt;enqueue&lt;/code&gt;, will never allocate memory. If there&#39;s not enough room in the queue, it simply returns false. The key to using this method properly, then, is to ensure enough space is pre-allocated for your desired maximum element count.&lt;/p&gt; &#xA;&lt;p&gt;The constructor accepts a count of the number of elements that it should reserve space for. Because the queue works with blocks of elements, however, and not individual elements themselves, the value to pass in order to obtain an effective number of pre-allocated element slots is non-obvious.&lt;/p&gt; &#xA;&lt;p&gt;First, be aware that the count passed is rounded up to the next multiple of the block size. Note that the default block size is 32 (this can be changed via the traits). Second, once a slot in a block has been enqueued to, that slot cannot be re-used until the rest of the block has been completely filled up and then completely emptied. This affects the number of blocks you need in order to account for the overhead of partially-filled blocks. Third, each producer (whether implicit or explicit) claims and recycles blocks in a different manner, which again affects the number of blocks you need to account for a desired number of usable slots.&lt;/p&gt; &#xA;&lt;p&gt;Suppose you want the queue to be able to hold at least &lt;code&gt;N&lt;/code&gt; elements at any given time. Without delving too deep into the rather arcane implementation details, here are some simple formulas for the number of elements to request for pre-allocation in such a case. Note the division is intended to be arithmetic division and not integer division (in order for &lt;code&gt;ceil()&lt;/code&gt; to work).&lt;/p&gt; &#xA;&lt;p&gt;For explicit producers (using tokens to enqueue):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;(ceil(N / BLOCK_SIZE) + 1) * MAX_NUM_PRODUCERS * BLOCK_SIZE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For implicit producers (no tokens):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;(ceil(N / BLOCK_SIZE) - 1 + 2 * MAX_NUM_PRODUCERS) * BLOCK_SIZE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When using mixed producer types:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;((ceil(N / BLOCK_SIZE) - 1) * (MAX_EXPLICIT_PRODUCERS + 1) + 2 * (MAX_IMPLICIT_PRODUCERS + MAX_EXPLICIT_PRODUCERS)) * BLOCK_SIZE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If these formulas seem rather inconvenient, you can use the constructor overload that accepts the minimum number of elements (&lt;code&gt;N&lt;/code&gt;) and the maximum number of explicit and implicit producers directly, and let it do the computation for you.&lt;/p&gt; &#xA;&lt;p&gt;In addition to blocks, there are other internal data structures that require allocating memory if they need to resize (grow). If using &lt;code&gt;try_enqueue&lt;/code&gt; exclusively, the initial sizes may be exceeded, causing subsequent &lt;code&gt;try_enqueue&lt;/code&gt; operations to fail. Specifically, the &lt;code&gt;INITIAL_IMPLICIT_PRODUCER_HASH_SIZE&lt;/code&gt; trait limits the number of implicit producers that can be active at once before the internal hash needs resizing. Along the same lines, the &lt;code&gt;IMPLICIT_INITIAL_INDEX_SIZE&lt;/code&gt; trait limits the number of unconsumed elements that an implicit producer can insert before its internal hash needs resizing. Similarly, the &lt;code&gt;EXPLICIT_INITIAL_INDEX_SIZE&lt;/code&gt; trait limits the number of unconsumed elements that an explicit producer can insert before its internal hash needs resizing. In order to avoid hitting these limits when using &lt;code&gt;try_enqueue&lt;/code&gt;, it is crucial to adjust the initial sizes in the traits appropriately, in addition to sizing the number of blocks properly as outlined above.&lt;/p&gt; &#xA;&lt;p&gt;Finally, it&#39;s important to note that because the queue is only eventually consistent and takes advantage of weak memory ordering for speed, there&#39;s always a possibility that under contention &lt;code&gt;try_enqueue&lt;/code&gt; will fail even if the queue is correctly pre-sized for the desired number of elements. (e.g. A given thread may think that the queue&#39;s full even when that&#39;s no longer the case.) So no matter what, you still need to handle the failure case (perhaps looping until it succeeds), unless you don&#39;t mind dropping elements.&lt;/p&gt; &#xA;&lt;h4&gt;Exception safety&lt;/h4&gt; &#xA;&lt;p&gt;The queue is exception safe, and will never become corrupted if used with a type that may throw exceptions. The queue itself never throws any exceptions (operations fail gracefully (return false) if memory allocation fails instead of throwing &lt;code&gt;std::bad_alloc&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;It is important to note that the guarantees of exception safety only hold if the element type never throws from its destructor, and that any iterators passed into the queue (for bulk operations) never throw either. Note that in particular this means &lt;code&gt;std::back_inserter&lt;/code&gt; iterators must be used with care, since the vector being inserted into may need to allocate and throw a &lt;code&gt;std::bad_alloc&lt;/code&gt; exception from inside the iterator; so be sure to reserve enough capacity in the target container first if you do this.&lt;/p&gt; &#xA;&lt;p&gt;The guarantees are presently as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Enqueue operations are rolled back completely if an exception is thrown from an element&#39;s constructor. For bulk enqueue operations, this means that elements are copied instead of moved (in order to avoid having only some objects moved in the event of an exception). Non-bulk enqueues always use the move constructor if one is available.&lt;/li&gt; &#xA; &lt;li&gt;If the assignment operator throws during a dequeue operation (both single and bulk), the element(s) are considered dequeued regardless. In such a case, the dequeued elements are all properly destructed before the exception is propagated, but there&#39;s no way to get the elements themselves back.&lt;/li&gt; &#xA; &lt;li&gt;Any exception that is thrown is propagated up the call stack, at which point the queue is in a consistent state.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note: If any of your type&#39;s copy constructors/move constructors/assignment operators don&#39;t throw, be sure to annotate them with &lt;code&gt;noexcept&lt;/code&gt;; this will avoid the exception-checking overhead in the queue where possible (even with zero-cost exceptions, there&#39;s still a code size impact that has to be taken into account).&lt;/p&gt; &#xA;&lt;h4&gt;Traits&lt;/h4&gt; &#xA;&lt;p&gt;The queue also supports a traits template argument which defines various types, constants, and the memory allocation and deallocation functions that are to be used by the queue. The typical pattern to providing your own traits is to create a class that inherits from the default traits and override only the values you wish to change. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;struct MyTraits : public moodycamel::ConcurrentQueueDefaultTraits&#xA;{&#xA;&#x9;static const size_t BLOCK_SIZE = 256;&#x9;&#x9;// Use bigger blocks&#xA;};&#xA;&#xA;moodycamel::ConcurrentQueue&amp;lt;int, MyTraits&amp;gt; q;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;How to dequeue types without calling the constructor&lt;/h4&gt; &#xA;&lt;p&gt;The normal way to dequeue an item is to pass in an existing object by reference, which is then assigned to internally by the queue (using the move-assignment operator if possible). This can pose a problem for types that are expensive to construct or don&#39;t have a default constructor; fortunately, there is a simple workaround: Create a wrapper class that copies the memory contents of the object when it is assigned by the queue (a poor man&#39;s move, essentially). Note that this only works if the object contains no internal pointers. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;struct MyObjectMover {&#xA;    inline void operator=(MyObject&amp;amp;&amp;amp; obj) {&#xA;        std::memcpy(data, &amp;amp;obj, sizeof(MyObject));&#xA;        &#xA;        // TODO: Cleanup obj so that when it&#39;s destructed by the queue&#xA;        // it doesn&#39;t corrupt the data of the object we just moved it into&#xA;    }&#xA;&#xA;    inline MyObject&amp;amp; obj() { return *reinterpret_cast&amp;lt;MyObject*&amp;gt;(data); }&#xA;&#xA;private:&#xA;    align(alignof(MyObject)) char data[sizeof(MyObject)];&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A less dodgy alternative, if moves are cheap but default construction is not, is to use a wrapper that defers construction until the object is assigned, enabling use of the move constructor:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-C++&#34;&gt;struct MyObjectMover {&#xA;    inline void operator=(MyObject&amp;amp;&amp;amp; x) {&#xA;        new (data) MyObject(std::move(x));&#xA;        created = true;&#xA;    }&#xA;&#xA;    inline MyObject&amp;amp; obj() {&#xA;        assert(created);&#xA;        return *reinterpret_cast&amp;lt;MyObject*&amp;gt;(data);&#xA;    }&#xA;&#xA;    ~MyObjectMover() {&#xA;        if (created)&#xA;            obj().~MyObject();&#xA;    }&#xA;&#xA;private:&#xA;    align(alignof(MyObject)) char data[sizeof(MyObject)];&#xA;    bool created = false;&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Samples&lt;/h2&gt; &#xA;&lt;p&gt;There are some more detailed samples &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/samples.md&#34;&gt;here&lt;/a&gt;. The source of the &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/tree/master/tests/unittests&#34;&gt;unit tests&lt;/a&gt; and &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/tree/master/benchmarks&#34;&gt;benchmarks&lt;/a&gt; are available for reference as well.&lt;/p&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;See my blog post for some &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++#benchmarks&#34;&gt;benchmark results&lt;/a&gt; (including versus &lt;code&gt;boost::lockfree::queue&lt;/code&gt; and &lt;code&gt;tbb::concurrent_queue&lt;/code&gt;), or run the benchmarks yourself (requires MinGW and certain GnuWin32 utilities to build on Windows, or a recent g++ on Linux):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;cd build&#xA;make benchmarks&#xA;bin/benchmarks&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The short version of the benchmarks is that it&#39;s so fast (especially the bulk methods), that if you&#39;re actually using the queue to &lt;em&gt;do&lt;/em&gt; anything, the queue won&#39;t be your bottleneck.&lt;/p&gt; &#xA;&lt;h2&gt;Tests (and bugs)&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;ve written quite a few unit tests as well as a randomized long-running fuzz tester. I also ran the core queue algorithm through the &lt;a href=&#34;http://demsky.eecs.uci.edu/c11modelchecker.html&#34;&gt;CDSChecker&lt;/a&gt; C++11 memory model model checker. Some of the inner algorithms were tested separately using the &lt;a href=&#34;http://www.1024cores.net/home/relacy-race-detector&#34;&gt;Relacy&lt;/a&gt; model checker, and full integration tests were also performed with Relacy. I&#39;ve tested on Linux (Fedora 19) and Windows (7), but only on x86 processors so far (Intel and AMD). The code was written to be platform-independent, however, and should work across all processors and OSes.&lt;/p&gt; &#xA;&lt;p&gt;Due to the complexity of the implementation and the difficult-to-test nature of lock-free code in general, there may still be bugs. If anyone is seeing buggy behaviour, I&#39;d like to hear about it! (Especially if a unit test for it can be cooked up.) Just open an issue on GitHub.&lt;/p&gt; &#xA;&lt;h2&gt;Using vcpkg&lt;/h2&gt; &#xA;&lt;p&gt;You can download and install &lt;code&gt;moodycamel::ConcurrentQueue&lt;/code&gt; using the &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;vcpkg&lt;/a&gt; dependency manager:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;git clone https://github.com/Microsoft/vcpkg.git&#xA;cd vcpkg&#xA;./bootstrap-vcpkg.sh&#xA;./vcpkg integrate install&#xA;vcpkg install concurrentqueue&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;moodycamel::ConcurrentQueue&lt;/code&gt; port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;create an issue or pull request&lt;/a&gt; on the vcpkg repository.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;m releasing the source of this repository (with the exception of third-party code, i.e. the Boost queue (used in the benchmarks for comparison), Intel&#39;s TBB library (ditto), CDSChecker, Relacy, and Jeff Preshing&#39;s cross-platform semaphore, which all have their own licenses) under a simplified BSD license. I&#39;m also dual-licensing under the Boost Software License. See the &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/LICENSE.md&#34;&gt;LICENSE.md&lt;/a&gt; file for more details.&lt;/p&gt; &#xA;&lt;p&gt;Note that lock-free programming is a patent minefield, and this code may very well violate a pending patent (I haven&#39;t looked), though it does not to my present knowledge. I did design and implement this queue from scratch.&lt;/p&gt; &#xA;&lt;h2&gt;Diving into the code&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;re interested in the source code itself, it helps to have a rough idea of how it&#39;s laid out. This section attempts to describe that.&lt;/p&gt; &#xA;&lt;p&gt;The queue is formed of several basic parts (listed here in roughly the order they appear in the source). There&#39;s the helper functions (e.g. for rounding to a power of 2). There&#39;s the default traits of the queue, which contain the constants and malloc/free functions used by the queue. There&#39;s the producer and consumer tokens. Then there&#39;s the queue&#39;s public API itself, starting with the constructor, destructor, and swap/assignment methods. There&#39;s the public enqueue methods, which are all wrappers around a small set of private enqueue methods found later on. There&#39;s the dequeue methods, which are defined inline and are relatively straightforward.&lt;/p&gt; &#xA;&lt;p&gt;Then there&#39;s all the main internal data structures. First, there&#39;s a lock-free free list, used for recycling spent blocks (elements are enqueued to blocks internally). Then there&#39;s the block structure itself, which has two different ways of tracking whether it&#39;s fully emptied or not (remember, given two parallel consumers, there&#39;s no way to know which one will finish first) depending on where it&#39;s used. Then there&#39;s a small base class for the two types of internal SPMC producer queues (one for explicit producers that holds onto memory but attempts to be faster, and one for implicit ones which attempt to recycle more memory back into the parent but is a little slower). The explicit producer is defined first, then the implicit one. They both contain the same general four methods: One to enqueue, one to dequeue, one to enqueue in bulk, and one to dequeue in bulk. (Obviously they have constructors and destructors too, and helper methods.) The main difference between them is how the block handling is done (they both use the same blocks, but in different ways, and map indices to them in different ways).&lt;/p&gt; &#xA;&lt;p&gt;Finally, there&#39;s the miscellaneous internal methods: There&#39;s the ones that handle the initial block pool (populated when the queue is constructed), and an abstract block pool that comprises the initial pool and any blocks on the free list. There&#39;s ones that handle the producer list (a lock-free add-only linked list of all the producers in the system). There&#39;s ones that handle the implicit producer lookup table (which is really a sort of specialized TLS lookup). And then there&#39;s some helper methods for allocating and freeing objects, and the data members of the queue itself, followed lastly by the free-standing swap functions.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>YosysHQ/yosys</title>
    <updated>2024-06-02T01:45:02Z</updated>
    <id>tag:github.com,2024-06-02:/YosysHQ/yosys</id>
    <link href="https://github.com/YosysHQ/yosys" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Yosys Open SYnthesis Suite&lt;/p&gt;&lt;hr&gt;&lt;pre&gt;&lt;code&gt;yosys -- Yosys Open SYnthesis Suite&#xA;&#xA;Copyright (C) 2012 - 2024  Claire Xenia Wolf &amp;lt;claire@yosyshq.com&amp;gt;&#xA;&#xA;Permission to use, copy, modify, and/or distribute this software for any&#xA;purpose with or without fee is hereby granted, provided that the above&#xA;copyright notice and this permission notice appear in all copies.&#xA;&#xA;THE SOFTWARE IS PROVIDED &#34;AS IS&#34; AND THE AUTHOR DISCLAIMS ALL WARRANTIES&#xA;WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF&#xA;MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR&#xA;ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES&#xA;WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN&#xA;ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF&#xA;OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;yosys – Yosys Open SYnthesis Suite&lt;/h1&gt; &#xA;&lt;p&gt;This is a framework for RTL synthesis tools. It currently has extensive Verilog-2005 support and provides a basic set of synthesis algorithms for various application domains.&lt;/p&gt; &#xA;&lt;p&gt;Yosys can be adapted to perform any synthesis job by combining the existing passes (algorithms) using synthesis scripts and adding additional passes as needed by extending the yosys C++ code base.&lt;/p&gt; &#xA;&lt;p&gt;Yosys is free software licensed under the ISC license (a GPL compatible license that is similar in terms to the MIT license or the 2-clause BSD license).&lt;/p&gt; &#xA;&lt;h1&gt;Web Site and Other Resources&lt;/h1&gt; &#xA;&lt;p&gt;More information and documentation can be found on the Yosys web site:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yosyshq.net/yosys/&#34;&gt;https://yosyshq.net/yosys/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The &#34;Documentation&#34; page on the web site contains links to more resources, including a manual that even describes some of the Yosys internals:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yosyshq.net/yosys/documentation.html&#34;&gt;https://yosyshq.net/yosys/documentation.html&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The directory &lt;code&gt;guidelines&lt;/code&gt; contains additional information for people interested in using the Yosys C++ APIs.&lt;/p&gt; &#xA;&lt;p&gt;Users interested in formal verification might want to use the formal verification front-end for Yosys, SymbiYosys:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://symbiyosys.readthedocs.io/en/latest/&#34;&gt;https://symbiyosys.readthedocs.io/en/latest/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/YosysHQ/SymbiYosys&#34;&gt;https://github.com/YosysHQ/SymbiYosys&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;Yosys is part of the &lt;a href=&#34;https://www.yosyshq.com/tabby-cad-datasheet&#34;&gt;Tabby CAD Suite&lt;/a&gt; and the &lt;a href=&#34;https://github.com/YosysHQ/oss-cad-suite-build&#34;&gt;OSS CAD Suite&lt;/a&gt;! The easiest way to use yosys is to install the binary software suite, which contains all required dependencies and related tools.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.yosyshq.com/contact&#34;&gt;Contact YosysHQ&lt;/a&gt; for a &lt;a href=&#34;https://www.yosyshq.com/tabby-cad-datasheet&#34;&gt;Tabby CAD Suite&lt;/a&gt; Evaluation License and download link&lt;/li&gt; &#xA; &lt;li&gt;OR go to &lt;a href=&#34;https://github.com/YosysHQ/oss-cad-suite-build/releases&#34;&gt;https://github.com/YosysHQ/oss-cad-suite-build/releases&lt;/a&gt; to download the free OSS CAD Suite&lt;/li&gt; &#xA; &lt;li&gt;Follow the &lt;a href=&#34;https://github.com/YosysHQ/oss-cad-suite-build#installation&#34;&gt;Install Instructions on GitHub&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Make sure to get a Tabby CAD Suite Evaluation License if you need features such as industry-grade SystemVerilog and VHDL parsers!&lt;/p&gt; &#xA;&lt;p&gt;For more information about the difference between Tabby CAD Suite and the OSS CAD Suite, please visit &lt;a href=&#34;https://www.yosyshq.com/tabby-cad-datasheet&#34;&gt;https://www.yosyshq.com/tabby-cad-datasheet&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Many Linux distributions also provide Yosys binaries, some more up to date than others. Check with your package manager!&lt;/p&gt; &#xA;&lt;h1&gt;Building from Source&lt;/h1&gt; &#xA;&lt;p&gt;You need a C++ compiler with C++11 support (up-to-date CLANG or GCC is recommended) and some standard tools such as GNU Flex, GNU Bison, and GNU Make. TCL, readline and libffi are optional (see &lt;code&gt;ENABLE_*&lt;/code&gt; settings in Makefile). Xdot (graphviz) is used by the &lt;code&gt;show&lt;/code&gt; command in yosys to display schematics.&lt;/p&gt; &#xA;&lt;p&gt;For example on Ubuntu Linux 16.04 LTS the following commands will install all prerequisites for building yosys:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install build-essential clang bison flex \&#xA;&#x9;libreadline-dev gawk tcl-dev libffi-dev git \&#xA;&#x9;graphviz xdot pkg-config python3 libboost-system-dev \&#xA;&#x9;libboost-python-dev libboost-filesystem-dev zlib1g-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Similarily, on Mac OS X Homebrew can be used to install dependencies (from within cloned yosys repository):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ brew tap Homebrew/bundle &amp;amp;&amp;amp; brew bundle&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or MacPorts:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo port install bison flex readline gawk libffi \&#xA;&#x9;git graphviz pkgconfig python36 boost zlib tcl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On FreeBSD use the following command to install all prerequisites:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# pkg install bison flex readline gawk libffi\&#xA;&#x9;git graphviz pkgconf python3 python36 tcl-wrapper boost-libs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On FreeBSD system use gmake instead of make. To run tests use: % MAKE=gmake CC=cc gmake test&lt;/p&gt; &#xA;&lt;p&gt;For Cygwin use the following command to install all prerequisites, or select these additional packages:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;setup-x86_64.exe -q --packages=bison,flex,gcc-core,gcc-g++,git,libffi-devel,libreadline-devel,make,pkg-config,python3,tcl-devel,boost-build,zlib-devel&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The environment variable &lt;code&gt;CXX&lt;/code&gt; can be used to control the C++ compiler used, or run one of the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make config-clang&#xA;$ make config-gcc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that these will result in &lt;code&gt;make&lt;/code&gt; ignoring the &lt;code&gt;CXX&lt;/code&gt; environment variable, unless &lt;code&gt;CXX&lt;/code&gt; is assigned in the call to make, e.g.&lt;/p&gt; &#xA;&lt;p&gt;$ make CXX=$CXX&lt;/p&gt; &#xA;&lt;p&gt;For other compilers and build configurations it might be necessary to make some changes to the config section of the Makefile.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ vi Makefile            # ..or..&#xA;$ vi Makefile.conf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To build Yosys simply type &#39;make&#39; in this directory.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make&#xA;$ sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that this also downloads, builds and installs ABC (using yosys-abc as executable name).&lt;/p&gt; &#xA;&lt;p&gt;Tests are located in the tests subdirectory and can be executed using the test target. Note that you need gawk as well as a recent version of iverilog (i.e. build from git). Then, execute tests via:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use a separate (out-of-tree) build directory, provide a path to the Makefile.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ mkdir build; cd build&#xA;$ make -f ../Makefile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Out-of-tree builds require a clean source tree.&lt;/p&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;p&gt;Yosys can be used with the interactive command shell, with synthesis scripts or with command line arguments. Let&#39;s perform a simple synthesis job using the interactive command shell:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./yosys&#xA;yosys&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;the command &lt;code&gt;help&lt;/code&gt; can be used to print a list of all available commands and &lt;code&gt;help &amp;lt;command&amp;gt;&lt;/code&gt; to print details on the specified command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yosys&amp;gt; help help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;reading and elaborating the design using the Verilog frontend:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yosys&amp;gt; read -sv tests/simple/fiedler-cooley.v&#xA;yosys&amp;gt; hierarchy -top up3down5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;writing the design to the console in the RTLIL format used by Yosys internally:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yosys&amp;gt; write_rtlil&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;convert processes (&lt;code&gt;always&lt;/code&gt; blocks) to netlist elements and perform some simple optimizations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yosys&amp;gt; proc; opt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;display design netlist using &lt;code&gt;xdot&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yosys&amp;gt; show&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;the same thing using &lt;code&gt;gv&lt;/code&gt; as postscript viewer:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yosys&amp;gt; show -format ps -viewer gv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;translating netlist to gate logic and perform some simple optimizations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yosys&amp;gt; techmap; opt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;write design netlist to a new Verilog file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yosys&amp;gt; write_verilog synth.v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or using a simple synthesis script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cat synth.ys&#xA;read -sv tests/simple/fiedler-cooley.v&#xA;hierarchy -top up3down5&#xA;proc; opt; techmap; opt&#xA;write_verilog synth.v&#xA;&#xA;$ ./yosys synth.ys&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If ABC is enabled in the Yosys build configuration and a cell library is given in the liberty file &lt;code&gt;mycells.lib&lt;/code&gt;, the following synthesis script will synthesize for the given cell library:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# read design&#xA;read -sv tests/simple/fiedler-cooley.v&#xA;hierarchy -top up3down5&#xA;&#xA;# the high-level stuff&#xA;proc; fsm; opt; memory; opt&#xA;&#xA;# mapping to internal cell library&#xA;techmap; opt&#xA;&#xA;# mapping flip-flops to mycells.lib&#xA;dfflibmap -liberty mycells.lib&#xA;&#xA;# mapping logic to mycells.lib&#xA;abc -liberty mycells.lib&#xA;&#xA;# cleanup&#xA;clean&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you do not have a liberty file but want to test this synthesis script, you can use the file &lt;code&gt;examples/cmos/cmos_cells.lib&lt;/code&gt; from the yosys sources as simple example.&lt;/p&gt; &#xA;&lt;p&gt;Liberty file downloads for and information about free and open ASIC standard cell libraries can be found here:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.vlsitechnology.org/html/libraries.html&#34;&gt;http://www.vlsitechnology.org/html/libraries.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.vlsitechnology.org/synopsys/vsclib013.lib&#34;&gt;http://www.vlsitechnology.org/synopsys/vsclib013.lib&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The command &lt;code&gt;synth&lt;/code&gt; provides a good default synthesis script (see &lt;code&gt;help synth&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;read -sv tests/simple/fiedler-cooley.v&#xA;synth -top up3down5&#xA;&#xA;# mapping to target cells&#xA;dfflibmap -liberty mycells.lib&#xA;abc -liberty mycells.lib&#xA;clean&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The command &lt;code&gt;prep&lt;/code&gt; provides a good default word-level synthesis script, as used in SMT-based formal verification.&lt;/p&gt; &#xA;&lt;h1&gt;Unsupported Verilog-2005 Features&lt;/h1&gt; &#xA;&lt;p&gt;The following Verilog-2005 features are not supported by Yosys and there are currently no plans to add support for them:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Non-synthesizable language features as defined in IEC 62142(E):2005 / IEEE Std. 1364.1(E):2002&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;tri&lt;/code&gt;, &lt;code&gt;triand&lt;/code&gt; and &lt;code&gt;trior&lt;/code&gt; net types&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;config&lt;/code&gt; and &lt;code&gt;disable&lt;/code&gt; keywords and library map files&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Verilog Attributes and non-standard features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;full_case&lt;/code&gt; attribute on case statements is supported (also the non-standard &lt;code&gt;// synopsys full_case&lt;/code&gt; directive)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;parallel_case&lt;/code&gt; attribute on case statements is supported (also the non-standard &lt;code&gt;// synopsys parallel_case&lt;/code&gt; directive)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;// synopsys translate_off&lt;/code&gt; and &lt;code&gt;// synopsys translate_on&lt;/code&gt; directives are also supported (but the use of &lt;code&gt;`ifdef .. `endif&lt;/code&gt; is strongly recommended instead).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;nomem2reg&lt;/code&gt; attribute on modules or arrays prohibits the automatic early conversion of arrays to separate registers. This is potentially dangerous. Usually the front-end has good reasons for converting an array to a list of registers. Prohibiting this step will likely result in incorrect synthesis results.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;mem2reg&lt;/code&gt; attribute on modules or arrays forces the early conversion of arrays to separate registers.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;nomeminit&lt;/code&gt; attribute on modules or arrays prohibits the creation of initialized memories. This effectively puts &lt;code&gt;mem2reg&lt;/code&gt; on all memories that are written to in an &lt;code&gt;initial&lt;/code&gt; block and are not ROMs.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;nolatches&lt;/code&gt; attribute on modules or always-blocks prohibits the generation of logic-loops for latches. Instead all not explicitly assigned values default to x-bits. This does not affect clocked storage elements such as flip-flops.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;nosync&lt;/code&gt; attribute on registers prohibits the generation of a storage element. The register itself will always have all bits set to &#39;x&#39; (undefined). The variable may only be used as blocking assigned temporary variable within an always block. This is mostly used internally by Yosys to synthesize Verilog functions and access arrays.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;nowrshmsk&lt;/code&gt; attribute on a register prohibits the generation of shift-and-mask type circuits for writing to bit slices of that register.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;onehot&lt;/code&gt; attribute on wires mark them as one-hot state register. This is used for example for memory port sharing and set by the fsm_map pass.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;blackbox&lt;/code&gt; attribute on modules is used to mark empty stub modules that have the same ports as the real thing but do not contain information on the internal configuration. This modules are only used by the synthesis passes to identify input and output ports of cells. The Verilog backend also does not output blackbox modules on default. &lt;code&gt;read_verilog&lt;/code&gt;, unless called with &lt;code&gt;-noblackbox&lt;/code&gt; will automatically set the blackbox attribute on any empty module it reads.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;noblackbox&lt;/code&gt; attribute set on an empty module prevents &lt;code&gt;read_verilog&lt;/code&gt; from automatically setting the blackbox attribute on the module.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;whitebox&lt;/code&gt; attribute on modules triggers the same behavior as &lt;code&gt;blackbox&lt;/code&gt;, but is for whitebox modules, i.e. library modules that contain a behavioral model of the cell type.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;lib_whitebox&lt;/code&gt; attribute overwrites &lt;code&gt;whitebox&lt;/code&gt; when &lt;code&gt;read_verilog&lt;/code&gt; is run in &lt;code&gt;-lib&lt;/code&gt; mode. Otherwise it&#39;s automatically removed.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;dynports&lt;/code&gt; attribute is used by the Verilog front-end to mark modules that have ports with a width that depends on a parameter.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;hdlname&lt;/code&gt; attribute is used by some passes to document the original (HDL) name of a module when renaming a module. It should contain a single name, or, when describing a hierarchical name in a flattened design, multiple names separated by a single space character.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;keep&lt;/code&gt; attribute on cells and wires is used to mark objects that should never be removed by the optimizer. This is used for example for cells that have hidden connections that are not part of the netlist, such as IO pads. Setting the &lt;code&gt;keep&lt;/code&gt; attribute on a module has the same effect as setting it on all instances of the module.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;keep_hierarchy&lt;/code&gt; attribute on cells and modules keeps the &lt;code&gt;flatten&lt;/code&gt; command from flattening the indicated cells and modules.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;init&lt;/code&gt; attribute on wires is set by the frontend when a register is initialized &#34;FPGA-style&#34; with &lt;code&gt;reg foo = val&lt;/code&gt;. It can be used during synthesis to add the necessary reset logic.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;top&lt;/code&gt; attribute on a module marks this module as the top of the design hierarchy. The &lt;code&gt;hierarchy&lt;/code&gt; command sets this attribute when called with &lt;code&gt;-top&lt;/code&gt;. Other commands, such as &lt;code&gt;flatten&lt;/code&gt; and various backends use this attribute to determine the top module.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;src&lt;/code&gt; attribute is set on cells and wires created by to the string &lt;code&gt;&amp;lt;hdl-file-name&amp;gt;:&amp;lt;line-number&amp;gt;&lt;/code&gt; by the HDL front-end and is then carried through the synthesis. When entities are combined, a new |-separated string is created that contains all the string from the original entities.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;defaultvalue&lt;/code&gt; attribute is used to store default values for module inputs. The attribute is attached to the input wire by the HDL front-end when the input is declared with a default value.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;parameter&lt;/code&gt; and &lt;code&gt;localparam&lt;/code&gt; attributes are used to mark wires that represent module parameters or localparams (when the HDL front-end is run in &lt;code&gt;-pwires&lt;/code&gt; mode).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Wires marked with the &lt;code&gt;hierconn&lt;/code&gt; attribute are connected to wires with the same name (format &lt;code&gt;cell_name.identifier&lt;/code&gt;) when they are imported from sub-modules by &lt;code&gt;flatten&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;clkbuf_driver&lt;/code&gt; attribute can be set on an output port of a blackbox module to mark it as a clock buffer output, and thus prevent &lt;code&gt;clkbufmap&lt;/code&gt; from inserting another clock buffer on a net driven by such output.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;clkbuf_sink&lt;/code&gt; attribute can be set on an input port of a module to request clock buffer insertion by the &lt;code&gt;clkbufmap&lt;/code&gt; pass.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;clkbuf_inv&lt;/code&gt; attribute can be set on an output port of a module with the value set to the name of an input port of that module. When the &lt;code&gt;clkbufmap&lt;/code&gt; would otherwise insert a clock buffer on this output, it will instead try inserting the clock buffer on the input port (this is used to implement clock inverter cells that clock buffer insertion will &#34;see through&#34;).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;clkbuf_inhibit&lt;/code&gt; is the default attribute to set on a wire to prevent automatic clock buffer insertion by &lt;code&gt;clkbufmap&lt;/code&gt;. This behaviour can be overridden by providing a custom selection to &lt;code&gt;clkbufmap&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;invertible_pin&lt;/code&gt; attribute can be set on a port to mark it as invertible via a cell parameter. The name of the inversion parameter is specified as the value of this attribute. The value of the inversion parameter must be of the same width as the port, with 1 indicating an inverted bit and 0 indicating a non-inverted bit.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;iopad_external_pin&lt;/code&gt; attribute on a blackbox module&#39;s port marks it as the external-facing pin of an I/O pad, and prevents &lt;code&gt;iopadmap&lt;/code&gt; from inserting another pad cell on it.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The module attribute &lt;code&gt;abc9_lut&lt;/code&gt; is an integer attribute indicating to &lt;code&gt;abc9&lt;/code&gt; that this module describes a LUT with an area cost of this value, and propagation delays described using &lt;code&gt;specify&lt;/code&gt; statements.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The module attribute &lt;code&gt;abc9_box&lt;/code&gt; is a boolean specifying a black/white-box definition, with propagation delays described using &lt;code&gt;specify&lt;/code&gt; statements, for use by &lt;code&gt;abc9&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The port attribute &lt;code&gt;abc9_carry&lt;/code&gt; marks the carry-in (if an input port) and carry-out (if output port) ports of a box. This information is necessary for &lt;code&gt;abc9&lt;/code&gt; to preserve the integrity of carry-chains. Specifying this attribute onto a bus port will affect only its most significant bit.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The module attribute &lt;code&gt;abc9_flop&lt;/code&gt; is a boolean marking the module as a flip-flop. This allows &lt;code&gt;abc9&lt;/code&gt; to analyse its contents in order to perform sequential synthesis.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The frontend sets attributes &lt;code&gt;always_comb&lt;/code&gt;, &lt;code&gt;always_latch&lt;/code&gt; and &lt;code&gt;always_ff&lt;/code&gt; on processes derived from SystemVerilog style always blocks according to the type of the always. These are checked for correctness in &lt;code&gt;proc_dlatch&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The cell attribute &lt;code&gt;wildcard_port_conns&lt;/code&gt; represents wildcard port connections (SystemVerilog &lt;code&gt;.*&lt;/code&gt;). These are resolved to concrete connections to matching wires in &lt;code&gt;hierarchy&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In addition to the &lt;code&gt;(* ... *)&lt;/code&gt; attribute syntax, Yosys supports the non-standard &lt;code&gt;{* ... *}&lt;/code&gt; attribute syntax to set default attributes for everything that comes after the &lt;code&gt;{* ... *}&lt;/code&gt; statement. (Reset by adding an empty &lt;code&gt;{* *}&lt;/code&gt; statement.)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In module parameter and port declarations, and cell port and parameter lists, a trailing comma is ignored. This simplifies writing Verilog code generators a bit in some cases.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Modules can be declared with &lt;code&gt;module mod_name(...);&lt;/code&gt; (with three dots instead of a list of module ports). With this syntax it is sufficient to simply declare a module port as &#39;input&#39; or &#39;output&#39; in the module body.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;When defining a macro with `define, all text between triple double quotes is interpreted as macro body, even if it contains unescaped newlines. The triple double quotes are removed from the macro body. For example:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;`define MY_MACRO(a, b) &#34;&#34;&#34;&#xA;   assign a = 23;&#xA;   assign b = 42;&#xA;&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The attribute &lt;code&gt;via_celltype&lt;/code&gt; can be used to implement a Verilog task or function by instantiating the specified cell type. The value is the name of the cell type to use. For functions the name of the output port can be specified by appending it to the cell type separated by a whitespace. The body of the task or function is unused in this case and can be used to specify a behavioral model of the cell type for simulation. For example:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;module my_add3(A, B, C, Y);&#xA;  parameter WIDTH = 8;&#xA;  input [WIDTH-1:0] A, B, C;&#xA;  output [WIDTH-1:0] Y;&#xA;  ...&#xA;endmodule&#xA;&#xA;module top;&#xA;  ...&#xA;  (* via_celltype = &#34;my_add3 Y&#34; *)&#xA;  (* via_celltype_defparam_WIDTH = 32 *)&#xA;  function [31:0] add3;&#xA;    input [31:0] A, B, C;&#xA;    begin&#xA;      add3 = A + B + C;&#xA;    end&#xA;  endfunction&#xA;  ...&#xA;endmodule&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;wiretype&lt;/code&gt; attribute is added by the verilog parser for wires of a typedef&#39;d type to indicate the type identifier.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Various &lt;code&gt;enum_value_{value}&lt;/code&gt; attributes are added to wires of an enumerated type to give a map of possible enum items to their values.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;enum_base_type&lt;/code&gt; attribute is added to enum items to indicate which enum they belong to (enums -- anonymous and otherwise -- are automatically named with an auto-incrementing counter). Note that enums are currently not strongly typed.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;A limited subset of DPI-C functions is supported. The plugin mechanism (see &lt;code&gt;help plugin&lt;/code&gt;) can be used to load .so files with implementations of DPI-C routines. As a non-standard extension it is possible to specify a plugin alias using the &lt;code&gt;&amp;lt;alias&amp;gt;:&lt;/code&gt; syntax. For example:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;module dpitest;&#xA;  import &#34;DPI-C&#34; function foo:round = real my_round (real);&#xA;  parameter real r = my_round(12.345);&#xA;endmodule&#xA;&#xA;$ yosys -p &#39;plugin -a foo -i /lib/libm.so; read_verilog dpitest.v&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Sized constants (the syntax &lt;code&gt;&amp;lt;size&amp;gt;&#39;s?[bodh]&amp;lt;value&amp;gt;&lt;/code&gt;) support constant expressions as &lt;code&gt;&amp;lt;size&amp;gt;&lt;/code&gt;. If the expression is not a simple identifier, it must be put in parentheses. Examples: &lt;code&gt;WIDTH&#39;d42&lt;/code&gt;, &lt;code&gt;(4+2)&#39;b101010&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The system tasks &lt;code&gt;$finish&lt;/code&gt;, &lt;code&gt;$stop&lt;/code&gt; and &lt;code&gt;$display&lt;/code&gt; are supported in initial blocks in an unconditional context (only if/case statements on expressions over parameters and constant values are allowed). The intended use for this is synthesis-time DRC.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;There is limited support for converting &lt;code&gt;specify&lt;/code&gt; .. &lt;code&gt;endspecify&lt;/code&gt; statements to special &lt;code&gt;$specify2&lt;/code&gt;, &lt;code&gt;$specify3&lt;/code&gt;, and &lt;code&gt;$specrule&lt;/code&gt; cells, for use in blackboxes and whiteboxes. Use &lt;code&gt;read_verilog -specify&lt;/code&gt; to enable this functionality. (By default these blocks are ignored.)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;reprocess_after&lt;/code&gt; internal attribute is used by the Verilog frontend to mark cells with bindings which might depend on the specified instantiated module. Modules with such cells will be reprocessed during the &lt;code&gt;hierarchy&lt;/code&gt; pass once the referenced module definition(s) become available.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;smtlib2_module&lt;/code&gt; attribute can be set on a blackbox module to specify a formal model directly using SMT-LIB 2. For such a module, the &lt;code&gt;smtlib2_comb_expr&lt;/code&gt; attribute can be used on output ports to define their value using an SMT-LIB 2 expression. For example:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;(* blackbox *)&#xA;(* smtlib2_module *)&#xA;module submod(a, b);&#xA;  input [7:0] a;&#xA;  (* smtlib2_comb_expr = &#34;(bvnot a)&#34; *)&#xA;  output [7:0] b;&#xA;endmodule&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Non-standard or SystemVerilog features for formal verification&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Support for &lt;code&gt;assert&lt;/code&gt;, &lt;code&gt;assume&lt;/code&gt;, &lt;code&gt;restrict&lt;/code&gt;, and &lt;code&gt;cover&lt;/code&gt; is enabled when &lt;code&gt;read_verilog&lt;/code&gt; is called with &lt;code&gt;-formal&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The system task &lt;code&gt;$initstate&lt;/code&gt; evaluates to 1 in the initial state and to 0 otherwise.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The system function &lt;code&gt;$anyconst&lt;/code&gt; evaluates to any constant value. This is equivalent to declaring a reg as &lt;code&gt;rand const&lt;/code&gt;, but also works outside of checkers. (Yosys also supports &lt;code&gt;rand const&lt;/code&gt; outside checkers.)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The system function &lt;code&gt;$anyseq&lt;/code&gt; evaluates to any value, possibly a different value in each cycle. This is equivalent to declaring a reg as &lt;code&gt;rand&lt;/code&gt;, but also works outside of checkers. (Yosys also supports &lt;code&gt;rand&lt;/code&gt; variables outside checkers.)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The system functions &lt;code&gt;$allconst&lt;/code&gt; and &lt;code&gt;$allseq&lt;/code&gt; can be used to construct formal exist-forall problems. Assumptions only hold if the trace satisfies the assumption for all &lt;code&gt;$allconst/$allseq&lt;/code&gt; values. For assertions and cover statements it is sufficient if just one &lt;code&gt;$allconst/$allseq&lt;/code&gt; value triggers the property (similar to &lt;code&gt;$anyconst/$anyseq&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Wires/registers declared using the &lt;code&gt;anyconst/anyseq/allconst/allseq&lt;/code&gt; attribute (for example &lt;code&gt;(* anyconst *) reg [7:0] foobar;&lt;/code&gt;) will behave as if driven by a &lt;code&gt;$anyconst/$anyseq/$allconst/$allseq&lt;/code&gt; function.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The SystemVerilog tasks &lt;code&gt;$past&lt;/code&gt;, &lt;code&gt;$stable&lt;/code&gt;, &lt;code&gt;$rose&lt;/code&gt; and &lt;code&gt;$fell&lt;/code&gt; are supported in any clocked block.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The syntax &lt;code&gt;@($global_clock)&lt;/code&gt; can be used to create FFs that have no explicit clock input (&lt;code&gt;$ff&lt;/code&gt; cells). The same can be achieved by using &lt;code&gt;@(posedge &amp;lt;netname&amp;gt;)&lt;/code&gt; or &lt;code&gt;@(negedge &amp;lt;netname&amp;gt;)&lt;/code&gt; when &lt;code&gt;&amp;lt;netname&amp;gt;&lt;/code&gt; is marked with the &lt;code&gt;(* gclk *)&lt;/code&gt; Verilog attribute.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Supported features from SystemVerilog&lt;/h1&gt; &#xA;&lt;p&gt;When &lt;code&gt;read_verilog&lt;/code&gt; is called with &lt;code&gt;-sv&lt;/code&gt;, it accepts some language features from SystemVerilog:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;assert&lt;/code&gt; statement from SystemVerilog is supported in its most basic form. In module context: &lt;code&gt;assert property (&amp;lt;expression&amp;gt;);&lt;/code&gt; and within an always block: &lt;code&gt;assert(&amp;lt;expression&amp;gt;);&lt;/code&gt;. It is transformed to an &lt;code&gt;$assert&lt;/code&gt; cell.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;assume&lt;/code&gt;, &lt;code&gt;restrict&lt;/code&gt;, and &lt;code&gt;cover&lt;/code&gt; statements from SystemVerilog are also supported. The same limitations as with the &lt;code&gt;assert&lt;/code&gt; statement apply.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The keywords &lt;code&gt;always_comb&lt;/code&gt;, &lt;code&gt;always_ff&lt;/code&gt; and &lt;code&gt;always_latch&lt;/code&gt;, &lt;code&gt;logic&lt;/code&gt; and &lt;code&gt;bit&lt;/code&gt; are supported.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Declaring free variables with &lt;code&gt;rand&lt;/code&gt; and &lt;code&gt;rand const&lt;/code&gt; is supported.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Checkers without a port list that do not need to be instantiated (but instead behave like a named block) are supported.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SystemVerilog packages are supported. Once a SystemVerilog file is read into a design with &lt;code&gt;read_verilog&lt;/code&gt;, all its packages are available to SystemVerilog files being read into the same design afterwards.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;typedefs are supported (including inside packages)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;type casts are currently not supported&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;enums are supported (including inside packages)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;but are currently not strongly typed&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;packed structs and unions are supported&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;arrays of packed structs/unions are currently not supported&lt;/li&gt; &#xA;   &lt;li&gt;structure literals are currently not supported&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;multidimensional arrays are supported&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;array assignment of unpacked arrays is currently not supported&lt;/li&gt; &#xA;   &lt;li&gt;array literals are currently not supported&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SystemVerilog interfaces (SVIs) are supported. Modports for specifying whether ports are inputs or outputs are supported.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Assignments within expressions are supported.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Building the documentation&lt;/h1&gt; &#xA;&lt;p&gt;Note that there is no need to build the manual if you just want to read it. Simply visit &lt;a href=&#34;https://yosys.readthedocs.io/en/latest/&#34;&gt;https://yosys.readthedocs.io/en/latest/&lt;/a&gt; instead.&lt;/p&gt; &#xA;&lt;p&gt;In addition to those packages listed above for building Yosys from source, the following are used for building the website:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt install pdf2svg faketime&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;PDFLaTeX, included with most LaTeX distributions, is also needed during the build process for the website. Or, run the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt install texlive-latex-base texlive-latex-extra latexmk&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The Python package, Sphinx, is needed along with those listed in &lt;code&gt;docs/source/requirements.txt&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install -U sphinx -r docs/source/requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;From the root of the repository, run &lt;code&gt;make docs&lt;/code&gt;. This will build/rebuild yosys as necessary before generating the website documentation from the yosys help commands. To build for pdf instead of html, call &lt;code&gt;make docs DOC_TARGET=latexpdf&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>