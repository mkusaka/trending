<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-09T01:39:48Z</updated>
  <subtitle>Weekly Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ggml-org/ggml</title>
    <updated>2025-02-09T01:39:48Z</updated>
    <id>tag:github.com,2025-02-09:/ggml-org/ggml</id>
    <link href="https://github.com/ggml-org/ggml" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tensor library for machine learning&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ggml&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/users/ggerganov/projects/7&#34;&gt;Roadmap&lt;/a&gt; / &lt;a href=&#34;https://github.com/ggerganov/llama.cpp/discussions/205&#34;&gt;Manifesto&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Tensor library for machine learning&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note that this project is under active development. &lt;br&gt; Some of the development is currently happening in the &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; and &lt;a href=&#34;https://github.com/ggerganov/whisper.cpp&#34;&gt;whisper.cpp&lt;/a&gt; repos&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Low-level cross-platform implementation&lt;/li&gt; &#xA; &lt;li&gt;Integer quantization support&lt;/li&gt; &#xA; &lt;li&gt;Broad hardware support&lt;/li&gt; &#xA; &lt;li&gt;Automatic differentiation&lt;/li&gt; &#xA; &lt;li&gt;ADAM and L-BFGS optimizers&lt;/li&gt; &#xA; &lt;li&gt;No third-party dependencies&lt;/li&gt; &#xA; &lt;li&gt;Zero memory allocations during runtime&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Build&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/ggml-org/ggml&#xA;cd ggml&#xA;&#xA;# install python dependencies in a virtual environment&#xA;python3.10 -m venv .venv&#xA;source .venv/bin/activate&#xA;pip install -r requirements.txt&#xA;&#xA;# build the examples&#xA;mkdir build &amp;amp;&amp;amp; cd build&#xA;cmake ..&#xA;cmake --build . --config Release -j 8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;GPT inference (example)&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# run the GPT-2 small 117M model&#xA;../examples/gpt-2/download-ggml-model.sh 117M&#xA;./bin/gpt-2-backend -m models/gpt-2-117M/ggml-model.bin -p &#34;This is an example&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information, checkout the corresponding programs in the &lt;a href=&#34;https://raw.githubusercontent.com/ggml-org/ggml/master/examples&#34;&gt;examples&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;Using CUDA&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# fix the path to point to your CUDA compiler&#xA;cmake -DGGML_CUDA=ON -DCMAKE_CUDA_COMPILER=/usr/local/cuda-12.1/bin/nvcc ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using hipBLAS&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cmake -DCMAKE_C_COMPILER=&#34;$(hipconfig -l)/clang&#34; -DCMAKE_CXX_COMPILER=&#34;$(hipconfig -l)/clang++&#34; -DGGML_HIP=ON&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using SYCL&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# linux&#xA;source /opt/intel/oneapi/setvars.sh&#xA;cmake -G &#34;Ninja&#34; -DCMAKE_C_COMPILER=icx -DCMAKE_CXX_COMPILER=icpx -DGGML_SYCL=ON ..&#xA;&#xA;# windows&#xA;&#34;C:\Program Files (x86)\Intel\oneAPI\setvars.bat&#34;&#xA;cmake -G &#34;Ninja&#34; -DCMAKE_C_COMPILER=cl -DCMAKE_CXX_COMPILER=icx -DGGML_SYCL=ON ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Compiling for Android&lt;/h2&gt; &#xA;&lt;p&gt;Download and unzip the NDK from this download &lt;a href=&#34;https://developer.android.com/ndk/downloads&#34;&gt;page&lt;/a&gt;. Set the NDK_ROOT_PATH environment variable or provide the absolute path to the CMAKE_ANDROID_NDK in the command below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cmake .. \&#xA;   -DCMAKE_SYSTEM_NAME=Android \&#xA;   -DCMAKE_SYSTEM_VERSION=33 \&#xA;   -DCMAKE_ANDROID_ARCH_ABI=arm64-v8a \&#xA;   -DCMAKE_ANDROID_NDK=$NDK_ROOT_PATH&#xA;   -DCMAKE_ANDROID_STL_TYPE=c++_shared&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# create directories&#xA;adb shell &#39;mkdir /data/local/tmp/bin&#39;&#xA;adb shell &#39;mkdir /data/local/tmp/models&#39;&#xA;&#xA;# push the compiled binaries to the folder&#xA;adb push bin/* /data/local/tmp/bin/&#xA;&#xA;# push the ggml library&#xA;adb push src/libggml.so /data/local/tmp/&#xA;&#xA;# push model files&#xA;adb push models/gpt-2-117M/ggml-model.bin /data/local/tmp/models/&#xA;&#xA;adb shell&#xA;cd /data/local/tmp&#xA;export LD_LIBRARY_PATH=/data/local/tmp&#xA;./bin/gpt-2-backend -m models/ggml-model.bin -p &#34;this is an example&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/blog/introduction-to-ggml&#34;&gt;Introduction to ggml&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggerganov/ggml/raw/master/docs/gguf.md&#34;&gt;The GGUF file format&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>mamedev/mame</title>
    <updated>2025-02-09T01:39:48Z</updated>
    <id>tag:github.com,2025-02-09:/mamedev/mame</id>
    <link href="https://github.com/mamedev/mame" rel="alternate"></link>
    <summary type="html">&lt;p&gt;MAME&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MAME&lt;/h1&gt; &#xA;&lt;h2&gt;What is MAME?&lt;/h2&gt; &#xA;&lt;p&gt;MAME is a multi-purpose emulation framework.&lt;/p&gt; &#xA;&lt;p&gt;MAME&#39;s purpose is to preserve decades of software history. As electronic technology continues to rush forward, MAME prevents this important &#34;vintage&#34; software from being lost and forgotten. This is achieved by documenting the hardware and how it functions. The source code to MAME serves as this documentation. The fact that the software is usable serves primarily to validate the accuracy of the documentation (how else can you prove that you have recreated the hardware faithfully?). Over time, MAME (originally stood for Multiple Arcade Machine Emulator) absorbed the sister-project MESS (Multi Emulator Super System), so MAME now documents a wide variety of (mostly vintage) computers, video game consoles and calculators, in addition to the arcade video games that were its initial focus.&lt;/p&gt; &#xA;&lt;h2&gt;Where can I find out more?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mamedev.org/&#34;&gt;Official MAME Development Team Site&lt;/a&gt; (includes binary downloads, wiki, forums, and more)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mametesters.org/&#34;&gt;MAME Testers&lt;/a&gt; (official bug tracker for MAME)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Community&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://forums.bannister.org/ubbthreads.php?ubb=cfrm&amp;amp;c=5&#34;&gt;MAME Forums on bannister.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/MAME/&#34;&gt;r/MAME&lt;/a&gt; on Reddit&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mameworld.info/ubbthreads/&#34;&gt;MAMEWorld Forums&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://repobeats.axiom.co/api/embed/8461d8ae4630322dafc736fc25782de214b49630.svg?sanitize=true&#34; alt=&#34;Alt&#34; title=&#34;Repobeats analytics image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;CI status and code scanning&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mamedev/mame/actions/workflows/ci-linux.yml&#34;&gt;&lt;img src=&#34;https://github.com/mamedev/mame/workflows/CI%20(Linux)/badge.svg?sanitize=true&#34; alt=&#34;CI (Linux)&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mamedev/mame/actions/workflows/ci-windows.yml&#34;&gt;&lt;img src=&#34;https://github.com/mamedev/mame/workflows/CI%20(Windows)/badge.svg?sanitize=true&#34; alt=&#34;CI (Windows&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mamedev/mame/actions/workflows/ci-macos.yml&#34;&gt;&lt;img src=&#34;https://github.com/mamedev/mame/workflows/CI%20(macOS)/badge.svg?sanitize=true&#34; alt=&#34;CI (macOS)&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mamedev/mame/actions/workflows/language.yml&#34;&gt;&lt;img src=&#34;https://github.com/mamedev/mame/workflows/Compile%20UI%20translations/badge.svg?sanitize=true&#34; alt=&#34;Compile UI translations&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mamedev/mame/actions/workflows/docs.yml&#34;&gt;&lt;img src=&#34;https://github.com/mamedev/mame/workflows/Build%20documentation/badge.svg?sanitize=true&#34; alt=&#34;Build documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://scan.coverity.com/projects/mame-emulator&#34;&gt;&lt;img src=&#34;https://scan.coverity.com/projects/5727/badge.svg?flat=1&#34; alt=&#34;Coverity Scan Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;How to compile?&lt;/h3&gt; &#xA;&lt;p&gt;If you&#39;re on a UNIX-like system (including Linux and macOS), it could be as easy as typing&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;for a full build,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make SUBTARGET=tiny&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;for a build including a small subset of supported systems.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;http://docs.mamedev.org/initialsetup/compilingmame.html&#34;&gt;Compiling MAME&lt;/a&gt; page on our documentation site for more information, including prerequisites for macOS and popular Linux distributions.&lt;/p&gt; &#xA;&lt;p&gt;For recent versions of macOS you need to install &lt;a href=&#34;https://developer.apple.com/xcode/&#34;&gt;Xcode&lt;/a&gt; including command-line tools and &lt;a href=&#34;https://github.com/libsdl-org/SDL/releases/latest&#34;&gt;SDL 2.0&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For Windows users, we provide a ready-made &lt;a href=&#34;http://www.mamedev.org/tools/&#34;&gt;build environment&lt;/a&gt; based on MinGW-w64.&lt;/p&gt; &#xA;&lt;p&gt;Visual Studio builds are also possible, but you still need &lt;a href=&#34;http://www.mamedev.org/tools/&#34;&gt;build environment&lt;/a&gt; based on MinGW-w64. In order to generate solution and project files just run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make vs2022&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or use this command to build it directly using msbuild&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make vs2022 MSBUILD=1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Coding standard&lt;/h3&gt; &#xA;&lt;p&gt;MAME source code should be viewed and edited with your editor set to use four spaces per tab. Tabs are used for initial indentation of lines, with one tab used per indentation level. Spaces are used for other alignment within a line.&lt;/p&gt; &#xA;&lt;p&gt;Some parts of the code follow &lt;a href=&#34;https://en.wikipedia.org/wiki/Indent_style#Allman_style&#34;&gt;Allman style&lt;/a&gt;; some parts of the code follow &lt;a href=&#34;https://en.wikipedia.org/wiki/Indent_style#K.26R_style&#34;&gt;K&amp;amp;R style&lt;/a&gt; -- mostly depending on who wrote the original version. &lt;strong&gt;Above all else, be consistent with what you modify, and keep whitespace changes to a minimum when modifying existing source.&lt;/strong&gt; For new code, the majority tends to prefer Allman style, so if you don&#39;t care much, use that.&lt;/p&gt; &#xA;&lt;p&gt;All contributors need to either add a standard header for license info (on new files) or inform us of their wishes regarding which of the following licenses they would like their code to be made available under: the &lt;a href=&#34;http://opensource.org/licenses/BSD-3-Clause&#34;&gt;BSD-3-Clause&lt;/a&gt; license, the &lt;a href=&#34;http://opensource.org/licenses/LGPL-2.1&#34;&gt;LGPL-2.1&lt;/a&gt;, or the &lt;a href=&#34;http://opensource.org/licenses/GPL-2.0&#34;&gt;GPL-2.0&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See more specific &lt;a href=&#34;https://docs.mamedev.org/contributing/cxx.html&#34;&gt;C++ Coding Guidelines&lt;/a&gt; on our documentation web site.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The MAME project as a whole is made available under the terms of the &lt;a href=&#34;http://opensource.org/licenses/GPL-2.0&#34;&gt;GNU General Public License, version 2&lt;/a&gt; or later (GPL-2.0+), since it contains code made available under multiple GPL-compatible licenses. A great majority of the source files (over 90% including core files) are made available under the terms of the &lt;a href=&#34;http://opensource.org/licenses/BSD-3-Clause&#34;&gt;3-clause BSD License&lt;/a&gt;, and we would encourage new contributors to make their contributions available under the terms of this license.&lt;/p&gt; &#xA;&lt;p&gt;Please note that MAME is a registered trademark of Gregory Ember, and permission is required to use the &#34;MAME&#34; name, logo, or wordmark.&lt;/p&gt; &#xA;&lt;a href=&#34;http://opensource.org/licenses/GPL-2.0&#34; target=&#34;_blank&#34;&gt; &lt;img align=&#34;right&#34; width=&#34;100&#34; src=&#34;https://opensource.org/wp-content/uploads/2009/06/OSIApproved.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA;&lt;pre&gt;&lt;code&gt;Copyright (c) 1997-2025  MAMEdev and contributors&#xA;&#xA;This program is free software; you can redistribute it and/or modify it&#xA;under the terms of the GNU General Public License version 2, as provided in&#xA;docs/legal/GPL-2.0.&#xA;&#xA;This program is distributed in the hope that it will be useful, but WITHOUT&#xA;ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or&#xA;FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for&#xA;more details.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/mamedev/mame/master/COPYING&#34;&gt;COPYING&lt;/a&gt; for more details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>tensorflow/tflite-micro</title>
    <updated>2025-02-09T01:39:48Z</updated>
    <id>tag:github.com,2025-02-09:/tensorflow/tflite-micro</id>
    <link href="https://github.com/tensorflow/tflite-micro" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Infrastructure to enable deployment of ML models to low-power resource-constrained embedded targets (including microcontrollers and digital signal processors).&lt;/p&gt;&lt;hr&gt;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/#tensorflow-lite-for-microcontrollers&#34;&gt;TensorFlow Lite for Microcontrollers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/#build-status&#34;&gt;Build Status&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/#official-builds&#34;&gt;Official Builds&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/#community-supported-tflm-examples&#34;&gt;Community Supported TFLM Examples&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/#community-supported-kernels-and-unit-tests&#34;&gt;Community Supported Kernels and Unit Tests&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/#getting-help&#34;&gt;Getting Help&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/#additional-documentation&#34;&gt;Additional Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/#rfcs&#34;&gt;RFCs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- Added by: advaitjain, at: Mon 04 Oct 2021 11:23:57 AM PDT --&gt; &#xA;&lt;!--te--&gt; &#xA;&lt;h1&gt;TensorFlow Lite for Microcontrollers&lt;/h1&gt; &#xA;&lt;p&gt;TensorFlow Lite for Microcontrollers is a port of TensorFlow Lite designed to run machine learning models on DSPs, microcontrollers and other devices with limited memory.&lt;/p&gt; &#xA;&lt;p&gt;Additional Links:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/&#34;&gt;Tensorflow github repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/lite/microcontrollers&#34;&gt;TFLM at tensorflow.org&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Build Status&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.githubstatus.com/&#34;&gt;GitHub Status&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Official Builds&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Build Type&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CI (Linux)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/run_ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/run_ci.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Code Sync&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/sync.yml&#34;&gt;&lt;img src=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/sync.yml/badge.svg?sanitize=true&#34; alt=&#34;Sync from Upstream TF&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Community Supported TFLM Examples&lt;/h2&gt; &#xA;&lt;p&gt;This table captures platforms that TFLM has been ported to. Please see &lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/new_platform_support.md&#34;&gt;New Platform Support&lt;/a&gt; for additional documentation.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Platform&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Arduino&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tflite-micro-arduino-examples/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/tensorflow/tflite-micro-arduino-examples/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;Arduino&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/antmicro/tensorflow-arduino-examples/actions/workflows/test_examples.yml&#34;&gt;&lt;img src=&#34;https://github.com/antmicro/tensorflow-arduino-examples/actions/workflows/test_examples.yml/badge.svg?sanitize=true&#34; alt=&#34;Antmicro&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://coral.ai/products/dev-board-micro&#34;&gt;Coral Dev Board Micro&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-coral/coralmicro&#34;&gt;TFLM + EdgeTPU Examples for Coral Dev Board Micro&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Espressif Systems Dev Boards&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/espressif/tflite-micro-esp-examples/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/espressif/tflite-micro-esp-examples/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;ESP Dev Boards&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Renesas Boards&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/renesas/tflite-micro-renesas&#34;&gt;TFLM Examples for Renesas Boards&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Silicon Labs Dev Kits&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/SiliconLabs/tflite-micro-efr32-examples&#34;&gt;TFLM Examples for Silicon Labs Dev Kits&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sparkfun Edge&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/advaitjain/tflite-micro-sparkfun-edge-examples/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/advaitjain/tflite-micro-sparkfun-edge-examples/actions/workflows/ci.yml/badge.svg?event=schedule&#34; alt=&#34;Sparkfun Edge&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Texas Instruments Dev Boards&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/TexasInstruments/tensorflow-lite-micro-examples/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/TexasInstruments/tensorflow-lite-micro-examples/actions/workflows/ci.yml/badge.svg?event=status&#34; alt=&#34;Texas Instruments Dev Boards&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Community Supported Kernels and Unit Tests&lt;/h2&gt; &#xA;&lt;p&gt;This is a list of targets that have optimized kernel implementations and/or run the TFLM unit tests using software emulation or instruction set simulators.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Build Type&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Cortex-M&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/cortex_m.yml&#34;&gt;&lt;img src=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/cortex_m.yml/badge.svg?sanitize=true&#34; alt=&#34;Cortex-M&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Hexagon&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/run_hexagon.yml&#34;&gt;&lt;img src=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/run_hexagon.yml/badge.svg?sanitize=true&#34; alt=&#34;Hexagon&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RISC-V&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/riscv.yml&#34;&gt;&lt;img src=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/riscv.yml/badge.svg?sanitize=true&#34; alt=&#34;RISC-V&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xtensa&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/run_xtensa.yml&#34;&gt;&lt;img src=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/run_xtensa.yml/badge.svg?sanitize=true&#34; alt=&#34;Xtensa&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generate Integration Test&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/generate_integration_tests.yml&#34;&gt;&lt;img src=&#34;https://github.com/tensorflow/tflite-micro/actions/workflows/generate_integration_tests.yml/badge.svg?sanitize=true&#34; alt=&#34;Generate Integration Test&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;See our &lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/CONTRIBUTING.md&#34;&gt;contribution documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Getting Help&lt;/h1&gt; &#xA;&lt;p&gt;A &lt;a href=&#34;https://github.com/tensorflow/tflite-micro/issues/new/choose&#34;&gt;Github issue&lt;/a&gt; should be the primary method of getting in touch with the TensorFlow Lite Micro (TFLM) team.&lt;/p&gt; &#xA;&lt;p&gt;The following resources may also be useful:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;SIG Micro &lt;a href=&#34;https://groups.google.com/a/tensorflow.org/g/micro&#34;&gt;email group&lt;/a&gt; and &lt;a href=&#34;http://doc/1YHq9rmhrOUdcZnrEnVCWvd87s2wQbq4z17HbeRl-DBc&#34;&gt;monthly meetings&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SIG Micro &lt;a href=&#34;https://gitter.im/tensorflow/sig-micro&#34;&gt;gitter chat room&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For questions that are not specific to TFLM, please consult the broader TensorFlow project, e.g.:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Create a topic on the &lt;a href=&#34;https://discuss.tensorflow.org&#34;&gt;TensorFlow Discourse forum&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Send an email to the &lt;a href=&#34;https://groups.google.com/a/tensorflow.org/g/tflite&#34;&gt;TensorFlow Lite mailing list&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Create a &lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/new/choose&#34;&gt;TensorFlow issue&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Create a &lt;a href=&#34;https://github.com/tensorflow/model-optimization&#34;&gt;Model Optimization Toolkit&lt;/a&gt; issue&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Additional Documentation&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/docs/continuous_integration.md&#34;&gt;Continuous Integration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/benchmarks/README.md&#34;&gt;Benchmarks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/profiling.md&#34;&gt;Profiling&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/memory_management.md&#34;&gt;Memory Management&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/logging.md&#34;&gt;Logging&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/porting_reference_ops.md&#34;&gt;Porting Reference Kernels from TfLite to TFLM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/optimized_kernel_implementations.md&#34;&gt;Optimized Kernel Implementations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/new_platform_support.md&#34;&gt;New Platform Support&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Platform/IP support &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/arm.md&#34;&gt;Arm IP support&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/renode.md&#34;&gt;Software Emulation with Renode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/qemu.md&#34;&gt;Software Emulation with QEMU&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/docs/python.md&#34;&gt;Python Dev Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/docs/automatically_generated_files.md&#34;&gt;Automatically Generated Files&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/python/tflite_micro/README.md&#34;&gt;Python Interpreter Guide&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;RFCs&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/rfc/001_preallocated_tensors.md&#34;&gt;Pre-allocated tensors&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/tflite-micro/main/tensorflow/lite/micro/docs/rfc/002_16x8_quantization_port.md&#34;&gt;TensorFlow Lite for Microcontrollers Port of 16x8 Quantized Operators&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
</feed>