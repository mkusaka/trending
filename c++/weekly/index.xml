<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-14T01:51:44Z</updated>
  <subtitle>Weekly Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>praydog/UEVR</title>
    <updated>2024-01-14T01:51:44Z</updated>
    <id>tag:github.com,2024-01-14:/praydog/UEVR</id>
    <link href="https://github.com/praydog/UEVR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Universal Unreal Engine VR Mod (4.8 - 5.3)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;UEVR &lt;img src=&#34;https://github.com/praydog/UEVR/actions/workflows/dev-release.yml/badge.svg?sanitize=true&#34; alt=&#34;build&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Universal Unreal Engine VR Mod (4/5)&lt;/p&gt; &#xA;&lt;p&gt;4.8 - 5.3&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://praydog.github.io/uevr-docs&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://flat2vr.com&#34;&gt;Flat2VR Discord&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Full 6DOF support out of the box (HMD movement)&lt;/li&gt; &#xA; &lt;li&gt;Full stereoscopic 3D out of the box&lt;/li&gt; &#xA; &lt;li&gt;Native UE4/UE5 stereo rendering system&lt;/li&gt; &#xA; &lt;li&gt;Frontend GUI for easy process injection&lt;/li&gt; &#xA; &lt;li&gt;Supports OpenVR and OpenXR runtimes&lt;/li&gt; &#xA; &lt;li&gt;3 rendering modes: Native Stereo, Synchronized Sequential, and Alternating/AFR&lt;/li&gt; &#xA; &lt;li&gt;Automatic handling of most in-game UI so it is projected into 3D space&lt;/li&gt; &#xA; &lt;li&gt;Optional 3DOF motion controls out of the box in many games, essentially emulating a semi-native VR experience&lt;/li&gt; &#xA; &lt;li&gt;Optional roomscale movement in many games, moving the player character itself in 3D space along with the headset&lt;/li&gt; &#xA; &lt;li&gt;User-authored UI-based system for adding motion controls and first person to games that don&#39;t support them&lt;/li&gt; &#xA; &lt;li&gt;In-game menu with shortcuts for adjusting settings&lt;/li&gt; &#xA; &lt;li&gt;Access to various CVars for fixing broken shaders/effects/performance issues&lt;/li&gt; &#xA; &lt;li&gt;Optional depth buffer integration for improved latency on some headsets&lt;/li&gt; &#xA; &lt;li&gt;Per-game configurations&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://praydog.github.io/uevr-docs/plugins/getting_started.html&#34;&gt;C++ Plugin system&lt;/a&gt; and &lt;a href=&#34;https://praydog.github.io/uevr-docs/plugins/blueprint.html&#34;&gt;Blueprint support&lt;/a&gt; for modders to add additional features like motion controls&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Before launching, ensure you have installed .NET 6.0. It should tell you where to install it upon first open, but if not, you can &lt;a href=&#34;https://dotnet.microsoft.com/en-us/download/dotnet/6.0&#34;&gt;download it from here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Launch UEVRInjector.exe&lt;/li&gt; &#xA; &lt;li&gt;Launch the target game&lt;/li&gt; &#xA; &lt;li&gt;Locate the game in the process dropdown list&lt;/li&gt; &#xA; &lt;li&gt;Select your desired runtime (OpenVR/OpenXR)&lt;/li&gt; &#xA; &lt;li&gt;Toggle existing VR plugin nullification (if necessary)&lt;/li&gt; &#xA; &lt;li&gt;Configure pre-injection settings&lt;/li&gt; &#xA; &lt;li&gt;Inject&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;To-dos before injection&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Disable HDR (it will still work without it, but the game will be darker than usual if it is)&lt;/li&gt; &#xA; &lt;li&gt;Start as administrator if the game is not visible in the list&lt;/li&gt; &#xA; &lt;li&gt;Pass &lt;code&gt;-nohmd&lt;/code&gt; to the game&#39;s command line and/or delete VR plugins from the game directory if the game contains any existing VR plugins&lt;/li&gt; &#xA; &lt;li&gt;Disable any overlays that may conflict and cause crashes (Rivatuner, ASUS software, Razer software, Overwolf, etc...)&lt;/li&gt; &#xA; &lt;li&gt;Disable graphical options in-game that may cause crashes or severe issues like DLSS Frame Generation&lt;/li&gt; &#xA; &lt;li&gt;Consider disabling &lt;code&gt;Hardware Accelerated GPU Scheduling&lt;/code&gt; in your Windows &lt;code&gt;Graphics settings&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;In-Game Menu&lt;/h2&gt; &#xA;&lt;p&gt;Press the &lt;strong&gt;Insert&lt;/strong&gt; key or &lt;strong&gt;L3+R3&lt;/strong&gt; on an XInput based controller to access the in-game menu, which opens by default at startup. With the menu open, hold &lt;strong&gt;RT&lt;/strong&gt; for various shortcuts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;RT + Left Stick: Move the camera left/right/forward/back&lt;/li&gt; &#xA; &lt;li&gt;RT + Right Stick: Move the camera up/down&lt;/li&gt; &#xA; &lt;li&gt;RT + B: Reset camera offset&lt;/li&gt; &#xA; &lt;li&gt;RT + Y: Recenter view&lt;/li&gt; &#xA; &lt;li&gt;RT + X: Reset standing origin&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick overview of rendering methods&lt;/h2&gt; &#xA;&lt;h3&gt;Native Stereo&lt;/h3&gt; &#xA;&lt;p&gt;When it works, it looks the best, performs the best (usually). Can cause crashes or graphical bugs if the game does not play well with it.&lt;/p&gt; &#xA;&lt;p&gt;Temporal effects like TAA are fully intact. DLSS/FSR2 usually work completely fine with no ghosting in this mode.&lt;/p&gt; &#xA;&lt;p&gt;Fully synchronized eye rendering. Works with the majority of games. Uses the actual stereo rendering pipeline in the Unreal Engine to achieve a stereoscopic image.&lt;/p&gt; &#xA;&lt;h3&gt;Synchronized Sequential&lt;/h3&gt; &#xA;&lt;p&gt;A form of AFR. Can fix many rendering bugs that are introduced with Native Stereo. Renders two frames &lt;strong&gt;sequentially&lt;/strong&gt; in a &lt;strong&gt;synchronized&lt;/strong&gt; fashion on the same engine tick.&lt;/p&gt; &#xA;&lt;p&gt;Fully synchronized eye rendering. Game world does not advance time between frames.&lt;/p&gt; &#xA;&lt;p&gt;Looks normal but temporal effects like TAA will have ghosting/doubling effect. Motion blur will need to be turned off.&lt;/p&gt; &#xA;&lt;p&gt;This is the first alternative option that should be used if Native Stereo is not working as expected or you are encountering graphical bugs.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Skip Draw&lt;/strong&gt; skips the viewport draw on the next engine tick. Usually works the best but sometimes particle effects may not play at the correct speed.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Skip Tick&lt;/strong&gt; skips the next engine tick entirely. Usually buggy but does fix particle effects and sometimes brings higher performance.&lt;/p&gt; &#xA;&lt;h3&gt;AFR&lt;/h3&gt; &#xA;&lt;p&gt;Alternated Frame Rendering. Renders each eye on separate frames in an alternating fashion, with the game world advancing time in between frames. Causes eye desyncs and usually nausea along with it.&lt;/p&gt; &#xA;&lt;p&gt;Not synchronized. Generally should not be used unless the other two are unusable in some way.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>IntelRealSense/librealsense</title>
    <updated>2024-01-14T01:51:44Z</updated>
    <id>tag:github.com,2024-01-14:/IntelRealSense/librealsense</id>
    <link href="https://github.com/IntelRealSense/librealsense" rel="alternate"></link>
    <summary type="html">&lt;p&gt;IntelÂ® RealSenseâ„¢ SDK&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/doc/img/realsense.png&#34; width=&#34;70%&#34;&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/actions/workflows/buildsCI.yaml&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/IntelRealSense/actions/workflows/buildsCI.yaml/badge.svg?branch=development&#34; alt=&#34;GitHub CI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;IntelÂ® RealSenseâ„¢ SDK 2.0&lt;/strong&gt; is a cross-platform library for IntelÂ® RealSenseâ„¢ depth cameras (D400 &amp;amp; L500 series and the SR300).&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; For other IntelÂ® RealSenseâ„¢ devices (F200, R200, LR200 and ZR300), please refer to the &lt;a href=&#34;https://github.com/IntelRealSense/librealsense/tree/v1.12.1&#34;&gt;latest legacy release&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;The SDK allows depth and color streaming, and provides intrinsic and extrinsic calibration information. The library also offers synthetic streams (pointcloud, depth aligned to color and vise-versa), and a built-in support for &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/doc/record-and-playback.md&#34;&gt;record and playback&lt;/a&gt; of streaming sessions.&lt;/p&gt; &#xA;&lt;p&gt;Developer kits containing the necessary hardware to use this library are available for purchase at &lt;a href=&#34;https://store.intelrealsense.com/products.html&#34;&gt;store.intelrealsense.com&lt;/a&gt;. Information about the IntelÂ® RealSenseâ„¢ technology at &lt;a href=&#34;https://www.intelrealsense.com/&#34;&gt;www.intelrealsense.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“‚&lt;/span&gt; Don&#39;t have access to a RealSense camera? Check-out &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/doc/sample-data.md&#34;&gt;sample data&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Update on Recent Changes to the RealSense Product Line&lt;/h2&gt; &#xA;&lt;p&gt;Intel has EOLed the LiDAR, Facial Authentication, and Tracking product lines. These products have been discontinued and will no longer be available for new orders.&lt;/p&gt; &#xA;&lt;p&gt;Intel WILL continue to sell and support stereo products including the following: D410, D415, D430, , D401 ,D450 modules and D415, D435, D435i, D435f, D405, D455, D457 depth cameras. We will also continue the work to support and develop our LibRealSense open source SDK.&lt;/p&gt; &#xA;&lt;p&gt;In the future, Intel and the RealSense team will focus our new development on advancing innovative technologies that better support our core businesses and IDM 2.0 strategy.&lt;/p&gt; &#xA;&lt;h2&gt;Building librealsense - Using vcpkg&lt;/h2&gt; &#xA;&lt;p&gt;You can download and install librealsense using the &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;vcpkg&lt;/a&gt; dependency manager:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/Microsoft/vcpkg.git&#xA;cd vcpkg&#xA;./bootstrap-vcpkg.sh&#xA;./vcpkg integrate install&#xA;./vcpkg install realsense2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The librealsense port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;create an issue or pull request&lt;/a&gt; on the vcpkg repository.&lt;/p&gt; &#xA;&lt;h2&gt;Download and Install&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt; - The latest releases including the Intel RealSense SDK, Viewer and Depth Quality tools are available at: &lt;a href=&#34;https://github.com/IntelRealSense/librealsense/releases&#34;&gt;&lt;strong&gt;latest releases&lt;/strong&gt;&lt;/a&gt;. Please check the &lt;a href=&#34;https://github.com/IntelRealSense/librealsense/wiki/Release-Notes&#34;&gt;&lt;strong&gt;release notes&lt;/strong&gt;&lt;/a&gt; for the supported platforms, new features and capabilities, known issues, how to upgrade the Firmware and more.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install&lt;/strong&gt; - You can also install or build from source the SDK (on &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/doc/distribution_linux.md&#34;&gt;Linux&lt;/a&gt; \ &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/doc/distribution_windows.md&#34;&gt;Windows&lt;/a&gt; \ &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/doc/installation_osx.md&#34;&gt;Mac OS&lt;/a&gt; \ &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/doc/android.md&#34;&gt;Android&lt;/a&gt; \ &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/scripts/Docker/readme.md&#34;&gt;Docker&lt;/a&gt;), connect your D400 depth camera and you are ready to start writing your first application.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Support &amp;amp; Issues&lt;/strong&gt;: If you need product support (e.g. ask a question about / are having problems with the device), please check the &lt;a href=&#34;https://github.com/IntelRealSense/librealsense/wiki/Troubleshooting-Q%26A&#34;&gt;FAQ &amp;amp; Troubleshooting&lt;/a&gt; section. If not covered there, please search our &lt;a href=&#34;https://github.com/IntelRealSense/librealsense/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aclosed&#34;&gt;Closed GitHub Issues&lt;/a&gt; page, &lt;a href=&#34;https://communities.intel.com/community/tech/realsense&#34;&gt;Community&lt;/a&gt; and &lt;a href=&#34;https://www.intel.com/content/www/us/en/support/emerging-technologies/intel-realsense-technology.html&#34;&gt;Support&lt;/a&gt; sites. If you still cannot find an answer to your question, please &lt;a href=&#34;https://github.com/IntelRealSense/librealsense/issues/new&#34;&gt;open a new issue&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Whatâ€™s included in the SDK:&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;What&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Download link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/tools/realsense-viewer&#34;&gt;IntelÂ® RealSenseâ„¢ Viewer&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;With this application, you can quickly access your IntelÂ® RealSenseâ„¢ Depth Camera to view the depth stream, visualize point clouds, record and playback streams, configure your camera settings, modify advanced controls, enable depth visualization and post processing and much more.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/IntelRealSense/librealsense/releases&#34;&gt;&lt;strong&gt;Intel.RealSense.Viewer.exe&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/tools/depth-quality&#34;&gt;Depth Quality Tool&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This application allows you to test the cameraâ€™s depth quality, including: standard deviation from plane fit, normalized RMS â€“ the subpixel accuracy, distance accuracy and fill rate. You should be able to easily get and interpret several of the depth quality metrics and record and save the data for offline analysis.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/IntelRealSense/librealsense/releases&#34;&gt;&lt;strong&gt;Depth.Quality.Tool.exe&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/tools/&#34;&gt;Debug Tools&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Device enumeration, FW logger, etc as can be seen at the tools directory&lt;/td&gt; &#xA;   &lt;td&gt;Included in &lt;a href=&#34;https://github.com/IntelRealSense/librealsense/releases&#34;&gt;&lt;strong&gt;Intel.RealSense.SDK.exe&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/examples&#34;&gt;Code Samples&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;These simple examples demonstrate how to easily use the SDK to include code snippets that access the camera into your applications. Check some of the &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/examples&#34;&gt;&lt;strong&gt;C++ examples&lt;/strong&gt;&lt;/a&gt; including capture, pointcloud and more and basic &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/examples/C&#34;&gt;&lt;strong&gt;C examples&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Included in &lt;a href=&#34;https://github.com/IntelRealSense/librealsense/releases&#34;&gt;&lt;strong&gt;Intel.RealSense.SDK.exe&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/IntelRealSense/librealsense/tree/development/wrappers&#34;&gt;Wrappers&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/wrappers/python&#34;&gt;Python&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/wrappers/csharp&#34;&gt;C#/.NET&lt;/a&gt; API, as well as integration with the following 3rd-party technologies: &lt;a href=&#34;https://github.com/IntelRealSense/realsense-ros/tree/ros1-legacy&#34;&gt;ROS1&lt;/a&gt;, &lt;a href=&#34;https://github.com/IntelRealSense/realsense-ros/tree/ros2-development&#34;&gt;ROS2&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/wrappers/labview&#34;&gt;LabVIEW&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/wrappers/opencv&#34;&gt;OpenCV&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/wrappers/pcl&#34;&gt;PCL&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/wrappers/unity&#34;&gt;Unity&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/wrappers/matlab&#34;&gt;Matlab&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/wrappers/openni2&#34;&gt;OpenNI&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/wrappers/unrealengine4&#34;&gt;UnrealEngine4&lt;/a&gt; and more to come.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Ready to Hack!&lt;/h2&gt; &#xA;&lt;p&gt;Our library offers a high level API for using Intel RealSense depth cameras (in addition to lower level ones). The following snippet shows how to start streaming frames and extracting the depth value of a pixel:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Create a Pipeline - this serves as a top-level API for streaming and processing frames&#xA;rs2::pipeline p;&#xA;&#xA;// Configure and start the pipeline&#xA;p.start();&#xA;&#xA;while (true)&#xA;{&#xA;    // Block program until frames arrive&#xA;    rs2::frameset frames = p.wait_for_frames();&#xA;&#xA;    // Try to get a frame of a depth image&#xA;    rs2::depth_frame depth = frames.get_depth_frame();&#xA;&#xA;    // Get the depth frame&#39;s dimensions&#xA;    float width = depth.get_width();&#xA;    float height = depth.get_height();&#xA;&#xA;    // Query the distance from the camera to the object in the center of the image&#xA;    float dist_to_center = depth.get_distance(width / 2, height / 2);&#xA;&#xA;    // Print the distance&#xA;    std::cout &amp;lt;&amp;lt; &#34;The camera is facing an object &#34; &amp;lt;&amp;lt; dist_to_center &amp;lt;&amp;lt; &#34; meters away \r&#34;;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information on the library, please follow our &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/examples&#34;&gt;examples&lt;/a&gt;, and read the &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/doc&#34;&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;In order to contribute to Intel RealSense SDK, please follow our &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/CONTRIBUTING.md&#34;&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/IntelRealSense/librealsense/master/LICENSE&#34;&gt;Apache License, Version 2.0&lt;/a&gt;. Copyright 2018 Intel Corporation&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>scylladb/scylladb</title>
    <updated>2024-01-14T01:51:44Z</updated>
    <id>tag:github.com,2024-01-14:/scylladb/scylladb</id>
    <link href="https://github.com/scylladb/scylladb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;NoSQL data store using the seastar framework, compatible with Apache Cassandra&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Scylla&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://slack.scylladb.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/slack-scylla-brightgreen.svg?logo=slack&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/follow?screen_name=ScyllaDB&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/ScyllaDB.svg?style=social&amp;amp;label=Follow&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Scylla?&lt;/h2&gt; &#xA;&lt;p&gt;Scylla is the real-time big data database that is API-compatible with Apache Cassandra and Amazon DynamoDB. Scylla embraces a shared-nothing approach that increases throughput and storage capacity to realize order-of-magnitude performance improvements and reduce hardware costs.&lt;/p&gt; &#xA;&lt;p&gt;For more information, please see the &lt;a href=&#34;https://www.scylladb.com&#34;&gt;ScyllaDB web site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Build Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Scylla is fairly fussy about its build environment, requiring very recent versions of the C++20 compiler and of many libraries to build. The document &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/HACKING.md&#34;&gt;HACKING.md&lt;/a&gt; includes detailed information on building and developing Scylla, but to get Scylla building quickly on (almost) any build machine, Scylla offers a &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/tools/toolchain/README.md&#34;&gt;frozen toolchain&lt;/a&gt;, This is a pre-configured Docker image which includes recent versions of all the required compilers, libraries and build tools. Using the frozen toolchain allows you to avoid changing anything in your build machine to meet Scylla&#39;s requirements - you just need to meet the frozen toolchain&#39;s prerequisites (mostly, Docker or Podman being available).&lt;/p&gt; &#xA;&lt;h2&gt;Building Scylla&lt;/h2&gt; &#xA;&lt;p&gt;Building Scylla with the frozen toolchain &lt;code&gt;dbuild&lt;/code&gt; is as easy as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git submodule update --init --force --recursive&#xA;$ ./tools/toolchain/dbuild ./configure.py&#xA;$ ./tools/toolchain/dbuild ninja build/release/scylla&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For further information, please see:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/HACKING.md&#34;&gt;Developer documentation&lt;/a&gt; for more information on building Scylla.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/dev/building.md&#34;&gt;Build documentation&lt;/a&gt; on how to build Scylla binaries, tests, and packages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/dist/docker/debian/README.md&#34;&gt;Docker image build documentation&lt;/a&gt; for information on how to build Docker images.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Running Scylla&lt;/h2&gt; &#xA;&lt;p&gt;To start Scylla server, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./tools/toolchain/dbuild ./build/release/scylla --workdir tmp --smp 1 --developer-mode 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will start a Scylla node with one CPU core allocated to it and data files stored in the &lt;code&gt;tmp&lt;/code&gt; directory. The &lt;code&gt;--developer-mode&lt;/code&gt; is needed to disable the various checks Scylla performs at startup to ensure the machine is configured for maximum performance (not relevant on development workstations). Please note that you need to run Scylla with &lt;code&gt;dbuild&lt;/code&gt; if you built it with the frozen toolchain.&lt;/p&gt; &#xA;&lt;p&gt;For more run options, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./tools/toolchain/dbuild ./build/release/scylla --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/dev/testing.md&#34;&gt;test.py manual&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Scylla APIs and compatibility&lt;/h2&gt; &#xA;&lt;p&gt;By default, Scylla is compatible with Apache Cassandra and its APIs - CQL and Thrift. There is also support for the API of Amazon DynamoDBâ„¢, which needs to be enabled and configured in order to be used. For more information on how to enable the DynamoDBâ„¢ API in Scylla, and the current compatibility of this feature as well as Scylla-specific extensions, see &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/alternator/alternator.md&#34;&gt;Alternator&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/alternator/getting-started.md&#34;&gt;Getting started with Alternator&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Documentation can be found &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/dev/README.md&#34;&gt;here&lt;/a&gt;. Seastar documentation can be found &lt;a href=&#34;http://docs.seastar.io/master/index.html&#34;&gt;here&lt;/a&gt;. User documentation can be found &lt;a href=&#34;https://docs.scylladb.com/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;Training material and online courses can be found at &lt;a href=&#34;https://university.scylladb.com/&#34;&gt;Scylla University&lt;/a&gt;. The courses are free, self-paced and include hands-on examples. They cover a variety of topics including Scylla data modeling, administration, architecture, basic NoSQL concepts, using drivers for application development, Scylla setup, failover, compactions, multi-datacenters and how Scylla integrates with third-party applications.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing to Scylla&lt;/h2&gt; &#xA;&lt;p&gt;If you want to report a bug or submit a pull request or a patch, please read the &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/CONTRIBUTING.md&#34;&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you are a developer working on Scylla, please read the &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/HACKING.md&#34;&gt;developer guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://forum.scylladb.com/&#34;&gt;community forum&lt;/a&gt; and &lt;a href=&#34;http://slack.scylladb.com/&#34;&gt;Slack channel&lt;/a&gt; are for users to discuss configuration, management, and operations of the ScyllaDB open source.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://groups.google.com/forum/#!forum/scylladb-dev&#34;&gt;developers mailing list&lt;/a&gt; is for developers and people interested in following the development of ScyllaDB to discuss technical topics.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>