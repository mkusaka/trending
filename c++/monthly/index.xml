<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-09-01T01:47:45Z</updated>
  <subtitle>Monthly Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>leejet/stable-diffusion.cpp</title>
    <updated>2024-09-01T01:47:45Z</updated>
    <id>tag:github.com,2024-09-01:/leejet/stable-diffusion.cpp</id>
    <link href="https://github.com/leejet/stable-diffusion.cpp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stable Diffusion and Flux in pure C/C++&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/cat_with_sd_cpp_42.png&#34; width=&#34;360x&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;stable-diffusion.cpp&lt;/h1&gt; &#xA;&lt;p&gt;Inference of Stable Diffusion and Flux in pure C/C++&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Plain C/C++ implementation based on &lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;ggml&lt;/a&gt;, working in the same way as &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Super lightweight and without external dependencies&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SD1.x, SD2.x, SDXL and SD3 support&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;!!!The VAE in SDXL encounters NaN issues under FP16, but unfortunately, the ggml_conv_2d only operates under FP16. Hence, a parameter is needed to specify the VAE that has fixed the FP16 NaN issue. You can find it here: &lt;a href=&#34;https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl_vae.safetensors&#34;&gt;SDXL VAE FP16 Fix&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/docs/flux.md&#34;&gt;Flux-dev/Flux-schnell Support&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/stabilityai/sd-turbo&#34;&gt;SD-Turbo&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/stabilityai/sdxl-turbo&#34;&gt;SDXL-Turbo&lt;/a&gt; support&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/TencentARC/PhotoMaker&#34;&gt;PhotoMaker&lt;/a&gt; support.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;16-bit, 32-bit float support&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2-bit, 3-bit, 4-bit, 5-bit and 8-bit integer quantization support&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Accelerated memory-efficient CPU inference&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Only requires ~2.3GB when using txt2img with fp16 precision to generate a 512x512 image, enabling Flash Attention just requires ~1.8GB.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;AVX, AVX2 and AVX512 support for x86 architectures&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Full CUDA, Metal, Vulkan and SYCL backend for GPU acceleration.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Can load ckpt, safetensors and diffusers models/checkpoints. Standalone VAEs models&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;No need to convert to &lt;code&gt;.ggml&lt;/code&gt; or &lt;code&gt;.gguf&lt;/code&gt; anymore!&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Flash Attention for memory usage optimization (only cpu for now)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Original &lt;code&gt;txt2img&lt;/code&gt; and &lt;code&gt;img2img&lt;/code&gt; mode&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Negative prompt&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;stable-diffusion-webui&lt;/a&gt; style tokenizer (not all the features, only token weighting for now)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;LoRA support, same as &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#lora&#34;&gt;stable-diffusion-webui&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Latent Consistency Models support (LCM/LCM-LoRA)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Faster and memory efficient latent decoding with &lt;a href=&#34;https://github.com/madebyollin/taesd&#34;&gt;TAESD&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Upscale images generated with &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;ESRGAN&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;VAE tiling processing for reduce memory usage&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Control Net support with SD 1.5&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Sampling method&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;Euler A&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Euler&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Heun&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;DPM2&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;DPM++ 2M&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/8457&#34;&gt;&lt;code&gt;DPM++ 2M v2&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;DPM++ 2S a&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/13952&#34;&gt;&lt;code&gt;LCM&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Cross-platform reproducibility (&lt;code&gt;--rng cuda&lt;/code&gt;, consistent with the &lt;code&gt;stable-diffusion-webui GPU RNG&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Embedds generation parameters into png output as webui-compatible text string&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Supported platforms&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Linux&lt;/li&gt; &#xA;   &lt;li&gt;Mac OS&lt;/li&gt; &#xA;   &lt;li&gt;Windows&lt;/li&gt; &#xA;   &lt;li&gt;Android (via Termux)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;TODO&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; More sampling methods&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Make inference faster &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The current implementation of ggml_conv_2d is slow and has high memory usage&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Continuing to reduce memory usage (quantizing the weights of ggml_conv_2d)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implement Inpainting support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;For most users, you can download the built executable program from the latest &lt;a href=&#34;https://github.com/leejet/stable-diffusion.cpp/releases/latest&#34;&gt;release&lt;/a&gt;. If the built product does not meet your requirements, you can choose to build it manually.&lt;/p&gt; &#xA;&lt;h3&gt;Get the Code&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone --recursive https://github.com/leejet/stable-diffusion.cpp&#xA;cd stable-diffusion.cpp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you have already cloned the repository, you can use the following command to update the repository to the latest code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd stable-diffusion.cpp&#xA;git pull origin master&#xA;git submodule init&#xA;git submodule update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Download weights&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;download original weights(.ckpt or .safetensors). For example&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Stable Diffusion v1.4 from &lt;a href=&#34;https://huggingface.co/CompVis/stable-diffusion-v-1-4-original&#34;&gt;https://huggingface.co/CompVis/stable-diffusion-v-1-4-original&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Stable Diffusion v1.5 from &lt;a href=&#34;https://huggingface.co/runwayml/stable-diffusion-v1-5&#34;&gt;https://huggingface.co/runwayml/stable-diffusion-v1-5&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Stable Diffuison v2.1 from &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2-1&#34;&gt;https://huggingface.co/stabilityai/stable-diffusion-2-1&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Stable Diffusion 3 2B from &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-3-medium&#34;&gt;https://huggingface.co/stabilityai/stable-diffusion-3-medium&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -L -O https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt&#xA;# curl -L -O https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors&#xA;# curl -L -O https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-nonema-pruned.safetensors&#xA;# curl -L -O https://huggingface.co/stabilityai/stable-diffusion-3-medium/resolve/main/sd3_medium_incl_clips_t5xxlfp16.safetensors&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Build&lt;/h3&gt; &#xA;&lt;h4&gt;Build from scratch&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir build&#xA;cd build&#xA;cmake ..&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Using OpenBLAS&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmake .. -DGGML_OPENBLAS=ON&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Using CUBLAS&lt;/h5&gt; &#xA;&lt;p&gt;This provides BLAS acceleration using the CUDA cores of your Nvidia GPU. Make sure to have the CUDA toolkit installed. You can download it from your Linux distro&#39;s package manager (e.g. &lt;code&gt;apt install nvidia-cuda-toolkit&lt;/code&gt;) or from here: &lt;a href=&#34;https://developer.nvidia.com/cuda-downloads&#34;&gt;CUDA Toolkit&lt;/a&gt;. Recommended to have at least 4 GB of VRAM.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmake .. -DSD_CUBLAS=ON&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Using HipBLAS&lt;/h5&gt; &#xA;&lt;p&gt;This provides BLAS acceleration using the ROCm cores of your AMD GPU. Make sure to have the ROCm toolkit installed.&lt;/p&gt; &#xA;&lt;p&gt;Windows User Refer to &lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/docs%2FhipBLAS_on_Windows.md&#34;&gt;docs/hipBLAS_on_Windows.md&lt;/a&gt; for a comprehensive guide.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmake .. -G &#34;Ninja&#34; -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ -DSD_HIPBLAS=ON -DCMAKE_BUILD_TYPE=Release -DAMDGPU_TARGETS=gfx1100&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Using Metal&lt;/h5&gt; &#xA;&lt;p&gt;Using Metal makes the computation run on the GPU. Currently, there are some issues with Metal when performing operations on very large matrices, making it highly inefficient at the moment. Performance improvements are expected in the near future.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmake .. -DSD_METAL=ON&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Using Vulkan&lt;/h5&gt; &#xA;&lt;p&gt;Install Vulkan SDK from &lt;a href=&#34;https://www.lunarg.com/vulkan-sdk/&#34;&gt;https://www.lunarg.com/vulkan-sdk/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmake .. -DSD_VULKAN=ON&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Using SYCL&lt;/h5&gt; &#xA;&lt;p&gt;Using SYCL makes the computation run on the Intel GPU. Please make sure you have installed the related driver and &lt;a href=&#34;https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html&#34;&gt;Intel® oneAPI Base toolkit&lt;/a&gt; before start. More details and steps can refer to &lt;a href=&#34;https://github.com/ggerganov/llama.cpp/raw/master/docs/backend/SYCL.md#linux&#34;&gt;llama.cpp SYCL backend&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Export relevant ENV variables&#xA;source /opt/intel/oneapi/setvars.sh&#xA;&#xA;# Option 1: Use FP32 (recommended for better performance in most cases)&#xA;cmake .. -DSD_SYCL=ON -DCMAKE_C_COMPILER=icx -DCMAKE_CXX_COMPILER=icpx&#xA;&#xA;# Option 2: Use FP16&#xA;cmake .. -DSD_SYCL=ON -DCMAKE_C_COMPILER=icx -DCMAKE_CXX_COMPILER=icpx -DGGML_SYCL_F16=ON&#xA;&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example of text2img by using SYCL backend:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;download &lt;code&gt;stable-diffusion&lt;/code&gt; model weight, refer to &lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/#download-weights&#34;&gt;download-weight&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;run &lt;code&gt;./bin/sd -m ../models/sd3_medium_incl_clips_t5xxlfp16.safetensors --cfg-scale 5 --steps 30 --sampling-method euler -H 512 -W 512 --seed 42 -p &#34;fantasy medieval village world inside a glass sphere , high detail, fantasy, realistic, light effect, hyper detail, volumetric lighting, cinematic, macro, depth of field, blur, red light and clouds from the back, highly detailed epic cinematic concept art cg render made in maya, blender and photoshop, octane render, excellent composition, dynamic dramatic cinematic lighting, aesthetic, very inspirational, world inside a glass sphere by james gurney by artgerm with james jean, joe fenton and tristan eaton by ross tran, fine details, 4k resolution&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/sycl_sd3_output.png&#34; width=&#34;360x&#34;&gt; &lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Try to set smaller image height and width (for example, &lt;code&gt;-H 512 -W 512&lt;/code&gt;) if you meet &lt;code&gt;Provided range is out of integer limits. Pass &#39;-fno-sycl-id-queries-fit-in-int&#39; to disable range check.&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h5&gt;Using Flash Attention&lt;/h5&gt; &#xA;&lt;p&gt;Enabling flash attention reduces memory usage by at least 400 MB. At the moment, it is not supported when CUBLAS is enabled because the kernel implementation is missing.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmake .. -DSD_FLASH_ATTN=ON&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;usage: ./bin/sd [arguments]&#xA;&#xA;arguments:&#xA;  -h, --help                         show this help message and exit&#xA;  -M, --mode [MODEL]                 run mode (txt2img or img2img or convert, default: txt2img)&#xA;  -t, --threads N                    number of threads to use during computation (default: -1).&#xA;                                     If threads &amp;lt;= 0, then threads will be set to the number of CPU physical cores&#xA;  -m, --model [MODEL]                path to full model&#xA;  --diffusion-model                  path to the standalone diffusion model&#xA;  --clip_l                           path to the clip-l text encoder&#xA;  --t5xxl                            path to the the t5xxl text encoder.&#xA;  --vae [VAE]                        path to vae&#xA;  --taesd [TAESD_PATH]               path to taesd. Using Tiny AutoEncoder for fast decoding (low quality)&#xA;  --control-net [CONTROL_PATH]       path to control net model&#xA;  --embd-dir [EMBEDDING_PATH]        path to embeddings.&#xA;  --stacked-id-embd-dir [DIR]        path to PHOTOMAKER stacked id embeddings.&#xA;  --input-id-images-dir [DIR]        path to PHOTOMAKER input id images dir.&#xA;  --normalize-input                  normalize PHOTOMAKER input id images&#xA;  --upscale-model [ESRGAN_PATH]      path to esrgan model. Upscale images after generate, just RealESRGAN_x4plus_anime_6B supported by now.&#xA;  --upscale-repeats                  Run the ESRGAN upscaler this many times (default 1)&#xA;  --type [TYPE]                      weight type (f32, f16, q4_0, q4_1, q5_0, q5_1, q8_0, q2_k, q3_k, q4_k)&#xA;                                     If not specified, the default is the type of the weight file.&#xA;  --lora-model-dir [DIR]             lora model directory&#xA;  -i, --init-img [IMAGE]             path to the input image, required by img2img&#xA;  --control-image [IMAGE]            path to image condition, control net&#xA;  -o, --output OUTPUT                path to write result image to (default: ./output.png)&#xA;  -p, --prompt [PROMPT]              the prompt to render&#xA;  -n, --negative-prompt PROMPT       the negative prompt (default: &#34;&#34;)&#xA;  --cfg-scale SCALE                  unconditional guidance scale: (default: 7.0)&#xA;  --strength STRENGTH                strength for noising/unnoising (default: 0.75)&#xA;  --style-ratio STYLE-RATIO          strength for keeping input identity (default: 20%)&#xA;  --control-strength STRENGTH        strength to apply Control Net (default: 0.9)&#xA;                                     1.0 corresponds to full destruction of information in init image&#xA;  -H, --height H                     image height, in pixel space (default: 512)&#xA;  -W, --width W                      image width, in pixel space (default: 512)&#xA;  --sampling-method {euler, euler_a, heun, dpm2, dpm++2s_a, dpm++2m, dpm++2mv2, ipndm, ipndm_v, lcm}&#xA;                                     sampling method (default: &#34;euler_a&#34;)&#xA;  --steps  STEPS                     number of sample steps (default: 20)&#xA;  --rng {std_default, cuda}          RNG (default: cuda)&#xA;  -s SEED, --seed SEED               RNG seed (default: 42, use random seed for &amp;lt; 0)&#xA;  -b, --batch-count COUNT            number of images to generate.&#xA;  --schedule {discrete, karras, exponential, ays, gits} Denoiser sigma schedule (default: discrete)&#xA;  --clip-skip N                      ignore last layers of CLIP network; 1 ignores none, 2 ignores one layer (default: -1)&#xA;                                     &amp;lt;= 0 represents unspecified, will be 1 for SD1.x, 2 for SD2.x&#xA;  --vae-tiling                       process vae in tiles to reduce memory usage&#xA;  --vae-on-cpu                       keep vae in cpu (for low vram)&#xA;  --clip-on-cpu                      keep clip in cpu (for low vram).&#xA;  --control-net-cpu                  keep controlnet in cpu (for low vram)&#xA;  --canny                            apply canny preprocessor (edge detection)&#xA;  --color                            Colors the logging tags according to level&#xA;  -v, --verbose                      print extra info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;txt2img example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./bin/sd -m ../models/sd-v1-4.ckpt -p &#34;a lovely cat&#34;&#xA;# ./bin/sd -m ../models/v1-5-pruned-emaonly.safetensors -p &#34;a lovely cat&#34;&#xA;# ./bin/sd -m ../models/sd_xl_base_1.0.safetensors --vae ../models/sdxl_vae-fp16-fix.safetensors -H 1024 -W 1024 -p &#34;a lovely cat&#34; -v&#xA;# ./bin/sd -m ../models/sd3_medium_incl_clips_t5xxlfp16.safetensors -H 1024 -W 1024 -p &#39;a lovely cat holding a sign says \&#34;Stable Diffusion CPP\&#34;&#39; --cfg-scale 4.5 --sampling-method euler -v&#xA;# ./bin/sd --diffusion-model  ../models/flux1-dev-q3_k.gguf --vae ../models/ae.sft --clip_l ../models/clip_l.safetensors --t5xxl ../models/t5xxl_fp16.safetensors  -p &#34;a lovely cat holding a sign says &#39;flux.cpp&#39;&#34; --cfg-scale 1.0 --sampling-method euler -v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Using formats of different precisions will yield results of varying quality.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;f32&lt;/th&gt; &#xA;   &lt;th&gt;f16&lt;/th&gt; &#xA;   &lt;th&gt;q8_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_1&lt;/th&gt; &#xA;   &lt;th&gt;q4_0&lt;/th&gt; &#xA;   &lt;th&gt;q4_1&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/f32.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/f16.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q8_0.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q5_0.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q5_1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q4_0.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q4_1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;img2img example&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;./output.png&lt;/code&gt; is the image generated from the above txt2img pipeline&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;./bin/sd --mode img2img -m ../models/sd-v1-4.ckpt -p &#34;cat with blue eyes&#34; -i ./output.png -o ./img2img_output.png --strength 0.4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/img2img_output.png&#34; width=&#34;256x&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;More Guides&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/docs/lora.md&#34;&gt;LoRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/docs/lcm.md&#34;&gt;LCM/LCM-LoRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/docs/photo_maker.md&#34;&gt;Using PhotoMaker to personalize image generation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/docs/esrgan.md&#34;&gt;Using ESRGAN to upscale results&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/docs/taesd.md&#34;&gt;Using TAESD to faster decoding&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/docs/docker.md&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/docs/quantization_and_gguf.md&#34;&gt;Quantization and GGUF&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Bindings&lt;/h2&gt; &#xA;&lt;p&gt;These projects wrap &lt;code&gt;stable-diffusion.cpp&lt;/code&gt; for easier use in other languages/frameworks.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Golang: &lt;a href=&#34;https://github.com/seasonjs/stable-diffusion&#34;&gt;seasonjs/stable-diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;C#: &lt;a href=&#34;https://github.com/DarthAffe/StableDiffusion.NET&#34;&gt;DarthAffe/StableDiffusion.NET&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;UIs&lt;/h2&gt; &#xA;&lt;p&gt;These projects use &lt;code&gt;stable-diffusion.cpp&lt;/code&gt; as a backend for their image generation.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jellybox.com&#34;&gt;Jellybox&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Thank you to all the people who have already contributed to stable-diffusion.cpp!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/leejet/stable-diffusion.cpp/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=leejet/stable-diffusion.cpp&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#leejet/stable-diffusion.cpp&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=leejet/stable-diffusion.cpp&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;ggml&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;stable-diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Stability-AI/sd3-ref&#34;&gt;sd3-ref&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Stability-AI/stablediffusion&#34;&gt;stable-diffusion-stability-ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;stable-diffusion-webui&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/comfyanonymous/ComfyUI&#34;&gt;ComfyUI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crowsonkb/k-diffusion&#34;&gt;k-diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/luosiallen/latent-consistency-model&#34;&gt;latent-consistency-model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Stability-AI/generative-models/&#34;&gt;generative-models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/TencentARC/PhotoMaker&#34;&gt;PhotoMaker&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ton-blockchain/ton</title>
    <updated>2024-09-01T01:47:45Z</updated>
    <id>tag:github.com,2024-09-01:/ton-blockchain/ton</id>
    <link href="https://github.com/ton-blockchain/ton" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Main TON monorepo&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://ton.org&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://ton.org/download/ton_logo_dark_background.svg&#34;&gt; &#xA;   &lt;img alt=&#34;TON logo&#34; src=&#34;https://ton.org/download/ton_logo_light_background.svg?sanitize=true&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &#xA; &lt;h3&gt;Reference implementation of TON Node and tools&lt;/h3&gt; &#xA; &lt;hr&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://tonresear.ch&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/TON%20Research-0098EA?style=flat&amp;amp;logo=discourse&amp;amp;label=Forum&amp;amp;labelColor=gray&#34; alt=&#34;Ton Research&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://t.me/toncoin&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/TON%20Community-0098EA?logo=telegram&amp;amp;logoColor=white&amp;amp;style=flat&#34; alt=&#34;Telegram Community Group&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://t.me/tonblockchain&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/TON%20Foundation-0098EA?logo=telegram&amp;amp;logoColor=white&amp;amp;style=flat&#34; alt=&#34;Telegram Foundation Group&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://t.me/tondev_eng&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/chat-TONDev-0098EA?logo=telegram&amp;amp;logoColor=white&amp;amp;style=flat&#34; alt=&#34;Telegram Community Chat&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://twitter.com/ton_blockchain&#34;&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/ton_blockchain&#34; alt=&#34;Twitter Group&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://answers.ton.org&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/-TON%20Overflow-FE7A16?style=flat&amp;amp;logo=stack-overflow&amp;amp;logoColor=white&#34; alt=&#34;TON Overflow Group&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://stackoverflow.com/questions/tagged/ton&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/-Stack%20Overflow-FE7A16?style=flat&amp;amp;logo=stack-overflow&amp;amp;logoColor=white&#34; alt=&#34;Stack Overflow Group&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;Main TON monorepo, which includes the code of the node/validator, lite-client, tonlib, FunC compiler, etc.&lt;/p&gt; &#xA;&lt;h2&gt;The Open Network&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Open Network (TON)&lt;/strong&gt; is a fast, secure, scalable blockchain focused on handling &lt;em&gt;millions of transactions per second&lt;/em&gt; (TPS) with the goal of reaching hundreds of millions of blockchain users.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To learn more about different aspects of TON blockchain and its underlying ecosystem check &lt;a href=&#34;https://ton.org/docs&#34;&gt;documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To run node, validator or lite-server check &lt;a href=&#34;https://ton.org/docs/participate/nodes/run-node&#34;&gt;Participate section&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To develop decentralised apps check &lt;a href=&#34;https://ton.org/docs/develop/smart-contracts/&#34;&gt;Tutorials&lt;/a&gt;, &lt;a href=&#34;https://ton.org/docs/develop/func/overview&#34;&gt;FunC docs&lt;/a&gt; and &lt;a href=&#34;https://ton.org/docs/develop/dapps/&#34;&gt;DApp tutorials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To work on TON check &lt;a href=&#34;https://ton.app/wallets&#34;&gt;wallets&lt;/a&gt;, &lt;a href=&#34;https://ton.app/explorers&#34;&gt;explorers&lt;/a&gt;, &lt;a href=&#34;https://ton.app/dex&#34;&gt;DEXes&lt;/a&gt; and &lt;a href=&#34;https://ton.app/utilities&#34;&gt;utilities&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To interact with TON check &lt;a href=&#34;https://ton.org/docs/develop/dapps/apis/&#34;&gt;APIs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Updates flow&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;master branch&lt;/strong&gt; - mainnet is running on this stable branch.&lt;/p&gt; &lt;p&gt;Only emergency updates, urgent updates, or updates that do not affect the main codebase (GitHub workflows / docker images / documentation) are committed directly to this branch.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;testnet branch&lt;/strong&gt; - testnet is running on this branch. The branch contains a set of new updates. After testing, the testnet branch is merged into the master branch and then a new set of updates is added to testnet branch.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;backlog&lt;/strong&gt; - other branches that are candidates to getting into the testnet branch in the next iteration.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Usually, the response to your pull request will indicate which section it falls into.&lt;/p&gt; &#xA;&lt;h2&gt;&#34;Soft&#34; Pull Request rules&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Thou shall not merge your own PRs, at least one person should review the PR and merge it (4-eyes rule)&lt;/li&gt; &#xA; &lt;li&gt;Thou shall make sure that workflows are cleanly completed for your PR before considering merge&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Build TON blockchain&lt;/h2&gt; &#xA;&lt;h3&gt;Ubuntu 20.4, 22.04 (x86-64, aarch64)&lt;/h3&gt; &#xA;&lt;p&gt;Install additional system libraries&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  sudo apt-get update&#xA;  sudo apt-get install -y build-essential git cmake ninja-build zlib1g-dev libsecp256k1-dev libmicrohttpd-dev libsodium-dev&#xA;          &#xA;  wget https://apt.llvm.org/llvm.sh&#xA;  chmod +x llvm.sh&#xA;  sudo ./llvm.sh 16 all&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Compile TON binaries&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  cp assembly/native/build-ubuntu-shared.sh .&#xA;  chmod +x build-ubuntu-shared.sh&#xA;  ./build-ubuntu-shared.sh  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;MacOS 11, 12 (x86-64, aarch64)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  cp assembly/native/build-macos-shared.sh .&#xA;  chmod +x build-macos-shared.sh&#xA;  ./build-macos-shared.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Windows 10, 11, Server (x86-64)&lt;/h3&gt; &#xA;&lt;p&gt;You need to install &lt;code&gt;MS Visual Studio 2022&lt;/code&gt; first. Go to &lt;a href=&#34;https://www.visualstudio.com/downloads/&#34;&gt;https://www.visualstudio.com/downloads/&lt;/a&gt; and download &lt;code&gt;MS Visual Studio 2022 Community&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Launch installer and select &lt;code&gt;Desktop development with C++&lt;/code&gt;. After installation, also make sure that &lt;code&gt;cmake&lt;/code&gt; is globally available by adding &lt;code&gt;C:\Program Files\Microsoft Visual Studio\2022\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin&lt;/code&gt; to the system &lt;code&gt;PATH&lt;/code&gt; (adjust the path per your needs).&lt;/p&gt; &#xA;&lt;p&gt;Open an elevated (Run as Administrator) &lt;code&gt;x86-64 Native Tools Command Prompt for VS 2022&lt;/code&gt;, go to the root folder and execute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  copy assembly\native\build-windows.bat .&#xA;  build-windows.bat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Building TON to WebAssembly&lt;/h3&gt; &#xA;&lt;p&gt;Install additional system libraries on Ubuntu&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  sudo apt-get update&#xA;  sudo apt-get install -y build-essential git cmake ninja-build zlib1g-dev libsecp256k1-dev libmicrohttpd-dev libsodium-dev&#xA;          &#xA;  wget https://apt.llvm.org/llvm.sh&#xA;  chmod +x llvm.sh&#xA;  sudo ./llvm.sh 16 all&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Compile TON binaries with emscripten&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  cd assembly/wasm&#xA;  chmod +x fift-func-wasm-build-ubuntu.sh&#xA;  ./fift-func-wasm-build-ubuntu.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Building TON tonlib library for Android (arm64-v8a, armeabi-v7a, x86, x86-64)&lt;/h3&gt; &#xA;&lt;p&gt;Install additional system libraries on Ubuntu&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  sudo apt-get update&#xA;  sudo apt-get install -y build-essential git cmake ninja-build automake libtool texinfo autoconf libgflags-dev \&#xA;  zlib1g-dev libssl-dev libreadline-dev libmicrohttpd-dev pkg-config libgsl-dev python3 python3-dev \&#xA;  libtool autoconf libsodium-dev libsecp256k1-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Compile TON tonlib library&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  cp assembly/android/build-android-tonlib.sh .&#xA;  chmod +x build-android-tonlib.sh&#xA;  ./build-android-tonlib.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Build TON portable binaries with Nix package manager&lt;/h3&gt; &#xA;&lt;p&gt;You need to install Nix first.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;   sh &amp;lt;(curl -L https://nixos.org/nix/install) --daemon&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then compile TON with Nix by executing below command from the root folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  cp -r assembly/nix/* .&#xA;  export NIX_PATH=nixpkgs=https://github.com/nixOS/nixpkgs/archive/23.05.tar.gz&#xA;  nix-build linux-x86-64-static.nix&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More examples for other platforms can be found under &lt;code&gt;assembly/nix&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Running tests&lt;/h2&gt; &#xA;&lt;p&gt;Tests are executed by running &lt;code&gt;ctest&lt;/code&gt; in the build directory. See &lt;code&gt;doc/Tests.md&lt;/code&gt; for more information.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>amnezia-vpn/amnezia-client</title>
    <updated>2024-09-01T01:47:45Z</updated>
    <id>tag:github.com,2024-09-01:/amnezia-vpn/amnezia-client</id>
    <link href="https://github.com/amnezia-vpn/amnezia-client" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Amnezia VPN Client (Desktop+Mobile)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Amnezia VPN&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;em&gt;The best client for self-hosted VPN&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/amnezia-vpn/amnezia-client/actions/workflows/deploy.yml?query=branch:dev&#34;&gt;&lt;img src=&#34;https://github.com/amnezia-vpn/amnezia-client/actions/workflows/deploy.yml/badge.svg?branch=dev&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitpod.io/#https://github.com/amnezia-vpn/amnezia-client&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&#34; alt=&#34;Gitpod ready-to-code&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Amnezia is an open-source VPN client, with a key feature that enables you to deploy your own VPN server on your server.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/uipic4.png&#34; alt=&#34;Image&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/amnezia-vpn/amnezia-client/releases/download/4.7.0.0/AmneziaVPN_4.7.0.0_x64.exe&#34;&gt;&lt;img src=&#34;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/win.png&#34; width=&#34;150&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/amnezia-vpn/amnezia-client/releases/download/4.7.0.0/AmneziaVPN_4.7.0.0.dmg&#34;&gt;&lt;img src=&#34;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/mac.png&#34; width=&#34;150&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/amnezia-vpn/amnezia-client/releases/download/4.7.0.0/AmneziaVPN_Linux_4.7.0.0.tar.zip&#34;&gt;&lt;img src=&#34;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/lin.png&#34; width=&#34;150&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/amnezia-vpn/amnezia-client/releases/tag/4.7.0.0&#34;&gt;&lt;img src=&#34;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/andr.png&#34; width=&#34;150&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://play.google.com/store/search?q=amnezia+vpn&amp;amp;c=apps&#34;&gt;&lt;img src=&#34;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/play.png&#34; width=&#34;150&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://apps.apple.com/us/app/amneziavpn/id1600529900&#34;&gt;&lt;img src=&#34;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/apl.png&#34; width=&#34;150&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/amnezia-vpn/amnezia-client/releases&#34;&gt;All releases&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Very easy to use - enter your IP address, SSH login, password and Amnezia will automatically install VPN docker containers to your server and connect to the VPN.&lt;/li&gt; &#xA; &lt;li&gt;Classic VPN-protocols: OpenVPN, WireGuard and IKEv2 protocols.&lt;/li&gt; &#xA; &lt;li&gt;Protocols with traffic Masking (Obfuscation): OpenVPN over &lt;a href=&#34;https://github.com/cbeuw/Cloak&#34;&gt;Cloak&lt;/a&gt; plugin, Shadowsocks (OpenVPN over Shadowsocks), &lt;a href=&#34;https://docs.amnezia.org/documentation/amnezia-wg/&#34;&gt;AmneziaWG&lt;/a&gt; and XRay.&lt;/li&gt; &#xA; &lt;li&gt;Split tunneling support - add any sites to the client to enable VPN only for them or add Apps (only for Android and Desktop).&lt;/li&gt; &#xA; &lt;li&gt;Windows, MacOS, Linux, Android, iOS releases.&lt;/li&gt; &#xA; &lt;li&gt;Support for AmneziaWG protocol configuration on &lt;a href=&#34;https://docs.keenetic.com/ua/air/kn-1611/en/6319-latest-development-release.html#UUID-186c4108-5afd-c10b-f38a-cdff6c17fab3_section-idm33192196168192-improved&#34;&gt;Keenetic beta firmware&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://amnezia.org&#34;&gt;https://amnezia.org&lt;/a&gt; - project website&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/AmneziaVPN&#34;&gt;https://www.reddit.com/r/AmneziaVPN&lt;/a&gt; - Reddit&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://t.me/amnezia_vpn_en&#34;&gt;https://t.me/amnezia_vpn_en&lt;/a&gt; - Telegram support channel (English)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://t.me/amnezia_vpn_ir&#34;&gt;https://t.me/amnezia_vpn_ir&lt;/a&gt; - Telegram support channel (Farsi)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://t.me/amnezia_vpn_mm&#34;&gt;https://t.me/amnezia_vpn_mm&lt;/a&gt; - Telegram support channel (Myanmar)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://t.me/amnezia_vpn&#34;&gt;https://t.me/amnezia_vpn&lt;/a&gt; - Telegram support channel (Russian)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vpnpay.io/en/amnezia-premium/&#34;&gt;https://vpnpay.io/en/amnezia-premium/&lt;/a&gt; - Amnezia Premium&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Tech&lt;/h2&gt; &#xA;&lt;p&gt;AmneziaVPN uses several open-source projects to work:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.openssl.org/&#34;&gt;OpenSSL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openvpn.net/&#34;&gt;OpenVPN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shadowsocks.org/&#34;&gt;Shadowsocks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.qt.io/&#34;&gt;Qt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://libssh.org&#34;&gt;LibSsh&lt;/a&gt; - forked from Qt Creator&lt;/li&gt; &#xA; &lt;li&gt;and more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Checking out the source code&lt;/h2&gt; &#xA;&lt;p&gt;Make sure to pull all submodules after checking out the repo.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;Want to contribute? Welcome!&lt;/p&gt; &#xA;&lt;h3&gt;Help with translations&lt;/h3&gt; &#xA;&lt;p&gt;Download the most actual translation files.&lt;/p&gt; &#xA;&lt;p&gt;Go to &lt;a href=&#34;https://github.com/amnezia-vpn/amnezia-client/actions?query=is%3Asuccess+branch%3Adev&#34;&gt;&#34;Actions&#34; tab&lt;/a&gt;, click on the first line. Then scroll down to the &#34;Artifacts&#34; section and download &#34;AmneziaVPN_translations&#34;.&lt;/p&gt; &#xA;&lt;p&gt;Unzip this file. Each *.ts file contains strings for one corresponding language.&lt;/p&gt; &#xA;&lt;p&gt;Translate or correct some strings in one or multiple *.ts files and commit them back to this repository into the &lt;code&gt;client/translations&lt;/code&gt; folder. You can do it via a web-interface or any other method you&#39;re familiar with.&lt;/p&gt; &#xA;&lt;h3&gt;Building sources and deployment&lt;/h3&gt; &#xA;&lt;p&gt;Check deploy folder for build scripts.&lt;/p&gt; &#xA;&lt;h3&gt;How to build an iOS app from source code on MacOS&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;First, make sure you have &lt;a href=&#34;https://developer.apple.com/xcode/&#34;&gt;XCode&lt;/a&gt; installed, at least version 14 or higher.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;We use QT to generate the XCode project. We need QT version 6.6.2. Install QT for MacOS &lt;a href=&#34;https://doc.qt.io/qt-6/macos.html&#34;&gt;here&lt;/a&gt; or &lt;a href=&#34;https://www.qt.io/download-open-source&#34;&gt;QT Online Installer&lt;/a&gt;. Required modules:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;MacOS&lt;/li&gt; &#xA;   &lt;li&gt;iOS&lt;/li&gt; &#xA;   &lt;li&gt;Qt 5 Compatibility Module&lt;/li&gt; &#xA;   &lt;li&gt;Qt Shader Tools&lt;/li&gt; &#xA;   &lt;li&gt;Additional Libraries: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Qt Image Formats&lt;/li&gt; &#xA;     &lt;li&gt;Qt Multimedia&lt;/li&gt; &#xA;     &lt;li&gt;Qt Remote Objects&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install CMake if required. We recommend CMake version 3.25. You can install CMake &lt;a href=&#34;https://cmake.org/download/&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You also need to install go &amp;gt;= v1.16. If you don&#39;t have it installed already, download go from the &lt;a href=&#34;https://golang.org/dl/&#34;&gt;official website&lt;/a&gt; or use Homebrew. The latest version is recommended. Install gomobile&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PATH=$PATH:~/go/bin&#xA;go install golang.org/x/mobile/cmd/gomobile@latest&#xA;gomobile init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Build the project&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export QT_BIN_DIR=&#34;&amp;lt;PATH-TO-QT-FOLDER&amp;gt;/Qt/&amp;lt;QT-VERSION&amp;gt;/ios/bin&#34;&#xA;export QT_MACOS_ROOT_DIR=&#34;&amp;lt;PATH-TO-QT-FOLDER&amp;gt;/Qt/&amp;lt;QT-VERSION&amp;gt;/macos&#34;&#xA;export QT_IOS_BIN=$QT_BIN_DIR&#xA;export PATH=$PATH:~/go/bin&#xA;mkdir build-ios&#xA;$QT_IOS_BIN/qt-cmake . -B build-ios -GXcode -DQT_HOST_PATH=$QT_MACOS_ROOT_DIR&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Replace PATH-TO-QT-FOLDER and QT-VERSION to your environment&lt;/p&gt; &#xA;&lt;p&gt;If you get &lt;code&gt;gomobile: command not found&lt;/code&gt; make sure to set PATH to the location of the bin folder where gomobile was installed. Usually, it&#39;s in &lt;code&gt;GOPATH&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PATH=$(PATH):/path/to/GOPATH/bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Open the XCode project. You can then run /test/archive/ship the app.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If the build fails with the following error&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make: *** &#xA;[$(PROJECTDIR)/client/build/AmneziaVPN.build/Debug-iphoneos/wireguard-go-bridge/goroot/.prepared] &#xA;Error 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add a user-defined variable to both AmneziaVPN and WireGuardNetworkExtension targets&#39; build settings with key &lt;code&gt;PATH&lt;/code&gt; and value &lt;code&gt;${PATH}/path/to/bin/folder/with/go/executable&lt;/code&gt;, e.g. &lt;code&gt;${PATH}:/usr/local/go/bin&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;if the above error persists on your M1 Mac, then most probably you need to install arch based CMake&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;arch -arm64 brew install cmake&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Build might fail with the &#34;source files not found&#34; error the first time you try it, because the modern XCode build system compiles dependencies in parallel, and some dependencies end up being built after the ones that require them. In this case, simply restart the build.&lt;/p&gt; &#xA;&lt;h2&gt;How to build the Android app&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Tested on Mac OS&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Android app has the following requirements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;JDK 11&lt;/li&gt; &#xA; &lt;li&gt;Android platform SDK 33&lt;/li&gt; &#xA; &lt;li&gt;CMake 3.25.0&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;After you have installed QT, QT Creator, and Android Studio, you need to configure QT Creator correctly.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Click in the top menu bar on &lt;code&gt;QT Creator&lt;/code&gt; -&amp;gt; &lt;code&gt;Preferences&lt;/code&gt; -&amp;gt; &lt;code&gt;Devices&lt;/code&gt; and select the tab &lt;code&gt;Android&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Set path to JDK 11&lt;/li&gt; &#xA; &lt;li&gt;Set path to Android SDK (&lt;code&gt;$ANDROID_HOME&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In case you get errors regarding missing SDK or &#39;SDK manager not running&#39;, you cannot fix them by correcting the paths. If you have some spare GBs on your disk, you can let QT Creator install all requirements by choosing an empty folder for &lt;code&gt;Android SDK location&lt;/code&gt; and clicking on &lt;code&gt;Set Up SDK&lt;/code&gt;. Be aware: This will install a second Android SDK and NDK on your machine!&amp;nbsp; Double-check that the right CMake version is configured: &amp;nbsp;Click on &lt;code&gt;QT Creator&lt;/code&gt; -&amp;gt; &lt;code&gt;Preferences&lt;/code&gt; and click on the side menu on &lt;code&gt;Kits&lt;/code&gt;. Under the center content view&#39;s &lt;code&gt;Kits&lt;/code&gt; tab, you&#39;ll find an entry for &lt;code&gt;CMake Tool&lt;/code&gt;. If the default selected CMake version is lower than 3.25.0, install on your system CMake &amp;gt;= 3.25.0 and choose &lt;code&gt;System CMake at &amp;lt;path&amp;gt;&lt;/code&gt; from the drop-down list. If this entry is missing, you either have not installed CMake yet or QT Creator hasn&#39;t found the path to it. In that case, click in the preferences window on the side menu item &lt;code&gt;CMake&lt;/code&gt;, then on the tab &lt;code&gt;Tools&lt;/code&gt; in the center content view, and finally on the button &lt;code&gt;Add&lt;/code&gt; to set the path to your installed CMake.&amp;nbsp; Please make sure that you have selected Android Platform SDK 33 for your project: click in the main view&#39;s side menu on &lt;code&gt;Projects&lt;/code&gt;, and on the left, you&#39;ll see a section &lt;code&gt;Build &amp;amp; Run&lt;/code&gt; showing different Android build targets. You can select any of them, Amnezia VPN&#39;s project setup is designed in a way that all Android targets will be built. Click on the targets submenu item &lt;code&gt;Build&lt;/code&gt; and scroll in the center content view to &lt;code&gt;Build Steps&lt;/code&gt;. Click on &lt;code&gt;Details&lt;/code&gt; at the end of the headline &lt;code&gt;Build Android APK&lt;/code&gt; (the &lt;code&gt;Details&lt;/code&gt; button might be hidden in case the QT Creator Window is not running in full screen!). Here we are: Choose &lt;code&gt;android-33&lt;/code&gt; as &lt;code&gt;Android Build Platform SDK&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;That&#39;s it! You should be ready to compile the project from QT Creator!&lt;/p&gt; &#xA;&lt;h3&gt;Development flow&lt;/h3&gt; &#xA;&lt;p&gt;After you&#39;ve hit the build button, QT-Creator copies the whole project to a folder in the repository parent directory. The folder should look something like &lt;code&gt;build-amnezia-client-Android_Qt_&amp;lt;version&amp;gt;_Clang_&amp;lt;architecture&amp;gt;-&amp;lt;BuildType&amp;gt;&lt;/code&gt;. If you want to develop Amnezia VPNs Android components written in Kotlin, such as components using system APIs, you need to import the generated project in Android Studio with &lt;code&gt;build-amnezia-client-Android_Qt_&amp;lt;version&amp;gt;_Clang_&amp;lt;architecture&amp;gt;-&amp;lt;BuildType&amp;gt;/client/android-build&lt;/code&gt; as the projects root directory. While you should be able to compile the generated project from Android Studio, you cannot work directly in the repository&#39;s Android project. So whenever you are confident with your work in the generated project, you&#39;ll need to copy and paste the affected files to the corresponding path in the repository&#39;s Android project so that you can add and commit your changes!&lt;/p&gt; &#xA;&lt;p&gt;You may face compiling issues in QT Creator after you&#39;ve worked in Android Studio on the generated project. Just do a &lt;code&gt;./gradlew clean&lt;/code&gt; in the generated project&#39;s root directory (&lt;code&gt;&amp;lt;path&amp;gt;/client/android-build/.&lt;/code&gt;) and you should be good to go.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;GPL v3.0&lt;/p&gt; &#xA;&lt;h2&gt;Donate&lt;/h2&gt; &#xA;&lt;p&gt;Patreon: &lt;a href=&#34;https://www.patreon.com/amneziavpn&#34;&gt;https://www.patreon.com/amneziavpn&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Bitcoin: bc1q26eevjcg9j0wuyywd2e3uc9cs2w58lpkpjxq6p &lt;br&gt; USDT BEP20: 0x6abD576765a826f87D1D95183438f9408C901bE4 &lt;br&gt; USDT TRC20: TELAitazF1MZGmiNjTcnxDjEiH5oe7LC9d &lt;br&gt; XMR: 48spms39jt1L2L5vyw2RQW6CXD6odUd4jFu19GZcDyKKQV9U88wsJVjSbL4CfRys37jVMdoaWVPSvezCQPhHXUW5UKLqUp3&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;This project is tested with BrowserStack. We express our gratitude to &lt;a href=&#34;https://www.browserstack.com&#34;&gt;BrowserStack&lt;/a&gt; for supporting our project.&lt;/p&gt;</summary>
  </entry>
</feed>