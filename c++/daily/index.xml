<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-01T01:27:56Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Alwaysssssss/nndeploy</title>
    <updated>2023-09-01T01:27:56Z</updated>
    <id>tag:github.com,2023-09-01:/Alwaysssssss/nndeploy</id>
    <link href="https://github.com/Alwaysssssss/nndeploy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;nndeploy是一款最新上线的支持多平台、简单易用、高性能的机器学习部署框架，一套实现可在多端(云、边、端)完成模型的高性能部署。&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;介绍&lt;/h2&gt; &#xA;&lt;p&gt;nndeploy是一款最新上线的支持多平台、简单易用、高性能的机器学习部署框架，一套实现可在多端(云、边、端)完成模型的高性能部署。&lt;/p&gt; &#xA;&lt;p&gt;作为一个多平台模型部署工具，我们的框架最大的宗旨就是简单贴心(^‹^)，目前nndeploy已接入TensorRT、MNN、OpenVINO、ONNXRuntime、TNN五个业界知名的推理框架，后续会继续接入NCNN、tf-lite、paddle-lite、coreML，在我们的框架下可使用一套代码轻松切换不同的推理后端进行推理，且不用担心部署框架对推理框架的抽象而带来的性能损失。&lt;/p&gt; &#xA;&lt;p&gt;如果您需要部署自己的模型，目前nndeploy可帮助您在一个文件（大概只要200行代码）之内完成多端部署，提供了一些的前后处理和推理模板可供选择帮助您简化流程；如果只需使用已有主流模型进行自己的推理，目前nndeploy已完成YOLO系列等多个开源模型的部署，可供直接使用，目前我们还在积极部署其它开源模型（如果您或团队有需要部署的开源模型或者其他部署相关的问题，欢迎随时来和我们探讨(^-^)）&lt;/p&gt; &#xA;&lt;h2&gt;架构简介&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Alwaysssssss/nndeploy/main/doc/image/%E6%9E%B6%E6%9E%84.jpg&#34; alt=&#34;架构简介&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;注：白色部分为相关功能正在开发验证中，即将上线&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;能力展示&lt;/h2&gt; &#xA;&lt;p&gt;nndeploy具有如下优势特性：&lt;/p&gt; &#xA;&lt;h3&gt;支持多平台&lt;/h3&gt; &#xA;&lt;p&gt;支持的平台和推理框架如下表所示&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;OS/Inference&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Linux&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Windows&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Android&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MacOS&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;iOS&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;开发人员&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;备注&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/NVIDIA/TensorRT&#34;&gt;TensorRT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Alwaysssssss&#34;&gt;Always&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino&#34;&gt;OpenVINO&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Alwaysssssss&#34;&gt;Always&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/microsoft/onnxruntime&#34;&gt;ONNXRuntime&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Alwaysssssss&#34;&gt;Always&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/alibaba/MNN&#34;&gt;MNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Alwaysssssss&#34;&gt;Always&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/TNN&#34;&gt;TNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;no&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/02200059Z&#34;&gt;02200059Z&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;code&gt;注: yes：完成在该平台的验证，no：目前正在验证中&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;直接可用的算法&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;算法&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Inference&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;开发人员&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;备注&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ultralytics/yolov5&#34;&gt;YOLOV5&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TensorRt/OpenVINO/ONNXRuntime/MNN&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/02200059Z&#34;&gt;02200059Z&lt;/a&gt;、&lt;a href=&#34;https://github.com/Alwaysssssss&#34;&gt;Always&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/meituan/YOLOv6&#34;&gt;YOLOV6&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TensorRt/OpenVINO/ONNXRuntime&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/02200059Z&#34;&gt;02200059Z&lt;/a&gt;、&lt;a href=&#34;https://github.com/Alwaysssssss&#34;&gt;Always&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ultralytics&#34;&gt;YOLOV8&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TensorRt/OpenVINO/ONNXRuntime/MNN&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/02200059Z&#34;&gt;02200059Z&lt;/a&gt;、&lt;a href=&#34;https://github.com/Alwaysssssss&#34;&gt;Always&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;简单易用&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;通过切换推理配置，一套代码可在多端部署，算法的使用接口简单易用&lt;/li&gt; &#xA; &lt;li&gt;新增算法简单，将AI算法部署抽象为有向无环图Pipeline，前处理为一个任务Task，推理也为一个任务Task，后处理也为一个任务Task，也可以将多个Pipeline组合成一个新的Pipeline&lt;/li&gt; &#xA; &lt;li&gt;通用的推理模板和前后处理模板&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;高性能&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;可配置推理框架所有参数，不会因为对推理框架的抽象而带来性能损失&lt;/li&gt; &#xA; &lt;li&gt;可直接操作理框架内部分配的输入输出，实现前后处理的零拷贝，目前正在不断完善不同格式的Tensor的零拷贝&lt;/li&gt; &#xA; &lt;li&gt;线程池正在开发完善中，可实现多任务流水线并行&lt;/li&gt; &#xA; &lt;li&gt;一组高性能的算子正在开发中，完成后将加速你模型前后处理速度&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;快速开始&lt;/h2&gt; &#xA;&lt;h3&gt;使用demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Alwaysssssss/nndeploy/main/demo%5Cdetect%5Cdemo.cc&#34;&gt;以检测模型demo为例&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;创建检测模型有向无环图pipeline &lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;// 检测模型的有向无环图pipeline名称，例如:&#xA;// NNDEPLOY_YOLOV5/NNDEPLOY_YOLOV6/NNDEPLOY_YOLOV8&#xA;std::string name = demo::getName();&#xA;// 推理后端类型，例如:&#xA;// kInferenceTypeOpenVino/kInferenceTypeTensorRt/kInferenceTypeOnnxRuntime/...&#xA;base::InferenceType inference_type = demo::getInferenceType();&#xA;// 推理设备类型，例如:&#xA;// kDeviceTypeCodeX86:0/kDeviceTypeCodeCuda:0/...&#xA;base::DeviceType device_type = demo::getDeviceType();&#xA;// 模型类型，例如:&#xA;// kModelTypeOnnx/kModelTypeMnn/...&#xA;base::ModelType model_type = demo::getModelType();&#xA;// 模型是否是路径&#xA;bool is_path = demo::isPath();&#xA;// 模型路径或者模型字符串&#xA;std::vector&amp;lt;std::string&amp;gt; model_value = demo::getModelValue();&#xA;// 有向无环图pipeline的输入边packert&#xA;model::Packet input(&#34;detect_in&#34;);&#xA;// 有向无环图pipeline的输出边packert&#xA;model::Packet output(&#34;detect_out&#34;);&#xA;// 创建检测模型有向无环图pipeline&#xA;model::Pipeline *pipeline =&#xA;    model::createPipeline(name, inference_type, device_type, &amp;amp;input, &amp;amp;output,&#xA;                          model_type, is_path, model_value);&#xA;if (pipeline == nullptr) {&#xA;  NNDEPLOY_LOGE(&#34;pipeline is nullptr&#34;);&#xA;  return -1;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;初始化有向无环图pipeline &lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;base::Status status = pipeline-&amp;gt;init();&#xA;if (status != base::kStatusCodeOk) {&#xA;  NNDEPLOY_LOGE(&#34;pipeline init failed&#34;);&#xA;  return -1;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;给有向无环图pipeline写入输入边输出边 &lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;// 有向无环图pipeline的输入图片路径&#xA;std::string input_path = demo::getInputPath();&#xA;// opencv读图&#xA;cv::Mat input_mat = cv::imread(input_path);&#xA;// 将图片写入有向无环图pipeline输入边&#xA;input.set(input_mat);&#xA;// 定义有向无环图pipeline的输出结果&#xA;model::DetectResult result;&#xA;// 将输出结果写入有向无环图pipeline输出边&#xA;output.set(result);&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;有向无环图pipeline运行 &lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;status = pipeline-&amp;gt;run();&#xA;if (status != base::kStatusCodeOk) {&#xA;  NNDEPLOY_LOGE(&#34;pipeline run failed&#34;);&#xA;  return -1;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;有向无环图pipeline反初始化 &lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;status = pipeline-&amp;gt;deinit();&#xA;if (status != base::kStatusCodeOk) {&#xA;  NNDEPLOY_LOGE(&#34;pipeline deinit failed&#34;);&#xA;  return -1;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;有向无环图pipeline销毁 &lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;delete pipeline;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;部署模型&lt;/h3&gt; &#xA;&lt;p&gt;以YOLOV5为例。&lt;a href=&#34;https://raw.githubusercontent.com/Alwaysssssss/nndeploy/main/source%5Cnndeploy%5Cmodel%5Cdetect%5Cyolo%5Cyolo.cc&#34;&gt;源文件&lt;/a&gt;，&lt;a href=&#34;https://raw.githubusercontent.com/Alwaysssssss/nndeploy/main/include%5Cnndeploy%5Cmodel%5Cdetect%5Cyolo%5Cyolo.h&#34;&gt;头文件&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;准备模型文件&lt;/li&gt; &#xA; &lt;li&gt;搭建模型部署的有向无环图 &lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;model::Pipeline* createYoloV5Pipeline(const std::string&amp;amp; name,&#xA;                                    base::InferenceType inference_type,&#xA;                                    base::DeviceType device_type,&#xA;                                    Packet* input, Packet* output,&#xA;                                    base::ModelType model_type, bool is_path,&#xA;                                    std::vector&amp;lt;std::string&amp;gt;&amp;amp; model_value) {&#xA;  model::Pipeline* pipeline = new model::Pipeline(name, input, output); // 有向无环图&#xA;  model::Packet* infer_input = pipeline-&amp;gt;createPacket(&#34;infer_input&#34;); // infer任务的输入&#xA;  model::Packet* infer_output = pipeline-&amp;gt;createPacket(&#34;infer_output&#34;); // infer任务的输出&#xA;  // YOLOV5模型前处理任务model::CvtColrResize，输入边为input，输出边为infer_input&#xA;  model::Task* pre = pipeline-&amp;gt;createTask&amp;lt;model::CvtColrResize&amp;gt;(&#xA;      &#34;preprocess&#34;, input, infer_input);&#xA;  // YOLOV5模型推理任务model::Infer(通用模板)，输入边为infer_input，输出边为infer_output&#xA;  model::Task* infer = pipeline-&amp;gt;createInfer&amp;lt;model::Infer&amp;gt;(&#xA;      &#34;infer&#34;, inference_type, infer_input, infer_output);&#xA;  // YOLOV5模型后处理任务YoloPostProcess，输入边为infer_output，输出边为output&#xA;  model::Task* post = pipeline-&amp;gt;createTask&amp;lt;YoloPostProcess&amp;gt;(&#xA;      &#34;postprocess&#34;, infer_output, output);&#xA;  // YOLOV5模型前处理任务pre的参数配置&#xA;  model::CvtclorResizeParam* pre_param =&#xA;      dynamic_cast&amp;lt;model::CvtclorResizeParam*&amp;gt;(pre-&amp;gt;getParam());&#xA;  pre_param-&amp;gt;src_pixel_type_ = base::kPixelTypeBGR;&#xA;  pre_param-&amp;gt;dst_pixel_type_ = base::kPixelTypeRGB;&#xA;  pre_param-&amp;gt;interp_type_ = base::kInterpTypeLinear;&#xA;  // YOLOV5模型推理任务infer的参数配置&#xA;  inference::InferenceParam* inference_param =&#xA;      (inference::InferenceParam*)(infer-&amp;gt;getParam());&#xA;  inference_param-&amp;gt;is_path_ = is_path;&#xA;  inference_param-&amp;gt;model_value_ = model_value;&#xA;  inference_param-&amp;gt;device_type_ = device_type;&#xA;&#xA;  // YOLOV5模型后处理任务post的参数配置&#xA;  YoloPostParam* post_param = dynamic_cast&amp;lt;YoloPostParam*&amp;gt;(post-&amp;gt;getParam());&#xA;  post_param-&amp;gt;score_threshold_ = 0.5;&#xA;  post_param-&amp;gt;nms_threshold_ = 0.45;&#xA;  post_param-&amp;gt;num_classes_ = 80;&#xA;  post_param-&amp;gt;model_h_ = 640;&#xA;  post_param-&amp;gt;model_w_ = 640;&#xA;  post_param-&amp;gt;version_ = 5;&#xA;&#xA;  return pipeline;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;code&gt;注：前后处理任务有时候需要自己写&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;注册createYoloV5Pipeline &lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#define NNDEPLOY_YOLOV5 &#34;NNDEPLOY_YOLOV5&#34;&#xA;class TypePipelineRegister g_register_yolov5_pipeline(NNDEPLOY_YOLOV5,&#xA;                                                  createYoloV5Pipeline);&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;编译&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;在根目录创建&lt;code&gt;build&lt;/code&gt;目录，将&lt;code&gt;cmake/config.cmake&lt;/code&gt;复制到该目录 &lt;pre&gt;&lt;code&gt;mkdir build&#xA;cp cmake/config.cmake build&#xA;cd build&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;编辑&lt;code&gt;build/config.cmake&lt;/code&gt;来定制编译选项 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;将&lt;code&gt;set(ENABLE_NNDEPLOY_OPENCV OFF)&lt;/code&gt;改为&lt;code&gt;set(ENABLE_NNDEPLOY_OPENCV PATH/linux/OpenCV)&lt;/code&gt;，&lt;code&gt;nndeploy&lt;/code&gt;会启用并链接&lt;code&gt;OpenCV&lt;/code&gt;，如果你想启用并链接的其他第三方库，也是做同样的处理&lt;/li&gt; &#xA;   &lt;li&gt;将&lt;code&gt;set(ENABLE_NNDEPLOY_DEVICE_CPU OFF)&lt;/code&gt;改为&lt;code&gt;set(ENABLE_NNDEPLOY_DEVICE_CPU ON)&lt;/code&gt;，&lt;code&gt;nndeploy&lt;/code&gt;会启用&lt;code&gt;CPU&lt;/code&gt;设备。如果你想启用其他设备（ARM、X86、CUDA …），也是做同样的处理&lt;/li&gt; &#xA;   &lt;li&gt;将&lt;code&gt;set(ENABLE_NNDEPLOY_INFERENCE_ONNXRUNTIME OFF)&lt;/code&gt;改为&lt;code&gt;set(ENABLE_NNDEPLOY_INFERENCE_ONNXRUNTIME &#34;PATH/linux/onnxruntime-linux-x64-1.15.1&#34;)&lt;/code&gt;，&lt;code&gt;nndeploy&lt;/code&gt;会启用并链接推理后端&lt;code&gt;ONNXRuntime&lt;/code&gt;。如果你想启用并链接其他推理后端（OpenVINO、TensorRT、TNN …），也是做同样的处理&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;启用并链接第三方库有两种选择&lt;/code&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;开关&lt;code&gt;ON&lt;/code&gt; - 当你安装了该库，并且可以通过find_package找到该库，可以采用该方式，例如CUDA、CUDNN、OpenCV、TenosrRT&lt;/li&gt; &#xA;     &lt;li&gt;路径&lt;code&gt;PATH&lt;/code&gt; - 头文件以及库的根路径，其形式必须为 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;头文件：&lt;code&gt;PATH/include&lt;/code&gt;&lt;/li&gt; &#xA;       &lt;li&gt;库：&lt;code&gt;PATH/lib &lt;/code&gt;&lt;/li&gt; &#xA;       &lt;li&gt;windows dll: &lt;code&gt;PATH/bin&lt;/code&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;开始&lt;code&gt;make nndeploy&lt;/code&gt;库 &lt;pre&gt;&lt;code&gt;cmake ..&#xA;make -j4&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;安装，将nndeploy相关库可执行文件、第三方库安装至&lt;code&gt;build/install/lib&lt;/code&gt; &lt;pre&gt;&lt;code&gt;make install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;第三方库&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;第三方库&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;主版本&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;编译文档&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;官方库下载链接&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;备注&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/opencv/opencv&#34;&gt;opencv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.8.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://opencv.org/get-started/&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://opencv.org/get-started/&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/NVIDIA/TensorRT&#34;&gt;TensorRT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.6.0.12&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://developer.nvidia.com/zh-cn/tensorrt&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;支持TensorRT 7、支持jetson-orin-nano&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino&#34;&gt;OpenVINO&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023.0.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/raw/master/docs/dev/build.md&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/download.html?ENVIRONMENT=RUNTIME&amp;amp;OP_SYSTEM=MACOS&amp;amp;VERSION=v_2023_0_1&amp;amp;DISTRIBUTION=ARCHIVE&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/microsoft/onnxruntime&#34;&gt;ONNXRuntime&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;v1.15.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/DefTruth/lite.ai.toolkit/raw/main/docs/ort/ort_useful_api.zh.md&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/microsoft/onnxruntime/releases/tag/v1.15.1&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/alibaba/MNN&#34;&gt;MNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.6.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://mnn-docs.readthedocs.io/en/latest/compile/engine.html&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/alibaba/MNN/releases/tag/2.6.0&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/TNN&#34;&gt;TNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;v0.3.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/TNN/raw/master/doc/cn/user/compile.md&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/TNN/releases/tag/v0.3.0&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;补充说明 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;我使用第三方库的上述版本，通常使用其他版本的也没有问题&lt;/li&gt; &#xA;   &lt;li&gt;TensorRT &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/476679322&#34;&gt;Windows链接&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;安装前请确保 显卡驱动、cuda、cudnn均已安装且版本一致&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;资源仓库&lt;/h2&gt; &#xA;&lt;p&gt;我们将部分已验证模型、第三方库、测试数据放在&lt;a href=&#34;https://huggingface.co/alwaysssss/nndeploy&#34;&gt;HuggingFace&lt;/a&gt;上，如果您有需要可以去下载，&lt;code&gt;但强烈建议您自己去管理自己的模型仓库、第三方库、测试数据&lt;/code&gt;。&lt;/p&gt; &#xA;&lt;h2&gt;参考&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/TNN&#34;&gt;TNN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/FastDeploy&#34;&gt;FastDeploy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/opencv/opencv&#34;&gt;opencv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ChunelFeng/CGraph&#34;&gt;CGraph&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/apache/tvm&#34;&gt;tvm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdeploy&#34;&gt;mmdeploy&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;加入我们&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;欢迎大家参与，一起打造最简单易用、高性能的机器学习部署框架&lt;/li&gt; &#xA; &lt;li&gt;微信：titian5566，备注：nndeploy&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; src=&#34;https://raw.githubusercontent.com/Alwaysssssss/nndeploy/main/doc/image/Always.jpg&#34; width=&#34;512px&#34;&gt;</summary>
  </entry>
</feed>