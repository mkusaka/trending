<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-20T01:30:31Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>nomic-ai/gpt4all-chat</title>
    <updated>2023-04-20T01:30:31Z</updated>
    <id>tag:github.com,2023-04-20:/nomic-ai/gpt4all-chat</id>
    <link href="https://github.com/nomic-ai/gpt4all-chat" rel="alternate"></link>
    <summary type="html">&lt;p&gt;gpt4all-j chat&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;gpt4all-chat&lt;/h1&gt; &#xA;&lt;p&gt;Cross platform Qt based GUI for GPT4All versions with GPT-J as the base model. NOTE: The model seen in the screenshot is actually a preview of a new training run for GPT4All based on GPT-J. The GPT4All project is busy at work getting ready to release this model including installers for all three major OS&#39;s. In the meantime, you can try this UI out with the original GPT-J model by following build instructions below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/50458173/231464085-da9edff6-a593-410e-8f38-7513f75c8aab.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cross-platform (Linux, Windows, MacOSX)&lt;/li&gt; &#xA; &lt;li&gt;Fast CPU based inference using ggml for GPT-J based models&lt;/li&gt; &#xA; &lt;li&gt;The UI is made to look and feel like you&#39;ve come to expect from a chatty gpt&lt;/li&gt; &#xA; &lt;li&gt;Check for updates so you can alway stay fresh with latest models&lt;/li&gt; &#xA; &lt;li&gt;Easy to install with precompiled binaries available for all three major desktop platforms&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Feature wishlist&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Multi-chat - a list of current and past chats and the ability to save/delete/export and switch between&lt;/li&gt; &#xA; &lt;li&gt;Text to speech - have the AI response with voice&lt;/li&gt; &#xA; &lt;li&gt;Speech to text - give the prompt with your voice&lt;/li&gt; &#xA; &lt;li&gt;Multi-modal - Ability to load more than one model and switch between them&lt;/li&gt; &#xA; &lt;li&gt;Python bindings&lt;/li&gt; &#xA; &lt;li&gt;Typescript bindings&lt;/li&gt; &#xA; &lt;li&gt;Plugin support for langchain other developer tools&lt;/li&gt; &#xA; &lt;li&gt;Save your prompt/responses to disk&lt;/li&gt; &#xA; &lt;li&gt;Upload prompt/respones manually/automatically to nomic.ai to aid future training runs&lt;/li&gt; &#xA; &lt;li&gt;Syntax highlighting support for programming languages, etc.&lt;/li&gt; &#xA; &lt;li&gt;REST API with a built-in webserver in the chat gui itself with a headless operation mode as well&lt;/li&gt; &#xA; &lt;li&gt;Advanced settings for changing temperature, topk, etc. (DONE)&lt;/li&gt; &#xA; &lt;li&gt;YOUR IDEA HERE&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building and running&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install Qt 6.x for your platform &lt;a href=&#34;https://doc.qt.io/qt-6/get-and-install-qt.html&#34;&gt;https://doc.qt.io/qt-6/get-and-install-qt.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install cmake for your platform &lt;a href=&#34;https://cmake.org/install/&#34;&gt;https://cmake.org/install/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Download &lt;a href=&#34;https://huggingface.co/EleutherAI/gpt-j-6b&#34;&gt;https://huggingface.co/EleutherAI/gpt-j-6b&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Clone this repo and build&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone --recurse-submodules https://github.com/nomic-ai/gpt4all-chat&#xA;cd gpt4all-chat&#xA;mkdir build&#xA;cd build&#xA;cmake ..&#xA;cmake --build . --parallel&#xA;python3 ../ggml/examples/gpt-j/convert-h5-to-ggml.py /path/to/your/local/copy/of/EleutherAI/gpt-j-6B 0&#xA;./bin/gpt-j-quantize /path/to/your/local/copy/of/EleutherAI/gpt-j-6B/ggml-model-f32.bin ./ggml-model-q4_0.bin 2&#xA;./chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Building and running CLI tools only (no Qt required)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install cmake for your platform &lt;a href=&#34;https://cmake.org/install/&#34;&gt;https://cmake.org/install/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Clone this repo and build the &lt;code&gt;ggml&lt;/code&gt; subfolder&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone --recurse-submodules https://github.com/nomic-ai/gpt4all-chat&#xA;cd gpt4all-chat/ggml&#xA;mkdir build&#xA;cd build&#xA;cmake ..&#xA;cmake --build . --parallel&#xA;wget https://gpt4all.io/models/ggml-gpt4all-j.bin # Download GGML model if required&#xA;./bin/gpt-j -m ggml-gpt4all-j.bin -n 200 --top_k 40 --top_p 0.9 -b 9 --temp 0.9 -p &#34;Below is an instruction that describes a task. Write a response that appropriately completes the request.&#xA;### Instruction:&#xA;Tell me about artifical intelligence&#xA;### Response:&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;To get Qt installed for your system&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Highly advise using the official Qt online open source installer.&lt;/li&gt; &#xA; &lt;li&gt;You can obtain this by creating an account on qt.io and downloading the installer.&lt;/li&gt; &#xA; &lt;li&gt;You should get latest Qt {Qt 6.5.x} for your system and the developer tools including QtCreator, cmake, ninja.&lt;/li&gt; &#xA; &lt;li&gt;WINDOWS NOTE: you need to use the mingw64 toolchain and not msvc&lt;/li&gt; &#xA; &lt;li&gt;ALL PLATFORMS NOTE: the installer has options for lots of different targets which will add a lot of download overhead. You can deselect webassembly target, android, sources, etc to save space on your disk.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pull requests welcome. See the feature wish list for ideas :)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The source code of this chat interface is currently under a MIT license. The underlying GPT4All-j model is released under non-restrictive open-source Apache 2 License.&lt;/p&gt; &#xA;&lt;p&gt;The GPT4All-J license allows for users to use generated outputs as they see fit. Users take responsibility for ensuring their content meets applicable requirements for publication in a given context or region.&lt;/p&gt;</summary>
  </entry>
</feed>