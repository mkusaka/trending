<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-12T01:31:06Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>openxla/xla</title>
    <updated>2023-03-12T01:31:06Z</updated>
    <id>tag:github.com,2023-03-12:/openxla/xla</id>
    <link href="https://github.com/openxla/xla" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A machine learning compiler for GPUs, CPUs, and ML accelerators&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;XLA&lt;/h1&gt; &#xA;&lt;p&gt;XLA (Accelerated Linear Algebra) is an open-source machine learning (ML) compiler for GPUs, CPUs, and ML accelerators.&lt;/p&gt; &#xA;&lt;p&gt;The XLA compiler takes models from popular ML frameworks such as PyTorch, TensorFlow, and JAX, and optimizes them for high-performance execution across different hardware platforms including GPUs, CPUs, and ML accelerators.&lt;/p&gt; &#xA;&lt;h2&gt;Get started&lt;/h2&gt; &#xA;&lt;p&gt;If you want to use XLA to compile your ML project, refer to the corresponding documentation for your ML framework:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pytorch.org/xla&#34;&gt;PyTorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/xla&#34;&gt;TensorFlow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jax.readthedocs.io/en/latest/notebooks/quickstart.html&#34;&gt;JAX&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you&#39;re not contributing code to the XLA compiler, you don&#39;t need to clone and build this repo. Everything here is intended for XLA contributors who want to develop the compiler and XLA integrators who want to debug or add support for ML frontends and hardware backends.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s how you can start developing in the XLA compiler:&lt;/p&gt; &#xA;&lt;p&gt;To build XLA, you will need to install &lt;a href=&#34;https://bazel.build/install&#34;&gt;Bazel&lt;/a&gt;. &lt;a href=&#34;https://github.com/bazelbuild/bazelisk#readme&#34;&gt;Bazelisk&lt;/a&gt; is an easy way to install Bazel and automatically downloads the correct Bazel version for XLA. If Bazelisk is unavailable, you can manually install Bazel instead.&lt;/p&gt; &#xA;&lt;p&gt;Clone this repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/openxla/xla &amp;amp;&amp;amp; cd xla&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We recommend using a suitable docker container to build/test XLA, such as &lt;a href=&#34;https://www.tensorflow.org/install/docker&#34;&gt;TensorFlow&#39;s docker container&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --name xla -w /xla -it -d --rm -v $PWD:/xla tensorflow/build:latest-python3.9 bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run an end to end test using an example StableHLO module:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker exec xla ./configure&#xA;docker exec xla bazel test xla/examples/axpy:stablehlo_compile_test --nocheck_visibility --test_output=all&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will take quite a while your first time because it must build the entire stack, including MLIR, StableHLO, XLA, and more.&lt;/p&gt; &#xA;&lt;p&gt;When it&#39;s done, you should see output like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;==================== Test output for //xla/examples/axpy:stablehlo_compile_test:&#xA;[==========] Running 1 test from 1 test suite.&#xA;[----------] Global test environment set-up.&#xA;[----------] 1 test from StableHloAxpyTest&#xA;[ RUN      ] StableHloAxpyTest.LoadAndRunCpuExecutable&#xA;Loaded StableHLO program from xla/examples/axpy/stablehlo_axpy.mlir:&#xA;func.func @main(&#xA;  %alpha: tensor&amp;lt;f32&amp;gt;, %x: tensor&amp;lt;4xf32&amp;gt;, %y: tensor&amp;lt;4xf32&amp;gt;&#xA;) -&amp;gt; tensor&amp;lt;4xf32&amp;gt; {&#xA;  %0 = stablehlo.broadcast_in_dim %alpha, dims = []&#xA;    : (tensor&amp;lt;f32&amp;gt;) -&amp;gt; tensor&amp;lt;4xf32&amp;gt;&#xA;  %1 = stablehlo.multiply %0, %x : tensor&amp;lt;4xf32&amp;gt;&#xA;  %2 = stablehlo.add %1, %y : tensor&amp;lt;4xf32&amp;gt;&#xA;  func.return %2: tensor&amp;lt;4xf32&amp;gt;&#xA;}&#xA;&#xA;Computation inputs:&#xA;        alpha:f32[] 3.14&#xA;        x:f32[4] {1, 2, 3, 4}&#xA;        y:f32[4] {10.5, 20.5, 30.5, 40.5}&#xA;Computation output: f32[4] {13.64, 26.78, 39.920002, 53.06}&#xA;[       OK ] StableHloAxpyTest.LoadAndRunCpuExecutable (264 ms)&#xA;[----------] 1 test from StableHloAxpyTest (264 ms total)&#xA;&#xA;[----------] Global test environment tear-down&#xA;[==========] 1 test from 1 test suite ran. (264 ms total)&#xA;[  PASSED  ] 1 test.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openxla/xla/main/docs/build_from_source.md&#34;&gt;This document contains more information about how to build XLA.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contacts&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For questions, contact Thea Lamkin - thealamkin at google.com.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GitHub (&lt;a href=&#34;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/xla&#34;&gt;current&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openxla/community&#34;&gt;Community Resources&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;While under TensorFlow governance, all community spaces for SIG OpenXLA are subject to the &lt;a href=&#34;https://github.com/tensorflow/tensorflow/raw/master/CODE_OF_CONDUCT.md&#34;&gt;TensorFlow Code of Conduct&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>openxla/iree</title>
    <updated>2023-03-12T01:31:06Z</updated>
    <id>tag:github.com,2023-03-12:/openxla/iree</id>
    <link href="https://github.com/openxla/iree" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A retargetable MLIR-based machine learning compiler and runtime toolkit.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;IREE: Intermediate Representation Execution Environment&lt;/h1&gt; &#xA;&lt;p&gt;IREE (&lt;strong&gt;I&lt;/strong&gt;ntermediate &lt;strong&gt;R&lt;/strong&gt;epresentation &lt;strong&gt;E&lt;/strong&gt;xecution &lt;strong&gt;E&lt;/strong&gt;nvironment, pronounced as &#34;eerie&#34;) is an &lt;a href=&#34;https://mlir.llvm.org/&#34;&gt;MLIR&lt;/a&gt;-based end-to-end compiler and runtime that lowers Machine Learning (ML) models to a unified IR that scales up to meet the needs of the datacenter and down to satisfy the constraints and special considerations of mobile and edge deployments.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://openxla.github.io/iree/&#34;&gt;our website&lt;/a&gt; for project details, user guides, and instructions on building from source.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/openxla/iree/actions/workflows/ci.yml?query=branch%3Amain+event%3Apush&#34;&gt;&lt;img src=&#34;https://github.com/openxla/iree/actions/workflows/ci.yml/badge.svg?query=branch%3Amain+event%3Apush&#34; alt=&#34;CI Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Project Status&lt;/h4&gt; &#xA;&lt;p&gt;IREE is still in its early phase. We have settled down on the overarching infrastructure and are actively improving various software components as well as project logistics. It is still quite far from ready for everyday use and is made available without any support at the moment. With that said, we welcome any kind of feedback on any &lt;a href=&#34;https://raw.githubusercontent.com/openxla/iree/main/#communication-channels&#34;&gt;communication channels&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Communication Channels&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openxla/iree/issues&#34;&gt;GitHub issues&lt;/a&gt;: Feature requests, bugs, and other work tracking&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/26P4xW4&#34;&gt;IREE Discord server&lt;/a&gt;: Daily development discussions with the core team and collaborators&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/iree-discuss&#34;&gt;iree-discuss email list&lt;/a&gt;: Announcements, general and low-priority discussion&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Related Project Channels&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://llvm.discourse.group/c/llvm-project/mlir/31&#34;&gt;MLIR topic within LLVM Discourse&lt;/a&gt;: IREE is enabled by and heavily relies on &lt;a href=&#34;https://mlir.llvm.org&#34;&gt;MLIR&lt;/a&gt;. IREE sometimes is referred to in certain MLIR discussions. Useful if you are also interested in MLIR evolution.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Architecture Overview&lt;/h2&gt; &#xA;&lt;!-- TODO(scotttodd): switch to &lt;picture&gt; once better supported? https://github.blog/changelog/2022-05-19-specify-theme-context-for-images-in-markdown-beta/ --&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/openxla/iree/main/docs/website/docs/assets/images/iree_architecture_dark.svg#gh-dark-mode-only&#34; alt=&#34;IREE Architecture&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/openxla/iree/main/docs/website/docs/assets/images/iree_architecture.svg#gh-light-mode-only&#34; alt=&#34;IREE Architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://openxla.github.io/iree/&#34;&gt;our website&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Presentations and Talks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2021-06-09: IREE Runtime Design Tech Talk (&lt;a href=&#34;https://drive.google.com/file/d/1p0DcysaIg8rC7ErKYEgutQkOJGPFCU3s/view&#34;&gt;recording&lt;/a&gt; and &lt;a href=&#34;https://drive.google.com/file/d/1ikgOdZxnMz1ExqwrAiuTY9exbe3yMWbB/view?usp=sharing&#34;&gt;slides&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;2020-08-20: IREE CodeGen: MLIR Open Design Meeting Presentation (&lt;a href=&#34;https://drive.google.com/file/d/1325zKXnNIXGw3cdWrDWJ1-bp952wvC6W/view?usp=sharing&#34;&gt;recording&lt;/a&gt; and &lt;a href=&#34;https://docs.google.com/presentation/d/1NetHjKAOYg49KixY5tELqFp6Zr2v8_ujGzWZ_3xvqC8/edit&#34;&gt;slides&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;2020-03-18: Interactive HAL IR Walkthrough (&lt;a href=&#34;https://drive.google.com/file/d/1_sWDgAPDfrGQZdxAapSA90AD1jVfhp-f/view?usp=sharing&#34;&gt;recording&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;2020-01-31: End-to-end MLIR Workflow in IREE: MLIR Open Design Meeting Presentation (&lt;a href=&#34;https://drive.google.com/open?id=1os9FaPodPI59uj7JJI3aXnTzkuttuVkR&#34;&gt;recording&lt;/a&gt; and &lt;a href=&#34;https://drive.google.com/open?id=1RCQ4ZPQFK9cVgu3IH1e5xbrBcqy7d_cEZ578j84OvYI&#34;&gt;slides&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;IREE is licensed under the terms of the Apache 2.0 License with LLVM Exceptions. See &lt;a href=&#34;https://raw.githubusercontent.com/openxla/iree/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>NaruseMioShirakana/MoeSS</title>
    <updated>2023-03-12T01:31:06Z</updated>
    <id>tag:github.com,2023-03-12:/NaruseMioShirakana/MoeSS</id>
    <link href="https://github.com/NaruseMioShirakana/MoeSS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;使用C++ OnnxRuntime 重构了Tacotron2、VITS、SoVIts、DiffSvc和DiffSinger推理的集成UI软件&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NaruseMioShirakana/MoeSS/V2/README.md&#34;&gt;简体中文&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/NaruseMioShirakana/MoeSS/V2/README_en.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;强调&lt;/h1&gt; &#xA;&lt;p&gt;使用GPU（CUDA）版本的MoeSS或者工具箱，请安装12.0以下，11.0版本以上的CUDA驱动程序，83.0版本以下的CUDNN动态库，并按照网上的教程安装。&lt;/p&gt; &#xA;&lt;p&gt;为什么有这样的要求？那就得问CUDA，CUDNN背后的英伟达公司以及OnnxRuntime的官方了，这两个问题都是由CUDA驱动的一些特性和OnnxRuntime的一些问题引起的。&lt;/p&gt; &#xA;&lt;p&gt;MoeSS和工具箱之前的版本不支持中文路径是什么原因？实际上就是上述问题的体现。MoeSS和工具箱的本体是支持中文路径的，不过它底层的OnnxRuntime是不支持中文路径的，因为Windows版本的OnnxRuntime使用了Win32Api的A系列函数，A系列函数都是不支持非ANSI编码的路径的。这个问题并不是我能够解决的也不是我应该解决的，只有OnnxRuntime官方修复了这个BUG才可以解决，不过好在最新的OnnxRuntime使用了W系列函数，解决了中文路径的这个问题。&lt;/p&gt; &#xA;&lt;p&gt;模型加载时候遇到弹窗报错，就是由于上述问题引起（主要是没有安装或者没有按照要求安装CUDA和CUDNN），如果引发了这些问题，可以前往&lt;a href=&#34;https://github.com/microsoft/onnxruntime&#34;&gt;https://github.com/microsoft/onnxruntime&lt;/a&gt; Onnx官方仓库的Issue查找解决办法。&lt;/p&gt; &#xA;&lt;p&gt;建议使用CPU版本，CPU版本推理速度也比较可观，且没有其他问题。&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;一些已经做好的前置模型：&lt;/h1&gt; &#xA;&lt;p&gt;停止更新（由于下载和上传速度）: &lt;a href=&#34;https://github.com/NaruseMioShirakana/RequireMent-Model-For-MoeSS&#34;&gt;Vocoder &amp;amp; HiddenUnitBert&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;最新仓库地址 : &lt;a href=&#34;https://huggingface.co/NaruseMioShirakana/MoeSS-SUBModel&#34;&gt;HuggingFace&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;自己导出前置：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;HuBert：input_names应该为[&#34;source&#34;]，output_names应该为[&#34;embed&#34;]，dynamic_axes应当为{&#34;source&#34;:[0,2],}&lt;/li&gt; &#xA; &lt;li&gt;Diffusion模型使用的hifigan：input_names应该为[&#34;c&#34;,&#34;f0&#34;]，output_names应该为[&#34;audio&#34;]，dynamic_axes应当为{&#34;c&#34;:[0,1],&#34;f0&#34;:[0,1],}&lt;/li&gt; &#xA; &lt;li&gt;Tacotron2使用的hifigan：input_names应该为[&#34;x&#34;]，output_names应该为[&#34;audio&#34;]，dynamic_axes应当为{&#34;x&#34;:[0,1],}&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;用户协议：&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;引用该项目请注明该项目仓库。该项目暂时无法编译（由于使用到的界面库未开源）&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;使用本项目进行二创时请标注本项目仓库地址或作者bilibili空间地址：&lt;a href=&#34;https://space.bilibili.com/108592413&#34;&gt;https://space.bilibili.com/108592413&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;使用该项目代表你同意如下几点：&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;1、你必须自行承担由于使用该项目而造成的一切后果。&lt;/li&gt; &#xA; &lt;li&gt;2、你不能出售该程序以及其附属模型，由于出售而造成的一切后果由你自己承担。&lt;/li&gt; &#xA; &lt;li&gt;3、使用该项目时，你必须自觉遵守当地的法律法规，你不能使用MoeSS从事违法活动，若从事违法活动，造成的一切后果由你自己承担。&lt;/li&gt; &#xA; &lt;li&gt;4、禁止用于任何商业游戏、低创游戏以及Galgame制作，不反对无偿的精品游戏制作以及Mod制作。&lt;/li&gt; &#xA; &lt;li&gt;5、禁止使用该项目及该项目衍生物以及发布模型等制作各种电子垃圾（比方说AIGalgame，AI游戏制作等）&lt;/li&gt; &#xA; &lt;li&gt;6、禁止一切政治相关内容，政治相关内容造成的后果由你自己承担。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Q&amp;amp;A：&lt;/h2&gt; &#xA;&lt;h3&gt;Q：该项目以后会收费吗？&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;A：该项目永久开源免费，如果在其他地方存在本软件的收费版本，请立即举报且不要购买，本软件永久免费。如果想用疯狂星期四塞满白叶，可以前往爱发癫 https://afdian.net/a/NaruseMioShirakana &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Q：是否提供有偿模型代训练？&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;A：原则上不提供，训练TTS模型比较简单，没必要花冤枉钱，按照网上教程一步一步走就可以了。提供免费的Onnx转换。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Q：电子垃圾评判标准是什么？&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;A：1、原创度。自己的东西在整个项目中的比例（对于AI来说，使用完全由你独立训练模型的创作属于你自己；使用他人模型的创作属于别人）。涵盖的方面包括但不限于程序、美工、音频、策划等等。举个例子，套用Unity等引擎模板换皮属于电子垃圾。&#xA;&#xA;2、开发者态度。作者开发的态度是不是捞一波流量和钱走人或单纯虚荣。比方说打了无数的tag，像什么“国产”“首个”“最强”“自制”这种引流宣传，结果是非常烂或是平庸的东西，且作者明显没有好好制作该项目的想法，属于电子垃圾。&#xA;&#xA;3、反对一切使用未授权的数据集训练出来的AI模型商用的行为。 &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Q：技术支持？&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;A：如果能够确定你做的不是电子垃圾，同时合法合规，没有严重的政治错误，我会提供一些力所能及的技术支持。 &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Moe Speech Synthesis&lt;/h1&gt; &#xA;&lt;p&gt;一个基于各种开源TTS、VC以及SVS项目的完全C++Speech Synthesis UI软件&lt;/p&gt; &#xA;&lt;p&gt;支持的Net：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVIDIA/DeepLearningExamples&#34;&gt;DeepLearningExamples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;VITS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/innnky/so-vits-svc/tree/32k&#34;&gt;SoVits&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/prophesier/diff-SVC&#34;&gt;DiffSvc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvpi/DiffSinger&#34;&gt;DiffSinger&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;使用的图像素材来源于：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://key.visualarts.gr.jp/summer/&#34;&gt;SummerPockets&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;目前仅支持Windows&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;使用方法：&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;1、在release中下载软件压缩包，解压之&#xA;&#xA;2、在上文 [Vocoder &amp;amp; HiddenUnitBert] 仓库中下载相应的前置模型或附加模块，并放置到相应文件夹，前置模型与项目的对应关系会在下文提到&#xA;&#xA;3、将模型放置在Mods文件夹中，在左上方模型选择模块中选择模型，标准模型结构请查阅下文“支持的项目”&#xA;&#xA;4、在下方输入框中输入要转换的文字，点击“启用插件”可以执行文本Cleaner，换行为批量转换的分句符号（SoVits/DiffSvc需要输入音频路径，DiffSinger需要输入ds或json项目文件的路径）&#xA;&#xA;5、点击开始合成，即可开始合成语音，等待进度完成后，可以在右上方播放器预览，也可以在右上方直接保存&#xA;&#xA;6、可以使用命令行启动：（仅1.X版本）&#xA;Shell：&amp;amp; &#39;.\xxx.exe&#39; &#34;ModDir&#34; &#34;InputText.&#34; &#34;outputDir&#34; &#34;Symbol&#34;&#xA;CMD：&#34;xxx.exe&#34; &#34;ModDir&#34; &#34;InputText.&#34; &#34;outputDir&#34; &#34;Symbol&#34;&#xA;其中ModDir为&#34;模型路径\\模型名&#34; 如预置模型的&#34;Mods\\Shiroha\\Shiroha&#34;&#xA;InputText为需要转换的文字（仅支持空格逗号句号以及字母）&#xA;outputDir为输出文件名（不是路径，是文件名，不需要加后缀）&#xA;Symbol见下文&#xA;输出文件默认在tmpDir中&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;模型制作：&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;本软件标准化了模型读取模块，模型保存在Mods文件夹下的子文件夹中********.json文件用于声明模型路径以及其显示名称，需要将模型转换为Onnx，转换的仓库在我GitHub主页Pin了出来。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;通用参数(不管是啥模型都必须填的，不填就不识别)：&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Folder：保存模型的文件夹名&lt;/li&gt; &#xA; &lt;li&gt;Name：模型在UI中的显示名称&lt;/li&gt; &#xA; &lt;li&gt;Type：模型类别&lt;/li&gt; &#xA; &lt;li&gt;Rate：采样率（必须和你训练时候的一模一样，不明白原因建议去学计算机音频相关的知识）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Tacotron2：&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;{&#xA;    &#34;Folder&#34; : &#34;Atri&#34;,&#xA;    &#34;Name&#34; : &#34;亚托莉-Tacotron2&#34;,&#xA;    &#34;Type&#34; : &#34;Tacotron2&#34;,&#xA;    &#34;Rate&#34; : 22050,&#xA;    &#34;Symbol&#34; : &#34;_-!&#39;(),.:;? ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz&#34;,&#xA;    &#34;Cleaner&#34; : &#34;JapaneseCleaner&#34;,&#xA;    &#34;Hifigan&#34;: &#34;hifigan&#34;&#xA;}&#xA;//Symbol：模型的Symbol，不知道Symbol是啥的建议多看几个视频了解了解TTS的基础知识，这一项在Tacotron2中必须填。&#xA;//Cleaner：插件名，可以不填，填了就必须要在Cleaner文件夹防止相应的CleanerDll，如果Dll不存在或者是Dll内部有问题，则会在加载模型时报插件错误&#xA;//Hifigan：Hifigan模型名，必须填且必须将在前置模型中下载到的hifigan放置到hifigan文件夹&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Vits：&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;{&#xA;    &#34;Folder&#34; : &#34;SummerPockets&#34;,&#xA;    &#34;Name&#34; : &#34;SummerPocketsReflectionBlue&#34;,&#xA;    &#34;Type&#34; : &#34;Vits&#34;,&#xA;    &#34;Rate&#34; : 22050,&#xA;    &#34;Symbol&#34; : &#34;_,.!?-~…AEINOQUabdefghijkmnoprstuvwyzʃʧʦ↓↑ &#34;,&#xA;    &#34;Cleaner&#34; : &#34;JapaneseCleaner&#34;,&#xA;    &#34;Characters&#34; : [&#34;鳴瀬しろは&#34;,&#34;空門蒼&#34;,&#34;鷹原うみ&#34;,&#34;紬ヴェンダース&#34;,&#34;神山識&#34;,&#34;水織静久&#34;,&#34;野村美希&#34;,&#34;久島鴎&#34;,&#34;岬鏡子&#34;]&#xA;}&#xA;//Symbol：模型的Symbol，不知道Symbol是啥的建议多看几个视频了解了解TTS的基础知识，这一项在Vits中必须填。&#xA;//Cleaner：插件名，可以不填，填了就必须要在Cleaner文件夹防止相应的CleanerDll，如果Dll不存在或者是Dll内部有问题，则会在加载模型时报插件错误&#xA;//Characters：如果是多角色模型必须填写为你的角色名称组成的列表，如果是单角色模型可以不填&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pits：&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;{&#xA;    &#34;Folder&#34; : &#34;SummerPockets&#34;,&#xA;    &#34;Name&#34; : &#34;SummerPocketsReflectionBlue&#34;,&#xA;    &#34;Type&#34; : &#34;Pits&#34;,&#xA;    &#34;Rate&#34; : 22050,&#xA;    &#34;Symbol&#34; : &#34;_,.!?-~…AEINOQUabdefghijkmnoprstuvwyzʃʧʦ↓↑ &#34;,&#xA;    &#34;Cleaner&#34; : &#34;JapaneseCleaner&#34;,&#xA;    &#34;Characters&#34; : [&#34;鳴瀬しろは&#34;,&#34;空門蒼&#34;,&#34;鷹原うみ&#34;,&#34;紬ヴェンダース&#34;,&#34;神山識&#34;,&#34;水織静久&#34;,&#34;野村美希&#34;,&#34;久島鴎&#34;,&#34;岬鏡子&#34;]&#xA;}&#xA;//Symbol：模型的Symbol，不知道Symbol是啥的建议多看几个视频了解了解TTS的基础知识，这一项在Vits中必须填。&#xA;//Cleaner：插件名，可以不填，填了就必须要在Cleaner文件夹防止相应的CleanerDll，如果Dll不存在或者是Dll内部有问题，则会在加载模型时报插件错误&#xA;//Characters：如果是多角色模型必须填写为你的角色名称组成的列表，如果是单角色模型可以不填&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;SoVits_3.0_32k：&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;{&#xA;    &#34;Folder&#34; : &#34;NyaruTaffySo&#34;,&#xA;    &#34;Name&#34; : &#34;NyaruTaffy-SoVits&#34;,&#xA;    &#34;Type&#34; : &#34;SoVits&#34;,&#xA;    &#34;Rate&#34; : 32000,&#xA;    &#34;Hop&#34; : 320,&#xA;    &#34;Cleaner&#34; : &#34;&#34;,&#xA;    &#34;Hubert&#34;: &#34;hubert&#34;,&#xA;    &#34;SoVits3&#34;: true,&#xA;    &#34;Characters&#34; : [&#34;Taffy&#34;,&#34;Nyaru&#34;]&#xA;}&#xA;//Hop：模型的HopLength，不知道HopLength是啥的建议多看几个视频了解了解音频的基础知识，这一项在SoVits中必须填。（数值必须为你训练时的数值，可以在你训练模型时候的配置文件里看到）&#xA;//Cleaner：插件名，可以不填，填了就必须要在Cleaner文件夹防止相应的CleanerDll，如果Dll不存在或者是Dll内部有问题，则会在加载模型时报插件错误&#xA;//Hubert：Hubert模型名，必须填且必须将在前置模型中下载到的Hubert放置到Hubert文件夹&#xA;//Characters：如果是多角色模型必须填写为你的角色名称组成的列表，如果是单角色模型可以不填&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;SoVits_3.0_48k：&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;{&#xA;    &#34;Folder&#34; : &#34;NyaruTaffySo&#34;,&#xA;    &#34;Name&#34; : &#34;NyaruTaffy-SoVits&#34;,&#xA;    &#34;Type&#34; : &#34;SoVits&#34;,&#xA;    &#34;Rate&#34; : 48000,&#xA;    &#34;Hop&#34; : 320,&#xA;    &#34;Cleaner&#34; : &#34;&#34;,&#xA;    &#34;Hubert&#34;: &#34;hubert&#34;,&#xA;    &#34;SoVits3&#34;: true,&#xA;    &#34;Characters&#34; : [&#34;Taffy&#34;,&#34;Nyaru&#34;]&#xA;}&#xA;//Hop：模型的HopLength，不知道HopLength是啥的建议多看几个视频了解了解音频的基础知识，这一项在SoVits中必须填。（数值必须为你训练时的数值，可以在你训练模型时候的配置文件里看到）&#xA;//Cleaner：插件名，可以不填，填了就必须要在Cleaner文件夹防止相应的CleanerDll，如果Dll不存在或者是Dll内部有问题，则会在加载模型时报插件错误&#xA;//Hubert：Hubert模型名，必须填且必须将在前置模型中下载到的Hubert放置到Hubert文件夹&#xA;//Characters：如果是多角色模型必须填写为你的角色名称组成的列表，如果是单角色模型可以不填&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;SoVits_4.0：&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;{&#xA;    &#34;Folder&#34; : &#34;NyaruTaffySo&#34;,&#xA;    &#34;Name&#34; : &#34;NyaruTaffy-SoVits&#34;,&#xA;    &#34;Type&#34; : &#34;SoVits&#34;,&#xA;    &#34;Rate&#34; : 44100,&#xA;    &#34;Hop&#34; : 512,&#xA;    &#34;Cleaner&#34; : &#34;&#34;,&#xA;    &#34;Hubert&#34;: &#34;hubert4.0&#34;,&#xA;    &#34;SoVits4&#34;: true,&#xA;    &#34;Characters&#34; : [&#34;Taffy&#34;,&#34;Nyaru&#34;]&#xA;}&#xA;//Hop：模型的HopLength，不知道HopLength是啥的建议多看几个视频了解了解音频的基础知识，这一项在SoVits中必须填。（数值必须为你训练时的数值，可以在你训练模型时候的配置文件里看到）&#xA;//Cleaner：插件名，可以不填，填了就必须要在Cleaner文件夹防止相应的CleanerDll，如果Dll不存在或者是Dll内部有问题，则会在加载模型时报插件错误&#xA;//Hubert：Hubert模型名，必须填且必须将在前置模型中下载到的Hubert放置到Hubert文件夹&#xA;//Characters：如果是多角色模型必须填写为你的角色名称组成的列表，如果是单角色模型可以不填&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;DiffSVC：&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;{&#xA;    &#34;Folder&#34; : &#34;DiffShiroha&#34;,&#xA;    &#34;Name&#34; : &#34;白羽&#34;,&#xA;    &#34;Type&#34; : &#34;DiffSvc&#34;,&#xA;    &#34;Rate&#34; : 44100,&#xA;    &#34;Hop&#34; : 512,&#xA;    &#34;MelBins&#34; : 128,&#xA;    &#34;Cleaner&#34; : &#34;&#34;,&#xA;    &#34;Hifigan&#34;: &#34;nsf_hifigan&#34;,&#xA;    &#34;Hubert&#34;: &#34;hubert&#34;,&#xA;    &#34;Characters&#34; : [],&#xA;    &#34;Pndm&#34; : 100,&#xA;    &#34;V2&#34; : true&#xA;}&#xA;//Hop：模型的HopLength，不知道HopLength是啥的建议多看几个视频了解了解音频的基础知识，这一项在SoVits中必须填。（数值必须为你训练时的数值，可以在你训练模型时候的配置文件里看到）&#xA;//MelBins：模型的MelBins，不知道MelBins是啥的建议多看几个视频了解了解梅尔基础知识，这一项在SoVits中必须填。（数值必须为你训练时的数值，可以在你训练模型时候的配置文件里看到）&#xA;//Cleaner：插件名，可以不填，填了就必须要在Cleaner文件夹防止相应的CleanerDll，如果Dll不存在或者是Dll内部有问题，则会在加载模型时报插件错误&#xA;//Hubert：Hubert模型名，必须填且必须将在前置模型中下载到的Hubert放置到Hubert文件夹&#xA;//Hifigan：Hifigan模型名，必须填且必须将在前置模型中下载到的nsf_hifigan放置到hifigan文件夹&#xA;//Characters：如果是多角色模型必须填写为你的角色名称组成的列表，如果是单角色模型可以不填&#xA;//Pndm：加速倍数，如果是V1模型则必填且必须为导出时设置的加速倍率&#xA;//V2：是否为V2模型，V2模型就是后来我分4个模块导出的那个&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;DiffSinger：&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;{&#xA;    &#34;Folder&#34; : &#34;utagoe&#34;,&#xA;    &#34;Name&#34; : &#34;utagoe&#34;,&#xA;    &#34;Type&#34; : &#34;DiffSinger&#34;,&#xA;    &#34;Rate&#34; : 44100,&#xA;    &#34;Hop&#34; : 512,&#xA;    &#34;Cleaner&#34; : &#34;&#34;,&#xA;    &#34;Hifigan&#34;: &#34;singer_nsf_hifigan&#34;,&#xA;    &#34;Characters&#34; : [],&#xA;    &#34;MelBins&#34; : 128&#xA;}&#xA;//Hop：模型的HopLength，不知道HopLength是啥的建议多看几个视频了解了解音频的基础知识，这一项在SoVits中必须填。（数值必须为你训练时的数值，可以在你训练模型时候的配置文件里看到）&#xA;//Cleaner：插件名，可以不填，填了就必须要在Cleaner文件夹防止相应的CleanerDll，如果Dll不存在或者是Dll内部有问题，则会在加载模型时报插件错误&#xA;//Hifigan：Hifigan模型名，必须填且必须将在前置模型中下载到的singer_nsf_hifigan放置到hifigan文件夹&#xA;//Characters：如果是多角色模型必须填写为你的角色名称组成的列表，如果是单角色模型可以不填&#xA;//MelBins：模型的MelBins，不知道MelBins是啥的建议多看几个视频了解了解梅尔基础知识，这一项在SoVits中必须填。（数值必须为你训练时的数值，可以在你训练模型时候的配置文件里看到）&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;支持的model项目&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cxx&#34;&gt;// ${xxx}是什么意思大家应该都知道吧，总之以下是多个不同项目需要的模型文件（需要放置在对应的模型文件夹下）。&#xA;// Tacotron2：&#xA;    ${Folder}_decoder_iter.onnx&#xA;    ${Folder}_encoder.onnx&#xA;    ${Folder}_postnet.onnx&#xA;// Vits:    单角色VITS&#xA;    ${Folder}_dec.onnx&#xA;    ${Folder}_flow.onnx&#xA;    ${Folder}_enc_p.onnx&#xA;    ${Folder}_dp.onnx &#xA;// Vits:   多角色VITS&#xA;    ${Folder}_dec.onnx&#xA;    ${Folder}_emb.onnx&#xA;    ${Folder}_flow.onnx&#xA;    ${Folder}_enc_p.onnx&#xA;    ${Folder}_dp.onnx&#xA;// SoVits:&#xA;    ${Folder}_SoVits.onnx&#xA;// DiffSvc:&#xA;    ${Folder}_diffSvc.onnx&#xA;// DiffSvc: V2&#xA;    ${Folder}_encoder.onnx&#xA;    ${Folder}_denoise.onnx&#xA;    ${Folder}_pred.onnx&#xA;    ${Folder}_after.onnx&#xA;// DiffSinger: OpenVpiVersion&#xA;    ${Folder}_diffSinger.onnx&#xA;// DiffSinger: &#xA;    ${Folder}_encoder.onnx&#xA;    ${Folder}_denoise.onnx&#xA;    ${Folder}_pred.onnx&#xA;    ${Folder}_after.onnx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Symbol的设置&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;例如：_-!&#39;(),.:;? ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz&#xA;打开你训练模型的项目，打开text\symbol.py，如图按照划线的List顺序将上面的4个字符串连接即可&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/40709280/183290732-dcb93323-1061-431b-aafa-c285a3ec5e82.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Cleaner的设置&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cxx&#34;&gt;/*&#xA;Cleaner请放置于根目录的Cleaners文件夹内，应该是一个按照要求定义的动态库（.dll），dll应当命名为Cleaner名，Cleaner名即为模型定义Json文件中Cleaner一栏填写的内容。&#xA;所有的插件dll需要定义以下函数，函数名必须为PluginMain，Dll名必须为插件名（或Cleaner名）：&#xA;*/&#xA;const wchar_t* PluginMain(const wchar_t*);&#xA;// 该接口只要求输入输出一致，并不要求功能一致，也就是说，你可以在改Dll中实现任何想要的功能，比方说ChatGpt，机器翻译等等。&#xA;// 以ChatGpt为例，PluginMain函数传入了一个输入字符串input，将该输入传入ChatGpt，再将ChatGpt的输出传入PluginMain，最后返回输出。&#xA;wchar_t* PluginMain(wchar_t* input){&#xA;    wchar_t* tmpOutput = ChatGpt(input);&#xA;    return Clean(tmpOutput);&#xA;}&#xA;// 注意：导出dll时请使用 extern &#34;C&#34; 关键字来防止C++语言的破坏性命名。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;杂项&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FujiwaraShirakana/ShirakanaTTSMods&#34;&gt;已经制作好的模型&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1bD4y1V7zu&#34;&gt;演示视频&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;依赖列表&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ffmpeg.org/&#34;&gt;FFmpeg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder&#34;&gt;World&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/rapidjson&#34;&gt;rapidJson&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>