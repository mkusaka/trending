<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-20T01:31:37Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>NVIDIA-AI-IOT/Lidar_AI_Solution</title>
    <updated>2023-05-20T01:31:37Z</updated>
    <id>tag:github.com,2023-05-20:/NVIDIA-AI-IOT/Lidar_AI_Solution</id>
    <link href="https://github.com/NVIDIA-AI-IOT/Lidar_AI_Solution" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A project demonstrating Lidar related AI solutions, including three GPU accelerated Lidar/camera DL networks (PointPillars, CenterPoint, BEVFusion) and the related libs (cuPCL, 3D SparseConvolution, YUV2RGB, cuOSD,).&lt;/p&gt;&lt;hr&gt;&lt;h1 style=&#34;text-align: center&#34;&gt;Lidar AI Solution&lt;/h1&gt; This is a highly optimized solution for self-driving 3D-lidar repository. It does a great job of speeding up sparse convolution/CenterPoint/BEVFusion/OSD/Conversion. &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NVIDIA-AI-IOT/Lidar_AI_Solution/master/assets/title.png&#34; alt=&#34;title&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Pipeline overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NVIDIA-AI-IOT/Lidar_AI_Solution/master/assets/pipeline.png&#34; alt=&#34;pipeline&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;GetStart&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install git-lfs&#xA;$ git clone --recursive https://github.com/NVIDIA-AI-IOT/Lidar_AI_Solution&#xA;$ cd Lidar_AI_Solution&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For each specific task please refer to the readme in the sub-folder.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;3D Sparse Convolution&lt;/h2&gt; &#xA;&lt;p&gt;A tiny inference engine for &lt;a href=&#34;https://github.com/tianweiy/CenterPoint/raw/master/det3d/models/backbones/scn.py&#34;&gt;3d sparse convolutional networks&lt;/a&gt; using int8/fp16.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tiny Engine:&lt;/strong&gt; Tiny Lidar-Backbone inference engine independent of TensorRT.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flexible:&lt;/strong&gt; Build execution graph from ONNX.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Easy To Use:&lt;/strong&gt; Simple interface and onnx export solution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;High Fidelity:&lt;/strong&gt; Low accuracy drop on nuScenes validation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Low Memory:&lt;/strong&gt; 422MB@SCN FP16, 426MB@SCN INT8.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Compact:&lt;/strong&gt; Based on the CUDA kernels and independent of cutlass.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;CUDA BEVFusion&lt;/h2&gt; &#xA;&lt;p&gt;CUDA &amp;amp; TensorRT solution for &lt;a href=&#34;https://arxiv.org/abs/2205.13542&#34;&gt;BEVFusion&lt;/a&gt; inference, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Camera Encoder&lt;/strong&gt;: ResNet50 and finetuned BEV pooling with TensorRT and onnx export solution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Lidar Encoder&lt;/strong&gt;: Tiny Lidar-Backbone inference independent of TensorRT and onnx export solution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Feature Fusion&lt;/strong&gt;: Camera &amp;amp; Lidar feature fuser with TensorRT and onnx export solution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Pre/Postprocess&lt;/strong&gt;: Interval precomputing, lidar voxelization, feature decoder with CUDA kernels.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Easy To Use&lt;/strong&gt;: Preparation, inference, evaluation all in one to reproduce torch Impl accuracy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;PTQ&lt;/strong&gt;: Quantization solutions for &lt;a href=&#34;https://github.com/mit-han-lab/bevfusion/tree/main/mmdet3d/ops/spconv&#34;&gt;mmdet3d/spconv&lt;/a&gt;, Easy to understand.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;CUDA CenterPoint&lt;/h2&gt; &#xA;&lt;p&gt;CUDA &amp;amp; TensorRT solution for &lt;a href=&#34;https://arxiv.org/abs/2006.11275&#34;&gt;CenterPoint&lt;/a&gt; inference, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Preprocess&lt;/strong&gt;: Voxelization with CUDA kernel&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Encoder&lt;/strong&gt;: 3D backbone with NV spconv-scn and onnx export solution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Neck &amp;amp; Header&lt;/strong&gt;: RPN &amp;amp; CenterHead with TensorRT and onnx export solution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Postprocess&lt;/strong&gt;: Decode &amp;amp; NMS with CUDA kernel&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Easy To Use&lt;/strong&gt;: Preparation, inference, evaluation all in one to reproduce torch Impl accuracy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;QAT&lt;/strong&gt;: Quantization solutions for &lt;a href=&#34;https://github.com/traveller59/spconv&#34;&gt;traveller59/spconv&lt;/a&gt;, Easy to understand.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;CUDA PointPillars&lt;/h2&gt; &#xA;&lt;p&gt;CUDA &amp;amp; TensorRT solution for &lt;a href=&#34;https://arxiv.org/abs/1812.05784&#34;&gt;pointpillars&lt;/a&gt; inference, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Preprocess&lt;/strong&gt;: Voxelization &amp;amp; Feature Extending with CUDA kernel&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Detector&lt;/strong&gt;: 2.5D backbone with TensorRT and onnx export solution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Postprocess&lt;/strong&gt;: Parse bounding box, class type and direction&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Easy To Use&lt;/strong&gt;: Preparation, inference, evaluation all in one to reproduce torch Impl accuracy.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;cuOSD(CUDA On-Screen Display Library)&lt;/h2&gt; &#xA;&lt;p&gt;Draw all elements using a single CUDA kernel.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Line:&lt;/strong&gt; Plotting lines by interpolation(Nearest or Linear).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;RotateBox:&lt;/strong&gt; Supports drawn with different border colors and fill colors.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Circle:&lt;/strong&gt; Supports drawn with different border colors and fill colors.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Rectangle:&lt;/strong&gt; Supports drawn with different border colors and fill colors.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Text:&lt;/strong&gt; Supports &lt;a href=&#34;https://github.com/nothings/stb/raw/master/stb_truetype.h&#34;&gt;stb_truetype&lt;/a&gt; and &lt;a href=&#34;https://pango.gnome.org/&#34;&gt;pango-cairo&lt;/a&gt; backends, allowing fonts to be read via TTF or using font-family.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Arrow:&lt;/strong&gt; Combination of arrows by 3 lines.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Point:&lt;/strong&gt; Plotting points by interpolation(Nearest or Linear).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Clock:&lt;/strong&gt; Time plotting based on text support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;cuPCL(CUDA Point Cloud Library)&lt;/h2&gt; &#xA;&lt;p&gt;Provide several GPU accelerated Point Cloud operations with high accuracy and high perfomrance at the same time: cuICP, cuFilter, cuSegmentation, cuOctree, cuCluster, cuNDT, Voxelization(incoming).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;cuICP:&lt;/strong&gt; CUDA accelerated iterative corresponding point vertex cloud(point-to-point) registration implementation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;cuFilter:&lt;/strong&gt; Support CUDA accelerated features: PassThrough and VoxelGrid.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;cuSegmentation:&lt;/strong&gt; Support CUDA accelerated features: RandomSampleConsensus with a plane model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;cuOctree:&lt;/strong&gt; Support CUDA accelerated features: Approximate Nearest Search and Radius Search.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;cuCluster:&lt;/strong&gt; Support CUDA accelerated features: Cluster based on the distance among points.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;cuNDT:&lt;/strong&gt; CUDA accelerated 3D Normal Distribution Transform registration implementation for point cloud data.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;YUVToRGB(CUDA Conversion)&lt;/h2&gt; &#xA;&lt;p&gt;YUV to RGB conversion. Combine Resize/Padding/Conversion/Normalization into a single kernel function.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Most of the time, it can be bit-aligned with OpenCV.&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;It will give an exact result when the scaling factor is a rational number.&lt;/li&gt; &#xA;   &lt;li&gt;Better performance is usually achieved when the stride can divide by 4.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Supported Input Format: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;NV12BlockLinear&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;NV12PitchLinear&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;YUV422Packed_YUYV&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Supported Interpolation methods: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Nearest&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Bilinear&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Supported Output Data Type: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Uint8&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Float32&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Float16&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Supported Output Layout: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;CHW_RGB/BGR&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;HWC_RGB/BGR&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;CHW16/32/4/RGB/BGR for DLA input&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Supported Features: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Resize&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Padding&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Conversion&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Normalization&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Thanks&lt;/h2&gt; &#xA;&lt;p&gt;This project makes use of a number of awesome open source libraries, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nothings/stb&#34;&gt;stb_image&lt;/a&gt; for PNG and JPEG support&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pybind/pybind11&#34;&gt;pybind11&lt;/a&gt; for seamless C++ / Python interop&lt;/li&gt; &#xA; &lt;li&gt;and others! See the dependencies folder.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Many thanks to the authors of these brilliant projects!&lt;/p&gt;</summary>
  </entry>
</feed>