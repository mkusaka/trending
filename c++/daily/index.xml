<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-21T01:27:27Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Anttwo/SuGaR</title>
    <updated>2023-12-21T01:27:27Z</updated>
    <id>tag:github.com,2023-12-21:/Anttwo/SuGaR</id>
    <link href="https://github.com/Anttwo/SuGaR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official implementation of SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering&lt;/h1&gt; &#xA; &lt;font size=&#34;4&#34;&gt; &lt;a href=&#34;https://anttwo.github.io/&#34; style=&#34;font-size:100%;&#34;&gt;Antoine Guédon&lt;/a&gt;  &lt;a href=&#34;https://vincentlepetit.github.io/&#34; style=&#34;font-size:100%;&#34;&gt;Vincent Lepetit&lt;/a&gt;  &lt;/font&gt; &#xA; &lt;br&gt; &#xA; &lt;font size=&#34;4&#34;&gt; LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS &lt;/font&gt; &#xA; &lt;p&gt;| &lt;a href=&#34;https://anttwo.github.io/sugar/&#34;&gt;Webpage&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2311.12775&#34;&gt;arXiv&lt;/a&gt; | &lt;a href=&#34;https://www.youtube.com/watch?v=MAkFyWfiBQo&#34;&gt;Presentation video&lt;/a&gt; |&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/examples/walk.gif&#34; alt=&#34;walk.gif&#34; width=&#34;350&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/examples/attack.gif&#34; alt=&#34;attack.gif&#34; width=&#34;350&#34;&gt; &lt;br&gt; &lt;b&gt;Our method extracts meshes from 3D Gaussian Splatting reconstructions and build hybrid representations &lt;br&gt;that enable easy composition and animation in Gaussian Splatting scenes by manipulating the mesh.&lt;/b&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Abstract&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;We propose a method to allow precise and extremely fast mesh extraction from &lt;a href=&#34;https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/&#34;&gt;3D Gaussian Splatting (SIGGRAPH 2023)&lt;/a&gt;. Gaussian Splatting has recently become very popular as it yields realistic rendering while being significantly faster to train than NeRFs. It is however challenging to extract a mesh from the millions of tiny 3D Gaussians as these Gaussians tend to be unorganized after optimization and no method has been proposed so far. Our first key contribution is a regularization term that encourages the 3D Gaussians to align well with the surface of the scene. We then introduce a method that exploits this alignment to sample points on the real surface of the scene and extract a mesh from the Gaussians using Poisson reconstruction, which is fast, scalable, and preserves details, in contrast to the Marching Cubes algorithm usually applied to extract meshes from Neural SDFs. Finally, we introduce an optional refinement strategy that binds Gaussians to the surface of the mesh, and jointly optimizes these Gaussians and the mesh through Gaussian splatting rendering. This enables easy editing, sculpting, rigging, animating, or relighting of the Gaussians using traditional softwares (Blender, Unity, Unreal Engine, etc.) by manipulating the mesh instead of the Gaussians themselves. Retrieving such an editable mesh for realistic rendering is done within minutes with our method, compared to hours with the state-of-the-art method on neural SDFs, while providing a better rendering quality in terms of PSNR, SSIM and LPIPS.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;b&gt;Hybrid representation (Mesh + Gaussians on the surface)&lt;/b&gt;&#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/garden_hybrid.gif&#34; alt=&#34;garden_hybrid.gif&#34; width=&#34;250&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/kitchen_hybrid.gif&#34; alt=&#34;kitchen_hybrid.gif&#34; width=&#34;250&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/counter_hybrid.gif&#34; alt=&#34;counter_hybrid.gif&#34; width=&#34;250&#34;&gt;&#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/playroom_hybrid.gif&#34; alt=&#34;playroom_hybrid.gif&#34; width=&#34;323&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/qant03_hybrid.gif&#34; alt=&#34;qant03_hybrid.gif&#34; width=&#34;323&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/dukemon_hybrid.gif&#34; alt=&#34;_hybrid.gif&#34; width=&#34;102&#34;&gt;&#xA; &lt;br&gt; &#xA; &lt;b&gt;Underlying mesh without texture&lt;/b&gt;&#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/garden_notex.gif&#34; alt=&#34;garden_notex.gif&#34; width=&#34;250&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/kitchen_notex.gif&#34; alt=&#34;kitchen_notex.gif&#34; width=&#34;250&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/counter_notex.gif&#34; alt=&#34;counter_notex.gif&#34; width=&#34;250&#34;&gt;&#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/playroom_notex.gif&#34; alt=&#34;playroom_notex.gif&#34; width=&#34;323&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/qant03_notex.gif&#34; alt=&#34;qant03_notex.gif&#34; width=&#34;323&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/dukemon_notex.gif&#34; alt=&#34;dukemon_notex.gif&#34; width=&#34;102&#34;&gt;&#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{guedon2023sugar,&#xA;  title={SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering},&#xA;  author={Gu{\&#39;e}don, Antoine and Lepetit, Vincent},&#xA;  journal={arXiv:2311.12775},&#xA;  year={2023},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Updates and To-do list&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;span style=&#34;font-weight: bold;&#34;&gt;Updates&lt;/span&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;b&gt;[12/20/2023]&lt;/b&gt; Added a short notebook showing how to render images with the hybrid representation using the Gaussian Splatting rasterizer.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;b&gt;[12/18/2023]&lt;/b&gt; Code release.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt;&#xA;&lt;br&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;span style=&#34;font-weight: bold;&#34;&gt;To-do list&lt;/span&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;b&gt;Composition and animation:&lt;/b&gt; Finish to clean the code for composition and animation, and add it to the &lt;code&gt;sugar_scene/sugar_compositor.py&lt;/code&gt; script. &lt;/li&gt; &#xA;  &lt;li&gt;&lt;b&gt;Composition and animation:&lt;/b&gt; Make a tutorial on how to use the scripts in the &lt;code&gt;blender&lt;/code&gt; directory and the &lt;code&gt;sugar_scene/sugar_compositor.py&lt;/code&gt; class to import composition and animation data into PyTorch and apply it to the SuGaR hybrid representation. &lt;/li&gt; &#xA;  &lt;!-- &lt;li&gt;&lt;b&gt;Improvement:&lt;/b&gt; Implement a simple method to avoid artifacts when reconstructing thin objects with poor coverage/visibility in the training images.&lt;/li&gt;&#xA;  &lt;/li&gt; --&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;As we explain in the paper, SuGaR optimization starts with first optimizing a 3D Gaussian Splatting model for 7k iterations with no additional regularization term. In this sense, SuGaR is a method that can be applied on top of any 3D Gaussian Splatting model, and a Gaussian Splatting model optimized for 7k iterations must be provided to SuGaR.&lt;/p&gt; &#xA;&lt;p&gt;Consequently, the current implementation contains a version of the original &lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;3D Gaussian Splatting code&lt;/a&gt;, and we built our model as a wrapper of a vanilla 3D Gaussian Splatting model. Please note that, even though this wrapper implementation is convenient for many reasons, it may not be the most optimal one for memory usage, so we might change it in the future.&lt;/p&gt; &#xA;&lt;p&gt;After optimizing a vanilla Gaussian Splatting model, the SuGaR pipeline consists of 3 main steps, and an optional one:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;SuGaR optimization&lt;/strong&gt;: optimizing Gaussians alignment with the surface of the scene&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Mesh extraction&lt;/strong&gt;: extracting a mesh from the optimized Gaussians&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;SuGaR refinement&lt;/strong&gt;: refining the Gaussians and the mesh together to build a hybrid representation&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Textured mesh extraction (Optional)&lt;/strong&gt;: extracting a traditional textured mesh from the refined SuGaR model&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/examples/process_0.png&#34; alt=&#34;process_0.png&#34; width=&#34;750&#34;&gt;&#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/examples/process_1.png&#34; alt=&#34;process_.png&#34; width=&#34;750&#34;&gt;&#xA; &lt;br&gt; &#xA;&lt;/div&gt;&#xA;&lt;br&gt; &#xA;&lt;p&gt;We provide a dedicated script for each of these steps, as well as a script &lt;code&gt;train.py&lt;/code&gt; that runs the entire pipeline. We explain how to use this script in the next sections. &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please note that the final step, &lt;em&gt;Textured mesh extraction&lt;/em&gt;, is optional but is enabled by default in the &lt;code&gt;train.py&lt;/code&gt; script. Indeed, it is very convenient to have a traditional textured mesh for visualization, composition and animation using traditional softwares such as Blender. However, this step is not needed to produce, modify or animate hybrid representations.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;b&gt;Hybrid representation (Mesh + Gaussians on the surface)&lt;/b&gt;&#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/garden_hybrid.png&#34; alt=&#34;garden_hybrid.gif&#34; height=&#34;135&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/kitchen_hybrid.png&#34; alt=&#34;kitchen_hybrid.gif&#34; height=&#34;135&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/qant03_hybrid.png&#34; alt=&#34;qant03_hybrid.gif&#34; height=&#34;135&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/dukemon_hybrid.png&#34; alt=&#34;_hybrid.gif&#34; height=&#34;135&#34;&gt;&#xA; &lt;br&gt; &#xA; &lt;b&gt;Underlying mesh with a traditional colored UV texture&lt;/b&gt;&#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/garden_texture.png&#34; alt=&#34;garden_notex.gif&#34; height=&#34;135&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/kitchen_texture.png&#34; alt=&#34;kitchen_notex.gif&#34; height=&#34;135&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/qant03_texture.png&#34; alt=&#34;qant03_notex.gif&#34; height=&#34;135&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/overview/dukemon_texture.png&#34; alt=&#34;dukemon_notex.gif&#34; height=&#34;135&#34;&gt;&#xA; &lt;br&gt; &#xA;&lt;/div&gt;&#xA;&lt;br&gt; &#xA;&lt;p&gt;Below is another example of a scene showing a robot with a black and specular material. The following images display the hybrid representation (Mesh + Gaussians on the surface), the mesh with a traditional colored UV texture, and a depth map of the mesh:&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;b&gt;Hybrid representation - Textured mesh - Depth map of the mesh&lt;/b&gt;&#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/examples/alpha_hybrid.png&#34; alt=&#34;alpha_hybrid.png&#34; height=&#34;400&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/examples/alpha_texture.png&#34; alt=&#34;alpha_texture.gif&#34; height=&#34;400&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/examples/alpha_depth.png&#34; alt=&#34;alpha_depth.gif&#34; height=&#34;400&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;0. Requirements&lt;/h3&gt; &#xA;&lt;p&gt;The software requirements are the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Conda (recommended for easy setup)&lt;/li&gt; &#xA; &lt;li&gt;C++ Compiler for PyTorch extensions&lt;/li&gt; &#xA; &lt;li&gt;CUDA toolkit 11.8 for PyTorch extensions&lt;/li&gt; &#xA; &lt;li&gt;C++ Compiler and CUDA SDK must be compatible&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please refer to the original &lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;3D Gaussian Splatting repository&lt;/a&gt; for more details about requirements.&lt;/p&gt; &#xA;&lt;h3&gt;1. Clone the repository&lt;/h3&gt; &#xA;&lt;p&gt;Start by cloning this repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# HTTPS&#xA;git clone https://github.com/Anttwo/SuGaR.git --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# SSH&#xA;git clone git@github.com:Anttwo/SuGaR.git --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Install the required Python packages&lt;/h3&gt; &#xA;&lt;p&gt;To install the required Python packages and activate the environment, go inside the &lt;code&gt;SuGaR/&lt;/code&gt; directory and run the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda env create -f environment.yml&#xA;conda activate sugar&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;span style=&#34;font-weight: bold;&#34;&gt;If this command fails to create a working environment&lt;/span&gt;&lt;/summary&gt; &#xA; &lt;p&gt;Then you can try to install the required packages manually by running the following commands:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda create --name sugar -y python=3.9&#xA;conda activate sugar&#xA;conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.8 -c pytorch -c nvidia&#xA;conda install -c fvcore -c iopath -c conda-forge fvcore iopath&#xA;conda install pytorch3d==0.7.4 -c pytorch3d&#xA;conda install -c plotly plotly&#xA;conda install -c conda-forge rich&#xA;conda install -c conda-forge plyfile==0.8.1&#xA;conda install -c conda-forge jupyterlab&#xA;conda install -c conda-forge nodejs&#xA;conda install -c conda-forge ipywidgets&#xA;pip install open3d&#xA;pip install --upgrade PyMCubes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;3. Install the Gaussian Splatting rasterizer&lt;/h3&gt; &#xA;&lt;p&gt;Run the following commands inside the sugar directory to install the additional Python submodules required for Gaussian Splatting:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd gaussian_splatting/submodules/diff-gaussian-rasterization/&#xA;pip install -e .&#xA;cd ../simple-knn/&#xA;pip install -e .&#xA;cd ../../../&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;3D Gaussian Splatting repository&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Start by optimizing a vanilla Gaussian Splatting model for 7k iterations by running the script &lt;code&gt;gaussian_splatting/train.py&lt;/code&gt;, as shown below. Please refer to the original &lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;3D Gaussian Splatting repository&lt;/a&gt; for more details. This optimization should be very fast, and last only a few minutes.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python gaussian_splatting/train.py -s &amp;lt;path to COLMAP or NeRF Synthetic dataset&amp;gt; --iterations 7000 -m &amp;lt;path to the desired output directory&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, run the script &lt;code&gt;train.py&lt;/code&gt; in the root directory to optimize a SuGaR model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python train.py -s &amp;lt;path to COLMAP or NeRF Synthetic dataset&amp;gt; -c &amp;lt;path to the Gaussian Splatting checkpoint&amp;gt; -r &amp;lt;&#34;density&#34; or &#34;sdf&#34;&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The most important arguments for the &lt;code&gt;train.py&lt;/code&gt; script are the following:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Parameter&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Type&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--scene_path&lt;/code&gt; / &lt;code&gt;-s&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Path to the source directory containing a COLMAP or Synthetic NeRF data set.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--checkpoint_path&lt;/code&gt; / &lt;code&gt;-c&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Path to the checkpoint directory of the vanilla 3D Gaussian Splatting model.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--regularization_type&lt;/code&gt; / &lt;code&gt;-r&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Type of regularization to use for optimizing SuGaR. Can be &lt;code&gt;&#34;density&#34;&lt;/code&gt; or &lt;code&gt;&#34;sdf&#34;&lt;/code&gt;. For reconstructing detailed objects centered in the scene with 360° coverage, &lt;code&gt;&#34;density&#34;&lt;/code&gt; provides a better foreground mesh. For a stronger regularization and a better balance between foreground and background, choose &lt;code&gt;&#34;sdf&#34;&lt;/code&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--eval&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;If True, performs an evaluation split of the training images. Default is &lt;code&gt;True&lt;/code&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--low_poly&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;If True, uses the standard config for a low poly mesh, with &lt;code&gt;200_000&lt;/code&gt; vertices and &lt;code&gt;6&lt;/code&gt; Gaussians per triangle.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--high_poly&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;If True, uses the standard config for a high poly mesh, with &lt;code&gt;1_000_000&lt;/code&gt; vertices and &lt;code&gt;1&lt;/code&gt; Gaussian per triangle.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--refinement_time&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Default configs for time to spend on refinement. Can be &lt;code&gt;&#34;short&#34;&lt;/code&gt; (2k iterations), &lt;code&gt;&#34;medium&#34;&lt;/code&gt; (7k iterations) or &lt;code&gt;&#34;long&#34;&lt;/code&gt; (15k iterations).&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--export_uv_textured_mesh&lt;/code&gt; / &lt;code&gt;-t&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;If True, will optimize and export a traditional textured mesh as an &lt;code&gt;.obj&lt;/code&gt; file from the refined SuGaR model, after refinement. Computing a traditional color UV texture should take less than 10 minutes. Default is &lt;code&gt;True&lt;/code&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;We provide more details about the two regularization methods &lt;code&gt;&#34;density&#34;&lt;/code&gt; and &lt;code&gt;&#34;sdf&#34;&lt;/code&gt; in the next section. For reconstructing detailed objects centered in the scene with 360° coverage, &lt;code&gt;&#34;density&#34;&lt;/code&gt; provides a better foreground mesh. For a stronger regularization and a better balance between foreground and background, choose &lt;code&gt;&#34;sdf&#34;&lt;/code&gt;. &lt;br&gt; The default configuration is &lt;code&gt;high_poly&lt;/code&gt; with &lt;code&gt;refinement_time&lt;/code&gt; set to &lt;code&gt;&#34;long&#34;&lt;/code&gt;. Results are saved in the &lt;code&gt;output/&lt;/code&gt; directory.&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;As we explain in the paper, this script extracts a mesh in 30~35 minutes on average on a single GPU. After mesh extraction, the refinement time only takes a few minutes when using &lt;code&gt;--refinement_time &#34;short&#34;&lt;/code&gt;, but can take up to an hour when using &lt;code&gt;--refinement_time &#34;long&#34;&lt;/code&gt;. A short refinement time is enough to produce a good-looking hybrid representation in most cases.&lt;/p&gt; &#xA;&lt;p&gt;Please note that the optimization time may vary (from 20 to 45 minutes) depending on the complexity of the scene and the GPU used. Moreover, the current implementation splits the optimization into 3 scripts that can be run separately (SuGaR optimization, mesh extraction, model refinement) so it reloads the data at each part, which is not optimal and takes several minutes. We will update the code in a near future to optimize this.&lt;/p&gt; &#xA;&lt;p&gt;Below is a detailed list of all the command line arguments for the &lt;code&gt;train.py&lt;/code&gt; script.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;span style=&#34;font-weight: bold;&#34;&gt;All command line arguments for train.py&lt;/span&gt;&lt;/summary&gt; &#xA; &lt;h4&gt;Data and initial 3D Gaussian Splatting optimization&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Parameter&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Type&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--scene_path&lt;/code&gt; / &lt;code&gt;-s&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Path to the source directory containing a COLMAP or Synthetic NeRF data set.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--checkpoint_path&lt;/code&gt; / &lt;code&gt;-c&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Path to the checkpoint directory of the vanilla 3D Gaussian Splatting model.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--iteration_to_load&lt;/code&gt; / &lt;code&gt;-i&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Iteration to load from the 3DGS checkpoint directory. If not specified, loads the iteration &lt;code&gt;7000&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--eval&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;If True, performs an evaluation split of the training images. Default is &lt;code&gt;True&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;SuGaR optimization&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Parameter&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Type&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--regularization_type&lt;/code&gt; / &lt;code&gt;-r&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Type of regularization to use for optimizing SuGaR. Can be &lt;code&gt;&#34;density&#34;&lt;/code&gt; or &lt;code&gt;&#34;sdf&#34;&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--gpu&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Index of GPU device to use. Default is &lt;code&gt;0&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;Mesh extraction&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Parameter&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Type&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--surface_level&lt;/code&gt; / &lt;code&gt;-l&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Surface level to extract the mesh at. Default is &lt;code&gt;0.3&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--n_vertices_in_mesh&lt;/code&gt; / &lt;code&gt;-v&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Number of vertices in the extracted mesh. Default is &lt;code&gt;1_000_000&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--bboxmin&lt;/code&gt; / &lt;code&gt;-b&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Min coordinates to use for foreground bounding box, formatted as a string &lt;code&gt;&#34;(x,y,z)&#34;&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--bboxmax&lt;/code&gt; / &lt;code&gt;-B&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Max coordinates to use for foreground bounding box, formatted as a string &lt;code&gt;&#34;(x,y,z)&#34;&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--center_bbox&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;If True, centers the bbox. Default is True.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;SuGaR and mesh refinement (Hybrid representation)&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Parameter&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Type&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--gaussians_per_triangle&lt;/code&gt; / &lt;code&gt;-g&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Number of gaussians per triangle. Default is &lt;code&gt;1&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--refinement_iterations&lt;/code&gt; / &lt;code&gt;-f&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Number of refinement iterations. Default is &lt;code&gt;15_000&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;(Optional) Parameters for traditional textured mesh extraction&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Parameter&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Type&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--export_uv_textured_mesh&lt;/code&gt; / &lt;code&gt;-t&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;If True, will optimize and export a textured mesh as an .obj file from the refined SuGaR model. Computing a traditional colored UV texture should take less than 10 minutes. Default is &lt;code&gt;True&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--square_size&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Size of the square to use for the UV texture. Default is &lt;code&gt;10&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--postprocess_mesh&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;If True, postprocess the mesh by removing border triangles with low-density. This step takes a few minutes and is not needed in general, as it can also be risky. However, it increases the quality of the mesh in some cases, especially when very thin objects are visible only from one side in the images. Default is &lt;code&gt;False&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--postprocess_density_threshold&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;float&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Threshold to use for postprocessing the mesh. Default is &lt;code&gt;0.1&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--postprocess_iterations&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Number of iterations to use for postprocessing the mesh. Default is &lt;code&gt;5&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;(Optional) Default configurations&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Parameter&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Type&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--low_poly&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;If True, uses standard config for a low poly mesh, with &lt;code&gt;200_000&lt;/code&gt; vertices and &lt;code&gt;6&lt;/code&gt; Gaussians per triangle.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--high_poly&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;If True, uses standard config for a high poly mesh, with &lt;code&gt;1_000_000&lt;/code&gt; vertices and &lt;code&gt;1&lt;/code&gt; Gaussians per triangle.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;--refinement_time&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Default configs for time to spend on refinement. Can be &lt;code&gt;&#34;short&#34;&lt;/code&gt; (2k iterations), &lt;code&gt;&#34;medium&#34;&lt;/code&gt; (7k iterations) or &lt;code&gt;&#34;long&#34;&lt;/code&gt; (15k iterations).&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Tips for using SuGaR on your own data and obtain better reconstructions&lt;/h2&gt; &#xA;&lt;h3&gt;1. Capture images or videos that cover the entire surface of the scene&lt;/h3&gt; &#xA;&lt;p&gt;Using a smartphone or a camera, capture images or a video that cover the entire surface of the 3D scene you want to reconstruct. The easiest way to do this is to move around the scene while recording a video. Try to move slowly and smoothly in order to avoid motion blur. For consistent reconstruction and easier camera pose estimation with COLMAP, maintaining a uniform focal length and a constant exposure time is also important. We recommend to disable auto-focus on your smartphone to ensure that the focal length remains constant.&lt;/p&gt; &#xA;&lt;p&gt;For better reconstructions, try to cover objects from several and different angles, especially for thin and detailed parts of the scene. Indeed, SuGaR is able to reconstruct very thin and detailed objects, but some artifacts may appear if these thin objects are not covered enough and are visible only from one side in the training images.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;span style=&#34;font-weight: bold;&#34;&gt;Detailed explanation&lt;/span&gt;&lt;/summary&gt; SuGaR applies Poisson reconstruction with 3D points sampled on the parts of the surface that are visible in the training images. This visibility constraint is important to prevent sampling points on the backside of the Gaussian level sets, located behind the surface of the scene, which would produce a lot of self-collisions and many unnecessary vertices in the mesh after applying Poisson reconstruction. However, this visibility constraint also means that SuGaR cannot reconstruct parts of the surface that are not visible in the training images. If thin objects are visible only from one side in the training images, the Poisson reconstruction will try to reconstruct a closed surface, and will extend the surface of the thin objects, which produces an inaccurate mesh. &#xA; &lt;p&gt;&lt;em&gt;TODO: Add images illustrating such artifacts.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/details&gt;&#xA;&lt;br&gt; &#xA;&lt;p&gt;However, such artifacts are not visible in the hybrid representation, because the gaussian texturing gives low-opacity to these artifacts during refinement.&lt;/p&gt; &#xA;&lt;p&gt;We already have simple ideas that could help to avoid such artifacts, such as &lt;strong&gt;(a)&lt;/strong&gt; identifying new camera poses that cover parts of the surface non-visible in the training images that are likely to be on the same level set as the visible parts, and &lt;strong&gt;(b)&lt;/strong&gt; adding these camera poses to the set of cameras used for sampling the points when applying Poisson reconstruction. We will update the code in a near future to include this.&lt;/p&gt; &#xA;&lt;p&gt;To convert a video to images, you can install &lt;code&gt;ffmpeg&lt;/code&gt; and run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ffmpeg -i &amp;lt;Path to the video file&amp;gt; -qscale:v 1 -qmin 1 -vf fps=&amp;lt;FPS&amp;gt; %04d.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;&amp;lt;FPS&amp;gt;&lt;/code&gt; is the desired sampling rate of the video images. An FPS value of 1 corresponds to sampling one image per second. We recommend to adjust the sampling rate to the length of the video, so that the number of sampled images is between 100 and 300.&lt;/p&gt; &#xA;&lt;h3&gt;2. Estimate camera poses with COLMAP&lt;/h3&gt; &#xA;&lt;p&gt;Please first install a recent version of COLMAP (ideally CUDA-powered) and make sure to put the images you want to use in a directory &lt;code&gt;&amp;lt;location&amp;gt;/input&lt;/code&gt;. Then, run the script &lt;code&gt;gaussian_splatting/convert.py&lt;/code&gt; from the original Gaussian splatting implementation to compute the camera poses from the images using COLMAP. Please refer to the original &lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;3D Gaussian Splatting repository&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python gaussian_splatting/convert.py -s &amp;lt;location&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Sometimes COLMAP fails to reconstruct all images into the same model and hence produces multiple sub-models. The smaller sub-models generally contain only a few images. However, by default, the script &lt;code&gt;convert.py&lt;/code&gt; will apply Image Undistortion only on the first sub-model, which may contain only a few images.&lt;/p&gt; &#xA;&lt;p&gt;If this is the case, a simple solution is to keep only the largest sub-model and discard the others. To do this, open the source directory containing your input images, then open the sub-directory &lt;code&gt;&amp;lt;Source_directory&amp;gt;/distorted/sparse/&lt;/code&gt;. You should see several sub-directories named &lt;code&gt;0/&lt;/code&gt;, &lt;code&gt;1/&lt;/code&gt;, etc., each containing a sub-model. Remove all sub-directories except the one containing the largest files, and rename it to &lt;code&gt;0/&lt;/code&gt;. Then, run the script &lt;code&gt;convert.py&lt;/code&gt; one more time but skip the matching process:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python gaussian_splatting/convert.py -s &amp;lt;location&amp;gt; --skip_matching&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: If the sub-models have common registered images, they could be merged into a single model as post-processing step using COLMAP; However, merging sub-models requires to run another global bundle adjustment after the merge, which can be time consuming.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;3. Density or SDF? Choose a regularization method that fits your scene&lt;/h3&gt; &#xA;&lt;p&gt;As we explain in the paper, we provide two separate regularization methods for SuGaR: a density regularization and an SDF regularization. The density regularization is the simplest one and works well with objects centered in the scene. The SDF provides a stronger regularization, especially in background regions. As a consequence, the SDF regularization produces higher metrics on standard datasets. However, for reconstructing an object centered in the scene with images taken from all around the object, the simpler density regularization generally produces a better mesh.&lt;/p&gt; &#xA;&lt;p&gt;Therefore, we recommend the following when using the &lt;code&gt;train.py&lt;/code&gt; script:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For reconstructing detailed objects centered in the scene with 360° coverage (such as the toys we reconstructed in our presentation video), start with the density regularization &lt;code&gt;-r &#39;density&#39;&lt;/code&gt;. However, this may result in more chaotic Gaussians in the background.&lt;/li&gt; &#xA; &lt;li&gt;For reconstructing more challenging scenes or enforcing a stronger regularization in the background, use the SDF regularization &lt;code&gt;-r &#39;sdf&#39;&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;4. (Optional) Adapt the scale and the bounding box of the scene&lt;/h3&gt; &#xA;&lt;p&gt;As it is explained in the original &lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;3D Gaussian Splatting repository&lt;/a&gt;, the method is expected to reconstruct a scene with reasonable scale. For reconstructing much larger datasets, like a city district, the original authors recommend to lower the learning rates of the positions and scaling factors of the Gaussians. The more extensive the scene, the lower these values should be.&lt;/p&gt; &#xA;&lt;p&gt;Concerning SuGaR, such learning rates should also be lowered when reconstructing a very large scene. Moreover, as we explain in the supplementary material of the paper, for extracting a mesh from the Gaussians with an optimal repartition of vertices, we apply two Poisson reconstructions in practice: one on &lt;em&gt;foreground&lt;/em&gt; Gaussians, and one on &lt;em&gt;background&lt;/em&gt; Gaussians. The foreground Gaussians are defined as the Gaussians located inside a predefined bounding box, and the background Gaussians are defined as the Gaussians located outside this bounding box.&lt;/p&gt; &#xA;&lt;p&gt;By default, this bounding box is computed as the bounding box of all camera centers. This general approach is coherent with how the original 3D Gaussian Splatting scales the learning rates. We used this default bounding box for all the reconstructions shown in the paper and the presentation video.&lt;/p&gt; &#xA;&lt;p&gt;However, this bounding box might not be optimal in very specific cases, especially when the user wants to reconstruct with high details a very specific object located somewhere in the scene, or if the scene is very large, or if the camera centers are very far from the scene. The user is free to provide a custom bounding box to the &lt;code&gt;train.py&lt;/code&gt; script, using the parameters &lt;code&gt;--bboxmin&lt;/code&gt; and &lt;code&gt;--bboxmax&lt;/code&gt;. Please note that the bounding box must be provided as strings, formatted as &lt;code&gt;&#34;(x,y,z)&#34;&lt;/code&gt;, where &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt; are the coordinates of the min and max points of the bounding box.&lt;/p&gt; &#xA;&lt;h2&gt;Rendering, composition and animation&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;metrics.py&lt;/code&gt; script provides an example of how to load a refined SuGaR model for rendering a scene with the hybrid representation and the Gaussian Splatting rasterizer. We will add more details about this in a near future, as well as a notebook with a detailed tutorial.&lt;/p&gt; &#xA;&lt;p&gt;We also provide in the &lt;code&gt;blender&lt;/code&gt; directory several python scripts to export from Blender composition and animation data of SuGaR meshes modified or animated within Blender. Additionally, we provide in the &lt;code&gt;sugar_scene/sugar_compositor.py&lt;/code&gt; script a Python class that can be used to import such animation or composition data into PyTorch and apply it to the SuGaR hybrid representation.&lt;/p&gt; &#xA;&lt;p&gt;The hybrid representation allows for high-quality rendering of the scene with the Gaussian Splatting rasterizer, as shown below.&lt;br&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Anttwo/SuGaR/main/media/blender/full_teaser.png&#34; alt=&#34;teaser.gif&#34; width=&#34;800&#34;&gt; &#xA;&lt;/div&gt;&#xA;&lt;br&gt; &#xA;&lt;p&gt;The usage of these scripts and class may be a bit tricky, so we will add a detailed tutorial on how to use them in a near future.&lt;/p&gt; &#xA;&lt;h2&gt;Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;To evaluate the quality of the reconstructions, we provide a script &lt;code&gt;metrics.py&lt;/code&gt; that computes the PSNR, SSIM and LPIPS metrics on test images. Start by optimizing SuGaR models for the desired scenes and a regularization method (&lt;code&gt;&#34;density&#34;&lt;/code&gt; or &lt;code&gt;&#34;sdf&#34;&lt;/code&gt;), then create a &lt;code&gt;.json&lt;/code&gt; config file containing the paths to the scenes in the following format: &lt;code&gt;{source_images_dir_path: vanilla_gaussian_splatting_checkpoint_path}&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Finally, run the script as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python metrics.py --scene_config &amp;lt;Path to the .json file&amp;gt; -r &amp;lt;&#34;sdf&#34; or &#34;density&#34;&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Results are saved in a &lt;code&gt;.json&lt;/code&gt; file in the &lt;code&gt;output/metrics/&lt;/code&gt; directory. Please refer to the script for more details on the command line arguments.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cagnulein/qdomyos-zwift</title>
    <updated>2023-12-21T01:27:27Z</updated>
    <id>tag:github.com,2023-12-21:/cagnulein/qdomyos-zwift</id>
    <link href="https://github.com/cagnulein/qdomyos-zwift" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Zwift bridge for smart treadmills and bike/cyclette&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;qdomyos-zwift&lt;/h1&gt; &#xA;&lt;p&gt;Zwift bridge for Treadmills and Bike!&lt;/p&gt; &#xA;&lt;h2&gt;QZ is not affiliated with or endorsed by any subscription service or maker of exercise equipment.&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://play.google.com/store/apps/details?id=org.cagnulen.qdomyoszwift&amp;amp;fbclid=IwAR3CVoYb0scvGf7gb0Y20VFh5Na5fDWwe7VACk-2c45Tm0x5s8sXpIGhGyw&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/docs/img/google_play.png&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://apps.apple.com/app/id1543684531?fbclid=IwAR10H6y3mEgwkTlGJON3e8voYOh2wt3kLFOpFzoIXaYZ_N0y0pDvKxHMUaM&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/docs/img/app_store.png&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.buymeacoffee.com/cagnulein&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png&#34; alt=&#34;Buy Me A Coffee&#34; style=&#34;height: 41px !important;width: 174px !important;box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/icons/AppScreen/iOS%20Phones%20-%206.5_/screenshot1.jpeg&#34; style=&#34;height: 400px !important; box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/icons/AppScreen/iOS%20Phones%20-%206.5_/screenshot2.jpeg&#34; style=&#34;height: 400px !important; box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/icons/AppScreen/iOS%20Phones%20-%206.5_/screenshot3.jpeg&#34; style=&#34;height: 400px !important; box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/icons/AppScreen/iOS%20Phones%20-%206.5_/screenshot4.jpeg&#34; style=&#34;height: 400px !important; box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/icons/AppScreen/iOS%20Phones%20-%206.5_/screenshot5.jpeg&#34; style=&#34;height: 400px !important; box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;h1&gt;UI Features&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Bike&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Treadmill&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Elliptical&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Rower&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Tiles Customization&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;Order and visibility of each tile&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Profiles&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;Different user or different fitness device profiles&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;UI Zoom Customization&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Peloton Features&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Bike&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Treadmill&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Elliptical&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Rower&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Bike metrics on the peloton app&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Power zone with auto resistance&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peloton real-time resistance conversion&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;with the possibility to customize it&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peloton real-time auto-resistance&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;with the possibility to customize it&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peloton auto speed and auto inclination&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;with the possibility to customize it&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Heart Rate Features&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Bike&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Treadmill&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Elliptical&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Rower&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Heart Rate support&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;Apple Watch, ANT+ devices and Bluetooth devices&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Heart Rate Zones Customizations&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Ability to calculate Wattage from HR and Cadence&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;for the bikes that doesn&#39;t have a power sensor&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;3rd Apps Compatibility&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Bike&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Treadmill&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Elliptical&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Rower&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Zwift Compatibility&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Zwift Auto resistance&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Zwift Auto inclination and speed&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=KTQ2n7yeDbo&#34;&gt;https://www.youtube.com/watch?v=KTQ2n7yeDbo&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Wahoo RGT Compatibility&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;VzFit Compatibility&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Rouvy Compatibility&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;IFIT app Compatibility&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Echelon app Compatibility&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Wahoo Dircon Compatibility&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;in order to send data to Zwift or RGT with Wifi only!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;One device only support for Zwift and Wahoo RGT&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;using Wahoo Dircon &lt;a href=&#34;https://www.youtube.com/watch?v=gYYUXNWFAok&#34;&gt;https://www.youtube.com/watch?v=gYYUXNWFAok&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Training Program&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Bike&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Treadmill&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Elliptical&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Rower&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Builtin video support (Kinomap like)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;Files could be local or on the cloud!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;GPX auto following&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;2D/3D maps for GPX&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ZWO (Zwift workout file) compatibility&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;XML Workout file compatibility&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Auto follow workout based on your heart rate&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Random workout&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Statistics&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Bike&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Treadmill&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Elliptical&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Rower&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;E-Mail report&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;at the end of the workout&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Strava integration&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;press stop at the end of the workout to auto upload it&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Misc&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Bike&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Treadmill&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Elliptical&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Rower&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Resistance shifting with bluetooth remote&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;TTS support&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;You can install it on multiple platforms. Read the &lt;a href=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/docs/10_Installation.md&#34;&gt;installation procedure&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Tested on&lt;/h3&gt; &#xA;&lt;p&gt;You can run the app on &lt;a href=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/docs/10_Installation.md&#34;&gt;Macintosh or Linux devices&lt;/a&gt;. IOS and Android are also supported.&lt;/p&gt; &#xA;&lt;p&gt;QDomyos-Zwift works on every &lt;a href=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/docs/20_supported_devices_and_applications.md&#34;&gt;FTMS-compatible application&lt;/a&gt;, and virtually any &lt;a href=&#34;https://raw.githubusercontent.com/cagnulein/qdomyos-zwift/master/docs/20_supported_devices_and_applications.md&#34;&gt;bluetooth enabled device&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;No GUI version&lt;/h3&gt; &#xA;&lt;p&gt;run as&lt;/p&gt; &#xA;&lt;p&gt;$ sudo ./qdomyos-zwift -no-gui&lt;/p&gt; &#xA;&lt;h3&gt;Reference&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ProH4Ck/treadmill-bridge&#34;&gt;https://github.com/ProH4Ck/treadmill-bridge&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.livestrong.com/article/422012-what-is-10-degrees-in-incline-on-a-treadmill/&#34;&gt;https://www.livestrong.com/article/422012-what-is-10-degrees-in-incline-on-a-treadmill/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Icons used in this documentation come from &lt;a href=&#34;https://www.flaticon.com&#34;&gt;flaticon.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Blog&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://robertoviola.cloud&#34;&gt;https://robertoviola.cloud&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Librum-Reader/Librum</title>
    <updated>2023-12-21T01:27:27Z</updated>
    <id>tag:github.com,2023-12-21:/Librum-Reader/Librum</id>
    <link href="https://github.com/Librum-Reader/Librum" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Librum client application&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Librum&lt;/h1&gt; &#xA;&lt;p&gt;Librum is an application designed to make reading &lt;b&gt;enjoyable&lt;/b&gt; and &lt;b&gt;straightforward&lt;/b&gt; for everyone.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s not &lt;strong&gt;just&lt;/strong&gt; an e-book reader. With Librum, you can manage your own online library and access it from any device anytime, anywhere. It has features like note-taking, bookmarking, and highlighting, while offering customization to make it as personal as you want!&lt;/p&gt; &#xA;&lt;p&gt;Librum also provides free access to over 70,000 books and personal reading statistics while being free and completely open source.&lt;/p&gt; &#xA;&lt;h1&gt;Preview&lt;/h1&gt; &#xA;&lt;p&gt;A simple and modern interface&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Librum-Reader/Librum/assets/69865187/bf1d0401-62bd-4f4e-b008-523fb2efd275&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Setup and manage your own library&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Librum-Reader/Librum/assets/69865187/ea94fc68-1bf0-4933-8d80-43a57c6590c5&#34; alt=&#34;HomeScreenDark&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Customize Librum to make it personal to you&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Librum-Reader/Librum/assets/69865187/b8995cf1-a0e6-4993-8c8b-92f7f8e79ebd&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;How can I get Librum?&lt;/h1&gt; &#xA;&lt;p&gt;Simply go to &lt;a href=&#34;https://librumreader.com&#34;&gt;https://librumreader.com&lt;/a&gt; to download Librum.&lt;/p&gt; &#xA;&lt;p&gt;If you want to build Librum from source, follow the instructions &lt;a href=&#34;https://raw.githubusercontent.com/Librum-Reader/Librum/main/#build-guide&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Translations&lt;/h1&gt; &#xA;&lt;p&gt;Librum is currently available in:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;English&lt;/li&gt; &#xA; &lt;li&gt;German&lt;/li&gt; &#xA; &lt;li&gt;Russian&lt;/li&gt; &#xA; &lt;li&gt;Mandarin&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you want to translate Librum to another language, follow the steps below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download the file at: &lt;a href=&#34;https://github.com/Librum-Reader/Librum/raw/main/src/presentation/translations/librum_en.ts&#34;&gt;https://github.com/Librum-Reader/Librum/blob/main/src/presentation/translations/librum_en.ts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Rename the file to contain your language&#39;s suffix, e.g. &#34;librum_ru.ts&#34; for Russian or &#34;librum_de.ts&#34; for German&lt;/li&gt; &#xA; &lt;li&gt;Download the translation software (Qt Linguist) either for Windows from &lt;a href=&#34;https://github.com/thurask/Qt-Linguist&#34;&gt;https://github.com/thurask/Qt-Linguist&lt;/a&gt; or using the Qt Installer at &lt;a href=&#34;https://www.qt.io/download-open-source&#34;&gt;https://www.qt.io/download-open-source&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Now start Qt Linguist, open the downloaded file, set the target language to the language you want to translate to and start translating. (For a quick guide on Qt Linguist, check out: &lt;a href=&#34;https://youtu.be/xNIz78IPBu0?t=347&#34;&gt;https://youtu.be/xNIz78IPBu0?t=347&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Once you are done, create a pull request or an issue with your new translation file!&lt;br&gt; If you run into any problems, need guidance or have questions, feel free to reach out to us at: &lt;a href=&#34;mailto:contact@librumreader.com&#34;&gt;contact@librumreader.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Notes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make sure that your translations are approximately the same length as the original text&lt;/li&gt; &#xA; &lt;li&gt;Make sure that you keep to the punctuation and capitalisation&lt;/li&gt; &#xA; &lt;li&gt;Make sure that your translations make sense in the context they are in&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p&gt;For documentation go to &lt;a href=&#34;https://github.com/Librum-Reader/Librum/wiki&#34;&gt;Librum&#39;s GitHub-wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Donations&lt;/h1&gt; &#xA;&lt;p&gt;Donations make it possible for us to cover our server costs and allow us to make investments into new areas of development. &lt;br&gt; If you would like to support us, check out: &lt;a href=&#34;https://librumreader.com/contribute/donate&#34;&gt;https://librumreader.com/contribute/donate&lt;/a&gt; or become a github sponsor! &lt;br&gt; &lt;br&gt; As a team of opensource developers we rely on donations to continue working on projects like Librum. Your help is greatly appreciated.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;If you&#39;d like to contribute, check out: &lt;a href=&#34;https://librumreader.com/contribute&#34;&gt;https://librumreader.com/contribute&lt;/a&gt; &lt;br&gt; &lt;br&gt; If you are interested in contributing, feel free to contact us on either:&lt;br&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Discord (m_david#0631)&lt;/li&gt; &#xA; &lt;li&gt;Email (&lt;a href=&#34;mailto:contact@librumreader.com&#34;&gt;contact@librumreader.com&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; We are following a pull request workflow where every contribution is sent as a pull request and merged into the dev/develop branch for testing. &#xA;&lt;br&gt; Please make sure to run clang format, keep to the conventions used throughout the application and ensure that all tests pass, before submitting any pull request. &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Contact&lt;/h1&gt; &#xA;&lt;p&gt;For questions, you can reach us under: &lt;a href=&#34;mailto:help@librumreader.com&#34;&gt;help@librumreader.com&lt;/a&gt; &lt;br&gt; For business related contact, reach out to us here: &lt;a href=&#34;mailto:contact@librumreader.com&#34;&gt;contact@librumreader.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Details&lt;/h1&gt; &#xA;&lt;h3&gt;Supported platforms&lt;/h3&gt; &#xA;&lt;p&gt;Part of Librum&#39;s aim is to work on &lt;strong&gt;any&lt;/strong&gt; platform. No matter where you are or which device you use, you can always continue your book with Librum, as it is &lt;b&gt;cross platform&lt;/b&gt;.&lt;br&gt; We support:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows&lt;/li&gt; &#xA; &lt;li&gt;GNU/Linux&lt;/li&gt; &#xA; &lt;li&gt;MacOS&lt;/li&gt; &#xA; &lt;li&gt;IOS (Coming Soon)&lt;/li&gt; &#xA; &lt;li&gt;Android (Coming Soon)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Supported formats&lt;/h3&gt; &#xA;&lt;p&gt;Librum is the best choice for all kinds of books, since Librum supports &lt;b&gt;all&lt;/b&gt; major book formats&lt;br&gt; including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PDF&lt;/li&gt; &#xA; &lt;li&gt;EPUB&lt;/li&gt; &#xA; &lt;li&gt;CBZ (Comic books)&lt;/li&gt; &#xA; &lt;li&gt;XPS&lt;/li&gt; &#xA; &lt;li&gt;PS&lt;/li&gt; &#xA; &lt;li&gt;All plain text formats&lt;/li&gt; &#xA; &lt;li&gt;Images&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;p&gt;Librum&#39;s objective is to make your reading more &lt;b&gt;productive&lt;/b&gt;; to that end, we provide you with a variety of features that you can access via a &lt;b&gt;simple&lt;/b&gt; and &lt;b&gt;straightforward&lt;/b&gt; interface.&lt;br&gt; These features include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A modern e-reader&lt;/li&gt; &#xA; &lt;li&gt;A personalized and customizable library&lt;/li&gt; &#xA; &lt;li&gt;Book meta-data editing&lt;/li&gt; &#xA; &lt;li&gt;A free in-app bookstore with more than 70.000 books&lt;/li&gt; &#xA; &lt;li&gt;Book syncing across all of your devices&lt;/li&gt; &#xA; &lt;li&gt;Highlighting&lt;/li&gt; &#xA; &lt;li&gt;Bookmarking&lt;/li&gt; &#xA; &lt;li&gt;Text search&lt;/li&gt; &#xA; &lt;li&gt;Unlimited customization&lt;/li&gt; &#xA; &lt;li&gt;Note-taking (Coming Soon)&lt;/li&gt; &#xA; &lt;li&gt;TTS (Coming Soon)&lt;/li&gt; &#xA; &lt;li&gt;Personalized reading statistics (Coming Soon)&lt;/li&gt; &#xA; &lt;li&gt;No-login book reading (Coming Soon)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Want a new feature? Feel free to leave a feature request ticket!&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Build Guide&lt;/h1&gt; &#xA;&lt;p&gt;Follow this guide to build Librum from source. &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;For GNU/Linux&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;cmake (&lt;a href=&#34;https://cmake.org/download&#34;&gt;https://cmake.org/download&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;make (&lt;a href=&#34;http://ftp.gnu.org/gnu/make&#34;&gt;http://ftp.gnu.org/gnu/make&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;g++ (&lt;a href=&#34;https://gcc.gnu.org&#34;&gt;https://gcc.gnu.org&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;python3-venv (on ubuntu use &lt;code&gt;sudo apt install python3-venv&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Qt 6.5 (&lt;a href=&#34;https://www.qt.io/download-open-source&#34;&gt;https://www.qt.io/download-open-source&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;The installation is straight forward, just follow the steps below:&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/Librum-Reader/Librum.git --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Step into the cloned project folder. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd Librum&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Create the build folder and step into it. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mkdir build-Release&#xA;cd build-Release&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Run cmake. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=&amp;lt;path/to/Qt&amp;gt; ..&#xA;&lt;/code&gt;&lt;/pre&gt; Set &lt;code&gt;CMAKE_PREFIX_PATH&lt;/code&gt; to your Qt installation path. Installing Qt via the online installer usually installs it to &lt;code&gt;/home/&amp;lt;name&amp;gt;/Qt/&amp;lt;version&amp;gt;/gcc_64&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Build the project &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake --build . -j $(nproc)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Install Librum &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake --install .&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Troubleshooting&lt;/h3&gt; &#xA;&lt;p&gt;Here are solutions to some common errors. If your error is not listed here, please open an issue. &lt;br&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Error: &lt;code&gt;Failed to find required Qt component &#34;Quick&#34;.&lt;/code&gt;&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Solution: Install the libGL mesa dev package, on ubuntu its &lt;code&gt;sudo apt install libgl1-mesa-dev&lt;/code&gt; and on fedora its &lt;code&gt;sudo dnf install mesa-libGL-devel&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Error: &lt;code&gt;Could not load the qt platform plugin &#34;xcb&#34; even though it was found&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Solution: Install the libxcb-cursor-dev, on ubuntu its &lt;code&gt;sudo apt install libxcb-cursor-dev&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;For Windows&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;cmake (&lt;a href=&#34;https://cmake.org/download&#34;&gt;https://cmake.org/download&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Visual Studio &lt;b&gt;19&lt;/b&gt; (&lt;a href=&#34;https://visualstudio.microsoft.com/de/vs/older-downloads&#34;&gt;https://visualstudio.microsoft.com/de/vs/older-downloads&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Python (&lt;a href=&#34;https://www.python.org/downloads&#34;&gt;https://www.python.org/downloads&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Qt 6.5 (&lt;a href=&#34;https://www.qt.io/download-open-source&#34;&gt;https://www.qt.io/download-open-source&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;To build Librum on windows, run the following commands in the Powershell:&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/Librum-Reader/Librum.git --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Step into the cloned project folder. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd Librum&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Create the build folder and step into it. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mkdir build&#xA;cd build&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Run cmake. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=&amp;lt;path/to/qt&amp;gt; ..&#xA;&lt;/code&gt;&lt;/pre&gt; Set &lt;code&gt;CMAKE_PREFIX_PATH&lt;/code&gt; to your Qt installation path. Installing Qt via the online installer usually installs it to &lt;code&gt;&amp;lt;Drive&amp;gt;\\Qt\\&amp;lt;version&amp;gt;\\msvc2019_64&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Build the project &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Run the app &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./librum&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Additional Info&lt;/h3&gt; &#xA;&lt;p&gt;Here are some things to keep in mind during the build process. &lt;br&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make sure to add cmake and the Qt binaries to the &lt;code&gt;PATH&lt;/code&gt; environment variable&lt;/li&gt; &#xA; &lt;li&gt;You need Visual Studio 2019, newer versions will &lt;strong&gt;not&lt;/strong&gt; work&lt;/li&gt; &#xA; &lt;li&gt;For the Qt installation, you &lt;strong&gt;only&lt;/strong&gt; need to choose &#34;MSVC 2019 64-bit&#34;, you can untick everything else to reduce the download size&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;For MacOS&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;cmake (&lt;a href=&#34;https://cmake.org/download&#34;&gt;https://cmake.org/download&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;make (&lt;a href=&#34;http://ftp.gnu.org/gnu/make&#34;&gt;http://ftp.gnu.org/gnu/make&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;g++ (&lt;a href=&#34;https://gcc.gnu.org&#34;&gt;https://gcc.gnu.org&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;python3 (&lt;a href=&#34;https://www.python.org/downloads&#34;&gt;https://www.python.org/downloads&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Qt 6.5 (&lt;a href=&#34;https://www.qt.io/download-open-source&#34;&gt;https://www.qt.io/download-open-source&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;The installation is straight forward, just follow the steps below:&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/Librum-Reader/Librum.git --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Step into the cloned project folder. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd Librum&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Create the build folder and step into it. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mkdir build-Release&#xA;cd build-Release&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Run cmake. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake -DCMAKE_INSTALL_PREFIX=/usr/local -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=&amp;lt;path/to/Qt&amp;gt; ..&#xA;&lt;/code&gt;&lt;/pre&gt; Set &lt;code&gt;CMAKE_PREFIX_PATH&lt;/code&gt; to your Qt installation path. Installing Qt via the online installer usually installs it to &lt;code&gt;/Users/&amp;lt;name&amp;gt;/Qt/&amp;lt;version&amp;gt;/macos&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Build the project &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake --build . -j $(nproc)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Install Librum &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake --install .&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt;</summary>
  </entry>
</feed>