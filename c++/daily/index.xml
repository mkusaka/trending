<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-30T01:31:43Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>OpenNMT/CTranslate2</title>
    <updated>2023-03-30T01:31:43Z</updated>
    <id>tag:github.com,2023-03-30:/OpenNMT/CTranslate2</id>
    <link href="https://github.com/OpenNMT/CTranslate2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fast inference engine for Transformer models&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/OpenNMT/CTranslate2/actions?query=workflow%3ACI&#34;&gt;&lt;img src=&#34;https://github.com/OpenNMT/CTranslate2/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://badge.fury.io/py/ctranslate2&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/ctranslate2.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opennmt.net/CTranslate2/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-latest-blue.svg?sanitize=true&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/OpenNMT/CTranslate2?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/OpenNMT/CTranslate2.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://forum.opennmt.net/&#34;&gt;&lt;img src=&#34;https://img.shields.io/discourse/status?server=https%3A%2F%2Fforum.opennmt.net%2F&#34; alt=&#34;Forum&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;CTranslate2&lt;/h1&gt; &#xA;&lt;p&gt;CTranslate2 is a C++ and Python library for efficient inference with Transformer models.&lt;/p&gt; &#xA;&lt;p&gt;The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to &lt;a href=&#34;https://raw.githubusercontent.com/OpenNMT/CTranslate2/master/#benchmarks&#34;&gt;accelerate and reduce the memory usage&lt;/a&gt; of Transformer models on CPU and GPU. The following model types are currently supported:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Encoder-decoder models: Transformer base/big, M2M-100, NLLB, BART, mBART, Pegasus, T5, Whisper&lt;/li&gt; &#xA; &lt;li&gt;Decoder-only models: GPT-2, OPT, BLOOM&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Compatible models should be first converted into an optimized model format. The library includes converters for multiple frameworks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opennmt.net/CTranslate2/guides/opennmt_py.html&#34;&gt;OpenNMT-py&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opennmt.net/CTranslate2/guides/opennmt_tf.html&#34;&gt;OpenNMT-tf&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opennmt.net/CTranslate2/guides/fairseq.html&#34;&gt;Fairseq&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opennmt.net/CTranslate2/guides/marian.html&#34;&gt;Marian&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opennmt.net/CTranslate2/guides/opus_mt.html&#34;&gt;OPUS-MT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opennmt.net/CTranslate2/guides/transformers.html&#34;&gt;Transformers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The project is production-oriented and comes with &lt;a href=&#34;https://opennmt.net/CTranslate2/versioning.html&#34;&gt;backward compatibility guarantees&lt;/a&gt;, but it also includes experimental features related to model compression and inference acceleration.&lt;/p&gt; &#xA;&lt;h2&gt;Key features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fast and efficient execution on CPU and GPU&lt;/strong&gt;&lt;br&gt;The execution &lt;a href=&#34;https://raw.githubusercontent.com/OpenNMT/CTranslate2/master/#benchmarks&#34;&gt;is significantly faster and requires less resources&lt;/a&gt; than general-purpose deep learning frameworks on supported models and tasks thanks to many advanced optimizations: layer fusion, padding removal, batch reordering, in-place operations, caching mechanism, etc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Quantization and reduced precision&lt;/strong&gt;&lt;br&gt;The model serialization and computation support weights with &lt;a href=&#34;https://opennmt.net/CTranslate2/quantization.html&#34;&gt;reduced precision&lt;/a&gt;: 16-bit floating points (FP16), 16-bit integers (INT16), and 8-bit integers (INT8).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multiple CPU architectures support&lt;/strong&gt;&lt;br&gt;The project supports x86-64 and AArch64/ARM64 processors and integrates multiple backends that are optimized for these platforms: &lt;a href=&#34;https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/onemkl.html&#34;&gt;Intel MKL&lt;/a&gt;, &lt;a href=&#34;https://github.com/oneapi-src/oneDNN&#34;&gt;oneDNN&lt;/a&gt;, &lt;a href=&#34;https://www.openblas.net/&#34;&gt;OpenBLAS&lt;/a&gt;, &lt;a href=&#34;https://github.com/google/ruy&#34;&gt;Ruy&lt;/a&gt;, and &lt;a href=&#34;https://developer.apple.com/documentation/accelerate&#34;&gt;Apple Accelerate&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Automatic CPU detection and code dispatch&lt;/strong&gt;&lt;br&gt;One binary can include multiple backends (e.g. Intel MKL and oneDNN) and instruction set architectures (e.g. AVX, AVX2) that are automatically selected at runtime based on the CPU information.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Parallel and asynchronous execution&lt;/strong&gt;&lt;br&gt;Multiple batches can be processed in parallel and asynchronously using multiple GPUs or CPU cores.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Dynamic memory usage&lt;/strong&gt;&lt;br&gt;The memory usage changes dynamically depending on the request size while still meeting performance requirements thanks to caching allocators on both CPU and GPU.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Lightweight on disk&lt;/strong&gt;&lt;br&gt;Quantization can make the models 4 times smaller on disk with minimal accuracy loss.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Simple integration&lt;/strong&gt;&lt;br&gt;The project has few dependencies and exposes simple APIs in &lt;a href=&#34;https://opennmt.net/CTranslate2/python/overview.html&#34;&gt;Python&lt;/a&gt; and C++ to cover most integration needs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Configurable and interactive decoding&lt;/strong&gt;&lt;br&gt;&lt;a href=&#34;https://opennmt.net/CTranslate2/decoding.html&#34;&gt;Advanced decoding features&lt;/a&gt; allow autocompleting a partial sequence and returning alternatives at a specific location in the sequence.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Some of these features are difficult to achieve with standard deep learning frameworks and are the motivation for this project.&lt;/p&gt; &#xA;&lt;h2&gt;Installation and usage&lt;/h2&gt; &#xA;&lt;p&gt;CTranslate2 can be installed with pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install ctranslate2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The Python module is used to convert models and can translate or generate text with few lines of code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;translator = ctranslate2.Translator(translation_model_path)&#xA;translator.translate_batch(tokens)&#xA;&#xA;generator = ctranslate2.Generator(generation_model_path)&#xA;generator.generate_batch(start_tokens)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://opennmt.net/CTranslate2&#34;&gt;documentation&lt;/a&gt; for more information and examples.&lt;/p&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;We translate the En-&amp;gt;De test set &lt;em&gt;newstest2014&lt;/em&gt; with multiple models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opennmt.net/Models-tf/#translation&#34;&gt;OpenNMT-tf WMT14&lt;/a&gt;: a base Transformer trained with OpenNMT-tf on the WMT14 dataset (4.5M lines)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opennmt.net/Models-py/#translation&#34;&gt;OpenNMT-py WMT14&lt;/a&gt;: a base Transformer trained with OpenNMT-py on the WMT14 dataset (4.5M lines)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Helsinki-NLP/OPUS-MT-train/tree/master/models/en-de#opus-2020-02-26zip&#34;&gt;OPUS-MT&lt;/a&gt;: a base Transformer trained with Marian on all OPUS data available on 2020-02-26 (81.9M lines)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The benchmark reports the number of target tokens generated per second (higher is better). The results are aggregated over multiple runs. See the &lt;a href=&#34;https://raw.githubusercontent.com/OpenNMT/CTranslate2/master/tools/benchmark&#34;&gt;benchmark scripts&lt;/a&gt; for more details and reproduce these numbers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note that the results presented below are only valid for the configuration used during this benchmark: absolute and relative performance may change with different settings.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h4&gt;CPU&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Tokens per second&lt;/th&gt; &#xA;   &lt;th&gt;Max. memory&lt;/th&gt; &#xA;   &lt;th&gt;BLEU&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;OpenNMT-tf WMT14 model&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenNMT-tf 2.31.0 (with TensorFlow 2.11.0)&lt;/td&gt; &#xA;   &lt;td&gt;209.2&lt;/td&gt; &#xA;   &lt;td&gt;2653MB&lt;/td&gt; &#xA;   &lt;td&gt;26.93&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;OpenNMT-py WMT14 model&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenNMT-py 3.0.4 (with PyTorch 1.13.1)&lt;/td&gt; &#xA;   &lt;td&gt;275.8&lt;/td&gt; &#xA;   &lt;td&gt;2012MB&lt;/td&gt; &#xA;   &lt;td&gt;26.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int8&lt;/td&gt; &#xA;   &lt;td&gt;323.3&lt;/td&gt; &#xA;   &lt;td&gt;1359MB&lt;/td&gt; &#xA;   &lt;td&gt;26.72&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CTranslate2 3.6.0&lt;/td&gt; &#xA;   &lt;td&gt;658.8&lt;/td&gt; &#xA;   &lt;td&gt;849MB&lt;/td&gt; &#xA;   &lt;td&gt;26.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int16&lt;/td&gt; &#xA;   &lt;td&gt;733.0&lt;/td&gt; &#xA;   &lt;td&gt;672MB&lt;/td&gt; &#xA;   &lt;td&gt;26.82&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int8&lt;/td&gt; &#xA;   &lt;td&gt;860.2&lt;/td&gt; &#xA;   &lt;td&gt;529MB&lt;/td&gt; &#xA;   &lt;td&gt;26.78&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int8 + vmap&lt;/td&gt; &#xA;   &lt;td&gt;1126.2&lt;/td&gt; &#xA;   &lt;td&gt;598MB&lt;/td&gt; &#xA;   &lt;td&gt;26.64&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;OPUS-MT model&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Transformers 4.26.1 (with PyTorch 1.13.1)&lt;/td&gt; &#xA;   &lt;td&gt;147.3&lt;/td&gt; &#xA;   &lt;td&gt;2332MB&lt;/td&gt; &#xA;   &lt;td&gt;27.90&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Marian 1.11.0&lt;/td&gt; &#xA;   &lt;td&gt;344.5&lt;/td&gt; &#xA;   &lt;td&gt;7605MB&lt;/td&gt; &#xA;   &lt;td&gt;27.93&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int16&lt;/td&gt; &#xA;   &lt;td&gt;330.2&lt;/td&gt; &#xA;   &lt;td&gt;5901MB&lt;/td&gt; &#xA;   &lt;td&gt;27.65&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int8&lt;/td&gt; &#xA;   &lt;td&gt;355.8&lt;/td&gt; &#xA;   &lt;td&gt;4763MB&lt;/td&gt; &#xA;   &lt;td&gt;27.27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CTranslate2 3.6.0&lt;/td&gt; &#xA;   &lt;td&gt;525.0&lt;/td&gt; &#xA;   &lt;td&gt;721MB&lt;/td&gt; &#xA;   &lt;td&gt;27.92&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int16&lt;/td&gt; &#xA;   &lt;td&gt;596.1&lt;/td&gt; &#xA;   &lt;td&gt;660MB&lt;/td&gt; &#xA;   &lt;td&gt;27.53&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int8&lt;/td&gt; &#xA;   &lt;td&gt;696.1&lt;/td&gt; &#xA;   &lt;td&gt;516MB&lt;/td&gt; &#xA;   &lt;td&gt;27.65&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Executed with 4 threads on a &lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/c5/&#34;&gt;&lt;em&gt;c5.2xlarge&lt;/em&gt;&lt;/a&gt; Amazon EC2 instance equipped with an Intel(R) Xeon(R) Platinum 8275CL CPU.&lt;/p&gt; &#xA;&lt;h4&gt;GPU&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Tokens per second&lt;/th&gt; &#xA;   &lt;th&gt;Max. GPU memory&lt;/th&gt; &#xA;   &lt;th&gt;Max. CPU memory&lt;/th&gt; &#xA;   &lt;th&gt;BLEU&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;OpenNMT-tf WMT14 model&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenNMT-tf 2.31.0 (with TensorFlow 2.11.0)&lt;/td&gt; &#xA;   &lt;td&gt;1483.5&lt;/td&gt; &#xA;   &lt;td&gt;3031MB&lt;/td&gt; &#xA;   &lt;td&gt;3122MB&lt;/td&gt; &#xA;   &lt;td&gt;26.94&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;OpenNMT-py WMT14 model&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenNMT-py 3.0.4 (with PyTorch 1.13.1)&lt;/td&gt; &#xA;   &lt;td&gt;1795.2&lt;/td&gt; &#xA;   &lt;td&gt;2973MB&lt;/td&gt; &#xA;   &lt;td&gt;3099MB&lt;/td&gt; &#xA;   &lt;td&gt;26.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FasterTransformer 5.3&lt;/td&gt; &#xA;   &lt;td&gt;6979.0&lt;/td&gt; &#xA;   &lt;td&gt;2402MB&lt;/td&gt; &#xA;   &lt;td&gt;1131MB&lt;/td&gt; &#xA;   &lt;td&gt;26.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- float16&lt;/td&gt; &#xA;   &lt;td&gt;8592.5&lt;/td&gt; &#xA;   &lt;td&gt;1360MB&lt;/td&gt; &#xA;   &lt;td&gt;1135MB&lt;/td&gt; &#xA;   &lt;td&gt;26.80&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CTranslate2 3.6.0&lt;/td&gt; &#xA;   &lt;td&gt;6634.7&lt;/td&gt; &#xA;   &lt;td&gt;1261MB&lt;/td&gt; &#xA;   &lt;td&gt;953MB&lt;/td&gt; &#xA;   &lt;td&gt;26.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int8&lt;/td&gt; &#xA;   &lt;td&gt;8567.2&lt;/td&gt; &#xA;   &lt;td&gt;1005MB&lt;/td&gt; &#xA;   &lt;td&gt;807MB&lt;/td&gt; &#xA;   &lt;td&gt;26.85&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- float16&lt;/td&gt; &#xA;   &lt;td&gt;10990.7&lt;/td&gt; &#xA;   &lt;td&gt;941MB&lt;/td&gt; &#xA;   &lt;td&gt;807MB&lt;/td&gt; &#xA;   &lt;td&gt;26.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int8 + float16&lt;/td&gt; &#xA;   &lt;td&gt;8725.4&lt;/td&gt; &#xA;   &lt;td&gt;813MB&lt;/td&gt; &#xA;   &lt;td&gt;800MB&lt;/td&gt; &#xA;   &lt;td&gt;26.83&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;OPUS-MT model&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Transformers 4.26.1 (with PyTorch 1.13.1)&lt;/td&gt; &#xA;   &lt;td&gt;1022.9&lt;/td&gt; &#xA;   &lt;td&gt;4097MB&lt;/td&gt; &#xA;   &lt;td&gt;2109MB&lt;/td&gt; &#xA;   &lt;td&gt;27.90&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Marian 1.11.0&lt;/td&gt; &#xA;   &lt;td&gt;3241.0&lt;/td&gt; &#xA;   &lt;td&gt;3381MB&lt;/td&gt; &#xA;   &lt;td&gt;2156MB&lt;/td&gt; &#xA;   &lt;td&gt;27.92&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- float16&lt;/td&gt; &#xA;   &lt;td&gt;3962.4&lt;/td&gt; &#xA;   &lt;td&gt;3239MB&lt;/td&gt; &#xA;   &lt;td&gt;1976MB&lt;/td&gt; &#xA;   &lt;td&gt;27.94&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CTranslate2 3.6.0&lt;/td&gt; &#xA;   &lt;td&gt;5876.4&lt;/td&gt; &#xA;   &lt;td&gt;1197MB&lt;/td&gt; &#xA;   &lt;td&gt;754MB&lt;/td&gt; &#xA;   &lt;td&gt;27.92&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int8&lt;/td&gt; &#xA;   &lt;td&gt;7521.9&lt;/td&gt; &#xA;   &lt;td&gt;1005MB&lt;/td&gt; &#xA;   &lt;td&gt;792MB&lt;/td&gt; &#xA;   &lt;td&gt;27.79&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- float16&lt;/td&gt; &#xA;   &lt;td&gt;9296.7&lt;/td&gt; &#xA;   &lt;td&gt;909MB&lt;/td&gt; &#xA;   &lt;td&gt;814MB&lt;/td&gt; &#xA;   &lt;td&gt;27.90&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;- int8 + float16&lt;/td&gt; &#xA;   &lt;td&gt;8362.7&lt;/td&gt; &#xA;   &lt;td&gt;813MB&lt;/td&gt; &#xA;   &lt;td&gt;766MB&lt;/td&gt; &#xA;   &lt;td&gt;27.90&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Executed with CUDA 11 on a &lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/g5/&#34;&gt;&lt;em&gt;g5.xlarge&lt;/em&gt;&lt;/a&gt; Amazon EC2 instance equipped with a NVIDIA A10G GPU (driver version: 510.47.03).&lt;/p&gt; &#xA;&lt;h2&gt;Additional resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opennmt.net/CTranslate2&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://forum.opennmt.net&#34;&gt;Forum&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gitter.im/OpenNMT/CTranslate2&#34;&gt;Gitter&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>zer0condition/ReverseKit</title>
    <updated>2023-03-30T01:31:43Z</updated>
    <id>tag:github.com,2023-03-30:/zer0condition/ReverseKit</id>
    <link href="https://github.com/zer0condition/ReverseKit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;x64 Dynamic Reverse Engineering Toolkit&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;left&#34;&gt; ReverseKit - Dynamic Reverse Engineering Toolkit&lt;br&gt; &lt;img src=&#34;https://i.imgur.com/q92np0W.png&#34; alt=&#34;ReverseKit Logo&#34; align=&#34;right&#34;&gt; &lt;/h1&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/zer0condition/reversekit?style=flat-square&#34; alt=&#34;License&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/zer0condition/reversekit&#34; alt=&#34;Stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/zer0condition/reversekit&#34; alt=&#34;Forks&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;ReverseKit is a comprehensive toolkit designed to aid reverse engineers in the process of dynamic RE. With a wide range of features and functionalities, it provides an easy-to-use interface and helps you intercept, analyze, and manipulate code and data during runtime.&lt;/p&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://raw.githubusercontent.com/zer0condition/ReverseKit/master/#features&#34;&gt;Features&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/zer0condition/ReverseKit/master/#getting-started&#34;&gt;Getting Started&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/zer0condition/ReverseKit/master/#usage&#34;&gt;Usage&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/zer0condition/ReverseKit/master/#contributing&#34;&gt;Contributing&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/zer0condition/ReverseKit/master/#license&#34;&gt;License&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/zer0condition/ReverseKit/master/#youtube-showcase&#34;&gt;Showcase&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Imports information - along with DLL name, function name, and address.&lt;/li&gt; &#xA; &lt;li&gt;Intercept all commands executed - system(), ShellExecuteEx(), etc.&lt;/li&gt; &#xA; &lt;li&gt;Intercept all thread creations - APIs like std::thread, CreateThread(), etc.&lt;/li&gt; &#xA; &lt;li&gt;Intercept URLs - APIs like UrlDownloadToFileA and InternetOpenUrlA, etc.&lt;/li&gt; &#xA; &lt;li&gt;Threads - lists thread ids along with cpu usage, allows you to suspend them with a button.&lt;/li&gt; &#xA; &lt;li&gt;Bypass common debugger checks - CheckRemoteDebugger() and IsDebuggerPresent().&lt;/li&gt; &#xA; &lt;li&gt;Easy-to-use interface powered by ImGui.&lt;/li&gt; &#xA; &lt;li&gt;Hook library with a normal JMP hook and trampoline hook.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started with ReverseKit, you can clone this repository and build the project. Once the build is complete, you can inject the tool and start using it to analyze binaries.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;ReverseKit provides a user-friendly interface that enables you to easily intercept, analyze, and manipulate code and data during runtime. With the wide range of features and functionalities, you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Monitor and intercept system calls and API functions&lt;/li&gt; &#xA; &lt;li&gt;Monitor CPU usage by active threads and option to suspend&lt;/li&gt; &#xA; &lt;li&gt;Analyze network traffic and intercept URLs&lt;/li&gt; &#xA; &lt;li&gt;Analyze and manipulate thread creations&lt;/li&gt; &#xA; &lt;li&gt;Hook into binary code and redirect execution flow&lt;/li&gt; &#xA; &lt;li&gt;Bypass common debugger checks&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the community. If you find a bug or have an idea for a new feature, please open an issue or submit a pull request.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt; &#xA;&lt;h2&gt;Todo&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Fix instrumentation callback crashing for DLL.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;YouTube Showcase&lt;/h2&gt; &#xA;&lt;div&gt; &#xA; &lt;a href=&#34;https://www.youtube.com/watch?v=3P8ck5U_OXY&#34;&gt;&lt;img src=&#34;https://i.imgur.com/uGuwNif.png&#34; alt=&#34;ReverseKit demo video&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
</feed>