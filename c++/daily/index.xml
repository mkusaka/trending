<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-07T01:29:47Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>finos/perspective</title>
    <updated>2023-04-07T01:29:47Z</updated>
    <id>tag:github.com,2023-04-07:/finos/perspective</id>
    <link href="https://github.com/finos/perspective" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A data visualization and analytics component, especially well-suited for large and/or streaming datasets.&lt;/p&gt;&lt;hr&gt;&lt;br&gt; &#xA;&lt;a href=&#34;https://github.com/finos/perspective/raw/master/docs/static/svg/perspective-logo-light.svg?raw=true#gh-light-mode-only&#34;&gt;&lt;img src=&#34;https://github.com/finos/perspective/raw/master/docs/static/svg/perspective-logo-light.svg?raw=true#gh-light-mode-only&#34; alt=&#34;Perspective&#34; width=&#34;260&#34;&gt;&lt;/a&gt; &#xA;&lt;a href=&#34;https://github.com/finos/perspective/raw/master/docs/static/svg/perspective-logo-dark.svg?raw=true#gh-dark-mode-only&#34;&gt;&lt;img src=&#34;https://github.com/finos/perspective/raw/master/docs/static/svg/perspective-logo-dark.svg?raw=true#gh-dark-mode-only&#34; alt=&#34;Perspective&#34; width=&#34;260&#34;&gt;&lt;/a&gt; &#xA;&lt;br&gt;&#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.npmjs.com/package/@finos/perspective&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/@finos/perspective.svg?style=flat&#34; alt=&#34;npm&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/perspective-python&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/perspective-python.svg?style=flat&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/finos/perspective/actions/workflows/build.yml&#34;&gt;&lt;img src=&#34;https://github.com/finos/perspective/actions/workflows/build.yml/badge.svg?branch=master&amp;amp;event=push&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Perspective is an &lt;i&gt;interactive&lt;/i&gt; analytics and data visualization component, which is especially well-suited for &lt;i&gt;large&lt;/i&gt; and/or &lt;i&gt;streaming&lt;/i&gt; datasets. Use it to create user-configurable reports, dashboards, notebooks and applications, then deploy stand-alone in the browser, or in concert with Python and/or &lt;a href=&#34;https://jupyterlab.readthedocs.io/en/stable/&#34;&gt;Jupyterlab&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;A fast, memory efficient streaming query engine, written in C++ and compiled for both &lt;a href=&#34;https://webassembly.org/&#34;&gt;WebAssembly&lt;/a&gt; and &lt;a href=&#34;https://www.python.org/&#34;&gt;Python&lt;/a&gt;, with read/write/streaming for &lt;a href=&#34;https://arrow.apache.org/&#34;&gt;Apache Arrow&lt;/a&gt;, and a high-performance columnar expression language based on &lt;a href=&#34;https://github.com/ArashPartow/exprtk&#34;&gt;ExprTK&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;A framework-agnostic User Interface packaged as a &lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_custom_elements&#34;&gt;Custom Element&lt;/a&gt;, powered either in-browser via WebAssembly or virtually via WebSocket server (Python/Node).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;A &lt;a href=&#34;https://jupyter.org/&#34;&gt;JupyterLab&lt;/a&gt; widget and Python client library, for interactive data analysis in a notebook, as well as &lt;em&gt;scalable&lt;/em&gt; production &lt;a href=&#34;https://github.com/voila-dashboards/voila&#34;&gt;Voila&lt;/a&gt; applications.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Examples&lt;/h3&gt; &#xA;&lt;!-- Examples --&gt; &#xA;&lt;table&gt;&#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;magic&lt;/td&gt;&#xA;   &lt;td&gt;nft&lt;/td&gt;&#xA;   &lt;td&gt;nypd ccrb&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://texodus.github.io/mtg-perspective/?seasons-in-the-abyss-67&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/img/mtg_preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://sc1f.github.io/pudgy-penguin-perspective/&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://raw.githubusercontent.com/sc1f/pudgy-penguin-perspective/pages/meta.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://texodus.github.io/nypd-ccrb/&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://texodus.github.io/nypd-ccrb/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;jupyterlab&lt;/td&gt;&#xA;   &lt;td&gt;fractal&lt;/td&gt;&#xA;   &lt;td&gt;market&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;http://beta.mybinder.org/v2/gh/finos/perspective/master?urlpath=lab/tree/examples/jupyter-notebooks&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/img/jupyterlab.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=fractal&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/fractal/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=market&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/market/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;raycasting&lt;/td&gt;&#xA;   &lt;td&gt;evictions&lt;/td&gt;&#xA;   &lt;td&gt;streaming&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=raycasting&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/raycasting/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=evictions&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/evictions/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=streaming&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/streaming/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;covid&lt;/td&gt;&#xA;   &lt;td&gt;movies&lt;/td&gt;&#xA;   &lt;td&gt;superstore&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=covid&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/covid/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=movies&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/movies/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=superstore&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/superstore/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;citibike&lt;/td&gt;&#xA;   &lt;td&gt;olympics&lt;/td&gt;&#xA;   &lt;td&gt;editable&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=citibike&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/citibike/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=olympics&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/olympics/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=editable&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/editable/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;csv&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://perspective.finos.org/block?example=csv&#34;&gt;&lt;img height=&#34;125&#34; src=&#34;https://perspective.finos.org/blocks/csv/preview.png&#34;&gt;&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;!-- Examples --&gt; &#xA;&lt;h3&gt;Documentation&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/&#34;&gt;Project Site&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;User Guides &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/docs/js.html&#34;&gt;Javascript User Guide&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/docs/python.html&#34;&gt;Python User Guide&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/docs/development.html&#34;&gt;Developer Guide&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Concepts &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/docs/table.html&#34;&gt;Table&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/docs/view.html&#34;&gt;View&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/docs/expressions.html&#34;&gt;Expression Columns&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/docs/table.html&#34;&gt;Data Binding&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;API &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/finos/perspective/raw/master/packages/perspective/README.md&#34;&gt;Perspective API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/docs/obj/perspective-viewer/&#34;&gt;Perspective Viewer API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://perspective.finos.org/docs/obj/perspective-python.html&#34;&gt;Perspective Python API&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Community / Media&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=IO-HJsGdleE&#34;&gt;Streaming, cross-sectional data visualization in JupyterLab | Junyuan Tan, JupyterCon 2020&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0ut-ynvBpGI&#34;&gt;Perspective in 3D | Andrew Stein, Open Source in Finance Forum NYC 2022&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=no0qChjvdgQ&#34;&gt;Build an order book simulation with Perspective | Andrew Stein, FINOS Open Source in Fintech Meetup 2021&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.finos.org/hubfs/FINOS/assets/FINOS%20Perspective%20Case%20Study.pdf&#34;&gt;Perspective project case study | FINOS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>mozilla/DeepSpeech</title>
    <updated>2023-04-07T01:29:47Z</updated>
    <id>tag:github.com,2023-04-07:/mozilla/DeepSpeech</id>
    <link href="https://github.com/mozilla/DeepSpeech" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Project DeepSpeech&lt;/h1&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://readthedocs.org/projects/deepspeech/badge/?version=latest&#34;&gt;https://readthedocs.org/projects/deepspeech/badge/?version=latest&lt;/a&gt; :target: &lt;a href=&#34;https://deepspeech.readthedocs.io/?badge=latest&#34;&gt;https://deepspeech.readthedocs.io/?badge=latest&lt;/a&gt; :alt: Documentation&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://github.com/mozilla/DeepSpeech/actions/workflows/macOS-amd64.yml/badge.svg&#34;&gt;https://github.com/mozilla/DeepSpeech/actions/workflows/macOS-amd64.yml/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/mozilla/DeepSpeech/actions/workflows/macOS-amd64.yml&#34;&gt;https://github.com/mozilla/DeepSpeech/actions/workflows/macOS-amd64.yml&lt;/a&gt; :alt: macOS builds&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://github.com/mozilla/DeepSpeech/actions/workflows/lint.yml/badge.svg&#34;&gt;https://github.com/mozilla/DeepSpeech/actions/workflows/lint.yml/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/mozilla/DeepSpeech/actions/workflows/lint.yml&#34;&gt;https://github.com/mozilla/DeepSpeech/actions/workflows/lint.yml&lt;/a&gt; :alt: Linters&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://github.com/mozilla/DeepSpeech/actions/workflows/docker.yml/badge.svg&#34;&gt;https://github.com/mozilla/DeepSpeech/actions/workflows/docker.yml/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/mozilla/DeepSpeech/actions/workflows/docker.yml&#34;&gt;https://github.com/mozilla/DeepSpeech/actions/workflows/docker.yml&lt;/a&gt; :alt: Docker Images&lt;/p&gt; &#xA;&lt;p&gt;DeepSpeech is an open-source Speech-To-Text engine, using a model trained by machine learning techniques based on &lt;code&gt;Baidu&#39;s Deep Speech research paper &amp;lt;https://arxiv.org/abs/1412.5567&amp;gt;&lt;/code&gt;&lt;em&gt;. Project DeepSpeech uses Google&#39;s &lt;code&gt;TensorFlow &amp;lt;https://www.tensorflow.org/&amp;gt;&lt;/code&gt;&lt;/em&gt; to make the implementation easier.&lt;/p&gt; &#xA;&lt;p&gt;Documentation for installation, usage, and training models are available on &lt;code&gt;deepspeech.readthedocs.io &amp;lt;https://deepspeech.readthedocs.io/?badge=latest&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;p&gt;For the latest release, including pre-trained models and checkpoints, &lt;code&gt;see the latest release on GitHub &amp;lt;https://github.com/mozilla/DeepSpeech/releases/latest&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;p&gt;For contribution guidelines, see &lt;code&gt;CONTRIBUTING.rst &amp;lt;CONTRIBUTING.rst&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;p&gt;For contact and support information, see &lt;code&gt;SUPPORT.rst &amp;lt;SUPPORT.rst&amp;gt;&lt;/code&gt;_.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>CL2-UWaterloo/f1tenth_ws</title>
    <updated>2023-04-07T01:29:47Z</updated>
    <id>tag:github.com,2023-04-07:/CL2-UWaterloo/f1tenth_ws</id>
    <link href="https://github.com/CL2-UWaterloo/f1tenth_ws" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A repository for autonomous racing written in ROS2, designed for the F1TENTH platform. Code can run both in the physical car, as well as simulation with custom launch files.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;f1tenth_ws&lt;/h1&gt; &#xA;&lt;p&gt;This a repository that contains ready-to-run autonomous racing packages for the &lt;a href=&#34;https://f1tenth.org/&#34;&gt;F1TENTH&lt;/a&gt; on ROS2 Foxy. It can be directly be deployed on the physical car. We&#39;ve also included launch and config files for the &lt;a href=&#34;https://github.com/f1tenth/f1tenth_gym_ros&#34;&gt;simulation environment&lt;/a&gt;, which uses slightly different topics for odometry.&lt;/p&gt; &#xA;&lt;p&gt;Below is a demo of the car running the code from this repository in the E7 building at the University of Waterloo at a top speed of ~25km/h, record on March 13th 2023.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/43485866/226077068-774f02dd-bc90-4eb6-96f8-d0ba284538ad.mp4&#34;&gt;https://user-images.githubusercontent.com/43485866/226077068-774f02dd-bc90-4eb6-96f8-d0ba284538ad.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Software Stack Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Our current software stack consists of&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/SteveMacenski/slam_toolbox&#34;&gt;slam_toolbox&lt;/a&gt; for &lt;strong&gt;mapping&lt;/strong&gt; (reference the following &lt;a href=&#34;https://docs.google.com/presentation/d/1DP2F9l-yHe9gQobk2CzYduk6KR5QtDCp7sLsxqR2fag/edit#slide=id.g115c48c178d_0_1&#34;&gt;slides&lt;/a&gt; for running it on the physical car)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/CL2-UWaterloo/f1tenth_ws/main/src/particle_filter/&#34;&gt;Particle Filter&lt;/a&gt; for &lt;strong&gt;localization&lt;/strong&gt; $\rightarrow$ &lt;code&gt;src/particle_filter&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/CL2-UWaterloo/f1tenth_ws/main/src/pure_pursuit/&#34;&gt;Pure Pursuit&lt;/a&gt; for &lt;strong&gt;waypoint following&lt;/strong&gt; (planning + control) $\rightarrow$ &lt;code&gt;src/pure_pursuit&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/CL2-UWaterloo/f1tenth_ws/main/src/rrt&#34;&gt;RRT&lt;/a&gt; for a pure pursuit algorithm that includes &lt;strong&gt;dynamic obstacle avoidance&lt;/strong&gt; (slightly slower) $\rightarrow$ &lt;code&gt;src/rrt&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Racing lines are generated through the &lt;a href=&#34;https://github.com/CL2-UWaterloo/Raceline-Optimization&#34;&gt;Cl2-UWaterloo/Raceline-Optimization&lt;/a&gt; repository.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Other algorithms that are not used, but are in this repository include&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/CL2-UWaterloo/f1tenth_ws/main/src/waypoint_generator/&#34;&gt;Waypoint Generator&lt;/a&gt; for manually generating waypoints in simulation $\rightarrow$ &lt;code&gt;src/waypoint_generator&lt;/code&gt; (this has been replaced with a script that automatically generates optimal racelines given a map)&lt;/li&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/CL2-UWaterloo/f1tenth_ws/main/src/wall_follow/&#34;&gt;PID controller&lt;/a&gt; for staying at a constant distance to the wall $\rightarrow$ &lt;code&gt;src/wall_follow&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/CL2-UWaterloo/f1tenth_ws/main/src/scan_matching&#34;&gt;Scan matching&lt;/a&gt; $\rightarrow$ &lt;code&gt;src/scan_matching&lt;/code&gt; (To be completed)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/CL2-UWaterloo/f1tenth_ws/main/src/gap_follow&#34;&gt;gap_follow&lt;/a&gt; $\rightarrow$ &lt;code&gt;src/gap_follow&lt;/code&gt; (To be completed)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;High-Level Usage Guide&lt;/h2&gt; &#xA;&lt;p&gt;These are the high level steps followed to get the F1TENTH driving in a new location:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Run SLAM on the physical car to generate a map with &lt;code&gt;slam_toolbox&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Clean up map in Photoshop, and generate a racing line using the &lt;a href=&#34;https://github.com/CL2-UWaterloo/Raceline-Optimization&#34;&gt;Cl2-UWaterloo/Raceline-Optimization&lt;/a&gt; repository.&lt;/li&gt; &#xA; &lt;li&gt;Store the racing lines under &lt;code&gt;src/pure_pursuit/racelines/&lt;/code&gt; and &lt;code&gt;src/rrt/racelines/&lt;/code&gt; (for dynamic obstacle avoidance)&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;particle_filter&lt;/code&gt; with the new map to localize the car properly&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;pure_pursuit&lt;/code&gt; or &lt;code&gt;rrt&lt;/code&gt; to follow the racing line. Make sure to incrementally increase the &lt;code&gt;velocity_profile&lt;/code&gt; inside the &lt;a href=&#34;https://raw.githubusercontent.com/CL2-UWaterloo/f1tenth_ws/main/src/pure_pursuit/config/config.yaml&#34;&gt;config.yaml&lt;/a&gt; file.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You can consult these accompanying notes: &lt;a href=&#34;https://stevengong.co/notes/F1TENTH-Field-Usage&#34;&gt;https://stevengong.co/notes/F1TENTH-Field-Usage&lt;/a&gt;, which shows every command used to get code working the physical car. Note that they are mainly written for our own personal reference, so the paths will be different in your setup.&lt;/p&gt; &#xA;&lt;p&gt;If you feel confused / stuck by all of this, you might want to start with following the &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1kAd0bf6nc1OVi_4IP1P3-H6PPU97hLjqW8d0mTLCsxg/edit#gid=29915317&#34;&gt;F1TENTH Course&lt;/a&gt;, where they actually teach why these algorithms are needed, and how they are implemented. The &lt;a href=&#34;https://f1tenth.readthedocs.io/en/foxy_test/&#34;&gt;official documentation&lt;/a&gt; describes how to setup the hardware and basic software for the car.&lt;/p&gt; &#xA;&lt;h2&gt;Running Simulation&lt;/h2&gt; &#xA;&lt;p&gt;If you want to run these nodes inside the simulation environment, you need to clone the &lt;a href=&#34;https://github.com/f1tenth/f1tenth_gym_ros&#34;&gt;simulation repository&lt;/a&gt;. Then, you should mount this repository&#39;s packages to the &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;- INSERT_PATH_HERE/f1tenth_ws/src:/sim_ws/src&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Each package can then be built inside the simulation environment.&lt;/p&gt; &#xA;&lt;h2&gt;Next Steps&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;A non-exhaustive list of things we want to do in the future, include&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Running SLAM + pure pursuit on the fly, without having to do the offline computation. Something like &lt;a href=&#34;https://www.youtube.com/watch?v=aCDPwZZm9C4&amp;amp;ab_channel=AMZFormulaStudent&#34;&gt;this&lt;/a&gt; would be incredible&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;About Us&lt;/h2&gt; &#xA;&lt;p&gt;The Control, Learning and Logic (CL2) group at the University of Waterloo works on research that aims to develop methods for reliable decision-making of autonomous systems in the wild, led by professor Yash Vardhan Pant. Current members working on the F1TENTH is composed of Steven Gong, Oluwatofolafun Damilola Opeoluwa-Calebs, and Soham Lakhi.&lt;/p&gt;</summary>
  </entry>
</feed>