<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-31T01:30:32Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>abcz316/SKRoot-linuxKernelRoot</title>
    <updated>2023-03-31T01:30:32Z</updated>
    <id>tag:github.com,2023-03-31:/abcz316/SKRoot-linuxKernelRoot</id>
    <link href="https://github.com/abcz316/SKRoot-linuxKernelRoot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;新一代SKRoot，挑战全网root检测手段，跟面具完全不同思路，摆脱面具被检测的弱点，完美隐藏root功能，全程不需要暂停SELinux，实现真正的SELinux 0%触碰，通用性强，通杀所有内核，不需要内核源码，直接patch内核，兼容安卓APP直接JNI调用，稳定、流畅、不闪退。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SKRoot - SuperKernelRoot - Linux 完美内核级隐藏ROOT演示&lt;/h1&gt; &#xA;&lt;p&gt;新一代SKRoot，挑战全网root检测手段，跟面具完全不同思路，摆脱面具被检测的弱点，完美隐藏root功能，全程不需要暂停SELinux，实现真正的SELinux 0%触碰，通用性强，通杀所有内核，不需要内核源码，直接patch内核，兼容安卓APP直接JNI调用，稳定、流畅、不闪退。&lt;/p&gt; &#xA;&lt;h3&gt;本工具功能列表：&lt;/h3&gt; &#xA;&lt;h3&gt;1.显示自身权限信息&lt;/h3&gt; &#xA;&lt;h3&gt;2.获取ROOT权限&lt;/h3&gt; &#xA;&lt;h3&gt;3.执行ROOT命令&lt;/h3&gt; &#xA;&lt;h3&gt;4.执行原生内核命令&lt;/h3&gt; &#xA;&lt;h3&gt;5.安装部署su&lt;/h3&gt; &#xA;&lt;h3&gt;6.注入su到指定进程&lt;/h3&gt; &#xA;&lt;h3&gt;7.完全卸载清理su&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/abcz316/linuxKernelRoot/raw/master/ScreenCap/1.png&#34; alt=&#34;image&#34;&gt; &lt;img src=&#34;https://github.com/abcz316/linuxKernelRoot/raw/master/ScreenCap/2.png&#34; alt=&#34;image&#34;&gt; &lt;img src=&#34;https://github.com/abcz316/linuxKernelRoot/raw/master/ScreenCap/3.png&#34; alt=&#34;image&#34;&gt; &lt;img src=&#34;https://github.com/abcz316/linuxKernelRoot/raw/master/ScreenCap/4.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>wangzhaode/ChatGLM-MNN</title>
    <updated>2023-03-31T01:30:32Z</updated>
    <id>tag:github.com,2023-03-31:/wangzhaode/ChatGLM-MNN</id>
    <link href="https://github.com/wangzhaode/ChatGLM-MNN" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Pure C++, Easy Deploy ChatGLM-6B.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGLM-MNN&lt;/h1&gt; &#xA;&lt;h2&gt;Describe&lt;/h2&gt; &#xA;&lt;p&gt;该项目将模型&lt;a href=&#34;https://huggingface.co/THUDM/chatglm-6b&#34;&gt;ChatGLM-6B&lt;/a&gt;转换到&lt;code&gt;MNN&lt;/code&gt;并使用&lt;code&gt;C++&lt;/code&gt;进行推理。 在实现上做了如下优化：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;对其中的词表做了部分删减，删除了模型中未使用的前20000个图片词；将&lt;code&gt;vocab&lt;/code&gt;, &lt;code&gt;embedding&lt;/code&gt;, &lt;code&gt;lm_head&lt;/code&gt;的大小从150528缩小到130528;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Embedding&lt;/code&gt;操作调用次数较少，使用&lt;code&gt;fseek&lt;/code&gt;, &lt;code&gt;fread&lt;/code&gt;加载的方式降低内存;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;lm_head&lt;/code&gt;操作为&lt;code&gt;[num, 4096] @ [4096, 130528]&lt;/code&gt;，转换为&lt;code&gt;[130528, 4096] @ [4096, 1]&lt;/code&gt;;&lt;/li&gt; &#xA; &lt;li&gt;原模型对显存要求较高；将模型按层拆分成28个模型，可以根据用户显存大小动态将计算任务分配给GPU和CPU，充分利用GPU与CPU内存与算力; 即使小显存显卡也可以加速生成。&lt;/li&gt; &#xA; &lt;li&gt;针对端侧设备可以逐次加载计算，&lt;code&gt;2G&lt;/code&gt;内存的Android设备也可以执行推理（速度较慢）。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;现已提供ONNX模型，可以使用其他框架部署；&lt;a href=&#34;https://github.com/wangzhaode/ChatGLM-MNN/releases/tag/v0.4&#34;&gt;点击下载&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;目前支持命令行对话与Web UI对话两种形式的Demo &lt;img src=&#34;https://raw.githubusercontent.com/wangzhaode/ChatGLM-MNN/master/resource/web/web_demo.png&#34; alt=&#34;web_demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Speed&lt;/h2&gt; &#xA;&lt;p&gt;移动端：将分段模型逐个加载推理可以在内存大小大于&lt;code&gt;2G&lt;/code&gt;的设备执行推理，实验性测试性能较差；目前性能约为：63 &lt;code&gt;s/word&lt;/code&gt;。&lt;/p&gt; &#xA;&lt;p&gt;PC测试平台：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Memory: 32G (+32G Swap)&lt;/li&gt; &#xA; &lt;li&gt;CPU: AMD Ryzen 9 3900X 12-Core Processor&lt;/li&gt; &#xA; &lt;li&gt;GPU: GeForce RTX 2080 Ti&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;FP Model&lt;/h3&gt; &#xA;&lt;p&gt;仅测试浮点模型(CPU: fp32/ GPU: fp16)，输入&lt;code&gt;你好&lt;/code&gt;，在回复完内容相同的情况下，平均生成一个词语的时间(&lt;code&gt;s/word&lt;/code&gt;)对比如下：&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;impl&lt;/th&gt; &#xA;   &lt;th&gt;GPU + CPU&lt;/th&gt; &#xA;   &lt;th&gt;CPU only&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MNN&lt;/td&gt; &#xA;   &lt;td&gt;0.292&lt;/td&gt; &#xA;   &lt;td&gt;0.877&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Pytorch&lt;/td&gt; &#xA;   &lt;td&gt;out of memory&lt;/td&gt; &#xA;   &lt;td&gt;1.344&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Quantize Model&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;TODO&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;1. Compile MNN library&lt;/h3&gt; &#xA;&lt;p&gt;从源码编译MNN&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/alibaba/MNN.git&#xA;cd MNN&#xA;mkdir build &amp;amp;&amp;amp; cd build&#xA;cmake .. # if using CUDA, add -DMNN_CUDA=ON&#xA;make -j8&#xA;cp -r ../include /path/to/ChatGLM-MNN/&#xA;cp libMNN.so /path/to/ChatGLM-MNN/libs&#xA;cp express/libMNN_Express.so /path/to/ChatGLM-MNN/libs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Download Models&lt;/h3&gt; &#xA;&lt;p&gt;从 &lt;code&gt;github release&lt;/code&gt; 下载模型文件到 &lt;code&gt;/path/to/ChatGLM-MNN/resource/models&lt;/code&gt;， 如下：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd resource/models&#xA;./download_models_fp16.sh # 下载fp16权值模型&#xA;./download_models_int8.sh # 下载int8权值模型，推荐使用&#xA;./download_models_int4.sh # 下载int4权值模型，有精度损失&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Build and Run&lt;/h3&gt; &#xA;&lt;p&gt;Mac/Linux/Windows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir build&#xA;cd build&#xA;cmake ..&#xA;make -j8&#xA;./cli_demo # cli demo&#xA;./web_demo # web ui demo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Android:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir build&#xA;cd build&#xA;../android_build.sh&#xA;make -j8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;4. Using CUDA&lt;/h4&gt; &#xA;&lt;p&gt;默认用法为使用&lt;code&gt;CPU&lt;/code&gt;, 使用&lt;code&gt;CUDA&lt;/code&gt;需要在编译MNN时添加宏&lt;code&gt;-DMNN_CUDA=ON&lt;/code&gt;，在创建&lt;code&gt;ChatGLM&lt;/code&gt;时指定显存大小，如下：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// 8G CUDA Memory&#xA;ChatGLM chatglm(8);&#xA;// 命令式&#xA;std::cout &amp;lt;&amp;lt; chatglm.response(&#34;你好&#34;);&#xA;// 交互式&#xA;chatglm.chat();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;Q: 用Python帮我写一段快速排序代码&lt;/p&gt; &#xA;&lt;p&gt;A: 当然可以!以下是使用Python实现快速排序算法的示例代码:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def quick_sort(arr):&#xA;    if len(arr) &amp;lt;= 1:&#xA;        return arr&#xA;    else:&#xA;        pivot = arr[0]&#xA;        left = []&#xA;        right = []&#xA;        for i in range(1, len(arr)):&#xA;            if arr[i] &amp;lt; pivot:&#xA;                left.append(arr[i])&#xA;            else:&#xA;                right.append(arr[i])&#xA;        return quick_sort(left) + [pivot] + quick_sort(right)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;这个实现中,我们首先检查传入的数组长度是否小于等于1。如果是,我们直接返回该数组,因为这种情况下快速排序是不稳定的。否则,我们选择数组的第一个元素作为基准点(pivot),并将数组分为两个部分:左边的部分的所有元素都小于基准点,右边的部分的所有元素都大于基准点。然后我们递归地对左边和右边的部分执行快速排序,并将结果拼接起来。最后,我们递归地对左右两个部分执行相同的操作,并返回结果。&lt;/p&gt; &#xA;&lt;p&gt;你可以像这样调用这个函数:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;arr = [3, 6, 1, 9, 2, 5, 8, 4]&#xA;sorted_arr = quick_sort(arr)&#xA;print(sorted_arr)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;这将输出 &lt;code&gt;[1, 2, 3, 4, 5, 6, 7, 8, 9]&lt;/code&gt;,表示快速排序已成功地对数组进行了排序。&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Q: 内存泄露如何定位&lt;/p&gt; &#xA;&lt;p&gt;A: 内存泄漏(Memory Leak)是指程序在运行过程中,占用的内存空间不断增加,最终导致程序无法继续运行,或者运行效率降低。&lt;/p&gt; &#xA;&lt;p&gt;以下是一些常见的内存泄漏检查方法:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;使用内存分析工具:例如Eclipse Memory Analyzer、VisualVM等,这些工具可以帮助检测程序中未释放的内存空间,以及内存分配的异常。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;检查变量的生命周期:如果一个变量在它的生命周期内没有被释放,那么它的内存空间就会被一直占用,最终导致内存泄漏。可以通过查看变量的生命周期信息来检查是否存在这个问题。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;检查代码中的异常:如果程序在执行过程中出现了异常,而没有释放所占用的内存空间,也会导致内存泄漏。可以通过调试程序,查找并释放这些内存空间。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;优化代码:如果程序中的代码存在内存泄漏问题,那么可能是因为程序的性能问题或者内存占用过高导致的。可以通过优化代码,减少内存分配和释放的次数,来解决这个问题。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;定期清理无用的数据:如果程序中存在大量的无用数据,也会导致内存泄漏。可以通过定期清理这些数据,释放内存空间。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;内存泄漏问题的解决需要从多个方面入手,通过不断地调试和优化程序,来找到内存泄漏的根本原因,并有效地解决问题。&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Q: 北京有什么特色小吃？&lt;/p&gt; &#xA;&lt;p&gt;A: 北京是中国历史文化名城,也是中国美食之都之一,有许多特色小吃。以下是一些著名的北京特色小吃:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;炸酱面:炸酱面是中国传统面食之一,以黄酱和肉末为主要材料,配以豆瓣酱、黄瓜丝和豆芽等配料,味道鲜美。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;烤鸭:烤鸭是北京最著名的美食之一,以薄饼和鸭肉为主要材料,烤制过程中还会加入葱、姜等调料,口感鲜美。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;豆汁:豆汁是一种传统的北京小吃,以黄豆为主要原料,配以辣椒油、醋、蒜泥等调料,味道酸甜可口。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;羊蝎子:羊蝎子是一道以羊肉和羊肝为主要材料的炖菜,口感鲜美,营养丰富。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;糖葫芦:糖葫芦是一种传统的北京小吃,以草莓、山楂等水果为主料,沾上糖浆,口感酸甜可口。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;煎饼果子:煎饼果子是一种流行的中式早餐,以薄饼和蛋、肉松、油条等为主要材料,口感酥脆。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;驴打滚:驴打滚是一种传统的北京小吃,以糯米粉和豆沙为主要材料,通过卷起来和炸的方式制作,口感香甜。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;这只是北京众多特色小吃中的一小部分,北京还有很多其他美食,如北京火锅、北京炸酱面、北京小吃街等等,值得一试。&lt;/p&gt; &#xA;&lt;h2&gt;Reference&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/THUDM/chatglm-6b&#34;&gt;ChatGLM-6B&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yhirose/cpp-httplib&#34;&gt;cpp-httplib&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xqdoo00o/chatgpt-web&#34;&gt;chatgpt-web&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yanyiwu/cppjieba&#34;&gt;cppjieba&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>XaFF-XaFF/CaveCarver</title>
    <updated>2023-03-31T01:30:32Z</updated>
    <id>tag:github.com,2023-03-31:/XaFF-XaFF/CaveCarver</id>
    <link href="https://github.com/XaFF-XaFF/CaveCarver" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CaveCarver - PE backdooring tool which utilizes and automates code cave technique&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CaveCarver&lt;/h1&gt; &#xA;&lt;p&gt;Code cave is a technique used to inject additional code or shellcode into an executable without affecting the original functionality of the program. Our Project instruments code cave by adding an additional Section to the PE file where the shellcode resides in. After patching the PEs EntryPoint the control flow gets redirected to the shellcode.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;CaveCarver.exe path_to_exe path_to_shellcode&lt;/code&gt;&lt;/p&gt;</summary>
  </entry>
</feed>