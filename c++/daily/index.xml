<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-01T01:29:48Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Cambricon/triton-linalg</title>
    <updated>2024-06-01T01:29:48Z</updated>
    <id>tag:github.com,2024-06-01:/Cambricon/triton-linalg</id>
    <link href="https://github.com/Cambricon/triton-linalg" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Development repository for the Triton-Linalg conversion&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;triton-linalg&lt;/h1&gt; &#xA;&lt;p&gt;A project dedicated to converting the Triton Dialect to the Linalg Dialect for the Triton compiler. Currently, it has successfully supported the Cambricon backend as a front-end representation, and functionally, it is capable of handling nearly all features of the Triton language.&lt;/p&gt; &#xA;&lt;p&gt;In the era of artificial intelligence, numerous domain-specific architectures (DSA) have emerged to meet performance demands. To optimize the efficiency of program executed on these architectures, designers often define a series of coarse-grained operators. These operators are tailor-made for specific tasks, enabling the hardware to handle complex computational demands more efficiently. For this purpose, the &lt;code&gt;triton-linalg&lt;/code&gt; repository adheres to several principles during the conversion process:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use structured operators as much as possible, avoiding the use of &lt;code&gt;linalg.generic&lt;/code&gt;, For instance: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;tt.reduce&lt;/code&gt; becomes &lt;code&gt;linalg.reduce&lt;/code&gt; and &lt;code&gt;tt.dot&lt;/code&gt; becomes &lt;code&gt;linalg.matmul&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;element-wise &lt;code&gt;arith&lt;/code&gt; and &lt;code&gt;math&lt;/code&gt; operators are converted to their corresponding &lt;code&gt;linalg.map&lt;/code&gt; versions.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Identify operator semantics as early as possible. For instance: &lt;code&gt;tt.reduce&lt;/code&gt; becomes &lt;code&gt;linalg.pool&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;This repo now includes &lt;code&gt;triton&lt;/code&gt; as a submodule and builds as an out-of-tree backend.&lt;/p&gt; &#xA;&lt;p&gt;To build this repo clone &lt;code&gt;triton-linalg&lt;/code&gt; to a folder called &lt;code&gt;triton_linalg&lt;/code&gt; (notice the &lt;strong&gt;underscore&lt;/strong&gt;).&lt;/p&gt; &#xA;&lt;p&gt;You need to set the &lt;code&gt;TRITON_PLUGIN_DIRS&lt;/code&gt; environment variable to the location of your &lt;code&gt;triton-linalg&lt;/code&gt; directory for &lt;code&gt;triton&lt;/code&gt; to find it.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export TRITON_PLUGIN_DIRS=$(pwd)/triton_linalg&#xA;&#xA;git clone --recurse-submodules https://github.com/Cambricon/triton-linalg.git&#xA;cd triton-linalg/triton&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To build with Clang:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 -m pip install --upgrade pip&#xA;python3 -m pip install cmake==3.24 ninja pytest-xdist&#xA;sudo apt-get update -y&#xA;sudo apt-get install -y ccache clang lld&#xA;TRITON_BUILD_WITH_CLANG_LLD=true TRITON_BUILD_WITH_CCACHE=true python3 -m pip install --no-build-isolation -vvv &#39;.[tests]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To build with a virtualenv:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 -m venv .venv --prompt triton&#xA;source .venv/bin/activate&#xA;&#xA;pip3 install ninja cmake wheel pytest&#xA;pip3 install -e python --no-build-isolation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Stand-Alone&lt;/h3&gt; &#xA;&lt;p&gt;Linalg can be used as a stand-alone component to convert Triton dialect to the Linalg dialect. This is intended for testing and validation purposes, but could potentially be used before sending the IR to another MLIR complier.&lt;/p&gt; &#xA;&lt;p&gt;Stand-alone example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;triton-linalg-opt --convert-triton-to-linalg ${TRITON_LINALG_DIR}/test/Dialect/LinalgExt/ops.mlir&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Implementation details&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;triton-linalg&lt;/code&gt; is composed of four parts: Analysis, Conversion, Dialect, and Transforms.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Dialect: Defines Linalg Extension operators as well as Auxiliary support operators.&lt;/li&gt; &#xA; &lt;li&gt;Analysis: Includes algorithms for pointer analysis, Mask Tracker, and pointer offset Tracker.&lt;/li&gt; &#xA; &lt;li&gt;Conversion: Contains conversions from triton/arith/math to linalg.&lt;/li&gt; &#xA; &lt;li&gt;Transforms: Expands the standardization of community Dialects and includes some auxiliary optimization passes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Dialect&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;triton-linalg&lt;/code&gt; has added two new dialects.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Auxiliary: Includes some auxiliary operators, such as the &lt;code&gt;view&lt;/code&gt; operator, used to bind structured information such as offsets, sizes, and strides to a llvm pointer, converting them into memref types.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;aux.view %ptr to offset: [0], sizes: [%size0, 10], strides: [1, %stride1]&#xA;    : llvm.ptr&amp;lt;f32&amp;gt; to memref&amp;lt;?x10xf32, strided&amp;lt;[1, ?], offset: 0&amp;gt;&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LinalgExt: Includes extension operators of the Linalg Dialect, such as &lt;code&gt;linalg_ext.gather&lt;/code&gt;, &lt;code&gt;linalg_ext.scatter&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Analysis&lt;/h3&gt; &#xA;&lt;p&gt;As part of the conversion process, there are three important analyses:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;AxisInfo analysis:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This analysis is based on the official &lt;code&gt;AxisInfoAnalysis&lt;/code&gt;, it has been expanded to support the recognition of multi-dimensional continuity.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Mask Tracker:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This analysis is responsible for handling masked loads and stores.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Pointer Offset Tracker.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This analysis is responsible for tracking pointer offsets.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Conversion&lt;/h3&gt; &#xA;&lt;p&gt;We introduce the &lt;code&gt;TritonToLinalg&lt;/code&gt; conversion pass that converts the &lt;code&gt;triton&lt;/code&gt; dialects to the &lt;code&gt;linalg&lt;/code&gt; dialect on &lt;em&gt;tensors&lt;/em&gt;. This means the resulting IR is fully compatible with &lt;code&gt;linalg&lt;/code&gt; tiling and fusion transformation passes. As mentioned in the &lt;code&gt;Pointer analysis&lt;/code&gt;&#39;s description, we do however have to deal with memref instructions at the load and store boundaries and have to convert them to tensors using &lt;code&gt;bufferization.to_tensor&lt;/code&gt;. Here&#39;s a simple example of what the IR looks like:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;add_kernel&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-mlir&#34;&gt;&#xA;module attributes {&#xA;  tt.func public @add_kernel_01234(%arg0: !tt.ptr&amp;lt;f32&amp;gt;, %arg1: !tt.ptr&amp;lt;f32&amp;gt;, %arg2: !tt.ptr&amp;lt;f32&amp;gt;, %arg3: i32) {&#xA;    %c1024_i32 = arith.constant 1024 : i32&#xA;    %0 = tt.get_program_id x : i32&#xA;    %1 = arith.muli %0, %c1024_i32 : i32&#xA;    %2 = tt.make_range {end = 1024 : i32, start = 0 : i32} : tensor&amp;lt;1024xi32&amp;gt;&#xA;    %3 = tt.splat %1 : i32 -&amp;gt; tensor&amp;lt;1024xi32&amp;gt;&#xA;    %4 = arith.addi %3, %2 : tensor&amp;lt;1024xi32&amp;gt;&#xA;    %5 = tt.splat %arg3 : i32 -&amp;gt; tensor&amp;lt;1024xi32&amp;gt;&#xA;    %6 = arith.cmpi slt, %4, %5 : tensor&amp;lt;1024xi32&amp;gt;&#xA;    %7 = tt.splat %arg0 : !tt.ptr&amp;lt;f32&amp;gt; -&amp;gt; tensor&amp;lt;1024x!tt.ptr&amp;lt;f32&amp;gt;&amp;gt;&#xA;    %8 = tt.addptr %7, %4 : tensor&amp;lt;1024x!tt.ptr&amp;lt;f32&amp;gt;&amp;gt;, tensor&amp;lt;1024xi32&amp;gt;&#xA;    %9 = tt.load %8, %6 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor&amp;lt;1024x!tt.ptr&amp;lt;f32&amp;gt;&amp;gt;&#xA;    %10 = tt.splat %arg1 : !tt.ptr&amp;lt;f32&amp;gt; -&amp;gt; tensor&amp;lt;1024x!tt.ptr&amp;lt;f32&amp;gt;&amp;gt;&#xA;    %11 = tt.addptr %10, %4 : tensor&amp;lt;1024x!tt.ptr&amp;lt;f32&amp;gt;&amp;gt;, tensor&amp;lt;1024xi32&amp;gt;&#xA;    %12 = tt.load %11, %6 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor&amp;lt;1024x!tt.ptr&amp;lt;f32&amp;gt;&amp;gt;&#xA;    %13 = arith.addf %9, %12 : tensor&amp;lt;1024xf32&amp;gt;&#xA;    %14 = tt.splat %arg2 : !tt.ptr&amp;lt;f32&amp;gt; -&amp;gt; tensor&amp;lt;1024x!tt.ptr&amp;lt;f32&amp;gt;&amp;gt;&#xA;    %15 = tt.addptr %14, %4 : tensor&amp;lt;1024x!tt.ptr&amp;lt;f32&amp;gt;&amp;gt;, tensor&amp;lt;1024xi32&amp;gt;&#xA;    tt.store %15, %13, %6 {cache = 1 : i32, evict = 1 : i32} : tensor&amp;lt;1024x!tt.ptr&amp;lt;f32&amp;gt;&amp;gt;&#xA;    tt.return&#xA;  }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;after conversion:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-mlir&#34;&gt;module {&#xA;  func.func public @add_kernel_01234(%arg0: int64, %arg1: int64, %arg2: int64, %arg3: i32) {&#xA;    ...&#xA;    %offset = ...&#xA;    %extracted = tensor.extract %offset[%c0] : tensor&amp;lt;1024xi32&amp;gt;&#xA;    %offset0 = arith.index_cast %extracted : i32 to index&#xA;    %ptr = llvm.inttoptr %arg0 : i64 to !llvm.ptr&#xA;    %view_memref = aux.view %ptr to offset: [%offset0], sizes: [%size], strides: [1] : !llvm.ptr to memref&amp;lt;?xf32, #map&amp;gt;&#xA;    %tensor = bufferization.to_tensor %view_memref restrict writable : memref&amp;lt;?xf32, #map&amp;gt;&#xA;    %c0 = arith.constant 0 : index&#xA;    %dim = tensor.dim %35, %c0 : tensor&amp;lt;?xf32&amp;gt;&#xA;    %empty = tensor.empty(%dim) : tensor&amp;lt;?xf32&amp;gt;&#xA;    %data = linalg.copy ins(%tensor : tensor&amp;lt;?xf32&amp;gt;) outs(%empty : tensor&amp;lt;?xf32&amp;gt;) -&amp;gt; tensor&amp;lt;?xf32&amp;gt;&#xA;    ...&#xA;    return&#xA;  }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Important details to note is the handling of pointers(not block pointers) for &lt;code&gt;tt.load&lt;/code&gt; and &lt;code&gt;tt.store&lt;/code&gt; operations. The pointers are mainly categorized into continuous(pointer to a tensor) and discrete cases.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Continuous case:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Based on the pointer tensor information obtained from &lt;code&gt;AxisInfoAnalysis&lt;/code&gt;, combined with the offsets tracked by the &lt;code&gt;Pointer Offsets Tracker&lt;/code&gt;, the actual pointer offsets/strides can be calculated. Then, using &lt;code&gt;aux.view&lt;/code&gt;, &lt;code&gt;buffertion.to_tensor&lt;/code&gt; and &lt;code&gt;linalg.copy&lt;/code&gt;, it is converted to tensor semantics.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Discrete case:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;We cannot deduce continuity, nor can we determine the actual size of the space pointed to by the pointer. Therefore, we assume that the pointer points to an infinitely large space. Then using &lt;code&gt;aux.view&lt;/code&gt;, &lt;code&gt;buffertion.to_tensor&lt;/code&gt; and &lt;code&gt;linalg_ext.gather&lt;/code&gt;, it is converted to tensor semantics.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Transforms&lt;/h3&gt; &#xA;&lt;p&gt;We have introduced some optimization passes to assist in the conversion process, there are some important passes:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;WrapFuncBodyWithSingleBlock: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This pass wraps function body into a block by moving body to a &lt;code&gt;scf.execute_region&lt;/code&gt;. The primary aim is to resolve the issue of inlining of function calls within &lt;code&gt;scf.for&lt;/code&gt; due to multiple block problems.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ExtractLikeMoveBackwardPass： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This pass moves extract-like operations backward, and changes operations in the backward path with extracted tensor or scalar.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Pass Pipeline&lt;/h3&gt; &#xA;&lt;p&gt;We introduce the &lt;code&gt;triton-to-linalg&lt;/code&gt; pass pipeline to convert a triton dialect ir to linalg/linalg_ext dialect ir. Here is an example:&lt;/p&gt; &#xA;&lt;p&gt;Regarding the IR of &lt;a href=&#34;https://raw.githubusercontent.com/Cambricon/triton-linalg/master/#add_kernel&#34;&gt;add_kernel&lt;/a&gt; in the Conversion section above, the result after executing the triton-to-linalg pipeline is as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#map = affine_map&amp;lt;(d0)[s0] -&amp;gt; (d0 + s0)&amp;gt;&#xA;module {&#xA;  func.func @add_kernel(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i32) {&#xA;    %c1024 = arith.constant 1024 : index&#xA;    %c1024_i32 = arith.constant 1024 : i32&#xA;    %cst = arith.constant 0.000000e+00 : f32&#xA;    %0 = tt.get_program_id x : i32&#xA;    %1 = arith.muli %0, %c1024_i32 : i32&#xA;    %2 = arith.index_cast %1 : i32 to index&#xA;    %3 = arith.addi %2, %c1024 : index&#xA;    %4 = arith.index_cast %arg3 : i32 to index&#xA;    %5 = arith.maxsi %4, %2 : index&#xA;    %6 = arith.minsi %3, %5 : index&#xA;    %7 = arith.subi %6, %2 : index&#xA;    %8 = llvm.inttoptr %arg0 : i64 to !llvm.ptr&#xA;    %view_memref = aux.view %8 to offset: [%2], sizes: [%7], strides: [1] : !llvm.ptr to memref&amp;lt;?xf32, #map&amp;gt;&#xA;    %9 = bufferization.to_tensor %view_memref restrict writable : memref&amp;lt;?xf32, #map&amp;gt;&#xA;    %10 = tensor.empty(%7) : tensor&amp;lt;?xf32&amp;gt;&#xA;    %11 = linalg.copy ins(%9 : tensor&amp;lt;?xf32&amp;gt;) outs(%10 : tensor&amp;lt;?xf32&amp;gt;) -&amp;gt; tensor&amp;lt;?xf32&amp;gt;&#xA;    %12 = tensor.empty() : tensor&amp;lt;1024xf32&amp;gt;&#xA;    %13 = arith.subi %c1024, %7 : index&#xA;    %14 = linalg_ext.pad ins(%11 : tensor&amp;lt;?xf32&amp;gt;) outs(%12 : tensor&amp;lt;1024xf32&amp;gt;) pvalue(%cst : f32) low = [0] high = [%13] {&#xA;    ^bb0(%arg4: f32):&#xA;      linalg_ext.yield %arg4 : f32&#xA;    } -&amp;gt; tensor&amp;lt;1024xf32&amp;gt;&#xA;    %15 = llvm.inttoptr %arg1 : i64 to !llvm.ptr&#xA;    %view_memref_0 = aux.view %15 to offset: [%2], sizes: [%7], strides: [1] : !llvm.ptr to memref&amp;lt;?xf32, #map&amp;gt;&#xA;    %16 = bufferization.to_tensor %view_memref_0 restrict writable : memref&amp;lt;?xf32, #map&amp;gt;&#xA;    %17 = linalg.copy ins(%16 : tensor&amp;lt;?xf32&amp;gt;) outs(%10 : tensor&amp;lt;?xf32&amp;gt;) -&amp;gt; tensor&amp;lt;?xf32&amp;gt;&#xA;    %18 = linalg_ext.pad ins(%17 : tensor&amp;lt;?xf32&amp;gt;) outs(%12 : tensor&amp;lt;1024xf32&amp;gt;) pvalue(%cst : f32) low = [0] high = [%13] {&#xA;    ^bb0(%arg4: f32):&#xA;      linalg_ext.yield %arg4 : f32&#xA;    } -&amp;gt; tensor&amp;lt;1024xf32&amp;gt;&#xA;    %mapped = linalg.map { arith.addf } ins(%14, %18 : tensor&amp;lt;1024xf32&amp;gt;, tensor&amp;lt;1024xf32&amp;gt;) outs(%12 : tensor&amp;lt;1024xf32&amp;gt;)&#xA;    %19 = llvm.inttoptr %arg2 : i64 to !llvm.ptr&#xA;    %view_memref_1 = aux.view %19 to offset: [%2], sizes: [%7], strides: [1] : !llvm.ptr to memref&amp;lt;?xf32, #map&amp;gt;&#xA;    %extracted_slice = tensor.extract_slice %mapped[0] [%7] [1] : tensor&amp;lt;1024xf32&amp;gt; to tensor&amp;lt;?xf32&amp;gt;&#xA;    bufferization.materialize_in_destination %extracted_slice in writable %view_memref_1 : (tensor&amp;lt;?xf32&amp;gt;, memref&amp;lt;?xf32, #map&amp;gt;) -&amp;gt; ()&#xA;    return&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Related work&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/triton-shared.git&#34;&gt;triton-shared&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>baidu/babylon</title>
    <updated>2024-06-01T01:29:48Z</updated>
    <id>tag:github.com,2024-06-01:/baidu/babylon</id>
    <link href="https://github.com/baidu/babylon" rel="alternate"></link>
    <summary type="html">&lt;p&gt;High-Performance C++ Fundamental Library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Babylon&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/baidu/babylon/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/baidu/babylon/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/baidu/babylon&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/baidu/babylon/badge.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Babylon是一个用于支持C++高性能服务端开发的基础库，从内存和并行管理角度提供了大量的基础组件。广泛应用在对性能有严苛要求的场景，典型例如搜索推荐引擎，自动驾驶车载计算等场景&lt;/p&gt; &#xA;&lt;h2&gt;核心功能&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;高效的应用级内存池机制 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;兼容并扩展了&lt;a href=&#34;https://en.cppreference.com/w/cpp/memory/memory_resource&#34;&gt;std::pmr::memory_resource&lt;/a&gt;机制&lt;/li&gt; &#xA;   &lt;li&gt;整合并增强了&lt;a href=&#34;https://protobuf.dev/reference/cpp/arenas&#34;&gt;google::protobuf::Arena&lt;/a&gt;机制&lt;/li&gt; &#xA;   &lt;li&gt;在对象池结合内存池使用的情况下提供了保留容量清理和重建的机制&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;组件式并行计算框架 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;基于无锁DAG推导的高性能自动组件并行框架&lt;/li&gt; &#xA;   &lt;li&gt;依照执行流天然生成数据流管理方案，复杂计算图场景下提供安全的数据竞争管理&lt;/li&gt; &#xA;   &lt;li&gt;微流水线并行机制，提供上限更好的并行化能力&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;并行开发基础组件 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;wait-free级别的并发安全容器（vector/queue/hash_table/...）&lt;/li&gt; &#xA;   &lt;li&gt;可遍历的线程缓存开发框架&lt;/li&gt; &#xA;   &lt;li&gt;可扩展支持线程/协程的同步原语（future/mutex/...）&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;应用/框架搭建基础工具 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;IOC组件开发框架&lt;/li&gt; &#xA;   &lt;li&gt;C++对象序列化框架&lt;/li&gt; &#xA;   &lt;li&gt;零拷贝/零分配异步日志框架&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;编译并使用&lt;/h2&gt; &#xA;&lt;h3&gt;支持平台和编译器&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;OS: Linux&lt;/li&gt; &#xA; &lt;li&gt;CPU: x86-64/aarch64&lt;/li&gt; &#xA; &lt;li&gt;COMPILER: gcc-9/gcc-10/gcc-12/clang-10/clang-14&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Bazel&lt;/h3&gt; &#xA;&lt;p&gt;Babylon使用&lt;a href=&#34;https://bazel.build&#34;&gt;Bazel&lt;/a&gt;进行构建并使用&lt;a href=&#34;https://bazel.build/external/module&#34;&gt;bzlmod&lt;/a&gt;进行依赖管理，考虑到目前Bazel生态整体处于bzlmod的转换周期，Babylon也依然兼容&lt;a href=&#34;https://bazel.build/rules/lib/globals/workspace&#34;&gt;workspace&lt;/a&gt;依赖管理模式&lt;/p&gt; &#xA;&lt;h4&gt;bzlmod&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;增加仓库注册表&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in .bazelrc&#xA;# babylon自身发布在独立注册表&#xA;common --registry=https://baidu.github.io/babylon/registry&#xA;# babylon依赖的boost发布在bazelboost项目的注册表，当然如果有其他源可以提供boost的注册表也可以替换&#xA;# 只要同样能够提供boost.preprocessor和boost.spirit模块寻址即可&#xA;common --registry=https://raw.githubusercontent.com/bazelboost/registry/main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;增加依赖项&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in MODULE.bazel&#xA;bazel_dep(name = &#39;babylon&#39;, version = &#39;1.1.6&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;添加依赖的子模块到编译目标，全部可用子模块可以参照&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/#%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E6%96%87%E6%A1%A3&#34;&gt;模块功能文档&lt;/a&gt;，或者&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/BUILD&#34;&gt;BUILD&lt;/a&gt;文件&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in BUILD&#xA;cc_library(&#xA;  ...&#xA;  deps = [&#xA;    ...&#xA;    &#39;@babylon//:any&#39;,&#xA;    &#39;@babylon//:concurrent&#39;,&#xA;  ],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;也可以直接添加All in One依赖目标&lt;code&gt;@babylon//:babylon&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;在&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/example/depend-use-bzlmod&#34;&gt;example/depend-use-bzlmod&lt;/a&gt;可以找到一个如何通过bzlmod依赖的简单样例&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;workspace&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;增加babylon依赖项&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in WORKSPACE&#xA;http_archive(&#xA;  name = &#39;com_baidu_babylon&#39;,&#xA;  urls = [&#39;https://github.com/baidu/babylon/archive/refs/tags/v1.1.6.tar.gz&#39;],&#xA;  strip_prefix = &#39;babylon-1.1.6&#39;,&#xA;  sha256 = &#39;a5bbc29f55819c90e00b40f9b5d2716d5f0232a158d69c530d8c7bac5bd794b6&#39;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;增加传递依赖项，内容拷贝自babylon代码库的WORKSPACE，并和项目自身依赖项合并&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in WORKSPACE&#xA;... // 增加babylon的WORKSPACE内的依赖项，注意和项目已有依赖去重合并&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;添加依赖的子模块到编译目标，全部可用子模块可以参照&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/#%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E6%96%87%E6%A1%A3&#34;&gt;模块功能文档&lt;/a&gt;，或者&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/BUILD&#34;&gt;BUILD&lt;/a&gt;文件&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in BUILD&#xA;cc_library(&#xA;  ...&#xA;  deps = [&#xA;    ...&#xA;    &#39;@com_baidu_babylon//:any&#39;,&#xA;    &#39;@com_baidu_babylon//:concurrent&#39;,&#xA;  ],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;也可以直接添加All in One依赖目标&lt;code&gt;@com_baidu_babylon//:babylon&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;在&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/example/depend-use-workspace&#34;&gt;example/depend-use-workspace&lt;/a&gt;可以找到一个如何通过workspace依赖的简单样例&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;CMake&lt;/h3&gt; &#xA;&lt;p&gt;Babylon也支持使用&lt;a href=&#34;https://cmake.org&#34;&gt;CMake&lt;/a&gt;进行构建，并支持通过&lt;a href=&#34;https://cmake.org/cmake/help/latest/command/find_package.html&#34;&gt;find_package&lt;/a&gt;、&lt;a href=&#34;https://cmake.org/cmake/help/latest/command/add_subdirectory.html&#34;&gt;add_subdirectory&lt;/a&gt;或&lt;a href=&#34;https://cmake.org/cmake/help/latest/module/FetchContent.html&#34;&gt;FetchContent&lt;/a&gt;进行依赖引入&lt;/p&gt; &#xA;&lt;h4&gt;FetchContent&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;增加依赖项到目标项目&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in CMakeList.txt&#xA;set(BUILD_DEPS ON)&#xA;&#xA;include(FetchContent)&#xA;FetchContent_Declare(&#xA;  babylon&#xA;  URL &#34;https://github.com/baidu/babylon/archive/refs/tags/v1.1.6.tar.gz&#34;&#xA;  URL_HASH SHA256=a5bbc29f55819c90e00b40f9b5d2716d5f0232a158d69c530d8c7bac5bd794b6&#xA;)&#xA;FetchContent_MakeAvailable(babylon)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;添加依赖到编译目标，CMake编译目前只提供All in One依赖目标&lt;code&gt;babylon::babylon&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in CMakeList.txt&#xA;target_link_libraries(your_target babylon::babylon)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;编译目标项目 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;cmake -Bbuild&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;cmake --build build -j$(nproc)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;在&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/example/depend-use-cmake-fetch&#34;&gt;example/depend-use-cmake-fetch&lt;/a&gt;可以找到一个如何通过CMake FetchContent依赖的简单样例&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;find_package&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;编译并安装&lt;code&gt;boost&lt;/code&gt; &lt;code&gt;abseil-cpp&lt;/code&gt; &lt;code&gt;protobuf&lt;/code&gt;或者直接使用apt等包管理工具安装对应平台的预编译包&lt;/li&gt; &#xA; &lt;li&gt;编译并安装babylon &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;cmake -Bbuild -DCMAKE_INSTALL_PREFIX=/your/install/path -DCMAKE_PREFIX_PATH=/your/install/path&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;cmake --build build -j$(nproc)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;cmake --install build&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;增加依赖项到目标项目&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in CMakeList.txt&#xA;find_package(babylon REQUIRED)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;添加依赖到编译目标，CMake编译目前只提供All in One依赖目标&lt;code&gt;babylon::babylon&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in CMakeList.txt&#xA;target_link_libraries(your_target babylon::babylon)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;编译目标项目 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;cmake -Bbuild -DCMAKE_PREFIX_PATH=/your/install/path&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;cmake --build build -j$(nproc)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;在&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/example/depend-use-cmake-find&#34;&gt;example/depend-use-cmake-find&lt;/a&gt;可以找到一个如何通过CMake find_package依赖的简单样例&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;add_subdirectory&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;下载&lt;code&gt;boost&lt;/code&gt; &lt;code&gt;abseil-cpp&lt;/code&gt; &lt;code&gt;protobuf``babylon&lt;/code&gt;源码&lt;/li&gt; &#xA; &lt;li&gt;增加依赖项到目标项目&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in CMakeList.txt&#xA;set(BOOST_INCLUDE_LIBRARIES preprocessor spirit)&#xA;add_subdirectory(boost EXCLUDE_FROM_ALL)&#xA;set(ABSL_ENABLE_INSTALL ON)&#xA;add_subdirectory(abseil-cpp)&#xA;set(protobuf_BUILD_TESTS OFF)&#xA;add_subdirectory(protobuf)&#xA;add_subdirectory(babylon)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;添加依赖到编译目标，CMake编译目前只提供All in One依赖目标&lt;code&gt;babylon::babylon&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# in CMakeList.txt&#xA;target_link_libraries(your_target babylon::babylon)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;编译目标项目 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;cmake -Bbuild&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;cmake --build build -j$(nproc)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;在&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/example/depend-use-cmake-subdir&#34;&gt;example/depend-use-cmake-subdir&lt;/a&gt;可以找到一个如何通过CMake sub_directory依赖的简单样例&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;模块功能文档&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/any.md&#34;&gt;:any&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/anyflow/index.md&#34;&gt;:anyflow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/concurrent/index.md&#34;&gt;:concurrent&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/executor.md&#34;&gt;:executor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/future.md&#34;&gt;:future&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/logging.md&#34;&gt;:logging&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/reusable/index.md&#34;&gt;:reusable&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/serialization.md&#34;&gt;:serialization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/time.md&#34;&gt;:time&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Protobuf &lt;a href=&#34;https://raw.githubusercontent.com/baidu/babylon/main/docs/arenastring.md&#34;&gt;arenastring&lt;/a&gt; patch&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;整体设计思路&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;amp;mid=2247489076&amp;amp;idx=1&amp;amp;sn=748bf716d94d5ed2739ea8a9385cd4a6&amp;amp;chksm=c03d2648f74aaf5e11298cf450c3453a273eb6d2161bc90e411b6d62fa0c1b96a45e411af805&amp;amp;scene=178&amp;amp;cur_album_id=1693053794688761860#rd&#34;&gt;百度C++工程师的那些极限优化（内存篇）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/0Ofo8ak7-UXuuOoD0KIHwA&#34;&gt;百度C++工程师的那些极限优化（并发篇）&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;如何贡献&lt;/h2&gt; &#xA;&lt;p&gt;如果你遇到问题或需要新功能，欢迎创建issue。&lt;/p&gt; &#xA;&lt;p&gt;如果你可以解决某个issue, 欢迎发送PR。&lt;/p&gt; &#xA;&lt;p&gt;发送PR前请确认有对应的单测代码。&lt;/p&gt;</summary>
  </entry>
</feed>