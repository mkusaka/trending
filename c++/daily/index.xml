<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-03T01:31:40Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>marcoslucianops/DeepStream-Yolo</title>
    <updated>2023-02-03T01:31:40Z</updated>
    <id>tag:github.com,2023-02-03:/marcoslucianops/DeepStream-Yolo</id>
    <link href="https://github.com/marcoslucianops/DeepStream-Yolo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;NVIDIA DeepStream SDK 6.1.1 / 6.1 / 6.0.1 / 6.0 implementation for YOLO models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DeepStream-Yolo&lt;/h1&gt; &#xA;&lt;p&gt;NVIDIA DeepStream SDK 6.1.1 / 6.1 / 6.0.1 / 6.0 configuration for YOLO models&lt;/p&gt; &#xA;&lt;h3&gt;Future updates&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;DeepStream tutorials&lt;/li&gt; &#xA; &lt;li&gt;Dynamic batch-size&lt;/li&gt; &#xA; &lt;li&gt;Segmentation model support&lt;/li&gt; &#xA; &lt;li&gt;Classification model support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Improvements on this repository&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Darknet cfg params parser (no need to edit &lt;code&gt;nvdsparsebbox_Yolo.cpp&lt;/code&gt; or other files)&lt;/li&gt; &#xA; &lt;li&gt;Support for &lt;code&gt;new_coords&lt;/code&gt; and &lt;code&gt;scale_x_y&lt;/code&gt; params&lt;/li&gt; &#xA; &lt;li&gt;Support for new models&lt;/li&gt; &#xA; &lt;li&gt;Support for new layers&lt;/li&gt; &#xA; &lt;li&gt;Support for new activations&lt;/li&gt; &#xA; &lt;li&gt;Support for convolutional groups&lt;/li&gt; &#xA; &lt;li&gt;Support for INT8 calibration&lt;/li&gt; &#xA; &lt;li&gt;Support for non square models&lt;/li&gt; &#xA; &lt;li&gt;New documentation for multiple models&lt;/li&gt; &#xA; &lt;li&gt;YOLOv5 &amp;gt;= 2.0 support&lt;/li&gt; &#xA; &lt;li&gt;YOLOR support&lt;/li&gt; &#xA; &lt;li&gt;GPU YOLO Decoder &lt;a href=&#34;https://github.com/marcoslucianops/DeepStream-Yolo/issues/138&#34;&gt;#138&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;PP-YOLOE support&lt;/li&gt; &#xA; &lt;li&gt;YOLOv7 support&lt;/li&gt; &#xA; &lt;li&gt;Optimized NMS &lt;a href=&#34;https://github.com/marcoslucianops/DeepStream-Yolo/issues/142&#34;&gt;#142&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Models benchmarks&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;YOLOv8 support&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;YOLOX support&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;PP-YOLOE+ support&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;YOLOv6 &amp;gt;= 2.0 support&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Getting started&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/#supported-models&#34;&gt;Suported models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/#benchmarks&#34;&gt;Benchmarks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/#dgpu-installation&#34;&gt;dGPU installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/#basic-usage&#34;&gt;Basic usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/#docker-usage&#34;&gt;Docker usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/#nms-configuration&#34;&gt;NMS configuration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/#int8-calibration&#34;&gt;INT8 calibration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/docs/YOLOv5.md&#34;&gt;YOLOv5 usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/docs/YOLOv6.md&#34;&gt;YOLOv6 usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/docs/YOLOv7.md&#34;&gt;YOLOv7 usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/docs/YOLOv8.md&#34;&gt;YOLOv8 usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/docs/YOLOR.md&#34;&gt;YOLOR usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/docs/YOLOX.md&#34;&gt;YOLOX usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/docs/PPYOLOE.md&#34;&gt;PP-YOLOE / PP-YOLOE+ usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/docs/customModels.md&#34;&gt;Using your custom model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/marcoslucianops/DeepStream-Yolo/master/docs/multipleGIEs.md&#34;&gt;Multiple YOLO GIEs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;h4&gt;DeepStream 6.1.1 on x86 platform&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://releases.ubuntu.com/20.04/&#34;&gt;Ubuntu 20.04&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-11-7-1-download-archive?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;Distribution=Ubuntu&amp;amp;target_version=20.04&amp;amp;target_type=runfile_local&#34;&gt;CUDA 11.7 Update 1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/nvidia-tensorrt-8x-download&#34;&gt;TensorRT 8.4 GA (8.4.1.5)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nvidia.com.br/Download/index.aspx&#34;&gt;NVIDIA Driver 515.65.01&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/deepstream-getting-started&#34;&gt;NVIDIA DeepStream SDK 6.1.1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gstreamer.freedesktop.org/&#34;&gt;GStreamer 1.16.2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/marcoslucianops/DeepStream-Yolo&#34;&gt;DeepStream-Yolo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;DeepStream 6.1 on x86 platform&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://releases.ubuntu.com/20.04/&#34;&gt;Ubuntu 20.04&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-11-6-1-download-archive?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;Distribution=Ubuntu&amp;amp;target_version=20.04&amp;amp;target_type=runfile_local&#34;&gt;CUDA 11.6 Update 1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/nvidia-tensorrt-8x-download&#34;&gt;TensorRT 8.2 GA Update 4 (8.2.5.1)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nvidia.com.br/Download/index.aspx&#34;&gt;NVIDIA Driver 510.47.03&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/deepstream-getting-started&#34;&gt;NVIDIA DeepStream SDK 6.1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gstreamer.freedesktop.org/&#34;&gt;GStreamer 1.16.2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/marcoslucianops/DeepStream-Yolo&#34;&gt;DeepStream-Yolo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;DeepStream 6.0.1 / 6.0 on x86 platform&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://releases.ubuntu.com/18.04.6/&#34;&gt;Ubuntu 18.04&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-11-4-1-download-archive?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;Distribution=Ubuntu&amp;amp;target_version=18.04&amp;amp;target_type=runfile_local&#34;&gt;CUDA 11.4 Update 1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/nvidia-tensorrt-8x-download&#34;&gt;TensorRT 8.0 GA (8.0.1)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nvidia.com.br/Download/index.aspx&#34;&gt;NVIDIA Driver &amp;gt;= 470.63.01&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/deepstream-sdk-download-tesla-archived&#34;&gt;NVIDIA DeepStream SDK 6.0.1 / 6.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gstreamer.freedesktop.org/&#34;&gt;GStreamer 1.14.5&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/marcoslucianops/DeepStream-Yolo&#34;&gt;DeepStream-Yolo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;DeepStream 6.1.1 on Jetson platform&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/embedded/jetpack&#34;&gt;JetPack 5.0.2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/deepstream-sdk&#34;&gt;NVIDIA DeepStream SDK 6.1.1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/marcoslucianops/DeepStream-Yolo&#34;&gt;DeepStream-Yolo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;DeepStream 6.1 on Jetson platform&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/embedded/jetpack-sdk-501dp&#34;&gt;JetPack 5.0.1 DP&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/embedded/deepstream-on-jetson-downloads-archived&#34;&gt;NVIDIA DeepStream SDK 6.1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/marcoslucianops/DeepStream-Yolo&#34;&gt;DeepStream-Yolo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;DeepStream 6.0.1 / 6.0 on Jetson platform&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/embedded/jetpack-sdk-462&#34;&gt;JetPack 4.6.2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/embedded/deepstream-on-jetson-downloads-archived&#34;&gt;NVIDIA DeepStream SDK 6.0.1 / 6.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/marcoslucianops/DeepStream-Yolo&#34;&gt;DeepStream-Yolo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Suported models&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AlexeyAB/darknet&#34;&gt;Darknet YOLO&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dog-qiuqiu/MobileNet-Yolo&#34;&gt;MobileNet-YOLO&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dog-qiuqiu/Yolo-Fastest&#34;&gt;YOLO-Fastest&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ultralytics/yolov5&#34;&gt;YOLOv5 &amp;gt;= 2.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meituan/YOLOv6&#34;&gt;YOLOv6 &amp;gt;= 2.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7&#34;&gt;YOLOv7&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ultralytics/ultralytics&#34;&gt;YOLOv8&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolor&#34;&gt;YOLOR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Megvii-BaseDetection/YOLOX&#34;&gt;YOLOX&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.5/configs/ppyoloe&#34;&gt;PP-YOLOE / PP-YOLOE+&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Benchmarks&lt;/h3&gt; &#xA;&lt;h4&gt;Config&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;board = NVIDIA Tesla V100 16GB (AWS: p3.2xlarge)&#xA;batch-size = 1&#xA;eval = val2017 (COCO)&#xA;sample = 1920x1080 video&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Used maintain-aspect-ratio=1 in config_infer file for Darknet (with letter_box=1) and PyTorch models.&lt;/p&gt; &#xA;&lt;h4&gt;NMS config&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Eval&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;nms-iou-threshold = 0.6 (Darknet and YOLOv8) / 0.65 (YOLOv5, YOLOv6, YOLOv7, YOLOR and YOLOX) / 0.7 (Paddle)&#xA;pre-cluster-threshold = 0.001&#xA;topk = 300&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Test&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;nms-iou-threshold = 0.45 / 0.7 (Paddle)&#xA;pre-cluster-threshold = 0.25&#xA;topk = 300&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Results&lt;/h4&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: * = PyTorch&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: ** = The YOLOv4 is trained with the trainvalno5k set, so the mAP is high on val2017 test&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;DeepStream&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Precision&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Resolution&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;IoU=0.5:0.95&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;IoU=0.5&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;IoU=0.75&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;FPS&lt;br&gt;(without display)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;PP-YOLOE-x&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.506&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.681&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.551&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;116.54&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;PP-YOLOE-l&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.498&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.674&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.545&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;187.93&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;PP-YOLOE-m&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.476&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.646&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.522&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;257.42&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;PP-YOLOE-s (400)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.422&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.589&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.463&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;465.23&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv7-E6E&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.476&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.648&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.521&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.82&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv7-D6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.479&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.648&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.520&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60.66&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv7-E6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.471&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.516&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;73.05&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv7-W6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.444&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.610&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.483&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;110.29&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv7-X*&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.496&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.679&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.536&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;162.31&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv7*&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.476&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.660&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.518&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;237.79&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv7-Tiny Leaky*&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.345&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.516&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.372&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;611.36&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv7-Tiny Leaky*&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;416&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.328&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.493&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.348&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;633.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5x6 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.508&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.683&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.554&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.88&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5l6 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.494&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.668&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.540&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;87.86&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5m6 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.469&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.644&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.514&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;142.68&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5s6 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.399&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.581&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.438&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;271.19&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5n6 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.317&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.487&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.344&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;392.20&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5x 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.470&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.652&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.513&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;152.99&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5l 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.454&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.636&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.496&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;247.60&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5m 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.421&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.604&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.458&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;375.06&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5s 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.344&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.528&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.371&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;602.44&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv5n 6.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.247&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.413&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.256&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;629.04&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv4**&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;608&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.497&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.739&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.549&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;206.23&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;YOLOv4-Tiny&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FP16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;416&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.215&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.402&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.205&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;634.69&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;dGPU installation&lt;/h3&gt; &#xA;&lt;p&gt;To install the DeepStream on dGPU (x86 platform), without docker, we need to do some steps to prepare the computer.&lt;/p&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;DeepStream 6.1.1&lt;/summary&gt; &#xA; &lt;h4&gt;1. Disable Secure Boot in BIOS&lt;/h4&gt; &#xA; &lt;h4&gt;2. Install dependencies&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt-get update&#xA;sudo apt-get install gcc make git libtool autoconf autogen pkg-config cmake&#xA;sudo apt-get install python3 python3-dev python3-pip&#xA;sudo apt-get install dkms&#xA;sudo apt-get install libssl1.1 libgstreamer1.0-0 gstreamer1.0-tools gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav libgstreamer-plugins-base1.0-dev libgstrtspserver-1.0-0 libjansson4 libyaml-cpp-dev&#xA;sudo apt-get install linux-headers-$(uname -r)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Purge all NVIDIA driver, CUDA, etc (replace $CUDA_PATH to your CUDA path)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo nvidia-uninstall&#xA;sudo $CUDA_PATH/bin/cuda-uninstaller&#xA;sudo apt-get remove --purge &#39;*nvidia*&#39;&#xA;sudo apt-get remove --purge &#39;*cuda*&#39;&#xA;sudo apt-get remove --purge &#39;*cudnn*&#39;&#xA;sudo apt-get remove --purge &#39;*tensorrt*&#39;&#xA;sudo apt autoremove --purge &amp;amp;&amp;amp; sudo apt autoclean &amp;amp;&amp;amp; sudo apt clean&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;3. Install CUDA Keyring&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb&#xA;sudo dpkg -i cuda-keyring_1.0-1_all.deb&#xA;sudo apt-get update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;4. Download and install NVIDIA Driver&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;TITAN, GeForce RTX / GTX series and RTX / Quadro series&lt;/p&gt; &lt;pre&gt;&lt;code&gt;wget https://us.download.nvidia.com/XFree86/Linux-x86_64/515.65.01/NVIDIA-Linux-x86_64-515.65.01.run&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Data center / Tesla series&lt;/p&gt; &lt;pre&gt;&lt;code&gt;wget https://us.download.nvidia.com/tesla/515.65.01/NVIDIA-Linux-x86_64-515.65.01.run&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo sh NVIDIA-Linux-x86_64-515.65.01.run --silent --disable-nouveau --dkms --install-libglvnd&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This step will disable the nouveau drivers.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Reboot&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo reboot&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Install&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo sh NVIDIA-Linux-x86_64-515.65.01.run --silent --disable-nouveau --dkms --install-libglvnd&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you are using a laptop with NVIDIA Optimius, run&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt-get install nvidia-prime&#xA;sudo prime-select nvidia&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;5. Download and install CUDA&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;wget https://developer.download.nvidia.com/compute/cuda/11.7.1/local_installers/cuda_11.7.1_515.65.01_linux.run&#xA;sudo sh cuda_11.7.1_515.65.01_linux.run --silent --toolkit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;Export environment variables&lt;/p&gt; &lt;pre&gt;&lt;code&gt;echo $&#39;export PATH=/usr/local/cuda-11.7/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-11.7/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}&#39; &amp;gt;&amp;gt; ~/.bashrc &amp;amp;&amp;amp; source ~/.bashrc&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;6. Download from &lt;a href=&#34;https://developer.nvidia.com/nvidia-tensorrt-8x-download&#34;&gt;NVIDIA website&lt;/a&gt; and install the TensorRT&lt;/h4&gt; &#xA; &lt;p&gt;TensorRT 8.4 GA for Ubuntu 20.04 and CUDA 11.0, 11.1, 11.2, 11.3, 11.4, 11.5, 11.6 and 11.7 DEB local repo Package&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo dpkg -i nv-tensorrt-repo-ubuntu2004-cuda11.6-trt8.4.1.5-ga-20220604_1-1_amd64.deb &#xA;sudo apt-key add /var/nv-tensorrt-repo-ubuntu2004-cuda11.6-trt8.4.1.5-ga-20220604/9a60d8bf.pub&#xA;sudo apt-get update&#xA;sudo apt-get install libnvinfer8=8.4.1-1+cuda11.6 libnvinfer-plugin8=8.4.1-1+cuda11.6 libnvparsers8=8.4.1-1+cuda11.6 libnvonnxparsers8=8.4.1-1+cuda11.6 libnvinfer-bin=8.4.1-1+cuda11.6 libnvinfer-dev=8.4.1-1+cuda11.6 libnvinfer-plugin-dev=8.4.1-1+cuda11.6 libnvparsers-dev=8.4.1-1+cuda11.6 libnvonnxparsers-dev=8.4.1-1+cuda11.6 libnvinfer-samples=8.4.1-1+cuda11.6 libcudnn8=8.4.1.50-1+cuda11.6 libcudnn8-dev=8.4.1.50-1+cuda11.6 python3-libnvinfer=8.4.1-1+cuda11.6 python3-libnvinfer-dev=8.4.1-1+cuda11.6&#xA;sudo apt-mark hold libnvinfer* libnvparsers* libnvonnxparsers* libcudnn8* tensorrt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;7. Download from &lt;a href=&#34;https://developer.nvidia.com/deepstream-getting-started&#34;&gt;NVIDIA website&lt;/a&gt; and install the DeepStream SDK&lt;/h4&gt; &#xA; &lt;p&gt;DeepStream 6.1.1 for Servers and Workstations (.deb)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt-get install ./deepstream-6.1_6.1.1-1_amd64.deb&#xA;rm ${HOME}/.cache/gstreamer-1.0/registry.x86_64.bin&#xA;sudo ln -snf /usr/local/cuda-11.7 /usr/local/cuda&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;8. Reboot the computer&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo reboot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;DeepStream 6.1&lt;/summary&gt; &#xA; &lt;h4&gt;1. Disable Secure Boot in BIOS&lt;/h4&gt; &#xA; &lt;h4&gt;2. Install dependencies&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt-get update&#xA;sudo apt-get install gcc make git libtool autoconf autogen pkg-config cmake&#xA;sudo apt-get install python3 python3-dev python3-pip&#xA;sudo apt-get install dkms&#xA;sudo apt-get install libssl1.1 libgstreamer1.0-0 gstreamer1.0-tools gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav libgstrtspserver-1.0-0 libjansson4 libyaml-cpp-dev&#xA;sudo apt-get install linux-headers-$(uname -r)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Purge all NVIDIA driver, CUDA, etc (replace $CUDA_PATH to your CUDA path)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo nvidia-uninstall&#xA;sudo $CUDA_PATH/bin/cuda-uninstaller&#xA;sudo apt-get remove --purge &#39;*nvidia*&#39;&#xA;sudo apt-get remove --purge &#39;*cuda*&#39;&#xA;sudo apt-get remove --purge &#39;*cudnn*&#39;&#xA;sudo apt-get remove --purge &#39;*tensorrt*&#39;&#xA;sudo apt autoremove --purge &amp;amp;&amp;amp; sudo apt autoclean &amp;amp;&amp;amp; sudo apt clean&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;3. Install CUDA Keyring&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb&#xA;sudo dpkg -i cuda-keyring_1.0-1_all.deb&#xA;sudo apt-get update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;4. Download and install NVIDIA Driver&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;TITAN, GeForce RTX / GTX series and RTX / Quadro series&lt;/p&gt; &lt;pre&gt;&lt;code&gt;wget https://us.download.nvidia.com/XFree86/Linux-x86_64/510.47.03/NVIDIA-Linux-x86_64-510.47.03.run&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Data center / Tesla series&lt;/p&gt; &lt;pre&gt;&lt;code&gt;wget https://us.download.nvidia.com/tesla/510.47.03/NVIDIA-Linux-x86_64-510.47.03.run&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo sh NVIDIA-Linux-x86_64-510.47.03.run --silent --disable-nouveau --dkms --install-libglvnd&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This step will disable the nouveau drivers.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Reboot&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo reboot&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Install&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo sh NVIDIA-Linux-x86_64-510.47.03.run --silent --disable-nouveau --dkms --install-libglvnd&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you are using a laptop with NVIDIA Optimius, run&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt-get install nvidia-prime&#xA;sudo prime-select nvidia&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;5. Download and install CUDA&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;wget https://developer.download.nvidia.com/compute/cuda/11.6.1/local_installers/cuda_11.6.1_510.47.03_linux.run&#xA;sudo sh cuda_11.6.1_510.47.03_linux.run --silent --toolkit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;Export environment variables&lt;/p&gt; &lt;pre&gt;&lt;code&gt;echo $&#39;export PATH=/usr/local/cuda-11.6/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-11.6/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}&#39; &amp;gt;&amp;gt; ~/.bashrc &amp;amp;&amp;amp; source ~/.bashrc&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;6. Download from &lt;a href=&#34;https://developer.nvidia.com/nvidia-tensorrt-8x-download&#34;&gt;NVIDIA website&lt;/a&gt; and install the TensorRT&lt;/h4&gt; &#xA; &lt;p&gt;TensorRT 8.2 GA Update 4 for Ubuntu 20.04 and CUDA 11.0, 11.1, 11.2, 11.3, 11.4 and 11.5 DEB local repo Package&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo dpkg -i nv-tensorrt-repo-ubuntu2004-cuda11.4-trt8.2.5.1-ga-20220505_1-1_amd64.deb&#xA;sudo apt-key add /var/nv-tensorrt-repo-ubuntu2004-cuda11.4-trt8.2.5.1-ga-20220505/82307095.pub&#xA;sudo apt-get update&#xA;sudo apt-get install libnvinfer8=8.2.5-1+cuda11.4 libnvinfer-plugin8=8.2.5-1+cuda11.4 libnvparsers8=8.2.5-1+cuda11.4 libnvonnxparsers8=8.2.5-1+cuda11.4 libnvinfer-bin=8.2.5-1+cuda11.4 libnvinfer-dev=8.2.5-1+cuda11.4 libnvinfer-plugin-dev=8.2.5-1+cuda11.4 libnvparsers-dev=8.2.5-1+cuda11.4 libnvonnxparsers-dev=8.2.5-1+cuda11.4 libnvinfer-samples=8.2.5-1+cuda11.4 libnvinfer-doc=8.2.5-1+cuda11.4 libcudnn8-dev=8.4.0.27-1+cuda11.6 libcudnn8=8.4.0.27-1+cuda11.6&#xA;sudo apt-mark hold libnvinfer* libnvparsers* libnvonnxparsers* libcudnn8* tensorrt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;7. Download from &lt;a href=&#34;https://developer.nvidia.com/deepstream-sdk-download-tesla-archived&#34;&gt;NVIDIA website&lt;/a&gt; and install the DeepStream SDK&lt;/h4&gt; &#xA; &lt;p&gt;DeepStream 6.1 for Servers and Workstations (.deb)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt-get install ./deepstream-6.1_6.1.0-1_amd64.deb&#xA;rm ${HOME}/.cache/gstreamer-1.0/registry.x86_64.bin&#xA;sudo ln -snf /usr/local/cuda-11.6 /usr/local/cuda&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;8. Reboot the computer&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo reboot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;DeepStream 6.0.1 / 6.0&lt;/summary&gt; &#xA; &lt;h4&gt;1. Disable Secure Boot in BIOS&lt;/h4&gt; &#xA; &lt;details&gt;&#xA;  &lt;summary&gt;If you are using a laptop with newer Intel/AMD processors and your Graphics in Settings-&amp;gt;Details-&amp;gt;About tab is llvmpipe, please update the kernel.&lt;/summary&gt; &#xA;  &lt;pre&gt;&lt;code&gt;wget https://kernel.ubuntu.com/~kernel-ppa/mainline/v5.11/amd64/linux-headers-5.11.0-051100_5.11.0-051100.202102142330_all.deb&#xA;wget https://kernel.ubuntu.com/~kernel-ppa/mainline/v5.11/amd64/linux-headers-5.11.0-051100-generic_5.11.0-051100.202102142330_amd64.deb&#xA;wget https://kernel.ubuntu.com/~kernel-ppa/mainline/v5.11/amd64/linux-image-unsigned-5.11.0-051100-generic_5.11.0-051100.202102142330_amd64.deb&#xA;wget https://kernel.ubuntu.com/~kernel-ppa/mainline/v5.11/amd64/linux-modules-5.11.0-051100-generic_5.11.0-051100.202102142330_amd64.deb&#xA;sudo dpkg -i  *.deb&#xA;sudo reboot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;/details&gt; &#xA; &lt;h4&gt;2. Install dependencies&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt-get update&#xA;sudo apt-get install gcc make git libtool autoconf autogen pkg-config cmake&#xA;sudo apt-get install python3 python3-dev python3-pip&#xA;sudo apt-get install libssl1.0.0 libgstreamer1.0-0 gstreamer1.0-tools gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav libgstrtspserver-1.0-0 libjansson4&#xA;sudo apt-get install linux-headers-$(uname -r)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Install DKMS only if you are using the default Ubuntu kernel&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt-get install dkms&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Purge all NVIDIA driver, CUDA, etc (replace $CUDA_PATH to your CUDA path)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo nvidia-uninstall&#xA;sudo $CUDA_PATH/bin/cuda-uninstaller&#xA;sudo apt-get remove --purge &#39;*nvidia*&#39;&#xA;sudo apt-get remove --purge &#39;*cuda*&#39;&#xA;sudo apt-get remove --purge &#39;*cudnn*&#39;&#xA;sudo apt-get remove --purge &#39;*tensorrt*&#39;&#xA;sudo apt autoremove --purge &amp;amp;&amp;amp; sudo apt autoclean &amp;amp;&amp;amp; sudo apt clean&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;3. Install CUDA Keyring&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-keyring_1.0-1_all.deb&#xA;sudo dpkg -i cuda-keyring_1.0-1_all.deb&#xA;sudo apt-get update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;4. Download and install NVIDIA Driver&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;TITAN, GeForce RTX / GTX series and RTX / Quadro series&lt;/p&gt; &lt;pre&gt;&lt;code&gt;wget https://us.download.nvidia.com/XFree86/Linux-x86_64/470.129.06/NVIDIA-Linux-x86_64-470.129.06.run&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Data center / Tesla series&lt;/p&gt; &lt;pre&gt;&lt;code&gt;wget https://us.download.nvidia.com/tesla/470.129.06/NVIDIA-Linux-x86_64-470.129.06.run&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo sh NVIDIA-Linux-x86_64-470.129.06.run --silent --disable-nouveau --dkms --install-libglvnd&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This step will disable the nouveau drivers.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Remove --dkms flag if you installed the 5.11.0 kernel.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Reboot&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo reboot&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Install&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo sh NVIDIA-Linux-x86_64-470.129.06.run --silent --disable-nouveau --dkms --install-libglvnd&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Remove --dkms flag if you installed the 5.11.0 kernel.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you are using a laptop with NVIDIA Optimius, run&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo apt-get install nvidia-prime&#xA;sudo prime-select nvidia&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;5. Download and install CUDA&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;wget https://developer.download.nvidia.com/compute/cuda/11.4.1/local_installers/cuda_11.4.1_470.57.02_linux.run&#xA;sudo sh cuda_11.4.1_470.57.02_linux.run --silent --toolkit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;Export environment variables&lt;/p&gt; &lt;pre&gt;&lt;code&gt;echo $&#39;export PATH=/usr/local/cuda-11.4/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-11.4/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}&#39; &amp;gt;&amp;gt; ~/.bashrc &amp;amp;&amp;amp; source ~/.bashrc&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;6. Download from &lt;a href=&#34;https://developer.nvidia.com/nvidia-tensorrt-8x-download&#34;&gt;NVIDIA website&lt;/a&gt; and install the TensorRT&lt;/h4&gt; &#xA; &lt;p&gt;TensorRT 8.0.1 GA for Ubuntu 18.04 and CUDA 11.3 DEB local repo package&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo dpkg -i nv-tensorrt-repo-ubuntu1804-cuda11.3-trt8.0.1.6-ga-20210626_1-1_amd64.deb&#xA;sudo apt-key add /var/nv-tensorrt-repo-ubuntu1804-cuda11.3-trt8.0.1.6-ga-20210626/7fa2af80.pub&#xA;sudo apt-get update&#xA;sudo apt-get install libnvinfer8=8.0.1-1+cuda11.3 libnvinfer-plugin8=8.0.1-1+cuda11.3 libnvparsers8=8.0.1-1+cuda11.3 libnvonnxparsers8=8.0.1-1+cuda11.3 libnvinfer-bin=8.0.1-1+cuda11.3 libnvinfer-dev=8.0.1-1+cuda11.3 libnvinfer-plugin-dev=8.0.1-1+cuda11.3 libnvparsers-dev=8.0.1-1+cuda11.3 libnvonnxparsers-dev=8.0.1-1+cuda11.3 libnvinfer-samples=8.0.1-1+cuda11.3 libnvinfer-doc=8.0.1-1+cuda11.3 libcudnn8-dev=8.2.1.32-1+cuda11.3 libcudnn8=8.2.1.32-1+cuda11.3&#xA;sudo apt-mark hold libnvinfer* libnvparsers* libnvonnxparsers* libcudnn8* tensorrt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;7. Download from &lt;a href=&#34;https://developer.nvidia.com/deepstream-sdk-download-tesla-archived&#34;&gt;NVIDIA website&lt;/a&gt; and install the DeepStream SDK&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;DeepStream 6.0.1 for Servers and Workstations (.deb)&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo apt-get install ./deepstream-6.0_6.0.1-1_amd64.deb&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;DeepStream 6.0 for Servers and Workstations (.deb)&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo apt-get install ./deepstream-6.0_6.0.0-1_amd64.deb&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;rm ${HOME}/.cache/gstreamer-1.0/registry.x86_64.bin&#xA;sudo ln -snf /usr/local/cuda-11.4 /usr/local/cuda&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;8. Reboot the computer&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code&gt;sudo reboot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Basic usage&lt;/h3&gt; &#xA;&lt;h4&gt;1. Download the repo&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/marcoslucianops/DeepStream-Yolo.git&#xA;cd DeepStream-Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. Download the &lt;code&gt;cfg&lt;/code&gt; and &lt;code&gt;weights&lt;/code&gt; files from &lt;a href=&#34;https://github.com/AlexeyAB/darknet&#34;&gt;Darknet&lt;/a&gt; repo to the DeepStream-Yolo folder&lt;/h4&gt; &#xA;&lt;h4&gt;3. Compile the lib&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.1.1 on x86 platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=11.7 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.1 on x86 platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=11.6 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.0.1 / 6.0 on x86 platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=11.4 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.1.1 / 6.1 on Jetson platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=11.4 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.0.1 / 6.0 on Jetson platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=10.2 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;4. Edit the &lt;code&gt;config_infer_primary.txt&lt;/code&gt; file according to your model (example for YOLOv4)&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;[property]&#xA;...&#xA;custom-network-config=yolov4.cfg&#xA;model-file=yolov4.weights&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;5. Run&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;deepstream-app -c deepstream_app_config.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you want to use YOLOv2 or YOLOv2-Tiny models, change the &lt;code&gt;deepstream_app_config.txt&lt;/code&gt; file before run it&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;...&#xA;[primary-gie]&#xA;...&#xA;config-file=config_infer_primary_yoloV2.txt&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Docker usage&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;x86 platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;nvcr.io/nvidia/deepstream:6.1.1-devel&#xA;nvcr.io/nvidia/deepstream:6.1.1-triton&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Jetson platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;nvcr.io/nvidia/deepstream-l4t:6.1.1-samples&#xA;nvcr.io/nvidia/deepstream-l4t:6.1.1-triton&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: To compile the &lt;code&gt;nvdsinfer_custom_impl_Yolo&lt;/code&gt;, you need to install the g++ inside the container&lt;/p&gt; &lt;pre&gt;&lt;code&gt;apt-get install build-essential&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: With DeepStream 6.1.1, the docker containers do not package libraries necessary for certain multimedia operations like audio data parsing, CPU decode, and CPU encode. This change could affect processing certain video streams/files like mp4 that include audio track. Please run the below script inside the docker images to install additional packages that might be necessary to use all of the DeepStreamSDK features:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;/opt/nvidia/deepstream/deepstream/user_additional_install.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: With DeepStream 6.1, the container image missed to include certain header files that will be available on host machine with Compute libraries installed from Jetpack. To mount the headers, use:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;-v /usr/include/aarch64-linux-gnu/NvInfer.h:/usr/include/aarch64-linux-gnu/NvInfer.h -v /usr/include/aarch64-linux-gnu/NvInferLegacyDims.h:/usr/include/aarch64-linux-gnu/NvInferLegacyDims.h -v /usr/include/aarch64-linux-gnu/NvInferRuntimeCommon.h:/usr/include/aarch64-linux-gnu/NvInferRuntimeCommon.h -v /usr/include/aarch64-linux-gnu/NvInferVersion.h:/usr/include/aarch64-linux-gnu/NvInferVersion.h -v /usr/include/aarch64-linux-gnu/NvInferRuntime.h:/usr/include/aarch64-linux-gnu/NvInferRuntime.h -v /usr/include/aarch64-linux-gnu/NvInferImpl.h:/usr/include/aarch64-linux-gnu/NvInferImpl.h -v /usr/include/aarch64-linux-gnu/NvCaffeParser.h:/usr/include/aarch64-linux-gnu/NvCaffeParser.h -v /usr/include/aarch64-linux-gnu/NvUffParser.h:/usr/include/aarch64-linux-gnu/NvUffParser.h -v /usr/include/aarch64-linux-gnu/NvInferPlugin.h:/usr/include/aarch64-linux-gnu/NvInferPlugin.h -v /usr/include/aarch64-linux-gnu/NvInferPluginUtils.h:/usr/include/aarch64-linux-gnu/NvInferPluginUtils.h -v /usr/local/cuda/:/usr/local/cuda/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Example&lt;/summary&gt; &#xA;   &lt;pre&gt;&lt;code&gt;sudo docker run -it --rm --net=host --runtime nvidia -e DISPLAY=$DISPLAY -w /opt/nvidia/deepstream/deepstream-6.1 -v /tmp/.X11-unix/:/tmp/.X11-unix -v /usr/include/aarch64-linux-gnu/NvInfer.h:/usr/include/aarch64-linux-gnu/NvInfer.h -v /usr/include/aarch64-linux-gnu/NvInferLegacyDims.h:/usr/include/aarch64-linux-gnu/NvInferLegacyDims.h -v /usr/include/aarch64-linux-gnu/NvInferRuntimeCommon.h:/usr/include/aarch64-linux-gnu/NvInferRuntimeCommon.h -v /usr/include/aarch64-linux-gnu/NvInferVersion.h:/usr/include/aarch64-linux-gnu/NvInferVersion.h -v /usr/include/aarch64-linux-gnu/NvInferRuntime.h:/usr/include/aarch64-linux-gnu/NvInferRuntime.h -v /usr/include/aarch64-linux-gnu/NvInferImpl.h:/usr/include/aarch64-linux-gnu/NvInferImpl.h -v /usr/include/aarch64-linux-gnu/NvCaffeParser.h:/usr/include/aarch64-linux-gnu/NvCaffeParser.h -v /usr/include/aarch64-linux-gnu/NvUffParser.h:/usr/include/aarch64-linux-gnu/NvUffParser.h -v /usr/include/aarch64-linux-gnu/NvInferPlugin.h:/usr/include/aarch64-linux-gnu/NvInferPlugin.h -v /usr/include/aarch64-linux-gnu/NvInferPluginUtils.h:/usr/include/aarch64-linux-gnu/NvInferPluginUtils.h -v /usr/local/cuda/:/usr/local/cuda/ nvcr.io/nvidia/deepstream-l4t:6.1-samples&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;NMS Configuration&lt;/h3&gt; &#xA;&lt;p&gt;To change the &lt;code&gt;nms-iou-threshold&lt;/code&gt;, &lt;code&gt;pre-cluster-threshold&lt;/code&gt; and &lt;code&gt;topk&lt;/code&gt; values, modify the config_infer file and regenerate the model engine file&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[class-attrs-all]&#xA;nms-iou-threshold=0.45&#xA;pre-cluster-threshold=0.25&#xA;topk=300&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: It is important to regenerate the engine to get the max detection speed based on &lt;code&gt;pre-cluster-threshold&lt;/code&gt; you set.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Lower &lt;code&gt;topk&lt;/code&gt; values will result in more performance.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Make sure to set &lt;code&gt;cluster-mode=2&lt;/code&gt; in the config_infer file.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;INT8 calibration&lt;/h3&gt; &#xA;&lt;h4&gt;1. Install OpenCV&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt-get install libopencv-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. Compile/recompile the &lt;code&gt;nvdsinfer_custom_impl_Yolo&lt;/code&gt; lib with OpenCV support&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.1.1 on x86 platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=11.7 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.1 on x86 platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=11.6 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.0.1 / 6.0 on x86 platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=11.4 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.1.1 / 6.1 on Jetson platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=11.4 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;DeepStream 6.0.1 / 6.0 on Jetson platform&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA_VER=10.2 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;3. For COCO dataset, download the &lt;a href=&#34;https://drive.google.com/file/d/1gbvfn7mcsGDRZ_luJwtITL-ru2kK99aK/view?usp=sharing&#34;&gt;val2017&lt;/a&gt;, extract, and move to DeepStream-Yolo folder&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Select 1000 random images from COCO dataset to run calibration&lt;/p&gt; &lt;pre&gt;&lt;code&gt;mkdir calibration&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code&gt;for jpg in $(ls -1 val2017/*.jpg | sort -R | head -1000); do \&#xA;    cp ${jpg} calibration/; \&#xA;done&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create the &lt;code&gt;calibration.txt&lt;/code&gt; file with all selected images&lt;/p&gt; &lt;pre&gt;&lt;code&gt;realpath calibration/*jpg &amp;gt; calibration.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set environment variables&lt;/p&gt; &lt;pre&gt;&lt;code&gt;export INT8_CALIB_IMG_PATH=calibration.txt&#xA;export INT8_CALIB_BATCH_SIZE=1&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Edit the &lt;code&gt;config_infer&lt;/code&gt; file&lt;/p&gt; &lt;pre&gt;&lt;code&gt;...&#xA;model-engine-file=model_b1_gpu0_fp32.engine&#xA;#int8-calib-file=calib.table&#xA;...&#xA;network-mode=0&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To&lt;/p&gt; &lt;pre&gt;&lt;code&gt;...&#xA;model-engine-file=model_b1_gpu0_int8.engine&#xA;int8-calib-file=calib.table&#xA;...&#xA;network-mode=1&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;deepstream-app -c deepstream_app_config.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: NVIDIA recommends at least 500 images to get a good accuracy. On this example, I used 1000 images to get better accuracy (more images = more accuracy). Higher &lt;code&gt;INT8_CALIB_BATCH_SIZE&lt;/code&gt; values will result in more accuracy and faster calibration speed. Set it according to you GPU memory. This process can take a long time.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Extract metadata&lt;/h3&gt; &#xA;&lt;p&gt;You can get metadata from DeepStream using Python and C/C++. For C/C++, you can edit the &lt;code&gt;deepstream-app&lt;/code&gt; or &lt;code&gt;deepstream-test&lt;/code&gt; codes. For Python, your can install and edit &lt;a href=&#34;https://github.com/NVIDIA-AI-IOT/deepstream_python_apps&#34;&gt;deepstream_python_apps&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Basically, you need manipulate the &lt;code&gt;NvDsObjectMeta&lt;/code&gt; (&lt;a href=&#34;https://docs.nvidia.com/metropolis/deepstream/python-api/PYTHON_API/NvDsMeta/NvDsObjectMeta.html&#34;&gt;Python&lt;/a&gt; / &lt;a href=&#34;https://docs.nvidia.com/metropolis/deepstream/sdk-api/struct__NvDsObjectMeta.html&#34;&gt;C/C++&lt;/a&gt;) &lt;code&gt;and NvDsFrameMeta&lt;/code&gt; (&lt;a href=&#34;https://docs.nvidia.com/metropolis/deepstream/python-api/PYTHON_API/NvDsMeta/NvDsFrameMeta.html&#34;&gt;Python&lt;/a&gt; / &lt;a href=&#34;https://docs.nvidia.com/metropolis/deepstream/sdk-api/struct__NvDsFrameMeta.html&#34;&gt;C/C++&lt;/a&gt;) to get the label, position, etc. of bboxes.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;p&gt;My projects: &lt;a href=&#34;https://www.youtube.com/MarcosLucianoTV&#34;&gt;https://www.youtube.com/MarcosLucianoTV&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/GSL</title>
    <updated>2023-02-03T01:31:40Z</updated>
    <id>tag:github.com,2023-02-03:/microsoft/GSL</id>
    <link href="https://github.com/microsoft/GSL" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Guidelines Support Library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GSL: Guidelines Support Library&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://dev.azure.com/cppstat/GSL/_build/latest?definitionId=1&amp;amp;branchName=main&#34;&gt;&lt;img src=&#34;https://dev.azure.com/cppstat/GSL/_apis/build/status/microsoft.GSL?branchName=main&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Guidelines Support Library (GSL) contains functions and types that are suggested for use by the &lt;a href=&#34;https://github.com/isocpp/CppCoreGuidelines&#34;&gt;C++ Core Guidelines&lt;/a&gt; maintained by the &lt;a href=&#34;https://isocpp.org&#34;&gt;Standard C++ Foundation&lt;/a&gt;. This repo contains Microsoft&#39;s implementation of GSL.&lt;/p&gt; &#xA;&lt;p&gt;The entire implementation is provided inline in the headers under the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/GSL/main/include/gsl&#34;&gt;gsl&lt;/a&gt; directory. The implementation generally assumes a platform that implements C++14 support.&lt;/p&gt; &#xA;&lt;p&gt;While some types have been broken out into their own headers (e.g. &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/GSL/main/include/gsl/span&#34;&gt;gsl/span&lt;/a&gt;), it is simplest to just include &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/GSL/main/include/gsl/gsl&#34;&gt;gsl/gsl&lt;/a&gt; and gain access to the entire library.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;NOTE: We encourage contributions that improve or refine any of the types in this library as well as ports to other platforms. Please see &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/GSL/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for more information about contributing.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;Project Code of Conduct&lt;/h1&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h1&gt;Usage of Third Party Libraries&lt;/h1&gt; &#xA;&lt;p&gt;This project makes use of the &lt;a href=&#34;https://github.com/google/googletest&#34;&gt;Google Test&lt;/a&gt; testing library. Please see the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/GSL/main/ThirdPartyNotices.txt&#34;&gt;ThirdPartyNotices.txt&lt;/a&gt; file for details regarding the licensing of Google Test.&lt;/p&gt; &#xA;&lt;h1&gt;Supported features&lt;/h1&gt; &#xA;&lt;h2&gt;Microsoft GSL implements the following from the C++ Core Guidelines:&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Supported?&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/isocpp/CppCoreGuidelines/raw/master/CppCoreGuidelines.md#gslview-views&#34;&gt;&lt;strong&gt;1. Views&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;owner&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;an alias for a raw pointer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;not_null&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;restricts a pointer / smart pointer to hold non-null values&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a view over a contiguous sequence of memory. Based on the standardized version of &lt;code&gt;std::span&lt;/code&gt;, however &lt;code&gt;gsl::span&lt;/code&gt; enforces bounds checking. See the &lt;a href=&#34;https://github.com/microsoft/GSL/wiki/gsl::span-and-std::span&#34;&gt;wiki&lt;/a&gt; for additional information.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;span_p&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;spans a range starting from a pointer to the first place for which the predicate is true&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;basic_zstring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;A pointer to a C-string (zero-terminated array) with a templated char type&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;zstring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;An alias to &lt;code&gt;basic_zstring&lt;/code&gt; with dynamic extent and a char type of char&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;czstring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;An alias to &lt;code&gt;basic_zstring&lt;/code&gt; with dynamic extent and a char type of const char&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;wzstring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;An alias to &lt;code&gt;basic_zstring&lt;/code&gt; with dynamic extent and a char type of wchar_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;cwzstring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;An alias to &lt;code&gt;basic_zstring&lt;/code&gt; with dynamic extent and a char type of const wchar_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;u16zstring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;An alias to &lt;code&gt;basic_zstring&lt;/code&gt; with dynamic extent and a char type of char16_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;cu16zstring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;An alias to &lt;code&gt;basic_zstring&lt;/code&gt; with dynamic extent and a char type of const char16_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;u32zstring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;An alias to &lt;code&gt;basic_zstring&lt;/code&gt; with dynamic extent and a char type of char32_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;cu32zstring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;An alias to &lt;code&gt;basic_zstring&lt;/code&gt; with dynamic extent and a char type of const char32_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/isocpp/CppCoreGuidelines/raw/master/CppCoreGuidelines.md#gslowner-ownership-pointers&#34;&gt;&lt;strong&gt;2. Owners&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;unique_ptr&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;an alias to &lt;code&gt;std::unique_ptr&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;shared_ptr&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;an alias to &lt;code&gt;std::shared_ptr&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stack_array&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;a stack-allocated array&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;dyn_array&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;a heap-allocated array&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/isocpp/CppCoreGuidelines/raw/master/CppCoreGuidelines.md#gslassert-assertions&#34;&gt;&lt;strong&gt;3. Assertions&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Expects&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a precondition assertion; on failure it terminates&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ensures&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a postcondition assertion; on failure it terminates&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/isocpp/CppCoreGuidelines/raw/master/CppCoreGuidelines.md#gslutil-utilities&#34;&gt;&lt;strong&gt;4. Utilities&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;move_owner&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;a helper function that moves one &lt;code&gt;owner&lt;/code&gt; to the other&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;byte&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;either an alias to &lt;code&gt;std::byte&lt;/code&gt; or a byte type&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;final_action&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a RAII style class that invokes a functor on its destruction&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;finally&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a helper function instantiating &lt;code&gt;final_action&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GSL_SUPPRESS&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a macro that takes an argument and turns it into &lt;code&gt;[[gsl::suppress(x)]]&lt;/code&gt; or &lt;code&gt;[[gsl::suppress(&#34;x&#34;)]]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;[[implicit]]&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;a &#34;marker&#34; to put on single-argument constructors to explicitly make them non-explicit&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;index&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a type to use for all container and array indexing (currently an alias for &lt;code&gt;std::ptrdiff_t&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;joining_thread&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;a RAII style version of &lt;code&gt;std::thread&lt;/code&gt; that joins&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;narrow&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a checked version of &lt;code&gt;narrow_cast&lt;/code&gt;; it can throw &lt;code&gt;narrowing_error&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;narrow_cast&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a narrowing cast for values and a synonym for &lt;code&gt;static_cast&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;narrowing_error&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;a custom exception type thrown by &lt;code&gt;narrow()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/isocpp/CppCoreGuidelines/raw/master/CppCoreGuidelines.md#gslconcept-concepts&#34;&gt;&lt;strong&gt;5. Concepts&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;The following features do not exist in or have been removed from the C++ Core Guidelines:&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Supported?&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;strict_not_null&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☑&lt;/td&gt; &#xA;   &lt;td&gt;A stricter version of &lt;code&gt;not_null&lt;/code&gt; with explicit constructors&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multi_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. Multi-dimensional span.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;strided_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. Support for this type has been discontinued.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;basic_string_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. Like &lt;code&gt;span&lt;/code&gt; but for strings with a templated char type&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;string_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. An alias to &lt;code&gt;basic_string_span&lt;/code&gt; with a char type of char&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;cstring_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. An alias to &lt;code&gt;basic_string_span&lt;/code&gt; with a char type of const char&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;wstring_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. An alias to &lt;code&gt;basic_string_span&lt;/code&gt; with a char type of wchar_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;cwstring_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. An alias to &lt;code&gt;basic_string_span&lt;/code&gt; with a char type of const wchar_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;u16string_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. An alias to &lt;code&gt;basic_string_span&lt;/code&gt; with a char type of char16_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;cu16string_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. An alias to &lt;code&gt;basic_string_span&lt;/code&gt; with a char type of const char16_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;u32string_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. An alias to &lt;code&gt;basic_string_span&lt;/code&gt; with a char type of char32_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;cu32string_span&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;☐&lt;/td&gt; &#xA;   &lt;td&gt;Deprecated. An alias to &lt;code&gt;basic_string_span&lt;/code&gt; with a char type of const char32_t&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;This is based on &lt;a href=&#34;https://github.com/isocpp/CppCoreGuidelines/raw/master/CppCoreGuidelines.md#gsl-guidelines-support-library&#34;&gt;CppCoreGuidelines semi-specification&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Quick Start&lt;/h1&gt; &#xA;&lt;h2&gt;Supported Compilers / Toolsets&lt;/h2&gt; &#xA;&lt;p&gt;The GSL officially supports the latest and previous major versions of VS with MSVC &amp;amp; LLVM, GCC, Clang, and XCode with Apple-Clang. Within these two major versions, we try to target the latest minor updates / revisions (although this may be affected by delays between a toolchain&#39;s release and when it becomes widely available for use). Below is a table showing the versions currently being tested.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Compiler&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Toolset Versions Currently Tested&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;XCode&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;13.2.1 &amp;amp; 12.5.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;GCC&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;11[^1] &amp;amp; 10[^2]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Clang&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;12[^2] &amp;amp; 11[^2]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Visual Studio with MSVC&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;VS2022[^3] &amp;amp; VS2019[^4]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Visual Studio with LLVM&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;VS2022[^3] &amp;amp; VS2019[^4]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;[^1]: Precise version may be found in the &lt;a href=&#34;https://dev.azure.com/cppstat/GSL/_build?definitionId=1&amp;amp;branchFilter=26&#34;&gt;latest CI results&lt;/a&gt;. [^2]: Precise version may be found in the &lt;a href=&#34;https://dev.azure.com/cppstat/GSL/_build?definitionId=1&amp;amp;branchFilter=26&#34;&gt;latest CI results&lt;/a&gt;. Should be the version specified &lt;a href=&#34;https://github.com/actions/virtual-environments/raw/main/images/linux/Ubuntu2004-Readme.md#language-and-runtime&#34;&gt;here&lt;/a&gt;. [^3]: Precise version may be found in the &lt;a href=&#34;https://dev.azure.com/cppstat/GSL/_build?definitionId=1&amp;amp;branchFilter=26&#34;&gt;latest CI results&lt;/a&gt;. Should be the version specified &lt;a href=&#34;https://github.com/actions/virtual-environments/raw/main/images/win/Windows2022-Readme.md#visual-studio-enterprise-2022&#34;&gt;here&lt;/a&gt;. [^4]: Precise version may be found in the &lt;a href=&#34;https://dev.azure.com/cppstat/GSL/_build?definitionId=1&amp;amp;branchFilter=26&#34;&gt;latest CI results&lt;/a&gt;. Should be the version specified &lt;a href=&#34;https://github.com/actions/virtual-environments/raw/main/images/win/Windows2019-Readme.md#visual-studio-enterprise-2019&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;If you successfully port GSL to another platform, we would love to hear from you!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Submit an issue specifying the platform and target.&lt;/li&gt; &#xA; &lt;li&gt;Consider contributing your changes by filing a pull request with any necessary changes.&lt;/li&gt; &#xA; &lt;li&gt;If at all possible, add a CI/CD step and add the button to the table below!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Target&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;CI/CD Status&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;iOS&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;img src=&#34;https://github.com/microsoft/GSL/workflows/CI_iOS/badge.svg?sanitize=true&#34; alt=&#34;CI_iOS&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Android&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;img src=&#34;https://github.com/microsoft/GSL/workflows/CI_Android/badge.svg?sanitize=true&#34; alt=&#34;CI_Android&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Note: These CI/CD steps are run with each pull request, however failures in them are non-blocking.&lt;/p&gt; &#xA;&lt;h2&gt;Building the tests&lt;/h2&gt; &#xA;&lt;p&gt;To build the tests, you will require the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://cmake.org&#34;&gt;CMake&lt;/a&gt;, version 3.8 or later to be installed and in your PATH.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These steps assume the source code of this repository has been cloned into a directory named &lt;code&gt;c:\GSL&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a directory to contain the build outputs for a particular architecture (we name it c:\GSL\build-x86 in this example).&lt;/p&gt; &lt;pre&gt;&lt;code&gt; cd GSL&#xA; md build-x86&#xA; cd build-x86&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Configure CMake to use the compiler of your choice (you can see a list by running &lt;code&gt;cmake --help&lt;/code&gt;).&lt;/p&gt; &lt;pre&gt;&lt;code&gt; cmake -G &#34;Visual Studio 15 2017&#34; c:\GSL&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build the test suite (in this case, in the Debug configuration, Release is another good choice).&lt;/p&gt; &lt;pre&gt;&lt;code&gt; cmake --build . --config Debug&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the test suite.&lt;/p&gt; &lt;pre&gt;&lt;code&gt; ctest -C Debug&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;All tests should pass - indicating your platform is fully supported and you are ready to use the GSL types!&lt;/p&gt; &#xA;&lt;h2&gt;Building GSL - Using vcpkg&lt;/h2&gt; &#xA;&lt;p&gt;You can download and install GSL using the &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;vcpkg&lt;/a&gt; dependency manager:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/Microsoft/vcpkg.git&#xA;cd vcpkg&#xA;./bootstrap-vcpkg.sh&#xA;./vcpkg integrate install&#xA;vcpkg install ms-gsl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The GSL port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;create an issue or pull request&lt;/a&gt; on the vcpkg repository.&lt;/p&gt; &#xA;&lt;h2&gt;Using the libraries&lt;/h2&gt; &#xA;&lt;p&gt;As the types are entirely implemented inline in headers, there are no linking requirements.&lt;/p&gt; &#xA;&lt;p&gt;You can copy the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/GSL/main/include/gsl&#34;&gt;gsl&lt;/a&gt; directory into your source tree so it is available to your compiler, then include the appropriate headers in your program.&lt;/p&gt; &#xA;&lt;p&gt;Alternatively set your compiler&#39;s &lt;em&gt;include path&lt;/em&gt; flag to point to the GSL development folder (&lt;code&gt;c:\GSL\include&lt;/code&gt; in the example above) or installation folder (after running the install). Eg.&lt;/p&gt; &#xA;&lt;p&gt;MSVC++&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;/I c:\GSL\include&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GCC/clang&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;-I$HOME/dev/GSL/include&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Include the library using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;gsl/gsl&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage in CMake&lt;/h2&gt; &#xA;&lt;p&gt;The library provides a Config file for CMake, once installed it can be found via &lt;code&gt;find_package&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Which, when successful, will add library target called &lt;code&gt;Microsoft.GSL::GSL&lt;/code&gt; which you can use via the usual &lt;code&gt;target_link_libraries&lt;/code&gt; mechanism.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cmake&#34;&gt;find_package(Microsoft.GSL CONFIG REQUIRED)&#xA;&#xA;target_link_libraries(foobar PRIVATE Microsoft.GSL::GSL)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;FetchContent&lt;/h3&gt; &#xA;&lt;p&gt;If you are using CMake version 3.11+ you can use the offical &lt;a href=&#34;https://cmake.org/cmake/help/latest/module/FetchContent.html&#34;&gt;FetchContent module&lt;/a&gt;. This allows you to easily incorporate GSL into your project.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cmake&#34;&gt;# NOTE: This example uses CMake version 3.14 (FetchContent_MakeAvailable).&#xA;# Since it streamlines the FetchContent process&#xA;cmake_minimum_required(VERSION 3.14)&#xA;&#xA;include(FetchContent)&#xA;&#xA;FetchContent_Declare(GSL&#xA;    GIT_REPOSITORY &#34;https://github.com/microsoft/GSL&#34;&#xA;    GIT_TAG &#34;v4.0.0&#34;&#xA;    GIT_SHALLOW ON&#xA;)&#xA;&#xA;FetchContent_MakeAvailable(GSL)&#xA;&#xA;target_link_libraries(foobar PRIVATE Microsoft.GSL::GSL)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Debugging visualization support&lt;/h2&gt; &#xA;&lt;p&gt;For Visual Studio users, the file &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/GSL/main/GSL.natvis&#34;&gt;GSL.natvis&lt;/a&gt; in the root directory of the repository can be added to your project if you would like more helpful visualization of GSL types in the Visual Studio debugger than would be offered by default.&lt;/p&gt; &#xA;&lt;p&gt;If you are using CMake this will be done automatically for you. See &#39;GSL_VS_ADD_NATIVE_VISUALIZERS&#39;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>TheD1rkMtr/D1rkLrd</title>
    <updated>2023-02-03T01:31:40Z</updated>
    <id>tag:github.com,2023-02-03:/TheD1rkMtr/D1rkLrd</id>
    <link href="https://github.com/TheD1rkMtr/D1rkLrd" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Shellcode Loader with Indirect Dynamic syscall Implementation , shellcode in MAC format, API resolving from PEB, Syscall calll and syscall instruction address resolving at run time&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;D1rkLrd&lt;/h1&gt; &#xA;&lt;p&gt;Shellcode Loader with Indirect Dynamic syscall Implementation , shellcode in MAC format, API resolving from PEB, Syscall calll and syscall instruction address resolving at run time&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/123980007/215594960-1a612745-69c8-43e0-b8e5-f95fb336998a.png&#34; alt=&#34;CrowdStrike&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>