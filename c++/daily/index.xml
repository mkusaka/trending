<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-24T01:29:48Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>CVCUDA/CV-CUDA</title>
    <updated>2022-12-24T01:29:48Z</updated>
    <id>tag:github.com,2022-12-24:/CVCUDA/CV-CUDA</id>
    <link href="https://github.com/CVCUDA/CV-CUDA" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CV-CUDAâ„¢ is an open-source, graphics processing unit (GPU)-accelerated library for cloud-scale image processing and computer vision.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CV-CUDA&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache_2.0-yellogreen.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/Version-v0.2.0--alpha-blue&#34; alt=&#34;Version&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/Platform-linux--64_%7C_win--64_wsl2-gray&#34; alt=&#34;Platform&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-toolkit-archive&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/CUDA-v11.7-%2376B900?logo=nvidia&#34; alt=&#34;Cuda&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gcc.gnu.org/gcc-11/changes.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GCC-v11.0-yellow&#34; alt=&#34;GCC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.python.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-v3.7_%7c_v3.8_%7c_v3.9_%7c_v3.10-blue?logo=python&#34; alt=&#34;Python&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cmake.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/CMake-v3.22-%23008FBA?logo=cmake&#34; alt=&#34;CMake&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;CV-CUDA is an open-source project that enables building efficient cloud-scale Artificial Intelligence (AI) imaging and computer vision (CV) applications. It uses graphics processing unit (GPU) acceleration to help developers build highly efficient pre- and post-processing pipelines. CV-CUDA originated as a collaborative effort between &lt;a href=&#34;https://developer.nvidia.com/&#34;&gt;NVIDIA&lt;/a&gt; and &lt;a href=&#34;https://www.bytedance.com/&#34;&gt;ByteDance&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Refer to our &lt;a href=&#34;https://raw.githubusercontent.com/CVCUDA/CV-CUDA/release_v0.2.x/DEVELOPER_GUIDE.md&#34;&gt;Developer Guide&lt;/a&gt; for more information on the operators avaliable as of release v0.2.0-alpha.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get a local copy up and running follow these steps.&lt;/p&gt; &#xA;&lt;h3&gt;Pre-requisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Linux distro: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Ubuntu x86_64 &amp;gt;= 18.04&lt;/li&gt; &#xA;   &lt;li&gt;WSL2 with Ubuntu &amp;gt;= 20.04 (tested with 20.04)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;CUDA Driver &amp;gt;= 11.7 (Not tested on 12.0)&lt;/li&gt; &#xA; &lt;li&gt;GCC &amp;gt;= 11.0&lt;/li&gt; &#xA; &lt;li&gt;Python &amp;gt;= 3.7&lt;/li&gt; &#xA; &lt;li&gt;cmake &amp;gt;= 3.22&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;The following steps describe how to install CV-CUDA from pre-built install packages. Choose the installation method that meets your environment needs.&lt;/p&gt; &#xA;&lt;h4&gt;Tar File Installation&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;tar -xvf nvcv-lib-0.2.0-cuda11-x86_64-linux.tar.xz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;DEB File Installation&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo dpkg -i nvcv-lib-0.2.0-cuda11-x86_64-linux.deb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Python WHL File Installation&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install nvcv_python-0.2.0-cp38-cp38-linux_x86_64.whl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Build from Source&lt;/h3&gt; &#xA;&lt;p&gt;Follow these instruction to successfully build CV-CUDA from source:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Build CV-CUDA&lt;/p&gt; &lt;pre&gt;&lt;code&gt;cd ~/cvcuda&#xA;ci/build.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will compile a x86 release build of CV-CUDA inside &lt;code&gt;build-rel&lt;/code&gt; directory. The library is in build-rel/lib, docs in build-rel/docs and executables (tests, etc...) in build-rel/bin.&lt;/p&gt; &lt;p&gt;The script accepts some parameters to control the creation of the build tree:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ci/build.sh [release|debug] [output build tree path]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;By default it builds for release.&lt;/p&gt; &lt;p&gt;If output build tree path isn&#39;t specified, it&#39;ll be &lt;code&gt;build-rel&lt;/code&gt; for release builds, and build-deb for debug.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build Documentation&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ci/build_docs.sh [build folder]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Example: `ci/build_docs.sh build&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build Samples&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./ci/build_samples.sh [build folder]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;(For instructions on how to compile samples outside of the CV-CUDA project, see the &lt;a href=&#34;https://raw.githubusercontent.com/CVCUDA/CV-CUDA/release_v0.2.x/samples/README.md&#34;&gt;Samples&lt;/a&gt; documentation)&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run Tests&lt;/p&gt; &lt;p&gt;The tests are in &lt;code&gt;&amp;lt;buildtree&amp;gt;/bin&lt;/code&gt;. You can run the script below to run all tests at once. Here&#39;s an example when build tree is created in &lt;code&gt;build-rel&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;build-rel/bin/run_tests.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run Samples&lt;/p&gt; &lt;p&gt;The samples are installed in &lt;code&gt;&amp;lt;buildtree&amp;gt;/bin&lt;/code&gt;. You can run the script below to download and serialize the model and run the sample with the test data provided.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;./ci/run_samples.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Package installers&lt;/p&gt; &lt;p&gt;From a succesfully built project, installers can be generated using cpack:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd build-rel&#xA;cpack .&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will generate in the build directory both Debian installers and tarballs (*.tar.xz), needed for integration in other distros.&lt;/p&gt; &lt;p&gt;For a fine-grained choice of what installers to generate, the full syntax is:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;cmake . -G [DEB|TXZ]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;DEB for Debian packages&lt;/li&gt; &#xA;   &lt;li&gt;TXZ for *.tar.xz tarballs.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;CV-CUDA is an open source project. As part of the Open Source Community, we are committed to the cycle of learning, improving, and updating that makes this community thrive. However, as of release v0.2.0-alpha, CV-CUDA is not yet ready for external contributions.&lt;/p&gt; &#xA;&lt;p&gt;To understand the process for contributing the CV-CUDA, see our &lt;a href=&#34;https://raw.githubusercontent.com/CVCUDA/CV-CUDA/release_v0.2.x/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt; page. To understand our committment to the Open Source Community, and providing an environment that both supports and respects the efforts of all contributors, please read our &lt;a href=&#34;https://raw.githubusercontent.com/CVCUDA/CV-CUDA/release_v0.2.x/CODE_OF_CONDUCT.md&#34;&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;CV-CUDA operates under the &lt;a href=&#34;https://raw.githubusercontent.com/CVCUDA/CV-CUDA/release_v0.2.x/LICENSE.md&#34;&gt;Apache-2.0&lt;/a&gt; license.&lt;/p&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;CV-CUDA, as a NVIDIA program, is committed to secure development practices. Please read our &lt;a href=&#34;https://raw.githubusercontent.com/CVCUDA/CV-CUDA/release_v0.2.x/SECURITY.md&#34;&gt;Security&lt;/a&gt; page to learn more.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;CV-CUDA is developed jointly by NVIDIA and ByteDance.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>wolfpld/tracy</title>
    <updated>2022-12-24T01:29:48Z</updated>
    <id>tag:github.com,2022-12-24:/wolfpld/tracy</id>
    <link href="https://github.com/wolfpld/tracy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;C++ frame profiler&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tracy Profiler&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/sponsors/wolfpld/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/wolfpld/tracy/master/.github/sponsor.png&#34; alt=&#34;Sponsor&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;A real time, nanosecond resolution, remote telemetry, hybrid frame and sampling profiler for games and other applications.&lt;/h3&gt; &#xA;&lt;p&gt;Tracy supports profiling CPU (Direct support is provided for C, C++, and Lua integration. At the same time, third-party bindings to many other languages exist on the internet, such as Rust, Zig, C#, OCaml, Odin, etc.), GPU (All major graphic APIs: OpenGL, Vulkan, Direct3D 11/12, OpenCL.), memory allocations, locks, context switches, automatically attribute screenshots to captured frames, and much more.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wolfpld/tracy/releases/latest/download/tracy.pdf&#34;&gt;Documentation&lt;/a&gt; for usage and build process instructions&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wolfpld/tracy/releases&#34;&gt;Releases&lt;/a&gt; containing the documentation (&lt;code&gt;tracy.pdf&lt;/code&gt;) and compiled Windows x64 binaries (&lt;code&gt;Tracy-&amp;lt;version&amp;gt;.7z&lt;/code&gt;) as assets&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wolfpld/tracy/master/NEWS&#34;&gt;Changelog&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tracy.nereid.pl/&#34;&gt;Interactive demo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/wolfpld/tracy/master/doc/profiler.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/wolfpld/tracy/master/doc/profiler2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/wolfpld/tracy/master/doc/profiler3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=fB5B46lbapc&#34;&gt;Introduction to Tracy Profiler v0.2&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=3SXpDpDh2Uo&#34;&gt;New features in Tracy Profiler v0.3&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=eAkgkaO8B9o&#34;&gt;New features in Tracy Profiler v0.4&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=P6E7qLMmzTQ&#34;&gt;New features in Tracy Profiler v0.5&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=uJkrFgriuOo&#34;&gt;New features in Tracy Profiler v0.6&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=_hU7vw00MZ4&#34;&gt;New features in Tracy Profiler v0.7&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=30wpRpHTTag&#34;&gt;New features in Tracy Profiler v0.8&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lightvector/KataGo</title>
    <updated>2022-12-24T01:29:48Z</updated>
    <id>tag:github.com,2022-12-24:/lightvector/KataGo</id>
    <link href="https://github.com/lightvector/KataGo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GTP engine and self-play learning in Go&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;KataGo&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#training-history-and-research&#34;&gt;Training History and Research&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#where-to-download-stuff&#34;&gt;Where To Download Stuff&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#setting-up-and-running-katago&#34;&gt;Setting Up and Running KataGo&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#guis&#34;&gt;GUIs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#windows-and-linux&#34;&gt;Windows and Linux&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#macos&#34;&gt;MacOS&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#opencl-vs-cuda-vs-tensorrt-vs-eigen&#34;&gt;OpenCL vs CUDA vs TensorRT vs Eigen&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#how-to-use&#34;&gt;How To Use&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#tuning-for-performance&#34;&gt;Tuning for Performance&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#common-questions-and-issues&#34;&gt;Common Questions and Issues&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#issues-with-specific-gpus-or-gpu-drivers&#34;&gt;Issues with specific GPUs or GPU drivers&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#common-problems&#34;&gt;Common Problems&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#other-questions&#34;&gt;Other Questions&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#features-for-developers&#34;&gt;Features for Developers&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#gtp-extensions&#34;&gt;GTP Extensions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#analysis-engine&#34;&gt;Analysis Engine&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#compiling-katago&#34;&gt;Compiling KataGo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#source-code-overview&#34;&gt;Source Code Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#selfplay-training&#34;&gt;Selfplay Training&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#contributors&#34;&gt;Contributors&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;KataGo has begun its first public distributed training run! See &lt;a href=&#34;https://katagotraining.org/&#34;&gt;https://katagotraining.org/&lt;/a&gt; for more details, to download the latest and strongest neural nets, or to learn how to contribute if you want to help KataGo improve further! Also check out the computer Go &lt;a href=&#34;https://discord.gg/bqkZAz3&#34;&gt;discord channel&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt;As of January 2021, KataGo is one of the strongest open source Go bots available online. KataGo was trained using an AlphaZero-like process with many enhancements and improvements, and is capable of reaching top levels rapidly and entirely from scratch with no outside data, improving only via self-play. Some of these improvements take advantage of game-specific features and training targets, but also many of the techniques are general and could be applied in other games. As a result, early training is immensely faster than in other self-play-trained bots - with only a few strong GPUs for a few days, any researcher/enthusiast should be able to train a neural net from nothing to high amateur dan strength on the full 19x19 board. If tuned well, a training run using only a &lt;em&gt;single&lt;/em&gt; top-end consumer GPU could possibly train a bot from scratch to superhuman strength within a few months.&lt;/p&gt; &#xA;&lt;p&gt;Experimentally, KataGo did also try some limited ways of using external data at the end of its June 2020 run, and has continued to do so into its most recent public distributed run, &#34;kata1&#34; at &lt;a href=&#34;https://katagotraining.org/&#34;&gt;https://katagotraining.org/&lt;/a&gt;. External data is not necessary for reaching top levels of play, but still appears to provide some mild benefits against some opponents, and noticeable benefits in a useful analysis tool for a variety of kinds of situations that don&#39;t occur in self-play but that do occur in human games and games that users wish to analyze.&lt;/p&gt; &#xA;&lt;p&gt;Paper about the major new ideas and techniques used in KataGo: &lt;a href=&#34;https://arxiv.org/abs/1902.10565&#34;&gt;Accelerating Self-Play Learning in Go (arXiv)&lt;/a&gt;. A few major further improvements have been found since then, which have been incorporated into KataGo&#39;s more recent runs. These and a few research notes can be found &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/docs/KataGoMethods.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Many thanks to &lt;a href=&#34;https://www.janestreet.com/&#34;&gt;Jane Street&lt;/a&gt; for supporting the training of KataGo&#39;s major earlier published runs, as well as numerous many smaller testing runs and experiments. Blog posts about the initial release and some interesting subsequent experiments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.janestreet.com/accelerating-self-play-learning-in-go/&#34;&gt;Accelerating Self-Play Learning in Go&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.janestreet.com/deep-learning-the-hardest-go-problem-in-the-world/&#34;&gt;Deep-Learning the Hardest Go Problem in the World&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;KataGo&#39;s engine also aims to be a useful tool for Go players and developers, and supports the following features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Estimates territory and score, rather than only &#34;winrate&#34;, helping analyze kyu and amateur dan games besides only on moves that actually would swing the game outcome at pro/superhuman-levels of play.&lt;/li&gt; &#xA; &lt;li&gt;Cares about maximizing score, enabling strong play in handicap games when far behind, and reducing slack play in the endgame when winning.&lt;/li&gt; &#xA; &lt;li&gt;Supports alternative values of komi (including integer values) and good high-handicap game play.&lt;/li&gt; &#xA; &lt;li&gt;Supports board sizes ranging from 7x7 to 19x19, and as of May 2020 may be the strongest open-source bot on both 9x9 and 13x13 as well.&lt;/li&gt; &#xA; &lt;li&gt;Supports a wide variety of &lt;a href=&#34;https://lightvector.github.io/KataGo/rules.html&#34;&gt;rules&lt;/a&gt;, including rules that match Japanese rules in almost all common cases, and ancient stone-counting-like rules.&lt;/li&gt; &#xA; &lt;li&gt;For tool/back-end developers - supports a JSON-based analysis engine that can batch multiple-game evaluations efficiently and be easier to use than GTP.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Training History and Research&lt;/h2&gt; &#xA;&lt;p&gt;For more details about KataGo&#39;s older training runs, including comparisons to other bots, see &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/TrainingHistory.md&#34;&gt;Training History and Research&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt;Also if you&#39;re looking to ask about general information about KataGo or how it works, or about some past Go bots besides KataGo, consider the computer Go &lt;a href=&#34;https://discord.gg/bqkZAz3&#34;&gt;discord channel&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Where To Download Stuff&lt;/h2&gt; &#xA;&lt;p&gt;Precompiled executables for KataGo can be found at the &lt;a href=&#34;https://github.com/lightvector/KataGo/releases&#34;&gt;releases page&lt;/a&gt; for Windows and Linux.&lt;/p&gt; &#xA;&lt;p&gt;And the latest neural nets are available at &lt;a href=&#34;https://katagotraining.org/&#34;&gt;https://katagotraining.org/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Setting Up and Running KataGo&lt;/h2&gt; &#xA;&lt;p&gt;KataGo implements just a GTP engine, which is a simple text protocol that Go software uses. It does NOT have a graphical interface on its own. So generally, you will want to use KataGo along with a GUI or analysis program. A few of them bundle KataGo in their download so that you can get everything from one place rather than downloading separately and managing the file paths and commands.&lt;/p&gt; &#xA;&lt;h3&gt;GUIs&lt;/h3&gt; &#xA;&lt;p&gt;This is by no means a complete list - there are lots of things out there. But, writing as of 2020, a few of the easier and/or popular ones might be:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sanderland/katrain&#34;&gt;KaTrain&lt;/a&gt; - KaTrain might be the easiest to set up for non-technical users, offering an all-in-one package (no need to download KataGo separately!), modified-strength bots for weaker players, and good analysis features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/featurecat/lizzie&#34;&gt;Lizzie&lt;/a&gt; - Lizzie is very popular for running long interactive analyses and visualizing them as they happen. Lizzie also offers an all-in-one package. However keep mind that KataGo&#39;s OpenCL version may take quite a while to tune and load on the very first startup as described &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#opencl-vs-cuda&#34;&gt;here&lt;/a&gt;, and Lizzie does a poor job of displaying this progress as it happens. And in case of an actual error or failure, Lizzie&#39;s interface is not the best at explaining these errors and will appear to hang forever. The version of KataGo packaged with Lizzie is quite strong but might not always be the newest or strongest, so once you have it working, you may want to download KataGo and a newer network from &lt;a href=&#34;https://github.com/lightvector/KataGo/releases&#34;&gt;releases page&lt;/a&gt; and replace Lizzie&#39;s versions with them.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rooklift/ogatak&#34;&gt;Ogatak&lt;/a&gt; is a KataGo-specific GUI with an emphasis on displaying the basics in a snappy, responsive fashion. It does not come with KataGo included.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bernds/q5Go&#34;&gt;q5Go&lt;/a&gt; and &lt;a href=&#34;https://sabaki.yichuanshen.de/&#34;&gt;Sabaki&lt;/a&gt; are general SGF editors and GUIs that support KataGo, including KataGo&#39;s score estimation, and many high-quality features.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Generally, for GUIs that don&#39;t offer an all-in-one package, you will need to download KataGo (or any other Go engine of your choice!) and tell the GUI the proper command line to run to invoke your engine, with the proper file paths involved. See &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#how-to-use&#34;&gt;How To Use&lt;/a&gt; below for details on KataGo&#39;s command line interface.&lt;/p&gt; &#xA;&lt;h3&gt;Windows and Linux&lt;/h3&gt; &#xA;&lt;p&gt;KataGo currently officially supports both Windows and Linux, with &lt;a href=&#34;https://github.com/lightvector/KataGo/releases&#34;&gt;precompiled executables provided each release&lt;/a&gt;. Not all different OS versions and compilers have been tested, so if you encounter problems, feel free to open an issue. KataGo can also of course be compiled from source on Windows via MSVC on Windows or on Linux via usual compilers like g++, documented further down.&lt;/p&gt; &#xA;&lt;h3&gt;MacOS&lt;/h3&gt; &#xA;&lt;p&gt;The community also provides KataGo packages for &lt;a href=&#34;https://brew.sh&#34;&gt;Homebrew&lt;/a&gt; on MacOS - releases there may lag behind official releases slightly.&lt;/p&gt; &#xA;&lt;p&gt;Use &lt;code&gt;brew install katago&lt;/code&gt;. The latest config files and networks are installed in KataGo&#39;s &lt;code&gt;share&lt;/code&gt; directory. Find them via &lt;code&gt;brew list --verbose katago&lt;/code&gt;. A basic way to run katago will be &lt;code&gt;katago gtp -config $(brew list --verbose katago | grep gtp*.cfg) -model $(brew list --verbose katago | grep .gz | head -1)&lt;/code&gt;. You should choose the Network according to the release notes here and customize the provided example config as with every other way of installing KataGo.&lt;/p&gt; &#xA;&lt;h3&gt;OpenCL vs CUDA vs TensorRT vs Eigen&lt;/h3&gt; &#xA;&lt;p&gt;KataGo has four backends, OpenCL (GPU), CUDA (GPU), TensorRT (GPU), and Eigen (CPU).&lt;/p&gt; &#xA;&lt;p&gt;The quick summary is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;To easily get something working, try OpenCL if you have any good or decent GPU.&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;For often much better performance on NVIDIA GPUs, try TensorRT&lt;/strong&gt;, but you may need to install CUDA+CUDNN+TensorRT from Nvidia.&lt;/li&gt; &#xA; &lt;li&gt;Use Eigen with AVX2 if you don&#39;t have a GPU or if your GPU is too old/weak to work with OpenCL, and you just want a plain CPU KataGo.&lt;/li&gt; &#xA; &lt;li&gt;Use Eigen without AVX2 if your CPU is old or on a low-end device that doesn&#39;t support AVX2.&lt;/li&gt; &#xA; &lt;li&gt;The CUDA backend can work for NVIDIA GPUs without using TensorRT but is likely worse than TensorRT.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;More in detail:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;OpenCL is a general GPU backend should be able to run with any GPUs or accelerators that support &lt;a href=&#34;https://en.wikipedia.org/wiki/OpenCL&#34;&gt;OpenCL&lt;/a&gt;, including NVIDIA GPUs, AMD GPUs, as well CPU-based OpenCL implementations or things like Intel Integrated Graphics. This is the most general GPU version of KataGo and doesn&#39;t require a complicated install like CUDA does, so is most likely to work out of the box as long as you have a fairly modern GPU. &lt;strong&gt;However, it also need to take some time when run for the very first time to tune itself.&lt;/strong&gt; For many systems, this will take 5-30 seconds, but on a few older/slower systems, may take many minutes or longer. Also, the quality of OpenCL implementations is sometimes inconsistent, particularly for Intel Integrated Graphics and for AMD GPUs that are older than several years, so it might not work for very old machines, as well as specific buggy newer AMD GPUs, see also &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#issues-with-specific-gpus-or-gpu-drivers&#34;&gt;Issues with specific GPUs or GPU drivers&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;CUDA is a GPU backend specific to NVIDIA GPUs (it will not work with AMD or Intel or any other GPUs) and requires installing &lt;a href=&#34;https://developer.nvidia.com/cuda-zone&#34;&gt;CUDA&lt;/a&gt; and &lt;a href=&#34;https://developer.nvidia.com/cudnn&#34;&gt;CUDNN&lt;/a&gt; and a modern NVIDIA GPU. On most GPUs, the OpenCL implementation will actually beat NVIDIA&#39;s own CUDA/CUDNN at performance. The exception is for top-end NVIDIA GPUs that support FP16 and tensor cores, in which case sometimes one is better and sometimes the other is better.&lt;/li&gt; &#xA; &lt;li&gt;TensorRT is similar to CUDA and depends on CUDA+CUDNN itself, but also uses NVIDIA&#39;s TensorRT framework to run the neural network with more optimized kernels. For modern NVIDIA GPUs, it should work whenever CUDA does and will usually be faster than CUDA or any other backend.&lt;/li&gt; &#xA; &lt;li&gt;Eigen is a &lt;em&gt;CPU&lt;/em&gt; backend that should work widely &lt;em&gt;without&lt;/em&gt; needing a GPU or fancy drivers. Use this if you don&#39;t have a good GPU or really any GPU at all. It will be quite significantly slower than OpenCL or CUDA, but on a good CPU can still often get 10 to 20 playouts per second if using the smaller (15 or 20) block neural nets. Eigen can also be compiled with AVX2 and FMA support, which can provide a big performance boost for Intel and AMD CPUs from the last few years. However, it will not run at all on older CPUs (and possibly even some recent but low-power modern CPUs) that don&#39;t support these fancy vector instructions.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For &lt;strong&gt;any&lt;/strong&gt; implementation, it&#39;s recommended that you also tune the number of threads used if you care about optimal performance, as it can make a factor of 2-3 difference in the speed. See &#34;Tuning for Performance&#34; below. However, if you mostly just want to get it working, then the default untuned settings should also be still reasonable.&lt;/p&gt; &#xA;&lt;h3&gt;How To Use&lt;/h3&gt; &#xA;&lt;p&gt;KataGo is just an engine and does not have its own graphical interface. So generally you will want to use KataGo along with a &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#guis&#34;&gt;GUI or analysis program&lt;/a&gt;. If you encounter any problems while setting this up, check out &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#common-questions-and-issues&#34;&gt;Common Questions and Issues&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;First&lt;/strong&gt;: Run a command like this to make sure KataGo is working, with the neural net file you &lt;a href=&#34;https://github.com/lightvector/KataGo/releases/tag/v1.4.5&#34;&gt;downloaded&lt;/a&gt;. On OpenCL, it will also tune for your GPU.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./katago.exe benchmark                                                   # if you have default_gtp.cfg and default_model.bin.gz&#xA;./katago.exe benchmark -model &amp;lt;NEURALNET&amp;gt;.bin.gz                         # if you have default_gtp.cfg&#xA;./katago.exe benchmark -model &amp;lt;NEURALNET&amp;gt;.bin.gz -config gtp_custom.cfg  # use this .bin.gz neural net and this .cfg file&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will tell you a good number of threads. Edit your .cfg file and set &#34;numSearchThreads&#34; to that many to get best performance.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Or&lt;/strong&gt;: Run this command to have KataGo generate a custom gtp config for you based on answering some questions:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./katago.exe genconfig -model &amp;lt;NEURALNET&amp;gt;.bin.gz -output gtp_custom.cfg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Next&lt;/strong&gt;: A command like this will run KataGo&#39;s engine. This is the command to give to your &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#guis&#34;&gt;GUI or analysis program&lt;/a&gt; so that it can run KataGo.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./katago.exe gtp                                                   # if you have default_gtp.cfg and default_model.bin.gz&#xA;./katago.exe gtp -model &amp;lt;NEURALNET&amp;gt;.bin.gz                         # if you have default_gtp.cfg&#xA;./katago.exe gtp -model &amp;lt;NEURALNET&amp;gt;.bin.gz -config gtp_custom.cfg  # use this .bin.gz neural net and this .cfg file&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may need to specify different paths when entering KataGo&#39;s command for a GUI program, e.g.:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;path/to/katago.exe gtp -model path/to/&amp;lt;NEURALNET&amp;gt;.bin.gz&#xA;path/to/katago.exe gtp -model path/to/&amp;lt;NEURALNET&amp;gt;.bin.gz -config path/to/gtp_custom.cfg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Other Commands:&lt;/h4&gt; &#xA;&lt;p&gt;Run a JSON-based &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/docs/Analysis_Engine.md&#34;&gt;analysis engine&lt;/a&gt; that can do efficient batched evaluations for a backend Go service:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;./katago analysis -model &amp;lt;NEURALNET&amp;gt;.gz -config &amp;lt;ANALYSIS_CONFIG&amp;gt;.cfg&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Run a high-performance match engine that will play a pool of bots against each other sharing the same GPU batches and CPUs with each other:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;./katago match -config &amp;lt;MATCH_CONFIG&amp;gt;.cfg -log-file match.log -sgf-output-dir &amp;lt;DIR TO WRITE THE SGFS&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Force OpenCL tuner to re-tune:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;./katago tuner -config &amp;lt;GTP_CONFIG&amp;gt;.cfg&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Print version:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;./katago version&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Tuning for Performance&lt;/h3&gt; &#xA;&lt;p&gt;The most important parameter to optimize for KataGo&#39;s performance is the number of threads to use - this can easily make a factor of 2 or 3 difference.&lt;/p&gt; &#xA;&lt;p&gt;Secondarily, you can also read over the parameters in your GTP config (&lt;code&gt;default_gtp.cfg&lt;/code&gt; or &lt;code&gt;gtp_example.cfg&lt;/code&gt; or &lt;code&gt;configs/gtp_example.cfg&lt;/code&gt;, etc). A lot of other settings are described in there that you can set to adjust KataGo&#39;s resource usage, or choose which GPUs to use. You can also adjust things like KataGo&#39;s resign threshold, pondering behavior or utility function. Most parameters are documented directly inline in the &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/cpp/configs/gtp_example.cfg&#34;&gt;example config file&lt;/a&gt;. Many can also be interactively set when generating a config via the &lt;code&gt;genconfig&lt;/code&gt; command described above.&lt;/p&gt; &#xA;&lt;h3&gt;Common Questions and Issues&lt;/h3&gt; &#xA;&lt;p&gt;This section summarizes a number of common questions and issues when running KataGo.&lt;/p&gt; &#xA;&lt;h4&gt;Issues with specific GPUs or GPU drivers&lt;/h4&gt; &#xA;&lt;p&gt;If you are observing any crashes in KataGo while attempting to run the benchmark or the program itself, and you have one of the below GPUs, then this is likely the reason.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;AMD Radeon RX 5700&lt;/strong&gt; - AMD&#39;s drivers for OpenCL for this GPU have been buggy ever since this GPU was released, and as of May 2020 AMD has still never released a fix. If you are using this GPU, you will just not be able to run KataGo (Leela Zero and other Go engines will probably fail too) and will probably also obtain incorrect calculations or crash if doing anything else scientific or mathematical that uses OpenCL. See for example these reddit threads: &lt;a href=&#34;https://www.reddit.com/r/Amd/comments/ebso1x/its_not_just_setihome_any_mathematic_or/&#34;&gt;[1]&lt;/a&gt; or &lt;a href=&#34;https://www.reddit.com/r/BOINC/comments/ebiz18/psa_please_remove_your_amd_rx5700xt_from_setihome/&#34;&gt;[2]&lt;/a&gt; or this &lt;a href=&#34;https://lifein19x19.com/viewtopic.php?f=18&amp;amp;t=17093&#34;&gt;L19 thread&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;OpenCL Mesa&lt;/strong&gt; - These drivers for OpenCL are buggy. Particularly if on startup before crashing you see KataGo printing something like &lt;code&gt;Found OpenCL Platform 0: ... (Mesa) (OpenCL 1.1 Mesa ...) ...&lt;/code&gt; then you are using the Mesa drivers. You will need to change your drivers, see for example this &lt;a href=&#34;https://github.com/lightvector/KataGo/issues/182#issuecomment-607943405&#34;&gt;KataGo issue&lt;/a&gt; which links to &lt;a href=&#34;https://bbs.archlinux.org/viewtopic.php?pid=1895516#p1895516&#34;&gt;this thread&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Intel Integrated Graphics&lt;/strong&gt; - For weaker/older machines or laptops or devices that don&#39;t have a dedicated GPU, KataGo might end up using the weak &#34;Intel Integrated Graphics&#34; that is built in with the CPU. Often this will work fine (although KataGo will be slow and only get a tiny number of playouts compared to using a real GPU), but various versions of Intel Integrated Graphics can also be buggy and not work at all. If a driver update doesn&#39;t work for you, then the only solution is to upgrade to a better GPU. See for example this &lt;a href=&#34;https://github.com/lightvector/KataGo/issues/54&#34;&gt;issue&lt;/a&gt; or this &lt;a href=&#34;https://github.com/lightvector/KataGo/issues/78&#34;&gt;issue&lt;/a&gt;, or this &lt;a href=&#34;https://github.com/CNugteren/CLBlast/issues/280&#34;&gt;other Github&#39;s issue&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Common Problems&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;KataGo seems to hang or is &#34;loading&#34; forever on startup in Lizzie/Sabaki/q5go/GoReviewPartner/etc.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Likely either you have some misconfiguration, have specified file paths incorrectly, a bad GPU, etc. Many of these GUIs do a poor job of reporting errors and may completely swallow the error message from KataGo that would have told you what was wrong. Try running KataGo&#39;s &lt;code&gt;benchmark&lt;/code&gt; or &lt;code&gt;gtp&lt;/code&gt; directly on the command line, as described &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#how-to-use&#34;&gt;above&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Sometimes there is no error at all, it is merely that the &lt;em&gt;first&lt;/em&gt; time KataGo runs on a given network size, it needs to do some expensive tuning, which may take a few minutes. Again this is clearer if you run the &lt;code&gt;benchmark&lt;/code&gt; command directly in the command line. After tuning, then subsequent runs will be faster.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;KataGo works on the command line but having trouble specifying the right file paths for the GUI.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;As described &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/#how-to-use&#34;&gt;above&lt;/a&gt;, you can name your config &lt;code&gt;default_gtp.cfg&lt;/code&gt; and name whichever network file you&#39;ve downloaded to &lt;code&gt;default_model.bin.gz&lt;/code&gt; (for newer &lt;code&gt;.bin.gz&lt;/code&gt; models) or &lt;code&gt;default_model.txt.gz&lt;/code&gt; (for older &lt;code&gt;.txt.gz&lt;/code&gt; models). Stick those into the same directory as KataGo&#39;s executable, and then you don&#39;t need to specify &lt;code&gt;-config&lt;/code&gt; or &lt;code&gt;-model&lt;/code&gt; paths at all.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;KataGo gives an error like &lt;code&gt;Could not create file&lt;/code&gt; when trying to run the initial tuning.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;KataGo probably does not have access permissions to write files in the directory where you placed it.&lt;/li&gt; &#xA;   &lt;li&gt;On Windows for example, the &lt;code&gt;Program Files&lt;/code&gt; directory and its subdirectories are often restricted to only allow writes with admin-level permissions. Try placing KataGo somewhere else.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I&#39;m new to the command line and still having trouble knowing what to tell Lizzie/q5go/Sabaki/whatever to make it run KataGo&lt;/strong&gt;.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Again, make sure you have your directory paths right.&lt;/li&gt; &#xA;   &lt;li&gt;A common issue: AVOID having any spaces in any file or directory names anywhere, since depending on the GUI, this may require you to have to quote or character-escape the paths or arguments in various ways.&lt;/li&gt; &#xA;   &lt;li&gt;If you don&#39;t understand command line arguments and flags, relative vs absolute file paths, etc, search online. Try pages like &lt;a href=&#34;https://superuser.com/questions/1270591/how-to-use-relative-paths-on-windows-cmd&#34;&gt;https://superuser.com/questions/1270591/how-to-use-relative-paths-on-windows-cmd&lt;/a&gt; or &lt;a href=&#34;https://www.bleepingcomputer.com/tutorials/understanding-command-line-arguments-and-how-to-use-them/&#34;&gt;https://www.bleepingcomputer.com/tutorials/understanding-command-line-arguments-and-how-to-use-them/&lt;/a&gt; or other pages you find, or get someone tech-savvy to help you in a chat or even in-person if you can.&lt;/li&gt; &#xA;   &lt;li&gt;Consider using &lt;a href=&#34;https://github.com/sanderland/katrain&#34;&gt;https://github.com/sanderland/katrain&lt;/a&gt; instead - this is an excellent GUI written by someone else for KataGo that usually automates all of the technical setup for you.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I&#39;m getting a different error or still want further help.&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Check out &lt;a href=&#34;https://discord.gg/bqkZAz3&#34;&gt;the discord chat where Leela Zero, KataGo, and other bots hang out&lt;/a&gt; and ask in the &#34;#help&#34; channel.&lt;/li&gt; &#xA;   &lt;li&gt;If you think you&#39;ve found a bug in KataGo itself, feel free also to &lt;a href=&#34;https://github.com/lightvector/KataGo/issues&#34;&gt;open an issue&lt;/a&gt;. Please provide as much detail as possible about the exact commands you ran, the full error message and output (if you&#39;re in a GUI, please make sure to check that GUI&#39;s raw GTP console or log), the things you&#39;ve tried, your config file and network, your GPU and operating system, etc.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Other Questions&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;How do I make KataGo use Japanese rules or other rules?&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;KataGo supports some &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/docs/GTP_Extensions.md&#34;&gt;GTP extensions&lt;/a&gt; for developers of GUIs to set the rules, but unfortunately as of June 2020, only a few of them make use of this. So as a workaround, there are a few ways: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Edit KataGo&#39;s config (&lt;code&gt;default_gtp.cfg&lt;/code&gt; or &lt;code&gt;gtp_example.cfg&lt;/code&gt; or &lt;code&gt;gtp.cfg&lt;/code&gt;, or whatever you&#39;ve named it) to use &lt;code&gt;rules=japanese&lt;/code&gt; or &lt;code&gt;rules=chinese&lt;/code&gt; or whatever you need, or set the individual rules &lt;code&gt;koRule&lt;/code&gt;,&lt;code&gt;scoringRule&lt;/code&gt;,&lt;code&gt;taxRule&lt;/code&gt;, etc. to what they should be. See &lt;a href=&#34;https://github.com/lightvector/KataGo/raw/master/cpp/configs/gtp_example.cfg#L91&#34;&gt;here&lt;/a&gt; for where this is in the config, or and see &lt;a href=&#34;https://lightvector.github.io/KataGo/rules.html&#34;&gt;this webpage&lt;/a&gt; for the full description of KataGo&#39;s ruleset.&lt;/li&gt; &#xA;     &lt;li&gt;Use the &lt;code&gt;genconfig&lt;/code&gt; command (&lt;code&gt;./katago genconfig -model &amp;lt;NEURALNET&amp;gt;.gz -output &amp;lt;PATH_TO_SAVE_GTP_CONFIG&amp;gt;.cfg&lt;/code&gt;) to generate a config, and it will interactively help you, including asking you for what default rules you want.&lt;/li&gt; &#xA;     &lt;li&gt;If your GUI allows access directly to the GTP console (for example, press &lt;code&gt;E&lt;/code&gt; in Lizzie), then you can run &lt;code&gt;kata-set-rules japanese&lt;/code&gt; or similar for other rules directly in the GTP console, to change the rules dynamically in the middle of a game or an analysis session.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;How do I make KataGo show me a wider range of possible good moves and options during analysis?&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add &lt;code&gt;analysisWideRootNoise = X&lt;/code&gt; to the config (&lt;code&gt;default_gtp.cfg&lt;/code&gt; or &lt;code&gt;gtp_example.cfg&lt;/code&gt; or &lt;code&gt;gtp.cfg&lt;/code&gt;, or whatever you&#39;ve named it). A value of 0.03 will mildly widen the range of moves that get searched and evaluated. A value of 0.10 will very noticeably widen the search. Much larger values will start pushing KataGo toward evaluating every move on the board, at the cost of evaluating the best moves less thoroughly. You can play with this parameter to see what you prefer. You can &lt;em&gt;also&lt;/em&gt; change it at runtime by typing &lt;code&gt;kata-set-param analysisWideRootNoise X&lt;/code&gt; into the GTP console, if your GUI program exposes the GTP console for you to provide direct commands.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Which model/network should I use?&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;For weaker or mid-range GPUs, try the final 20-block network from &lt;a href=&#34;https://github.com/lightvector/KataGo/releases/tag/v1.4.5&#34;&gt;here&lt;/a&gt;, which is the best of its size.&lt;/li&gt; &#xA;   &lt;li&gt;For top-tier GPUs and/or for the highest-quality analysis if you&#39;re going to use many thousands and thousands of playouts and long thinking times, try the final 40-block network from &lt;a href=&#34;https://github.com/lightvector/KataGo/releases/tag/v1.4.5&#34;&gt;here&lt;/a&gt;, which is more costly to run but should be the strongest and best overall.&lt;/li&gt; &#xA;   &lt;li&gt;If you care a lot about theoretical purity - no outside data, bot learns strictly on its own - use the 20 or 40 block nets from &lt;a href=&#34;https://github.com/lightvector/KataGo/releases/tag/v1.4.0&#34;&gt;this release&lt;/a&gt;, which are pure in this way and still much stronger than Leela Zero, but also not quite as strong as the final nets.&lt;/li&gt; &#xA;   &lt;li&gt;If you want some nets that are much faster to run, and each with their own interesting style of play due to their unique stages of learning, try any of the &#34;b10c128&#34; or &#34;b15c192&#34; Extended Training Nets &lt;a href=&#34;https://katagoarchive.org/g170/neuralnets/index.html&#34;&gt;here&lt;/a&gt; which are 10 block and 15 block networks from earlier in the run that are much weaker but still pro-level-and-beyond.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features for Developers&lt;/h2&gt; &#xA;&lt;h4&gt;GTP Extensions:&lt;/h4&gt; &#xA;&lt;p&gt;In addition to a basic set of &lt;a href=&#34;https://www.lysator.liu.se/~gunnar/gtp/&#34;&gt;GTP commands&lt;/a&gt;, KataGo supports a few additional commands, for use with analysis tools and other programs.&lt;/p&gt; &#xA;&lt;p&gt;KataGo&#39;s GTP extensions are documented &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/docs/GTP_Extensions.md&#34;&gt;here&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Notably: KataGo exposes a GTP command &lt;code&gt;kata-analyze&lt;/code&gt; that in addition to policy and winrate, also reports an estimate of the &lt;em&gt;expected score&lt;/em&gt; and a heatmap of the predicted territory ownership of every location of the board. Expected score should be particularly useful for reviewing handicap games or games of weaker players. Whereas the winrate for black will often remain pinned at nearly 100% in a handicap game even as black makes major mistakes (until finally the game becomes very close), expected score should make it more clear which earlier moves are losing points that allow white to catch up, and exactly how much or little those mistakes lose. If you&#39;re interested in adding support for this to any analysis tool, feel free to reach out, I&#39;d be happy to answer questions and help.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;KataGo also exposes a few GTP extensions that allow setting what rules are in effect (Chinese, AGA, Japanese, etc). See again &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/docs/GTP_Extensions.md&#34;&gt;here&lt;/a&gt; for details.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Analysis Engine:&lt;/h4&gt; &#xA;&lt;p&gt;KataGo also implements a separate engine that can evaluate much faster due to batching if you want to analyze whole games at once and might be much less of a hassle than GTP if you are working in an environment where JSON parsing is easy. See &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/docs/Analysis_Engine.md&#34;&gt;here&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Compiling KataGo&lt;/h2&gt; &#xA;&lt;p&gt;KataGo is written in C++. It should compile on Linux or OSX via g++ that supports at least C++14, or on Windows via MSVC 15 (2017) and later. Instructions may be found at &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/Compiling.md&#34;&gt;Compiling KataGo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Source Code Overview:&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/cpp/README.md&#34;&gt;cpp readme&lt;/a&gt; or the &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/python/README.md&#34;&gt;python readme&lt;/a&gt; for some high-level overviews of the source code in this repo, if you want to get a sense of what is where and how it fits together.&lt;/p&gt; &#xA;&lt;h2&gt;Selfplay Training:&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;d also like to run the full self-play loop and train your own neural nets using the code here, see &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/SelfplayTraining.md&#34;&gt;Selfplay Training&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Many thanks to the various people who have contributed to this project! See &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/CONTRIBUTORS&#34;&gt;CONTRIBUTORS&lt;/a&gt; for a list of contributors.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Except for several external libraries that have been included together in this repo under &lt;code&gt;cpp/external/&lt;/code&gt; as well as the single file &lt;code&gt;cpp/core/sha2.cpp&lt;/code&gt;, which all have their own individual licenses, all code and other content in this repo is released for free use or modification under the license in the following file: &lt;a href=&#34;https://raw.githubusercontent.com/lightvector/KataGo/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;License aside, if you end up using any of the code in this repo to do any of your own cool new self-play or neural net training experiments, I (lightvector) would to love hear about it.&lt;/p&gt;</summary>
  </entry>
</feed>