<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-11-24T01:29:27Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>rl-tools/rl-tools</title>
    <updated>2024-11-24T01:29:27Z</updated>
    <id>tag:github.com,2024-11-24:/rl-tools/rl-tools</id>
    <link href="https://github.com/rl-tools/rl-tools" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Fastest Deep Reinforcement Learning Library&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;center&gt;&#xA;  &lt;h1&gt;&lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt;: The Fastest Deep Reinforcement Learning Library&lt;/h1&gt;&#xA; &lt;/center&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/overview.jpg&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://arxiv.org/abs/2306.03530&#34;&gt;Paper on arXiv&lt;/a&gt; | &lt;a href=&#34;https://rl.tools&#34;&gt;Live demo (browser)&lt;/a&gt; | &lt;a href=&#34;https://docs.rl.tools&#34;&gt;Documentation&lt;/a&gt; | &lt;a href=&#34;https://zoo.rl.tools&#34;&gt;Zoo&lt;/a&gt; | &lt;a href=&#34;https://studio.rl.tools&#34;&gt;Studio&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/rl-tools/rl-tools/actions/workflows/tests-backend.yml&#34;&gt; &lt;img src=&#34;https://github.com/rl-tools/rl-tools/actions/workflows/tests-backend.yml/badge.svg?sanitize=true&#34; alt=&#34;Documentation&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/rl-tools/rl-tools&#34;&gt; &lt;img src=&#34;https://codecov.io/gh/rl-tools/rl-tools/graph/badge.svg?token=3TJZ635O8V&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://docs.rl.tools&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Documentation-Read%20the%20Docs-blue.svg?sanitize=true&#34; alt=&#34;Documentation&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://mybinder.org/v2/gh/rl-tools/documentation/binder?labpath=01-Containers.ipynb&#34;&gt; &lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Run tutorials on Binder&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/rl-tools/documentation/blob/master/docs/09-Python%20Interface.ipynb&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Run Example on Colab&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://discord.gg/kbvxCavb5h&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1194228521216778250?label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;color=7289da&#34; alt=&#34;Join our Discord!&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/acrobot-swing-up-sac.gif&#34; alt=&#34;animated&#34; height=&#34;200&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/racing_car.gif&#34; alt=&#34;animated&#34; height=&#34;200&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  Trained on a 2020 MacBook Pro (M1) using &#xA; &lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt; SAC and TD3 (respectively) &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/rl-tools/rl-tools/raw/master/src/rl/environments/mujoco/ant/ppo/cpu/training.h&#34;&gt; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/rl_tools_mujoco_ant_ppo.gif&#34; alt=&#34;animated&#34; height=&#34;200&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/rl-tools/rl-tools/raw/e033cc1d739f66d18ef685233d8dd84dddb3fe69/src/rl/zoo/ppo/bottleneck-v0.h&#34;&gt; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/bottleneck.gif&#34; alt=&#34;animated&#34; height=&#34;200&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  Trained on a 2020 MacBook Pro (M1) using &#xA; &lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt; PPO/Multi-Agent PPO &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/arplaboratory/learning-to-fly&#34;&gt; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/learning-to-fly-in-seconds.gif&#34; alt=&#34;animated&#34; width=&#34;350&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  Trained in 18s on a 2020 MacBook Pro (M1) using &#xA; &lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt; TD3 &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/benchmark_horizontal_ppo.png&#34; width=&#34;300&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/benchmark_horizontal_sac.png&#34; width=&#34;300&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  Benchmarks of training the Pendulum swing-up using different RL libraries (PPO and SAC respectively) &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/benchmark_vertical.png&#34; width=&#34;350&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  Benchmarks of training the Pendulum swing-up on different devices (SAC, RLtools) &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/rl-tools/media/raw/master/microcontroller_inference.png&#34; width=&#34;600&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  Benchmarks of the inference frequency for a two-layer [64, 64] fully-connected neural network across different microcontrollers (types and architectures). &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Clone this repo, then build a Zoo example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;g++ -std=c++17 -Ofast -I include src/rl/zoo/l2f/sac.cpp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run it &lt;code&gt;./a.out 1337&lt;/code&gt; (number = seed) then run &lt;code&gt;python3 -m http.server&lt;/code&gt; to visualize the results. Open &lt;code&gt;http://localhost:8000&lt;/code&gt; and navigate to the ExTrack UI to watch the quadrotor flying.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: Append &lt;code&gt;-framework Accelerate -DRL_TOOLS_BACKEND_ENABLE_ACCELERATE&lt;/code&gt; for fast training (~4s on M3)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Ubuntu&lt;/strong&gt;: Use &lt;code&gt;apt install libopenblas-dev&lt;/code&gt; and append &lt;code&gt;-lopenblas -DRL_TOOLS_BACKEND_ENABLE_OPENBLAS&lt;/code&gt; (~6s on Zen 5).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Algorithms&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Algorithm&lt;/th&gt; &#xA;   &lt;th&gt;Example&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;TD3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/pendulum/td3/cpu/standalone.cpp&#34;&gt;Pendulum&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/car/car.cpp&#34;&gt;Racing Car&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/mujoco/ant/td3/training.h&#34;&gt;MuJoCo Ant-v4&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/acrobot/td3/acrobot.cpp&#34;&gt;Acrobot&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;PPO&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/pendulum/ppo/cpu/training.cpp&#34;&gt;Pendulum&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/car/training_ppo.h&#34;&gt;Racing Car&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/mujoco/ant/ppo/cpu/training.h&#34;&gt;MuJoCo Ant-v4 (CPU)&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/mujoco/ant/ppo/cuda/training_ppo.cu&#34;&gt;MuJoCo Ant-v4 (CUDA)&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Multi-Agent PPO&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/zoo/ppo/bottleneck-v0.h&#34;&gt;Bottleneck&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;SAC&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/pendulum/sac/cpu/training.cpp&#34;&gt;Pendulum (CPU)&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/pendulum/sac/cuda/sac.cu&#34;&gt;Pendulum (CUDA)&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/src/rl/environments/acrobot/sac/acrobot.cpp&#34;&gt;Acrobot&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Projects Based on &lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Learning to Fly in Seconds: &lt;a href=&#34;https://github.com/arplaboratory/learning-to-fly&#34;&gt;GitHub&lt;/a&gt; / &lt;a href=&#34;https://arxiv.org/abs/2311.13081&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://youtu.be/NRD43ZA1D-4&#34;&gt;YouTube&lt;/a&gt; / &lt;a href=&#34;https://spectrum.ieee.org/amp/drone-quadrotor-2667196800&#34;&gt;IEEE Spectrum&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Data-Driven System Identification of Quadrotors Subject to Motor Delays &lt;a href=&#34;https://github.com/arplaboratory/data-driven-system-identification&#34;&gt;GitHub&lt;/a&gt; / &lt;a href=&#34;https://arxiv.org/abs/2404.07837&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://youtu.be/G3WGthRx2KE&#34;&gt;YouTube&lt;/a&gt; / &lt;a href=&#34;https://sysid.tools&#34;&gt;Project Page&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;p&gt;Simple example on how to implement your own environment and train a policy using PPO:&lt;/p&gt; &#xA;&lt;p&gt;Clone and checkout:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/rl-tools/example&#xA;cd example&#xA;git submodule update --init external/rl_tools&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;build and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir build&#xA;cd build&#xA;cmake .. -DCMAKE_BUILD_TYPE=Release&#xA;cmake --build .&#xA;./my_pendulum&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note this example does not have dependencies and should work on any system with CMake and a C++ 17 compiler.&lt;/p&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p&gt;The documentation is available at &lt;a href=&#34;https://docs.rl.tools&#34;&gt;docs.rl.tools&lt;/a&gt; and consists of C++ notebooks. You can also run them locally to tinker around:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -p 8888:8888 rltools/documentation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After running the Docker container, open the link that is displayed in the CLI (&lt;a href=&#34;http://127.0.0.1:8888/&#34;&gt;http://127.0.0.1:8888/&lt;/a&gt;...) in your browser and enjoy tinkering!&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Chapter&lt;/th&gt; &#xA;   &lt;th&gt;Documentation&lt;/th&gt; &#xA;   &lt;th&gt;Interactive Notebook&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/overview.html&#34;&gt;Overview &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/01-Containers.html&#34;&gt;Containers &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/rl-tools/documentation/binder?labpath=01-Containers.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/02-Multiple%20Dispatch.html&#34;&gt;Multiple Dispatch &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/rl-tools/documentation/binder?labpath=02-Multiple%20Dispatch.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/03-Deep%20Learning.html&#34;&gt;Deep Learning &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/rl-tools/documentation/binder?labpath=03-Deep%20Learning.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/04-CPU%20Acceleration.html&#34;&gt;CPU Acceleration &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/rl-tools/documentation/binder?labpath=04-CPU%20Acceleration.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/05-MNIST%20Classification.html&#34;&gt;MNIST Classification &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/rl-tools/documentation/binder?labpath=05-MNIST%20Classification.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/06-Deep%20Reinforcement%20Lear&#34;&gt;Deep Reinforcement Learning &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/rl-tools/documentation/binder?labpath=06-Deep%20Reinforcement%20Learning.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/07-The%20Loop%20Interface.html&#34;&gt;The Loop Interface &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/rl-tools/documentation/binder?labpath=07-The%20Loop%20Interface.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/08-Custom%20Environment.html&#34;&gt;Custom Environment &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/rl-tools/documentation/binder?labpath=08-Custom%20Environment.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.rl.tools/09-Python%20Interface.html&#34;&gt;Python Interface &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/rl-tools/documentation/blob/master/docs/09-Python%20Interface.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Run Example on Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Repository Structure&lt;/h1&gt; &#xA;&lt;p&gt;To build the examples from source (either in Docker or natively), first the repository should be cloned. Instead of cloning all submodules using &lt;code&gt;git clone --recursive&lt;/code&gt; which takes a lot of space and bandwidth we recommend cloning the main repo containing all the standalone code for &lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt; and then cloning the required sets of submodules later:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/rl-tools/rl-tools.git rl_tools&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Cloning submodules&lt;/h4&gt; &#xA;&lt;p&gt;There are three classes of submodules:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;External dependencies (in &lt;code&gt;external/&lt;/code&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;E.g. HDF5 for checkpointing, Tensorboard for logging, or MuJoCo for the simulation of contact dynamics&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Examples/Code for embedded platforms (in &lt;code&gt;embedded_platforms/&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Redistributable dependencies (in &lt;code&gt;redistributable/&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Test dependencies (in &lt;code&gt;tests/lib&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Test data (in &lt;code&gt;tests/data&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;These sets of submodules can be cloned incrementally/independent of each other. For most use-cases (like e.g. most of the Docker examples) you should clone the submodules for external dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd rl_tools&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;git submodule update --init --recursive -- external&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The submodules for the embedded platforms, the redistributable binaries and test dependencies/data can be cloned in the same fashion (by replacing &lt;code&gt;external&lt;/code&gt; with the appropriate folder from the enumeration above). Note: Make sure that for the redistributable dependencies and test data &lt;code&gt;git-lfs&lt;/code&gt; is installed (e.g. &lt;code&gt;sudo apt install git-lfs&lt;/code&gt; on Ubuntu) and activated (&lt;code&gt;git lfs install&lt;/code&gt;) otherwise only the metadata of the blobs is downloaded.&lt;/p&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;If you would like to take advantage of the features that require additional dependencies, but don&#39;t want to install them on your machine yet, you can use Docker. In our experiments on Linux using the NVIDIA container runtime we were able to achieve close to native performance. &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/examples/docker/README.MD&#34;&gt;Docker instructions &amp;amp; examples&lt;/a&gt; While it depends on personal preferences, we believe that there are good reasons (ease of debugging, usage of IDEs etc.) to run everything natively when developing. We make sure that the additional dependencies requried for the full feature set are not invasive and usually available through your systems package manager. We believe &lt;code&gt;sudo ./setup.sh&lt;/code&gt; is harmful and should not exist. Instead we make the setup explicit so that users maintain agency over their systems.&lt;/p&gt; &#xA;&lt;h3&gt;Native&lt;/h3&gt; &#xA;&lt;p&gt;For maximum performance and malleability for research and development we recommend to run &lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt; natively. Since &lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt; itself is dependency free the most basic examples don&#39;t need any platform setup. However, for an improved experience, we support HDF5 checkpointing and Tensorboard logging as well as optimized BLAS libraries which comes with some system-dependent requirements.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/examples/unix/README.MD&#34;&gt;Unix (Linux and macOS) instructions &amp;amp; examples&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/examples/windows/README.MD&#34;&gt;Windows instructions &amp;amp; examples&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pro tip&lt;/strong&gt;: Enable &lt;code&gt;lldb&lt;/code&gt; data formatters to get nicely formatted, human- (and machine-) readable outputs for &lt;code&gt;rl_tools::Matrix&lt;/code&gt; and &lt;code&gt;rl_tools::Tensor&lt;/code&gt; while debugging. Instructions to use &lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/.lldbinit&#34;&gt;.lldbinit&lt;/a&gt; for &lt;a href=&#34;https://www.jetbrains.com/help/clion/configuring-debugger-options.html#enable-initfiles-root&#34;&gt;CLion&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://code.visualstudio.com/docs/cpp/cpp-debug#_lldb-data-formatters&#34;&gt;VS Code&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Python Interface&lt;/h3&gt; &#xA;&lt;p&gt;We provide Python bindings that available as &lt;code&gt;rltools&lt;/code&gt; through PyPI (the pip package index). Note that using Python Gym environments can slow down the trianing significantly compared to native &lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt; environments.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install rltools gymnasium&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from rltools import SAC&#xA;import gymnasium as gym&#xA;from gymnasium.wrappers import RescaleAction&#xA;&#xA;seed = 0xf00d&#xA;def env_factory():&#xA;    env = gym.make(&#34;Pendulum-v1&#34;)&#xA;    env = RescaleAction(env, -1, 1)&#xA;    env.reset(seed=seed)&#xA;    return env&#xA;&#xA;sac = SAC(env_factory)&#xA;state = sac.State(seed)&#xA;&#xA;finished = False&#xA;while not finished:&#xA;    finished = state.step()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find more details in the &lt;a href=&#34;https://docs.rl.tools/09-Python%20Interface.html&#34;&gt;Python Interface documentation&lt;/a&gt; and from the repository &lt;a href=&#34;https://github.com/rl-tools/python-interface&#34;&gt;rl-tools/python-interface&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Embedded Platforms&lt;/h2&gt; &#xA;&lt;h3&gt;Inference &amp;amp; Training&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rl-tools/ios&#34;&gt;iOS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/embedded_platforms&#34;&gt;teensy&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Inference&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/embedded_platforms/crazyflie&#34;&gt;Crazyflie&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/embedded_platforms&#34;&gt;ESP32&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rl-tools/rl-tools/master/embedded_platforms&#34;&gt;PX4&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Naming Convention&lt;/h2&gt; &#xA;&lt;p&gt;We use &lt;code&gt;snake_case&lt;/code&gt; for variables/instances, functions as well as namespaces and &lt;code&gt;PascalCase&lt;/code&gt; for structs/classes. Furthermore, we use upper case &lt;code&gt;SNAKE_CASE&lt;/code&gt; for compile-time constants.&lt;/p&gt; &#xA;&lt;h2&gt;Citing&lt;/h2&gt; &#xA;&lt;p&gt;When using &lt;span style=&#34;color:#7DB9B6&#34;&gt;RLtools&lt;/span&gt; in an academic work please cite our publication using the following Bibtex citation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{eschmann_rltools_2024,&#xA;  author  = {Jonas Eschmann and Dario Albani and Giuseppe Loianno},&#xA;  title   = {RLtools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control},&#xA;  journal = {Journal of Machine Learning Research},&#xA;  year    = {2024},&#xA;  volume  = {25},&#xA;  number  = {301},&#xA;  pages   = {1--19},&#xA;  url     = {http://jmlr.org/papers/v25/24-0248.html}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>