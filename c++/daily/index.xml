<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-16T01:31:25Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>apache/doris</title>
    <updated>2022-07-16T01:31:25Z</updated>
    <id>tag:github.com,2022-07-16:/apache/doris</id>
    <link href="https://github.com/apache/doris" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache Doris is an MPP-based interactive SQL data warehousing for reporting and analysis.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache Doris&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-4EB1BA.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/doris&#34;&gt;&lt;img src=&#34;https://tokei.rs/b1/github/apache/doris?category=lines&#34; alt=&#34;Total Lines&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/doris/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/apache/doris.svg?sanitize=true&#34; alt=&#34;GitHub release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/apachedoriscommunity/shared_invite/zt-11jb8gesh-7IukzSrdea6mqoG0HB4gZg&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/chat-slack-brightgreen&#34; alt=&#34;Join the Doris Community at Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/apache-doris/Lobby?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/apache-doris/Lobby.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/apache-doris/Lobby&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Doris is an MPP-based interactive SQL data warehousing for reporting and analysis. Its original name was Palo, developed in Baidu. After donated to Apache Software Foundation, it was renamed Doris.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Doris provides high concurrent low latency point query performance, as well as high throughput queries of ad-hoc analysis.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Doris provides batch data loading and real-time mini-batch data loading.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Doris provides high availability, reliability, fault tolerance, and scalability.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The main advantages of Doris are the simplicity (of developing, deploying and using) and meeting many data serving requirements in a single system. For details, refer to &lt;a href=&#34;https://github.com/apache/doris/wiki/Doris-Overview&#34;&gt;Overview&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Official website: &lt;a href=&#34;https://doris.apache.org/&#34;&gt;https://doris.apache.org/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.apiseven.com/en/contributor-graph?chart=contributorMonthlyActivity&amp;amp;repo=apache/doris&#34;&gt;&lt;img src=&#34;https://contributor-overtime-api.apiseven.com/contributors-svg?chart=contributorMonthlyActivity&amp;amp;repo=apache/doris&#34; alt=&#34;Monthly Active Contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.apiseven.com/en/contributor-graph?chart=contributorOverTime&amp;amp;repo=apache/doris&#34;&gt;&lt;img src=&#34;https://contributor-overtime-api.apiseven.com/contributors-svg?chart=contributorOverTime&amp;amp;repo=apache/doris&#34; alt=&#34;Contributor over time&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License, Version 2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; Some licenses of the third-party dependencies are not compatible with Apache 2.0 License. So you need to disable some Doris features to be complied with Apache 2.0 License. For details, refer to the &lt;code&gt;thirdparty/LICENSE.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Technology&lt;/h2&gt; &#xA;&lt;p&gt;Doris mainly integrates the technology of &lt;a href=&#34;https://research.google/pubs/pub42851/&#34;&gt;Google Mesa&lt;/a&gt; and &lt;a href=&#34;https://impala.apache.org/&#34;&gt;Apache Impala&lt;/a&gt;, and it is based on a column-oriented storage engine and can communicate by MySQL client.&lt;/p&gt; &#xA;&lt;h2&gt;Compile and install&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://doris.apache.org/docs/install/source-install/compilation-with-ldb-toolchain.html&#34;&gt;Compilation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting start&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://doris.apache.org/docs/data-table/basic-usage.html&#34;&gt;Basic Usage&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Doris Connector&lt;/h2&gt; &#xA;&lt;p&gt;Doris provides support for Spark/Flink to read data stored in Doris through Connector, and also supports to write data to Doris through Connector.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/doris-flink-connector&#34;&gt;apache/doris-flink-connector&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/doris-spark-connector&#34;&gt;apache/doris-spark-connector&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Doris Manager&lt;/h2&gt; &#xA;&lt;p&gt;Doris provides one-click visual automatic installation and deployment, cluster management and monitoring tools for clusters.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/doris-manager&#34;&gt;apache/doris-manager&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Report issues or submit pull request&lt;/h2&gt; &#xA;&lt;p&gt;If you find any bugs, feel free to file a &lt;a href=&#34;https://github.com/apache/doris/issues&#34;&gt;GitHub issue&lt;/a&gt; or fix it by submitting a &lt;a href=&#34;https://github.com/apache/doris/pulls&#34;&gt;pull request&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact Us&lt;/h2&gt; &#xA;&lt;p&gt;Contact us through the following mailing list.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Name&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Scope&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;mailto:dev@doris.apache.org&#34;&gt;dev@doris.apache.org&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Development-related discussions&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;mailto:dev-subscribe@doris.apache.org&#34;&gt;Subscribe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;mailto:dev-unsubscribe@doris.apache.org&#34;&gt;Unsubscribe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;http://mail-archives.apache.org/mod_mbox/doris-dev/&#34;&gt;Archives&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Doris official site - &lt;a href=&#34;https://doris.apache.org&#34;&gt;https://doris.apache.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Developer Mailing list - &lt;a href=&#34;mailto:dev@doris.apache.org&#34;&gt;dev@doris.apache.org&lt;/a&gt;. Mail to &lt;a href=&#34;mailto:dev-subscribe@doris.apache.org&#34;&gt;dev-subscribe@doris.apache.org&lt;/a&gt;, follow the reply to subscribe the mail list.&lt;/li&gt; &#xA; &lt;li&gt;Slack channel - &lt;a href=&#34;https://join.slack.com/t/apachedoriscommunity/shared_invite/zt-18u6vjopj-Th15vTVfmCzVfhhL5rz26A&#34;&gt;Join the Slack&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>LiteLDev/LiteLoaderBDS</title>
    <updated>2022-07-16T01:31:25Z</updated>
    <id>tag:github.com,2022-07-16:/LiteLDev/LiteLoaderBDS</id>
    <link href="https://github.com/LiteLDev/LiteLoaderBDS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A lightweight &amp; cross-language plugin loader for Minecraft Bedrock Dedicated Server (BDS)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LiteLoaderBDS - Epoch-making &amp;amp; Cross-language Bedrock Dedicated Servers Plugin Loader&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/LiteLDev/LiteLoader/actions&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/LiteLDev/LiteLoader/Build%20LiteLoader?style=for-the-badge&#34; alt=&#34;status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/27KTrxHc9t&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/849252980430864384?color=blue&amp;amp;label=Discord&amp;amp;style=for-the-badge&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://t.me/liteloader&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/telegram-LiteLoader-%232CA5E0?style=for-the-badge&amp;amp;logo=Telegram&#34; alt=&#34;Telegram&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/LiteLDev/LiteLoader/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/tag/LiteLDev/LiteLoader?label=LATEST%20TAG&amp;amp;style=for-the-badge&#34; alt=&#34;Latest Tag&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/downloads/LiteLDev/LiteLoader/latest/total?style=for-the-badge&#34; alt=&#34;GitHub Releases (by Asset)&#34;&gt; &lt;/a&gt;&lt;br&gt; QQ Group: &lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=lagwtrfh&#34;&gt;656669024&lt;/a&gt; QQ Group 2: &lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=zeUbrETH&#34;&gt;850517473&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/LiteLDev/LiteLoaderBDS/main/README_zh-cn.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/h5&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://socialify.git.ci/liteldev/liteloaderbds/image?description=1&amp;amp;descriptionEditable=Lightweight%20%26%20Cross-language%0A%20BDS%20Plugin%20Loader&amp;amp;font=KoHo&amp;amp;forks=1&amp;amp;issues=1&amp;amp;logo=https%3A%2F%2Fraw.githubusercontent.com%2FLiteLDev%2FLiteLoaderBDS%2Fmain%2Fdocs%2F.vuepress%2Fpublic%2Fassets%2FLL-Logo.png&amp;amp;name=1&amp;amp;owner=1&amp;amp;pattern=Circuit%20Board&amp;amp;pulls=1&amp;amp;stargazers=1&amp;amp;theme=Light&#34; alt=&#34;LiteLoaderBDS&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;LiteLoaderBDS&lt;/code&gt; is an unofficial plugin loader that provides basic API support for &lt;code&gt;Bedrock Dedicated Server&lt;/code&gt;, with a massive API, lots of packed utility interfaces, a rich event system and powerful basic interface support.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;LiteLoader&lt;/code&gt; provides a massive API, a powerful event system and a large number of encapsulated development infrastructure interfaces, providing a solid foundation for extending the Bedrock Edition &lt;strong&gt;BDS&lt;/strong&gt; with more gameplay and functionality. With plugins, it is easy to extend the functionality of BDS, the associated development is easy to learn, and the development approach is flexible.&lt;/p&gt; &#xA;&lt;p&gt;Writing plugins in &lt;strong&gt;C++ÔºåGolangÔºåJavaScriptÔºåLuaÔºåPython&lt;/strong&gt; and other languages, which allows developers to easily extend and customize &lt;strong&gt;BDS&lt;/strong&gt; functionality, making it easy to learn and extremely flexible.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üéÅ First impression&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;‚ÄúWhy should I choose LiteLoader?‚Äù&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;They have interface that is easy to use and intuitive!!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;C++ language sample plugin&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;// Template project: https://github.com/LiteLDev/PluginTemplate&#xA;// More examples: https://github.com/LiteLDev/LiteLoaderPlugins&#xA;#include &amp;lt;EventAPI.h&amp;gt;&#xA;#include &amp;lt;LoggerAPI.h&amp;gt;&#xA;#include &amp;lt;LLAPI.h&amp;gt;&#xA;#include &amp;lt;MC/Player.hpp&amp;gt;&#xA;#include &amp;lt;MC/Actor.hpp&amp;gt;&#xA;Logger logger(&#34;AttackLog&#34;);&#xA;&#xA;void PluginInit()&#xA;{&#xA;    logger.info(&#34;Plugin xxx has been loaded.&#34;);&#xA;    // Subscribe Player-Attack Event&#xA;    Event::PlayerAttackEvent::subscribe([](const Event::PlayerAttackEvent&amp;amp; ev) {&#xA;        Player* player = ev.mPlayer;&#xA;        Actor* actor = ev.mTarget;&#xA;        logger.info(&#34;Player:{} attacks {} | at {} in Dimension {}&#34;, &#xA;         player-&amp;gt;getRealName(), actor-&amp;gt;getTypeName(), actor-&amp;gt;getPos().toString(),&#xA;            std::to_string(actor-&amp;gt;getDimensionId()));&#xA;        return true;&#xA;    });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Script language sample plugin (Use Js as an example)&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// Register for shutdown command&#xA;mc.listen(&#34;onServerStarted&#34;, () =&amp;gt; {&#xA;    const cmd = mc.newCommand(&#34;stopsvr&#34;, &#34;close server&#34;, PermType.GameMasters);&#xA;    cmd.overload();&#xA;    cmd.setCallback((_cmd, ori, out, _res) =&amp;gt; {&#xA;        const pl = ori.player;&#xA;        out.success(&#34;stop command executed successfully&#34;);&#xA;        mc.broadcast(&#xA;            `Player${pl.realName}Execute the stop command. The server will be shut down after 5 seconds`&#xA;        );&#xA;&#xA;        // Execute stop command&#xA;        setTimeout(() =&amp;gt; {&#xA;            mc.runcmd(&#34;stop&#34;);&#xA;        }, 5000);&#xA;    });&#xA;    cmd.setup();&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üíé Advantage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üíª Support for developing plugins in many different languages, Keeping the API uniform&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Supported languages&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;C++&lt;/code&gt;Ôºå&lt;code&gt;JavaScript&lt;/code&gt;Ôºå&lt;code&gt;Lua&lt;/code&gt;Ôºå&lt;code&gt;Golang&lt;/code&gt;Ôºå&lt;code&gt;.Net&lt;/code&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Upcoming supported languages&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;Python&lt;/code&gt;Ôºå&lt;code&gt;Ruby&lt;/code&gt;Ôºå&lt;code&gt;TypeScript&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;üìï Smooth development experience with great compatibility&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Auto-generated C++ headers, access to all &lt;code&gt;BDS&lt;/code&gt; classes and functions, full toolchain support and evolving features&lt;/li&gt; &#xA;   &lt;li&gt;For scripting language plugins, a multi-language code completion library, a powerful VSCode plugin, a hot-loading system ...... Many tools to help you write every line of code more efficiently&lt;/li&gt; &#xA;   &lt;li&gt;When a version is updated, the API is guaranteed to be largely &lt;strong&gt;backward compatible&lt;/strong&gt; and the plugin requires little or no code changes with the version update. With the &lt;code&gt;LiteLoader&lt;/code&gt; series&#39; unique symbol lookup technology, cross-version &lt;strong&gt;auto-adaptation&lt;/strong&gt; is no longer a dream&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üìã Well documented and explained in detail&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Welcome to üëâ&lt;a href=&#34;https://docs.litebds.com/&#34;&gt;LiteLoader documentation&lt;/a&gt;üëà to see more&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üéà Numerous well-packaged interfaces&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Numerous game APIs support: players, entities, cubes, items, containers, NBTs, server systems ......&lt;/li&gt; &#xA;   &lt;li&gt;Up to &lt;strong&gt;50+&lt;/strong&gt; game events to listen to, no matter what happens, the first to respond&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üõ° Secure, stable and versatile&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fixes a number of vulnerabilities in BDS to ensure the stability and security of your server&lt;/li&gt; &#xA;   &lt;li&gt;Extensive use of the seh exception protection framework to minimise the risk of server crashes&lt;/li&gt; &#xA;   &lt;li&gt;Supports running on Linux, MacOS platforms via &lt;strong&gt;Wine&lt;/strong&gt;, bringing a free plugin experience to other platforms as well: write once, &lt;strong&gt;share on multiple platforms&lt;/strong&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üèÜ Sound app ecosystem&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A large number of existing plugins, mature publishing platform, instantly üëâ&lt;a href=&#34;https://www.minebbs.com/resources/?prefix_id=67&#34;&gt;Go to MineBBS&lt;/a&gt;üëà to find and download your favorite LL plugins&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üèÉ Open Source &amp;amp; Community Building&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The project is licensed under the &lt;code&gt;AGPL-3.0&lt;/code&gt; open source license and will &lt;strong&gt;never&lt;/strong&gt; be charged for or released as a commercial version.&lt;/li&gt; &#xA;   &lt;li&gt;The design philosophy is &lt;strong&gt;decentralised&lt;/strong&gt; and you can be assured of a &lt;strong&gt;free&lt;/strong&gt; plugin loading framework!&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üíª Install&lt;/h2&gt; &#xA;&lt;h3&gt;For Windows&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the latest &lt;code&gt;LiteLoader-&lt;i&gt;version&lt;/i&gt;.zip&lt;/code&gt; from &lt;a href=&#34;https://github.com/LiteLDev/LiteLoader/releases&#34;&gt;Releases&lt;/a&gt; or &lt;a href=&#34;https://github.com/LiteLDev/LiteLoader/actions&#34;&gt;Actions&lt;/a&gt;,&lt;/li&gt; &#xA; &lt;li&gt;Unzip everything into the directory of &lt;code&gt;bedrock_server.exe&lt;/code&gt;. If you are prompted with conflicting files during the decompression process, just select &lt;code&gt;Overwrite&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Ensure that the &lt;code&gt;bedrock_server.pdb&lt;/code&gt; file exists. Run &lt;code&gt;LLPeEditor.exe&lt;/code&gt; to generate the BDS with the exported symbols (&lt;code&gt;bedrock_server_mod.exe&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;When the console output &lt;code&gt;Press any key to continue. . .&lt;/code&gt; , press any key to close the window&lt;/li&gt; &#xA; &lt;li&gt;Execute &lt;code&gt;bedrock_server_mod.exe&lt;/code&gt; and enjoy it !&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;For Linux&lt;/h3&gt; &#xA;&lt;h4&gt;Installation script(Ubuntu)&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;wget https://github.com/LiteLDev/LiteLoaderBDS/raw/beta/Scripts/install.sh&#xA;chmod +x install.sh&#xA;./install.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Docker&lt;/h4&gt; &#xA;&lt;p&gt;Enter the following lines in your terminal:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker pull shrbox/liteloaderbds&#xA;docker create --name liteloader -p 19132:19132/udp -i -t shrbox/liteloaderbds&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Start server: &lt;code&gt;docker container start liteloader&lt;/code&gt;&lt;br&gt; Force stop server(not recommended): &lt;code&gt;docker container stop liteloader&lt;/code&gt;&lt;br&gt; Enter console: &lt;code&gt;docker attach liteloader&lt;/code&gt;&lt;br&gt; Exit console: Press &lt;code&gt;Ctrl + P + Q&lt;/code&gt;. If you press &lt;code&gt;Ctrl + C&lt;/code&gt;, the server process will exit.&lt;br&gt; If you want to manage server files, use &lt;code&gt;docker volume --help&lt;/code&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;Everything&#39;s done! Next, you can install &lt;strong&gt;LiteLoader&lt;/strong&gt; plugins!&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üéØ Find &amp;amp; Install plugins&lt;/h2&gt; &#xA;&lt;h3&gt;Plugin downloads&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;LiteLoader&lt;/code&gt; main plugin distribution channels.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://forum.litebds.com/&#34;&gt;Official Forum&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.minebbs.com/resources/?prefix_id=59&#34;&gt;MineBBS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Plugin installation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;If you downloaded a zip file, unzip it&lt;/li&gt; &#xA; &lt;li&gt;Place all the obtained contents directly into the &lt;code&gt;plugins&lt;/code&gt; directory&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;bedrock_server_mod.exe&lt;/code&gt; to start the service&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For more &lt;strong&gt;installation and usage guides&lt;/strong&gt;, come to üëâ&lt;a href=&#34;https://docs.litebds.com/en_US/Usage/&#34;&gt;LiteLoader documentation&lt;/a&gt;üëà to view&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üìï LiteLoader plugin development&lt;/h2&gt; &#xA;&lt;h3&gt;Developing plugins with C++&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to the &lt;a href=&#34;https://github.com/LiteLDev/PluginTemplate&#34;&gt;LiteLoader plugin template repository&lt;/a&gt; to download project templates, or create your own project repository based on the templates and download the code locally&lt;/li&gt; &#xA; &lt;li&gt;Open the Template.sln project file&lt;/li&gt; &#xA; &lt;li&gt;Start writing the plugin code in Plugin.cpp&lt;/li&gt; &#xA; &lt;li&gt;Compile, and select the appropriate PDB file as prompted to generate the dependency libs&lt;/li&gt; &#xA; &lt;li&gt;Copy the plugin to the plugins directory for testing&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For plugins development examples and guidance, please come to üëâ&lt;a href=&#34;https://docs.litebds.com/en_US/Usage/&#34;&gt;LiteLoader documentation&lt;/a&gt;üëà&lt;br&gt; If you have a revision request or need to add an API, please contact the author or post an Issue&lt;/p&gt; &#xA;&lt;h3&gt;Developing plugins using scripting Languages&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create the file&lt;/li&gt; &#xA; &lt;li&gt;Write the code&lt;/li&gt; &#xA; &lt;li&gt;Copy the plugin to the plugins directory for testing&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Please come to üëâ&lt;a href=&#34;https://docs.litebds.com/en_US/Development/&#34;&gt;LiteLoader documentation&lt;/a&gt;üëà for detailed &lt;strong&gt;API documentation&lt;/strong&gt; and &lt;strong&gt;plugin development tutorial&lt;/strong&gt;.&lt;br&gt; If you have a revision request or need to add an API, please feel free to contact the author or post an Issue&lt;/p&gt; &#xA;&lt;h3&gt;Example Plugins&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/LiteLDev&#34;&gt;Click here&lt;/a&gt; for more open source LiteLoader plugins as sample plugins. You can use them directly in production environments You can also learn plugin development methods and tips here&lt;/p&gt; &#xA;&lt;h3&gt;Development Aids - VSCode Development Aids &amp;amp; Complementary Libraries&lt;/h3&gt; &#xA;&lt;p&gt;Use the LiteLoader development helper plugin developed by Moxicat&lt;br&gt; Helps you do better with &lt;strong&gt;script plugins&lt;/strong&gt;!&lt;br&gt; Code hint, auto-completion, auto-documentation, error alert, runtime debugging and so on&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.minebbs.com/resources/llscripthelper.2672/&#34;&gt;Click here&lt;/a&gt; View more description and introduction of this extension&lt;br&gt; VSCode extension store search &lt;code&gt;LLScriptHelper&lt;/code&gt;, install &lt;strong&gt;LLScriptHelper&lt;/strong&gt; and experience it instantly!&lt;/p&gt; &#xA;&lt;h3&gt;Development Aids - Blockly-LXL Graphical Development Kit&lt;/h3&gt; &#xA;&lt;p&gt;No programming foundation? Tired of complex language rules?&lt;br&gt; Have you ever thought that BDS plug-in development could be as easy as a puzzle?&lt;/p&gt; &#xA;&lt;p&gt;Here it is! The Blockly-LXL graphical development kit from pa733 takes the plugin development experience to a new level!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.minebbs.com/resources/blockly-lxl.2671/&#34;&gt;Click here&lt;/a&gt; View related installation and usage instructions&lt;/p&gt; &#xA;&lt;h2&gt;üî® Build project&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Go to &lt;a href=&#34;https://github.com/LiteLDev/LiteLoaderBDS/actions&#34;&gt;&lt;code&gt;GitHub Actions&lt;/code&gt;&lt;/a&gt; to get the latest build artifact&lt;/p&gt; &#xA; &lt;p&gt;Of course, if you prefer to build the project yourself, or contribute code to LiteLoader, you can build the project yourself by following these instructions&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;install the latest &lt;strong&gt;Microsoft Visual Studio&lt;/strong&gt; and the standard C++ desktop development suite&lt;/li&gt; &#xA; &lt;li&gt;Install the latest &lt;strong&gt;Windows SDK&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Open the &lt;code&gt;LiteLoader.sln&lt;/code&gt; project file and click on the &lt;strong&gt;Batch Generation&lt;/strong&gt; item in the &lt;strong&gt;Generation&lt;/strong&gt; menu&lt;/li&gt; &#xA; &lt;li&gt;Bring up the batch generation dialog, check all the generation checkboxes on the right side of the dialog&lt;/li&gt; &#xA; &lt;li&gt;When you have finished selecting, click the &lt;strong&gt;Generate&lt;/strong&gt; button in the dialog box to perform batch generation&lt;/li&gt; &#xA; &lt;li&gt;After successful compilation, go back to the project root directory and execute the &lt;code&gt;PackRelease.cmd&lt;/code&gt; script in the Scripts folder.&lt;br&gt; After execution, the contents of the &lt;code&gt;RELEASE&lt;/code&gt; folder in the root directory will be the complete &lt;code&gt;LiteLoader&lt;/code&gt; environment and all dependencies.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üé¨ Participate in contribution&lt;/h2&gt; &#xA;&lt;p&gt;You can use the following methods to contribute to the &lt;code&gt;LiteLoader&lt;/code&gt; project&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Contribute code, maintain symbols&lt;/li&gt; &#xA; &lt;li&gt;Help us modify and optimize development documents&lt;/li&gt; &#xA; &lt;li&gt;Write the new API that you want in the format and submit a PR, or make good suggestions&lt;/li&gt; &#xA; &lt;li&gt;Help us promote &lt;code&gt;LiteLoader&lt;/code&gt;, support our development&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;‚≠ê‚≠ê‚≠êWe welcome your contributions to LiteLoader!‚≠ê‚≠ê‚≠ê&lt;/p&gt; &#xA;&lt;p&gt;If you are interested in contributing to LiteLoaderBDS, feel free to come to üëâ&lt;a href=&#34;https://docs.litebds.com/en_US/Maintenance/&#34;&gt;LiteLoader documentation&lt;/a&gt;üëà to view &lt;strong&gt;Project Maintenance and Support Documentation&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üìç LICENSE&lt;/h2&gt; &#xA;&lt;p&gt;You must accept the Minecraft EULA.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It means &lt;strong&gt;DO NOT MAKE COMMERCIAL USE OF ANYTHING which breaks the EULA.&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Accepting this &lt;strong&gt;LICENSE&lt;/strong&gt; means you &lt;strong&gt;ACCEPTED&lt;/strong&gt; &lt;a href=&#34;https://account.mojang.com/terms&#34;&gt;Minecraft EULA&lt;/a&gt; too.&lt;/li&gt; &#xA; &lt;li&gt;If you violate the &lt;strong&gt;EULA&lt;/strong&gt;, any legal liability is &lt;strong&gt;IRRELEVANT&lt;/strong&gt; to the developers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;NO WARRANTY&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Project&lt;/th&gt; &#xA;   &lt;th&gt;License&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/LiteLDev/LiteLoader&#34;&gt;LiteLoader&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;AGPLv3 with extra restrictions&amp;amp;exceptions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Sysca11/BedrockX&#34;&gt;BedrockX&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPLv3 with extra restrictions&amp;amp;exceptions&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Element-0/ElementZero&#34;&gt;ElementZero&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPLv3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Tencent/ScriptX&#34;&gt;ScriptX&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Apache License Version 2.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/openssl/openssl&#34;&gt;OpenSSL&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Apache-2.0 License&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/brofield/simpleini&#34;&gt;SimpleIni&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIT License&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/nlohmann/json&#34;&gt;Nlohmann-Json&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIT License&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/handtruth/nbt-cpp&#34;&gt;nbt-cpp&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIT License&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Chocobo1/Hash&#34;&gt;Hash&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPLv3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/jhasse/ThreadPool&#34;&gt;ThreadPool&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Zlib License&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/cyanray/LightWebSocketClient&#34;&gt;LightWebSocketClient&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIT License&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Neargye/magic_enum&#34;&gt;magic_enum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIT License&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.dyncall.org/index&#34;&gt;dyncall&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ISC license&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/pr701/vcproxy&#34;&gt;vcproxy&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIT License&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/MolecularMatters/raw_pdb&#34;&gt;RawPDB&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;BSD 2-Clause License&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Extra Restrictions &amp;amp; Exceptions&lt;/h3&gt; &#xA;&lt;p&gt;If you provide a server hosting service,you can use this framework for free, but you SHOULD NOT make PRIVATE changes to this framework or as a selling point. If you fixed or tweaked the code, please pull request, instead of making it private or using it for commercial propose.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Do not do evil.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Although we expected to build an open-source community, but forcing everything open-source will ruin this community. So you can write plugins based on &lt;code&gt;LiteLoader&lt;/code&gt; with ANY open-source license or even don&#39;t publish your source code. but if you modified the framework, or write a new framework based on this framework, you MUST open-source it.&lt;/p&gt; &#xA;&lt;p&gt;If you want to reproduce and distribute this framework, you have to get our authorization!&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üèÜ Acknowledgement&lt;/h2&gt; &#xA;&lt;h4&gt;Important Contributors&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/53301243?s=96&amp;amp;v=4&#34; alt=&#34;ShrBox&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/62042544?s=96&amp;amp;v=4&#34; alt=&#34;dreamguxiang&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/42824603?s=96&amp;amp;v=4&#34; alt=&#34;WangYneos&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/59381521?s=96&amp;amp;v=4&#34; alt=&#34;wzy&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/37901097?s=96&amp;amp;v=4&#34; alt=&#34;xiaoqch&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/37969157?s=96&amp;amp;v=4&#34; alt=&#34;yqs112358&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/46832985?s=96&amp;amp;v=4&#34; alt=&#34;Sysca11&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/42002296?s=96&amp;amp;v=4&#34; alt=&#34;RimuruChan&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ShrBox&#34;&gt;@ShrBox&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/dreamguxiang&#34;&gt;@dreamguxiang&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/WangYneos&#34;&gt;@WangYneos&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/wzyyyyyyy&#34;&gt;@wzy&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/xiaoqch&#34;&gt;@xiaoqch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/yqs112358&#34;&gt;@yqs112358&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Sysca11&#34;&gt;@Sysca11&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/RimuruChan&#34;&gt;@RimuruChan&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Thanks to &lt;a href=&#34;https://www.jetbrains.com/&#34;&gt;JetBrains&lt;/a&gt; for allocating free open-source licences for IDEs such as &lt;a href=&#34;https://www.jetbrains.com/clion/&#34;&gt;CLion&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt; &lt;a href=&#34;https://www.jetbrains.com/&#34;&gt;&lt;img src=&#34;https://upload.cc/i1/2021/12/29/XNohu5.png&#34; width=&#34;200&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cameron314/concurrentqueue</title>
    <updated>2022-07-16T01:31:25Z</updated>
    <id>tag:github.com,2022-07-16:/cameron314/concurrentqueue</id>
    <link href="https://github.com/cameron314/concurrentqueue" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A fast multi-producer, multi-consumer lock-free concurrent queue for C++11&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;moodycamel::ConcurrentQueue&#xA; &lt;t&gt;&lt;/t&gt;&lt;/h1&gt; &#xA;&lt;p&gt;An industrial-strength lock-free queue for C++.&lt;/p&gt; &#xA;&lt;p&gt;Note: If all you need is a single-producer, single-consumer queue, I have &lt;a href=&#34;https://github.com/cameron314/readerwriterqueue&#34;&gt;one of those too&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Knock-your-socks-off &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++#benchmarks&#34;&gt;blazing fast performance&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Single-header implementation. Just drop it in your project.&lt;/li&gt; &#xA; &lt;li&gt;Fully thread-safe lock-free queue. Use concurrently from any number of threads.&lt;/li&gt; &#xA; &lt;li&gt;C++11 implementation -- elements are moved (instead of copied) where possible.&lt;/li&gt; &#xA; &lt;li&gt;Templated, obviating the need to deal exclusively with pointers -- memory is managed for you.&lt;/li&gt; &#xA; &lt;li&gt;No artificial limitations on element types or maximum count.&lt;/li&gt; &#xA; &lt;li&gt;Memory can be allocated once up-front, or dynamically as needed.&lt;/li&gt; &#xA; &lt;li&gt;Fully portable (no assembly; all is done through standard C++11 primitives).&lt;/li&gt; &#xA; &lt;li&gt;Supports super-fast bulk operations.&lt;/li&gt; &#xA; &lt;li&gt;Includes a low-overhead blocking version (BlockingConcurrentQueue).&lt;/li&gt; &#xA; &lt;li&gt;Exception safe.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Reasons to use&lt;/h2&gt; &#xA;&lt;p&gt;There are not that many full-fledged lock-free queues for C++. Boost has one, but it&#39;s limited to objects with trivial assignment operators and trivial destructors, for example. Intel&#39;s TBB queue isn&#39;t lock-free, and requires trivial constructors too. There&#39;re many academic papers that implement lock-free queues in C++, but usable source code is hard to find, and tests even more so.&lt;/p&gt; &#xA;&lt;p&gt;This queue not only has less limitations than others (for the most part), but &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++#benchmarks&#34;&gt;it&#39;s also faster&lt;/a&gt;. It&#39;s been fairly well-tested, and offers advanced features like &lt;strong&gt;bulk enqueueing/dequeueing&lt;/strong&gt; (which, with my new design, is much faster than one element at a time, approaching and even surpassing the speed of a non-concurrent queue even under heavy contention).&lt;/p&gt; &#xA;&lt;p&gt;In short, there was a lock-free queue shaped hole in the C++ open-source universe, and I set out to fill it with the fastest, most complete, and well-tested design and implementation I could. The result is &lt;code&gt;moodycamel::ConcurrentQueue&lt;/code&gt; :-)&lt;/p&gt; &#xA;&lt;h2&gt;Reasons &lt;em&gt;not&lt;/em&gt; to use&lt;/h2&gt; &#xA;&lt;p&gt;The fastest synchronization of all is the kind that never takes place. Fundamentally, concurrent data structures require some synchronization, and that takes time. Every effort was made, of course, to minimize the overhead, but if you can avoid sharing data between threads, do so!&lt;/p&gt; &#xA;&lt;p&gt;Why use concurrent data structures at all, then? Because they&#39;re gosh darn convenient! (And, indeed, sometimes sharing data concurrently is unavoidable.)&lt;/p&gt; &#xA;&lt;p&gt;My queue is &lt;strong&gt;not linearizable&lt;/strong&gt; (see the next section on high-level design). The foundations of its design assume that producers are independent; if this is not the case, and your producers co-ordinate amongst themselves in some fashion, be aware that the elements won&#39;t necessarily come out of the queue in the same order they were put in &lt;em&gt;relative to the ordering formed by that co-ordination&lt;/em&gt; (but they will still come out in the order they were put in by any &lt;em&gt;individual&lt;/em&gt; producer). If this affects your use case, you may be better off with another implementation; either way, it&#39;s an important limitation to be aware of.&lt;/p&gt; &#xA;&lt;p&gt;My queue is also &lt;strong&gt;not NUMA aware&lt;/strong&gt;, and does a lot of memory re-use internally, meaning it probably doesn&#39;t scale particularly well on NUMA architectures; however, I don&#39;t know of any other lock-free queue that &lt;em&gt;is&lt;/em&gt; NUMA aware (except for &lt;a href=&#34;http://webee.technion.ac.il/~idish/ftp/spaa049-gidron.pdf&#34;&gt;SALSA&lt;/a&gt;, which is very cool, but has no publicly available implementation that I know of).&lt;/p&gt; &#xA;&lt;p&gt;Finally, the queue is &lt;strong&gt;not sequentially consistent&lt;/strong&gt;; there &lt;em&gt;is&lt;/em&gt; a happens-before relationship between when an element is put in the queue and when it comes out, but other things (such as pumping the queue until it&#39;s empty) require more thought to get right in all eventualities, because explicit memory ordering may have to be done to get the desired effect. In other words, it can sometimes be difficult to use the queue correctly. This is why it&#39;s a good idea to follow the &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/samples.md&#34;&gt;samples&lt;/a&gt; where possible. On the other hand, the upside of this lack of sequential consistency is better performance.&lt;/p&gt; &#xA;&lt;h2&gt;High-level design&lt;/h2&gt; &#xA;&lt;p&gt;Elements are stored internally using contiguous blocks instead of linked lists for better performance. The queue is made up of a collection of sub-queues, one for each producer. When a consumer wants to dequeue an element, it checks all the sub-queues until it finds one that&#39;s not empty. All of this is largely transparent to the user of the queue, however -- it mostly just works&lt;sup&gt;TM&lt;/sup&gt;.&lt;/p&gt; &#xA;&lt;p&gt;One particular consequence of this design, however, (which seems to be non-intuitive) is that if two producers enqueue at the same time, there is no defined ordering between the elements when they&#39;re later dequeued. Normally this is fine, because even with a fully linearizable queue there&#39;d be a race between the producer threads and so you couldn&#39;t rely on the ordering anyway. However, if for some reason you do extra explicit synchronization between the two producer threads yourself, thus defining a total order between enqueue operations, you might expect that the elements would come out in the same total order, which is a guarantee my queue does not offer. At that point, though, there semantically aren&#39;t really two separate producers, but rather one that happens to be spread across multiple threads. In this case, you can still establish a total ordering with my queue by creating a single producer token, and using that from both threads to enqueue (taking care to synchronize access to the token, of course, but there was already extra synchronization involved anyway).&lt;/p&gt; &#xA;&lt;p&gt;I&#39;ve written a more detailed &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++&#34;&gt;overview of the internal design&lt;/a&gt;, as well as &lt;a href=&#34;http://moodycamel.com/blog/2014/detailed-design-of-a-lock-free-queue&#34;&gt;the full nitty-gritty details of the design&lt;/a&gt;, on my blog. Finally, the &lt;a href=&#34;https://github.com/cameron314/concurrentqueue&#34;&gt;source&lt;/a&gt; itself is available for perusal for those interested in its implementation.&lt;/p&gt; &#xA;&lt;h2&gt;Basic use&lt;/h2&gt; &#xA;&lt;p&gt;The entire queue&#39;s implementation is contained in &lt;strong&gt;one header&lt;/strong&gt;, &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/concurrentqueue.h&#34;&gt;&lt;code&gt;concurrentqueue.h&lt;/code&gt;&lt;/a&gt;. Simply download and include that to use the queue. The blocking version is in a separate header, &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/blockingconcurrentqueue.h&#34;&gt;&lt;code&gt;blockingconcurrentqueue.h&lt;/code&gt;&lt;/a&gt;, that depends on &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/concurrentqueue.h&#34;&gt;&lt;code&gt;concurrentqueue.h&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/lightweightsemaphore.h&#34;&gt;&lt;code&gt;lightweightsemaphore.h&lt;/code&gt;&lt;/a&gt;. The implementation makes use of certain key C++11 features, so it requires a relatively recent compiler (e.g. VS2012+ or g++ 4.8; note that g++ 4.6 has a known bug with &lt;code&gt;std::atomic&lt;/code&gt; and is thus not supported). The algorithm implementations themselves are platform independent.&lt;/p&gt; &#xA;&lt;p&gt;Use it like you would any other templated queue, with the exception that you can use it from many threads at once :-)&lt;/p&gt; &#xA;&lt;p&gt;Simple example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#include &#34;concurrentqueue.h&#34;&#xA;&#xA;moodycamel::ConcurrentQueue&amp;lt;int&amp;gt; q;&#xA;q.enqueue(25);&#xA;&#xA;int item;&#xA;bool found = q.try_dequeue(item);&#xA;assert(found &amp;amp;&amp;amp; item == 25);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Description of basic methods:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;ConcurrentQueue(size_t initialSizeEstimate)&lt;/code&gt; Constructor which optionally accepts an estimate of the number of elements the queue will hold&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;enqueue(T&amp;amp;&amp;amp; item)&lt;/code&gt; Enqueues one item, allocating extra space if necessary&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;try_enqueue(T&amp;amp;&amp;amp; item)&lt;/code&gt; Enqueues one item, but only if enough memory is already allocated&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;try_dequeue(T&amp;amp; item)&lt;/code&gt; Dequeues one item, returning true if an item was found or false if the queue appeared empty&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note that it is up to the user to ensure that the queue object is completely constructed before being used by any other threads (this includes making the memory effects of construction visible, possibly via a memory barrier). Similarly, it&#39;s important that all threads have finished using the queue (and the memory effects have fully propagated) before it is destructed.&lt;/p&gt; &#xA;&lt;p&gt;There&#39;s usually two versions of each method, one &#34;explicit&#34; version that takes a user-allocated per-producer or per-consumer token, and one &#34;implicit&#34; version that works without tokens. Using the explicit methods is almost always faster (though not necessarily by a huge factor). Apart from performance, the primary distinction between them is their sub-queue allocation behaviour for enqueue operations: Using the implicit enqueue methods causes an automatically-allocated thread-local producer sub-queue to be allocated. Explicit producers, on the other hand, are tied directly to their tokens&#39; lifetimes (but are recycled internally).&lt;/p&gt; &#xA;&lt;p&gt;In order to avoid the number of sub-queues growing without bound, implicit producers are marked for reuse once their thread exits. However, this is not supported on all platforms. If using the queue from short-lived threads, it is recommended to use explicit producer tokens instead.&lt;/p&gt; &#xA;&lt;p&gt;Full API (pseudocode):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Allocates more memory if necessary&#xA;enqueue(item) : bool&#xA;enqueue(prod_token, item) : bool&#xA;enqueue_bulk(item_first, count) : bool&#xA;enqueue_bulk(prod_token, item_first, count) : bool&#xA;&#xA;# Fails if not enough memory to enqueue&#xA;try_enqueue(item) : bool&#xA;try_enqueue(prod_token, item) : bool&#xA;try_enqueue_bulk(item_first, count) : bool&#xA;try_enqueue_bulk(prod_token, item_first, count) : bool&#xA;&#xA;# Attempts to dequeue from the queue (never allocates)&#xA;try_dequeue(item&amp;amp;) : bool&#xA;try_dequeue(cons_token, item&amp;amp;) : bool&#xA;try_dequeue_bulk(item_first, max) : size_t&#xA;try_dequeue_bulk(cons_token, item_first, max) : size_t&#xA;&#xA;# If you happen to know which producer you want to dequeue from&#xA;try_dequeue_from_producer(prod_token, item&amp;amp;) : bool&#xA;try_dequeue_bulk_from_producer(prod_token, item_first, max) : size_t&#xA;&#xA;# A not-necessarily-accurate count of the total number of elements&#xA;size_approx() : size_t&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Blocking version&lt;/h2&gt; &#xA;&lt;p&gt;As mentioned above, a full blocking wrapper of the queue is provided that adds &lt;code&gt;wait_dequeue&lt;/code&gt; and &lt;code&gt;wait_dequeue_bulk&lt;/code&gt; methods in addition to the regular interface. This wrapper is extremely low-overhead, but slightly less fast than the non-blocking queue (due to the necessary bookkeeping involving a lightweight semaphore).&lt;/p&gt; &#xA;&lt;p&gt;There are also timed versions that allow a timeout to be specified (either in microseconds or with a &lt;code&gt;std::chrono&lt;/code&gt; object).&lt;/p&gt; &#xA;&lt;p&gt;The only major caveat with the blocking version is that you must be careful not to destroy the queue while somebody is waiting on it. This generally means you need to know for certain that another element is going to come along before you call one of the blocking methods. (To be fair, the non-blocking version cannot be destroyed while in use either, but it can be easier to coordinate the cleanup.)&lt;/p&gt; &#xA;&lt;p&gt;Blocking example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#include &#34;blockingconcurrentqueue.h&#34;&#xA;&#xA;moodycamel::BlockingConcurrentQueue&amp;lt;int&amp;gt; q;&#xA;std::thread producer([&amp;amp;]() {&#xA;    for (int i = 0; i != 100; ++i) {&#xA;        std::this_thread::sleep_for(std::chrono::milliseconds(i % 10));&#xA;        q.enqueue(i);&#xA;    }&#xA;});&#xA;std::thread consumer([&amp;amp;]() {&#xA;    for (int i = 0; i != 100; ++i) {&#xA;        int item;&#xA;        q.wait_dequeue(item);&#xA;        assert(item == i);&#xA;        &#xA;        if (q.wait_dequeue_timed(item, std::chrono::milliseconds(5))) {&#xA;            ++i;&#xA;            assert(item == i);&#xA;        }&#xA;    }&#xA;});&#xA;producer.join();&#xA;consumer.join();&#xA;&#xA;assert(q.size_approx() == 0);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Advanced features&lt;/h2&gt; &#xA;&lt;h4&gt;Tokens&lt;/h4&gt; &#xA;&lt;p&gt;The queue can take advantage of extra per-producer and per-consumer storage if it&#39;s available to speed up its operations. This takes the form of &#34;tokens&#34;: You can create a consumer token and/or a producer token for each thread or task (tokens themselves are not thread-safe), and use the methods that accept a token as their first parameter:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;moodycamel::ConcurrentQueue&amp;lt;int&amp;gt; q;&#xA;&#xA;moodycamel::ProducerToken ptok(q);&#xA;q.enqueue(ptok, 17);&#xA;&#xA;moodycamel::ConsumerToken ctok(q);&#xA;int item;&#xA;q.try_dequeue(ctok, item);&#xA;assert(item == 17);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you happen to know which producer you want to consume from (e.g. in a single-producer, multi-consumer scenario), you can use the &lt;code&gt;try_dequeue_from_producer&lt;/code&gt; methods, which accept a producer token instead of a consumer token, and cut some overhead.&lt;/p&gt; &#xA;&lt;p&gt;Note that tokens work with the blocking version of the queue too.&lt;/p&gt; &#xA;&lt;p&gt;When producing or consuming many elements, the most efficient way is to:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Use the bulk methods of the queue with tokens&lt;/li&gt; &#xA; &lt;li&gt;Failing that, use the bulk methods without tokens&lt;/li&gt; &#xA; &lt;li&gt;Failing that, use the single-item methods with tokens&lt;/li&gt; &#xA; &lt;li&gt;Failing that, use the single-item methods without tokens&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Having said that, don&#39;t create tokens willy-nilly -- ideally there would be one token (of each kind) per thread. The queue will work with what it is given, but it performs best when used with tokens.&lt;/p&gt; &#xA;&lt;p&gt;Note that tokens aren&#39;t actually tied to any given thread; it&#39;s not technically required that they be local to the thread, only that they be used by a single producer/consumer at a time.&lt;/p&gt; &#xA;&lt;h4&gt;Bulk operations&lt;/h4&gt; &#xA;&lt;p&gt;Thanks to the &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++&#34;&gt;novel design&lt;/a&gt; of the queue, it&#39;s just as easy to enqueue/dequeue multiple items as it is to do one at a time. This means that overhead can be cut drastically for bulk operations. Example syntax:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;moodycamel::ConcurrentQueue&amp;lt;int&amp;gt; q;&#xA;&#xA;int items[] = { 1, 2, 3, 4, 5 };&#xA;q.enqueue_bulk(items, 5);&#xA;&#xA;int results[5];     // Could also be any iterator&#xA;size_t count = q.try_dequeue_bulk(results, 5);&#xA;for (size_t i = 0; i != count; ++i) {&#xA;    assert(results[i] == items[i]);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Preallocation (correctly using &lt;code&gt;try_enqueue&lt;/code&gt;)&lt;/h4&gt; &#xA;&lt;p&gt;&lt;code&gt;try_enqueue&lt;/code&gt;, unlike just plain &lt;code&gt;enqueue&lt;/code&gt;, will never allocate memory. If there&#39;s not enough room in the queue, it simply returns false. The key to using this method properly, then, is to ensure enough space is pre-allocated for your desired maximum element count.&lt;/p&gt; &#xA;&lt;p&gt;The constructor accepts a count of the number of elements that it should reserve space for. Because the queue works with blocks of elements, however, and not individual elements themselves, the value to pass in order to obtain an effective number of pre-allocated element slots is non-obvious.&lt;/p&gt; &#xA;&lt;p&gt;First, be aware that the count passed is rounded up to the next multiple of the block size. Note that the default block size is 32 (this can be changed via the traits). Second, once a slot in a block has been enqueued to, that slot cannot be re-used until the rest of the block has completely been completely filled up and then completely emptied. This affects the number of blocks you need in order to account for the overhead of partially-filled blocks. Third, each producer (whether implicit or explicit) claims and recycles blocks in a different manner, which again affects the number of blocks you need to account for a desired number of usable slots.&lt;/p&gt; &#xA;&lt;p&gt;Suppose you want the queue to be able to hold at least &lt;code&gt;N&lt;/code&gt; elements at any given time. Without delving too deep into the rather arcane implementation details, here are some simple formulas for the number of elements to request for pre-allocation in such a case. Note the division is intended to be arithmetic division and not integer division (in order for &lt;code&gt;ceil()&lt;/code&gt; to work).&lt;/p&gt; &#xA;&lt;p&gt;For explicit producers (using tokens to enqueue):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(ceil(N / BLOCK_SIZE) + 1) * MAX_NUM_PRODUCERS * BLOCK_SIZE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For implicit producers (no tokens):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(ceil(N / BLOCK_SIZE) - 1 + 2 * MAX_NUM_PRODUCERS) * BLOCK_SIZE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When using mixed producer types:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;((ceil(N / BLOCK_SIZE) - 1) * (MAX_EXPLICIT_PRODUCERS + 1) + 2 * (MAX_IMPLICIT_PRODUCERS + MAX_EXPLICIT_PRODUCERS)) * BLOCK_SIZE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If these formulas seem rather inconvenient, you can use the constructor overload that accepts the minimum number of elements (&lt;code&gt;N&lt;/code&gt;) and the maximum number of explicit and implicit producers directly, and let it do the computation for you.&lt;/p&gt; &#xA;&lt;p&gt;Finally, it&#39;s important to note that because the queue is only eventually consistent and takes advantage of weak memory ordering for speed, there&#39;s always a possibility that under contention &lt;code&gt;try_enqueue&lt;/code&gt; will fail even if the queue is correctly pre-sized for the desired number of elements. (e.g. A given thread may think that the queue&#39;s full even when that&#39;s no longer the case.) So no matter what, you still need to handle the failure case (perhaps looping until it succeeds), unless you don&#39;t mind dropping elements.&lt;/p&gt; &#xA;&lt;h4&gt;Exception safety&lt;/h4&gt; &#xA;&lt;p&gt;The queue is exception safe, and will never become corrupted if used with a type that may throw exceptions. The queue itself never throws any exceptions (operations fail gracefully (return false) if memory allocation fails instead of throwing &lt;code&gt;std::bad_alloc&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;It is important to note that the guarantees of exception safety only hold if the element type never throws from its destructor, and that any iterators passed into the queue (for bulk operations) never throw either. Note that in particular this means &lt;code&gt;std::back_inserter&lt;/code&gt; iterators must be used with care, since the vector being inserted into may need to allocate and throw a &lt;code&gt;std::bad_alloc&lt;/code&gt; exception from inside the iterator; so be sure to reserve enough capacity in the target container first if you do this.&lt;/p&gt; &#xA;&lt;p&gt;The guarantees are presently as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Enqueue operations are rolled back completely if an exception is thrown from an element&#39;s constructor. For bulk enqueue operations, this means that elements are copied instead of moved (in order to avoid having only some of the objects be moved in the event of an exception). Non-bulk enqueues always use the move constructor if one is available.&lt;/li&gt; &#xA; &lt;li&gt;If the assignment operator throws during a dequeue operation (both single and bulk), the element(s) are considered dequeued regardless. In such a case, the dequeued elements are all properly destructed before the exception is propagated, but there&#39;s no way to get the elements themselves back.&lt;/li&gt; &#xA; &lt;li&gt;Any exception that is thrown is propagated up the call stack, at which point the queue is in a consistent state.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note: If any of your type&#39;s copy constructors/move constructors/assignment operators don&#39;t throw, be sure to annotate them with &lt;code&gt;noexcept&lt;/code&gt;; this will avoid the exception-checking overhead in the queue where possible (even with zero-cost exceptions, there&#39;s still a code size impact that has to be taken into account).&lt;/p&gt; &#xA;&lt;h4&gt;Traits&lt;/h4&gt; &#xA;&lt;p&gt;The queue also supports a traits template argument which defines various types, constants, and the memory allocation and deallocation functions that are to be used by the queue. The typical pattern to providing your own traits is to create a class that inherits from the default traits and override only the values you wish to change. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;struct MyTraits : public moodycamel::ConcurrentQueueDefaultTraits&#xA;{&#xA;&#x9;static const size_t BLOCK_SIZE = 256;&#x9;&#x9;// Use bigger blocks&#xA;};&#xA;&#xA;moodycamel::ConcurrentQueue&amp;lt;int, MyTraits&amp;gt; q;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;How to dequeue types without calling the constructor&lt;/h4&gt; &#xA;&lt;p&gt;The normal way to dequeue an item is to pass in an existing object by reference, which is then assigned to internally by the queue (using the move-assignment operator if possible). This can pose a problem for types that are expensive to construct or don&#39;t have a default constructor; fortunately, there is a simple workaround: Create a wrapper class that copies the memory contents of the object when it is assigned by the queue (a poor man&#39;s move, essentially). Note that this only works if the object contains no internal pointers. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;struct MyObjectMover {&#xA;    inline void operator=(MyObject&amp;amp;&amp;amp; obj) {&#xA;        std::memcpy(data, &amp;amp;obj, sizeof(MyObject));&#xA;        &#xA;        // TODO: Cleanup obj so that when it&#39;s destructed by the queue&#xA;        // it doesn&#39;t corrupt the data of the object we just moved it into&#xA;    }&#xA;&#xA;    inline MyObject&amp;amp; obj() { return *reinterpret_cast&amp;lt;MyObject*&amp;gt;(data); }&#xA;&#xA;private:&#xA;    align(alignof(MyObject)) char data[sizeof(MyObject)];&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A less dodgy alternative, if moves are cheap but default construction is not, is to use a wrapper that defers construction until the object is assigned, enabling use of the move constructor:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;struct MyObjectMover {&#xA;    inline void operator=(MyObject&amp;amp;&amp;amp; x) {&#xA;        new (data) MyObject(std::move(x));&#xA;        created = true;&#xA;    }&#xA;&#xA;    inline MyObject&amp;amp; obj() {&#xA;        assert(created);&#xA;        return *reinterpret_cast&amp;lt;MyObject*&amp;gt;(data);&#xA;    }&#xA;&#xA;    ~MyObjectMover() {&#xA;        if (created)&#xA;            obj().~MyObject();&#xA;    }&#xA;&#xA;private:&#xA;    align(alignof(MyObject)) char data[sizeof(MyObject)];&#xA;    bool created = false;&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Samples&lt;/h2&gt; &#xA;&lt;p&gt;There are some more detailed samples &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/samples.md&#34;&gt;here&lt;/a&gt;. The source of the &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/tree/master/tests/unittests&#34;&gt;unit tests&lt;/a&gt; and &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/tree/master/benchmarks&#34;&gt;benchmarks&lt;/a&gt; are available for reference as well.&lt;/p&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;See my blog post for some &lt;a href=&#34;http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++#benchmarks&#34;&gt;benchmark results&lt;/a&gt; (including versus &lt;code&gt;boost::lockfree::queue&lt;/code&gt; and &lt;code&gt;tbb::concurrent_queue&lt;/code&gt;), or run the benchmarks yourself (requires MinGW and certain GnuWin32 utilities to build on Windows, or a recent g++ on Linux):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd build&#xA;make benchmarks&#xA;bin/benchmarks&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The short version of the benchmarks is that it&#39;s so fast (especially the bulk methods), that if you&#39;re actually using the queue to &lt;em&gt;do&lt;/em&gt; anything, the queue won&#39;t be your bottleneck.&lt;/p&gt; &#xA;&lt;h2&gt;Tests (and bugs)&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;ve written quite a few unit tests as well as a randomized long-running fuzz tester. I also ran the core queue algorithm through the &lt;a href=&#34;http://demsky.eecs.uci.edu/c11modelchecker.html&#34;&gt;CDSChecker&lt;/a&gt; C++11 memory model model checker. Some of the inner algorithms were tested separately using the &lt;a href=&#34;http://www.1024cores.net/home/relacy-race-detector&#34;&gt;Relacy&lt;/a&gt; model checker, and full integration tests were also performed with Relacy. I&#39;ve tested on Linux (Fedora 19) and Windows (7), but only on x86 processors so far (Intel and AMD). The code was written to be platform-independent, however, and should work across all processors and OSes.&lt;/p&gt; &#xA;&lt;p&gt;Due to the complexity of the implementation and the difficult-to-test nature of lock-free code in general, there may still be bugs. If anyone is seeing buggy behaviour, I&#39;d like to hear about it! (Especially if a unit test for it can be cooked up.) Just open an issue on GitHub.&lt;/p&gt; &#xA;&lt;h2&gt;Using vcpkg&lt;/h2&gt; &#xA;&lt;p&gt;You can download and install &lt;code&gt;moodycamel::ConcurrentQueue&lt;/code&gt; using the &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;vcpkg&lt;/a&gt; dependency manager:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/Microsoft/vcpkg.git&#xA;cd vcpkg&#xA;./bootstrap-vcpkg.sh&#xA;./vcpkg integrate install&#xA;vcpkg install concurrentqueue&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;moodycamel::ConcurrentQueue&lt;/code&gt; port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;create an issue or pull request&lt;/a&gt; on the vcpkg repository.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;m releasing the source of this repository (with the exception of third-party code, i.e. the Boost queue (used in the benchmarks for comparison), Intel&#39;s TBB library (ditto), CDSChecker, Relacy, and Jeff Preshing&#39;s cross-platform semaphore, which all have their own licenses) under a simplified BSD license. I&#39;m also dual-licensing under the Boost Software License. See the &lt;a href=&#34;https://github.com/cameron314/concurrentqueue/raw/master/LICENSE.md&#34;&gt;LICENSE.md&lt;/a&gt; file for more details.&lt;/p&gt; &#xA;&lt;p&gt;Note that lock-free programming is a patent minefield, and this code may very well violate a pending patent (I haven&#39;t looked), though it does not to my present knowledge. I did design and implement this queue from scratch.&lt;/p&gt; &#xA;&lt;h2&gt;Diving into the code&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;re interested in the source code itself, it helps to have a rough idea of how it&#39;s laid out. This section attempts to describe that.&lt;/p&gt; &#xA;&lt;p&gt;The queue is formed of several basic parts (listed here in roughly the order they appear in the source). There&#39;s the helper functions (e.g. for rounding to a power of 2). There&#39;s the default traits of the queue, which contain the constants and malloc/free functions used by the queue. There&#39;s the producer and consumer tokens. Then there&#39;s the queue&#39;s public API itself, starting with the constructor, destructor, and swap/assignment methods. There&#39;s the public enqueue methods, which are all wrappers around a small set of private enqueue methods found later on. There&#39;s the dequeue methods, which are defined inline and are relatively straightforward.&lt;/p&gt; &#xA;&lt;p&gt;Then there&#39;s all the main internal data structures. First, there&#39;s a lock-free free list, used for recycling spent blocks (elements are enqueued to blocks internally). Then there&#39;s the block structure itself, which has two different ways of tracking whether it&#39;s fully emptied or not (remember, given two parallel consumers, there&#39;s no way to know which one will finish first) depending on where it&#39;s used. Then there&#39;s a small base class for the two types of internal SPMC producer queues (one for explicit producers that holds onto memory but attempts to be faster, and one for implicit ones which attempt to recycle more memory back into the parent but is a little slower). The explicit producer is defined first, then the implicit one. They both contain the same general four methods: One to enqueue, one to dequeue, one to enqueue in bulk, and one to dequeue in bulk. (Obviously they have constructors and destructors too, and helper methods.) The main difference between them is how the block handling is done (they both use the same blocks, but in different ways, and map indices to them in different ways).&lt;/p&gt; &#xA;&lt;p&gt;Finally, there&#39;s the miscellaneous internal methods: There&#39;s the ones that handle the initial block pool (populated when the queue is constructed), and an abstract block pool that comprises the initial pool and any blocks on the free list. There&#39;s ones that handle the producer list (a lock-free add-only linked list of all the producers in the system). There&#39;s ones that handle the implicit producer lookup table (which is really a sort of specialized TLS lookup). And then there&#39;s some helper methods for allocating and freeing objects, and the data members of the queue itself, followed lastly by the free-standing swap functions.&lt;/p&gt;</summary>
  </entry>
</feed>