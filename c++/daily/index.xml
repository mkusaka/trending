<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-04T01:31:00Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>tensorflow/serving</title>
    <updated>2022-08-04T01:31:00Z</updated>
    <id>tag:github.com,2022-08-04:/tensorflow/serving</id>
    <link href="https://github.com/tensorflow/serving" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A flexible, high-performance serving system for machine learning models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TensorFlow Serving&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/ubuntu.html&#34;&gt;&lt;img src=&#34;https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/ubuntu.svg?sanitize=true&#34; alt=&#34;Ubuntu Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/ubuntu-tf-head.html&#34;&gt;&lt;img src=&#34;https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/ubuntu-tf-head.svg?sanitize=true&#34; alt=&#34;Ubuntu Build Status at TF HEAD&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/docker-cpu-nightly.svg?sanitize=true&#34; alt=&#34;Docker CPU Nightly Build Status&#34;&gt; &lt;img src=&#34;https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/docker-gpu-nightly.svg?sanitize=true&#34; alt=&#34;Docker GPU Nightly Build Status&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. It deals with the &lt;em&gt;inference&lt;/em&gt; aspect of machine learning, taking models after &lt;em&gt;training&lt;/em&gt; and managing their lifetimes, providing clients with versioned access via a high-performance, reference-counted lookup table. TensorFlow Serving provides out-of-the-box integration with TensorFlow models, but can be easily extended to serve other types of models and data.&lt;/p&gt; &#xA;&lt;p&gt;To note a few features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Can serve multiple models, or multiple versions of the same model simultaneously&lt;/li&gt; &#xA; &lt;li&gt;Exposes both gRPC as well as HTTP inference endpoints&lt;/li&gt; &#xA; &lt;li&gt;Allows deployment of new model versions without changing any client code&lt;/li&gt; &#xA; &lt;li&gt;Supports canarying new versions and A/B testing experimental models&lt;/li&gt; &#xA; &lt;li&gt;Adds minimal latency to inference time due to efficient, low-overhead implementation&lt;/li&gt; &#xA; &lt;li&gt;Features a scheduler that groups individual inference requests into batches for joint execution on GPU, with configurable latency controls&lt;/li&gt; &#xA; &lt;li&gt;Supports many &lt;em&gt;servables&lt;/em&gt;: Tensorflow models, embeddings, vocabularies, feature transformations and even non-Tensorflow-based machine learning models&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Serve a Tensorflow model in 60 seconds&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Download the TensorFlow Serving Docker image and repo&#xA;docker pull tensorflow/serving&#xA;&#xA;git clone https://github.com/tensorflow/serving&#xA;# Location of demo models&#xA;TESTDATA=&#34;$(pwd)/serving/tensorflow_serving/servables/tensorflow/testdata&#34;&#xA;&#xA;# Start TensorFlow Serving container and open the REST API port&#xA;docker run -t --rm -p 8501:8501 \&#xA;    -v &#34;$TESTDATA/saved_model_half_plus_two_cpu:/models/half_plus_two&#34; \&#xA;    -e MODEL_NAME=half_plus_two \&#xA;    tensorflow/serving &amp;amp;&#xA;&#xA;# Query the model using the predict API&#xA;curl -d &#39;{&#34;instances&#34;: [1.0, 2.0, 5.0]}&#39; \&#xA;    -X POST http://localhost:8501/v1/models/half_plus_two:predict&#xA;&#xA;# Returns =&amp;gt; { &#34;predictions&#34;: [2.5, 3.0, 4.5] }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;End-to-End Training &amp;amp; Serving Tutorial&lt;/h2&gt; &#xA;&lt;p&gt;Refer to the official Tensorflow documentations site for &lt;a href=&#34;https://www.tensorflow.org/tfx/tutorials/serving/rest_simple&#34;&gt;a complete tutorial to train and serve a Tensorflow Model&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;h3&gt;Set up&lt;/h3&gt; &#xA;&lt;p&gt;The easiest and most straight-forward way of using TensorFlow Serving is with Docker images. We highly recommend this route unless you have specific needs that are not addressed by running in a container.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/docker.md&#34;&gt;Install Tensorflow Serving using Docker&lt;/a&gt; &lt;em&gt;(Recommended)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/setup.md&#34;&gt;Install Tensorflow Serving without Docker&lt;/a&gt; &lt;em&gt;(Not Recommended)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/building_with_docker.md&#34;&gt;Build Tensorflow Serving from Source with Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/serving_kubernetes.md&#34;&gt;Deploy Tensorflow Serving on Kubernetes&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Use&lt;/h3&gt; &#xA;&lt;h4&gt;Export your Tensorflow model&lt;/h4&gt; &#xA;&lt;p&gt;In order to serve a Tensorflow model, simply export a SavedModel from your Tensorflow program. &lt;a href=&#34;https://github.com/tensorflow/tensorflow/raw/master/tensorflow/python/saved_model/README.md&#34;&gt;SavedModel&lt;/a&gt; is a language-neutral, recoverable, hermetic serialization format that enables higher-level systems and tools to produce, consume, and transform TensorFlow models.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://www.tensorflow.org/guide/saved_model#save_and_restore_models&#34;&gt;Tensorflow documentation&lt;/a&gt; for detailed instructions on how to export SavedModels.&lt;/p&gt; &#xA;&lt;h4&gt;Configure and Use Tensorflow Serving&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/serving_basic.md&#34;&gt;Follow a tutorial on Serving Tensorflow models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/serving_config.md&#34;&gt;Configure Tensorflow Serving to make it fit your serving use case&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Read the &lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/performance.md&#34;&gt;Performance Guide&lt;/a&gt; and learn how to &lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/tensorboard.md&#34;&gt;use TensorBoard to profile and optimize inference requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Read the &lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/api_rest.md&#34;&gt;REST API Guide&lt;/a&gt; or &lt;a href=&#34;https://github.com/tensorflow/serving/tree/master/tensorflow_serving/apis&#34;&gt;gRPC API definition&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/saved_model_warmup.md&#34;&gt;Use SavedModel Warmup if initial inference requests are slow due to lazy initialization of graph&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/signature_defs.md&#34;&gt;If encountering issues regarding model signatures, please read the SignatureDef documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;If using a model with custom ops, &lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/custom_op.md&#34;&gt;learn how to serve models with custom ops&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Extend&lt;/h3&gt; &#xA;&lt;p&gt;Tensorflow Serving&#39;s architecture is highly modular. You can use some parts individually (e.g. batch scheduling) and/or extend it to serve new use cases.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/building_with_docker.md&#34;&gt;Ensure you are familiar with building Tensorflow Serving&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/architecture.md&#34;&gt;Learn about Tensorflow Serving&#39;s architecture&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/tfx/serving/api_docs/cc/&#34;&gt;Explore the Tensorflow Serving C++ API reference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/custom_servable.md&#34;&gt;Create a new type of Servable&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/tensorflow_serving/g3doc/custom_source.md&#34;&gt;Create a custom Source of Servable versions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;If you&#39;d like to contribute to TensorFlow Serving, be sure to review the &lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/serving/master/CONTRIBUTING.md&#34;&gt;contribution guidelines&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;For more information&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the official &lt;a href=&#34;http://tensorflow.org&#34;&gt;TensorFlow website&lt;/a&gt; for more information.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>zeux/meshoptimizer</title>
    <updated>2022-08-04T01:31:00Z</updated>
    <id>tag:github.com,2022-08-04:/zeux/meshoptimizer</id>
    <link href="https://github.com/zeux/meshoptimizer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Mesh optimization library that makes meshes smaller and faster to render&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🐇 meshoptimizer &lt;a href=&#34;https://github.com/zeux/meshoptimizer/actions&#34;&gt;&lt;img src=&#34;https://github.com/zeux/meshoptimizer/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;Actions Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/zeux/meshoptimizer?branch=master&#34;&gt;&lt;img src=&#34;https://codecov.io/github/zeux/meshoptimizer/coverage.svg?branch=master&#34; alt=&#34;codecov.io&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true&#34; alt=&#34;MIT&#34;&gt; &lt;a href=&#34;https://github.com/zeux/meshoptimizer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/repo-github-green.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;h2&gt;Purpose&lt;/h2&gt; &#xA;&lt;p&gt;When a GPU renders triangle meshes, various stages of the GPU pipeline have to process vertex and index data. The efficiency of these stages depends on the data you feed to them; this library provides algorithms to help optimize meshes for these stages, as well as algorithms to reduce the mesh complexity and storage overhead.&lt;/p&gt; &#xA;&lt;p&gt;The library provides a C and C++ interface for all algorithms; you can use it from C/C++ or from other languages via FFI (such as P/Invoke). If you want to use this library from Rust, you should use &lt;a href=&#34;https://crates.io/crates/meshopt&#34;&gt;meshopt crate&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zeux/meshoptimizer/master/gltf&#34;&gt;gltfpack&lt;/a&gt;, which is a tool that can automatically optimize glTF files, is developed and distributed alongside the library.&lt;/p&gt; &#xA;&lt;h2&gt;Installing&lt;/h2&gt; &#xA;&lt;p&gt;meshoptimizer is hosted on GitHub; you can download the latest release using git:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone -b v0.18 https://github.com/zeux/meshoptimizer.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively you can &lt;a href=&#34;https://github.com/zeux/meshoptimizer/archive/v0.15.zip&#34;&gt;download the .zip archive from GitHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The library is also available as a package (&lt;a href=&#34;https://aur.archlinux.org/packages/meshoptimizer/&#34;&gt;ArchLinux&lt;/a&gt;, &lt;a href=&#34;https://packages.debian.org/libmeshoptimizer&#34;&gt;Debian&lt;/a&gt;, &lt;a href=&#34;https://packages.ubuntu.com/libmeshoptimizer&#34;&gt;Ubuntu&lt;/a&gt;, &lt;a href=&#34;https://github.com/microsoft/vcpkg/tree/master/ports/meshoptimizer&#34;&gt;Vcpkg&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;Installing gltfpack&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;gltfpack&lt;/code&gt; is a CLI tool for optimizing meshes using meshoptimizer.&lt;/p&gt; &#xA;&lt;p&gt;You can download a pre-built binary for gltfpack on &lt;a href=&#34;https://github.com/zeux/meshoptimizer/releases&#34;&gt;Releases page&lt;/a&gt;, or install &lt;a href=&#34;https://www.npmjs.com/package/gltfpack&#34;&gt;npm package&lt;/a&gt; as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm install -g gltfpack&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also find prebuilt binaries of &lt;code&gt;gltfpack&lt;/code&gt; built from master on &lt;a href=&#34;https://github.com/zeux/meshoptimizer/actions&#34;&gt;Actions page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zeux/meshoptimizer/master/gltf/README.md&#34;&gt;Learn more about gltfpack&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;meshoptimizer is distributed as a set of C++ source files. To include it into your project, you can use one of the two options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use CMake to build the library (either as a standalone project or as part of your project)&lt;/li&gt; &#xA; &lt;li&gt;Add source files to your project&#39;s build system&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The source files are organized in such a way that you don&#39;t need to change your build-system settings, and you only need to add the files for the algorithms you use.&lt;/p&gt; &#xA;&lt;h2&gt;Pipeline&lt;/h2&gt; &#xA;&lt;p&gt;When optimizing a mesh, you should typically feed it through a set of optimizations (the order is important!):&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Indexing&lt;/li&gt; &#xA; &lt;li&gt;(optional, discussed last) Simplification&lt;/li&gt; &#xA; &lt;li&gt;Vertex cache optimization&lt;/li&gt; &#xA; &lt;li&gt;Overdraw optimization&lt;/li&gt; &#xA; &lt;li&gt;Vertex fetch optimization&lt;/li&gt; &#xA; &lt;li&gt;Vertex quantization&lt;/li&gt; &#xA; &lt;li&gt;(optional) Vertex/index buffer compression&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Indexing&lt;/h2&gt; &#xA;&lt;p&gt;Most algorithms in this library assume that a mesh has a vertex buffer and an index buffer. For algorithms to work well and also for GPU to render your mesh efficiently, the vertex buffer has to have no redundant vertices; you can generate an index buffer from an unindexed vertex buffer or reindex an existing (potentially redundant) index buffer as follows:&lt;/p&gt; &#xA;&lt;p&gt;First, generate a remap table from your existing vertex (and, optionally, index) data:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;size_t index_count = face_count * 3;&#xA;std::vector&amp;lt;unsigned int&amp;gt; remap(index_count); // allocate temporary memory for the remap table&#xA;size_t vertex_count = meshopt_generateVertexRemap(&amp;amp;remap[0], NULL, index_count, &amp;amp;unindexed_vertices[0], index_count, sizeof(Vertex));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that in this case we only have an unindexed vertex buffer; the remap table is generated based on binary equivalence of the input vertices, so the resulting mesh will render the same way. Binary equivalence considers all input bytes, including padding which should be zero-initialized if the vertex structure has gaps.&lt;/p&gt; &#xA;&lt;p&gt;After generating the remap table, you can allocate space for the target vertex buffer (&lt;code&gt;vertex_count&lt;/code&gt; elements) and index buffer (&lt;code&gt;index_count&lt;/code&gt; elements) and generate them:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;meshopt_remapIndexBuffer(indices, NULL, index_count, &amp;amp;remap[0]);&#xA;meshopt_remapVertexBuffer(vertices, &amp;amp;unindexed_vertices[0], index_count, sizeof(Vertex), &amp;amp;remap[0]);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can then further optimize the resulting buffers by calling the other functions on them in-place.&lt;/p&gt; &#xA;&lt;h2&gt;Vertex cache optimization&lt;/h2&gt; &#xA;&lt;p&gt;When the GPU renders the mesh, it has to run the vertex shader for each vertex; usually GPUs have a built-in fixed size cache that stores the transformed vertices (the result of running the vertex shader), and uses this cache to reduce the number of vertex shader invocations. This cache is usually small, 16-32 vertices, and can have different replacement policies; to use this cache efficiently, you have to reorder your triangles to maximize the locality of reused vertex references like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;meshopt_optimizeVertexCache(indices, indices, index_count, vertex_count);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Overdraw optimization&lt;/h2&gt; &#xA;&lt;p&gt;After transforming the vertices, GPU sends the triangles for rasterization which results in generating pixels that are usually first ran through the depth test, and pixels that pass it get the pixel shader executed to generate the final color. As pixel shaders get more expensive, it becomes more and more important to reduce overdraw. While in general improving overdraw requires view-dependent operations, this library provides an algorithm to reorder triangles to minimize the overdraw from all directions, which you should run after vertex cache optimization like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;meshopt_optimizeOverdraw(indices, indices, index_count, &amp;amp;vertices[0].x, vertex_count, sizeof(Vertex), 1.05f);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The overdraw optimizer needs to read vertex positions as a float3 from the vertex; the code snippet above assumes that the vertex stores position as &lt;code&gt;float x, y, z&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When performing the overdraw optimization you have to specify a floating-point threshold parameter. The algorithm tries to maintain a balance between vertex cache efficiency and overdraw; the threshold determines how much the algorithm can compromise the vertex cache hit ratio, with 1.05 meaning that the resulting ratio should be at most 5% worse than before the optimization.&lt;/p&gt; &#xA;&lt;h2&gt;Vertex fetch optimization&lt;/h2&gt; &#xA;&lt;p&gt;After the final triangle order has been established, we still can optimize the vertex buffer for memory efficiency. Before running the vertex shader GPU has to fetch the vertex attributes from the vertex buffer; the fetch is usually backed by a memory cache, and as such optimizing the data for the locality of memory access is important. You can do this by running this code:&lt;/p&gt; &#xA;&lt;p&gt;To optimize the index/vertex buffers for vertex fetch efficiency, call:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;meshopt_optimizeVertexFetch(vertices, indices, index_count, vertices, vertex_count, sizeof(Vertex));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will reorder the vertices in the vertex buffer to try to improve the locality of reference, and rewrite the indices in place to match; if the vertex data is stored using multiple streams, you should use &lt;code&gt;meshopt_optimizeVertexFetchRemap&lt;/code&gt; instead. This optimization has to be performed on the final index buffer since the optimal vertex order depends on the triangle order.&lt;/p&gt; &#xA;&lt;p&gt;Note that the algorithm does not try to model cache replacement precisely and instead just orders vertices in the order of use, which generally produces results that are close to optimal.&lt;/p&gt; &#xA;&lt;h2&gt;Vertex quantization&lt;/h2&gt; &#xA;&lt;p&gt;To optimize memory bandwidth when fetching the vertex data even further, and to reduce the amount of memory required to store the mesh, it is often beneficial to quantize the vertex attributes to smaller types. While this optimization can technically run at any part of the pipeline (and sometimes doing quantization as the first step can improve indexing by merging almost identical vertices), it generally is easier to run this after all other optimizations since some of them require access to float3 positions.&lt;/p&gt; &#xA;&lt;p&gt;Quantization is usually domain specific; it&#39;s common to quantize normals using 3 8-bit integers but you can use higher-precision quantization (for example using 10 bits per component in a 10_10_10_2 format), or a different encoding to use just 2 components. For positions and texture coordinate data the two most common storage formats are half precision floats, and 16-bit normalized integers that encode the position relative to the AABB of the mesh or the UV bounding rectangle.&lt;/p&gt; &#xA;&lt;p&gt;The number of possible combinations here is very large but this library does provide the building blocks, specifically functions to quantize floating point values to normalized integers, as well as half-precision floats. For example, here&#39;s how you can quantize a normal:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;unsigned int normal =&#xA;&#x9;(meshopt_quantizeUnorm(v.nx, 10) &amp;lt;&amp;lt; 20) |&#xA;&#x9;(meshopt_quantizeUnorm(v.ny, 10) &amp;lt;&amp;lt; 10) |&#xA;&#x9; meshopt_quantizeUnorm(v.nz, 10);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and here&#39;s how you can quantize a position:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;unsigned short px = meshopt_quantizeHalf(v.x);&#xA;unsigned short py = meshopt_quantizeHalf(v.y);&#xA;unsigned short pz = meshopt_quantizeHalf(v.z);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Vertex/index buffer compression&lt;/h2&gt; &#xA;&lt;p&gt;In case storage size or transmission bandwidth is of importance, you might want to additionally compress vertex and index data. While several mesh compression libraries, like Google Draco, are available, they typically are designed to maximize the compression ratio at the cost of disturbing the vertex/index order (which makes the meshes inefficient to render on GPU) or decompression performance. They also frequently don&#39;t support custom game-ready quantized vertex formats and thus require to re-quantize the data after loading it, introducing extra quantization errors and making decoding slower.&lt;/p&gt; &#xA;&lt;p&gt;Alternatively you can use general purpose compression libraries like zstd or Oodle to compress vertex/index data - however these compressors aren&#39;t designed to exploit redundancies in vertex/index data and as such compression rates can be unsatisfactory.&lt;/p&gt; &#xA;&lt;p&gt;To that end, this library provides algorithms to &#34;encode&#34; vertex and index data. The result of the encoding is generally significantly smaller than initial data, and remains compressible with general purpose compressors - so you can either store encoded data directly (for modest compression ratios and maximum decoding performance), or further compress it with zstd/Oodle to maximize compression ratio.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: this compression scheme is available as a glTF extension &lt;a href=&#34;https://github.com/KhronosGroup/glTF/raw/main/extensions/2.0/Vendor/EXT_meshopt_compression/README.md&#34;&gt;EXT_meshopt_compression&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;To encode, you need to allocate target buffers (preferably using the worst case bound) and call encoding functions:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::vector&amp;lt;unsigned char&amp;gt; vbuf(meshopt_encodeVertexBufferBound(vertex_count, sizeof(Vertex)));&#xA;vbuf.resize(meshopt_encodeVertexBuffer(&amp;amp;vbuf[0], vbuf.size(), vertices, vertex_count, sizeof(Vertex)));&#xA;&#xA;std::vector&amp;lt;unsigned char&amp;gt; ibuf(meshopt_encodeIndexBufferBound(index_count, vertex_count));&#xA;ibuf.resize(meshopt_encodeIndexBuffer(&amp;amp;ibuf[0], ibuf.size(), indices, index_count));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can then either serialize &lt;code&gt;vbuf&lt;/code&gt;/&lt;code&gt;ibuf&lt;/code&gt; as is, or compress them further. To decode the data at runtime, call decoding functions:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;int resvb = meshopt_decodeVertexBuffer(vertices, vertex_count, sizeof(Vertex), &amp;amp;vbuf[0], vbuf.size());&#xA;int resib = meshopt_decodeIndexBuffer(indices, index_count, &amp;amp;ibuf[0], ibuf.size());&#xA;assert(resvb == 0 &amp;amp;&amp;amp; resib == 0);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that vertex encoding assumes that vertex buffer was optimized for vertex fetch, and that vertices are quantized; index encoding assumes that the vertex/index buffers were optimized for vertex cache and vertex fetch. Feeding unoptimized data into the encoders will produce poor compression ratios. Both codecs are lossless - the only lossy step is quantization that happens before encoding.&lt;/p&gt; &#xA;&lt;p&gt;To reduce the data size further, it&#39;s recommended to use &lt;code&gt;meshopt_optimizeVertexCacheStrip&lt;/code&gt; instead of &lt;code&gt;meshopt_optimizeVertexCache&lt;/code&gt; when optimizing for vertex cache, and to use new index codec version (&lt;code&gt;meshopt_encodeIndexVersion(1)&lt;/code&gt;). This trades off some efficiency in vertex transform for smaller vertex and index data.&lt;/p&gt; &#xA;&lt;p&gt;Decoding functions are heavily optimized and can directly target write-combined memory; you can expect both decoders to run at 1-3 GB/s on modern desktop CPUs. Compression ratios depend on the data; vertex data compression ratio is typically around 2-4x (compared to already quantized data), index data compression ratio is around 5-6x (compared to raw 16-bit index data). General purpose lossless compressors can further improve on these results.&lt;/p&gt; &#xA;&lt;p&gt;Index buffer codec only supports triangle list topology; when encoding triangle strips or line lists, use &lt;code&gt;meshopt_encodeIndexSequence&lt;/code&gt;/&lt;code&gt;meshopt_decodeIndexSequence&lt;/code&gt; instead. This codec typically encodes indices into ~1 byte per index, but compressing the results further with a general purpose compressor can improve the results to 1-3 bits per index.&lt;/p&gt; &#xA;&lt;p&gt;The following guarantees on data compatibility are provided for point releases (&lt;em&gt;no&lt;/em&gt; guarantees are given for development branch):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Data encoded with older versions of the library can always be decoded with newer versions;&lt;/li&gt; &#xA; &lt;li&gt;Data encoded with newer versions of the library can be decoded with older versions, provided that encoding versions are set correctly; if binary stability of encoded data is important, use &lt;code&gt;meshopt_encodeVertexVersion&lt;/code&gt; and &lt;code&gt;meshopt_encodeIndexVersion&lt;/code&gt; to &#39;pin&#39; the data versions.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Due to a very high decoding performance and compatibility with general purpose lossless compressors, the compression is a good fit for the use on the web. To that end, meshoptimizer provides both vertex and index decoders compiled into WebAssembly and wrapped into a module with JavaScript-friendly interface, &lt;code&gt;js/meshopt_decoder.js&lt;/code&gt;, that you can use to decode meshes that were encoded offline:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// ready is a Promise that is resolved when (asynchronous) WebAssembly compilation finishes&#xA;await MeshoptDecoder.ready;&#xA;&#xA;// decode from *Data (Uint8Array) into *Buffer (Uint8Array)&#xA;MeshoptDecoder.decodeVertexBuffer(vertexBuffer, vertexCount, vertexSize, vertexData);&#xA;MeshoptDecoder.decodeIndexBuffer(indexBuffer, indexCount, indexSize, indexData);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://meshoptimizer.org/demo/&#34;&gt;Usage example&lt;/a&gt; is available, with source in &lt;code&gt;demo/index.html&lt;/code&gt;; this example uses .GLB files encoded using &lt;code&gt;gltfpack&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Point cloud compression&lt;/h2&gt; &#xA;&lt;p&gt;The vertex encoding algorithms can be used to compress arbitrary streams of attribute data; one other use case besides triangle meshes is point cloud data. Typically point clouds come with position, color and possibly other attributes but don&#39;t have an implied point order.&lt;/p&gt; &#xA;&lt;p&gt;To compress point clouds efficiently, it&#39;s recommended to first preprocess the points by sorting them using the spatial sort algorithm:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::vector&amp;lt;unsigned int&amp;gt; remap(point_count);&#xA;meshopt_spatialSortRemap(&amp;amp;remap[0], positions, point_count, sizeof(vec3));&#xA;&#xA;// for each attribute stream&#xA;meshopt_remapVertexBuffer(positions, positions, point_count, sizeof(vec3), &amp;amp;remap[0]);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After this the resulting arrays should be quantized (e.g. using 16-bit fixed point numbers for positions and 8-bit color components), and the result can be compressed using &lt;code&gt;meshopt_encodeVertexBuffer&lt;/code&gt; as described in the previous section. To decompress, &lt;code&gt;meshopt_decodeVertexBuffer&lt;/code&gt; will recover the quantized data that can be used directly or converted back to original floating-point data. The compression ratio depends on the nature of source data, for colored points it&#39;s typical to get 35-40 bits per point as a result.&lt;/p&gt; &#xA;&lt;h2&gt;Triangle strip conversion&lt;/h2&gt; &#xA;&lt;p&gt;On most hardware, indexed triangle lists are the most efficient way to drive the GPU. However, in some cases triangle strips might prove beneficial:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;On some older GPUs, triangle strips may be a bit more efficient to render&lt;/li&gt; &#xA; &lt;li&gt;On extremely memory constrained systems, index buffers for triangle strips could save a bit of memory&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This library provides an algorithm for converting a vertex cache optimized triangle list to a triangle strip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::vector&amp;lt;unsigned int&amp;gt; strip(meshopt_stripifyBound(index_count));&#xA;unsigned int restart_index = ~0u;&#xA;size_t strip_size = meshopt_stripify(&amp;amp;strip[0], indices, index_count, vertex_count, restart_index);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Typically you should expect triangle strips to have ~50-60% of indices compared to triangle lists (~1.5-1.8 indices per triangle) and have ~5% worse ACMR. Note that triangle strips can be stitched with or without restart index support. Using restart indices can result in ~10% smaller index buffers, but on some GPUs restart indices may result in decreased performance.&lt;/p&gt; &#xA;&lt;p&gt;To reduce the triangle strip size further, it&#39;s recommended to use &lt;code&gt;meshopt_optimizeVertexCacheStrip&lt;/code&gt; instead of &lt;code&gt;meshopt_optimizeVertexCache&lt;/code&gt; when optimizing for vertex cache. This trades off some efficiency in vertex transform for smaller index buffers.&lt;/p&gt; &#xA;&lt;h2&gt;Deinterleaved geometry&lt;/h2&gt; &#xA;&lt;p&gt;All of the examples above assume that geometry is represented as a single vertex buffer and a single index buffer. This requires storing all vertex attributes - position, normal, texture coordinate, skinning weights etc. - in a single contiguous struct. However, in some cases using multiple vertex streams may be preferable. In particular, if some passes require only positional data - such as depth pre-pass or shadow map - then it may be beneficial to split it from the rest of the vertex attributes to make sure the bandwidth use during these passes is optimal. On some mobile GPUs a position-only attribute stream also improves efficiency of tiling algorithms.&lt;/p&gt; &#xA;&lt;p&gt;Most of the functions in this library either only need the index buffer (such as vertex cache optimization) or only need positional information (such as overdraw optimization). However, several tasks require knowledge about all vertex attributes.&lt;/p&gt; &#xA;&lt;p&gt;For indexing, &lt;code&gt;meshopt_generateVertexRemap&lt;/code&gt; assumes that there&#39;s just one vertex stream; when multiple vertex streams are used, it&#39;s necessary to use &lt;code&gt;meshopt_generateVertexRemapMulti&lt;/code&gt; as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;meshopt_Stream streams[] = {&#xA;    {&amp;amp;unindexed_pos[0], sizeof(float) * 3, sizeof(float) * 3},&#xA;    {&amp;amp;unindexed_nrm[0], sizeof(float) * 3, sizeof(float) * 3},&#xA;    {&amp;amp;unindexed_uv[0], sizeof(float) * 2, sizeof(float) * 2},&#xA;};&#xA;&#xA;std::vector&amp;lt;unsigned int&amp;gt; remap(index_count);&#xA;size_t vertex_count = meshopt_generateVertexRemapMulti(&amp;amp;remap[0], NULL, index_count, index_count, streams, sizeof(streams) / sizeof(streams[0]));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After this &lt;code&gt;meshopt_remapVertexBuffer&lt;/code&gt; needs to be called once for each vertex stream to produce the correctly reindexed stream.&lt;/p&gt; &#xA;&lt;p&gt;Instead of calling &lt;code&gt;meshopt_optimizeVertexFetch&lt;/code&gt; for reordering vertices in a single vertex buffer for efficiency, calling &lt;code&gt;meshopt_optimizeVertexFetchRemap&lt;/code&gt; and then calling &lt;code&gt;meshopt_remapVertexBuffer&lt;/code&gt; for each stream again is recommended.&lt;/p&gt; &#xA;&lt;p&gt;Finally, when compressing vertex data, &lt;code&gt;meshopt_encodeVertexBuffer&lt;/code&gt; should be used on each vertex stream separately - this allows the encoder to best utilize corellation between attribute values for different vertices.&lt;/p&gt; &#xA;&lt;h2&gt;Simplification&lt;/h2&gt; &#xA;&lt;p&gt;All algorithms presented so far don&#39;t affect visual appearance at all, with the exception of quantization that has minimal controlled impact. However, fundamentally the most effective way at reducing the rendering or transmission cost of a mesh is to make the mesh simpler.&lt;/p&gt; &#xA;&lt;p&gt;This library provides two simplification algorithms that reduce the number of triangles in the mesh. Given a vertex and an index buffer, they generate a second index buffer that uses existing vertices in the vertex buffer. This index buffer can be used directly for rendering with the original vertex buffer (preferably after vertex cache optimization), or a new compact vertex/index buffer can be generated using &lt;code&gt;meshopt_optimizeVertexFetch&lt;/code&gt; that uses the optimal number and order of vertices.&lt;/p&gt; &#xA;&lt;p&gt;The first simplification algorithm, &lt;code&gt;meshopt_simplify&lt;/code&gt;, follows the topology of the original mesh in an attempt to preserve attribute seams, borders and overall appearance. For meshes with inconsistent topology or many seams, such as faceted meshes, it can result in simplifier getting &#34;stuck&#34; and not being able to simplify the mesh fully; it&#39;s recommended to preprocess the index buffer with &lt;code&gt;meshopt_generateShadowIndexBuffer&lt;/code&gt; to discard any vertex attributes that aren&#39;t critical and can be rebuilt later such as normals.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;float threshold = 0.2f;&#xA;size_t target_index_count = size_t(index_count * threshold);&#xA;float target_error = 1e-2f;&#xA;&#xA;std::vector&amp;lt;unsigned int&amp;gt; lod(index_count);&#xA;float lod_error = 0.f;&#xA;lod.resize(meshopt_simplify(&amp;amp;lod[0], indices, index_count, &amp;amp;vertices[0].x, vertex_count, sizeof(Vertex),&#xA;    target_index_count, target_error, &amp;amp;lod_error));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Target error is an approximate measure of the deviation from the original mesh using distance normalized to 0..1 (so 1e-2f means that simplifier will try to maintain the error to be below 1% of the mesh extents). Note that because of topological restrictions and error bounds simplifier isn&#39;t guaranteed to reach the target index count and can stop earlier.&lt;/p&gt; &#xA;&lt;p&gt;The second simplification algorithm, &lt;code&gt;meshopt_simplifySloppy&lt;/code&gt;, doesn&#39;t follow the topology of the original mesh. This means that it doesn&#39;t preserve attribute seams or borders, but it can collapse internal details that are too small to matter better because it can merge mesh features that are topologically disjoint but spatially close.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;float threshold = 0.2f;&#xA;size_t target_index_count = size_t(index_count * threshold);&#xA;float target_error = 1e-1f;&#xA;&#xA;std::vector&amp;lt;unsigned int&amp;gt; lod(index_count);&#xA;float lod_error = 0.f;&#xA;lod.resize(meshopt_simplifySloppy(&amp;amp;lod[0], indices, index_count, &amp;amp;vertices[0].x, vertex_count, sizeof(Vertex),&#xA;    target_index_count, target_error, &amp;amp;lod_error));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This algorithm will not stop early due to topology restrictions but can still do so if target index count can&#39;t be reached without introducing an error larger than target. It is 5-6x faster than &lt;code&gt;meshopt_simplify&lt;/code&gt; when simplification ratio is large, and is able to reach ~20M triangles/sec on a desktop CPU (&lt;code&gt;meshopt_simplify&lt;/code&gt; works at ~3M triangles/sec).&lt;/p&gt; &#xA;&lt;p&gt;When a sequence of LOD meshes is generated that all use the original vertex buffer, care must be taken to order vertices optimally to not penalize mobile GPU architectures that are only capable of transforming a sequential vertex buffer range. It&#39;s recommended in this case to first optimize each LOD for vertex cache, then assemble all LODs in one large index buffer starting from the coarsest LOD (the one with fewest triangles), and call &lt;code&gt;meshopt_optimizeVertexFetch&lt;/code&gt; on the final large index buffer. This will make sure that coarser LODs require a smaller vertex range and are efficient wrt vertex fetch and transform.&lt;/p&gt; &#xA;&lt;p&gt;Both algorithms can also return the resulting normalized deviation that can be used to choose the correct level of detail based on screen size or solid angle; the error can be converted to world space by multiplying by the scaling factor returned by &lt;code&gt;meshopt_simplifyScale&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Mesh shading&lt;/h2&gt; &#xA;&lt;p&gt;Modern GPUs are beginning to deviate from the traditional rasterization model. NVidia GPUs starting from Turing and AMD GPUs starting from RDNA2 provide a new programmable geometry pipeline that, instead of being built around index buffers and vertex shaders, is built around mesh shaders - a new shader type that allows to provide a batch of work to the rasterizer.&lt;/p&gt; &#xA;&lt;p&gt;Using mesh shaders in context of traditional mesh rendering provides an opportunity to use a variety of optimization techniques, starting from more efficient vertex reuse, using various forms of culling (e.g. cluster frustum or occlusion culling) and in-memory compression to maximize the utilization of GPU hardware. Beyond traditional rendering mesh shaders provide a richer programming model that can synthesize new geometry more efficiently than common alternatives such as geometry shaders. Mesh shading can be accessed via Vulkan or Direct3D 12 APIs; please refer to &lt;a href=&#34;https://developer.nvidia.com/blog/introduction-turing-mesh-shaders/&#34;&gt;Introduction to Turing Mesh Shaders&lt;/a&gt; and &lt;a href=&#34;https://devblogs.microsoft.com/directx/coming-to-directx-12-mesh-shaders-and-amplification-shaders-reinventing-the-geometry-pipeline/&#34;&gt;Mesh Shaders and Amplification Shaders: Reinventing the Geometry Pipeline&lt;/a&gt; for additional information.&lt;/p&gt; &#xA;&lt;p&gt;To use mesh shaders for conventional rendering efficiently, geometry needs to be converted into a series of meshlets; each meshlet represents a small subset of the original mesh and comes with a small set of vertices and a separate micro-index buffer that references vertices in the meshlet. This information can be directly fed to the rasterizer from the mesh shader. This library provides algorithms to create meshlet data for a mesh, and - assuming geometry is static - can compute bounding information that can be used to perform cluster culling, a technique that can reject a meshlet if it&#39;s invisible on screen.&lt;/p&gt; &#xA;&lt;p&gt;To generate meshlet data, this library provides two algorithms - &lt;code&gt;meshopt_buildMeshletsScan&lt;/code&gt;, which creates the meshlet data using a vertex cache-optimized index buffer as a starting point by greedily aggregating consecutive triangles until they go over the meshlet limits, and &lt;code&gt;meshopt_buildMeshlets&lt;/code&gt;, which doesn&#39;t depend on any other algorithms and tries to balance topological efficiency (by maximizing vertex reuse inside meshlets) with culling efficiency (by minimizing meshlet radius and triangle direction divergence). &lt;code&gt;meshopt_buildMeshlets&lt;/code&gt; is recommended in cases when the resulting meshlet data will be used in cluster culling algorithms.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;const size_t max_vertices = 64;&#xA;const size_t max_triangles = 124;&#xA;const float cone_weight = 0.0f;&#xA;&#xA;size_t max_meshlets = meshopt_buildMeshletsBound(indices.size(), max_vertices, max_triangles);&#xA;std::vector&amp;lt;meshopt_Meshlet&amp;gt; meshlets(max_meshlets);&#xA;std::vector&amp;lt;unsigned int&amp;gt; meshlet_vertices(max_meshlets * max_vertices);&#xA;std::vector&amp;lt;unsigned char&amp;gt; meshlet_triangles(max_meshlets * max_triangles * 3);&#xA;&#xA;size_t meshlet_count = meshopt_buildMeshlets(meshlets.data(), meshlet_vertices.data(), meshlet_triangles.data(), indices.data(),&#xA;    indices.size(), &amp;amp;vertices[0].x, vertices.size(), sizeof(Vertex), max_vertices, max_triangles, cone_weight);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate the meshlet data, &lt;code&gt;max_vertices&lt;/code&gt; and &lt;code&gt;max_triangles&lt;/code&gt; need to be set within limits supported by the hardware; for NVidia the values of 64 and 124 are recommended. &lt;code&gt;cone_weight&lt;/code&gt; should be left as 0 if cluster cone culling is not used, and set to a value between 0 and 1 to balance cone culling efficiency with other forms of culling like frustum or occlusion culling.&lt;/p&gt; &#xA;&lt;p&gt;Each resulting meshlet refers to a portion of &lt;code&gt;meshlet_vertices&lt;/code&gt; and &lt;code&gt;meshlet_triangles&lt;/code&gt; arrays; this data can be uploaded to GPU and used directly after trimming:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;const meshopt_Meshlet&amp;amp; last = meshlets[meshlet_count - 1];&#xA;&#xA;meshlet_vertices.resize(last.vertex_offset + last.vertex_count);&#xA;meshlet_triangles.resize(last.triangle_offset + ((last.triangle_count * 3 + 3) &amp;amp; ~3));&#xA;meshlets.resize(meshlet_count);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;However depending on the application other strategies of storing the data can be useful; for example, &lt;code&gt;meshlet_vertices&lt;/code&gt; serves as indices into the original vertex buffer but it might be worthwhile to generate a mini vertex buffer for each meshlet to remove the extra indirection when accessing vertex data, or it might be desirable to compress vertex data as vertices in each meshlet are likely to be very spatially coherent.&lt;/p&gt; &#xA;&lt;p&gt;After generating the meshlet data, it&#39;s also possible to generate extra data for each meshlet that can be saved and used at runtime to perform cluster culling, where each meshlet can be discarded if it&#39;s guaranteed to be invisible. To generate the data, &lt;code&gt;meshlet_computeMeshletBounds&lt;/code&gt; can be used:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;meshopt_Bounds bounds = meshopt_computeMeshletBounds(&amp;amp;meshlet_vertices[m.vertex_offset], &amp;amp;meshlet_triangles[m.triangle_offset],&#xA;    m.triangle_count, &amp;amp;vertices[0].x, vertices.size(), sizeof(Vertex));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The resulting &lt;code&gt;bounds&lt;/code&gt; values can be used to perform frustum or occlusion culling using the bounding sphere, or cone culling using the cone axis/angle (which will reject the entire meshlet if all triangles are guaranteed to be back-facing from the camera point of view):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;if (dot(normalize(cone_apex - camera_position), cone_axis) &amp;gt;= cone_cutoff) reject();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Efficiency analyzers&lt;/h2&gt; &#xA;&lt;p&gt;While the only way to get precise performance data is to measure performance on the target GPU, it can be valuable to measure the impact of these optimization in a GPU-independent manner. To this end, the library provides analyzers for all three major optimization routines. For each optimization there is a corresponding analyze function, like &lt;code&gt;meshopt_analyzeOverdraw&lt;/code&gt;, that returns a struct with statistics.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;meshopt_analyzeVertexCache&lt;/code&gt; returns vertex cache statistics. The common metric to use is ACMR - average cache miss ratio, which is the ratio of the total number of vertex invocations to the triangle count. The worst-case ACMR is 3 (GPU has to process 3 vertices for each triangle); on regular grids the optimal ACMR approaches 0.5. On real meshes it usually is in [0.5..1.5] range depending on the amount of vertex splits. One other useful metric is ATVR - average transformed vertex ratio - which represents the ratio of vertex shader invocations to the total vertices, and has the best case of 1.0 regardless of mesh topology (each vertex is transformed once).&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;meshopt_analyzeVertexFetch&lt;/code&gt; returns vertex fetch statistics. The main metric it uses is overfetch - the ratio between the number of bytes read from the vertex buffer to the total number of bytes in the vertex buffer. Assuming non-redundant vertex buffers, the best case is 1.0 - each byte is fetched once.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;meshopt_analyzeOverdraw&lt;/code&gt; returns overdraw statistics. The main metric it uses is overdraw - the ratio between the number of pixel shader invocations to the total number of covered pixels, as measured from several different orthographic cameras. The best case for overdraw is 1.0 - each pixel is shaded once.&lt;/p&gt; &#xA;&lt;p&gt;Note that all analyzers use approximate models for the relevant GPU units, so the numbers you will get as the result are only a rough approximation of the actual performance.&lt;/p&gt; &#xA;&lt;h2&gt;Memory management&lt;/h2&gt; &#xA;&lt;p&gt;Many algorithms allocate temporary memory to store intermediate results or accelerate processing. The amount of memory allocated is a function of various input parameters such as vertex count and index count. By default memory is allocated using &lt;code&gt;operator new&lt;/code&gt; and &lt;code&gt;operator delete&lt;/code&gt;; if these operators are overloaded by the application, the overloads will be used instead. Alternatively it&#39;s possible to specify custom allocation/deallocation functions using &lt;code&gt;meshopt_setAllocator&lt;/code&gt;, e.g.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;meshopt_setAllocator(malloc, free);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note that the library expects the allocation function to either throw in case of out-of-memory (in which case the exception will propagate to the caller) or abort, so technically the use of &lt;code&gt;malloc&lt;/code&gt; above isn&#39;t safe. If you want to handle out-of-memory errors without using C++ exceptions, you can use &lt;code&gt;setjmp&lt;/code&gt;/&lt;code&gt;longjmp&lt;/code&gt; instead.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Vertex and index decoders (&lt;code&gt;meshopt_decodeVertexBuffer&lt;/code&gt;, &lt;code&gt;meshopt_decodeIndexBuffer&lt;/code&gt;, &lt;code&gt;meshopt_decodeIndexSequence&lt;/code&gt;) do not allocate memory and work completely within the buffer space provided via arguments.&lt;/p&gt; &#xA;&lt;p&gt;All functions have bounded stack usage that does not exceed 32 KB for any algorithms.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This library is available to anybody free of charge, under the terms of MIT License (see LICENSE.md).&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>google/draco</title>
    <updated>2022-08-04T01:31:00Z</updated>
    <id>tag:github.com,2022-08-04:/google/draco</id>
    <link href="https://github.com/google/draco" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Draco is a library for compressing and decompressing 3D geometric meshes and point clouds. It is intended to improve the storage and transmission of 3D graphics.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;350px&#34; src=&#34;https://raw.githubusercontent.com/google/draco/master/docs/artwork/draco3d-vert.svg?sanitize=true&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/google/draco/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/google/draco/workflows/draco-ci/badge.svg?branch=master&#34; alt=&#34;draco-ci&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;News&lt;/h1&gt; &#xA;&lt;p&gt;Attention GStatic users: the Draco team strongly recommends using the versioned URLs for accessing Draco GStatic content. If you are using the URLs that include the &lt;code&gt;v1/decoders&lt;/code&gt; substring within the URL, edge caching and GStatic propagation delays can result in transient errors that can be difficult to diagnose when new Draco releases are launched. To avoid the issue pin your sites to a versioned release.&lt;/p&gt; &#xA;&lt;h3&gt;Version 1.5.3 release:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Using the versioned &lt;a href=&#34;http://www.gstatic.com&#34;&gt;www.gstatic.com&lt;/a&gt; WASM and Javascript decoders continues to be recommended. To use v1.5.3, use this URL: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.5.3/&#34;&gt;https://www.gstatic.com/draco/versioned/decoders/1.5.3/&lt;/a&gt;*&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Bug fixes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.5.2 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This is the same as v1.5.1 with the following two bug fixes: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fixes DRACO_TRANSCODER_SUPPORTED enabled builds.&lt;/li&gt; &#xA;   &lt;li&gt;ABI version updated.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.5.1 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Adds assertion enabled Emscripten builds to the release, and a subset of the assertion enabled builds to GStatic. See the file listing below.&lt;/li&gt; &#xA; &lt;li&gt;Custom paths to third party dependencies are now supported. See BUILDING.md for more information.&lt;/li&gt; &#xA; &lt;li&gt;The CMake configuration file draco-config.cmake is now tested and known to work for using Draco in Linux, MacOS, and Windows CMake projects. See the &lt;code&gt;install_test&lt;/code&gt; subdirectory of &lt;code&gt;src/draco/tools&lt;/code&gt; for more information.&lt;/li&gt; &#xA; &lt;li&gt;Bug fixes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.5.0 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Adds the draco_transcoder tool. See the section below on the glTF transcoding tool, and BUILDING.md for build and dependency information.&lt;/li&gt; &#xA; &lt;li&gt;Some changes to configuration variables have been made for this release: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The DRACO_GLTF flag has been renamed to DRACO_GLTF_BITSTREAM to help increase understanding of its purpose, which is to limit Draco features to those included in the Draco glTF specification.&lt;/li&gt; &#xA;   &lt;li&gt;Variables exported in CMake via draco-config.cmake and find-draco.cmake (formerly FindDraco.cmake) have been renamed. It&#39;s unlikely that this impacts any existing projects as the aforementioned files were not formed correctly. See &lt;a href=&#34;https://github.com/google/draco/pull/775&#34;&gt;PR775&lt;/a&gt; for full details of the changes.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;A CMake version file has been added.&lt;/li&gt; &#xA; &lt;li&gt;The CMake install target now uses absolute paths direct from CMake instead of building them using CMAKE_INSTALL_PREFIX. This was done to make Draco easier to use for downstream packagers and should have little to no impact on users picking up Draco from source.&lt;/li&gt; &#xA; &lt;li&gt;Certain MSVC warnings have had their levels changed via compiler flag to reduce the amount of noise output by the MSVC compilers. Set MSVC warning level to 4, or define DRACO_DEBUG_MSVC_WARNINGS at CMake configuration time to restore previous behavior.&lt;/li&gt; &#xA; &lt;li&gt;Bug fixes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.4.3 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Using the versioned &lt;a href=&#34;http://www.gstatic.com&#34;&gt;www.gstatic.com&lt;/a&gt; WASM and Javascript decoders continues to be recommended. To use v1.4.3, use this URL: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.4.3/&#34;&gt;https://www.gstatic.com/draco/versioned/decoders/1.4.3/&lt;/a&gt;*&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Bug fixes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.4.1 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Using the versioned &lt;a href=&#34;http://www.gstatic.com&#34;&gt;www.gstatic.com&lt;/a&gt; WASM and Javascript decoders is now recommended. To use v1.4.1, use this URL: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.4.1/&#34;&gt;https://www.gstatic.com/draco/versioned/decoders/1.4.1/&lt;/a&gt;* &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Replace the * with the files to load. E.g.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.4.1/draco_decoder.js&#34;&gt;https://www.gstatic.com/draco/versioned/decoders/1.4.1/draco_decoder.js&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;This works with the v1.3.6 and v1.4.0 releases, and will work with future Draco releases.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Bug fixes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.4.0 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;WASM and JavaScript decoders are hosted from a static URL. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;It is recommended to always pull your Draco WASM and JavaScript decoders from this URL:&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/v1/decoders/&#34;&gt;https://www.gstatic.com/draco/v1/decoders/&lt;/a&gt;* &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Replace * with the files to load. E.g.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/v1/decoders/draco_decoder_gltf.wasm&#34;&gt;https://www.gstatic.com/draco/v1/decoders/draco_decoder_gltf.wasm&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Users will benefit from having the Draco decoder in cache as more sites start using the static URL&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Changed npm modules to use WASM, which increased performance by ~200%.&lt;/li&gt; &#xA; &lt;li&gt;Updated Emscripten to 2.0. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This causes the Draco codec modules to return a promise instead of the module directly.&lt;/li&gt; &#xA;   &lt;li&gt;Please see the example code on how to handle the promise.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Changed NORMAL quantization default to 8.&lt;/li&gt; &#xA; &lt;li&gt;Added new array API to decoder and deprecated DecoderBuffer. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;See PR &lt;a href=&#34;https://github.com/google/draco/issues/513&#34;&gt;https://github.com/google/draco/issues/513&lt;/a&gt; for more information.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Changed WASM/JavaScript behavior of catching exceptions. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;See issue &lt;a href=&#34;https://github.com/google/draco/issues/629&#34;&gt;https://github.com/google/draco/issues/629&lt;/a&gt; for more information.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Code cleanup.&lt;/li&gt; &#xA; &lt;li&gt;Emscripten builds now disable NODEJS_CATCH_EXIT and NODEJS_CATCH_REJECTION. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Authors of a CLI tool might want to add their own error handlers.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Added Maya plugin builds.&lt;/li&gt; &#xA; &lt;li&gt;Unity plugin builds updated. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Builds are now stored as archives.&lt;/li&gt; &#xA;   &lt;li&gt;Added iOS build.&lt;/li&gt; &#xA;   &lt;li&gt;Unity users may want to look into &lt;a href=&#34;https://github.com/atteneder/DracoUnity&#34;&gt;https://github.com/atteneder/DracoUnity&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Bug fixes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.3.6 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;WASM and JavaScript decoders are now hosted from a static URL &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;It is recommended to always pull your Draco WASM and JavaScript decoders from this URL:&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/v1/decoders/&#34;&gt;https://www.gstatic.com/draco/v1/decoders/&lt;/a&gt;* &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Replace * with the files to load. E.g.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/v1/decoders/draco_decoder_gltf.wasm&#34;&gt;https://www.gstatic.com/draco/v1/decoders/draco_decoder_gltf.wasm&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Users will benefit from having the Draco decoder in cache as more sites start using the static URL&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Changed web examples to pull Draco decoders from static URL&lt;/li&gt; &#xA; &lt;li&gt;Added new API to Draco WASM decoder, which increased performance by ~15%&lt;/li&gt; &#xA; &lt;li&gt;Decreased Draco WASM decoder size by ~20%&lt;/li&gt; &#xA; &lt;li&gt;Added support for generic and multiple attributes to Draco Unity plug-ins&lt;/li&gt; &#xA; &lt;li&gt;Added new API to Draco Unity, which increased decoder performance by ~15%&lt;/li&gt; &#xA; &lt;li&gt;Changed quantization defaults: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;POSITION: 11&lt;/li&gt; &#xA;   &lt;li&gt;NORMAL: 7&lt;/li&gt; &#xA;   &lt;li&gt;TEX_COORD: 10&lt;/li&gt; &#xA;   &lt;li&gt;COLOR: 8&lt;/li&gt; &#xA;   &lt;li&gt;GENERIC: 8&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Code cleanup&lt;/li&gt; &#xA; &lt;li&gt;Bug fixes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.3.5 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Added option to build Draco for Universal Scene Description&lt;/li&gt; &#xA; &lt;li&gt;Code cleanup&lt;/li&gt; &#xA; &lt;li&gt;Bug fixes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.3.4 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Released Draco Animation code&lt;/li&gt; &#xA; &lt;li&gt;Fixes for Unity&lt;/li&gt; &#xA; &lt;li&gt;Various file location and name changes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.3.3 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Added ExpertEncoder to the Javascript API &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Allows developers to set quantization options per attribute id&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Bug fixes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.3.2 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bug fixes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.3.1 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fix issue with multiple attributes when skipping an attribute transform&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Version 1.3.0 release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Improved kD-tree based point cloud encoding &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Now applicable to point clouds with any number of attributes&lt;/li&gt; &#xA;   &lt;li&gt;Support for all integer attribute types and quantized floating point types&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Improved mesh compression up to 10% (on average ~2%) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;For meshes, the 1.3.0 bitstream is fully compatible with 1.2.x decoders&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Improved Javascript API &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Added support for all signed and unsigned integer types&lt;/li&gt; &#xA;   &lt;li&gt;Added support for point clouds to our Javascript encoder API&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Added support for integer properties to the PLY decoder&lt;/li&gt; &#xA; &lt;li&gt;Bug fixes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Previous releases&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/google/draco/releases&#34;&gt;https://github.com/google/draco/releases&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Description&lt;/h1&gt; &#xA;&lt;p&gt;Draco is a library for compressing and decompressing 3D geometric &lt;a href=&#34;https://en.wikipedia.org/wiki/Polygon_mesh&#34;&gt;meshes&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Point_cloud&#34;&gt;point clouds&lt;/a&gt;. It is intended to improve the storage and transmission of 3D graphics.&lt;/p&gt; &#xA;&lt;p&gt;Draco was designed and built for compression efficiency and speed. The code supports compressing points, connectivity information, texture coordinates, color information, normals, and any other generic attributes associated with geometry. With Draco, applications using 3D graphics can be significantly smaller without compromising visual fidelity. For users, this means apps can now be downloaded faster, 3D graphics in the browser can load quicker, and VR and AR scenes can now be transmitted with a fraction of the bandwidth and rendered quickly.&lt;/p&gt; &#xA;&lt;p&gt;Draco is released as C++ source code that can be used to compress 3D graphics as well as C++ and Javascript decoders for the encoded data.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Contents&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#building&#34;&gt;Building&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#unity&#34;&gt;Unity&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#WASM-and-JavaScript-Decoders&#34;&gt;WASM and JavaScript Decoders&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#command-line-applications&#34;&gt;Command Line Applications&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#encoding-tool&#34;&gt;Encoding Tool&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#encoding-point-clouds&#34;&gt;Encoding Point Clouds&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#decoding-tool&#34;&gt;Decoding Tool&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#gltf-transcoding-tool&#34;&gt;glTF Transcoding Tool&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#c-decoder-api&#34;&gt;C++ Decoder API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#javascript-encoder-api&#34;&gt;Javascript Encoder API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#javascript-decoder-api&#34;&gt;Javascript Decoder API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#javascript-decoder-performance&#34;&gt;Javascript Decoder Performance&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#metadata-api&#34;&gt;Metadata API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#npm-package&#34;&gt;NPM Package&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#threejs-renderer-example&#34;&gt;three.js Renderer Example&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#gstatic-javascript-builds&#34;&gt;GStatic Javascript Builds&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#support&#34;&gt;Support&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Building&lt;/h1&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/BUILDING.md&#34;&gt;BUILDING&lt;/a&gt; for building instructions.&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;h2&gt;Unity&lt;/h2&gt; &#xA;&lt;p&gt;For the best information about using Unity with Draco please visit &lt;a href=&#34;https://github.com/atteneder/DracoUnity&#34;&gt;https://github.com/atteneder/DracoUnity&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For a simple example of using Unity with Draco see &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/unity/README.md&#34;&gt;README&lt;/a&gt; in the unity folder.&lt;/p&gt; &#xA;&lt;h2&gt;WASM and JavaScript Decoders&lt;/h2&gt; &#xA;&lt;p&gt;It is recommended to always pull your Draco WASM and JavaScript decoders from:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;https://www.gstatic.com/draco/v1/decoders/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Users will benefit from having the Draco decoder in cache as more sites start using the static URL.&lt;/p&gt; &#xA;&lt;h2&gt;Command Line Applications&lt;/h2&gt; &#xA;&lt;p&gt;The default target created from the build files will be the &lt;code&gt;draco_encoder&lt;/code&gt; and &lt;code&gt;draco_decoder&lt;/code&gt; command line applications. Additionally, &lt;code&gt;draco_transcoder&lt;/code&gt; is generated when CMake is run with the DRACO_TRANSCODER_SUPPORTED variable set to ON (see &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/BUILDING.md#transcoder&#34;&gt;BUILDING&lt;/a&gt; for more details). For all applications, if you run them without any arguments or &lt;code&gt;-h&lt;/code&gt;, the applications will output usage and options.&lt;/p&gt; &#xA;&lt;h2&gt;Encoding Tool&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;draco_encoder&lt;/code&gt; will read OBJ or PLY files as input, and output Draco-encoded files. We have included Stanford&#39;s &lt;a href=&#34;https://graphics.stanford.edu/data/3Dscanrep/&#34;&gt;Bunny&lt;/a&gt; mesh for testing. The basic command line looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./draco_encoder -i testdata/bun_zipper.ply -o out.drc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A value of &lt;code&gt;0&lt;/code&gt; for the quantization parameter will not perform any quantization on the specified attribute. Any value other than &lt;code&gt;0&lt;/code&gt; will quantize the input values for the specified attribute to that number of bits. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./draco_encoder -i testdata/bun_zipper.ply -o out.drc -qp 14&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;will quantize the positions to 14 bits (default is 11 for the position coordinates).&lt;/p&gt; &#xA;&lt;p&gt;In general, the more you quantize your attributes the better compression rate you will get. It is up to your project to decide how much deviation it will tolerate. In general, most projects can set quantization values of about &lt;code&gt;11&lt;/code&gt; without any noticeable difference in quality.&lt;/p&gt; &#xA;&lt;p&gt;The compression level (&lt;code&gt;-cl&lt;/code&gt;) parameter turns on/off different compression features.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./draco_encoder -i testdata/bun_zipper.ply -o out.drc -cl 8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In general, the highest setting, &lt;code&gt;10&lt;/code&gt;, will have the most compression but worst decompression speed. &lt;code&gt;0&lt;/code&gt; will have the least compression, but best decompression speed. The default setting is &lt;code&gt;7&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Encoding Point Clouds&lt;/h2&gt; &#xA;&lt;p&gt;You can encode point cloud data with &lt;code&gt;draco_encoder&lt;/code&gt; by specifying the &lt;code&gt;-point_cloud&lt;/code&gt; parameter. If you specify the &lt;code&gt;-point_cloud&lt;/code&gt; parameter with a mesh input file, &lt;code&gt;draco_encoder&lt;/code&gt; will ignore the connectivity data and encode the positions from the mesh file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./draco_encoder -point_cloud -i testdata/bun_zipper.ply -o out.drc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command line will encode the mesh input as a point cloud, even though the input might not produce compression that is representative of other point clouds. Specifically, one can expect much better compression rates for larger and denser point clouds.&lt;/p&gt; &#xA;&lt;h2&gt;Decoding Tool&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;draco_decoder&lt;/code&gt; will read Draco files as input, and output OBJ or PLY files. The basic command line looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./draco_decoder -i in.drc -o out.obj&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;glTF Transcoding Tool&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;draco_transcoder&lt;/code&gt; can be used to add Draco compression to glTF assets. The basic command line looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./draco_transcoder -i in.glb -o out.glb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command line will add geometry compression to all meshes in the &lt;code&gt;in.glb&lt;/code&gt; file. Quantization values for different glTF attributes can be specified similarly to the &lt;code&gt;draco_encoder&lt;/code&gt; tool. For example &lt;code&gt;-qp&lt;/code&gt; can be used to define quantization of the position attribute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./draco_transcoder -i in.glb -o out.glb -qp 12&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;C++ Decoder API&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;d like to add decoding to your applications you will need to include the &lt;code&gt;draco_dec&lt;/code&gt; library. In order to use the Draco decoder you need to initialize a &lt;code&gt;DecoderBuffer&lt;/code&gt; with the compressed data. Then call &lt;code&gt;DecodeMeshFromBuffer()&lt;/code&gt; to return a decoded mesh object or call &lt;code&gt;DecodePointCloudFromBuffer()&lt;/code&gt; to return a decoded &lt;code&gt;PointCloud&lt;/code&gt; object. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;draco::DecoderBuffer buffer;&#xA;buffer.Init(data.data(), data.size());&#xA;&#xA;const draco::EncodedGeometryType geom_type =&#xA;    draco::GetEncodedGeometryType(&amp;amp;buffer);&#xA;if (geom_type == draco::TRIANGULAR_MESH) {&#xA;  unique_ptr&amp;lt;draco::Mesh&amp;gt; mesh = draco::DecodeMeshFromBuffer(&amp;amp;buffer);&#xA;} else if (geom_type == draco::POINT_CLOUD) {&#xA;  unique_ptr&amp;lt;draco::PointCloud&amp;gt; pc = draco::DecodePointCloudFromBuffer(&amp;amp;buffer);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/src/draco/mesh/mesh.h&#34;&gt;src/draco/mesh/mesh.h&lt;/a&gt; for the full &lt;code&gt;Mesh&lt;/code&gt; class interface and &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/src/draco/point_cloud/point_cloud.h&#34;&gt;src/draco/point_cloud/point_cloud.h&lt;/a&gt; for the full &lt;code&gt;PointCloud&lt;/code&gt; class interface.&lt;/p&gt; &#xA;&lt;h2&gt;Javascript Encoder API&lt;/h2&gt; &#xA;&lt;p&gt;The Javascript encoder is located in &lt;code&gt;javascript/draco_encoder.js&lt;/code&gt;. The encoder API can be used to compress mesh and point cloud. In order to use the encoder, you need to first create an instance of &lt;code&gt;DracoEncoderModule&lt;/code&gt;. Then use this instance to create &lt;code&gt;MeshBuilder&lt;/code&gt; and &lt;code&gt;Encoder&lt;/code&gt; objects. &lt;code&gt;MeshBuilder&lt;/code&gt; is used to construct a mesh from geometry data that could be later compressed by &lt;code&gt;Encoder&lt;/code&gt;. First create a mesh object using &lt;code&gt;new encoderModule.Mesh()&lt;/code&gt; . Then, use &lt;code&gt;AddFacesToMesh()&lt;/code&gt; to add indices to the mesh and use &lt;code&gt;AddFloatAttributeToMesh()&lt;/code&gt; to add attribute data to the mesh, e.g. position, normal, color and texture coordinates. After a mesh is constructed, you could then use &lt;code&gt;EncodeMeshToDracoBuffer()&lt;/code&gt; to compress the mesh. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const mesh = {&#xA;  indices : new Uint32Array(indices),&#xA;  vertices : new Float32Array(vertices),&#xA;  normals : new Float32Array(normals)&#xA;};&#xA;&#xA;const encoderModule = DracoEncoderModule();&#xA;const encoder = new encoderModule.Encoder();&#xA;const meshBuilder = new encoderModule.MeshBuilder();&#xA;const dracoMesh = new encoderModule.Mesh();&#xA;&#xA;const numFaces = mesh.indices.length / 3;&#xA;const numPoints = mesh.vertices.length;&#xA;meshBuilder.AddFacesToMesh(dracoMesh, numFaces, mesh.indices);&#xA;&#xA;meshBuilder.AddFloatAttributeToMesh(dracoMesh, encoderModule.POSITION,&#xA;  numPoints, 3, mesh.vertices);&#xA;if (mesh.hasOwnProperty(&#39;normals&#39;)) {&#xA;  meshBuilder.AddFloatAttributeToMesh(&#xA;    dracoMesh, encoderModule.NORMAL, numPoints, 3, mesh.normals);&#xA;}&#xA;if (mesh.hasOwnProperty(&#39;colors&#39;)) {&#xA;  meshBuilder.AddFloatAttributeToMesh(&#xA;    dracoMesh, encoderModule.COLOR, numPoints, 3, mesh.colors);&#xA;}&#xA;if (mesh.hasOwnProperty(&#39;texcoords&#39;)) {&#xA;  meshBuilder.AddFloatAttributeToMesh(&#xA;    dracoMesh, encoderModule.TEX_COORD, numPoints, 3, mesh.texcoords);&#xA;}&#xA;&#xA;if (method === &#34;edgebreaker&#34;) {&#xA;  encoder.SetEncodingMethod(encoderModule.MESH_EDGEBREAKER_ENCODING);&#xA;} else if (method === &#34;sequential&#34;) {&#xA;  encoder.SetEncodingMethod(encoderModule.MESH_SEQUENTIAL_ENCODING);&#xA;}&#xA;&#xA;const encodedData = new encoderModule.DracoInt8Array();&#xA;// Use default encoding setting.&#xA;const encodedLen = encoder.EncodeMeshToDracoBuffer(dracoMesh,&#xA;                                                   encodedData);&#xA;encoderModule.destroy(dracoMesh);&#xA;encoderModule.destroy(encoder);&#xA;encoderModule.destroy(meshBuilder);&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/src/draco/javascript/emscripten/draco_web_encoder.idl&#34;&gt;src/draco/javascript/emscripten/draco_web_encoder.idl&lt;/a&gt; for the full API.&lt;/p&gt; &#xA;&lt;h2&gt;Javascript Decoder API&lt;/h2&gt; &#xA;&lt;p&gt;The Javascript decoder is located in &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/javascript/draco_decoder.js&#34;&gt;javascript/draco_decoder.js&lt;/a&gt;. The Javascript decoder can decode mesh and point cloud. In order to use the decoder, you must first create an instance of &lt;code&gt;DracoDecoderModule&lt;/code&gt;. The instance is then used to create &lt;code&gt;DecoderBuffer&lt;/code&gt; and &lt;code&gt;Decoder&lt;/code&gt; objects. Set the encoded data in the &lt;code&gt;DecoderBuffer&lt;/code&gt;. Then call &lt;code&gt;GetEncodedGeometryType()&lt;/code&gt; to identify the type of geometry, e.g. mesh or point cloud. Then call either &lt;code&gt;DecodeBufferToMesh()&lt;/code&gt; or &lt;code&gt;DecodeBufferToPointCloud()&lt;/code&gt;, which will return a Mesh object or a point cloud. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// Create the Draco decoder.&#xA;const decoderModule = DracoDecoderModule();&#xA;const buffer = new decoderModule.DecoderBuffer();&#xA;buffer.Init(byteArray, byteArray.length);&#xA;&#xA;// Create a buffer to hold the encoded data.&#xA;const decoder = new decoderModule.Decoder();&#xA;const geometryType = decoder.GetEncodedGeometryType(buffer);&#xA;&#xA;// Decode the encoded geometry.&#xA;let outputGeometry;&#xA;let status;&#xA;if (geometryType == decoderModule.TRIANGULAR_MESH) {&#xA;  outputGeometry = new decoderModule.Mesh();&#xA;  status = decoder.DecodeBufferToMesh(buffer, outputGeometry);&#xA;} else {&#xA;  outputGeometry = new decoderModule.PointCloud();&#xA;  status = decoder.DecodeBufferToPointCloud(buffer, outputGeometry);&#xA;}&#xA;&#xA;// You must explicitly delete objects created from the DracoDecoderModule&#xA;// or Decoder.&#xA;decoderModule.destroy(outputGeometry);&#xA;decoderModule.destroy(decoder);&#xA;decoderModule.destroy(buffer);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/src/draco/javascript/emscripten/draco_web_decoder.idl&#34;&gt;src/draco/javascript/emscripten/draco_web_decoder.idl&lt;/a&gt; for the full API.&lt;/p&gt; &#xA;&lt;h2&gt;Javascript Decoder Performance&lt;/h2&gt; &#xA;&lt;p&gt;The Javascript decoder is built with dynamic memory. This will let the decoder work with all of the compressed data. But this option is not the fastest. Pre-allocating the memory sees about a 2x decoder speed improvement. If you know all of your project&#39;s memory requirements, you can turn on static memory by changing &lt;code&gt;CMakeLists.txt&lt;/code&gt; accordingly.&lt;/p&gt; &#xA;&lt;h2&gt;Metadata API&lt;/h2&gt; &#xA;&lt;p&gt;Starting from v1.0, Draco provides metadata functionality for encoding data other than geometry. It could be used to encode any custom data along with the geometry. For example, we can enable metadata functionality to encode the name of attributes, name of sub-objects and customized information. For one mesh and point cloud, it can have one top-level geometry metadata class. The top-level metadata then can have hierarchical metadata. Other than that, the top-level metadata can have metadata for each attribute which is called attribute metadata. The attribute metadata should be initialized with the correspondent attribute id within the mesh. The metadata API is provided both in C++ and Javascript. For example, to add metadata in C++:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;draco::PointCloud pc;&#xA;// Add metadata for the geometry.&#xA;std::unique_ptr&amp;lt;draco::GeometryMetadata&amp;gt; metadata =&#xA;  std::unique_ptr&amp;lt;draco::GeometryMetadata&amp;gt;(new draco::GeometryMetadata());&#xA;metadata-&amp;gt;AddEntryString(&#34;description&#34;, &#34;This is an example.&#34;);&#xA;pc.AddMetadata(std::move(metadata));&#xA;&#xA;// Add metadata for attributes.&#xA;draco::GeometryAttribute pos_att;&#xA;pos_att.Init(draco::GeometryAttribute::POSITION, nullptr, 3,&#xA;             draco::DT_FLOAT32, false, 12, 0);&#xA;const uint32_t pos_att_id = pc.AddAttribute(pos_att, false, 0);&#xA;&#xA;std::unique_ptr&amp;lt;draco::AttributeMetadata&amp;gt; pos_metadata =&#xA;    std::unique_ptr&amp;lt;draco::AttributeMetadata&amp;gt;(&#xA;        new draco::AttributeMetadata(pos_att_id));&#xA;pos_metadata-&amp;gt;AddEntryString(&#34;name&#34;, &#34;position&#34;);&#xA;&#xA;// Directly add attribute metadata to geometry.&#xA;// You can do this without explicitly add |GeometryMetadata| to mesh.&#xA;pc.AddAttributeMetadata(pos_att_id, std::move(pos_metadata));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To read metadata from a geometry in C++:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Get metadata for the geometry.&#xA;const draco::GeometryMetadata *pc_metadata = pc.GetMetadata();&#xA;&#xA;// Request metadata for a specific attribute.&#xA;const draco::AttributeMetadata *requested_pos_metadata =&#xA;  pc.GetAttributeMetadataByStringEntry(&#34;name&#34;, &#34;position&#34;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/src/draco/metadata&#34;&gt;src/draco/metadata&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/src/draco/point_cloud&#34;&gt;src/draco/point_cloud&lt;/a&gt; for the full API.&lt;/p&gt; &#xA;&lt;h2&gt;NPM Package&lt;/h2&gt; &#xA;&lt;p&gt;Draco NPM NodeJS package is located in &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/javascript/npm/draco3d&#34;&gt;javascript/npm/draco3d&lt;/a&gt;. Please see the doc in the folder for detailed usage.&lt;/p&gt; &#xA;&lt;h2&gt;three.js Renderer Example&lt;/h2&gt; &#xA;&lt;p&gt;Here&#39;s an &lt;a href=&#34;https://storage.googleapis.com/demos.webmproject.org/draco/draco_loader_throw.html&#34;&gt;example&lt;/a&gt; of a geometric compressed with Draco loaded via a Javascript decoder using the &lt;code&gt;three.js&lt;/code&gt; renderer.&lt;/p&gt; &#xA;&lt;p&gt;Please see the &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/javascript/example/README.md&#34;&gt;javascript/example/README.md&lt;/a&gt; file for more information.&lt;/p&gt; &#xA;&lt;h1&gt;GStatic Javascript Builds&lt;/h1&gt; &#xA;&lt;p&gt;Prebuilt versions of the Emscripten-built Draco javascript decoders are hosted on &lt;a href=&#34;http://www.gstatic.com&#34;&gt;www.gstatic.com&lt;/a&gt; in version labeled directories:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/VERSION/&#34;&gt;https://www.gstatic.com/draco/versioned/decoders/VERSION/&lt;/a&gt;*&lt;/p&gt; &#xA;&lt;p&gt;As of the v1.4.3 release the files available are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.4.3/draco_decoder.js&#34;&gt;draco_decoder.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.4.3/draco_decoder.wasm&#34;&gt;draco_decoder.wasm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.4.3/draco_decoder_gltf.js&#34;&gt;draco_decoder_gltf.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.4.3/draco_decoder_gltf.wasm&#34;&gt;draco_decoder_gltf.wasm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.4.3/draco_wasm_wrapper.js&#34;&gt;draco_wasm_wrapper.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.4.3/draco_wasm_wrapper_gltf.js&#34;&gt;draco_wasm_wrapper_gltf.js&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Beginning with the v1.5.1 release assertion enabled builds of the following files are available:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.5.1/with_asserts/draco_decoder.js&#34;&gt;draco_decoder.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.5.1/with_asserts/draco_decoder.wasm&#34;&gt;draco_decoder.wasm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gstatic.com/draco/versioned/decoders/1.5.1/with_asserts/draco_wasm_wrapper.js&#34;&gt;draco_wasm_wrapper.js&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Support&lt;/h1&gt; &#xA;&lt;p&gt;For questions/comments please email &lt;a href=&#34;mailto:draco-3d-discuss@googlegroups.com&#34;&gt;draco-3d-discuss@googlegroups.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you have found an error in this library, please file an issue at &lt;a href=&#34;https://github.com/google/draco/issues&#34;&gt;https://github.com/google/draco/issues&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Patches are encouraged, and may be submitted by forking this project and submitting a pull request through GitHub. See &lt;a href=&#34;https://raw.githubusercontent.com/google/draco/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING&lt;/a&gt; for more detail.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; &#xA;&lt;h1&gt;References&lt;/h1&gt; &#xA;&lt;p&gt;Bunny model from Stanford&#39;s graphic department &lt;a href=&#34;https://graphics.stanford.edu/data/3Dscanrep/&#34;&gt;https://graphics.stanford.edu/data/3Dscanrep/&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>