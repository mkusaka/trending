<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-17T01:31:17Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>hackerhouse-opensource/iscsicpl_bypassUAC</title>
    <updated>2022-07-17T01:31:17Z</updated>
    <id>tag:github.com,2022-07-17:/hackerhouse-opensource/iscsicpl_bypassUAC</id>
    <link href="https://github.com/hackerhouse-opensource/iscsicpl_bypassUAC" rel="alternate"></link>
    <summary type="html">&lt;p&gt;UAC bypass for x64 Windows 7 - 11&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;iscsicpl autoelevate DLL Search Order hijacking UAC Bypass 0day&lt;/h1&gt; &#xA;&lt;p&gt;The iscsicpl.exe binary is vulnerable to a DLL Search Order hijacking vulnerability when running 32bit Microsoft binary on a 64bit host via SysWOW64. The 32bit binary, will perform a search within user %Path% for the DLL iscsiexe.dll. This can be exploited using a Proxy DLL to execute code via &#34;iscsicpl.exe&#34; as autoelevate is enabled. This exploit has been tested against the following versions of Windows desktop:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows 11 Enterprise x64 (Version 10.0.22000.739).&lt;/li&gt; &#xA; &lt;li&gt;Windows 8.1 Professional x64 (Version 6.3.9600).&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>carla-simulator/carla</title>
    <updated>2022-07-17T01:31:17Z</updated>
    <id>tag:github.com,2022-07-17:/carla-simulator/carla</id>
    <link href="https://github.com/carla-simulator/carla" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open-source simulator for autonomous driving research.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CARLA Simulator&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/carla-simulator/carla&#34;&gt;&lt;img src=&#34;https://travis-ci.org/carla-simulator/carla.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://carla.readthedocs.io&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/carla/badge/?version=latest&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://carla.org&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/carla-simulator/carla/master/Docs/img/btn/web.png&#34; alt=&#34;carla.org&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/carla-simulator/carla/raw/master/Docs/download.md&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/carla-simulator/carla/master/Docs/img/btn/download.png&#34; alt=&#34;download&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://carla.readthedocs.io&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/carla-simulator/carla/master/Docs/img/btn/docs.png&#34; alt=&#34;documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/carla-simulator/carla/discussions&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/carla-simulator/carla/master/Docs/img/btn/forum.png&#34; alt=&#34;forum&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/8kqACuC&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/carla-simulator/carla/master/Docs/img/btn/chat.png&#34; alt=&#34;discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;CARLA is an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=7jej46ALVRE&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/carla-simulator/carla/master/Docs/img/video_thumbnail_0910.jpg&#34; alt=&#34;CARLA Video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to benchmark your model in the same conditions as in our CoRL’17 paper, check out &lt;a href=&#34;https://github.com/carla-simulator/driving-benchmarks&#34;&gt;Benchmarking&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://carla-releases.s3.amazonaws.com/Linux/Dev/CARLA_Latest.tar.gz&#34;&gt;&lt;strong&gt;Get CARLA overnight build&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Recommended system&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Intel i7 gen 9th - 11th / Intel i9 gen 9th - 11th / AMD ryzen 7 / AMD ryzen 9&lt;/li&gt; &#xA; &lt;li&gt;+16 GB RAM memory&lt;/li&gt; &#xA; &lt;li&gt;NVIDIA RTX 2070 / NVIDIA RTX 2080 / NVIDIA RTX 3070, NVIDIA RTX 3080&lt;/li&gt; &#xA; &lt;li&gt;Ubuntu 18.04&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;CARLA Ecosystem&lt;/h2&gt; &#xA;&lt;p&gt;Repositories associated to the CARLA simulation platform:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://leaderboard.carla.org/&#34;&gt;&lt;strong&gt;CARLA Autonomous Driving leaderboard&lt;/strong&gt;&lt;/a&gt;: Automatic platform to validate Autonomous Driving stacks&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/carla-simulator/scenario_runner&#34;&gt;&lt;strong&gt;Scenario_Runner&lt;/strong&gt;&lt;/a&gt;: Engine to execute traffic scenarios in CARLA 0.9.X&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/carla-simulator/ros-bridge&#34;&gt;&lt;strong&gt;ROS-bridge&lt;/strong&gt;&lt;/a&gt;: Interface to connect CARLA 0.9.X to ROS&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/carla-simulator/driving-benchmarks&#34;&gt;&lt;strong&gt;Driving-benchmarks&lt;/strong&gt;&lt;/a&gt;: Benchmark tools for Autonomous Driving tasks&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/felipecode/coiltraine&#34;&gt;&lt;strong&gt;Conditional Imitation-Learning&lt;/strong&gt;&lt;/a&gt;: Training and testing Conditional Imitation Learning models in CARLA&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/carla-simulator/carla-autoware&#34;&gt;&lt;strong&gt;AutoWare AV stack&lt;/strong&gt;&lt;/a&gt;: Bridge to connect AutoWare AV stack to CARLA&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/carla-simulator/reinforcement-learning&#34;&gt;&lt;strong&gt;Reinforcement-Learning&lt;/strong&gt;&lt;/a&gt;: Code for running Conditional Reinforcement Learning models in CARLA&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/carla-simulator/carla-map-editor&#34;&gt;&lt;strong&gt;Map Editor&lt;/strong&gt;&lt;/a&gt;: Standalone GUI application to enhance RoadRunner maps with traffic lights and traffic signs information&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Like what you see? Star us on GitHub to support the project!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Paper&lt;/h2&gt; &#xA;&lt;p&gt;If you use CARLA, please cite our CoRL’17 paper.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;CARLA: An Open Urban Driving Simulator&lt;/em&gt;&lt;br&gt;Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, Vladlen Koltun; PMLR 78:1-16 [&lt;a href=&#34;http://proceedings.mlr.press/v78/dosovitskiy17a/dosovitskiy17a.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://www.youtube.com/watch?v=xfyK03MEZ9Q&amp;amp;feature=youtu.be&amp;amp;t=2h44m30s&#34;&gt;talk&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{Dosovitskiy17,&#xA;  title = {{CARLA}: {An} Open Urban Driving Simulator},&#xA;  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},&#xA;  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},&#xA;  pages = {1--16},&#xA;  year = {2017}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Building CARLA&lt;/h2&gt; &#xA;&lt;p&gt;Use &lt;code&gt;git clone&lt;/code&gt; or download the project from this page. Note that the master branch contains the most recent release of CARLA with the latest fixes and features.&lt;/p&gt; &#xA;&lt;p&gt;Then follow the instruction at &lt;a href=&#34;https://carla.readthedocs.io/en/latest/build_linux/&#34;&gt;How to build on Linux&lt;/a&gt; or &lt;a href=&#34;https://carla.readthedocs.io/en/latest/build_windows/&#34;&gt;How to build on Windows&lt;/a&gt;.&lt;br&gt; The Linux build needs for an UE patch to solve some visualization issues regarding Vulkan. Those already working with a Linux build should install the patch and make the UE build again using the following commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Download and install the UE patch  &#xA;cd ~/UnrealEngine_4.24&#xA;wget https://carla-releases.s3.eu-west-3.amazonaws.com/Linux/UE_Patch/430667-13636743-patch.txt ~/430667-13636743-patch.txt&#xA;patch --strip=4 &amp;lt; ~/430667-13636743-patch.txt&#xA;# Build UE&#xA;./Setup.sh &amp;amp;&amp;amp; ./GenerateProjectFiles.sh &amp;amp;&amp;amp; make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Unfortunately we don&#39;t have official instructions to build on Mac yet, please check the progress at &lt;a href=&#34;https://github.com/carla-simulator/carla/issues/150&#34;&gt;issue #150&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please take a look at our &lt;a href=&#34;https://carla.readthedocs.io/en/latest/cont_contribution_guidelines/&#34;&gt;Contribution guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;F.A.Q.&lt;/h2&gt; &#xA;&lt;p&gt;If you run into problems, check our &lt;a href=&#34;https://carla.readthedocs.io/en/latest/build_faq/&#34;&gt;FAQ&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;CARLA Talks&lt;/h2&gt; &#xA;&lt;p&gt;The team creates some additional content for users, besides the docs. This is a great way to cover different subjects such as detailed explanations for a specific module, latest improvements in a feature, future work and much more.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CARLA Talks 2020 (May):&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;General&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Art improvements: environment and rendering — &lt;a href=&#34;https://youtu.be/ZZaHevsz8W8&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/1l9Ztaq0Q8fNN5YPU4-5vL13eZUwsQl5P/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Core implementations: synchrony, snapshots and landmarks — &lt;a href=&#34;https://youtu.be/nyyTLmphqY4&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/1yaOwf1419qWZqE1gTSrrknsWOhawEWh_/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Data ingestion — &lt;a href=&#34;https://youtu.be/mHiUUZ4xC9o&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/10uNBAMreKajYimIhwCqSYXjhfVs2bX31/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Pedestrians and their implementation — &lt;a href=&#34;https://youtu.be/Uoz2ihDwaWA&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/1Tsosin7BLP1k558shtbzUdo2ZXVKy5CB/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Sensors in CARLA — &lt;a href=&#34;https://youtu.be/T8qCSet8WK0&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/1UO8ZAIOp-1xaBzcFMfn_IoipycVkUo4q/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Modules&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Improvements in the Traffic Manager — &lt;a href=&#34;https://youtu.be/n9cufaJ17eA&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/1R9uNZ6pYHSZoEBxs2vYK7swiriKbbuxo/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Integration of autoware and ROS — &lt;a href=&#34;https://youtu.be/ChIgcC2scwU&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/1uO6nBaFirrllb08OeqGAMVLApQ6EbgAt/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Introducing ScenarioRunner — &lt;a href=&#34;https://youtu.be/dcnnNJowqzM&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/1zgoH_kLOfIw117FJGm2IVZZAIRw9U2Q0/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;OpenSCENARIO support — &lt;a href=&#34;https://drive.google.com/file/d/1g6ATxZRTWEdstiZwfBN1_T_x_WwZs0zE/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Features&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Co-Simulations with SUMO and PTV-Vissim — &lt;a href=&#34;https://youtu.be/PuFSbj1PU94&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/10DgMNUBqKqWBrdiwBiAIT4DdR9ObCquI/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Integration of RSS-lib — &lt;a href=&#34;https://drive.google.com/file/d/1whREmrCv67fOMipgCk6kkiW4VPODig0A/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;The External Sensor Interface (ESI) — &lt;a href=&#34;https://youtu.be/5hXHPV9FIeY&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/1VWFaEoS12siW6NtQDUkm44BVO7tveRbJ/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;The OpenDRIVE Standalone Mode — &lt;a href=&#34;https://youtu.be/U25GhofVV1Q&#34;&gt;video&lt;/a&gt; | &lt;a href=&#34;https://drive.google.com/file/d/1D5VsgfX7dmgPWn7UtDDid3-OdS1HI4pY/view?usp=sharing&#34;&gt;slides&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Licenses&lt;/h2&gt; &#xA;&lt;h4&gt;CARLA licenses&lt;/h4&gt; &#xA;&lt;p&gt;CARLA specific code is distributed under MIT License.&lt;/p&gt; &#xA;&lt;p&gt;CARLA specific assets are distributed under CC-BY License.&lt;/p&gt; &#xA;&lt;h4&gt;CARLA Dependency and Integration licenses&lt;/h4&gt; &#xA;&lt;p&gt;The ad-rss-lib library compiled and linked by the &lt;a href=&#34;https://raw.githubusercontent.com/carla-simulator/carla/master/Docs/adv_rss.md&#34;&gt;RSS Integration build variant&lt;/a&gt; introduces &lt;a href=&#34;https://opensource.org/licenses/LGPL-2.1&#34;&gt;LGPL-2.1-only License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Unreal Engine 4 follows its &lt;a href=&#34;https://www.unrealengine.com/en-US/faq&#34;&gt;own license terms&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;CARLA uses three dependencies as part of the SUMO integration:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://proj.org/&#34;&gt;PROJ&lt;/a&gt;, a generic coordinate transformation software which uses the &lt;a href=&#34;https://proj.org/about.html#license&#34;&gt;X/MIT open source license&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.sqlite.org&#34;&gt;SQLite&lt;/a&gt;, part of the PROJ dependencies, which is &lt;a href=&#34;https://www.sqlite.org/purchase/license&#34;&gt;in the public domain&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xerces.apache.org/xerces-c/&#34;&gt;Xerces-C&lt;/a&gt;, a validating XML parser, which is made available under the &lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt;Apache Software License, Version 2.0&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;CARLA uses one dependency as part of the Chrono integration:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://eigen.tuxfamily.org/index.php?title=Main_Page&#34;&gt;Eigen&lt;/a&gt;, a C++ template library for linear algebra which uses the &lt;a href=&#34;https://www.mozilla.org/en-US/MPL/2.0/&#34;&gt;MPL2 license&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;CARLA uses the Autodesk FBX SDK for converting FBX to OBJ in the import process of maps. This step is optional, and the SDK is located &lt;a href=&#34;https://www.autodesk.com/developer-network/platform-technologies/fbx-sdk-2020-0&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This software contains Autodesk® FBX® code developed by Autodesk, Inc. Copyright 2020 Autodesk, Inc. All rights, reserved. Such code is provided &#34;as is&#34; and Autodesk, Inc. disclaims any and all warranties, whether express or implied, including without limitation the implied warranties of merchantability, fitness for a particular purpose or non-infringement of third party rights. In no event shall Autodesk, Inc. be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of such code.&#34;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>RobustFieldAutonomyLab/LeGO-LOAM</title>
    <updated>2022-07-17T01:31:17Z</updated>
    <id>tag:github.com,2022-07-17:/RobustFieldAutonomyLab/LeGO-LOAM</id>
    <link href="https://github.com/RobustFieldAutonomyLab/LeGO-LOAM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LeGO-LOAM&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains code for a lightweight and ground optimized lidar odometry and mapping (LeGO-LOAM) system for ROS compatible UGVs. The system takes in point cloud from a Velodyne VLP-16 Lidar (palced horizontally) and optional IMU data as inputs. It outputs 6D pose estimation in real-time. A demonstration of the system can be found here -&amp;gt; &lt;a href=&#34;https://www.youtube.com/watch?v=O3tz_ftHV48&#34;&gt;https://www.youtube.com/watch?v=O3tz_ftHV48&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!--&#xA;[![Watch the video](/LeGO-LOAM/launch/demo.gif)](https://www.youtube.com/watch?v=O3tz_ftHV48)&#xA;--&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/RobustFieldAutonomyLab/LeGO-LOAM/master/LeGO-LOAM/launch/demo.gif&#34; alt=&#34;drawing&#34; width=&#34;800&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Lidar-inertial Odometry&lt;/h2&gt; &#xA;&lt;p&gt;An updated lidar-initial odometry package, &lt;a href=&#34;https://github.com/TixiaoShan/LIO-SAM&#34;&gt;LIO-SAM&lt;/a&gt;, has been open-sourced and available for testing.&lt;/p&gt; &#xA;&lt;h2&gt;Dependency&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://wiki.ros.org/ROS/Installation&#34;&gt;ROS&lt;/a&gt; (tested with indigo, kinetic, and melodic)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/borglab/gtsam/releases&#34;&gt;gtsam&lt;/a&gt; (Georgia Tech Smoothing and Mapping library, 4.0.0-alpha2) &lt;pre&gt;&lt;code&gt;wget -O ~/Downloads/gtsam.zip https://github.com/borglab/gtsam/archive/4.0.0-alpha2.zip&#xA;cd ~/Downloads/ &amp;amp;&amp;amp; unzip gtsam.zip -d ~/Downloads/&#xA;cd ~/Downloads/gtsam-4.0.0-alpha2/&#xA;mkdir build &amp;amp;&amp;amp; cd build&#xA;cmake ..&#xA;sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Compile&lt;/h2&gt; &#xA;&lt;p&gt;You can use the following commands to download and compile the package.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd ~/catkin_ws/src&#xA;git clone https://github.com/RobustFieldAutonomyLab/LeGO-LOAM.git&#xA;cd ..&#xA;catkin_make -j1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When you compile the code for the first time, you need to add &#34;-j1&#34; behind &#34;catkin_make&#34; for generating some message types. &#34;-j1&#34; is not needed for future compiling.&lt;/p&gt; &#xA;&lt;h2&gt;The system&lt;/h2&gt; &#xA;&lt;p&gt;LeGO-LOAM is speficifally optimized for a horizontally placed VLP-16 on a ground vehicle. It assumes there is always a ground plane in the scan. The UGV we are using is Clearpath Jackal. It has a built-in IMU.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/RobustFieldAutonomyLab/LeGO-LOAM/master/LeGO-LOAM/launch/jackal-label.jpg&#34; alt=&#34;drawing&#34; width=&#34;400&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;The package performs segmentation before feature extraction.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/RobustFieldAutonomyLab/LeGO-LOAM/master/LeGO-LOAM/launch/seg-total.jpg&#34; alt=&#34;drawing&#34; width=&#34;400&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Lidar odometry performs two-step Levenberg Marquardt optimization to get 6D transformation.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/RobustFieldAutonomyLab/LeGO-LOAM/master/LeGO-LOAM/launch/odometry.jpg&#34; alt=&#34;drawing&#34; width=&#34;400&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;New Lidar&lt;/h2&gt; &#xA;&lt;p&gt;The key thing to adapt the code to a new sensor is making sure the point cloud can be properly projected to an range image and ground can be correctly detected. For example, VLP-16 has a angular resolution of 0.2° and 2° along two directions. It has 16 beams. The angle of the bottom beam is -15°. Thus, the parameters in &#34;utility.h&#34; are listed as below. When you implement new sensor, make sure that the ground_cloud has enough points for matching. Before you post any issues, please read this.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;extern const int N_SCAN = 16;&#xA;extern const int Horizon_SCAN = 1800;&#xA;extern const float ang_res_x = 0.2;&#xA;extern const float ang_res_y = 2.0;&#xA;extern const float ang_bottom = 15.0;&#xA;extern const int groundScanInd = 7;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Another example for Velodyne HDL-32e range image projection:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;extern const int N_SCAN = 32;&#xA;extern const int Horizon_SCAN = 1800;&#xA;extern const float ang_res_x = 360.0/Horizon_SCAN;&#xA;extern const float ang_res_y = 41.333/float(N_Scan-1);&#xA;extern const float ang_bottom = 30.666666;&#xA;extern const int groundScanInd = 20;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;New&lt;/strong&gt;: a new &lt;strong&gt;useCloudRing&lt;/strong&gt; flag has been added to help with point cloud projection (i.e., VLP-32C, VLS-128). Velodyne point cloud has &#34;ring&#34; channel that directly gives the point row id in a range image. Other lidars may have a same type of channel, i.e., &#34;r&#34; in Ouster. If you are using a non-Velodyne lidar but it has a similar &#34;ring&#34; channel, you can change the PointXYZIR definition in utility.h and the corresponding code in imageProjection.cpp.&lt;/p&gt; &#xA;&lt;p&gt;For &lt;strong&gt;KITTI&lt;/strong&gt; users, if you want to use our algorithm with &lt;strong&gt;HDL-64e&lt;/strong&gt;, you need to write your own implementation for such projection. If the point cloud is not projected properly, you will lose many points and performance.&lt;/p&gt; &#xA;&lt;p&gt;If you are using your lidar with an IMU, make sure your IMU is aligned properly with the lidar. The algorithm uses IMU data to correct the point cloud distortion that is cause by sensor motion. If the IMU is not aligned properly, the usage of IMU data will deteriorate the result. Ouster lidar IMU is not supported in the package as LeGO-LOAM needs a 9-DOF IMU.&lt;/p&gt; &#xA;&lt;h2&gt;Run the package&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Run the launch file:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;roslaunch lego_loam run.launch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Notes: The parameter &#34;/use_sim_time&#34; is set to &#34;true&#34; for simulation, &#34;false&#34; to real robot usage.&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Play existing bag files:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;rosbag play *.bag --clock --topic /velodyne_points /imu/data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Notes: Though /imu/data is optinal, it can improve estimation accuracy greatly if provided. Some sample bags can be downloaded from &lt;a href=&#34;https://github.com/RobustFieldAutonomyLab/jackal_dataset_20170608&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;New data-set&lt;/h2&gt; &#xA;&lt;p&gt;This dataset, &lt;a href=&#34;https://github.com/TixiaoShan/Stevens-VLP16-Dataset&#34;&gt;Stevens data-set&lt;/a&gt;, is captured using a Velodyne VLP-16, which is mounted on an UGV - Clearpath Jackal, on Stevens Institute of Technology campus. The VLP-16 rotation rate is set to 10Hz. This data-set features over 20K scans and many loop-closures.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/RobustFieldAutonomyLab/LeGO-LOAM/master/LeGO-LOAM/launch/dataset-demo.gif&#34; alt=&#34;drawing&#34; width=&#34;600&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/RobustFieldAutonomyLab/LeGO-LOAM/master/LeGO-LOAM/launch/google-earth.png&#34; alt=&#34;drawing&#34; width=&#34;600&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Cite &lt;em&gt;LeGO-LOAM&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Thank you for citing &lt;a href=&#34;https://raw.githubusercontent.com/RobustFieldAutonomyLab/LeGO-LOAM/master/Shan_Englot_IROS_2018_Preprint.pdf&#34;&gt;our &lt;em&gt;LeGO-LOAM&lt;/em&gt; paper&lt;/a&gt; if you use any of this code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{legoloam2018,&#xA;  title={LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain},&#xA;  author={Shan, Tixiao and Englot, Brendan},&#xA;  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},&#xA;  pages={4758-4765},&#xA;  year={2018},&#xA;  organization={IEEE}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Loop Closure&lt;/h2&gt; &#xA;&lt;p&gt;The loop-closure method implemented in this package is a naive ICP-based method. It often fails when the odometry drift is too large. For more advanced loop-closure methods, there is a package called &lt;a href=&#34;https://github.com/irapkaist/SC-LeGO-LOAM&#34;&gt;SC-LeGO-LOAM&lt;/a&gt;, which features utilizing point cloud descriptor.&lt;/p&gt; &#xA;&lt;h2&gt;Speed Optimization&lt;/h2&gt; &#xA;&lt;p&gt;An optimized version of LeGO-LOAM can be found &lt;a href=&#34;https://github.com/facontidavide/LeGO-LOAM/tree/speed_optimization&#34;&gt;here&lt;/a&gt;. All credits go to @facontidavide. Improvements in this directory include but not limited to:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;+ To improve the quality of the code, making it more readable, consistent and easier to understand and modify.&#xA;+ To remove hard-coded values and use proper configuration files to describe the hardware.&#xA;+ To improve performance, in terms of amount of CPU used to calculate the same result.&#xA;+ To convert a multi-process application into a single-process / multi-threading one; this makes the algorithm more deterministic and slightly faster.&#xA;+ To make it easier and faster to work with rosbags: processing a rosbag should be done at maximum speed allowed by the CPU and in a deterministic way.&#xA;+ As a consequence of the previous point, creating unit and regression tests will be easier.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>