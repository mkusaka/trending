<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-26T01:30:22Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>airockchip/rknn-llm</title>
    <updated>2025-06-26T01:30:22Z</updated>
    <id>tag:github.com,2025-06-26:/airockchip/rknn-llm</id>
    <link href="https://github.com/airockchip/rknn-llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Description&lt;/h1&gt; &#xA;&lt;p&gt;RKLLM software stack can help users to quickly deploy AI models to Rockchip chips. The overall framework is as follows: &lt;/p&gt;&#xA;&lt;center class=&#34;half&#34;&gt; &#xA; &lt;div style=&#34;background-color:#ffffff;&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/airockchip/rknn-llm/main/res/framework.jpg&#34; title=&#34;RKLLM&#34;&gt; &#xA; &lt;/div&gt;&#xA;&lt;/center&gt;&#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt;In order to use RKNPU, users need to first run the RKLLM-Toolkit tool on the computer, convert the trained model into an RKLLM format model, and then inference on the development board using the RKLLM C API.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;RKLLM-Toolkit is a software development kit for users to perform model conversionand quantization on PC.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;RKLLM Runtime provides C/C++ programming interfaces for Rockchip NPU platform to help users deploy RKLLM models and accelerate the implementation of LLM applications.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;RKNPU kernel driver is responsible for interacting with NPU hardware. It has been open source and can be found in the Rockchip kernel code.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Support Platform&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;RK3588 Series&lt;/li&gt; &#xA; &lt;li&gt;RK3576 Series&lt;/li&gt; &#xA; &lt;li&gt;RK3562 Series&lt;/li&gt; &#xA; &lt;li&gt;RV1126B Series&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Support Models&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;LLAMA models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/TinyLlama&#34;&gt;TinyLLAMA models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/Qwen&#34;&gt;Qwen2/Qwen2.5/Qwen3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/microsoft&#34;&gt;Phi2/Phi3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/THUDM/chatglm3-6b/tree/103caa40027ebfd8450289ca2f278eac4ff26405&#34;&gt;ChatGLM3-6B&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/google&#34;&gt;Gemma2/Gemma3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/collections/internlm/internlm2-65b0ce04970888799707893c&#34;&gt;InternLM2 models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/openbmb&#34;&gt;MiniCPM3/MiniCPM4&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/Tele-AI&#34;&gt;TeleChat2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/Qwen&#34;&gt;Qwen2-VL-2B-Instruct/Qwen2-VL-7B-Instruct/Qwen2.5-VL-3B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-V-2_6&#34;&gt;MiniCPM-V-2_6&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d&#34;&gt;DeepSeek-R1-Distill&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/deepseek-ai/Janus-Pro-1B&#34;&gt;Janus-Pro-1B&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/OpenGVLab/InternVL2-1B&#34;&gt;InternVL2-1B&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/HuggingFaceTB&#34;&gt;SmolVLM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/fla-hub&#34;&gt;RWKV7&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Model Performance&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/airockchip/rknn-llm/tree/main/benchmark.md&#34;&gt;Benchmark&lt;/a&gt; results of common LLMs.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;&lt;strong&gt;Performance Testing Methods&lt;/strong&gt;&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Run the frequency-setting script from the &lt;code&gt;scripts&lt;/code&gt; directory on the target platform.&lt;/li&gt; &#xA; &lt;li&gt;Execute &lt;code&gt;export RKLLM_LOG_LEVEL=1&lt;/code&gt; on the device to log model inference performance and memory usage.&lt;/li&gt; &#xA; &lt;li&gt;Use the &lt;code&gt;eval_perf_watch_cpu.sh&lt;/code&gt; script to measure CPU utilization.&lt;/li&gt; &#xA; &lt;li&gt;Use the &lt;code&gt;eval_perf_watch_npu.sh&lt;/code&gt; script to measure NPU utilization.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Download&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;You can download the &lt;strong&gt;latest package&lt;/strong&gt; from &lt;a href=&#34;https://console.zbox.filez.com/l/RJJDmB&#34;&gt;RKLLM_SDK&lt;/a&gt;, fetch code: rkllm&lt;/li&gt; &#xA; &lt;li&gt;You can download the &lt;strong&gt;converted rkllm model&lt;/strong&gt; from &lt;a href=&#34;https://console.box.lenovo.com/l/l0tXb8&#34;&gt;rkllm_model_zoo&lt;/a&gt;, fetch code: rkllm&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Examples&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Multimodel deployment demo: &lt;a href=&#34;https://github.com/airockchip/rknn-llm/tree/main/examples/Qwen2-VL_Demo&#34;&gt;Qwen2-VL_Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;API usage demo: &lt;a href=&#34;https://github.com/airockchip/rknn-llm/tree/main/examples/DeepSeek-R1-Distill-Qwen-1.5B_Demo&#34;&gt;DeepSeek-R1-Distill-Qwen-1.5B_Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;API server demo: &lt;a href=&#34;https://github.com/airockchip/rknn-llm/tree/main/examples/rkllm_server_demo&#34;&gt;rkllm_server_demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Multimodal_Interactive_Dialogue_Demo &lt;a href=&#34;https://github.com/airockchip/rknn-llm/tree/main/examples/Multimodal_Interactive_Dialogue_Demo&#34;&gt;Multimodal_Interactive_Dialogue_Demo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Note&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The supported Python versions are:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Python 3.8&lt;/li&gt; &#xA;   &lt;li&gt;Python 3.9&lt;/li&gt; &#xA;   &lt;li&gt;Python 3.10&lt;/li&gt; &#xA;   &lt;li&gt;Python 3.11&lt;/li&gt; &#xA;   &lt;li&gt;Python 3.12&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: Before installing package in a Python 3.12 environment, please run the command:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export BUILD_CUDA_EXT=0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;On some platforms, you may encounter an error indicating that &lt;strong&gt;libomp.so&lt;/strong&gt; cannot be found. To resolve this, locate the library in the corresponding cross-compilation toolchain and place it in the board&#39;s lib directory, at the same level as librkllmrt.so.&lt;/li&gt; &#xA; &lt;li&gt;RWKV model conversion only supports Python 3.12. Please use &lt;code&gt;requirements_rwkv7.txt&lt;/code&gt; to set up the pip environment.&lt;/li&gt; &#xA; &lt;li&gt;Latest version: &lt;a href=&#34;https://github.com/airockchip/rknn-llm/releases/tag/release-v1.2.1&#34;&gt; &lt;u&gt;v1.2.1&lt;/u&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;RKNN Toolkit2&lt;/h1&gt; &#xA;&lt;p&gt;If you want to deploy additional AI model, we have introduced a SDK called RKNN-Toolkit2. For details, please refer to:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/airockchip/rknn-toolkit2&#34;&gt;https://github.com/airockchip/rknn-toolkit2&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;CHANGELOG&lt;/h1&gt; &#xA;&lt;h2&gt;v1.2.1&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Added support for RWKV7, Qwen3, and MiniCPM4 models&lt;/li&gt; &#xA; &lt;li&gt;Added support for the RV1126B platform&lt;/li&gt; &#xA; &lt;li&gt;Enabled function calling capability&lt;/li&gt; &#xA; &lt;li&gt;Enabled cross-attention inference&lt;/li&gt; &#xA; &lt;li&gt;Optimize the callback function to support pausing inference&lt;/li&gt; &#xA; &lt;li&gt;Supported multi-batch inference&lt;/li&gt; &#xA; &lt;li&gt;Optimized KV cache clearing interface&lt;/li&gt; &#xA; &lt;li&gt;Improved chat template parsing with support for thinking mode selection&lt;/li&gt; &#xA; &lt;li&gt;Server demo updated to support OpenAI-compatible format&lt;/li&gt; &#xA; &lt;li&gt;Added return of model inference performance statistics&lt;/li&gt; &#xA; &lt;li&gt;Supported mrope multimodal position encoding&lt;/li&gt; &#xA; &lt;li&gt;A new quantization optimization algorithm has been added to improve quantization accuracy&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;for older version, please refer &lt;a href=&#34;https://raw.githubusercontent.com/airockchip/rknn-llm/main/CHANGELOG.md&#34;&gt;CHANGELOG&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>MrNeRF/gaussian-splatting-cuda</title>
    <updated>2025-06-26T01:30:22Z</updated>
    <id>tag:github.com,2025-06-26:/MrNeRF/gaussian-splatting-cuda</id>
    <link href="https://github.com/MrNeRF/gaussian-splatting-cuda" rel="alternate"></link>
    <summary type="html">&lt;p&gt;3D Gaussian Splatting, reimagined: Unleashing unmatched speed with C++ and CUDA from the ground up!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;3D Gaussian Splatting for Real-Time Radiance Field Rendering - C++ and CUDA Implementation&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/TbxJST2BbC&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mrnerf.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Website-mrnerf.com-blue&#34; alt=&#34;Website&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mrnerf.github.io/awesome-3D-gaussian-splatting/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Papers-Awesome%203DGS-orange&#34; alt=&#34;Papers&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A high-performance C++ and CUDA implementation of 3D Gaussian Splatting, built upon the &lt;a href=&#34;https://github.com/nerfstudio-project/gsplat&#34;&gt;gsplat&lt;/a&gt; rasterization backend.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MrNeRF/gaussian-splatting-cuda/master/docs/viewer_demo.gif&#34; alt=&#34;3D Gaussian Splatting Viewer&#34; width=&#34;80%&#34;&gt; &#xA;&lt;h2&gt;🏆 Competition&lt;/h2&gt; &#xA;&lt;p&gt;Reduce training time by half and win &lt;strong&gt;$900 prize&lt;/strong&gt;!&lt;br&gt; Details here: &lt;a href=&#34;https://github.com/MrNeRF/gaussian-splatting-cuda/issues/135&#34;&gt;Issue #135&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This competition is sponsored by &lt;a href=&#34;https://github.com/vincentwoo&#34;&gt;@vincentwoo&lt;/a&gt;, &lt;a href=&#34;https://github.com/mazy1998&#34;&gt;@mazy1998&lt;/a&gt;, and myself - each contributing &lt;strong&gt;$300&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;📰 News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2025-06-24]&lt;/strong&gt;: The competition is live with a &lt;strong&gt;$900 prize pool&lt;/strong&gt;!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2025-06-20]&lt;/strong&gt;: Added interactive viewer with real-time visualization during training by @panxkun.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2025-06-19]&lt;/strong&gt;: Metrics are now on par with gsplat-mcmc. Gsplat evals on downscaled png images whereas I used jpgs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2025-06-15]&lt;/strong&gt;: Different render modes exposed, refactors, added bilateral grid.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2025-06-13]&lt;/strong&gt;: Metrics are getting very close to gsplat-mcmc. LPIPS and time estimates are not comparable as of now.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2025-06-10]&lt;/strong&gt;: Fixed some issues. We are closing the gap to the gsplat metrics. However, there is still a small mismatch.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2025-06-04]&lt;/strong&gt;: Added MCMC strategy with &lt;code&gt;--max-cap&lt;/code&gt; command line option for controlling maximum Gaussian count.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2025-06-03]&lt;/strong&gt;: Switched to Gsplat backend and updated license to Apache 2.0.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2024-05-27]&lt;/strong&gt;: Updated to LibTorch 2.7.0 for better compatibility and performance. Breaking changes in optimizer state management have been addressed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LPIPS Model&lt;/h3&gt; &#xA;&lt;p&gt;The implementation uses &lt;code&gt;weights/lpips_vgg.pt&lt;/code&gt;, which is exported from &lt;code&gt;torchmetrics.image.lpip.LearnedPerceptualImagePatchSimilarity&lt;/code&gt; with:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Network type&lt;/strong&gt;: VGG&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Normalize&lt;/strong&gt;: False (model expects inputs in [-1, 1] range)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Model includes&lt;/strong&gt;: VGG backbone with pretrained ImageNet weights and the scaling normalization layer&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: While the model was exported with &lt;code&gt;normalize=False&lt;/code&gt;, the C++ implementation handles the [0,1] to [-1,1] conversion internally during LPIPS computation, ensuring compatibility with images loaded in [0,1] range.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Scene&lt;/th&gt; &#xA;   &lt;th&gt;Iteration&lt;/th&gt; &#xA;   &lt;th&gt;PSNR&lt;/th&gt; &#xA;   &lt;th&gt;SSIM&lt;/th&gt; &#xA;   &lt;th&gt;LPIPS&lt;/th&gt; &#xA;   &lt;th&gt;Num Gaussians&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;garden&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;27.538504&lt;/td&gt; &#xA;   &lt;td&gt;0.866146&lt;/td&gt; &#xA;   &lt;td&gt;0.148426&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;bicycle&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;25.771051&lt;/td&gt; &#xA;   &lt;td&gt;0.790709&lt;/td&gt; &#xA;   &lt;td&gt;0.244115&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stump&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;27.141726&lt;/td&gt; &#xA;   &lt;td&gt;0.805854&lt;/td&gt; &#xA;   &lt;td&gt;0.246617&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;bonsai&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;32.586533&lt;/td&gt; &#xA;   &lt;td&gt;0.953505&lt;/td&gt; &#xA;   &lt;td&gt;0.224543&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;counter&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;29.346529&lt;/td&gt; &#xA;   &lt;td&gt;0.923511&lt;/td&gt; &#xA;   &lt;td&gt;0.223990&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;kitchen&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;31.840155&lt;/td&gt; &#xA;   &lt;td&gt;0.938906&lt;/td&gt; &#xA;   &lt;td&gt;0.141826&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;room&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;32.511021&lt;/td&gt; &#xA;   &lt;td&gt;0.938708&lt;/td&gt; &#xA;   &lt;td&gt;0.253696&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;mean&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;30000&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;29.533646&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.888191&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.211888&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;1000000&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;For reference, here are the metrics for the official gsplat-mcmc implementation below. However, the lpips results are not directly comparable, as the gsplat-mcmc implementation uses a different lpips model.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Scene&lt;/th&gt; &#xA;   &lt;th&gt;Iteration&lt;/th&gt; &#xA;   &lt;th&gt;PSNR&lt;/th&gt; &#xA;   &lt;th&gt;SSIM&lt;/th&gt; &#xA;   &lt;th&gt;LPIPS&lt;/th&gt; &#xA;   &lt;th&gt;Num Gaussians&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;garden&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;27.307266&lt;/td&gt; &#xA;   &lt;td&gt;0.854643&lt;/td&gt; &#xA;   &lt;td&gt;0.103883&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;bicycle&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;25.615253&lt;/td&gt; &#xA;   &lt;td&gt;0.774689&lt;/td&gt; &#xA;   &lt;td&gt;0.182401&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stump&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;26.964493&lt;/td&gt; &#xA;   &lt;td&gt;0.789816&lt;/td&gt; &#xA;   &lt;td&gt;0.162758&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;bonsai&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;32.735737&lt;/td&gt; &#xA;   &lt;td&gt;0.953360&lt;/td&gt; &#xA;   &lt;td&gt;0.105922&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;counter&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;29.495266&lt;/td&gt; &#xA;   &lt;td&gt;0.924103&lt;/td&gt; &#xA;   &lt;td&gt;0.129898&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;kitchen&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;31.660593&lt;/td&gt; &#xA;   &lt;td&gt;0.935315&lt;/td&gt; &#xA;   &lt;td&gt;0.087113&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;room&lt;/td&gt; &#xA;   &lt;td&gt;30000&lt;/td&gt; &#xA;   &lt;td&gt;32.265732&lt;/td&gt; &#xA;   &lt;td&gt;0.937518&lt;/td&gt; &#xA;   &lt;td&gt;0.132472&lt;/td&gt; &#xA;   &lt;td&gt;1000000&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;mean&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;30000&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;29.434906&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.881349&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.129207&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;1000000&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; &#xA;&lt;p&gt;Join our growing community for discussions, support, and updates:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;💬 &lt;strong&gt;&lt;a href=&#34;https://discord.gg/TbxJST2BbC&#34;&gt;Discord Community&lt;/a&gt;&lt;/strong&gt; - Get help, share results, and discuss development&lt;/li&gt; &#xA; &lt;li&gt;🌐 &lt;strong&gt;&lt;a href=&#34;https://mrnerf.com&#34;&gt;mrnerf.com&lt;/a&gt;&lt;/strong&gt; - Visit our website for more resources&lt;/li&gt; &#xA; &lt;li&gt;📚 &lt;strong&gt;&lt;a href=&#34;https://mrnerf.github.io/awesome-3D-gaussian-splatting/&#34;&gt;Awesome 3D Gaussian Splatting&lt;/a&gt;&lt;/strong&gt; - Comprehensive paper list and resources&lt;/li&gt; &#xA; &lt;li&gt;🐦 &lt;strong&gt;&lt;a href=&#34;https://twitter.com/janusch_patas&#34;&gt;@janusch_patas&lt;/a&gt;&lt;/strong&gt; - Follow for the latest updates&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Build and Execution Instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Software Prerequisites&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; (tested with Ubuntu 22.04) - Windows is currently not supported&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CMake&lt;/strong&gt; 3.24 or higher&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CUDA&lt;/strong&gt; 11.8 or higher (may work with lower versions with manual configuration)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt; with development headers&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LibTorch 2.7.0&lt;/strong&gt; - Setup instructions below&lt;/li&gt; &#xA; &lt;li&gt;Other dependencies are handled automatically by CMake&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Hardware Prerequisites&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;NVIDIA GPU&lt;/strong&gt; with CUDA support &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Successfully tested: RTX 4090, RTX A5000, RTX 3090Ti, A100&lt;/li&gt; &#xA;   &lt;li&gt;Known issue with RTX 3080Ti on larger datasets (see #21)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Minimum compute capability: 8.0&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;If you successfully run on other hardware, please share your experience in the Discussions section!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Build Instructions&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Clone the repository with submodules&#xA;git clone --recursive https://github.com/MrNeRF/gaussian-splatting-cuda&#xA;cd gaussian-splatting-cuda&#xA;&#xA;# Download and setup LibTorch&#xA;wget https://download.pytorch.org/libtorch/cu118/libtorch-cxx11-abi-shared-with-deps-2.7.0%2Bcu118.zip  &#xA;unzip libtorch-cxx11-abi-shared-with-deps-2.7.0+cu118.zip -d external/&#xA;rm libtorch-cxx11-abi-shared-with-deps-2.7.0+cu118.zip&#xA;&#xA;# Build the project&#xA;cmake -B build -DCMAKE_BUILD_TYPE=Release&#xA;cmake --build build -- -j&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;LibTorch 2.7.0&lt;/h2&gt; &#xA;&lt;p&gt;This project uses &lt;strong&gt;LibTorch 2.7.0&lt;/strong&gt; for optimal performance and compatibility:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Enhanced Performance&lt;/strong&gt;: Improved optimization and memory management&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;API Stability&lt;/strong&gt;: Latest stable PyTorch C++ API&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CUDA Compatibility&lt;/strong&gt;: Better integration with CUDA 11.8+&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bug Fixes&lt;/strong&gt;: Resolved optimizer state management issues&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Upgrading from Previous Versions&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the new LibTorch version using the build instructions&lt;/li&gt; &#xA; &lt;li&gt;Clean your build directory: &lt;code&gt;rm -rf build/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Rebuild the project&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Dataset&lt;/h2&gt; &#xA;&lt;p&gt;Download the dataset from the original repository: &lt;a href=&#34;https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/datasets/input/tandt_db.zip&#34;&gt;Tanks &amp;amp; Trains Dataset&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Extract it to the &lt;code&gt;data&lt;/code&gt; folder in the project root.&lt;/p&gt; &#xA;&lt;h2&gt;Command-Line Options&lt;/h2&gt; &#xA;&lt;h3&gt;Required Options&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;-d, --data-path [PATH]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Path to the training data containing COLMAP sparse reconstruction (required)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Output Options&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;-o, --output-path [PATH]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Path to save the trained model (default: &lt;code&gt;./output&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Training Options&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;-i, --iter [NUM]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Number of training iterations (default: 30000)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Paper suggests 30k, but 6k-7k often yields good preliminary results&lt;/li&gt; &#xA;   &lt;li&gt;Outputs are saved every 7k iterations and at completion&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;-r, --resolution [NUM]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Set the resolution for training images&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;-1: Use original resolution (default)&lt;/li&gt; &#xA;   &lt;li&gt;Positive values: Target resolution for image loading&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--steps-scaler [NUM]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Scale all training steps by this factor (default: 1)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Multiplies iterations, refinement steps, and evaluation/save intervals&lt;/li&gt; &#xA;   &lt;li&gt;Creates multiple scaled checkpoints for each original step&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;MCMC-Specific Options&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;--max-cap [NUM]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Maximum number of Gaussians for MCMC strategy (default: 1000000) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Controls the upper limit of Gaussian splats during training&lt;/li&gt; &#xA;   &lt;li&gt;Useful for memory-constrained environments&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Dataset Configuration&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--images [FOLDER]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Images folder name (default: &lt;code&gt;images&lt;/code&gt;)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Options: &lt;code&gt;images&lt;/code&gt;, &lt;code&gt;images_2&lt;/code&gt;, &lt;code&gt;images_4&lt;/code&gt;, &lt;code&gt;images_8&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Mip-NeRF 360 dataset uses different resolutions&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--test-every [NUM]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Every N-th image is used as a test image (default: 8)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Used for train/validation split&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Evaluation Options&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--eval&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Enable evaluation during training&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Computes metrics (PSNR, SSIM, LPIPS) at specified steps&lt;/li&gt; &#xA;   &lt;li&gt;Evaluation steps defined in &lt;code&gt;parameter/optimization_params.json&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--save-eval-images&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Save evaluation images during training&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Requires &lt;code&gt;--eval&lt;/code&gt; to be enabled&lt;/li&gt; &#xA;   &lt;li&gt;Saves comparison images and depth maps (if applicable)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Render Mode Options&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;--render-mode [MODE]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Render mode for training and evaluation (default: &lt;code&gt;RGB&lt;/code&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;RGB&lt;/code&gt;: Color only&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;D&lt;/code&gt;: Accumulated depth only&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;ED&lt;/code&gt;: Expected depth only&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;RGB_D&lt;/code&gt;: Color + accumulated depth&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;RGB_ED&lt;/code&gt;: Color + expected depth&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Visualization Options&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;-v, --viz&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Enable the Visualization mode &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Displays the current state of the Gaussian splatting in a window&lt;/li&gt; &#xA;   &lt;li&gt;Useful for debugging and monitoring training progress&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Advanced Options&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--bilateral-grid&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Enable bilateral grid for appearance modeling&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Helps with per-image appearance variations&lt;/li&gt; &#xA;   &lt;li&gt;Adds TV (Total Variation) regularization&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;--sh-degree-interval [NUM]&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Interval for increasing spherical harmonics degree&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Controls how often SH degree is incremented during training&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;-h, --help&lt;/code&gt;&lt;/strong&gt;&lt;br&gt; Display the help menu&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Example Usage&lt;/h3&gt; &#xA;&lt;p&gt;Basic training:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./build/gaussian_splatting_cuda -d /path/to/data -o /path/to/output&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;MCMC training with limited Gaussians:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./build/gaussian_splatting_cuda -d /path/to/data -o /path/to/output --max-cap 500000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Training with evaluation and custom settings:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./build/gaussian_splatting_cuda \&#xA;    -d data/garden \&#xA;    -o output/garden \&#xA;    --images images_4 \&#xA;    --test-every 8 \&#xA;    --eval \&#xA;    --save-eval-images \&#xA;    --render-mode RGB_D \&#xA;    -i 30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Force overwrite existing output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./build/gaussian_splatting_cuda -d data/garden -o output/garden -f&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Training with step scaling for multiple checkpoints:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./build/gaussian_splatting_cuda \&#xA;    -d data/garden \&#xA;    -o output/garden \&#xA;    --steps-scaler 3 \&#xA;    -i 10000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configuration Files&lt;/h2&gt; &#xA;&lt;p&gt;The implementation uses JSON configuration files located in the &lt;code&gt;parameter/&lt;/code&gt; directory:&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;optimization_params.json&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Controls training hyperparameters including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Learning rates for different components&lt;/li&gt; &#xA; &lt;li&gt;Regularization weights&lt;/li&gt; &#xA; &lt;li&gt;Refinement schedules&lt;/li&gt; &#xA; &lt;li&gt;Evaluation and save steps&lt;/li&gt; &#xA; &lt;li&gt;Render mode settings&lt;/li&gt; &#xA; &lt;li&gt;Bilateral grid parameters&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Key parameters can be overridden via command-line options.&lt;/p&gt; &#xA;&lt;h2&gt;Contribution Guidelines&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions! Here&#39;s how to get started:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Check out issues labeled as &lt;strong&gt;good first issues&lt;/strong&gt; for beginner-friendly tasks&lt;/li&gt; &#xA;   &lt;li&gt;For new ideas, open a discussion or join our &lt;a href=&#34;https://discord.gg/TbxJST2BbC&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Before Submitting a PR&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Apply &lt;code&gt;clang-format&lt;/code&gt; for consistent code style&lt;/li&gt; &#xA;   &lt;li&gt;Use the pre-commit hook: &lt;code&gt;cp tools/pre-commit .git/hooks/&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Discuss new dependencies in an issue first - we aim to minimize dependencies&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;This implementation builds upon several key projects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/nerfstudio-project/gsplat&#34;&gt;gsplat&lt;/a&gt;&lt;/strong&gt;: We use gsplat&#39;s highly optimized CUDA rasterization backend, which provides significant performance improvements and better memory efficiency.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Original 3D Gaussian Splatting&lt;/strong&gt;: Based on the groundbreaking work by Kerbl et al.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use this software in your research, please cite the original work:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{kerbl3Dgaussians,&#xA;  author    = {Kerbl, Bernhard and Kopanas, Georgios and Leimkühler, Thomas and Drettakis, George},&#xA;  title     = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},&#xA;  journal   = {ACM Transactions on Graphics},&#xA;  number    = {4},&#xA;  volume    = {42},&#xA;  month     = {July},&#xA;  year      = {2023},&#xA;  url       = {https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;See LICENSE file for details.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;Connect with us:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🌐 Website: &lt;a href=&#34;https://mrnerf.com&#34;&gt;mrnerf.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;📚 Papers: &lt;a href=&#34;https://mrnerf.github.io/awesome-3D-gaussian-splatting/&#34;&gt;Awesome 3D Gaussian Splatting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;💬 Discord: &lt;a href=&#34;https://discord.gg/TbxJST2BbC&#34;&gt;Join our community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🐦 Twitter: Follow &lt;a href=&#34;https://twitter.com/janusch_patas&#34;&gt;@janusch_patas&lt;/a&gt; for development updates&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>