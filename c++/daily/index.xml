<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-16T01:30:42Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>IonelPopJara/ascii-video-player</title>
    <updated>2022-06-16T01:30:42Z</updated>
    <id>tag:github.com,2022-06-16:/IonelPopJara/ascii-video-player</id>
    <link href="https://github.com/IonelPopJara/ascii-video-player" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A simple script that turns .mp4 files into ASCII characters&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ascii-video-player&lt;/h1&gt; &#xA;&lt;p&gt;A simple script that turns .mp4 files into ASCII characters&lt;/p&gt; &#xA;&lt;p&gt;This is a modified version inspired by PtitGnou.&lt;/p&gt; &#xA;&lt;p&gt;Original Code: &lt;a href=&#34;https://github.com/PtitGnou/AsciiVideoCPP&#34;&gt;https://github.com/PtitGnou/AsciiVideoCPP&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;In order to use the script you should have the .mp4 file in the same folder and when asked in the promt write the name of the files without the &#34;.mp4&#34;. For example if the file is &#34;video.mp4&#34; you just need to write &#34;video&#34;.&lt;/p&gt; &#xA;&lt;p&gt;You need to make sure to install OpenCV and use C++17 or Newer.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>google/sentencepiece</title>
    <updated>2022-06-16T01:30:42Z</updated>
    <id>tag:github.com,2022-06-16:/google/sentencepiece</id>
    <link href="https://github.com/google/sentencepiece" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Unsupervised text tokenizer for Neural Network-based text generation.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SentencePiece&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/google/sentencepiece/actions/workflows/cmake.yml&#34;&gt;&lt;img src=&#34;https://github.com/google/sentencepiece/actions/workflows/cmake.yml/badge.svg?sanitize=true&#34; alt=&#34;Build C++&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/google/sentencepiece/actions/workflows/wheel.yml&#34;&gt;&lt;img src=&#34;https://github.com/google/sentencepiece/actions/workflows/wheel.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Wheels&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/google/sentencepiece/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/google/sentencepiece.svg?sanitize=true&#34; alt=&#34;GitHub Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://badge.fury.io/py/sentencepiece&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/sentencepiece.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/sentencepiece/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/sentencepiece?style=flat-square&amp;amp;logo=pypi&amp;amp;logoColor=white&#34; alt=&#34;PyPi downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/CONTRIBUTING.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?sanitize=true&#34; alt=&#34;Contributions welcome&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements &lt;strong&gt;subword units&lt;/strong&gt; (e.g., &lt;strong&gt;byte-pair-encoding (BPE)&lt;/strong&gt; [&lt;a href=&#34;https://www.aclweb.org/anthology/P16-1162&#34;&gt;Sennrich et al.&lt;/a&gt;]) and &lt;strong&gt;unigram language model&lt;/strong&gt; [&lt;a href=&#34;https://arxiv.org/abs/1804.10959&#34;&gt;Kudo.&lt;/a&gt;]) with the extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;This is not an official Google product.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Technical highlights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Purely data driven&lt;/strong&gt;: SentencePiece trains tokenization and detokenization models from sentences. Pre-tokenization (&lt;a href=&#34;https://github.com/moses-smt/mosesdecoder/raw/master/scripts/tokenizer/tokenizer.perl&#34;&gt;Moses tokenizer&lt;/a&gt;/&lt;a href=&#34;http://taku910.github.io/mecab/&#34;&gt;MeCab&lt;/a&gt;/&lt;a href=&#34;http://www.phontron.com/kytea/&#34;&gt;KyTea&lt;/a&gt;) is not always required.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Language independent&lt;/strong&gt;: SentencePiece treats the sentences just as sequences of Unicode characters. There is no language-dependent logic.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multiple subword algorithms&lt;/strong&gt;: &lt;strong&gt;BPE&lt;/strong&gt; [&lt;a href=&#34;https://www.aclweb.org/anthology/P16-1162&#34;&gt;Sennrich et al.&lt;/a&gt;] and &lt;strong&gt;unigram language model&lt;/strong&gt; [&lt;a href=&#34;https://arxiv.org/abs/1804.10959&#34;&gt;Kudo.&lt;/a&gt;] are supported.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Subword regularization&lt;/strong&gt;: SentencePiece implements subword sampling for &lt;a href=&#34;https://arxiv.org/abs/1804.10959&#34;&gt;subword regularization&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/1910.13267&#34;&gt;BPE-dropout&lt;/a&gt; which help to improve the robustness and accuracy of NMT models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fast and lightweight&lt;/strong&gt;: Segmentation speed is around 50k sentences/sec, and memory footprint is around 6MB.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Self-contained&lt;/strong&gt;: The same tokenization/detokenization is obtained as long as the same model file is used.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Direct vocabulary id generation&lt;/strong&gt;: SentencePiece manages vocabulary to id mapping and can directly generate vocabulary id sequences from raw sentences.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;NFKC-based normalization&lt;/strong&gt;: SentencePiece performs NFKC-based text normalization.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For those unfamiliar with SentencePiece as a software/algorithm, one can read &lt;a href=&#34;https://medium.com/@jacky2wong/understanding-sentencepiece-under-standing-sentence-piece-ac8da59f6b08&#34;&gt;a gentle introduction here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Comparisons with other implementations&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Feature&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;SentencePiece&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/rsennrich/subword-nmt&#34;&gt;subword-nmt&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/pdf/1609.08144.pdf&#34;&gt;WordPiece&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Supported algorithm&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;BPE, unigram, char, word&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;BPE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;BPE*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;OSS?&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Google internal&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Subword regularization&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/#subword-regularization&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Python Library (pip)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/python/README.md&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;C++ Library&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/doc/api.md&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Pre-segmentation required?&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/#whitespace-is-treated-as-a-basic-symbol&#34;&gt;No&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Customizable normalization (e.g., NFKC)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/doc/normalization.md&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Direct id generation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/#end-to-end-example&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Note that BPE algorithm used in WordPiece is slightly different from the original BPE.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;h3&gt;What is SentencePiece?&lt;/h3&gt; &#xA;&lt;p&gt;SentencePiece is a re-implementation of &lt;strong&gt;sub-word units&lt;/strong&gt;, an effective way to alleviate the open vocabulary problems in neural machine translation. SentencePiece supports two segmentation algorithms, &lt;strong&gt;byte-pair-encoding (BPE)&lt;/strong&gt; [&lt;a href=&#34;http://www.aclweb.org/anthology/P16-1162&#34;&gt;Sennrich et al.&lt;/a&gt;] and &lt;strong&gt;unigram language model&lt;/strong&gt; [&lt;a href=&#34;https://arxiv.org/abs/1804.10959&#34;&gt;Kudo.&lt;/a&gt;]. Here are the high level differences from other implementations.&lt;/p&gt; &#xA;&lt;h4&gt;The number of unique tokens is predetermined&lt;/h4&gt; &#xA;&lt;p&gt;Neural Machine Translation models typically operate with a fixed vocabulary. Unlike most unsupervised word segmentation algorithms, which assume an infinite vocabulary, SentencePiece trains the segmentation model such that the final vocabulary size is fixed, e.g., 8k, 16k, or 32k.&lt;/p&gt; &#xA;&lt;p&gt;Note that SentencePiece specifies the final vocabulary size for training, which is different from &lt;a href=&#34;https://github.com/rsennrich/subword-nmt&#34;&gt;subword-nmt&lt;/a&gt; that uses the number of merge operations. The number of merge operations is a BPE-specific parameter and not applicable to other segmentation algorithms, including unigram, word and character.&lt;/p&gt; &#xA;&lt;h4&gt;Trains from raw sentences&lt;/h4&gt; &#xA;&lt;p&gt;Previous sub-word implementations assume that the input sentences are pre-tokenized. This constraint was required for efficient training, but makes the preprocessing complicated as we have to run language dependent tokenizers in advance. The implementation of SentencePiece is fast enough to train the model from raw sentences. This is useful for training the tokenizer and detokenizer for Chinese and Japanese where no explicit spaces exist between words.&lt;/p&gt; &#xA;&lt;h4&gt;Whitespace is treated as a basic symbol&lt;/h4&gt; &#xA;&lt;p&gt;The first step of Natural Language processing is text tokenization. For example, a standard English tokenizer would segment the text &#34;Hello world.&#34; into the following three tokens.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[Hello] [World] [.]&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;One observation is that the original input and tokenized sequence are &lt;strong&gt;NOT reversibly convertible&lt;/strong&gt;. For instance, the information that is no space between “World” and “.” is dropped from the tokenized sequence, since e.g., &lt;code&gt;Tokenize(“World.”) == Tokenize(“World .”)&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;SentencePiece treats the input text just as a sequence of Unicode characters. Whitespace is also handled as a normal symbol. To handle the whitespace as a basic token explicitly, SentencePiece first escapes the whitespace with a meta symbol &#34;▁&#34; (U+2581) as follows.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Hello▁World.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Then, this text is segmented into small pieces, for example:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[Hello] [▁Wor] [ld] [.]&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Since the whitespace is preserved in the segmented text, we can detokenize the text without any ambiguities.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  detokenized = &#39;&#39;.join(pieces).replace(&#39;▁&#39;, &#39; &#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This feature makes it possible to perform detokenization without relying on language-specific resources.&lt;/p&gt; &#xA;&lt;p&gt;Note that we cannot apply the same lossless conversions when splitting the sentence with standard word segmenters, since they treat the whitespace as a special symbol. Tokenized sequences do not preserve the necessary information to restore the original sentence.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;(en) Hello world. → [Hello] [World] [.] (A space between Hello and World)&lt;/li&gt; &#xA; &lt;li&gt;(ja) こんにちは世界。 → [こんにちは] [世界] [。] (No space between こんにちは and 世界)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Subword regularization and BPE-dropout&lt;/h4&gt; &#xA;&lt;p&gt;Subword regularization [&lt;a href=&#34;https://arxiv.org/abs/1804.10959&#34;&gt;Kudo.&lt;/a&gt;] and BPE-dropout &lt;a href=&#34;https://arxiv.org/abs/1910.13267&#34;&gt;Provilkov et al&lt;/a&gt; are simple regularization methods that virtually augment training data with on-the-fly subword sampling, which helps to improve the accuracy as well as robustness of NMT models.&lt;/p&gt; &#xA;&lt;p&gt;To enable subword regularization, you would like to integrate SentencePiece library (&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/doc/api.md#sampling-subword-regularization&#34;&gt;C++&lt;/a&gt;/&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/python/README.md&#34;&gt;Python&lt;/a&gt;) into the NMT system to sample one segmentation for each parameter update, which is different from the standard off-line data preparations. Here&#39;s the example of &lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/python/README.md&#34;&gt;Python library&lt;/a&gt;. You can find that &#39;New York&#39; is segmented differently on each &lt;code&gt;SampleEncode (C++)&lt;/code&gt; or &lt;code&gt;encode with enable_sampling=True (Python)&lt;/code&gt; calls. The details of sampling parameters are found in &lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/src/sentencepiece_processor.h&#34;&gt;sentencepiece_processor.h&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import sentencepiece as spm&#xA;&amp;gt;&amp;gt;&amp;gt; s = spm.SentencePieceProcessor(model_file=&#39;spm.model&#39;)&#xA;&amp;gt;&amp;gt;&amp;gt; for n in range(5):&#xA;...     s.encode(&#39;New York&#39;, out_type=str, enable_sampling=True, alpha=0.1, nbest_size=-1)&#xA;...&#xA;[&#39;▁&#39;, &#39;N&#39;, &#39;e&#39;, &#39;w&#39;, &#39;▁York&#39;]&#xA;[&#39;▁&#39;, &#39;New&#39;, &#39;▁York&#39;]&#xA;[&#39;▁&#39;, &#39;New&#39;, &#39;▁Y&#39;, &#39;o&#39;, &#39;r&#39;, &#39;k&#39;]&#xA;[&#39;▁&#39;, &#39;New&#39;, &#39;▁York&#39;]&#xA;[&#39;▁&#39;, &#39;New&#39;, &#39;▁York&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Python module&lt;/h3&gt; &#xA;&lt;p&gt;SentencePiece provides Python wrapper that supports both SentencePiece training and segmentation. You can install Python binary package of SentencePiece with.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% pip install sentencepiece&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more detail, see &lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/python/README.md&#34;&gt;Python module&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Build and install SentencePiece command line tools from C++ source&lt;/h3&gt; &#xA;&lt;p&gt;The following tools and libraries are required to build SentencePiece:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cmake.org/&#34;&gt;cmake&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;C++11 compiler&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gperftools/gperftools&#34;&gt;gperftools&lt;/a&gt; library (optional, 10-40% performance improvement can be obtained.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;On Ubuntu, the build tools can be installed with apt-get:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% sudo apt-get install cmake build-essential pkg-config libgoogle-perftools-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, you can build and install command line tools as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% git clone https://github.com/google/sentencepiece.git &#xA;% cd sentencepiece&#xA;% mkdir build&#xA;% cd build&#xA;% cmake ..&#xA;% make -j $(nproc)&#xA;% sudo make install&#xA;% sudo ldconfig -v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On OSX/macOS, replace the last command with &lt;code&gt;sudo update_dyld_shared_cache&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Build and install using vcpkg&lt;/h3&gt; &#xA;&lt;p&gt;You can download and install sentencepiece using the &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;vcpkg&lt;/a&gt; dependency manager:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/Microsoft/vcpkg.git&#xA;cd vcpkg&#xA;./bootstrap-vcpkg.sh&#xA;./vcpkg integrate install&#xA;./vcpkg install sentencepiece&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The sentencepiece port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please &lt;a href=&#34;https://github.com/Microsoft/vcpkg&#34;&gt;create an issue or pull request&lt;/a&gt; on the vcpkg repository.&lt;/p&gt; &#xA;&lt;h2&gt;Usage instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Train SentencePiece Model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_train --input=&amp;lt;input&amp;gt; --model_prefix=&amp;lt;model_name&amp;gt; --vocab_size=8000 --character_coverage=1.0 --model_type=&amp;lt;type&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--input&lt;/code&gt;: one-sentence-per-line &lt;strong&gt;raw&lt;/strong&gt; corpus file. No need to run tokenizer, normalizer or preprocessor. By default, SentencePiece normalizes the input with Unicode NFKC. You can pass a comma-separated list of files.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--model_prefix&lt;/code&gt;: output model name prefix. &lt;code&gt;&amp;lt;model_name&amp;gt;.model&lt;/code&gt; and &lt;code&gt;&amp;lt;model_name&amp;gt;.vocab&lt;/code&gt; are generated.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--vocab_size&lt;/code&gt;: vocabulary size, e.g., 8000, 16000, or 32000&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--character_coverage&lt;/code&gt;: amount of characters covered by the model, good defaults are: &lt;code&gt;0.9995&lt;/code&gt; for languages with rich character set like Japanese or Chinese and &lt;code&gt;1.0&lt;/code&gt; for other languages with small character set.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--model_type&lt;/code&gt;: model type. Choose from &lt;code&gt;unigram&lt;/code&gt; (default), &lt;code&gt;bpe&lt;/code&gt;, &lt;code&gt;char&lt;/code&gt;, or &lt;code&gt;word&lt;/code&gt;. The input sentence must be pretokenized when using &lt;code&gt;word&lt;/code&gt; type.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Use &lt;code&gt;--help&lt;/code&gt; flag to display all parameters for training, or see &lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/doc/options.md&#34;&gt;here&lt;/a&gt; for an overview.&lt;/p&gt; &#xA;&lt;h3&gt;Encode raw text into sentence pieces/ids&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_encode --model=&amp;lt;model_file&amp;gt; --output_format=piece &amp;lt; input &amp;gt; output&#xA;% spm_encode --model=&amp;lt;model_file&amp;gt; --output_format=id &amp;lt; input &amp;gt; output&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use &lt;code&gt;--extra_options&lt;/code&gt; flag to insert the BOS/EOS markers or reverse the input sequence.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_encode --extra_options=eos (add &amp;lt;/s&amp;gt; only)&#xA;% spm_encode --extra_options=bos:eos (add &amp;lt;s&amp;gt; and &amp;lt;/s&amp;gt;)&#xA;% spm_encode --extra_options=reverse:bos:eos (reverse input and add &amp;lt;s&amp;gt; and &amp;lt;/s&amp;gt;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;SentencePiece supports nbest segmentation and segmentation sampling with &lt;code&gt;--output_format=(nbest|sample)_(piece|id)&lt;/code&gt; flags.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_encode --model=&amp;lt;model_file&amp;gt; --output_format=sample_piece --nbest_size=-1 --alpha=0.5 &amp;lt; input &amp;gt; output&#xA;% spm_encode --model=&amp;lt;model_file&amp;gt; --output_format=nbest_id --nbest_size=10 &amp;lt; input &amp;gt; output&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Decode sentence pieces/ids into raw text&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_decode --model=&amp;lt;model_file&amp;gt; --input_format=piece &amp;lt; input &amp;gt; output&#xA;% spm_decode --model=&amp;lt;model_file&amp;gt; --input_format=id &amp;lt; input &amp;gt; output&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use &lt;code&gt;--extra_options&lt;/code&gt; flag to decode the text in reverse order.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_decode --extra_options=reverse &amp;lt; input &amp;gt; output&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;End-to-End Example&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_train --input=data/botchan.txt --model_prefix=m --vocab_size=1000&#xA;unigram_model_trainer.cc(494) LOG(INFO) Starts training with :&#xA;input: &#34;../data/botchan.txt&#34;&#xA;... &amp;lt;snip&amp;gt;&#xA;unigram_model_trainer.cc(529) LOG(INFO) EM sub_iter=1 size=1100 obj=10.4973 num_tokens=37630 num_tokens/piece=34.2091&#xA;trainer_interface.cc(272) LOG(INFO) Saving model: m.model&#xA;trainer_interface.cc(281) LOG(INFO) Saving vocabs: m.vocab&#xA;&#xA;% echo &#34;I saw a girl with a telescope.&#34; | spm_encode --model=m.model&#xA;▁I ▁saw ▁a ▁girl ▁with ▁a ▁ te le s c o pe .&#xA;&#xA;% echo &#34;I saw a girl with a telescope.&#34; | spm_encode --model=m.model --output_format=id&#xA;9 459 11 939 44 11 4 142 82 8 28 21 132 6&#xA;&#xA;% echo &#34;9 459 11 939 44 11 4 142 82 8 28 21 132 6&#34; | spm_decode --model=m.model --input_format=id&#xA;I saw a girl with a telescope.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find that the original input sentence is restored from the vocabulary id sequence.&lt;/p&gt; &#xA;&lt;h3&gt;Export vocabulary list&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_export_vocab --model=&amp;lt;model_file&amp;gt; --output=&amp;lt;output file&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;&amp;lt;output file&amp;gt;&lt;/code&gt; stores a list of vocabulary and emission log probabilities. The vocabulary id corresponds to the line number in this file.&lt;/p&gt; &#xA;&lt;h3&gt;Redefine special meta tokens&lt;/h3&gt; &#xA;&lt;p&gt;By default, SentencePiece uses Unknown (&amp;lt;unk&amp;gt;), BOS (&amp;lt;s&amp;gt;) and EOS (&amp;lt;/s&amp;gt;) tokens which have the ids of 0, 1, and 2 respectively. We can redefine this mapping in the training phase as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_train --bos_id=0 --eos_id=1 --unk_id=5 --input=... --model_prefix=... --character_coverage=...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When setting -1 id e.g., &lt;code&gt;bos_id=-1&lt;/code&gt;, this special token is disabled. Note that the unknown id cannot be disabled. We can define an id for padding (&amp;lt;pad&amp;gt;) as &lt;code&gt;--pad_id=3&lt;/code&gt;. &amp;nbsp;&lt;/p&gt; &#xA;&lt;p&gt;If you want to assign another special tokens, please see &lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/doc/special_symbols.md&#34;&gt;Use custom symbols&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Vocabulary restriction&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;spm_encode&lt;/code&gt; accepts a &lt;code&gt;--vocabulary&lt;/code&gt; and a &lt;code&gt;--vocabulary_threshold&lt;/code&gt; option so that &lt;code&gt;spm_encode&lt;/code&gt; will only produce symbols which also appear in the vocabulary (with at least some frequency). The background of this feature is described in &lt;a href=&#34;https://github.com/rsennrich/subword-nmt#best-practice-advice-for-byte-pair-encoding-in-nmt&#34;&gt;subword-nmt page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The usage is basically the same as that of &lt;code&gt;subword-nmt&lt;/code&gt;. Assuming that L1 and L2 are the two languages (source/target languages), train the shared spm model, and get resulting vocabulary for each:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% cat {train_file}.L1 {train_file}.L2 | shuffle &amp;gt; train&#xA;% spm_train --input=train --model_prefix=spm --vocab_size=8000 --character_coverage=0.9995&#xA;% spm_encode --model=spm.model --generate_vocabulary &amp;lt; {train_file}.L1 &amp;gt; {vocab_file}.L1&#xA;% spm_encode --model=spm.model --generate_vocabulary &amp;lt; {train_file}.L2 &amp;gt; {vocab_file}.L2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;shuffle&lt;/code&gt; command is used just in case because &lt;code&gt;spm_train&lt;/code&gt; loads the first 10M lines of corpus by default.&lt;/p&gt; &#xA;&lt;p&gt;Then segment train/test corpus with &lt;code&gt;--vocabulary&lt;/code&gt; option&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;% spm_encode --model=spm.model --vocabulary={vocab_file}.L1 --vocabulary_threshold=50 &amp;lt; {test_file}.L1 &amp;gt; {test_file}.seg.L1&#xA;% spm_encode --model=spm.model --vocabulary={vocab_file}.L2 --vocabulary_threshold=50 &amp;lt; {test_file}.L2 &amp;gt; {test_file}.seg.L2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Advanced topics&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/doc/experiments.md&#34;&gt;SentencePiece Experiments&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/doc/api.md&#34;&gt;SentencePieceProcessor C++ API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/doc/normalization.md&#34;&gt;Use custom text normalization rules&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/doc/special_symbols.md&#34;&gt;Use custom symbols&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/python/README.md&#34;&gt;Python Module&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/sentencepiece/master/tensorflow/README.md&#34;&gt;TensorFlow Module&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[Segmentation and training algorithms in detail]&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>facebookincubator/velox</title>
    <updated>2022-06-16T01:30:42Z</updated>
    <id>tag:github.com,2022-06-16:/facebookincubator/velox</id>
    <link href="https://github.com/facebookincubator/velox" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A new C++ vectorized database acceleration library aimed to optimizing query engines and data processing systems.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://raw.githubusercontent.com/facebookincubator/velox/main/static/logo.svg?sanitize=true&#34; alt=&#34;Velox logo&#34; width=&#34;50%&#34; align=&#34;center&#34;&gt; &#xA;&lt;p&gt;Velox is a C++ database acceleration library which provides reusable, extensible, and high-performance data processing components. These components can be reused to build compute engines focused on different analytical workloads, including batch, interactive, stream processing, and AI/ML. Velox was created by Facebook and it is currently developed in partnership with Intel, ByteDance, and Ahana.&lt;/p&gt; &#xA;&lt;p&gt;In common usage scenarios, Velox takes a fully optimized query plan as input and performs the described computation. Considering Velox does not provide a SQL parser, a dataframe layer, or a query optimizer, it is usually not meant to be used directly by end-users; rather, it is mostly used by developers integrating and optimizing their compute engines.&lt;/p&gt; &#xA;&lt;p&gt;Velox provides the following high-level components:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt;: a generic typing system that supports scalar, complex, and nested types, such as structs, maps, arrays, tensors, etc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vector&lt;/strong&gt;: an &lt;a href=&#34;https://facebookincubator.github.io/velox/develop/vectors.html&#34;&gt;Arrow-compatible columnar memory layout module&lt;/a&gt;, which provides multiple encodings, such as Flat, Dictionary, Constant, Sequence/RLE, and Bias, in addition to a lazy materialization pattern and support for out-of-order writes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Expression Eval&lt;/strong&gt;: a &lt;a href=&#34;https://facebookincubator.github.io/velox/develop/expression-evaluation.html&#34;&gt;fully vectorized expression evaluation engine&lt;/a&gt; that allows expressions to be efficiently executed on top of Vector/Arrow encoded data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Function Packages&lt;/strong&gt;: sets of vectorized function implementations following the Presto and Spark semantic.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Operators&lt;/strong&gt;: implementation of common data processing operators such as scans, projection, filtering, groupBy, orderBy, shuffle, &lt;a href=&#34;https://facebookincubator.github.io/velox/develop/joins.html&#34;&gt;hash join&lt;/a&gt;, unnest, and more.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;I/O&lt;/strong&gt;: a generic connector interface that allows different file formats (ORC/DWRF and Parquet) and storage adapters (S3, HDFS, local files) to be used.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Network Serializers&lt;/strong&gt;: an interface where different wire protocols can be implemented, used for network communication, supporting &lt;a href=&#34;https://prestodb.io/docs/current/develop/serialized-page.html&#34;&gt;PrestoPage&lt;/a&gt; and Spark&#39;s UnsafeRow.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Resource Management&lt;/strong&gt;: a collection of primitives for handling computational resources, such as &lt;a href=&#34;https://facebookincubator.github.io/velox/develop/arena.html&#34;&gt;memory arenas&lt;/a&gt; and buffer management, tasks, drivers, and thread pools for CPU and thread execution, spilling, and caching.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Velox is extensible and allows developers to define their own engine-specific specializations, including:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Custom types&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://facebookincubator.github.io/velox/develop/scalar-functions.html&#34;&gt;Simple and vectorized functions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://facebookincubator.github.io/velox/develop/aggregate-functions.html&#34;&gt;Aggregate functions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Operators&lt;/li&gt; &#xA; &lt;li&gt;File formats&lt;/li&gt; &#xA; &lt;li&gt;Storage adapters&lt;/li&gt; &#xA; &lt;li&gt;Network serializers&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;Examples of extensibility and integration with different component APIs &lt;a href=&#34;https://raw.githubusercontent.com/facebookincubator/velox/main/velox/examples&#34;&gt;can be found here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Developer guides detailing many aspects of the library, in addition to the list of available functions &lt;a href=&#34;https://facebookincubator.github.io/velox&#34;&gt;can be found here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;We provide scripts to help developers setup and install Velox dependencies.&lt;/p&gt; &#xA;&lt;h3&gt;Get the Velox Source&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone --recursive https://github.com/facebookincubator/velox.git&#xA;cd velox&#xA;# if you are updating an existing checkout&#xA;git submodule sync --recursive&#xA;git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Setting up on macOS&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookincubator/velox/main/scripts/setup-macos.sh&#34;&gt;scripts/setup-macos.sh&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Setting up on Linux (Ubuntu 20.04 or later)&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookincubator/velox/main/scripts/setup-ubuntu.sh&#34;&gt;scripts/setup-ubuntu.sh&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Building Velox&lt;/h3&gt; &#xA;&lt;p&gt;Run &lt;code&gt;make&lt;/code&gt; in the root directory to compile the sources. For development, use &lt;code&gt;make debug&lt;/code&gt; to build a non-optimized debug version, or &lt;code&gt;make release&lt;/code&gt; to build an optimized version. Use &lt;code&gt;make unittest&lt;/code&gt; to build and run tests.&lt;/p&gt; &#xA;&lt;p&gt;Note that,&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Velox requires C++17 , thus minimum supported compiler is GCC 5.0 and Clang 5.0.&lt;/li&gt; &#xA; &lt;li&gt;Velox requires the CPU to support instruction sets: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;bmi&lt;/li&gt; &#xA;   &lt;li&gt;bmi2&lt;/li&gt; &#xA;   &lt;li&gt;f16c&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Velox tries to use the following (or equivalent) instruction sets where available: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;On Intel CPUs &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;avx&lt;/li&gt; &#xA;     &lt;li&gt;avx2&lt;/li&gt; &#xA;     &lt;li&gt;sse&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;On ARM &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Neon&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Check our &lt;a href=&#34;https://raw.githubusercontent.com/facebookincubator/velox/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; to learn about how to contribute to the project.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;The main communication channel with the Velox OSS community is through the &lt;a href=&#34;http://velox-oss.slack.com&#34;&gt;the Velox-OSS Slack workspace&lt;/a&gt;. Please reach out to &lt;strong&gt;&lt;a href=&#34;mailto:velox@fb.com&#34;&gt;velox@fb.com&lt;/a&gt;&lt;/strong&gt; to get access to Velox Slack Channel.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Velox is licensed under the Apache 2.0 License. A copy of the license &lt;a href=&#34;https://raw.githubusercontent.com/facebookincubator/velox/main/LICENSE&#34;&gt;can be found here.&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>