<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-28T01:33:48Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>abhi1kumar/DEVIANT</title>
    <updated>2022-07-28T01:33:48Z</updated>
    <id>tag:github.com,2022-07-28:/abhi1kumar/DEVIANT</id>
    <link href="https://github.com/abhi1kumar/DEVIANT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[ECCV 2022] Official PyTorch Code of DEVIANT: Depth EquiVarIAnt NeTwork for Monocular 3D Object Detection&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&#34;https://arxiv.org/pdf/2207.10758.pdf&#34;&gt;DEVIANT: Depth EquiVarIAnt NeTwork for Monocular 3D Object Detection&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2D73ZBrU-PA&#34;&gt;KITTI Demo&lt;/a&gt; | &lt;a href=&#34;https://www.youtube.com/watch?v=70DIjQkuZvw&#34;&gt;KITTI Eqv Error Demo&lt;/a&gt; | &lt;a href=&#34;http://cvlab.cse.msu.edu/project-deviant.html&#34;&gt;Project&lt;/a&gt; | &lt;a href=&#34;&#34;&gt;Slides&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sites.google.com/view/abhinavkumar/&#34;&gt;Abhinav Kumar&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;https://garrickbrazil.com/&#34;&gt;Garrick Brazil&lt;/a&gt;&lt;sup&gt;2&lt;/sup&gt;, &lt;a href=&#34;https://www.linkedin.com/in/enrique-corona-0752b84&#34;&gt;Enrique Corona&lt;/a&gt;&lt;sup&gt;3&lt;/sup&gt;, &lt;a href=&#34;https://www.linkedin.com/in/parchami/&#34;&gt;Armin Parchami&lt;/a&gt;&lt;sup&gt;3&lt;/sup&gt;, &lt;a href=&#34;http://www.cse.msu.edu/~liuxm/index2.html&#34;&gt;Xiaoming Liu&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt; &lt;br&gt; &lt;sup&gt;1&lt;/sup&gt;Michigan State University, &lt;sup&gt;2&lt;/sup&gt;Meta AI, &lt;sup&gt;3&lt;/sup&gt;Ford Motor Company&lt;/p&gt; &#xA;&lt;p&gt;in &lt;a href=&#34;https://eccv2022.ecva.net/&#34;&gt;ECCV 2022&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/abhi1kumar/DEVIANT/main/code/images/waymo_detection_demo.gif&#34; width=&#34;512&#34;&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/abhi1kumar/DEVIANT/main/code/images/idea_overview.png&#34;&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Modern neural networks use building blocks such as convolutions that are equivariant to arbitrary 2D translations $(t_u, t_v)$. However, these vanilla blocks are not equivariant to arbitrary 3D translations $(t_x, t_y, t_z)$ in the projective manifold. Even then, all monocular 3D detectors use vanilla blocks to obtain the 3D coordinates, a task for which the vanilla blocks are not designed for. This paper takes the first step towards convolutions equivariant to arbitrary 3D translations in the projective manifold. Since the depth is the hardest to estimate for monocular detection, this paper proposes Depth EquiVarIAnt NeTwork (DEVIANT) built with existing scale equivariant steerable blocks. As a result, DEVIANT is equivariant to the depth translations $(t_z)$ in the projective manifold whereas vanilla networks are not. The additional depth equivariance forces the DEVIANT to learn consistent depth estimates, and therefore, DEVIANT achieves state-of-the-art monocular 3D detection results on KITTI and Waymo datasets in the image-only category and performs competitively to methods using extra information. Moreover, DEVIANT works better than vanilla networks in cross-dataset evaluation.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Much of the codebase is based on &lt;a href=&#34;https://github.com/SuperMHP/GUPNet&#34;&gt;GUP Net&lt;/a&gt;. Some implementations are from &lt;a href=&#34;https://github.com/abhi1kumar/groomed_nms&#34;&gt;GrooMeD-NMS&lt;/a&gt; and &lt;a href=&#34;https://github.com/amazon-research/progressive-coordinate-transforms&#34;&gt;PCT&lt;/a&gt;. Scale Equivariant Steerable (SES) implementations are from &lt;a href=&#34;https://github.com/ISosnovik/SiamSE&#34;&gt;SiamSE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our work useful in your research, please consider starring the repo and citing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Bibtex&#34;&gt;@inproceedings{kumar2022deviant,&#xA;   title={{DEVIANT: Depth EquiVarIAnt NeTwork for Monocular $3$D Object Detection}},&#xA;   author={Kumar, Abhinav and Brazil, Garrick and Corona, Enrique and Parchami, Armin and Liu, Xiaoming},&#xA;   booktitle={ECCV},&#xA;   year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Requirements&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Python 3.7&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://pytorch.org&#34;&gt;PyTorch&lt;/a&gt; 1.10&lt;/li&gt; &#xA;   &lt;li&gt;Torchvision 0.11&lt;/li&gt; &#xA;   &lt;li&gt;Cuda 11.3&lt;/li&gt; &#xA;   &lt;li&gt;Ubuntu 18.04/Debian 8.9&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This is tested with NVIDIA A100 GPU. Other platforms have not been tested. Clone the repo first. Unless otherwise stated, the below scripts and instructions assume the working directory is the directory &lt;code&gt;code&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/abhi1kumar/DEVIANT.git&#xA;cd DEVIANT/code&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cuda &amp;amp; Python&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Build the DEVIANT environment by installing the requirements:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create --name DEVIANT --file conda_GUP_environment_a100.txt&#xA;conda activate DEVIANT&#xA;pip install opencv-python pandas&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;KITTI, nuScenes and Waymo Data&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Follow instructions of &lt;a href=&#34;https://raw.githubusercontent.com/abhi1kumar/DEVIANT/main/code/data/data_setup_README.md&#34;&gt;data_setup_README.md&lt;/a&gt; to setup KITTI, nuScenes and Waymo as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./code&#xA;├── data&#xA;│      ├── KITTI&#xA;│      │      ├── ImageSets&#xA;│      │      ├── kitti_split1&#xA;│      │      ├── training&#xA;│      │      │     ├── calib&#xA;│      │      │     ├── image_2&#xA;│      │      │     └── label_2&#xA;│      │      │&#xA;│      │      └── testing&#xA;│      │            ├── calib&#xA;│      │            └── image_2&#xA;│      │&#xA;│      ├── nusc_kitti&#xA;│      │      ├── ImageSets&#xA;│      │      ├── training&#xA;│      │      │     ├── calib&#xA;│      │      │     ├── image&#xA;│      │      │     └── label&#xA;│      │      │&#xA;│      │      └── validation&#xA;│      │            ├── calib&#xA;│      │            ├── image&#xA;│      │            └── label&#xA;│      │&#xA;│      └── waymo&#xA;│             ├── ImageSets&#xA;│             ├── training&#xA;│             │     ├── calib&#xA;│             │     ├── image&#xA;│             │     └── label&#xA;│             │&#xA;│             └── validation&#xA;│                   ├── calib&#xA;│                   ├── image&#xA;│                   └── label&#xA;│&#xA;├── experiments&#xA;├── images&#xA;├── lib&#xA;├── nuscenes-devkit        &#xA;│ ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;AP Evaluation&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Run the following to generate the KITTI binaries corresponding to &lt;code&gt;R40&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh data/KITTI/kitti_split1/devkit/cpp/build.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We finally setup the Waymo evaluation. The Waymo evaluation is setup in a different environment &lt;code&gt;py36_waymo_tf&lt;/code&gt; to avoid package conflicts with our DEVIANT environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Set up environment&#xA;conda create -n py36_waymo_tf python=3.7&#xA;conda activate py36_waymo_tf&#xA;conda install cudatoolkit=11.3 -c pytorch&#xA;&#xA;# Newer versions of tf are not in conda. tf&amp;gt;=2.4.0 is compatible with conda.&#xA;pip install tensorflow-gpu==2.4&#xA;conda install pandas&#xA;pip3 install waymo-open-dataset-tf-2-4-0 --user&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To verify that your Waymo evaluation is working correctly, pass the ground truth labels as predictions for a sanity check. Type the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/mnt/home/kumarab6/anaconda3/envs/py36_waymo_tf/bin/python -u data/waymo/waymo_eval.py --sanity&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see AP numbers as 100 in every entry after running this sanity check.&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;Train the model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chmod +x scripts_training.sh&#xA;./scripts_training.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The current Waymo config files use the full val set in training. For Waymo models, we had subsampled Waymo validation set by a factor of 10 (4k images) to save training time as in &lt;a href=&#34;https://github.com/TRI-ML/dd3d#models&#34;&gt;DD3D&lt;/a&gt;. Change &lt;code&gt;val_split_name&lt;/code&gt; from &lt;code&gt;&#39;val&#39;&lt;/code&gt; to &lt;code&gt;&#39;val_small&#39;&lt;/code&gt; in waymo configs to use subsampled Waymo val set.&lt;/p&gt; &#xA;&lt;h2&gt;Testing Pre-trained Models&lt;/h2&gt; &#xA;&lt;h3&gt;Model Zoo&lt;/h3&gt; &#xA;&lt;p&gt;We provide logs/models/predictions for the main experiments on KITTI Val /KITTI Test/Waymo Val data splits available to download here.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Data Split&lt;/th&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Run Name/Config Yaml&lt;/th&gt; &#xA;   &lt;th&gt;Weights&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;KITTI Val&lt;/td&gt; &#xA;   &lt;td&gt;GUP Net&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/abhi1kumar/DEVIANT/main/code/experiments/config_run_201_a100_v0_1.yaml&#34;&gt;config_run_201_a100_v0_1&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/17qezmIjckRSAva1fNnYBmgR9LaY-dPnp/view?usp=sharing&#34;&gt;gdrive&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;KITTI Val&lt;/td&gt; &#xA;   &lt;td&gt;DEVIANT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/abhi1kumar/DEVIANT/main/code/experiments/run_221.yaml&#34;&gt;run_221&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1CBJf8keOutXVSAiu9Fj7XQPQftNYC1qv/view?usp=sharing&#34;&gt;gdrive&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;KITTI Test&lt;/td&gt; &#xA;   &lt;td&gt;DEVIANT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/abhi1kumar/DEVIANT/main/code/experiments/run_250.yaml&#34;&gt;run_250&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1_79GfHcpAQR3wdvhj9GDHc7_c_ndf1Al/view?usp=sharing&#34;&gt;gdrive&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Waymo Val&lt;/td&gt; &#xA;   &lt;td&gt;GUP Net&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/abhi1kumar/DEVIANT/main/code/experiments/run_1050.yaml&#34;&gt;run_1050&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1wuTTuZrFVsEv4ttQ0r3X_s8D3OjYE84E/view?usp=sharing&#34;&gt;gdrive&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Waymo Val&lt;/td&gt; &#xA;   &lt;td&gt;DEVIANT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/abhi1kumar/DEVIANT/main/code/experiments/run_1051.yaml&#34;&gt;run_1051&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1ixCVS85yVU9k6kuHrcYw_qJoy9Z4d0FD/view?usp=sharing&#34;&gt;gdrive&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Testing&lt;/h3&gt; &#xA;&lt;p&gt;Make &lt;code&gt;output&lt;/code&gt; folder in the &lt;code&gt;code&lt;/code&gt; directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir output&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Place models in the &lt;code&gt;output&lt;/code&gt; folder as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./code&#xA;├── output&#xA;│      ├── config_run_201_a100_v0_1&#xA;│      ├── run_221&#xA;│      ├── run_250&#xA;│      ├── run_1050&#xA;│      └── run_1051&#xA;│&#xA;│ ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, to test, run the file as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chmod +x scripts_inference.sh&#xA;./scripts_inference.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Cross-Dataset Evaluation of KITTI on nuScenes Frontal Val&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/abhi1kumar/DEVIANT/main/code/scripts_inference.sh&#34;&gt;scripts_inference.sh&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Qualitative Plots&lt;/h3&gt; &#xA;&lt;p&gt;To get qualitative plots, type the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python plot/plot_qualitative_output.py --dataset waymo --folder output/run_1051/results_test/data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Type the following to reproduce our other plots:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python plot/plot_sesn_basis.py&#xA;python plot/visualize_output_of_cnn_and_sesn.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Inference on older cuda version&lt;/strong&gt; For inference on older cuda version, type the following before running inference:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source cuda_9.0_env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Correct Waymo version&lt;/strong&gt; You should see a 16th column in each ground truth file inside &lt;code&gt;data/waymo/validation/label/&lt;/code&gt;. This corresponds to the &lt;code&gt;num_lidar_points_per_box&lt;/code&gt;. If you do not see this column, run:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd data/waymo&#xA;python waymo_check.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to see if &lt;code&gt;num_lidar_points_per_box&lt;/code&gt; is printed. If nothing is printed, you are using the wrong Waymo dataset version and you should download the correct dataset version.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cannot convert a symbolic Tensor (strided_slice:0) to a numpy array&lt;/strong&gt; This error indicates that you&#39;re trying to pass a Tensor to a NumPy call&#34;. This means you have a wrong numpy version. Install the correct numpy as:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install numpy==1.19.5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;We thank the authors of &lt;a href=&#34;https://github.com/SuperMHP/GUPNet&#34;&gt;GUP Net&lt;/a&gt;, &lt;a href=&#34;https://github.com/abhi1kumar/groomed_nms&#34;&gt;GrooMeD-NMS&lt;/a&gt;, &lt;a href=&#34;https://github.com/ISosnovik/SiamSE&#34;&gt;SiamSE&lt;/a&gt;, &lt;a href=&#34;https://github.com/amazon-research/progressive-coordinate-transforms&#34;&gt;PCT&lt;/a&gt; and &lt;a href=&#34;https://github.com/abhi1kumar/nuscenes-devkit&#34;&gt;patched nuscenes-devkit&lt;/a&gt; for their awesome codebases. Please also consider citing them.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;For questions, feel free to post here or drop an email to this address- &lt;code&gt;abhinav3663@gmail.com&lt;/code&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>sam-astro/Astro8-Computer</title>
    <updated>2022-07-28T01:33:48Z</updated>
    <id>tag:github.com,2022-07-28:/sam-astro/Astro8-Computer</id>
    <link href="https://github.com/sam-astro/Astro8-Computer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;16-bit homebrew CPU&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Astro-8 Computer&lt;/h1&gt; &#xA;&lt;p&gt;This is a 16-bit computer design called the Astro-8. It has a fully functional design in the logic simulator called Logisim Evolution. I also made an emulator for running programs at full speed. Continue reading for installation instructions and how to use it.&lt;/p&gt; &#xA;&lt;h2&gt;Installation:&lt;/h2&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Navigate to &lt;a href=&#34;https://github.com/sam-astro/Astro8-Computer/releases&#34;&gt;the most recent release&lt;/a&gt;, and download the &lt;strong&gt;Windows&lt;/strong&gt; version&lt;/li&gt; &#xA; &lt;li&gt;Unzip the downloaded file&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Linux&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Navigate to &lt;a href=&#34;https://github.com/sam-astro/Astro8-Computer/releases&#34;&gt;the most recent release&lt;/a&gt;, and download the &lt;strong&gt;Linux&lt;/strong&gt; version&lt;/li&gt; &#xA; &lt;li&gt;Unzip the downloaded file&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;From Source&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository in a command line using &lt;code&gt;git clone https://github.com/sam-astro/Astro8-Computer.git&lt;/code&gt; OR by downloading the repository as a .ZIP file and unzipping it to your location of choice&lt;/li&gt; &#xA; &lt;li&gt;Enter the directory &lt;code&gt;Astro8-Computer/Astro8-Emulator/linux-build&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run CMake using &lt;code&gt;cmake ..&lt;/code&gt; to generate Unix Makefile&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;make -j5&lt;/code&gt; to generate executable&lt;/li&gt; &#xA; &lt;li&gt;The executable is &lt;code&gt;Astro8-Computer/Astro8-Emulator/linux-build/Astro8-Emulator&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Use&lt;/h2&gt; &#xA;&lt;h3&gt;Emulator&lt;/h3&gt; &#xA;&lt;p&gt;The file called &lt;code&gt;Astro8-Emulator&lt;/code&gt; serves multiple purposes.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Emulates machine code just like the real hardware&lt;/li&gt; &#xA; &lt;li&gt;Compiles Armstrong into assembly&lt;/li&gt; &#xA; &lt;li&gt;Assembles assembly into machine code and stores it into a file called &lt;code&gt;program_machine_code&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To run your code, you may either simply start the program where you will be prompted to input your code - OR, you can provide a path as a command line argument. You can either type directly into the command line (don&#39;t use any blank lines), or enter a path to your armstrong or assembly file and press enter &lt;em&gt;&lt;strong&gt;twice&lt;/strong&gt;&lt;/em&gt;. The type will be determined by the first line of the file. &lt;em&gt;&lt;strong&gt;All Armstrong files should have &lt;code&gt;#AS&lt;/code&gt; as the first line.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;There is a second executable written in C# called &lt;code&gt;ResourceGenerator&lt;/code&gt;. This is used to generate binary data from the character-set PNG file. Unless you want to change the font or add new characters, you don&#39;t need to use this.&lt;/p&gt; &#xA;&lt;h3&gt;Logisim&lt;/h3&gt; &#xA;&lt;p&gt;Along with the emulator, you can look at the actual circuit design for the system and even run your programs in it.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Compile/Assemble your program using &lt;code&gt;Astro8-Emulator&lt;/code&gt;. It will save the machine code to a file called &lt;code&gt;program_machine_code&lt;/code&gt; automatically. This file is located directly next to the &lt;code&gt;Astro8-Emulator&lt;/code&gt; executable.&lt;/li&gt; &#xA; &lt;li&gt;Open the file called &lt;code&gt;cpu-circuit.circ&lt;/code&gt; in the newest version of &lt;a href=&#34;https://github.com/logisim-evolution/logisim-evolution/releases&#34;&gt;Logisim Evolution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Locate the RAM area, and find the one called &lt;code&gt;MEMORY&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Right-click on it, and click &lt;code&gt;Load Image...&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;In the file view that just appeared, locate your compiled program file directly next to the &lt;code&gt;Astro8-Emulator&lt;/code&gt; executable, and click &lt;code&gt;Open&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Press play, and it should run.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Programming in Armstrong:&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The complete list of armstrong commands are at the bottom of this page.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a file, name it &lt;code&gt;main.armstrong&lt;/code&gt;. It can also end with &lt;code&gt;.arm&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The first line inside this file &lt;em&gt;&lt;strong&gt;must&lt;/strong&gt;&lt;/em&gt; be &lt;code&gt;#AS&lt;/code&gt;. This is how the compiler knows what to do.&lt;/li&gt; &#xA; &lt;li&gt;I recommend using VSCode, because I developed a syntax highlighting &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=sam-astro.armstrong&#34;&gt;extension here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Try out some of the example code in the &lt;code&gt;example_armstrong_programs&lt;/code&gt; folder in this repo.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Technical details:&lt;/h2&gt; &#xA;&lt;h3&gt;Instruction set:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;NOP         00000   : no operation&#xA;AIN &amp;lt;addr&amp;gt;  00001   : load data from &amp;lt;addr&amp;gt; to reg A&#xA;BIN &amp;lt;addr&amp;gt;  00010   : load data from &amp;lt;addr&amp;gt; to reg B&#xA;CIN &amp;lt;addr&amp;gt;  00011   : load data from &amp;lt;addr&amp;gt; to reg C&#xA;LDIA &amp;lt;val&amp;gt;  00100   : immediately load &amp;lt;val&amp;gt; into reg A&#xA;LDIB &amp;lt;val&amp;gt;  00101   : immediately load &amp;lt;val&amp;gt; into reg B&#xA;RDEXP       00110   : load value stored on the expansion port into reg B&#xA;WREXP       00111   : copy reg A into the expansion port&#xA;STA &amp;lt;addr&amp;gt;  01000   : store value of A into &amp;lt;addr&amp;gt; of memory&#xA;STC &amp;lt;addr&amp;gt;  01001   : store value of C into &amp;lt;addr&amp;gt; of memory&#xA;ADD         01010   : add reg B to reg A, and set reg A = to sum&#xA;SUB         01011   : subtract reg B from reg A, and set reg A = to sum&#xA;MULT        01100   : multiply reg B with reg A, and set reg A = to product&#xA;DIV         01101   : divide reg A by reg B, and set reg A = to quotient&#xA;JMP &amp;lt;val&amp;gt;   01110   : change counter to &amp;lt;val&amp;gt; (changes which instruction is next)&#xA;JMPZ &amp;lt;val&amp;gt;  01111   : jump to &amp;lt;val&amp;gt; if the value in reg A is equal to zero&#xA;JMPC &amp;lt;val&amp;gt;  10000   : jump if the carry bit is set&#xA;LDAIN       10001   : load from reg A as memory address, then copy value from memory into A (allows for 16-bit addressing)&#xA;STAOUT      10010   : use reg A as memory address, then copy value from B into memory&#xA;LDLGE       10010   : use value directly after instruction as address to copy from memory to reg A and advance counter by 2&#xA;STLGE       10100   : use value directly after counter as address, then copy value from reg A to memory and advance counter by 2&#xA;SWP         10011   : swap the contents of register A and register B (this overwrites register C)&#xA;SWPC        10110   : swap register A and register C (this overwrites register B)&#xA;HLT         10111   : stop the clock&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Microinstructions:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;(logisim microinstructions are in reversed order. Bottom of this list is left of binary code )&#xA;&#xA;// 000000000000 11  compact&#xA;SU : enable subtraction in ALU&#xA;MU : enable multiplication in ALU&#xA;DI : enable division in ALU&#xA;&#xA;&#xA;// 000000000 111 00  compact&#xA;RA : read from reg A to bus&#xA;RB : read from reg B to bus&#xA;RC : read from reg C to bus&#xA;RM : read from memory to bus at the address in mem addr. register&#xA;IR : read from lowest 12 bits of instruction register to bus&#xA;CR : read value from counter to bus&#xA;RE : read from expansion port to bus&#xA;&#xA;&#xA;// 00000 1111 00000  compact&#xA;WA : write from bus to reg A&#xA;WB : write from bus to reg B&#xA;WC : write from bus to reg C&#xA;IW : write from bus to instruction register&#xA;DW : write from bus to display register&#xA;WM : write from bus to memory&#xA;J  : write from bus to counter current value&#xA;AW : write lowest 12 bits from bus to mem. addr. register&#xA;WE : write from bus to expansion port&#xA;&#xA;// 11111 000000000  full&#xA;FL : update flags register&#xA;EI : end instruction, resets step counter to move to next instruction&#xA;ST : stop the clock&#xA;CE : enable incrementing of counter&#xA;EO : read from ALU to bus&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Memory Layout:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;word 0 |                                                       .                                                  | word 65535&#xA;       | Program mem. 0 - 16382    I                           I                          Video memory 61439-65535|&#xA;&#xA;0-25%    (0 - 16382)   16382 words  -  Program mem.&#xA;25-25%   (16383-16527) 144 words    -  Character mem. (contains index of character to be displayed at the corresponding location)&#xA;25-25%   (16528-16656) 128 words    -  Variable mem.&#xA;&#xA;93-100%  (61439-65535) 4096 words   -  Video mem. &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Armstrong:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;// Use hex values (0xff) when referring to addresses, and decimal (213) for a new immediate integer&#xA;&#xA;@A - A register&#xA;@B - B register&#xA;@C - C register&#xA;@EX - Expansion port&#xA;&#xA;$                              - &#39;$&#39; symbol refers to a variable containing an integer (address in memory)&#xA;@                              - &#39;@&#39; symbol refers to a register, ie. (&#39;@A&#39; for register &#39;A&#39;)&#xA;#                              - &#39;#&#39; symbol refers to a label, which is a point the program can jump to ie. (&#39;#main&#39;) (address in program counter)&#xA;define &amp;lt;addr&amp;gt; &amp;lt;val&amp;gt;            - Assembler defines &amp;lt;addr&amp;gt; equal to &amp;lt;val&amp;gt;. Sets memory values before the program is executed, then is removed.&#xA;change &amp;lt;addr&amp;gt; = &amp;lt;val&amp;gt;          - Change &amp;lt;addr&amp;gt; to &amp;lt;val&amp;gt; at any time&#xA;add &amp;lt;valA&amp;gt;,&amp;lt;valB&amp;gt; -&amp;gt; &amp;lt;addr&amp;gt;    - Add the values &amp;lt;valA&amp;gt; and &amp;lt;valB&amp;gt;, then store the result in &amp;lt;addr&amp;gt;&#xA;sub &amp;lt;valA&amp;gt;,&amp;lt;valB&amp;gt; -&amp;gt; &amp;lt;addr&amp;gt;    - Subtract the values &amp;lt;valA&amp;gt; and &amp;lt;valB&amp;gt; (valA - valB), then store the result in &amp;lt;addr&amp;gt;&#xA;mult &amp;lt;valA&amp;gt;,&amp;lt;valB&amp;gt; -&amp;gt; &amp;lt;addr&amp;gt;   - Multiply the values &amp;lt;valA&amp;gt; and &amp;lt;valB&amp;gt;, then store the result in &amp;lt;addr&amp;gt;&#xA;div &amp;lt;valA&amp;gt;,&amp;lt;valB&amp;gt; -&amp;gt; &amp;lt;addr&amp;gt;    - Divide the values &amp;lt;valA&amp;gt; and &amp;lt;valB&amp;gt; (valA / valB), then store the result in &amp;lt;addr&amp;gt;&#xA;goto &amp;lt;addr&amp;gt;                    - Jumps to the given address or label&#xA;gotoif &amp;lt;valA&amp;gt;&amp;lt;C&amp;gt;&amp;lt;valB&amp;gt;,&amp;lt;addr&amp;gt;  - Jumps to &amp;lt;addr&amp;gt;, given the logic relationship between &amp;lt;valA&amp;gt; and &amp;lt;valB&amp;gt; given a comparer &amp;lt;C&amp;gt;, ie. (jmpc 0x12==4,0x0)&#xA;if &amp;lt;valA&amp;gt;&amp;lt;C&amp;gt;&amp;lt;valB&amp;gt;             - Continues if the logic relationship between &amp;lt;valA&amp;gt; and &amp;lt;valB&amp;gt; given a comparer &amp;lt;C&amp;gt; is true, ie. (if 0x12==4)&#xA;endif                          - Marks the ending of the contents of an if statement&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>fholger/openvr_fsr</title>
    <updated>2022-07-28T01:33:48Z</updated>
    <id>tag:github.com,2022-07-28:/fholger/openvr_fsr</id>
    <link href="https://github.com/fholger/openvr_fsr" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Add Image Upscaling via AMD FidelityFX SuperResolution or NVIDIA Image Scaling to SteamVR games&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Modified OpenVR DLL with AMD FidelityFX SuperResolution / NVIDIA Image Scaling&lt;/h2&gt; &#xA;&lt;p&gt;This modified openvr_api.dll allows you to apply either &lt;a href=&#34;https://gpuopen.com/fidelityfx-superresolution/&#34;&gt;AMD&#39;s FidelityFX SuperResolution&lt;/a&gt; or &lt;a href=&#34;https://github.com/NVIDIAGameWorks/NVIDIAImageScaling&#34;&gt;NVIDIA&#39;s Image Scaling&lt;/a&gt; to many SteamVR games, as long as they use D3D11.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;NOTE&lt;/em&gt;: I am working on a new project that supercedes this mod. It supports the same upscaling methods as this mod, but in addition also works with the Oculus runtime and will eventually add additional performance enhancement tools. As a consequence, this project is in maintenance mode, and I encourage you to check out the new project: &lt;a href=&#34;https://github.com/fholger/vrperfkit&#34;&gt;VR Performance Toolkit&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;About AMD&#39;s FidelityFX Super Resolution&lt;/h3&gt; &#xA;&lt;p&gt;FidelityFX Super Resolution (FSR for short) is an upscaling technique developed by AMD, but it works on pretty much any graphics card, including NVIDIA cards. The idea is that the game internally renders to a lower resolution, thus saving GPU time and reaching higher FPS, as long as it is not bottlenecked by the CPU. The resulting lower resolution render is then upscaled to the target resolution by FSR, with the aim of restoring some of the lost detail due to the lower resolution rendering. It does so in two steps - the first being the actual upscaling to the target resolution, where particular attention is paid to edges in the lower resolution picture. The second step is a sharpening step to counter some of the blur introduced by the upscaling.&lt;/p&gt; &#xA;&lt;h3&gt;About NVIDIA Image Scaling&lt;/h3&gt; &#xA;&lt;p&gt;NVIDIA Image Scaling (NIS for short) is NVIDIA&#39;s answer to FSR. Like FSR, it is an upscaling algorithm intended to scale a lower-resolution rendered frame to a higher-resolution output. The algorithm works differently, though, and so the output of NIS will differ from that of FSR. It is hard to say which one is better. It may come down to personal preference and even the particular game you are using it for. Feel free to experiment with both, that&#39;s why both are available in this mod :)&lt;/p&gt; &#xA;&lt;h3&gt;Notes about image quality&lt;/h3&gt; &#xA;&lt;p&gt;Note that, unlike DLSS, FSR/NIS is &lt;em&gt;not&lt;/em&gt; an anti-aliasing solution. Any aliasing and shimmering edges present in the original image will not be fixed in the output. As such, the final image quality depends a lot on the particular game you are using it with. &lt;em&gt;AMD specifically advises that FSR should be used in conjunction with the highest-quality anti-aliasing setting a game has to offer.&lt;/em&gt; In the case of VR games, that means enabling MSAA if it is available, or else TAA. You may also want to experiment with turning off any sort of post-processing effects in the games, as some of these should ideally run after FSR/NIS, but with this plugin will run before it and so may negatively affect the image quality.&lt;/p&gt; &#xA;&lt;h3&gt;Installation instructions&lt;/h3&gt; &#xA;&lt;p&gt;First, download the &lt;code&gt;openvr_fsr.zip&lt;/code&gt; file from the &lt;a href=&#34;https://github.com/fholger/openvr_fsr/releases/latest&#34;&gt;latest release&lt;/a&gt; under &#34;Assets&#34;.&lt;/p&gt; &#xA;&lt;p&gt;Then find the location of the openvr_api.dll in the game&#39;s installation folder:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It might be located right next to the main executable (e.g. Skyrim, FO4).&lt;/li&gt; &#xA; &lt;li&gt;For Unity games, look in: &lt;code&gt;&amp;lt;GameDir&amp;gt;\&amp;lt;Game&amp;gt;_Data\Plugins&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;For Unreal 4 games, look in: &lt;code&gt;&amp;lt;GameDir&amp;gt;\Engine\Binaries\ThirdParty\OpenVR\OpenVRvX_Y_Z&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Rename the existing &lt;code&gt;openvr_api.dll&lt;/code&gt; to &lt;code&gt;openvr_api.orig.dll&lt;/code&gt;, then extract both the &lt;code&gt;openvr_api.dll&lt;/code&gt; and the &lt;code&gt;openvr_mod.cfg&lt;/code&gt; from the archive to this directory. You should now edit the &lt;code&gt;openvr_mod.cfg&lt;/code&gt; to your liking and adjust the &lt;code&gt;renderScale&lt;/code&gt; and &lt;code&gt;sharpness&lt;/code&gt; parameters to your liking.&lt;/p&gt; &#xA;&lt;p&gt;In case you want to uninstall the mod, simply remove the &lt;code&gt;openvr_api.dll&lt;/code&gt; file again and rename the original &lt;code&gt;openvr_api.orig.dll&lt;/code&gt; back to &lt;code&gt;openvr_api.dll&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In case you run into issues, the log file (&lt;code&gt;openvr_mod.log&lt;/code&gt;) may provide clues to what&#39;s going on.&lt;/p&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;The mod is configured by editing the values in its config file, &lt;code&gt;openvr_mod.cfg&lt;/code&gt;. The most important setting is &lt;code&gt;renderScale&lt;/code&gt;, which determines the lowered render resolution that the game will be using internally. If you have set a render resolution of e.g. 2244x2492 in SteamVR, then that&#39;s the target resolution. The internal resolution will be scaled by the value of &lt;code&gt;renderScale&lt;/code&gt; in both dimensions. For example, if &lt;code&gt;renderScale&lt;/code&gt; is set to 0.75, then the actual render resolution will become 1683x1869. The render is then upscaled by FSR to the original resolution of 2244x2492.&lt;/p&gt; &#xA;&lt;p&gt;If you set a value higher than 1 for &lt;code&gt;renderScale&lt;/code&gt;, then the game will render at the native resolution, i.e. the one configured in SteamVR. But FSR will then take this render and upscale it to a resolution multiplied by the value of &lt;code&gt;renderScale&lt;/code&gt; in each dimension. For example, if the resolution in SteamVR is 2242x2492 and you have configured a value of 1.3 for &lt;code&gt;renderScale&lt;/code&gt;, then the game will render at 2242x2492, but the image will be upscaled by FSR to 2915x3240.&lt;/p&gt; &#xA;&lt;p&gt;The second relevant parameter is &lt;code&gt;sharpness&lt;/code&gt;. Generally, the higher you set &lt;code&gt;sharpness&lt;/code&gt;, the sharper the final image will appear. You probably want to set this value higher if you lower &lt;code&gt;renderScale&lt;/code&gt;, but beware of over-sharpening. The default of 0.9 gives a fairly sharp result. You can increase it up to 1.0 if you like an even sharper image. But if the image is too sharp for your taste, consider experimenting with lower values.&lt;/p&gt; &#xA;&lt;p&gt;To switch between FSR and NIS, set the parameter &lt;code&gt;useNIS&lt;/code&gt; either to &lt;code&gt;false&lt;/code&gt; (FSR, default) or &lt;code&gt;true&lt;/code&gt; (NIS).&lt;/p&gt; &#xA;&lt;h3&gt;In-game hotkeys&lt;/h3&gt; &#xA;&lt;p&gt;By default, a few hotkeys are enabled which you can use to modify certain options of the mod on the fly. While it is not technically possible to switch the mod on and off, you can switch between FSR and NIS and also adjust the sharpness and sharpen radius dynamically. Note that any changes you make via the hotkeys is &lt;em&gt;not&lt;/em&gt; persisted in the config file and will be reset to the values i the config on the next game launch.&lt;/p&gt; &#xA;&lt;p&gt;By default, the following hotkeys are available. You can configure the keys in the config file and also disable hotkeys altogether.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;F1 - toggles between FSR and NIS.&lt;/li&gt; &#xA; &lt;li&gt;F2 - toggles debug mode on or off.&lt;/li&gt; &#xA; &lt;li&gt;F3 - decreases sharpness by 0.05.&lt;/li&gt; &#xA; &lt;li&gt;F4 - increases sharpness by 0.05.&lt;/li&gt; &#xA; &lt;li&gt;F5 - decreases sharpening radius by 0.05.&lt;/li&gt; &#xA; &lt;li&gt;F6 - increases sharpening radius by 0.05.&lt;/li&gt; &#xA; &lt;li&gt;F7 - take a screen capture of the final output and save it as a .dds file next to the DLL location&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Performance considerations&lt;/h3&gt; &#xA;&lt;p&gt;While rendering at a lower resolution will save you performance (which is the entire point), the upscaler does have a fixed cost in GPU time, and this time depends on your GPU and the target resolution (&lt;em&gt;not&lt;/em&gt; the render resolution). So the higher your target resolution, the higher the cost of the upscaler. It means that, the higher your target resolution, the lower you may have to set the render resolution (by lowering &lt;code&gt;renderScale&lt;/code&gt;) before you see an actual net benefit for your GPU times.&lt;/p&gt; &#xA;&lt;p&gt;A part of the overhead of FSR/NIS can be mitigated by using a sort of &#34;fixed foveated&#34; optimization where only the center of the image is upscaled by the more expensive FSR algorithm, while the edges are upscaled by cheaper bilinear sampling. This can be controlled in the mod by the &lt;code&gt;radius&lt;/code&gt; setting, where anything within the radius from the center of the image is upscaled with FSR, and anything outside is upscaled with bilinear filtering. Due to the natural loss of clarity in the edges of current HMD lenses, even with a fairly small radius you will probably have a hard time to tell the difference.&lt;/p&gt; &#xA;&lt;h3&gt;Results&lt;/h3&gt; &#xA;&lt;p&gt;Example results:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://imgsli.com/NjAxNTM/0/1&#34;&gt;Skyrim VR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://imgsli.com/NjAxNTE/0/1&#34;&gt;Fallout 4 VR Native vs FSR modes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://imgsli.com/NTk1OTI/2/1&#34;&gt;Fallout 4 VR Native vs FSR upsampling vs CAS sharpening&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Troubleshooting&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you encounter issues like the view looking misaligned or mismatched between the eyes, or one eye is sharper than the other, try setting &lt;code&gt;radius&lt;/code&gt; to &lt;code&gt;2&lt;/code&gt; in the config and check if that fixes it. This will disable a performance optimization, but it doesn&#39;t always work with all games or headsets.&lt;/li&gt; &#xA; &lt;li&gt;If you encounter missing textures or banding, try setting &lt;code&gt;applyMIPBias&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt; in the config.&lt;/li&gt; &#xA; &lt;li&gt;If your tracking stops working or is misbehaving with the mod applied, there is a chance that you copied the mod DLL to the wrong place. Please re-read the installation instructions and take special note of the plugin subfolders for Unity and Unreal engines.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Important disclaimer&lt;/h3&gt; &#xA;&lt;p&gt;This is a best-effort experiment and hack to bring these upscaling techniques to VR games which do not support them natively. Please understand that the approach taken here cannot guarantee the optimal quality that FSR or NIS might, in theory, be capable of. AMD has specific recommendations where and how FSR should be placed in the render pipeline. Due to the nature of this generic hack, I cannot guarantee nor control that all of these recommendations are actually met for any particular game. Please do not judge the quality of FSR solely by this mod :)&lt;/p&gt; &#xA;&lt;p&gt;I intend to keep working on the performance, quality and compatibility of this mod, so do check back occasionally.&lt;/p&gt; &#xA;&lt;h3&gt;Known issues&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Half Life: Alyx and Star Wars: Squadrons do not work, because they don&#39;t like you replacing their openvr_dll.api.&lt;/li&gt; &#xA; &lt;li&gt;Please report any other game that isn&#39;t working, assuming that it is a SteamVR game and uses D3D11 for rendering.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;OpenVR SDK&lt;/h2&gt; &#xA;&lt;p&gt;OpenVR is an API and runtime that allows access to VR hardware from multiple vendors without requiring that applications have specific knowledge of the hardware they are targeting. This repository is an SDK that contains the API and samples. The runtime is under SteamVR in Tools on Steam.&lt;/p&gt; &#xA;&lt;h3&gt;Documentation&lt;/h3&gt; &#xA;&lt;p&gt;Documentation for the API is available on the &lt;a href=&#34;https://github.com/ValveSoftware/openvr/wiki/API-Documentation&#34;&gt;GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;More information on OpenVR and SteamVR can be found on &lt;a href=&#34;http://steamvr.com&#34;&gt;http://steamvr.com&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>