<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-19T01:30:46Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>maxbbraun/llama4micro</title>
    <updated>2023-11-19T01:30:46Z</updated>
    <id>tag:github.com,2023-11-19:/maxbbraun/llama4micro</id>
    <link href="https://github.com/maxbbraun/llama4micro" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A &#34;large&#34; language model running on a microcontroller&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;llama4micro ðŸ¦™ðŸ”¬&lt;/h1&gt; &#xA;&lt;p&gt;A &#34;large&#34; language model running on a microcontroller.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/maxbbraun/llama4micro/main/llama4micro.gif&#34; alt=&#34;Example run&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Background&lt;/h2&gt; &#xA;&lt;p&gt;I was wondering if it&#39;s possible to fit a non-trivial language model on a microcontroller. Turns out the answer is some version of yes!&lt;/p&gt; &#xA;&lt;p&gt;This project is using the &lt;a href=&#34;https://coral.ai/products/dev-board-micro&#34;&gt;Coral Dev Board Micro&lt;/a&gt; with its &lt;a href=&#34;https://coral.ai/docs/dev-board-micro/freertos/&#34;&gt;FreeRTOS toolchain&lt;/a&gt;. The board has a number of neat &lt;a href=&#34;https://coral.ai/docs/dev-board-micro/get-started/#the-hardware&#34;&gt;hardware features&lt;/a&gt; not currently being used here (notably a &lt;a href=&#34;https://coral.ai/technology/&#34;&gt;TPU&lt;/a&gt;, sensors, and a &lt;a href=&#34;https://coral.ai/docs/dev-board-micro/multicore/&#34;&gt;second CPU core&lt;/a&gt;). It does, however, also have 64MB of RAM. That&#39;s tiny for LLMs, which are typically measured in the GBs, but comparatively huge for a microcontroller. Inference runs on the 800 MHz &lt;a href=&#34;https://developer.arm.com/Processors/Cortex-M7&#34;&gt;Arm Cortex-M7&lt;/a&gt; CPU core.&lt;/p&gt; &#xA;&lt;p&gt;The LLM implementation itself is an adaptation of &lt;a href=&#34;https://github.com/karpathy/llama2.c&#34;&gt;llama2.c&lt;/a&gt; and the &lt;a href=&#34;https://huggingface.co/karpathy/tinyllamas/tree/main&#34;&gt;tinyllamas&lt;/a&gt; checkpoints trained on the &lt;a href=&#34;https://huggingface.co/datasets/roneneldan/TinyStories&#34;&gt;TinyStories&lt;/a&gt; dataset. The quality of the smaller model versions isn&#39;t ideal, but good enough to generate somewhat coherent (and occasionally weird) stories.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Clone this repo with its submodules &lt;a href=&#34;https://github.com/karpathy/llama2.c&#34;&gt;&lt;code&gt;karpathy/llama2.c&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/google-coral/coralmicro&#34;&gt;&lt;code&gt;google-coral/coralmicro&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone --recurse-submodules https://github.com/maxbbraun/llama4micro.git&#xA;&#xA;cd llama4micro&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some of the tools use Python. Install their dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 -m venv venv&#xA;. venv/bin/activate&#xA;&#xA;pip install -r llama2.c/requirements.txt&#xA;pip install -r coralmicro/scripts/requirements.txt&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Download the model and quantize it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;LLAMA_MODEL_NAME=stories15M&#xA;wget -P data https://huggingface.co/karpathy/tinyllamas/resolve/main/${LLAMA_MODEL_NAME}.pt&#xA;&#xA;python llama2.c/export.py data/${LLAMA_MODEL_NAME}_q80.bin --version 2 --checkpoint data/${LLAMA_MODEL_NAME}.pt&#xA;&#xA;cp llama2.c/tokenizer.bin data/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Build and flash the image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir build&#xA;cd build&#xA;&#xA;cmake ..&#xA;make -j&#xA;&#xA;python ../coralmicro/scripts/flashtool.py --build_dir . --elf_path llama4micro&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The model loads automatically when the board powers up. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This takes ~6 seconds.&lt;/li&gt; &#xA;   &lt;li&gt;The green light will turn on when it&#39;s ready.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Press the button next to the green light. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The green light will turn off.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;The model now generates tokens. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The results are streamed to the serial port.&lt;/li&gt; &#xA;   &lt;li&gt;This happens at a rate of ~2.5 tokens per second.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Generation stops after the end token or maximum steps. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The green light will turn on again.&lt;/li&gt; &#xA;   &lt;li&gt;Goto 2.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>Tencent/tgfx</title>
    <updated>2023-11-19T01:30:46Z</updated>
    <id>tag:github.com,2023-11-19:/Tencent/tgfx</id>
    <link href="https://github.com/Tencent/tgfx" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A lightweight 2D graphics library for rendering texts, geometries, and images with high-performance APIs that work across various platforms.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Tencent/tgfx/main/resources/readme/TGFX.jpg&#34; alt=&#34;TGFX Logo&#34; width=&#34;992&#34;&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Tencent/tgfx/raw/master/LICENSE.txt&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-BSD--3--Clause-blue&#34; alt=&#34;license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Tencent/tgfx/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/Tencent/tgfx&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/Tencent/tgfx/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Tencent/tgfx/actions/workflows/autotest.yml&#34;&gt;&lt;img src=&#34;https://github.com/Tencent/tgfx/actions/workflows/autotest.yml/badge.svg?branch=main&#34; alt=&#34;autotest&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Tencent/tgfx/actions/workflows/build.yml&#34;&gt;&lt;img src=&#34;https://github.com/Tencent/tgfx/actions/workflows/build.yml/badge.svg?branch=main&#34; alt=&#34;build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Tencent/tgfx/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/Tencent/tgfx&#34; alt=&#34;GitHub release (latest SemVer)&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;TGFX (Tencent Graphics) is a lightweight 2D graphics library designed for rendering texts, geometries, and images. It provides high-performance APIs that work across a variety of GPU hardware and software platforms, including iOS, Android, macOS, Windows, Linux, Web, and more. TGFX was originally designed to serve as the default graphics engine for the &lt;a href=&#34;https://pag.art&#34;&gt;PAG&lt;/a&gt; project starting from version 4.0. Its main objective is to offer a compelling alternative to the Skia graphics library while maintaining a much smaller binary size. Over time, it has found its way into many other products, such as &lt;a href=&#34;https://github.com/Tencent/Hippy&#34;&gt;Hippy&lt;/a&gt;, &lt;a href=&#34;https://docs.qq.com&#34;&gt;Tencent Docs&lt;/a&gt; and various video-editing apps.&lt;/p&gt; &#xA;&lt;h2&gt;Platform Support&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;iOS 9.0 or later&lt;/li&gt; &#xA; &lt;li&gt;Android 4.4 or later&lt;/li&gt; &#xA; &lt;li&gt;macOS 10.15 or later&lt;/li&gt; &#xA; &lt;li&gt;Windows 7.0 or later&lt;/li&gt; &#xA; &lt;li&gt;Chrome 69.0 or later (Web)&lt;/li&gt; &#xA; &lt;li&gt;Safari 11.3 or later (Web)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Backing Renderers&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Vector Backend&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GPU Backend&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Target Platforms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Status&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FreeType&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;OpenGL&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;All&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;complete&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;CoreGraphics&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;OpenGL&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;iOS, macOS&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;complete&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Canvas2D&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;WebGL&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Web&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;complete&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;CoreGraphics&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Metal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;iOS, macOS&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;in progress&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FreeType&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Vulkan&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Android, Linux&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;planned&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Branch Management&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;code&gt;main&lt;/code&gt; branch is our active developing branch which contains the latest features and bugfixes.&lt;/li&gt; &#xA; &lt;li&gt;The branches under &lt;code&gt;release/&lt;/code&gt; are our stable milestone branches which are fully tested. We will periodically cut a &lt;code&gt;release/{version}&lt;/code&gt; branch from the &lt;code&gt;main&lt;/code&gt; branch. After one &lt;code&gt;release/{version}&lt;/code&gt; branch is cut, only high-priority fixes are checked into it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Build Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;TGFX utilizes the &lt;strong&gt;C++17&lt;/strong&gt; features for development. Below are the minimum tools needed for building tgfx on different platforms:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Xcode 11.0+&lt;/li&gt; &#xA; &lt;li&gt;GCC 8.0+&lt;/li&gt; &#xA; &lt;li&gt;Visual Studio 2019&lt;/li&gt; &#xA; &lt;li&gt;NodeJS 14.14.0+&lt;/li&gt; &#xA; &lt;li&gt;Ninja 1.9.0+&lt;/li&gt; &#xA; &lt;li&gt;CMake 3.10.2+&lt;/li&gt; &#xA; &lt;li&gt;NDK 19.2.5345600&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please pay attention to the following additional notices:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make sure you have installed at least the &lt;strong&gt;[Desktop development with C++]&lt;/strong&gt; and &lt;strong&gt;[Universal Windows Platform development]&lt;/strong&gt; components for VS2019.&lt;/li&gt; &#xA; &lt;li&gt;It is highly recommended to &lt;strong&gt;use the latest version of CMake&lt;/strong&gt;, Numerous outdated versions of CMake may carry various bugs across different platforms.&lt;/li&gt; &#xA; &lt;li&gt;Please use NDK version &lt;strong&gt;&lt;code&gt;19.2.5345600&lt;/code&gt;&lt;/strong&gt; to avoid potential failures. You can place the NDK in the default location or set environment variables (&lt;code&gt;NDK_HOME&lt;/code&gt;, &lt;code&gt;NDK_PATH&lt;/code&gt;, &lt;code&gt;ANDROID_NDK_HOME&lt;/code&gt;, &lt;code&gt;ANDROID_NDK&lt;/code&gt;) for tgfx to locate it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Dependency Management&lt;/h2&gt; &#xA;&lt;p&gt;TGFX uses &lt;a href=&#34;https://github.com/domchen/depsync&#34;&gt;depsync&lt;/a&gt; tool to manage third-party dependencies.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For macOS platformï¼š&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Run the script in the root of the project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sync_deps.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This script will automatically install the necessary tools and synchronize all third-party repositories.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For other platformsï¼š&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;First, make sure you have installed the latest version of node.js (You may need to restart your computer after this step). And then run the following command to install depsync tool:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm install -g depsync&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then run &lt;code&gt;depsync&lt;/code&gt; in the root directory of the project.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;depsync&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Git account and password may be required during synchronizing. Please make sure you have enabled the &lt;code&gt;git-credential-store&lt;/code&gt; so that &lt;code&gt;CMakeList.txt&lt;/code&gt; can trigger synchronizing automatically next time.&lt;/p&gt; &#xA;&lt;h2&gt;Build TGFX&lt;/h2&gt; &#xA;&lt;p&gt;TGFX uses a set of &lt;a href=&#34;https://github.com/libpag/vendor_tools&#34;&gt;build tools&lt;/a&gt; written in NodeJS, enabling a unified approach to build tgfx across all platforms.&lt;/p&gt; &#xA;&lt;p&gt;To quickly get started, simply execute the following command in the root directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;node build_tgfx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command will build the release version of the tgfx library for the native platform. After the execution, you will locate the compiled tgfx libraries in the &lt;code&gt;out/release&lt;/code&gt; directory. If you wish to target a specific platform, simply use the &lt;code&gt;-p [--platform]&lt;/code&gt; option. The supported platform names are as follows: &lt;code&gt;win&lt;/code&gt;, &lt;code&gt;mac&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;linux&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;web&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;node build_tgfx -p ios&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When working with apple platforms, you have the additional &lt;code&gt;-x [--xcframework]&lt;/code&gt; option at your disposal, which allows you to effortlessly create xcframeworks.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;node build_tgfx -p mac -x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After the execution, you will locate the &lt;code&gt;tgfx.xcframework&lt;/code&gt; in the &lt;code&gt;out/release/mac&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;p&gt;Additionally, you can pass cmake options using the &lt;code&gt;-D&lt;/code&gt; prefix. For example, if you want to build tgfx with the freetype option enabled, please run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;node build_tgfx -DTGFX_USE_FREETYPE=ON&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To access additional details and options, execute the command along with the &lt;code&gt;-h [--help]&lt;/code&gt; option:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;node build_tgfx -h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Integration&lt;/h2&gt; &#xA;&lt;p&gt;We offer concise demos for different platforms, demonstrating the seamless integration of the tgfx library into your project. For more information, please refer to the README.md documentation within each demo directory. If you are looking for guidance on API usage, consider exploring the test cases found in the &lt;code&gt;test/&lt;/code&gt; directory. They may provide valuable insights and assistance.&lt;/p&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;We recommend using CLion IDE on the macOS platform for development. After the synchronization, you can open the project with CLion and build the tgfx library.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For macOS platformï¼š&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;There are no extra configurations of CLion required.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;For Windows platformï¼š&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Open the &lt;strong&gt;File-&amp;gt;Setting&lt;/strong&gt; panel, and go to &lt;strong&gt;Build, Execution, Deployment-&amp;gt;ToolChains&lt;/strong&gt;, then set the toolchain of CLion to &lt;strong&gt;Visual Studio&lt;/strong&gt; with &lt;strong&gt;amd64 (Recommended)&lt;/strong&gt; or &lt;strong&gt;x86&lt;/strong&gt; architecture.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And then, launch CLion and open the tgfx project. You&#39;ll be good to go!&lt;/p&gt; &#xA;&lt;h2&gt;Support Us&lt;/h2&gt; &#xA;&lt;p&gt;If you find tgfx is helpful, please give us a &lt;strong&gt;Star&lt;/strong&gt;. We sincerely appreciate your support :)&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#Tencent/tgfx&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=Tencent/tgfx&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;TGFX is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/Tencent/tgfx/main/LICENSE.txt&#34;&gt;BSD-3-Clause License&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;p&gt;If you have any ideas or suggestions to improve tgfx, welcome to open a &lt;a href=&#34;https://github.com/Tencent/tgfx/discussions/new/choose&#34;&gt;discussion&lt;/a&gt; / &lt;a href=&#34;https://github.com/Tencent/tgfx/issues/new/choose&#34;&gt;issue&lt;/a&gt; / &lt;a href=&#34;https://github.com/Tencent/tgfx/pulls&#34;&gt;pull request&lt;/a&gt;. Before making a pull request or issue, please make sure to read &lt;a href=&#34;https://raw.githubusercontent.com/Tencent/tgfx/main/CONTRIBUTING.md&#34;&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ros-perception/vision_opencv</title>
    <updated>2023-11-19T01:30:46Z</updated>
    <id>tag:github.com,2023-11-19:/ros-perception/vision_opencv</id>
    <link href="https://github.com/ros-perception/vision_opencv" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;vision_opencv&lt;/h1&gt; &#xA;&lt;p&gt;ros2 vision_opencv contains packages to interface ROS 2 with &lt;a href=&#34;http://opencv.org/&#34;&gt;OpenCV&lt;/a&gt; which is a library designed for computational efficiency and strong focus for real time computer vision applications. This repository contains:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;cv_bridge&lt;/code&gt;: Bridge between ROS 2 image messages and OpenCV image representation&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;image_geometry&lt;/code&gt;: Collection of methods for dealing with image and pixel geometry&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;opencv_tests&lt;/code&gt;: Integration tests to use the capability of the packages with opencv&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;vision_opencv&lt;/code&gt;: Meta-package to install both &lt;code&gt;cv_bridge&lt;/code&gt; and &lt;code&gt;image_geometry&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In order to use ROS 2 with OpenCV, please see the details within &lt;a href=&#34;https://github.com/ros-perception/vision_opencv/tree/ros2/cv_bridge&#34;&gt;cv_bridge&lt;/a&gt; package.&lt;/p&gt;</summary>
  </entry>
</feed>