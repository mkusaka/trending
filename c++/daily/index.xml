<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-07-27T01:28:09Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>pytorch/FBGEMM</title>
    <updated>2024-07-27T01:28:09Z</updated>
    <id>tag:github.com,2024-07-27:/pytorch/FBGEMM</id>
    <link href="https://github.com/pytorch/FBGEMM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;FB (Facebook) + GEMM (General Matrix-Matrix Multiplication) - https://code.fb.com/ml-applications/fbgemm/&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FBGEMM&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/pytorch/FBGEMM/actions/workflows/fbgemm_ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/pytorch/FBGEMM/actions/workflows/fbgemm_ci.yml/badge.svg?sanitize=true&#34; alt=&#34;FBGEMM CI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;FBGEMM (Facebook GEneral Matrix Multiplication) is a low-precision, high-performance matrix-matrix multiplications and convolution library for server-side inference.&lt;/p&gt; &#xA;&lt;p&gt;The library provides efficient low-precision general matrix multiplication for small batch sizes and support for accuracy-loss minimizing techniques such as row-wise quantization and outlier-aware quantization. FBGEMM also exploits fusion opportunities in order to overcome the unique challenges of matrix multiplication at lower precision with bandwidth-bound operations.&lt;/p&gt; &#xA;&lt;p&gt;FBGEMM is used as a backend of PyTorch quantized operators for x86 machines:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PyTorch: &lt;a href=&#34;https://github.com/pytorch/pytorch/tree/master/aten/src/ATen/native/quantized/cpu&#34;&gt;https://github.com/pytorch/pytorch/tree/master/aten/src/ATen/native/quantized/cpu&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the full &lt;a href=&#34;https://pytorch.org/FBGEMM&#34;&gt;Documentation&lt;/a&gt; for more information on building, installing, and developing with FBGEMM, as well as the most up-to-date support matrix and API documentation for this library.&lt;/p&gt; &#xA;&lt;h3&gt;What&#39;s New?&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/FBGEMM/wiki/Recent-feature-additions-and-improvements-in-FBGEMM&#34;&gt;New Features and Recent Improvements&lt;/a&gt; (January, 2020)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt;For a high-level overview, design philosophy and brief descriptions of various parts of FBGEMM please see &lt;a href=&#34;https://code.fb.com/ml-applications/fbgemm&#34;&gt;our blog post&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For those looking for the appropriate article to cite regarding FBGEMM, we recommend citing our &lt;a href=&#34;https://arxiv.org/pdf/2101.05615.pdf&#34;&gt;paper&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{fbgemm,&#xA;  title={FBGEMM: Enabling High-Performance Low-Precision Deep Learning Inference},&#xA;  author={Khudia, Daya and Huang, Jianyu and Basu, Protonu and Deng, Summer and Liu, Haixin and Park, Jongsoo and Smelyanskiy, Mikhail},&#xA;  journal={arXiv preprint arXiv:2101.05615},&#xA;  year={2021}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Join the FBGEMM community&lt;/h2&gt; &#xA;&lt;p&gt;For questions, support, news updates, or feature requests, please feel free to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;File a ticket in &lt;a href=&#34;https://github.com/pytorch/FBGEMM/issues&#34;&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Post a discussion in &lt;a href=&#34;https://github.com/pytorch/FBGEMM/discussions&#34;&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Reach out to us on the &lt;code&gt;#fbgemm&lt;/code&gt; channel in &lt;a href=&#34;https://bit.ly/ptslack&#34;&gt;PyTorch Slack&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For contributions, please see the &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/FBGEMM/main/CONTRIBUTING.md&#34;&gt;&lt;code&gt;CONTRIBUTING&lt;/code&gt;&lt;/a&gt; file for ways to help out.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;FBGEMM is BSD licensed, as found in the &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/FBGEMM/main/LICENSE&#34;&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
</feed>