<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-09T01:31:12Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>SteveMacenski/slam_toolbox</title>
    <updated>2023-03-09T01:31:12Z</updated>
    <id>tag:github.com,2023-03-09:/SteveMacenski/slam_toolbox</id>
    <link href="https://github.com/SteveMacenski/slam_toolbox" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Slam Toolbox for lifelong mapping and localization in potentially massive maps with ROS&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Slam Toolbox&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;DockerHub&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://hub.docker.com/r/stevemacenski/slam-toolbox&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/cloud/build/stevemacenski/slam-toolbox.svg?label=build&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://hub.docker.com/r/stevemacenski/slam-toolbox&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/stevemacenski/slam-toolbox.svg?maxAge=2592000&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Build Farm&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://build.ros2.org/job/Ddev__slam_toolbox__ubuntu_bionic_amd64/&#34;&gt;&lt;img src=&#34;http://build.ros2.org/job/Ddev__slam_toolbox__ubuntu_bionic_amd64/badge/icon&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;We&#39;ve received feedback from users and have robots operating in the following environments with SLAM Toolbox:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Retail&lt;/li&gt; &#xA; &lt;li&gt;Warehouses&lt;/li&gt; &#xA; &lt;li&gt;Libraries&lt;/li&gt; &#xA; &lt;li&gt;Research&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;It is also the currently supported ROS2-SLAM library. See tutorials for working with it in &lt;a href=&#34;https://navigation.ros.org/tutorials/docs/navigation2_with_slam.html&#34;&gt;ROS2 Navigation here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Cite This Work&lt;/h3&gt; &#xA;&lt;p&gt;You can find this work &lt;a href=&#34;https://joss.theoj.org/papers/10.21105/joss.02783&#34;&gt;here&lt;/a&gt; and clicking on the image below.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Macenski, S., Jambrecic I., &#34;SLAM Toolbox: SLAM for the dynamic world&#34;, Journal of Open Source Software, 6(61), 2783, 2021.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Macenski, S., &#34;On Use of SLAM Toolbox, A fresh(er) look at mapping and localization for the dynamic world&#34;, ROSCon 2019.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://vimeo.com/378682207&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/14944147/74176653-f69beb80-4bec-11ea-906a-a233541a6064.png&#34; alt=&#34;IMAGE ALT TEXT&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Introduction&lt;/h1&gt; &#xA;&lt;p&gt;Slam Toolbox is a set of tools and capabilities for 2D SLAM built by &lt;a href=&#34;https://www.linkedin.com/in/steve-macenski-41a985101&#34;&gt;Steve Macenski&lt;/a&gt; while at &lt;a href=&#34;https://www.simberobotics.com/&#34;&gt;Simbe Robotics&lt;/a&gt;, maintained whil at Samsung Research, and largely in his free time.&lt;/p&gt; &#xA;&lt;p&gt;This project contains the ability to do most everything any other available SLAM library, both free and paid, and more. This includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ordinary point-and-shoot 2D SLAM mobile robotics folks expect (start, map, save pgm file) with some nice built in utilities like saving maps&lt;/li&gt; &#xA; &lt;li&gt;Continuing to refine, remap, or continue mapping a saved (serialized) pose-graph at any time&lt;/li&gt; &#xA; &lt;li&gt;life-long mapping: load a saved pose-graph continue mapping in a space while also removing extraneous information from newly added scans&lt;/li&gt; &#xA; &lt;li&gt;an optimization-based localization mode built on the pose-graph. Optionally run localization mode without a prior map for &#34;lidar odometry&#34; mode with local loop closures&lt;/li&gt; &#xA; &lt;li&gt;synchronous and asynchronous modes of mapping&lt;/li&gt; &#xA; &lt;li&gt;kinematic map merging (with an elastic graph manipulation merging technique in the works)&lt;/li&gt; &#xA; &lt;li&gt;plugin-based optimization solvers with a new optimized Google Ceres based plugin&lt;/li&gt; &#xA; &lt;li&gt;RVIZ plugin for interacting with the tools&lt;/li&gt; &#xA; &lt;li&gt;graph manipulation tools in RVIZ to manipulate nodes and connections during mapping&lt;/li&gt; &#xA; &lt;li&gt;Map serialization and lossless data storage&lt;/li&gt; &#xA; &lt;li&gt;... more but those are the highlights&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For running on live production robots, I recommend using the snap: slam-toolbox, it has optimizations in it that make it about 10x faster. You need the deb/source install for the other developer level tools that don&#39;t need to be on the robot (rviz plugins, etc).&lt;/p&gt; &#xA;&lt;p&gt;This package has been benchmarked mapping building at 5x+ realtime up to about 30,000 sqft and 3x realtime up to about 60,000 sqft. with the largest area (I&#39;m aware of) used was a 200,000 sq.ft. building in synchronous mode (e.i. processing all scans, regardless of lag), and &lt;em&gt;much&lt;/em&gt; larger spaces in asynchronous mode.&lt;/p&gt; &#xA;&lt;p&gt;The video below was collected at &lt;a href=&#34;https://www.circuitlaunch.com/&#34;&gt;Circuit Launch&lt;/a&gt; in Oakland, California. Thanks to &lt;a href=&#34;https://svrobo.org/&#34;&gt;Silicon Valley Robotics&lt;/a&gt; &amp;amp; Circuit Launch for being a testbed for some of this work.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SteveMacenski/slam_toolbox/ros2/images/circuit_launch.gif?raw=true&#34; alt=&#34;map_image&#34; title=&#34;Map Image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;An overview of how the map was generated is presented below: &lt;img src=&#34;https://raw.githubusercontent.com/SteveMacenski/slam_toolbox/ros2/images/slam_toolbox_sync.png&#34; alt=&#34;slam_toolbox_sync_diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ROS Node: SLAM toolbox is run in synchronous mode, which generates a ROS node. This node subscribes to laser scan and odometry topics, and publishes map to odom transform and a map.&lt;/li&gt; &#xA; &lt;li&gt;Get odometry and LIDAR data: A callback for the laser topic will generate a pose (using odometry) and a laser scan tied at that node. These PosedScan objects form a queue, which are processed by the algorithm.&lt;/li&gt; &#xA; &lt;li&gt;Process Data: The queue of PosedScan objects are used to construct a pose graph; odometry is refined using laser scan matching. This pose graph is used to compute robot pose, and find loop closures. If a loop closure is found, the pose graph is optimized, and pose estimates are updated. Pose estimates are used to compute and publish a map to odom transform for the robot.&lt;/li&gt; &#xA; &lt;li&gt;Mapping: Laser scans associated with each pose in the pose graph are used to construct and publish a map.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Support and Contribution&lt;/h1&gt; &#xA;&lt;p&gt;If you have any questions on use or configuration, please post your questions on &lt;a href=&#34;https://raw.githubusercontent.com/SteveMacenski/slam_toolbox/ros2/answers.ros.org&#34;&gt;ROS Answers&lt;/a&gt; and someone from the community will work their hardest to get back to you. Tangible issues in the codebase or feature requests should be made with GitHub issues.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re interested in contributing to this project in a substantial way, please file a public GitHub issue on your new feature / patch. If for some reason the development of this feature is sensitive, please email the maintainers at their email addresses listed in the &lt;code&gt;package.xml&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;For all contributions, please properly fill in the GitHub issue and PR templates with all necessary context. All PRs must be passing CI and maintaining ABI compatibility within released ROS distributions. A maintainer will follow up shortly thereafter.&lt;/p&gt; &#xA;&lt;h1&gt;03/23/2021 Note On Serialized Files&lt;/h1&gt; &#xA;&lt;p&gt;As of 03/23/2021, the contents of the serialized files has changed. For all new users after this date, this regard this section it does not impact you.&lt;/p&gt; &#xA;&lt;p&gt;If you have previously existing serialized files (e.g. not &lt;code&gt;pgm&lt;/code&gt; maps, but &lt;code&gt;.posegraph&lt;/code&gt; serialized slam sessions), after this date, you may need to take some action to maintain current features. Unfortunately, an ABI breaking change was required to be made in order to fix a very large bug affecting any 360 or non-axially-mounted LIDAR system.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discourse.ros.org/t/request-for-input-potential-existing-slam-toolbox-serialized-file-invalidation/19520&#34;&gt;This Discourse post&lt;/a&gt; highlights the issues. The frame storing the scan data for the optimizer was incorrect leading to explosions or flipping of maps for 360 and non-axially-aligned robots when using conservative loss functions. This change permanently fixes this issue, however it changes the frame of reference that this data is stored and serialized in. If your system as a non-360 lidar and it is mounted with its frame aligned with the robot base frame, you&#39;re unlikely to notice a problem and can disregard this statement. For all others noticing issues, you have the following options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use the &lt;code&gt;&amp;lt;distro&amp;gt;-devel-unfixed&lt;/code&gt; branch rather than &lt;code&gt;&amp;lt;distro&amp;gt;-devel&lt;/code&gt;, which contains the unfixed version of this distribution&#39;s release which will be maintained in parallel to the main branches to have an option to continue with your working solution&lt;/li&gt; &#xA; &lt;li&gt;Convert your serialized files into the new reference frame with an offline utility&lt;/li&gt; &#xA; &lt;li&gt;Take the raw data and rerun the SLAM sessions to get a new serialized file with the right content&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;More of the conversation can be seen on tickets #198 and #281. I apologize for the inconvenience, however this solves a very large bug that was impacting a large number of users. I&#39;ve worked hard to make sure there&#39;s a viable path forward for everyone.&lt;/p&gt; &#xA;&lt;h1&gt;LifeLong Mapping&lt;/h1&gt; &#xA;&lt;!--  Continuing mapping Gif here--&gt; &#xA;&lt;p&gt;LifeLong mapping is the concept of being able to map a space, completely or partially, and over time, refine and update that map as you continue to interact with the space. Our approach implements this and also takes care to allow for the application of operating in the cloud, as well as mapping with many robots in a shared space (cloud distributed mapping). While Slam Toolbox can also just be used for a point-and-shoot mapping of a space and saving that map as a .pgm file as maps are traditionally stored in, it also allows you to save the pose-graph and metadata losslessly to reload later with the same or different robot and continue to map the space.&lt;/p&gt; &#xA;&lt;p&gt;Our lifelong mapping consists of a few key steps&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Serialization and Deserialization to store and reload map information&lt;/li&gt; &#xA; &lt;li&gt;KD-Tree search matching to locate the robot in its position on reinitalization&lt;/li&gt; &#xA; &lt;li&gt;pose-graph optimizition based SLAM with 2D scan matching abstraction&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This will allow the user to create and update existing maps, then serialize the data for use in other mapping sessions, something sorely lacking from most SLAM implementations and nearly all planar SLAM implementations. Other good libraries that do this include RTab-Map and Cartographer, though they themselves have their own quirks that make them (in my opinion) unusable for production robotics applications. This library provides the mechanics to save not only the data, but the pose graph, and associated metadata to work with. This has been used to create maps by merging techniques (taking 2 or more serialized objects and creating 1 globally consistent one) as well as continuous mapping techniques (updating 1, same, serialized map object over time and refining it). The major benefit of this over RTab-Map or Cartographer is the maturity of the underlying (but heavily modified) &lt;code&gt;open_karto&lt;/code&gt; library the project is based on. The scan matcher of Karto is well known as an extremely good matcher for 2D laser scans and modified versions of Karto can be found in companies across the world.&lt;/p&gt; &#xA;&lt;p&gt;Slam Toolbox supports all the major modes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Starting from a predefined dock (assuming to be near start region)&lt;/li&gt; &#xA; &lt;li&gt;Starting at any particular node - select a node ID to start near&lt;/li&gt; &#xA; &lt;li&gt;Starting in any particular area - indicate current pose in the map frame to start at, like AMCL&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In the RVIZ interface (see section below) you&#39;ll be able to re-localize in a map or continue mapping graphically or programatically using ROS services.&lt;/p&gt; &#xA;&lt;p&gt;On time of writing: there a &lt;strong&gt;highly&lt;/strong&gt; experimental implementation of what I call &#34;true lifelong&#34; mapping that does support the method for removing nodes over time as well as adding nodes, this results in a true ability to map for life since the computation is bounded by removing extraneous or outdated information. Its recommended to run the non-full LifeLong mapping mode in the cloud for the increased computational burdens if you&#39;d like to be continuously refining a map. However a real and desperately needed application of this is to have multi-session mapping to update just a section of the map or map half an area at a time to create a full (and then static) map for AMCL or Slam Toolbox localization mode, which this will handle in spades. The immediate plan is to create a mode within LifeLong mapping to decay old nodes to bound the computation and allow it to run on the edge by refining the experimental node. Continuing mapping (lifelong) should be used to build a complete map then switch to the pose-graph deformation localization mode until node decay is implemented, and &lt;strong&gt;you should not see any substantial performance impacts&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Localization&lt;/h1&gt; &#xA;&lt;!-- map refind local area localization Gif here--&gt; &#xA;&lt;p&gt;Localization mode consists of 3 things:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Loads existing serialized map into the node&lt;/li&gt; &#xA; &lt;li&gt;Maintains a rolling buffer of recent scans in the pose-graph&lt;/li&gt; &#xA; &lt;li&gt;After expiring from the buffer scans are removed and the underlying map is not affected&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Localization methods on image map files has been around for years and works relatively well. There has not been a great deal of work in academia to refine these algorithms to a degree that satesfies me. However SLAM is a rich and well benchmarked topic. The inspiration of this work was the concept of &#34;Can we make localization, SLAM again?&#34; such that we can take advantage of all the nice things about SLAM for localization, but remove the unbounded computational increase.&lt;/p&gt; &#xA;&lt;p&gt;To enable, set &lt;code&gt;mode: localization&lt;/code&gt; in the configuration file to allow for the Ceres plugin to set itself correctly to be able to quickly add &lt;em&gt;and remove&lt;/em&gt; nodes and constraints from the pose graph, but isn&#39;t strictly required, but a performance optimization. The localization mode will automatically load your pose graph, take the first scan and match it against the local area to further refine your estimated position, and start localizing.&lt;/p&gt; &#xA;&lt;p&gt;To minimize the amount of changes required for moving to this mode over AMCL, we also expose a subscriber to the &lt;code&gt;/initialpose&lt;/code&gt; topic used by AMCL to relocalize to a position, which also hooks up to the &lt;code&gt;2D Pose Estimation&lt;/code&gt; tool in RVIZ. This way you can enter localization mode with our approach but continue to use the same API as you expect from AMCL for ease of integration.&lt;/p&gt; &#xA;&lt;p&gt;In summary, this approach I dub &lt;code&gt;elastic pose-graph localization&lt;/code&gt; is where we take existing map pose-graphs and localized with-in them with a rolling window of recent scans. This way we can localize in an existing map using the scan matcher, but not update the underlaying map long-term should something go wrong. It can be considered a replacement to AMCL and results is not needing any .pgm maps ever again. The lifelong mapping/continuous slam mode above will do better if you&#39;d like to modify the underlying graph while moving. This method of localization might not be suitable for all applications, it does require quite a bit of tuning for your particular robot and needs high quality odometry. If in doubt, you&#39;re always welcome to use other 2D map localizers in the ecosystem like AMCL. For most beginners or users looking for a good out of the box experience, I&#39;d recommend AMCL.&lt;/p&gt; &#xA;&lt;h2&gt;Tools&lt;/h2&gt; &#xA;&lt;h3&gt;Plugin based Optimizers&lt;/h3&gt; &#xA;&lt;p&gt;I have created a pluginlib interface for the ScanSolver abstract class so that you can change optimizers on runtime to test many different ones if you like.&lt;/p&gt; &#xA;&lt;p&gt;Then I generated plugins for a few different solvers that people might be interested in. I like to swap them out for benchmarking and make sure its the same code running for all. I have supported Ceres, G2O, SPA, and GTSAM.&lt;/p&gt; &#xA;&lt;p&gt;GTSAM/G2O/SPA is currently &#34;unsupported&#34; although all the code is there. They don&#39;t outperform Ceres settings I describe below so I stopped compiling them to save on build time, but they&#39;re there and work if you would like to use them. PRs to implement other optimizer plugins are welcome.&lt;/p&gt; &#xA;&lt;h3&gt;Map Merging - Example uses of serialized raw data &amp;amp; posegraphs&lt;/h3&gt; &#xA;&lt;h4&gt;Kinematic&lt;/h4&gt; &#xA;&lt;p&gt;This uses RVIZ and the plugin to load any number of posegraphs that will show up in RVIZ under &lt;code&gt;map_N&lt;/code&gt; and a set of interactive markers to allow you to move them around. Once you have them all positioned relative to each other in the way you like, you can merge the submaps into a global &lt;code&gt;map&lt;/code&gt; which can be downloaded with your map server implementation of choice.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s more of a demonstration of other things you can do once you have the raw data to work with, but I don&#39;t suspect many people will get much use out of it unless you&#39;re used to stitching maps by hand.&lt;/p&gt; &#xA;&lt;p&gt;More information in the RVIZ Plugin section below.&lt;/p&gt; &#xA;&lt;h3&gt;RVIZ Plugin&lt;/h3&gt; &#xA;&lt;p&gt;An rviz plugin is furnished to help with manual loop closures and online / offline mapping. By default interactive mode is off (allowing you to move nodes) as this takes quite a toll on rviz. When you want to move nodes, tick the interactive box, move what you want, and save changes to prompt a manual loop closure. Clear if you made a mistake. When done, exit interactive mode again.&lt;/p&gt; &#xA;&lt;p&gt;There&#39;s also a tool to help you control online and offline data. You can at any time stop processing new scans or accepting new scans into the queue. This is desirable when you want to allow the package to catch up while the robot sits still (&lt;strong&gt;This option is only meaningful in synchronous mode. In asynchronous mode the robot will never fall behind.&lt;/strong&gt;) or you want to stop processing new scans while you do a manual loop closure / manual &#34;help&#34;. If there&#39;s more in the queue than you want, you may also clear it.&lt;/p&gt; &#xA;&lt;p&gt;Additionally there&#39;s exposed buttons for the serialization and deserialization services to load an old pose-graph to update and refine, or continue mapping, then save back to file. The &#34;Start By Dock&#34; checkbox will try to scan match against the first node (assuming you started at your dock) to give you an odometry estimate to start with. Another option is to start using an inputted position in the GUI or by calling the underlying service. Additionally, you can use the current odometric position estimation if you happened to have just paused the robot or not moved much between runs. Finally (and most usefully), you can use the RVIZ tool for &lt;strong&gt;2D Pose Estimation&lt;/strong&gt; to tell it where to go in &lt;strong&gt;localization mode&lt;/strong&gt; just like AMCL.&lt;/p&gt; &#xA;&lt;p&gt;Additionally the RVIZ plugin will allow you to add serialized map files as submaps in RVIZ. They will be displayed with an interactive marker you can translate and rotate to match up, then generate a composite map with the Generate Map button. At that point the composite map is being broadcasted on the &lt;code&gt;/map&lt;/code&gt; topic and you can save it with the &lt;code&gt;map_saver&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s recommended to always continue mapping near the dock, if that&#39;s not possible, look into the starting from pose or map merging techniques. This RVIZ plugin is mostly here as a debug utility, but if you often find yourself mapping areas using rviz already, I&#39;d just have it open. All the RVIZ buttons are implemented using services that a master application can control.&lt;/p&gt; &#xA;&lt;p&gt;The interface is shown below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SteveMacenski/slam_toolbox/ros2/images/rviz_plugin.png?raw=true&#34; alt=&#34;rviz_plugin&#34; title=&#34;Rviz Plugin&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Graph Manipulation&lt;/h3&gt; &#xA;&lt;p&gt;By enabling &lt;code&gt;Interactive Mode&lt;/code&gt;, the graph nodes will change from markers to interactive markers which you can manipulate. When you move a node(s), you can Save Changes and it will send the updated position to the pose-graph and cause an optimization run to occur to change the pose-graph with your new node location. This is helpful if the robot gets pushed, slips, runs into a wall, or otherwise has drifting odometry and you would like to manually correct it.&lt;/p&gt; &#xA;&lt;p&gt;When a map is sufficiently large, the number of interactive markers in RVIZ may be too large and RVIZ may start to lag. I only recommend using this feature as a testing debug tool and not for production. However if you are able to make it work with 10,000 interactive markers, I&#39;ll merge that PR in a heartbeat. Otherwise I&#39;d restrict the use of this feature to small maps or with limited time to make a quick change and return to static mode by unchecking the box.&lt;/p&gt; &#xA;&lt;h2&gt;Metrics&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;re a weirdo like me and you want to see how I came up with the settings I had for the Ceres optimizer, see below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/14944147/41576505-a6802d76-733c-11e8-8eca-334da2c8bd50.png&#34; alt=&#34;ceres_solver_comparison&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The data sets present solve time vs number of nodes in the pose graph on a large dataset, as that is not open source, but suffice to say that the settings I recommend work well. I think anyone would be hardset in a normal application to exceed or find that another solver type is better (that super low curve on the bottom one, yeah, that&#39;s it). Benchmark on a low power 7th gen i7 machine.&lt;/p&gt; &#xA;&lt;p&gt;It can map &lt;em&gt;very&lt;/em&gt; large spaces with reasonable CPU and memory consumption. My default settings increase O(N) on number of elements in the pose graph. I recommend from extensive testing to use the &lt;code&gt;SPARSE_NORMAL_CHOLESKY&lt;/code&gt; solver with Ceres and the &lt;code&gt;SCHUR_JACOBI&lt;/code&gt; preconditioner. Using &lt;code&gt;LM&lt;/code&gt; at the trust region strategy is comparable to the dogleg subspace strategy, but &lt;code&gt;LM&lt;/code&gt; is much better supported so why argue with it.&lt;/p&gt; &#xA;&lt;p&gt;You can get away without a loss function if your odometry is good (ie likelihood for outliers is extremely low). If you have an abnormal application or expect wheel slippage, I might recommend a &lt;code&gt;HuberLoss&lt;/code&gt; function, which is a really good catch-all loss function if you&#39;re looking for a place to start. All these options and more are available from the ROS parameter server.&lt;/p&gt; &#xA;&lt;h1&gt;API&lt;/h1&gt; &#xA;&lt;p&gt;The following are the services/topics that are exposed for use. See the rviz plugin for an implementation of their use.&lt;/p&gt; &#xA;&lt;h2&gt;Subscribed topics&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;/scan&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;sensor_msgs/LaserScan&lt;/code&gt;&lt;/th&gt; &#xA;   &lt;th&gt;the input scan from your laser to utilize&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;tf&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;a valid transform from your configured odom_frame to base_frame&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Published topics&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Topic&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;map&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;nav_msgs/OccupancyGrid&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;occupancy grid representation of the pose-graph at &lt;code&gt;map_update_interval&lt;/code&gt; frequency&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;pose&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;geometry_msgs/PoseWithCovarianceStamped&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;pose of the base_frame in the configured map_frame along with the covariance calculated from the scan match&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Exposed Services&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Topic&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;/slam_toolbox/clear_changes&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;slam_toolbox/Clear&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Clear all manual pose-graph manipulation changes pending&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;/slam_toolbox/deserialize_map&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;slam_toolbox/DeserializePoseGraph&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Load a saved serialized pose-graph files from disk&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;/slam_toolbox/dynamic_map&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;nav_msgs/OccupancyGrid&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Request the current state of the pose-graph as an occupancy grid&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;/slam_toolbox/manual_loop_closure&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;slam_toolbox/LoopClosure&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Request the manual changes to the pose-graph pending to be processed&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;/slam_toolbox/pause_new_measurements&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;slam_toolbox/Pause&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Pause processing of new incoming laser scans by the toolbox&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;/slam_toolbox/save_map&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;slam_toolbox/SaveMap&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Save the map image file of the pose-graph that is useable for display or AMCL localization. It is a simple wrapper on &lt;code&gt;map_server/map_saver&lt;/code&gt; but is useful.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;/slam_toolbox/serialize_map&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;slam_toolbox/SerializePoseGraph&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Save the map pose-graph and datathat is useable for continued mapping, slam_toolbox localization, offline manipulation, and more&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;/slam_toolbox/toggle_interactive_mode&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;slam_toolbox/ToggleInteractive&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Toggling in and out of interactive mode, publishing interactive markers of the nodes and their positions to be updated in an application&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Configuration&lt;/h1&gt; &#xA;&lt;p&gt;The following settings and options are exposed to you. My default configuration is given in &lt;code&gt;config&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h2&gt;Solver Params&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;solver_plugin&lt;/code&gt; - The type of nonlinear solver to utilize for karto&#39;s scan solver. Options: &lt;code&gt;solver_plugins::CeresSolver&lt;/code&gt;, &lt;code&gt;solver_plugins::SpaSolver&lt;/code&gt;, &lt;code&gt;solver_plugins::G2oSolver&lt;/code&gt;. Default: &lt;code&gt;solver_plugins::CeresSolver&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ceres_linear_solver&lt;/code&gt; - The linear solver for Ceres to use. Options: &lt;code&gt;SPARSE_NORMAL_CHOLESKY&lt;/code&gt;, &lt;code&gt;SPARSE_SCHUR&lt;/code&gt;, &lt;code&gt;ITERATIVE_SCHUR&lt;/code&gt;, &lt;code&gt;CGNR&lt;/code&gt;. Defaults to &lt;code&gt;SPARSE_NORMAL_CHOLESKY&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ceres_preconditioner&lt;/code&gt; - The preconditioner to use with that solver. Options: &lt;code&gt;JACOBI&lt;/code&gt;, &lt;code&gt;IDENTITY&lt;/code&gt; (none), &lt;code&gt;SCHUR_JACOBI&lt;/code&gt;. Defaults to &lt;code&gt;JACOBI&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ceres_trust_strategy&lt;/code&gt; - The trust region strategy. Line searach strategies are not exposed because they perform poorly for this use. Options: &lt;code&gt;LEVENBERG_MARQUARDT&lt;/code&gt;, &lt;code&gt;DOGLEG&lt;/code&gt;. Default: &lt;code&gt;LEVENBERG_MARQUARDT&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ceres_dogleg_type&lt;/code&gt; - The dogleg strategy to use if the trust strategy is &lt;code&gt;DOGLEG&lt;/code&gt;. Options: &lt;code&gt;TRADITIONAL_DOGLEG&lt;/code&gt;, &lt;code&gt;SUBSPACE_DOGLEG&lt;/code&gt;. Default: &lt;code&gt;TRADITIONAL_DOGLEG&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ceres_loss_function&lt;/code&gt; - The type of loss function to reject outlier measurements. None is equatable to a squared loss. Options: &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;HuberLoss&lt;/code&gt;, &lt;code&gt;CauchyLoss&lt;/code&gt;. Default: &lt;code&gt;None&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;mode&lt;/code&gt; - &#34;mapping&#34; or &#34;localization&#34; mode for performance optimizations in the Ceres problem creation&lt;/p&gt; &#xA;&lt;h2&gt;Toolbox Params&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;odom_frame&lt;/code&gt; - Odometry frame&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;map_frame&lt;/code&gt; - Map frame&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;base_frame&lt;/code&gt; - Base frame&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;scan_topic&lt;/code&gt; - scan topic, &lt;em&gt;absolute&lt;/em&gt; path, ei &lt;code&gt;/scan&lt;/code&gt; not &lt;code&gt;scan&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;scan_queue_size&lt;/code&gt; - The number of scan messages to queue up before throwing away old ones. Should always be set to 1 in async mode&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;map_file_name&lt;/code&gt; - Name of the pose-graph file to load on startup if available&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;map_start_pose&lt;/code&gt; - Pose to start pose-graph mapping/localization in, if available&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;map_start_at_dock&lt;/code&gt; - Starting pose-graph loading at the dock (first node), if available. If both pose and dock are set, it will use pose&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;debug_logging&lt;/code&gt; - Change logger to debug&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;throttle_scans&lt;/code&gt; - Number of scans to throttle in synchronous mode&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;transform_publish_period&lt;/code&gt; - The map to odom transform publish period. 0 will not publish transforms&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;map_update_interval&lt;/code&gt; - Interval to update the 2D occupancy map for other applications / visualization&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;enable_interactive_mode&lt;/code&gt; - Whether or not to allow for interactive mode to be enabled. Interactive mode will retain a cache of laser scans mapped to their ID for visualization in interactive mode. As a result the memory for the process will increase. This is manually disabled in localization and lifelong modes since they would increase the memory utilization over time. Valid for either mapping or continued mapping modes.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;position_covariance_scale&lt;/code&gt; - Amount to scale position covariance when publishing pose from scan match. This can be used to tune the influence of the pose position in a downstream localization filter. The covariance represents the uncertainty of the measurement, so scaling up the covariance will result in the pose position having less influence on downstream filters. Default: 1.0&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;yaw_covariance_scale&lt;/code&gt; - Amount to scale yaw covariance when publishing pose from scan match. See description of position_covariance_scale. Default: 1.0&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;resolution&lt;/code&gt; - Resolution of the 2D occupancy map to generate&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;max_laser_range&lt;/code&gt; - Maximum laser range to use for 2D occupancy map rastering&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;minimum_time_interval&lt;/code&gt; - The minimum duration of time between scans to be processed in synchronous mode&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;transform_timeout&lt;/code&gt; - TF timeout for looking up transforms&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;tf_buffer_duration&lt;/code&gt; - Duration to store TF messages for lookup. Set high if running offline at multiple times speed in synchronous mode.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;stack_size_to_use&lt;/code&gt; - The number of bytes to reset the stack size to, to enable serialization/deserialization of files. A liberal default is 40000000, but less is fine.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;minimum_travel_distance&lt;/code&gt; - Minimum distance of travel before processing a new scan&lt;/p&gt; &#xA;&lt;h2&gt;Matcher Params&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;use_scan_matching&lt;/code&gt; - whether to use scan matching to refine odometric pose (uh, why would you not?)&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;use_scan_barycenter&lt;/code&gt; - Whether to use the barycenter or scan pose&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;minimum_travel_heading&lt;/code&gt; - Minimum changing in heading to justify an update&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;scan_buffer_size&lt;/code&gt; - The number of scans to buffer into a chain, also used as the number of scans in the circular buffer of localization mode&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;scan_buffer_maximum_scan_distance&lt;/code&gt; - Maximum distance of a scan from the pose before removing the scan from the buffer&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;link_match_minimum_response_fine&lt;/code&gt; - The threshold link matching algorithm response for fine resolution to pass&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;link_scan_maximum_distance&lt;/code&gt; - Maximum distance between linked scans to be valid&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;loop_search_maximum_distance&lt;/code&gt; - Maximum threshold of distance for scans to be considered for loop closure&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;do_loop_closing&lt;/code&gt; - Whether to do loop closure (if you&#39;re not sure, the answer is &#34;true&#34;)&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;loop_match_minimum_chain_size&lt;/code&gt; - The minimum chain length of scans to look for loop closure&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;loop_match_maximum_variance_coarse&lt;/code&gt; - The threshold variance in coarse search to pass to refine&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;loop_match_minimum_response_coarse&lt;/code&gt; - The threshold response of the loop closure algorithm in coarse search to pass to refine&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;loop_match_minimum_response_fine&lt;/code&gt; - The threshold response of the loop closure algorithm in fine search to pass to refine&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;correlation_search_space_dimension&lt;/code&gt; - Search grid size to do scan correlation over&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;correlation_search_space_resolution&lt;/code&gt; - Search grid resolution to do scan correlation over&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;correlation_search_space_smear_deviation&lt;/code&gt; - Amount of multimodal smearing to smooth out responses&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;loop_search_space_dimension&lt;/code&gt; - Size of the search grid over the loop closure algorith&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;loop_search_space_resolution&lt;/code&gt; - Search grid resolution to do loop closure over&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;loop_search_space_smear_deviation&lt;/code&gt; - Amount of multimodal smearing to smooth out responses&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;distance_variance_penalty&lt;/code&gt; - A penalty to apply to a matched scan as it differs from the odometric pose&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;angle_variance_penalty&lt;/code&gt; - A penalty to apply to a matched scan as it differs from the odometric pose&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;fine_search_angle_offset&lt;/code&gt; - Range of angles to test for fine scan matching&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;coarse_search_angle_offset&lt;/code&gt; - Range of angles to test for coarse scan matching&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;coarse_angle_resolution&lt;/code&gt; - Resolution of angles over the Offset range to test in scan matching&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;minimum_angle_penalty&lt;/code&gt; - Smallest penalty an angle can have to ensure the size doesn&#39;t blow up&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;minimum_distance_penalty&lt;/code&gt; - Smallest penalty a scan can have to ensure the size doesn&#39;t blow up&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;use_response_expansion&lt;/code&gt; - Whether to automatically increase the search grid size if no viable match is found&lt;/p&gt; &#xA;&lt;h1&gt;Install&lt;/h1&gt; &#xA;&lt;p&gt;ROSDep will take care of the major things&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;rosdep install -q -y -r --from-paths src --ignore-src&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or install via apt&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;apt install ros-eloquent-slam-toolbox&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run your colcon build procedure of choice.&lt;/p&gt; &#xA;&lt;p&gt;You can run via &lt;code&gt;ros2 launch slam_toolbox online_sync_launch.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Etc&lt;/h1&gt; &#xA;&lt;h2&gt;NanoFlann!&lt;/h2&gt; &#xA;&lt;p&gt;In order to do some operations quickly for continued mapping and localization, I make liberal use of NanoFlann (shout out!).&lt;/p&gt; &#xA;&lt;h2&gt;Brief incursion into snaps&lt;/h2&gt; &#xA;&lt;p&gt;Snap are completely isolated containerized packages that one can run through the Canonical organization on a large number of Linux distributions. They&#39;re similar to Docker containers but it doesn&#39;t share the kernel or any of the libraries, and rather has everything internal as essentially a seperate partitioned operating system based on Ubuntu Core.&lt;/p&gt; &#xA;&lt;p&gt;We package up slam toolbox in this way for a nice multiple-on speed up in execution from a couple of pretty nuanced reasons in this particular project, but generally speaking you shouldn&#39;t expect a speedup from a snap.&lt;/p&gt; &#xA;&lt;p&gt;Since Snaps are totally isolated and there&#39;s no override flags like in Docker, there&#39;s only a couple of fixed directories that both the snap and the host system can write and read from, including SNAP_COMMON (usually in &lt;code&gt;/var/snap/[snap name]/common&lt;/code&gt;). Therefore, this is the place that if you&#39;re serializing and deserializing maps, you need to have them accessible to that directory.&lt;/p&gt; &#xA;&lt;p&gt;You can optionally store all your serialized maps there, move maps there as needed, take maps from there after serialization, or do my favorite option and &lt;code&gt;link&lt;/code&gt; the directories with &lt;code&gt;ln&lt;/code&gt; to where ever you normally store your maps and you&#39;re wanting to dump your serialized map files.&lt;/p&gt; &#xA;&lt;p&gt;Example of &lt;code&gt;ln&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#           Source                           Linked&#xA;sudo ln -s /home/steve/maps/serialized_map/ /var/snap/slam-toolbox/common&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and then all you have to do when you specify a map to use is set the filename to &lt;code&gt;slam-toolbox/map_name&lt;/code&gt; and it should work no matter if you&#39;re running in a snap, docker, or on bare metal. The &lt;code&gt;-s&lt;/code&gt; makes a symbol link so rather than &lt;code&gt;/var/snap/slam-toolbox/common/*&lt;/code&gt; containing the maps, &lt;code&gt;/var/snap/slam-toolbox/common/serialized_map/*&lt;/code&gt; will. By default on bare metal, the maps will be saved in &lt;code&gt;.ros&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;More Gifs!&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SteveMacenski/slam_toolbox/ros2/images/mapping_steves_apartment.gif?raw=true&#34; alt=&#34;map_image&#34; title=&#34;Map Image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If someone from iRobot can use this to tell me my Roomba serial number by correlating to its maps, I&#39;ll buy them lunch and probably try to hire them.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>unum-cloud/ujrpc</title>
    <updated>2023-03-09T01:31:12Z</updated>
    <id>tag:github.com,2023-03-09:/unum-cloud/ujrpc</id>
    <link href="https://github.com/unum-cloud/ujrpc" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Up to 100x Faster FastAPI. JSON-RPC with io_uring, SIMDJSON, and pure CPython bindings&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;Uninterrupted JSON RPC&lt;/h1&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; Remote Procedure Calls&lt;br&gt; Up to 100x Faster than FastAPI&lt;br&gt; &lt;/h3&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/xuDmpbEDnQ&#34;&gt;&lt;img height=&#34;25&#34; src=&#34;https://github.com/unum-cloud/ukv/raw/main/assets/icons/discord.svg?sanitize=true&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://www.linkedin.com/company/unum-cloud/&#34;&gt;&lt;img height=&#34;25&#34; src=&#34;https://github.com/unum-cloud/ukv/raw/main/assets/icons/linkedin.svg?sanitize=true&#34; alt=&#34;LinkedIn&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://twitter.com/unum_cloud&#34;&gt;&lt;img height=&#34;25&#34; src=&#34;https://github.com/unum-cloud/ukv/raw/main/assets/icons/twitter.svg?sanitize=true&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://unum.cloud/post&#34;&gt;&lt;img height=&#34;25&#34; src=&#34;https://github.com/unum-cloud/ukv/raw/main/assets/icons/blog.svg?sanitize=true&#34; alt=&#34;Blog&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://github.com/unum-cloud/ujrpc&#34;&gt;&lt;img height=&#34;25&#34; src=&#34;https://github.com/unum-cloud/ukv/raw/main/assets/icons/github.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Most modern networking is built either on slow and ambiguous REST APIs or unnecessarily complex gRPC. FastAPI, for example, looks very approachable. We aim to be equally or even simpler to use.&lt;/p&gt; &#xA;&lt;table width=&#34;100%&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th width=&#34;50%&#34;&gt;FastAPI&lt;/th&gt;&#xA;   &lt;th width=&#34;50%&#34;&gt;UJRPC&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install fastapi uvicorn&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install ujrpc&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fastapi import FastAPI&#xA;import uvicorn&#xA;&#xA;server = FastAPI()&#xA;&#xA;@server.get(&#39;/sum&#39;)&#xA;def sum(a: int, b: int):&#xA;    return a + b&#xA;&#xA;uvicorn.run(...)    &#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from ujrpc.posix import Server&#xA;# from ujrpc.uring import Server on 5.19+&#xA;&#xA;server = Server()&#xA;&#xA;@server&#xA;def sum(a: int, b: int):&#xA;    return a + b&#xA;&#xA;server.run()    &#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;It takes over a millisecond to handle a trivial FastAPI call on a recent 8-core CPU. In that time, light could have traveled 300 km through optics to the neighboring city or country, in my case. How does UJRPC compare to FastAPI and gRPC?&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Setup&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;🔁&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Server&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Latency w 1 client&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Throughput w 32 clients&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Fast API over REST&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🐍&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1&#39;203 μs&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3&#39;184 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Fast API over WebSocket&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🐍&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;86 μs&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;11&#39;356 rps ¹&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;gRPC ²&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🐍&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;164 μs&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;9&#39;849 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;UJRPC with POSIX&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;62 μs&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;79&#39;000 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;UJRPC with io_uring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🐍&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;23 μs&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;43&#39;000 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;UJRPC with io_uring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;22 μs&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;231&#39;000 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Table legend&lt;/summary&gt; &#xA; &lt;p&gt;All benchmarks were conducted on AWS on general purpose instances with &lt;strong&gt;Ubuntu 22.10 AMI&lt;/strong&gt;. It is the first major AMI to come with &lt;strong&gt;Linux Kernel 5.19&lt;/strong&gt;, featuring much wider &lt;code&gt;io_uring&lt;/code&gt; support for networking operations. These specific numbers were obtained on &lt;code&gt;c7g.metal&lt;/code&gt; beefy instances with Graviton 3 chips.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;The 🔁 column marks, if the TCP/IP connection is being reused during subsequent requests.&lt;/li&gt; &#xA;  &lt;li&gt;The &#34;server&#34; column defines the programming language, in which the server was implemented.&lt;/li&gt; &#xA;  &lt;li&gt;The &#34;latency&#34; column report the amount of time between sending a request and receiving a response. μ stands for micro, μs subsequently means microseconds.&lt;/li&gt; &#xA;  &lt;li&gt;The &#34;throughput&#34; column reports the number of Requests Per Second when querying the same server application from multiple client processes running on the same machine.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;p&gt;¹ FastAPI couldn&#39;t process concurrent requests with WebSockets.&lt;/p&gt; &#xA; &lt;/blockquote&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;p&gt;² We tried generating C++ backends with gRPC, but its numbers, suspiciously, weren&#39;t better. There is also an async gRPC option, that wasn&#39;t tried.&lt;/p&gt; &#xA; &lt;/blockquote&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;How is that possible?!&lt;/h2&gt; &#xA;&lt;p&gt;How can a tiny pet-project with just a couple thousand lines of code compete with two of the most established networking libraries? &lt;strong&gt;UJRPC stands on the shoulders of Giants&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;io_uring&lt;/code&gt; for interrupt-less IO.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;io_uring_prep_read_fixed&lt;/code&gt; on 5.1+.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;io_uring_prep_accept_direct&lt;/code&gt; on 5.19+.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;io_uring_register_files_sparse&lt;/code&gt; on 5.19+.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;IORING_SETUP_COOP_TASKRUN&lt;/code&gt; optional on 5.19+.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;IORING_SETUP_SINGLE_ISSUER&lt;/code&gt; optional on 6.0+.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SIMD-accelerated parsers with manual memory control.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/simdjson/simdjson&#34;&gt;&lt;code&gt;simdjson&lt;/code&gt;&lt;/a&gt; to parse JSON faster than gRPC can unpack &lt;code&gt;ProtoBuf&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/powturbo/Turbo-Base64&#34;&gt;&lt;code&gt;Turbo-Base64&lt;/code&gt;&lt;/a&gt; to decode binary values from a &lt;code&gt;Base64&lt;/code&gt; form.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/h2o/picohttpparser&#34;&gt;&lt;code&gt;picohttpparser&lt;/code&gt;&lt;/a&gt; to navigate HTTP headers.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You have already seen the latency of the round trip..., the throughput in requests per second..., want to see the bandwidth? Try yourself!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@server&#xA;def echo(data: bytes):&#xA;    return data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Free Tier Throughput&lt;/h3&gt; &#xA;&lt;p&gt;We will leave bandwidth measurements to enthusiasts, but will share some more numbers. The general logic is that you can&#39;t squeeze high performance from Free-Tier machines. Currently AWS provides following options: &lt;code&gt;t2.micro&lt;/code&gt; and &lt;code&gt;t4g.small&lt;/code&gt;, on older Intel and newer Graviton 2 chips. This library is so fast, that it doesn&#39;t need more than 1 core, so you can run a fast server even on a tiny Free-Tier server!&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Setup&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;🔁&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Server&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Clients&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;&lt;code&gt;t2.micro&lt;/code&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;&lt;code&gt;t4g.small&lt;/code&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Fast API over REST&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🐍&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;328 rps&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;424 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Fast API over WebSocket&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🐍&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1&#39;504 rps&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3&#39;051 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;gRPC&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🐍&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1&#39;169 rps&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1&#39;974 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;UJRPC with POSIX&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1&#39;082 rps&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;2&#39;438 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;UJRPC with io_uring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5&#39;864 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;UJRPC with POSIX&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3&#39;399 rps&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;39&#39;877 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;UJRPC with io_uring&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;88&#39;455 rps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;In this case, every server was bombarded by requests from 1 or a fleet of 32 other instances in the same availability zone. If you want to reproduce those benchmarks, check out the &lt;a href=&#34;https://github.com/unum-cloud/ujrpc/tree/dev/examples/sum&#34;&gt;&lt;code&gt;sum&lt;/code&gt; examples on GitHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;For Python:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install ujrpc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For CMake projects:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cmake&#34;&gt;include(FetchContent)&#xA;FetchContent_Declare(&#xA;    ujrpc&#xA;    GIT_REPOSITORY https://github.com/unum-cloud/ujrpc&#xA;    GIT_SHALLOW TRUE&#xA;)&#xA;FetchContent_MakeAvailable(ujrpc)&#xA;include_directories(${ujrpc_SOURCE_DIR}/include)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The C usage example is mouthful compared to Python. We wanted to make it as lightweight as possible and to allow optional arguments without dynamic allocations and named lookups. So unlike the Python layer, we expect the user to manually extract the arguments from the call context with &lt;code&gt;ujrpc_param_named_i64()&lt;/code&gt;, and its siblings.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;cstdio.h&amp;gt;&#xA;#include &amp;lt;ujrpc/ujrpc.h&amp;gt;&#xA;&#xA;static void sum(ujrpc_call_t call, ujrpc_callback_tag_t) {&#xA;    int64_t a{}, b{};&#xA;    char printed_sum[256]{};&#xA;    bool got_a = ujrpc_param_named_i64(call, &#34;a&#34;, 0, &amp;amp;a);&#xA;    bool got_b = ujrpc_param_named_i64(call, &#34;b&#34;, 0, &amp;amp;b);&#xA;    if (!got_a || !got_b)&#xA;        return ujrpc_call_reply_error_invalid_params(call);&#xA;&#xA;    int len = snprintf(printed_sum, 256, &#34;%ll&#34;, a + b);&#xA;    ujrpc_call_reply_content(call, printed_sum, len);&#xA;}&#xA;&#xA;int main(int argc, char** argv) {&#xA;&#xA;    ujrpc_server_t server{};&#xA;    ujrpc_config_t config{};&#xA;&#xA;    ujrpc_init(&amp;amp;config, &amp;amp;server);&#xA;    ujrpc_add_procedure(server, &#34;sum&#34;, &amp;amp;sum, NULL);&#xA;    ujrpc_take_calls(server, 0);&#xA;    ujrpc_free(server);&#xA;    return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Batch Requests&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; JSON-RPC over raw TCP sockets&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; JSON-RPC over TCP with HTTP&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Concurrent sessions&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Numpy &lt;code&gt;array&lt;/code&gt; serialization&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; HTTP&lt;strong&gt;S&lt;/strong&gt; support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Batch-capable endpoints for ML&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Zero-ETL relay calls&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Integrating with &lt;a href=&#34;https://github.com/unum-cloud/ukv&#34;&gt;UKV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; WebSockets for web interfaces&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; AF_XDP and UDP-based analogs on Linux&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Want to affect the roadmap and request a feature? Join the discussions on Discord.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Why JSON-RPC?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Transport independent: UDP, TCP, bring what you want.&lt;/li&gt; &#xA; &lt;li&gt;Application layer is optional: use HTTP or not.&lt;/li&gt; &#xA; &lt;li&gt;Unlike REST APIs, there is just one way to pass arguments.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Roblox/luau</title>
    <updated>2023-03-09T01:31:12Z</updated>
    <id>tag:github.com,2023-03-09:/Roblox/luau</id>
    <link href="https://github.com/Roblox/luau" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A fast, small, safe, gradually typed embeddable scripting language derived from Lua&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Luau &lt;img src=&#34;https://github.com/Roblox/luau/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt; &lt;a href=&#34;https://codecov.io/gh/Roblox/luau&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/Roblox/luau/branch/master/graph/badge.svg?token=S3U44WN416&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Luau (lowercase u, /ˈlu.aʊ/) is a fast, small, safe, gradually typed embeddable scripting language derived from &lt;a href=&#34;https://lua.org&#34;&gt;Lua&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It is designed to be backwards compatible with Lua 5.1, as well as incorporating &lt;a href=&#34;https://luau-lang.org/compatibility&#34;&gt;some features&lt;/a&gt; from future Lua releases, but also expands the feature set (most notably with type annotations). Luau is largely implemented from scratch, with the language runtime being a very heavily modified version of Lua 5.1 runtime, with completely rewritten interpreter and other &lt;a href=&#34;https://luau-lang.org/performance&#34;&gt;performance innovations&lt;/a&gt;. The runtime mostly preserves Lua 5.1 API, so existing bindings should be more or less compatible with a few caveats.&lt;/p&gt; &#xA;&lt;p&gt;Luau is used by Roblox game developers to write game code, as well as by Roblox engineers to implement large parts of the user-facing application code as well as portions of the editor (Roblox Studio) as plugins. Roblox chose to open-source Luau to foster collaboration within the Roblox community as well as to allow other companies and communities to benefit from the ongoing language and runtime innovation.&lt;/p&gt; &#xA;&lt;p&gt;This repository hosts source code for the language implementation and associated tooling, documentation for the language as well as RFCs and other materials. The documentation portion of this repository can be viewed at &lt;a href=&#34;https://luau-lang.org/&#34;&gt;https://luau-lang.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;Luau is an embeddable language, but it also comes with two command-line tools by default, &lt;code&gt;luau&lt;/code&gt; and &lt;code&gt;luau-analyze&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;luau&lt;/code&gt; is a command-line REPL and can also run input files. Note that REPL runs in a sandboxed environment and as such doesn&#39;t have access to the underlying file system except for ability to &lt;code&gt;require&lt;/code&gt; modules.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;luau-analyze&lt;/code&gt; is a command-line type checker and linter; given a set of input files, it produces errors/warnings according to the file configuration, which can be customized by using &lt;code&gt;--!&lt;/code&gt; comments in the files or &lt;a href=&#34;https://github.com/Roblox/luau/raw/master/rfcs/config-luaurc.md&#34;&gt;&lt;code&gt;.luaurc&lt;/code&gt;&lt;/a&gt; files. For details please refer to &lt;a href=&#34;https://luau-lang.org/typecheck&#34;&gt;type checking&lt;/a&gt; and &lt;a href=&#34;https://luau-lang.org/lint&#34;&gt;linting&lt;/a&gt; documentation.&lt;/p&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;You can install and run Luau by downloading the compiled binaries from &lt;a href=&#34;https://github.com/Roblox/luau/releases&#34;&gt;a recent release&lt;/a&gt;; note that &lt;code&gt;luau&lt;/code&gt; and &lt;code&gt;luau-analyze&lt;/code&gt; binaries from the archives will need to be added to PATH or copied to a directory like &lt;code&gt;/usr/local/bin&lt;/code&gt; on Linux/macOS.&lt;/p&gt; &#xA;&lt;p&gt;Alternatively, you can use one of the packaged distributions (note that these are not maintained by Luau development team):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;macOS: &lt;a href=&#34;https://docs.brew.sh/Installation&#34;&gt;Install Homebrew&lt;/a&gt; and run &lt;code&gt;brew install luau&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Arch Linux: Run &lt;code&gt;pacman -S luau&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Alpine Linux: &lt;a href=&#34;https://wiki.alpinelinux.org/w/index.php?title=Enable_Community_Repository&#34;&gt;Enable community repositories&lt;/a&gt; and run &lt;code&gt;apk add luau&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;After installing, you will want to validate the installation was successful by running the test case &lt;a href=&#34;https://luau-lang.org/getting-started&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;On all platforms, you can use CMake to run the following commands to build Luau binaries from source:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mkdir cmake &amp;amp;&amp;amp; cd cmake&#xA;cmake .. -DCMAKE_BUILD_TYPE=RelWithDebInfo&#xA;cmake --build . --target Luau.Repl.CLI --config RelWithDebInfo&#xA;cmake --build . --target Luau.Analyze.CLI --config RelWithDebInfo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, on Linux/macOS you can use &lt;code&gt;make&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make config=release luau luau-analyze&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To integrate Luau into your CMake application projects as a library, at the minimum you&#39;ll need to depend on &lt;code&gt;Luau.Compiler&lt;/code&gt; and &lt;code&gt;Luau.VM&lt;/code&gt; projects. From there you need to create a new Luau state (using Lua 5.x API such as &lt;code&gt;lua_newstate&lt;/code&gt;), compile source to bytecode and load it into the VM like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// needs lua.h and luacode.h&#xA;size_t bytecodeSize = 0;&#xA;char* bytecode = luau_compile(source, strlen(source), NULL, &amp;amp;bytecodeSize);&#xA;int result = luau_load(L, chunkname, bytecode, bytecodeSize, 0);&#xA;free(bytecode);&#xA;&#xA;if (result == 0)&#xA;    return 1; /* return chunk main function */&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more details about the use of host API you currently need to consult &lt;a href=&#34;https://www.lua.org/manual/5.1/manual.html#3&#34;&gt;Lua 5.x API&lt;/a&gt;. Luau closely tracks that API but has a few deviations, such as the need to compile source separately (which is important to be able to deploy VM without a compiler), or lack of &lt;code&gt;__gc&lt;/code&gt; support (use &lt;code&gt;lua_newuserdatadtor&lt;/code&gt; instead).&lt;/p&gt; &#xA;&lt;p&gt;To gain advantage of many performance improvements it&#39;s highly recommended to use &lt;code&gt;safeenv&lt;/code&gt; feature, which sandboxes individual scripts&#39; global tables from each other as well as protects builtin libraries from monkey-patching. For this to work you need to call &lt;code&gt;luaL_sandbox&lt;/code&gt; for the global state and &lt;code&gt;luaL_sandboxthread&lt;/code&gt; for each new script&#39;s execution thread.&lt;/p&gt; &#xA;&lt;h1&gt;Testing&lt;/h1&gt; &#xA;&lt;p&gt;Luau has an internal test suite; in CMake builds it is split into two targets, &lt;code&gt;Luau.UnitTest&lt;/code&gt; (for bytecode compiler and type checker/linter tests) and &lt;code&gt;Luau.Conformance&lt;/code&gt; (for VM tests). The unit tests are written in C++, whereas the conformance tests are largely written in Luau (see &lt;code&gt;tests/conformance&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Makefile builds combine both into a single target and can be ran via &lt;code&gt;make test&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Dependencies&lt;/h1&gt; &#xA;&lt;p&gt;Luau uses C++ as its implementation language. The runtime requires C++11, whereas the compiler and analysis components require C++17. It should build without issues using Microsoft Visual Studio 2017 or later, or gcc-7 or clang-7 or later.&lt;/p&gt; &#xA;&lt;p&gt;Other than the STL/CRT, Luau library components don&#39;t have external dependencies. The test suite depends on &lt;a href=&#34;https://github.com/onqtam/doctest&#34;&gt;doctest&lt;/a&gt; testing framework, and the REPL command-line depends on &lt;a href=&#34;https://github.com/daanx/isocline&#34;&gt;isocline&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;Luau implementation is distributed under the terms of &lt;a href=&#34;https://github.com/Roblox/luau/raw/master/LICENSE.txt&#34;&gt;MIT License&lt;/a&gt;. It is based on Lua 5.x implementation that is MIT licensed as well.&lt;/p&gt; &#xA;&lt;p&gt;When Luau is integrated into external projects, we ask to honor the license agreement and include Luau attribution into the user-facing product documentation. The attribution using &lt;a href=&#34;https://github.com/Roblox/luau/raw/master/docs/logo.svg&#34;&gt;Luau logo&lt;/a&gt; is also encouraged.&lt;/p&gt;</summary>
  </entry>
</feed>