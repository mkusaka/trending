<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-22T01:31:28Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>oisyn/parkerwords</title>
    <updated>2022-10-22T01:31:28Z</updated>
    <id>tag:github.com,2022-10-22:/oisyn/parkerwords</id>
    <link href="https://github.com/oisyn/parkerwords" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;A solution to the problem of finding five English words with 25 distinct characters, as posed in this video by Matt Parker: &lt;a href=&#34;https://www.youtube.com/watch?v=_-AfhLQfb6w&#34;&gt;https://www.youtube.com/watch?v=_-AfhLQfb6w&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;While you&#39;re here, Benjamin Paassen was nice enough to run all solutions on his PC and made a sheet with the timing results. Check out the twitter thread &lt;a href=&#34;https://twitter.com/bpaassen1/status/1556900513505021953&#34;&gt;here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;To compile, either open parkerwords.sln in VS 2019 or later, or compile parkerwords.cpp using your favorite C++20 compiler.&lt;/p&gt; &#xA;&lt;p&gt;It takes 0.055 seconds to run on my AMD Ryzen 5800X, and finds all the 538 solutions mentioned in the video. Result is written to solutions.txt.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Total time: 55332us (0.055332s)&#xA;Read:       11661us&#xA;Process:    43255us&#xA;Write:        416us&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For an implementation using AVX2, see the &lt;a href=&#34;https://github.com/oisyn/parkerwords/tree/sse&#34;&gt;SSE branch&lt;/a&gt; (currently at 23ms)&lt;/p&gt; &#xA;&lt;p&gt;Since writing to stdout now no longer takes a negligible amount of time relative to the rest of the algorithm, I&#39;ve made most output conditional. Uncomment the NO_OUTPUT #define in the top of the file to reenable some verbose information and progress indication.&lt;/p&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;The algorithm handles words as bitsets stored in a 32-bit integer, where each bit position represents the inclusion of that letter in the word, with &#39;a&#39; being bit 0, &#39;b&#39; bit 1, and so forth, up to 26 bits in total. Using a bitwise AND, we can quickly check if two words have overlapping letters, which would then give a non-zero result.&lt;/p&gt; &#xA;&lt;p&gt;Furthermore, it uses an index to quickly look up a list of words containing a certain letter. By leveraging the fact that the algorithm looks for the letters in a certain order, we only need to store each word in the index once; with it&#39;s lowest ordered letter as the index. To determine the order of the letters, the frequency of each letter is recorded and the order of letters is from least to most frequently used letter (using this dataset, it produces the order: &#34;qxjzvfwbkgpmhdcytlnuroisea&#34;).&lt;/p&gt; &#xA;&lt;p&gt;As there are 26 letters in the English alphabet, and we&#39;re looking for a list of 5 words, only one letter remains unused. The algorithm is therefore only allowed to skip a single letter.&lt;/p&gt; &#xA;&lt;p&gt;It basically works as follows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Start with an empty set of letters.&lt;/li&gt; &#xA; &lt;li&gt;Look up which words contains the lowest unused letter&lt;/li&gt; &#xA; &lt;li&gt;For each word in step 2, check whether all its letters are still unused by intersecting it with the current set (using bitwise AND). If this is the case, add it to the set and recursively apply step 2, 3 and 4, until you find a set of 5 words; this is a valid solution.&lt;/li&gt; &#xA; &lt;li&gt;If you have not skipped a letter before, skip the lowest unused letter and redo step 2 again but with the next-lowest unused letter.&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>rapidsai/cudf</title>
    <updated>2022-10-22T01:31:28Z</updated>
    <id>tag:github.com,2022-10-22:/rapidsai/cudf</id>
    <link href="https://github.com/rapidsai/cudf" rel="alternate"></link>
    <summary type="html">&lt;p&gt;cuDF - GPU DataFrame Library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&#xA; &lt;div align=&#34;left&#34;&gt;&#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/rapidsai/cudf/branch-22.12/img/rapids_logo.png&#34; width=&#34;90px&#34;&gt;&amp;nbsp;cuDF - GPU DataFrames&#xA; &lt;/div&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gpuci.gpuopenanalytics.com/job/rapidsai/job/gpuci/job/cudf/job/branches/job/cudf-branch-pipeline/&#34;&gt;&lt;img src=&#34;https://gpuci.gpuopenanalytics.com/job/rapidsai/job/gpuci/job/cudf/job/branches/job/cudf-branch-pipeline/badge/icon&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; For the latest stable &lt;a href=&#34;https://github.com/rapidsai/cudf/raw/main/README.md&#34;&gt;README.md&lt;/a&gt; ensure you are on the &lt;code&gt;main&lt;/code&gt; branch.&lt;/p&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rapids.ai/api/cudf/stable/&#34;&gt;cuDF Reference Documentation&lt;/a&gt;: Python API reference, tutorials, and topic guides.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rapids.ai/api/libcudf/stable/&#34;&gt;libcudf Reference Documentation&lt;/a&gt;: C/C++ CUDA library API reference.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rapids.ai/start.html&#34;&gt;Getting Started&lt;/a&gt;: Instructions for installing cuDF.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rapids.ai/community.html&#34;&gt;RAPIDS Community&lt;/a&gt;: Get help, contribute, and collaborate.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rapidsai/cudf&#34;&gt;GitHub repository&lt;/a&gt;: Download the cuDF source code.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rapidsai/cudf/issues&#34;&gt;Issue tracker&lt;/a&gt;: Report issues or request features.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Built based on the &lt;a href=&#34;http://arrow.apache.org/&#34;&gt;Apache Arrow&lt;/a&gt; columnar memory format, cuDF is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data.&lt;/p&gt; &#xA;&lt;p&gt;cuDF provides a pandas-like API that will be familiar to data engineers &amp;amp; data scientists, so they can use it to easily accelerate their workflows without going into the details of CUDA programming.&lt;/p&gt; &#xA;&lt;p&gt;For example, the following snippet downloads a CSV, then uses the GPU to parse it into rows and columns and run calculations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cudf, requests&#xA;from io import StringIO&#xA;&#xA;url = &#34;https://github.com/plotly/datasets/raw/master/tips.csv&#34;&#xA;content = requests.get(url).content.decode(&#39;utf-8&#39;)&#xA;&#xA;tips_df = cudf.read_csv(StringIO(content))&#xA;tips_df[&#39;tip_percentage&#39;] = tips_df[&#39;tip&#39;] / tips_df[&#39;total_bill&#39;] * 100&#xA;&#xA;# display average tip by dining party size&#xA;print(tips_df.groupby(&#39;size&#39;).tip_percentage.mean())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;size&#xA;1    21.729201548727808&#xA;2    16.571919173482897&#xA;3    15.215685473711837&#xA;4    14.594900639351332&#xA;5    14.149548965142023&#xA;6    15.622920072028379&#xA;Name: tip_percentage, dtype: float64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For additional examples, browse our complete &lt;a href=&#34;https://docs.rapids.ai/api/cudf/stable/&#34;&gt;API documentation&lt;/a&gt;, or check out our more detailed &lt;a href=&#34;https://github.com/rapidsai/notebooks-contrib&#34;&gt;notebooks&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Please see the &lt;a href=&#34;https://hub.docker.com/r/rapidsai/rapidsai/&#34;&gt;Demo Docker Repository&lt;/a&gt;, choosing a tag based on the NVIDIA CUDA version you’re running. This provides a ready to run Docker container with example notebooks and data, showcasing how you can utilize cuDF.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;CUDA/GPU requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CUDA 11.0+&lt;/li&gt; &#xA; &lt;li&gt;NVIDIA driver 450.80.02+&lt;/li&gt; &#xA; &lt;li&gt;Pascal architecture or better (Compute Capability &amp;gt;=6.0)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Conda&lt;/h3&gt; &#xA;&lt;p&gt;cuDF can be installed with conda (&lt;a href=&#34;https://conda.io/miniconda.html&#34;&gt;miniconda&lt;/a&gt;, or the full &lt;a href=&#34;https://www.anaconda.com/download&#34;&gt;Anaconda distribution&lt;/a&gt;) from the &lt;code&gt;rapidsai&lt;/code&gt; channel:&lt;/p&gt; &#xA;&lt;p&gt;For &lt;code&gt;cudf version == 22.06&lt;/code&gt; :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# for CUDA 11.0&#xA;conda install -c rapidsai -c nvidia -c numba -c conda-forge \&#xA;    cudf=22.06 python=3.9 cudatoolkit=11.0&#xA;&#xA;# or, for CUDA 11.2&#xA;conda install -c rapidsai -c nvidia -c numba -c conda-forge \&#xA;    cudf=22.06 python=3.9 cudatoolkit=11.2&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For the nightly version of &lt;code&gt;cudf&lt;/code&gt; :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# for CUDA 11.0&#xA;conda install -c rapidsai-nightly -c nvidia -c numba -c conda-forge \&#xA;    cudf python=3.9 cudatoolkit=11.0&#xA;&#xA;# or, for CUDA 11.2&#xA;conda install -c rapidsai-nightly -c nvidia -c numba -c conda-forge \&#xA;    cudf python=3.9 cudatoolkit=11.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: cuDF is supported only on Linux, and with Python versions 3.8 and later.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://rapids.ai/start.html&#34;&gt;Get RAPIDS version picker&lt;/a&gt; for more OS and version info.&lt;/p&gt; &#xA;&lt;h2&gt;Build/Install from Source&lt;/h2&gt; &#xA;&lt;p&gt;See build &lt;a href=&#34;https://raw.githubusercontent.com/rapidsai/cudf/branch-22.12/CONTRIBUTING.md#setting-up-your-build-environment&#34;&gt;instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please see our &lt;a href=&#34;https://raw.githubusercontent.com/rapidsai/cudf/branch-22.12/CONTRIBUTING.md&#34;&gt;guide for contributing to cuDF&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;Find out more details on the &lt;a href=&#34;https://rapids.ai/community.html&#34;&gt;RAPIDS site&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&#xA; &lt;div align=&#34;left&#34;&gt;&#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/rapidsai/cudf/branch-22.12/img/rapids_logo.png&#34; width=&#34;265px&#34;&gt;&#xA; &lt;/div&gt; Open GPU Data Science&lt;/h2&gt; &#xA;&lt;p&gt;The RAPIDS suite of open source software libraries aim to enable execution of end-to-end data science and analytics pipelines entirely on GPUs. It relies on NVIDIA® CUDA® primitives for low-level compute optimization, but exposing that GPU parallelism and high-bandwidth memory speed through user-friendly Python interfaces.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rapidsai/cudf/branch-22.12/img/rapids_arrow.png&#34; width=&#34;80%&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Apache Arrow on GPU&lt;/h3&gt; &#xA;&lt;p&gt;The GPU version of &lt;a href=&#34;https://arrow.apache.org/&#34;&gt;Apache Arrow&lt;/a&gt; is a common API that enables efficient interchange of tabular data between processes running on the GPU. End-to-end computation on the GPU avoids unnecessary copying and converting of data off the GPU, reducing compute time and cost for high-performance analytics common in artificial intelligence workloads. As the name implies, cuDF uses the Apache Arrow columnar data format on the GPU. Currently, a subset of the features in Apache Arrow are supported.&lt;/p&gt;</summary>
  </entry>
</feed>