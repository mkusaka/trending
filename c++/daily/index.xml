<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-20T01:29:55Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>stereolabs/zed-ros2-wrapper</title>
    <updated>2025-06-20T01:29:55Z</updated>
    <id>tag:github.com,2025-06-20:/stereolabs/zed-ros2-wrapper</id>
    <link href="https://github.com/stereolabs/zed-ros2-wrapper" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ROS 2 wrapper for the ZED SDK&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/images/Picto+STEREOLABS_Black.jpg&#34; alt=&#34;Stereolabs&#34; title=&#34;Stereolabs&#34;&gt;&lt;br \&gt; ROS 2 wrapper &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ROS 2 packages for using Stereolabs ZED Camera cameras.&lt;br&gt; ROS 2 Foxy Fitzroy (Ubuntu 20.04) - ROS 2 Humble Hawksbill (Ubuntu 22.04) - ROS 2 Jazzy Jalisco (Ubuntu 24.04) &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;This package enables the use of ZED cameras with ROS 2, providing access to a variety of data types, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Color and grayscale images, both rectified and unrectified&lt;/li&gt; &#xA; &lt;li&gt;Depth data&lt;/li&gt; &#xA; &lt;li&gt;Colored 3D point clouds&lt;/li&gt; &#xA; &lt;li&gt;Position and mapping, with optional GNSS data fusion&lt;/li&gt; &#xA; &lt;li&gt;Sensor data&lt;/li&gt; &#xA; &lt;li&gt;Detected objects&lt;/li&gt; &#xA; &lt;li&gt;Human skeleton data&lt;/li&gt; &#xA; &lt;li&gt;And more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.stereolabs.com/docs/ros2&#34;&gt;More information&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/images/PointCloud_Depth_ROS.jpg&#34; alt=&#34;Point_cloud&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://releases.ubuntu.com/focal/&#34;&gt;Ubuntu 20.04 (Focal Fossa)&lt;/a&gt;, &lt;a href=&#34;https://releases.ubuntu.com/jammy/&#34;&gt;Ubuntu 22.04 (Jammy Jellyfish)&lt;/a&gt;, or &lt;a href=&#34;https://releases.ubuntu.com/noble/&#34;&gt;Ubuntu 24.04 (Noble Numbat)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.stereolabs.com/developers/release/latest/&#34;&gt;ZED SDK&lt;/a&gt; v5.0 EA (for older versions support please check the &lt;a href=&#34;https://github.com/stereolabs/zed-ros2-wrapper/releases&#34;&gt;releases&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-downloads&#34;&gt;CUDA&lt;/a&gt; dependency&lt;/li&gt; &#xA; &lt;li&gt;ROS 2 Foxy Fitzroy (deprecated), ROS 2 Humble Hawksbill, or ROS 2 Jazzy Jalisco: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.ros.org/en/foxy/Installation/Linux-Install-Debians.html&#34;&gt;Foxy on Ubuntu 20.04&lt;/a&gt; [&lt;strong&gt;Not recommended. EOL reached&lt;/strong&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.ros.org/en/humble/Installation/Linux-Install-Debians.html&#34;&gt;Humble on Ubuntu 22.04&lt;/a&gt; [EOL May 2027]&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.ros.org/en/jazzy/Installation/Linux-Install-Debians.html&#34;&gt;Jazzy Jalisco on Ubuntu 24.04&lt;/a&gt; [EOL May 2029]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Build the package&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;strong&gt;zed_ros2_wrapper&lt;/strong&gt; is a &lt;a href=&#34;http://design.ros2.org/articles/build_tool.html&#34;&gt;colcon&lt;/a&gt; package.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; If you havenâ€™t set up your colcon workspace yet, please follow this short &lt;a href=&#34;https://index.ros.org/doc/ros2/Tutorials/Colcon-Tutorial/&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;To install the &lt;strong&gt;zed_ros2_wrapper&lt;/strong&gt;, open a bash terminal, clone the package from GitHub, and build it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/ros2_ws/src/ # create your workspace if it does not exist&#xA;cd ~/ros2_ws/src/ #use your current ros2 workspace folder&#xA;git clone https://github.com/stereolabs/zed-ros2-wrapper.git&#xA;cd ..&#xA;sudo apt update&#xA;rosdep update&#xA;rosdep install --from-paths src --ignore-src -r -y # install dependencies&#xA;colcon build --symlink-install --cmake-args=-DCMAKE_BUILD_TYPE=Release --parallel-workers $(nproc) # build the workspace&#xA;echo source $(pwd)/install/local_setup.bash &amp;gt;&amp;gt; ~/.bashrc # automatically source the installation in every new bash (optional)&#xA;source ~/.bashrc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; the dependency &lt;code&gt;zed_msgs&lt;/code&gt; is no longer installed as a submodule of this package, but is available through &lt;code&gt;apt&lt;/code&gt; as a binary package with ROS 2 Humble. When working with ROS 2 Foxy, or other distributions, you can install it from the sources from the &lt;a href=&#34;https://github.com/stereolabs/zed-ros2-interfaces?tab=readme-ov-file#install-the-package-from-the-source-code&#34;&gt;zed-ros2-interfaces repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; If &lt;code&gt;rosdep&lt;/code&gt; is missing, you can install it with:&lt;/p&gt; &#xA; &lt;p&gt;&lt;code&gt;sudo apt-get install python3-rosdep python3-rosinstall-generator python3-vcstool python3-rosinstall build-essential&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; When using the ZED ROS 2 Wrapper on an NVIDIA Jetson with JP6, you may get the following error when building the package for the first time&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CMake Error at /usr/share/cmake-3.22/Modules/FindCUDA.cmake:859 (message):&#xA;  Specify CUDA_TOOLKIT_ROOT_DIR&#xA;Call Stack (most recent call first):&#xA; /usr/local/zed/zed-config.cmake:72 (find_package)&#xA; CMakeLists.txt:81 (find_package)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;You can fix the problem by installing the missing &lt;code&gt;nvidia-jetpack&lt;/code&gt; packages:&lt;/p&gt; &#xA; &lt;p&gt;&lt;code&gt;sudo apt install nvidia-jetpack nvidia-jetpack-dev&lt;/code&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; The option &lt;code&gt;--symlink-install&lt;/code&gt; is very important, it allows the use of symlinks instead of copying files to the ROS 2 folders during the installation, where possible. Each package in ROS 2 must be installed, and all the files used by the nodes must be copied into the installation folders. Using symlinks allows you to modify them in your workspace, reflecting the modification during the next executions without issuing a new &lt;code&gt;colcon build&lt;/code&gt; command. This is true only for all the files that don&#39;t need to be compiled (Python scripts, configurations, etc.).&lt;/p&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; If you are using a different console interface like zsh, you have to change the &lt;code&gt;source&lt;/code&gt; command as follows: &lt;code&gt;echo source $(pwd)/install/local_setup.zsh &amp;gt;&amp;gt; ~/.zshrc&lt;/code&gt; and &lt;code&gt;source ~/.zshrc&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Starting the ZED node&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; we recommend reading &lt;a href=&#34;https://www.stereolabs.com/docs/ros2/150_dds_and_network_tuning&#34;&gt;this ROS 2 tuning guide&lt;/a&gt; to improve the ROS 2 experience with ZED.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;To start the ZED node, open a bash terminal and use the &lt;a href=&#34;https://index.ros.org/doc/ros2/Tutorials/Introspection-with-command-line-tools/&#34;&gt;CLI&lt;/a&gt; command &lt;code&gt;ros2 launch&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ros2 launch zed_wrapper zed_camera.launch.py camera_model:=&amp;lt;camera_model&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Replace &lt;code&gt;&amp;lt;camera_model&amp;gt;&lt;/code&gt; with the model of the camera that you are using: &lt;code&gt;&#39;zed&#39;&lt;/code&gt;, &lt;code&gt;&#39;zedm&#39;&lt;/code&gt;, &lt;code&gt;&#39;zed2&#39;&lt;/code&gt;, &lt;code&gt;&#39;zed2i&#39;&lt;/code&gt;, &lt;code&gt;&#39;zedx&#39;&lt;/code&gt;, &lt;code&gt;&#39;zedxm&#39;&lt;/code&gt;, &lt;code&gt;&#39;virtual&#39;&lt;/code&gt;,&lt;code&gt;&#39;zedxonegs&#39;&lt;/code&gt;,&lt;code&gt;&#39;zedxone4k&#39;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;zed_camera.launch.py&lt;/code&gt; is a Python launch script that automatically starts the ZED node using &lt;a href=&#34;https://index.ros.org/doc/ros2/Tutorials/Composition/&#34;&gt;&#34;manual composition&#34;&lt;/a&gt;. The parameters for the indicated camera model are loaded from the relative &#34;YAML files.&#34; A Robot State Publisher node is started to publish the camera static links and joints loaded from the URDF model associated with the camera model.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; You can set your configurations by modifying the parameters in the files &lt;strong&gt;common_stereo.yaml&lt;/strong&gt;, &lt;strong&gt;zed.yaml&lt;/strong&gt; &lt;strong&gt;zedm.yaml&lt;/strong&gt;, &lt;strong&gt;zed2.yaml&lt;/strong&gt;, &lt;strong&gt;zed2i.yaml&lt;/strong&gt;, &lt;strong&gt;zedx.yaml&lt;/strong&gt;, &lt;strong&gt;zedxm.yaml&lt;/strong&gt;, &lt;strong&gt;common_mono.yaml&lt;/strong&gt;, &lt;strong&gt;zedxonegs.yaml&lt;/strong&gt;, and &lt;strong&gt;zedxone4k.yaml&lt;/strong&gt; available in the folder &lt;code&gt;zed_wrapper/config&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;You can get the list of all the available launch parameters by using the &lt;code&gt;-s&lt;/code&gt; launch option:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ros2 launch zed_wrapper zed_camera.launch.py -s&#xA;ros2 launch zed_display_rviz2 display_zed_cam.launch.py -s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For full descriptions of each parameter, follow the complete guide &lt;a href=&#34;https://www.stereolabs.com/docs/ros2/zed_node#configuration-parameters&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;RViz visualization&lt;/h3&gt; &#xA;&lt;p&gt;To start a pre-configured RViz environment and visualize the data of all ZED cameras, we provide in the &lt;a href=&#34;https://github.com/stereolabs/zed-ros2-examples/tree/master/zed_display_rviz2&#34;&gt;&lt;code&gt;zed-ros2-examples&lt;/code&gt; repository&lt;/a&gt;. You&#39;ll see there more advanced examples and visualization that demonstrate depth, point clouds, odometry, object detection, etc.&lt;/p&gt; &#xA;&lt;p&gt;You can also quickly check that your depth data is correctly retrieved in RViz with &lt;code&gt;rviz2 -d ./zed_wrapper/config/rviz2/&amp;lt;your camera model&amp;gt;.rviz&lt;/code&gt;. RViz subscribes to numerous ROS topics, which can potentially impact the performance of your application compared to when it runs without RViz.&lt;/p&gt; &#xA;&lt;h3&gt;Simulation mode&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; This feature is incompatible with the ZED X One and the older first-generation ZED cameras.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Launch a standalone ZED ROS 2 node with simulated ZED data as input by using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ros2 launch zed_wrapper zed_camera.launch.py camera_model:=zedx sim_mode:=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Launch options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[Mandatory] &lt;code&gt;camera_model&lt;/code&gt;: indicates the model of the simulated camera. It&#39;s required that this parameter matches the model of the simulated camera. In most cases, it will be a ZED X, since the first versions of the simulation plugins that we released are simulating this type of device.&lt;/li&gt; &#xA; &lt;li&gt;[Mandatory] &lt;code&gt;sim_mode&lt;/code&gt;: start the ZED node in simulation mode if &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[Optional] &lt;code&gt;use_sim_time&lt;/code&gt;: force the node to wait for valid messages on the topic &lt;code&gt;/clock&lt;/code&gt;, and so use the simulation clock as the time reference.&lt;/li&gt; &#xA; &lt;li&gt;[Optional] &lt;code&gt;sim_address&lt;/code&gt;: set the address of the simulation server. The default is &lt;code&gt;127.0.0.1&lt;/code&gt;, and it&#39;s valid if the node runs on the same machine as the simulator.&lt;/li&gt; &#xA; &lt;li&gt;[Optional] &lt;code&gt;sim_port&lt;/code&gt;: set the port of the simulation server. It must match the value of the field &lt;code&gt;Streaming Port&lt;/code&gt; of the properties of the &lt;code&gt;ZED camera streamer&lt;/code&gt; Action Graph node. A different &lt;code&gt;Streaming Port&lt;/code&gt; value for each camera is required in multi-camera simulations.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can also start a preconfigured instance of &lt;code&gt;rviz2&lt;/code&gt; to visualize all the information available in the simulation by using the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ros2 launch zed_display_rviz2 display_zed_cam.launch.py camera_model:=zedx sim_mode:=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;display_zed_cam.launch.py&lt;/code&gt; launch file includes the &lt;code&gt;zed_camera.launch.py&lt;/code&gt; launch file, hence it gets the same parameters.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s an example of &lt;code&gt;rviz2&lt;/code&gt; running with the simulated information obtained by placing the ZED camera on a shelf of a simulated warehouse:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/images/sim_rviz.jpg&#34; alt=&#34;Sim RVIZ2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/images/zed_shelves.jpg&#34; alt=&#34;Shelves&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Supported simulation environments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.stereolabs.com/docs/isaac-sim/&#34;&gt;NVIDIA Omniverse Isaac Sim&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;More features&lt;/h2&gt; &#xA;&lt;h3&gt;SVO recording&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.stereolabs.com/docs/video/recording/&#34;&gt;SVO recording&lt;/a&gt; can be started and stopped while the ZED node is running using the service &lt;code&gt;start_svo_recording&lt;/code&gt; and the service &lt;code&gt;stop_svo_recording&lt;/code&gt;. &lt;a href=&#34;https://www.stereolabs.com/docs/ros2/zed_node/#services&#34;&gt;More information&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Object Detection&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; This feature is incompatible with the ZED X One and the older first-generation ZED cameras.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Object Detection can be enabled &lt;em&gt;automatically&lt;/em&gt; when the node starts by setting the parameter &lt;code&gt;object_detection/od_enabled&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; in the file &lt;code&gt;common_stereo.yaml&lt;/code&gt;. The Object Detection can be enabled/disabled &lt;em&gt;manually&lt;/em&gt; by calling the services &lt;code&gt;enable_obj_det&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can find a detailed explanation of the Object Detection module in the &lt;a href=&#34;https://www.stereolabs.com/docs/ros2/object-detection&#34;&gt;ZED ROS 2 documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Custom Object Detection with YOLO-like ONNX model file&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; This feature is incompatible with the ZED X One and the older first-generation ZED cameras.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Object Detection inference can be performed using a &lt;strong&gt;custom inference engine&lt;/strong&gt; in YOLO-like ONNX format.&lt;/p&gt; &#xA;&lt;p&gt;You can generate your ONNX model by using Ultralytics YOLO tools.&lt;/p&gt; &#xA;&lt;p&gt;Install Ultralytics YOLO tools:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m pip install ultralytics&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have already installed the &lt;code&gt;ultralytics&lt;/code&gt; package, we recommend updating it to the latest version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -U ultralytics&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Export an ONNX file from a YOLO model (more info &lt;a href=&#34;https://docs.ultralytics.com/modes/export/&#34;&gt;here&lt;/a&gt;), for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yolo export model=yolo11n.pt format=onnx simplify=True dynamic=False imgsz=640&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For a custom-trained YOLO model, the weight file can be changed, for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yolo export model=yolov8l_custom_model.pt format=onnx simplify=True dynamic=False imgsz=512&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://github.com/ultralytics/ultralytics&#34;&gt;Ultralytics documentation&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;Modify the &lt;code&gt;common_stereo.yaml&lt;/code&gt; parameters to match your configuration:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Set &lt;code&gt;object_detection.model&lt;/code&gt; to &lt;code&gt;CUSTOM_YOLOLIKE_BOX_OBJECTS&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Modify the &lt;code&gt;custom_object_detection.yaml&lt;/code&gt; parameters to match your configuration.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; The first time the custom model is used, the ZED SDK optimizes it to get the best performance from the GPU installed on the host. Please wait for the optimization to complete. When using Docker, we recommend using a shared volume to store the optimized file on the host and perform the optimization only once.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Console log while optimization is running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[zed_wrapper-3] [INFO] [1729184874.634985183] [zed.zed_node]: === Starting Object Detection ===&#xA;[zed_wrapper-3] [2024-10-17 17:07:55 UTC][ZED][INFO] Please wait while the AI model is being optimized for your graphics card&#xA;[zed_wrapper-3]  This operation will be run only once and may take a few minutes &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find a detailed explanation of the Custom Object Detection module in the &lt;a href=&#34;https://www.stereolabs.com/docs/ros2/custom-object-detection&#34;&gt;ZED ROS 2 documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Body Tracking&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; This feature is incompatible with the ZED X One and the older first-generation ZED cameras.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;The Body Tracking can be enabled &lt;em&gt;automatically&lt;/em&gt; when the node starts by setting the parameter &lt;code&gt;body_tracking/bt_enabled&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; in the file &lt;code&gt;common_stereo.yaml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Spatial Mapping&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; This feature is incompatible with the ZED X One camera.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;The Spatial Mapping can be enabled automatically when the node starts setting the parameter &lt;code&gt;mapping/mapping_enabled&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; in the file &lt;code&gt;common_stereo.yaml&lt;/code&gt;. The Spatial Mapping can be enabled/disabled manually by calling the service &lt;code&gt;enable_mapping&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;GNSS fusion&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; This feature is incompatible with the ZED X One camera.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;The ZED ROS 2 Wrapper can subscribe to a &lt;code&gt;NavSatFix&lt;/code&gt; topic and fuse GNSS data information with Positional Tracking information to obtain a precise robot localization referred to Earth coordinates. To enable GNSS fusion, set the parameter &lt;code&gt;gnss_fusion.gnss_fusion_enabled&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;. You must set the correct &lt;code&gt;gnss_frame&lt;/code&gt; parameter when launching the node, e.g. &lt;code&gt;gnss_frame:=&#39;gnss_link&#39;&lt;/code&gt;. The services &lt;code&gt;toLL&lt;/code&gt; and &lt;code&gt;fromLL&lt;/code&gt; can be used to convert Latitude/Longitude coordinates to robot &lt;code&gt;map&lt;/code&gt; coordinates.&lt;/p&gt; &#xA;&lt;h3&gt;2D mode&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ðŸ“Œ&lt;/span&gt; &lt;strong&gt;Note:&lt;/strong&gt; This feature is incompatible with the ZED X One camera.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;For robots moving on a planar surface, activating the &#34;2D mode&#34; (parameter &lt;code&gt;pos_tracking/two_d_mode&lt;/code&gt; in &lt;code&gt;common_stereo.yaml&lt;/code&gt;) is possible. The value of the coordinate Z for odometry and pose will have a fixed value (parameter &lt;code&gt;pos_tracking/fixed_z_value&lt;/code&gt; in &lt;code&gt;common_stereo.yaml&lt;/code&gt;). Roll, Pitch, and the relative velocities will be fixed to zero.&lt;/p&gt; &#xA;&lt;h2&gt;Examples and Tutorials&lt;/h2&gt; &#xA;&lt;p&gt;Examples and tutorials are provided to better understand how to use the ZED wrapper and how to integrate it into the ROS 2 framework. See the &lt;a href=&#34;https://github.com/stereolabs/zed-ros2-examples&#34;&gt;&lt;code&gt;zed-ros2-examples&lt;/code&gt; repository&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;RVIZ2 visualization examples&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Example launch files to start a preconfigured instance of Rviz displaying all the ZED Wrapper node information: &lt;a href=&#34;https://github.com/stereolabs/zed-ros2-examples/tree/master/zed_display_rviz2&#34;&gt;zed_display_rviz2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ROS 2 plugin for ZED2 to visualize the results of the Object Detection and Body Tracking modules (bounding boxes and skeletons): &lt;a href=&#34;https://github.com/stereolabs/zed-ros2-examples/tree/master/rviz-plugin-zed-od&#34;&gt;rviz-plugin-zed-od&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Tutorials&lt;/h3&gt; &#xA;&lt;p&gt;A series of tutorials are provided to better understand how to use the ZED nodes in the ROS2 environment :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/zed_video_tutorial&#34;&gt;Video subscribing&lt;/a&gt;: &lt;code&gt;zed_video_tutorial&lt;/code&gt; - In this tutorial, you will learn how to write a simple node that subscribes to messages of type &lt;code&gt;sensor_msgs/Image&lt;/code&gt; to retrieve the left and right rectified images published by the ZED node.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/zed_depth_tutorial&#34;&gt;Depth subscribing&lt;/a&gt;: &lt;code&gt;zed_depth_tutorial&lt;/code&gt; - In this tutorial, you will learn how to write a simple node that subscribes to messages of type &lt;code&gt;sensor_msgs/Image&lt;/code&gt; to retrieve the depth images published by the ZED node and to get the measured distance at the center of the image.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/zed_pose_tutorial&#34;&gt;Pose/Odometry subscribing&lt;/a&gt;: &lt;code&gt;zed_pose_tutorial&lt;/code&gt; - In this tutorial, you will learn how to write a simple node that subscribes to messages of type &lt;code&gt;geometry_msgs/PoseStamped&lt;/code&gt; and &lt;code&gt;nav_msgs/Odometry&lt;/code&gt; to retrieve the position and the odometry of the camera while moving in the world.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/zed_rgb_convert&#34;&gt;ROS2 Composition + BGRA2BGR conversion&lt;/a&gt;: &lt;code&gt;zed_rgb_convert&lt;/code&gt; - In this tutorial, you will learn how to use the concept of &#34;ROS2 Composition&#34; and &#34;Intra Process Communication&#34; to write a ROS2 component that gets a 4 channel BGRA image as input and re-publishes it as 3 channels BGR image.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/zed_multi_camera&#34;&gt;ROS2 Multi-Camera&lt;/a&gt;: &lt;code&gt;zed_multi_camera&lt;/code&gt; - In this tutorial, you will learn how to use the provided launch file to start a multi-camera robot configuration.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/zed_robot_integration&#34;&gt;Robot integration&lt;/a&gt;: &lt;code&gt;zed_robot_integration&lt;/code&gt; - In this tutorial, you will learn how to add one or more ZED cameras to a robot configuration.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Examples&lt;/h3&gt; &#xA;&lt;p&gt;How to use the ZED ROS 2 nodes alongside other ROS 2 packages or advanced features.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/zed_aruco_localization&#34;&gt;zed_aruco_localization&lt;/a&gt;: Use localized ArUco tag as a reference for localization.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stereolabs/zed-ros2-wrapper/master/zed_depth_to_laserscan&#34;&gt;zed_depth_to_laserscan&lt;/a&gt;: Convert ZED Depth maps into virtual Laser Scans using&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Update the local repository&lt;/h2&gt; &#xA;&lt;p&gt;To update the repository to the latest release, use the following command that will retrieve the latest commits of &lt;code&gt;zed-ros2-wrapper&lt;/code&gt; and of all the submodules:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git checkout master # if you are not on the main branch  &#xA;git pull &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Clean the cache of your colcon workspace before compiling with the &lt;code&gt;colcon build&lt;/code&gt; command to be sure that everything will work as expected:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd &amp;lt;ros2_workspace_root&amp;gt; # replace with your workspace folder, for example ~/ros2_ws/src/&#xA;rm -r install&#xA;rm -r build&#xA;rm -r log&#xA;colcon build --symlink-install --cmake-args=-DCMAKE_BUILD_TYPE=Release --parallel-workers $(nproc)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Known issues&lt;/h2&gt;</summary>
  </entry>
</feed>