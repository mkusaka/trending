<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-15T01:28:20Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>duckdb/pg_duckdb</title>
    <updated>2024-08-15T01:28:20Z</updated>
    <id>tag:github.com,2024-08-15:/duckdb/pg_duckdb</id>
    <link href="https://github.com/duckdb/pg_duckdb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DuckDB-powered Postgres for high performance apps &amp; analytics.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;pg_duckdb: Official Postgres extension for DuckDB&lt;/h1&gt; &#xA;&lt;p&gt;pg_duckdb is a Postgres extension that embeds DuckDB&#39;s columnar-vectorized analytics engine and features into Postgres. We recommend using pg_duckdb to build high performance analytics and data-intensive applications.&lt;/p&gt; &#xA;&lt;p&gt;pg_duckdb was developed in collaboration with our partners, &lt;a href=&#34;https://hydra.so&#34;&gt;Hydra&lt;/a&gt; and &lt;a href=&#34;https://motherduck.com&#34;&gt;MotherDuck&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Pre-built binaries and additional installation options are coming soon.&lt;/p&gt; &#xA;&lt;p&gt;To build pg_duckdb, you need:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Postgres 16&lt;/li&gt; &#xA; &lt;li&gt;Ubuntu 22.04 or MacOS&lt;/li&gt; &#xA; &lt;li&gt;Standard set of build tools for building Postgres extensions&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://duckdb.org/docs/dev/building/build_instructions&#34;&gt;Build tools that are required to build DuckDB&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To build and install, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, load the pg_duckdb extension:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE EXTENSION pg_duckdb;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;IMPORTANT:&lt;/strong&gt; Once loaded you can use DuckDB execution by running &lt;code&gt;SET duckdb.execution TO true&lt;/code&gt;. This is &lt;em&gt;opt-in&lt;/em&gt; to avoid breaking existing queries. To avoid doing that for every session, you can configure it for a certain user by doing &lt;code&gt;ALTER USER my_analytics_user SET duckdb.execution TO true&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;SELECT&lt;/code&gt; queries executed by the DuckDB engine can directly read Postgres tables.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Able to read &lt;a href=&#34;https://www.postgresql.org/docs/current/datatype.html&#34;&gt;data types&lt;/a&gt; that exist in both Postgres and DuckDB. The following data types are supported: numeric, character, binary, date/time, boolean, uuid, json, and arrays.&lt;/li&gt; &#xA;   &lt;li&gt;If DuckDB cannot support the query for any reason, execution falls back to Postgres.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Read parquet and CSV files from object storage (AWS S3, Cloudflare R2, or Google GCS).&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;SELECT n FROM read_parquet(&#39;s3://bucket/file.parquet&#39;) AS (n int)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;SELECT n FROM read_csv(&#39;s3://bucket/file.csv&#39;) AS (n int)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;You can pass globs and arrays to these functions, just like in DuckDB&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Enable the DuckDB Iceberg extension using &lt;code&gt;SELECT duckdb.enable_extension(&#39;iceberg&#39;)&lt;/code&gt; and read Iceberg files with &lt;code&gt;iceberg_scan&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Write a query — or an entire table — to parquet in object storage.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;COPY (SELECT foo, bar FROM baz) TO &#39;s3://...&#39;&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;COPY table TO &#39;s3://...&#39;&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Read and write to Parquet format in a single query&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt; COPY (&#xA;   SELECT count(*), name&#xA;   FROM read_parquet(&#39;s3://bucket/file.parquet&#39;) AS (name text)&#xA;   GROUP BY name&#xA;   ORDER BY count DESC&#xA; ) TO &#39;s3://bucket/results.parquet&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Query and &lt;code&gt;JOIN&lt;/code&gt; data in object storage with Postgres tables, views, and materialized views.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create indexes on Postgres tables to accelerate your DuckDB queries&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install DuckDB extensions using &lt;code&gt;SELECT duckdb.install_extension(&#39;extension_name&#39;);&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Toggle DuckDB execution on/off with a setting:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;SET duckdb.execution = true|false&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The best way to get started is to connect Postgres to a new or existing object storage bucket (AWS S3, Cloudflare R2, or Google GCS) with pg_duckdb. You can query data in Parquet, CSV, and Iceberg format using &lt;code&gt;read_parquet&lt;/code&gt;, &lt;code&gt;read_csv&lt;/code&gt;, and &lt;code&gt;iceberg_scan&lt;/code&gt; respectively.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Add a credential to enable DuckDB&#39;s httpfs support.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;INSERT INTO duckdb.secrets&#xA;(cloud_type, cloud_id, cloud_secret, cloud_region)&#xA;VALUES (&#39;S3&#39;, &#39;access_key_id&#39;, &#39;secret_accss_key&#39;, &#39;us-east-1&#39;);&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Copy data directly to your bucket - no ETL pipeline!&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;COPY (SELECT user_id, item_id, price, purchased_at FROM purchases)&#xA;TO &#39;s3://your-bucket/purchases.parquet;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Perform analytics on your data.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT SUM(price) AS total, item_id&#xA;FROM read_parquet(&#39;s3://your-bucket/purchases.parquet&#39;)&#xA;  AS (price float, item_id int)&#xA;GROUP BY item_id&#xA;ORDER BY total DESC&#xA;LIMIT 100;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;Please see the &lt;a href=&#34;https://github.com/orgs/duckdb/projects/10&#34;&gt;project roadmap&lt;/a&gt; for upcoming planned tasks and features.&lt;/p&gt; &#xA;&lt;h3&gt;Connect with MotherDuck&lt;/h3&gt; &#xA;&lt;p&gt;pg_duckdb integration with MotherDuck will enable hybrid execution with Differential Storage.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Zero-copy snapshots and forks&lt;/li&gt; &#xA; &lt;li&gt;Time travel&lt;/li&gt; &#xA; &lt;li&gt;Data tiering&lt;/li&gt; &#xA; &lt;li&gt;Improved concurrency and cacheability&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;pg_duckdb was developed in collaboration with our partners, &lt;a href=&#34;https://hydra.so&#34;&gt;Hydra&lt;/a&gt; and &lt;a href=&#34;https://motherduck.com&#34;&gt;MotherDuck&lt;/a&gt;. We look forward to their continued contributions and leadership.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hydra.so&#34;&gt;Hydra&lt;/a&gt; is a Y Combinator-backed database company, focused on DuckDB-Powered Postgres for app developers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://motherduck.com&#34;&gt;MotherDuck&lt;/a&gt; is the cloud-based data warehouse that extends the power of DuckDB.&lt;/p&gt; &#xA;&lt;p&gt;We welcome all contributions big and small:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Vote on or suggest features for our roadmap.&lt;/li&gt; &#xA; &lt;li&gt;Open a PR.&lt;/li&gt; &#xA; &lt;li&gt;Submit a feature request or bug report.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Please see the &lt;a href=&#34;https://github.com/orgs/duckdb/projects/10&#34;&gt;project roadmap&lt;/a&gt; for upcoming planned tasks and features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/duckdb/pg_duckdb/issues&#34;&gt;GitHub Issues&lt;/a&gt; for bugs and missing features&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.duckdb.org/&#34;&gt;Discord discussion&lt;/a&gt; with the DuckDB community&lt;/li&gt; &#xA; &lt;li&gt;See our docs for more info and limitations&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>