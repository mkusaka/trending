<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-05T01:32:22Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>RPCSX/rpcsx</title>
    <updated>2023-07-05T01:32:22Z</updated>
    <id>tag:github.com,2023-07-05:/RPCSX/rpcsx</id>
    <link href="https://github.com/RPCSX/rpcsx" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RPCSX&lt;/h1&gt; &#xA;&lt;p&gt;This is an experimental emulator for PS4 (Play Station 4) written in C++ for Linux. It&#39;s NOT possible to run any games yet. It&#39;s also unknown when it will become possible.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you want to contribute as a developer, please contact us in the Discord. &lt;a href=&#34;https://discord.gg/PYUcckGr&#34;&gt;https://discord.gg/PYUcckGr&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;Under construction.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;RPCSX is licensed under GPLv2 license except directories containing their own LICENSE file, or files containing their own license. Thus, orbis-kernel is licensed under the MIT license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>li-plus/chatglm.cpp</title>
    <updated>2023-07-05T01:32:22Z</updated>
    <id>tag:github.com,2023-07-05:/li-plus/chatglm.cpp</id>
    <link href="https://github.com/li-plus/chatglm.cpp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;C++ implementation of ChatGLM-6B &amp; ChatGLM2-6B&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGLM.cpp&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/li-plus/chatglm.cpp/actions/workflows/cmake.yml&#34;&gt;&lt;img src=&#34;https://github.com/li-plus/chatglm.cpp/actions/workflows/cmake.yml/badge.svg?sanitize=true&#34; alt=&#34;CMake&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/li-plus/chatglm.cpp/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;C++ implementation of &lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM-6B&lt;/a&gt; and &lt;a href=&#34;https://github.com/THUDM/ChatGLM2-6B&#34;&gt;ChatGLM2-6B&lt;/a&gt; for real-time chatting on your MacBook.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/li-plus/chatglm.cpp/main/docs/demo.gif&#34; alt=&#34;demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Pure C++ implementation based on &lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;ggml&lt;/a&gt;, working in the same way as &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Accelerated memory-efficient CPU inference with int4/int8 quantization, optimized KV cache and parallel computing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Streaming generation with typewriter effect.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Python binding, web demo, and more possibilities.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Preparation&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Clone the ChatGLM.cpp repository into your local machine:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone --recursive https://github.com/li-plus/chatglm.cpp.git &amp;amp;&amp;amp; cd chatglm.cpp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you forgot the &lt;code&gt;--recursive&lt;/code&gt; flag when cloning the repository, run the following command in the &lt;code&gt;chatglm.cpp&lt;/code&gt; folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Quantize Model&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Use &lt;code&gt;convert.py&lt;/code&gt; to transform ChatGLM-6B or ChatGLM2-6B into quantized GGML format. For example, to convert the fp16 base model to q4_0 (quantized int4) GGML model, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# For ChatGLM-6B&#xA;python3 convert.py -i THUDM/chatglm-6b -t q4_0 -o chatglm-ggml.bin&#xA;# For ChatGLM2-6B&#xA;python3 convert.py -i THUDM/chatglm2-6b -t q4_0 -o chatglm2-ggml.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You are free to try any of the below quantization types by specifying &lt;code&gt;-t &amp;lt;type&amp;gt;&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;q4_0&lt;/code&gt;: 4-bit integer quantization with fp16 scales.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q4_1&lt;/code&gt;: 4-bit integer quantization with fp16 scales and minimum values.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q5_0&lt;/code&gt;: 5-bit integer quantization with fp16 scales.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q5_1&lt;/code&gt;: 5-bit integer quantization with fp16 scales and minimum values.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q8_0&lt;/code&gt;: 8-bit integer quantization with fp16 scales.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;f16&lt;/code&gt;: half precision floating point weights without quantization.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;f32&lt;/code&gt;: single precision floating point weights without quantization.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For LoRA model, add &lt;code&gt;-l &amp;lt;lora_model_name_or_path&amp;gt;&lt;/code&gt; flag to merge your LoRA weights into the base model.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Build &amp;amp; Run&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Compile the project using CMake:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake -B build&#xA;cmake --build build -j&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you may chat with the quantized ChatGLM-6B model by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./build/bin/main -m chatglm-ggml.bin -p ä½ å¥½                            # ChatGLM-6B&#xA;# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚&#xA;./build/bin/main -m chatglm2-ggml.bin -p ä½ å¥½ --top_p 0.8 --temp 0.8    # ChatGLM2-6B&#xA;# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the model in interactive mode, add the &lt;code&gt;-i&lt;/code&gt; flag. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./build/bin/main -m chatglm-ggml.bin -i&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In interactive mode, your chat history will serve as the context for the next-round conversation.&lt;/p&gt; &#xA;&lt;p&gt;Run &lt;code&gt;./build/bin/main -h&lt;/code&gt; to explore more options!&lt;/p&gt; &#xA;&lt;h2&gt;Using BLAS&lt;/h2&gt; &#xA;&lt;p&gt;BLAS library can be integrated to further accelerate matrix multiplication. However, in some cases, using BLAS may cause performance degradation. Whether to turn on BLAS should depend on the benchmarking result.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerate Framework&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Accelerate Framework is automatically enabled on macOS. To disable it, add the CMake flag &lt;code&gt;-DGGML_NO_ACCELERATE=ON&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;OpenBLAS&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;OpenBLAS provides acceleration on CPU. Add the CMake flag &lt;code&gt;-DGGML_OPENBLAS=ON&lt;/code&gt; to enable it.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake -B build -DGGML_OPENBLAS=ON&#xA;cmake --build build -j&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;cuBLAS&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;cuBLAS uses NVIDIA GPU to accelerate BLAS. Add the CMake flag &lt;code&gt;-DGGML_CUBLAS=ON&lt;/code&gt; to enable it.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake -B build -DGGML_CUBLAS=ON&#xA;cmake --build build -j&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the current GGML CUDA implementation is really slow. The community is making efforts to optimize it.&lt;/p&gt; &#xA;&lt;h2&gt;Python Binding&lt;/h2&gt; &#xA;&lt;p&gt;To install the Python binding from source, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# install from the latest source hosted on GitHub&#xA;pip install git+https://github.com/li-plus/chatglm.cpp.git@main&#xA;# or install from your local source&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the Python example to chat with the quantized model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd examples &amp;amp;&amp;amp; python3 cli_chat.py -m ../chatglm-ggml.bin -i&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may also launch a web demo to chat in your browser:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd examples &amp;amp;&amp;amp; python3 web_demo.py -m ../chatglm-ggml.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For ChatGLM2, change the model path to &lt;code&gt;../chatglm2-ggml.bin&lt;/code&gt; and everything works fine.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/li-plus/chatglm.cpp/main/docs/web_demo.jpg&#34; alt=&#34;web_demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;Measured on a Linux server with Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz using 16 threads.&lt;/p&gt; &#xA;&lt;p&gt;ChatGLM-6B:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Q4_0&lt;/th&gt; &#xA;   &lt;th&gt;Q4_1&lt;/th&gt; &#xA;   &lt;th&gt;Q5_0&lt;/th&gt; &#xA;   &lt;th&gt;Q5_1&lt;/th&gt; &#xA;   &lt;th&gt;Q8_0&lt;/th&gt; &#xA;   &lt;th&gt;F16&lt;/th&gt; &#xA;   &lt;th&gt;F32&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ms/token&lt;/td&gt; &#xA;   &lt;td&gt;74&lt;/td&gt; &#xA;   &lt;td&gt;77&lt;/td&gt; &#xA;   &lt;td&gt;86&lt;/td&gt; &#xA;   &lt;td&gt;89&lt;/td&gt; &#xA;   &lt;td&gt;114&lt;/td&gt; &#xA;   &lt;td&gt;189&lt;/td&gt; &#xA;   &lt;td&gt;357&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;file size&lt;/td&gt; &#xA;   &lt;td&gt;3.3GB&lt;/td&gt; &#xA;   &lt;td&gt;3.7GB&lt;/td&gt; &#xA;   &lt;td&gt;4.0GB&lt;/td&gt; &#xA;   &lt;td&gt;4.4GB&lt;/td&gt; &#xA;   &lt;td&gt;6.2GB&lt;/td&gt; &#xA;   &lt;td&gt;12GB&lt;/td&gt; &#xA;   &lt;td&gt;23GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mem usage&lt;/td&gt; &#xA;   &lt;td&gt;4.0GB&lt;/td&gt; &#xA;   &lt;td&gt;4.4GB&lt;/td&gt; &#xA;   &lt;td&gt;4.7GB&lt;/td&gt; &#xA;   &lt;td&gt;5.1GB&lt;/td&gt; &#xA;   &lt;td&gt;6.9GB&lt;/td&gt; &#xA;   &lt;td&gt;13GB&lt;/td&gt; &#xA;   &lt;td&gt;24GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;ChatGLM2-6B:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Q4_0&lt;/th&gt; &#xA;   &lt;th&gt;Q4_1&lt;/th&gt; &#xA;   &lt;th&gt;Q5_0&lt;/th&gt; &#xA;   &lt;th&gt;Q5_1&lt;/th&gt; &#xA;   &lt;th&gt;Q8_0&lt;/th&gt; &#xA;   &lt;th&gt;F16&lt;/th&gt; &#xA;   &lt;th&gt;F32&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ms/token&lt;/td&gt; &#xA;   &lt;td&gt;64&lt;/td&gt; &#xA;   &lt;td&gt;71&lt;/td&gt; &#xA;   &lt;td&gt;79&lt;/td&gt; &#xA;   &lt;td&gt;83&lt;/td&gt; &#xA;   &lt;td&gt;106&lt;/td&gt; &#xA;   &lt;td&gt;189&lt;/td&gt; &#xA;   &lt;td&gt;372&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;file size&lt;/td&gt; &#xA;   &lt;td&gt;3.3GB&lt;/td&gt; &#xA;   &lt;td&gt;3.7GB&lt;/td&gt; &#xA;   &lt;td&gt;4.0GB&lt;/td&gt; &#xA;   &lt;td&gt;4.4GB&lt;/td&gt; &#xA;   &lt;td&gt;6.2GB&lt;/td&gt; &#xA;   &lt;td&gt;12GB&lt;/td&gt; &#xA;   &lt;td&gt;24GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mem usage&lt;/td&gt; &#xA;   &lt;td&gt;3.4GB&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;4.1GB&lt;/td&gt; &#xA;   &lt;td&gt;4.5GB&lt;/td&gt; &#xA;   &lt;td&gt;6.2GB&lt;/td&gt; &#xA;   &lt;td&gt;12GB&lt;/td&gt; &#xA;   &lt;td&gt;23GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To perform unit tests, add the CMake flag &lt;code&gt;-DCHATGLM_ENABLE_TESTING=ON&lt;/code&gt;, recompile, and run &lt;code&gt;./build/bin/chatglm_test&lt;/code&gt;. For benchmark only, run &lt;code&gt;./build/bin/chatglm_test --gtest_filter=ChatGLM.benchmark&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;To format the code, run &lt;code&gt;cmake --build build --target lint&lt;/code&gt;. You should have &lt;code&gt;clang-format&lt;/code&gt;, &lt;code&gt;black&lt;/code&gt; and &lt;code&gt;isort&lt;/code&gt; pre-installed.&lt;/li&gt; &#xA; &lt;li&gt;To check performance issue, add the CMake flag &lt;code&gt;-DGGML_PERF=ON&lt;/code&gt;. It will show timing for each graph operation when running the model.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This project is greatly inspired by &lt;a href=&#34;https://github.com/ggerganov&#34;&gt;@ggerganov&lt;/a&gt;&#39;s &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; and is based on his NN library &lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;ggml&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Thank &lt;a href=&#34;https://github.com/THUDM&#34;&gt;@THUDM&lt;/a&gt; for the amazing &lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM-6B&lt;/a&gt; and &lt;a href=&#34;https://github.com/THUDM/ChatGLM2-6B&#34;&gt;ChatGLM2-6B&lt;/a&gt; and for releasing the model sources and checkpoints.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>primihub/primihub</title>
    <updated>2023-07-05T01:32:22Z</updated>
    <id>tag:github.com,2023-07-05:/primihub/primihub</id>
    <link href="https://github.com/primihub/primihub" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Privacy-Preserving Computing Platform ç”±å¯†ç å­¦ä¸“å®¶å›¢é˜Ÿæ‰“é€ çš„å¼€æºéšç§è®¡ç®—å¹³å°ï¼Œæ”¯æŒå®‰å…¨å¤šæ–¹è®¡ç®—ã€è”é‚¦å­¦ä¹ ã€éšç§æ±‚äº¤ã€éšç§æŸ¥è¯¢ç­‰ã€‚&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/primihub/primihub/develop/doc/header.jpeg&#34; alt=&#34;Header&#34;&gt; &lt;br&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt;&lt;strong&gt;ç”±å¯†ç å­¦ä¸“å®¶å›¢é˜Ÿæ‰“é€ çš„å¼€æºéšç§è®¡ç®—å¹³å°&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/primihub/primihub/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/primihub/primihub?style=flat-square&#34; alt=&#34;GitHub Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/primihub/primihub/actions/workflows/main.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/primihub/primihub/main.yml?logo=github&amp;amp;style=flat-square&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/primihub/primihub-node&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/primihub/primihub-node?style=flat-square&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ä¸­æ–‡ | &lt;a href=&#34;https://raw.githubusercontent.com/primihub/primihub/develop/README_EN.md&#34;&gt;English&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h2&gt;éšç§è®¡ç®—&lt;/h2&gt; &#xA;&lt;p&gt;æ•°æ®æµåŠ¨èµ·æ¥æ‰å¯ä»¥åˆ›é€ æ›´å¤§çš„ä»·å€¼ï¼Œéšç€æ•°å­—ç»æµæŒç»­é«˜é€Ÿå¢é•¿ï¼Œ&lt;strong&gt;æ•°æ®çš„äº’è”äº’é€šéœ€æ±‚è¶Šæ¥è¶Šæ—ºç››&lt;/strong&gt;ï¼Œå¤§åˆ°æ”¿åºœæœºå…³çš„æœºå¯†æ•°æ®ã€å…¬å¸æ ¸å¿ƒå•†ä¸šæ•°æ®ã€å°åˆ°ä¸ªäººä¿¡æ¯ã€‚è¿‘ä¸¤å¹´ï¼Œæˆ‘å›½ä¹Ÿç›¸ç»§å‡ºå°äº† &lt;strong&gt;ã€Šæ•°æ®å®‰å…¨æ³•ã€‹&lt;/strong&gt; å’Œ &lt;strong&gt;ã€Šä¸ªäººä¿¡æ¯ä¿æŠ¤æ³•ã€‹&lt;/strong&gt;ã€‚å› æ­¤ï¼Œ&lt;strong&gt;å¦‚ä½•è®©æ•°æ®å®‰å…¨åœ°æµé€šèµ·æ¥ï¼Œæ˜¯ä¸€ä¸ªå¿…é¡»è¦è§£å†³çš„é—®é¢˜&lt;/strong&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;éšç§è®¡ç®—æŠ€æœ¯ä½œä¸º&lt;strong&gt;è¿æ¥æ•°æ®æµé€šå’Œéšç§ä¿æŠ¤æ³•è§„çš„çº½å¸¦&lt;/strong&gt;ï¼Œå®ç°äº† &lt;strong&gt;â€œæ•°æ®å¯ç”¨ä¸å¯è§â€&lt;/strong&gt;ã€‚å³&lt;strong&gt;åœ¨ä¿æŠ¤æ•°æ®æœ¬èº«ä¸å¯¹å¤–æ³„éœ²çš„å‰æä¸‹å®ç°æ•°æ®åˆ†æè®¡ç®—çš„æŠ€æœ¯é›†åˆ&lt;/strong&gt;ã€‚éšç§è®¡ç®—ä½œä¸ºæ•°æ®æµé€šçš„&lt;strong&gt;é‡è¦åˆ›æ–°å‰æ²¿æŠ€æœ¯&lt;/strong&gt;ï¼Œå·²ç»å¹¿æ³›åº”ç”¨äºé‡‘èã€åŒ»ç–—ã€é€šä¿¡ã€æ”¿åŠ¡ç­‰å¤šä¸ªè¡Œä¸šã€‚&lt;/p&gt; &#xA;&lt;h2&gt;PrimiHub&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä½ å¯¹éšç§è®¡ç®—æ„Ÿå…´è¶£ï¼Œæƒ³è¿‘è·ç¦»ä½“éªŒä¸‹éšç§è®¡ç®—çš„é­…åŠ›ï¼Œä¸å¦¨è¯•è¯• PrimiHubï¼ä¸€æ¬¾&lt;strong&gt;ç”±å¯†ç å­¦ä¸“å®¶å›¢é˜Ÿæ‰“é€ çš„å¼€æºéšç§è®¡ç®—å¹³å°&lt;/strong&gt;ï¼Œå®ƒå®‰å…¨å¯é ã€å¼€ç®±å³ç”¨ã€è‡ªä¸»ç ”å‘ã€åŠŸèƒ½ä¸°å¯Œã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ç‰¹æ€§&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;å¼€æº&lt;/strong&gt;ï¼šå®Œå…¨å¼€æºã€å…è´¹&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;å®‰è£…ç®€å•&lt;/strong&gt;ï¼šæ”¯æŒ Docker ä¸€é”®éƒ¨ç½²&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;å¼€ç®±å³ç”¨&lt;/strong&gt;ï¼šæ‹¥æœ‰ &lt;a href=&#34;https://github.com/primihub/primihub-platform&#34;&gt;Webç•Œé¢&lt;/a&gt;ã€&lt;a href=&#34;https://docs.primihub.com/docs/category/%E5%88%9B%E5%BB%BA%E4%BB%BB%E5%8A%A1&#34;&gt;å‘½ä»¤è¡Œ&lt;/a&gt; å’Œ &lt;a href=&#34;https://docs.primihub.com/docs/category/python-sdk-client&#34;&gt;Python SDK&lt;/a&gt; å¤šç§ä½¿ç”¨æ–¹å¼&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;åŠŸèƒ½ä¸°å¯Œ&lt;/strong&gt;ï¼šæ”¯æŒéšåŒ¿æŸ¥è¯¢ã€éšç§æ±‚äº¤ã€è”åˆç»Ÿè®¡ã€æ•°æ®èµ„æºç®¡ç†ç­‰åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;çµæ´»é…ç½®&lt;/strong&gt;ï¼šæ”¯æŒè‡ªå®šä¹‰æ‰©å±•è¯­æ³•ã€è¯­ä¹‰ã€å®‰å…¨åè®®ç­‰&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;è‡ªä¸»ç ”å‘&lt;/strong&gt;ï¼šåŸºäºå®‰å…¨å¤šæ–¹è®¡ç®—ã€è”é‚¦å­¦ä¹ ã€åŒæ€åŠ å¯†ã€å¯ä¿¡è®¡ç®—ç­‰éšç§è®¡ç®—æŠ€æœ¯&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;å¿«é€Ÿå¼€å§‹&lt;/h2&gt; &#xA;&lt;p&gt;æ¨èä½¿ç”¨ Docker éƒ¨ç½² PrimiHubï¼Œå¼€å¯ä½ çš„éšç§è®¡ç®—ä¹‹æ—…ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# ç¬¬ä¸€æ­¥ï¼šä¸‹è½½&#xA;git clone https://github.com/primihub/primihub.git&#xA;# ç¬¬äºŒæ­¥ï¼šå¯åŠ¨å®¹å™¨&#xA;cd primihub &amp;amp;&amp;amp; docker-compose up -d&#xA;# ç¬¬ä¸‰æ­¥ï¼šè¿›å…¥å®¹å™¨&#xA;docker exec -it primihub-node0 bash&#xA;# ç¬¬å››æ­¥ï¼šæ‰§è¡Œéšç§æ±‚äº¤è®¡ç®—&#xA;./primihub-cli --task_config_file=&#34;example/psi_ecdh_task_conf.json&#34;&#xA;I20230616 13:40:10.683375    28 cli.cc:524] all node has finished&#xA;I20230616 13:40:10.683745    28 cli.cc:598] SubmitTask time cost(ms): 1419&#xA;# æŸ¥çœ‹ç»“æœ&#xA;cat data/result/psi_result.csv&#xA;&#34;intersection_row&#34;&#xA;X3&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/primihub/primihub/develop/doc/kt.gif&#34; width=&#34;700&#34; alt=&#34;PSI&#34;&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;em&gt;éšç§æ±‚äº¤ä¾‹å­ &lt;a href=&#34;https://docs.primihub.com/docs/quick-start-platform/&#34;&gt;åœ¨çº¿å°è¯•&lt;/a&gt;ãƒ»&lt;a href=&#34;https://docs.primihub.com/docs/advance-usage/create-tasks/psi-task/&#34;&gt;å‘½ä»¤è¡Œ&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;é™¤æ­¤ä¹‹å¤–ï¼ŒPrimiHub è¿˜æä¾›äº†å¤šç§é€‚åˆ&lt;strong&gt;ä¸åŒäººç¾¤&lt;/strong&gt;çš„ä½¿ç”¨æ–¹å¼ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.primihub.com/docs/quick-start-platform/&#34;&gt;åœ¨çº¿ä½“éªŒ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.primihub.com/docs/advance-usage/start/quick-start&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.primihub.com/docs/advance-usage/start/start-nodes&#34;&gt;å¯æ‰§è¡Œæ–‡ä»¶&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.primihub.com/docs/advance-usage/start/build&#34;&gt;è‡ªè¡Œç¼–è¯‘&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;é—®é¢˜ / å¸®åŠ© / Bug&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœæ‚¨åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œéœ€è¦æˆ‘ä»¬çš„å¸®åŠ©å¯ä»¥ &lt;a href=&#34;https://github.com/primihub/primihub/issues/new/choose&#34;&gt;ç‚¹å‡»&lt;/a&gt; åé¦ˆé—®é¢˜ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ¬¢è¿æ·»åŠ æˆ‘ä»¬çš„å¾®ä¿¡åŠ©æ‰‹ï¼ŒåŠ å…¥ã€ŒPrimiHub å¼€æºç¤¾åŒºã€å¾®ä¿¡ç¾¤ã€‚â€œé›¶è·ç¦»â€æ¥è§¦&lt;strong&gt;é¡¹ç›®æ ¸å¿ƒå¼€å‘ã€å¯†ç å­¦ä¸“å®¶ã€éšç§è®¡ç®—è¡Œä¸šå¤§å’–&lt;/strong&gt;ï¼Œè·å¾—æ›´åŠæ—¶çš„å›å¤å’Œéšç§è®¡ç®—çš„ç¬¬ä¸€æ‰‹èµ„è®¯ã€‚&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/primihub/primihub/develop/doc/wechat.jpeg&#34; alt=&#34;Header&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;è®¸å¯è¯&lt;/h2&gt; &#xA;&lt;p&gt;æ­¤ä»£ç åœ¨ Apache 2.0 ä¸‹å‘å¸ƒï¼Œå‚è§ &lt;a href=&#34;https://github.com/primihub/primihub/raw/develop/LICENSE&#34;&gt;LICENSE&lt;/a&gt; æ–‡ä»¶ã€‚&lt;/p&gt;</summary>
  </entry>
</feed>