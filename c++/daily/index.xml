<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-07T01:31:16Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>fmrico/book_ros2</title>
    <updated>2023-01-07T01:31:16Z</updated>
    <id>tag:github.com,2023-01-07:/fmrico/book_ros2</id>
    <link href="https://github.com/fmrico/book_ros2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;A Concise Introduction to Robot Programming with ROS2 - Code Repository&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/fmrico/book_ros2&#34;&gt;&lt;img src=&#34;https://github.com/fmrico/book_ros2/workflows/main/badge.svg?sanitize=true&#34; alt=&#34;GitHub Action Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/fmrico/book_ros2&#34;&gt;&lt;img src=&#34;https://github.com/fmrico/book_ros2/actions/workflows/humble-devel.yaml/badge.svg?branch=humble-devel&#34; alt=&#34;GitHub Action Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/fmrico/book_ros2&#34;&gt;&lt;img src=&#34;https://github.com/fmrico/book_ros2/workflows/foxy-devel/badge.svg?sanitize=true&#34; alt=&#34;GitHub Action Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Code&lt;/h2&gt; &#xA;&lt;p&gt;This repository contains the source code shown and analyzed in book &lt;em&gt;A Concise Introduction to Robot Programming with ROS2&lt;/em&gt;, as well as complementary teaching material that will be added.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Requirements for &lt;code&gt;main&lt;/code&gt; branch&lt;/strong&gt;: Ubuntu 22.04 LTS + ROS2 Humble Hawksbill&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Requirements for &lt;code&gt;humble-devel&lt;/code&gt; branch&lt;/strong&gt;: Ubuntu 22.04 LTS + ROS2 Humble Hawksbill&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Requirements for &lt;code&gt;foxy-devel&lt;/code&gt; branch&lt;/strong&gt;: Ubuntu 20.04 LTS + ROS2 Foxy Fitzroy&lt;/p&gt; &#xA;&lt;h2&gt;Slides&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.dropbox.com/s/nsx9s0ns6igfnoo/BR2_chapters_PDF.zip?dl=0&#34;&gt;Slides in PDF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.dropbox.com/s/uzs281ztld4mau8/BR2_chapters_KEY.zip?dl=0&#34;&gt;Slides in Keynote&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.dropbox.com/s/6ba6fiee86w9ufr/BR2_chapters_PPT.zip?dl=0&#34;&gt;Slides in Powerpoint&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/3810011/183239477-c98ee6a0-332f-40d2-b368-08a1383747e6.jpg&#34; alt=&#34;9781032264653&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Order book: &lt;a href=&#34;https://www.routledge.com/A-Concise-Introduction-to-Robot-Programming-with-ROS2/Rico/p/book/9781032264653#:~:text=A%20Concise%20Introduction%20to%20Robot%20Programming%20with%20ROS2%20provides%20the,the%20new%20version%20of%20ROS.&#34;&gt;https://www.routledge.com/A-Concise-Introduction-to-Robot-Programming-with-ROS2&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>BVLC/caffe</title>
    <updated>2023-01-07T01:31:16Z</updated>
    <id>tag:github.com,2023-01-07:/BVLC/caffe</id>
    <link href="https://github.com/BVLC/caffe" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Caffe: a fast open framework for deep learning.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Caffe&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/BVLC/caffe&#34;&gt;&lt;img src=&#34;https://travis-ci.org/BVLC/caffe.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/BVLC/caffe/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-BSD-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Caffe is a deep learning framework made with expression, speed, and modularity in mind. It is developed by Berkeley AI Research (&lt;a href=&#34;http://bair.berkeley.edu&#34;&gt;BAIR&lt;/a&gt;)/The Berkeley Vision and Learning Center (BVLC) and community contributors.&lt;/p&gt; &#xA;&lt;p&gt;Check out the &lt;a href=&#34;http://caffe.berkeleyvision.org&#34;&gt;project site&lt;/a&gt; for all the details like&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.p&#34;&gt;DIY Deep Learning for Vision with Caffe&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://caffe.berkeleyvision.org/tutorial/&#34;&gt;Tutorial Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://caffe.berkeleyvision.org/model_zoo.html&#34;&gt;BAIR reference models&lt;/a&gt; and the &lt;a href=&#34;https://github.com/BVLC/caffe/wiki/Model-Zoo&#34;&gt;community model zoo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://caffe.berkeleyvision.org/installation.html&#34;&gt;Installation instructions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;and step-by-step examples.&lt;/p&gt; &#xA;&lt;h2&gt;Custom distributions&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BVLC/caffe/tree/intel&#34;&gt;Intel Caffe&lt;/a&gt; (Optimized for CPU and support for multi-node), in particular IntelÂ® Xeon processors.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BVLC/caffe/tree/opencl&#34;&gt;OpenCL Caffe&lt;/a&gt; e.g. for AMD or Intel devices.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BVLC/caffe/tree/windows&#34;&gt;Windows Caffe&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/BVLC/caffe?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/Join%20Chat.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/BVLC/caffe&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please join the &lt;a href=&#34;https://groups.google.com/forum/#!forum/caffe-users&#34;&gt;caffe-users group&lt;/a&gt; or &lt;a href=&#34;https://gitter.im/BVLC/caffe&#34;&gt;gitter chat&lt;/a&gt; to ask questions and talk about methods and models. Framework development discussions and thorough bug reports are collected on &lt;a href=&#34;https://github.com/BVLC/caffe/issues&#34;&gt;Issues&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Happy brewing!&lt;/p&gt; &#xA;&lt;h2&gt;License and Citation&lt;/h2&gt; &#xA;&lt;p&gt;Caffe is released under the &lt;a href=&#34;https://github.com/BVLC/caffe/raw/master/LICENSE&#34;&gt;BSD 2-Clause license&lt;/a&gt;. The BAIR/BVLC reference models are released for unrestricted use.&lt;/p&gt; &#xA;&lt;p&gt;Please cite Caffe in your publications if it helps your research:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{jia2014caffe,&#xA;  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},&#xA;  Journal = {arXiv preprint arXiv:1408.5093},&#xA;  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},&#xA;  Year = {2014}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>EmberGL-org/EmberGL</title>
    <updated>2023-01-07T01:31:16Z</updated>
    <id>tag:github.com,2023-01-07:/EmberGL-org/EmberGL</id>
    <link href="https://github.com/EmberGL-org/EmberGL" rel="alternate"></link>
    <summary type="html">&lt;p&gt;EmberGL - 2D/3D graphics library featuring a tiled software rasterizer.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/doc/images/embergl_logo.png&#34; alt=&#34;EmberGL logo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;EmberGL (Ember Graphics Library) is a low-level open source graphics library, similar to OpenGL/DirectX/Vulkan, designed for real-time 2D/3D rendering on MCUs and other memory constrained non-GPU systems. The graphics API has been specifically designed for such systems, utilizing modern techniques to be able to maximize rendering performance within tight memory budgets, while providing a lot of flexibility and customizability. The library can be also useful on other targets with more generous budgets, for projects which benefit from software rasterization, and can be compiled for example with &lt;a href=&#34;https://visualstudio.microsoft.com/&#34;&gt;Visual Studio&lt;/a&gt; and &lt;a href=&#34;https://gcc.gnu.org/&#34;&gt;GCC&lt;/a&gt;. Because EmberGL is a low-level library, it provides only the core rendering functionality of flexible and efficient triangle rasterization, along with supporting components and a set of display drivers. These low-level features can be used either for direct application development or development of efficient higher level graphics libraries, such as GUI libraries or 3D engines.&lt;/p&gt; &#xA;&lt;p&gt;The library features a tile-based software rasterizer, which enables flicker-free rendering without requiring RAM for the entire display frame &amp;amp; depth buffers, thus expands the applicability of the library to a wider set of devices &amp;amp; projects. Tile-Base Rendering (TBR) architectures are commonly used on mobile devices and also on some desktop GPUs mainly due to the memory bandwidth benefits (more info on &lt;a href=&#34;https://developer.arm.com/documentation/102662/latest&#34;&gt;Arm Developer website&lt;/a&gt;). The TBR engine of EmberGL can be customized for wide range of memory and performance requirements by configuring the rasterizer properties such as the tile size, depth buffer format, intermediate tile pixel format, etc.&lt;/p&gt; &#xA;&lt;p&gt;EmberGL supports various fixed-function pipeline features, such as a set of depth tests, triangle culling modes, triangle interpolation modes, etc. In addition to the fixed-function features, the library also supports C++ programmable blending and vertex &amp;amp; pixel shading stages for custom geometry and lighting effects. To obtain high performance while supporting a flexible set of features, the rasterizer extensively utilizes C++ templates to generate optimized rasterizers for each set of utilized features during program compilation time. This eliminates any unused feature branching and tightly embeds shader code to the rasterizer, resulting in optimized rasterizers for each used combination of features &amp;amp; shaders.&lt;/p&gt; &#xA;&lt;p&gt;In addition to the rasterizer, EmberGL provides a growing set of optimized display drivers to efficiently deliver the rasterized pixels to the display. For example, the library contains optimized display driver for popular ILI9341 display with DMA support. The set of drivers can be extended by implementing a narrow device interface, which hooks new drivers to the rasterizer, where the main implementation focus is the device initialization and pixel data transfer without having to worry about the rasterizer complexities.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to get started with EmberGL is to check out &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/examples/&#34;&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt;. The examples are provided as verbosely commented Arduino &lt;code&gt;.ino&lt;/code&gt; files, and for anyone not familiar with Arduino, the &lt;code&gt;.ino&lt;/code&gt; files are just C++ code where &lt;code&gt;setup()&lt;/code&gt; function is executed once in the beginning of the program and &lt;code&gt;loop()&lt;/code&gt; function is executing in an infinite loop once per frame. The first example shows how to setup display hardware and initialize the accompanying graphics device, and then proceed with increasing complexity in the further examples. Even though some examples may appear boring, it&#39;s good to check them in order, because they progressively explain more concepts that are not necessarily explained again in the latter examples. You can find videos of each example in EmberGL &lt;a href=&#34;https://www.youtube.com/playlist?list=PLZ_pJuzhfjjR8VHPLceESsA72lAbV4BrV&#34;&gt;Examples playlist&lt;/a&gt; to know what to expect, or click video thumbnails below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/RFGE5kELUfs&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/RFGE5kELUfs/2.jpg&#34; alt=&#34;00_HelloRect&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/DNwPy96wWfY&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/DNwPy96wWfY/1.jpg&#34; alt=&#34;01_TexturedRects&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/dvLV1YZV8DA&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/dvLV1YZV8DA/1.jpg&#34; alt=&#34;02_RotoMonkey&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/PNskpOR5SBQ&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/PNskpOR5SBQ/1.jpg&#34; alt=&#34;03_MultiDispatch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/5OtgsO4JMHA&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/5OtgsO4JMHA/1.jpg&#34; alt=&#34;04_TexCube&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/WdXELRNCcqY&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/WdXELRNCcqY/2.jpg&#34; alt=&#34;05_Speedometer&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/eHPmojXcEkw&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/eHPmojXcEkw/3.jpg&#34; alt=&#34;06_LitMonkey&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/d9-UDttT1P0&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/d9-UDttT1P0/3.jpg&#34; alt=&#34;07_ClusterCulling&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/8bJHSxFcICQ&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/8bJHSxFcICQ/2.jpg&#34; alt=&#34;08_TightMem&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Geometry and Rasterization Pipeline&lt;/h2&gt; &#xA;&lt;p&gt;The EmberGL rasterizer processes the geometry in triangle clusters (a.k.a. meshlets) where each cluster contains some small number of vertices and triangles (e.g. &amp;lt;=64 vertices and &amp;lt;=128 triangles). This is important to optimize both performance and RAM usage of the rasterizer, and to minimize vertex and pixel processing. For 3D geometry, EmberGL supports &lt;a href=&#34;https://github.com/JarkkoPFC/meshlete/raw/master/doc/file_format_p3g.xlsx&#34;&gt;P3G file format&lt;/a&gt; that can be generated with &lt;a href=&#34;https://github.com/JarkkoPFC/meshlete&#34;&gt;Meshlete&lt;/a&gt; tool, which splits 3D models in OBJ/FBX/DAE/etc. format to clusters and exports the clustered models as P3G file that can be used with the provided &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_mesh.h&#34;&gt;&lt;code&gt;p3g_mesh&lt;/code&gt;&lt;/a&gt; class. The tool also calculates cluster bounding volumes and visibility cones that are used by the rasterizer to optimize rendering. The P3G format has been designed so that the data can be loaded as a binary blob to memory and requires no post-load processing for rendering. On MCU&#39;s this enables storing and rendering the geometry straight from the flash memory without RAM usage, thus enables rendering complex 3D models with a small RAM budget. On other platforms the file can be simply loaded to a dynamically allocated memory block and initialized in place making the loading very efficient.&lt;/p&gt; &#xA;&lt;p&gt;Objects are dispatched for rasterization using &lt;code&gt;graphics_device::dispatch_pso()&lt;/code&gt; function (more details about PSCs and PSOs in a chapter below). When the function is called, the object clusters go through a programmable cluster setup stage where they can be culled (e.g. with visibility cones) and then binned to screen tiles (e.g. 64x64px tiles) based on their bounding volumes. Once all the geometry for a frame has been dispatched to the device, calling &lt;code&gt;graphics_device::commit()&lt;/code&gt; (with an optional tile shader) triggers the rasterization of the tiles. The tiles are rasterized one by one to the tile buffer containing up to 4 render targets, a depth buffer and Hi-Z buffer, and after completing each tile the results are transferred to the display frame buffer. This means that the rasterizer requires render target and depth buffer memory only for a single tile and not for the entire frame buffer. Upon the transfer, the tile pixels are converted from the intermediate tile pixel format to the native display frame buffer format, or alternatively the tile shader is executed to perform custom pixel processing and format conversion. During tile rasterization, the clusters that are binned to the tile are rasterized in the dispatch order and the bounding volume of each cluster is first tested against tile Hi-Z for occlusion. Hi-Z is a low-resolution representation of the depth buffer that can be used for fast region depth test. Clusters that fail the test are rejected and thus skip both vertex transform and rasterization, while the passing clusters go through cluster vertex transform with the associated vertex shader, or previously cached transformed vertices are fetched from the post-transform vertex cache (v-cache). The result of the vertex transform is then potentially stored to v-cache for reuse by other tiles that have the same cluster binned, thus reducing the vertex transform cost. After this the passing cluster triangles go through the rasterization with the associated pixel shader.&lt;/p&gt; &#xA;&lt;p&gt;The rasterizer complies to top-left rasterization rule to ensure that pixels at the shared edges of adjacent triangles are rasterized exactly once. This is particularly important for proper render target blending (e.g. additive or alpha blending) so the triangle edges don&#39;t suffer from pixel overdraw artifacts. Upon triangle rasterization, the rasterized pixels are tested against depth buffer with the selected depth test. Pixels that pass the test execute a programmable pixel shader function which takes the three transformed vertices of the triangle along with barycentric coordinates of the pixel as arguments. The pixel shader can be used to implement custom lighting effects and the barycentric coordinates are used to interpolate post-transform vertex attributes exported from the vertex shader (e.g. texture coordinates or colors). Finally the pixel shader exports the result, potential to Multiple Render Targets (MRT), and the result goes through the programmable blending stage (e.g. opaque, alpha, additive blending).&lt;/p&gt; &#xA;&lt;p&gt;To minimize vertex and pixel processing with EmberGL it&#39;s a good strategy to render opaque objects in increasing distance from the camera, i.e. sort PSOs by camera distance before dispatching. This way clusters are more likely occlusion culled by previously rasterized clusters in the frame and thus eliminate vertex transform and triangle rasterization cost. The pixels of rasterized clusters are also more likely culled by the depth test thus eliminating the pixel processing cost. It&#39;s also recommended to apply visibility cone culling during cluster rasterization setup stage, because that will potentially skip the tile binning and the occlusion testing cost for a small culling cost.&lt;/p&gt; &#xA;&lt;h2&gt;Pipeline State Classes (PSCs) and Objects (PSOs)&lt;/h2&gt; &#xA;&lt;p&gt;Pipeline State Classes (PSCs) are user defined C++ classes which define the render state and operations performed in different stages of the rasterizer (e.g. vertex &amp;amp; pixel shading). These classes are initialized to create Pipeline State Objects (PSOs), which are then setup (e.g. with a mesh and object transformation) and submitted to the graphics device for rasterization with &lt;code&gt;graphics_device::dispatch_pso()&lt;/code&gt; function. To be compatible with the rasterizer, the PSCs must provide an implementation of the PSC interface defined in &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_rasterizer_psc.h&#34;&gt;&lt;code&gt;rasterizer_pcs_base&lt;/code&gt;&lt;/a&gt;. While not mandatory, it&#39;s recommended to derive the PSCs from the class to make them more resilient for future EmberGL changes, e.g. if new optional render states or pipeline stages are added to EmberGL, default implementations can be added to &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_rasterizer_psc.h&#34;&gt;&lt;code&gt;rasterizer_pcs_base&lt;/code&gt;&lt;/a&gt; making the derived custom PSCs better compatible with the changes.&lt;/p&gt; &#xA;&lt;p&gt;Render states define the fixed-function features used for rendering the geometry upon the PSO dispatch, such as depth test or triangle culling mode. The states are defined with enums within the PSC that&#39;s used for dispatch. This method of defining the state with compile-time constants enables optimizing rasterizers at compile-time for specific render states, which is important for performance. The available set of render states can be found in &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_rasterizer_psc.h&#34;&gt;&lt;code&gt;rasterizer_psc_base&lt;/code&gt;&lt;/a&gt; definition, which also defines the default render states. By deriving a new PSC from the class the default render states can be overridden simply by redefining the enums in the class:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct my_psc: rasterizer_psc_base&#xA;{&#xA;  enum {depth_write=false}; // disable depth write and keep the rest of the state as default&#xA;  ...&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For convenience, EmberGL provides a generic template PSC &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_mesh.h&#34;&gt;&lt;code&gt;psc_p3g_mesh&lt;/code&gt;&lt;/a&gt; for rendering P3G meshes. This class can be instantiated for given vertex &amp;amp; pixel shaders and vertex input format. It also enables setting the render states via a base class passed as a template argument. The vertex and pixel shaders are implemented as C++ classes with specific interface and both implement &lt;code&gt;exec()&lt;/code&gt; function which performs the vertex/pixel shading (see &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/examples/&#34;&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; for details).&lt;/p&gt; &#xA;&lt;p&gt;The shaders can be combined in flexible yet efficient ways for high reuse of the shader code. Vertex shaders can be used with different vertex inputs as long as the data required by the shader is provided by the input. Furthermore, the input data can be provided in different formats transparently to the shaders, e.g. the vertex 3D position data could be uncompressed &lt;code&gt;vec3f&lt;/code&gt; or quantized to &lt;code&gt;vec3s&lt;/code&gt; in object bounds and dequantization is done transparently to the vertex shader. The pixel shaders can write to different render target formats and can be combined with any vertex shader that provides post-transform attributes required by the pixel shader.&lt;/p&gt; &#xA;&lt;p&gt;The shaders can be written so that any post-transform attributes that are unused by pixel shaders are eliminated along with the associated vertex shader code, thus enabling efficient composition of shaders. Unavailable vertex input attributes fetched by vertex shaders return zero values thus enables writing more generic vertex shaders. Also, if the vertex shader doesn&#39;t export vertex attributes required by the combined pixel shader, a C++ compilation error occurs informing programmer early about invalid combinations.&lt;/p&gt; &#xA;&lt;h2&gt;Textures&lt;/h2&gt; &#xA;&lt;p&gt;EmberGL currently supports 2D textures in various texture formats that can be sampled for example during triangle rasterization. Source textures stored as PNG/JPG/TGA/DDS/etc. file format can be converted to &lt;a href=&#34;https://github.com/JarkkoPFC/ptx_converter/raw/main/doc/file_format_ptx.xlsx&#34;&gt;PTX format&lt;/a&gt; with &lt;a href=&#34;https://github.com/JarkkoPFC/ptx_converter&#34;&gt;PTX Texture Converter&lt;/a&gt; tool, which can be used with &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_texture.h&#34;&gt;&lt;code&gt;texture&lt;/code&gt;&lt;/a&gt; class. Like the P3G format, the PTX format has been designed so that the data can be loaded as a binary blob to memory and requires no post-load processing for sampling, which on MCU&#39;s enables storing and sampling textures straight from the flash memory saving RAM.&lt;/p&gt; &#xA;&lt;p&gt;Once &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_texture.h&#34;&gt;&lt;code&gt;texture&lt;/code&gt;&lt;/a&gt; has been initialized with the PTX data, it can be sampled using an appropriate sampler class for the texture type (e.g. &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_texture.h&#34;&gt;&lt;code&gt;sampler2d&lt;/code&gt;&lt;/a&gt; for 2D textures). The sampler fetches texture data at the requested texture coordinates and provides the data in the requested pixel format. The sampling can be done either with point or bilinear sampling and samplers support wrap and clamp-to-edge texture address modes.&lt;/p&gt; &#xA;&lt;h2&gt;Math Library&lt;/h2&gt; &#xA;&lt;p&gt;EmberGL comes with a comprehensive C++ template math library that provides various math components relevant for 2D and 3D rendering (e.g. matrix/vector/quaternion classes). These components are used throughout EmberGL and are also useful in client code to perform the necessary math operations which seamlessly interface with the library.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_math.h&#34;&gt;&lt;code&gt;egl_math.h&lt;/code&gt;&lt;/a&gt;: Linear algebra classes: 2D, 3D and 4D vector and matrix classes, quaternion and complex number classes with large set of operations that can be performed on them (matrix multiplication, dot/cross products, etc.etc.)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_tform3.h&#34;&gt;&lt;code&gt;egl_tform3.h&lt;/code&gt;&lt;/a&gt;: 3D transformation and camera classes along with many operations for them.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_color.h&#34;&gt;&lt;code&gt;egl_color.h&lt;/code&gt;&lt;/a&gt;: RGB, XYZ, YIQ and HSV color classes, operations and transformations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_fast_math.h&#34;&gt;&lt;code&gt;egl_fast_math.h&lt;/code&gt;&lt;/a&gt;: Fast approximations for some math operations (e.g. &lt;code&gt;1.0f/sqrt(x)&lt;/code&gt;). Can be useful where performance is more important than accuracy.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;EmberGL has three predefined build configurations to control the level of program validation: Debug, Release and Retail. These builds can be respectively selected in &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_core.h&#34;&gt;&lt;code&gt;egl_core.h&lt;/code&gt;&lt;/a&gt; by uncommenting one of the defines: &lt;code&gt;EGL_DEBUG&lt;/code&gt;, &lt;code&gt;EGL_RELEASE&lt;/code&gt; or &lt;code&gt;EGL_RETAIL&lt;/code&gt;. Debug build has all programming run-time validation enabled and is the most verbose of the builds. It&#39;s recommended to use the Debug build during development to catch programming errors with the most information during program execution, if the performance and memory usage isn&#39;t an issue. Release build is a compromise between the validation, performance and memory usage, which can be used for builds deployed during development (e.g. internally for testing). All but the most performance intensive validation are enabled in Release, but for example the C++ source file and line number information is omitted from errors for reduced memory footprint. Retail build has all the programming validation disabled and is the best performing build with the smallest memory footprint, and should be used for the final shipping product to users. The level of validation and logging can be tweaked in &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/src/egl_core.h&#34;&gt;&lt;code&gt;egl_core.h&lt;/code&gt;&lt;/a&gt; for these predefined builds if necessary and new build configurations can be added with different configuration because none of the EmberGL code checks for the selected build directly. In the beginning of the program &lt;code&gt;init_serial()&lt;/code&gt; must be called which enables run-time logging to the serial monitor.&lt;/p&gt; &#xA;&lt;p&gt;There are several macros provided with the library, that can be used to check for programming errors within EmberGL (e.g. invalid parameters passed to a function) and can be also used in client code. Note that these macros shouldn&#39;t be used for validating user errors, because they are disabled in the Retail builds delivered to users, and because they terminate the program execution, which shows as a crash to users. If the validation fails, the macros output a message to the log and terminates the program execution, and trigger debugger if attached. Below is the list of provided macros with their intended use, but for use-case references it&#39;s the best to check EmberGL code:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_ASSERT()&lt;/code&gt;: Validates that given expression is true, and upon error outputs the failed expression to the log and terminates the program.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_ASSERT_MSG()&lt;/code&gt;: Validates the expression, and upon error outputs the given formatted message to the log and terminates the program.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_ASSERT_PEDANTIC()&lt;/code&gt;: The same as &lt;code&gt;EGL_ASSERT()&lt;/code&gt; but is used only in performance critical code where the validation adds relatively large overhead. Pedantic asserts can be disabled with the build configuration separate from non-pedantic asserts to improve performance (these are disabled in Release build).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_ASSERT_PEDANTIC_MSG()&lt;/code&gt;: The same as &lt;code&gt;EGL_ASSERT_PEDANTIC()&lt;/code&gt; but with the formatted message.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_ERROR()&lt;/code&gt;: Outputs the given formatted error message to the log and terminates the program execution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_ERROR_NOT_IMPL()&lt;/code&gt;: Special error message for functionality that hasn&#39;t been implemented and terminates the program execution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_WARN()&lt;/code&gt;: Outputs the given formatted warning message to the log but doesn&#39;t terminate the program execution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_LOGF()&lt;/code&gt;: Outputs given formatted message to the log. These logs are supposed to ship with the final Retail build.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_LOG()&lt;/code&gt;: The same as &lt;code&gt;EGL_LOGF()&lt;/code&gt; but with unformatted message. This is more efficient than &lt;code&gt;EGL_LOGF()&lt;/code&gt; and should be used when no formatting is required.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EGL_DEBUG_LOGF()&lt;/code&gt; and &lt;code&gt;EGL_DEBUG_LOG()&lt;/code&gt;: The same as &lt;code&gt;EGL_LOGF()&lt;/code&gt; and &lt;code&gt;EGL_LOG()&lt;/code&gt; respectively, but used for development logging and are not included in the final shipping builds.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Developing more complex applications and libraries directly on MCUs (e.g. with the Arduino IDE) can be challenging due to the constrained system and the lack of development tools, such as a good debugger. Because of the portability of EmberGL, most of the development can be done for example on PC, and once the application runs as expected then compiled for MCUs. Naturally some code is MCU specific (e.g. display drivers or interfacing with the MCU hardware), but structuring the code to portable and MCU specific parts can significantly help with the development.&lt;/p&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;p&gt;Some planned further improvements (excluding issues) of the library:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/EmberGL-org/EmberGL/issues/1&#34;&gt;Near plane triangle clipping &amp;amp; culling&lt;/a&gt; &lt;em&gt;&lt;strong&gt;[S5]&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/EmberGL-org/EmberGL/issues/2&#34;&gt;2D texture mipmap support&lt;/a&gt; &lt;em&gt;&lt;strong&gt;[S2]&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/EmberGL-org/EmberGL/issues/3&#34;&gt;Cubemap support&lt;/a&gt; &lt;em&gt;&lt;strong&gt;[S2]&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/EmberGL-org/EmberGL/issues/4&#34;&gt;Support to control HiZ update frequency&lt;/a&gt; &lt;em&gt;&lt;strong&gt;[S1]&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/EmberGL-org/EmberGL/issues/5&#34;&gt;Depth-only rendering&lt;/a&gt; &lt;em&gt;&lt;strong&gt;[S0]&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/EmberGL-org/EmberGL/issues/6&#34;&gt;Refined cluster occlusion &amp;amp; tile culling with PTV&lt;/a&gt; &lt;em&gt;&lt;strong&gt;[S1]&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/EmberGL-org/EmberGL/issues/7&#34;&gt;Example: Shadow mapping&lt;/a&gt; &lt;em&gt;&lt;strong&gt;[S2]&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/EmberGL-org/EmberGL/issues/8&#34;&gt;Example: Deferred shading&lt;/a&gt; &lt;em&gt;&lt;strong&gt;[S3]&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;EmberGL is licensed under MIT license. See &lt;a href=&#34;https://raw.githubusercontent.com/EmberGL-org/EmberGL/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
</feed>