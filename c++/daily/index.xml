<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-19T01:32:08Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>COVESA/vsomeip</title>
    <updated>2023-01-19T01:32:08Z</updated>
    <id>tag:github.com,2023-01-19:/COVESA/vsomeip</id>
    <link href="https://github.com/COVESA/vsomeip" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An implementation of Scalable service-Oriented MiddlewarE over IP&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;vsomeip&lt;/h3&gt; &#xA;&lt;h5&gt;Copyright&lt;/h5&gt; &#xA;&lt;p&gt;Copyright (C) 2015-2017, Bayerische Motoren Werke Aktiengesellschaft (BMW AG)&lt;/p&gt; &#xA;&lt;h5&gt;License&lt;/h5&gt; &#xA;&lt;p&gt;This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at &lt;a href=&#34;http://mozilla.org/MPL/2.0/&#34;&gt;http://mozilla.org/MPL/2.0/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h5&gt;vsomeip Overview&lt;/h5&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;The vsomeip stack implements the &lt;a href=&#34;http://some-ip.com/&#34;&gt;http://some-ip.com/&lt;/a&gt; (Scalable service-Oriented MiddlewarE over IP (SOME/IP)) protocol. The stack consists out of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;a shared library for SOME/IP (&lt;code&gt;libvsomeip3.so&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;a second shared library for SOME/IP&#39;s service discovery (&lt;code&gt;libvsomeip3-sd.so&lt;/code&gt;) which is loaded during runtime if the service discovery is enabled.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;Build Instructions for Linux&lt;/h5&gt; &#xA;&lt;h6&gt;Dependencies&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A C++11 enabled compiler like gcc &amp;gt;= 4.8 is needed.&lt;/li&gt; &#xA; &lt;li&gt;vsomeip uses CMake as buildsystem.&lt;/li&gt; &#xA; &lt;li&gt;vsomeip uses Boost &amp;gt;= 1.55:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Ubuntu 14.04:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;sudo apt-get install libboost-system1.55-dev libboost-thread1.55-dev libboost-log1.55-dev&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Ubuntu 12.04: a PPA is necessary to use version 1.54 of Boost: -- URL: &lt;a href=&#34;https://launchpad.net/~boost-latest/+archive/ubuntu/ppa&#34;&gt;https://launchpad.net/~boost-latest/+archive/ubuntu/ppa&lt;/a&gt; --&lt;code&gt;sudo add-apt-repository ppa:boost-latest/ppa&lt;/code&gt; --&lt;code&gt;sudo apt-get install libboost-system1.55-dev libboost-thread1.55-dev libboost-log1.55-dev&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;For the tests Google&#39;s test framework &lt;a href=&#34;https://code.google.com/p/googletest/%5Bgtest%5D&#34;&gt;https://code.google.com/p/googletest/[gtest]&lt;/a&gt; in version 1.7.0 is needed. -- URL: &lt;a href=&#34;https://googletest.googlecode.com/files/gtest-1.7.0.zip&#34;&gt;https://googletest.googlecode.com/files/gtest-1.7.0.zip&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To build the documentation asciidoc, source-highlight, doxygen and graphviz is needed: --&lt;code&gt;sudo apt-get install asciidoc source-highlight doxygen graphviz&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h6&gt;Compilation&lt;/h6&gt; &#xA;&lt;p&gt;For compilation call:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir build&#xA;cd build&#xA;cmake ..&#xA;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To specify a installation directory (like &lt;code&gt;--prefix=&lt;/code&gt; if you&#39;re used to autotools) call cmake like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cmake -DCMAKE_INSTALL_PREFIX:PATH=$YOUR_PATH ..&#xA;make&#xA;make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h6&gt;Compilation with predefined unicast and/or diagnosis address&lt;/h6&gt; &#xA;&lt;p&gt;To predefine the unicast address, call cmake like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cmake -DUNICAST_ADDRESS=&amp;lt;YOUR IP ADDRESS&amp;gt; ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To predefine the diagnosis address, call cmake like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cmake -DDIAGNOSIS_ADDRESS=&amp;lt;YOUR DIAGNOSIS ADDRESS&amp;gt; ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The diagnosis address is a single byte value.&lt;/p&gt; &#xA;&lt;h6&gt;Compilation with custom default configuration folder&lt;/h6&gt; &#xA;&lt;p&gt;To change the default configuration folder, call cmake like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cmake -DDEFAULT_CONFIGURATION_FOLDER=&amp;lt;DEFAULT CONFIGURATION FOLDER&amp;gt; ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The default configuration folder is /etc/vsomeip.&lt;/p&gt; &#xA;&lt;h6&gt;Compilation with custom default configuration file&lt;/h6&gt; &#xA;&lt;p&gt;To change the default configuration file, call cmake like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cmake -DDEFAULT_CONFIGURATION_FILE=&amp;lt;DEFAULT CONFIGURATION FILE&amp;gt; ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The default configuration file is /etc/vsomeip.json.&lt;/p&gt; &#xA;&lt;h6&gt;Compilation with signal handling&lt;/h6&gt; &#xA;&lt;p&gt;To compile vsomeip with signal handling (SIGINT/SIGTERM) enabled, call cmake like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cmake -DENABLE_SIGNAL_HANDLING=1 ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the default setting, the application has to take care of shutting down vsomeip in case these signals are received.&lt;/p&gt; &#xA;&lt;h5&gt;Build Instructions for Android&lt;/h5&gt; &#xA;&lt;h6&gt;Dependencies&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;vsomeip uses Boost &amp;gt;= 1.55. The boost libraries (system, thread and log) must be included in the Android source tree and integrated into the build process with an appropriate Android.bp file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;Compilation&lt;/h6&gt; &#xA;&lt;p&gt;In general for building the Android source tree the instructions found on the pages from the Android Open Source Project (AOSP) apply (&lt;a href=&#34;https://source.android.com/setup/build/requirements&#34;&gt;https://source.android.com/setup/build/requirements&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;To integrate the vsomeip library into the build process, the source code together with the Android.bp file has to be inserted into the Android source tree (by simply copying or by fetching with a custom platform manifest). When building the Android source tree, the Android.bp file is automatically found and considered by the build system.&lt;/p&gt; &#xA;&lt;p&gt;In order that the vsomeip library is also included in the Android image, the library has to be added to the PRODUCT_PACKAGES variable in one of a device/target specific makefile:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PRODUCT_PACKAGES += \&#xA;    libvsomeip \&#xA;    libvsomeip_cfg \&#xA;    libvsomeip_sd&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>sofneo/import-hoodini</title>
    <updated>2023-01-19T01:32:08Z</updated>
    <id>tag:github.com,2023-01-19:/sofneo/import-hoodini</id>
    <link href="https://github.com/sofneo/import-hoodini" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Simple runtime import protection &amp; hook mitigation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;import-hoodini&lt;/h1&gt; &#xA;&lt;p&gt;Simple runtime import protection &amp;amp; hook mitigation&lt;/p&gt; &#xA;&lt;p&gt;A video demonstration of this can be found here: &lt;a href=&#34;https://youtu.be/TWWLiTAPz1U&#34;&gt;https://youtu.be/TWWLiTAPz1U&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Import Hoodini is a simple concept of reversing the common usage of the Import Address Table. The IAT (Import Address Table) is used in every native Windows application to allow modules to import routines which have been exported by other libraries/modules. Attackers will often abuse the IAT by either swapping the pointer to their own prologue OR by hooking the exported routine. This project mitigates and prevents these types of attacks by registering callbacks using small assembly stubs relative to every import which is responsbible for integrity checking them before allowing the call to commence. A snippet of this stub can be found below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-asm&#34;&gt;0:  48 81 ec 88 00 00 00    sub    rsp,0x88                     ; allocating stack space&#xA;7:  48 89 4c 24 28          mov    QWORD PTR [rsp+0x28],rcx     ; &#39;saving&#39; the stack so that the original call can commence&#xA;c:  48 89 54 24 30          mov    QWORD PTR [rsp+0x30],rdx&#xA;11: 4c 89 44 24 38          mov    QWORD PTR [rsp+0x38],r8&#xA;16: 4c 89 4c 24 40          mov    QWORD PTR [rsp+0x40],r9&#xA;1b: 0f 11 44 24 48          movups XMMWORD PTR [rsp+0x48],xmm0&#xA;20: 0f 11 4c 24 58          movups XMMWORD PTR [rsp+0x58],xmm1&#xA;25: 0f 11 54 24 68          movups XMMWORD PTR [rsp+0x68],xmm2&#xA;2a: 0f 11 5c 24 78          movups XMMWORD PTR [rsp+0x78],xmm3&#xA;    &#xA;2f: 48 b9 fe ca be ba 00    movups rcx,0xbabecafe ; setting a1 (rcx) to the import&#39;s pointer&#xA;36: 00 00 00&#xA;39: 48 8d 54 24 28          lea    rdx,[rsp+0x28]&#xA;3e: 48 b8 ef be ad de 00    movabs rax,0xdeadbeef               ; call our &#39;callback&#39; which handles integrity&#xA;45: 00 00 00&#xA;48: ff d0                   call   rax                        &#xA;&#x9;&#x9;&#xA;4a: 48 8b 4c 24 28          mov    rcx,QWORD PTR [rsp+0x28]     ; restore the stack&#xA;4f: 48 8b 54 24 30          mov    rdx,QWORD PTR [rsp+0x30]&#xA;54: 4c 8b 44 24 38          mov    r8,QWORD PTR [rsp+0x38]&#xA;59: 4c 8b 4c 24 40          mov    r9,QWORD PTR [rsp+0x40]&#xA;5e: 0f 10 44 24 48          movups xmm0,XMMWORD PTR [rsp+0x48]&#xA;63: 0f 10 4c 24 58          movups xmm1,XMMWORD PTR [rsp+0x58]&#xA;68: 0f 10 54 24 68          movups xmm2,XMMWORD PTR [rsp+0x68]&#xA;6d: 0f 10 5c 24 78          movups xmm3,XMMWORD PTR [rsp+0x78]&#xA;72: 49 ba fe ca be ba 00    movups r10,0xbabecafe&#xA;79: 00 00 00&#xA;7c: 48 81 c4 88 00 00 00    add    rsp,0x88                  &#xA;83: 41 ff e2                jmp    r10                          ; call original export / imported routine&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Project Usage&lt;/h1&gt; &#xA;&lt;p&gt;Usage of this project is very simple. Simply include &#34;import-hoodini.hpp&#34; and call one of the following setups in your entrypoint.&lt;/p&gt; &#xA;&lt;p&gt;A generic project may do the following which will simply protect ALL imported routines:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;ImportHoodini::Setup_AllImports();&#xA;ImportHoodini::ActivateImportCallbacks();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;OR if you wish to specify a list of imports which should NOT be protected:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Basic refuse list for printf()&#xA;std::vector&amp;lt;std::uint64_t&amp;gt; RefuseList = {&#xA;  (std::uint64_t)&amp;amp;__stdio_common_vfprintf,&#xA;  (std::uint64_t)&amp;amp;__acrt_iob_func&#xA;};&#xA;&#xA;ImportHoodini::Setup_AllImports(&#xA;  GetModuleHandleA(NULL),&#xA;  RefuseList&#xA;);&#xA;&#xA;ImportHoodini::ActivateImportCallbacks();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;OR if you wish to specify a list of imports which should ONLY be protected:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// ONLY protect IsDebuggerPresent&#xA;std::vector&amp;lt;std::uint64_t&amp;gt; ProtectionList = {&#xA;  (std::uint64_t)&amp;amp;IsDebuggerPresent&#xA;};&#xA;&#xA;ImportHoodini::Setup_Specific(&#xA;  GetModuleHandleA(NULL),&#xA;  ProtectionList&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Report System&lt;/h1&gt; &#xA;&lt;p&gt;Any time a function is hooked and ImportHoodini restores it, a report is made.&lt;/p&gt; &#xA;&lt;p&gt;These reports can be obtained by calling:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;ImportHoodini::Reports::GetReports();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The object in the std::vector&amp;lt;&amp;gt; return value contains the type of hook and also a function dump which is created when the hook is detected.&lt;/p&gt; &#xA;&lt;h1&gt;--&lt;/h1&gt; &#xA;&lt;p&gt;Advantages of this project:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Integrity checks functions inline and restores patches so that an attacker&#39;s hook is never hit&lt;/li&gt; &#xA; &lt;li&gt;Protection checks to ensure that VEH hooks and other sorts of protection hooks are not hit.&lt;/li&gt; &#xA; &lt;li&gt;Safe for multi-threaded projects/libraries&lt;/li&gt; &#xA; &lt;li&gt;Report system so that you can log all patches that are made. This will also create a report of the function dump.&lt;/li&gt; &#xA; &lt;li&gt;Requires no macros or any code modifications to work.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Disadvantages/to-do:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Uses STL therefore will require some changes to work in pure C modules&lt;/li&gt; &#xA; &lt;li&gt;All imports in the callback function must be resolved before import protection is enabled&lt;/li&gt; &#xA; &lt;li&gt;Uses a disassembler to calculate function size (set to maximum of 0x20h bytes) however this does not handle near jumps and other instructions which could change order of execution.&lt;/li&gt; &#xA; &lt;li&gt;Ignores all imports from MSVCP140.dll &amp;amp; also free, malloc and realloc as they may cause deadlocks.&lt;/li&gt; &#xA; &lt;li&gt;This project assumes that patches / inline hooks are placed at the start of the prologue which is not always true therefore it will not detect hooks past 0x20 bytes into the prologue.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please ensure optimizations are disabled if you attempt to use this project!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Credits to &lt;a href=&#34;https://www.github.com/irql0&#34;&gt;@irql0&lt;/a&gt; for assembly stub &amp;amp; other bits.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>FeiYull/TensorRT-Alpha</title>
    <updated>2023-01-19T01:32:08Z</updated>
    <id>tag:github.com,2023-01-19:/FeiYull/TensorRT-Alpha</id>
    <link href="https://github.com/FeiYull/TensorRT-Alpha" rel="alternate"></link>
    <summary type="html">&lt;p&gt;《TensorRT-Alpha》 supports YOLOv8, YOLOv7, YOLOv6, YOLOv5, YOLOv4, YOLOv3, YOLOX, YOLOR and so on. TensorRT-Alpha implements CUDA C accelerated deployment models.The other 10 more CNN and transformer models are being sorted out,which will be updated in the future.CUDA IS ALL YOU NEED.Best Wish!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TensorRT-Alpha&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-toolkit-archive&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/CUDA-11.3-%2376B900?logo=nvidia&#34; alt=&#34;Cuda&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://developer.nvidia.com/nvidia-tensorrt-8x-download&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/TensorRT-8.4.2.4-%2376B900.svg?style=flat&amp;amp;logo=tensorrt&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://releases.ubuntu.com/18.04/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/ubuntu-18.04-orange.svg?style=flat&amp;amp;logo=ubuntu&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.microsoft.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/windows-10-blue.svg?style=flat&amp;amp;logo=windows&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pytorch.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/pytorch-1.9.0-blue.svg?style=flat&amp;amp;logo=pytorch&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/README_cn.md&#34;&gt;简体中文&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Visualization&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/facemesh.jpg&#34; width=&#34;145px&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/poeple640640.gif&#34; width=&#34;320px&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/NBA.gif&#34; height=&#34;190px&#34; width=&#34;230px&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/nuScenes.gif&#34; width=&#34;257px&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/u2net.gif&#34; width=&#34;190px&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/libfacedet.gif&#34; width=&#34;250px&#34;&gt; &#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Introduce&lt;/h2&gt; &#xA;&lt;p&gt;This repository provides accelerated deployment cases of deep learning CV popular models, and cuda c accelerated methods for pre-processing and post-processing of mainstream models. Most of the model transformation process is torch-&amp;gt;onnx-&amp;gt;tensorrt. There are two ways to obtain onnx files:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;According to the network disk provided by this repository, download ONNX directly&lt;/li&gt; &#xA; &lt;li&gt;Follow the instructions provided in this repository to manually export ONNX from the relevant source code framework.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR&#xA;    pytorch/tensorflow --&amp;gt;onnx--&amp;gt;tensorrt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Update&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2023.01.01 🔥 update yolov3, yolov4, yolov5, yolov6&lt;/li&gt; &#xA; &lt;li&gt;2023.01.04 🍅 update yolov7, yolox, yolor&lt;/li&gt; &#xA; &lt;li&gt;2023.01.05 🎉 update u2net, libfacedetection&lt;/li&gt; &#xA; &lt;li&gt;2023.01.08 🚀 The whole network is the first to support yolov8&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Platforms: Windows and Linux. The following environments have been tested：&lt;br&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Ubuntu18.04&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;cuda11.3&lt;/li&gt; &#xA;  &lt;li&gt;cudnn8.2.0&lt;/li&gt; &#xA;  &lt;li&gt;gcc7.5.0&lt;/li&gt; &#xA;  &lt;li&gt;tensorrt8.4.2.4&lt;/li&gt; &#xA;  &lt;li&gt;opencv3.x or 4.x&lt;/li&gt; &#xA;  &lt;li&gt;cmake3.10.2&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Windows10&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;cuda11.3&lt;/li&gt; &#xA;  &lt;li&gt;cudnn8.2.0&lt;/li&gt; &#xA;  &lt;li&gt;visual studio 2017 or 2019 or 2022&lt;/li&gt; &#xA;  &lt;li&gt;tensorrt8.4.2.4&lt;/li&gt; &#xA;  &lt;li&gt;opencv3.x or 4.x&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Python environment(Optional）&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# install miniconda first&#xA;conda create -n tensorrt-alpha python==3.8 -y&#xA;conda activate tensorrt-alpha&#xA;git clone https://github.com/FeiYull/tensorrt-alpha&#xA;cd tensorrt-alpha&#xA;pip install -r requirements.txt  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;Ubuntu18.04&lt;/h3&gt; &#xA;&lt;p&gt;set your TensorRT_ROOT path:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/FeiYull/tensorrt-alpha&#xA;cd tensorrt-alpha/cmake&#xA;vim common.cmake&#xA;# set var TensorRT_ROOT to your path in line 20, eg:&#xA;# set(TensorRT_ROOT /root/TensorRT-8.4.2.4)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;start to build project: For example:&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/yolov8/README.md&#34;&gt;yolov8&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Windows10&lt;/h3&gt; &#xA;&lt;p&gt;waiting for update&lt;/p&gt; &#xA;&lt;h2&gt;Onnx&lt;/h2&gt; &#xA;&lt;p&gt;At present, more than 30 models have been implemented, and some onnx files of them are organized as follows:&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;model&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;weiyun&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;google driver&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/yolov3/README.md&#34;&gt;yolov3&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/yolov4/README.md&#34;&gt;yolov4&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/yolov5/README.md&#34;&gt;yolov5&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/yolov6/README.md&#34;&gt;yolov6&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/yolov7/README.md&#34;&gt;yolov7&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/yolov8/README.md&#34;&gt;yolov8&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/yolox/README.md&#34;&gt;yolox&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/yolor/README.md&#34;&gt;yolor&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/u2net/README.md&#34;&gt;u2net&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/libfacedetection/README.md&#34;&gt;libfacedet&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/facemesh/README.md&#34;&gt;facemesh&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://share.weiyun.com/3T3mZKBm&#34;&gt;weiyun&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-8phZHkx_Z274UVqgw6Ma-6u5AKmqCOv?usp=sharing&#34;&gt;google driver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;more...(🚀: I will be back soon!)&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Some Precision Alignment Renderings Comparison&lt;/h2&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;!--块级封装--&gt; &#xA; &lt;center&gt; &#xA;  &lt;!--将图片和文字居中--&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/yolov8n-Offical(left)vsOurs(right).jpg&#34; alt=&#34;无法显示图片时显示的文字&#34; style=&#34;zoom:100%&#34;&gt; &#xA;  &lt;br&gt; &#xA;  &lt;!--换行--&gt; &#xA;  &lt;center&gt;&#xA;   yolov8n : Offical( left ) vs Ours( right ) &#xA;   &lt;!--标题--&gt;&#xA;  &lt;/center&gt; &#xA;  &lt;br&gt; &#xA;  &lt;!--换行--&gt; &#xA;  &lt;br&gt; &#xA;  &lt;!--换行--&gt; &#xA;  &lt;center&gt; &#xA;   &lt;!--将图片和文字居中--&gt; &#xA;   &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/yolov7-tiny-Offical(left)vsOurs(right).jpg&#34; alt=&#34;无法显示图片时显示的文字&#34; style=&#34;zoom:100%&#34;&gt; &#xA;   &lt;br&gt; &#xA;   &lt;!--换行--&gt; &#xA;   &lt;center&gt;&#xA;    yolov7-tiny : Offical( left ) vs Ours( right ) &#xA;    &lt;!--标题--&gt;&#xA;   &lt;/center&gt; &#xA;   &lt;br&gt; &#xA;   &lt;!--换行--&gt; &#xA;   &lt;br&gt; &#xA;   &lt;!--换行--&gt; &#xA;   &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/yolov5s-Offical(left)vsOurs(right).jpg&#34; alt=&#34;无法显示图片时显示的文字&#34; style=&#34;zoom:100%&#34;&gt; &#xA;   &lt;br&gt; &#xA;   &lt;!--换行--&gt; &#xA;   &lt;center&gt;&#xA;    yolov5s : Offical( left ) vs Ours( right ) &#xA;    &lt;!--标题--&gt;&#xA;   &lt;/center&gt; &#xA;   &lt;br&gt; &#xA;   &lt;!--换行--&gt; &#xA;   &lt;br&gt; &#xA;   &lt;!--换行--&gt; &#xA;   &lt;img src=&#34;https://raw.githubusercontent.com/FeiYull/TensorRT-Alpha/main/.github/libfacedet-Offical(left)vsOurs(right-topk-4000).jpg&#34; alt=&#34;无法显示图片时显示的文字&#34; style=&#34;zoom:100%&#34;&gt; &#xA;   &lt;br&gt; &#xA;   &lt;!--换行--&gt; &#xA;   &lt;center&gt;&#xA;    libfacedetction : Offical( left ) vs Ours( right topK:4000) &#xA;    &lt;!--标题--&gt;&#xA;   &lt;/center&gt; &#xA;   &lt;br&gt; &#xA;   &lt;!--换行--&gt; &#xA;   &lt;br&gt; &#xA;   &lt;!--换行--&gt; &#xA;  &lt;/center&gt; &#xA; &lt;/center&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Reference&lt;/h2&gt; &#xA;&lt;p&gt;[0].&lt;a href=&#34;https://github.com/NVIDIA/TensorRT&#34;&gt;https://github.com/NVIDIA/TensorRT&lt;/a&gt;&lt;br&gt; [1].&lt;a href=&#34;https://github.com/onnx/onnx-tensorrt&#34;&gt;https://github.com/onnx/onnx-tensorrt&lt;/a&gt;&lt;br&gt; [2].&lt;a href=&#34;https://github.com/NVIDIA-AI-IOT/torch2trt&#34;&gt;https://github.com/NVIDIA-AI-IOT/torch2trt&lt;/a&gt;&lt;br&gt; [3].&lt;a href=&#34;https://github.com/shouxieai/tensorRT_Pro&#34;&gt;https://github.com/shouxieai/tensorRT_Pro&lt;/a&gt;&lt;br&gt; [4].&lt;a href=&#34;https://github.com/opencv/opencv_zoo&#34;&gt;https://github.com/opencv/opencv_zoo&lt;/a&gt;&lt;br&gt;&lt;/p&gt;</summary>
  </entry>
</feed>