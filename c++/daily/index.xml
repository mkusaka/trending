<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C++ Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-08-06T01:30:48Z</updated>
  <subtitle>Daily Trending of C++ in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>duixcom/Duix-Mobile</title>
    <updated>2025-08-06T01:30:48Z</updated>
    <id>tag:github.com,2025-08-06:/duixcom/Duix-Mobile</id>
    <link href="https://github.com/duixcom/Duix-Mobile" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🚀 全网效果最好的移动端【实时对话数字人】。 支持本地部署、多模态交互（语音、文本、表情），响应速度低于 1.5 秒，适用于直播、教学、客服、金融、政务等对隐私与实时性要求极高的场景。开箱即用，开发者友好。&lt;/p&gt;&lt;hr&gt;&lt;p&gt;简体中文 | &lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/README_en.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1t2g7z3ERK/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/main_video_thumbnail.jpg&#34; alt=&#34;Duix Mobile thumbnail&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;🚀🚀🚀 Duix Mobile —— 全网效果最好的移动端【实时对话数字人】&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;📱 跨平台支持：iOS / Android / 平板 / 车载系统 / VR设备 / IoT终端 / 大屏交互等&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;😎 Duix Mobile 是什么？&lt;/h2&gt; &#xA;&lt;p&gt;本次由硅基智能开源的 Duix Mobile，是一个&lt;strong&gt;可部署在手机或嵌入式屏幕的实时对话数字人 SDK&lt;/strong&gt;。&lt;/p&gt; &#xA;&lt;p&gt;开发者可以轻松集成自有或第三方的大语言模型（LLM）、语音识别（ASR）和语音合成（TTS）服务，快速构建能与用户自然对话的数字人界面。&lt;/p&gt; &#xA;&lt;p&gt;Duix Mobile 支持一键跨平台部署（Android/iOS），上手门槛低，适用于智能客服、虚拟医生、虚拟律师、虚拟陪伴、虚拟教学等多种应用场景。&lt;/p&gt; &#xA;&lt;p&gt;现在就开始构建你自己的交互数字人，大幅提升你的产品业绩吧！&lt;/p&gt; &#xA;&lt;h2&gt;🤩 有哪些应用场景？&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Duix Mobile 在 Andorid/iOS/Pad/大屏等设备下可以支持到多种实际应用场景；&lt;/li&gt; &#xA; &lt;li&gt;大幅度提升你的产品表现力，从而提升你的营收水平。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/example.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🥳 有什么优势？&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;仿真数字人体验&lt;/strong&gt;：自然呈现面部表情、语调和情绪共鸣，打造「像人一样」的 AI 对话。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;支持流式音频&lt;/strong&gt;：边合成、边说话，支持中途打断、抢话，让数字人不仅会说话，而且更像「人」。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;极致响应速度&lt;/strong&gt;：数字人响应延迟低于 120ms（测试设备为骁龙® 8 Gen 2 SoC），带来毫秒级流畅互动体验。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;成本友好，随处部署&lt;/strong&gt;：轻量化运行，资源占用极低，轻松适配手机、平板、智能屏等终端。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;无惧弱网环境&lt;/strong&gt;：核心处理本地完成，对网络依赖极低，尤其适合金融、政务、法律等高稳定性场景。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;全行业适配&lt;/strong&gt;：模块化设计，支持快速定制，轻松打造各行业专属数字人解决方案。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;📑 开发文档&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Android 开发者：&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/duix-android/dh_aigc_android/README.md&#34;&gt;Duix Mobile&amp;nbsp;SDK for Android&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;iOS 开发者：&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/duix-ios/GJLocalDigitalDemo/README.md&#34;&gt;Duix Mobile&amp;nbsp;SDK for iOS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;💚 实际部署案例&lt;/h2&gt; &#xA;&lt;p&gt;前往哔哩哔哩查看：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1QSgczPESS&#34;&gt;《程序员与奶奶的虚拟重逢》&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Dbg3zbExC/&#34;&gt;《Grok 遇见 Duix，谁才是你的真女友？》&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;✨ 公用数字人下载&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;以下是 Duix 提供的 8 个公有数字人，可供下载和集成。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/avatar/1.png&#34; alt=&#34;Model 1&#34; width=&#34;100%&#34;&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/duixcom/Duix.mobile/releases/download/v1.0.0/guilv0515_20240516_optim_m80.zip&#34;&gt;&lt;button&gt;下载&lt;/button&gt;&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/avatar/2.png&#34; alt=&#34;Model 2&#34; width=&#34;100%&#34;&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/duixcom/Duix.mobile/releases/download/v1.0.0/guilv3_20240511_optim_m80.zip&#34;&gt;&lt;button&gt;下载&lt;/button&gt;&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/avatar/3.png&#34; alt=&#34;Model 3&#34; width=&#34;100%&#34;&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/duixcom/Duix.mobile/releases/download/v1.0.0/wuhao_20240418_optim_m80.zip&#34;&gt;&lt;button&gt;下载&lt;/button&gt;&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/avatar/8.png&#34; alt=&#34;Model 8&#34; width=&#34;100%&#34;&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/duixcom/Duix.mobile/releases/download/v1.0.0/siyao_20240418_optim_m80.zip&#34;&gt;&lt;button&gt;下载&lt;/button&gt;&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/avatar/5.jpg&#34; alt=&#34;Model 5&#34; width=&#34;100%&#34;&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/duixcom/Duix.mobile/releases/download/v1.0.0/696309955760197_fdc4a25a012c99789cd1ec95f5faf0de_optim_m80.zip&#34;&gt;&lt;button&gt;下载&lt;/button&gt;&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/avatar/6.png&#34; alt=&#34;Model 6&#34; width=&#34;100%&#34;&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/duixcom/Duix.mobile/releases/download/v1.0.0/696303589556293_268307125eeeff7e2c85461dd8c3ac52_optim_m80.zip&#34;&gt;&lt;button&gt;下载&lt;/button&gt;&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/avatar/7.jpg&#34; alt=&#34;Model 7&#34; width=&#34;100%&#34;&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/duixcom/Duix.mobile/releases/download/v1.0.0/696326678212677_9d4da9041e81466f5dadc99ddd1e3bd9.zip&#34;&gt;&lt;button&gt;下载&lt;/button&gt;&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/avatar/4.png&#34; alt=&#34;Model 4&#34; width=&#34;100%&#34;&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/duixcom/Duix.mobile/releases/download/v1.0.0/651686686687301_846161843f9ffdaaeace716bf3436be5_optim_m80.zip&#34;&gt;&lt;button&gt;下载&lt;/button&gt;&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;🤗 如何定制私有数字人？&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;部署遇到问题？想要定制私有化数字人？&lt;/li&gt; &#xA; &lt;li&gt;请发邮件至邮箱：&lt;code&gt;amos.young@duix.com&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;或者加入技术支持群：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix-Mobile/main/res/contact.png&#34; alt=&#34;企业微信&#34; width=&#34;260&#34;&gt; &#xA;&lt;h2&gt;🙌 常见问题解答&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;我可以集成自己的大模型（LLM）、语音识别（ASR）和语音合成（TTS）吗？&lt;/summary&gt; &#xA; &lt;p&gt;当然可以，你可以将 Duix Mobile 的数字人与你的自己 LLM、ASR 和 TTS 进行集成。&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;是否支持「唇动同步」？&lt;/summary&gt; &#xA; &lt;p&gt;支持。&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;是否支持「多语种字幕」？&lt;/summary&gt; &#xA; &lt;p&gt;支持。&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;我如何创建自定义数字人？&lt;/summary&gt; &#xA; &lt;p&gt;我们提供了 8 个公有数字人，如需额外定制，请联系上方的企业微信。&lt;/p&gt; &#xA; &lt;p&gt;通常录制 15 秒至 2 分钟的视频即可完成定制过程，简单便捷。&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;是否支持流式音频？&lt;/summary&gt; &#xA; &lt;p&gt;支持，流式音频已于 2025 年 7 月 17 日版本更新中上线。&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;是否提供数字人语音开始和结束的回调？&lt;/summary&gt; &#xA; &lt;p&gt;是的，我们提供语音开始和结束的回调文档。&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;💡&amp;nbsp;版本计划&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 流式音频能力，2025 年 7 月 16 日上线&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 算法响应优化，预计时间：2025 年 8 月 30 日前&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;📚 相关开源仓库&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GitHub: &lt;a href=&#34;https://github.com/duixcom/Duix-Mobile&#34;&gt;https://github.com/duixcom/Duix-Mobile&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Gitee: &lt;a href=&#34;https://gitee.com/duix/Duix-Mobile&#34;&gt;https://gitee.com/duix/Duix-Mobile&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;GitCode: &lt;a href=&#34;https://gitcode.com/openguiji/duix-mobile&#34;&gt;https://gitcode.com/openguiji/duix-mobile&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>deepseek-ai/FlashMLA</title>
    <updated>2025-08-06T01:30:48Z</updated>
    <id>tag:github.com,2025-08-06:/deepseek-ai/FlashMLA</id>
    <link href="https://github.com/deepseek-ai/FlashMLA" rel="alternate"></link>
    <summary type="html">&lt;p&gt;FlashMLA: Efficient MLA kernels&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FlashMLA&lt;/h1&gt; &#xA;&lt;h2&gt;Performance Update (2025.04.22)&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re excited to announce the new release of Flash MLA, which delivers 5% ~ 15% performance improvement on compute-bound workloads, achieving up to 660 TFlops on NVIDIA H800 SXM5 GPUs. The interface of the new version is fully compatible with the old one. Just switch to the new version and enjoy the instant speedup! 🚀🚀🚀&lt;/p&gt; &#xA;&lt;p&gt;Besides, we&#39;d love to share the technical details behind the new kernel! Check out our deep-dive write-up &lt;a href=&#34;https://raw.githubusercontent.com/deepseek-ai/FlashMLA/main/docs/20250422-new-kernel-deep-dive.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The new kernel primarily targets compute-intensive settings (where the number of q heads $\times$ the number of q tokens per request (if MTP is disabled then it&#39;s 1) $\ge 64$). For memory-bound cases, we recommend using version &lt;a href=&#34;https://github.com/deepseek-ai/FlashMLA/tree/b31bfe72a83ea205467b3271a5845440a03ed7cb&#34;&gt;b31bfe7&lt;/a&gt; for optimal performance.&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;FlashMLA is an efficient MLA decoding kernel for Hopper GPUs, optimized for variable-length sequences serving.&lt;/p&gt; &#xA;&lt;p&gt;Currently released:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;BF16, FP16&lt;/li&gt; &#xA; &lt;li&gt;Paged kvcache with block size of 64&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Hopper GPUs&lt;/li&gt; &#xA; &lt;li&gt;CUDA 12.3 and above &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;But we highly recommend 12.8 or above for the best performance&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;PyTorch 2.0 and above&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;h3&gt;Install&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -v .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Benchmark&lt;/h3&gt; &#xA;&lt;h4&gt;Testing MLA Decoding&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python tests/test_flash_mla_sm90.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Testing MLA Forward/Backward&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python tests/test_fmha_sm100.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It is able up to 3000 GB/s in memory-bound configuration and 660 TFLOPS in computation-bound configuration on H800 SXM5, using CUDA 12.8.&lt;/p&gt; &#xA;&lt;p&gt;Note. For memory-bound cases, we recommend using version &lt;a href=&#34;https://github.com/deepseek-ai/FlashMLA/tree/b31bfe72a83ea205467b3271a5845440a03ed7cb&#34;&gt;b31bfe7&lt;/a&gt; for optimal performance.&lt;/p&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from flash_mla import get_mla_metadata, flash_mla_with_kvcache&#xA;&#xA;tile_scheduler_metadata, num_splits = get_mla_metadata(cache_seqlens, s_q * h_q // h_kv, h_kv)&#xA;&#xA;for i in range(num_layers):&#xA;    ...&#xA;    o_i, lse_i = flash_mla_with_kvcache(&#xA;        q_i, kvcache_i, block_table, cache_seqlens, dv,&#xA;        tile_scheduler_metadata, num_splits, causal=True,&#xA;    )&#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;FlashMLA is inspired by &lt;a href=&#34;https://github.com/dao-AILab/flash-attention/&#34;&gt;FlashAttention 2&amp;amp;3&lt;/a&gt; and &lt;a href=&#34;https://github.com/nvidia/cutlass&#34;&gt;cutlass&lt;/a&gt; projects.&lt;/p&gt; &#xA;&lt;h2&gt;Community Support&lt;/h2&gt; &#xA;&lt;h3&gt;MetaX&lt;/h3&gt; &#xA;&lt;p&gt;For MetaX GPUs, visit the official website: &lt;a href=&#34;https://www.metax-tech.com&#34;&gt;MetaX&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The corresponding FlashMLA version can be found at: &lt;a href=&#34;https://github.com/MetaX-MACA/FlashMLA&#34;&gt;MetaX-MACA/FlashMLA&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Moore Threads&lt;/h3&gt; &#xA;&lt;p&gt;For the Moore Threads GPU, visit the official website: &lt;a href=&#34;https://www.mthreads.com/&#34;&gt;Moore Threads&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The corresponding FlashMLA version is available on GitHub: &lt;a href=&#34;https://github.com/MooreThreads/MT-flashMLA&#34;&gt;MooreThreads/MT-flashMLA&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Hygon DCU&lt;/h3&gt; &#xA;&lt;p&gt;For the Hygon DCU, visit the official website: &lt;a href=&#34;https://developer.sourcefind.cn/&#34;&gt;Hygon Developer&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The corresponding FlashMLA version is available here: &lt;a href=&#34;https://developer.sourcefind.cn/codes/OpenDAS/MLAttention&#34;&gt;OpenDAS/MLAttention&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Intellifusion&lt;/h3&gt; &#xA;&lt;p&gt;For the Intellifusion NNP, visit the official website: &lt;a href=&#34;https://www.intellif.com&#34;&gt;Intellifusion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The corresponding FlashMLA version is available on Gitee: &lt;a href=&#34;https://gitee.com/Intellifusion_2025/tyllm/blob/master/python/tylang/flash_mla.py&#34;&gt;Intellifusion/tyllm&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Iluvatar Corex&lt;/h3&gt; &#xA;&lt;p&gt;For Iluvatar Corex GPUs, visit the official website: &lt;a href=&#34;https://www.iluvatar.com&#34;&gt;Iluvatar Corex&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The corresponding FlashMLA version is available on GitHub: &lt;a href=&#34;https://github.com/Deep-Spark/FlashMLA/tree/iluvatar_flashmla&#34;&gt;Deep-Spark/FlashMLA&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;AMD Instinct&lt;/h3&gt; &#xA;&lt;p&gt;For AMD Instinct GPUs, visit the official website: &lt;a href=&#34;https://www.amd.com/en/products/accelerators/instinct.html&#34;&gt;AMD Instinct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The corresponding FlashMLA version can be found at: &lt;a href=&#34;https://github.com/ROCm/aiter/raw/main/aiter/mla.py&#34;&gt;AITER/MLA&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{flashmla2025,&#xA;      title={FlashMLA: Efficient MLA decoding kernels},&#xA;      author={Jiashi Li, Shengyu Liu},&#xA;      year={2025},&#xA;      publisher = {GitHub},&#xA;      howpublished = {\url{https://github.com/deepseek-ai/FlashMLA}},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>