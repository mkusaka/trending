<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Haskell Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-28T01:37:35Z</updated>
  <subtitle>Daily Trending of Haskell in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Bodigrim/bitvec</title>
    <updated>2023-03-28T01:37:35Z</updated>
    <id>tag:github.com,2023-03-28:/Bodigrim/bitvec</id>
    <link href="https://github.com/Bodigrim/bitvec" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bit vectors: 8x less memory, up to 1000x faster than Vector Bool&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitvec &lt;a href=&#34;https://hackage.haskell.org/package/bitvec&#34;&gt;&lt;img src=&#34;https://img.shields.io/hackage/v/bitvec.svg?sanitize=true&#34; alt=&#34;Hackage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.stackage.org/lts/package/bitvec&#34;&gt;&lt;img src=&#34;https://www.stackage.org/package/bitvec/badge/lts&#34; alt=&#34;Stackage LTS&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.stackage.org/nightly/package/bitvec&#34;&gt;&lt;img src=&#34;https://www.stackage.org/package/bitvec/badge/nightly&#34; alt=&#34;Stackage Nightly&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;A newtype over &lt;code&gt;Bool&lt;/code&gt; with a better &lt;code&gt;Vector&lt;/code&gt; instance: 8x less memory, up to 1000x faster.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://hackage.haskell.org/package/vector&#34;&gt;&lt;code&gt;vector&lt;/code&gt;&lt;/a&gt; package represents unboxed arrays of &lt;code&gt;Bool&lt;/code&gt;s spending 1 byte (8 bits) per boolean. This library provides a newtype wrapper &lt;code&gt;Bit&lt;/code&gt; and a custom instance of an unboxed &lt;code&gt;Vector&lt;/code&gt;, which packs bits densely, achieving an &lt;strong&gt;8x smaller memory footprint.&lt;/strong&gt; The performance stays mostly the same; the most significant degradation happens for random writes (up to 10% slower). On the other hand, for certain bulk bit operations &lt;code&gt;Vector Bit&lt;/code&gt; is up to 1000x faster than &lt;code&gt;Vector Bool&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Thread safety&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Data.Bit&lt;/code&gt; is faster, but writes and flips are thread-unsafe. This is because naive updates are not atomic: they read the whole word from memory, then modify a bit, then write the whole word back.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Data.Bit.ThreadSafe&lt;/code&gt; is slower (usually 10-20%), but writes and flips are thread-safe.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;p&gt;Consider the following (very naive) implementation of &lt;a href=&#34;https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes&#34;&gt;the sieve of Eratosthenes&lt;/a&gt;. It returns a vector with &lt;code&gt;True&lt;/code&gt; at prime indices and &lt;code&gt;False&lt;/code&gt; at composite indices.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;import Control.Monad&#xA;import Control.Monad.ST&#xA;import qualified Data.Vector.Unboxed as U&#xA;import qualified Data.Vector.Unboxed.Mutable as MU&#xA;&#xA;eratosthenes :: U.Vector Bool&#xA;eratosthenes = runST $ do&#xA;  let len = 100&#xA;  sieve &amp;lt;- MU.replicate len True&#xA;  MU.write sieve 0 False&#xA;  MU.write sieve 1 False&#xA;  forM_ [2 .. floor (sqrt (fromIntegral len))] $ \p -&amp;gt; do&#xA;    isPrime &amp;lt;- MU.read sieve p&#xA;    when isPrime $&#xA;      forM_ [2 * p, 3 * p .. len - 1] $ \i -&amp;gt;&#xA;        MU.write sieve i False&#xA;  U.unsafeFreeze sieve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can switch from &lt;code&gt;Bool&lt;/code&gt; to &lt;code&gt;Bit&lt;/code&gt; just by adding newtype constructors:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;import Data.Bit&#xA;&#xA;import Control.Monad&#xA;import Control.Monad.ST&#xA;import qualified Data.Vector.Unboxed as U&#xA;import qualified Data.Vector.Unboxed.Mutable as MU&#xA;&#xA;eratosthenes :: U.Vector Bit&#xA;eratosthenes = runST $ do&#xA;  let len = 100&#xA;  sieve &amp;lt;- MU.replicate len (Bit True)&#xA;  MU.write sieve 0 (Bit False)&#xA;  MU.write sieve 1 (Bit False)&#xA;  forM_ [2 .. floor (sqrt (fromIntegral len))] $ \p -&amp;gt; do&#xA;    Bit isPrime &amp;lt;- MU.read sieve p&#xA;    when isPrime $&#xA;      forM_ [2 * p, 3 * p .. len - 1] $ \i -&amp;gt;&#xA;        MU.write sieve i (Bit False)&#xA;  U.unsafeFreeze sieve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;Bit&lt;/code&gt;-based implementation requires 8x less memory to store the vector. For large sizes it allows to crunch more data in RAM without swapping. For smaller arrays it helps to fit into CPU caches.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;&amp;gt; listBits eratosthenes&#xA;[2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are several high-level helpers, digesting bits in bulk, which makes them up to 64x faster than the respective counterparts for &lt;code&gt;Vector Bool&lt;/code&gt;. One can query the population count (popcount) of a vector (giving us &lt;a href=&#34;https://en.wikipedia.org/wiki/Prime-counting_function&#34;&gt;the prime-counting function&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;&amp;gt; countBits eratosthenes&#xA;25&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And vice versa, query an address of the &lt;em&gt;n&lt;/em&gt;-th set bit (which corresponds to the &lt;em&gt;n&lt;/em&gt;-th prime number here):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;&amp;gt; nthBitIndex (Bit True) 10 eratosthenes&#xA;Just 29&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;One may notice that the order of the inner traversal by &lt;code&gt;i&lt;/code&gt; does not matter and get tempted to run it in several parallel threads. In this case it is vital to switch from &lt;code&gt;Data.Bit&lt;/code&gt; to &lt;code&gt;Data.Bit.ThreadSafe&lt;/code&gt;, because the former is thread-unsafe with regards to writes. There is a moderate performance penalty (usually 10-20%) for using the thread-safe interface.&lt;/p&gt; &#xA;&lt;h2&gt;Sets&lt;/h2&gt; &#xA;&lt;p&gt;Bit vectors can be used as a blazingly fast representation of sets, as long as their elements are &lt;code&gt;Enum&lt;/code&gt;eratable and sufficiently dense, leaving &lt;code&gt;IntSet&lt;/code&gt; far behind.&lt;/p&gt; &#xA;&lt;p&gt;For example, consider three possible representations of a set of &lt;code&gt;Word16&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;As an &lt;code&gt;IntSet&lt;/code&gt; with a readily available &lt;code&gt;union&lt;/code&gt; function.&lt;/li&gt; &#xA; &lt;li&gt;As a 64k-long unboxed &lt;code&gt;Vector Bool&lt;/code&gt;, implementing union as &lt;code&gt;zipWith (||)&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;As a 64k-long unboxed &lt;code&gt;Vector Bit&lt;/code&gt;, implementing union as &lt;code&gt;zipBits (.|.)&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When the &lt;code&gt;simd&lt;/code&gt; flag is enabled, according to our benchmarks (see &lt;code&gt;bench&lt;/code&gt; folder), the union of &lt;code&gt;Vector Bit&lt;/code&gt; evaluates 24x-36x faster than the union of not-too-sparse &lt;code&gt;IntSet&lt;/code&gt;s and stunningly outperforms &lt;code&gt;Vector Bool&lt;/code&gt; by 500x-1000x.&lt;/p&gt; &#xA;&lt;h2&gt;Binary polynomials&lt;/h2&gt; &#xA;&lt;p&gt;Binary polynomials are polynomials with coefficients modulo 2. Their applications include coding theory and cryptography. While one can successfully implement them with the &lt;a href=&#34;https://hackage.haskell.org/package/poly&#34;&gt;&lt;code&gt;poly&lt;/code&gt;&lt;/a&gt; package, operating on &lt;code&gt;UPoly Bit&lt;/code&gt;, this package provides even faster arithmetic routines exposed via the &lt;code&gt;F2Poly&lt;/code&gt; data type and its instances.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;&amp;gt; :set -XBinaryLiterals&#xA;&amp;gt; -- (1 + x) * (1 + x + x^2) = 1 + x^3 (mod 2)&#xA;&amp;gt; 0b11 * 0b111 :: F2Poly&#xA;F2Poly {unF2Poly = [1,0,0,1]}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use &lt;code&gt;fromInteger&lt;/code&gt; / &lt;code&gt;toInteger&lt;/code&gt; to convert binary polynomials from &lt;code&gt;Integer&lt;/code&gt; to &lt;code&gt;F2Poly&lt;/code&gt; and back.&lt;/p&gt; &#xA;&lt;h2&gt;Package flags&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Flag &lt;code&gt;simd&lt;/code&gt;, enabled by default.&lt;/p&gt; &lt;p&gt;Use a C SIMD implementation for the ultimate performance of &lt;code&gt;zipBits&lt;/code&gt;, &lt;code&gt;invertBits&lt;/code&gt; and &lt;code&gt;countBits&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Similar packages&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://hackage.haskell.org/package/bv&#34;&gt;&lt;code&gt;bv&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://hackage.haskell.org/package/bv-little&#34;&gt;&lt;code&gt;bv-little&lt;/code&gt;&lt;/a&gt; do not offer mutable vectors.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://hackage.haskell.org/package/array&#34;&gt;&lt;code&gt;array&lt;/code&gt;&lt;/a&gt; is memory-efficient for &lt;code&gt;Bool&lt;/code&gt;, but lacks a handy &lt;code&gt;Vector&lt;/code&gt; interface and is not thread-safe.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Additional resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bit vectors without compromises&lt;/strong&gt;, Haskell Love, 31.07.2020: &lt;a href=&#34;https://github.com/Bodigrim/my-talks/raw/master/haskelllove2020/slides.pdf&#34;&gt;slides&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/HhpH8DKFBls&#34;&gt;video&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>