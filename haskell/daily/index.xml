<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Haskell Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-14T01:35:07Z</updated>
  <subtitle>Daily Trending of Haskell in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>input-output-hk/marlowe-cardano</title>
    <updated>2022-09-14T01:35:07Z</updated>
    <id>tag:github.com,2022-09-14:/input-output-hk/marlowe-cardano</id>
    <link href="https://github.com/input-output-hk/marlowe-cardano" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Marlowe smart contract language Cardano implementation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&#34;https://github.com/input-output-hk/marlowe-cardano&#34;&gt;Marlowe on the Cardano Blockchain&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt; &#xA; &lt;div id=&#34;toctitle&#34;&gt;&#xA;  Table of Contents&#xA; &lt;/div&gt; &#xA; &lt;ul class=&#34;sectlevel1&#34;&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#_documentation&#34;&gt;Documentation&lt;/a&gt; &#xA;   &lt;ul class=&#34;sectlevel2&#34;&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#_user_documentation&#34;&gt;User documentation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#_working_with_the_project&#34;&gt;Working with the project&lt;/a&gt; &#xA;   &lt;ul class=&#34;sectlevel2&#34;&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#_how_to_submit_an_issue&#34;&gt;How to submit an issue&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#how-to-develop&#34;&gt;How to develop and contribute to the project&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#_how_to_depend_on_the_project_from_another_haskell_project&#34;&gt;How to depend on the project from another Haskell project&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#_how_to_build_the_projects_artifacts&#34;&gt;How to build the project’s artifacts&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#_deployment&#34;&gt;Deployment&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#nix-advice&#34;&gt;Nix&lt;/a&gt; &#xA;   &lt;ul class=&#34;sectlevel2&#34;&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#iohk-binary-cache&#34;&gt;How to set up the IOHK binary caches&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#_nix_on_macos&#34;&gt;Nix on macOS&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#nix-build-attributes&#34;&gt;Which attributes to use to build different artifacts&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#_licensing&#34;&gt;Licensing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/div&gt; &#xA;&lt;div id=&#34;preamble&#34;&gt; &#xA; &lt;div class=&#34;sectionbody&#34;&gt; &#xA;  &lt;div class=&#34;paragraph&#34;&gt; &#xA;   &lt;p&gt;Marlowe is a platform for financial products as smart contracts. Marlowe-Cardano is an implementation of Marlowe for the Cardano blockchain, built on top of Plutus.&lt;/p&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div class=&#34;paragraph&#34;&gt; &#xA;   &lt;p&gt;This repository contains:&lt;/p&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div class=&#34;ulist&#34;&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt; &lt;p&gt;The implementation of the Marlowe domain-specific language.&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;li&gt; &lt;p&gt;Tools for working with Marlowe, including static analysis.&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;li&gt; &lt;p&gt;A selection of examples using Marlowe, including a number based on the ACTUS financial standard.&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;li&gt; &lt;p&gt;The Marlowe Playground, a web-based playground for learning and writing Marlowe Applications.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;/ul&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div class=&#34;admonitionblock important&#34;&gt; &#xA;   &lt;table&gt; &#xA;    &lt;tbody&gt;&#xA;     &lt;tr&gt; &#xA;      &lt;td class=&#34;icon&#34;&gt; &#xA;       &lt;div class=&#34;title&#34;&gt;&#xA;        Important&#xA;       &lt;/div&gt; &lt;/td&gt; &#xA;      &lt;td class=&#34;content&#34;&gt; &#xA;       &lt;div class=&#34;paragraph&#34;&gt; &#xA;        &lt;p&gt;The rest of this README is focussed on people who want to develop or contribute to Marlowe.&lt;/p&gt; &#xA;       &lt;/div&gt; &#xA;       &lt;div class=&#34;paragraph&#34;&gt; &#xA;        &lt;p&gt;For people who want to &lt;strong&gt;use&lt;/strong&gt; Marlowe, please consult the &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#user-documentation&#34;&gt;[user-documentation]&lt;/a&gt;.&lt;/p&gt; &#xA;       &lt;/div&gt; &lt;/td&gt; &#xA;     &lt;/tr&gt; &#xA;    &lt;/tbody&gt;&#xA;   &lt;/table&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div id=&#34;cache-warning&#34; class=&#34;admonitionblock important&#34;&gt; &#xA;   &lt;table&gt; &#xA;    &lt;tbody&gt;&#xA;     &lt;tr&gt; &#xA;      &lt;td class=&#34;icon&#34;&gt; &#xA;       &lt;div class=&#34;title&#34;&gt;&#xA;        Important&#xA;       &lt;/div&gt; &lt;/td&gt; &#xA;      &lt;td class=&#34;content&#34;&gt; &#xA;       &lt;div class=&#34;paragraph&#34;&gt; &#xA;        &lt;p&gt;DO NOT IGNORE THIS&lt;/p&gt; &#xA;       &lt;/div&gt; &#xA;       &lt;div class=&#34;paragraph&#34;&gt; &#xA;        &lt;p&gt;If you want to use Nix with this project, make sure to set up the &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#iohk-binary-cache&#34;&gt;IOHK binary cache&lt;/a&gt;. If you do not do this, you will end up building GHC, which takes several hours. If you find yourself building GHC, STOP and fix the cache.&lt;/p&gt; &#xA;       &lt;/div&gt; &lt;/td&gt; &#xA;     &lt;/tr&gt; &#xA;    &lt;/tbody&gt;&#xA;   &lt;/table&gt; &#xA;  &lt;/div&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;div class=&#34;sect1&#34;&gt; &#xA; &lt;h2 id=&#34;_documentation&#34;&gt;Documentation&lt;/h2&gt; &#xA; &lt;div class=&#34;sectionbody&#34;&gt; &#xA;  &lt;div class=&#34;sect2&#34;&gt; &#xA;   &lt;h3 id=&#34;_user_documentation&#34;&gt;User documentation&lt;/h3&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;The main documentation for the whole Plutus ecosystem is located &lt;a href=&#34;https://plutus.readthedocs.io/en/latest/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;  &lt;/div&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;div class=&#34;sect1&#34;&gt; &#xA; &lt;h2 id=&#34;_working_with_the_project&#34;&gt;Working with the project&lt;/h2&gt; &#xA; &lt;div class=&#34;sectionbody&#34;&gt; &#xA;  &lt;div class=&#34;sect2&#34;&gt; &#xA;   &lt;h3 id=&#34;_how_to_submit_an_issue&#34;&gt;How to submit an issue&lt;/h3&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;Issues can be filed in the &lt;a href=&#34;https://github.com/input-output-hk/marlowe-cardano/issues&#34;&gt;GitHub Issue tracker&lt;/a&gt;.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;However, note that this is pre-release software, so we will not usually be providing support.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div class=&#34;sect2&#34;&gt; &#xA;   &lt;h3 id=&#34;how-to-develop&#34;&gt;How to develop and contribute to the project&lt;/h3&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/CONTRIBUTING.html&#34;&gt;CONTRIBUTING&lt;/a&gt;, which describes our processes in more detail including development environments; and &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/ARCHITECTURE.html&#34;&gt;ARCHITECTURE&lt;/a&gt;, which describes the structure of the repository.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div class=&#34;sect2&#34;&gt; &#xA;   &lt;h3 id=&#34;_how_to_depend_on_the_project_from_another_haskell_project&#34;&gt;How to depend on the project from another Haskell project&lt;/h3&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;None of our libraries are on Hackage, unfortunately (many of our dependencies aren’t either). So for the time being, you need to:&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;olist arabic&#34;&gt; &#xA;    &lt;ol class=&#34;arabic&#34;&gt; &#xA;     &lt;li&gt; &lt;p&gt;Add &lt;code&gt;marlowe&lt;/code&gt; as a &lt;code&gt;source-repository-package&lt;/code&gt; to your &lt;code&gt;cabal.project&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;Copy the &lt;code&gt;source-repository-package&lt;/code&gt; stanzas from our &lt;code&gt;cabal.project&lt;/code&gt; to yours.&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;Copy additional stanzas from our &lt;code&gt;cabal.project&lt;/code&gt; as you need, e.g. you may need some of the &lt;code&gt;allow-newer&lt;/code&gt; stanzas.&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ol&gt; &#xA;   &lt;/div&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div class=&#34;sect2&#34;&gt; &#xA;   &lt;h3 id=&#34;_how_to_build_the_projects_artifacts&#34;&gt;How to build the project’s artifacts&lt;/h3&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;This section contains information about how to build the project’s artifacts for independent usage. For development work see &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#how-to-develop&#34;&gt;How to develop and contribute to the project&lt;/a&gt; for more information.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;sect3&#34;&gt; &#xA;    &lt;h4 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h4&gt; &#xA;    &lt;div class=&#34;paragraph&#34;&gt; &#xA;     &lt;p&gt;The Haskell libraries in the Marlowe project are built with &lt;code&gt;cabal&lt;/code&gt; and Nix. The other artifacts (docs etc.) are also most easily built with Nix.&lt;/p&gt; &#xA;    &lt;/div&gt; &#xA;    &lt;div class=&#34;sect4&#34;&gt; &#xA;     &lt;h5 id=&#34;_nix&#34;&gt;Nix&lt;/h5&gt; &#xA;     &lt;div class=&#34;paragraph&#34;&gt; &#xA;      &lt;p&gt;Install &lt;a href=&#34;https://nixos.org/nix/&#34;&gt;Nix&lt;/a&gt; (recommended). following the instructions on the &lt;a href=&#34;https://nixos.org/nix/&#34;&gt;Nix website&lt;/a&gt;.&lt;/p&gt; &#xA;     &lt;/div&gt; &#xA;     &lt;div class=&#34;paragraph&#34;&gt; &#xA;      &lt;p&gt;Make sure you have read and understood the &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#cache-warning&#34;&gt;cache warning&lt;/a&gt;. DO NOT IGNORE THIS.&lt;/p&gt; &#xA;     &lt;/div&gt; &#xA;     &lt;div class=&#34;paragraph&#34;&gt; &#xA;      &lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#nix-advice&#34;&gt;Nix&lt;/a&gt; for further advice on using Nix.&lt;/p&gt; &#xA;     &lt;/div&gt; &#xA;    &lt;/div&gt; &#xA;    &lt;div class=&#34;sect4&#34;&gt; &#xA;     &lt;h5 id=&#34;_non_nix&#34;&gt;Non-Nix&lt;/h5&gt; &#xA;     &lt;div class=&#34;paragraph&#34;&gt; &#xA;      &lt;p&gt;You can build some of the Haskell packages without Nix, but this is not recommended and we don’t guarantee that these prerequisites are sufficient. If you use Nix, these tools are provided for you via &lt;code&gt;nix develop&lt;/code&gt;, and you do &lt;strong&gt;not&lt;/strong&gt; need to install them yourself.&lt;/p&gt; &#xA;     &lt;/div&gt; &#xA;     &lt;div class=&#34;ulist&#34;&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt; &lt;p&gt;If you want to build our Haskell packages with &lt;a href=&#34;https://www.haskell.org/cabal/&#34;&gt;&lt;code&gt;cabal&lt;/code&gt;&lt;/a&gt;, then install it.&lt;/p&gt; &lt;/li&gt; &#xA;       &lt;li&gt; &lt;p&gt;If you want to build our Haskell packages with &lt;a href=&#34;https://haskellstack.org/&#34;&gt;&lt;code&gt;stack&lt;/code&gt;&lt;/a&gt;, then install it.&lt;/p&gt; &lt;/li&gt; &#xA;       &lt;li&gt; &lt;p&gt;If you want to build our Agda code, then install &lt;a href=&#34;https://github.com/agda/agda&#34;&gt;Agda&lt;/a&gt; and the &lt;a href=&#34;https://github.com/agda/agda-stdlib&#34;&gt;standard library&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;      &lt;/ul&gt; &#xA;     &lt;/div&gt; &#xA;    &lt;/div&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;sect3&#34;&gt; &#xA;    &lt;h4 id=&#34;building-with-nix&#34;&gt;How to build the Haskell packages and other artifacts with Nix&lt;/h4&gt; &#xA;    &lt;div class=&#34;paragraph&#34;&gt; &#xA;     &lt;p&gt;Run &lt;code&gt;nix build .#marlowe.haskell.packages.marlowe.components.library&lt;/code&gt; from the root to build the Marlowe library.&lt;/p&gt; &#xA;    &lt;/div&gt; &#xA;    &lt;div class=&#34;paragraph&#34;&gt; &#xA;     &lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#nix-build-attributes&#34;&gt;Which attributes to use to build different artifacts&lt;/a&gt; to find out what other attributes you can build.&lt;/p&gt; &#xA;    &lt;/div&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;sect3&#34;&gt; &#xA;    &lt;h4 id=&#34;_how_to_build_the_haskell_packages_with_cabal&#34;&gt;How to build the Haskell packages with &lt;code&gt;cabal&lt;/code&gt;&lt;/h4&gt; &#xA;    &lt;div class=&#34;paragraph&#34;&gt; &#xA;     &lt;p&gt;The Haskell packages can be built directly with &lt;code&gt;cabal&lt;/code&gt;. We do this during development (see &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#how-to-develop&#34;&gt;How to develop and contribute to the project&lt;/a&gt;). The best way is to do this is inside a &lt;code&gt;nix develop&lt;/code&gt;.&lt;/p&gt; &#xA;    &lt;/div&gt; &#xA;    &lt;div class=&#34;admonitionblock note&#34;&gt; &#xA;     &lt;table&gt; &#xA;      &lt;tbody&gt;&#xA;       &lt;tr&gt; &#xA;        &lt;td class=&#34;icon&#34;&gt; &#xA;         &lt;div class=&#34;title&#34;&gt;&#xA;          Note&#xA;         &lt;/div&gt; &lt;/td&gt; &#xA;        &lt;td class=&#34;content&#34;&gt; &#xA;         &lt;div class=&#34;paragraph&#34;&gt; &#xA;          &lt;p&gt;For fresh development setups, you also need to run &lt;code&gt;cabal update&lt;/code&gt;.&lt;/p&gt; &#xA;         &lt;/div&gt; &lt;/td&gt; &#xA;       &lt;/tr&gt; &#xA;      &lt;/tbody&gt;&#xA;     &lt;/table&gt; &#xA;    &lt;/div&gt; &#xA;    &lt;div class=&#34;paragraph&#34;&gt; &#xA;     &lt;p&gt;Run &lt;code&gt;cabal build marlowe&lt;/code&gt; from the root to build the Marlowe library.&lt;/p&gt; &#xA;    &lt;/div&gt; &#xA;    &lt;div class=&#34;paragraph&#34;&gt; &#xA;     &lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/cabal.project&#34;&gt;cabal project file&lt;/a&gt; to see the other packages that you can build with &lt;code&gt;cabal&lt;/code&gt;.&lt;/p&gt; &#xA;    &lt;/div&gt; &#xA;   &lt;/div&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div class=&#34;sect2&#34;&gt; &#xA;   &lt;h3 id=&#34;_deployment&#34;&gt;Deployment&lt;/h3&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;Marlowe Run and the Marlowe Playground are automatically deployed upon certain pushes to GitHub&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;ulist&#34;&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://marlowe-playground-staging.plutus.aws.iohkdev.io/&#34;&gt;Marlowe Playground staging&lt;/a&gt; and &lt;a href=&#34;https://marlowe-run-staging.plutus.aws.iohkdev.io/&#34;&gt;Marlowe Run staging&lt;/a&gt; are deployed from every commit pushed to &lt;code&gt;main&lt;/code&gt; (these URLs subject to change)&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://play.marlowe-finance.io/&#34;&gt;Marlowe Playground production&lt;/a&gt; and &lt;a href=&#34;https://run.marlowe-finance.io/&#34;&gt;Marlowe Run production&lt;/a&gt; are deployed from every commit pushed to &lt;code&gt;production&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;For more details, including instructions for setting up ad hoc testing deployments, see &lt;a href=&#34;https://github.com/input-output-hk/plutus-ops&#34;&gt;the plutus-ops repo&lt;/a&gt;.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;  &lt;/div&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;div class=&#34;sect1&#34;&gt; &#xA; &lt;h2 id=&#34;nix-advice&#34;&gt;Nix&lt;/h2&gt; &#xA; &lt;div class=&#34;sectionbody&#34;&gt; &#xA;  &lt;div class=&#34;sect2&#34;&gt; &#xA;   &lt;h3 id=&#34;iohk-binary-cache&#34;&gt;How to set up the IOHK binary caches&lt;/h3&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;Adding the IOHK binary cache to your Nix configuration will speed up builds a lot, since many things will have been built already by our CI.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;If you find you are building packages that are not defined in this repository, or if the build seems to take a very long time then you may not have this set up properly.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;To set up the cache:&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;olist arabic&#34;&gt; &#xA;    &lt;ol class=&#34;arabic&#34;&gt; &#xA;     &lt;li&gt; &lt;p&gt;On non-NixOS, edit &lt;code&gt;/etc/nix/nix.conf&lt;/code&gt; and add the following lines:&lt;/p&gt; &#xA;      &lt;div class=&#34;listingblock&#34;&gt; &#xA;       &lt;div class=&#34;content&#34;&gt; &#xA;        &lt;pre&gt;substituters        = https://hydra.iohk.io https://iohk.cachix.org https://cache.nixos.org/&#xA;trusted-public-keys = hydra.iohk.io:f/Ea+s+dFdN+3Y/G+FDgSq+a5NEWhJGzdjvKNGv0/EQ= iohk.cachix.org-1:DpRUyj7h7V830dp/i6Nti+NEO2/nhblbov/8MW7Rqoo= cache.nixos.org-1:6NCHdD59X431o0gWypbMrAURkbJ16ZPMQFGspcDShjY=&lt;/pre&gt; &#xA;       &lt;/div&gt; &#xA;      &lt;/div&gt; &#xA;      &lt;div class=&#34;admonitionblock note&#34;&gt; &#xA;       &lt;table&gt; &#xA;        &lt;tbody&gt;&#xA;         &lt;tr&gt; &#xA;          &lt;td class=&#34;icon&#34;&gt; &#xA;           &lt;div class=&#34;title&#34;&gt;&#xA;            Note&#xA;           &lt;/div&gt; &lt;/td&gt; &#xA;          &lt;td class=&#34;content&#34;&gt; &#xA;           &lt;div class=&#34;paragraph&#34;&gt; &#xA;            &lt;p&gt;If you don’t have an &lt;code&gt;/etc/nix/nix.conf&lt;/code&gt; or don’t want to edit it, you may add the &lt;code&gt;nix.conf&lt;/code&gt; lines to &lt;code&gt;~/.config/nix/nix.conf&lt;/code&gt; instead. You must be a &lt;a href=&#34;https://nixos.org/nix/manual/#ssec-multi-user&#34;&gt;trusted user&lt;/a&gt; to do this.&lt;/p&gt; &#xA;           &lt;/div&gt; &lt;/td&gt; &#xA;         &lt;/tr&gt; &#xA;        &lt;/tbody&gt;&#xA;       &lt;/table&gt; &#xA;      &lt;/div&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;On NixOS, set the following NixOS options:&lt;/p&gt; &#xA;      &lt;div class=&#34;listingblock&#34;&gt; &#xA;       &lt;div class=&#34;content&#34;&gt; &#xA;        &lt;pre&gt;nix = {&#xA;  binaryCaches          = [ &#34;https://hydra.iohk.io&#34; &#34;https://iohk.cachix.org&#34; ];&#xA;  binaryCachePublicKeys = [ &#34;hydra.iohk.io:f/Ea+s+dFdN+3Y/G+FDgSq+a5NEWhJGzdjvKNGv0/EQ=&#34; &#34;iohk.cachix.org-1:DpRUyj7h7V830dp/i6Nti+NEO2/nhblbov/8MW7Rqoo=&#34; ];&#xA;};&lt;/pre&gt; &#xA;       &lt;/div&gt; &#xA;      &lt;/div&gt; &lt;/li&gt; &#xA;    &lt;/ol&gt; &#xA;   &lt;/div&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div class=&#34;sect2&#34;&gt; &#xA;   &lt;h3 id=&#34;_nix_on_macos&#34;&gt;Nix on macOS&lt;/h3&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;Nix on macOS can be a bit tricky. In particular, sandboxing is disabled by default, which can lead to strange failures.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;These days it should be safe to turn on sandboxing on macOS with a few exceptions. Consider setting the following Nix settings, in the same way as in &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/#iohk-binary-cache&#34;&gt;previous section&lt;/a&gt;:&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;listingblock&#34;&gt; &#xA;    &lt;div class=&#34;content&#34;&gt; &#xA;     &lt;pre&gt;sandbox = true&#xA;extra-sandbox-paths = /System/Library/Frameworks /System/Library/PrivateFrameworks /usr/lib /private/tmp /private/var/tmp /usr/bin/env&lt;/pre&gt; &#xA;    &lt;/div&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;Changes to &lt;code&gt;/etc/nix/nix.conf&lt;/code&gt; may require a restart of the nix daemon in order to take affect. Restart the nix daemon by running the following commands:&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;listingblock&#34;&gt; &#xA;    &lt;div class=&#34;content&#34;&gt; &#xA;     &lt;pre&gt;sudo launchctl stop org.nixos.nix-daemon&#xA;sudo launchctl start org.nixos.nix-daemon&lt;/pre&gt; &#xA;    &lt;/div&gt; &#xA;   &lt;/div&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;div class=&#34;sect2&#34;&gt; &#xA;   &lt;h3 id=&#34;nix-build-attributes&#34;&gt;Which attributes to use to build different artifacts&lt;/h3&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/packages.nix&#34;&gt;&lt;code&gt;packages.nix&lt;/code&gt;&lt;/a&gt; defines a package set with attributes for all the artifacts you can build from this repository. These can be built using &lt;code&gt;nix build&lt;/code&gt;. For example:&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;listingblock&#34;&gt; &#xA;    &lt;div class=&#34;content&#34;&gt; &#xA;     &lt;pre&gt;nix build .#docs.site&lt;/pre&gt; &#xA;    &lt;/div&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;ulist&#34;&gt; &#xA;    &lt;div class=&#34;title&#34;&gt;&#xA;     Example attributes&#xA;    &lt;/div&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;Project packages: defined inside &lt;code&gt;marlowe.haskell.packages&lt;/code&gt;&lt;/p&gt; &#xA;      &lt;div class=&#34;ulist&#34;&gt; &#xA;       &lt;ul&gt; &#xA;        &lt;li&gt; &lt;p&gt;e.g.&amp;nbsp;&lt;code&gt;marlowe.haskell.packages.marlowe.components.library&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;       &lt;/ul&gt; &#xA;      &lt;/div&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &#xA;   &lt;/div&gt; &#xA;   &lt;div class=&#34;paragraph&#34;&gt; &#xA;    &lt;p&gt;There are other attributes defined in &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/packages.nix&#34;&gt;&lt;code&gt;packages.nix&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;   &lt;/div&gt; &#xA;  &lt;/div&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;div class=&#34;sect1&#34;&gt; &#xA; &lt;h2 id=&#34;_licensing&#34;&gt;Licensing&lt;/h2&gt; &#xA; &lt;div class=&#34;sectionbody&#34;&gt; &#xA;  &lt;div class=&#34;paragraph&#34;&gt; &#xA;   &lt;p&gt;You are free to copy, modify, and distribute Marlowe under the terms of the Apache 2.0 license. See the &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/input-output-hk/marlowe-cardano/main/NOTICE&#34;&gt;NOTICE&lt;/a&gt; files for details.&lt;/p&gt; &#xA;  &lt;/div&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>ServiceNow/picard</title>
    <updated>2022-09-14T01:35:07Z</updated>
    <id>tag:github.com,2022-09-14:/ServiceNow/picard</id>
    <link href="https://github.com/ServiceNow/picard" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PICARD - Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models. PICARD is a ServiceNow Research project that was started at Element AI.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;ServiceNow completed its acquisition of Element AI on January 8, 2021. All references to Element AI in the materials that are part of this project should refer to ServiceNow.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img alt=&#34;make it parse&#34; src=&#34;https://repository-images.githubusercontent.com/401779782/c2f46be5-b74b-4620-ad64-57487be3b1ab&#34; width=&#34;600&#34;&gt; &lt;br&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/ElementAI/picard/actions/workflows/build.yml&#34;&gt; &lt;img alt=&#34;build&#34; src=&#34;https://github.com/ElementAI/picard/actions/workflows/build.yml/badge.svg?branch=main&amp;amp;event=push&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/ElementAI/picard/raw/main/LICENSE&#34;&gt; &lt;img alt=&#34;license&#34; src=&#34;https://img.shields.io/github/license/ElementAI/picard.svg?color=blue&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/paper/picard-parsing-incrementally-for-constrained&#34;&gt; &lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/picard-parsing-incrementally-for-constrained/text-to-sql-on-spider&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/paper/picard-parsing-incrementally-for-constrained&#34;&gt; &lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/picard-parsing-incrementally-for-constrained/dialogue-state-tracking-on-cosql&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;This is the official implementation of the following paper:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/tscholak&#34;&gt;Torsten Scholak&lt;/a&gt;, Nathan Schucher, Dzmitry Bahdanau. &lt;a href=&#34;https://arxiv.org/abs/2109.05093&#34;&gt;PICARD - Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models&lt;/a&gt;. &lt;em&gt;Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP).&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you use this code, please cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{Scholak2021:PICARD,&#xA;  author = {Torsten Scholak and Nathan Schucher and Dzmitry Bahdanau},&#xA;  title = &#34;{PICARD}: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models&#34;,&#xA;  booktitle = &#34;Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing&#34;,&#xA;  month = nov,&#xA;  year = &#34;2021&#34;,&#xA;  publisher = &#34;Association for Computational Linguistics&#34;,&#xA;  url = &#34;https://aclanthology.org/2021.emnlp-main.779&#34;,&#xA;  pages = &#34;9895--9901&#34;,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Watch The Video&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/kTpixsr-37w&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/kTpixsr-37w/maxresdefault.jpg&#34; alt=&#34;Watch the video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;This code implements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The PICARD algorithm for constrained decoding from language models.&lt;/li&gt; &#xA; &lt;li&gt;A text-to-SQL semantic parser based on pre-trained sequence-to-sequence models and PICARD achieving state-of-the-art performance on both the &lt;a href=&#34;https://yale-lily.github.io/spider&#34;&gt;Spider&lt;/a&gt; and the &lt;a href=&#34;https://yale-lily.github.io/cosql&#34;&gt;CoSQL&lt;/a&gt; datasets.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;About PICARD&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; We introduce PICARD -- a new method for simple and effective constrained decoding from large pre-trained language models. On the challenging Spider and CoSQL text-to-SQL datasets, PICARD significantly improves the performance of fine-tuned but otherwise unmodified T5 models. Using PICARD, our T5-3B models achieved state-of-the-art performance on both Spider and CoSQL.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;In text-to-SQL translation, the goal is to translate a natural language question into a SQL query. There are two main challenges to this task:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The generated SQL needs to be semantically correct, that is, correctly reflect the meaning of the question.&lt;/li&gt; &#xA; &lt;li&gt;The SQL also needs to be valid, that is, it must not result in an execution error.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;So far, there has been a trade-off between these two goals: The second problem can be solved by using a special decoder architecture that -- by construction -- always produces valid SQL. This is the approach taken by most prior work. Those decoders are called &#34;constrained decoders&#34;, and they need to be trained from scratch on the text-to-SQL dataset. However, this limits the generality of the decoders, which is a problem for the first goal.&lt;/p&gt; &#xA;&lt;p&gt;A better approach would be to use a pre-trained encoder-decoder model and to constrain its decoder to produce valid SQL after fine-tuning the model on the text-to-SQL task. This is the approach taken by the PICARD algorithm.&lt;/p&gt; &#xA;&lt;h3&gt;How is PICARD different from existing constrained decoders?&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It’s an incremental parsing algorithm that integrates with ordinary beam search.&lt;/li&gt; &#xA; &lt;li&gt;It doesn’t require any training.&lt;/li&gt; &#xA; &lt;li&gt;It doesn’t require modifying the model.&lt;/li&gt; &#xA; &lt;li&gt;It works with any model that generates a sequence of tokens (including language models).&lt;/li&gt; &#xA; &lt;li&gt;It doesn’t require a special vocabulary.&lt;/li&gt; &#xA; &lt;li&gt;It works with character-, sub-word-, and word-level language models.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;How does PICARD work?&lt;/h3&gt; &#xA;&lt;p&gt;The following picture shows how PICARD is integrated with beam search.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ServiceNow/picard/main/beam_search_with_picard.svg?sanitize=true&#34; width=&#34;400&#34;&gt; &lt;br&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;Decoding starts from the left and proceeds to the right. The algorithm begins with a single token (usually &lt;code&gt;&amp;lt;s&amp;gt;&lt;/code&gt;), and then keeps expanding the beam with hypotheses generated token-by-token by the decoder. At each decoding step and for each hypothesis, PICARD checks whether the next top-&lt;code&gt;k&lt;/code&gt; tokens are valid. In the image above, only 3 token predictions are shown, and &lt;code&gt;k&lt;/code&gt; is set to 2. Valid tokens (☑) are added to the beam. Invalid ones (☒) are discarded. The &lt;code&gt;k+1&lt;/code&gt;-th, &lt;code&gt;k+2&lt;/code&gt;-th, ... tokens are discarded, too. Like in normal beam search, the beam is pruned to contain only the top-&lt;code&gt;n&lt;/code&gt; hypotheses. &lt;code&gt;n&lt;/code&gt; is the beam size, and in the image above it is set to 2 as well. Hypotheses that are terminated with the end-of-sentence token (usually &lt;code&gt;&amp;lt;/s&amp;gt;&lt;/code&gt;) are not expanded further. The algorithm stops when the all hypotheses are terminated or when the maximum number of tokens has been reached.&lt;/p&gt; &#xA;&lt;h3&gt;How does PICARD know whether a token is valid?&lt;/h3&gt; &#xA;&lt;p&gt;In PICARD, checking, accepting, and rejecting of tokens and token sequences is achieved through &lt;em&gt;parsing&lt;/em&gt;. Parsing means that we attempt to assemble a data structure from the tokens that are currently in the beam or are about to be added to it. This data structure (and the parsing rules that are used to build it) encode the constraints we want to enforce.&lt;/p&gt; &#xA;&lt;p&gt;In the case of SQL, the data structure we parse to is the abstract syntax tree (AST) of the SQL query. The parsing rules are defined in a computer program called a parser. Database engines, such as PostgreSQL, MySQL, and SQLite, have their own built-in parser that they use internally to process SQL queries. For Spider and CoSQL, we have implemented a parser that supports a subset of the SQLite syntax and that checks additional constraints on the AST. In our implementation, the parsing rules are made up from simpler rules and primitives that are provided by a third-party parsing library.&lt;/p&gt; &#xA;&lt;p&gt;PICARD uses a parsing library called &lt;a href=&#34;https://hackage.haskell.org/package/attoparsec&#34;&gt;attoparsec&lt;/a&gt; that supports incremental input. This is a special capability that is not available in many other parsing libraries. You can feed attoparsec a string that represents only part of the expected input to parse. When parsing reaches the end of an input fragment, attoparsec will return a &lt;a href=&#34;https://hackage.haskell.org/package/attoparsec-0.14.1/docs/Data-Attoparsec-Text.html#t:IResult&#34;&gt;continuation function&lt;/a&gt; that can be used to continue parsing. Think of the continuation function as a suspended computation that can be resumed later. Input fragments can be parsed one after the other when they become available until the input is complete.&lt;/p&gt; &#xA;&lt;p&gt;Herein lies the key to PICARD: Incremental parsing of input fragments is exactly what we need to check tokens one by one during decoding.&lt;/p&gt; &#xA;&lt;p&gt;In PICARD, parsing is initialized with an empty string, and attoparsec will return the first continuation function. We then call that continuation function with all the token predictions we want to check in the first decoding step. For those tokens that are valid, the continuation function will return a new continuation function that we can use to continue parsing in the next decoding step. For those tokens that are invalid, the continuation function will return a failure value which cannot be used to continue parsing. Such failures are discarded and never end up in the beam. We repeat the process until the end of the input is reached. The input is complete once the model predicts the end-of-sentence token. When that happens, we finalize the parsing by calling the continuation function with an empty string. If the parsing is successful, it will return the final AST. If not, it will return a failure value.&lt;/p&gt; &#xA;&lt;p&gt;The parsing rules are described at a high level in the &lt;a href=&#34;https://arxiv.org/abs/2109.05093&#34;&gt;PICARD paper&lt;/a&gt;. For details, see the PICARD code, specifically the &lt;a href=&#34;https://github.com/ElementAI/picard/raw/main/picard/src/Language/SQL/SpiderSQL/Parse.hs&#34;&gt;Language.SQL.SpiderSQL.Parse module&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;How well does PICARD work?&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s look at the numbers:&lt;/p&gt; &#xA;&lt;h4&gt;On &lt;a href=&#34;https://yale-lily.github.io/spider&#34;&gt;Spider&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th rowspan=&#34;2&#34; valign=&#34;bottom&#34;&gt;URL&lt;/th&gt; &#xA;   &lt;th rowspan=&#34;2&#34; valign=&#34;bottom&#34;&gt;Based on&lt;/th&gt; &#xA;   &lt;th colspan=&#34;2&#34;&gt;Exact-set Match Accuracy&lt;/th&gt; &#xA;   &lt;th colspan=&#34;2&#34;&gt;Execution Accuracy&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Dev&lt;/th&gt; &#xA;   &lt;th&gt;Test&lt;/th&gt; &#xA;   &lt;th&gt;Dev&lt;/th&gt; &#xA;   &lt;th&gt;Test&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;b&gt;&lt;a href=&#34;https://huggingface.co/tscholak/cxmefzzi&#34;&gt;tscholak/cxmefzzi&lt;/a&gt; w PICARD&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;T5-3B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;75.5 %&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;71.9 %&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;79.3 %&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;75.1 %&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/cxmefzzi&#34;&gt;tscholak/cxmefzzi&lt;/a&gt; w/o PICARD&lt;/td&gt; &#xA;   &lt;td&gt;T5-3B&lt;/td&gt; &#xA;   &lt;td&gt;71.5 %&lt;/td&gt; &#xA;   &lt;td&gt;68.0 %&lt;/td&gt; &#xA;   &lt;td&gt;74.4 %&lt;/td&gt; &#xA;   &lt;td&gt;70.1 %&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/3vnuv1vf&#34;&gt;tscholak/3vnuv1vf&lt;/a&gt; w PICARD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-research/text-to-text-transfer-transformer/raw/main/released_checkpoints.md#lm-adapted-t511lm100k&#34;&gt;t5.1.1.lm100k.large&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;74.8 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;79.2 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/3vnuv1vf&#34;&gt;tscholak/3vnuv1vf&lt;/a&gt; w/o PICARD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-research/text-to-text-transfer-transformer/raw/main/released_checkpoints.md#lm-adapted-t511lm100k&#34;&gt;t5.1.1.lm100k.large&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;71.2 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;74.4 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/1wnr382e&#34;&gt;tscholak/1wnr382e&lt;/a&gt; w PICARD&lt;/td&gt; &#xA;   &lt;td&gt;T5-Large&lt;/td&gt; &#xA;   &lt;td&gt;69.1 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;72.9 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/1wnr382e&#34;&gt;tscholak/1wnr382e&lt;/a&gt; w/o PICARD&lt;/td&gt; &#xA;   &lt;td&gt;T5-Large&lt;/td&gt; &#xA;   &lt;td&gt;65.3 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;67.2 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/1zha5ono&#34;&gt;tscholak/1zha5ono&lt;/a&gt; w PICARD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-research/text-to-text-transfer-transformer/raw/main/released_checkpoints.md#lm-adapted-t511lm100k&#34;&gt;t5.1.1.lm100k.base&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;66.6 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;68.4 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/1zha5ono&#34;&gt;tscholak/1zha5ono&lt;/a&gt; w/o PICARD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-research/text-to-text-transfer-transformer/raw/main/released_checkpoints.md#lm-adapted-t511lm100k&#34;&gt;t5.1.1.lm100k.base&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;59.4 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;60.0 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;Click on the links to download the models. &lt;a href=&#34;https://huggingface.co/tscholak/cxmefzzi&#34;&gt;tscholak/cxmefzzi&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/tscholak/1wnr382e&#34;&gt;tscholak/1wnr382e&lt;/a&gt; are the versions of the model that we used in our experiments for the paper, reported as T5-3B and T5-Large, respectively. &lt;a href=&#34;https://huggingface.co/tscholak/cxmefzzi&#34;&gt;tscholak/cxmefzzi&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/tscholak/3vnuv1vf&#34;&gt;tscholak/3vnuv1vf&lt;/a&gt;, and &lt;a href=&#34;https://huggingface.co/tscholak/1zha5ono&#34;&gt;tscholak/1zha5ono&lt;/a&gt; were trained to use database content, whereas &lt;a href=&#34;https://huggingface.co/tscholak/1wnr382e&#34;&gt;tscholak/1wnr382e&lt;/a&gt; was not.&lt;/p&gt; &#xA;&lt;p&gt;Note that, without PICARD, 12% of the SQL queries generated by &lt;a href=&#34;https://huggingface.co/tscholak/cxmefzzi&#34;&gt;tscholak/cxmefzzi&lt;/a&gt; on Spider’s development set resulted in an execution error. With PICARD, this number decreased to 2%.&lt;/p&gt; &#xA;&lt;h4&gt;On &lt;a href=&#34;https://yale-lily.github.io/cosql&#34;&gt;CoSQL&lt;/a&gt; Dialogue State Tracking&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th rowspan=&#34;2&#34; valign=&#34;bottom&#34;&gt;URL&lt;/th&gt; &#xA;   &lt;th rowspan=&#34;2&#34; valign=&#34;bottom&#34;&gt;Based on&lt;/th&gt; &#xA;   &lt;th colspan=&#34;2&#34;&gt;Question Match Accuracy&lt;/th&gt; &#xA;   &lt;th colspan=&#34;2&#34;&gt;Interaction Match Accuracy&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Dev&lt;/th&gt; &#xA;   &lt;th&gt;Test&lt;/th&gt; &#xA;   &lt;th&gt;Dev&lt;/th&gt; &#xA;   &lt;th&gt;Test&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;b&gt;&lt;a href=&#34;https://huggingface.co/tscholak/2e826ioa&#34;&gt;tscholak/2e826ioa&lt;/a&gt; w PICARD&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;T5-3B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;56.9 %&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;54.6 %&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;24.2 %&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;23.7 %&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/2e826ioa&#34;&gt;tscholak/2e826ioa&lt;/a&gt; w/o PICARD&lt;/td&gt; &#xA;   &lt;td&gt;T5-3B&lt;/td&gt; &#xA;   &lt;td&gt;53.8 %&lt;/td&gt; &#xA;   &lt;td&gt;51.4 %&lt;/td&gt; &#xA;   &lt;td&gt;21.8 %&lt;/td&gt; &#xA;   &lt;td&gt;21.7 %&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/2jrayxos&#34;&gt;tscholak/2jrayxos&lt;/a&gt; w PICARD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-research/text-to-text-transfer-transformer/raw/main/released_checkpoints.md#lm-adapted-t511lm100k&#34;&gt;t5.1.1.lm100k.large&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;54.2 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tscholak/2jrayxos&#34;&gt;tscholak/2jrayxos&lt;/a&gt; w/o PICARD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-research/text-to-text-transfer-transformer/raw/main/released_checkpoints.md#lm-adapted-t511lm100k&#34;&gt;t5.1.1.lm100k.large&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;52.5 %&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;   &lt;td&gt;—&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;Click on the links to download the models. &lt;a href=&#34;https://huggingface.co/tscholak/2e826ioa&#34;&gt;tscholak/2e826ioa&lt;/a&gt; is the version of the model that we used in our experiments for the paper, reported as T5-3B.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;This repository uses git submodules. Clone it like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git clone git@github.com:ElementAI/picard.git&#xA;$ cd picard&#xA;$ git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Training&lt;/h3&gt; &#xA;&lt;p&gt;The training script is located in &lt;code&gt;seq2seq/run_seq2seq.py&lt;/code&gt;. You can run it with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make train&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The model will be trained on the Spider dataset by default. You can also train on CoSQL by running &lt;code&gt;make train-cosql&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The training script will create the directory &lt;code&gt;train&lt;/code&gt; in the current directory. Training artifacts like checkpoints will be stored in this directory.&lt;/p&gt; &#xA;&lt;p&gt;The default configuration is stored in &lt;code&gt;configs/train.json&lt;/code&gt;. The settings are optimized for a GPU with 40GB of memory.&lt;/p&gt; &#xA;&lt;p&gt;These training settings should result in a model with at least 71% exact-set-match accuracy on the Spider development set. With PICARD, the accuracy should go up to at least 75%.&lt;/p&gt; &#xA;&lt;p&gt;We have uploaded a model trained on the Spider dataset to the huggingface model hub, &lt;a href=&#34;https://huggingface.co/tscholak/cxmefzzi&#34;&gt;tscholak/cxmefzzi&lt;/a&gt;. A model trained on the CoSQL dialog state tracking dataset is available, too, &lt;a href=&#34;https://huggingface.co/tscholak/2e826ioa&#34;&gt;tscholak/2e826ioa&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;The evaluation script is located in &lt;code&gt;seq2seq/run_seq2seq.py&lt;/code&gt;. You can run it with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make eval&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, the evaluation will be run on the Spider evaluation set. Evaluation on the CoSQL evaluation set can be run with &lt;code&gt;make eval-cosql&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The evaluation script will create the directory &lt;code&gt;eval&lt;/code&gt; in the current directory. The evaluation results will be stored there.&lt;/p&gt; &#xA;&lt;p&gt;The default configuration is stored in &lt;code&gt;configs/eval.json&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Serving&lt;/h3&gt; &#xA;&lt;p&gt;A trained model can be served using the &lt;code&gt;seq2seq/serve_seq2seq.py&lt;/code&gt; script. The configuration file can be found in &lt;code&gt;configs/serve.json&lt;/code&gt;. You can start serving with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make serve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, the 800-million-parameter &lt;a href=&#34;https://huggingface.co/tscholak/3vnuv1vf&#34;&gt;tscholak/3vnuv1vf&lt;/a&gt; model will be loaded. You can also load a different model by specifying the model name in the configuration file. The device to use can be specified as well. The default is to use the first available GPU. CPU can be used by specifying &lt;code&gt;-1&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When the script is called, it uses the folder specified by the &lt;code&gt;db_path&lt;/code&gt; option to look for SQL database files. The default folder is &lt;code&gt;database&lt;/code&gt;, which will be created in the current directory. Initially, this folder will be empty, and you can add your own SQL files to it. The structure of the folder should be like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;database/&#xA;  my_1st_database/&#xA;    my_1st_database.sqlite&#xA;  my_2nd_database/&#xA;    my_2nd_database.sqlite&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;my_1st_database&lt;/code&gt; and &lt;code&gt;my_2nd_database&lt;/code&gt; are the &lt;code&gt;db_id&lt;/code&gt;s of the databases.&lt;/p&gt; &#xA;&lt;p&gt;Once the server is up and running, use the Swagger UI to test inference with the &lt;code&gt;/ask&lt;/code&gt; endpoint. The server will be listening at &lt;code&gt;http://localhost:8000/&lt;/code&gt;, and the Swagger UI will be available at &lt;code&gt;http://localhost:8000/docs#/default/ask_ask__db_id___question__get&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;There are three docker images that can be used to run the code:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://hub.docker.com/repository/docker/tscholak/text-to-sql-dev&#34;&gt;tscholak/text-to-sql-dev&lt;/a&gt;:&lt;/strong&gt; Base image with development dependencies. Use this for development. Pull it with &lt;code&gt;make pull-dev-image&lt;/code&gt; from the docker hub. Rebuild the image with &lt;code&gt;make build-dev-image&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://hub.docker.com/repository/docker/tscholak/text-to-sql-train&#34;&gt;tsscholak/text-to-sql-train&lt;/a&gt;:&lt;/strong&gt; Training image with development dependencies but without Picard dependencies. Use this for fine-tuning a model. Pull it with &lt;code&gt;make pull-train-image&lt;/code&gt; from the docker hub. Rebuild the image with &lt;code&gt;make build-train-image&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://hub.docker.com/repository/docker/tscholak/text-to-sql-eval&#34;&gt;tscholak/text-to-sql-eval&lt;/a&gt;:&lt;/strong&gt; Training/evaluation image with all dependencies. Use this for evaluating a fine-tuned model with Picard. This image can also be used for training if you want to run evaluation during training with Picard. Pull it with &lt;code&gt;make pull-eval-image&lt;/code&gt; from the docker hub. Rebuild the image with &lt;code&gt;make build-eval-image&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All images are tagged with the current commit hash. The images are built with the buildx tool which is available in the latest docker-ce. Use &lt;code&gt;make init-buildkit&lt;/code&gt; to initialize the buildx tool on your machine. You can then use &lt;code&gt;make build-dev-image&lt;/code&gt;, &lt;code&gt;make build-train-image&lt;/code&gt;, etc. to rebuild the images. Local changes to the code will not be reflected in the docker images unless they are committed to git.&lt;/p&gt;</summary>
  </entry>
</feed>