<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Haskell Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-07T01:37:22Z</updated>
  <subtitle>Daily Trending of Haskell in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>haskell/security-advisories</title>
    <updated>2023-05-07T01:37:22Z</updated>
    <id>tag:github.com,2023-05-07:/haskell/security-advisories</id>
    <link href="https://github.com/haskell/security-advisories" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Haskell Security Advisory DB&lt;/h1&gt; &#xA;&lt;p&gt;The Haskell Security Advisory Database is a repository of security advisories filed against packages published via Hackage.&lt;/p&gt; &#xA;&lt;p&gt;This database is still new. If you develop a tool or database that uses its information, please open a PR listing it here.&lt;/p&gt; &#xA;&lt;h2&gt;Reporting Vulnerabilities&lt;/h2&gt; &#xA;&lt;p&gt;To report a new vulnerability, open a pull request using the template below. See &lt;a href=&#34;https://github.com/haskell/security-advisories/raw/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Advisory Format&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/haskell/security-advisories/raw/main/EXAMPLE_ADVISORY.md&#34;&gt;EXAMPLE_ADVISORY.md&lt;/a&gt; for a template.&lt;/p&gt; &#xA;&lt;p&gt;Advisories are formatted in &lt;a href=&#34;https://www.markdownguide.org/&#34;&gt;Markdown&lt;/a&gt; with machine-readable &lt;a href=&#34;https://github.com/toml-lang/toml&#34;&gt;TOML&lt;/a&gt; &#34;front matter&#34;.&lt;/p&gt; &#xA;&lt;p&gt;Below is the schema of the &lt;a href=&#34;https://github.com/toml-lang/toml&#34;&gt;TOML&lt;/a&gt; &#34;front matter&#34; section of an advisory. If you base your advisory on this explanation rather than on &lt;a href=&#34;https://github.com/haskell/security-advisories/raw/main/EXAMPLE_ADVISORY.md&#34;&gt;EXAMPLE_ADVISORY.md&lt;/a&gt;, please remember to remove the explanatory comments for each field.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;&#xA;[advisory]&#xA;# Identifier for the advisory (mandatory). Will be assigned a &#34;HSEC-YYYY-NNNN&#34;&#xA;# identifier e.g. HSEC-2022-0001. Please use &#34;HSEC-0000-0000&#34; in PRs.&#xA;id = &#34;HSEC-0000-0000&#34;&#xA;&#xA;# Name of the affected package on Hackage (mandatory)&#xA;package = &#34;acme-broken&#34;&#xA;&#xA;# Disclosure date of the advisory as an RFC 3339 date (mandatory)&#xA;date = 2021-01-31&#xA;&#xA;# URL to a long-form description of this issue, e.g. a GitHub issue/PR,&#xA;# a change log entry, or a blogpost announcing the release (optional)&#xA;url = &#34;https://github.com/username/package/issues/123&#34;&#xA;&#xA;# Optional: Classification of the advisory with respect to the Common Weakness Enumeration.&#xA;cwe = [820]&#xA;&#xA;# Mandatory: a Common Vulnerability Scoring System score. More information&#xA;# can be found on the CVSS website, https://www.first.org/cvss/.&#xA;# The committee will assist advisory authors in constructing an appropriate CVSS if necessary.&#xA;cvss = &#34;CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H&#34;&#xA;&#xA;# Freeform keywords which describe this vulnerability (optional)&#xA;keywords = [&#34;ssl&#34;, &#34;mitm&#34;]&#xA;&#xA;# Vulnerability aliases, e.g. CVE IDs (optional but recommended)&#xA;# Request a CVE for your HSec vulns: https://iwantacve.org/&#xA;#aliases = [&#34;CVE-2018-XXXX&#34;]&#xA;&#xA;# Related vulnerabilities (optional)&#xA;# e.g. CVE for a C library wrapped by a Haskell library&#xA;#related = [&#34;CVE-2018-YYYY&#34;, &#34;CVE-2018-ZZZZ&#34;]&#xA;&#xA;# Optional: metadata which narrows the scope of what this advisory affects&#xA;[affected]&#xA;# CPU architectures impacted by this vulnerability (optional).&#xA;# Only use this if the vulnerability is specific to a particular CPU architecture,&#xA;# e.g. the vulnerability is in x86 assembly.&#xA;# For a list of CPU architecture strings, see the documentation for System.Info.arch:&#xA;# &amp;lt;https://hackage.haskell.org/package/base-4.16.1.0/docs/System-Info.html&amp;gt;&#xA;#arch = [&#34;x86&#34;, &#34;x86_64&#34;]&#xA;&#xA;# Operating systems impacted by this vulnerability (optional)&#xA;# Only use this if the vulnerable is specific to a particular OS, e.g. it was&#xA;# located in a binding to a Windows-specific API.&#xA;# For a list of OS strings, see the documentation for System.Info.os:&#xA;# &amp;lt;https://hackage.haskell.org/package/base-4.16.1.0/docs/System-Info.html&amp;gt;&#xA;#os = [&#34;mingw32&#34;]&#xA;&#xA;# Table of canonical paths to vulnerable declarations in the package (optional)&#xA;# that describes which versions impacted by this advisory used that particular&#xA;# name (e.g. if an affected function or datatype was renamed between versions). &#xA;# The path syntax is the module import path, without any type signatures or&#xA;# additional information, followed by the affected versions.&#xA;#declarations = { &#34;Acme.Broken.function&#34; = &#34;&amp;gt;= 1.1.0 &amp;amp;&amp;amp; &amp;lt; 1.2.0&#34;, &#34;Acme.Broken.renamedFunction&#34; = &#34;&amp;gt;= 1.2.0 &amp;amp;&amp;amp; &amp;lt; 1.2.0.5&#34;}&#xA;&#xA;# Versions affected by the vulnerability&#xA;[versions]&#xA;affected = &#34;&amp;gt;= 1.1.0 &amp;amp;&amp;amp; &amp;lt; 1.2.0.5&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above &lt;a href=&#34;https://github.com/toml-lang/toml&#34;&gt;TOML&lt;/a&gt; &#34;front matter&#34; is followed by the long description in &lt;a href=&#34;https://www.markdownguide.org/&#34;&gt;Markdown&lt;/a&gt; format.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;The process and documentation in this repository are based off the work of the &lt;a href=&#34;https://github.com/rustsec/advisory-db&#34;&gt;RustSec&lt;/a&gt; team.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;All content in this repository is placed in the public domain.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/haskell/security-advisories/LICENSE.txt&#34;&gt;&lt;img src=&#34;http://i.creativecommons.org/p/zero/1.0/88x31.png&#34; alt=&#34;Public Domain&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>McMasterU/HashedExpression</title>
    <updated>2023-05-07T01:37:22Z</updated>
    <id>tag:github.com,2023-05-07:/McMasterU/HashedExpression</id>
    <link href="https://github.com/McMasterU/HashedExpression" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Type-safe modelling DSL, symbolic transformation, and code generation for solving optimization problems.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;HashedExpression&lt;/h1&gt; &#xA;&lt;p&gt;Haskell-embeded Algebraic Modeling Language: solving mathematical optimization with type-safety, symbolic transformation and C-code generation.&lt;/p&gt; &#xA;&lt;p&gt;Further reading: &lt;a href=&#34;https://macsphere.mcmaster.ca/handle/11375/26691&#34;&gt;Type-safe Modeling for Optimization&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;A type-safe, correct-by-construction APIs to model optimization problems using type-level programming.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;For example, adding 2 expressions with mismatched shape or element type (&lt;strong&gt;R&lt;/strong&gt; or &lt;strong&gt;C&lt;/strong&gt;) will result in type error will result in type error:&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;λ&amp;gt; let x = variable1D @10 &#34;x&#34;&#xA;λ&amp;gt; let y = variable1D @9 &#34;y&#34;&#xA;λ&amp;gt; :t x&#xA;x :: TypedExpr &#39;[10] &#39;R&#xA;λ&amp;gt; :t y&#xA;y :: TypedExpr &#39;[9] &#39;R&#xA;λ&amp;gt; x + y&#xA;&amp;lt;interactive&amp;gt;:5:5: error:&#xA;    • Couldn&#39;t match type ‘9’ with ‘10’&#xA;      Expected type: TypedExpr &#39;[10] &#39;R&#xA;        Actual type: TypedExpr &#39;[9] &#39;R&#xA;    • In the second argument of ‘(+)’, namely ‘y’&#xA;      In the expression: x + y&#xA;      In an equation for ‘it’: it = x + y&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;λ&amp;gt; let x = variable1D @10 &#34;x&#34;&#xA;λ&amp;gt; let x = variable2D @10 @10 &#34;x&#34;&#xA;λ&amp;gt; let y = variable2D @10 @10 &#34;y&#34;&#xA;λ&amp;gt; let c = x +: y&#xA;λ&amp;gt; :t c&#xA;c :: TypedExpr &#39;[10, 10] &#39;C&#xA;λ&amp;gt; let z = variable2D @10 @10 &#34;z&#34;&#xA;λ&amp;gt; :t z&#xA;z :: TypedExpr &#39;[10, 10] &#39;R&#xA;λ&amp;gt; z + c&#xA;&#xA;&amp;lt;interactive&amp;gt;:13:5: error:&#xA;    • Couldn&#39;t match type ‘&#39;C’ with ‘&#39;R’&#xA;      Expected type: TypedExpr &#39;[10, 10] &#39;R&#xA;        Actual type: TypedExpr &#39;[10, 10] &#39;C&#xA;      Type synonyms expanded:&#xA;      Expected type: TypedExpr &#39;[10, 10] &#39;R&#xA;        Actual type: TypedExpr &#39;[10, 10] &#39;C&#xA;    • In the second argument of ‘(+)’, namely ‘c’&#xA;      In the expression: z + c&#xA;      In an equation for ‘it’: it = z + c&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Automatically simplify expressions and compute derivatives, identify common subexpressions.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;We represent expressions symbolically. Expressions are hashed and indexed in a common lookup table, thus allows for identifying common subexpressions.&lt;/li&gt; &#xA;   &lt;li&gt;Derivatives are computed by reverse accumulation method.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Generate code which can be compiled with optimization solvers (such as LBFGS, LBFGS-B, Ipopt, see &lt;a href=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/solvers&#34;&gt;solvers&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Supported operations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;basic algebraic operations: addition, multiplication, etc.&lt;/li&gt; &#xA; &lt;li&gt;complex related: real, imag, conjugate, etc.&lt;/li&gt; &#xA; &lt;li&gt;trigonometry, log, exponential, power.&lt;/li&gt; &#xA; &lt;li&gt;rotation, projection (think of Python&#39;s slice notation, but with type-safety), and injection (reverse of projection)&lt;/li&gt; &#xA; &lt;li&gt;piecewise function&lt;/li&gt; &#xA; &lt;li&gt;Fourier Transform, inverse Fourier Transform&lt;/li&gt; &#xA; &lt;li&gt;dot product (inner product), matrix multiplication&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;For those examples taken from Coursera&#39;s &lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;Machine Learning&lt;/a&gt;, data and plotting scripts are based on &lt;a href=&#34;https://github.com/nsoojin/coursera-ml-py&#34;&gt;https://github.com/nsoojin/coursera-ml-py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Linear regression&lt;/h3&gt; &#xA;&lt;p&gt;Taken from &lt;a href=&#34;https://github.com/nsoojin/coursera-ml-py/tree/master/machine-learning-ex1&#34;&gt;exercise 1&lt;/a&gt; - &lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;Machine Learning&lt;/a&gt; - Coursera.&lt;/p&gt; &#xA;&lt;p&gt;Model is in &lt;a href=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/app/Examples/LinearRegression.hs&#34;&gt;app/Examples/LinearRegression.hs&lt;/a&gt;, data &amp;amp; plotting script is in &lt;a href=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/examples/LinearRegression&#34;&gt;examples/LinearRegression&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;ex1_linearRegression :: OptimizationProblem&#xA;ex1_linearRegression =&#xA;  let x = param1D @97 &#34;x&#34;&#xA;      y = param1D @97 &#34;y&#34;&#xA;      theta0 = variable &#34;theta0&#34;&#xA;      theta1 = variable &#34;theta1&#34;&#xA;      objective = norm2square ((theta0 *. 1) + (theta1 *. x) - y)&#xA;   in OptimizationProblem&#xA;        { objective = objective,&#xA;          constraints = [],&#xA;          values =&#xA;            [ x :-&amp;gt; VFile (TXT &#34;x.txt&#34;),&#xA;              y :-&amp;gt; VFile (TXT &#34;y.txt&#34;)&#xA;            ]&#xA;        }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(&lt;code&gt;(*.)&lt;/code&gt; is scaling )&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/docs/images/ex1_before.png&#34; width=&#34;450px&#34;&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/docs/images/ex1_after.png&#34; width=&#34;450px&#34;&gt; &#xA;&lt;h3&gt;Logistic regression&lt;/h3&gt; &#xA;&lt;p&gt;Taken from &lt;a href=&#34;https://github.com/nsoojin/coursera-ml-py/tree/master/machine-learning-ex2&#34;&gt;exercise 2&lt;/a&gt; - &lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;Machine Learning&lt;/a&gt; - Coursera.&lt;/p&gt; &#xA;&lt;p&gt;Model is in &lt;a href=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/app/Examples/LogisticRegression.hs&#34;&gt;app/Examples/LogisticRegression.hs&lt;/a&gt;, data &amp;amp; plotting script is in &lt;a href=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/examples/LogisticRegression&#34;&gt;examples/LogisticRegression&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;sigmoid :: (ToShape d) =&amp;gt; TypedExpr d R -&amp;gt; TypedExpr d R&#xA;sigmoid x = 1.0 / (1.0 + exp (- x))&#xA;&#xA;ex2_logisticRegression :: OptimizationProblem&#xA;ex2_logisticRegression =&#xA;  let -- variables&#xA;      theta = variable1D @28 &#34;theta&#34;&#xA;      -- parameters&#xA;      x = param2D @118 @28 &#34;x&#34;&#xA;      y = param1D @118 &#34;y&#34;&#xA;      hypothesis = sigmoid (x ** theta)&#xA;      -- regularization&#xA;      lambda = 1&#xA;      regTheta = project (range @1 @27) theta&#xA;      regularization = (lambda / 2) * (regTheta &amp;lt;.&amp;gt; regTheta)&#xA;   in OptimizationProblem&#xA;        { objective = sumElements ((- y) * log hypothesis - (1 - y) * log (1 - hypothesis)) + regularization,&#xA;          constraints = [],&#xA;          values =&#xA;            [ x :-&amp;gt; VFile (TXT &#34;x_expanded.txt&#34;),&#xA;              y :-&amp;gt; VFile (TXT &#34;y.txt&#34;)&#xA;            ]&#xA;        }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;( &lt;code&gt;(**)&lt;/code&gt; is matrix multiplication, &lt;code&gt;(&amp;lt;.&amp;gt;)&lt;/code&gt; is dot product, &lt;code&gt;project (range @1 @27, at @0) theta&lt;/code&gt; is the typed version of &lt;code&gt;theta[1:27,0]&lt;/code&gt; )&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/docs/images/ex2_before.png&#34; width=&#34;450px&#34;&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/docs/images/ex2_after.png&#34; width=&#34;450px&#34;&gt; &#xA;&lt;h3&gt;MRI Reconstruction&lt;/h3&gt; &#xA;&lt;p&gt;Model is in &lt;a href=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/app/Examples/Brain.hs&#34;&gt;app/Examples/Brain.hs&lt;/a&gt;, data is in &lt;a href=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/examples/Brain&#34;&gt;examples/Brain&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;brainReconstructFromMRI :: OptimizationProblem&#xA;brainReconstructFromMRI =&#xA;  let -- variables&#xA;      x = variable2D @128 @128 &#34;x&#34;&#xA;      --- bound&#xA;      xLowerBound = bound2D @128 @128 &#34;x_lb&#34;&#xA;      xUpperBound = bound2D @128 @128 &#34;x_ub&#34;&#xA;      -- parameters&#xA;      im = param2D @128 @128 &#34;im&#34;&#xA;      re = param2D @128 @128 &#34;re&#34;&#xA;      mask = param2D @128 @128 &#34;mask&#34;&#xA;      -- regularization&#xA;      regularization = norm2square (rotate (0, 1) x - x) + norm2square (rotate (1, 0) x - x)&#xA;      lambda = 3000&#xA;   in OptimizationProblem&#xA;        { objective =&#xA;            norm2square ((mask +: 0) * (ft (x +: 0) - (re +: im)))&#xA;              + lambda * regularization,&#xA;          constraints =&#xA;            [ x .&amp;lt;= xUpperBound,&#xA;              x .&amp;gt;= xLowerBound&#xA;            ],&#xA;          values =&#xA;            [ im :-&amp;gt; VFile (HDF5 &#34;kspace.h5&#34; &#34;im&#34;),&#xA;              re :-&amp;gt; VFile (HDF5 &#34;kspace.h5&#34; &#34;re&#34;),&#xA;              mask :-&amp;gt; VFile (HDF5 &#34;mask.h5&#34; &#34;mask&#34;),&#xA;              xLowerBound :-&amp;gt; VFile (HDF5 &#34;bound.h5&#34; &#34;lb&#34;),&#xA;              xUpperBound :-&amp;gt; VFile (HDF5 &#34;bound.h5&#34; &#34;ub&#34;)&#xA;            ]&#xA;        }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/docs/images/brain_before.png&#34; width=&#34;450px&#34;&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/docs/images/brain_after.png&#34; width=&#34;450px&#34;&gt; &#xA;&lt;h3&gt;Neural network&lt;/h3&gt; &#xA;&lt;p&gt;Taken from &lt;a href=&#34;https://github.com/nsoojin/coursera-ml-py/tree/master/machine-learning-ex4&#34;&gt;exercise 4&lt;/a&gt; - &lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;Machine Learning&lt;/a&gt; - Coursera.&lt;/p&gt; &#xA;&lt;p&gt;Model is in &lt;a href=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/app/Examples/NeuralNetwork.hs&#34;&gt;app/Examples/NeuralNetwork.hs&lt;/a&gt;, data &amp;amp; plotting script is in &lt;a href=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/examples/NeuralNetwork&#34;&gt;examples/NeuralNetwork&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;sigmoid :: (ToShape d) =&amp;gt; TypedExpr d R -&amp;gt; TypedExpr d R&#xA;sigmoid x = 1.0 / (1.0 + exp (- x))&#xA;&#xA;prependColumn ::&#xA;  forall m n.&#xA;  (Injectable 0 (m - 1) m m, Injectable 1 n n (n + 1)) =&amp;gt;&#xA;  Double -&amp;gt;&#xA;  TypedExpr &#39;[m, n] R -&amp;gt;&#xA;  TypedExpr &#39;[m, n + 1] R&#xA;prependColumn v exp = inject (range @0 @(m - 1), range @1 @n) exp (constant2D @m @(n + 1) v)&#xA;&#xA;ex4_neuralNetwork :: OptimizationProblem&#xA;ex4_neuralNetwork =&#xA;  let x = param2D @5000 @400 &#34;x&#34;&#xA;      y = param2D @5000 @10 &#34;y&#34;&#xA;      -- variables&#xA;      theta1 = variable2D @401 @25 &#34;theta1&#34;&#xA;      theta2 = variable2D @26 @10 &#34;theta2&#34;&#xA;      -- neural net&#xA;      a1 = prependColumn 1 x&#xA;      z2 = sigmoid (a1 ** theta1)&#xA;      a2 = prependColumn 1 z2&#xA;      hypothesis = sigmoid (a2 ** theta2)&#xA;      -- regularization&#xA;      lambda = 1&#xA;      regTheta1 = project (range @1 @400, range @0 @24) theta1 -- no first row&#xA;      regTheta2 = project (range @1 @25, range @0 @9) theta2 -- no first row&#xA;      regularization = (lambda / 2) * (norm2square regTheta1 + norm2square regTheta2)&#xA;   in OptimizationProblem&#xA;        { objective = sumElements ((- y) * log hypothesis - (1 - y) * log (1 - hypothesis)) + regularization,&#xA;          constraints = [],&#xA;          values =&#xA;            [ x :-&amp;gt; VFile (HDF5 &#34;data.h5&#34; &#34;x&#34;),&#xA;              y :-&amp;gt; VFile (HDF5 &#34;data.h5&#34; &#34;y&#34;)&#xA;            ]&#xA;        }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/docs/images/nn_before.png&#34; width=&#34;450px&#34;&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/McMasterU/HashedExpression/master/docs/images/nn_weight.png&#34; width=&#34;450px&#34;&gt; &#xA;&lt;p&gt;(The second image visualizes the (trained) hidden layer. Training set accuracy 99.64%)&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please read &lt;code&gt;Contributing.md&lt;/code&gt;. PRs are welcome.&lt;/p&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;The project is developed and maintained by &lt;a href=&#34;https://github.com/christopheranand&#34;&gt;Dr. Christopher Anand&lt;/a&gt;&#39;s research group, Computing and Software department, McMaster University.&lt;/p&gt; &#xA;&lt;p&gt;List of contributors:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dandoh&#34;&gt;Nhan Thai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dalvescb&#34;&gt;Curtis D&#39;alves&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/christopheranand&#34;&gt;Christopher Anand&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CSchank&#34;&gt;Christopher Schankula&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Nasim91&#34;&gt;Nasim Khoonkari &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ghhabib2&#34;&gt;Habib Ghaffari Hadigheh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/padmapasupathi&#34;&gt;Padma Pasupathi&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>danr/structural-induction</title>
    <updated>2023-05-07T01:37:22Z</updated>
    <id>tag:github.com,2023-05-07:/danr/structural-induction</id>
    <link href="https://github.com/danr/structural-induction" rel="alternate"></link>
    <summary type="html">&lt;p&gt;SII: Structural Induction Instantiator over any strictly-positive algebraic data type.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;This package aims to perform the fiddly details of instantiating induction schemas for algebraic data types. The library is parameterised over the type of variables (&lt;code&gt;v&lt;/code&gt;), constructors (&lt;code&gt;c&lt;/code&gt;) and types (&lt;code&gt;t&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s see how it looks if you instantiate all these three with String and want to do induction over natural numbers. First, one needs to create a type environment, a &lt;code&gt;TyEnv&lt;/code&gt;. For every type (we only have one), we need to list its constructors. For each constructor, we need to list its arguments and whether they are recursive or not.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;testEnv :: TyEnv String String&#xA;testEnv &#34;Nat&#34; = Just [ (&#34;zero&#34;,[]) , (&#34;succ&#34;,[Rec &#34;Nat&#34;]) ]&#xA;testEnv _ = Nothing&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now, we can use the &lt;code&gt;subtermInduction&lt;/code&gt; to get induction hypotheses which are just subterms of the conclusion. Normally, you would translate the &lt;code&gt;Term&lt;/code&gt;s from the proof &lt;code&gt;Obligation&lt;/code&gt;s to some other representation, but there is also linearisation functions included (&lt;code&gt;linObligations&lt;/code&gt;, for instance.)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;natInd :: [String] -&amp;gt; [Int] -&amp;gt; IO ()&#xA;natInd vars coords = putStrLn&#xA;    $ render&#xA;    $ linObligations strStyle&#xA;    $ unTag (\(x :~ i) -&amp;gt; x ++ show i)&#xA;    $ subtermInduction testEnv typed_vars coords&#xA;  where&#xA;    typed_vars = zip vars (repeat &#34;Nat&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The library will create fresh variables for you (called &lt;code&gt;Tagged&lt;/code&gt; variables), but you need to remove them, using for instance &lt;code&gt;unTag&lt;/code&gt;. If you want to sync it with your own name supply, use &lt;code&gt;unTagM&lt;/code&gt; or &lt;code&gt;unTagMapM&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;An example invocation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;*Mini&amp;gt; natInd [&#34;X&#34;] [0]&#xA;P(zero).&#xA;! [X1 : Nat] : (P(X1) =&amp;gt; P(succ(X1))).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This means to do induction on the zeroth coord (hence the &lt;code&gt;0&lt;/code&gt;), and the variable is called &#34;X&#34;. When using the library, it is up to you to translate the abstract &lt;code&gt;P&lt;/code&gt; predicate to something meaningful.&lt;/p&gt; &#xA;&lt;p&gt;We can also do induction on several variables:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;*Mini&amp;gt; natInd [&#34;X&#34;,&#34;Y&#34;] [0,1]&#xA;P(zero,zero).&#xA;! [Y3 : Nat] : (P(zero,Y3) =&amp;gt; P(zero,succ(Y3))).&#xA;! [X1 : Nat] : (P(X1,zero) =&amp;gt; P(succ(X1),zero)).&#xA;! [X1 : Nat,Y3 : Nat] :&#xA;    (P(X1,Y3) &amp;amp;&#xA;    P(X1,succ(Y3)) &amp;amp;&#xA;    P(succ(X1),Y3)&#xA;     =&amp;gt; P(succ(X1),succ(Y3))).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the last step case, all proper subterms of &lt;code&gt;succ(X1),succ(Y3)&lt;/code&gt; are used as hypotheses.&lt;/p&gt; &#xA;&lt;p&gt;A bigger example is in &lt;code&gt;example/Example.hs&lt;/code&gt; in the distribution.&lt;/p&gt;</summary>
  </entry>
</feed>