<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-15T02:03:54Z</updated>
  <subtitle>Weekly Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>yihui/knitr</title>
    <updated>2023-01-15T02:03:54Z</updated>
    <id>tag:github.com,2023-01-15:/yihui/knitr</id>
    <link href="https://github.com/yihui/knitr" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A general-purpose tool for dynamic report generation in R&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;knitr&lt;/h1&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/yihui/knitr/actions/workflows/R-CMD-check.yaml&#34;&gt;&lt;img src=&#34;https://github.com/yihui/knitr/actions/workflows/R-CMD-check.yaml/badge.svg?sanitize=true&#34; alt=&#34;R-CMD-check&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/yihui/knitr/actions/workflows/knitr-examples.yaml&#34;&gt;&lt;img src=&#34;https://github.com/yihui/knitr/actions/workflows/knitr-examples.yaml/badge.svg?sanitize=true&#34; alt=&#34;Check knitr examples&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/yihui/knitr?branch=master&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/yihui/knitr/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;Codecov test coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cran.r-project.org/package=knitr&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/knitr&#34; alt=&#34;CRAN release&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;p&gt;The R package &lt;strong&gt;knitr&lt;/strong&gt; is a general-purpose literate programming engine, with lightweight API&#39;s designed to give users full control of the output without heavy coding work. It combines many features into one package with slight tweaks motivated from my everyday use of Sweave. See the package &lt;a href=&#34;https://yihui.org/knitr/&#34;&gt;homepage&lt;/a&gt; for details and examples. See &lt;a href=&#34;https://yihui.org/knitr/faq/&#34;&gt;FAQ&#39;s&lt;/a&gt; for a list of frequently asked questions (including where to ask questions).&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install the stable version on &lt;a href=&#34;https://cran.r-project.org/package=knitr&#34;&gt;CRAN&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#39;knitr&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also install the development version (hourly build) from &lt;a href=&#34;https://yihui.r-universe.dev&#34;&gt;https://yihui.r-universe.dev&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;options(repos = c(&#xA;  yihui = &#39;https://yihui.r-universe.dev&#39;,&#xA;  CRAN = &#39;https://cloud.r-project.org&#39;&#xA;))&#xA;&#xA;install.packages(&#39;knitr&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Motivation&lt;/h2&gt; &#xA;&lt;p&gt;While Sweave and related add-on packages like &lt;a href=&#34;https://cran.r-project.org/package=cacheSweave&#34;&gt;&lt;strong&gt;cacheSweave&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/package=pgfSweave&#34;&gt;&lt;strong&gt;pgfSweave&lt;/strong&gt;&lt;/a&gt; are fairly good engines for literate programming in R, I often feel my hands are tied. For example:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;I stared at the source code of Sweave and wished for hundreds of times, &lt;em&gt;if only I could easily insert&lt;/em&gt; &lt;code&gt;[width=.8\textwidth]&lt;/code&gt; &lt;em&gt;between&lt;/em&gt; &lt;code&gt;\includegraphics&lt;/code&gt; &lt;em&gt;and&lt;/em&gt; &lt;code&gt;{my-plot.pdf}&lt;/code&gt;. (The official way in Sweave is &lt;code&gt;\setkeys{Gin}&lt;/code&gt; but it is setting a global width, which is unrealistic since we often have to set widths individually; yes, you can use &lt;code&gt;\setkeys{Gin}&lt;/code&gt; for many times, but why not just provide an option for each chunk?)&lt;/li&gt; &#xA; &lt;li&gt;I wished for many times, &lt;em&gt;if only I could use graphics devices other than PDF and postscript&lt;/em&gt;; now the dream has come true in the official R, but what I was hoping for was an option as simple as &lt;code&gt;dev = &#39;png&#39;&lt;/code&gt; or &lt;code&gt;dev = &#39;CairoJPEG&#39;&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;I wished multiple plots in a code chunk could be recorded instead of only the last one.&lt;/li&gt; &#xA; &lt;li&gt;I wished there was a way to round the numbers in &lt;code&gt;\Sexpr{}&lt;/code&gt; other than writing expressions like &lt;code&gt;\Sexpr{round(x, 3)}&lt;/code&gt; for &lt;em&gt;each single&lt;/em&gt; &lt;code&gt;\Sexpr{}&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;I wished I did not have to &lt;code&gt;print()&lt;/code&gt; plots from. &lt;a href=&#34;https://cran.r-project.org/package=ggplot2&#34;&gt;&lt;strong&gt;ggplot2&lt;/strong&gt;&lt;/a&gt; and a simple &lt;code&gt;qplot(x, y)&lt;/code&gt; would just give me a plot in Sweave.&lt;/li&gt; &#xA; &lt;li&gt;I wished users would never need instructions on &lt;code&gt;Sweave.sty&lt;/code&gt; or run into troubles due to the fact that LaTeX cannot find &lt;code&gt;Sweave.sty&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;I wished &lt;strong&gt;cacheSweave&lt;/strong&gt; could print the results of a code chunk even if it was cached.&lt;/li&gt; &#xA; &lt;li&gt;I wished &lt;a href=&#34;https://cran.r-project.org/package=brew&#34;&gt;&lt;strong&gt;brew&lt;/strong&gt;&lt;/a&gt; could support graphics.&lt;/li&gt; &#xA; &lt;li&gt;I wished &lt;a href=&#34;https://cran.r-project.org/package=R2HTML&#34;&gt;&lt;strong&gt;R2HTML&lt;/strong&gt;&lt;/a&gt; could support R code syntax highlighting.&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/dp/1498716962/&#34;&gt;&lt;img src=&#34;http://i.imgur.com/yYw46aF.jpg&#34; align=&#34;right&#34; alt=&#34;The book Dynamic Documents with R and knitr&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The package &lt;strong&gt;knitr&lt;/strong&gt; was designed to give the user access to every part of the process of dealing with a literate programming document, so there is no need to hack at any core components if you want more freedom. I have gone through the source code of &lt;strong&gt;pgfSweave&lt;/strong&gt; and &lt;strong&gt;cacheSweave&lt;/strong&gt; for a couple of times and I often feel uncomfortable with the large amount of code copied from official R, especially when R has a new version released (I will begin to worry if the add-on packages are still up-to-date with the official Sweave).&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(knitr)&#xA;?knit&#xA;knit(input)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If options are not explicitly specified, &lt;strong&gt;knitr&lt;/strong&gt; will try to guess reasonable default settings. A few manuals are available such as the &lt;a href=&#34;https://yihui.org/knitr/demo/manual/&#34;&gt;main manual&lt;/a&gt;, and the &lt;a href=&#34;https://yihui.org/knitr/demo/graphics/&#34;&gt;graphics manual&lt;/a&gt;. For a more organized reference, see the &lt;a href=&#34;https://www.amazon.com/dp/1498716962/&#34;&gt;knitr book&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This package is free and open source software, licensed under GPL.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>GoogleCloudPlatform/google-analytics-premium-bigquery-statistics</title>
    <updated>2023-01-15T02:03:54Z</updated>
    <id>tag:github.com,2023-01-15:/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics</id>
    <link href="https://github.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tutorial: Create a Remarketing List with Predictive Analytics&lt;/h1&gt; &#xA;&lt;p&gt;In this tutorial, you will learn how to create a predictive model for customer conversion based on a combination of in-house CRM data and Google Analytics Premium logs. It consists of an initial code lab using pre-generated sample data, followed by a detailed implementation guide that shows you how to put predictive analytics into practice using your own data.&lt;/p&gt; &#xA;&lt;p&gt;The material in this repository complements &lt;a href=&#34;https://cloud.google.com/solutions/google-analytics-bigquery&#34;&gt;an article&lt;/a&gt; introducing the topic on the Google Cloud Platform Solutions website.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/code-lab-2-chevron.png&#34; alt=&#34;Two step tutorial&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;You will start by diving into the deep-end and use the &lt;a href=&#34;http://www.r-project.org/&#34;&gt;R&lt;/a&gt; statistics software to generate a report of how probable it is to make a conversion for a given customer based on website behaviour. This will be a step-by-step code-lab which aims to give you a solid grounding in some of the statistical methods you can incorporate into your own predictive analytics. Hopefully, it will also whet your appetite for implementing this using your own Google Analytics Premium and CRM data.&lt;/p&gt; &#xA;&lt;p&gt;Following the code lab, you can move onto the detailed implementation guide showing you how to analyze your own Google Analytics Premium logs using the powerful capabilities of BigQuery. The implementation guide will walk you through the required steps to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;setup your website to capture the all-important Google Analytics Client ID&lt;/li&gt; &#xA; &lt;li&gt;use BigQuery to generate your own training dataset for creating a statistical model&lt;/li&gt; &#xA; &lt;li&gt;create a &lt;a href=&#34;https://support.google.com/adwords/answer/2453998?hl=en&#34;&gt;remarketing&lt;/a&gt; list based on your statistical predictive model, again using the power of BigQuery&lt;/li&gt; &#xA; &lt;li&gt;create an AdWords audience that will target only the website visitors that are more likely to convert into a sale&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you&#39;re all set to go, dive into the code lab to build a statistical model.&lt;/p&gt; &#xA;&lt;h2&gt;Code Lab: Create a Remarketing List with Predictive Analytics&lt;/h2&gt; &#xA;&lt;p&gt;In this code lab you will analyze a sample dataset and create a predictive statistical model based on a combination of CRM and website log data. You will be using the R software to analyze the sample data.&lt;/p&gt; &#xA;&lt;h3&gt;Before you Start&lt;/h3&gt; &#xA;&lt;p&gt;The code lab makes some assumptions about your skills and experience. These are not strict requirements, but ideally, you will have some experience using R and a basic understanding of statistical concepts like &lt;a href=&#34;https://en.wikipedia.org/wiki/Correlation_and_dependence&#34;&gt;correlation&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_regression&#34;&gt;regression&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Follow these steps to setup R on your platform if you do not already have an R environment available:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download and install R for your platform using &lt;a href=&#34;http://cran.rstudio.com/&#34;&gt;these installation instructions&lt;/a&gt;. The Code Lab was developed and tested using R v3.2.1., but a later version should work as well.&lt;/li&gt; &#xA; &lt;li&gt;Install the required R packages by following these steps: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Start your R interactive environment by executing the &lt;code&gt;R&lt;/code&gt; command&lt;/li&gt; &#xA;   &lt;li&gt;Run the following commands on the interactive prompt&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; install.packages(&#34;ggplot2&#34;)&#xA;&amp;gt; install.packages(&#34;ROCR&#34;)&#xA;&amp;gt; install.packages(&#34;car&#34;)&#xA;&amp;gt; install.packages(&#34;rms&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;The Code Lab Scenario&lt;/h3&gt; &#xA;&lt;p&gt;The example scenario is that of a car dealership chain with showrooms across the nation. Your company website provides general information and advertises your latest promotions, but all actual car sales happen in-person in one of your showrooms. Wouldn&#39;t it be great if you could find out which website visitors are most likely to visit your showroom and take a test drive if you reach out to them?&lt;/p&gt; &#xA;&lt;p&gt;Conveniently, the internal company CRM system has a field, &lt;code&gt;customer_level&lt;/code&gt;, that records the level of engagement the customer has had with the company to date. A value of 3, for example, means that the customer has been on a test drive. A value of 5 means that the customer has made a car purchase.&lt;/p&gt; &#xA;&lt;p&gt;In an attempt to analyse this existing data and better understand how their website has affected customers&#39; decisions and behaviour in the past, the company has linked their historical Google Analytics Premium log data and the relevant CRM customer records together. They now want to build a statistical model from the historical data, with the aim of using this model to predict future behaviour and prioritise remarketing efforts towards website visitors who seem most likely to further engage based on their web browsing on the corporate website.&lt;/p&gt; &#xA;&lt;p&gt;To this end, the company has added a field in the CRM called &lt;code&gt;CV_flag&lt;/code&gt; to indicate whether a customer has at least taken a test drive. In other words, &lt;code&gt;CV_flag&lt;/code&gt; will be &lt;code&gt;1&lt;/code&gt; if the &lt;code&gt;customer_level&lt;/code&gt; is &lt;code&gt;3&lt;/code&gt; or higher, and &lt;code&gt;0&lt;/code&gt; otherwise. They have created a set of training data based on historical GAP logs linked to specific customers in the CRM, including the &lt;code&gt;CV_flag&lt;/code&gt; variable, and now it is your job to take this data and build a statistical model (in the implementation guide you will learn how to create this type of training data using your own data).&lt;/p&gt; &#xA;&lt;h3&gt;Building the model&lt;/h3&gt; &#xA;&lt;p&gt;This model hinges on a binary outcome. Either the customer converts and at least books a test drive (success) or they don&#39;t (failure). To model this scenario, you will build a statistical model using &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_regression&#34;&gt;logistic regression&lt;/a&gt; analysis to predict the likelihood of a conversion.&lt;/p&gt; &#xA;&lt;p&gt;The formal model can be defined as follows:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/bernoulli-formula.png&#34; alt=&#34;Bernoulli function&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Y&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt; is the objective variable, in this case the conversion success or failure for each customer, &lt;em&gt;i&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;X&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt; is the explanatory variable&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;alpha&lt;/em&gt; is the intercept and &lt;em&gt;beta&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt; are the regression coefficients&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;p&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt; is predicting the conversion rate, which will be used in the remarketing list&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The sample data has been provided in &lt;code&gt;sample_data/train_data.csv.&lt;/code&gt;If you open the file to have a look, you will see that it contains comma separated values (CSV) where the first line contains the header information for each column. (After completing this code lab you will learn how to create this type of file using your own data)&lt;/p&gt; &#xA;&lt;p&gt;The first two fields, &lt;code&gt;a_fullVisitorId&lt;/code&gt; and &lt;code&gt;a_hits_customDimensions_value&lt;/code&gt; are unique IDs that are generated by Google Analytics Premium to identify a specific client device (Client ID). The next fields from &lt;code&gt;a_COUNT&lt;/code&gt; to &lt;code&gt;a_page201406&lt;/code&gt; are Google Analytics Premium fields that the data analysts deemed potentially relevant to the model. And finally, &lt;code&gt;b_hits_customDimensions_value&lt;/code&gt; provides the CRM link back to the Google Analytics Premium data and &lt;code&gt;b_CV_flag&lt;/code&gt; refers to the conversion flag for that customer. You can find detailed descriptions for all Google Analytics Premium fields &lt;a href=&#34;https://support.google.com/analytics/answer/3437719?hl=en&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Enough with the build-up, let&#39;s run some code! Open your R interactive execution environment so that you see a &lt;code&gt;&amp;gt;&lt;/code&gt; prompt, typically by running the following command from the root folder of the cloned github repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ R&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If your R execution environment is different, run the commands in the manner that you usually run interactively with your R installation.&lt;/p&gt; &#xA;&lt;p&gt;First, you need to read the data in the &lt;code&gt;train_data.csv&lt;/code&gt; file and check that the correct columns have been imported. Execute the commands below to save the sample data in the variable &lt;code&gt;data1&lt;/code&gt; (Do not enter the &lt;code&gt;&amp;gt;&lt;/code&gt;, it only represents the interactive R prompt):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; data1 &amp;lt;- read.csv(&#34;./sample_data/train_data.csv&#34;)&#xA;&amp;gt; names(data1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see 23 columns at this point. Some of these columns are probably not relevant to the statistical model. Specifically, you can remove the &lt;code&gt;a_fullVisitorId&lt;/code&gt;, &lt;code&gt;a_hits_customDimensions_value&lt;/code&gt;, &lt;code&gt;a_mobile_flag&lt;/code&gt; and &lt;code&gt;b_hits_customDimensions_value&lt;/code&gt;, or columns number 1, 2, 12 and 22. To do so, run the following command that removes these columns from the variable &lt;code&gt;data1&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; data1 &amp;lt;- data1[c(-1,-2,-12,-22)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Based on this data, you can now generate correlation coefficients for each pair of variables. The correlation coefficients tell you how correlated two variables are where a value of 1 or -1 means they are perfectly positively or negatively correlated. A value of 0 means they are completely uncorrelated. For this model, you will select 0.9 as the upper threshold. The commands below outputs the correlation coefficients for each variable pair.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; cor(data1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Let&#39;s group correlations and assign them ASCII symbols in the output so we can see which ones are most interesting.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; symnum(abs(cor(data1)),cutpoints = c(0, 0.2, 0.4, 0.6, 0.9, 1), symbols = c(&#34; &#34;, &#34;.&#34;, &#34;_&#34;, &#34;+&#34;, &#34;*&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Look for the &lt;code&gt;*&lt;/code&gt; symbol to indicate a value higher than 0.9. Note that each variable&#39;s own coefficient is always &lt;code&gt;1&lt;/code&gt;, so don&#39;t remove all the stars. Below is an extract from the sample data, showing two examples of strong correlation coefficients.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;                        a_SUM_totals_hits&#xA;a_SUM_totals_pageviews  0.954889672&#xA;&#xA;                        a_diffdays_oldest&#xA;a_diffdays_latest       0.968898001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Based on this, you should exclude one of each pair, in this case &lt;code&gt;a_SUM_totals_hits&lt;/code&gt; and &lt;code&gt;a_diffdays_oldest&lt;/code&gt; from the model. This is easily done using R using the following command. The &lt;code&gt;data1&lt;/code&gt; variable now no longer contains columns 3 and 7:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; data1 &amp;lt;- data1[c(-3,-7)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you were to run through with this data to the end, you would find that the regression coefficient for the &lt;code&gt;a_midnight_flag&lt;/code&gt; variable would be undefined when running the model. So in the interest of time you can remove this variable from the data by running the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; data1 &amp;lt;- data1[,c(-13)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run the Regression&lt;/h3&gt; &#xA;&lt;p&gt;In this step, you will run the regression. You will use the R function &lt;code&gt;glm&lt;/code&gt; to perform the logistic regression by specifying a binomial distribution (&lt;code&gt;family=binomial&lt;/code&gt;). You can generate the initial model and print the results to the screen with the following commands. Note the use of &lt;code&gt;b_CV_flag&lt;/code&gt; as the objective variable:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; model &amp;lt;- glm(formula = b_CV_flag ~., data = data1, family = binomial(&#34;logit&#34;))&#xA;&amp;gt; result &amp;lt;- summary(model)&#xA;&amp;gt; result&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This shows the estimated coefficients. Before you accept this model, however, you should check for multicollinearity, dependencies between three or more variables. To do this, you can use the &lt;code&gt;vif&lt;/code&gt; function and see if any variables have a VIF (Variables Inflation Factor) of more than 10. If so, you should also exclude those variables from the analysis. For this function to work, you&#39;ll need to load a couple of the previously installed libraries.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; library(car)&#xA;&amp;gt; library(rms)&#xA;&amp;gt; vif(model)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see that two variables have a value of more than 10, &lt;code&gt;a_SUM_totals_pageviews&lt;/code&gt; (over 30) and &lt;code&gt;a_SUM_hits_hitNumber&lt;/code&gt; (over 27). In other words, multicollinearity occurs. Therefore, you should delete one of the variables, in this case &lt;code&gt;a_SUM_totals_pageviews&lt;/code&gt;, and rerun the logistic analysis giving the data set and model a new name, &lt;code&gt;data1_2&lt;/code&gt; and &lt;code&gt;model1_2&lt;/code&gt; respectively.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; data1_2 &amp;lt;- data1[,c(-2)]&#xA;&amp;gt; model1_2 &amp;lt;- glm(formula = b_CV_flag ~., data = data1_2, family = binomial(&#34;logit&#34;))&#xA;&amp;gt; result1_2 &amp;lt;- summary(model1_2)&#xA;&amp;gt; result1_2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Below is the result output, showing the estimated model. The estimated coefficients are listed in the column &lt;code&gt;Estimate&lt;/code&gt; for each of the included variables.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Call:&#xA;glm(formula = b_CV_flag ~ ., family = binomial(&#34;logit&#34;), data = data1_2)&#xA;&#xA;Deviance Residuals:&#xA;    Min       1Q   Median       3Q      Max&#xA;-2.0110  -0.5281  -0.2039  -0.0923   3.2817&#xA;&#xA;Coefficients:&#xA;                          Estimate Std. Error z value Pr(&amp;gt;|z|)&#xA;(Intercept)             -2.3298773  1.3069659  -1.783   0.0746 .&#xA;a_COUNT                  0.0578391  0.2152773   0.269   0.7882&#xA;a_SUM_totals_timeOnSite -0.0004421  0.0003392  -1.303   0.1924&#xA;a_SUM_hits_hitNumber     0.0389365  0.0433719   0.898   0.3693&#xA;a_diffdays_latest       -0.1301964  0.0110120 -11.823   &amp;lt;2e-16 ***&#xA;a_desktop_flag           0.9450177  1.1271481   0.838   0.4018&#xA;a_tablet_flag            2.9104792  1.3544122   2.149   0.0316 *&#xA;a_OS_Windows_flag        1.0340938  0.9495262   1.089   0.2761&#xA;a_OS_Macintosh_flag      0.8657634  1.0523633   0.823   0.4107&#xA;a_SUM_morning_visit      0.3425241  0.2438371   1.405   0.1601&#xA;a_SUM_daytime_visit      0.2992608  0.2228069   1.343   0.1792&#xA;a_SUM_evening_visit      0.2578074  0.2488274   1.036   0.3002&#xA;a_page201404             0.3279693  0.3790867   0.865   0.3870&#xA;a_page201405             1.0019170  0.5065072   1.978   0.0479 *&#xA;a_page201406            -1.3596393  1.2626093  -1.077   0.2815&#xA;---&#xA;Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1&#xA;&#xA;(Dispersion parameter for binomial family taken to be 1)&#xA;&#xA;    Null deviance: 1062.20  on 1294  degrees of freedom&#xA;Residual deviance:  758.65  on 1280  degrees of freedom&#xA;AIC: 788.65&#xA;&#xA;Number of Fisher Scoring iterations: 7&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the VIF function again to check for multicollinearity, and the output should now show that there are no variables with VIF values over 10.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; vif(model1_2)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Verify the Model Accuracy (Gain and ROC)&lt;/h3&gt; &#xA;&lt;p&gt;One way to evaluate the value of a predictive model is to generate a cumulative Gain chart. Simply put, it visually shows the gain in response from using the predictive model as opposed to remarketing randomly across the customer database. The larger the distance between the Gain line and the baseline the better the predictive model is. To generate the Gain chart in R you will need to run the following commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; prob &amp;lt;- data.frame(predict(model1_2, data1_2, type = &#34;response&#34;))&#xA;&amp;gt; gain &amp;lt;- cumsum(sort(prob[, 1], decreasing = TRUE)) / sum(prob)&#xA;&amp;gt; png(&#39;gain_curve_plot.png&#39;)&#xA;&amp;gt; plot(gain,main =&#34;Gain chart&#34;,xlab=&#34;number of users&#34;, ylab=&#34;cumulative conversion rate&#34;)&#xA;&amp;gt; dev.off()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This saves the Gain chart as a PNG file called &lt;code&gt;gain_curve_plot.png&lt;/code&gt; in your local directory. It should look like this:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/gain_curve_plot.png&#34; alt=&#34;Gain chart&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The ROC (Receiver Operating Characteristic) curve, is normalized from the gain chart. Here, the value of AUC (the area under the ROC curve) becomes the indicator of the goodness of the performance of the classification algorithm. It takes a value between zero and one, where 0.5 would be random and a higher number would indicate a better model than randomness. You can generate the curve by running the R commands below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; pred &amp;lt;- prediction(prob, data1_2$b_CV_flag)&#xA;&amp;gt; perf &amp;lt;- performance(pred, measure = &#34;tpr&#34;, x.measure = &#34;fpr&#34;)&#xA;&amp;gt; pdf(&#39;Rplots.pdf&#39;)&#xA;&amp;gt; qplot(x = perf@x.values[[1]], y = perf@y.values[[1]], xlab = perf@x.name, ylab = perf@y.name, main=&#34;ROC curve&#34;)&#xA;&amp;gt; dev.off()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It saves the output graph in a PDF file named &lt;code&gt;Rplots.pdf&lt;/code&gt; in your local directory or opens a new window depending on which R tool you use. Either way, it should look like this.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/ROC_plot.png&#34; alt=&#34;ROC plot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Check the model in R using an alternative function, &lt;code&gt;lrm&lt;/code&gt; (logistic regression model):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; Logistic_Regression_Model &amp;lt;- lrm(b_CV_flag ~., data1_2)&#xA;&amp;gt; Logistic_Regression_Model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Check the AIC (An Information Criteria) of the two models. A smaller number indicates a better model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; AIC(model)&#xA;&amp;gt; AIC(model1_2)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As expected, the later model has a lower number and appears to be the better model. Use that model to create a simple coefficient list of all the variables. To do so, run the following commands to parse the data from &lt;code&gt;model1_2&lt;/code&gt; into something easy to copy and paste:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; coef &amp;lt;- names(model1_2$coefficient)&#xA;&amp;gt; value &amp;lt;- as.vector(model1_2$coefficient)&#xA;&amp;gt; result &amp;lt;- data.frame(coef, value)&#xA;&amp;gt; result&#xA;&#xA;                      coef         value&#xA;1              (Intercept) -2.3298773233&#xA;2                  a_COUNT  0.0578391477&#xA;3  a_SUM_totals_timeOnSite -0.0004420572&#xA;4     a_SUM_hits_hitNumber  0.0389364789&#xA;5        a_diffdays_latest -0.1301964399&#xA;6           a_desktop_flag  0.9450177277&#xA;7            a_tablet_flag  2.9104792404&#xA;8        a_OS_Windows_flag  1.0340938208&#xA;9      a_OS_Macintosh_flag  0.8657633791&#xA;10     a_SUM_morning_visit  0.3425240801&#xA;11     a_SUM_daytime_visit  0.2992608455&#xA;12     a_SUM_evening_visit  0.2578073685&#xA;13            a_page201404  0.3279692978&#xA;14            a_page201405  1.0019169671&#xA;15            a_page201406 -1.3596393104&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Congratulations! You&#39;ve successfully completed a statistical model based on historic data and come to the end of this code lab. But there&#39;s plenty more to learn in the next section where you will see a detailed implementation guide for how you can apply this approach to your own data. You will also learn how to take the coefficient values you generated in R and apply them to your visitor dataset in BigQuery to generate a remarketing list.&lt;/p&gt; &#xA;&lt;p&gt;All the commands are also provided in the &lt;code&gt;gap-bq-regression.r&lt;/code&gt; file. To execute this script, run the following command (assuming that you are running it from the base of the sample code):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ Rscript gap-bq-regression.r&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If your R execution environment is different, run the &lt;code&gt;gap-bq-regression.r&lt;/code&gt; scripts in the way you normally run r scripts. Running the script is the equivalent the step-by-step interactive execution you just performed.&lt;/p&gt; &#xA;&lt;h1&gt;Implementation Guide&lt;/h1&gt; &#xA;&lt;p&gt;Hopefully you&#39;ve been able to complete the code lab and are now ready to learn more about how to implement predictive analytics with Google Analytics Premium, BigQuery and R using your own data. In this implementation guide you will get a step by step view on what to do, as well as helpful templates to get you started.&lt;/p&gt; &#xA;&lt;p&gt;You&#39;ll go through these main steps:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/implementation-guide-chevron.png&#34; alt=&#34;The steps&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Step 1: Setup Google Analytics Premium and your Website&lt;/h2&gt; &#xA;&lt;p&gt;Before you can start implementing the predictive analytics, you need to have all these following preliminary steps completed:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Sign up for Google Analytics Premium&lt;/strong&gt;: Submit &lt;a href=&#34;http://www.google.com/analytics/premium/contact.html&#34;&gt;the signup form&lt;/a&gt; and our sales representative will walk you through the subscription process. After completing the process, you will receive a notification from the sales representative that you have successfully been signed up for Google Analytics Premium&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Configure your website to use Google Analytics:&lt;/strong&gt; If you&#39;re not using Analytics on your website already, &lt;a href=&#34;https://support.google.com/analytics/answer/1008015?hl=en&#34;&gt;you need to enable it&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Create a new project and open the BigQuery Browser tool:&lt;/strong&gt; Open the &lt;a href=&#34;https://console.developers.google.com/&#34;&gt;Google Developers Console&lt;/a&gt; and press [Create Project]. Open the project and click [Big Data] - [BigQuery] menu to launch the BigQuery Browser tool and take note of your Project ID&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Reach out to your Google Analytics Premium Account Manager to submit a BigQuery export request with your Project ID&lt;/strong&gt;: Your account manager will take care of your BigQuery export request and will give you a monthly credit of USD 500 towards usage of BigQuery for this project&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;That&#39;s it!&lt;/strong&gt; You will see your Google Analytics logs imported into your project several times per day, with BigQuery tables named &lt;em&gt;ga_sessions_YYYYMMDD&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Creating an Entry Form to Capture Client ID&lt;/h3&gt; &#xA;&lt;p&gt;You have at least two data sources: Google Analytics Premium logs and your own CRM or similar customer-based data. To link the two data sets, you need to have a unique key in both places to match a customer in your CRM with the web visitor that is browsing your website. The key you should use is called &lt;a href=&#34;https://developers.google.com/analytics/devguides/collection/analyticsjs/domains&#34;&gt;Client ID&lt;/a&gt; and is a unique key that is generated by Google Analytics Premium based on the cookie information of the visitor. This idea is illustrated below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/analytics-bigquery-crm-clientid.png&#34; alt=&#34;Client ID&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The question, then, is how do you get this Client ID inserted into your CRM database? One common approach is to set up a form on your website where visitors enter information, such as their name and email address, along with a hidden field for Client ID, and then save that information in your internal CRM database. By saving the same unique ID in Google Analytics you can tie the two records together. It is important to note that you should &lt;a href=&#34;https://support.google.com/analytics/answer/2795983?hl=en&#34;&gt;never save personally identifiable information (PII)&lt;/a&gt; in Google Analytics, just the &lt;em&gt;Client ID&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Add Google Analytics Client ID to HTML Entry Form&lt;/h3&gt; &#xA;&lt;p&gt;To achieve this in practice, your simple HTML entry form might look something like the below HTML snippet on your website, where the &lt;code&gt;/formComplete&lt;/code&gt; action will perform the necessary steps to save this information in your CRM system.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;form id=&#34;lead-form&#34; method=&#34;POST&#34; action=&#34;/formComplete&#34;&amp;gt;&#xA;&#x9;&amp;lt;input id=&#34;email&#34; type=&#34;text&#34;/&amp;gt;&#xA;&#x9;&amp;lt;input id=&#34;name&#34; type=&#34;text&#34;/&amp;gt;&#xA;&#x9;. . .&#xA;&#x9;&amp;lt;input id=&#34;clientId&#34; type=&#34;hidden&#34;/&amp;gt;&#xA;&#x9;&amp;lt;input type=&#34;submit&#34; value=&#34;Submit&#34;/&amp;gt;&#xA;&amp;lt;/form&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The key here is the hidden input field called &lt;code&gt;clientId&lt;/code&gt;. With just the HTML form element, this value would be empty when the visitor submits the form. Therefore, you will need to add some JavaScript code on your web page that will trigger when the visitor submits the &lt;code&gt;lead-form&lt;/code&gt; and inserts the value:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;&#xA;document.getElementById(&#39;lead-form&#39;).addEventListener(&#xA;  &#39;submit&#39;, function(event) {&#xA;  ga(function(tracker) {&#xA;    clientId = tracker.get(&#39;clientId&#39;);&#xA;    document.getElementById(&#39;clientId&#39;).value = clientId;&#xA;    tracker.send(&#39;event&#39;, &#39;online form&#39;, &#39;submit&#39;, {&#xA;      &#39;dimension6&#39;: clientId&#xA;  });&#xA;  }); });&#xA;&amp;lt;/script&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The three key lines are:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;    clientId = tracker.get(&#39;clientId&#39;);&#xA;    document.getElementById(&#39;clientId&#39;).value = clientId;&#xA;    tracker.send(&#39;event&#39;, &#39;online form&#39;, &#39;submit&#39;, {&#xA;      &#39;dimension6&#39;: clientId&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Line 1 gets the &lt;code&gt;clientId&lt;/code&gt; value, a unique identifier assigned to this website visitor, from the Google Analytics &lt;code&gt;tracker&lt;/code&gt; object&lt;/li&gt; &#xA; &lt;li&gt;Line 2 sets the hidden form field you just created to the value of &lt;code&gt;clientId&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;So when the website visitor submits the entry form, the unique &lt;code&gt;clientId&lt;/code&gt; identifier is saved in your CRM database.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Line 3 saves the &lt;code&gt;clientId&lt;/code&gt; as a custom dimension (&lt;code&gt;dimension6&lt;/code&gt;) in Google Analytics&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You may be wondering what the &lt;code&gt;dimension6&lt;/code&gt; element in the last line refers to. Google Analytics allows for custom data chosen by you to be added to its log entries, and call these &lt;a href=&#34;https://developers.google.com/analytics/devguides/collection/analyticsjs/custom-dims-mets&#34;&gt;&lt;em&gt;custom dimensions&lt;/em&gt;&lt;/a&gt;. The number represents the index of the particular dimension, index 6 in this case. If you are using multiple dimensions in your Google Analytics already, you may choose another index, for example &lt;code&gt;dimension7&lt;/code&gt; instead.&lt;/p&gt; &#xA;&lt;p&gt;Since you are using hit level custom dimensions you also need a way of injecting the &lt;code&gt;clientId&lt;/code&gt; into every page view on your website. Otherwise, Google Analytics Premium will not store this value for each hit. A sample script is provided below, but you should adapt this to fit your site, if necessary. See the &lt;a href=&#34;https://developers.google.com/analytics/devguides/collection/analyticsjs/custom-dims-mets&#34;&gt;developer guide&lt;/a&gt; for examples of different approaches you can take. This example &lt;a href=&#34;https://developers.google.com/analytics/devguides/collection/analyticsjs/&#34;&gt;Google Analytics snippet&lt;/a&gt; sets the &lt;code&gt;clientId&lt;/code&gt; for every page view in the custom dimension &lt;code&gt;dimension6&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;&#xA;  (function(i,s,o,g,r,a,m){i[&#39;GoogleAnalyticsObject&#39;]=r;i[r]=i[r]||function(){&#xA;  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),&#xA;  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)&#xA;  })(window,document,&#39;script&#39;,&#39;//www.google-analytics.com/analytics.js&#39;,&#39;ga&#39;);&#xA;&#xA;  ga(&#39;create&#39;, &#39;UA-XXXXX-Y&#39;, &#39;auto&#39;);&#xA;  ga(function(tracker) {&#xA;    var clientId = tracker.get(&#39;clientId&#39;);&#xA;    ga(&#39;set&#39;, &#39;dimension6&#39;, clientId);&#xA;  });&#xA;  ga(&#39;send&#39;, &#39;pageview&#39;);&#xA;&amp;lt;/script&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Congratulations! You&#39;ve successfully linked your CRM database with Google Analytics, so what&#39;s next? As it turns out, linking your different data sources opens up a number of exciting opportunities for generating more insight into your customers.&lt;/p&gt; &#xA;&lt;h2&gt;Step 2: Import your Own CRM Data into BigQuery&lt;/h2&gt; &#xA;&lt;p&gt;Before attempting this step, you need to &lt;a href=&#34;https://cloud.google.com/bigquery/bq-command-line-tool-quickstart#setup&#34;&gt;activate the BigQuery API&lt;/a&gt; (if you haven&#39;t already) and download the &lt;a href=&#34;https://cloud.google.com/sdk/&#34;&gt;Cloud SDK&lt;/a&gt;. This will allow you to use the &lt;a href=&#34;https://cloud.google.com/bigquery/bq-command-line-tool&#34;&gt;&lt;code&gt;bq&lt;/code&gt;&lt;/a&gt; command line tool to load data into BigQuery. You should also ensure that you are working with the correct Google Cloud Project (the one that you created when setting up the Google Analytics Premium export to BigQuery). To set the working project, you run the following command that is part of the Cloud SDK:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ gcloud config set project &amp;lt;project-id&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Where you replace the &lt;code&gt;&amp;lt;project-id&amp;gt;&lt;/code&gt; with the unique ID of your project.&lt;/p&gt; &#xA;&lt;p&gt;Your Google Analytics Premium logs are already imported automatically into BigQuery. But since the CRM database contains key columns like the conversion probability, you will need to import the CRM data into BigQuery as well to run queries against both data sources. You can do this easily using the &lt;code&gt;bq&lt;/code&gt; command line tool. You can find an example mock data set in the &lt;code&gt;sample_data/crm_mock_data.csv&lt;/code&gt; file if you just want to try it out before uploading your own CRM data.&lt;/p&gt; &#xA;&lt;p&gt;BigQuery also requires a database schema when you load data into a new table, so you will find the table schema associated with the mock data in the file &lt;code&gt;sample_data/crm_schema.json&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Create a BigQuery Dataset&lt;/h3&gt; &#xA;&lt;p&gt;BigQuery has the concept of a Dataset that acts as a container for one or more tables. You can create a new Dataset using the &lt;code&gt;bq mk&lt;/code&gt; command giving the name of the new Dataset to create as an argument. In this example, the Dataset is called &lt;code&gt;gap_bq_r&lt;/code&gt;, but you can call it something else if you like, as long as you use the same name consistently.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bq mk gap_bq_r&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The Google Analytics Premium logs export will produce tables in BigQuery with names like &lt;code&gt;ga_sessions_20150630&lt;/code&gt;, where the last part is the date. To collate these tables, Google Analytics Premium creates a Dataset with a numeric name like &lt;code&gt;12345678&lt;/code&gt;. So the full path for a specific log file would look this this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;project-id&amp;gt;:12345678.ga_sessions_20150630&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Load Mock CRM Data into BigQuery&lt;/h3&gt; &#xA;&lt;p&gt;Next, you can load your own CRM data into the dataset you created. The commands below use the sample data files, but you can replace them with your own database exports if you have them. The command to load a CSV or JSON file into a BigQuery table is &lt;code&gt;bq load&lt;/code&gt;. You then give the table name, input data file and table schema as arguments. If the table does not exist, it will create it under your chosen Dataset.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bq load --skip_leading_rows=1 gap_bq_r.CRM ./sample_data/crm_mock_data.csv ./sample_data/crm_schema.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the example above the new table will be called &lt;code&gt;CRM&lt;/code&gt;. The &lt;code&gt;--skip_leading_rows=1&lt;/code&gt; optional argument tells the load job to ignore the header row of the CSV since that information will come from the schema JSON file. This job will execute synchronously, but you can automate a similar task to run &lt;a href=&#34;https://cloud.google.com/bigquery/bq-command-line-tool#async&#34;&gt;asynchronously&lt;/a&gt;. After the load command completes, verify that it was uploaded correctly by showing the first three rows using the &lt;code&gt;head&lt;/code&gt; command. For example, using the sample data:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bq head -n 3 gap_bq_r.CRM&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Of course, you can do all this from the BigQuery web interface as well, but by learning some of the key uses of commands it is easier to automate and script solutions. For example, if you want to upload CRM data from thousands of existing files, it will be a lot easier and less cumbersome to use the command line directly.&lt;/p&gt; &#xA;&lt;h2&gt;Step 3: Clean the Data&lt;/h2&gt; &#xA;&lt;p&gt;Before you start running regression analyses against your newly imported data sources, it&#39;s important to verify its validity and clean the data to make it ready for processing. In this step you will commonly encounter a few data-quality problems including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Missing data&lt;/li&gt; &#xA; &lt;li&gt;Invalid or inconsistent data types&lt;/li&gt; &#xA; &lt;li&gt;Distribution bias or uniformity&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In this section you will learn some techniques of how to address them, and by the end you will have prepared a complete BigQuery SQL statement that can extract the relevant data from the Google Analytics Premium logs as well as your CRM database. You can find a sample template SQL query statement based on the mock data in the file &lt;code&gt;join_data_sources.sql&lt;/code&gt;, but it&#39;s important to note that your own final query will be different from the template, since your own data sources will differ from the mock data provided as a sample.&lt;/p&gt; &#xA;&lt;p&gt;The next few sections will explain in more detail what the different lines in the &lt;code&gt;join_data_sources.sql&lt;/code&gt; template mean, and will hopefully give you insight to start crafting your own BigQuery SQL statement to join your own data sources together.&lt;/p&gt; &#xA;&lt;h3&gt;Match the Google Analytics data with your own CRM database&lt;/h3&gt; &#xA;&lt;p&gt;One critical part of the logic behind the SQL statement is to perform a BigQuery table join between the CRM database and Google Analytics Premium log tables. The line that does this in the SQL statement is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;JOIN&#xA;  [&amp;lt;PROJECT-NAME&amp;gt;:gap_bq_r.CRM] b&#xA;ON&#xA;  a.hits.customDimensions.value = b.hits_customDimensions_value&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It links the Google Analytics (&lt;code&gt;a&lt;/code&gt;) and CRM (&lt;code&gt;b&lt;/code&gt;) tables by performing a &lt;a href=&#34;https://cloud.google.com/bigquery/query-reference#joins&#34;&gt;&lt;code&gt;JOIN&lt;/code&gt;&lt;/a&gt; on the rows where the variable &lt;code&gt;hits.customDimensions.value&lt;/code&gt; is the same in both tables. Remember that variable? That&#39;s right, it&#39;s the one generated through the HTML entry form and JavaScript example in Step 1. It&#39;s important that you replace the &lt;code&gt;&amp;lt;YOUR-PROJECT&amp;gt;&lt;/code&gt; part with the name of your specific project, and the Dataset and table name if you&#39;re using your own data.&lt;/p&gt; &#xA;&lt;h3&gt;Processing missing values&lt;/h3&gt; &#xA;&lt;p&gt;For statistically meaningful results, you should only include variables with a sufficiently high fill rate in the analysis phase. This means that variables that have a large number of missing values will be be excluded. For the variables that will be included in your model, you should ensure that any missing values are of the correct data type. For continuous variables, for example, replace&lt;em&gt; &lt;/em&gt;the empty value with with a number that does not significantly affect the distribution of the data, like the average (mean), or median value.&lt;/p&gt; &#xA;&lt;p&gt;Here is one example of this technique in the sample query template that uses the built-in BigQuery &lt;a href=&#34;https://cloud.google.com/bigquery/query-reference#otherfunctions&#34;&gt;IF()&lt;/a&gt; function:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;IF (SUM(INTEGER(totals.pageviews)) is null, 1, SUM(INTEGER(totals.pageviews))) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This line checks if &lt;code&gt;SUM(INTEGER(totals.pageviews)&lt;/code&gt; is a null field and, if true, replaces it with the value 1 instead. Otherwise it leaves the value as is.&lt;/p&gt; &#xA;&lt;h3&gt;Convert Nominal or Mutually Exclusive Variables into Dummy Variables&lt;/h3&gt; &#xA;&lt;p&gt;You may want to include nominal variables, such as whether the visitors used desktops or tablets, Windows or MacOS, in your regression model. For example, Google Analytics Premium logs provide a column called &lt;em&gt;deviceOperatingSystem&lt;/em&gt;. The values here can include &lt;em&gt;Windows &lt;/em&gt;and &lt;em&gt;Macintosh&lt;/em&gt;. Unfortunately, with the data in that form, you won&#39;t be able to include it as an explanatory variable in the model.&lt;/p&gt; &#xA;&lt;p&gt;To do so, you need to create &lt;a href=&#34;https://en.wikipedia.org/wiki/Dummy_variable_(statistics)&#34;&gt;dummy variables&lt;/a&gt; for each category of value (e.g. Windows). As an example, you can create a new table column called &lt;code&gt;OS_Windows_flag&lt;/code&gt; and insert the value &lt;code&gt;1&lt;/code&gt; if &lt;code&gt;deviceOperatingSystem&lt;/code&gt; is Windows, or else the value &lt;code&gt;0&lt;/code&gt; if it is anything else. You need to create a column for each alternative category as well, for example &lt;code&gt;OS_Macintosh_flag&lt;/code&gt;. Here is one example from the sample template:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;CASE WHEN device.operatingSystem = &#39;Windows&#39; THEN 1 ELSE 0 END&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Convert Hit Level Logs into Per-User Format&lt;/h3&gt; &#xA;&lt;p&gt;The BigQuery SQL query also converts the data from hit level rows and aggregates it based on the unique user. In other words, each row in the result set will represent one unique website visitor. This is done through the following line.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;GROUP BY fullVisitorId&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You will also want to use BigQuery &lt;a href=&#34;https://cloud.google.com/bigquery/query-reference#aggfunctions&#34;&gt;aggregate functions&lt;/a&gt;, like &lt;code&gt;SUM()&lt;/code&gt;, &lt;code&gt;MAX()&lt;/code&gt;, and &lt;code&gt;MIN()&lt;/code&gt; to represent the data in the most appropriate, grouped way. For example the following calculation of the most recent and oldest timestamp for the visit using the &lt;a href=&#34;https://cloud.google.com/bigquery/query-reference#datetimefunctions&#34;&gt;DATEDIFF()&lt;/a&gt; function.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;DATEDIFF(TIMESTAMP(&#39;2014-09-10 00:00:00&#39;), MAX(date)) AS diffdays_latest,&#xA;DATEDIFF(TIMESTAMP(&#39;2014-09-10 00:00:00&#39;), MIN(date)) AS diffdays_oldest,&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may also want to include specific events that the user performs, and can track these using Google Analytics Premium &lt;em&gt;&lt;a href=&#34;https://support.google.com/analytics/answer/1033068?hl=en&#34;&gt;Events&lt;/a&gt;&lt;/em&gt;. In the line below, all the hits for the specific &lt;em&gt;eventLabel&lt;/em&gt; are summed together using the BigQuery &lt;code&gt;SUM()&lt;/code&gt; function.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SUM(hits.eventInfo.eventLabel=&#39;&amp;lt;website_path&amp;gt;&#39;) AS page201404&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once you have executed your BigQuery SQL statement to join and extract the appropriate data, you can proceed to create a statistical model, which is the next step.&lt;/p&gt; &#xA;&lt;h2&gt;Step 4: Create the Regression Model&lt;/h2&gt; &#xA;&lt;p&gt;Does this step look familiar? Well, it should. This is the step that you performed in the Code Lab earlier. You can take the sample R script provided for the Code Lab and update it to fit your own data and modelling needs. Once you&#39;re satisfied with the regression model and you have the coefficient for every variable, you can proceed to the next step, creating a remarketing list based on your regression model.&lt;/p&gt; &#xA;&lt;h2&gt;Step 5: Create the Remarketing List&lt;/h2&gt; &#xA;&lt;p&gt;Having completed the regression analysis using R, you should now have regression coefficients (beta) for each explanatory variable (X&lt;sub&gt;i&lt;/sub&gt;) in your model. You can apply these coefficients against each user (&lt;em&gt;j&lt;/em&gt;) in the Google Analytics exported data to calculate their conversion probability. To perform this computation in R would take a very long time if the number of users is high. That is why you will use BigQuery instead, since this service can easily calculate a score for each user through in-built mathematical functions, like &lt;em&gt;exp&lt;/em&gt;, as demonstrated in this formula:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/prob-formula.png&#34; alt=&#34;Probability formula&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Run BigQuery Job&lt;/h3&gt; &#xA;&lt;p&gt;Below, you can see the top part of a BigQuery SQL statement using sample data. The coefficients are multiplied with the respective variable and multiplied by 100 to create a score between 0 to 100 for each user. The results are sorted in descending order of probability. You can find the complete SQL query template in the file &lt;code&gt;generate_remarketing_list.sql&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SELECT&#xA;hits.customDimensions.value,&#xA;(1 / (1+exp(-(-2.3298773233 +&#xA;0.0578391477*(COUNT) +&#xA;(-0.0004420572)*SUM_totals_timeOnSite) +&#xA;0.0389364789*(SUM_hits_hitNumber) +&#xA;...&#xA;1.0019169671*(page201405) +&#xA;(-1.3596393104)*(page201406) ))) * 100&#xA;AS CV_probability&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;hits_customDimensions_value    CV_probability&#xA;6600000098.3400000057          95.18373911417612&#xA;3100000022.2400000081          94.07515998878802&#xA;8000000037.7400000053          93.55577449415483&#xA;940000034.2400000085           93.30393516985602&#xA;240000000.9400000018           92.78654733606425&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The first results column contains the Google Analytics ID for each user (&lt;code&gt;hits_customDimensions_value&lt;/code&gt;), and the second column shows the probability of that user converting based on the regression model. In other words, the model is estimating a 95% likelihood that the top user will at least book a test drive.&lt;/p&gt; &#xA;&lt;p&gt;By sorting this list based on the conversion probability in descending order, you will have a prioritised list of users to follow up with for remarketing outreach, for example through Google Adwords, DoubleClick, and Google Analytics Premium.&lt;/p&gt; &#xA;&lt;h3&gt;Download the Remarketing List from BigQuery&lt;/h3&gt; &#xA;&lt;p&gt;Before you can import this list into Google Analytics Premium, you will have to download the results from BigQuery. To do this, click the &#34;Download as CSV&#34; button and save the file with a representative name, for example &lt;code&gt;remarketing_list.csv&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Step 6: Import Remarketing List into Google Analytics Premium&lt;/h2&gt; &#xA;&lt;p&gt;Before importing the remarketing list into Google Analytics, you need to have completed the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://support.google.com/analytics/answer/1033961?hl=en&#34;&gt;Link your AdWords account&lt;/a&gt; with the Google Analytics Premium account that you will import the remarketing list into&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://support.google.com/analytics/answer/2444872?hl=en&#34;&gt;Enable remarketing&lt;/a&gt; in your Google Analytics Premium account&lt;/li&gt; &#xA; &lt;li&gt;Create a &lt;a href=&#34;https://support.google.com/analytics/answer/2709829?hl=en&#34;&gt;custom dimension and (optionally) a custom metric&lt;/a&gt; to store the conversion probability&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you are including the Client ID with every hit, you may wish to not create a custom metric for the conversion probability and use only a custom dimension since the value can become very large. If you approach it from a session or user level then the metric can be very useful. It all comes down to the specific approach that&#39;s right for your scenario.&lt;/p&gt; &#xA;&lt;h3&gt;Create a New Google Analytics Data Set&lt;/h3&gt; &#xA;&lt;p&gt;Login to your Google Analytics Premium account and navigate to the &#34;Admin&#34; section. Create a new data set by clicking the &#34;+ NEW DATA SET&#34; button under the &#34;Data Import&#34; menu item for the relevant property. This starts a step-by-step setup wizard.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/data-import-new-set.png&#34; alt=&#34;New data set&#34;&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Select the &#34;Custom Data&#34; type and go to the next step.&lt;/li&gt; &#xA; &lt;li&gt;Select &#34;Processing time&#34; as the Import behavior. Do note that this means the uploaded conversion probability data will only be processed when the user visits the website again with the same Client ID.&lt;/li&gt; &#xA; &lt;li&gt;Name the data set and choose which views you want to make use of it. You&#39;ll have to select at least one view or else the data set will be inactive.&lt;/li&gt; &#xA; &lt;li&gt;Define the schema for the data set. Specifically, you should choose the &#34;clientId&#34; Custom Dimension (custom dimension 6 in the sample) as the key and the &#34;Conversion Probability&#34; Custom Metric. Click &#34;Save&#34; and move to the next step.&lt;/li&gt; &#xA; &lt;li&gt;Select &#34;Yes&#34; when asked about &#34;Overwrite hit data&#34; and define the header line in the CSV file as shown in the screenshot below. Note the link to Custom Dimension 6, Custom Dimension 9 and Custom Metric 1 as defined above.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/import-csv-header.png&#34; alt=&#34;CSV Header&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Import Remarketing List into Google Analytics Premium&lt;/h3&gt; &#xA;&lt;p&gt;Now that you have defined the Data Set in Google Analytics Premium, it&#39;s time to import the remarketing list CSV file. Again, navigate to &#34;Data Import&#34; and click the &#34;Manage Uploads&#34; link in your newly created Data Set.&lt;/p&gt; &#xA;&lt;p&gt;Click the &#34;Upload file&#34; button, choose the CSV file you exported from BigQuery containing the conversion probabilities and click the &#34;Upload&#34; button.&lt;/p&gt; &#xA;&lt;h3&gt;Create Remarketing Audience in Google Analytics Premium&lt;/h3&gt; &#xA;&lt;p&gt;After the import processing has completed, you can create Remarketing Audiences. Note that it may take some time before the newly imported data is ready to use. Once ready, go to the &#34;Admin&#34; section and choose the &#34;Remarketing&#34; and &#34;Audiences&#34; menu options. Click the &#34;+ NEW AUDIENCE&#34; button to create a new Audience and select the AdWords account that you&#39;d like to share the remarketing list with.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/new-audience.png&#34; alt=&#34;New Audience&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Then, select the &#34;Conditions&#34; menu in the &#34;Advanced&#34; section of the Audience Builder screen. Here you can define the condition for including a user in the Audience. In the screenshot below the condition chosen is to only include users with a Conversion Probability of more than 75%. Click &#34;Apply&#34; and, after a while, the remarketing list will start to populate based on the condition listed.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/google-analytics-premium-bigquery-statistics/master/images/audience-builder.png&#34; alt=&#34;Audience builder&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;As you experiment, be sure to read the &lt;a href=&#34;https://support.google.com/analytics/answer/2795983?hl=en&#34;&gt;usage guidelines&lt;/a&gt; with regards to what data you can send to Google Analytics and in particular the restriction on sending any personally identifiable information (PII), and your Google Analytics Premium agreement, including the &lt;a href=&#34;https://support.google.com/analytics/answer/2700409?vid=1-635766380079250047-476492744&#34;&gt;Advertising Features policy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Hopefully, this tutorial has shown you how to get started and gather more insight into your data based on the Google Analytics Premium + BigQuery integration. This is only a starting point, so now you can experiment with your own data and come up with other ways to gain value from online and offline data sources.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>XSaintX/libroR-AnalisisDatos</title>
    <updated>2023-01-15T02:03:54Z</updated>
    <id>tag:github.com,2023-01-15:/XSaintX/libroR-AnalisisDatos</id>
    <link href="https://github.com/XSaintX/libroR-AnalisisDatos" rel="alternate"></link>
    <summary type="html">&lt;p&gt;this project contains R code about analysing data from the book Analisis de datos con R&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;libroR-AnalisisDatos&lt;/h1&gt; &#xA;&lt;p&gt;This project contains my solutions in R about analysing data from the book Analisis de datos con R from Mariano Mendez Suarez.&lt;/p&gt; &#xA;&lt;p&gt;This project includes the csv files that will be useful to run the R code.&lt;/p&gt; &#xA;&lt;p&gt;Each R code is from each chapter of the book.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Capitulo 1. Objetivos de la investigacion y pasos iniciales.&lt;/li&gt; &#xA; &lt;li&gt;Capitulo 2. Top Two Box y Net Promoter Score&lt;/li&gt; &#xA; &lt;li&gt;Capitulo 3. Analisis bivariante&lt;/li&gt; &#xA; &lt;li&gt;Capitulo 4. Analisis Factorial&lt;/li&gt; &#xA; &lt;li&gt;Capitulo 5. Analisis cluster o de conglomerado&lt;/li&gt; &#xA; &lt;li&gt;Capitulo 6. Analisis de regresion lineal multiple&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
</feed>