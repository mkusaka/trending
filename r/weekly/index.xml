<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-24T02:20:16Z</updated>
  <subtitle>Weekly Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>adriancorrendo/metrica</title>
    <updated>2022-07-24T02:20:16Z</updated>
    <id>tag:github.com,2022-07-24:/adriancorrendo/metrica</id>
    <link href="https://github.com/adriancorrendo/metrica" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Prediction Performance Metrics&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;metrica: Prediction performance metrics.&lt;/h1&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=metrica&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/metrica&#34; alt=&#34;CRAN status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://r-pkg.org/pkg/metrica&#34;&gt;&lt;img src=&#34;https://cranlogs.r-pkg.org/badges/grand-total/metrica?color=blue&#34; alt=&#34;CRAN RStudio mirror downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://r-pkg.org/pkg/metrica&#34;&gt;&lt;img src=&#34;https://cranlogs.r-pkg.org/badges/last-month/metrica?color=blue&#34; alt=&#34;CRAN RStudio mirror downloads&#34;&gt;&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ci.appveyor.com/project/adriancorrendo/metrica&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/github/adriancorrendo/metrica?branch=master&amp;amp;svg=true&#34; alt=&#34;AppVeyor build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/adriancorrendo/metrica/actions&#34;&gt;&lt;img src=&#34;https://github.com/adriancorrendo/metrica/workflows/R-CMD-check/badge.svg?sanitize=true&#34; alt=&#34;R-CMD-check&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/adriancorrendo/metrica&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/adriancorrendo/metrica/branch/master/graph/badge.svg?token=CfK5NhXzYn&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.5281/zenodo.6474101&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.6474101.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;h2&gt;Introduction &lt;br&gt;&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/metrica_logo.png&#34; align=&#34;right&#34; height=&#34;150&#34; style=&#34;float:right; height:150px;&#34;&gt; &#xA;&lt;br&gt; `metrica` is a compilation of more than 80 functions designed to quantitatively and visually evaluate the prediction performance of regression (continuous variables) and classification (categorical variables) point-forecast models (e.g.&amp;nbsp;APSIM, DSSAT, DNDC, Supervised Machine Learning). `metrica` offers a toolbox with a wide spectrum of goodness of fit, error metrics, indices, and coefficients accounting for different aspects of the agreement between predicted and observed values, plus some basic visualization functions to assess models performance (e.g.&amp;nbsp;confusion matrix, scatter with regression line; Bland-Altman plot) provided in customizable format (ggplot). &#xA;&lt;p&gt;For supervised models, always keep in mind the concept of “cross-validation” since predicted values should ideally come from out-of-bag samples (unseen by training sets) to avoid overestimation of the prediction performance. &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;Check the Documentation at &lt;a href=&#34;https://adriancorrendo.github.io/metrica/&#34;&gt;https://adriancorrendo.github.io/metrica/&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Vignettes&lt;/strong&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html&#34;&gt;1. List of metrics for Regression&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html&#34;&gt;2. List of metrics for Classification&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/regression_case.html&#34;&gt;3. A regression case (numerical variables)&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/classification_case.html&#34;&gt;4. A classification case (categorical variables)&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/apsim_open.html&#34;&gt;5. Import files from APSIM&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Functions &lt;br&gt;&lt;/h2&gt; &#xA;&lt;p&gt;For regression models, it includes 4 plotting functions (scatter, tiles, density, &amp;amp; Bland-Altman plots), and 48 prediction performance scores including error metrics (MBE, MAE, RAE, RMAE, MAPE, SMAPE, MSE, RMSE, RRMSE, RSR, PBE, iqRMSE), error decomposition (MLA, MLP, PLA, PLP, PAB, PPB, SB, SDSD, LCS, Ub, Uc, Ue), model efficiency (NSE, E1, Erel, KGE), indices of agreement (d, d1, d1r, RAC, AC, lambda), goodness of fit (r, R2, RSS, TSS, RSE), adjusted correlation coefficients (CCC, Xa, distance correlation-dcorr-, maximal information coefficient -MIC-), variability (uSD, var_u), and symmetric regression coefficients (B0_sma, B1_sma). Specifically for time-series predictions, &lt;code&gt;metrica&lt;/code&gt; also includes the Mean Absolute Scaled Error (MASE). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For classification (binomial and multinomial) tasks, it includes a function to visualize the confusion matrix using ggplot2, and 27 functions of prediction scores including: accuracy, error rate, precision, recall, specificity, balanced accuracy (balacc), F-score (fscore), adjusted F-score (agf), G-mean (gmean), Bookmaker Informedness (bmi, a.k.a. Youden’s J-index), Markedness (deltaP), Matthews Correlation Coefficient (mcc), Cohen’s Kappa (khat), negative predictive value (npv), positive and negative likelihood ratios (posLr, negLr), diagnostic odds ratio (dor), prevalence (preval), prevalence threshold (preval_t), critical success index (csi, a.k.a. threat score), false positive rate (FPR), false negative rate (FNR), false detection rate (FDR), false omission rate (FOR), and area under the ROC curve (AUC_roc). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;metrica&lt;/code&gt; also offers a function that allows users to run all prediction performance scores at once. The user just needs to specify the type of model (“regression” or “classification”). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For more details visit the vignettes &lt;a href=&#34;https://adriancorrendo.github.io/metrica/&#34;&gt;https://adriancorrendo.github.io/metrica/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Using the functions &lt;br&gt;&lt;/h2&gt; &#xA;&lt;p&gt;There are two basic arguments common to all &lt;code&gt;metrica&lt;/code&gt; functions: (i) &lt;code&gt;obs&lt;/code&gt;(Oi; observed, a.k.a. actual, measured, truth, target, label), and (ii) &lt;code&gt;pred&lt;/code&gt; (Pi; predicted, a.k.a. simulated, fitted, modeled, estimate) values. &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;Optional arguments include &lt;code&gt;data&lt;/code&gt; that allows to call an existing data frame containing both observed and predicted vectors, and &lt;code&gt;tidy&lt;/code&gt;, which controls the type of output as a list (tidy = FALSE) or as a data.frame (tidy = TRUE). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For regression, some specific functions for regression also require to define the axis &lt;code&gt;orientation&lt;/code&gt;. For example, the slope of the symmetric linear regression describing the bivariate scatter (SMA). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For binary classification (two classes), functions also require to check the &lt;code&gt;pos_level&lt;/code&gt; arg., which indicates the alphanumeric order of the “positive level”. Normally, the most common binary denominations are c(0,1), c(“Negative”, “Positive”), c(“FALSE”, “TRUE”), so the default pos_level = 2 (1, “Positive”, “TRUE”). However, other cases are also possible, such as c(“Crop”, “NoCrop”) for which the user needs to specify pos_level = 1. &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For multiclass classification tasks, some functions present the &lt;code&gt;atom&lt;/code&gt; arg. (logical TRUE / FALSE), which controls the output to be an overall average estimate across all classes, or a class-wise estimate. For example, user might be interested in obtaining estimates of precision and recall for each possible class of the prediction. &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;1. Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install the CRAN version of &lt;code&gt;metrica&lt;/code&gt; with: &lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;metrica&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can install the development version from &lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt; with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# install.packages(&#34;devtools&#34;)&#xA;devtools::install_github(&#34;adriancorrendo/metrica&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;2. Native datasets&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;em&gt;metrica&lt;/em&gt; package comes with four example datasets of continuous variables (regression) from the APSIM software: &lt;br&gt; 1. &lt;code&gt;wheat&lt;/code&gt;. 137 data-points of wheat grain N (grams per squared meter) &lt;br&gt; 2. &lt;code&gt;barley&lt;/code&gt;. 69 data-points of barley grain number (x1000 grains per squared meter) &lt;br&gt; 3. &lt;code&gt;sorghum&lt;/code&gt;. 36 data-points of sorghum grain number (x1000 grains per squared meter) &lt;br&gt; 4. &lt;code&gt;chickpea&lt;/code&gt;. 39 data-points of chickpea aboveground dry mass (kg per hectare) &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;These data correspond to the latest, up-to-date, documentation and validation of version number 2020.03.27.4956. Data available at: &lt;a href=&#34;https://doi.org/10.7910/DVN/EJS4M0&#34;&gt;https://doi.org/10.7910/DVN/EJS4M0&lt;/a&gt;. Further details can be found at the official APSIM Next Generation website: &lt;a href=&#34;https://APSIMnextgeneration.netlify.app/modeldocumentation&#34;&gt;https://APSIMnextgeneration.netlify.app/modeldocumentation&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;3. Example Code&lt;/h2&gt; &#xA;&lt;h3&gt;Libraries&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(metrica)&#xA;library(dplyr)&#xA;library(purrr)&#xA;library(ggplot2)&#xA;library(tidyr)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is a basic example which shows you the core regression and classification functions of &lt;em&gt;metrica&lt;/em&gt;: &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;3.1. REGRESSION&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# 1. A. Create a random dataset&#xA;# Set seed for reproducibility&#xA;set.seed(1)&#xA;# Create a random vector (X) with 100 values&#xA;X &amp;lt;- rnorm(n = 100, mean = 0, sd = 10)&#xA;# Create a second vector (Y) with 100 values by adding error with respect&#xA;# to the first vector (X).&#xA;Y &amp;lt;- X + rnorm(n=100, mean = 0, sd = 3)&#xA;# Merge vectors in a data frame, rename them as synonyms of observed (measured) and predicted (simulated)&#xA;example.data &amp;lt;- data.frame(measured = X, simulated = Y)&#xA;&#xA;# 1. B. Or call native example datasets&#xA;&#xA;example.data &amp;lt;- barley %&amp;gt;%  # or &#39;wheat&#39;, &#39;sorghum&#39;, or &#39;chickpea&#39;&#xA;# 1.b. create columns as synonyms of observed (measured) and predicted (simulated)&#xA;                mutate(measured = obs, simulated = pred)  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.1. Plot functions&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.1.1. Create a customizable scatter plot with PO orientation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barley.scat.plot &amp;lt;- &#xA;  metrica::scatter_plot(data = example.data, &#xA;                        obs = measured, &#xA;                        pred = simulated,&#xA;                        orientation = &#34;PO&#34;, &#xA;                        print_eq = TRUE,&#xA;                        position_eq = c(x=24, y =8), &#xA;                        # Optional arguments to customize the plot&#xA;                        shape_type = 21,&#xA;                        shape_color = &#34;steelblue&#34;,&#xA;                        shape_size = 3,&#xA;                        regline_type = &#34;F1&#34;,&#xA;                        regline_color = &#34;#9e0059&#34;,&#xA;                        regline_size = 2)+&#xA;  # Customize axis breaks&#xA;  scale_y_continuous(breaks = seq(0,30, by = 5))+&#xA;  scale_x_continuous(breaks = seq(0,30, by = 5))&#xA;&#xA;barley.scat.plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-4-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Alternative using vectors instead of dataframe&#xA;#metrica::scatter_plot(obs = example.data$obs, pred = example.data$pred)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.1.2. Create tiles plot with OP orientation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barley.tiles.plot &amp;lt;- &#xA;  tiles_plot(data = example.data, &#xA;                      obs = measured, &#xA;                      pred = simulated,&#xA;                      bins = 10, &#xA;                      orientation = &#34;PO&#34;,&#xA;                      colors = c(low = &#34;pink&#34;, high = &#34;steelblue&#34;))&#xA;&#xA;barley.tiles.plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-5-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.1.3. Create a density plot with OP orientation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barley.density.plot &amp;lt;-&#xA;metrica::density_plot(data = example.data, &#xA;                      obs = measured, pred = simulated,&#xA;                      n = 5, &#xA;                      orientation = &#34;PO&#34;, &#xA;           colors = c(low = &#34;white&#34;, high = &#34;steelblue&#34;) )+&#xA;  theme(legend.position = &#34;none&#34;)&#xA;&#xA;barley.density.plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-6-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.1.4. Create a Bland-Altman plot&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barley.ba.plot &amp;lt;- metrica::bland_altman_plot(data = example.data,&#xA;                                             obs = measured, pred = simulated)&#xA;&#xA;barley.ba.plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-7-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.2. Metrics functions&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.2.2. Single estimates&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# a. Estimate coefficient of determination (R2)&#xA;&#xA;metrica::R2(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $R2&#xA;#&amp;gt; [1] 0.4512998&#xA;&#xA;# b. Estimate root mean squared error (RMSE)&#xA;metrica::RMSE(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $RMSE&#xA;#&amp;gt; [1] 3.986028&#xA;&#xA;# c. Estimate mean bias error (MBE)&#xA;metrica::MBE(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $MBE&#xA;#&amp;gt; [1] 0.207378&#xA;&#xA;# c. Estimate index of agreement (d)&#xA;metrica::d(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $d&#xA;#&amp;gt; [1] 0.8191397&#xA;&#xA;# e. Estimate SMA regression intercept (B0)&#xA;metrica::B0_sma(data = example.data, obs = measured, pred = simulated, tidy = TRUE)&#xA;#&amp;gt;         B0&#xA;#&amp;gt; 1 1.128274&#xA;&#xA;# f. Estimate SMA regression slope (B1)&#xA;metrica::B1_sma(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $B1&#xA;#&amp;gt; [1] 0.9288715&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.2.2. Metrics Summary&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;metrics.sum &amp;lt;- metrics_summary(data = example.data, &#xA;                               obs = measured, pred = simulated,&#xA;                               type = &#34;regression&#34;)  &#xA;# Print first 15&#xA;head(metrics.sum, n = 15)&#xA;#&amp;gt;    Metric      Score&#xA;#&amp;gt; 1      B0  1.1282743&#xA;#&amp;gt; 2      B1  0.9288715&#xA;#&amp;gt; 3       r  0.6717885&#xA;#&amp;gt; 4      R2  0.4512998&#xA;#&amp;gt; 5      Xa  0.9963915&#xA;#&amp;gt; 6     CCC  0.6693644&#xA;#&amp;gt; 7     MAE  3.0595501&#xA;#&amp;gt; 8    RMAE  0.1629325&#xA;#&amp;gt; 9    MAPE 16.8112673&#xA;#&amp;gt; 10  SMAPE 16.7848032&#xA;#&amp;gt; 11    RAE  0.7639151&#xA;#&amp;gt; 12    RSE  0.6164605&#xA;#&amp;gt; 13    MBE  0.2073780&#xA;#&amp;gt; 14    PBE  1.1043657&#xA;#&amp;gt; 15    PAB  0.2706729&#xA;&#xA;# Optional wrangling (WIDE)&#xA;metrics.sum.wide &amp;lt;- metrics.sum %&amp;gt;%&#xA;  tidyr::pivot_wider(tidyr::everything(),&#xA;                      names_from = &#34;Metric&#34;,&#xA;                      values_from = &#34;Score&#34;)&#xA;&#xA;metrics.sum.wide&#xA;#&amp;gt; # A tibble: 1 × 45&#xA;#&amp;gt;      B0    B1     r    R2    Xa   CCC   MAE  RMAE  MAPE SMAPE   RAE   RSE   MBE&#xA;#&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;&#xA;#&amp;gt; 1  1.13 0.929 0.672 0.451 0.996 0.669  3.06 0.163  16.8  16.8 0.764 0.616 0.207&#xA;#&amp;gt; # … with 32 more variables: PBE &amp;lt;dbl&amp;gt;, PAB &amp;lt;dbl&amp;gt;, PPB &amp;lt;dbl&amp;gt;, MSE &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   RMSE &amp;lt;dbl&amp;gt;, RRMSE &amp;lt;dbl&amp;gt;, RSR &amp;lt;dbl&amp;gt;, iqRMSE &amp;lt;dbl&amp;gt;, MLA &amp;lt;dbl&amp;gt;, MLP &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   RMLA &amp;lt;dbl&amp;gt;, RMLP &amp;lt;dbl&amp;gt;, SB &amp;lt;dbl&amp;gt;, SDSD &amp;lt;dbl&amp;gt;, LCS &amp;lt;dbl&amp;gt;, PLA &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   PLP &amp;lt;dbl&amp;gt;, Ue &amp;lt;dbl&amp;gt;, Uc &amp;lt;dbl&amp;gt;, Ub &amp;lt;dbl&amp;gt;, NSE &amp;lt;dbl&amp;gt;, E1 &amp;lt;dbl&amp;gt;, Erel &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   KGE &amp;lt;dbl&amp;gt;, d &amp;lt;dbl&amp;gt;, d1 &amp;lt;dbl&amp;gt;, d1r &amp;lt;dbl&amp;gt;, RAC &amp;lt;dbl&amp;gt;, AC &amp;lt;dbl&amp;gt;, lambda &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   dcorr &amp;lt;dbl&amp;gt;, MIC &amp;lt;dbl&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.3. Run multiple datasets at once&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.3.1. Nested data&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# a. Create nested df with the native examples&#xA;nested.examples &amp;lt;- bind_rows(list(wheat = metrica::wheat, &#xA;                                  barley = metrica::barley,&#xA;                                  sorghum = metrica::sorghum, &#xA;                                  chickpea = metrica::chickpea), &#xA;                             .id = &#34;id&#34;) %&amp;gt;%&#xA;  dplyr::group_by(id) %&amp;gt;% tidyr::nest() %&amp;gt;% dplyr::ungroup()&#xA;&#xA;head(nested.examples %&amp;gt;% group_by(id) %&amp;gt;% dplyr::slice_head(n=2))&#xA;#&amp;gt; # A tibble: 4 × 2&#xA;#&amp;gt; # Groups:   id [4]&#xA;#&amp;gt;   id       data              &#xA;#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;list&amp;gt;            &#xA;#&amp;gt; 1 barley   &amp;lt;tibble [69 × 2]&amp;gt; &#xA;#&amp;gt; 2 chickpea &amp;lt;tibble [39 × 2]&amp;gt; &#xA;#&amp;gt; 3 sorghum  &amp;lt;tibble [36 × 2]&amp;gt; &#xA;#&amp;gt; 4 wheat    &amp;lt;tibble [137 × 2]&amp;gt;&#xA;&#xA;# b. Run &#xA;multiple.sum &amp;lt;- nested.examples %&amp;gt;% &#xA;  # Store metrics in new.column &#34;performance&#34;&#xA;  mutate(performance = map(data, ~metrica::metrics_summary(data=., obs = obs, pred = pred, &#xA;                                                           type = &#34;regression&#34;)))&#xA;&#xA;head(multiple.sum)&#xA;#&amp;gt; # A tibble: 4 × 3&#xA;#&amp;gt;   id       data               performance  &#xA;#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;       &#xA;#&amp;gt; 1 wheat    &amp;lt;tibble [137 × 2]&amp;gt; &amp;lt;df [45 × 2]&amp;gt;&#xA;#&amp;gt; 2 barley   &amp;lt;tibble [69 × 2]&amp;gt;  &amp;lt;df [45 × 2]&amp;gt;&#xA;#&amp;gt; 3 sorghum  &amp;lt;tibble [36 × 2]&amp;gt;  &amp;lt;df [45 × 2]&amp;gt;&#xA;#&amp;gt; 4 chickpea &amp;lt;tibble [39 × 2]&amp;gt;  &amp;lt;df [45 × 2]&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.3.2. Non-nested data &lt;br&gt;&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;non_nested_summary &amp;lt;- nested.examples %&amp;gt;% unnest(cols = &#34;data&#34;) %&amp;gt;% &#xA;  group_by(id) %&amp;gt;% &#xA;  summarise(metrics_summary(obs = obs, pred = pred, type = &#34;regression&#34;)) %&amp;gt;% &#xA;  dplyr::arrange(Metric)&#xA;&#xA;head(non_nested_summary)&#xA;#&amp;gt; # A tibble: 6 × 3&#xA;#&amp;gt; # Groups:   id [4]&#xA;#&amp;gt;   id       Metric    Score&#xA;#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;&#xA;#&amp;gt; 1 barley   AC       0.253 &#xA;#&amp;gt; 2 chickpea AC       0.434 &#xA;#&amp;gt; 3 sorghum  AC       0.0889&#xA;#&amp;gt; 4 wheat    AC       0.842 &#xA;#&amp;gt; 5 barley   B0       1.13  &#xA;#&amp;gt; 6 chickpea B0     -99.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.4. Print metrics in a plot&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df &amp;lt;- metrica::wheat&#xA;&#xA;# Create list of selected metrics&#xA;selected.metrics &amp;lt;- c(&#34;MAE&#34;,&#34;RMSE&#34;, &#34;RRMSE&#34;, &#34;R2&#34;, &#34;NSE&#34;, &#34;KGE&#34;, &#34;PLA&#34;, &#34;PLP&#34;)&#xA;&#xA;&#xA;df &amp;lt;- metrica::wheat&#xA;# Create the plot&#xA;plot &amp;lt;- metrica::scatter_plot(data = df, &#xA;                              obs = obs, pred = pred,&#xA;                              # Activate print_metrics arg.&#xA;                              print_metrics = TRUE, &#xA;                              # Indicate metrics list&#xA;                              metrics_list = selected.metrics,&#xA;                              # Customize metrics position&#xA;                              position_metrics = c(x = 16 , y = 9),&#xA;                              # Customize equation position&#xA;                              position_eq = c(x = 16.2, y = 9.5))&#xA;&#xA;plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-12-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h2&gt;3.1. CLASSIFICATION &lt;br&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Example datasets&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binomial_case &amp;lt;- data.frame(labels = sample(c(&#34;Pos&#34;,&#34;Neg&#34;), 100, replace = TRUE),&#xA;                            predictions = sample(c(&#34;Pos&#34;,&#34;Neg&#34;), 100, replace = TRUE)) %&amp;gt;% &#xA;  mutate(predictions = as.factor(predictions), labels = as.factor(labels))&#xA;&#xA;multinomial_case &amp;lt;- data.frame(labels = sample(c(&#34;Red&#34;,&#34;Green&#34;, &#34;Blue&#34;), 100, replace = TRUE),&#xA;                               predictions = sample(c(&#34;Red&#34;,&#34;Green&#34;, &#34;Blue&#34;), 100, replace = TRUE) ) %&amp;gt;% &#xA;  mutate(predictions = as.factor(predictions), labels = as.factor(labels))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.1. Confusion Matrix &lt;br&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.1.1. Binary&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# a. Print&#xA;binomial_case %&amp;gt;% confusion_matrix(obs = labels, pred = predictions, &#xA;                                            plot = FALSE, colors = c(low=&#34;#f9dbbd&#34; , high=&#34;#735d78&#34;), &#xA;                                            unit = &#34;count&#34;)&#xA;#&amp;gt;          OBSERVED&#xA;#&amp;gt; PREDICTED Neg Pos&#xA;#&amp;gt;       Neg  24  24&#xA;#&amp;gt;       Pos  21  31&#xA;&#xA;# b. Plot&#xA;binomial_case %&amp;gt;% confusion_matrix(obs = labels, pred = predictions, &#xA;                                            plot = TRUE, colors = c(low=&#34;#f9dbbd&#34; , high=&#34;#735d78&#34;), &#xA;                                            unit = &#34;count&#34;, print_metrics = TRUE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-14-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.1.2. Multiclass&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# a. Print&#xA;multinomial_case %&amp;gt;% confusion_matrix(obs = labels, &#xA;                                      pred = predictions, &#xA;                                      plot = FALSE, colors = c(low=&#34;#f9dbbd&#34; , high=&#34;#735d78&#34;),&#xA;                                      unit = &#34;count&#34;)&#xA;#&amp;gt;          OBSERVED&#xA;#&amp;gt; PREDICTED Blue Green Red&#xA;#&amp;gt;     Blue     9    11   9&#xA;#&amp;gt;     Green   11    12  11&#xA;#&amp;gt;     Red     13    13  11&#xA;&#xA;# b. Plot&#xA;multinomial_case %&amp;gt;% confusion_matrix(obs = labels, &#xA;                                      pred = predictions, &#xA;                                      plot = TRUE, colors = c(low=&#34;#d3dbbd&#34; , high=&#34;#885f78&#34;), &#xA;                                      unit = &#34;count&#34;, print_metrics = TRUE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-15-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.1. Classification Metrics &lt;br&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.1.1. Single dataset &lt;br&gt;&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Get classification metrics one by one&#xA;binomial_case %&amp;gt;% accuracy(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   accuracy&#xA;#&amp;gt; 1     0.55&#xA;binomial_case %&amp;gt;% error_rate(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   error_rate&#xA;#&amp;gt; 1       0.45&#xA;binomial_case %&amp;gt;% precision(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   precision&#xA;#&amp;gt; 1 0.5961538&#xA;binomial_case %&amp;gt;% recall(data = ., obs = labels, pred = predictions, atom = F, tidy=TRUE)&#xA;#&amp;gt;      recall&#xA;#&amp;gt; 1 0.5636364&#xA;binomial_case %&amp;gt;% specificity(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;        spec&#xA;#&amp;gt; 1 0.5333333&#xA;binomial_case %&amp;gt;% balacc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;      balacc&#xA;#&amp;gt; 1 0.5484848&#xA;binomial_case %&amp;gt;% fscore(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;      fscore&#xA;#&amp;gt; 1 0.5794393&#xA;binomial_case %&amp;gt;% agf(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         agf&#xA;#&amp;gt; 1 0.5795213&#xA;binomial_case %&amp;gt;% gmean(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       gmean&#xA;#&amp;gt; 1 0.5482755&#xA;binomial_case %&amp;gt;% khat(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         khat&#xA;#&amp;gt; 1 0.09638554&#xA;binomial_case %&amp;gt;% mcc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;          mcc&#xA;#&amp;gt; 1 0.09656091&#xA;binomial_case %&amp;gt;% fmi(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         fmi&#xA;#&amp;gt; 1 0.5796671&#xA;binomial_case %&amp;gt;% posLr(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;      posLr&#xA;#&amp;gt; 1 1.207792&#xA;binomial_case %&amp;gt;% negLr(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       negLr&#xA;#&amp;gt; 1 0.8181818&#xA;binomial_case %&amp;gt;% dor(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       dor&#xA;#&amp;gt; 1 1.47619&#xA;&#xA;# Get all at once with metrics_summary()&#xA;binomial_case %&amp;gt;% metrics_summary(data = ., obs = labels, pred = predictions, type = &#34;classification&#34;)&#xA;#&amp;gt;         Metric      Score&#xA;#&amp;gt; 1     accuracy 0.55000000&#xA;#&amp;gt; 2   error_rate 0.45000000&#xA;#&amp;gt; 3    precision 0.59615385&#xA;#&amp;gt; 4       recall 0.56363636&#xA;#&amp;gt; 5  specificity 0.53333333&#xA;#&amp;gt; 6       balacc 0.54848485&#xA;#&amp;gt; 7       fscore 0.57943925&#xA;#&amp;gt; 8          agf 0.57952126&#xA;#&amp;gt; 9        gmean 0.54827553&#xA;#&amp;gt; 10        khat 0.09638554&#xA;#&amp;gt; 11         mcc 0.09656091&#xA;#&amp;gt; 12         fmi 0.57966713&#xA;#&amp;gt; 13         bmi 0.09696970&#xA;#&amp;gt; 14         csi 0.40789474&#xA;#&amp;gt; 15      deltap 0.09615385&#xA;#&amp;gt; 16       posLr 1.20779221&#xA;#&amp;gt; 17       negLr 0.81818182&#xA;#&amp;gt; 18         dor 1.47619048&#xA;#&amp;gt; 19         npv 0.50000000&#xA;#&amp;gt; 20         FPR 0.46666667&#xA;#&amp;gt; 21         FNR 0.43636364&#xA;#&amp;gt; 22         FDR 0.40384615&#xA;#&amp;gt; 23         FOR 0.50000000&#xA;#&amp;gt; 24      preval 0.55000000&#xA;#&amp;gt; 25    preval_t 0.49309260&#xA;#&amp;gt; 26     AUC_roc 0.54848485&#xA;&#xA;# Multinomial&#xA;multinomial_case %&amp;gt;% metrics_summary(data = ., obs = labels, pred = predictions, type = &#34;classification&#34;)&#xA;#&amp;gt; Warning in metrica::fscore(data = ~., obs = ~labels, pred = ~predictions, :&#xA;#&amp;gt; For multiclass cases, the fscore should be estimated at a class level. Please,&#xA;#&amp;gt; consider using `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::agf(data = ~., obs = ~labels, pred = ~predictions, pos_level&#xA;#&amp;gt; = pos_level): For multiclass cases, the agf should be estimated at a class&#xA;#&amp;gt; level. Please, consider using `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::fmi(data = ~., obs = ~labels, pred = ~predictions, pos_level&#xA;#&amp;gt; = pos_level): The Fowlkes-Mallows Index is not available for multiclass cases.&#xA;#&amp;gt; The result has been recorded as NaN.&#xA;#&amp;gt; Warning in metrica::preval(data = ~., obs = ~labels, pred = ~predictions, : For&#xA;#&amp;gt; multiclass cases, prevalence should be estimated at a class level. A NaN has&#xA;#&amp;gt; been recorded as the result. Please, use `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::preval_t(data = ~., obs = ~labels, pred = ~predictions, : For multiclass cases, prevalence threshold should be estimated at a class level. &#xA;#&amp;gt;       A NaN has been recorded as the result. Please, use `atom = TRUE`.&#xA;#&amp;gt;         Metric       Score&#xA;#&amp;gt; 1     accuracy  0.32000000&#xA;#&amp;gt; 2   error_rate  0.68000000&#xA;#&amp;gt; 3    precision  0.32019443&#xA;#&amp;gt; 4       recall  0.32029977&#xA;#&amp;gt; 5  specificity  0.66031031&#xA;#&amp;gt; 6       balacc  0.49030504&#xA;#&amp;gt; 7       fscore  0.32024709&#xA;#&amp;gt; 8          agf  0.32024710&#xA;#&amp;gt; 9        gmean  0.45988829&#xA;#&amp;gt; 10        khat -0.01918465&#xA;#&amp;gt; 11         mcc -0.01926552&#xA;#&amp;gt; 12         fmi         NaN&#xA;#&amp;gt; 13         bmi -0.01938991&#xA;#&amp;gt; 14         csi  0.13793860&#xA;#&amp;gt; 15      deltap -0.01951385&#xA;#&amp;gt; 16       posLr  0.94291874&#xA;#&amp;gt; 17       negLr  1.02936485&#xA;#&amp;gt; 18         dor  0.91601996&#xA;#&amp;gt; 19         npv  0.66029172&#xA;#&amp;gt; 20         FPR  0.33968969&#xA;#&amp;gt; 21         FNR  0.67970023&#xA;#&amp;gt; 22         FDR  0.67980557&#xA;#&amp;gt; 23         FOR  0.33970828&#xA;#&amp;gt; 24      preval         NaN&#xA;#&amp;gt; 25    preval_t         NaN&#xA;#&amp;gt; 26     AUC_roc  0.49030504&#xA;&#xA;# Get a selected list at once with metrics_summary()&#xA;selected_class_metrics &amp;lt;- c(&#34;accuracy&#34;, &#34;recall&#34;, &#34;fscore&#34;)&#xA;&#xA;# Binary&#xA;binomial_case %&amp;gt;% metrics_summary(data = ., obs = labels, pred = predictions, type = &#34;classification&#34;,&#xA;                                  metrics_list = selected_class_metrics)&#xA;#&amp;gt;     Metric     Score&#xA;#&amp;gt; 1 accuracy 0.5500000&#xA;#&amp;gt; 2   recall 0.5636364&#xA;#&amp;gt; 3   fscore 0.5794393&#xA;&#xA;# Multiclass&#xA;multinomial_case %&amp;gt;% metrics_summary(data = ., obs = labels, pred = predictions, type = &#34;classification&#34;,&#xA;                                  metrics_list = selected_class_metrics)&#xA;#&amp;gt; Warning in metrica::fscore(data = ~., obs = ~labels, pred = ~predictions, :&#xA;#&amp;gt; For multiclass cases, the fscore should be estimated at a class level. Please,&#xA;#&amp;gt; consider using `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::agf(data = ~., obs = ~labels, pred = ~predictions, pos_level&#xA;#&amp;gt; = pos_level): For multiclass cases, the agf should be estimated at a class&#xA;#&amp;gt; level. Please, consider using `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::fmi(data = ~., obs = ~labels, pred = ~predictions, pos_level&#xA;#&amp;gt; = pos_level): The Fowlkes-Mallows Index is not available for multiclass cases.&#xA;#&amp;gt; The result has been recorded as NaN.&#xA;#&amp;gt; Warning in metrica::preval(data = ~., obs = ~labels, pred = ~predictions, : For&#xA;#&amp;gt; multiclass cases, prevalence should be estimated at a class level. A NaN has&#xA;#&amp;gt; been recorded as the result. Please, use `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::preval_t(data = ~., obs = ~labels, pred = ~predictions, : For multiclass cases, prevalence threshold should be estimated at a class level. &#xA;#&amp;gt;       A NaN has been recorded as the result. Please, use `atom = TRUE`.&#xA;#&amp;gt;     Metric     Score&#xA;#&amp;gt; 1 accuracy 0.3200000&#xA;#&amp;gt; 2   recall 0.3202998&#xA;#&amp;gt; 3   fscore 0.3202471&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;multinomial_case %&amp;gt;% accuracy(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   accuracy&#xA;#&amp;gt; 1     0.32&#xA;multinomial_case %&amp;gt;% error_rate(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   error_rate&#xA;#&amp;gt; 1       0.68&#xA;multinomial_case %&amp;gt;% precision(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   precision&#xA;#&amp;gt; 1 0.3201944&#xA;multinomial_case %&amp;gt;% recall(data = ., obs = labels, pred = predictions, atom = F, tidy=TRUE)&#xA;#&amp;gt;      recall&#xA;#&amp;gt; 1 0.3202998&#xA;multinomial_case %&amp;gt;% specificity(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;        spec&#xA;#&amp;gt; 1 0.6603103&#xA;multinomial_case %&amp;gt;% balacc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;     balacc&#xA;#&amp;gt; 1 0.490305&#xA;multinomial_case %&amp;gt;% fscore(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in fscore(data = ., obs = labels, pred = predictions, tidy = TRUE):&#xA;#&amp;gt; For multiclass cases, the fscore should be estimated at a class level. Please,&#xA;#&amp;gt; consider using `atom = TRUE`&#xA;#&amp;gt;      fscore&#xA;#&amp;gt; 1 0.3202471&#xA;multinomial_case %&amp;gt;% agf(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in agf(data = ., obs = labels, pred = predictions, tidy = TRUE): For&#xA;#&amp;gt; multiclass cases, the agf should be estimated at a class level. Please, consider&#xA;#&amp;gt; using `atom = TRUE`&#xA;#&amp;gt;         agf&#xA;#&amp;gt; 1 0.3202471&#xA;multinomial_case %&amp;gt;% gmean(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       gmean&#xA;#&amp;gt; 1 0.4598883&#xA;multinomial_case %&amp;gt;% khat(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;          khat&#xA;#&amp;gt; 1 -0.01918465&#xA;multinomial_case %&amp;gt;% mcc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;           mcc&#xA;#&amp;gt; 1 -0.01926552&#xA;multinomial_case %&amp;gt;% fmi(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in fmi(data = ., obs = labels, pred = predictions, tidy = TRUE): The&#xA;#&amp;gt; Fowlkes-Mallows Index is not available for multiclass cases. The result has been&#xA;#&amp;gt; recorded as NaN.&#xA;#&amp;gt;   fmi&#xA;#&amp;gt; 1 NaN&#xA;multinomial_case %&amp;gt;% posLr(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       posLr&#xA;#&amp;gt; 1 0.9429187&#xA;multinomial_case %&amp;gt;% negLr(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;      negLr&#xA;#&amp;gt; 1 1.029365&#xA;multinomial_case %&amp;gt;% dor(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       dor&#xA;#&amp;gt; 1 0.91602&#xA;multinomial_case %&amp;gt;% deltap(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;        deltap&#xA;#&amp;gt; 1 -0.01951385&#xA;multinomial_case %&amp;gt;% csi(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         csi&#xA;#&amp;gt; 1 0.1379386&#xA;multinomial_case %&amp;gt;% FPR(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         FPR&#xA;#&amp;gt; 1 0.3396897&#xA;multinomial_case %&amp;gt;% FNR(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         FNR&#xA;#&amp;gt; 1 0.6797002&#xA;multinomial_case %&amp;gt;% FDR(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         FDR&#xA;#&amp;gt; 1 0.6798056&#xA;multinomial_case %&amp;gt;% FOR(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         FOR&#xA;#&amp;gt; 1 0.3397083&#xA;multinomial_case %&amp;gt;% preval(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in preval(data = ., obs = labels, pred = predictions, tidy = TRUE): For&#xA;#&amp;gt; multiclass cases, prevalence should be estimated at a class level. A NaN has&#xA;#&amp;gt; been recorded as the result. Please, use `atom = TRUE`&#xA;#&amp;gt;   prev&#xA;#&amp;gt; 1  NaN&#xA;multinomial_case %&amp;gt;% preval_t(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in preval_t(data = ., obs = labels, pred = predictions, tidy = TRUE): For multiclass cases, prevalence threshold should be estimated at a class level. &#xA;#&amp;gt;       A NaN has been recorded as the result. Please, use `atom = TRUE`.&#xA;#&amp;gt;   preval_t&#xA;#&amp;gt; 1      NaN&#xA;multinomial_case %&amp;gt;% AUC_roc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;    AUC_roc&#xA;#&amp;gt; 1 0.490305&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;4. Import data from APSIM&lt;/h2&gt; &#xA;&lt;p&gt;Please, visit the &lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/apsim_open.html&#34;&gt;vignette&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rstudio/renv</title>
    <updated>2022-07-24T02:20:16Z</updated>
    <id>tag:github.com,2022-07-24:/rstudio/renv</id>
    <link href="https://github.com/rstudio/renv" rel="alternate"></link>
    <summary type="html">&lt;p&gt;renv: Project environments for R.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;renv&lt;a href=&#34;https://rstudio.github.io/renv/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rstudio/renv/main/man/figures/logo.svg?sanitize=true&#34; align=&#34;right&#34; height=&#34;115&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lifecycle.r-lib.org/articles/stages.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/lifecycle-stable-brightgreen.svg?sanitize=true&#34; alt=&#34;Lifecycle: stable&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://CRAN.R-project.org/package=renv&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/renv&#34; alt=&#34;CRAN status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/rstudio/renv/actions&#34;&gt;&lt;img src=&#34;https://github.com/rstudio/renv/workflows/R-CMD-check/badge.svg?sanitize=true&#34; alt=&#34;R-CMD-check&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ci.appveyor.com/project/rstudio/renv&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/github/rstudio/renv?branch=main&amp;amp;svg=true&#34; alt=&#34;AppVeyor build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/rstudio/renv?branch=main&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/rstudio/renv/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;Codecov test coverage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;renv&lt;/code&gt; package helps you create &lt;strong&gt;r&lt;/strong&gt;eproducible &lt;strong&gt;env&lt;/strong&gt;ironments for your R projects. Use &lt;code&gt;renv&lt;/code&gt; to make your R projects more:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Isolated&lt;/strong&gt;: Installing a new or updated package for one project won&#39;t break your other projects, and vice versa. That&#39;s because &lt;code&gt;renv&lt;/code&gt; gives each project its own private package library.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Portable&lt;/strong&gt;: Easily transport your projects from one computer to another, even across different platforms. &lt;code&gt;renv&lt;/code&gt; makes it easy to install the packages your project depends on.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Reproducible&lt;/strong&gt;: &lt;code&gt;renv&lt;/code&gt; records the exact package versions you depend on, and ensures those exact versions are the ones that get installed wherever you go.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Install the latest version of &lt;code&gt;renv&lt;/code&gt; from CRAN with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;renv&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also install the development version of &lt;code&gt;renv&lt;/code&gt; from &lt;a href=&#34;https://r-universe.dev/&#34;&gt;R-universe&lt;/a&gt; with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;renv&#34;, repos = &#34;https://rstudio.r-universe.dev&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Workflow&lt;/h2&gt; &#xA;&lt;p&gt;Use &lt;code&gt;renv::init()&lt;/code&gt; to initialize &lt;code&gt;renv&lt;/code&gt; with a new or existing project. This will set up your project with a private library, and also make sure to install all of the packages you&#39;re using into that library. The packages used in your project will be recorded into a &lt;em&gt;lockfile&lt;/em&gt;, called &lt;code&gt;renv.lock&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;As you work in your project, you may need to install or upgrade different packages. As these packages are installed, &lt;code&gt;renv&lt;/code&gt; will automatically write &lt;code&gt;renv.lock&lt;/code&gt; for you. The &lt;code&gt;renv.lock&lt;/code&gt; lockfile records the state of your project&#39;s private library, and can be used to restore the state of that library as required.&lt;/p&gt; &#xA;&lt;p&gt;Later, if you need to port your project to a new machine, you can call &lt;code&gt;renv::restore()&lt;/code&gt; to reinstall all of the packages as declared in the lockfile.&lt;/p&gt; &#xA;&lt;h2&gt;Learning More&lt;/h2&gt; &#xA;&lt;p&gt;You can browse the package documentation online at &lt;a href=&#34;https://rstudio.github.io/renv/&#34;&gt;https://rstudio.github.io/renv/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If this is your first time using &lt;code&gt;renv&lt;/code&gt;, we strongly recommend reading the &lt;a href=&#34;https://rstudio.github.io/renv/articles/renv.html&#34;&gt;Introduction to renv&lt;/a&gt; vignette.&lt;/p&gt; &#xA;&lt;p&gt;If you have a question about &lt;code&gt;renv&lt;/code&gt;, please first check the &lt;a href=&#34;https://rstudio.github.io/renv/articles/faq.html&#34;&gt;FAQ&lt;/a&gt; to see whether your question has already been addressed. If it hasn&#39;t, please feel free to either ask on the &lt;a href=&#34;https://community.rstudio.com&#34;&gt;RStudio Community forums&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you believe you&#39;ve found a bug in &lt;code&gt;renv&lt;/code&gt;, please file a bug (and, if possible, a &lt;a href=&#34;https://reprex.tidyverse.org&#34;&gt;reproducible example&lt;/a&gt;) at &lt;a href=&#34;https://github.com/rstudio/renv/issues&#34;&gt;https://github.com/rstudio/renv/issues&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>paul-buerkner/brms</title>
    <updated>2022-07-24T02:20:16Z</updated>
    <id>tag:github.com,2022-07-24:/paul-buerkner/brms</id>
    <link href="https://github.com/paul-buerkner/brms" rel="alternate"></link>
    <summary type="html">&lt;p&gt;brms R package for Bayesian generalized multivariate non-linear multilevel models using Stan&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/paul-buerkner/brms/master/man/figures/brms.png&#34; width=&#34;120&#34; alt=&#34;brms Logo&#34;&gt;&lt;a href=&#34;https://mc-stan.org/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stan-dev/logos/master/logo_tm.png&#34; align=&#34;right&#34; width=&#34;120&#34; alt=&#34;Stan Logo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;brms&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/paul-buerkner/brms/actions&#34;&gt;&lt;img src=&#34;https://github.com/paul-buerkner/brms/workflows/R-CMD-check/badge.svg?sanitize=true&#34; alt=&#34;R-CMD-check&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/paul-buerkner/brms?branch=master&#34;&gt;&lt;img src=&#34;https://codecov.io/github/paul-buerkner/brms/coverage.svg?branch=master&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cran.r-project.org/package=brms&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/brms&#34; alt=&#34;CRAN Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://CRAN.R-project.org/package=brms&#34;&gt;&lt;img src=&#34;https://cranlogs.r-pkg.org/badges/brms?color=brightgreen&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;strong&gt;brms&lt;/strong&gt; package provides an interface to fit Bayesian generalized (non-)linear multivariate multilevel models using Stan, which is a C++ package for performing full Bayesian inference (see &lt;a href=&#34;https://mc-stan.org/&#34;&gt;https://mc-stan.org/&lt;/a&gt;). The formula syntax is very similar to that of the package lme4 to provide a familiar and simple interface for performing regression analyses. A wide range of response distributions are supported, allowing users to fit – among others – linear, robust linear, count data, survival, response times, ordinal, zero-inflated, and even self-defined mixture models all in a multilevel context. Further modeling options include non-linear and smooth terms, auto-correlation structures, censored data, missing value imputation, and quite a few more. In addition, all parameters of the response distribution can be predicted in order to perform distributional regression. Multivariate models (i.e., models with multiple response variables) can be fit, as well. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. Model fit can easily be assessed and compared with posterior predictive checks, cross-validation, and Bayes factors.&lt;/p&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;Introduction to brms&lt;/a&gt; (Journal of Statistical Software)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://journal.r-project.org/archive/2018/RJ-2018-017/index.html&#34;&gt;Advanced multilevel modeling with brms&lt;/a&gt; (The R Journal)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paul-buerkner.github.io/brms/&#34;&gt;Website&lt;/a&gt; (Website of brms with documentation and vignettes)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paul-buerkner.github.io/blog/brms-blogposts/&#34;&gt;Blog posts&lt;/a&gt; (List of blog posts about brms)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discourse.mc-stan.org/&#34;&gt;Ask a question&lt;/a&gt; (Stan Forums on Discourse)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/paul-buerkner/brms/issues&#34;&gt;Open an issue&lt;/a&gt; (GitHub issues for bug reports and feature requests)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to use brms&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(brms)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As a simple example, we use poisson regression to model the seizure counts in epileptic patients to investigate whether the treatment (represented by variable &lt;code&gt;Trt&lt;/code&gt;) can reduce the seizure counts and whether the effect of the treatment varies with the (standardized) baseline number of seizures a person had before treatment (variable &lt;code&gt;zBase&lt;/code&gt;). As we have multiple observations per person, a group-level intercept is incorporated to account for the resulting dependency in the data.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit1 &amp;lt;- brm(count ~ zAge + zBase * Trt + (1|patient),&#xA;            data = epilepsy, family = poisson())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The results (i.e., posterior draws) can be investigated using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(fit1)&#xA;#&amp;gt;  Family: poisson &#xA;#&amp;gt;   Links: mu = log &#xA;#&amp;gt; Formula: count ~ zAge + zBase * Trt + (1 | patient) &#xA;#&amp;gt;    Data: epilepsy (Number of observations: 236) &#xA;#&amp;gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;&#xA;#&amp;gt;          total post-warmup draws = 4000&#xA;#&amp;gt; &#xA;#&amp;gt; Group-Level Effects: &#xA;#&amp;gt; ~patient (Number of levels: 59) &#xA;#&amp;gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS&#xA;#&amp;gt; sd(Intercept)     0.58      0.07     0.46     0.74 1.00      810     1753&#xA;#&amp;gt; &#xA;#&amp;gt; Population-Level Effects: &#xA;#&amp;gt;            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS&#xA;#&amp;gt; Intercept      1.77      0.12     1.53     2.00 1.00      779     1319&#xA;#&amp;gt; zAge           0.09      0.09    -0.09     0.26 1.00      684     1071&#xA;#&amp;gt; zBase          0.70      0.12     0.46     0.95 1.00      847     1453&#xA;#&amp;gt; Trt1          -0.27      0.17    -0.59     0.06 1.00      661     1046&#xA;#&amp;gt; zBase:Trt1     0.05      0.16    -0.26     0.37 1.00      993     1624&#xA;#&amp;gt; &#xA;#&amp;gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS&#xA;#&amp;gt; and Tail_ESS are effective sample size measures, and Rhat is the potential&#xA;#&amp;gt; scale reduction factor on split chains (at convergence, Rhat = 1).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On the top of the output, some general information on the model is given, such as family, formula, number of iterations and chains. Next, group-level effects are displayed separately for each grouping factor in terms of standard deviations and (in case of more than one group-level effect per grouping factor; not displayed here) correlations between group-level effects. On the bottom of the output, population-level effects (i.e.&amp;nbsp;regression coefficients) are displayed. If incorporated, autocorrelation effects and family specific parameters (e.g.&amp;nbsp;the residual standard deviation ‘sigma’ in normal models) are also given.&lt;/p&gt; &#xA;&lt;p&gt;In general, every parameter is summarized using the mean (‘Estimate’) and the standard deviation (‘Est.Error’) of the posterior distribution as well as two-sided 95% credible intervals (‘l-95% CI’ and ‘u-95% CI’) based on quantiles. We see that the coefficient of &lt;code&gt;Trt&lt;/code&gt; is negative with a zero overlapping 95%-CI. This indicates that, on average, the treatment may reduce seizure counts by some amount but the evidence based on the data and applied model is not very strong and still insufficient by standard decision rules. Further, we find little evidence that the treatment effect varies with the baseline number of seizures.&lt;/p&gt; &#xA;&lt;p&gt;The last two values (‘Eff.Sample’ and ‘Rhat’) provide information on how well the algorithm could estimate the posterior distribution of this parameter. If ‘Rhat’ is considerably greater than 1, the algorithm has not yet converged and it is necessary to run more iterations and / or set stronger priors.&lt;/p&gt; &#xA;&lt;p&gt;To visually investigate the chains as well as the posterior distributions, we can use the &lt;code&gt;plot&lt;/code&gt; method. If we just want to see results of the regression coefficients of &lt;code&gt;Trt&lt;/code&gt; and &lt;code&gt;zBase&lt;/code&gt;, we go for&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(fit1, variable = c(&#34;b_Trt1&#34;, &#34;b_zBase&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/paul-buerkner/brms/master/man/figures/README-plot-1.png&#34; width=&#34;60%&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;p&gt;A more detailed investigation can be performed by running &lt;code&gt;launch_shinystan(fit1)&lt;/code&gt;. To better understand the relationship of the predictors with the response, I recommend the &lt;code&gt;conditional_effects&lt;/code&gt; method:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(conditional_effects(fit1, effects = &#34;zBase:Trt&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/paul-buerkner/brms/master/man/figures/README-conditional_effects-1.png&#34; width=&#34;60%&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;p&gt;This method uses some prediction functionality behind the scenes, which can also be called directly. Suppose that we want to predict responses (i.e.&amp;nbsp;seizure counts) of a person in the treatment group (&lt;code&gt;Trt = 1&lt;/code&gt;) and in the control group (&lt;code&gt;Trt = 0&lt;/code&gt;) with average age and average number of previous seizures. Than we can use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;newdata &amp;lt;- data.frame(Trt = c(0, 1), zAge = 0, zBase = 0)&#xA;predict(fit1, newdata = newdata, re_formula = NA)&#xA;#&amp;gt;      Estimate Est.Error Q2.5 Q97.5&#xA;#&amp;gt; [1,]   5.8980  2.505627    2    11&#xA;#&amp;gt; [2,]   4.5595  2.162320    1     9&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We need to set &lt;code&gt;re_formula = NA&lt;/code&gt; in order not to condition of the group-level effects. While the &lt;code&gt;predict&lt;/code&gt; method returns predictions of the responses, the &lt;code&gt;fitted&lt;/code&gt; method returns predictions of the regression line.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fitted(fit1, newdata = newdata, re_formula = NA)&#xA;#&amp;gt;      Estimate Est.Error     Q2.5    Q97.5&#xA;#&amp;gt; [1,] 5.917144 0.7056695 4.632004 7.387471&#xA;#&amp;gt; [2,] 4.529949 0.5360204 3.544085 5.624005&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Both methods return the same estimate (up to random error), while the latter has smaller variance, because the uncertainty in the regression line is smaller than the uncertainty in each response. If we want to predict values of the original data, we can just leave the &lt;code&gt;newdata&lt;/code&gt; argument empty.&lt;/p&gt; &#xA;&lt;p&gt;Suppose, we want to investigate whether there is overdispersion in the model, that is residual variation not accounted for by the response distribution. For this purpose, we include a second group-level intercept that captures possible overdispersion.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit2 &amp;lt;- brm(count ~ zAge + zBase * Trt + (1|patient) + (1|obs),&#xA;            data = epilepsy, family = poisson())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can then go ahead and compare both models via approximate leave-one-out (LOO) cross-validation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;loo(fit1, fit2)&#xA;#&amp;gt; Output of model &#39;fit1&#39;:&#xA;#&amp;gt; &#xA;#&amp;gt; Computed from 4000 by 236 log-likelihood matrix&#xA;#&amp;gt; &#xA;#&amp;gt;          Estimate   SE&#xA;#&amp;gt; elpd_loo   -670.4 36.7&#xA;#&amp;gt; p_loo        92.8 14.3&#xA;#&amp;gt; looic      1340.8 73.3&#xA;#&amp;gt; ------&#xA;#&amp;gt; Monte Carlo SE of elpd_loo is NA.&#xA;#&amp;gt; &#xA;#&amp;gt; Pareto k diagnostic values:&#xA;#&amp;gt;                          Count Pct.    Min. n_eff&#xA;#&amp;gt; (-Inf, 0.5]   (good)     214   90.7%   251       &#xA;#&amp;gt;  (0.5, 0.7]   (ok)        17    7.2%   80        &#xA;#&amp;gt;    (0.7, 1]   (bad)        3    1.3%   81        &#xA;#&amp;gt;    (1, Inf)   (very bad)   2    0.8%   6         &#xA;#&amp;gt; See help(&#39;pareto-k-diagnostic&#39;) for details.&#xA;#&amp;gt; &#xA;#&amp;gt; Output of model &#39;fit2&#39;:&#xA;#&amp;gt; &#xA;#&amp;gt; Computed from 4000 by 236 log-likelihood matrix&#xA;#&amp;gt; &#xA;#&amp;gt;          Estimate   SE&#xA;#&amp;gt; elpd_loo   -595.2 14.1&#xA;#&amp;gt; p_loo       108.0  7.3&#xA;#&amp;gt; looic      1190.4 28.2&#xA;#&amp;gt; ------&#xA;#&amp;gt; Monte Carlo SE of elpd_loo is NA.&#xA;#&amp;gt; &#xA;#&amp;gt; Pareto k diagnostic values:&#xA;#&amp;gt;                          Count Pct.    Min. n_eff&#xA;#&amp;gt; (-Inf, 0.5]   (good)      82   34.7%   544       &#xA;#&amp;gt;  (0.5, 0.7]   (ok)       103   43.6%   153       &#xA;#&amp;gt;    (0.7, 1]   (bad)       47   19.9%   22        &#xA;#&amp;gt;    (1, Inf)   (very bad)   4    1.7%   7         &#xA;#&amp;gt; See help(&#39;pareto-k-diagnostic&#39;) for details.&#xA;#&amp;gt; &#xA;#&amp;gt; Model comparisons:&#xA;#&amp;gt;      elpd_diff se_diff&#xA;#&amp;gt; fit2   0.0       0.0  &#xA;#&amp;gt; fit1 -75.2      26.9&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;loo&lt;/code&gt; output when comparing models is a little verbose. We first see the individual LOO summaries of the two models and then the comparison between them. Since higher &lt;code&gt;elpd&lt;/code&gt; (i.e., expected log posterior density) values indicate better fit, we see that the model accounting for overdispersion (i.e., &lt;code&gt;fit2&lt;/code&gt;) fits substantially better. However, we also see in the individual LOO outputs that there are several problematic observations for which the approximations may have not have been very accurate. To deal with this appropriately, we need to fall back to other methods such as &lt;code&gt;reloo&lt;/code&gt; or &lt;code&gt;kfold&lt;/code&gt; but this requires the model to be refit several times which takes too long for the purpose of a quick example. The post-processing methods we have shown above are just the tip of the iceberg. For a full list of methods to apply on fitted model objects, type &lt;code&gt;methods(class = &#34;brmsfit&#34;)&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citing brms and related software&lt;/h2&gt; &#xA;&lt;p&gt;Developing and maintaining open source software is an important yet often underappreciated contribution to scientific progress. Thus, whenever you are using open source software (or software in general), please make sure to cite it appropriately so that developers get credit for their work.&lt;/p&gt; &#xA;&lt;p&gt;When using brms, please cite one or more of the following publications:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bürkner P. C. (2017). brms: An R Package for Bayesian Multilevel Models using Stan. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;. 80(1), 1-28. doi.org/10.18637/jss.v080.i01&lt;/li&gt; &#xA; &lt;li&gt;Bürkner P. C. (2018). Advanced Bayesian Multilevel Modeling with the R Package brms. &lt;em&gt;The R Journal&lt;/em&gt;. 10(1), 395-411. doi.org/10.32614/RJ-2018-017&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;As brms is a high-level interface to Stan, please additionally cite Stan:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Carpenter B., Gelman A., Hoffman M. D., Lee D., Goodrich B., Betancourt M., Brubaker M., Guo J., Li P., and Riddell A. (2017). Stan: A probabilistic programming language. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;. 76(1). 10.18637/jss.v076.i01&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Further, brms relies on several other R packages and, of course, on R itself. To find out how to cite R and its packages, use the &lt;code&gt;citation&lt;/code&gt; function. There are some features of brms which specifically rely on certain packages. The &lt;strong&gt;rstan&lt;/strong&gt; package together with &lt;strong&gt;Rcpp&lt;/strong&gt; makes Stan conveniently accessible in R. Visualizations and posterior-predictive checks are based on &lt;strong&gt;bayesplot&lt;/strong&gt; and &lt;strong&gt;ggplot2&lt;/strong&gt;. Approximate leave-one-out cross-validation using &lt;code&gt;loo&lt;/code&gt; and related methods is done via the &lt;strong&gt;loo&lt;/strong&gt; package. Marginal likelihood based methods such as &lt;code&gt;bayes_factor&lt;/code&gt; are realized by means of the &lt;strong&gt;bridgesampling&lt;/strong&gt; package. Splines specified via the &lt;code&gt;s&lt;/code&gt; and &lt;code&gt;t2&lt;/code&gt; functions rely on &lt;strong&gt;mgcv&lt;/strong&gt;. If you use some of these features, please also consider citing the related packages.&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;How do I install brms?&lt;/h3&gt; &#xA;&lt;p&gt;To install the latest release version from CRAN use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;brms&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The current developmental version can be downloaded from github via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;if (!requireNamespace(&#34;remotes&#34;)) {&#xA;  install.packages(&#34;remotes&#34;)&#xA;}&#xA;remotes::install_github(&#34;paul-buerkner/brms&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Because brms is based on Stan, a C++ compiler is required. The program Rtools (available on &lt;a href=&#34;https://cran.r-project.org/bin/windows/Rtools/&#34;&gt;https://cran.r-project.org/bin/windows/Rtools/&lt;/a&gt;) comes with a C++ compiler for Windows. On Mac, you should install Xcode. For further instructions on how to get the compilers running, see the prerequisites section on &lt;a href=&#34;https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started&#34;&gt;https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;I am new to brms. Where can I start?&lt;/h3&gt; &#xA;&lt;p&gt;Detailed instructions and case studies are given in the package’s extensive vignettes. See &lt;code&gt;vignette(package = &#34;brms&#34;)&lt;/code&gt; for an overview. For documentation on formula syntax, families, and prior distributions see &lt;code&gt;help(&#34;brm&#34;)&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Where do I ask questions, propose a new feature, or report a bug?&lt;/h3&gt; &#xA;&lt;p&gt;Questions can be asked on the &lt;a href=&#34;https://discourse.mc-stan.org/&#34;&gt;Stan forums&lt;/a&gt; on Discourse. To propose a new feature or report a bug, please open an issue on &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;How can I extract the generated Stan code?&lt;/h3&gt; &#xA;&lt;p&gt;If you have already fitted a model, just apply the &lt;code&gt;stancode&lt;/code&gt; method on the fitted model object. If you just want to generate the Stan code without any model fitting, use the &lt;code&gt;make_stancode&lt;/code&gt; function.&lt;/p&gt; &#xA;&lt;h3&gt;Can I avoid compiling models?&lt;/h3&gt; &#xA;&lt;p&gt;When you fit your model for the first time with brms, there is currently no way to avoid compilation. However, if you have already fitted your model and want to run it again, for instance with more draws, you can do this without recompilation by using the &lt;code&gt;update&lt;/code&gt; method. For more details see &lt;code&gt;help(&#34;update.brmsfit&#34;)&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;What is the difference between brms and rstanarm?&lt;/h3&gt; &#xA;&lt;p&gt;The rstanarm package is similar to brms in that it also allows to fit regression models using Stan for the backend estimation. Contrary to brms, rstanarm comes with precompiled code to save the compilation time (and the need for a C++ compiler) when fitting a model. However, as brms generates its Stan code on the fly, it offers much more flexibility in model specification than rstanarm. Also, multilevel models are currently fitted a bit more efficiently in brms. For detailed comparisons of brms with other common R packages implementing multilevel models, see &lt;code&gt;vignette(&#34;brms_multilevel&#34;)&lt;/code&gt; and &lt;code&gt;vignette(&#34;brms_overview&#34;)&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>