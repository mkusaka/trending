<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-26T01:43:45Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>toddwschneider/nyc-taxi-data</title>
    <updated>2023-02-26T01:43:45Z</updated>
    <id>tag:github.com,2023-02-26:/toddwschneider/nyc-taxi-data</id>
    <link href="https://github.com/toddwschneider/nyc-taxi-data" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Import public NYC taxi and for-hire vehicle (Uber, Lyft) trip data into a PostgreSQL or ClickHouse database&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;New York City Taxi and For-Hire Vehicle Data&lt;/h1&gt; &#xA;&lt;p&gt;Scripts to download, process, and analyze data from 3+ billion taxi and for-hire vehicle (Uber, Lyft, etc.) trips originating in New York City since 2009. There are separate sets of scripts for storing data in either a &lt;a href=&#34;https://www.postgresql.org/&#34;&gt;PostgreSQL&lt;/a&gt; or &lt;a href=&#34;https://clickhouse.com/&#34;&gt;ClickHouse&lt;/a&gt; database.&lt;/p&gt; &#xA;&lt;p&gt;Most of the &lt;a href=&#34;https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page&#34;&gt;raw data&lt;/a&gt; comes from the NYC Taxi &amp;amp; Limousine Commission.&lt;/p&gt; &#xA;&lt;p&gt;The repo was created originally in support of this post: &lt;a href=&#34;https://toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/&#34;&gt;Analyzing 1.1 Billion NYC Taxi and Uber Trips, with a Vengeance&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;TLC 2022 Parquet Format Update&lt;/h2&gt; &#xA;&lt;p&gt;The TLC changed the raw data format from CSV to Apache Parquet in May 2022, including a full replacement of all historical files. This repo is now updated to handle the Parquet files in one of two ways:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The &#34;old&#34; Postgres-based code still works, by adding an intermediate step that converts each Parquet file into a CSV before using the Postgres &lt;code&gt;COPY&lt;/code&gt; command&lt;/li&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://github.com/toddwschneider/nyc-taxi-data/tree/master/clickhouse&#34;&gt;separate set of scripts&lt;/a&gt; loads the Parquet files directly into a ClickHouse database&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;As part of the May 2022 update, the TLC added several new columns to the High Volume For-Hire Vehicle (Uber, Lyft) trip files, including information about passenger fares, driver pay, and time spent waiting for passengers. These new fields are available back to February 2019.&lt;/p&gt; &#xA;&lt;p&gt;This repo no longer works with the old CSV files provided by the TLC. Those files are no longer available to download from the TLC&#39;s website, but if you happen to have them lying around and want to use this repo, you should look at &lt;a href=&#34;https://github.com/toddwschneider/nyc-taxi-data/tree/2e805ab0f1bf362f890c6b6f227526c575f73b67&#34;&gt;this older verion of the code&lt;/a&gt; from before the Parquet file format change.&lt;/p&gt; &#xA;&lt;h2&gt;ClickHouse Instructions&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://github.com/toddwschneider/nyc-taxi-data/tree/master/clickhouse&#34;&gt;&lt;code&gt;clickhouse&lt;/code&gt;&lt;/a&gt; directory&lt;/p&gt; &#xA;&lt;h2&gt;PostgreSQL Instructions&lt;/h2&gt; &#xA;&lt;h5&gt;1. Install &lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;PostgreSQL&lt;/a&gt; and &lt;a href=&#34;https://postgis.net/install&#34;&gt;PostGIS&lt;/a&gt;&lt;/h5&gt; &#xA;&lt;p&gt;Both are available via &lt;a href=&#34;https://brew.sh/&#34;&gt;Homebrew&lt;/a&gt; on Mac&lt;/p&gt; &#xA;&lt;h5&gt;2. Install &lt;a href=&#34;https://www.r-project.org/&#34;&gt;R&lt;/a&gt;&lt;/h5&gt; &#xA;&lt;p&gt;From &lt;a href=&#34;https://cloud.r-project.org/&#34;&gt;CRAN&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note that R used to be optional for this repo, but is required starting with the 2022 file format change. The scripts use R to convert Parquet files to CSV before loading into Postgres. There are other ways to convert from Parquet to CSV that wouldn&#39;t require R, but I found that R&#39;s &lt;code&gt;arrow&lt;/code&gt; package was faster than some of the other CLI tools I tried&lt;/p&gt; &#xA;&lt;h5&gt;3. Download raw data&lt;/h5&gt; &#xA;&lt;p&gt;&lt;code&gt;./download_raw_data.sh&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h5&gt;4. Initialize database and set up schema&lt;/h5&gt; &#xA;&lt;p&gt;&lt;code&gt;./initialize_database.sh&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h5&gt;5. Import taxi and FHV data&lt;/h5&gt; &#xA;&lt;p&gt;&lt;code&gt;./import_yellow_taxi_trip_data.sh&lt;/code&gt; &lt;br&gt; &lt;code&gt;./import_green_taxi_trip_data.sh&lt;/code&gt; &lt;br&gt; &lt;code&gt;./import_fhv_taxi_trip_data.sh&lt;/code&gt; &lt;br&gt; &lt;code&gt;./import_fhvhv_trip_data.sh&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note that the full import process might take several hours or possibly even over a day depending on computing power&lt;/p&gt; &#xA;&lt;h2&gt;Schema&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;trips&lt;/code&gt; table contains all yellow and green taxi trips. Each trip has a &lt;code&gt;cab_type_id&lt;/code&gt;, which references the &lt;code&gt;cab_types&lt;/code&gt; table and refers to one of &lt;code&gt;yellow&lt;/code&gt; or &lt;code&gt;green&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;fhv_trips&lt;/code&gt; table contains all for-hire vehicle trip records, including ride-hailing apps Uber, Lyft, Via, and Juno&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;fhv_bases&lt;/code&gt; maps &lt;code&gt;fhv_trips&lt;/code&gt; to base names and &#34;doing business as&#34; labels, which include ride-hailing app names&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;nyct2010&lt;/code&gt; table contains NYC census tracts plus the Newark Airport. It also maps census tracts to NYC&#39;s official neighborhood tabulation areas&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;taxi_zones&lt;/code&gt; table contains the TLC&#39;s official taxi zone boundaries. Starting in July 2016, the TLC no longer provides pickup and dropoff coordinates. Instead, each trip comes with taxi zone pickup and dropoff location IDs&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;central_park_weather_observations&lt;/code&gt; has summary weather data by date&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Other data sources&lt;/h2&gt; &#xA;&lt;p&gt;These are bundled with the repository, so no need to download separately, but:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Shapefile for NYC census tracts and neighborhood tabulation areas comes from &lt;a href=&#34;https://www1.nyc.gov/site/planning/data-maps/open-data/districts-download-metadata.page&#34;&gt;Bytes of the Big Apple&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Shapefile for taxi zone locations comes from the TLC&lt;/li&gt; &#xA; &lt;li&gt;Mapping of FHV base numbers to names comes from &lt;a href=&#34;https://data.cityofnewyork.us/Transportation/FHV-Base-Aggregate-Report/2v9c-2k7f&#34;&gt;the TLC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Central Park weather data comes from the &lt;a href=&#34;https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00094728/detail&#34;&gt;National Climatic Data Center&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;See Also&lt;/h2&gt; &#xA;&lt;p&gt;Mark Litwintschik has used the taxi dataset to benchmark performance of many different technology stacks, including PostgreSQL and ClickHouse. His summary is here: &lt;a href=&#34;https://tech.marksblogg.com/benchmarks.html&#34;&gt;https://tech.marksblogg.com/benchmarks.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;TLC summary statistics&lt;/h2&gt; &#xA;&lt;p&gt;There&#39;s a Ruby script in the &lt;code&gt;tlc_statistics/&lt;/code&gt; folder to import data from the TLC&#39;s &lt;a href=&#34;https://www1.nyc.gov/site/tlc/about/aggregated-reports.page&#34;&gt;summary statistics reports&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ruby import_statistics_data.rb&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;These summary statistics are used in the &lt;a href=&#34;https://toddwschneider.com/dashboards/nyc-taxi-ridehailing-uber-lyft-data/&#34;&gt;NYC Taxi &amp;amp; Ridehailing Stats&lt;/a&gt; dashboard&lt;/p&gt; &#xA;&lt;h2&gt;Taxi vs. Citi Bike comparison&lt;/h2&gt; &#xA;&lt;p&gt;Code in support of the post &lt;a href=&#34;https://toddwschneider.com/posts/taxi-vs-citi-bike-nyc/&#34;&gt;When Are Citi Bikes Faster Than Taxis in New York City?&lt;/a&gt; lives in the &lt;code&gt;citibike_comparison/&lt;/code&gt; folder&lt;/p&gt; &#xA;&lt;h2&gt;2017 update&lt;/h2&gt; &#xA;&lt;p&gt;Code in support of the &lt;a href=&#34;https://toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/#update-2017&#34;&gt;2017 update&lt;/a&gt; to the original post lives in the &lt;code&gt;analysis/2017_update/&lt;/code&gt; folder&lt;/p&gt; &#xA;&lt;h2&gt;Questions/issues/contact&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;mailto:todd@toddwschneider.com&#34;&gt;todd@toddwschneider.com&lt;/a&gt;, or open a GitHub issue&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cran/translate.logit</title>
    <updated>2023-02-26T01:43:45Z</updated>
    <id>tag:github.com,2023-02-26:/cran/translate.logit</id>
    <link href="https://github.com/cran/translate.logit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;❗ This is a read-only mirror of the CRAN R package repository. translate.logit — Translation of Logit Regression Coefficients into Percentages&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>stemangiola/CuratedAtlasQueryR</title>
    <updated>2023-02-26T01:43:45Z</updated>
    <id>tag:github.com,2023-02-26:/stemangiola/CuratedAtlasQueryR</id>
    <link href="https://github.com/stemangiola/CuratedAtlasQueryR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tidy R query API for the harmonised and curated CELLxGENE single-cell atlas.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CuratedAtlasQueryR&lt;/h1&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.tidyverse.org/lifecycle/#maturing&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/lifecycle-maturing-blue.svg?sanitize=true&#34; alt=&#34;Lifecycle:maturing&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;p&gt;&lt;code&gt;CuratedAtlasQuery&lt;/code&gt; is a query interface that allow the programmatic exploration and retrieval of the harmonised, curated and reannotated CELLxGENE single-cell human cell atlas. Data can be retrieved at cell, sample, or dataset levels based on filtering criteria.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/stemangiola/CuratedAtlasQueryR/master/man/figures/logo.png&#34; width=&#34;120x&#34; height=&#34;139px&#34;&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stemangiola/CuratedAtlasQueryR/master/man/figures/svcf_logo.jpeg&#34; width=&#34;155x&#34; height=&#34;58px&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stemangiola/CuratedAtlasQueryR/master/man/figures/czi_logo.png&#34; width=&#34;129px&#34; height=&#34;58px&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stemangiola/CuratedAtlasQueryR/master/man/figures/bioconductor_logo.jpg&#34; width=&#34;202px&#34; height=&#34;58px&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stemangiola/CuratedAtlasQueryR/master/man/figures/vca_logo.png&#34; width=&#34;219px&#34; height=&#34;58px&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/stemangiola/CuratedAtlasQueryR/master/man/figures/nectar_logo.png&#34; width=&#34;180px&#34; height=&#34;58px&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://stemangiola.github.io/CuratedAtlasQueryR&#34;&gt;website&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Query interface&lt;/h1&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&#34;stemangiola/CuratedAtlasQueryR&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Load the package&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(CuratedAtlasQueryR)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Load and explore the metadata&lt;/h2&gt; &#xA;&lt;h3&gt;Load the metadata&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;metadata  = get_metadata()&#xA;&#xA;metadata&#xA;#&amp;gt; # Source:   table&amp;lt;/stornext/Home/data/allstaff/m/mangiola.s/.cache/R/CuratedAtlasQueryR/metadata.0.2.3.parquet&amp;gt; [?? x 56]&#xA;#&amp;gt; # Database: DuckDB 0.7.0 [unknown@Linux 3.10.0-1160.81.1.el7.x86_64:R 4.2.0/:memory:]&#xA;#&amp;gt;    cell_ sample_ cell_…¹ cell_…² confi…³ cell_…⁴ cell_…⁵ cell_…⁶ sampl…⁷ _samp…⁸&#xA;#&amp;gt;    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;  &#xA;#&amp;gt;  1 AAAC… 689e2f… basal … basal_…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    f297c7… D17PrP…&#xA;#&amp;gt;  2 AAAC… 689e2f… basal … basal_…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    f297c7… D17PrP…&#xA;#&amp;gt;  3 AAAC… 689e2f… lumina… lumina…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    930938… D17PrP…&#xA;#&amp;gt;  4 AAAC… 689e2f… lumina… lumina…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    930938… D17PrP…&#xA;#&amp;gt;  5 AAAC… 689e2f… basal … basal_…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    f297c7… D17PrP…&#xA;#&amp;gt;  6 AAAC… 689e2f… basal … basal_…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    f297c7… D17PrP…&#xA;#&amp;gt;  7 AAAC… 689e2f… basal … basal_…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    f297c7… D17PrP…&#xA;#&amp;gt;  8 AAAC… 689e2f… basal … basal_…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    f297c7… D17PrP…&#xA;#&amp;gt;  9 AAAC… 689e2f… lumina… lumina…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    930938… D17PrP…&#xA;#&amp;gt; 10 AAAC… 689e2f… basal … basal_…       1 &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    &amp;lt;NA&amp;gt;    f297c7… D17PrP…&#xA;#&amp;gt; # … with more rows, 46 more variables: assay &amp;lt;chr&amp;gt;,&#xA;#&amp;gt; #   assay_ontology_term_id &amp;lt;chr&amp;gt;, file_id_db &amp;lt;chr&amp;gt;,&#xA;#&amp;gt; #   cell_type_ontology_term_id &amp;lt;chr&amp;gt;, development_stage &amp;lt;chr&amp;gt;,&#xA;#&amp;gt; #   development_stage_ontology_term_id &amp;lt;chr&amp;gt;, disease &amp;lt;chr&amp;gt;,&#xA;#&amp;gt; #   disease_ontology_term_id &amp;lt;chr&amp;gt;, ethnicity &amp;lt;chr&amp;gt;,&#xA;#&amp;gt; #   ethnicity_ontology_term_id &amp;lt;chr&amp;gt;, experiment___ &amp;lt;chr&amp;gt;, file_id &amp;lt;chr&amp;gt;,&#xA;#&amp;gt; #   is_primary_data_x &amp;lt;chr&amp;gt;, organism &amp;lt;chr&amp;gt;, organism_ontology_term_id &amp;lt;chr&amp;gt;, …&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Explore the number of datasets per tissue&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;metadata |&amp;gt;&#xA;  dplyr::distinct(tissue, dataset_id) |&amp;gt; &#xA;  dplyr::count(tissue)&#xA;#&amp;gt; # Source:   SQL [?? x 2]&#xA;#&amp;gt; # Database: DuckDB 0.7.0 [unknown@Linux 3.10.0-1160.81.1.el7.x86_64:R 4.2.0/:memory:]&#xA;#&amp;gt;    tissue                          n&#xA;#&amp;gt;    &amp;lt;chr&amp;gt;                       &amp;lt;dbl&amp;gt;&#xA;#&amp;gt;  1 peripheral zone of prostate    10&#xA;#&amp;gt;  2 transition zone of prostate    10&#xA;#&amp;gt;  3 blood                          47&#xA;#&amp;gt;  4 intestine                      18&#xA;#&amp;gt;  5 middle temporal gyrus          24&#xA;#&amp;gt;  6 heart left ventricle           46&#xA;#&amp;gt;  7 apex of heart                  16&#xA;#&amp;gt;  8 heart right ventricle          16&#xA;#&amp;gt;  9 left cardiac atrium             7&#xA;#&amp;gt; 10 interventricular septum        16&#xA;#&amp;gt; # … with more rows&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Download single-cell RNA sequencing counts&lt;/h2&gt; &#xA;&lt;h3&gt;Query raw counts&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&#xA;single_cell_counts = &#xA;    metadata |&amp;gt;&#xA;    dplyr::filter(&#xA;        ethnicity == &#34;African&#34; &amp;amp;&#xA;        stringr::str_like(assay, &#34;%10x%&#34;) &amp;amp;&#xA;        tissue == &#34;lung parenchyma&#34; &amp;amp;&#xA;        stringr::str_like(cell_type, &#34;%CD4%&#34;)&#xA;    ) |&amp;gt;&#xA;    get_SingleCellExperiment()&#xA;#&amp;gt; ℹ Realising metadata.&#xA;#&amp;gt; ℹ Synchronising files&#xA;#&amp;gt; ℹ Reading files.&#xA;#&amp;gt; ℹ Compiling Single Cell Experiment.&#xA;&#xA;single_cell_counts&#xA;#&amp;gt; class: SingleCellExperiment &#xA;#&amp;gt; dim: 35615 1571 &#xA;#&amp;gt; metadata(0):&#xA;#&amp;gt; assays(2): counts cpm&#xA;#&amp;gt; rownames(35615): TSPAN6 TNMD ... LNCDAT HRURF&#xA;#&amp;gt; rowData names(0):&#xA;#&amp;gt; colnames(1571): ACAGCCGGTCCGTTAA_F02526_1 GGGAATGAGCCCAGCT_F02526_1 ...&#xA;#&amp;gt;   TACAACGTCAGCATTG_SC84_1 CATTCGCTCAATACCG_F02526_1&#xA;#&amp;gt; colData names(56): sample_ cell_type ... updated_at_y original_cell_id&#xA;#&amp;gt; reducedDimNames(0):&#xA;#&amp;gt; mainExpName: NULL&#xA;#&amp;gt; altExpNames(0):&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Query counts scaled per million&lt;/h3&gt; &#xA;&lt;p&gt;This is helpful if just few genes are of interest, as they can be compared across samples.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;single_cell_counts = &#xA;    metadata |&amp;gt;&#xA;    dplyr::filter(&#xA;        ethnicity == &#34;African&#34; &amp;amp;&#xA;        stringr::str_like(assay, &#34;%10x%&#34;) &amp;amp;&#xA;        tissue == &#34;lung parenchyma&#34; &amp;amp;&#xA;        stringr::str_like(cell_type, &#34;%CD4%&#34;)&#xA;    ) |&amp;gt;&#xA;    get_SingleCellExperiment(assays = &#34;cpm&#34;)&#xA;#&amp;gt; ℹ Realising metadata.&#xA;#&amp;gt; ℹ Synchronising files&#xA;#&amp;gt; ℹ Reading files.&#xA;#&amp;gt; ℹ Compiling Single Cell Experiment.&#xA;&#xA;single_cell_counts&#xA;#&amp;gt; class: SingleCellExperiment &#xA;#&amp;gt; dim: 35615 1571 &#xA;#&amp;gt; metadata(0):&#xA;#&amp;gt; assays(1): cpm&#xA;#&amp;gt; rownames(35615): TSPAN6 TNMD ... LNCDAT HRURF&#xA;#&amp;gt; rowData names(0):&#xA;#&amp;gt; colnames(1571): ACAGCCGGTCCGTTAA_F02526_1 GGGAATGAGCCCAGCT_F02526_1 ...&#xA;#&amp;gt;   TACAACGTCAGCATTG_SC84_1 CATTCGCTCAATACCG_F02526_1&#xA;#&amp;gt; colData names(56): sample_ cell_type ... updated_at_y original_cell_id&#xA;#&amp;gt; reducedDimNames(0):&#xA;#&amp;gt; mainExpName: NULL&#xA;#&amp;gt; altExpNames(0):&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Extract only a subset of genes&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;single_cell_counts = &#xA;    metadata |&amp;gt;&#xA;    dplyr::filter(&#xA;        ethnicity == &#34;African&#34; &amp;amp;&#xA;        stringr::str_like(assay, &#34;%10x%&#34;) &amp;amp;&#xA;        tissue == &#34;lung parenchyma&#34; &amp;amp;&#xA;        stringr::str_like(cell_type, &#34;%CD4%&#34;)&#xA;    ) |&amp;gt;&#xA;    get_SingleCellExperiment(assays = &#34;cpm&#34;, features = &#34;PUM1&#34;)&#xA;#&amp;gt; ℹ Realising metadata.&#xA;#&amp;gt; ℹ Synchronising files&#xA;#&amp;gt; ℹ Reading files.&#xA;#&amp;gt; ℹ Compiling Single Cell Experiment.&#xA;&#xA;single_cell_counts&#xA;#&amp;gt; class: SingleCellExperiment &#xA;#&amp;gt; dim: 1 1571 &#xA;#&amp;gt; metadata(0):&#xA;#&amp;gt; assays(1): cpm&#xA;#&amp;gt; rownames(1): PUM1&#xA;#&amp;gt; rowData names(0):&#xA;#&amp;gt; colnames(1571): ACAGCCGGTCCGTTAA_F02526_1 GGGAATGAGCCCAGCT_F02526_1 ...&#xA;#&amp;gt;   TACAACGTCAGCATTG_SC84_1 CATTCGCTCAATACCG_F02526_1&#xA;#&amp;gt; colData names(56): sample_ cell_type ... updated_at_y original_cell_id&#xA;#&amp;gt; reducedDimNames(0):&#xA;#&amp;gt; mainExpName: NULL&#xA;#&amp;gt; altExpNames(0):&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Extract the counts as a Seurat object&lt;/h3&gt; &#xA;&lt;p&gt;This convert the H5 SingleCellExperiment to Seurat so it might take long time and occupy a lot of memory depending on how many cells you are requesting.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;single_cell_counts = &#xA;    metadata |&amp;gt;&#xA;    dplyr::filter(&#xA;        ethnicity == &#34;African&#34; &amp;amp;&#xA;        stringr::str_like(assay, &#34;%10x%&#34;) &amp;amp;&#xA;        tissue == &#34;lung parenchyma&#34; &amp;amp;&#xA;        stringr::str_like(cell_type, &#34;%CD4%&#34;)&#xA;    ) |&amp;gt;&#xA;    get_seurat()&#xA;#&amp;gt; ℹ Realising metadata.&#xA;#&amp;gt; ℹ Synchronising files&#xA;#&amp;gt; ℹ Reading files.&#xA;#&amp;gt; ℹ Compiling Single Cell Experiment.&#xA;#&amp;gt; Warning: Non-unique features (rownames) present in the input matrix, making&#xA;#&amp;gt; unique&#xA;&#xA;single_cell_counts&#xA;#&amp;gt; An object of class Seurat &#xA;#&amp;gt; 35615 features across 1571 samples within 1 assay &#xA;#&amp;gt; Active assay: originalexp (35615 features, 0 variable features)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Visualise gene transcription&lt;/h2&gt; &#xA;&lt;p&gt;We can gather all CD14 monocytes cells and plot the distribution of HLA-A across all tissues&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidySingleCellExperiment)&#xA;library(ggplot2)&#xA;&#xA;metadata |&amp;gt;&#xA;  # Filter and subset&#xA;  filter(cell_type_harmonised==&#34;cd14 mono&#34;) |&amp;gt;&#xA;&#xA;  # Get counts per million for HCA-A gene&#xA;  get_SingleCellExperiment(assays = &#34;cpm&#34;, features = &#34;HLA-A&#34;) |&amp;gt; &#xA;  &#xA;  # Plot (styling code have been omitted)&#xA;  join_features(&#34;HLA-A&#34;, shape = &#34;wide&#34;) |&amp;gt; &#xA;  ggplot(aes( disease, `HLA.A`,color = file_id)) +&#xA;  geom_jitter(shape=&#34;.&#34;) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/stemangiola/CuratedAtlasQueryR/master/man/figures/HLA_A_disease_plot.png&#34; width=&#34;525&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&#xA;metadata |&amp;gt; &#xA;    &#xA;  # Filter and subset&#xA;  filter(cell_type_harmonised==&#34;nk&#34;) |&amp;gt; &#xA;&#xA;  # Get counts per million for HCA-A gene &#xA;  get_SingleCellExperiment(assays = &#34;cpm&#34;, features = &#34;HLA-A&#34;) |&amp;gt; &#xA;&#xA;    # Plot (styling code have been omitted)&#xA;  join_features(&#34;HLA-A&#34;, shape = &#34;wide&#34;) |&amp;gt; &#xA;  ggplot(aes( tissue_harmonised, `HLA.A`,color = file_id)) +&#xA;  geom_jitter(shape=&#34;.&#34;) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/stemangiola/CuratedAtlasQueryR/master/man/figures/HLA_A_tissue_plot.png&#34; width=&#34;525&#34;&gt; &#xA;&lt;h1&gt;Cell metadata&lt;/h1&gt; &#xA;&lt;p&gt;Dataset-specific columns (definitions available at cellxgene.cziscience.com)&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;cell_count&lt;/code&gt;, &lt;code&gt;collection_id&lt;/code&gt;, &lt;code&gt;created_at.x&lt;/code&gt;, &lt;code&gt;created_at.y&lt;/code&gt;, &lt;code&gt;dataset_deployments&lt;/code&gt;, &lt;code&gt;dataset_id&lt;/code&gt;, &lt;code&gt;file_id&lt;/code&gt;, &lt;code&gt;filename&lt;/code&gt;, &lt;code&gt;filetype&lt;/code&gt;, &lt;code&gt;is_primary_data.y&lt;/code&gt;, &lt;code&gt;is_valid&lt;/code&gt;, &lt;code&gt;linked_genesets&lt;/code&gt;, &lt;code&gt;mean_genes_per_cell&lt;/code&gt;, &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;published&lt;/code&gt;, &lt;code&gt;published_at&lt;/code&gt;, &lt;code&gt;revised_at&lt;/code&gt;, &lt;code&gt;revision&lt;/code&gt;, &lt;code&gt;s3_uri&lt;/code&gt;, &lt;code&gt;schema_version&lt;/code&gt;, &lt;code&gt;tombstone&lt;/code&gt;, &lt;code&gt;updated_at.x&lt;/code&gt;, &lt;code&gt;updated_at.y&lt;/code&gt;, &lt;code&gt;user_submitted&lt;/code&gt;, &lt;code&gt;x_normalization&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Sample-specific columns (definitions available at cellxgene.cziscience.com)&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;sample_&lt;/code&gt;, &lt;code&gt;sample_name&lt;/code&gt;, &lt;code&gt;age_days&lt;/code&gt;, &lt;code&gt;assay&lt;/code&gt;, &lt;code&gt;assay_ontology_term_id&lt;/code&gt;, &lt;code&gt;development_stage&lt;/code&gt;, &lt;code&gt;development_stage_ontology_term_id&lt;/code&gt;, &lt;code&gt;ethnicity&lt;/code&gt;, &lt;code&gt;ethnicity_ontology_term_id&lt;/code&gt;, &lt;code&gt;experiment___&lt;/code&gt;, &lt;code&gt;organism&lt;/code&gt;, &lt;code&gt;organism_ontology_term_id&lt;/code&gt;, &lt;code&gt;sample_placeholder&lt;/code&gt;, &lt;code&gt;sex&lt;/code&gt;, &lt;code&gt;sex_ontology_term_id&lt;/code&gt;, &lt;code&gt;tissue&lt;/code&gt;, &lt;code&gt;tissue_harmonised&lt;/code&gt;, &lt;code&gt;tissue_ontology_term_id&lt;/code&gt;, &lt;code&gt;disease&lt;/code&gt;, &lt;code&gt;disease_ontology_term_id&lt;/code&gt;, &lt;code&gt;is_primary_data.x&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Cell-specific columns (definitions available at cellxgene.cziscience.com)&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;cell_&lt;/code&gt;, &lt;code&gt;cell_type&lt;/code&gt;, &lt;code&gt;cell_type_ontology_term_idm&lt;/code&gt;, &lt;code&gt;cell_type_harmonised&lt;/code&gt;, &lt;code&gt;confidence_class&lt;/code&gt;, &lt;code&gt;cell_annotation_azimuth_l2&lt;/code&gt;, &lt;code&gt;cell_annotation_blueprint_singler&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Through harmonisation and curation we introduced custom column, not present in the original CELLxGENE metadata&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;tissue_harmonised&lt;/code&gt;: a coarser tissue name for better filtering&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;age_days&lt;/code&gt;: the number of days corresponding to the age&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cell_type_harmonised&lt;/code&gt;: the consensus call identity (for immune cells) using the original and three novel annotations using Seurat Azimuth and SingleR&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;confidence_class&lt;/code&gt;: an ordinal class of how confident &lt;code&gt;cell_type_harmonised&lt;/code&gt; is. 1 is complete consensus, 2 is 3 out of four and so on.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cell_annotation_azimuth_l2&lt;/code&gt;: Azimuth cell annotation&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cell_annotation_blueprint_singler&lt;/code&gt;: SingleR cell annotation using Blueprint reference&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cell_annotation_blueprint_monaco&lt;/code&gt;: SingleR cell annotation using Monaco reference&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sample_id_db&lt;/code&gt;: Sample subdivision for internal use&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;file_id_db&lt;/code&gt;: File subdivision for internal use&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sample_&lt;/code&gt;: Sample ID&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sample_name&lt;/code&gt;: How samples were defined&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;RNA abundance&lt;/h1&gt; &#xA;&lt;p&gt;The &lt;code&gt;raw&lt;/code&gt; assay includes RNA abundance in the positive real scale (not transformed with non-linear functions, e.g.&amp;nbsp;log sqrt). Originally CELLxGENE include a mix of scales and transformations specified in the &lt;code&gt;x_normalization&lt;/code&gt; column.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;cpm&lt;/code&gt; assay includes counts per million.&lt;/p&gt; &#xA;&lt;h1&gt;Installation and getting-started problems&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Default R cache path including non-standard characters (e.g.&amp;nbsp;dash)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get_metadata()&#xA;&#xA;# Error in `db_query_fields.DBIConnection()`:&#xA;# ! Can&#39;t query fields.&#xA;# Caused by error:&#xA;# ! Parser Error: syntax error at or near &#34;/&#34;&#xA;# LINE 2: FROM /Users/bob/Library/Cach...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Setup custom cache path (e.g.&amp;nbsp;user home directory)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get_metadata(cache_directory = path.expand(&#39;~&#39;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; namespace ‘dbplyr’ 2.2.1 is being loaded, but &amp;gt;= 2.3.0 is required&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Install new dbplyr&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;dbplyr&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;This project has been funded by&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Silicon Valley Foundation&lt;/em&gt; CZF2019-002443&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Bioconductor core funding&lt;/em&gt; NIH NHGRI 5U24HG004059-18&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Victoria Cancer Agency&lt;/em&gt; ECRF21036&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Australian National Health and Medical Research Council&lt;/em&gt; 1116955&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>