<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-20T01:41:44Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>jcrodriguez1989/chatgpt</title>
    <updated>2023-01-20T01:41:44Z</updated>
    <id>tag:github.com,2023-01-20:/jcrodriguez1989/chatgpt</id>
    <link href="https://github.com/jcrodriguez1989/chatgpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Interface to ChatGPT from R&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT coding assistant for RStudio&lt;/h1&gt; &#xA;&lt;center&gt; &#xA; &lt;img width=&#34;300&#34; height=&#34;400&#34; src=&#34;https://media.licdn.com/dms/image/C5622AQG8D9NQ_ePuzA/feedshare-shrink_800/0/1673359083125?e=1676505600&amp;amp;v=beta&amp;amp;t=cnmYmdjyiAZ4gwZqqwJy1UXBJ5IlHWAiLWLQuSEjeYk&#34;&gt; &#xA; &lt;p&gt; Meme by Programming Jokes I IT Humor &amp;amp; Memes &lt;/p&gt; &#xA;&lt;/center&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install the development version of {chatgpt} from &lt;a href=&#34;https://github.com/jcrodriguez1989/chatgpt&#34;&gt;GitHub&lt;/a&gt; with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# install.packages(&#34;remotes&#34;)&#xA;remotes::install_github(&#34;jcrodriguez1989/chatgpt&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;You need to setup your ChatGPT API key in R.&lt;/p&gt; &#xA;&lt;p&gt;First you will need to obtain your ChatGPT API key. You can create an API key by accessing &lt;a href=&#34;https://beta.openai.com/account/api-keys&#34;&gt;OpenAI API page&lt;/a&gt; -don’t miss their article about &lt;a href=&#34;https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety&#34;&gt;Best Practices for API Key Safety&lt;/a&gt;-.&lt;/p&gt; &#xA;&lt;p&gt;Then you have to assign your API key for usage in R, this can be done just for the actual session, by doing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sys.setenv(OPENAI_API_KEY = &#34;XX-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or you can do it persistent (session-wide), by assigning it in your &lt;code&gt;.Renviron&lt;/code&gt; file. For it, execute &lt;code&gt;usethis::edit_r_environ()&lt;/code&gt;, and in that file write a line at the end your API key as&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;OPENAI_API_KEY=XX-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;The {chatgpt} R package provides a set of features to assist in R coding. Current existing addins:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Ask ChatGPT:&lt;/strong&gt; Opens an interactive chat session with ChatGPT&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Comment selected code:&lt;/strong&gt; Comment the selected code&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Create variable name:&lt;/strong&gt; Create a name for a variable that would be assigned the result of this code&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Document code (in roxygen2 format):&lt;/strong&gt; Document a function definition, in roxygen2 format&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Explain selected code:&lt;/strong&gt; Explain the selected code&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Find issues in the selected code:&lt;/strong&gt; Find issues in the selected code&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Optimize selected code:&lt;/strong&gt; Optimize the selected code&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Refactor selected code:&lt;/strong&gt; Refactor the selected code&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When no code is selected, it will use the whole file’s code.&lt;/p&gt; &#xA;&lt;h2&gt;Code Examples&lt;/h2&gt; &#xA;&lt;h4&gt;&lt;code&gt;comment_code&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; cat(comment_code(&#34;for (i in 1:10) {\n  print(i ** 2)\n}&#34;))&#xA;&#xA;*** ChatGPT input:&#xA;&#xA;Add inline comments to the following R code: &#34;for (i in 1:10) {&#xA;  print(i ** 2)&#xA;}&#34;&#xA;# Loop through the values 1-10&#xA;for (i in 1:10) {&#xA;  # Print the squared value of i&#xA;  print(i ** 2)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;code&gt;create_unit_tests&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; cat(create_unit_tests(&#34;squared_numbers &amp;lt;- function(numbers) {\n  numbers ^ 2\n}&#34;))&#xA;&#xA;*** ChatGPT input:&#xA;&#xA;Create a full testthat file, with test cases for the following R code: &#34;squared_numbers &amp;lt;- function(numbers) {&#xA;  numbers ^ 2&#xA;}&#34;&#xA;library(testthat)&#xA;&#xA;context(&#34;Test squared_numbers function&#34;)&#xA;&#xA;# Test 1: Check if function works with a single input&#xA;test_that(&#34;Squared numbers should work with a single input&#34;, {&#xA;  expect_equal(squared_numbers(2), 4)&#xA;})&#xA;&#xA;# Test 2: Check if function works with a vector of inputs&#xA;test_that(&#34;Squared numbers should work with a vector of inputs&#34;, {&#xA;  expect_equal(squared_numbers(c(1, 2, 3)), c(1, 4, 9))&#xA;})&#xA;&#xA;# Test 3: Check if function works with a matrix of inputs&#xA;test_that(&#34;Squared numbers should work with a matrix of inputs&#34;, {&#xA;  expect_equal(squared_numbers(matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2)), &#xA;               matrix(c(1, 4, 9, 16), nrow = 2, ncol = 2))&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;code&gt;create_variable_name&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; cat(create_variable_name(&#34;sapply(1:10, function(i) i ** 2)&#34;))&#xA;&#xA;*** ChatGPT input:&#xA;&#xA;Give a good variable name to the result of the following R code: &#34;sapply(1:10, function(i) i ** 2)&#34;&#xA;squared_values&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;code&gt;document_code&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; cat(document_code(&#34;square_numbers &amp;lt;- function(numbers) numbers ** 2&#34;))&#xA;&#xA;*** ChatGPT input:&#xA;&#xA;Document, in roxygen2 format, this R function: &#34;square_numbers &amp;lt;- function(numbers) numbers ** 2&#34;&#xA;&#39;#&#39; Square Numbers&#xA;&#39;#&#39;&#xA;&#39;#&#39; Computes the square of a number&#xA;&#39;#&#39;&#xA;&#39;#&#39; @param numbers the number to be squared&#xA;&#39;#&#39; @return the squared number&#xA;&#39;#&#39; @export&#xA;square_numbers &amp;lt;- function(numbers) {&#xA;  numbers ** 2&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;code&gt;explain_code&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; cat(explain_code(&#34;for (i in 1:10) {\n  print(i ** 2)\n}&#34;))&#xA;&#xA;*** ChatGPT input:&#xA;&#xA;Explain the following R code: &#34;for (i in 1:10) {&#xA;  print(i ** 2)&#xA;}&#34;&#xA;This code will print the squares of the numbers 1 to 10. The for loop will iterate over the numbers 1 to 10, and for each number, the code will print the result of that number raised to the power of 2 (i.e. the square of that number).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;code&gt;find_issues_in_code&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; cat(find_issues_in_code(&#34;i &amp;lt;- 0\nwhile (i &amp;lt; 0) {\n  i &amp;lt;- i - 1\n}&#34;))&#xA;&#xA;*** ChatGPT input:&#xA;&#xA;Find issues or bugs in the following R code: &#34;i &amp;lt;- 0&#xA;while (i &amp;lt; 0) {&#xA;  i &amp;lt;- i - 1&#xA;}&#34;&#xA;1. The while loop is always false, since the starting value of i is 0 and the code is checking if it is less than 0. It should be while (i &amp;gt; 0).&#xA;&#xA;2. The value of i is not modified inside the loop, so the loop will never terminate. It should be i &amp;lt;- i - 1.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;code&gt;optimize_code&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; cat(optimize_code(&#34;i &amp;lt;- 10\nwhile (i &amp;gt; 0) {\n  i &amp;lt;- i - 1\n  print(i)\n}&#34;))&#xA;&#xA;*** ChatGPT input:&#xA;&#xA;Optimize the following R code: &#34;i &amp;lt;- 10&#xA;while (i &amp;gt; 0) {&#xA;  i &amp;lt;- i - 1&#xA;  print(i)&#xA;}&#34;&#xA;for (i in 10:0) {&#xA;  print(i)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;code&gt;refactor_code&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; cat(refactor_code(&#34;i &amp;lt;- 10\nwhile (i &amp;gt; 0) {\n  i &amp;lt;- i - 1\n  print(i)\n}&#34;))&#xA;&#xA;*** ChatGPT input:&#xA;&#xA;Refactor the following R code, returning valid R code: &#34;i &amp;lt;- 10&#xA;while (i &amp;gt; 0) {&#xA;  i &amp;lt;- i - 1&#xA;  print(i)&#xA;}&#34;&#xA;for(i in 10:1){&#xA;  print(i)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Additional Parameters&lt;/h2&gt; &#xA;&lt;h3&gt;Disable Console Messages&lt;/h3&gt; &#xA;&lt;p&gt;If you want {chatgpt} not to show messages in console, please set the environment variable &lt;code&gt;OPENAI_VERBOSE=FALSE&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Addin Changes in Place&lt;/h3&gt; &#xA;&lt;p&gt;If you want {chatgpt} addins to take place in the editor -i.e., replace the selected code with the result of the addin execution- then you sould set the environment variable &lt;code&gt;OPENAI_ADDIN_REPLACE=TRUE&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;ChatGPT Model Tweaks&lt;/h3&gt; &#xA;&lt;p&gt;ChatGPT model parameters can be tweaked by using environment variables.&lt;/p&gt; &#xA;&lt;p&gt;The following environment variables variables can be set to tweak the behavior, as documented in &lt;a href=&#34;https://beta.openai.com/docs/api-reference/completions/create&#34;&gt;https://beta.openai.com/docs/api-reference/completions/create&lt;/a&gt; .&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;OPENAI_MODEL&lt;/code&gt;; defaults to &lt;code&gt;&#34;text-davinci-003&#34;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OPENAI_MAX_TOKENS&lt;/code&gt;; defaults to &lt;code&gt;256&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OPENAI_TEMPERATURE&lt;/code&gt;; defaults to &lt;code&gt;0.7&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OPENAI_TOP_P&lt;/code&gt;; defaults to &lt;code&gt;1&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OPENAI_FREQUENCY_PENALTY&lt;/code&gt;; defaults to &lt;code&gt;0&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OPENAI_PRESENCE_PENALTY&lt;/code&gt;; defaults to &lt;code&gt;0&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>aws-samples/amazon-sagemaker-statistical-simulation-rstudio</title>
    <updated>2023-01-20T01:41:44Z</updated>
    <id>tag:github.com,2023-01-20:/aws-samples/amazon-sagemaker-statistical-simulation-rstudio</id>
    <link href="https://github.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This is a solution that allows you to offload a resource intensive Monte-Carlo simulation to more powerful machines on Amazon SageMaker, while still being able to develop your scripts in your RStudio IDE.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Perform Statistical Simulation using Amazon SageMaker on RStudio&lt;/h1&gt; &#xA;&lt;p&gt;RStudio is a great IDE for data scientists and statisticians who code in R. You can develop your statistical modeling, simulations and machine learning scripts in RStudio locally or on an EC2 and leverage SageMaker Training and Processing to distribute the execution of the scripts to a remote compute instance. In this workshop, we will walk through steps to build a docker container for a social distancing simulation program that uses parallelism, and run the simulation using SageMaker Processing from a RStudio IDE.&lt;/p&gt; &#xA;&lt;p&gt;You can read more in the blog &lt;a href=&#34;https://aws.amazon.com/blogs/machine-learning/performing-simulations-at-scale-with-amazon-sagemaker-processing-and-r-on-rstudio/&#34;&gt;Performing simulations at scale with Amazon SageMaker Processing and R on RStudio&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Lab 1: Deploy RStudio on EC2&lt;/h3&gt; &#xA;&lt;p&gt;We will deploy the resources using cloudformation in us-west-2 region to your Event Engine account. Please navigate to &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/create/template&#34;&gt;CloudFormation console&lt;/a&gt;, select &lt;strong&gt;Template is ready&lt;/strong&gt;, &lt;strong&gt;Upload a template file&lt;/strong&gt;, and &lt;strong&gt;Choose file&lt;/strong&gt; to upload the template yaml file &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/ec2_ubuntu_rstudio_sagemaker.yaml&#34;&gt;ec2_ubuntu_rstudio_sagemaker.yaml&lt;/a&gt; provided to you. Hit &lt;strong&gt;Next&lt;/strong&gt; to continue.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/doc/cloudformation_1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;In Step 2 &lt;strong&gt;Specify stack details&lt;/strong&gt;, you will be prompted to enter a &lt;strong&gt;Stack name&lt;/strong&gt;, review and accept the &lt;a href=&#34;http://www.gnu.org/licenses/agpl-3.0-standalone.html&#34;&gt;AGPL v3 license&lt;/a&gt; for installing RStudio Server, and select an &lt;strong&gt;EC2 key pair&lt;/strong&gt;. Then hit &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In Step 3 &lt;strong&gt;Configure stack options&lt;/strong&gt; page, we will bypass any options and keep default values, hit &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In Step 4 &lt;strong&gt;Review&lt;/strong&gt;, please acknowledge and hit &lt;strong&gt;Create Stack&lt;/strong&gt;. The stack creation will take about 5 minutes to get EC2 instance up and running, and another 5-10 minutes for RStudio to install some prerequisites.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/doc/cloudformation_4.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Once the stack creation completes, go to &lt;strong&gt;Output&lt;/strong&gt; tab to find the RStudio IDE login URL: ec2-xx-xxx-xxx-xxx.us-west-2.compute.amazonaws.com:8787. Copy the URL and paste it in your favorite browser.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/doc/cloudformation_5.png&#34; alt=&#34;cloudformation_5&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Login the RStudio instance with username &lt;strong&gt;ubuntu&lt;/strong&gt; and password &lt;strong&gt;rstudio7862&lt;/strong&gt;. [Note that this is a temporary environment for demonstration purposes. The use of public facing EC2 instance and simple login credential is &lt;em&gt;NOT&lt;/em&gt; the best security practice to host your RStudio instance.]&lt;/p&gt; &#xA;&lt;h3&gt;Lab 2: Create a Docker Container to run R scripts&lt;/h3&gt; &#xA;&lt;h4&gt;Background&lt;/h4&gt; &#xA;&lt;p&gt;Docker is a software platform that allows you to build, test, and deploy applications quickly. Docker packages software into standardized units called containers that have everything the software needs to run including libraries, system tools, code, and runtime. Using Docker, you can quickly deploy and scale applications into any environment and know your code will run.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/doc/docker_container_1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A Docker image is a read-only template that defines your container. The image contains the code that will run including any definitions for any libraries and dependancies your code needs. A Docker container is an instantiated (running) Docker image. AWS provides &lt;a href=&#34;https://aws.amazon.com/ecr/&#34;&gt;Amazon Elastic Container Registry (ECR)&lt;/a&gt;, an image registry for storing and quickly retrieving Docker images.&lt;/p&gt; &#xA;&lt;p&gt;Docker can build images automatically by reading the instructions from a &lt;code&gt;Dockerfile&lt;/code&gt;. A &lt;code&gt;Dockerfile&lt;/code&gt; is a text document that contains all the commands a user could call on the command line to assemble an image.&lt;/p&gt; &#xA;&lt;h4&gt;Scenario&lt;/h4&gt; &#xA;&lt;p&gt;Suppose that the &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/Submit_SageMaker_Processing_Job/Social_Distancing_Simulations_Parallel.R&#34;&gt;social distancing simulation program&lt;/a&gt; was originally developed with R 3.4.1 &lt;em&gt;Single Candle&lt;/em&gt; from a version of RStudio on ubuntu 16.04. The programs uses two libraries &lt;em&gt;foreach&lt;/em&gt; and &lt;em&gt;doParallel&lt;/em&gt; for parallelism purposes. We would like to run the simulation leveraging remote compute cluster exactly as developed, we need to either have the remote server satisfy all the dependency and version compatibility, which can be difficult to scale, or build a docker image that has all the dependencies installed in the layers and run it anywhere as a container. In this lab, we will create an image that has a R interpreter with dependent libraries to run the simulation and push the image to Amazon ECR so that, with the image, we will be able to run our R script the exact way we develop on any machine that may or may not have the compatible R or the R packages installed, as long as there is a Docker Engine on the host system. Below is the &lt;code&gt;Dockerfile&lt;/code&gt; that describe the runtime requirement and how the container should be executed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;FROM ubuntu:16.04&#xA;&#xA;RUN apt-get -y update &amp;amp;&amp;amp; apt-get install -y --no-install-recommends \&#xA;    wget \&#xA;    r-base \&#xA;    r-base-dev \&#xA;    apt-transport-https \&#xA;    ca-certificates&#xA;&#xA;RUN R -e &#34;install.packages(c(&#39;foreach&#39;, &#39;doParallel&#39;), repos=&#39;https://cloud.r-project.org&#39;)&#34;&#xA;&#xA;ENTRYPOINT [&#34;/usr/bin/Rscript&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Each line is an instruction to create one layer:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;FROM&lt;/code&gt; creates a layer from the &lt;code&gt;ubuntu:16.04&lt;/code&gt; Docker image.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;RUN&lt;/code&gt; executes command lines to create a new layer with results.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;ENTRYPOINT&lt;/code&gt; allows you to configure a container that will run as an executable.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt; for actual file. This file describe what dependency (ubuntu 16.04, &lt;code&gt;foreach&lt;/code&gt; and &lt;code&gt;doParallel&lt;/code&gt; and what software and runtime to be included in the container image.&lt;/p&gt; &#xA;&lt;p&gt;In order to build a docker image from Dockerfile, you need to execute the following docker command in where the Dockerfile is&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker build -t $image_name .&#xA;$ docker images # to see the built image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Push the docker image to AWS Elastic Container Registry (ECR)&lt;/h4&gt; &#xA;&lt;p&gt;The following shell commands show how to interact with ECR from your terminal and push the docker image to ECR.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Get the AWS account ID&#xA;account=$(aws sts get-caller-identity --query Account --output text)&#xA;&#xA;# Get the region defined in the current configuration (default to us-west-2 if none defined)&#xA;region=$(aws configure get region)&#xA;region=${region:-us-west-2}&#xA;&#xA;# Define the full image name on Amazon ECR&#xA;fullname=&#34;${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:${tag}&#34;&#xA;&#xA;# If the repository doesn&#39;t exist in ECR, create it.&#xA;aws ecr describe-repositories --repository-names &#34;${image_name}&#34; &amp;gt; /dev/null 2&amp;gt;&amp;amp;1&#xA;&#xA;if [ $? -ne 0 ]&#xA;then&#xA;    aws ecr create-repository --repository-name &#34;${image_name}&#34; &amp;gt; /dev/null&#xA;fi&#xA;&#xA;# Get the login command from ECR and execute it directly&#xA;aws ecr get-login-password --region ${region} \&#xA;  | docker login \&#xA;      --username AWS \&#xA;      --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com&#xA;&#xA;# Tag and push the local image to Amazon ECR&#xA;docker tag ${image_name} ${fullname}&#xA;docker push ${fullname}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Putting all together&lt;/h4&gt; &#xA;&lt;p&gt;Execute the shell script &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/build_and_push_docker.sh&#34;&gt;build_and_push_docker.sh&lt;/a&gt; to streamline the build and push process in the Terminal in your RStudio IDE. The script will build the Dockerfile as a image named &lt;code&gt;r_container&lt;/code&gt; with the &lt;code&gt;latest&lt;/code&gt; tag.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sh build_and_push_docker.sh r_container latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should be able to see your image in &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/ecr/repositories?region=us-west-2&#34;&gt;ECR&lt;/a&gt;. This image has all the dependencies to run our R script and can be used any time anywhere.&lt;/p&gt; &#xA;&lt;h3&gt;Lab 3: R simulation using SageMaker Processing&lt;/h3&gt; &#xA;&lt;p&gt;The social distancing simulation program (&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/Submit_SageMaker_Processing_Job/Social_Distancing_Simulations.R&#34;&gt;Social_Distancing_Simulations.R&lt;/a&gt;) runs a simulation of social distancing violation for given number of people in given space specification. It takes 4 positional input arguments: &lt;code&gt;x_length&lt;/code&gt;, &lt;code&gt;y_length&lt;/code&gt;, &lt;code&gt;num_people&lt;/code&gt; and &lt;code&gt;max_iteration&lt;/code&gt;. The first two specifies the area, &lt;code&gt;num_people&lt;/code&gt; specifies the amount of people in the area, and &lt;code&gt;max_iteration&lt;/code&gt; defines the number of iterations. We will run the simulation with the given parameters parallelly using multiple CPU cores.&lt;/p&gt; &#xA;&lt;p&gt;With SageMaker Processing, we will be able to leverage remote compute infrastructure to run the simulation and free up the local compute resources. Amazon SageMaker spins up a Processing job, takes your script, copies your data from Amazon Simple Storage Service (Amazon S3), and then pulls a processing container from ECR. The underlying infrastructure for a Processing job is fully managed by Amazon SageMaker. Cluster resources are provisioned for the duration of your job, and cleaned up when a job completes. The output of the Processing job is stored in the Amazon S3 bucket you specified. You can treat your RStudio instance as a launching station to submit simulation to remote compute with various parameters or input datasets. Complete SageMaker API is accessible through &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34;&gt;Reticulate&lt;/a&gt; library that provides an R interface to make calls to Amazon SageMaker Python SDK.&lt;/p&gt; &#xA;&lt;p&gt;The essense of job submission is the following lines of code. We define what container to use (our previously created r_container), what compute resource does this job run one and what script we want to execute with what input parameters.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;processor &amp;lt;- sagemaker$processing$ScriptProcessor(role = role_arn,&#xA;                                                  image_uri = container,&#xA;                                                  command = list(&#39;/usr/bin/Rscript&#39;),&#xA;                                                  instance_count = 1L,&#xA;                                                  instance_type = &#39;ml.m4.xlarge&#39;,&#xA;                                                  volume_size_in_gb = 5L,&#xA;                                                  max_runtime_in_seconds = 3600L,&#xA;                                                  base_job_name = &#39;social-distancing-simulation&#39;,&#xA;                                                  sagemaker_session = session)&#xA;&#xA;processor$run(code = &#39;Social_Distancing_Simulations.R&#39;,&#xA;              arguments = list(&#39;--args&#39;, paste(x_length), paste(y_length), paste(num_people),&#xA;                               paste(max_iterations)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We will execute the code line by line in the RStudio with the script &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/Submit_SageMaker_Processing_Job/SageMaker_Processing_SDS.R&#34;&gt;SageMaker_Processing_SDS.R&lt;/a&gt; to submit 5 additional simulations.&lt;/p&gt; &#xA;&lt;p&gt;In our simulation, we are not interacting with any data from a S3 bucket. If need be, you can specify data from a S3 bucket as input and save any processing/simulation output back to S3 by specifying &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;outputs&lt;/code&gt; arguments in &lt;code&gt;processor$run()&lt;/code&gt; call. For example,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;input_data &amp;lt;- sagemaker$processing$ProcessingInput(source=&#39;s3://path/to/my/input-data.csv&#39;,&#xA;                                                   destination=&#39;/opt/ml/processing/input&#39;)&#xA;output_data &amp;lt;- sagemaker$processing$ProcessingOutput(source=&#39;/opt/ml/processing/output/simulation&#39;,&#xA;                                                     destination=&#39;s3://path/to/my/output/&#39;)&#xA;processor$run(code = &#39;Social_Distancing_Simulations.R&#39;,&#xA;              arguments = list(&#39;--args&#39;, paste(x_length), paste(y_length), paste(num_people),&#xA;                               paste(max_iterations)),&#xA;              inputs=list(input_data),&#xA;              outputs=list(output_data))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;While the &lt;code&gt;Social_Distancing_Simulation.R&lt;/code&gt; is executed within the container, the &lt;code&gt;input-data.csv&lt;/code&gt; from S3 will be available at the path &lt;code&gt;/opt/ml/processing/input/&lt;/code&gt; in the container and if you save the results into the path &lt;code&gt;/opt/ml/processing/output/simulation&lt;/code&gt; within the container, they will be uploaded to specified S3 location. See the diagram below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/images/Processing-1.png&#34; alt=&#34;sm-processing-s3&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Cleaning up&lt;/h3&gt; &#xA;&lt;p&gt;Once we completed the workshop, please delete the stack from the &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks&#34;&gt;CloudFormation console&lt;/a&gt; by selecting the stack and hit &lt;strong&gt;Delete&lt;/strong&gt;. This will clean up all the resources we have created for the workshop.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/doc/cloudformation_6.png&#34; alt=&#34;cloudformation_6&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/CONTRIBUTING.md#security-issue-notifications&#34;&gt;CONTRIBUTING&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This library is licensed under the MIT-0 License. See the &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker</title>
    <updated>2023-01-20T01:41:44Z</updated>
    <id>tag:github.com,2023-01-20:/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker</id>
    <link href="https://github.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Customers using R can run simulation and machine learning securely and at scale with Amazon SageMaker while also reducing the cost of development by using the fully elastic resources in the cloud. In this demo, learn how to build, train, and deploy statistical and ML models in R at scale using Amazon SageMaker from your IDE.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Productionizing R workload with Amazon SageMaker&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to reInvent 2020 AIML session 404 &lt;strong&gt;Productionizing R workloads using Amazon SageMaker&lt;/strong&gt;. You can watch the session and the demo in action in this &lt;a href=&#34;https://www.youtube.com/watch?v=Zpp0nfvqDCA&#34;&gt;video&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;R language and its rich ecosystem with more than 16,000 packages dedicated to statistics and machine learning are widely used by statisticians and data scientists in industries, such as energy, healthcare, life science, and financial services. Customers using R can run simulation and machine learning securely and at scale with Amazon SageMaker while also reducing the cost of development by using the fully elastic resources in the cloud. In this session, learn how to build, train, and deploy statistical and ML models in R at scale using Amazon SageMaker from your IDE.&lt;/p&gt; &#xA;&lt;p&gt;In this repository, the code is provided for you to replicate the demo in the session. You are welcome to clone the repository while you watch the video. This Readme provides end-to-end instruction to run the demo. You can find the following sections:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/#Prerequisite&#34;&gt;Prerequisite&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/#prototyping-in-rstudio&#34;&gt;Prototyping in RStudio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/#scale-with-amazon-sagemaker&#34;&gt;Scale with Amazon SageMaker&lt;/a&gt;:&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/#orchestrate-with-aws-step-functions&#34;&gt;Orchestrate with AWS Step Functions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/#cleaning-up&#34;&gt;Cleaning up&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/#additional-resources&#34;&gt;Additional resources&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Prerequisite&lt;/h2&gt; &#xA;&lt;p&gt;We assume you have an RStudio instance running on your laptop or on a EC2 instance. You need the following IAM policies: &lt;code&gt;AmazonSageMakerFullAccess&lt;/code&gt; and &lt;code&gt;AmazonEC2ContainerRegistryFullAccess&lt;/code&gt; to be attached to your IAM role and credential that is used in your environment, eg. &lt;a href=&#34;https://aws.amazon.com/premiumsupport/knowledge-center/assign-iam-role-ec2-instance/&#34;&gt;Amazon EC2&lt;/a&gt; or &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html&#34;&gt;local computer&lt;/a&gt;. The R libraries that are used in the demo are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;fable==0.2.1, fabletool==0.2.1&lt;/li&gt; &#xA; &lt;li&gt;feasts==0.1.5&lt;/li&gt; &#xA; &lt;li&gt;tsibble==0.9.3&lt;/li&gt; &#xA; &lt;li&gt;reticulate==0.16&lt;/li&gt; &#xA; &lt;li&gt;dplyr==1.0.2&lt;/li&gt; &#xA; &lt;li&gt;ggplot2==3.3.2&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you do not have an RStudio IDE, please follow the &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/prerequisite.md&#34;&gt;instruction&lt;/a&gt; to deploy an &lt;a href=&#34;https://rstudio.com/products/rstudio/download-server/&#34;&gt;RStudio Server&lt;/a&gt; on an EC2 instance with all the necessary permission and networking for your convenience.&lt;/p&gt; &#xA;&lt;p&gt;Once you are logged into the RStudio IDE, please clone the code repository in the Terminal.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/clone_repo.png&#34; alt=&#34;code&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Prototyping in RStudio&lt;/h2&gt; &#xA;&lt;p&gt;Suppose your customer send you a dataset and ask you to forecast the number of visitors to city of Melbourne in Australia for the next 5 years. Let’s start playing with the data.&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s start with the prototyping script &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/fable_demo.r&#34;&gt;fable_demo.r&lt;/a&gt; where we do a simple exploratory analysis, visualization and modeling using exponential smoothing (ETS) and ARIMA algorithms from fable library to model the number of visitors from 1998-2007.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/prototyping.png&#34; alt=&#34;prototyping&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;It is perfectly fine running small scale analyses, modeling and visualization on a local instance. But what if each of your modeling job takes an hour with complete dataset and you need to run 100s of them with various input and parameters. You either need to have a very large instance and run them both in parallel and in serial.&lt;/p&gt; &#xA;&lt;h2&gt;Scale with Amazon SageMaker&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/sagemaker/&#34;&gt;Amazon SageMaker&lt;/a&gt; can be helpful in running your statistical and ML workloads at scale using the fully elastic resource in the cloud beyond local compute resource.&lt;/p&gt; &#xA;&lt;p&gt;First of all, data scientists and developers can use Amazon SageMaker features through &lt;a href=&#34;https://sagemaker.readthedocs.io/en/stable/&#34;&gt;SageMaker SDK&lt;/a&gt; from any IDE as long as there is internet and AWS credential setup. For R users, you can use your preferred IDE, such as RStudio, and interact with &lt;a href=&#34;https://sagemaker.readthedocs.io/en/stable/&#34;&gt;Amazon SageMaker SDK&lt;/a&gt; through &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34;&gt;reticulate&lt;/a&gt;, an R interface for python libraries. You can also communicate with all AWS resources with &lt;a href=&#34;https://boto3.amazonaws.com/v1/documentation/api/latest/index.html&#34;&gt;boto3&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Depending on whether there is a model artifact as output for inferencing new data, the following two patterns can be leveraged to scale your ML or statistical workloads.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/sm_patterns.png&#34; alt=&#34;sm_patterns&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;For machine learning, you can use Amazon SageMaker Processing to process the data, use Amazon SageMaker Training and Tuning to train an optimal model, and use Amazon SageMaker Endpoint to host the model for live traffic or Batch Transform for batch data. This is the use case described in this repository.&lt;/p&gt; &#xA;&lt;p&gt;For statistical analyses, simulations and optimizations where your output is data insight, you can use Amazon SageMaker Processing for both data processing and for your full scale statistical workloads, and save the results into Amazon S3 or purposefully built database on AWS. You can find an example in another blog and repository listed in &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/#additional-resources&#34;&gt;Additional resources&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;From prototype to SageMaker-ready&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s walk through step-by-step to transform our prototype script (&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/fable_demo.r&#34;&gt;&lt;code&gt;fable_demo.r&lt;/code&gt;&lt;/a&gt;) to SageMaker-ready script (&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/fable_sagemaker.r&#34;&gt;&lt;code&gt;fable_sagemaker.r&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Amazon SageMaker runs your R script in a &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers.html&#34;&gt;Docker container image&lt;/a&gt; with all the dependencies to make sure it operates in the exact manner how you develope the script. There are two changes we need to make to your R script:&lt;/p&gt; &#xA;&lt;h4&gt;1. Make the script aware of how Amazon SageMaker places the input and config files when launching the job;&lt;/h4&gt; &#xA;&lt;p&gt;The input data and hyperparameters are accessible to your script inside a container with the following directory structure.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;/opt/ml&#xA;|-- input&#xA;|   |-- config&#xA;|   |   |-- hyperparameters.json&#xA;|   |   `-- resourceConfig.json&#xA;|   `-- data&#xA;|       `-- &amp;lt;channel_name&amp;gt;&#xA;|           `-- &amp;lt;input data&amp;gt;&#xA;|-- model&#xA;|   `-- &amp;lt;model files&amp;gt;&#xA;|-- processing (if with SageMaker Processing)&#xA;|   |-- input&#xA;|   `-- output&#xA;|&#xA;`-- output&#xA;    `-- failure&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We should assign the path variables accordingly so that we can access the input data for analysis and modeling. (See &lt;a href=&#34;https://github.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/raw/d3f784069fa7fa6032c004dd73d0566cc01af08e/fable_sagemaker.r#L31-L41&#34;&gt;here&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;## Assigning paths&#xA;prefix &amp;lt;- &#39;/opt/ml&#39;&#xA;input_path &amp;lt;- file.path(prefix, &#39;input&#39;, &#39;data&#39;)&#xA;training_data_path &amp;lt;- file.path(input_path, &#39;train&#39;)&#xA;output_path &amp;lt;- file.path(prefix, &#39;output&#39;)&#xA;model_path &amp;lt;- file.path(prefix, &#39;model&#39;)&#xA;param_path &amp;lt;- file.path(prefix, &#39;input&#39;, &#39;config&#39;, &#39;hyperparameters.json&#39;)&#xA;&#xA;processing_path &amp;lt;- file.path(prefix, &#39;processing&#39;)&#xA;processing_input_path &amp;lt;- file.path(processing_path, &#39;input&#39;)&#xA;processing_output_path &amp;lt;- file.path(processing_path, &#39;output&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. Refactor the code into &lt;code&gt;train&lt;/code&gt;, &lt;code&gt;evaluate&lt;/code&gt; as that how SageMaker execute the codes from the container for training, and evaluating the model.&lt;/h4&gt; &#xA;&lt;p&gt;In our prototype, we do a forecast modeling, followed by an analysis of the model performance and a visualization. We need to refactor the codes in &lt;code&gt;fable_demo.r&lt;/code&gt;, put the modeling part into the function &lt;a href=&#34;https://github.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/raw/d3f784069fa7fa6032c004dd73d0566cc01af08e/fable_sagemaker.r#L43-L89&#34;&gt;&lt;code&gt;train&lt;/code&gt;&lt;/a&gt; and the analysis into &lt;a href=&#34;https://github.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/raw/d3f784069fa7fa6032c004dd73d0566cc01af08e/fable_sagemaker.r#L91-L127&#34;&gt;&lt;code&gt;evaluate&lt;/code&gt;&lt;/a&gt;. Amazon SageMaker calls the &lt;code&gt;train&lt;/code&gt; and &lt;code&gt;evaluate&lt;/code&gt; in a SageMaker Training job (&lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-dockerfile.html&#34;&gt;by default&lt;/a&gt;) and SageMaker Processing job (&lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/build-your-own-processing-container.html#byoc-run-image&#34;&gt;by design&lt;/a&gt;), respectively. We will talk more about how SageMaker Process calls the &lt;code&gt;evaluate&lt;/code&gt; function.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;train &amp;lt;- function() {&#xA;## Extract (hyper)parameters&#xA;  ...&#xA;  ## Getting data from local path that is downloaded from S3&#xA;  ...&#xA;  ## Training ETS and ARIMA models&#xA;  fitted_model &amp;lt;- tourism_city %&amp;gt;%&#xA;    model(&#xA;      ets = ETS(Trips ~ trend(ets_trend_method), ic = ic),&#xA;      arima = ARIMA(Trips, ic = ic)&#xA;    )&#xA;  ## Saving the model&#xA;  ...&#xA;}&#xA;&#xA;evaluate &amp;lt;- function(city) {&#xA;  ## Load model&#xA;  ...&#xA;  ## Load input data&#xA;  ...&#xA;  ## Analysis&#xA;  ...&#xA;  ggsave(file.path(processing_output_path,  &#39;forecast-report.png&#39;))&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you would like to host the model, you can do so inside a &lt;code&gt;serve&lt;/code&gt; function which can be called by &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-main.html&#34;&gt;SageMaker hosting features&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Getting started with SageMaker SDK&lt;/h3&gt; &#xA;&lt;p&gt;Now we are ready to run the script &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/fable_sagemaker.r&#34;&gt;fable_sagemaker.r&lt;/a&gt; with Amazon SageMaker. Let&#39;s open the script &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/sagemaker_training.r&#34;&gt;sagemaker_training.r&lt;/a&gt; and sets the working directory to where the scripts are. This script allows us to communicate with Amazon SageMaker using the SageMaker SDK through reticulate, a R interface to python libraries.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;# Remember to set the current working directory to where the code is.&#xA;# For example if you clone the repo in home, then set the working directory as  &#xA;# setwd(&#34;~/reinvent2020-aim404-productionize-r-using-amazon-sagemaker&#34;)&#xA;&#xA;## Getting libraries&#xA;library(reticulate)&#xA;use_python(&#39;/usr/bin/python&#39;) # instruct reticulate to use the system python&#xA;sagemaker &amp;lt;- import(&#39;sagemaker&#39;)&#xA;boto3 &amp;lt;- import(&#39;boto3&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We first build a Docker container image defined in the &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt; and push the container image to &lt;a href=&#34;https://aws.amazon.com/ecr/&#34;&gt;Amazon Elastic Container Registry (Amazon ECR)&lt;/a&gt; with a series of shell commands in &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/build_and_push_docker.sh&#34;&gt;build_and_push_docker.sh&lt;/a&gt;. The build takes about 5-10 minutes. After the execution, we have a container image that has the R runtime dependencies built and the script &lt;code&gt;fable_sagemaker.r&lt;/code&gt; copied into.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;# Amazon SageMaker runs your code in a container image with the dependencies.&#xA;# We build a R container using the shell script that reads the Dockerfile&#xA;container &amp;lt;- &#39;r-fable-trip-forecasting&#39;&#xA;tag &amp;lt;- &#39;latest&#39;&#xA;system(sprintf(&#39;./build_and_push_docker.sh %s %s&#39;, container, tag))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the container image is pushed to Amazon ECR, you can verify the image in the &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/ecr/repositories/r-fable-trip-forecasting/?region=us-west-2&#34;&gt;console&lt;/a&gt; (the URL assumes the region to be us-west-2).&lt;/p&gt; &#xA;&lt;h3&gt;Creating a SageMaker Training job&lt;/h3&gt; &#xA;&lt;p&gt;We can now run our script in the fully managed Amazon SageMaker Training infrastructure, using the &lt;code&gt;Estimator&lt;/code&gt; class from the SageMaker SDK.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;###############################&#xA;## Initiate SageMaker Estimator&#xA;estimator &amp;lt;- sagemaker$estimator$Estimator(role = role,&#xA;                                           image_uri = image,&#xA;                                           instance_type = &#39;ml.m4.xlarge&#39;,&#xA;                                           instance_count = 1L,&#xA;                                           volume_size_in_gb = 5L,&#xA;                                           max_run = 3600L,&#xA;                                           input_mode = &#39;File&#39;,&#xA;                                           base_job_name = &#39;r-fable-trip-forecasting&#39;,&#xA;                                           output_path = output_path,&#xA;                                           sagemaker_session = session, &#xA;                                           hyperparameters = hyperparameters)&#xA;&#xA;estimator$fit(inputs = list(&#39;train&#39;=training_input), &#xA;              wait = TRUE) # wait = FALSE submits an async job and get the RStudio console back&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that we can easily specify the right-sized compute resource with &lt;code&gt;instance_type&lt;/code&gt;, &lt;code&gt;instance_count&lt;/code&gt; and EBS size &lt;code&gt;volume_size_in_gb&lt;/code&gt;. When you execute the &lt;code&gt;$fit()&lt;/code&gt;, the following is happening behind the scene: the specified compute infrastructure is provisioned, your container image is pulled from ECR repository, and the input data is downloaded from S3 location before the training starts. You can see things in action in the RStudio console. You may also turn the &lt;code&gt;wait&lt;/code&gt; argument to &lt;code&gt;FALSE&lt;/code&gt; so that the &lt;code&gt;$fit()&lt;/code&gt; call can be an asynchronous one. Essentially you are submitting the training to Amazon SageMaker and you can move on to the following activities such as more prototyping or submit another job with a different set of parameters.&lt;/p&gt; &#xA;&lt;h3&gt;Creating a SageMaker Processing job&lt;/h3&gt; &#xA;&lt;p&gt;Once this training job is done, we can move on to evaluate the model performance with Amazon SageMaker Processing using &lt;code&gt;ScriptProcessor&lt;/code&gt; class from the SDK. It has similar construct to &lt;code&gt;Estimator&lt;/code&gt; and we are reusing the same container image.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;processor &amp;lt;- sagemaker$processing$ScriptProcessor(role = role,&#xA;                                                  image_uri = image,&#xA;                                                  command = list(&#39;/usr/bin/Rscript&#39;),&#xA;                                                  instance_type = &#39;ml.t3.large&#39;,&#xA;                                                  instance_count = 1L,&#xA;                                                  volume_size_in_gb = 5L,&#xA;                                                  max_runtime_in_seconds = 3600L,&#xA;                                                  base_job_name = &#39;r-fable-evaluation&#39;,&#xA;                                                  sagemaker_session = session)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We need to specify the input to be the trained model &lt;code&gt;model_data&lt;/code&gt; from the training job, and an output path on S3 for saving the evaluation report.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;output_processing_path &amp;lt;- sprintf(&#39;%s/%s/%s&#39;, output_path, &#39;evaluation&#39;, &#39;output&#39;) # on S3&#xA;processing_input &amp;lt;- list(sagemaker$processing$ProcessingInput(input_name = &#39;model-for-evaluate&#39;, &#xA;                                                              source = estimator$model_data, &#xA;                                                              destination = &#39;/opt/ml/processing/input&#39;))&#xA;processing_output &amp;lt;- list(sagemaker$processing$ProcessingOutput(output_name = &#39;evaluation-output&#39;, &#xA;                                                                source=&#39;/opt/ml/processing/output&#39;, &#xA;                                                                destination = output_processing_path))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The use of &lt;code&gt;ProcessingInput&lt;/code&gt; makes the &lt;code&gt;estimator$model_data&lt;/code&gt; which is pointing to a trained &lt;code&gt;model.tar.gz&lt;/code&gt; in S3 available at the path &lt;code&gt;/opt/ml/processing/input/&lt;/code&gt; in the container. Similarly, with &lt;code&gt;ProcessingOutput&lt;/code&gt;, if you save the results into the path &lt;code&gt;/opt/ml/processing/output&lt;/code&gt; within the container, they are uploaded to &lt;code&gt;output_processing_path&lt;/code&gt; in S3. This can be illustrated in the diagram below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/images/Processing-1.png&#34; alt=&#34;sm-processing-s3&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;We then start the job with the &lt;code&gt;$run()&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;result=processor$run(code = &#39;fable_sagemaker.r&#39;,&#xA;                     inputs = processing_input,&#xA;                     outputs = processing_output,&#xA;                     arguments = list(&#39;evaluate&#39;, hyperparameters$city),&#xA;                     wait = FALSE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that we are specifying &lt;code&gt;code = &#39;fable_sagemaker.r&#39;&lt;/code&gt; which is going to be uploaded to S3 from the local filesyste and for SageMaker Processing job to consume. Don&#39;t be confused with the same file included in the &lt;code&gt;Dockerfile&lt;/code&gt;. It just happens that we have everything in one single file and that the we have also included the same file in the &lt;code&gt;Dockerfile&lt;/code&gt;. SageMaker Processing SDK actually allows you to specify any scripts to be executed as long as the dependency is satisfied in the container image. According to &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/build-your-own-processing-container.html#byoc-run-image&#34;&gt;how SageMaker Processing runs the container&lt;/a&gt; and how we design the &lt;code&gt;fable_sagemaker.r&lt;/code&gt;, we are passing arguments to be &lt;code&gt;list(&#39;evaluate&#39;, hyperparameters$city)&lt;/code&gt; to execute the &lt;code&gt;evaluate&lt;/code&gt; function with the city &lt;code&gt;hyperparameters$city&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Orchestrate with AWS Step Functions&lt;/h2&gt; &#xA;&lt;p&gt;Let&#39;s take a look at how we can orchestrate a machine learning workflow for our forecasting model in R and Amazon SageMaker.&lt;/p&gt; &#xA;&lt;h3&gt;Scenairo&lt;/h3&gt; &#xA;&lt;p&gt;Consider the following scenario: you, the lead data scientist, has just completed the prototyping and experimentation and are happy with the models you build. you get an update on the actual visitors statistics from the customer every week. It makes sense to include the latest datapoints into your modeling so validate your previous model and retrain a new model. Instead of logging back onto the RStudio IDE and rerun the entire experiement, which you could for sure, it would be great to automate the process given that we have already built up the steps that work. What&#39;s even better is to allow a human review as a quality gate to make sure the models we are building are meeting the satisfactory standard before we push out the models.&lt;/p&gt; &#xA;&lt;h3&gt;Solution&lt;/h3&gt; &#xA;&lt;p&gt;We can design an event-driven architecture that would automate the machine learning training, evaluation and review process every time we have an updated dataset. By using AWS serverless services, the event-driven architecture that takes away the infrastucture management, and repetitive code execution would allow your team to focus what&#39;s most important to your business goal.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/step-functions/&#34;&gt;AWS Step Functions&lt;/a&gt; is a serverless function orchestrator that makes it easy to sequence &lt;a href=&#34;https://aws.amazon.com/lambda/&#34;&gt;AWS Lambda&lt;/a&gt; functions and multiple AWS services into business-critical applications. It has &lt;a href=&#34;https://docs.aws.amazon.com/step-functions/latest/dg/connect-sagemaker.html&#34;&gt;native integration with Amazon SageMaker features&lt;/a&gt;, meaning that it is easy to put our &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html&#34;&gt;SageMaker Training&lt;/a&gt; and &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateProcessingJob.html&#34;&gt;SageMaker Processing&lt;/a&gt; jobs into a Step Functions workflow. &lt;a href=&#34;https://aws.amazon.com/eventbridge/&#34;&gt;Amazon EventBridge&lt;/a&gt; makes it easy to set up rules to trigger a AWS Step Functions workflow in real time every time we upload new data to a S3 bucket.&lt;/p&gt; &#xA;&lt;p&gt;Below is a Step Function workflow we are using in the demo and how it works.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/stepfunctions_graph_horizontal.png&#34; alt=&#34;sfn-workflow&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/eventbridge/latest/userguide/log-s3-data-events.html&#34;&gt;An Amazon EventBridge rule and a AWS CloudTrail Trail&lt;/a&gt; are setup so that a new execution of the AWS Step Functions workflow can be triggered when data is dropped on to a specific bucket location. The workflow starts with a SageMaker Training job (&lt;code&gt;Train model (r-fable-forecasting)&lt;/code&gt;) to train a forecasting model using the container we have built, and generates evaluation report for the model using a SageMaker Processing job (&lt;code&gt;Evaluate model&lt;/code&gt;). Then a AWS Lambda function is executed to send an email which includes model information and evaluation to a reviewer using &lt;a href=&#34;https://aws.amazon.com/ses/&#34;&gt;Amazon Simple Email Service (Amazon SES)&lt;/a&gt; (&lt;code&gt;Send email for approval&lt;/code&gt;). Also within the email, reviewer can decide to approve the model or reject the model with a click of an hyperlink, backed by &lt;a href=&#34;https://aws.amazon.com/api-gateway/&#34;&gt;Amazon API Gateway&lt;/a&gt;. Once approved, the model is created and is saved as a &lt;a href=&#34;https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html&#34;&gt;SageMaker Model&lt;/a&gt; (&lt;code&gt;Save Model&lt;/code&gt;) for inference use.&lt;/p&gt; &#xA;&lt;p&gt;The architecture diagram is shown below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/Reinvent-Demo-architecture.png&#34; alt=&#34;architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;p&gt;Don&#39;t worry. All the resources in the architecture is ready for you to deploy in a CloudFormation template. Please follow the links to create a new stack with &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/cloudformation/human_approval.yaml&#34;&gt;the other template&lt;/a&gt; in the &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/create/template&#34;&gt;CloudFormation console&lt;/a&gt;. This time, you would need to provide the following parameters:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;ContainerImage&lt;/strong&gt;: the URI of the container image we used for SageMaker Training and Processing in a form of &lt;code&gt;{account-id}.dkr.ecr.{region}.amazonaws.com/r-fable-trip-forecasting:latest&lt;/code&gt;. You can get it in ECR console, or the &lt;code&gt;image&lt;/code&gt; variable from the script &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/sagemaker_training.r&#34;&gt;sagemaker_training.r&lt;/a&gt; in the RStudio IDE.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Email&lt;/strong&gt;: an email address that is used to send and receive the evaluation report sent by Amazon SES. Note that you will receive a verification email during the CloudFormation stack creation. You must verify it before receiving emails from the workflow.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;SageMakerExecutionRoleArn&lt;/strong&gt;: the IAM role ARN &lt;code&gt;role&lt;/code&gt; that we use in SageMaker Training and Processing jobs in &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/sagemaker_training.r&#34;&gt;sagemaker_training.r&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;s3Bucket&lt;/strong&gt;: A S3 bucket where we are going to save the output and setup the Amazon EventBridge trigger. You can use the &lt;code&gt;bucket&lt;/code&gt; defined in &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/sagemaker_training.r&#34;&gt;sagemaker_training.r&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/cloudformation_human_approval_1.png&#34; alt=&#34;cloudformation_human_approval&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The stack creation takes about 2 minutes.&lt;/p&gt; &#xA;&lt;h3&gt;Execution&lt;/h3&gt; &#xA;&lt;p&gt;We can trigger an execution by uploading the &lt;code&gt;tourism_tsbl.rds&lt;/code&gt; to the &lt;code&gt;s3Bucket&lt;/code&gt; that we defined in the stack with a prefix of &lt;code&gt;r-fable-trip-forecasting/new-data&lt;/code&gt;. Why &lt;code&gt;r-fable-trip-forecasting/new-data&lt;/code&gt;? Because that&#39;s how we defined &lt;a href=&#34;https://github.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/raw/7f476b629b6d2a30913039d1acefa6f474d709ba/cloudformation/human_approval.yaml#L740&#34;&gt;the EventRule with Amazon EventBridge&lt;/a&gt;. So back to the RStudio IDE, we run the following code to upload the file to S3.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;###################################&#xA;## Execute a StepFunctions workflow by uploading a file to a specific S3 bucket and prefix&#xA;s3_client$upload_file(rds_file, bucket, &#39;r-fable-trip-forecasting/new-data/tourism_tsbl.rds&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Switching to &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/states/home?region=us-west-2#/statemachines&#34;&gt;AWS Step Functions console&lt;/a&gt;, you can see a new execution in running state,&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/stepfunctions_execution_1.png&#34; alt=&#34;stepfunction_exe1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;and its progress.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/stepfunctions_execution_2.png&#34; alt=&#34;stepfunction_exe2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Once the workflow moves pass &lt;code&gt;Evaluate model&lt;/code&gt; step, you will receive an email &lt;em&gt;&#34;Required approval from AWS Step Functions&#34;&lt;/em&gt; with all the information about the trained model, a visualization of the forecasting that we saw during the prototyping. At the bottom, you can either approve or reject this model and will be redirected to AWS Step Functions console.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/email.png&#34; alt=&#34;email&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Once a model is approved, the model will become available for inference in &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/sagemaker/home?region=us-west-2#/models&#34;&gt;Amazon SageMaker Models console&lt;/a&gt; as shown below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/sm_model.png&#34; alt=&#34;model&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Cleaning up&lt;/h2&gt; &#xA;&lt;p&gt;You are reaching the end of the demo. After the demo, please delete all the resources created by the two CloudFormation stacks from the &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks?&#34;&gt;CloudFormation console&lt;/a&gt; to avoid incurring unnecessary cost.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/cloudformation_cleanup.png&#34; alt=&#34;cleanup&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note that the deletion initiated from CloudFormation console does not delete derivatives from the demo such as objects in S3 buckets, S3 buckets, verified email address in Amazon SES and models created in Amazon SageMaker. Please remove them individually. To remove the verified email adress in Amazon SES, please go to the &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/ses/home?region=us-west-2#verified-senders-email:&#34;&gt;Amazon SES console&lt;/a&gt;, select the email address you provided, and hit &lt;strong&gt;Remove&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/doc/email_remove.png&#34; alt=&#34;remove_email&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Additional resources&lt;/h2&gt; &#xA;&lt;p&gt;Come and learn how to run pure statistical simulation with Amazon SageMaker Processing. We have a &lt;a href=&#34;https://aws.amazon.com/blogs/machine-learning/performing-simulations-at-scale-with-amazon-sagemaker-processing-and-r-on-rstudio/&#34;&gt;blog&lt;/a&gt; and a &lt;a href=&#34;https://github.com/aws-samples/amazon-sagemaker-statistical-simulation-rstudio&#34;&gt;repository&lt;/a&gt; showing you how.&lt;/p&gt; &#xA;&lt;p&gt;The human approval architecture is inspired by and has taken parts from &lt;a href=&#34;https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-human-approval.html&#34;&gt;Deploying a Human Approval Project&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/CONTRIBUTING.md#security-issue-notifications&#34;&gt;CONTRIBUTING&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This library is licensed under the MIT-0 License. See the &lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/reinvent2020-aim404-productionize-r-using-amazon-sagemaker/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
</feed>