<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-11T01:43:15Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>cmks/DAS_Tool</title>
    <updated>2023-06-11T01:43:15Z</updated>
    <id>tag:github.com,2023-06-11:/cmks/DAS_Tool</id>
    <link href="https://github.com/cmks/DAS_Tool" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DAS Tool&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DAS Tool for genome resolved metagenomics&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cmks/DAS_Tool/master/img/logo.png&#34; alt=&#34;DAS Tool&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;DAS Tool is an automated method that integrates the results of a flexible number of binning algorithms to calculate an optimized, non-redundant set of bins from a single assembly.&lt;/p&gt; &#xA;&lt;h1&gt;Reference&lt;/h1&gt; &#xA;&lt;p&gt;Christian M. K. Sieber, Alexander J. Probst, Allison Sharrar, Brian C. Thomas, Matthias Hess, Susannah G. Tringe &amp;amp; Jillian F. Banfield (2018). &lt;a href=&#34;https://www.nature.com/articles/s41564-018-0171-1&#34;&gt;Recovery of genomes from metagenomes via a dereplication, aggregation and scoring strategy.&lt;/a&gt; Nature Microbiology. &lt;a href=&#34;https://doi.org/10.1038/s41564-018-0171-1&#34;&gt;https://doi.org/10.1038/s41564-018-0171-1.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;DAS_Tool [options] -i &amp;lt;contig2bin&amp;gt; -c &amp;lt;contigs_fasta&amp;gt; -o &amp;lt;outputbasename&amp;gt;&#xA;&#xA;Options:&#xA;   -i --bins=&amp;lt;contig2bin&amp;gt;                   Comma separated list of tab separated contigs to bin tables.&#xA;   -c --contigs=&amp;lt;contigs&amp;gt;                   Contigs in fasta format.&#xA;   -o --outputbasename=&amp;lt;outputbasename&amp;gt;     Basename of output files.&#xA;   -l --labels=&amp;lt;labels&amp;gt;                     Comma separated list of binning prediction names.&#xA;   --search_engine=&amp;lt;search_engine&amp;gt;          Engine used for single copy gene identification (diamond/blastp/usearch) [default: diamond].&#xA;   -p --proteins=&amp;lt;proteins&amp;gt;                 Predicted proteins (optional) in prodigal fasta format (&amp;gt;contigID_geneNo).&#xA;                                            Gene prediction step will be skipped.&#xA;   --write_bin_evals                        Write evaluation of input bin sets.&#xA;   --write_bins                             Export bins as fasta files.&#xA;   --write_unbinned                         Write unbinned contigs.&#xA;   -t --threads=&amp;lt;threads&amp;gt;                   Number of threads to use [default: 1].&#xA;   --score_threshold=&amp;lt;score_threshold&amp;gt;      Score threshold until selection algorithm will keep selecting bins (0..1) [default: 0.5].&#xA;   --duplicate_penalty=&amp;lt;duplicate_penalty&amp;gt;  Penalty for duplicate single copy genes per bin (weight b).&#xA;                                            Only change if you know what you are doing (0..3) [default: 0.6].&#xA;   --megabin_penalty=&amp;lt;megabin_penalty&amp;gt;      Penalty for megabins (weight c). Only change if you know what you are doing (0..3) [default: 0.5].&#xA;   --dbDirectory=&amp;lt;dbDirectory&amp;gt;              Directory of single copy gene database [default: db].&#xA;   --resume                                 Use existing predicted single copy gene files from a previous run.&#xA;   --debug                                  Write debug information to log file.&#xA;   -v --version                             Print version number and exit.&#xA;   -h --help                                Show this.&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Input file format&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bins [--bins, -i]: Tab separated files of contig-IDs and bin-IDs. Contigs to bin file example:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;Contig_1&#x9;bin.01&#xA;Contig_8&#x9;bin.01&#xA;Contig_42&#x9;bin.02&#xA;Contig_49&#x9;bin.03&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Contigs [--contigs, -c]: Assembled contigs in fasta format:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;Contig_1&#xA;ATCATCGTCCGCATCGACGAATTCGGCGAACGAGTACCCCTGACCATCTCCGATTA...&#xA;&amp;gt;Contig_2&#xA;GATCGTCACGCAGGCTATCGGAGCCTCGACCCGCAAGCTCTGCGCCTTGGAGCAGG...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Proteins (optional) [--proteins]: Predicted proteins in prodigal fasta format. Header contains contig-ID and gene number:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;Contig_1_1&#xA;MPRKNKKLPRHLLVIRTSAMGDVAMLPHALRALKEAYPEVKVTVATKSLFHPFFEG...&#xA;&amp;gt;Contig_1_2&#xA;MANKIPRVPVREQDPKVRATNFEEVCYGYNVEEATLEASRCLNCKNPRCVAACPVN...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Output files&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Summary of output bins including quality and completeness estimates (*_DASTool_summary.tsv).&lt;/li&gt; &#xA; &lt;li&gt;Contigs to bin file of output bins (*_DASTool_contigs2bin.tsv).&lt;/li&gt; &#xA; &lt;li&gt;Quality and completeness estimates of input bin sets, if &lt;code&gt;--write_bin_evals&lt;/code&gt; is set (*_allBins.eval).&lt;/li&gt; &#xA; &lt;li&gt;Bins in fasta format if &lt;code&gt;--write_bins&lt;/code&gt; is set (DASTool_bins).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Examples: Running DAS Tool on sample data.&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 1:&lt;/strong&gt; Run DAS Tool on binning predictions of MetaBAT, MaxBin, CONCOCT and tetraESOMs. Output files will start with the prefix &lt;em&gt;DASToolRun1&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;DAS_Tool  -i sample_data/sample.human.gut_concoct_contigs2bin.tsv,\&#xA;sample_data/sample.human.gut_maxbin2_contigs2bin.tsv,\&#xA;sample_data/sample.human.gut_metabat_contigs2bin.tsv,\&#xA;sample_data/sample.human.gut_tetraESOM_contigs2bin.tsv \&#xA;-l concoct,maxbin,metabat,tetraESOM \&#xA;-c sample_data/sample.human.gut_contigs.fa \&#xA;-o sample_output/DASToolRun1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 2:&lt;/strong&gt; Run DAS Tool again with different parameters. Use the proteins predicted in Example 1 to skip the gene prediction step, output evaluations of input bins, set the number of threads to 2 and score threshold to 0.6. Output files will start with the prefix &lt;em&gt;DASToolRun2&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;DAS_Tool -i sample_data/sample.human.gut_concoct_contigs2bin.tsv,\&#xA;sample_data/sample.human.gut_maxbin2_contigs2bin.tsv,\&#xA;sample_data/sample.human.gut_metabat_contigs2bin.tsv,\&#xA;sample_data/sample.human.gut_tetraESOM_contigs2bin.tsv \&#xA;-l concoct,maxbin,metabat,tetraESOM \&#xA;-c sample_data/sample.human.gut_contigs.fa \&#xA;-o sample_output/DASToolRun2 \&#xA;--proteins sample_output/DASToolRun1_proteins.faa \&#xA;--write_bin_evals \&#xA;--threads 2 \&#xA;--score_threshold 0.6&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Dependencies&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;R (&amp;gt;= 3.2.3): &lt;a href=&#34;https://www.r-project.org&#34;&gt;https://www.r-project.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;R-packages: data.table (&amp;gt;= 1.9.6), magrittr (&amp;gt;= 2.0.1), docopt (&amp;gt;= 0.7.1)&lt;/li&gt; &#xA; &lt;li&gt;ruby (&amp;gt;= v2.3.1): &lt;a href=&#34;https://www.ruby-lang.org&#34;&gt;https://www.ruby-lang.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Pullseq (&amp;gt;= 1.0.2): &lt;a href=&#34;https://github.com/bcthomas/pullseq&#34;&gt;https://github.com/bcthomas/pullseq&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Prodigal (&amp;gt;= 2.6.3): &lt;a href=&#34;https://github.com/hyattpd/Prodigal&#34;&gt;https://github.com/hyattpd/Prodigal&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;coreutils (only macOS/ OS X): &lt;a href=&#34;https://www.gnu.org/software/coreutils&#34;&gt;https://www.gnu.org/software/coreutils&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;One of the following search engines: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;DIAMOND (&amp;gt;= 0.9.14): &lt;a href=&#34;https://ab.inf.uni-tuebingen.de/software/diamond&#34;&gt;https://ab.inf.uni-tuebingen.de/software/diamond&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;BLAST+ (&amp;gt;= 2.5.0): &lt;a href=&#34;https://blast.ncbi.nlm.nih.gov/Blast.cgi&#34;&gt;https://blast.ncbi.nlm.nih.gov/Blast.cgi&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;USEARCH* (&amp;gt;= 8.1): &lt;a href=&#34;http://www.drive5.com/usearch/download.html&#34;&gt;http://www.drive5.com/usearch/download.html&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;*) The free version of USEARCH only can use up to 4Gb RAM. Therefore, the use of DIAMOND or BLAST+ is recommended for big datasets.&lt;/p&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Download and extract DASTool.zip archive:&#xA;unzip DAS_Tool-1.x.x.zip&#xA;cd ./DAS_Tool-1.x.x&#xA;&#xA;# Unzip SCG database:&#xA;unzip ./db.zip -d db&#xA;&#xA;# Run DAS Tool:&#xA;./DAS_Tool -h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Installation of dependent R-packages:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ R&#xA;&amp;gt; repo=&#39;http://cran.us.r-project.org&#39; #select a repository&#xA;&amp;gt; install.packages(&#39;data.table&#39;, repos=repo, dependencies = T)&#xA;&amp;gt; install.packages(&#39;magrittr&#39;, repos=repo, dependencies = T)&#xA;&amp;gt; install.packages(&#39;docopt&#39;, repos=repo, dependencies = T)&#xA;&amp;gt; q() #quit R-session&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Installation using conda or homebrew&lt;/h1&gt; &#xA;&lt;p&gt;DAS Tool now can also be installed via bioconda and homebrew.&lt;/p&gt; &#xA;&lt;h2&gt;Bioconda&lt;/h2&gt; &#xA;&lt;p&gt;Bioconda repository: &lt;a href=&#34;https://bioconda.github.io/recipes/das_tool/README.html&#34;&gt;https://bioconda.github.io/recipes/das_tool/README.html&lt;/a&gt;. Thanks @&lt;a href=&#34;https://raw.githubusercontent.com/cmks/DAS_Tool/master/%22https://github.com/keuv-grvl%22&#34;&gt;keuv-grvl&lt;/a&gt; and @&lt;a href=&#34;https://raw.githubusercontent.com/cmks/DAS_Tool/master/%22https://github.com/SilasK%22&#34;&gt;silask&lt;/a&gt;!.&lt;/p&gt; &#xA;&lt;p&gt;Add bioconda channel:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda config --add channels defaults&#xA;conda config --add channels bioconda&#xA;conda config --add channels conda-forge&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install DAS Tool using conda:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install -c bioconda das_tool&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Homebrew&lt;/h2&gt; &#xA;&lt;p&gt;Homebrew-bio repository: &lt;a href=&#34;https://github.com/brewsci/homebrew-bio&#34;&gt;https://github.com/brewsci/homebrew-bio&lt;/a&gt;. Thanks @&lt;a href=&#34;https://raw.githubusercontent.com/cmks/DAS_Tool/master/%22https://github.com/gaberoo%22&#34;&gt;gaberoo&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt;Install DAS Tool using Homebrew:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install brewsci/bio/das_tool&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Docker&lt;/h1&gt; &#xA;&lt;p&gt;It is also possible to run DAS Tool using Docker. A Docker image can be built using the Dockerfile included in the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd ./DAS_Tool-1.x.x&#xA;docker build -t cmks/das_tool .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To test the build run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it -v $(pwd)/sample_data:/sample_data -v $(pwd)/sample_output:/sample_output cmks/das_tool \&#xA;DAS_Tool -i /sample_data/sample.human.gut_concoct_contigs2bin.tsv,\&#xA;/sample_data/sample.human.gut_maxbin2_contigs2bin.tsv,\&#xA;/sample_data/sample.human.gut_metabat_contigs2bin.tsv,\&#xA;/sample_data/sample.human.gut_tetraESOM_contigs2bin.tsv \&#xA;-l concoct,maxbin,metabat,tetraESOM \&#xA;-c /sample_data/sample.human.gut_contigs.fa \&#xA;-o /sample_output/dockerTest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Preparation of input files&lt;/h1&gt; &#xA;&lt;p&gt;Not all binning tools provide results in a tab separated file of contig-IDs and bin-IDs. A helper script can be used to convert a set of bins in fasta format to tabular contigs2bin file, which can be used as input for DAS Tool: &lt;code&gt;src/Fasta_to_Contigs2Bin.sh -h&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Usage:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;Fasta_to_Contigs2Bin: Converts genome bins in fasta format to contigs-to-bin table.&#xA;&#xA;Usage: Fasta_to_Contigs2Bin.sh -e fasta &amp;gt; my_contigs2bin.tsv&#xA;&#xA;   -e, --extension            Extension of fasta files. (default: fasta)&#xA;   -i, --input_folder         Folder with bins in fasta format. (default: ./)&#xA;   -h, --help                 Show this message.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Example: Converting MaxBin fasta output into tab separated contigs2bin file:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ls /maxbin/output/folder&#xA;maxbin.001.fasta   maxbin.002.fasta   maxbin.003.fasta...&#xA;&#xA;$ src/Fasta_to_Contigs2Bin.sh -i /maxbin/output/folder -e fasta &amp;gt; maxbin.contigs2bin.tsv&#xA;&#xA;$ head gut_maxbin2_contigs2bin.tsv&#xA;NODE_10_length_127450_cov_375.783524&#x9;maxbin.001&#xA;NODE_27_length_95143_cov_427.155298&#x9;maxbin.001&#xA;NODE_51_length_78315_cov_504.322425&#x9;maxbin.001&#xA;NODE_84_length_66931_cov_376.684775&#x9;maxbin.001&#xA;NODE_87_length_65653_cov_460.202156&#x9;maxbin.001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some binning tools (such as CONCOCT) provide a comma separated tabular output. To convert a comma separated file into a tab separated file a one liner can be used: &lt;code&gt;perl -pe &#34;s/,/\t/g;&#34; contigs2bin.csv &amp;gt; contigs2bin.tsv&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Example: Converting CONCOCT csv output into tab separated contigs2bin file:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ head concoct_clustering_gt1000.csv&#xA;NODE_2_length_147519_cov_33.166976,42&#xA;NODE_3_length_141012_cov_38.678171,42&#xA;NODE_4_length_139685_cov_35.741896,42&#xA;&#xA;$ perl -pe &#34;s/,/\tconcoct./g;&#34; concoct_clustering_gt1000.csv &amp;gt; concoct.contigs2bin.tsv&#xA;&#xA;$ head concoct.contigs2bin.tsv&#xA;NODE_2_length_147519_cov_33.166976&#x9;concoct.42&#xA;NODE_3_length_141012_cov_38.678171&#x9;concoct.42&#xA;NODE_4_length_139685_cov_35.741896&#x9;concoct.42&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Troubleshooting/ known issues&lt;/h1&gt; &#xA;&lt;h3&gt;Docopt issue&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; When executing DAS Tool a truncated version of the help message is displayed (see below). This is a known bug of the current version of the &lt;code&gt;docopt&lt;/code&gt; R package, which occurs if the command-line syntax is violated.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Error: DAS Tool&#xA;&#xA;Usage:&#xA;  DAS_Tool [options] -i &amp;lt;contig2bin&amp;gt; -c &amp;lt;contigs_fasta&amp;gt; -o &amp;lt;outputbasename&amp;gt;&#xA;  DAS_Tool [--help]&#xA;&#xA;Options:&#xA;   -i --bins=&amp;lt;contig2bin&amp;gt;                   Comma separated list of tab separated contigs to bin tables.&#xA;   -c --contigs=&amp;lt;contigs&amp;gt;                   Contigs in fasta format.&#xA;   -o --outputbasename=&amp;lt;outputbasename&amp;gt;     Basename of output files.&#xA;   -l --labels=&amp;lt;labels&amp;gt;                     Comma separated list of binning prediction names.&#xA;   --search_engine=&amp;lt;search_engine&amp;gt;          Engine used for single copy gene identification (di&#xA;Execution halted&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Check command line for any typos.&lt;/p&gt; &#xA;&lt;h3&gt;Dependencies not found&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; All dependencies are installed and the environmental variables are set but DAS Tool still claims that specific depencendies are missing.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Make sure that the dependency executable names are correct. For example USEARCH has to be executable with the command If your USEARCH binary is called differently (e.g. &lt;code&gt;usearch9.0.2132_i86linux32&lt;/code&gt;) you can either rename it or add a symbolic link called usearch:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ln -s usearch9.0.2132_i86linux32 usearch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Memory limit of 32-bit usearch version exceeded&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Running DAS Tool with the free version of USEARCH on a large metagenomic dataset results in the following error:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;---Fatal error---&#xA;Memory limit of 32-bit process exceeded, 64-bit build required&#xA;makeblastdb did not work for my_proteins.faa, please check your input file&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Use DIAMOND or BLAST as alignment tool (&lt;code&gt;--search_engine diamond&lt;/code&gt; or &lt;code&gt;--search_engine blast&lt;/code&gt;):&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>dataPlusVisualizingDurhamPublicSchools/visualizing_DPS</title>
    <updated>2023-06-11T01:43:15Z</updated>
    <id>tag:github.com,2023-06-11:/dataPlusVisualizingDurhamPublicSchools/visualizing_DPS</id>
    <link href="https://github.com/dataPlusVisualizingDurhamPublicSchools/visualizing_DPS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tool for visualizing Durham Public Schools&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;visualizing_DPS&lt;/h1&gt; &#xA;&lt;p&gt;Tool for visualizing Durham Public Schools&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>chr1swallace/coloc</title>
    <updated>2023-06-11T01:43:15Z</updated>
    <id>tag:github.com,2023-06-11:/chr1swallace/coloc</id>
    <link href="https://github.com/chr1swallace/coloc" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Repo for the R package coloc&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;coloc&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=coloc&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/coloc&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/chr1swallace/coloc/main/man/figures/logo30.png&#34; align=&#34;right&#34;&gt; The coloc package can be used to perform genetic colocalisation analysis of two potentially related phenotypes, to ask whether they share common genetic causal variant(s) in a given region. &#xA;&lt;p&gt;Most of the questions I get relate to misunderstanding the assumptions behind coloc (dense genotypes across a single genomic region) and/or the data structures used. Please read &lt;code&gt;vignette(&#34;a02_data&#34;,package=&#34;coloc&#34;)&lt;/code&gt; before starting an issue.&lt;/p&gt; &#xA;&lt;h2&gt;version 5&lt;/h2&gt; &#xA;&lt;p&gt;This update (version 5) supercedes previously published version 4 by introducing use of the &lt;a href=&#34;https://stephenslab.github.io/susieR/index.html&#34;&gt;SuSiE&lt;/a&gt; approach to deal with multiple causal variants rather than conditioning or masking. See&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Wang, G., Sarkar, A., Carbonetto, P., &amp;amp; Stephens, M. (2020). A simple new approach to variable selection in regression, with application to genetic fine mapping. Journal of the Royal Statistical Society: Series B (Statistical Methodology). &lt;a href=&#34;https://doi.org/10.1111/rssb.12388&#34;&gt;https://doi.org/10.1111/rssb.12388&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;for the full SuSiE paper and&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Wallace (2021). A more accurate method for colocalisation analysis allowing for multiple causal variants. PLoS Genetics. &lt;a href=&#34;https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1009440&#34;&gt;https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1009440&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;for a description of its use in coloc.&lt;/p&gt; &#xA;&lt;p&gt;To install from R, do&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;if(!require(&#34;remotes&#34;))&#xA;   install.packages(&#34;remotes&#34;) # if necessary&#xA;library(remotes)&#xA;install_github(&#34;chr1swallace/coloc@main&#34;,build_vignettes=TRUE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that in all simulations, susie outperforms the earlier conditioning approach, so is recommended. However, it is also new code, so please consider the code &#34;beta&#34; and let me know of any issues that arise - they may be a bug on my part. If you want to use it, the function you want to look at is &lt;code&gt;coloc.susie&lt;/code&gt;. It can take raw datasets, but the time consuming part is running SuSiE. coloc runs SuSiE and saves a little extra information using the &lt;code&gt;runsusie&lt;/code&gt; function before running an adapted colocalisation on the results. So please look at the docs for &lt;code&gt;runsusie&lt;/code&gt; too. I found a helpful recipe is&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Run &lt;code&gt;runsusie&lt;/code&gt; on dataset 1, storing the results&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;runsusie&lt;/code&gt; on dataset 2, storing the results&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;coloc.susie&lt;/code&gt; on the two outputs from above&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;More detail is available in the vignette a06_SuSiE.html accessible by&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;vignette(&#34;a06_SuSiE&#34;,package=&#34;coloc&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- ## version 4 --&gt; &#xA;&lt;!-- This is an updated version of coloc.  I have tested it, but there may be bugs. Please test it, and let me know whether it works or not (both kinds of feedback useful!).   --&gt; &#xA;&lt;!-- It is not yet on CRAN. To install the new version, do --&gt; &#xA;&lt;!-- ``` --&gt; &#xA;&lt;!-- if(!require(&#34;remotes&#34;)) --&gt; &#xA;&lt;!--    install.packages(&#34;remotes&#34;) # if necessary --&gt; &#xA;&lt;!-- library(remotes) --&gt; &#xA;&lt;!-- install_github(&#34;chr1swallace/coloc&#34;) --&gt; &#xA;&lt;!-- ``` --&gt; &#xA;&lt;h1&gt;Background reading&lt;/h1&gt; &#xA;&lt;p&gt;For usage, please see the vignette at &lt;a href=&#34;https://chr1swallace.github.io/coloc&#34;&gt;https://chr1swallace.github.io/coloc&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Key previous references are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;original propostion of proportional colocalisation &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/19039033/&#34;&gt;Plagnol et al (2009)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;proportional colocalisation with type 1 error rate control &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/abs/10.1002/gepi.21765&#34;&gt;Wallace et al (2013)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;colocalisation by enumerating all the possible causal SNP configurations between two traits, assuming at most one causal variant per trait &lt;a href=&#34;https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1004383&#34;&gt;Giambartolomei et al (2013)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Thoughts about priors in coloc are described in &lt;a href=&#34;https://doi.org/10.1371/journal.pgen.1008720&#34;&gt;Wallace C (2020) Eliciting priors and relaxing the single causal variant assumption in colocalisation analyses. PLOS Genetics 16(4): e1008720&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Frequently Asked Questions&lt;/h1&gt; &#xA;&lt;p&gt;see &lt;a href=&#34;https://chr1swallace.github.io/coloc/FAQ.html&#34;&gt;FAQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Notes to self&lt;/h1&gt; &#xA;&lt;!-- *to generate vignettes:* --&gt; &#xA;&lt;!-- ``` --&gt; &#xA;&lt;!-- cp vignettes/colocqq-tests.R.tospin vignettes/colocqq-tests.R &amp;&amp; Rscript -e &#39;knitr::spin(&#34;vignettes/colocqq-tests.R&#34;,knit=FALSE); devtools::build_vignettes()&#39; --&gt; &#xA;&lt;!-- ``` --&gt; &#xA;&lt;p&gt;&lt;em&gt;to generate website:&lt;/em&gt; &lt;a href=&#34;https://chr1swallace.github.io/coloc/&#34;&gt;https://chr1swallace.github.io/coloc/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Rscript -e &#34;pkgdown::build_site()&#34;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>