<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-02T01:42:30Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>e-sensing/sits</title>
    <updated>2023-03-02T01:42:30Z</updated>
    <id>tag:github.com,2023-03-02:/e-sensing/sits</id>
    <link href="https://github.com/e-sensing/sits" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Satellite image time series in R&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SITS - Satellite Image Time Series Analysis for Earth Observation Data Cubes&lt;/h1&gt; &#xA;&lt;!-- README.md is generated from README.Rmd. Please edit that file --&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/e-sensing/sits/master/inst/extdata/sticker/sits_sticker.png&#34; alt=&#34;SITS icon&#34; align=&#34;right&#34; height=&#34;150&#34; width=&#34;150&#34;&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;!-- [![Build Status](https://drone.dpi.inpe.br/api/badges/e-sensing/sits/status.svg)](https://drone.dpi.inpe.br/e-sensing/sits) --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=sits&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/sits&#34; alt=&#34;CRAN status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cloud.drone.io/e-sensing/sits&#34;&gt;&lt;img src=&#34;https://cloud.drone.io/api/badges/e-sensing/sits/status.svg?sanitize=true&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/e-sensing/sits&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/e-sensing/sits/branch/dev/graph/badge.svg?token=hZxdJgKGcE&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://e-sensing.github.io/sitsbook/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-online-blueviolet&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://lifecycle.r-lib.org/articles/stages.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/lifecycle-stable-brightgreen.svg?sanitize=true&#34; alt=&#34;Life cycle&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/e-sensing/sits/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-GPL--2-green&#34; alt=&#34;Software License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;sits&lt;/code&gt; is an open source R package for satellite image time series analysis. It enables users to apply machine learning techniques for classifying image time series obtained from earth observation data cubes. The basic workflow in &lt;code&gt;sits&lt;/code&gt; is:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Select an image collection available on cloud providers AWS, Microsoft Planetary Computer, Digital Earth Africa and Brazil Data Cube.&lt;/li&gt; &#xA; &lt;li&gt;Build a regular data cube using analysis-ready image collections.&lt;/li&gt; &#xA; &lt;li&gt;Extract labelled time series from data cubes to be used as training samples.&lt;/li&gt; &#xA; &lt;li&gt;Perform quality control using self-organised maps.&lt;/li&gt; &#xA; &lt;li&gt;Filtering time series samples for noise reduction.&lt;/li&gt; &#xA; &lt;li&gt;Use the samples to train machine learning models.&lt;/li&gt; &#xA; &lt;li&gt;Tune machine learning models for improved accuracy.&lt;/li&gt; &#xA; &lt;li&gt;Classify data cubes using machine learning models.&lt;/li&gt; &#xA; &lt;li&gt;Post-process classified images with Bayesian smoothing to remove outliers.&lt;/li&gt; &#xA; &lt;li&gt;Estimate uncertainty values of classified images.&lt;/li&gt; &#xA; &lt;li&gt;Evaluate classification accuracy using best practices.&lt;/li&gt; &#xA; &lt;li&gt;Improve results with active learning and self-supervised learning methods.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/e-sensing/sits/master/inst/extdata/markdown/figures/sits_general_view.jpg&#34; title=&#34;Conceptual view of data cubes (source: authors)&#34; alt=&#34;Conceptual view of data cubes (source: authors)&#34; width=&#34;60%&#34; height=&#34;60%&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Detailed documentation on how to use &lt;code&gt;sits&lt;/code&gt; is available in the e-book &lt;a href=&#34;https://e-sensing.github.io/sitsbook/&#34;&gt;“Satellite Image Time Series Analysis on Earth Observation Data Cubes”&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;code&gt;sits&lt;/code&gt; on Kaggle&lt;/h2&gt; &#xA;&lt;p&gt;Those that want to evaluate the &lt;code&gt;sits&lt;/code&gt; package before installing are invited to run the examples available on &lt;a href=&#34;https://www.kaggle.com/esensing/code&#34;&gt;Kaggle&lt;/a&gt;. These examples provide a fast-track introduction to the package. We recommend running them in the following order:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/esensing/introduction-to-sits&#34;&gt;Introduction to SITS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/esensing/working-with-time-series-in-sits&#34;&gt;Working with time series in SITS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/esensing/creating-data-cubes-in-sits&#34;&gt;Creating data cubes in SITS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/esensing/raster-classification-in-sits&#34;&gt;Raster classification in SITS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/esensing/using-som-for-sample-quality-control-in-sits&#34;&gt;Using SOM for sample quality control in SITS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Pre-Requisites&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;sits&lt;/code&gt; package relies on the geospatial packages &lt;code&gt;sf&lt;/code&gt;, &lt;code&gt;stars&lt;/code&gt;, &lt;code&gt;gdalcubes&lt;/code&gt; and &lt;code&gt;terra&lt;/code&gt;, which depend on the external libraries GDAL and PROJ. Please follow the instructions for installing &lt;code&gt;sf&lt;/code&gt; together with GDAL available at the &lt;a href=&#34;https://github.com/r-spatial/sf&#34;&gt;RSpatial sf github repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Obtaining &lt;code&gt;sits&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;sits&lt;/code&gt; can be installed from CRAN:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;sits&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The development version is available on github.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&#34;e-sensing/sits&#34;, dependencies = TRUE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# load the sits library&#xA;library(sits)&#xA;#&amp;gt; Using configuration file: /home/sits/R/x86_64-pc-linux-gnu-library/4.2/sits/extdata/config.yml&#xA;#&amp;gt; Color configurations found in /home/sits/R/x86_64-pc-linux-gnu-library/4.2/sits/extdata/config_colors.yml&#xA;#&amp;gt; To provide additional configurations, create an YAML file and inform its path to environment variable &#39;SITS_CONFIG_USER_FILE&#39;.&#xA;#&amp;gt; Using raster package: terra&#xA;#&amp;gt; SITS - satellite image time series analysis.&#xA;#&amp;gt; Loaded sits v1.2.0.&#xA;#&amp;gt;         See ?sits for help, citation(&#34;sits&#34;) for use in publication.&#xA;#&amp;gt;         See demo(package = &#34;sits&#34;) for examples.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Building Earth Observation Data Cubes&lt;/h2&gt; &#xA;&lt;h3&gt;Image Collections Accessible by &lt;code&gt;sits&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;sits&lt;/code&gt; package allows users to created data cubes from analysis-ready data (ARD) image collections available in cloud services. The collections accessible in &lt;code&gt;sits&lt;/code&gt; 1.2.0 are:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Brazil Data Cube (&lt;a href=&#34;http://brazildatacube.org/en/home-page-2/#dataproducts&#34;&gt;BDC&lt;/a&gt;): Open data collections of Sentinel-2, Landsat-8 and CBERS-4 images.&lt;/li&gt; &#xA; &lt;li&gt;Microsoft Planetary Computer (&lt;a href=&#34;https://planetarycomputer.microsoft.com/catalog&#34;&gt;MPC&lt;/a&gt;): Open data collection of Sentinel-2/2A and Landsat-8&lt;/li&gt; &#xA; &lt;li&gt;Earth on AWS (&lt;a href=&#34;https://aws.amazon.com/earth/&#34;&gt;AWS&lt;/a&gt;): Sentinel-2/2A level 2A collections.&lt;/li&gt; &#xA; &lt;li&gt;Digital Earth Africa (&lt;a href=&#34;https://www.digitalearthafrica.org/&#34;&gt;DEAFRICA&lt;/a&gt;): Open data collection of Sentinel-2/2A and Landsat-8 for Africa.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://landsatlook.usgs.gov/stac-browser&#34;&gt;USGS&lt;/a&gt;: Landsat-4/5/7/8 collections, which are not open data.&lt;/li&gt; &#xA; &lt;li&gt;Swiss Data Cube (&lt;a href=&#34;https://www.swissdatacube.org/&#34;&gt;SDC&lt;/a&gt;): Open data collection of Sentinel-2/2A and Landsat-8.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Open data collections do not require payment of access fees. Except for those in the Brazil Data Cube, these collections are not regular. Irregular collections require further processing before they can be used for classification using machine learning models.&lt;/p&gt; &#xA;&lt;h3&gt;Building a Data Cube from an ARD Image Collection&lt;/h3&gt; &#xA;&lt;p&gt;The following code defines an irregular data cube of Sentinel-2/2A images available in the Microsoft Planetary Computer, using the open data collection &lt;code&gt;&#34;SENTINEL-2-L2A&#34;&lt;/code&gt;. The geographical area of the data cube is defined by the tiles &lt;code&gt;&#34;20LKP&#34;&lt;/code&gt; and &lt;code&gt;&#34;20LLKP&#34;&lt;/code&gt;, and the temporal extent by a start and end date. Access to other cloud services works in similar ways.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;s2_cube &amp;lt;- sits_cube(&#xA;    source = &#34;MPC&#34;,&#xA;    collection = &#34;SENTINEL-2-L2A&#34;,&#xA;    tiles = c(&#34;20LKP&#34;, &#34;20LLP&#34;),&#xA;    bands = c(&#34;B03&#34;, &#34;B08&#34;, &#34;B11&#34;, &#34;SCL&#34;),&#xA;    start_date = as.Date(&#34;2018-07-01&#34;),&#xA;    end_date = as.Date(&#34;2019-06-30&#34;),&#xA;    progress = FALSE&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This cube is irregular. The timelines of tiles &lt;code&gt;&#34;20LKP&#34;&lt;/code&gt; and &lt;code&gt;&#34;20LLKP&#34;&lt;/code&gt; and the resolutions of the bands are different. Sentinel-2 bands &lt;code&gt;&#34;B03&#34;&lt;/code&gt; and &lt;code&gt;&#34;B08&#34;&lt;/code&gt; have 10-meters resolution, while band &lt;code&gt;&#34;B11&#34;&lt;/code&gt; and the cloud band &lt;code&gt;&#34;SCL&#34;&lt;/code&gt; have 20-meters resolution. Irregular collections need an additional processing step to be converted to regular data cubes, as described below.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/e-sensing/sits/master/inst/extdata/markdown/figures/datacube_conception.jpg&#34; title=&#34;Conceptual view of data cubes (source: authors)&#34; alt=&#34;Conceptual view of data cubes (source: authors)&#34; width=&#34;90%&#34; height=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;p&gt;After defining an irregular ARD image collection from a cloud service using &lt;code&gt;sits_cube()&lt;/code&gt;, users should run &lt;code&gt;sits_regularize()&lt;/code&gt; to build a regular data cube. This function uses the &lt;a href=&#34;https://github.com/appelmar/gdalcubes&#34;&gt;gdalcubes R package&lt;/a&gt;, described in &lt;a href=&#34;https://www.mdpi.com/2306-5729/4/3/92&#34;&gt;Appel and Pebesma, 2019&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gc_cube &amp;lt;- sits_regularize(&#xA;    cube          = s2_cube,&#xA;    output_dir    = tempdir(),&#xA;    period        = &#34;P15D&#34;,&#xA;    res           = 60, &#xA;    multicores    = 4&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above command builds a regular data cube with all bands interpolated to 60 m spatial resolution and 15-days temporal resolution. Regular data cubes are the input to the &lt;code&gt;sits&lt;/code&gt; functions for time series retrieval, building machine learning models, and classification of raster images and time series.&lt;/p&gt; &#xA;&lt;p&gt;The cube can be shown in a leaflet using &lt;code&gt;sits_view()&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# View a color composite on a leaflet&#xA;sits_view(s2_cube[1,], green = &#34;B08&#34;, blue = &#34;B03&#34;, red = &#34;B04&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Working with Time Series in &lt;code&gt;sits&lt;/code&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Accessing Time Series in Data Cubes&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;sits&lt;/code&gt; has been designed to use satellite image time series to derive machine learning models. After the data cube has been created, time series can be retrieved individually or by using CSV or SHP files, as in the following example. The example below uses a data cube in a local directory, whose images have been obtained from the &lt;code&gt;&#34;MOD13Q1-6&#34;&lt;/code&gt; collection of the Brazil Data Cube.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(sits)&#xA;# this data cube uses images from the Brazil Data Cube that have &#xA;# downloaded to a local directory&#xA;data_dir &amp;lt;- system.file(&#34;extdata/raster/mod13q1&#34;, package = &#34;sits&#34;)&#xA;# create a cube from downloaded files&#xA;raster_cube &amp;lt;- sits_cube(&#xA;    source = &#34;BDC&#34;,&#xA;    collection = &#34;MOD13Q1-6&#34;,&#xA;    data_dir = data_dir,&#xA;    delim = &#34;_&#34;,&#xA;    parse_info = c(&#34;X1&#34;, &#34;tile&#34;, &#34;band&#34;, &#34;date&#34;),&#xA;    progress = FALSE&#xA;)&#xA;# obtain a set of samples defined by a CSV file&#xA;csv_file &amp;lt;- system.file(&#34;extdata/samples/samples_sinop_crop.csv&#34;,&#xA;                        package = &#34;sits&#34;)&#xA;# retrieve the time series associated with the samples from the data cube&#xA;points &amp;lt;- sits_get_data(raster_cube, samples = csv_file)&#xA;#&amp;gt; All points have been retrieved&#xA;# show the time series&#xA;points[1:3,]&#xA;#&amp;gt; # A tibble: 3 × 7&#xA;#&amp;gt;   longitude latitude start_date end_date   label    cube      time_series      &#xA;#&amp;gt;       &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt;     &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;list&amp;gt;           &#xA;#&amp;gt; 1     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6 &amp;lt;tibble [23 × 2]&amp;gt;&#xA;#&amp;gt; 2     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6 &amp;lt;tibble [23 × 2]&amp;gt;&#xA;#&amp;gt; 3     -55.7    -11.7 2013-09-14 2014-08-29 Soy_Corn MOD13Q1-6 &amp;lt;tibble [23 × 2]&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After a time series has been obtained, it is loaded in a tibble. The first six columns contain the metadata: spatial and temporal location, label assigned to the sample, and coverage from where the data has been extracted. The spatial location is given in longitude and latitude coordinates. The first sample has been labelled “Pasture”, at location (-55.65931, -11.76267), and is considered valid for the period (2013-09-14, 2014-08-29). To display the time series, use the &lt;code&gt;plot()&lt;/code&gt; function.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(points[1,])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/e-sensing/sits/master/man/figures/README-unnamed-chunk-9-1.png&#34; title=&#34;Plot of point at location (-55.65931, -11.76267) labelled as Pasture&#34; alt=&#34;Plot of point at location (-55.65931, -11.76267) labelled as Pasture&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;p&gt;For a large number of samples, where the amount of individual plots would be substantial, the default visualization combines all samples together in a single temporal interval.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# select only the samples with the cerrado label&#xA;samples_cerrado &amp;lt;- dplyr::filter(samples_modis_ndvi, &#xA;                  label == &#34;Cerrado&#34;)&#xA;plot(samples_cerrado)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/e-sensing/sits/master/man/figures/README-unnamed-chunk-10-1.png&#34; title=&#34;Samples for NDVI band for Cerrado class&#34; alt=&#34;Samples for NDVI band for Cerrado class&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;h2&gt;Time Series Clustering and Filtering&lt;/h2&gt; &#xA;&lt;h3&gt;Clustering for sample quality control&lt;/h3&gt; &#xA;&lt;p&gt;Clustering methods in &lt;code&gt;sits&lt;/code&gt; improve the quality of the samples and to remove those that might have been wrongly labeled or that have low discriminatory power. Good samples lead to good classification maps. &lt;code&gt;sits&lt;/code&gt; provides support for sample quality control using Self-organizing Maps (SOM). The process of clustering with SOM is done by &lt;code&gt;sits_som_map()&lt;/code&gt;, which creates a self-organizing map and assesses the quality of the samples.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# load the kohonen library&#xA;library(kohonen)&#xA;# create a SOM map from the samples&#xA;som_map &amp;lt;- sits_som_map(samples_modis_ndvi,&#xA;                        grid_xdim = 6,&#xA;                        grid_ydim = 6)&#xA;# plot the map&#xA;plot(som_map)&#xA;#&amp;gt; Warning in par(opar): argument 1 does not name a graphical parameter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/e-sensing/sits/master/man/figures/README-unnamed-chunk-11-1.png&#34; title=&#34;Samples analysis using SOM (grid 6x6)&#34; alt=&#34;Samples analysis using SOM (grid 6x6)&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;p&gt;This function uses the &lt;a href=&#34;https://www.jstatsoft.org/article/view/v087i07&#34;&gt;“kohonen” R package&lt;/a&gt; to compute a SOM grid [7]. Each sample is assigned to a neuron, and neurons are placed in the grid based on similarity. Each neuron will be associated with a discrete probability distribution. Homogeneous neurons (those with a single class) are assumed to be composed of good quality samples. Heterogeneous neurons (those with two or more classes with significant probability) are likely to contain noisy samples. Noisy samples can then be identified and removed from the sample set using &lt;code&gt;sits_som_clean_samples()&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# create a new sample set removing noisy points&#xA;new_samples &amp;lt;- sits_som_clean_samples(som_map)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Filtering&lt;/h3&gt; &#xA;&lt;p&gt;Satellite image time series are contaminated by atmospheric influence and directional effects. To make the best use of available satellite data archives, methods for satellite image time series analysis need to deal with data sets that are &lt;em&gt;noisy&lt;/em&gt; and &lt;em&gt;non-homogeneous&lt;/em&gt;. For data filtering, &lt;code&gt;sits&lt;/code&gt; supports Savitzky–Golay (&lt;code&gt;sits_sgolay()&lt;/code&gt;) and Whittaker (&lt;code&gt;sits_whittaker()&lt;/code&gt;) filters. As an example, we show how to apply the Whittaker smoother to a 16-year NDVI time series.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# apply Whitaker filter to a time series sample for the NDVI band from 2000 to 2016&#xA;# merge with the original data&#xA;# plot the original and the modified series&#xA;point_ndvi &amp;lt;- sits_select(point_mt_6bands, bands = &#34;NDVI&#34;)&#xA;point_ndvi %&amp;gt;% &#xA;    sits_filter(sits_whittaker(lambda = 10)) %&amp;gt;% &#xA;    sits_merge(point_ndvi) %&amp;gt;% &#xA;    plot()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/e-sensing/sits/master/man/figures/README-unnamed-chunk-13-1.png&#34; title=&#34;Whittaker filter of NDVI time series&#34; alt=&#34;Whittaker filter of NDVI time series&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;h2&gt;Time Series Classification&lt;/h2&gt; &#xA;&lt;h3&gt;Training Machine Learning Models&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;sits&lt;/code&gt; provides support for the classification of both individual time series as well as data cubes. The following machine learning methods are available in &lt;code&gt;sits&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support vector machines (&lt;code&gt;sits_svm()&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Random forests (&lt;code&gt;sits_rfor()&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Extreme gradient boosting (&lt;code&gt;sits_xgboost()&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Multi-layer perceptrons (&lt;code&gt;sits_mlp()&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Deep Residual Networks (&lt;code&gt;sits_resnet()&lt;/code&gt;) (see ref. [8])&lt;/li&gt; &#xA; &lt;li&gt;1D convolution neural networks (&lt;code&gt;sits_tempcnn()&lt;/code&gt;) (see ref. [9])&lt;/li&gt; &#xA; &lt;li&gt;Temporal self-attention encoder (&lt;code&gt;sits_tae()&lt;/code&gt;) (see ref. [10])&lt;/li&gt; &#xA; &lt;li&gt;Lightweight temporal attention encoder (&lt;code&gt;sits_lighttae()&lt;/code&gt;) (see ref. [11] and [12])&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following example illustrate how to train a dataset and classify an individual time series. First we use the &lt;code&gt;sits_train()&lt;/code&gt; function with two parameters: the training dataset (described above) and the chosen machine learning model (in this case, TempCNN). The trained model is then used to classify a time series from Mato Grosso Brazilian state, using &lt;code&gt;sits_classify()&lt;/code&gt;. The results can be shown in text format using the function &lt;code&gt;sits_show_prediction()&lt;/code&gt; or graphically using &lt;code&gt;plot&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# training data set&#xA;data(&#34;samples_modis_ndvi&#34;)&#xA;# point to be classified&#xA;data(&#34;point_mt_6bands&#34;)&#xA;# Train a deep learning model&#xA;tempcnn_model &amp;lt;- sits_train(samples_modis_ndvi, ml_method = sits_tempcnn()) &#xA;# Select NDVI band of the  point to be classified&#xA;# Classify using TempCNN model&#xA;# Plot the result&#xA;point_mt_6bands %&amp;gt;% &#xA;  sits_select(bands = &#34;NDVI&#34;) %&amp;gt;% &#xA;  sits_classify(tempcnn_model) %&amp;gt;% &#xA;  plot()&#xA;#&amp;gt;   |                                                                              |                                                                      |   0%  |                                                                              |===================================                                   |  50%  |                                                                              |======================================================================| 100%&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/e-sensing/sits/master/man/figures/README-unnamed-chunk-14-1.png&#34; title=&#34;Classification of NDVI time series using TempCNN&#34; alt=&#34;Classification of NDVI time series using TempCNN&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;p&gt;The following example shows how to classify a data cube organized as a set of raster images. The result can also be visualized interactively using &lt;code&gt;sits_view()&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a data cube to be classified&#xA;# Cube is composed of MOD13Q1 images from the Sinop region in Mato Grosso (Brazil)&#xA;data_dir &amp;lt;- system.file(&#34;extdata/raster/mod13q1&#34;, package = &#34;sits&#34;)&#xA;sinop &amp;lt;- sits_cube(&#xA;    source = &#34;BDC&#34;,&#xA;    collection = &#34;MOD13Q1-6&#34;,&#xA;    data_dir = data_dir,&#xA;    delim = &#34;_&#34;,&#xA;    parse_info = c(&#34;X1&#34;, &#34;tile&#34;, &#34;band&#34;, &#34;date&#34;),&#xA;    progress = FALSE&#xA;)&#xA;# Classify the raster cube, generating a probability file&#xA;# Filter the pixels in the cube to remove noise&#xA;probs_cube &amp;lt;- sits_classify(sinop, ml_model = tempcnn_model)&#xA;#&amp;gt; Using blocks of size (144 x 254)&#xA;#&amp;gt; Starting classification of tile &#39;h12v10&#39; at 2023-01-17 21:49:40&#xA;#&amp;gt;   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%&#xA;#&amp;gt; Tile &#39;h12v10&#39; finished at 2023-01-17 21:50:30&#xA;#&amp;gt; Elapsed time of 49.46 secs&#xA;#&amp;gt; &#xA;#&amp;gt; &#xA;#&amp;gt; Classification finished at 2023-01-17 21:50:30&#xA;#&amp;gt; Elapsed time of 49.46 secs&#xA;# apply a bayesian smoothing to remove outliers&#xA;bayes_cube &amp;lt;- sits_smooth(probs_cube)&#xA;# generate a thematic map&#xA;label_cube &amp;lt;- sits_label_classification(bayes_cube)&#xA;# plot the the labelled cube&#xA;plot(label_cube, title = &#34;Land use and Land cover in Sinop, MT, Brazil in 2018&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/e-sensing/sits/master/man/figures/README-unnamed-chunk-15-1.png&#34; title=&#34;Land use and Land cover in Sinop, MT, Brazil in 2018&#34; alt=&#34;Land use and Land cover in Sinop, MT, Brazil in 2018&#34; style=&#34;display: block; margin: auto;&#34;&gt; &#xA;&lt;h2&gt;Additional information&lt;/h2&gt; &#xA;&lt;p&gt;For more information, please see the on-line book &lt;a href=&#34;https://e-sensing.github.io/sitsbook/&#34;&gt;“SITS: Data analysis and machine learning for data cubes using satellite image time series”&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;References&lt;/h3&gt; &#xA;&lt;h4&gt;Citable papers for sits&lt;/h4&gt; &#xA;&lt;p&gt;If you use &lt;code&gt;sits&lt;/code&gt;, please cite the following paper:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[1] Rolf Simoes, Gilberto Camara, Gilberto Queiroz, Felipe Souza, Pedro R. Andrade, Lorena Santos, Alexandre Carvalho, and Karine Ferreira. “Satellite Image Time Series Analysis for Big Earth Observation Data”. Remote Sensing, 13: 2428, 2021. &lt;a href=&#34;doi:10.3390/rs13132428&#34;&gt;doi:10.3390/rs13132428&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Additionally, the sample quality control methods that use self-organized maps are described in the following reference:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2] Lorena Santos, Karine Ferreira, Gilberto Camara, Michelle Picoli, Rolf Simoes, “Quality control and class noise reduction of satellite image time series”. ISPRS Journal of Photogrammetry and Remote Sensing, 177:75-88, 2021. &lt;a href=&#34;doi:10.1016/j.isprsjprs.2021.04.014&#34;&gt;doi:10.1016/j.isprsjprs.2021.04.014&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Papers that use sits to produce LUCC maps&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[3] Rolf Simoes, Michelle Picoli, et al., “Land use and cover maps for Mato Grosso State in Brazil from 2001 to 2017”. Sci Data 7(34), 2020. &lt;a href=&#34;doi:10.1038/s41597-020-0371-4&#34;&gt;doi:10.1038/s41597-020-0371-4&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[4] Michelle Picoli, Gilberto Camara, et al., “Big Earth Observation Time Series Analysis for Monitoring Brazilian Agriculture”. ISPRS Journal of Photogrammetry and Remote Sensing, 2018. &lt;a href=&#34;doi:10.1016/j.isprsjprs.2018.08.007&#34;&gt;doi:10.1016/j.isprsjprs.2018.08.007&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[5] Karine Ferreira, Gilberto Queiroz et al., “Earth Observation Data Cubes for Brazil: Requirements, Methodology and Products”. Remote Sens. 12:4033, 2020. &lt;a href=&#34;doi:10.3390/rs12244033&#34;&gt;doi:10.3390/rs12244033&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Papers that describe software used in sits&lt;/h4&gt; &#xA;&lt;p&gt;We thank the authors of these papers for making their code available to be used in connection with sits.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[6] Marius Appel and Edzer Pebesma, “On-Demand Processing of Data Cubes from Satellite Image Collections with the Gdalcubes Library.” Data 4 (3): 1–16, 2020. &lt;a href=&#34;doi:10.3390/data4030092&#34;&gt;doi:10.3390/data4030092&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[7] Ron Wehrens and Johannes Kruisselbrink, “Flexible Self-Organising Maps in kohonen 3.0”. Journal of Statistical Software, 87(7), 2018. &lt;a href=&#34;doi:10.18637/jss.v087.i07&#34;&gt;doi:10.18637/jss.v087.i07&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[8] Hassan Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and Pierre-Alain Muller, “Deep learning for time series classification: a review”. Data Mining and Knowledge Discovery, 33(4): 917–963, 2019. &amp;lt;arxiv:1809.04356&amp;gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[9] Charlotte Pelletier, Geoffrey I. Webb, and Francois Petitjean. “Temporal Convolutional Neural Network for the Classification of Satellite Image Time Series.” Remote Sensing 11 (5), 2019. &lt;a href=&#34;doi:10.3390/rs11050523&#34;&gt;doi:10.3390/rs11050523&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[10] Vivien Garnot, Loic Landrieu, Sebastien Giordano, and Nesrine Chehata, “Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention”, Conference on Computer Vision and Pattern Recognition, 2020. &amp;lt;doi: 10.1109/CVPR42600.2020.01234&amp;gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[11] Vivien Garnot, Loic Landrieu, “Lightweight Temporal Self-Attention for Classifying Satellite Images Time Series”, 2020. &amp;lt;arXiv:2007.00586&amp;gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[12] Maja Schneider, Marco Körner, “[Re] Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention.” ReScience C 7 (2), 2021. &lt;a href=&#34;doi:10.5281/zenodo.4835356&#34;&gt;doi:10.5281/zenodo.4835356&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;R packages used in sits&lt;/h4&gt; &#xA;&lt;p&gt;The authors are thankful for the contributions of Marius Appel, Tim Appelhans, Henrik Bengtsson, Robert Hijmans, Edzer Pebesma, and Ron Wehrens, respectively chief developers of the packages &lt;code&gt;gdalcubes&lt;/code&gt;, &lt;code&gt;leafem&lt;/code&gt;, &lt;code&gt;data.table&lt;/code&gt;, &lt;code&gt;terra/raster&lt;/code&gt;, &lt;code&gt;sf&lt;/code&gt;/&lt;code&gt;stars&lt;/code&gt;, and &lt;code&gt;kohonen&lt;/code&gt;. The &lt;code&gt;sits&lt;/code&gt; package is also much indebted to the work of the RStudio team, including the &lt;code&gt;tidyverse&lt;/code&gt;. We are indepted to Daniel Falbel for his and the &lt;code&gt;torch&lt;/code&gt; packages. We thank Charlotte Pelletier and Hassan Fawaz for sharing the python code that has been reused for the TempCNN and ResNet machine learning models. We would like to thank Maja Schneider for sharing the python code that helped the implementation of the &lt;code&gt;sits_lighttae()&lt;/code&gt; and &lt;code&gt;sits_tae()&lt;/code&gt; model. We recognise the importance of the work by Chris Holmes and Mattias Mohr on the STAC specification and API.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements for Financial and Material Support&lt;/h2&gt; &#xA;&lt;p&gt;We acknowledge and thank the project funders that provided financial and material support:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Amazon Fund, established by the Brazilian government with financial contribution from Norway, through the project contract between the Brazilian Development Bank (BNDES) and the Foundation for Science, Technology and Space Applications (FUNCATE), for the establishment of the Brazil Data Cube, process 17.2.0536.1.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES) and from the Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq), for providing MSc and PhD scholarships.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Sao Paulo Research Foundation (FAPESP) under eScience Program grant 2014/08398-6, for for providing MSc, PhD and post-doc scholarships, equipment, and travel support.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;International Climate Initiative of the Germany Federal Ministry for the Environment, Nature Conservation, Building and Nuclear Safety (IKI) under grant 17-III-084- Global-A-RESTORE+ (“RESTORE+: Addressing Landscape Restoration on Degraded Land in Indonesia and Brazil”).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Microsoft Planetary Computer under the GEO-Microsoft Cloud Computer Grants Programme.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The Open-Earth-Monitor Cyberinfrastructure project, which has received funding from the European Union’s Horizon Europe research and innovation programme under &lt;a href=&#34;https://cordis.europa.eu/project/id/101059548&#34;&gt;grant agreement No.&amp;nbsp;101059548&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;How to contribute&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;sits&lt;/code&gt; project is released with a &lt;a href=&#34;https://github.com/e-sensing/sits/raw/master/CODE_OF_CONDUCT.md&#34;&gt;Contributor Code of Conduct&lt;/a&gt;. By contributing to this project, you agree to abide by its terms.&lt;/p&gt;</summary>
  </entry>
</feed>