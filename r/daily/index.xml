<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-17T01:32:09Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>moj-analytical-services/Rdbtools</title>
    <updated>2024-05-17T01:32:09Z</updated>
    <id>tag:github.com,2024-05-17:/moj-analytical-services/Rdbtools</id>
    <link href="https://github.com/moj-analytical-services/Rdbtools" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Accessing Athena on the Analytical Platform&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Rdbtools&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note that this is not officially supported by the AP team and is intended to be community supported.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Rdbtools?&lt;/h2&gt; &#xA;&lt;p&gt;This is an extension of the &lt;code&gt;noctua&lt;/code&gt; package, for interacting with AWS Athena through the MoJ&#39;s analytical platform. See &lt;a href=&#34;https://dyfanjones.github.io/noctua/reference/index.html&#34;&gt;https://dyfanjones.github.io/noctua/reference/index.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The primary purpose of this package is to easily allow MoJ analysts to access data on Athena, without having to understand anything about the underlying authentication systems. This access is provided through the R database interface &lt;a href=&#34;https://dbi.r-dbi.org/&#34;&gt;&lt;code&gt;DBI&lt;/code&gt;&lt;/a&gt;, and so works with the standard database functions used in R. It also works with &lt;a href=&#34;https://dbplyr.tidyverse.org/&#34;&gt;&lt;code&gt;dbplyr&lt;/code&gt;&lt;/a&gt;, which is an extention of &lt;code&gt;dplyr&lt;/code&gt; allowing you to use familiar tidyverse functions on data in Athena itself (reducing the need for large data pre-processing steps in R, and without having to learn SQL).&lt;/p&gt; &#xA;&lt;p&gt;In addition, this package extends the methods defined in the noctua package to allow users easy access to a safe temporary database for intermediate processing steps.&lt;/p&gt; &#xA;&lt;p&gt;The secondary purpose of this package is to provide backwards compatability with &lt;code&gt;dbtools&lt;/code&gt; which does not work on the new AP infrastructure. For this the package provides a few convenience functions for MoJ users. The key difference with this package over &lt;code&gt;dbtools&lt;/code&gt; is that it is implemented all in R and doesn&#39;t require a Python dependency.&lt;/p&gt; &#xA;&lt;h3&gt;Installing Rdbtools&lt;/h3&gt; &#xA;&lt;p&gt;Then install Rdbtools with one of the the following commands:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If using renv: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;install &lt;code&gt;Rdbtools&lt;/code&gt;: &lt;code&gt;renv::install(&#34;moj-analytical-services/Rdbtools&#34;)&lt;/code&gt; or if that doesn&#39;t work try &lt;code&gt;renv::install(&#34;git@github.com:moj-analytical-services/Rdbtools.git&#34;)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If not using renv: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;install &lt;code&gt;Rdbtools&lt;/code&gt;: &lt;code&gt;devtools::install_github(&#34;moj-analytical-services/Rdbtools&#34;)&lt;/code&gt; (you may need to install devtools first)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can use the same command to update the package, if it is changed on Github later.&lt;/p&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;h3&gt;Basic connecting a session and querying&lt;/h3&gt; &#xA;&lt;h4&gt;With SQL commands (using DBI)&lt;/h4&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://dyfanjones.github.io/noctua/reference/index.html&#34;&gt;https://dyfanjones.github.io/noctua/reference/index.html&lt;/a&gt; for the full list of functions you can call to interact with Athena.&lt;/p&gt; &#xA;&lt;p&gt;To query a database, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;library(Rdbtools)&#xA;con &amp;lt;- connect_athena() # creates a connection with sensible defaults&#xA;data &amp;lt;- dbGetQuery(con, &#34;SELECT * FROM database.table&#34;) # queries and puts data in R environment&#xA;dbDisconnect(con) # disconnects the connection&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Using dbplyr&lt;/h4&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://dbplyr.tidyverse.org/index.html&#34;&gt;https://dbplyr.tidyverse.org/index.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;As an example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;library(tidyverse)&#xA;library(dbplyr)&#xA;library(Rdbtools)&#xA;&#xA;con &amp;lt;- connect_athena()&#xA;datadb &amp;lt;- tbl(con, sql(&#34;select * from database.name&#34;)) # create the dbplyr link&#xA;# use dplyr as usual on this dataframe link&#xA;datadb %&amp;gt;%&#xA;  filter(size &amp;lt; 10) %&amp;gt;%&#xA;  group_by() %&amp;gt;%&#xA;  summarise(n = n(),&#xA;            total = sum(total))&#xA;&#xA;dbDisconnect(con) # disconnects the connection&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that if you need any function within dbplyr which does a copy (e.g. joining a local table to a remote table) then you need to ensure you have the right permissions for the staging directory you are using. See the help page for &lt;code&gt;dbWriteTable&lt;/code&gt; by running &lt;code&gt;?dbWriteTable&lt;/code&gt; in the console.&lt;/p&gt; &#xA;&lt;h3&gt;The temporary database&lt;/h3&gt; &#xA;&lt;p&gt;Each user can have a database which can store temporary tables.&lt;/p&gt; &#xA;&lt;p&gt;Note that the tables created here will have their underlying data stored in the default staging directory (which is different for each new connection) or that specified by the staging directory argument (which will remain the same for each new connection). The permissions of the staging directory will determine who can access the data in the temporary tables.&lt;/p&gt; &#xA;&lt;h4&gt;With SQL commands (using DBI)&lt;/h4&gt; &#xA;&lt;p&gt;Wherever you put the special string &lt;code&gt;__temp__&lt;/code&gt; in SQL commands then this will refer to a database which is specific to your user and where you can write temporary tables before you read them out. This works with the DBI functions (which are updated in this package for connections made via &lt;code&gt;connect_athena()&lt;/code&gt;) and the convenience functions (e.g. &lt;code&gt;read_sql()&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;library(Rdbtools)&#xA;con &amp;lt;- connect_athena() # creates a connection with sensible defaults&#xA;dbExecute(con, &#34;CREATE TABLE __temp__.name AS SELECT * FROM database.table&#34;) # queries and puts in temp space&#xA;data &amp;lt;- dbGetQuery(con, &#34;SELECT * FROM __temp__.name&#34;) # queries and puts data in R environment&#xA;dbDisconnect(con) # disconnects the connection&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;__temp__&lt;/code&gt; string substitution is implemented for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;dbGetQuery&lt;/li&gt; &#xA; &lt;li&gt;dbExecute&lt;/li&gt; &#xA; &lt;li&gt;dbGetTables&lt;/li&gt; &#xA; &lt;li&gt;dbListTables&lt;/li&gt; &#xA; &lt;li&gt;dbExistsTable&lt;/li&gt; &#xA; &lt;li&gt;dbListFields&lt;/li&gt; &#xA; &lt;li&gt;dbRemoveTable&lt;/li&gt; &#xA; &lt;li&gt;dbWriteTable (but note the permission issue in the help for this function by running &lt;code&gt;?dbWriteTable&lt;/code&gt; in the console)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If there are further noctua/DBI function where the &lt;code&gt;__temp__&lt;/code&gt; string substitution would be useful then open up an issue or pull request and the Rdbtools community can try and arrange an implementation.&lt;/p&gt; &#xA;&lt;h4&gt;Using dbplyr (or other packages)&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;__temp__&lt;/code&gt; string is not understood by dbplyr functions, so to use the temporary database for this or other packages you have two options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;When creating the connection, you can specify the temporary database as the default schema: &lt;code&gt;connect_athena(schema_name = &#34;__temp__&#34;)&lt;/code&gt;. In this case dbplyr commands which do not specify a database will default to the temporary database (e.g. then &lt;code&gt;compute(&#34;temp_tbl&#34;))&lt;/code&gt; at the end of a dbplyr chain will create a table in the temporary database with the name &#34;temp_tbl&#34;).&lt;/li&gt; &#xA; &lt;li&gt;Alternatively, the &lt;code&gt;athena_temp_db&lt;/code&gt; function will return a string with the name of the temporary database if required to manually create specific SQL commands, or in use in other functions not listed above.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The temporary database is the same each way, so you can mix dbplyr, DBI, and other packages in the same code.&lt;/p&gt; &#xA;&lt;h2&gt;Advanced use&lt;/h2&gt; &#xA;&lt;h3&gt;The connection object&lt;/h3&gt; &#xA;&lt;p&gt;The connection object returned by &lt;code&gt;connect_athena()&lt;/code&gt; contains all the information about a single authenticated session which allows access to the databases for which you have permission. By default the authenticated session will last for one hour, after which you will have to create a new connection or else refresh your connection. For most purposes creating a new connection will be sufficient, however you will lose access to any tables created in the &lt;code&gt;__temp__&lt;/code&gt; database (as these are only accessible under the same session). To refresh a connection, please use the &lt;code&gt;refresh_athena_connection()&lt;/code&gt; function, or in a long script the &lt;code&gt;refresh_if_expired()&lt;/code&gt; function may also be useful (see the help pages in RStudio for further details of these functions).&lt;/p&gt; &#xA;&lt;h3&gt;The region argument when creating connection object&lt;/h3&gt; &#xA;&lt;p&gt;The region passed into the connect_athena() will be used for&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Get temporary token for connecting athena service&lt;/li&gt; &#xA; &lt;li&gt;Run the query and store the query result to the staging dir&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In order to run the query successfully, the region need to the region where the query will be run and query result will be stored in the staging dir. You can pass the value based on your case when calling connect_athena(), by default, the region will be decided based on serveral environment variables below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;AWS_ATHENA_QUERY_REGION&lt;/code&gt;: An environment variable for specifying the region when the region where the query will be run is different from the default region from underlying running environment.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;AWS_DEFAULT_REGION&lt;/code&gt; and &lt;code&gt;AWS_REGION&lt;/code&gt;: The default region which usually will be setup by the underlying running environment e.g. cluster, and they cannot be amended&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;othewise use &lt;code&gt;eu-west-1&lt;/code&gt; as the default&lt;/p&gt; &#xA;&lt;p&gt;In most cases, you do not need to worry about the region, the default region (&lt;code&gt;AWS_DEFAULT_REGION&lt;/code&gt; and &lt;code&gt;AWS_REGION&lt;/code&gt;) should be the one for running query and the one where your staging dir is. When there is cross-region situation in your runnning environment and you want to save the time for passing the region every time when creating connection, you can use the &lt;code&gt;AWS_ATHENA_QUERY_REGION&lt;/code&gt; to specify it.&lt;/p&gt; &#xA;&lt;h2&gt;Single queries (deprecated)&lt;/h2&gt; &#xA;&lt;p&gt;The function &lt;code&gt;read_sql&lt;/code&gt; is provided which replicates the same function from &lt;code&gt;dbtools&lt;/code&gt; - this is kept for backwards compatibility only. This creates a database connection, reads the data and then closes the connection every call. If you want to do more than one call to Athena the method below is probably better. Also note that since authentication has moved to WebIdentity then any new temporary tables created under one connection will only be accessible by that same connection, so &lt;code&gt;read_sql&lt;/code&gt; cannot be used to read a table created by a another function unless the relevant connection object is supplied to the &lt;code&gt;con&lt;/code&gt; argument (this is different to previous usage of &lt;code&gt;read_sql&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>complexityatgmu/Rcodes</title>
    <updated>2024-05-17T01:32:09Z</updated>
    <id>tag:github.com,2024-05-17:/complexityatgmu/Rcodes</id>
    <link href="https://github.com/complexityatgmu/Rcodes" rel="alternate"></link>
    <summary type="html">&lt;p&gt;codes in R for DATA analysis&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Rcodes&lt;/h1&gt; &#xA;&lt;p&gt;codes in R for DATA analysis&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>CU-ESIIL/Innovation-Summit-2024__3_Biodiversity-resilience-to-climate-change</title>
    <updated>2024-05-17T01:32:09Z</updated>
    <id>tag:github.com,2024-05-17:/CU-ESIIL/Innovation-Summit-2024__3_Biodiversity-resilience-to-climate-change</id>
    <link href="https://github.com/CU-ESIIL/Innovation-Summit-2024__3_Biodiversity-resilience-to-climate-change" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://zenodo.org/doi/10.5281/zenodo.11189031&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/800243545.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Blip Hunterz&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to the &lt;strong&gt;Blip Hunterz&lt;/strong&gt; repository, an integral part of ESIIL&#39;s 2024 Innovation Summit focused on big data for resilience and adaptation. This repository is the central hub for our team, encompassing our project overview, team member information, codebase, and more...&lt;/p&gt; &#xA;&lt;h2&gt;Our Project&lt;/h2&gt; &#xA;&lt;p&gt;Our project aims to leverage long-term ecological data to better understand how climate change affects biological resilience across ecosystems. Insights provided by that data can then be used to inform decision-making around ecological restoration with the aim of increasing resilience in those ecosystems.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Access detailed documentation on our &lt;a href=&#34;https://your-gh-pages-url/&#34;&gt;GitHub Pages site&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1LPJUvmWBSLU5qyfaJVbn79pPDJAXgBMcKxNk6fTjSoQ/edit?usp=sharing&#34;&gt;ESIIL Meeting Report out Presentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Group Members&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Jen Kovacs: Associate Professor of Biology, Agnes Scott College, Evolutionary Ecologist, read more about my work &lt;a href=&#34;https://jkovacs.agnesscott.org/&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Greg Maurer: Environmental data scientist &amp;amp; data manager, New Mexico State University. &lt;a href=&#34;https://greg.pronghorns.net&#34;&gt;more here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Julia Portmann: Data research associate, Yale University Map of Life.&lt;/li&gt; &#xA; &lt;li&gt;Eric Sokol: Quantitative Ecologist at the National Ecological Observatory Network (&lt;a href=&#34;https://www.neonscience.org/&#34;&gt;NEON&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Trifosa Simamora&lt;/li&gt; &#xA; &lt;li&gt;Thilina Surasinge&lt;/li&gt; &#xA; &lt;li&gt;Andrew Quitmeyer: Director, &lt;a href=&#34;https://www.dinalab.net/&#34;&gt;Digital Naturalism Labs&lt;/a&gt;, Gamboa, Panama. Build open source tools for field biologists.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Code Repository Structure&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Data Processing&lt;/strong&gt;: Scripts for cleaning, merging, and managing datasets.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Analysis Code&lt;/strong&gt;: Scripts for data analysis, statistical modeling, etc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Visualization&lt;/strong&gt;: Code for creating figures, charts, and interactive visualizations.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Meeting Notes and Agendas&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Regular updates to keep all group members informed and engaged with the project&#39;s progress and direction.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/CU-ESIIL/Innovation-Summit-2024__3_Biodiversity-resilience-to-climate-change/main/docs/day_2_notes.md&#34;&gt;Day 2 notes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/CU-ESIIL/Innovation-Summit-2024__3_Biodiversity-resilience-to-climate-change/main/docs/day_3_notes.md&#34;&gt;Day 3 notes&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing to This Repository&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Contributions from all group members are welcome.&lt;/li&gt; &#xA; &lt;li&gt;Please adhere to these guidelines: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Ensure commits have clear and concise messages.&lt;/li&gt; &#xA;   &lt;li&gt;Document major changes in the meeting notes.&lt;/li&gt; &#xA;   &lt;li&gt;Review and merge changes through pull requests for oversight.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Help&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you encounter any issues or have questions, please refer to the &lt;a href=&#34;https://esiil-support-page-url/&#34;&gt;ESIIL Support Page&lt;/a&gt; or contact the repository maintainers directly.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Customize Your Repository&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Edit This Readme&lt;/strong&gt;: Update with information specific to your project.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Update Group Member Bios&lt;/strong&gt;: Add detailed information about each group member&#39;s expertise and role.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Organize Your Code&lt;/strong&gt;: Use logical structure and clear naming conventions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Document Your Data&lt;/strong&gt;: Include a data directory with README files for datasets.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Outline Your Methods&lt;/strong&gt;: Create a METHODS.md file for methodologies and tools.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Set Up Project Management&lt;/strong&gt;: Use &#39;Issues&#39; and &#39;Projects&#39; for task tracking.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Add a License&lt;/strong&gt;: Include an appropriate open-source license.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Create Contribution Guidelines&lt;/strong&gt;: Establish a CONTRIBUTING.md file.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Review and Merge Workflow&lt;/strong&gt;: Document your process for reviewing and merging changes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Establish Communication Channels&lt;/strong&gt;: Set up channels like Slack or Discord for discussions.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Remember, the goal is to make your repository clear, accessible, and useful for all current and future researchers. Happy researching!&lt;/p&gt;</summary>
  </entry>
</feed>