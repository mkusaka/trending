<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-14T01:35:41Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mlr-org/mlr3pipelines</title>
    <updated>2024-08-14T01:35:41Z</updated>
    <id>tag:github.com,2024-08-14:/mlr-org/mlr3pipelines</id>
    <link href="https://github.com/mlr-org/mlr3pipelines" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Dataflow Programming for Machine Learning in R&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;mlr3pipelines &lt;img src=&#34;https://raw.githubusercontent.com/mlr-org/mlr3pipelines/master/man/figures/logo.png&#34; align=&#34;right&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Package website: &lt;a href=&#34;https://mlr3pipelines.mlr-org.com/&#34;&gt;release&lt;/a&gt; | &lt;a href=&#34;https://mlr3pipelines.mlr-org.com/dev/&#34;&gt;dev&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Dataflow Programming for Machine Learning in R.&lt;/p&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mlr-org/mlr3pipelines/actions/workflows/r-cmd-check.yml&#34;&gt;&lt;img src=&#34;https://github.com/mlr-org/mlr3pipelines/actions/workflows/r-cmd-check.yml/badge.svg?sanitize=true&#34; alt=&#34;r-cmd-check&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cran.r-project.org/package=mlr3pipelines&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/mlr3pipelines&#34; alt=&#34;CRAN&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://stackoverflow.com/questions/tagged/mlr3&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/stackoverflow-mlr3-orange.svg?sanitize=true&#34; alt=&#34;StackOverflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/chat-mattermost-orange.svg?sanitize=true&#34; alt=&#34;Mattermost&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;h2&gt;What is &lt;code&gt;mlr3pipelines&lt;/code&gt;?&lt;/h2&gt; &#xA;&lt;p&gt;Watch our “WhyR 2020” Webinar Presentation on Youtube for an introduction! Find the slides &lt;a href=&#34;https://raw.githubusercontent.com/mlr-org/mlr-outreach/main/2020_whyr/slides.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4r8K3GO5wk4&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/4r8K3GO5wk4/0.jpg&#34; alt=&#34;WhyR 2020 mlr3pipelines&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;mlr3pipelines&lt;/code&gt;&lt;/strong&gt; is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Dataflow_programming&#34;&gt;dataflow programming&lt;/a&gt; toolkit for machine learning in R utilising the &lt;strong&gt;&lt;a href=&#34;https://github.com/mlr-org/mlr3&#34;&gt;mlr3&lt;/a&gt;&lt;/strong&gt; package. Machine learning workflows can be written as directed “Graphs” that represent data flows between preprocessing, model fitting, and ensemble learning units in an expressive and intuitive language. Using methods from the &lt;strong&gt;&lt;a href=&#34;https://github.com/mlr-org/mlr3tuning&#34;&gt;mlr3tuning&lt;/a&gt;&lt;/strong&gt; package, it is even possible to simultaneously optimize parameters of multiple processing units.&lt;/p&gt; &#xA;&lt;p&gt;In principle, &lt;em&gt;mlr3pipelines&lt;/em&gt; is about defining singular data and model manipulation steps as “PipeOps”:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pca        = po(&#34;pca&#34;)&#xA;filter     = po(&#34;filter&#34;, filter = mlr3filters::flt(&#34;variance&#34;), filter.frac = 0.5)&#xA;learner_po = po(&#34;learner&#34;, learner = lrn(&#34;classif.rpart&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;These pipeops can then be combined together to define machine learning pipelines. These can be wrapped in a &lt;code&gt;GraphLearner&lt;/code&gt; that behave like any other &lt;code&gt;Learner&lt;/code&gt; in &lt;code&gt;mlr3&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;graph = pca %&amp;gt;&amp;gt;% filter %&amp;gt;&amp;gt;% learner_po&#xA;glrn = GraphLearner$new(graph)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This learner can be used for resampling, benchmarking, and even tuning.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;resample(tsk(&#34;iris&#34;), glrn, rsmp(&#34;cv&#34;))&#xA;#&amp;gt; &amp;lt;ResampleResult&amp;gt; with 10 resampling iterations&#xA;#&amp;gt;  task_id                 learner_id resampling_id iteration warnings errors&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv         1        0      0&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv         2        0      0&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv         3        0      0&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv         4        0      0&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv         5        0      0&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv         6        0      0&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv         7        0      0&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv         8        0      0&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv         9        0      0&#xA;#&amp;gt;     iris pca.variance.classif.rpart            cv        10        0      0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Feature Overview&lt;/h2&gt; &#xA;&lt;p&gt;Single computational steps can be represented as so-called &lt;strong&gt;PipeOps&lt;/strong&gt;, which can then be connected with directed edges in a &lt;strong&gt;Graph&lt;/strong&gt;. The scope of &lt;em&gt;mlr3pipelines&lt;/em&gt; is still growing; currently supported features are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Simple data manipulation and preprocessing operations, e.g.&amp;nbsp;PCA, feature filtering&lt;/li&gt; &#xA; &lt;li&gt;Task subsampling for speed and outcome class imbalance handling&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;mlr3&lt;/em&gt; &lt;em&gt;Learner&lt;/em&gt; operations for prediction and stacking&lt;/li&gt; &#xA; &lt;li&gt;Simultaneous path branching (data going both ways)&lt;/li&gt; &#xA; &lt;li&gt;Alternative path branching (data going one specific way, controlled by hyperparameters)&lt;/li&gt; &#xA; &lt;li&gt;Ensemble methods and aggregation of predictions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;A good way to get into &lt;code&gt;mlr3pipelines&lt;/code&gt; are the following two vignettes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mlr3book.mlr-org.com/chapters/chapter7/sequential_pipelines.html&#34;&gt;Sequential Pipelines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mlr3book.mlr-org.com/chapters/chapter8/non-sequential_pipelines_and_tuning.html&#34;&gt;Non-Sequential Pipelines and Tuning&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Bugs, Questions, Feedback&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;mlr3pipelines&lt;/em&gt; is a free and open source software project that encourages participation and feedback. If you have any issues, questions, suggestions or feedback, please do not hesitate to open an “issue” about it on the GitHub page!&lt;/p&gt; &#xA;&lt;p&gt;In case of problems / bugs, it is often helpful if you provide a “minimum working example” that showcases the behaviour (but don’t worry about this if the bug is obvious).&lt;/p&gt; &#xA;&lt;p&gt;Please understand that the resources of the project are limited: response may sometimes be delayed by a few days, and some feature suggestions may be rejected if they are deemed too tangential to the vision behind the project.&lt;/p&gt; &#xA;&lt;h2&gt;Citing mlr3pipelines&lt;/h2&gt; &#xA;&lt;p&gt;If you use mlr3pipelines, please cite our &lt;a href=&#34;https://jmlr.org/papers/v22/21-0281.html&#34;&gt;JMLR article&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@Article{mlr3pipelines,&#xA;  title = {{mlr3pipelines} - Flexible Machine Learning Pipelines in R},&#xA;  author = {Martin Binder and Florian Pfisterer and Michel Lang and Lennart Schneider and Lars Kotthoff and Bernd Bischl},&#xA;  journal = {Journal of Machine Learning Research},&#xA;  year = {2021},&#xA;  volume = {22},&#xA;  number = {184},&#xA;  pages = {1-7},&#xA;  url = {https://jmlr.org/papers/v22/21-0281.html},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Similar Projects&lt;/h2&gt; &#xA;&lt;p&gt;A predecessor to this package is the &lt;a href=&#34;https://github.com/mlr-org/mlrCPO&#34;&gt;&lt;em&gt;mlrCPO&lt;/em&gt;-package&lt;/a&gt;, which works with &lt;em&gt;mlr&lt;/em&gt; 2.x. Other packages that provide, to varying degree, some preprocessing functionality or machine learning domain specific language, are the &lt;em&gt;&lt;a href=&#34;https://github.com/topepo/caret&#34;&gt;caret&lt;/a&gt;&lt;/em&gt; package and the related &lt;em&gt;&lt;a href=&#34;https://recipes.tidymodels.org/&#34;&gt;recipes&lt;/a&gt;&lt;/em&gt; project, and the &lt;em&gt;&lt;a href=&#34;https://github.com/tidyverse/dplyr&#34;&gt;dplyr&lt;/a&gt;&lt;/em&gt; package.&lt;/p&gt;</summary>
  </entry>
</feed>