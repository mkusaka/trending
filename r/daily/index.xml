<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-19T01:37:59Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>epiforecasts/scoringutils</title>
    <updated>2024-02-19T01:37:59Z</updated>
    <id>tag:github.com,2024-02-19:/epiforecasts/scoringutils</id>
    <link href="https://github.com/epiforecasts/scoringutils" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Utilities for Scoring and Assessing Predictions&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;scoringutils: Utilities for Scoring and Assessing Predictions&lt;/h1&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/epiforecasts/scoringutils/actions/workflows/R-CMD-check.yaml&#34;&gt;&lt;img src=&#34;https://github.com/epiforecasts/scoringutils/actions/workflows/R-CMD-check.yaml/badge.svg?sanitize=true&#34; alt=&#34;R-CMD-check&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/epiforecasts/scoringutils&#34;&gt;&lt;img src=&#34;https://codecov.io/github/epiforecasts/scoringutils/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://CRAN.R-project.org/package=scoringutils&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version-ago/scoringutils&#34; alt=&#34;CRAN_Release_Badge&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/r-package/v/epiforecasts/scoringutils&#34; alt=&#34;GitHub R package version&#34;&gt; &lt;a href=&#34;https://cran.r-project.org/package=scoringutils&#34;&gt;&lt;img src=&#34;http://cranlogs.r-pkg.org/badges/grand-total/scoringutils&#34; alt=&#34;metacran downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;a href=&#34;https://epiforecasts.io/scoringutils/dev&#34;&gt;This documentation&lt;/a&gt; refers to the development version of &lt;code&gt;scoringutils&lt;/code&gt;. You can also view the &lt;a href=&#34;https://epiforecasts.io/scoringutils&#34;&gt;documentation of the stable version&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;scoringutils&lt;/code&gt; package provides a collection of metrics and proper scoring rules and aims to make it simple to score probabilistic forecasts against observed values.&lt;/p&gt; &#xA;&lt;p&gt;A good starting point for those wishing to use &lt;code&gt;scoringutils&lt;/code&gt; are the vignettes on &lt;a href=&#34;https://epiforecasts.io/scoringutils/articles/scoringutils.html&#34;&gt;Getting started&lt;/a&gt;, &lt;a href=&#34;https://epiforecasts.io/scoringutils/articles/metric-details.html&#34;&gt;Details on the metrics implemented&lt;/a&gt; and &lt;a href=&#34;https://epiforecasts.io/scoringutils/articles/scoring-forecasts-directly.html&#34;&gt;Scoring forecasts directly&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For a detailed description of the package, its rationale and design, usage examples and how it relates to other packages in the R ecosystem, please see the corresponding paper:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Nikos I. Bosse, Hugo Gruson, Anne Cori, Edwin van Leeuwen, Sebastian Funk and Sam Abbott (2022). &lt;em&gt;&lt;code&gt;Evaluating Forecasts with scoringutils in R&lt;/code&gt;&lt;/em&gt;. arXiv:2205.07090 &lt;a href=&#34;https://doi.org/10.48550/arXiv.2205.07090&#34;&gt;https://doi.org/10.48550/arXiv.2205.07090&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;For further details on the specific issue of transforming forecasts for scoring see:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Nikos I. Bosse, Sam Abbott, Anne Cori, Edwin van Leeuwen, Johannes Bracher* and Sebastian Funk* (*: equal contribution) (2023). &lt;em&gt;&lt;code&gt;Scoring epidemiological forecasts on transformed scales&lt;/code&gt;&lt;/em&gt;, PLoS Comput Biol 19(8): e1011393 &lt;a href=&#34;https://doi.org/10.1371/journal.pcbi.1011393&#34;&gt;https://doi.org/10.1371/journal.pcbi.1011393&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Package overview&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;scoringutils&lt;/code&gt; package offers convenient automated forecast evaluation through the function &lt;code&gt;score()&lt;/code&gt;. The function operates on data.frames (it uses &lt;code&gt;data.table&lt;/code&gt; internally for speed and efficiency) and can easily be integrated in a workflow based on &lt;code&gt;dplyr&lt;/code&gt; or &lt;code&gt;data.table&lt;/code&gt;. It also provides experienced users with a set of reliable lower-level scoring metrics operating on vectors/matrices they can build upon in other applications. In addition it implements a wide range of flexible plots designed to cover many use cases.&lt;/p&gt; &#xA;&lt;p&gt;Where available &lt;code&gt;scoringutils&lt;/code&gt; depends on functionality from &lt;code&gt;scoringRules&lt;/code&gt; which provides a comprehensive collection of proper scoring rules for predictive probability distributions represented as sample or parametric distributions. For some forecast types, such as quantile forecasts, &lt;code&gt;scoringutils&lt;/code&gt; also implements additional metrics for evaluating forecasts. On top of providing an interface to the proper scoring rules implemented in &lt;code&gt;scoringRules&lt;/code&gt; and natively, &lt;code&gt;scoringutils&lt;/code&gt; also offers utilities for summarising and visualising forecasts and scores, and to obtain relative scores between models which may be useful for non-overlapping forecasts and forecasts across scales.&lt;/p&gt; &#xA;&lt;p&gt;Predictions can be handled in various formats: &lt;code&gt;scoringutils&lt;/code&gt; can handle probabilistic forecasts in either a sample based or a quantile based format. For more detail on the expected input formats please see below. True values can be integer, continuous or binary, and appropriate scores for each of these value types are selected automatically.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Install the CRAN version of this package using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;scoringutils&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install the stable development version of the package with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;scoringutils&#34;, repos = &#34;https://epiforecasts.r-universe.dev&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install the unstable development from GitHub using the following,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;remotes::install_github(&#34;epiforecasts/scoringutils&#34;, dependencies = TRUE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;p&gt;In this quick start guide we explore some of the functionality of the &lt;code&gt;scoringutils&lt;/code&gt; package using quantile forecasts from the &lt;a href=&#34;https://covid19forecasthub.eu/&#34;&gt;ECDC forecasting hub&lt;/a&gt; as an example. For more detailed documentation please see the package vignettes, and individual function documentation.&lt;/p&gt; &#xA;&lt;h3&gt;Plotting forecasts&lt;/h3&gt; &#xA;&lt;p&gt;As a first step to evaluating the forecasts we visualise them. For the purposes of this example here we make use of &lt;code&gt;plot_predictions()&lt;/code&gt; to filter the available forecasts for a single model, and forecast date.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;example_quantile %&amp;gt;%&#xA;  make_NA(what = &#34;truth&#34;, &#xA;          target_end_date &amp;gt;= &#34;2021-07-15&#34;, &#xA;          target_end_date &amp;lt; &#34;2021-05-22&#34;&#xA;  ) %&amp;gt;%&#xA;  make_NA(what = &#34;forecast&#34;,&#xA;          model != &#34;EuroCOVIDhub-ensemble&#34;, &#xA;          forecast_date != &#34;2021-06-28&#34;&#xA;  ) %&amp;gt;%&#xA;  plot_predictions(&#xA;    x = &#34;target_end_date&#34;,&#xA;    by = c(&#34;target_type&#34;, &#34;location&#34;)&#xA;  ) +&#xA;  facet_wrap(target_type ~ location, ncol = 4, scales = &#34;free&#34;) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/epiforecasts/scoringutils/main/man/figures/unnamed-chunk-4-1.png&#34; alt=&#34;&#34;&gt;&#xA; &lt;!-- --&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Scoring forecasts&lt;/h3&gt; &#xA;&lt;p&gt;Forecasts can be easily and quickly scored using the &lt;code&gt;score()&lt;/code&gt; function. &lt;code&gt;score()&lt;/code&gt; automatically tries to determine the &lt;code&gt;forecast_unit&lt;/code&gt;, i.e.&amp;nbsp;the set of columns that uniquely defines a single forecast, by taking all column names of the data into account. However, it is recommended to set the forecast unit manually using &lt;code&gt;set_forecast_unit()&lt;/code&gt; as this may help to avoid errors, especially when scoringutils is used in automated pipelines. The function &lt;code&gt;set_forecast_unit()&lt;/code&gt; will simply drop unneeded columns. To verify everything is in order, the function &lt;code&gt;validate_forecast()&lt;/code&gt; should be used. The result of that check can then passed directly into &lt;code&gt;score()&lt;/code&gt;. &lt;code&gt;score()&lt;/code&gt; returns unsummarised scores, which in most cases is not what the user wants. Here we make use of additional functions from &lt;code&gt;scoringutils&lt;/code&gt; to add empirical coverage-levels (&lt;code&gt;add_coverage()&lt;/code&gt;), and scores relative to a baseline model (here chosen to be the EuroCOVIDhub-ensemble model). See the getting started vignette for more details. Finally we summarise these scores by model and target type.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;example_quantile %&amp;gt;%&#xA;  set_forecast_unit(c(&#34;location&#34;, &#34;target_end_date&#34;, &#34;target_type&#34;, &#34;horizon&#34;, &#34;model&#34;)) %&amp;gt;%&#xA;  as_forecast() %&amp;gt;%&#xA;  add_coverage() %&amp;gt;%&#xA;  score() %&amp;gt;%&#xA;  summarise_scores(&#xA;    by = c(&#34;model&#34;, &#34;target_type&#34;)&#xA;  ) %&amp;gt;%&#xA;  add_pairwise_comparison(&#xA;    baseline = &#34;EuroCOVIDhub-ensemble&#34;&#xA;  ) %&amp;gt;%&#xA;  summarise_scores(&#xA;    fun = signif, &#xA;    digits = 2&#xA;  ) %&amp;gt;%&#xA;  kable()&#xA;#&amp;gt; Some rows containing NA values may be removed. This is fine if not unexpected.&#xA;#&amp;gt; Some rows containing NA values may be removed. This is fine if not unexpected.&#xA;#&amp;gt; Some rows containing NA values may be removed. This is fine if not unexpected.&#xA;#&amp;gt; Warning in get_score_names(scores, error = TRUE): The following scores have&#xA;#&amp;gt; been previously computed, but are no longer column names of the data:&#xA;#&amp;gt; `interval_coverage, quantile_coverage, quantile_coverage_deviation`. See&#xA;#&amp;gt; `?get_score_names` for further information.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;model&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;target_type&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;wis&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;overprediction&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;underprediction&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;dispersion&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;bias&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;interval_coverage_50&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;interval_coverage_90&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;interval_coverage_deviation&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;ae_median&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;wis_relative_skill&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;wis_scaled_relative_skill&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;EuroCOVIDhub-baseline&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Cases&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;28000&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;14000.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;10000.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;4100&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.0980&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.33&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.82&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-0.120&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;38000&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.30&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;EuroCOVIDhub-baseline&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Deaths&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;160&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;66.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;2.1&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;91&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.3400&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.66&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.120&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;230&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;2.30&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;EuroCOVIDhub-ensemble&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Cases&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;18000&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;10000.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;4200.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3700&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-0.0560&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.39&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.80&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-0.100&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;24000&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.82&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;EuroCOVIDhub-ensemble&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Deaths&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;41&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;7.1&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;4.1&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;30&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.0730&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.88&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.200&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;53&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.60&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;UMass-MechBayes&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Deaths&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;53&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;9.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;17.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;27&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-0.0220&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.46&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.88&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-0.025&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;78&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.75&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;epiforecasts-EpiNow2&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Cases&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;21000&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;12000.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3300.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5700&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-0.0790&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.47&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.79&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-0.070&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;28000&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.95&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;epiforecasts-EpiNow2&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Deaths&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;67&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;19.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;16.0&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;32&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-0.0051&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.42&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.91&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-0.045&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;100&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0.98&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;1.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;code&gt;scoringutils&lt;/code&gt; contains additional functionality to transform forecasts, to summarise scores at different levels, to visualise them, and to explore the forecasts themselves. See the package vignettes and function documentation for more information.&lt;/p&gt; &#xA;&lt;p&gt;You may want to score forecasts based on transformations of the original data in order to obtain a more complete evaluation (see &lt;a href=&#34;https://www.medrxiv.org/content/10.1101/2023.01.23.23284722v1&#34;&gt;this paper&lt;/a&gt; for more information). This can be done using the function &lt;code&gt;transform_forecasts()&lt;/code&gt;. In the following example, we truncate values at 0 and use the function &lt;code&gt;log_shift()&lt;/code&gt; to add 1 to all values before applying the natural logarithm.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;example_quantile %&amp;gt;%&#xA; .[, observed := ifelse(observed &amp;lt; 0, 0, observed)] %&amp;gt;%&#xA;  transform_forecasts(append = TRUE, fun = log_shift, offset = 1) %&amp;gt;%&#xA;  score %&amp;gt;%&#xA;  summarise_scores(by = c(&#34;model&#34;, &#34;target_type&#34;, &#34;scale&#34;)) %&amp;gt;%&#xA;  head()&#xA;#&amp;gt; Some rows containing NA values may be removed. This is fine if not unexpected.&#xA;#&amp;gt; Some rows containing NA values may be removed. This is fine if not unexpected.&#xA;#&amp;gt;                    model target_type   scale         wis overprediction&#xA;#&amp;gt;                   &amp;lt;char&amp;gt;      &amp;lt;char&amp;gt;  &amp;lt;char&amp;gt;       &amp;lt;num&amp;gt;          &amp;lt;num&amp;gt;&#xA;#&amp;gt; 1: EuroCOVIDhub-ensemble       Cases natural 11550.70664    3650.004755&#xA;#&amp;gt; 2: EuroCOVIDhub-baseline       Cases natural 22090.45747    7702.983696&#xA;#&amp;gt; 3:  epiforecasts-EpiNow2       Cases natural 14438.43943    5513.705842&#xA;#&amp;gt; 4: EuroCOVIDhub-ensemble      Deaths natural    41.42249       7.138247&#xA;#&amp;gt; 5: EuroCOVIDhub-baseline      Deaths natural   159.40387      65.899117&#xA;#&amp;gt; 6:       UMass-MechBayes      Deaths natural    52.65195       8.978601&#xA;#&amp;gt;    underprediction dispersion        bias interval_coverage_50&#xA;#&amp;gt;              &amp;lt;num&amp;gt;      &amp;lt;num&amp;gt;       &amp;lt;num&amp;gt;                &amp;lt;num&amp;gt;&#xA;#&amp;gt; 1:     4237.177310 3663.52458 -0.05640625            0.3906250&#xA;#&amp;gt; 2:    10284.972826 4102.50094  0.09726562            0.3281250&#xA;#&amp;gt; 3:     3260.355639 5664.37795 -0.07890625            0.4687500&#xA;#&amp;gt; 4:        4.103261   30.18099  0.07265625            0.8750000&#xA;#&amp;gt; 5:        2.098505   91.40625  0.33906250            0.6640625&#xA;#&amp;gt; 6:       16.800951   26.87239 -0.02234375            0.4609375&#xA;#&amp;gt;    interval_coverage_90 interval_coverage_deviation   ae_median&#xA;#&amp;gt;                   &amp;lt;num&amp;gt;                       &amp;lt;num&amp;gt;       &amp;lt;num&amp;gt;&#xA;#&amp;gt; 1:            0.8046875                 -0.10230114 17707.95312&#xA;#&amp;gt; 2:            0.8203125                 -0.11437500 32080.48438&#xA;#&amp;gt; 3:            0.7890625                 -0.06963068 21530.69531&#xA;#&amp;gt; 4:            1.0000000                  0.20380682    53.13281&#xA;#&amp;gt; 5:            1.0000000                  0.12142045   233.25781&#xA;#&amp;gt; 6:            0.8750000                 -0.02488636    78.47656&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If using &lt;code&gt;scoringutils&lt;/code&gt; in your work please consider citing it using the output of &lt;code&gt;citation(&#34;scoringutils&#34;)&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#&amp;gt; To cite scoringutils in publications use the following. If you use the&#xA;#&amp;gt; CRPS, DSS, or Log Score, please also cite scoringRules.&#xA;#&amp;gt; &#xA;#&amp;gt;   Nikos I. Bosse, Hugo Gruson, Sebastian Funk, Anne Cori, Edwin van&#xA;#&amp;gt;   Leeuwen, and Sam Abbott (2022). Evaluating Forecasts with&#xA;#&amp;gt;   scoringutils in R, arXiv. DOI: 10.48550/ARXIV.2205.07090&#xA;#&amp;gt; &#xA;#&amp;gt; To cite scoringRules in publications use:&#xA;#&amp;gt; &#xA;#&amp;gt;   Alexander Jordan, Fabian Krueger, Sebastian Lerch (2019). Evaluating&#xA;#&amp;gt;   Probabilistic Forecasts with scoringRules. Journal of Statistical&#xA;#&amp;gt;   Software, 90(12), 1-37. DOI 10.18637/jss.v090.i12&#xA;#&amp;gt; &#xA;#&amp;gt; To see these entries in BibTeX format, use &#39;print(&amp;lt;citation&amp;gt;,&#xA;#&amp;gt; bibtex=TRUE)&#39;, &#39;toBibtex(.)&#39;, or set&#xA;#&amp;gt; &#39;options(citation.bibtex.max=999)&#39;.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How to make a bug report or feature request&lt;/h2&gt; &#xA;&lt;p&gt;Please briefly describe your problem and what output you expect in an &lt;a href=&#34;https://github.com/epiforecasts/scoringutils/issues&#34;&gt;issue&lt;/a&gt;. If you have a question, please don’t open an issue. Instead, ask on our &lt;a href=&#34;https://github.com/epiforecasts/scoringutils/discussions/categories/q-a&#34;&gt;Q and A page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions and new contributors! We particularly appreciate help on priority problems in the &lt;a href=&#34;https://github.com/epiforecasts/scoringutils/issues&#34;&gt;issues&lt;/a&gt;. Please check and add to the issues, and/or add a &lt;a href=&#34;https://github.com/epiforecasts/scoringutils/pulls&#34;&gt;pull request&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;Please note that the &lt;code&gt;scoringutils&lt;/code&gt; project is released with a &lt;a href=&#34;https://epiforecasts.io/scoringutils/CODE_OF_CONDUCT.html&#34;&gt;Contributor Code of Conduct&lt;/a&gt;. By contributing to this project, you agree to abide by its terms.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pbreheny/plmm</title>
    <updated>2024-02-19T01:37:59Z</updated>
    <id>tag:github.com,2024-02-19:/pbreheny/plmm</id>
    <link href="https://github.com/pbreheny/plmm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fit penalized linear mixed models to correct for unobserved confounding effects.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/pbreheny/plmm&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=GitHub&amp;amp;message=2.2.1&amp;amp;color=blue&amp;amp;logo=github&#34; alt=&#34;GitHub version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pbreheny/plmm/actions&#34;&gt;&lt;img src=&#34;https://github.com/pbreheny/plmm/workflows/R-CMD-check/badge.svg?sanitize=true&#34; alt=&#34;R-CMD-check&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;h2&gt;Welcome&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;plmm&lt;/code&gt; package contains functions that fit penalized linear mixed models to correct for unobserved confounding effects. Documentation for this package is in progress.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To install the latest version of the package:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&#34;pbreheny/plmm&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For a description of the motivation of the functions in this package (along with examples) refer to the second module of &lt;a href=&#34;https://pbreheny.github.io/adv-gwas-tutorial/index.html&#34;&gt;this GWAS data tutorial&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Latest changes&lt;/h2&gt; &#xA;&lt;p&gt;The newest features of &lt;code&gt;plmm&lt;/code&gt; are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;version 2.2.0: parameter $\eta$ is no longer estimated in each fold of cross-validation&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;version 2.1.0: A new function &lt;code&gt;mfdr()&lt;/code&gt; for inference on model coefficients.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;version 2.0.3: An &lt;code&gt;xgboost&lt;/code&gt; method is now available in &lt;code&gt;process_plink()&lt;/code&gt;. Check out the documentation for details. This option should be regarded as being in &#39;beta-testing&#39; mode.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Note on branches&lt;/h2&gt; &#xA;&lt;p&gt;The branches of this repo are organized in the following way:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;master&lt;/code&gt; is the main branch with all the latest updates&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;estimate_eta&lt;/code&gt; is a development branch where we are working through an alternative approach for estimating $\eta$.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;fbm&lt;/code&gt; is a development branch where I am working to extend our current methods to analyze data from a design matrix stored as a file-backed object (a Filebacked Big Matrix, or FBM). See package &lt;a href=&#34;https://privefl.github.io/bigstatsr/&#34;&gt;bigstatsr&lt;/a&gt; for more info on these objects.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;sign_flip&lt;/code&gt; is a development branch where I am toying with how to handle the issues caused by +/- signs being flipped as part of truncated SVD.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;refine_workflow&lt;/code&gt; is an &lt;strong&gt;archived&lt;/strong&gt; branch in which I explored changing the workflow to make cross validation more efficient. This change involved moving the rotation step into &lt;code&gt;plmm_prep()&lt;/code&gt;, instead of having that step as part of model fitting in &lt;code&gt;plmm_fit()&lt;/code&gt;. I found that this change was not compatible with cross validation, for reasons that I am currently writing up as part of a paper. Once that paper is done, I will delete this branch.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Breeding-Analytics/cgiarGenomics</title>
    <updated>2024-02-19T01:37:59Z</updated>
    <id>tag:github.com,2024-02-19:/Breeding-Analytics/cgiarGenomics</id>
    <link href="https://github.com/Breeding-Analytics/cgiarGenomics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Functions for management of genomic data&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
</feed>