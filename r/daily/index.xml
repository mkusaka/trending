<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-29T01:35:43Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mlr-org/mlr3mbo</title>
    <updated>2022-11-29T01:35:43Z</updated>
    <id>tag:github.com,2022-11-29:/mlr-org/mlr3mbo</id>
    <link href="https://github.com/mlr-org/mlr3mbo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Flexible Bayesian Optimization in R&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;mlr3mbo&lt;/h1&gt; &#xA;&lt;p&gt;A new R6 and much more modular implementation for single- and multi-objective Bayesian Optimization.&lt;/p&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mlr-org/mlr3mbo/actions&#34;&gt;&lt;img src=&#34;https://github.com/mlr-org/mlr3mbo/workflows/tic/badge.svg?branch=main&#34; alt=&#34;tic&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cran.r-project.org/package=mlr3mbo&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/mlr3mbo&#34; alt=&#34;CRANstatus&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://stackoverflow.com/questions/tagged/mlr3&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/stackoverflow-mlr3-orange.svg?sanitize=true&#34; alt=&#34;StackOverflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/chat-mattermost-orange.svg?sanitize=true&#34; alt=&#34;Mattermost&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;An overview and gentle introduction is given in &lt;a href=&#34;https://mlr3mbo.mlr-org.com/articles/mlr3mbo.html&#34;&gt;this vignette&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Design&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;mlr3mbo&lt;/code&gt; is built modular relying on the following &lt;a href=&#34;https://cran.r-project.org/package=R6&#34;&gt;R6&lt;/a&gt; classes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Surrogate&lt;/code&gt;: Surrogate Model&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;AcqFunction&lt;/code&gt;: Acquisition Function&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;AcqOptimizer&lt;/code&gt;: Acquisition Function Optimizer&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Based on these, Bayesian Optimization loops can be written, see, e.g., &lt;code&gt;bayesopt_ego&lt;/code&gt; for sequential single-objective BO.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;mlr3mbo&lt;/code&gt; also provides an &lt;code&gt;OptimizerMbo&lt;/code&gt; class behaving like any other &lt;code&gt;Optimizer&lt;/code&gt; from the &lt;a href=&#34;https://cran.r-project.org/package=bbotk&#34;&gt;bbotk&lt;/a&gt; package as well as a &lt;code&gt;TunerMbo&lt;/code&gt; class behaving like any other &lt;code&gt;Tuner&lt;/code&gt; from the &lt;a href=&#34;https://cran.r-project.org/package=mlr3tuning&#34;&gt;mlr3tuning&lt;/a&gt; package.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;mlr3mbo&lt;/code&gt; uses sensible defaults for the &lt;code&gt;Surrogate&lt;/code&gt;, &lt;code&gt;AcqFunction&lt;/code&gt;, &lt;code&gt;AcqOptimizer&lt;/code&gt;, and even the &lt;code&gt;loop_function&lt;/code&gt;. See &lt;code&gt;?mbo_defaults&lt;/code&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Simple Optimization Example&lt;/h2&gt; &#xA;&lt;p&gt;Minimize &lt;code&gt;f(x) = x^2&lt;/code&gt; via sequential single-objective BO using a GP as surrogate and EI optimized via random search as acquisition function:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(bbotk)&#xA;library(mlr3mbo)&#xA;library(mlr3learners)&#xA;set.seed(1)&#xA;&#xA;obfun = ObjectiveRFun$new(&#xA;  fun = function(xs) list(y1 = xs$x ^ 2),&#xA;  domain = ps(x = p_dbl(lower = -10, upper = 10)),&#xA;  codomain = ps(y1 = p_dbl(tags = &#34;minimize&#34;)))&#xA;&#xA;instance = OptimInstanceSingleCrit$new(&#xA;  objective = obfun,&#xA;  terminator = trm(&#34;evals&#34;, n_evals = 10))&#xA;&#xA;surrogate = srlrn(lrn(&#34;regr.km&#34;, control = list(trace = FALSE)))&#xA;acqfun = acqf(&#34;ei&#34;)&#xA;acqopt = acqo(opt(&#34;random_search&#34;, batch_size = 100),&#xA;  terminator = trm(&#34;evals&#34;, n_evals = 100))&#xA;&#xA;optimizer = opt(&#34;mbo&#34;,&#xA;  loop_function = bayesopt_ego,&#xA;  surrogate = surrogate,&#xA;  acq_function = acqfun,&#xA;  acq_optimizer = acqopt)&#xA;&#xA;optimizer$optimize(instance)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;##             x  x_domain          y1&#xA;## 1: 0.03897209 &amp;lt;list[1]&amp;gt; 0.001518824&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that you can also use &lt;code&gt;bb_optimize&lt;/code&gt; as a shorthand:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(bbotk)&#xA;library(mlr3mbo)&#xA;library(mlr3learners)&#xA;set.seed(1)&#xA;&#xA;fun = function(xs) list(y1 = xs$x ^ 2)&#xA;&#xA;surrogate = srlrn(lrn(&#34;regr.km&#34;, control = list(trace = FALSE)))&#xA;acqfun = acqf(&#34;ei&#34;)&#xA;acqopt = acqo(opt(&#34;random_search&#34;, batch_size = 100),&#xA;  terminator = trm(&#34;evals&#34;, n_evals = 100))&#xA;&#xA;optimizer = opt(&#34;mbo&#34;,&#xA;  loop_function = bayesopt_ego,&#xA;  surrogate = surrogate,&#xA;  acq_function = acqfun,&#xA;  acq_optimizer = acqopt)&#xA;&#xA;result = bb_optimize(&#xA;  fun,&#xA;  method = optimizer,&#xA;  lower = c(x = -10),&#xA;  upper = c(x = 10),&#xA;  max_evals = 10)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Simple Tuning Example&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(mlr3)&#xA;library(mlr3learners)&#xA;library(mlr3tuning)&#xA;library(mlr3mbo)&#xA;set.seed(1)&#xA;&#xA;task = tsk(&#34;pima&#34;)&#xA;&#xA;learner = lrn(&#34;classif.rpart&#34;, cp = to_tune(lower = 1e-04, upper = 1, logscale = TRUE))&#xA;&#xA;instance = tune(&#xA;  method = &#34;mbo&#34;,&#xA;  task = task,&#xA;  learner = learner,&#xA;  resampling = rsmp(&#34;holdout&#34;),&#xA;  measure = msr(&#34;classif.ce&#34;),&#xA;  term_evals = 10)&#xA;&#xA;instance$result&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;##           cp learner_param_vals  x_domain classif.ce&#xA;## 1: -5.001241          &amp;lt;list[2]&amp;gt; &amp;lt;list[1]&amp;gt;  0.1914062&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>