<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-05T01:54:54Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>rmcelreath/rethinking</title>
    <updated>2022-06-05T01:54:54Z</updated>
    <id>tag:github.com,2022-06-05:/rmcelreath/rethinking</id>
    <link href="https://github.com/rmcelreath/rethinking" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Statistical Rethinking course and book package&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;rethinking&lt;/h1&gt; &#xA;&lt;p&gt;This R package accompanies a course and book on Bayesian data analysis: McElreath 2020. Statistical Rethinking, 2nd edition, CRC Press. If you are using it with the first edition of the book, please see the notes at the bottom of this file.&lt;/p&gt; &#xA;&lt;p&gt;It contains tools for conducting both quick quadratic approximation of the posterior distribution as well as Hamiltonian Monte Carlo (through RStan or cmdstanr - mc-stan.org). Many packages do this. The signature difference of this package is that it forces the user to specify the model as a list of explicit distributional assumptions. This is more tedious than typical formula-based tools, but it is also much more flexible and powerful and---most important---useful for teaching and learning. When students have to write out every detail of the model, they actually learn the model.&lt;/p&gt; &#xA;&lt;p&gt;For example, a simple Gaussian model could be specified with this list of formulas:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;f &amp;lt;- alist(&#xA;    y ~ dnorm( mu , sigma ),&#xA;    mu ~ dnorm( 0 , 10 ),&#xA;    sigma ~ dexp( 1 )&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The first formula in the list is the probability of the outcome (likelihood); the second is the prior for &lt;code&gt;mu&lt;/code&gt;; the third is the prior for &lt;code&gt;sigma&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;There are three steps. (1) Install &lt;code&gt;rstan&lt;/code&gt;, (2) install &lt;code&gt;cmdstanr&lt;/code&gt;, (3) install &lt;code&gt;rethinking&lt;/code&gt;. Details follow.&lt;/p&gt; &#xA;&lt;p&gt;First, install the C++ toolchain and install the &lt;code&gt;rstan&lt;/code&gt; package. Go to &lt;code&gt;https://mc-stan.org/users/interfaces/rstan.html&lt;/code&gt; and follow the instructions for your platform. The biggest challenge is getting a C++ compiler configured to work with your installation of R. The instructions are quite thorough. Obey them, and you&#39;ll succeed.&lt;/p&gt; &#xA;&lt;p&gt;Second, install the &lt;code&gt;cmdstanr&lt;/code&gt; package. Visit &lt;code&gt;https://mc-stan.org/cmdstanr/&lt;/code&gt;. The first time you install cmdstanr, you will also need compile the libraries with &lt;code&gt;cmdstanr::install_cmdstan()&lt;/code&gt;. All this of this bother is worth it. You just have to do it once.&lt;/p&gt; &#xA;&lt;p&gt;Third, once rstan and cmdstanr are installed (almost there), then you can install &lt;code&gt;rethinking&lt;/code&gt; from within R using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;install.packages(c(&#34;coda&#34;,&#34;mvtnorm&#34;,&#34;devtools&#34;,&#34;loo&#34;,&#34;dagitty&#34;,&#34;shape&#34;))&#xA;devtools::install_github(&#34;rmcelreath/rethinking&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If there are any problems, they likely arise when trying to install &lt;code&gt;rstan&lt;/code&gt;, so the &lt;code&gt;rethinking&lt;/code&gt; package has little to do with it. See the manual linked above for some hints about getting &lt;code&gt;rstan&lt;/code&gt; installed. But always consult the RStan section of the website at &lt;code&gt;mc-stan.org&lt;/code&gt; for the latest information on RStan.&lt;/p&gt; &#xA;&lt;p&gt;Note that the &lt;code&gt;rethinking&lt;/code&gt; package is not on CRAN, just on github. The &lt;code&gt;rethinking&lt;/code&gt; package is never going to be on CRAN.&lt;/p&gt; &#xA;&lt;h1&gt;rethinking slim - no MCMC&lt;/h1&gt; &#xA;&lt;p&gt;If you just want to work through the first half of the course, without bothering with MCMC and Stan installs, you can install the &#39;slim&#39; version of the rethinking package. Do this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;install.packages(c(&#34;coda&#34;,&#34;mvtnorm&#34;,&#34;devtools&#34;,&#34;loo&#34;,&#34;dagitty&#34;))&#xA;devtools::install_github(&#34;rmcelreath/rethinking@slim&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;quap&lt;/code&gt; function and related helper functions should still work, and you&#39;ll be able to work through Chapter 8 before you need to install the full version with Stan.&lt;/p&gt; &#xA;&lt;h1&gt;Quadratic Approximation with &lt;code&gt;quap&lt;/code&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Almost any ordinary generalized linear model can be specified with &lt;code&gt;quap&lt;/code&gt;. To use quadratic approximation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;library(rethinking)&#xA;&#xA;f &amp;lt;- alist(&#xA;    y ~ dnorm( mu , sigma ),&#xA;    mu ~ dnorm( 0 , 10 ),&#xA;    sigma ~ dexp( 1 )&#xA;)&#xA;&#xA;fit &amp;lt;- quap( &#xA;    f , &#xA;    data=list(y=c(-1,1)) , &#xA;    start=list(mu=0,sigma=1)&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The object &lt;code&gt;fit&lt;/code&gt; holds the result. For a summary of marginal posterior distributions, use &lt;code&gt;summary(fit)&lt;/code&gt; or &lt;code&gt;precis(fit)&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;      mean   sd  5.5% 94.5%&#xA;mu    0.00 0.59 -0.95  0.95&#xA;sigma 0.84 0.33  0.31  1.36&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It also supports vectorized parameters, which is convenient for categories. See examples &lt;code&gt;?quap&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In the first edition of the textbook, this function was called &lt;code&gt;map&lt;/code&gt;. It can still be used with that alias. It was renamed, because the name &lt;code&gt;map&lt;/code&gt; was misleading. This function produces quadratic approximations of the posterior distribution, not just maximum a posteriori (MAP) estimates.&lt;/p&gt; &#xA;&lt;h1&gt;Hamiltonian Monte Carlo with &lt;code&gt;ulam&lt;/code&gt; (and &lt;code&gt;map2stan&lt;/code&gt;)&lt;/h1&gt; &#xA;&lt;p&gt;The same formula list can be compiled into a Stan (mc-stan.org) model using one of two tools: &lt;code&gt;ulam&lt;/code&gt; or &lt;code&gt;map2stan&lt;/code&gt;. For simple models, they are identical. &lt;code&gt;ulam&lt;/code&gt; is the newer tool that allows for much more flexibility, including explicit variable types and custom distributions. &lt;code&gt;map2stan&lt;/code&gt; is the original tool from the first edition of the package and textbook. Going forward, new features will be added to &lt;code&gt;ulam&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ulam&lt;/code&gt; is named after Stanisław Ulam, who was one of the parents of the Monte Carlo method and is the namesake of the Stan project as well. It is pronounced something like [OO-lahm], not like [YOU-lamm].&lt;/p&gt; &#xA;&lt;p&gt;Both tools take the same kind of input as &lt;code&gt;quap&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;fit_stan &amp;lt;- ulam( f , data=list(y=c(-1,1)) )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The chain runs automatically, provided &lt;code&gt;rstan&lt;/code&gt; is installed. Chain diagnostics are displayed in the &lt;code&gt;precis(fit_stan)&lt;/code&gt; output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;      mean   sd  5.5% 94.5% n_eff Rhat&#xA;sigma 1.45 0.72  0.67  2.84   145    1&#xA;mu    0.12 1.04 -1.46  1.59   163    1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For &lt;code&gt;ulam&lt;/code&gt; models, &lt;code&gt;plot&lt;/code&gt; displays the same information as &lt;code&gt;precis&lt;/code&gt; and &lt;code&gt;traceplot&lt;/code&gt; displays the chains.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;extract.samples&lt;/code&gt; returns samples in a list. &lt;code&gt;extract.prior&lt;/code&gt; samples from the prior and returns the samples in a list as well.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;stanfit&lt;/code&gt; object itself is in the &lt;code&gt;@stanfit&lt;/code&gt; slot. Anything you&#39;d do with a Stan model can be done with that slot directly.&lt;/p&gt; &#xA;&lt;p&gt;The Stan code can be accessed by using &lt;code&gt;stancode(fit_stan)&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;data{&#xA;    real y[2];&#xA;}&#xA;parameters{&#xA;    real&amp;lt;lower=0&amp;gt; sigma;&#xA;    real mu;&#xA;}&#xA;model{&#xA;    sigma ~ exponential( 1 );&#xA;    mu ~ normal( 0 , 10 );&#xA;    y ~ normal( mu , sigma );&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that &lt;code&gt;ulam&lt;/code&gt; doesn&#39;t care about R distribution names. You can instead use Stan-style names:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;fit_stan &amp;lt;- ulam(&#xA;    alist(&#xA;        y ~ normal( mu , sigma ),&#xA;        mu ~ normal( 0 , 10 ),&#xA;        sigma ~ exponential( 1 )&#xA;    ), data=list(y=c(-1,1)) )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Posterior prediction&lt;/h2&gt; &#xA;&lt;p&gt;All &lt;code&gt;quap&lt;/code&gt;, &lt;code&gt;ulam&lt;/code&gt;, and &lt;code&gt;map2stan&lt;/code&gt; objects can be post-processed to produce posterior predictive distributions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;link&lt;/code&gt; is used to compute values of any linear models over samples from the posterior distribution.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;sim&lt;/code&gt; is used to simulate posterior predictive distributions, simulating outcomes over samples from the posterior distribution of parameters. &lt;code&gt;sim&lt;/code&gt; can also be used to simulate prior predictives.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;code&gt;?link&lt;/code&gt; and &lt;code&gt;?sim&lt;/code&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;postcheck&lt;/code&gt; automatically computes posterior predictive (retrodictive?) checks. It merely uses &lt;code&gt;link&lt;/code&gt; and &lt;code&gt;sim&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Multilevel model formulas&lt;/h2&gt; &#xA;&lt;p&gt;While &lt;code&gt;quap&lt;/code&gt; is limited to fixed effects models for the most part, &lt;code&gt;ulam&lt;/code&gt; can specify multilevel models, even quite complex ones. For example, a simple varying intercepts model looks like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# prep data&#xA;data( UCBadmit )&#xA;UCBadmit$male &amp;lt;- as.integer(UCBadmit$applicant.gender==&#34;male&#34;)&#xA;UCBadmit$dept &amp;lt;- rep( 1:6 , each=2 )&#xA;UCBadmit$applicant.gender &amp;lt;- NULL&#xA;&#xA;# varying intercepts model&#xA;m_glmm1 &amp;lt;- ulam(&#xA;    alist(&#xA;        admit ~ binomial(applications,p),&#xA;        logit(p) &amp;lt;- a[dept] + b*male,&#xA;        a[dept] ~ normal( abar , sigma ),&#xA;        abar ~ normal( 0 , 4 ),&#xA;        sigma ~ half_normal(0,1),&#xA;        b ~ normal(0,1)&#xA;    ), data=UCBadmit )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The analogous varying slopes model is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;m_glmm2 &amp;lt;- ulam(&#xA;    alist(&#xA;        admit ~ binomial(applications,p),&#xA;        logit(p) &amp;lt;- a[dept] + b[dept]*male,&#xA;        c( a , b )[dept] ~ multi_normal( c(abar,bbar) , Rho , sigma ),&#xA;        abar ~ normal( 0 , 4 ),&#xA;        bbar ~ normal(0,1),&#xA;        sigma ~ half_normal(0,1),&#xA;        Rho ~ lkjcorr(2)&#xA;    ),&#xA;    data=UCBadmit )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Another way to express the varying slopes model is with a vector of varying effects. This is made possible by using an explicit vector declaration inside the formula:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;m_glmm3 &amp;lt;- ulam(&#xA;    alist(&#xA;        admit ~ binomial(applications,p),&#xA;        logit(p) &amp;lt;- v[dept,1] + v[dept,2]*male,&#xA;        vector[2]:v[dept] ~ multi_normal( c(abar,bbar) , Rho , sigma ),&#xA;        abar ~ normal( 0 , 4 ),&#xA;        bbar ~ normal(0,1),&#xA;        sigma ~ half_normal(0,1),&#xA;        Rho ~ lkjcorr(2)&#xA;    ),&#xA;    data=UCBadmit )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That &lt;code&gt;vector[2]:v[dept]&lt;/code&gt; means &#34;declare a vector of length two for each unique dept&#34;. To access the elements of these vectors, the linear model uses multiple indexes inside the brackets: &lt;code&gt;[dept,1]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This strategy can be taken one step further and the means can be declared as a vector as well:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;m_glmm4 &amp;lt;- ulam(&#xA;    alist(&#xA;        admit ~ binomial(applications,p),&#xA;        logit(p) &amp;lt;- v[dept,1] + v[dept,2]*male,&#xA;        vector[2]:v[dept] ~ multi_normal( v_mu , Rho , sigma ),&#xA;        vector[2]:v_mu ~ normal(0,1),&#xA;        sigma[1] ~ half_normal(0,1),&#xA;        sigma[2] ~ half_normal(0,2),&#xA;        Rho ~ lkjcorr(2)&#xA;    ),&#xA;    data=UCBadmit )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And a completely non-centered parameterization can be coded directly as well:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;m_glmm5 &amp;lt;- ulam(&#xA;    alist(&#xA;        admit ~ binomial(applications,p),&#xA;        logit(p) &amp;lt;- v_mu[1] + v[dept,1] + (v_mu[2] + v[dept,2])*male,&#xA;        matrix[dept,2]: v &amp;lt;- t(diag_pre_multiply( sigma , L_Rho ) * z),&#xA;        matrix[2,dept]: z ~ normal( 0 , 1 ),&#xA;        vector[2]: v_mu[[1]] ~ normal(0,4),&#xA;        vector[2]: v_mu[[2]] ~ normal(0,1),&#xA;        vector[2]: sigma ~ half_normal(0,1),&#xA;        cholesky_factor_corr[2]: L_Rho ~ lkj_corr_cholesky( 2 )&#xA;    ),&#xA;    data=UCBadmit )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the above, the varying effects matrix &lt;code&gt;v&lt;/code&gt; is constructed from a matrix of z-scores &lt;code&gt;z&lt;/code&gt; and a covariance structure contained in &lt;code&gt;sigma&lt;/code&gt; and a Cholesky factor &lt;code&gt;L_Rho&lt;/code&gt;. Note the double-bracket notation &lt;code&gt;v_mu[[1]]&lt;/code&gt; allowing distinct priors for each index of a vector.&lt;/p&gt; &#xA;&lt;h2&gt;log-likelihood calculations for WAIC and LOOCV&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;ulam&lt;/code&gt; can optionally return pointwise log-likelihood values. These are needed for computing WAIC and PSIS-LOO. The &lt;code&gt;log_lik&lt;/code&gt; argument toggles this on:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;m_glmm1 &amp;lt;- ulam(&#xA;    alist(&#xA;        admit ~ binomial(applications,p),&#xA;        logit(p) &amp;lt;- a[dept] + b*male,&#xA;        a[dept] ~ normal( abar , sigma ),&#xA;        abar ~ normal( 0 , 4 ),&#xA;        sigma ~ half_normal(0,1),&#xA;        b ~ normal(0,1)&#xA;    ), data=UCBadmit , log_lik=TRUE )&#xA;WAIC(m_glmm1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The additional code has been added to the generated quantities block of the Stan model (see this with &lt;code&gt;stancode(m_glmm1)&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;generated quantities{&#xA;    vector[12] log_lik;&#xA;    vector[12] p;&#xA;    for ( i in 1:12 ) {&#xA;        p[i] = a[dept[i]] + b * male[i];&#xA;        p[i] = inv_logit(p[i]);&#xA;    }&#xA;    for ( i in 1:12 ) log_lik[i] = binomial_lpmf( admit[i] | applications[i] , p[i] );&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Conditional statements, custom distributions, and mixture models&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;ulam&lt;/code&gt; also supports if-then statements and custom distribution assignments. These are useful for coding mixture models, such as zero-inflated Poisson and discrete missing value models.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s an example zero-inflated Poisson model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# zero-inflated poisson&#xA;# gen data first - example from text&#xA;prob_drink &amp;lt;- 0.2 # 20% of days&#xA;rate_work &amp;lt;- 1    # average 1 manuscript per day&#xA;N &amp;lt;- 365&#xA;drink &amp;lt;- rbinom( N , 1 , prob_drink )&#xA;y &amp;lt;- as.integer( (1-drink)*rpois( N , rate_work ) )&#xA;x &amp;lt;- rnorm( N ) # dummy covariate&#xA;&#xA;# now ulam code&#xA;m_zip &amp;lt;- ulam(&#xA;    alist(&#xA;        y|y==0 ~ custom( log_mix( p , 0 , poisson_lpmf(0|lambda) ) ),&#xA;        y|y&amp;gt;0 ~ custom( log1m(p) + poisson_lpmf(y|lambda) ),&#xA;        logit(p) &amp;lt;- ap,&#xA;        log(lambda) &amp;lt;- al + bl*x,&#xA;        ap ~ dnorm(0,1),&#xA;        al ~ dnorm(0,10),&#xA;        bl ~ normal(0,1)&#xA;    ) ,&#xA;    data=list(y=y,x=x) )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The Stan code corresponding to the first two lines in the formula above is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;for ( i in 1:365 ) &#xA;    if ( y[i] &amp;gt; 0 ) target += log1m(p) + poisson_lpmf(y[i] | lambda[i]);&#xA;for ( i in 1:365 ) &#xA;    if ( y[i] == 0 ) target += log_mix(p, 0, poisson_lpmf(0 | lambda[i]));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;What &lt;code&gt;custom&lt;/code&gt; does is define custom &lt;code&gt;target&lt;/code&gt; updates. And the &lt;code&gt;|&lt;/code&gt; operator makes the line conditional. Note that &lt;code&gt;log1m&lt;/code&gt;, &lt;code&gt;log_mix&lt;/code&gt;, and &lt;code&gt;poisson_lpmf&lt;/code&gt; are Stan functions.&lt;/p&gt; &#xA;&lt;p&gt;The same &lt;code&gt;custom&lt;/code&gt; distribution approach allows for marginalization over discrete missing values. Let&#39;s introduce some missing values in the &lt;code&gt;UCBadmit&lt;/code&gt; data from earlier.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;UCBadmit$male2 &amp;lt;- UCBadmit$male&#xA;UCBadmit$male2[1:2] &amp;lt;- (-1) # missingness code&#xA;UCBadmit$male2 &amp;lt;- as.integer(UCBadmit$male2)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now the model needs to detect when &lt;code&gt;male2&lt;/code&gt; is missing (-1) and then compute a mixture over the unknown state.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;m_mix &amp;lt;- ulam(&#xA;    alist(&#xA;        admit|male2==-1 ~ custom( log_mix( &#xA;            phi_male , &#xA;            binomial_lpmf(admit|applications,p_m1) , &#xA;            binomial_lpmf(admit|applications,p_m0) ) ),&#xA;        admit|male2&amp;gt;-1 ~ binomial( applications , p ),&#xA;        logit(p) &amp;lt;- a[dept] + b*male2,&#xA;        logit(p_m1) &amp;lt;- a[dept] + b*1,&#xA;        logit(p_m0) &amp;lt;- a[dept] + b*0,&#xA;        male2|male2&amp;gt;-1 ~ bernoulli( phi_male ),&#xA;        phi_male ~ beta(2,2),&#xA;        a[dept] ~ normal(0,4),&#xA;        b ~ normal(0,1)&#xA;    ),&#xA;    data=UCBadmit )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note the addition of &lt;code&gt;phi_male&lt;/code&gt; to average over the unknown state.&lt;/p&gt; &#xA;&lt;h2&gt;Continuous missing data imputation&lt;/h2&gt; &#xA;&lt;p&gt;In principle, imputation of missing real-valued data is easy: Just replace each missing value with a parameter. In practice, this involves a bunch of annoying bookkeeping. &lt;code&gt;ulam&lt;/code&gt; has a macro named &lt;code&gt;merge_missing&lt;/code&gt; to simplify this.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;UCBadmit$x &amp;lt;- rnorm(12)&#xA;UCBadmit$x[1:2] &amp;lt;- NA&#xA;m_miss &amp;lt;- ulam(&#xA;    alist(&#xA;        admit ~ binomial(applications,p),&#xA;        logit(p) &amp;lt;- a + b*male + bx*x_merge,&#xA;        x_merge ~ normal( 0 , 1 ),&#xA;        x_merge &amp;lt;- merge_missing( x , x_impute ),&#xA;        a ~ normal(0,4),&#xA;        b ~ normal(0,1),&#xA;        bx ~ normal(0,1)&#xA;    ),&#xA;    data=UCBadmit )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;What &lt;code&gt;merge_missing&lt;/code&gt; does is find the &lt;code&gt;NA&lt;/code&gt; values in &lt;code&gt;x&lt;/code&gt; (whichever symbol is the first argument), build a vector of parameters called &lt;code&gt;x_impute&lt;/code&gt; (whatever you name the second argument) of the right length, and piece together a vector &lt;code&gt;x_merge&lt;/code&gt; that contains both, in the right places. You can then assign a prior to this vector and use it in linear models as usual.&lt;/p&gt; &#xA;&lt;p&gt;The merging is done as the Stan model runs, using a custom function block. See the Stan code &lt;code&gt;stancode(m_miss)&lt;/code&gt; for all the lovely details.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;merge missing&lt;/code&gt; is an example of a macro, which is a way for &lt;code&gt;ulam&lt;/code&gt; to use function names to trigger special compilation. In this case, &lt;code&gt;merge_missing&lt;/code&gt; both inserts a function in the Stan model and builds the necessary index to locate the missing values during run time. Macros will get full documentation later, once the system is finalized.&lt;/p&gt; &#xA;&lt;h2&gt;Gaussian processes&lt;/h2&gt; &#xA;&lt;p&gt;A simple Gaussian process, like the Oceanic islands example in Chapter 13 of the book, is done as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;data(Kline2)&#xA;d &amp;lt;- Kline2&#xA;data(islandsDistMatrix)&#xA;d$society &amp;lt;- 1:10&#xA;dat &amp;lt;- list(&#xA;    y=d$total_tools,&#xA;    society=d$society,&#xA;    log_pop = log(d$population),&#xA;    Dmat=islandsDistMatrix&#xA;)&#xA;&#xA;m_GP1 &amp;lt;- ulam(&#xA;    alist(&#xA;        y ~ poisson( mu ),&#xA;        log(mu) &amp;lt;- a + aj[society] + b*log_pop,&#xA;        a ~ normal(0,10),&#xA;        b ~ normal(0,1),&#xA;        vector[10]: aj ~ multi_normal( 0 , SIGMA ),&#xA;        matrix[10,10]: SIGMA &amp;lt;- cov_GPL2( Dmat , etasq , rhosq , 0.01 ),&#xA;        etasq ~ exponential(1),&#xA;        rhosq ~ exponential(1)&#xA;    ),&#xA;    data=dat )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is just an ordinary varying intercepts model, but all 10 intercepts are drawn from a single Gaussian distribution. The covariance matrix &lt;code&gt;SIGMA&lt;/code&gt; is defined in the usual L2-norm. Again, &lt;code&gt;cov_GPL2&lt;/code&gt; is a macro that inserts a function in the Stan code to compute the covariance matrix as the model runs.&lt;/p&gt; &#xA;&lt;p&gt;Fancier Gaussian processes require a different parameterization. And these can be built as well. Here&#39;s an example using 151 primate species and a phylogenetic distance matrix. First, prepare the data:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;data(Primates301)&#xA;data(Primates301_distance_matrix)&#xA;d &amp;lt;- Primates301&#xA;d$name &amp;lt;- as.character(d$name)&#xA;dstan &amp;lt;- d[ complete.cases( d$social_learning, d$research_effort , d$body , d$brain ) , ]&#xA;# prune distance matrix to spp in dstan&#xA;spp_obs &amp;lt;- dstan$name&#xA;y &amp;lt;- Primates301_distance_matrix&#xA;y2 &amp;lt;- y[ spp_obs , spp_obs ]&#xA;# scale distances&#xA;y3 &amp;lt;- y2/max(y2)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now the model, which is a non-centered L2-norm Gaussian process:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;m_GP2 &amp;lt;- ulam(&#xA;    alist(&#xA;        social_learning ~ poisson( lambda ),&#xA;        log(lambda) &amp;lt;- a + g[spp_id] + b_ef*log_research_effort + b_body*log_body + b_eq*log_brain,&#xA;        a ~ normal(0,1),&#xA;        vector[N_spp]: g &amp;lt;&amp;lt;- L_SIGMA * eta,&#xA;        vector[N_spp]: eta ~ normal( 0 , 1 ),&#xA;        matrix[N_spp,N_spp]: L_SIGMA &amp;lt;&amp;lt;- cholesky_decompose( SIGMA ),&#xA;        matrix[N_spp,N_spp]: SIGMA &amp;lt;- cov_GPL2( Dmat , etasq , rhosq , 0.01 ),&#xA;        b_body ~ normal(0,1),&#xA;        b_eq ~ normal(0,1),&#xA;        b_ef ~ normal(1,1),&#xA;        etasq ~ exponential(1),&#xA;        rhosq ~ exponential(1)&#xA;    ),&#xA;    data=list(&#xA;        N_spp = nrow(dstan),&#xA;        social_learning = dstan$social_learning,&#xA;        spp_id = 1:nrow(dstan),&#xA;        log_research_effort = log(dstan$research_effort),&#xA;        log_body = log(dstan$body),&#xA;        log_brain = log(dstan$brain),&#xA;        Dmat = y3&#xA;    ) , &#xA;    control=list(max_treedepth=15,adapt_delta=0.95) ,&#xA;    sample=FALSE )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This model does not sample quickly, so I&#39;ve set &lt;code&gt;sample=FALSE&lt;/code&gt;. You can still inspect the Stan code with &lt;code&gt;stancode(m_GP2)&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note that the covariance &lt;code&gt;SIGMA&lt;/code&gt; is built the same way as before, but then we immediately decompose it to a Cholesky factor and build the varying intercepts &lt;code&gt;g&lt;/code&gt; by matrix multiplication. The &lt;code&gt;&amp;lt;&amp;lt;-&lt;/code&gt; operator tells &lt;code&gt;ulam&lt;/code&gt; not to loop, but to do a direct assignment. So &lt;code&gt;g &amp;lt;&amp;lt;- L_SIGMA * eta&lt;/code&gt; does the right linear algebra.&lt;/p&gt; &#xA;&lt;h2&gt;Within-chain multithreading&lt;/h2&gt; &#xA;&lt;p&gt;Using &lt;code&gt;cmdstanr&lt;/code&gt; instead of &lt;code&gt;rstan&lt;/code&gt; is currently the only way to use within-chain multithreading with &lt;code&gt;rethinking&lt;/code&gt;. It also tends to compile models faster and is more intelligent about when models need to be re-compiled, so using &lt;code&gt;cmdstanr&lt;/code&gt; is recommended, even if you don&#39;t want multithreading.&lt;/p&gt; &#xA;&lt;p&gt;If you want &lt;code&gt;ulam&lt;/code&gt; to access Stan using the &lt;code&gt;cmdstanr&lt;/code&gt; package, then you may install that as well with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;devtools::install_github(&#34;stan-dev/cmdstanr&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you haven&#39;t installed cmdstan previously, you will also need to do that with &lt;code&gt;install_cmdstan()&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Then you need to add &lt;code&gt;cmdstan=TRUE&lt;/code&gt; to the &lt;code&gt;ulam&lt;/code&gt; code. The &lt;code&gt;threads&lt;/code&gt; argument controls the number of threads per chain. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;N &amp;lt;- 1e4&#xA;x &amp;lt;- rnorm(N)&#xA;m &amp;lt;- 1 + rpois(N,2)&#xA;y &amp;lt;- rbinom( N , size=m , prob=inv_logit(-3+x) )&#xA;dat &amp;lt;- list( y=y , x=x , m=m )&#xA;# two threads&#xA;m1 &amp;lt;- ulam(&#xA;    alist(&#xA;        y ~ binomial_logit( m , logit_p ),&#xA;        logit_p &amp;lt;- a + b*x,&#xA;        a ~ normal(0,1.5),&#xA;        b ~ normal(0,0.5)&#xA;    ) , data=dat , &#xA;    cmdstan=TRUE , threads=2 , refresh=1000 )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are models that cannot be automaticaly multithreaded this way, because of the complexity of the code. In those cases, you can write the code directly in Stan. See &lt;a href=&#34;https://mc-stan.org/users/documentation/case-studies/reduce_sum_tutorial.html&#34;&gt;this guide&lt;/a&gt;. Writing multithreaded models direct in Stan can also be more efficient, since you can make detailed choices about which variables to pass and which pieces of the model to multithread.&lt;/p&gt; &#xA;&lt;h2&gt;Work in progress&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;ulam&lt;/code&gt; is still in development, but mostly feature complete. It will remain primarily a teaching tool, exposing the statistical details of the model while hiding some of the programming details necessary in Stan.&lt;/p&gt; &#xA;&lt;h1&gt;&lt;code&gt;map2stan&lt;/code&gt; syntax and features&lt;/h1&gt; &#xA;&lt;p&gt;The older &lt;code&gt;map2stan&lt;/code&gt; function makes stronger assumtions about the formulas it will see. This allows is to provide some additional automation and it has some special syntax as a result. &lt;code&gt;ulam&lt;/code&gt; in contrast supports such features through its macros library.&lt;/p&gt; &#xA;&lt;h2&gt;Non-centered parameterization&lt;/h2&gt; &#xA;&lt;p&gt;Here is a non-centered parameterization that moves the scale parameters in the varying effects prior to the linear model, which is often more efficient for sampling:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;f4u &amp;lt;- alist(&#xA;    y ~ dnorm( mu , sigma ),&#xA;    mu &amp;lt;- a + zaj[group]*sigma_group[1] + &#xA;         (b + zbj[group]*sigma_group[2])*x,&#xA;    c(zaj,zbj)[group] ~ dmvnorm( 0 , Rho_group ),&#xA;    a ~ dnorm( 0 , 10 ),&#xA;    b ~ dnorm( 0 , 1 ),&#xA;    sigma ~ dcauchy( 0 , 1 ),&#xA;    sigma_group ~ dcauchy( 0 , 1 ),&#xA;    Rho_group ~ dlkjcorr(2)&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Chapter 13 of the book provides a lot more detail on this issue.&lt;/p&gt; &#xA;&lt;p&gt;We can take this strategy one step further and remove the correlation matrix, &lt;code&gt;Rho_group&lt;/code&gt;, from the prior as well. &lt;code&gt;map2stan&lt;/code&gt; facilitates this form via the &lt;code&gt;dmvnormNC&lt;/code&gt; density, which uses an internal Cholesky decomposition of the correlation matrix to build the varying effects. Here is the previous varying slopes model, now with the non-centered notation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;f4nc &amp;lt;- alist(&#xA;    y ~ dnorm( mu , sigma ),&#xA;    mu &amp;lt;- a + aj[group] + (b + bj[group])*x,&#xA;    c(aj,bj)[group] ~ dmvnormNC( sigma_group , Rho_group ),&#xA;    a ~ dnorm( 0 , 10 ),&#xA;    b ~ dnorm( 0 , 1 ),&#xA;    sigma ~ dcauchy( 0 , 1 ),&#xA;    sigma_group ~ dcauchy( 0 , 1 ),&#xA;    Rho_group ~ dlkjcorr(2)&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Internally, a Cholesky factor &lt;code&gt;L_Rho_group&lt;/code&gt; is used to perform sampling. It will appear in the returned samples, in addition to &lt;code&gt;Rho_group&lt;/code&gt;, which is constructed from it.&lt;/p&gt; &#xA;&lt;h2&gt;Semi-automated Bayesian imputation&lt;/h2&gt; &#xA;&lt;p&gt;It is possible to code simple Bayesian imputations. For example, let&#39;s simulate a simple regression with missing predictor values:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;N &amp;lt;- 100&#xA;N_miss &amp;lt;- 10&#xA;x &amp;lt;- rnorm( N )&#xA;y &amp;lt;- rnorm( N , 2*x , 1 )&#xA;x[ sample(1:N,size=N_miss) ] &amp;lt;- NA&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That removes 10 &lt;code&gt;x&lt;/code&gt; values. Then the &lt;code&gt;map2stan&lt;/code&gt; formula list just defines a distribution for &lt;code&gt;x&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;f5 &amp;lt;- alist(&#xA;    y ~ dnorm( mu , sigma ),&#xA;    mu &amp;lt;- a + b*x,&#xA;    x ~ dnorm( mu_x, sigma_x ),&#xA;    a ~ dnorm( 0 , 100 ),&#xA;    b ~ dnorm( 0  , 10 ),&#xA;    mu_x ~ dnorm( 0 , 100 ),&#xA;    sigma_x ~ dcauchy(0,2),&#xA;    sigma ~ dcauchy(0,2)&#xA;)&#xA;m5 &amp;lt;- map2stan( f5 , data=list(y=y,x=x) )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;What &lt;code&gt;map2stan&lt;/code&gt; does is notice the missing values, see the distribution assigned to the variable with the missing values, build the Stan code that uses a mix of observed and estimated &lt;code&gt;x&lt;/code&gt; values in the regression. See the &lt;code&gt;stancode(m5)&lt;/code&gt; for details of the implementation.&lt;/p&gt; &#xA;&lt;h2&gt;Semi-automated marginalization for binary discrete missing values&lt;/h2&gt; &#xA;&lt;p&gt;Binary (0/1) variables with missing values present a special obstacle, because Stan cannot sample discrete parameters. So instead of imputing binary missing values, &lt;code&gt;map2stan&lt;/code&gt; can average (marginalize) over them. As in the above case, when &lt;code&gt;map2stan&lt;/code&gt; detects missing values in a predictor variable, it will try to find a distribution for the variable containing them. If this variable is binary (0/1), then it will construct a mixture model in which each term is the log-likelihood conditional on the variables taking a particular combination of 0/1 values.&lt;/p&gt; &#xA;&lt;p&gt;Following the example in the previous section, we can simulate missingness in a binary predictor:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;N &amp;lt;- 100&#xA;N_miss &amp;lt;- 10&#xA;x &amp;lt;- rbinom( N , size=1 , prob=0.5 )&#xA;y &amp;lt;- rnorm( N , 2*x , 1 )&#xA;x[ sample(1:N,size=N_miss) ] &amp;lt;- NA&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The model definition is analogous to the previous, but also requires some care in specifying constraints for the hyperparameters that define the distribution for &lt;code&gt;x&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;f6 &amp;lt;- alist(&#xA;    y ~ dnorm( mu , sigma ),&#xA;    mu &amp;lt;- a + b*x,&#xA;    x ~ bernoulli( phi ),&#xA;    a ~ dnorm( 0 , 100 ),&#xA;    b ~ dnorm( 0  , 10 ),&#xA;    phi ~ beta( 1 , 1 ),&#xA;    sigma ~ dcauchy(0,2)&#xA;)&#xA;m6 &amp;lt;- map2stan( f6 , data=list(y=y,x=x) , constraints=list(phi=&#34;lower=0,upper=1&#34;) )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The algorithm works, in theory, for any number of binary predictors with missing values. For example, with two predictors, each with missingness:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;N &amp;lt;- 100&#xA;N_miss &amp;lt;- 10&#xA;x1 &amp;lt;- rbinom( N , size=1 , prob=0.5 )&#xA;x2 &amp;lt;- rbinom( N , size=1 , prob=0.1 )&#xA;y &amp;lt;- rnorm( N , 2*x1 - x2  , 1 )&#xA;x1[ sample(1:N,size=N_miss) ] &amp;lt;- NA&#xA;x2[ sample(1:N,size=N_miss) ] &amp;lt;- NA&#xA;f7 &amp;lt;- alist(&#xA;    y ~ dnorm( mu , sigma ),&#xA;    mu &amp;lt;- a + b1*x1 + b2*x2,&#xA;    x1 ~ bernoulli( phi1 ),&#xA;    x2 ~ bernoulli( phi2 ),&#xA;    a ~ dnorm( 0 , 100 ),&#xA;    c(b1,b2) ~ dnorm( 0  , 10 ),&#xA;    phi1 ~ beta( 1 , 1 ),&#xA;    phi2 ~ beta( 1 , 1 ),&#xA;    sigma ~ dcauchy(0,2)&#xA;)&#xA;m7 &amp;lt;- map2stan( f7 , data=list(y=y,x1=x1,x2=x2) , &#xA;      constraints=list(phi1=&#34;lower=0,upper=1&#34;,phi2=&#34;lower=0,upper=1&#34;) )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;While the unobserved values for the binary predictors are usually not of interest, they can be computed from the posterior distribution. Adding the argument &lt;code&gt;do_discrete_imputation=TRUE&lt;/code&gt; instructs &lt;code&gt;map2stan&lt;/code&gt; to perform these calculations automatically. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;m6 &amp;lt;- map2stan( f6 , data=list(y=y,x=x) , constraints=list(phi=&#34;lower=0,upper=1&#34;) ,&#xA;      do_discrete_imputation=TRUE )&#xA;precis( m6 , depth=2 )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The output contains samples for each case with imputed probilities that &lt;code&gt;x&lt;/code&gt; takes the value 1.&lt;/p&gt; &#xA;&lt;p&gt;The algorithm works by constructing a list of mixture terms that are needed to to compute the probability of each observed &lt;code&gt;y&lt;/code&gt; value. In the simplest case, with only one predictor with missing values, the implied mixture likelihood contains two terms:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Pr(y[i]) = Pr(x[i]=1)Pr(y[i]|x[i]=1) + Pr(x[i]=0)Pr(y[i]|x[i]=0)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the parameters of our example model &lt;code&gt;m6&lt;/code&gt; above, this is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Pr(y[i]) = phi*N(y[i]|a+b,sigma) + (1-phi)*N(y[i]|a,sigma)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It is now a simple matter to loop over cases &lt;code&gt;i&lt;/code&gt; and compute the above for each. Similarly the posterior probability of that &lt;code&gt;x[i]==1&lt;/code&gt; is given as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Pr(x[i]==1|y[i]) = phi*N(y[i]|a+b,sigma) / Pr(y[i])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When only one predictor has missingness, then this is simple. What about when there are two or more? In that case, all the possible combinations of missingness have to be accounted for. For example, suppose there are two predictors, &lt;code&gt;x1&lt;/code&gt; and &lt;code&gt;x2&lt;/code&gt;, both with missingness on case &lt;code&gt;i&lt;/code&gt;. Now the implied mixture likelihood is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Pr(y[i]) = Pr(x1=1)Pr(x2=1)*Pr(y[i]|x1=1,x2=1) + Pr(x1=1)Pr(x2=0)Pr(y[i]|x1=1,x2=0) + Pr(x1=0)Pr(x2=1)Pr(y[i]|x1=0,x2=1) + Pr(x1=0)Pr(x2=0)Pr(y[i]|x1=0,x2=0)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are four combinations of unobserved values, and so four terms in the mixture likelihood. When &lt;code&gt;x2&lt;/code&gt; is instead observed, we can substitute the observed value into the above, and then the mixture simplifies readily to our previous two-term likelihood:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Pr(y[i]|x2[i]==1) = Pr(x1=1)Pr(x2=1)Pr(y[i]|x1=1,x2=1) + Pr(x1=1)Pr(x2=0)Pr(y[i]|x1=1,x2=1) + Pr(x1=0)Pr(x2=1)Pr(y[i]|x1=0,x2=1) + Pr(x1=0)Pr(x2=0)Pr(y[i]|x1=0,x2=1)&#xA;                  = [Pr(x1=1)Pr(x2=1)+Pr(x1=1)Pr(x2=0)]Pr(y[i]|x1=1,x2=1) &#xA;                    + [Pr(x1=0)Pr(x2=1)+Pr(x1=0)Pr(x2=0)]Pr(y[i]|x1=0,x2=1)&#xA;                  = Pr(x1=1)Pr(y[i]|x1=1,x2=1) + Pr(x1=0)Pr(y[i]|x1=0,x2=1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This implies that if we loop over cases &lt;code&gt;i&lt;/code&gt; and insert any observed values into the general mixture likelihood, we can compute the relevant mixture for the specific combination of missingness on each case &lt;code&gt;i&lt;/code&gt;. That is what &lt;code&gt;map2stan&lt;/code&gt; does. The general mixture terms can be generated algorithmically. The code below generates a matrix of terms for &lt;code&gt;n&lt;/code&gt; binary variables with missingness.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ncombinations &amp;lt;- 2^n&#xA;d &amp;lt;- matrix(NA,nrow=ncombinations,ncol=n)&#xA;for ( col_var in 1:n ) &#xA;    d[,col_var] &amp;lt;- rep( 0:1 , each=2^(col_var-1) , length.out=ncombinations )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Rows of &lt;code&gt;d&lt;/code&gt; contain terms, columns contain variables, and the values in each column are the corresponding values of each variable. The algorithm builds a linear model for each row in this matrix, composes the mixture likelihood as the sum of these rows, and performs proper substitutions of observed values. All calculations are done on the log scale, for precision.&lt;/p&gt; &#xA;&lt;h2&gt;Gaussian process&lt;/h2&gt; &#xA;&lt;p&gt;A basic Gaussian process can be specified with the &lt;code&gt;GPL2&lt;/code&gt; distribution label. This implies a multivariate Gaussian with a covariance matrix defined by the ordinary L2 norm distance function:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;k(i,j) = eta^2 * exp( -rho^2 * D(i,j)^2 ) + ifelse(i==j,sigma^2,0)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;D&lt;/code&gt; is a matrix of pairwise distances. To use this convention in, for example, a spatial autocorrelation model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;library(rethinking)&#xA;data(Kline2)&#xA;d &amp;lt;- Kline2&#xA;data(islandsDistMatrix)&#xA;d$society &amp;lt;- 1:10&#xA;mGP &amp;lt;- map2stan(&#xA;    alist(&#xA;        total_tools ~ dpois( mu ),&#xA;        log(mu) &amp;lt;- a + aj[society],&#xA;        a ~ dnorm(0,10),&#xA;        aj[society] ~ GPL2( Dmat , etasq , rhosq , 0.01 ),&#xA;        etasq ~ dcauchy(0,1),&#xA;        rhosq ~ dcauchy(0,1)&#xA;    ),&#xA;    data=list(&#xA;        total_tools=d$total_tools,&#xA;        society=d$society,&#xA;        Dmat=islandsDistMatrix),&#xA;    constraints=list(&#xA;        etasq=&#34;lower=0&#34;,&#xA;        rhosq=&#34;lower=0&#34;&#xA;    ),&#xA;    warmup=1000 , iter=5000 , chains=4 )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note the use of the &lt;code&gt;constraints&lt;/code&gt; list to pass custom parameter constraints to Stan. This example is explored in more detail in the book.&lt;/p&gt; &#xA;&lt;h2&gt;Information criteria&lt;/h2&gt; &#xA;&lt;p&gt;Both &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;map2stan&lt;/code&gt; provide DIC and WAIC. Well, in most cases they do. In truth, both tools are flexible enough that you can specify models for which neither DIC nor WAIC can be correctly calculated. But for ordinary GLMs and GLMMs, it works. See the R help &lt;code&gt;?WAIC&lt;/code&gt;. A convenience function &lt;code&gt;compare&lt;/code&gt; summarizes information criteria comparisons, including standard errors for WAIC.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ulam&lt;/code&gt; supports WAIC calculation with the optional &lt;code&gt;log_lik=TRUE&lt;/code&gt; argument, which returns the kind of log-likelihood vector needed by the &lt;code&gt;loo&lt;/code&gt; package.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;ensemble&lt;/code&gt; computes &lt;code&gt;link&lt;/code&gt; and &lt;code&gt;sim&lt;/code&gt; output for an ensemble of models, each weighted by its Akaike weight, as computed from WAIC.&lt;/p&gt; &#xA;&lt;h1&gt;Code issues with 1st edition of Statistical Rethinking&lt;/h1&gt; &#xA;&lt;p&gt;A small change to &lt;code&gt;link&lt;/code&gt; has broken two examples in the first edition of the book, in Chapter 7.&lt;/p&gt; &#xA;&lt;h2&gt;R code 7.10&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;mu.Africa.mean &amp;lt;- apply( mu.Africa , 2 , mean ) Error in apply(mu.Africa, 2, mean) : dim(X) must have a positive length&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;This occurs because link() now returns all linear models. So mu.Africa is a list containing mu and gamma. To fix, use:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;mu.Africa.mean &amp;lt;- apply( mu.Africa$mu , 2 , mean )&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Use a similar fix in the other apply() calls in the same section.&lt;/p&gt; &#xA;&lt;h2&gt;R code 7.17&lt;/h2&gt; &#xA;&lt;p&gt;Similar problem as for R code 7.10. Use mu.ruggedlo$mu in place of mu.ruggedlo.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mojaveazure/seurat-disk</title>
    <updated>2022-06-05T01:54:54Z</updated>
    <id>tag:github.com,2022-06-05:/mojaveazure/seurat-disk</id>
    <link href="https://github.com/mojaveazure/seurat-disk" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Interfaces for HDF5-based Single Cell File Formats&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeuratDisk v0.0.0.9015&lt;/h1&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=SeuratDisk&#34;&gt;&lt;img src=&#34;https://img.shields.io/cran/v/SeuratDisk&#34; alt=&#34;CRAN/METACRAN&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mojaveazure/seurat-disk&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/lifecycle-experimental-orange.svg?sanitize=true&#34; alt=&#34;Lifecycle&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;!-- Interfaces for HDF5-based Single Cell File Formats --&gt; &#xA;&lt;p&gt;The h5Seurat file format is specifically designed for the storage and analysis of multi-modal single-cell and spatially-resolved expression experiments, for example, from CITE-seq or 10X Visium technologies. It holds all molecular information and associated metadata, including (for example) nearest-neighbor graphs, dimensional reduction information, spatial coordinates and image data, and cluster labels. We also support rapid and on-disk conversion between h5Seurat and AnnData objects, with the goal of enhancing interoperability between Seurat and Scanpy.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;SeuratDisk is not currently available on CRAN. You can install it from &lt;a href=&#34;https://github.com/mojaveazure/seurat-disk&#34;&gt;GitHub&lt;/a&gt; with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;if (!requireNamespace(&#34;remotes&#34;, quietly = TRUE)) {&#xA;  install.packages(&#34;remotes&#34;)&#xA;}&#xA;remotes::install_github(&#34;mojaveazure/seurat-disk&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;SeuratDisk depends on the following non-standard packages:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Package&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;CRAN Webpage&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Source&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Website&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;cli&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=cli&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/r-lib/cli#readme&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;–&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;crayon&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=crayon&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/r-lib/crayon#readme&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;–&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;hdf5r&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=hdf5r&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/hhoeflin/hdf5r&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://hhoeflin.github.io/hdf5r/&#34;&gt;Website&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Matrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=Matrix&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;–&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://Matrix.R-forge.R-project.org/&#34;&gt;Website&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;R6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=R6&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/r-lib/R6/&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://r6.r-lib.org&#34;&gt;Website&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;rlang&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=rlang&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/r-lib/rlang&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://rlang.r-lib.org&#34;&gt;Website&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Seurat&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=Seurat&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/satijalab/seurat&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://satijalab.org/seurat&#34;&gt;Website&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;SeuratObject&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=SeuratObject&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/mojaveazure/seurat-object&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://satijalab.org/seurat&#34;&gt;Website&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;stringi&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=stringi&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;–&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;[Website](&lt;a href=&#34;https://stringi.gagolewski.com/&#34;&gt;https://stringi.gagolewski.com/&lt;/a&gt; &lt;a href=&#34;http://site.icu-project.org/&#34;&gt;http://site.icu-project.org/&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.unicode.org/&#34;&gt;https://www.unicode.org/&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;withr&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/package=withr&#34;&gt;CRAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/r-lib/withr#readme&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://withr.r-lib.org&#34;&gt;Website&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>jennybc/gapminder</title>
    <updated>2022-06-05T01:54:54Z</updated>
    <id>tag:github.com,2022-06-05:/jennybc/gapminder</id>
    <link href="https://github.com/jennybc/gapminder" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Excerpt from the Gapminder data, as an R data package and in plain text delimited form&lt;/p&gt;&lt;hr&gt;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#gapminder&#34;&gt;gapminder&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#install-and-test-drive&#34;&gt;Install and test drive&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#color-schemes-for-countries-and-continents&#34;&gt;Color schemes for countries and continents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#how-to-use-color-scheme-in-ggplot2&#34;&gt;How to use color scheme in &lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#how-to-use-color-scheme-in-base-graphics&#34;&gt;How to use color scheme in base graphics&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#iso-3166-1-country-codes&#34;&gt;ISO 3166-1 country codes&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#what-is-gapminder-good-for&#34;&gt;What is &lt;code&gt;gapminder&lt;/code&gt; good for?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#how-this-sausage-was-made&#34;&gt;How this sausage was made&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#plain-text-delimited-files&#34;&gt;Plain text delimited files&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/#citation&#34;&gt;Citation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://doi.org/10.5281/zenodo.594018&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.594018.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://cran.r-project.org/package=gapminder&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/gapminder&#34; alt=&#34;CRAN version&#34;&gt;&lt;/a&gt; &lt;img src=&#34;http://cranlogs.r-pkg.org/badges/grand-total/gapminder&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;gapminder&lt;/h1&gt; &#xA;&lt;p&gt;Excerpt from the &lt;a href=&#34;http://www.gapminder.org/data/&#34;&gt;Gapminder&lt;/a&gt; data. The main object in this package is the &lt;code&gt;gapminder&lt;/code&gt; data frame or “tibble”. There are other goodies, such as the data in tab delimited form, a larger unfiltered dataset, premade color schemes for the countries and continents, and ISO 3166-1 country codes.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;gapminder&lt;/code&gt; data frames include six variables, (&lt;a href=&#34;http://www.gapminder.org/data/documentation/&#34;&gt;Gapminder.org documentation page&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;variable&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;meaning&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;country&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;continent&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;year&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;lifeExp&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;life expectancy at birth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;pop&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;total population&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;gdpPercap&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;per-capita GDP&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Per-capita GDP (Gross domestic product) is given in units of &lt;a href=&#34;http://en.wikipedia.org/wiki/Geary%E2%80%93Khamis_dollar&#34;&gt;international dollars&lt;/a&gt;, “a hypothetical unit of currency that has the same purchasing power parity that the U.S. dollar had in the United States at a given point in time” – 2005, in this case.&lt;/p&gt; &#xA;&lt;p&gt;Package contains two main data frames or tibbles:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;gapminder&lt;/code&gt;: 12 rows for each country (1952, 1955, …, 2007). It’s a subset of …&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;gapminder_unfiltered&lt;/code&gt;: more lightly filtered and therefore about twice as many rows.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: this package exists for the purpose of teaching and making code examples. It is an excerpt of data found in specific spreadsheets on Gapminder.org circa 2010. It is not a definitive source of socioeconomic data and I don’t update it. Use other data sources if it’s important to have the current best estimate of these statistics.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Install and test drive&lt;/h3&gt; &#xA;&lt;p&gt;Install &lt;code&gt;gapminder&lt;/code&gt; from CRAN:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;gapminder&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or you can install &lt;code&gt;gapminder&lt;/code&gt; from GitHub:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&#34;jennybc/gapminder&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Load it and test drive with some data aggregation and plotting:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&#34;gapminder&#34;)&#xA;&#xA;aggregate(lifeExp ~ continent, gapminder, median)&#xA;#&amp;gt;   continent lifeExp&#xA;#&amp;gt; 1    Africa 47.7920&#xA;#&amp;gt; 2  Americas 67.0480&#xA;#&amp;gt; 3      Asia 61.7915&#xA;#&amp;gt; 4    Europe 72.2410&#xA;#&amp;gt; 5   Oceania 73.6650&#xA;&#xA;library(&#34;dplyr&#34;)&#xA;gapminder %&amp;gt;%&#xA;    filter(year == 2007) %&amp;gt;%&#xA;    group_by(continent) %&amp;gt;%&#xA;    summarise(lifeExp = median(lifeExp))&#xA;#&amp;gt; # A tibble: 5 x 2&#xA;#&amp;gt;   continent lifeExp&#xA;#&amp;gt;   &amp;lt;fct&amp;gt;       &amp;lt;dbl&amp;gt;&#xA;#&amp;gt; 1 Africa       52.9&#xA;#&amp;gt; 2 Americas     72.9&#xA;#&amp;gt; 3 Asia         72.4&#xA;#&amp;gt; 4 Europe       78.6&#xA;#&amp;gt; 5 Oceania      80.7&#xA;    &#xA;library(&#34;ggplot2&#34;)&#xA;ggplot(gapminder, aes(x = continent, y = lifeExp)) +&#xA;  geom_boxplot(outlier.colour = &#34;hotpink&#34;) +&#xA;  geom_jitter(position = position_jitter(width = 0.1, height = 0), alpha = 1/4)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/man/figures/README-test-drive-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;Color schemes for countries and continents&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;country_colors&lt;/code&gt; and &lt;code&gt;continent_colors&lt;/code&gt; are provided as character vectors where elements are hex colors and the names are countries or continents.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(country_colors, 4)&#xA;#&amp;gt;          Nigeria            Egypt         Ethiopia Congo, Dem. Rep. &#xA;#&amp;gt;        &#34;#7F3B08&#34;        &#34;#833D07&#34;        &#34;#873F07&#34;        &#34;#8B4107&#34;&#xA;head(continent_colors)&#xA;#&amp;gt;    Africa  Americas      Asia    Europe   Oceania &#xA;#&amp;gt; &#34;#7F3B08&#34; &#34;#A50026&#34; &#34;#40004B&#34; &#34;#276419&#34; &#34;#313695&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/man/figures/gapminder-color-scheme-ggplot2.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;p&gt;The country scheme is available in this repo as&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/data-raw/gapminder-color-scheme-ggplot2.png&#34;&gt;PNG&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/data-raw/gapminder-color-scheme-base.pdf&#34;&gt;PDF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/inst/extdata/continent-colors.tsv&#34;&gt;&lt;code&gt;continent-colors.tsv&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/inst/extdata/country-colors.tsv&#34;&gt;&lt;code&gt;country-colors.tsv&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;How to use color scheme in &lt;code&gt;ggplot2&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Provide &lt;code&gt;country_colors&lt;/code&gt; to &lt;code&gt;scale_color_manual()&lt;/code&gt; like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;... + scale_color_manual(values = country_colors) + ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&#34;ggplot2&#34;)&#xA;&#xA;ggplot(subset(gapminder, continent != &#34;Oceania&#34;),&#xA;       aes(x = year, y = lifeExp, group = country, color = country)) +&#xA;  geom_line(lwd = 1, show.legend = FALSE) + facet_wrap(~ continent) +&#xA;  scale_color_manual(values = country_colors) +&#xA;  theme_bw() + theme(strip.text = element_text(size = rel(1.1)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/man/figures/README-demo-country-colors-ggplot2-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;How to use color scheme in base graphics&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# for convenience, integrate the country colors into the data.frame&#xA;gap_with_colors &amp;lt;-&#xA;  data.frame(gapminder,&#xA;             cc = I(country_colors[match(gapminder$country,&#xA;                                         names(country_colors))]))&#xA;&#xA;# bubble plot, focus just on Africa and Europe in 2007&#xA;keepers &amp;lt;- with(gap_with_colors,&#xA;                continent %in% c(&#34;Africa&#34;, &#34;Europe&#34;) &amp;amp; year == 2007)&#xA;plot(lifeExp ~ gdpPercap, gap_with_colors,&#xA;     subset = keepers, log = &#34;x&#34;, pch = 21,&#xA;     cex = sqrt(gap_with_colors$pop[keepers]/pi)/1500,&#xA;     bg = gap_with_colors$cc[keepers])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/man/figures/README-demo-country-colors-base-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;ISO 3166-1 country codes&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;country_codes&lt;/code&gt; data frame provides ISO 3166-1 country codes for all the countries in the &lt;code&gt;gapminder&lt;/code&gt; and &lt;code&gt;gapminder_unfiltered&lt;/code&gt; data frames. This can be used to practice joining or merging.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(dplyr)&#xA;&#xA;gapminder %&amp;gt;%&#xA; filter(year == 2007, country %in% c(&#34;Kenya&#34;, &#34;Peru&#34;, &#34;Syria&#34;)) %&amp;gt;%&#xA; select(country, continent) %&amp;gt;% &#xA; left_join(country_codes)&#xA;#&amp;gt; Warning: Column `country` joining factor and character vector, coercing&#xA;#&amp;gt; into character vector&#xA;#&amp;gt; # A tibble: 3 x 4&#xA;#&amp;gt;   country continent iso_alpha iso_num&#xA;#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;chr&amp;gt;       &amp;lt;int&amp;gt;&#xA;#&amp;gt; 1 Kenya   Africa    KEN           404&#xA;#&amp;gt; 2 Peru    Americas  PER           604&#xA;#&amp;gt; 3 Syria   Asia      SYR           760&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;What is &lt;code&gt;gapminder&lt;/code&gt; good for?&lt;/h3&gt; &#xA;&lt;p&gt;I have used this excerpt in &lt;a href=&#34;http://stat545-ubc.github.io&#34;&gt;STAT 545&lt;/a&gt; since 2008 and, more recently, in &lt;a href=&#34;http://jennybc.github.io/2014-05-12-ubc/&#34;&gt;R-flavored Software Carpentry Workshops&lt;/a&gt; and a &lt;a href=&#34;https://github.com/jennybc/ggplot2-tutorial&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt; tutorial&lt;/a&gt;. &lt;code&gt;gapminder&lt;/code&gt; is very useful for teaching novices data wrangling and visualization in R.&lt;/p&gt; &#xA;&lt;p&gt;Description:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;1704 observations; fills a size niche between &lt;code&gt;iris&lt;/code&gt; (150 rows) and the likes of &lt;code&gt;diamonds&lt;/code&gt; (54K rows)&lt;/li&gt; &#xA; &lt;li&gt;6 variables &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;country&lt;/code&gt; a factor with 142 levels&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;continent&lt;/code&gt;, a factor with 5 levels&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;year&lt;/code&gt;: going from 1952 to 2007 in increments of 5 years&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;pop&lt;/code&gt;: population&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;gdpPercap&lt;/code&gt;: GDP per capita&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;lifeExp&lt;/code&gt;: life expectancy&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;There are 12 rows for each country in &lt;code&gt;gapminder&lt;/code&gt;, i.e.&amp;nbsp;complete data for 1952, 1955, …, 2007.&lt;/p&gt; &#xA;&lt;p&gt;The two factors provide opportunities to demonstrate factor handling, in aggregation and visualization, for factors with very few and very many levels.&lt;/p&gt; &#xA;&lt;p&gt;The four quantitative variables are generally quite correlated with each other and these trends have interesting relationships to &lt;code&gt;country&lt;/code&gt; and &lt;code&gt;continent&lt;/code&gt;, so you will find that simple plots and aggregations tell a reasonable story and are not completely boring.&lt;/p&gt; &#xA;&lt;p&gt;Visualization of the temporal trends in life expectancy, by country, is particularly rewarding, since there are several countries with sharp drops due to political upheaval. This then motivates more systematic investigations via data aggregation to proactively identify all countries whose data exhibits certain properties.&lt;/p&gt; &#xA;&lt;h3&gt;How this sausage was made&lt;/h3&gt; &#xA;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;en&#34;&gt; &#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;p&gt;Data cleaning code cannot be clean. It&#39;s a sort of sin eater.&lt;/p&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA; &lt;p&gt;— Stat Fact (@StatFact) &lt;a href=&#34;https://twitter.com/StatFact/status/492753200190341120&#34;&gt;July 25, 2014&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/data-raw/&#34;&gt;&lt;code&gt;data-raw&lt;/code&gt;&lt;/a&gt; directory contains the Excel spreadsheets downloaded from &lt;a href=&#34;http://www.gapminder.org&#34;&gt;Gapminder&lt;/a&gt; in 2008 and 2009 and all the scripts necessary to create everything in this package, in raw and “compiled notebook” form.&lt;/p&gt; &#xA;&lt;h3&gt;Plain text delimited files&lt;/h3&gt; &#xA;&lt;p&gt;If you want to practice importing from file, various tab delimited files are included:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/inst/extdata/gapminder.tsv&#34;&gt;&lt;code&gt;gapminder.tsv&lt;/code&gt;&lt;/a&gt;: the same dataset available via &lt;code&gt;library(&#34;gapminder&#34;); gapminder&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/inst/extdata/gapminder-unfiltered.tsv&#34;&gt;&lt;code&gt;gapminder-unfiltered.tsv&lt;/code&gt;&lt;/a&gt;: the larger dataset available via &lt;code&gt;library(&#34;gapminder&#34;); gapminder_unfiltered&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/inst/extdata/continent-colors.tsv&#34;&gt;&lt;code&gt;continent-colors.tsv&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/inst/extdata/country-colors.tsv&#34;&gt;&lt;code&gt;country-colors.tsv&lt;/code&gt;&lt;/a&gt;: color schemes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Here in the source, these delimited files can be found:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;in the &lt;a href=&#34;https://raw.githubusercontent.com/jennybc/gapminder/main/inst/extdata/&#34;&gt;&lt;code&gt;inst/extdata/&lt;/code&gt;&lt;/a&gt; sub-directory&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Once you’ve installed the &lt;code&gt;gapminder&lt;/code&gt; package they can be found locally and used like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gap_tsv &amp;lt;- system.file(&#34;extdata&#34;, &#34;gapminder.tsv&#34;, package = &#34;gapminder&#34;)&#xA;gap_tsv &amp;lt;- read.delim(gap_tsv)&#xA;str(gap_tsv)&#xA;#&amp;gt; &#39;data.frame&#39;:    1704 obs. of  6 variables:&#xA;#&amp;gt;  $ country  : Factor w/ 142 levels &#34;Afghanistan&#34;,..: 1 1 1 1 1 1 1 1 1 1 ...&#xA;#&amp;gt;  $ continent: Factor w/ 5 levels &#34;Africa&#34;,&#34;Americas&#34;,..: 3 3 3 3 3 3 3 3 3 3 ...&#xA;#&amp;gt;  $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...&#xA;#&amp;gt;  $ lifeExp  : num  28.8 30.3 32 34 36.1 ...&#xA;#&amp;gt;  $ pop      : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...&#xA;#&amp;gt;  $ gdpPercap: num  779 821 853 836 740 ...&#xA;gap_tsv %&amp;gt;% # Bhutan did not make the cut because data for only 8 years :(&#xA;  filter(country == &#34;Bhutan&#34;)&#xA;#&amp;gt; [1] country   continent year      lifeExp   pop       gdpPercap&#xA;#&amp;gt; &amp;lt;0 rows&amp;gt; (or 0-length row.names)&#xA;&#xA;gap_bigger_tsv &amp;lt;-&#xA;  system.file(&#34;extdata&#34;, &#34;gapminder-unfiltered.tsv&#34;, package = &#34;gapminder&#34;)&#xA;gap_bigger_tsv &amp;lt;- read.delim(gap_bigger_tsv)&#xA;str(gap_bigger_tsv)&#xA;#&amp;gt; &#39;data.frame&#39;:    3313 obs. of  6 variables:&#xA;#&amp;gt;  $ country  : Factor w/ 187 levels &#34;Afghanistan&#34;,..: 1 1 1 1 1 1 1 1 1 1 ...&#xA;#&amp;gt;  $ continent: Factor w/ 6 levels &#34;Africa&#34;,&#34;Americas&#34;,..: 3 3 3 3 3 3 3 3 3 3 ...&#xA;#&amp;gt;  $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...&#xA;#&amp;gt;  $ lifeExp  : num  28.8 30.3 32 34 36.1 ...&#xA;#&amp;gt;  $ pop      : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...&#xA;#&amp;gt;  $ gdpPercap: num  779 821 853 836 740 ...&#xA;gap_bigger_tsv %&amp;gt;% # Bhutan IS here though! :)&#xA;  filter(country == &#34;Bhutan&#34;)&#xA;#&amp;gt;   country continent year lifeExp     pop gdpPercap&#xA;#&amp;gt; 1  Bhutan      Asia 1972  41.837 1087991  807.6226&#xA;#&amp;gt; 2  Bhutan      Asia 1977  44.708 1205659  816.3102&#xA;#&amp;gt; 3  Bhutan      Asia 1982  47.872 1333704  946.8130&#xA;#&amp;gt; 4  Bhutan      Asia 1987  50.717 1490857 1494.2901&#xA;#&amp;gt; 5  Bhutan      Asia 1992  54.471 1673428 1904.1795&#xA;#&amp;gt; 6  Bhutan      Asia 1997  58.929 1876236 2561.5077&#xA;#&amp;gt; 7  Bhutan      Asia 2002  63.458 2094176 3256.0193&#xA;#&amp;gt; 8  Bhutan      Asia 2007  65.625 2327849 4744.6400&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Gapminder’s data is released under the Creative Commons Attribution 3.0 Unported license. See their &lt;a href=&#34;https://docs.google.com/document/pub?id=1POd-pBMc5vDXAmxrpGjPLaCSDSWuxX6FLQgq5DhlUhM&#34;&gt;terms of use&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Run this command to get info on how to cite this package. If you’ve installed gapminder from CRAN, the year will be populated and populated correctly (unlike below).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;citation(&#34;gapminder&#34;)&#xA;#&amp;gt; &#xA;#&amp;gt; To cite package &#39;gapminder&#39; in publications use:&#xA;#&amp;gt; &#xA;#&amp;gt;   Jennifer Bryan (NA). gapminder: Data from Gapminder.&#xA;#&amp;gt;   https://github.com/jennybc/gapminder,&#xA;#&amp;gt;   http://www.gapminder.org/data/,&#xA;#&amp;gt;   https://doi.org/10.5281/zenodo.594018.&#xA;#&amp;gt; &#xA;#&amp;gt; A BibTeX entry for LaTeX users is&#xA;#&amp;gt; &#xA;#&amp;gt;   @Manual{,&#xA;#&amp;gt;     title = {gapminder: Data from Gapminder},&#xA;#&amp;gt;     author = {Jennifer Bryan},&#xA;#&amp;gt;     note = {https://github.com/jennybc/gapminder,&#xA;#&amp;gt; http://www.gapminder.org/data/,&#xA;#&amp;gt; https://doi.org/10.5281/zenodo.594018},&#xA;#&amp;gt;   }&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>