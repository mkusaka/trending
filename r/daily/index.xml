<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-24T01:42:25Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>linjf15/MR_tricks</title>
    <updated>2023-04-24T01:42:25Z</updated>
    <id>tag:github.com,2023-04-24:/linjf15/MR_tricks</id>
    <link href="https://github.com/linjf15/MR_tricks" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Post-GWAS analysis and Mendelian Randomization&lt;/h1&gt; &#xA;&lt;p&gt;During the study based on Mendelian Randomization, several functions were proposed to solve several common problems, including:&lt;/p&gt; &#xA;&lt;h2&gt;Special note&lt;/h2&gt; &#xA;&lt;p&gt;Recently, I noticed that some uploaders in Bilibili seem to sell my codes, such as &lt;a href=&#34;https://space.bilibili.com/295917932/&#34;&gt;Shining94&lt;/a&gt;. The original purpose of this project is to share my solutions to certain problems in Mendelian Randomization without charge. I urge those guys stop selling my codes, and I decide to not share my recent findings on MR. If you have any questions, leave me a message.&lt;/p&gt; &#xA;&lt;h2&gt;Preprocessing for exposure GWASs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;how to get rsID from chromosome and position: &lt;code&gt;get_rsID_from_chr_pos&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;how to find allele frequency, proxy of a given SNP: &lt;code&gt;snp_add_eaf&lt;/code&gt;, &lt;code&gt;snp_add_eaf_manual&lt;/code&gt;,&lt;code&gt;find_proxy&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;how to search pleiotropy for a given SNP: &lt;code&gt;snp_phenoscanner&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Exposure and outcome data harmonization&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;how to harmonize if direct removal is not allowed and proxy is required: &lt;code&gt;snp_replace_proxy&lt;/code&gt;, &lt;code&gt;harmonise_data_modified&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Main analysis for Mendelian Randomization&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;mr_meta&lt;/code&gt; is helpful conduct meta-analysis to pool estimates from different cohorts&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;mr_modified&lt;/code&gt; is alternative function to &lt;code&gt;mr&lt;/code&gt; in TwoSampleMR package, since the mr-raps cannot not be conducted in the original function&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;get_cohort_from_number&lt;/code&gt; transforms a number into a name of cohort&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;get_method_from_abbr&lt;/code&gt; transforms an abbreviation version of MR method into a full name&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;get_protein_from_uniprot&lt;/code&gt; transforms a UniProt ID to full name of protein, with UniProtRefPanel.xlsx as the reference panel&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;More functions are under developing...&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;data visualization: volcano plot, forest plot...&lt;/li&gt; &#xA; &lt;li&gt;colocolization&lt;/li&gt; &#xA; &lt;li&gt;TWAS&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Useful references&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mr-dictionary.mrcieu.ac.uk/&#34;&gt;MR dictionary&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Cohorts: &lt;a href=&#34;https://finngen.gitbook.io/documentation/&#34;&gt;FinnGen&lt;/a&gt;, &lt;a href=&#34;https://www.leelabsg.org/resources&#34;&gt;UK Biobank&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Algorithm: &lt;a href=&#34;https://github.com/qingyuanzhao/mr.raps&#34;&gt;MR-RAPS&lt;/a&gt;, &lt;a href=&#34;https://github.com/rondolab/MR-PRESSO&#34;&gt;MR-PRESSO&lt;/a&gt;, &lt;a href=&#34;https://github.com/gqi/MRMix&#34;&gt;MR-Mix&lt;/a&gt;, &lt;a href=&#34;https://github.com/xiaofengzhucase/IMRP&#34;&gt;IMRP&lt;/a&gt;, &lt;a href=&#34;https://github.com/bluosun/MR-GENIUS&#34;&gt;MR-GENIUS&lt;/a&gt;, &lt;a href=&#34;https://github.com/yuanzhongshang/MRAID&#34;&gt;MR-AID&lt;/a&gt;, &lt;a href=&#34;https://github.com/explodecomputer/tryx&#34;&gt;MR-TRYX&lt;/a&gt;, &lt;a href=&#34;https://github.com/jrs95/nlmr&#34;&gt;NLMR&lt;/a&gt;, &lt;a href=&#34;https://github.com/WSpiller/MVMR&#34;&gt;MVMR&lt;/a&gt;, &lt;a href=&#34;https://github.com/igbucur/BayesMR&#34;&gt;BayesMR&lt;/a&gt;, &lt;a href=&#34;https://github.com/william-denault/CFMR&#34;&gt;CFMR&lt;/a&gt;, &lt;a href=&#34;https://github.com/wanglu205/OMR&#34;&gt;OMR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Packages: &lt;a href=&#34;https://mrcieu.github.io/ieugwasr/articles/&#34;&gt;ieugwasr&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Dato-Futbol/soccerAnimate</title>
    <updated>2023-04-24T01:42:25Z</updated>
    <id>tag:github.com,2023-04-24:/Dato-Futbol/soccerAnimate</id>
    <link href="https://github.com/Dato-Futbol/soccerAnimate" rel="alternate"></link>
    <summary type="html">&lt;p&gt;R package to create 2D animations of soccer tracking data&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;soccerAnimate &lt;img src=&#34;https://raw.githubusercontent.com/Dato-Futbol/soccerAnimate/master/man/soccerAnimate.png&#34; width=&#34;160px&#34; align=&#34;right&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;An R package to create 2D animations of soccer tracking data&lt;/p&gt; &#xA;&lt;h2&gt;How to install it?&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;# install.packages(&#34;remotes&#34;)&#xA;remotes::install_github(&#34;Dato-Futbol/soccerAnimate&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How to use it?&lt;/h2&gt; &#xA;&lt;p&gt;Version 0.1.0 (23-08-2020) allows you to do the following tasks:&lt;/p&gt; &#xA;&lt;h3&gt;1) To get and process the data&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;get_tidy_data()&lt;/strong&gt; function reads, tidies and joins the rawdata of both the Home and Away teams. Currently only data from the provider Metrica Sport is supported. Even you could download the open tracking/event data following &lt;a href=&#34;https://github.com/metrica-sports/sample-data&#34;&gt;this link&lt;/a&gt;, it is also possible to get the processed data using the function &lt;em&gt;get_tidy_data()&lt;/em&gt; with the URLs of rawdata directly like the example for the Game 1:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;library(soccerAnimate)&#xA;home_team_file &amp;lt;- &#34;https://raw.githubusercontent.com/metrica-sports/sample-data/master/data/Sample_Game_1/Sample_Game_1_RawTrackingData_Home_Team.csv&#34;&#xA;away_team_file &amp;lt;- &#34;https://raw.githubusercontent.com/metrica-sports/sample-data/master/data/Sample_Game_1/Sample_Game_1_RawTrackingData_Away_Team.csv&#34;&#xA;td &amp;lt;- get_tidy_data(home_team_file, away_team_file)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have another dataset to share, please let me know in order to adapt the code.&lt;/p&gt; &#xA;&lt;h3&gt;2) To get events information&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;events_info()&lt;/strong&gt; function gets events information from the event dataset (Period, Team, Event, start and end time, start and end frame, etc.). You could get info for either shots, goals, free kicks or corner kicks. One of the current main usefulness of this is to know at which times/frames specific events occurs, then you will create both static plots and animations for those times/frames.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ed &amp;lt;- readr::read_csv(&#34;https://raw.githubusercontent.com/metrica-sports/sample-data/master/data/Sample_Game_1/Sample_Game_1_RawEventsData.csv&#34;)&#xA;goals &amp;lt;- events_info(ed, events = &#34;GOAL&#34;)&#xA;&#xA;# all_events &amp;lt;- events_info(ed, events = c(&#34;SHOT&#34;, &#34;GOAL&#34;, &#34;FREE KICK&#34;, &#34;CORNER KICK&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Dato-Futbol/soccerAnimate/master/man/goals_info.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;3) To create a 2D static plot&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;soccer_plot()&lt;/strong&gt; function creates a static plot of one specific and unique &lt;strong&gt;frame&lt;/strong&gt;. It is useful to explore and pre visualize your data, aesthetic and method setting, before to create the animation (whose creation time will be longer). You are able to export this plots as PNG files.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;soccer_plot(tidy_data = td, target_frame = 99035, export_png = T)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Dato-Futbol/soccerAnimate/master/man/plot.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;4) To create a 2D soccer animation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;soccer_animate()&lt;/strong&gt; function creates 2D soccer animations using tracking data. You are able to set multiple arguments besides tidy tracking data, like initial and end time to animate (in seconds, no frames!), geometric or spatial analysis method (options: &#34;base&#34;, &#34;convexhull&#34;, &#34;voronoi&#34;, &#34;delaunay&#34;), aesthetics setting (colors of pitch fill and lines, teams colors, titles, etc.), data provider and output setting. Most of this arguments are enabled also for &lt;strong&gt;soccer_plot()&lt;/strong&gt; function.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# example A&#xA;soccer_animate(tidy_data = td, ini_time = 3956, end_time = 3960)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Dato-Futbol/soccerAnimate/master/man/example_A.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# example B&#xA;soccer_animate(tidy_data = td, ini_time = 3956, end_time = 3960, method = &#34;convexhull&#34;, title = &#34;Convex Hull from second 3956 to 3960&#34;, subtitle = &#34;Metrica Sports open tracking data - Game 1&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Dato-Futbol/soccerAnimate/master/man/example_B.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# example C&#xA;soccer_animate(tidy_data = td, ini_time = 86, end_time = 92, method = &#34;voronoi&#34;, title = &#34;Voronoi tesselations from second 86 to 92&#34;, subtitle = &#34;Metrica Sports open tracking data - Game 1&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Dato-Futbol/soccerAnimate/master/man/example_C.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;General considerations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A soccer pitch of dimensions 105x68 meters was considered.&lt;/li&gt; &#xA; &lt;li&gt;Reverted coordinates for Period 2: Teams are always attacking in the same direction.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Currently working on&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Players and teams stats report (minutes played, distance, velocity)&lt;/li&gt; &#xA; &lt;li&gt;Adding events visualization&lt;/li&gt; &#xA; &lt;li&gt;Improving documentation&lt;/li&gt; &#xA; &lt;li&gt;More aesthetics user customization (color/fill themes, fonts)&lt;/li&gt; &#xA; &lt;li&gt;Creating the hex sticker (!)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;TO DO&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Implement soccer analytics community applications, like &lt;a href=&#34;https://github.com/Friends-of-Tracking-Data-FoTD/LaurieOnTracking/raw/master/Metrica_PitchControl.py&#34;&gt;pitch control model&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;open to suggestions&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ceslobfer/GPUmatrix</title>
    <updated>2023-04-24T01:42:25Z</updated>
    <id>tag:github.com,2023-04-24:/ceslobfer/GPUmatrix</id>
    <link href="https://github.com/ceslobfer/GPUmatrix" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GPUmatrix: An R package for algebra using GPU&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Abstract&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Motivation:&lt;/strong&gt; GPU computational power is a great resource for computational biology. specifically in statistics and linear algebra. Unfortunately, very few packages connect R with the GPU and none of them are transparent enough to perform the computations on the GPU without substantial changes in the code. Another problem of these packages is lacking proper maintenance: several of the previous attempts were removed from CRAN. It would be desirable to have a R package, properly maintained, that exploits the use of the GPU with minimal changes in the existing code.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Results:&lt;/strong&gt; We have developed the GPUMatrix package (available at CRAN). GPUMatrix mimics the behavior of the Matrix package. Therefore, is easy to learn and very few changes in the code are required to work on the GPU. GPUMatrix relies on either the tensorflow or the torch R packages to perform the GPU operations.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Before starting, please be advised that this R package is designed to have the lowest learning curve for the R user to perform algebraic operations using the GPU. Therefore, this tutorial will mostly cover procedures that will go beyond the operations that the user can already perform with R&#39;s CPU matrices.&lt;/p&gt; &#xA;&lt;h1&gt;0 Installation&lt;/h1&gt; &#xA;&lt;h2&gt;0.1 Dependences&lt;/h2&gt; &#xA;&lt;p&gt;GPUmatrix is an R package that utilizes tensors through the &lt;strong&gt;torch&lt;/strong&gt; or &lt;strong&gt;tensorflow&lt;/strong&gt; packages (see Advanced Users section for more information). One or the other must be installed for the use of GPUmatrix. Both packages are hosted in CRAN and have specific installation instructions. In both cases, it is necessary to have an NVIDIA® GPU card with the latest drivers installed in order to use the packages, as well as a version of Python 3. The NVIDIA card must be compatible; please see the list of capable cards &lt;a href=&#34;https://developer.nvidia.com/cuda-gpus#compute&#34;&gt;here&lt;/a&gt;. If there is no compatible graphics card or not graphic card at all, you can still install tensorFlow and torch, but only with the CPU version, which means that GPUmatrix will only be able to run in CPU mode.&lt;/p&gt; &#xA;&lt;h3&gt;For torch: (&lt;a href=&#34;https://cran.r-project.org/web/packages/torch/vignettes/installation.html&#34;&gt;Link installation here&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;torch&#34;)&#xA;library(torch)&#xA;install_torch() # In some cases is required.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;MUST INSTALL:&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;CUDA Toolkit 11.3. Link &lt;a href=&#34;https://developer.nvidia.com/cuda-11.3.0-download-archive&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;cuDNN 8.4 . Link &lt;a href=&#34;https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-840/install-guide/index.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;For Tensorflow: (&lt;a href=&#34;https://tensorflow.rstudio.com/install/&#34;&gt;Link installation here&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;The installation of TensorFlow allows the selection to install the GPU, CPU, or both versions. This will depend on the version of TensorFlow that we install with the &lt;code&gt;install_tensorflow()&lt;/code&gt; function. The mode in which the tensors are created using GPUmatrix, if we choose to use TensorFlow, will depend on the installation mode. The options to switch from CPU to GPU are not enabled when using GPUmatrix with TensorFlow for this precise reason. To install the GPU version, it is not necessary to specify the version since &lt;u&gt;if it detects that the CUDA dependencies are met&lt;/u&gt;, it will automatically install using the GPU mode. If you want to install the CPU version, you need to specify it as follows:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;install_tensorflow(version=&#34;nightly-cpu&#34;)&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;tensorflow&#34;)&#xA;library(tensorflow)&#xA;install_tensorflow(version = &#34;nightly-gpu&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;MUST INSTALL:&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;CUDA Toolkit 11.2. Link &lt;a href=&#34;https://developer.nvidia.com/cuda-11.3.0-download-archive&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;cuDNN 8.1 . Link &lt;a href=&#34;https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-840/install-guide/index.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;0.2 GPUmatrix installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;u&gt;Once the dependencies for Torch or TensorFlow are installed&lt;/u&gt;, the GPUmatrix package, being a package hosted on CRAN, can be easily installed using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;GPUmarix&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, it is possible to install the package from GitHub ot get the last version of the package.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&#34; ceslobfer/GPUmatrix&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;1 Initialization GPUmatrix&lt;/h1&gt; &#xA;&lt;p&gt;The GPUmatrix package is based on S4 objects in R and we have created a constructor function that acts similarly to the default &lt;code&gt;matrix()&lt;/code&gt; constructor in R for CPU matrices. The constructor function is &lt;code&gt;gpu.matrix()&lt;/code&gt; and accepts the same parameters as &lt;code&gt;matrix()&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt;library(GPUmatrix)&#xA;#R matrix initialization&#xA;&amp;gt;m &amp;lt;- matrix(c(1:20)+40,10,2)&#xA;#Show CPU matrix&#xA;&amp;gt;m&#xA;&#xA;      [,1] [,2]&#xA; [1,]   41   51&#xA; [2,]   42   52&#xA; [3,]   43   53&#xA; [4,]   44   54&#xA; [5,]   45   55&#xA; [6,]   46   56&#xA; [7,]   47   57&#xA; [8,]   48   58&#xA; [9,]   49   59&#xA;[10,]   50   60&#xA;&#xA;#GPU matrix initialization&#xA;&amp;gt;Gm &amp;lt;- gpu.matrix(c(1:20)+40,10,2)&#xA;#Show GPU matrix&#xA;&amp;gt;Gm&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 41  51&#xA; 42  52&#xA; 43  53&#xA; 44  54&#xA; 45  55&#xA; 46  56&#xA; 47  57&#xA; 48  58&#xA; 49  59&#xA; 50  60&#xA;[ CUDADoubleType{10,2} ]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the previous example, a normal R CPU matrix called &lt;code&gt;m&lt;/code&gt; and its GPU counterpart &lt;code&gt;Gm&lt;/code&gt; are created. Just like regular matrices, the created GPU matrices allow for indexing of its elements and assignment of values. The concatenation operators &lt;code&gt;rbind()&lt;/code&gt; and &lt;code&gt;cbind()&lt;/code&gt; work independently of the type of matrices that are to be concatenated, resulting in a &lt;em&gt;&lt;strong&gt;gpu.matrix&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt;Gm[c(2,3),1]&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 42&#xA; 43&#xA;[ CUDADoubleType{2,1} ]&#xA;&#xA;&amp;gt;Gm[,2]&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 51&#xA; 52&#xA; 53&#xA; 54&#xA; 55&#xA; 56&#xA; 57&#xA; 58&#xA; 59&#xA; 60&#xA;[ CUDADoubleType{10,1} ]&#xA; &#xA;&amp;gt;Gm2 &amp;lt;- cbind(Gm[c(1,2),], Gm[c(6,7),])&#xA;&amp;gt;Gm2&#xA; &#xA; GPUmatrix&#xA;torch_tensor&#xA; 41  51  46  56&#xA; 42  52  47  57&#xA;[ CUDADoubleType{2,4} ]&#xA;&#xA;&amp;gt;Gm2[1,3] &amp;lt;- 0&#xA;&amp;gt;Gm2&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 41  51   0  56&#xA; 42  52  47  57&#xA;[ CUDADoubleType{2,4} ]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;2 Cast GPU matrices and data types&lt;/h1&gt; &#xA;&lt;p&gt;The default matrices in R have limitations. The numeric data types it allows are int and float64, with float64 being the type used generally in R by default. It also does not natively allow for the creation and handling of sparse matrices. To make up for this lack of functionality, other R packages hosted in CRAN have been created that allow for programming these types of functionality in R. The problem with these packages is that in most cases they are not compatible with each other, meaning we can have a sparse matrix with float64 and a non-sparse matrix with float32, but not a sparse matrix with float32.&lt;/p&gt; &#xA;&lt;h2&gt;2.1 Cast from other packages&lt;/h2&gt; &#xA;&lt;p&gt;GPUmatrix allows for compatibility with sparse matrices and different data types such as float32. For this reason, casting operations between different matrix types from multiple packages to GPU matrix type have been implemented:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Matrix class&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Package&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Data type default&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;SPARSE&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Back cast&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;matrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;base&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;data.frame&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;base&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;integer&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;base&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;numeric&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;base&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;dgeMatrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Matrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ddiMatrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Matrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;dpoMatrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Matrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;dgCMatrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Matrix&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TRUE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float32&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float32&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FALSE&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;torch_tensor&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;torch&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Depends of tensor type&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;tensorflow.tensor&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;tensorflow&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;float64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Depends of tensor type&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Table 1. Casting operations between different packages&lt;/p&gt; &#xA;&lt;p&gt;There are two functions for casting to create a &lt;em&gt;&lt;strong&gt;gpu.matrix&lt;/strong&gt;&lt;/em&gt;: &lt;strong&gt;&lt;code&gt;as.gpu.matrix()&lt;/code&gt;&lt;/strong&gt; and the &lt;strong&gt;&lt;code&gt;gpu.matrix()&lt;/code&gt;&lt;/strong&gt; constructor itself. Both have the same input parameters for casting: the object to be cast and extra parameters for creating a GPU matrix.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#Create &#39;Gm&#39; from &#39;m&#39; matrix&#xA;&amp;gt;m &amp;lt;- matrix(c(1:20)+40,10,2)&#xA;&amp;gt;Gm &amp;lt;- gpu.matrix(m)&#xA;&amp;gt;Gm&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 41  51&#xA; 42  52&#xA; 43  53&#xA; 44  54&#xA; 45  55&#xA; 46  56&#xA; 47  57&#xA; 48  58&#xA; 49  59&#xA; 50  60&#xA;[ CUDADoubleType{10,2} ] &#xA;&#xA;#Create &#39;Gm&#39; from &#39;M&#39; with Matrix package&#xA;&amp;gt;library(Matrix)&#xA;&amp;gt;M &amp;lt;- Matrix(c(1:20)+40,10,2)&#xA;&amp;gt;Gm &amp;lt;- gpu.matrix(M)&#xA;&amp;gt;Gm&#xA; &#xA;GPUmatrix&#xA;torch_tensor&#xA; 41  51&#xA; 42  52&#xA; 43  53&#xA; 44  54&#xA; 45  55&#xA; 46  56&#xA; 47  57&#xA; 48  58&#xA; 49  59&#xA; 50  60&#xA;[ CUDADoubleType{10,2} ]&#xA;&#xA;#Create &#39;Gm&#39; from &#39;mfloat32&#39; with float package&#xA;&amp;gt;library(float)&#xA;&amp;gt;mfloat32 &amp;lt;- fl(m)&#xA;&amp;gt;Gm &amp;lt;- gpu.matrix(mfloat32)&#xA;&amp;gt;Gm&#xA; &#xA;GPUmatrix&#xA;torch_tensor&#xA; 41  51&#xA; 42  52&#xA; 43  53&#xA; 44  54&#xA; 45  55&#xA; 46  56&#xA; 47  57&#xA; 48  58&#xA; 49  59&#xA; 50  60&#xA;[ CUDAFloatType{10,2} ] #Float32 data type&#xA; &#xA;#Create &#39;Gms&#39; type sparse from &#39;Ms&#39; type sparse dgCMatrix with Matrix package&#xA;&amp;gt;Ms &amp;lt;- Matrix(sample(0:1, 20, replace = TRUE), nrow=10, ncol=2, sparse=TRUE)&#xA;&amp;gt;Ms&#xA; &#xA;10 x 2 sparse Matrix of class &#34;dgCMatrix&#34;&#xA;         &#xA; [1,] 1 1&#xA; [2,] . 1&#xA; [3,] . 1&#xA; [4,] 1 1&#xA; [5,] . .&#xA; [6,] . .&#xA; [7,] . .&#xA; [8,] 1 1&#xA; [9,] . .&#xA;[10,] . .&#xA; &#xA;&amp;gt;Gms &amp;lt;- gpu.matrix(Ms)&#xA;&amp;gt;Gms&#xA; &#xA;GPUmatrix&#xA;torch_tensor&#xA;[ SparseCUDADoubleType{}&#xA;indices:&#xA; 0  0  1  2  3  3  7  7&#xA; 0  1  1  1  0  1  0  1&#xA;[ CUDALongType{2,8} ]&#xA;values:&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA;[ CUDADoubleType{8} ]&#xA;size:&#xA;[10, 2]&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;2.2 Data type and sparsity&lt;/h2&gt; &#xA;&lt;p&gt;The data types allowed by GPUmatrix are: &lt;strong&gt;float64&lt;/strong&gt;, &lt;strong&gt;float32&lt;/strong&gt;, &lt;strong&gt;int&lt;/strong&gt;, &lt;strong&gt;bool&lt;/strong&gt; or &lt;strong&gt;logical&lt;/strong&gt;, &lt;strong&gt;complex64&lt;/strong&gt; and &lt;strong&gt;complex32&lt;/strong&gt;. We can create a GPU matrix with a specific data type using the &lt;strong&gt;&lt;code&gt;dtype&lt;/code&gt;&lt;/strong&gt; parameter of the &lt;strong&gt;&lt;code&gt;gpu.matrix()&lt;/code&gt;&lt;/strong&gt; constructor function or change the data type of a previously created GPU matrix using the &lt;strong&gt;&lt;code&gt;dtype()&lt;/code&gt;&lt;/strong&gt; function. The same applies to GPU sparse matrices, we can create them from the constructor using the &lt;strong&gt;&lt;code&gt;sparse&lt;/code&gt;&lt;/strong&gt; parameter, which will obtain a Boolean value of &lt;code&gt;TRUE&lt;/code&gt;/&lt;code&gt;FALSE&lt;/code&gt; depending on whether we want the resulting matrix to be sparse or not. We can also modify the sparsity of an existing GPU matrix with the functions &lt;strong&gt;&lt;code&gt;to_dense()&lt;/code&gt;&lt;/strong&gt;, if we want it to go from sparse to dense, and &lt;strong&gt;&lt;code&gt;to_sparse()&lt;/code&gt;&lt;/strong&gt;, if we want it to go from dense to sparse.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#Creating a float32 matrix&#xA;&amp;gt;Gm32 &amp;lt;- gpu.matrix(c(1:20)+40,10,2, dtype = &#34;float32&#34;)&#xA;&amp;gt;Gm32&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 41  51&#xA; 42  52&#xA; 43  53&#xA; 44  54&#xA; 45  55&#xA; 46  56&#xA; 47  57&#xA; 48  58&#xA; 49  59&#xA; 50  60&#xA;[ CUDAFloatType{10,2} ] #Float32 data type&#xA;&#xA;#Creating a non sparse martix with data type float32 from a sparse matrix type float64&#xA;&amp;gt;Ms &amp;lt;- Matrix(sample(0:1, 20, replace = TRUE), nrow=10, ncol=2, sparse=TRUE)&#xA;&amp;gt;Gm32 &amp;lt;- gpu.matrix(Ms, dtype = &#34;float32&#34;, sparse = F)&#xA;&amp;gt;Gm32&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 1  1&#xA; 0  1&#xA; 0  1&#xA; 1  1&#xA; 0  0&#xA; 0  0&#xA; 0  0&#xA; 1  1&#xA; 0  0&#xA; 0  0&#xA;[ CUDAFloatType{10,2} ]&#xA; &#xA;#Convert Gm32 in sparse matrix Gms32&#xA;&amp;gt;Gms32 &amp;lt;- to_sparse(Gm32)&#xA;&amp;gt;Gms32&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA;[ SparseCUDAFloatType{}&#xA;indices:&#xA; 0  0  1  2  3  3  7  7&#xA; 0  1  1  1  0  1  0  1&#xA;[ CUDALongType{2,8} ]&#xA;values:&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA;[ CUDAFloatType{8} ]&#xA;size:&#xA;[10, 2]&#xA;]&#xA;&#xA;##Convert data type Gms32 in float64&#xA;&amp;gt;Gms64 &amp;lt;- Gms32&#xA;&amp;gt;dtype(Gms64) &amp;lt;- &#34;float64&#34;&#xA;&amp;gt;Gms64&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA;[ SparseCUDADoubleType{}&#xA;indices:&#xA; 0  0  1  2  3  3  7  7&#xA; 0  1  1  1  0  1  0  1&#xA;[ CUDALongType{2,8} ]&#xA;values:&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA; 1&#xA;[ CUDADoubleType{8} ]&#xA;size:&#xA;[10, 2]&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;3 GPUmatrix functions&lt;/h1&gt; &#xA;&lt;h2&gt;3.1 Arithmetic and comparison operators&lt;/h2&gt; &#xA;&lt;p&gt;GPUmatrix supports all basic arithmetic operators in R: &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;^&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;%*%&lt;/code&gt; and &lt;code&gt;%%&lt;/code&gt;. Its usage is the same as for basic R matrices, and it allows compatibility with other matrix objects from the previously mentioned packages, always returning the result in GPUmatrix format.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt;(Gm + Gm) == (m + m)&#xA;&#xA;      [,1] [,2]&#xA; [1,] TRUE TRUE&#xA; [2,] TRUE TRUE&#xA; [3,] TRUE TRUE&#xA; [4,] TRUE TRUE&#xA; [5,] TRUE TRUE&#xA; [6,] TRUE TRUE&#xA; [7,] TRUE TRUE&#xA; [8,] TRUE TRUE&#xA; [9,] TRUE TRUE&#xA;[10,] TRUE TRUE&#xA;&#xA;&amp;gt;(Gm + M) == (mfloat32 + Gm)&#xA;&#xA;      [,1] [,2]&#xA; [1,] TRUE TRUE&#xA; [2,] TRUE TRUE&#xA; [3,] TRUE TRUE&#xA; [4,] TRUE TRUE&#xA; [5,] TRUE TRUE&#xA; [6,] TRUE TRUE&#xA; [7,] TRUE TRUE&#xA; [8,] TRUE TRUE&#xA; [9,] TRUE TRUE&#xA;[10,] TRUE TRUE&#xA;&#xA;&amp;gt;(M + M) == (mfloat32 + Gm)&#xA;&#xA;      [,1] [,2]&#xA; [1,] TRUE TRUE&#xA; [2,] TRUE TRUE&#xA; [3,] TRUE TRUE&#xA; [4,] TRUE TRUE&#xA; [5,] TRUE TRUE&#xA; [6,] TRUE TRUE&#xA; [7,] TRUE TRUE&#xA; [8,] TRUE TRUE&#xA; [9,] TRUE TRUE&#xA;[10,] TRUE TRUE&#xA;&#xA;&amp;gt;(Ms + Ms) &amp;gt; (Gms + Gms)*2&#xA;&#xA;      [,1]  [,2]&#xA; [1,]  TRUE  TRUE&#xA; [2,] FALSE  TRUE&#xA; [3,] FALSE  TRUE&#xA; [4,]  TRUE  TRUE&#xA; [5,] FALSE FALSE&#xA; [6,] FALSE FALSE&#xA; [7,] FALSE FALSE&#xA; [8,]  TRUE  TRUE&#xA; [9,] FALSE FALSE&#xA;[10,] FALSE FALSE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As seen in the previous example, the comparison operators (&lt;code&gt;==&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;) also work following the same dynamic as the arithmetic operators.&lt;/p&gt; &#xA;&lt;h2&gt;3.2 Math operators&lt;/h2&gt; &#xA;&lt;p&gt;Similarly to arithmetic operators, mathematical operators follow the same operation they would perform on regular matrices of R. &lt;code&gt;Gm&lt;/code&gt; is a &lt;em&gt;gpu.matrix&lt;/em&gt; variable:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Mathematical operators&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Usage&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;log&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;log(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;log2&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;log2(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;log10&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;log10(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cos&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cos(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cosh&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cosh(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;acos&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;acos(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;acosh&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;acosh(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sin&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sin(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sinh&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sinh(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;asin&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;asin(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;asinh&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;asinh(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;tan&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;tan(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;atan&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;atan(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;tanh&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;tanh(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;atanh&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;atanh(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sqrt&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sqrt(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;abs&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;abs(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sign&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sign(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;ceiling&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;ceiling(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;floor&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;floor(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cumsum&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cumsum(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cumprod&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cumprod(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;exp&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;exp(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;expm1&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;expm1(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Table 2. Mathematical operators that accept a gpu.matrix as input&lt;/p&gt; &#xA;&lt;h2&gt;3.2 Other functions&lt;/h2&gt; &#xA;&lt;p&gt;In the manual, we can find a multitude of functions that can be applied to &lt;em&gt;gpu.matrix&lt;/em&gt; type matrices. Most of the functions are functions from the base R package that can be used on &lt;em&gt;gpu.matrix&lt;/em&gt; matrices in the same way they would be applied to regular matrices of R. There are other functions from other packages like &lt;strong&gt;Matrix&lt;/strong&gt; or &lt;strong&gt;matrixStats&lt;/strong&gt; that have been implemented due to their widespread use within the user community, such as &lt;code&gt;rankMatrix&lt;/code&gt; or &lt;code&gt;colMaxs&lt;/code&gt;. The output of these functions, which originally produced R default matrix type objects, will now return &lt;em&gt;gpu.matrix&lt;/em&gt; type matrices if the input type of the function is &lt;em&gt;gpu.matrix&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt;m &amp;lt;- matrix(c(1:20)+40,10,2)&#xA;&amp;gt;Gm &amp;lt;- gpu.matrix(c(1:20)+40,10,2)&#xA;&#xA;&amp;gt;head(tcrossprod(m),2)&#xA;&#xA;     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]&#xA;[1,] 4282 4374 4466 4558 4650 4742 4834 4926 5018  5110&#xA;[2,] 4374 4468 4562 4656 4750 4844 4938 5032 5126  5220&#xA;&#xA;&amp;gt;head(tcrossprod(Gm),2)&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 4282  4374  4466  4558  4650  4742  4834  4926  5018  5110&#xA; 4374  4468  4562  4656  4750  4844  4938  5032  5126  5220&#xA;[ CUDADoubleType{2,10} ]&#xA;&#xA;&amp;gt;Gm &amp;lt;- tail(Gm,3)&#xA;&amp;gt;rownames(Gm) &amp;lt;- c(&#34;a&#34;,&#34;b&#34;,&#34;c&#34;)&#xA;&amp;gt;tail(Gm,2)&#xA; &#xA;GPUmatrix&#xA;torch_tensor&#xA; 49  59&#xA; 50  60&#xA;[ CUDADoubleType{2,2} ]&#xA;rownames: b c&#xA;&#xA;&amp;gt;colMaxs(Gm)&#xA;&#xA;[1] 50 60&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There is a wide variety of functions implemented in GPUmatrix, and they are adapted to be used just like regular R matrices.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Functions&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Usage&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Package&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;determinant&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;determinant(Gm, logarithm=T)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;fft&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;fft(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sort&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sort(Gm,decreasing=F)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;round&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;round(Gm, digits=0)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;show&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;show(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;length&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;length(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;dim(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;dim&amp;lt;-&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;dim(Gm) &amp;lt;- c(...,...)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rownames&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rownames(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rownames&amp;lt;-&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rownames(Gm) &amp;lt;- c(...)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;row.names&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;row.names(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;row.names&amp;lt;-&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;row.names(Gm) &amp;lt;- c(...)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colnames&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colnames(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colnames&amp;lt;-&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colnames(Gm) &amp;lt;- c(...)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowSums&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowSums(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;Matrix&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colSums&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colSums(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;Matrix&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cbind&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cbind(Gm,...)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rbind&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rbind(Gm,...)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;head&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;head(Gm,...)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;tail&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;tail(Gm,...)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;nrow&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;nrow(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;ncol&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;ncol(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;t&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;t(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;crossprod&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;crossprod(Gm,...)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;tcrossprod&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;tcrossprod(Gm,…)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;outer&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;outer(Gm,…)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;%o%&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;`Gm %o% …&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;%x%&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;`Gm %x% …&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;%^%&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;`Gm %^% …&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;diag&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;diag(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;diag&amp;lt;-&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;diag(Gm) &amp;lt;- c(…)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;solve&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;solve(Gm, …)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;qr&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;qr(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;eigen&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;eigen(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;svd&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;svd(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;ginv&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;ginv(Gm, tol = sqrt(.Machine$double.eps))&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;MASS&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;chol&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;chol(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;chol_solve&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;chol_solve(Gm, …)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;GPUmatrix&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;mean&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;mean(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;density&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;density(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;hist&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;hist(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colMeans&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colMeans(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;Matrix&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowMeans&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowMeans(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;Matrix&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sum&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;sum(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;min&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;min(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;max&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;max(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;which.max&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;which.max(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;which.min&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;which.min(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;aperm&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;aperm(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;apply&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;apply(Gm, MARGIN, FUN, …, simplify=TRUE)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cov&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cov(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;stats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cov2cor&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cov2cor(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;stats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cor&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;cor(Gm, …)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;stats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowVars&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowVars(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;matrixStats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colVars&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colVars(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;matrixStats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colMaxs&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colMaxs(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;matrixStats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowMaxs&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowMaxs(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;matrixStats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowRanks&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowRanks(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;matrixStats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colRanks&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colRanks(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;matrixStats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colMins&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;colMins(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;matrixStats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowMins&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;rowMins&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;matrixStats&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;dtype&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;dtype(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;GPUmatrix&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;dtype&amp;lt;-&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;dtype(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;GPUmatrix&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;to_dense&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;to_dense(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;GPUmatrix&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;to_sparse&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;to_sparse(Gm)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;GPUmatrix&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Table 3. Functions that accept one or several gpu.matrix matrices as input&lt;/p&gt; &#xA;&lt;h2&gt;3.3 Function time comparison&lt;/h2&gt; &#xA;&lt;p&gt;The computation time for the different functions and operations differs depending on the operation to be performed (Fig 1). Although the default data type is float64, operations with float32 have no comparison in terms of computation time. For this reason, we recommend their use whenever the data types and the objective allow it. This comparison is made using the Intel MKL BLAS.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ceslobfer/GPUmatrix/main/vignettes/images/Rplot.png&#34; alt=&#34;Computation time for GPU and R-base CPU for different operations. Time is in seconds and Size=n where matrix is (n x n) dimension*.*&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;4. Toy example: Non negative factorization of a matrix&lt;/h1&gt; &#xA;&lt;p&gt;As a toy example We will show a simple example on performing the non negative matrix factorization of a matrix (NMF) using the Lee and Seung multiplicative update rule.&lt;/p&gt; &#xA;&lt;p&gt;The rules are&lt;/p&gt; &#xA;&lt;p&gt;$\mathbf{W}_{[i, j]}^{n+1} \leftarrow \mathbf{W}_{[i, j]}^n \frac{\left(\mathbf{V}\left(\mathbf{H}^{n+1}\right)^T\right)_{[i, j]}}{\left(\mathbf{W}^n \mathbf{H}^{n+1}\left(\mathbf{H}^{n+1}\right)^T\right)_{[i, j]}}$&lt;/p&gt; &#xA;&lt;p&gt;and&lt;/p&gt; &#xA;&lt;p&gt;$\mathbf{H}_{[i, j]}^{n+1} \leftarrow \mathbf{H}_{[i, j]}^n \frac{\left(\left(\mathbf{W}^n\right)^T \mathbf{V}\right)_{[i, j]}}{\left(\left(\mathbf{W}^n\right)^T \mathbf{W}^n \mathbf{H}^n\right)_{[i, j]}}$&lt;/p&gt; &#xA;&lt;p&gt;to update the $\mathbf{W}$ and $\mathbf{H}$ respectively.&lt;/p&gt; &#xA;&lt;p&gt;It is straightforward to build two functions for these rules. The corresponding R code is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt;updateH &amp;lt;- function(V,W,H) {&#xA;&amp;gt;  H &amp;lt;- H * (t(W) %*% V)/((t(W) %*% W) %*% H)}&#xA;&amp;gt;updateW &amp;lt;- function(V,W,H) {&#xA;&amp;gt;  W &amp;lt;- W * (V %*% t(H))/(W %*% (H %*% t(H)) )}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We include a simple script that builds a matrix and run this update rules 100 times.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt;A &amp;lt;- matrix(runif(200*10),200,10)&#xA;&amp;gt;B &amp;lt;- matrix(runif(10*100),10,100)&#xA;&amp;gt;V &amp;lt;- A %*% B&#xA;&#xA;&amp;gt;W &amp;lt;- W1 &amp;lt;- matrix(runif(200*10),200,10)&#xA;&amp;gt;H &amp;lt;- H1 &amp;lt;- matrix(runif(10*100),10,100)&#xA;&#xA;&amp;gt;for (iter in 1:100) {&#xA;&amp;gt;  W &amp;lt;- updateW(V,W,H)&#xA;&amp;gt;  H &amp;lt;- updateH(V,W,H)&#xA;&amp;gt;}&#xA;&#xA;&amp;gt;print(W[1,1])&#xA;&amp;gt;print(H[1,1])&#xA;&#xA;[1] 0.5452606&#xA;[1] 0.5010532&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We include now a similar script where the operations are done on the GPU:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt;library(GPUmatrix)&#xA;&amp;gt;Vg &amp;lt;- gpu.matrix(V)&#xA;&#xA;&amp;gt;Wg &amp;lt;- gpu.matrix(W1)&#xA;&amp;gt;Hg &amp;lt;- gpu.matrix(H1)&#xA;&#xA;&amp;gt;for (iter in 1:100) {&#xA;&amp;gt;  Wg &amp;lt;- updateW(Vg,Wg,Hg)&#xA;&amp;gt;  Hg &amp;lt;- updateH(Vg,Wg,Hg)&#xA;&amp;gt;}&#xA;&#xA;&amp;gt;print(Wg[1,1])&#xA;&amp;gt;print(Hg[1,1])&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 0.5453&#xA;[ CUDADoubleType{1,1} ]&#xA;GPUmatrix&#xA;torch_tensor&#xA; 0.5011&#xA;[ CUDADoubleType{1,1} ]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Results are identical since the initial values also coincide.&lt;/p&gt; &#xA;&lt;h1&gt;5. Advanced options&lt;/h1&gt; &#xA;&lt;h2&gt;5.1 Using GPUMatrix on CPU&lt;/h2&gt; &#xA;&lt;p&gt;In the GPUmatrix constructor, we can specify the location of the matrix, i.e., we can decide to host it on the GPU or in RAM memory to use it with the CPU. As a package, as its name suggests, oriented towards algebraic operations in R using the GPU, it will by default be hosted on the GPU, but it allows the same functionalities using the CPU. To do this, we use the &lt;code&gt;device&lt;/code&gt; attribute of the constructor and assign it the value &lt;em&gt;&lt;strong&gt;&#34;cpu&#34;&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#GPUmatrix initialization with CPU option&#xA;&amp;gt;Gm &amp;lt;- gpu.matrix(c(1:20)+40,10,2,device=&#34;cpu&#34;)&#xA;#Show CPU matrix from GPUmatrix&#xA;&amp;gt;Gm&#xA;&#xA;GPUmatrix&#xA;torch_tensor&#xA; 41  51&#xA; 42  52&#xA; 43  53&#xA; 44  54&#xA; 45  55&#xA; 46  56&#xA; 47  57&#xA; 48  58&#xA; 49  59&#xA; 50  60&#xA;[ CPUDoubleType{10,2} ] #CPU tensor&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;R provides a standard BLAS version that is not multithreaded and not fully optimized for present computers. In the previous paragraphs, we compared the CUDA-GPU with MKL-R, i.e.&amp;nbsp;using CUDA for linear algebra through torch or tensorflow or boosting the standard R with the Intel MKL library. Switching from Standard R to MKL R implies changing the default behavior of R and ther can be side-effects. For examples some standard packages such as igraph do not work in this case.&lt;/p&gt; &#xA;&lt;p&gt;Torch and Tensorflow on the CPU are compiled using MKL as linear algebra library. Therefore, the performance between using MKL-R or using the GPUMatrix library on the CPU should be similar. The only differences would be related to the overhead from translating the objects or the different versions of the MKL library.&lt;/p&gt; &#xA;&lt;p&gt;Interestingly, the standard R matrix operations are indeed slightly slower than using the GPUMatrix package -perhaps owing to a more recent version of the MKL library- (Fig 2), especially in element-wise operations, where MKL-R does not seem to exploit the multithreaded implementation of the Intel MKL BLAS version and Torch and Tensorflow does.&lt;/p&gt; &#xA;&lt;p&gt;In addition, if MKL-R is not implemented for float32 -since R does not include this type of variable-. The multiplication of float32 matrices on MKL-R does not use MKL and is, in fact, much slower than multiplying float64 matrices (data not shown). Torch and Tensorflow do include MKL for float32 and there is an improvement in the performance (they are around two-fold faster).&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ceslobfer/GPUmatrix/main/vignettes/images/GPUmatrix_CPU.png&#34; alt=&#34;Computation time for GPUMatrix on CPU and MKL-R for different operations. Time is in seconds and Size=n where matrix is (n x n) dimension. There is a substantial speed performance in element-wise operations.&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;5.2 Using GPUMatrix with Tensorflow&lt;/h2&gt; &#xA;&lt;p&gt;As commented in the introduction and dependency section, GPUmatrix can be used with both TensorFlow and Torch. By default, the GPU matrix constructor is initialized with Torch tensors because, in our opinion, it provides an advantage in terms of installation and usage compared to TensorFlow. Additionally, it allows the use of GPUmatrix not only with GPU tensors but also with CPU tensors. To use GPUmatrix with TensorFlow, simply use the &lt;code&gt;type&lt;/code&gt; attribute in the constructor function and assign it the value &lt;strong&gt;&#34;tensorflow&#34;&lt;/strong&gt; as shown in the following example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# library(GPUmatrix)&#xA;&amp;gt;tensorflowGPUmatrix &amp;lt;- gpu.matrix(c(1:20)+40,10,2, type = &#34;tensorflow&#34;)&#xA;&amp;gt;tensorflowGPUmatrix&#xA;&#xA;GPUmatrix&#xA;tf.Tensor(&#xA;[[41. 51.]&#xA; [42. 52.]&#xA; [43. 53.]&#xA; [44. 54.]&#xA; [45. 55.]&#xA; [46. 56.]&#xA; [47. 57.]&#xA; [48. 58.]&#xA; [49. 59.]&#xA; [50. 60.]], shape=(10, 2), dtype=float64)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;References&lt;/h4&gt; &#xA;&lt;p&gt;Bates D, Maechler M, Jagan M (2022). Matrix: Sparse and Dense Matrix Classes and Methods. R package version 1.5-3, &lt;a href=&#34;https://CRAN.R-project.org/package=Matrix&#34;&gt;https://CRAN.R-project.org/package=Matrix&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Schmidt D (2022). &#34;float: 32-Bit Floats.&#34; R package version 0.3-0, &lt;a href=&#34;https://cran.r-project.org/package=float&#34;&gt;https://cran.r-project.org/package=float&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Falbel D, Luraschi J (2022). torch: Tensors and Neural Networks with &#39;GPU&#39; Acceleration. R package version 0.9.0, &lt;a href=&#34;https://CRAN.R-project.org/package=torch&#34;&gt;https://CRAN.R-project.org/package=torch&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Allaire J, Tang Y (2022). tensorflow: R Interface to &#39;TensorFlow&#39;. R package version 2.11.0,&amp;nbsp; &lt;a href=&#34;https://CRAN.R-project.org/package=tensorflow&#34;&gt;https://CRAN.R-project.org/package=tensorflow&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>