<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-01T01:43:46Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ddotta/parquetize</title>
    <updated>2022-12-01T01:43:46Z</updated>
    <id>tag:github.com,2022-12-01:/ddotta/parquetize</id>
    <link href="https://github.com/ddotta/parquetize" rel="alternate"></link>
    <summary type="html">&lt;p&gt;R package that allows to convert databases of different formats to parquet format&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/languages/top/ddotta/parquetize&#34; alt=&#34;GitHub top language&#34;&gt; &lt;a href=&#34;https://github.com/ddotta/parquetize/actions/workflows/check-release.yaml&#34;&gt;&lt;img src=&#34;https://github.com/ddotta/parquetize/workflows/R-CMD-check/badge.svg?sanitize=true&#34; alt=&#34;R check status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/ddotta/parquetize&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/ddotta/parquetize/branch/main/graph/badge.svg?token=25MHI8O62M&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;h1&gt;&lt;span&gt;📦&lt;/span&gt; Package &lt;code&gt;parquetize&lt;/code&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ddotta/parquetize/main/man/figures/hex_parquetize.png&#34; width=&#34;110&#34; align=&#34;right&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;R package that allows to convert databases of different formats (csv, SAS, SPSS, Stata, rds, duckdb, sqlite, JSON, ndJSON) to &lt;a href=&#34;https://parquet.apache.org/&#34;&gt;parquet&lt;/a&gt; format in a same function.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;remotes::install_github(&#34;ddotta/parquetize&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(parquetize)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;For the French Insee agents who want to use the package with AUS&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;parquetize&#34;, &#xA;                 repos = &#34;https://nexus.insee.fr/repository/r-local&#34;, &#xA;                 type = &#34;source&#34;) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Why this package ?&lt;/h2&gt; &#xA;&lt;p&gt;This package is a simple wrapper of some very useful functions from the &lt;a href=&#34;https://github.com/tidyverse/haven&#34;&gt;haven&lt;/a&gt;, &lt;a href=&#34;https://github.com/tidyverse/readr/&#34;&gt;readr&lt;/a&gt;, &lt;a href=&#34;https://github.com/jeroen/jsonlite&#34;&gt;jsonlite&lt;/a&gt;, &lt;a href=&#34;https://github.com/r-dbi/RSQLite&#34;&gt;RSQLite&lt;/a&gt;, &lt;a href=&#34;https://github.com/cran/duckdb&#34;&gt;duckdb&lt;/a&gt; and &lt;a href=&#34;https://github.com/apache/arrow&#34;&gt;arrow&lt;/a&gt; packages.&lt;/p&gt; &#xA;&lt;p&gt;While working, I realized that I was often repeating the same operation when working with parquet files :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;I import the file in R with {haven}, {jsonlite}, {readr}, {DBI}, {RSQLite} or {duckdb}.&lt;/li&gt; &#xA; &lt;li&gt;And I export the file in parquet format&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;As a fervent of the DRY principle (don&#39;t repeat yourself) the exported functions of this package make my life easier and &lt;strong&gt;execute these operations within the same function&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The last benefit&lt;/strong&gt; of using package &lt;code&gt;{parquetize}&lt;/code&gt; is that its functions allow to create single parquet files or partitioned files depending on the arguments chosen in the functions.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/csv_to_parquet.html&#34;&gt;csv_to_parquet()&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;The other benefit of this function&lt;/strong&gt; is that it allows you to convert csv files whether they are stored locally or available on the internet directly to csv format or inside a zip.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/json_to_parquet.html&#34;&gt;json_to_parquet()&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;The other benefit of this function&lt;/strong&gt; is that it handles JSON and ndJSON files in a same function. There is only one function to use for these 2 cases.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/rds_to_parquet.html&#34;&gt;rds_to_parquet()&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/table_to_parquet.html&#34;&gt;table_to_parquet()&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;The other benefit of this function&lt;/strong&gt;is that it handles SAS, SPSS and Stata files in a same function. There is only one function to use for these 3 cases.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/sqlite_to_parquet.html&#34;&gt;sqlite_to_parquet()&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/duckdb_to_parquet.html&#34;&gt;duckdb_to_parquet()&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For more details, see the documentation and examples :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/csv_to_parquet.html#ref-examples&#34;&gt;csv_to_parquet()&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/json_to_parquet.html#ref-examples&#34;&gt;json_to_parquet()&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/rds_to_parquet.html#ref-examples&#34;&gt;rds_to_parquet()&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/sqlite_to_parquet.html#ref-examples&#34;&gt;sqlite_to_parquet()&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ddotta.github.io/parquetize/reference/duckdb_to_parquet.html#ref-examples&#34;&gt;duckdb_to_parquet()&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;p&gt;Feel welcome to contribute to add features that you find useful in your daily work. Ideas are welcomed in &lt;a href=&#34;https://github.com/ddotta/parquetize/issues&#34;&gt;the issues&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ttimbers/breast_cancer_predictor</title>
    <updated>2022-12-01T01:43:46Z</updated>
    <id>tag:github.com,2022-12-01:/ttimbers/breast_cancer_predictor</id>
    <link href="https://github.com/ttimbers/breast_cancer_predictor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Demo of a data analysis project for DSCI 522 (Data Science workflows) at UBC&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Breast Cancer Predictor&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;author: Tiffany Timbers&lt;/li&gt; &#xA; &lt;li&gt;contributors: Melissa Lee&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Demo of a data analysis project for DSCI 522 (Data Science workflows); a course in the Master of Data Science program at the University of British Columbia.&lt;/p&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;Here we attempt to build a classification model using the k-nearest neighbours algorithm which can use breast cancer tumour image measurements to predict whether a newly discovered breast cancer tumour is benign (i.e., is not harmful and does not require treatment) or malignant (i.e., is harmful and requires treatment intervention). Our final classifier performed fairly well on an unseen test data set, with Cohen’s Kappa score of 0.9 and an overall accuracy calculated to be 0.97. On the 142 test data cases, it correctly predicted 138. However it incorrectly predicted 4 cases, and importantly these cases were false negatives; predicting that a tumour is benign when in fact it is malignant. These kind of incorrect predictions could have a severly negative impact on a patients health outcome, thus we recommend continuing study to improve this prediction model before it is put into production in the clinic.&lt;/p&gt; &#xA;&lt;p&gt;The data set that was used in this project is of digitized breast cancer image features created by Dr.&amp;nbsp;William H. Wolberg, W. Nick Street, and Olvi L. Mangasarian at the University of Wisconsin, Madison (Street, Wolberg, and Mangasarian 1993). It was sourced from the UCI Machine Learning Repository (Dua and Graff 2017) and can be found &lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)&#34;&gt;here&lt;/a&gt;, specifically &lt;a href=&#34;http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data&#34;&gt;this file&lt;/a&gt;. Each row in the data set represents summary statistics from measurements of an image of a tumour sample, including the diagnosis (benign or malignant) and several other measurements (e.g., nucleus texture, perimeter, area, etc.). Diagnosis for each image was conducted by physicians.&lt;/p&gt; &#xA;&lt;h2&gt;Report&lt;/h2&gt; &#xA;&lt;p&gt;The final report can be found &lt;a href=&#34;https://ttimbers.github.io/breast_cancer_predictor/doc/breast_cancer_predict_report.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;There are two suggested ways to run this analysis:&lt;/p&gt; &#xA;&lt;h4&gt;1. Using Docker&lt;/h4&gt; &#xA;&lt;p&gt;&lt;em&gt;note - the instructions in this section also depends on running this in a unix shell (e.g., terminal or Git Bash)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;To replicate the analysis, install &lt;a href=&#34;https://www.docker.com/get-started&#34;&gt;Docker&lt;/a&gt;. Then clone this GitHub repository and run the following command at the command line/terminal from the root directory of this project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -v /$(pwd):/home/rstudio/breast_cancer_predictor ttimbers/bc_predictor:v4.0 make -C /home/rstudio/breast_cancer_predictor all&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To reset the repo to a clean state, with no intermediate or results files, run the following command at the command line/terminal from the root directory of this project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -v /$(pwd):/home/rstudio/breast_cancer_predictor ttimbers/bc_predictor:v4.0 make -C /home/rstudio/breast_cancer_predictor clean&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. Without using Docker&lt;/h4&gt; &#xA;&lt;p&gt;To replicate the analysis, clone this GitHub repository, install the &lt;a href=&#34;https://raw.githubusercontent.com/ttimbers/breast_cancer_predictor/master/#dependencies&#34;&gt;dependencies&lt;/a&gt; listed below, and run the following command at the command line/terminal from the root directory of this project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make all&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To reset the repo to a clean state, with no intermediate or results files, run the following command at the command line/terminal from the root directory of this project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make clean&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.7.4 and Python packages: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;docopt=0.6.2&lt;/li&gt; &#xA;   &lt;li&gt;requests=2.22.0&lt;/li&gt; &#xA;   &lt;li&gt;pandas=0.25.1R&lt;/li&gt; &#xA;   &lt;li&gt;feather-format=0.4.0&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;R version 3.6.1 and R packages: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;knitr=1.26&lt;/li&gt; &#xA;   &lt;li&gt;feather=0.3.5&lt;/li&gt; &#xA;   &lt;li&gt;tidyverse=1.3.0&lt;/li&gt; &#xA;   &lt;li&gt;caret=6.0-85&lt;/li&gt; &#xA;   &lt;li&gt;ggridges=0.5.2&lt;/li&gt; &#xA;   &lt;li&gt;ggthemes=4.2.0&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;GNU make 4.2.1&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The Breast Cancer Predictor materials here are licensed under the Creative Commons Attribution 2.5 Canada License (CC BY 2.5 CA). If re-using/re-mixing please provide attribution and link to this webpage.&lt;/p&gt; &#xA;&lt;h1&gt;References&lt;/h1&gt; &#xA;&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt; &#xA; &lt;div id=&#34;ref-Dua2019&#34;&gt; &#xA;  &lt;p&gt;Dua, Dheeru, and Casey Graff. 2017. “UCI Machine Learning Repository.” University of California, Irvine, School of Information; Computer Sciences. &lt;a href=&#34;http://archive.ics.uci.edu/ml&#34;&gt;http://archive.ics.uci.edu/ml&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;/div&gt; &#xA; &lt;div id=&#34;ref-Streetetal&#34;&gt; &#xA;  &lt;p&gt;Street, W. Nick, W. H. Wolberg, and O. L. Mangasarian. 1993. “Nuclear feature extraction for breast tumor diagnosis.” In &lt;em&gt;Biomedical Image Processing and Biomedical Visualization&lt;/em&gt;, edited by Raj S. Acharya and Dmitry B. Goldgof, 1905:861–70. International Society for Optics; Photonics; SPIE. &lt;a href=&#34;https://doi.org/10.1117/12.148698&#34;&gt;https://doi.org/10.1117/12.148698&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>Chishio318/Kuznets-Curve</title>
    <updated>2022-12-01T01:43:46Z</updated>
    <id>tag:github.com,2022-12-01:/Chishio318/Kuznets-Curve</id>
    <link href="https://github.com/Chishio318/Kuznets-Curve" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kuznets Curve Project&lt;/h1&gt;</summary>
  </entry>
</feed>