<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-11T01:37:22Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>schaunwheeler/satp</title>
    <updated>2022-12-11T01:37:22Z</updated>
    <id>tag:github.com,2022-12-11:/schaunwheeler/satp</id>
    <link href="https://github.com/schaunwheeler/satp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Analysis of South Asia Terrorism Portal (SATP) data&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;satp&lt;/h1&gt; &#xA;&lt;p&gt;The aim of &lt;code&gt;satp&lt;/code&gt; is to document the cleaning, organization, exploration, and analysis of data on violent incidents reported in the English language Pakistan press, as documented by the South Asia Terrorism Portal. The original data can be found at &lt;a href=&#34;http://www.satp.org/satporgtp/countries/pakistan/database/index.html&#34;&gt;http://www.satp.org/satporgtp/countries/pakistan/database/index.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Code Sections&lt;/h2&gt; &#xA;&lt;p&gt;Data Acquisition and Cleaning:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;satp_clean.R&lt;/code&gt; downloads the data from the SATP website and standardizes the format of that data to make it easier to pull out location and even information. It then pulls information about province and district from each event and then deconflicts information across events.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Event Classification:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;satp_classify.R&lt;/code&gt; pulls information about instigators of attacks (Pakistani military, militants, unknown instigator, drones) and casualties (security personnel or non-personnel) to classify incidents. This code is extremely messy and will soon be replaced with a more efficient method for classifying events.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ModelOriented/DrWhy</title>
    <updated>2022-12-11T01:37:22Z</updated>
    <id>tag:github.com,2022-12-11:/ModelOriented/DrWhy</id>
    <link href="https://github.com/ModelOriented/DrWhy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DrWhy is the collection of tools for eXplainable AI (XAI). It&#39;s based on shared principles and simple grammar for exploration, explanation and visualisation of predictive models.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Responsible Machine Learning&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;With Great Power Comes Great Responsibility&lt;/em&gt;. Voltaire (well, maybe)&lt;/p&gt; &#xA;&lt;p&gt;How to develop machine learning models in a responsible manner? There are several topics worth considering:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Effective&lt;/strong&gt;. Is the model good enough? Models with low performance should not be used because they can do more harm than good. Communicate the performance of the model in a language that the user understands. Remember that the models will work on a different dataset than the training one. Make sure to assess the performance on the target dataset.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transparent&lt;/strong&gt;. Does the user know what influences model predictions? Interpretability and explainability is important. If the model decisions affect us directly or indirectly, we should know where these decisions come from and how they can be changed.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fair&lt;/strong&gt;. Does the model discriminate on the basis of gender, age, race or other sensitive attribute? Direct or indirect? It should not! Discrimination can come in many faces. The model may give lower scores, may have lower performance, or may be based on different variables for the protected population.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure&lt;/strong&gt;. Do not let your model be hacked. Every complex system has its vulnerabilities. Seek them out and fix them. Some users may use various tricks to pull model predictions onto their site.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Confidential&lt;/strong&gt;. Models are often built on sensitive data. Make sure that the data does not leak, so that sensitive attributes are not shared with unauthorized persons. Also beware of model leaks.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reproducible&lt;/strong&gt;. Usually the model development process consists of many steps. Make sure that they are completely reproducible and thus can be verified one by one.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Collection of tools for Visual Exploration, Explanation and Debugging of Predictive Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;It takes a village to raise a &lt;del&gt;child&lt;/del&gt; model&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The way how we do predictive modeling is very ineffective. We spend way too much time on manual time-consuming and easy to automate activities like data cleaning and exploration, crisp modeling, model validation. We should be focusing more on model understanding, productisation and communication.&lt;/p&gt; &#xA;&lt;p&gt;Here are gathered tools that can be used to make out work more efficient through the whole model lifecycle. The unified grammar beyond DrWhy.AI universe is described in the &lt;a href=&#34;https://pbiecek.github.io/ema/&#34;&gt;Explanatory Model Analysis: Explore, Explain and Examine Predictive Models&lt;/a&gt; book.&lt;/p&gt; &#xA;&lt;h2&gt;Lifecycle for Predictive Models&lt;/h2&gt; &#xA;&lt;p&gt;The DrWhy is based on an unified &lt;a href=&#34;https://github.com/ModelOriented/DrWhy/raw/master/images/ModelDevelopmentProcess.pdf&#34;&gt;Model Development Process&lt;/a&gt; inspired by RUP. Find an overview in the diagram below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://modeloriented.github.io/ModelDevelopmentProcess/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/DALEXverse.png&#34; alt=&#34;images/DALEXverse.png&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;The DrWhy.AI family&lt;/h2&gt; &#xA;&lt;p&gt;Packages in the &lt;code&gt;DrWhy.AI&lt;/code&gt; family of models may be divided into four classes.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model adapters&lt;/strong&gt;. Predictive models created with different tools have different structures, and different interfaces. Model adapters create uniform wrappers. This way other packages may operate on models in an unified way. &lt;code&gt;DALEX&lt;/code&gt; is a lightweight package with generic interface. &lt;code&gt;DALEXtra&lt;/code&gt; is a package with extensions for heavyweight interfaces like &lt;code&gt;scikitlearn&lt;/code&gt;, &lt;code&gt;h2o&lt;/code&gt;, &lt;code&gt;mlr&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model agnostic explainers&lt;/strong&gt;. These packages implement specific methods for model exploration. They can be applied to a single model or they can compare different models. &lt;code&gt;ingredients&lt;/code&gt; implements variable specific techniques like Ceteris Paribus, Partial Dependency, Permutation based Feature Importance. &lt;code&gt;iBreakDown&lt;/code&gt; implements techniques for variable attribution, like Break Down or SHAPley values. &lt;code&gt;auditor&lt;/code&gt; implements techniques for model validation, residual diagnostic and performance diagnostic.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model specific explainers&lt;/strong&gt;. These packages implement model specific techniques. &lt;code&gt;randomForestExplainer&lt;/code&gt; implements techniques for exploration of &lt;code&gt;randomForest&lt;/code&gt; models. &lt;code&gt;EIX&lt;/code&gt; implements techniques for exploration of gbm and xgboost models. &lt;code&gt;cr19&lt;/code&gt; implements techniques for exploration of survival models.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated exploration&lt;/strong&gt;. These packages combine series of model exploration techniques and produce an automated report of website for model exploration. &lt;code&gt;modelStudio&lt;/code&gt; implements a dashboard generator for local and global interactive model exploration. &lt;code&gt;modelDown&lt;/code&gt; implements a HTML website generator for global model cross comparison.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://drwhy.ai/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/grammar_of_explanations.png&#34; alt=&#34;images/grammar_of_explanations.png&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here is a more detailed overview.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/DALEX&#34;&gt;DALEX&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/DALEX/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=DALEX&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/DALEX&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/DALEX&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/DALEX.png&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/DALEX?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/DALEX/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt;&lt;a href=&#34;http://drwhy.ai/#BackBone&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-BackBone-373589&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The DALEX package (Descriptive mAchine Learning EXplanations) helps to understand how complex models are working. The main function &lt;a href=&#34;https://modeloriented.github.io/DALEX/reference/explain.html&#34;&gt;explain&lt;/a&gt; creates a wrapper around a predictive model. Wrapped models may then be explored and compared with a collection of local and global explainers. Recent developments from the area of Interpretable Machine Learning/eXplainable Artificial Intelligence.&lt;/p&gt; &#xA;&lt;p&gt;DALEX wraps methods from other packages, i.e. &#39;pdp&#39; (Greenwell 2017) &lt;a href=&#34;doi:10.32614/RJ-2017-016&#34;&gt;doi:10.32614/RJ-2017-016&lt;/a&gt;, &#39;ALEPlot&#39; (Apley 2018) &lt;a href=&#34;arXiv:1612.08468&#34;&gt;arXiv:1612.08468&lt;/a&gt;, &#39;factorMerger&#39; (Sitko and Biecek 2017) &lt;a href=&#34;arXiv:1709.04412&#34;&gt;arXiv:1709.04412&lt;/a&gt;, &#39;breakDown&#39; package (Staniak and Biecek 2018) &lt;a href=&#34;doi:10.32614/RJ-2018-072&#34;&gt;doi:10.32614/RJ-2018-072&lt;/a&gt;, (Fisher at al. 2018) &lt;a href=&#34;arXiv:1801.01489&#34;&gt;arXiv:1801.01489&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Vignettes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modeloriented.github.io/DALEX/articles/vignette_titanic.html&#34;&gt;General introduction: Survival on the RMS Titanic&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/DALEXtra&#34;&gt;DALEXtra&lt;/a&gt; &lt;img src=&#34;https://github.com/ModelOriented/DALEXtra/raw/master/man/figures/logo.png?raw=true&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=DALEXtra&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/DALEXtra&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/DALEXtra&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/DALEXtra.png&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/DALEXtra?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/DALEXtra/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#BackBone&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-BackBone-373589&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;DALEXtra&lt;/code&gt; package is an extension pack for &lt;a href=&#34;https://modeloriented.github.io/DALEX&#34;&gt;DALEX&lt;/a&gt; package. This package provides easy to use connectors for models created with scikitlearn, keras, H2O, mljar and mlr.&lt;/p&gt; &#xA;&lt;p&gt;Vignettes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githack.com/pbiecek/DALEX_docs/master/vignettes/How_to_use_DALEXtra_to_explain_and_visualize_scikitlearn_models.html&#34;&gt;General introduction: DALEX with scikitlearn models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/ingredients&#34;&gt;ingredients&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/ingredients/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=ingredients&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/ingredients&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/ingredients&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/ingredients.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/ingredients?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/ingredients/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#eXtraAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-eXtrAI-4378bf&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;ingredients&lt;/code&gt; package is a collection of tools for assessment of feature importance and feature effects.&lt;/p&gt; &#xA;&lt;p&gt;Key functions: &lt;code&gt;feature_importance()&lt;/code&gt; for assessment of global level feature importance, &lt;code&gt;ceteris_paribus()&lt;/code&gt; for calculation of the Ceteris Paribus / What-If Profiles, &lt;code&gt;partial_dependency()&lt;/code&gt; for Partial Dependency Plots, &lt;code&gt;conditional_dependency()&lt;/code&gt; for Conditional Dependency Plots also called M Plots, &lt;code&gt;accumulated_dependency()&lt;/code&gt; for Accumulated Local Effects Plots, &lt;code&gt;cluster_profiles()&lt;/code&gt; for aggregation of Ceteris Paribus Profiles, generic &lt;code&gt;print()&lt;/code&gt; and &lt;code&gt;plot()&lt;/code&gt; for better usability of selected explainers, generic &lt;code&gt;plotD3()&lt;/code&gt; for interactive D3 based explanations, and generic &lt;code&gt;describe()&lt;/code&gt; for explanations in natural language.&lt;/p&gt; &#xA;&lt;p&gt;Vignettes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modeloriented.github.io/ingredients/articles/vignette_titanic.html&#34;&gt;General introduction: Survival on the RMS Titanic&lt;/a&gt;,&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modeloriented.github.io/ingredients/articles/vignette_aspect_importance.html&#34;&gt;Aspects importance&lt;/a&gt;,&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modeloriented.github.io/ingredients/articles/Describing-Explanations.html&#34;&gt;Explanations in natural language&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/iBreakDown&#34;&gt;iBreakDown&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/iBreakDown/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=iBreakDown&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/iBreakDown&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/iBreakDown&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/iBreakDown.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/iBreakDown?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/iBreakDown/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#eXtraAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-eXtrAI-4378bf&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;iBreakDown&lt;/code&gt; package is a model agnostic tool for explanation of predictions from black boxes ML models. Break Down Table shows contributions of every variable to a final prediction. Break Down Plot presents variable contributions in a concise graphical way. SHAP (Shapley Additive Attributions) values are calculated as average from random Break Down profiles. This package works for binary classifiers as well as regression models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;iBreakDown&lt;/code&gt; is a successor of the &lt;a href=&#34;https://github.com/pbiecek/breakDown&#34;&gt;breakDown&lt;/a&gt; package. It is faster (complexity O(p) instead of O(p^2)). It supports interactions and interactive explainers with D3.js plots.&lt;/p&gt; &#xA;&lt;p&gt;Vignettes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modeloriented.github.io/iBreakDown/articles/vignette_iBreakDown_titanic.html&#34;&gt;General introduction: Survival on the RMS Titanic&lt;/a&gt;,&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modeloriented.github.io/iBreakDown/articles/vignette_iBreakDown_description.html&#34;&gt;Explanations in natural language&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/auditor&#34;&gt;auditor&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/auditor/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=auditor&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/auditor&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/auditor&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/auditor.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/auditor?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/auditor/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#eXtraAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-eXtrAI-4378bf&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;auditor&lt;/code&gt; package is a tool for model-agnostic validation. Implemented techniques facilitate assessing and comparing the goodness of fit and performance of models. In addition, they may be used for the analysis of the similarity of residuals and for the identification of outliers and influential observations. The examination is carried out by diagnostic scores and visual verification. Due to the flexible and consistent grammar, it is simple to validate models of any classes.&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Preprint: &lt;a href=&#34;https://arxiv.org/abs/1809.07763&#34;&gt;auditor: an R Package for Model-Agnostic Visual Validation and Diagnostic&lt;/a&gt;,&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/auditor#a-short-overview-of-plots&#34;&gt;List of implemented audits&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/fairmodels&#34;&gt;fairmodels&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/fairmodels/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=fairmodels&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/fairmodels&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ModelOriented/fairmodels/actions&#34;&gt;&lt;img src=&#34;https://github.com/ModelOriented/fairmodels/workflows/R-CMD-check/badge.svg?sanitize=true&#34; alt=&#34;R build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/ModelOriented/fairmodels?branch=master&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/ModelOriented/fairmodels/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;Codecov test coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#eXtraAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-eXtrAI-4378bf&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Flexible tool for bias detection, visualization, and mitigation. Use models explained with &lt;a href=&#34;https://modeloriented.github.io/DALEX/&#34;&gt;DALEX&lt;/a&gt; and calculate fairness classification metrics based on confusion matrices using &lt;code&gt;fairness_check()&lt;/code&gt; or try newly developed module for regression models using &lt;code&gt;fairness_check_regression()&lt;/code&gt;. R package fairmodels allows to compare and gain information about various machine learning models. Mitigate bias with various pre-processing and post-processing techniques. &lt;em&gt;Make sure your models are classifying protected groups similarly&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fairmodels.drwhy.ai/&#34;&gt;fairmodels website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Compas recidivism data use case: &lt;a href=&#34;https://modeloriented.github.io/fairmodels/articles/Basic_tutorial.html&#34;&gt;Basic tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Bias mitigation techniques on Adult data: &lt;a href=&#34;https://modeloriented.github.io/fairmodels/articles/Advanced_tutorial.html&#34;&gt;Advanced tutorial&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/vivo&#34;&gt;vivo&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/vivo/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=vivo&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/vivo&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/vivo&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/vivo.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/vivo?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/vivo/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#eXtraAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-eXtrAI-4378bf&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;vivo&lt;/code&gt; package helps to calculate instance level variable importance (measure of local sensitivity). The importance measure is based on Ceteris Paribus profiles and can be calculated in eight variants. Select the variant that suits your needs by setting parameters: &lt;code&gt;absolute_deviation&lt;/code&gt;, &lt;code&gt;point&lt;/code&gt; and &lt;code&gt;density&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/vivo#intuition&#34;&gt;Intuition for Ceteris Paribus Oscillations&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/randomForestExplainer&#34;&gt;randomForestExplainer&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/randomForestExplainer/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=randomForestExplainer&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/randomForestExplainer&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/randomForestExplainer&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/randomForestExplainer.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/randomForestExplainer?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/randomForestExplainer/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#eXtraAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-eXtrAI-4378bf&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;randomForestExplainer&lt;/code&gt; package helps to understand what is happening inside a Random Forest model. This package helps to explore main effects and pairwise interactions, depth distribution, conditional responses and feature importance.&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Vignettes: &lt;a href=&#34;https://modeloriented.github.io/randomForestExplainer/articles/randomForestExplainer.html&#34;&gt;Boston data: Understanding random forests with randomForestExplainer&lt;/a&gt;, &lt;a href=&#34;https://cdn.staticaly.com/gh/geneticsMiNIng/BlackBoxOpener/master/randomForestExplainer/inst/doc/randomForestExplainer.html&#34;&gt;Glioblastoma data: Understanding random forests with randomForestExplainer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/randomForestExplainer/raw/master/materials/cheatsheet.pdf&#34;&gt;Cheatsheet&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/xspliner&#34;&gt;xspliner&lt;/a&gt; &#xA; &lt;!-- &lt;img src=&#34;https://modeloriented.github.io/xspliner/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;/&gt; --&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=xspliner&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/xspliner&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/xspliner&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/xspliner.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/xspliner?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/vivo/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#AutoMat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-AutoMat-ae2c87&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;xspliner&lt;/code&gt; package is a collection of tools for training interpretable surrogate ML models. The package helps to build simple, interpretable models that inherits informations provided by more complicated ones - resulting model may be treated as explanation of provided black box, that was supplied prior to the algorithm. Provided functionality offers graphical and statistical evaluation both for overall model and its components.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/shapper&#34;&gt;shapper&lt;/a&gt; &lt;img src=&#34;https://github.com/ModelOriented/shapper/raw/master/man/figures/logo.png?raw=true&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=shapper&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/shapper&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/shapper&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/shapper.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/shapper?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/shapper/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#eXtraAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-eXtrAI-4378bf&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;shapper&lt;/code&gt; is an R wrapper of SHAP python library. It accesses python implementation through &lt;code&gt;reticulate&lt;/code&gt; connector.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/drifter&#34;&gt;drifter&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=drifter&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/drifter&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/drifter&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/drifter.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/drifter?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/drifter/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt;&lt;a href=&#34;http://drwhy.ai/#eXtraAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-eXtrAI-4378bf&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;drifter&lt;/code&gt; is an R package that identifies concept drift in model structure or in data structure.&lt;/p&gt; &#xA;&lt;p&gt;Machine learning models are often fitted and validated on historical data under an assumption that data are stationary. The most popular techniques for validation (k-fold cross-validation, repeated cross-validation, and so on) test models on data with the same distribution as training data.&lt;/p&gt; &#xA;&lt;p&gt;Yet, in many practical applications, deployed models are working in a changing environment. After some time, due to changes in the environment, model performance may degenerate, as model may be less reliable.&lt;/p&gt; &#xA;&lt;p&gt;Concept drift refers to the change in the data distribution or in the relationships between variables over time. Think about model for energy consumption for a school, over time the school may be equipped with larger number of devices of with more power-efficient devices that may affect the model performance.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/EIX&#34;&gt;EIX&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=EIX&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/EIX&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/EIX&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/EIX.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/EIX?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/EIX/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#eXtraAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-eXtrAI-4378bf&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;EIX&lt;/code&gt; package implements set of techniques to explore and explain &lt;code&gt;XGBoost&lt;/code&gt; and &lt;code&gt;LightGBM&lt;/code&gt; models. Main functions of this package cover various variable importance measures and well as functions for identification of interactions between variables.&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/EIX#cheatsheets&#34;&gt;Cheatsheet&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/modelStudio&#34;&gt;modelStudio&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/modelStudio/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=modelStudio&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/modelStudio&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/modelStudio&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/modelStudio.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/modelStudio?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/modelStudio/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#AutoMat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-AutoMat-ae2c87&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;modelStudio&lt;/code&gt; package &lt;strong&gt;automates the explanatory analysis of machine learning predictive models&lt;/strong&gt;. It generates advanced interactive model explanations in the form of a &lt;strong&gt;serverless HTML site&lt;/strong&gt; with only one line of code. This tool is model-agnostic, therefore compatible with most of the black-box predictive models and frameworks (e.g.&amp;nbsp;&lt;code&gt;mlr/mlr3&lt;/code&gt;, &lt;code&gt;xgboost&lt;/code&gt;, &lt;code&gt;caret&lt;/code&gt;, &lt;code&gt;h2o&lt;/code&gt;, &lt;code&gt;parsnip&lt;/code&gt;, &lt;code&gt;tidymodels&lt;/code&gt;, &lt;code&gt;scikit-learn&lt;/code&gt;, &lt;code&gt;lightgbm&lt;/code&gt;, &lt;code&gt;keras/tensorflow&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;The main &lt;code&gt;modelStudio()&lt;/code&gt; function computes various (instance and model-level) explanations and produces a&amp;nbsp;&lt;strong&gt;customisable dashboard&lt;/strong&gt;, which consists of multiple panels for plots with their short descriptions. Easily&amp;nbsp;&lt;strong&gt;save&lt;/strong&gt;&amp;nbsp; the dashboard and&amp;nbsp;&lt;strong&gt;share&lt;/strong&gt; it with others. Tools for &lt;a href=&#34;https://ema.drwhy.ai/&#34;&gt;Explanatory Model Analysis&lt;/a&gt; unite with tools for Exploratory Data Analysis to give a broad overview of the model behavior.&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modeloriented.github.io/modelStudio/#demo&#34;&gt;Getting started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelstudio.drwhy.ai/articles/ms-perks-features.html&#34;&gt;Vignette: perks and features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://joss.theoj.org/papers/10.21105/joss.01798&#34;&gt;JOSS paper: Interactive Studio with Explanations for ML Predictive Models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/ModelOriented/arenar&#34;&gt;arenar&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=arenar&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/arenar&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ModelOriented/ArenaR/actions&#34;&gt;&lt;img src=&#34;https://github.com/ModelOriented/ArenaR/workflows/R-CMD-check/badge.svg?sanitize=true&#34; alt=&#34;R build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/ModelOriented/ArenaR?branch=master&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/ModelOriented/ArenaR/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;Codecov test coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#AutoMat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-AutoMat-ae2c87&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Arena is an interactive tool that allows you to explore and compare any model regardless of its internal structure.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;arenar&lt;/code&gt; package can be run in two modes - live (R runs in the background and calculates all necessary explanations) and serverless (all necessary explanations are calculated earlier).&lt;/p&gt; &#xA;&lt;p&gt;Using the Arena is trivially simple. Examples with different levels of advancement are available:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://arenar.drwhy.ai/&#34;&gt;Arena website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arenar.drwhy.ai/&#34;&gt;arenar documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/modelDown&#34;&gt;modelDown&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=modelDown&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/modelDown&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/modelDown&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/modelDown.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/modelDown?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/modelDown/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#AutoMat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-AutoMat-ae2c87&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The&lt;code&gt;modelDown&lt;/code&gt; package generates a website with HTML summaries for predictive models. Is uses &lt;code&gt;DALEX&lt;/code&gt; explainers to compute and plot summaries of how given models behave. We can see how well models behave (&lt;em&gt;Model Performance&lt;/em&gt;, &lt;em&gt;Auditor&lt;/em&gt;), how much each variable contributes to predictions (&lt;em&gt;Variable Response&lt;/em&gt;) and which variables are the most important for a given model (&lt;em&gt;Variable Importance&lt;/em&gt;). We can also compare Concept Drift for pairs of models (&lt;em&gt;Drifter&lt;/em&gt;). Additionally, data available on the website can be easily recreated in current R session (using &lt;code&gt;archivist&lt;/code&gt; package).&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modeloriented.github.io/modelDown/getting-started&#34;&gt;Getting started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://joss.theoj.org/papers/10.21105/joss.01444&#34;&gt;JOSS paper: modelDown: automated website generator with interpretable documentation for predictive machine learning models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/rSAFE&#34;&gt;rSAFE&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/rSAFE/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=rSAFE&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/rSAFE&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/rSAFE&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/rSAFE.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/rSAFE?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/rSAFE/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt;&lt;a href=&#34;http://drwhy.ai/#AutoMat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-AutoMat-ae2c87&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;rSAFE&lt;/code&gt; package is a model agnostic tool for making an interpretable white-box model more accurate using alternative black-box model called surrogate model. Based on the complicated model, such as neural network or random forest, new features are being extracted and then used in the process of fitting a simpler interpretable model, improving its overall performance.&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;article &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S016792362100066X&#34;&gt;Simpler is better: Lifting interpretability-performance trade-off via automated feature engineering&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;package &lt;a href=&#34;https://modeloriented.github.io/rSAFE/&#34;&gt;website&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/ModelOriented/EloML&#34;&gt;EloML&lt;/a&gt; &lt;img src=&#34;https://modeloriented.github.io/EloML/reference/figures/logo.png&#34; align=&#34;right&#34; width=&#34;100&#34;&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=EloML&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/EloML&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/ModelOriented/EloML&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/ModelOriented/EloML.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/ModelOriented/EloML?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ModelOriented/EloML/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#AutoMat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-AutoMat-373589&#34; alt=&#34;DrWhy-AutoMat&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;EloML&lt;/code&gt; package provides Elo rating system for machine learning models. Elo Predictive Power (EPP) score helps to assess model performance based Elo ranking system.&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1908.09213&#34;&gt;arxiv&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://github.com/pbiecek/archivist&#34;&gt;archivist&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=archivist&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/archivist&#34; alt=&#34;CRAN_Status_Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/pbiecek/archivist&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/pbiecek/archivist.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/pbiecek/archivist?branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/pbiecek/archivist/master.svg?sanitize=true&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://drwhy.ai/#BackBone&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DrWhy-BackBone-373589&#34; alt=&#34;DrWhy-eXtrAI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;archivist&lt;/code&gt; package automate serialization and deserialization of R objects. Objects are stored with additional metadata to facilitate reproducibility and governance of data science projects.&lt;/p&gt; &#xA;&lt;p&gt;Everything that exists in R is an object. &lt;code&gt;archivist&lt;/code&gt; is an R package that stores copies of all objects along with their metadata. It helps to manage and recreate objects with final or partial results from data analysis. Use &lt;code&gt;archivist&lt;/code&gt; to record every result, to share these results with future you or with others, to search through repository of objects created in the past but needed now.&lt;/p&gt; &#xA;&lt;p&gt;Learn more:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pbiecek/archivist/raw/master/cheatsheets/archivistCheatsheet.png&#34;&gt;Cheatsheet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://doi.org/10.18637/jss.v082.i11&#34;&gt;JSS article&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Tools that are useful during the model lifetime. &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; stands for our internal tools.&lt;/p&gt; &#xA;&lt;h3&gt;1. Data preparation&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/dataMaid/index.html&#34;&gt;dataMaid&lt;/a&gt;; A Suite of Checks for Identification of Potential Errors in a Data Frame as Part of the Data Screening Process&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/inspectdf/index.html&#34;&gt;inspectdf&lt;/a&gt;; A collection of utilities for columnwise summary, comparison and visualisation of data frames.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/data-cleaning/validate&#34;&gt;validate&lt;/a&gt;; Professional data validation for the R environment&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/data-cleaning/errorlocate&#34;&gt;errorlocate&lt;/a&gt;; Find and replace erroneous fields in data using validation rules&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;ggplot2&lt;/a&gt;; System for declaratively creating graphics, based on The Grammar of Graphics.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2. Data understanding&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Model Agnostic Variable Importance Scores. Surrogate learning = Train an elastic model and measure feature importance in such model. See &lt;a href=&#34;https://github.com/pbiecek/DALEX/&#34;&gt;DALEX&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/1801.01489&#34;&gt;Model Class Reliance MCR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/koalaverse/vip&#34;&gt;vip&lt;/a&gt; Variable importance plots&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MI2DataLab/SAFE&#34;&gt;SAFE&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; Surrogate learning = Train an elastic model and extract feature transformations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/xspliner&#34;&gt;xspliner&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; Using surrogate black-boxes to train interpretable spline based additive models&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MI2DataLab/factorMerger&#34;&gt;factorMerger&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; Set of tools for factors merging &lt;a href=&#34;https://arxiv.org/abs/1709.04412&#34;&gt;paper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/ingredients&#34;&gt;ingredients&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; Set of tools for model level feature effects and feature importance.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;4. Model assembly&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mlr-org/mlr&#34;&gt;mlr&lt;/a&gt; Machine Learning in R &lt;a href=&#34;http://jmlr.org/papers/v17/15-066.html&#34;&gt;paper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/topepo/caret&#34;&gt;caret&lt;/a&gt; Classification And Regression Training &lt;a href=&#34;https://www.jstatsoft.org/article/view/v028i05&#34;&gt;paper&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;5. Model audit&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MI2DataLab/auditor&#34;&gt;auditor&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; model verification, validation, and error analysis &lt;a href=&#34;https://mi2datalab.github.io/auditor/articles/model_performance_audit.html&#34;&gt;vigniette&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pbiecek/DALEX/&#34;&gt;DALEX&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; Descriptive mAchine Learning EXplanations&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/christophM/iml&#34;&gt;iml&lt;/a&gt;; interpretable machine learning R package&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MI2DataLab/randomForestExplainer&#34;&gt;randomForestExplainer&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; A set of tools to understand what is happening inside a Random Forest&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MI2DataLab/survxai&#34;&gt;survxai&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; Explanations for survival models &lt;a href=&#34;http://joss.theoj.org/papers/dcc9d53e8a1b1f613d59b9658b113fff&#34;&gt;paper&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;6. Model delivery&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/iBreakDown&#34;&gt;iBreakDown&lt;/a&gt;, &lt;a href=&#34;https://github.com/MI2DataLab/pyBreakDown&#34;&gt;pyBreakDown&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; Model Agnostic Explainers for Individual Predictions (with interactions)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pbiecek/ceterisParibus&#34;&gt;ceterisParibus&lt;/a&gt;, &lt;a href=&#34;https://github.com/ModelOriented/pyCeterisParibus&#34;&gt;pyCeterisParibus&lt;/a&gt;, &lt;a href=&#34;https://github.com/MI2DataLab/ceterisParibusExt/tree/master/ceterisParibusD3&#34;&gt;ceterisParibusD3&lt;/a&gt; and &lt;a href=&#34;https://github.com/ModelOriented/ingredients&#34;&gt;ingredients&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; Ceteris Paribus Plots (What-If plots) for explanations of a single observation&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/localModel&#34;&gt;localModel&lt;/a&gt; and &lt;a href=&#34;https://github.com/MI2DataLab/live/&#34;&gt;live&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; LIME-like explanations with interpretable features based on Ceteris Paribus curves.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/thomasp85/lime&#34;&gt;lime&lt;/a&gt;; Local Interpretable Model-Agnostic Explanations (R port of original Python package)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/shapper&#34;&gt;shapper&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; An R wrapper of SHAP python library&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/modelDown&#34;&gt;modelDown&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; modelDown generates a website with HTML summaries for predictive models&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/modelStudio&#34;&gt;modelStudio&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; modelStudio generates an interactive dashboard with D3 based summaries for predictive models&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ModelOriented/drifter&#34;&gt;drifter&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; Concept Drift and Concept Shift Detection for Predictive Models&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pbiecek/archivist&#34;&gt;archivist&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/mi2.svg?sanitize=true&#34; alt=&#34;MI2&#34;&gt; A set of tools for datasets and plots archiving &lt;a href=&#34;http://doi.org/10.18637/jss.v082.i11&#34;&gt;paper&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Family of Model Explainers&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/DrWhyAI.png&#34; alt=&#34;images/DrWhyAI.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Architecture of DrWhy&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;DrWhy&lt;/code&gt; works on fully trained predictive models. Models can be created with any tool.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;DrWhy&lt;/code&gt; uses &lt;code&gt;DALEX&lt;/code&gt; package to wrap model with additional metadata required for explanations, like validation data, predict function etc.&lt;/p&gt; &#xA;&lt;p&gt;Explainers for predictive models can be created with model agnostic or model specific functions implemented in various packages.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ModelOriented/DrWhy/master/images/Hype_Cycle.svg?sanitize=true&#34; alt=&#34;Hype_Cycle&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cran/facebookorganicR</title>
    <updated>2022-12-11T01:37:22Z</updated>
    <id>tag:github.com,2022-12-11:/cran/facebookorganicR</id>
    <link href="https://github.com/cran/facebookorganicR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;❗ This is a read-only mirror of the CRAN R package repository. facebookorganicR — Get Data from &#39;Facebook Organic&#39; via the &#39;Windsor.ai&#39; API. Homepage: https://windsor.ai/&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;facebookorganicR&lt;/h1&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;p&gt;The goal of &lt;code&gt;facebookorganicR&lt;/code&gt; is to help &lt;code&gt;R&lt;/code&gt; users to access digital marketing data from Facebook Organic via &lt;code&gt;Windsor.ai&lt;/code&gt; &lt;code&gt;API&lt;/code&gt; in a convenient way from &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://windsor.ai/&#34;&gt;Windsor.ai&lt;/a&gt; allows to get marketing data from any platform. It beautifully simplifies the complexity of dealing with multiple platforms, unlocking unified, valuable information in a format that matters to you. For more details checkout &lt;a href=&#34;https://onboard.windsor.ai/&#34;&gt;onboard.windsor.ai&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install the development version of facebookorganicR from &lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt; with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# install.packages(&#34;devtools&#34;)&#xA;devtools::install_github(&#34;pablosanchezmart/facebookorganicR&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;h3&gt;Registration&lt;/h3&gt; &#xA;&lt;p&gt;You need to get a free API key to access windsor.ai&#39;s APIs. Register your account first and add a data source like Facebook Organic and then get the API key. For more details check out our official API documentation and this article. Get the API key at &lt;a href=&#34;https://onboard.windsor.ai&#34;&gt;https://onboard.windsor.ai&lt;/a&gt;. You have a 30 days trial for free.&lt;/p&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;The package currently has only one function &lt;code&gt;fetch_facebookorganicR&lt;/code&gt; which will return a &lt;code&gt;data.frame&lt;/code&gt; provided that all of the arguments are supplied to it:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;your API key,&lt;/li&gt; &#xA; &lt;li&gt;date range, (starting and ending date)&lt;/li&gt; &#xA; &lt;li&gt;and fields you require.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(facebookorganicR)&#xA;&#xA;my_facebookorganic_data &amp;lt;-&#xA;  fetch_facebookorganic(api_key = &#34;your api key&#34;,&#xA;           date_from = Sys.Date()-100,&#xA;           date_to = Sys.Date(),&#xA;           fields = c(&#34;campaign&#34;, &#34;clicks&#34;,&#xA;                      &#34;spend&#34;, &#34;impressions&#34;, &#34;date&#34;)) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&#xA;&#39;data.frame&#39;:&#x9;14 obs. of  5 variables:&#xA; $ campaign   : chr  &#34;retageting APAC&#34; &#34;retargeting UK&amp;amp;CO&#34; &#34;retageting APAC&#34; &#34;retargeting UK&amp;amp;CO&#34; ...&#xA; $ clicks     : num  4 0 5 7 0 0 4 2 3 0 ...&#xA; $ spend      : num  2.57 2.48 2.39 2.54 0.94 0.71 2.59 2.12 2.43 0.13 ...&#xA; $ impressions: num  806 693 819 689 299 190 682 688 822 135 ...&#xA; $ date       : chr  &#34;2022-09-28&#34; &#34;2022-09-28&#34; &#34;2022-09-29&#34; &#34;2022-09-29&#34; ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Will return a &lt;code&gt;data.frame&lt;/code&gt; with marketing data from Facebook Organic.&lt;/p&gt; &#xA;&lt;p&gt;For more details see the API documentation at &lt;a href=&#34;https://windsor.ai/api-fields/&#34;&gt;https://windsor.ai//api-fields/&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>