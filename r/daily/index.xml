<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-17T01:33:27Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>methods-2-f24/resources</title>
    <updated>2024-02-17T01:33:27Z</updated>
    <id>tag:github.com,2024-02-17:/methods-2-f24/resources</id>
    <link href="https://github.com/methods-2-f24/resources" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Methods 2: The General Linear Model&lt;/h1&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;This course is about regression modelling and its conceptual and mathematical foundations. The main emphasis is on &lt;em&gt;linear&lt;/em&gt; regression and the &lt;em&gt;general linear model&lt;/em&gt; (GLM). After familiarizing ourselves with the broader context and goals of linear regression modelling in the first three weeks of the course, we turn to the mathematical foundations of this type (and many other types) of modelling: linear algebra and calculus. The concepts covered here are essential to understanding the methods underlying not just the modelling we use in this course but also the approaches introduced in later semesters. Once the mathematical groundwork is laid, we proceed to applying everything in practice. Ultimately this will take us to generalizations of the GLM like logistic regression.&lt;/p&gt; &#xA;&lt;h2&gt;Repo structure&lt;/h2&gt; &#xA;&lt;p&gt;This repository has been initialised with the following directory structure:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Column&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;classes&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Instructions and folders for each of the practical classes. Has the folder &lt;code&gt;data&lt;/code&gt; in it containing the data we will use in classes.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;slides&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Slides from lectures.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Framework and tools&lt;/h2&gt; &#xA;&lt;p&gt;In most practical applications, we will work in the framework of Bayesian inference, which will be introduced at the beginning. Thanks to the modern software tools at our disposal - &lt;a href=&#34;https://www.r-project.org/&#34;&gt;R&lt;/a&gt; and &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt; - this is much easier nowadays than it used to be. For conceptual and practical reasons, this is the approach of choice. However, for a deeper understanding, we will also cover the &lt;em&gt;ordinary least squares&lt;/em&gt; (OLS) approach to model fitting.&lt;/p&gt; &#xA;&lt;h2&gt;Literature&lt;/h2&gt; &#xA;&lt;p&gt;The main textbook for this course is &lt;em&gt;Regression and Other Stories&lt;/em&gt; by Gelman, Hill, and Vehtari (2020), referenced below. Please get a copy of this. For the mathematical foundations, we will rely on parts of &lt;em&gt;Essential Mathematics for Political and Social Research&lt;/em&gt; by Gill (2006), also referenced below. You can download the relevant chapters of this via the Royal Library.&lt;/p&gt; &#xA;&lt;p&gt;Should you want to deepen your knowledge of the mathematical content, I can recommend the two companion books available here: &lt;a href=&#34;https://minireference.com/&#34;&gt;https://minireference.com/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Lesson Plan&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Course week&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Week of year&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Topics and readings&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Regression and the GLM: overview, data and measurement, (GHV&lt;sup&gt;1&lt;/sup&gt; 1,2)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Basic methods, statistical inference (GHV 3)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Statistical inference (continued), simulation (GHV 4,5)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Math basics: functions, equations, polynomials, logarithms (Gill&lt;sup&gt;2&lt;/sup&gt; 1)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Linear algebra basics: vectors, matrices, norms, transposition (Gill 3)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;More linear algebra: geometry, determinants, rank, inversion, eigenvectors (Gill 4)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Scalar calculus: derivatives, integrals, fundamental theorem (Gill 5)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;More calculus: root finding, extrema, Lagrange multipliers, vector calculus (Gill 6)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Conceptual foundations and history of the GLM, model fitting (GHV 6,7,8)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Fitting GLMs: prediction, Bayesian inference (GHV 9)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Multiple predictors, interactions (GHV 10)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Model comparison, assumptions and diagnostics (GHV 11)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Transformations, predictive simulations (GHV 12) [no class, just lecture]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; Gelman, A., Hill, J., &amp;amp; Vehtari, A. (2020). &lt;em&gt;Regression and Other Stories&lt;/em&gt; (Analytical Methods for Social Research). Cambridge: Cambridge University Press. &lt;a href=&#34;https://doi.org/10.1017/9781139161879&#34;&gt;doi:10.1017/9781139161879&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt; Gill, J. (2006). &lt;em&gt;Essential Mathematics for Political and Social Research&lt;/em&gt; (Analytical Methods for Social Research). Cambridge: Cambridge University Press. &lt;a href=&#34;https://doi.org/10.1017/CBO9780511606656&#34;&gt;doi:10.1017/CBO9780511606656&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Videos&lt;/h2&gt; &#xA;&lt;p&gt;This whole course (with a few exceptions) &lt;a href=&#34;https://www.youtube.com/playlist?list=PLvJwKACYy5_MTdnrzxx_1sN389dS9OB3S&#34;&gt;is on YouTube&lt;/a&gt;! These videos are from when the course took place under lockdown conditions. This year, we&#39;re going to cover topics in a slightly different order, starting with an introduction to regression modelling before we go into linear algebra and calculus. This means the videos will be less relevant during the first three weeks of the course, but from then on, you can watch them in the order of the playlist.&lt;/p&gt; &#xA;&lt;h2&gt;Flipped classroom&lt;/h2&gt; &#xA;&lt;p&gt;We will be using a so-called &#39;flipped classroom&#39; in this course. This means that you are generally expected to have read the literature and watched the videos before coming to the lecture. The purpose of the lecture then is for you to ask questions (the more, the better!) so that we can go over the material again together, deepening and broadening our understanding of it.&lt;/p&gt; &#xA;&lt;h2&gt;Questions?&lt;/h2&gt; &#xA;&lt;p&gt;In order for us to stay in contact, ask questions, and have discussions, we will use &lt;a href=&#34;https://github.com/orgs/methods-2-f23/discussions&#34;&gt;GitHub Discussion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Exam&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Portfolio consisting of 3 assignments&lt;/li&gt; &#xA; &lt;li&gt;Each assignment will require you to create an R Markdown notebook consisting of a mix of text and code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You will receive a (short) feedback message from us on your portfolio assignments that you can use for improvements before finalizing your hand-ins.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>easystats/bayestestR</title>
    <updated>2024-02-17T01:33:27Z</updated>
    <id>tag:github.com,2024-02-17:/easystats/bayestestR</id>
    <link href="https://github.com/easystats/bayestestR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üëª Utilities for analyzing Bayesian models and posterior distributions&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bayestestR &lt;img src=&#34;https://raw.githubusercontent.com/easystats/bayestestR/main/man/figures/logo.png&#34; align=&#34;right&#34; height=&#34;139&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://doi.org/10.21105/joss.01541&#34;&gt;&lt;img src=&#34;https://joss.theoj.org/papers/10.21105/joss.01541/status.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://CRAN.R-project.org/package=bayestestR&#34;&gt;&lt;img src=&#34;https://tinyverse.netlify.com/badge/bayestestR&#34; alt=&#34;status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://lifecycle.r-lib.org/articles/stages.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/lifecycle-maturing-blue.svg?sanitize=true&#34; alt=&#34;lifecycle&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Become a Bayesian master you will&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; We changed the default the CI width! Please make an &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/credible_interval.html&#34;&gt;informed decision&lt;/a&gt; and set it explicitly (&lt;code&gt;ci = 0.89&lt;/code&gt;, &lt;code&gt;ci = 0.95&lt;/code&gt; or anything else that you decide) &lt;span&gt;‚ö†&lt;/span&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Existing R packages allow users to easily fit a large variety of models and extract and visualize the posterior draws. However, most of these packages only return a limited set of indices (e.g., point-estimates and CIs). &lt;strong&gt;bayestestR&lt;/strong&gt; provides a comprehensive and consistent set of functions to analyze and describe posterior distributions generated by a variety of models objects, including popular modeling packages such as &lt;strong&gt;rstanarm&lt;/strong&gt;, &lt;strong&gt;brms&lt;/strong&gt; or &lt;strong&gt;BayesFactor&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can reference the package and its documentation as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Makowski, D., Ben-Shachar, M. S., &amp;amp; L√ºdecke, D. (2019). &lt;em&gt;bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework&lt;/em&gt;. Journal of Open Source Software, 4(40), 1541. &lt;a href=&#34;https://doi.org/10.21105/joss.01541&#34;&gt;10.21105/joss.01541&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Makowski, D., Ben-Shachar, M. S., Chen, S. H. A., &amp;amp; L√ºdecke, D. (2019). &lt;em&gt;Indices of Effect Existence and Significance in the Bayesian Framework&lt;/em&gt;. Frontiers in Psychology 2019;10:2767. &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2019.02767&#34;&gt;10.3389/fpsyg.2019.02767&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=bayestestR&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/bayestestR&#34; alt=&#34;CRAN&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://easystats.r-universe.dev&#34;&gt;&lt;img src=&#34;https://easystats.r-universe.dev/badges/bayestestR&#34; alt=&#34;insight status badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/easystats/bayestestR/actions&#34;&gt;&lt;img src=&#34;https://github.com/easystats/bayestestR/workflows/R-CMD-check/badge.svg?branch=main&#34; alt=&#34;R-CMD-check&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;em&gt;bayestestR&lt;/em&gt; package is available on CRAN, while its latest development version is available on R-universe (from &lt;em&gt;rOpenSci&lt;/em&gt;).&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Source&lt;/th&gt; &#xA;   &lt;th&gt;Command&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Release&lt;/td&gt; &#xA;   &lt;td&gt;CRAN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;install.packages(&#34;bayestestR&#34;)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Development&lt;/td&gt; &#xA;   &lt;td&gt;R-universe&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;install.packages(&#34;bayestestR&#34;, repos = &#34;https://easystats.r-universe.dev&#34;)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Once you have downloaded the package, you can then load it using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&#34;bayestestR&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Instead of &lt;code&gt;library(bayestestR)&lt;/code&gt;, use &lt;code&gt;library(easystats)&lt;/code&gt;.&lt;/strong&gt; &lt;strong&gt;This will make all features of the easystats-ecosystem available.&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;To stay updated, use &lt;code&gt;easystats::install_latest()&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Access the package &lt;a href=&#34;https://easystats.github.io/bayestestR/&#34;&gt;documentation&lt;/a&gt; and check-out these vignettes:&lt;/p&gt; &#xA;&lt;h3&gt;Tutorials&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayestestR.html&#34;&gt;Get Started with Bayesian Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/example1.html&#34;&gt;Example 1: Initiation to Bayesian models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/example2.html&#34;&gt;Example 2: Confirmation of Bayesian skills&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/example3.html&#34;&gt;Example 3: Become a Bayesian master&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Articles&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/credible_interval.html&#34;&gt;Credible Intervals (CI)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/probability_of_direction.html&#34;&gt;Probability of Direction (pd)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/region_of_practical_equivalence.html&#34;&gt;Region of Practical Equivalence (ROPE)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayes_factors.html&#34;&gt;Bayes Factors (BF)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/web_only/indicesEstimationComparison.html&#34;&gt;Comparison of Point-Estimates&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://doi.org/10.3389/fpsyg.2019.02767&#34;&gt;Comparison of Indices of Effect Existence&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/guidelines.html&#34;&gt;Reporting Guidelines&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;p&gt;In the Bayesian framework, parameters are estimated in a probabilistic fashion as &lt;em&gt;distributions&lt;/em&gt;. These distributions can be summarised and described by reporting four types of indices:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/web_only/indicesEstimationComparison.html&#34;&gt;&lt;strong&gt;Centrality&lt;/strong&gt;&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;mean()&lt;/code&gt;, &lt;code&gt;median()&lt;/code&gt; or &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/map_estimate.html&#34;&gt;&lt;code&gt;map_estimate()&lt;/code&gt;&lt;/a&gt; for an estimation of the mode.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/point_estimate.html&#34;&gt;&lt;code&gt;point_estimate()&lt;/code&gt;&lt;/a&gt; can be used to get them at once and can be run directly on models.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/credible_interval.html&#34;&gt;&lt;strong&gt;Uncertainty&lt;/strong&gt;&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/hdi.html&#34;&gt;&lt;code&gt;hdi()&lt;/code&gt;&lt;/a&gt; for &lt;em&gt;Highest Density Intervals (HDI)&lt;/em&gt;, &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/spi.html&#34;&gt;&lt;code&gt;spi()&lt;/code&gt;&lt;/a&gt; for &lt;em&gt;Shortest Probability Intervals (SPI)&lt;/em&gt; or &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/eti.html&#34;&gt;&lt;code&gt;eti()&lt;/code&gt;&lt;/a&gt; for &lt;em&gt;Equal-Tailed Intervals (ETI)&lt;/em&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/ci.html&#34;&gt;&lt;code&gt;ci()&lt;/code&gt;&lt;/a&gt; can be used as a general method for Confidence and Credible Intervals (CI).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/indicesExistenceComparison.html&#34;&gt;&lt;strong&gt;Effect Existence&lt;/strong&gt;&lt;/a&gt;: whether an effect is different from 0. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/p_direction.html&#34;&gt;&lt;code&gt;p_direction()&lt;/code&gt;&lt;/a&gt; for a Bayesian equivalent of the frequentist &lt;em&gt;p&lt;/em&gt;-value (see &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2019.02767&#34;&gt;Makowski et al., 2019&lt;/a&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/p_map.html&#34;&gt;&lt;code&gt;p_pointnull()&lt;/code&gt;&lt;/a&gt; represents the odds of null hypothesis (&lt;em&gt;h0 = 0&lt;/em&gt;) compared to the most likely hypothesis (the MAP).&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/bayesfactor_parameters.html&#34;&gt;&lt;code&gt;bf_pointnull()&lt;/code&gt;&lt;/a&gt; for a classic &lt;em&gt;Bayes Factor (BF)&lt;/em&gt; assessing the likelihood of effect presence against its absence (&lt;em&gt;h0 = 0&lt;/em&gt;).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/indicesExistenceComparison.html&#34;&gt;&lt;strong&gt;Effect Significance&lt;/strong&gt;&lt;/a&gt;: whether the effect size can be considered as non-negligible. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/p_rope.html&#34;&gt;&lt;code&gt;p_rope()&lt;/code&gt;&lt;/a&gt; is the probability of the effect falling inside a &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/region_of_practical_equivalence.html&#34;&gt;&lt;em&gt;Region of Practical Equivalence (ROPE)&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/bayesfactor_parameters.html&#34;&gt;&lt;code&gt;bf_rope()&lt;/code&gt;&lt;/a&gt; computes a Bayes factor against the null as defined by a region (the ROPE).&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/p_significance.html&#34;&gt;&lt;code&gt;p_significance()&lt;/code&gt;&lt;/a&gt; that combines a region of equivalence with the probability of direction.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/describe_posterior.html&#34;&gt;&lt;code&gt;describe_posterior()&lt;/code&gt;&lt;/a&gt; is the master function with which you can compute all of the indices cited below at once.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;describe_posterior(&#xA;  rnorm(10000),&#xA;  centrality = &#34;median&#34;,&#xA;  test = c(&#34;p_direction&#34;, &#34;p_significance&#34;),&#xA;  verbose = FALSE&#xA;)&#xA;## Summary of Posterior Distribution&#xA;## &#xA;## Parameter | Median |        95% CI |     pd |   ps&#xA;## --------------------------------------------------&#xA;## Posterior |  -0.01 | [-1.98, 1.93] | 50.52% | 0.46&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;describe_posterior()&lt;/code&gt; works for many objects, including more complex &lt;em&gt;brmsfit&lt;/em&gt;-models. For better readability, the output is separated by model components:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;zinb &amp;lt;- read.csv(&#34;http://stats.idre.ucla.edu/stat/data/fish.csv&#34;)&#xA;set.seed(123)&#xA;model &amp;lt;- brm(&#xA;  bf(&#xA;    count ~ child + camper + (1 | persons),&#xA;    zi ~ child + camper + (1 | persons)&#xA;  ),&#xA;  data = zinb,&#xA;  family = zero_inflated_poisson(),&#xA;  chains = 1,&#xA;  iter = 500&#xA;)&#xA;&#xA;describe_posterior(&#xA;  model,&#xA;  effects = &#34;all&#34;,&#xA;  component = &#34;all&#34;,&#xA;  test = c(&#34;p_direction&#34;, &#34;p_significance&#34;),&#xA;  centrality = &#34;all&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;## Summary of Posterior Distribution&#xA;## &#xA;## Parameter   | Median |  Mean |   MAP |         95% CI |     pd |   ps |  Rhat |    ESS&#xA;## --------------------------------------------------------------------------------------&#xA;## (Intercept) |   0.96 |  0.96 |  0.96 | [-0.81,  2.51] | 90.00% | 0.88 | 1.011 | 110.00&#xA;## child       |  -1.16 | -1.16 | -1.16 | [-1.36, -0.94] |   100% | 1.00 | 0.996 | 278.00&#xA;## camper      |   0.73 |  0.72 |  0.73 | [ 0.54,  0.91] |   100% | 1.00 | 0.996 | 271.00&#xA;## &#xA;## # Fixed effects (zero-inflated)&#xA;## &#xA;## Parameter   | Median |  Mean |   MAP |         95% CI |     pd |   ps |  Rhat |    ESS&#xA;## --------------------------------------------------------------------------------------&#xA;## (Intercept) |  -0.48 | -0.51 | -0.22 | [-2.03,  0.89] | 78.00% | 0.73 | 0.997 | 138.00&#xA;## child       |   1.85 |  1.86 |  1.81 | [ 1.19,  2.54] |   100% | 1.00 | 0.996 | 303.00&#xA;## camper      |  -0.88 | -0.86 | -0.99 | [-1.61, -0.07] | 98.40% | 0.96 | 0.996 | 292.00&#xA;## &#xA;## # Random effects (conditional) Intercept: persons&#xA;## &#xA;## Parameter |    Median |  Mean |   MAP |         95% CI |     pd |   ps |  Rhat |    ESS&#xA;## ---------------------------------------------------------------------------------------&#xA;## persons.1 |     -0.99 | -1.01 | -0.84 | [-2.68,  0.80] | 92.00% | 0.90 | 1.007 | 106.00&#xA;## persons.2 | -4.65e-03 | -0.04 |  0.03 | [-1.63,  1.66] | 50.00% | 0.45 | 1.013 | 109.00&#xA;## persons.3 |      0.69 |  0.66 |  0.69 | [-0.95,  2.34] | 79.60% | 0.78 | 1.010 | 114.00&#xA;## persons.4 |      1.57 |  1.56 |  1.56 | [-0.05,  3.29] | 96.80% | 0.96 | 1.009 | 114.00&#xA;## &#xA;## # Random effects (zero-inflated) Intercept: persons&#xA;## &#xA;## Parameter | Median |  Mean |   MAP |         95% CI |     pd |   ps |  Rhat |    ESS&#xA;## ------------------------------------------------------------------------------------&#xA;## persons.1 |   1.10 |  1.11 |  1.08 | [-0.23,  2.72] | 94.80% | 0.93 | 0.997 | 166.00&#xA;## persons.2 |   0.18 |  0.18 |  0.22 | [-0.94,  1.58] | 63.20% | 0.54 | 0.996 | 154.00&#xA;## persons.3 |  -0.30 | -0.31 | -0.54 | [-1.79,  1.02] | 64.00% | 0.59 | 0.997 | 154.00&#xA;## persons.4 |  -1.45 | -1.46 | -1.44 | [-2.90, -0.10] | 98.00% | 0.97 | 1.000 | 189.00&#xA;## &#xA;## # Random effects (conditional) SD/Cor: persons&#xA;## &#xA;## Parameter   | Median | Mean |  MAP |         95% CI |   pd |   ps |  Rhat |    ESS&#xA;## ----------------------------------------------------------------------------------&#xA;## (Intercept) |   1.42 | 1.58 | 1.07 | [ 0.71,  3.58] | 100% | 1.00 | 1.010 | 126.00&#xA;## &#xA;## # Random effects (zero-inflated) SD/Cor: persons&#xA;## &#xA;## Parameter   | Median | Mean |  MAP |         95% CI |   pd |   ps |  Rhat |    ESS&#xA;## ----------------------------------------------------------------------------------&#xA;## (Intercept) |   1.30 | 1.49 | 0.99 | [ 0.63,  3.41] | 100% | 1.00 | 0.996 | 129.00&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;bayestestR&lt;/em&gt; also includes &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/index.html&#34;&gt;&lt;strong&gt;many other features&lt;/strong&gt;&lt;/a&gt; useful for your Bayesian analyses. Here are some more examples:&lt;/p&gt; &#xA;&lt;h2&gt;Point-estimates&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(bayestestR)&#xA;&#xA;posterior &amp;lt;- distribution_gamma(10000, 1.5) # Generate a skewed distribution&#xA;centrality &amp;lt;- point_estimate(posterior) # Get indices of centrality&#xA;centrality&#xA;## Point Estimate&#xA;## &#xA;## Median | Mean |  MAP&#xA;## --------------------&#xA;## 1.18   | 1.50 | 0.51&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As for other &lt;a href=&#34;https://github.com/easystats&#34;&gt;&lt;strong&gt;easystats&lt;/strong&gt;&lt;/a&gt; packages, &lt;code&gt;plot()&lt;/code&gt; methods are available from the &lt;a href=&#34;https://easystats.github.io/see/&#34;&gt;&lt;strong&gt;see&lt;/strong&gt;&lt;/a&gt; package for many functions:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easystats/bayestestR/main/man/figures/unnamed-chunk-8-1.png&#34; alt=&#34;&#34;&gt;&#xA; &lt;!-- --&gt;&lt;/p&gt; &#xA;&lt;p&gt;While the &lt;strong&gt;median&lt;/strong&gt; and the &lt;strong&gt;mean&lt;/strong&gt; are available through base R functions, &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/map_estimate.html&#34;&gt;&lt;code&gt;map_estimate()&lt;/code&gt;&lt;/a&gt; in &lt;em&gt;bayestestR&lt;/em&gt; can be used to directly find the &lt;strong&gt;Highest Maximum A Posteriori (MAP)&lt;/strong&gt; estimate of a posterior, &lt;em&gt;i.e.&lt;/em&gt;, the value associated with the highest probability density (the ‚Äúpeak‚Äù of the posterior distribution). In other words, it is an estimation of the &lt;em&gt;mode&lt;/em&gt; for continuous parameters.&lt;/p&gt; &#xA;&lt;h2&gt;Uncertainty (CI)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/hdi.html&#34;&gt;&lt;code&gt;hdi()&lt;/code&gt;&lt;/a&gt; computes the &lt;strong&gt;Highest Density Interval (HDI)&lt;/strong&gt; of a posterior distribution, i.e., the interval which contains all points within the interval have a higher probability density than points outside the interval. The HDI can be used in the context of Bayesian posterior characterization as &lt;strong&gt;Credible Interval (CI)&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Unlike equal-tailed intervals (see &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/eti.html&#34;&gt;&lt;code&gt;eti()&lt;/code&gt;&lt;/a&gt;) that typically exclude 2.5% from each tail of the distribution, the HDI is &lt;em&gt;not&lt;/em&gt; equal-tailed and therefore always includes the mode(s) of posterior distributions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;posterior &amp;lt;- distribution_chisquared(10000, 4)&#xA;&#xA;hdi(posterior, ci = 0.89)&#xA;## 89% HDI: [0.18, 7.63]&#xA;&#xA;eti(posterior, ci = 0.89)&#xA;## 89% ETI: [0.75, 9.25]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easystats/bayestestR/main/man/figures/unnamed-chunk-10-1.png&#34; alt=&#34;&#34;&gt;&#xA; &lt;!-- --&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Existence and Significance Testing&lt;/h2&gt; &#xA;&lt;h3&gt;Probability of Direction (&lt;em&gt;pd&lt;/em&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/p_direction.html&#34;&gt;&lt;code&gt;p_direction()&lt;/code&gt;&lt;/a&gt; computes the &lt;em&gt;Probability of Direction&lt;/em&gt; (&lt;em&gt;p&lt;/em&gt;d, also known as the Maximum Probability of Effect - &lt;em&gt;MPE&lt;/em&gt;). It varies between 50% and 100% (&lt;em&gt;i.e.&lt;/em&gt;, &lt;code&gt;0.5&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;) and can be interpreted as the probability (expressed in percentage) that a parameter (described by its posterior distribution) is strictly positive or negative (whichever is the most probable). It is mathematically defined as the proportion of the posterior distribution that is of the median‚Äôs sign. Although differently expressed, this index is fairly similar (&lt;em&gt;i.e.&lt;/em&gt;, is strongly correlated) to the frequentist &lt;em&gt;p&lt;/em&gt;-value.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Relationship with the p-value&lt;/strong&gt;: In most cases, it seems that the &lt;em&gt;pd&lt;/em&gt; corresponds to the frequentist one-sided &lt;em&gt;p&lt;/em&gt;-value through the formula &lt;code&gt;p-value = (1-pd/100)&lt;/code&gt; and to the two-sided &lt;em&gt;p&lt;/em&gt;-value (the most commonly reported) through the formula &lt;code&gt;p-value = 2*(1-pd/100)&lt;/code&gt;. Thus, a &lt;code&gt;pd&lt;/code&gt; of &lt;code&gt;95%&lt;/code&gt;, &lt;code&gt;97.5%&lt;/code&gt; &lt;code&gt;99.5%&lt;/code&gt; and &lt;code&gt;99.95%&lt;/code&gt; corresponds approximately to a two-sided &lt;em&gt;p&lt;/em&gt;-value of respectively &lt;code&gt;.1&lt;/code&gt;, &lt;code&gt;.05&lt;/code&gt;, &lt;code&gt;.01&lt;/code&gt; and &lt;code&gt;.001&lt;/code&gt;. See the &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/guidelines.html&#34;&gt;&lt;em&gt;reporting guidelines&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;posterior &amp;lt;- distribution_normal(10000, 0.4, 0.2)&#xA;p_direction(posterior)&#xA;## Probability of Direction&#xA;## &#xA;## Parameter |     pd&#xA;## ------------------&#xA;## Posterior | 97.72%&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easystats/bayestestR/main/man/figures/unnamed-chunk-12-1.png&#34; alt=&#34;&#34;&gt;&#xA; &lt;!-- --&gt;&lt;/p&gt; &#xA;&lt;h3&gt;ROPE&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/rope.html&#34;&gt;&lt;code&gt;rope()&lt;/code&gt;&lt;/a&gt; computes the proportion (in percentage) of the HDI (default to the 89% HDI) of a posterior distribution that lies within a region of practical equivalence.&lt;/p&gt; &#xA;&lt;p&gt;Statistically, the probability of a posterior distribution of being different from 0 does not make much sense (the probability of it being different from a single point being infinite). Therefore, the idea underlining ROPE is to let the user define an area around the null value enclosing values that are &lt;em&gt;equivalent to the null&lt;/em&gt; value for practical purposes Kruschke (2018).&lt;/p&gt; &#xA;&lt;p&gt;Kruschke suggests that such null value could be set, by default, to the -0.1 to 0.1 range of a standardized parameter (negligible effect size according to Cohen, 1988). This could be generalized: For instance, for linear models, the ROPE could be set as &lt;code&gt;0 +/- .1 * sd(y)&lt;/code&gt;. This ROPE range can be automatically computed for models using the &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/rope_range.html&#34;&gt;rope_range&lt;/a&gt; function.&lt;/p&gt; &#xA;&lt;p&gt;Kruschke suggests using the proportion of the 95% (or 90%, considered more stable) HDI that falls within the ROPE as an index for ‚Äúnull-hypothesis‚Äù testing (as understood under the Bayesian framework, see &lt;a href=&#34;https://easystats.github.io/bayestestR/reference/equivalence_test.html&#34;&gt;equivalence_test&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;posterior &amp;lt;- distribution_normal(10000, 0.4, 0.2)&#xA;rope(posterior, range = c(-0.1, 0.1))&#xA;## # Proportion of samples inside the ROPE [-0.10, 0.10]:&#xA;## &#xA;## inside ROPE&#xA;## -----------&#xA;## 4.40 %&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easystats/bayestestR/main/man/figures/unnamed-chunk-14-1.png&#34; alt=&#34;&#34;&gt;&#xA; &lt;!-- --&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Bayes Factor&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/bayesfactor_parameters.html&#34;&gt;&lt;code&gt;bayesfactor_parameters()&lt;/code&gt;&lt;/a&gt; computes Bayes factors against the null (either a point or an interval), bases on prior and posterior samples of a single parameter. This Bayes factor indicates the degree by which the mass of the posterior distribution has shifted further away from or closer to the null value(s) (relative to the prior distribution), thus indicating if the null value has become less or more likely given the observed data.&lt;/p&gt; &#xA;&lt;p&gt;When the null is an interval, the Bayes factor is computed by comparing the prior and posterior odds of the parameter falling within or outside the null; When the null is a point, a Savage-Dickey density ratio is computed, which is also an approximation of a Bayes factor comparing the marginal likelihoods of the model against a model in which the tested parameter has been restricted to the point null (Wagenmakers, Lodewyckx, Kuriyal, &amp;amp; Grasman, 2010).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;prior &amp;lt;- distribution_normal(10000, mean = 0, sd = 1)&#xA;posterior &amp;lt;- distribution_normal(10000, mean = 1, sd = 0.7)&#xA;&#xA;bayesfactor_parameters(posterior, prior, direction = &#34;two-sided&#34;, null = 0, verbose = FALSE)&#xA;## Bayes Factor (Savage-Dickey density ratio)&#xA;## &#xA;## BF  &#xA;## ----&#xA;## 1.94&#xA;## &#xA;## * Evidence Against The Null: 0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easystats/bayestestR/main/man/figures/unnamed-chunk-16-1.png&#34; alt=&#34;&#34;&gt;&#xA; &lt;!-- --&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;sup&gt;&lt;em&gt;The lollipops represent the density of a point-null on the prior distribution (the blue lollipop on the dotted distribution) and on the posterior distribution (the red lollipop on the yellow distribution). The ratio between the two - the Savage-Dickey ratio - indicates the degree by which the mass of the parameter distribution has shifted away from or closer to the null.&lt;/em&gt;&lt;/sup&gt;&lt;/p&gt; &#xA;&lt;p&gt;For more info, see &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayes_factors.html&#34;&gt;the Bayes factors vignette&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Utilities&lt;/h2&gt; &#xA;&lt;h3&gt;Find ROPE‚Äôs appropriate range&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/rope_range.html&#34;&gt;&lt;code&gt;rope_range()&lt;/code&gt;&lt;/a&gt;: This function attempts at automatically finding suitable ‚Äúdefault‚Äù values for the Region Of Practical Equivalence (ROPE). Kruschke (2018) suggests that such null value could be set, by default, to a range from &lt;code&gt;-0.1&lt;/code&gt; to &lt;code&gt;0.1&lt;/code&gt; of a standardized parameter (negligible effect size according to Cohen, 1988), which can be generalised for linear models to &lt;code&gt;-0.1 * sd(y), 0.1 * sd(y)&lt;/code&gt;. For logistic models, the parameters expressed in log odds ratio can be converted to standardized difference through the formula &lt;code&gt;sqrt(3)/pi&lt;/code&gt;, resulting in a range of &lt;code&gt;-0.05&lt;/code&gt; to &lt;code&gt;0.05&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rope_range(model)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Density Estimation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/estimate_density.html&#34;&gt;&lt;code&gt;estimate_density()&lt;/code&gt;&lt;/a&gt;: This function is a wrapper over different methods of density estimation. By default, it uses the base R &lt;code&gt;density&lt;/code&gt; with by default uses a different smoothing bandwidth (&lt;code&gt;&#34;SJ&#34;&lt;/code&gt;) from the legacy default implemented the base R &lt;code&gt;density&lt;/code&gt; function (&lt;code&gt;&#34;nrd0&#34;&lt;/code&gt;). However, Deng &amp;amp; Wickham suggest that &lt;code&gt;method = &#34;KernSmooth&#34;&lt;/code&gt; is the fastest and the most accurate.&lt;/p&gt; &#xA;&lt;h3&gt;Perfect Distributions&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/distribution.html&#34;&gt;&lt;code&gt;distribution()&lt;/code&gt;&lt;/a&gt;: Generate a sample of size n with near-perfect distributions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;distribution(n = 10)&#xA;##  [1] -1.55 -1.00 -0.66 -0.38 -0.12  0.12  0.38  0.66  1.00  1.55&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Probability of a Value&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://easystats.github.io/bayestestR/reference/density_at.html&#34;&gt;&lt;code&gt;density_at()&lt;/code&gt;&lt;/a&gt;: Compute the density of a given point of a distribution.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;density_at(rnorm(1000, 1, 1), 1)&#xA;## [1] 0.41&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;Please note that the bayestestR project is released with a &lt;a href=&#34;https://contributor-covenant.org/version/2/1/CODE_OF_CONDUCT.html&#34;&gt;Contributor Code of Conduct&lt;/a&gt;. By contributing to this project, you agree to abide by its terms.&lt;/p&gt; &#xA;&lt;h1&gt;References&lt;/h1&gt; &#xA;&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt; &#xA; &lt;div id=&#34;ref-kruschke2018rejecting&#34; class=&#34;csl-entry&#34;&gt; &#xA;  &lt;p&gt;Kruschke, J. K. (2018). Rejecting or accepting parameter values in Bayesian estimation. &lt;em&gt;Advances in Methods and Practices in Psychological Science&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(2), 270‚Äì280.&lt;/p&gt; &#xA; &lt;/div&gt; &#xA; &lt;div id=&#34;ref-kruschke2018bayesian&#34; class=&#34;csl-entry&#34;&gt; &#xA;  &lt;p&gt;Kruschke, J. K., &amp;amp; Liddell, T. M. (2018). The bayesian new statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a bayesian perspective. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;25&lt;/em&gt;(1), 178‚Äì206.&lt;/p&gt; &#xA; &lt;/div&gt; &#xA; &lt;div id=&#34;ref-wagenmakers2010bayesian&#34; class=&#34;csl-entry&#34;&gt; &#xA;  &lt;p&gt;Wagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., &amp;amp; Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the savage‚Äìdickey method. &lt;em&gt;Cognitive Psychology&lt;/em&gt;, &lt;em&gt;60&lt;/em&gt;(3), 158‚Äì189.&lt;/p&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
</feed>