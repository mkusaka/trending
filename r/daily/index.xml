<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub R Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-10T01:51:53Z</updated>
  <subtitle>Daily Trending of R in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Mixtape-Sessions/Causal-Inference-2</title>
    <updated>2022-07-10T01:51:53Z</updated>
    <id>tag:github.com,2022-07-10:/Mixtape-Sessions/Causal-Inference-2</id>
    <link href="https://github.com/Mixtape-Sessions/Causal-Inference-2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Causal Inference II Mixtape Session&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>adriancorrendo/metrica</title>
    <updated>2022-07-10T01:51:53Z</updated>
    <id>tag:github.com,2022-07-10:/adriancorrendo/metrica</id>
    <link href="https://github.com/adriancorrendo/metrica" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Prediction Performance Metrics&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;metrica: Prediction performance metrics.&lt;/h1&gt; &#xA;&lt;!-- badges: start --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=metrica&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/metrica&#34; alt=&#34;CRAN status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://r-pkg.org/pkg/metrica&#34;&gt;&lt;img src=&#34;https://cranlogs.r-pkg.org/badges/grand-total/metrica?color=blue&#34; alt=&#34;CRAN RStudio mirror downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://r-pkg.org/pkg/metrica&#34;&gt;&lt;img src=&#34;https://cranlogs.r-pkg.org/badges/last-month/metrica?color=blue&#34; alt=&#34;CRAN RStudio mirror downloads&#34;&gt;&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ci.appveyor.com/project/adriancorrendo/metrica&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/github/adriancorrendo/metrica?branch=master&amp;amp;svg=true&#34; alt=&#34;AppVeyor build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/adriancorrendo/metrica/actions&#34;&gt;&lt;img src=&#34;https://github.com/adriancorrendo/metrica/workflows/R-CMD-check/badge.svg?sanitize=true&#34; alt=&#34;R-CMD-check&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/adriancorrendo/metrica&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/adriancorrendo/metrica/branch/master/graph/badge.svg?token=CfK5NhXzYn&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.5281/zenodo.6474101&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.6474101.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- badges: end --&gt; &#xA;&lt;h2&gt;Introduction &lt;br&gt;&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/metrica_logo.png&#34; align=&#34;right&#34; height=&#34;150&#34; style=&#34;float:right; height:150px;&#34;&gt; &#xA;&lt;br&gt; `metrica` is a compilation of more than 80 functions designed to quantitatively and visually evaluate the prediction performance of regression (continuous variables) and classification (categorical variables) point-forecast models (e.g.&amp;nbsp;APSIM, DSSAT, DNDC, Supervised Machine Learning). `metrica` offers a toolbox with a wide spectrum of goodness of fit, error metrics, indices, and coefficients accounting for different aspects of the agreement between predicted and observed values, plus some basic visualization functions to assess models performance (e.g.&amp;nbsp;confusion matrix, scatter with regression line; Bland-Altman plot) provided in customizable format (ggplot). &#xA;&lt;p&gt;For supervised models, always keep in mind the concept of “cross-validation” since predicted values should ideally come from out-of-bag samples (unseen by training sets) to avoid overestimation of the prediction performance. &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;Check the Documentation at &lt;a href=&#34;https://adriancorrendo.github.io/metrica/&#34;&gt;https://adriancorrendo.github.io/metrica/&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Vignettes&lt;/strong&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html&#34;&gt;1. List of metrics for Regression&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html&#34;&gt;2. List of metrics for Classification&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/regression_case.html&#34;&gt;3. A regression case (numerical variables)&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/classification_case.html&#34;&gt;4. A classification case (categorical variables)&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/apsim_open.html&#34;&gt;5. Import files from APSIM&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Functions &lt;br&gt;&lt;/h2&gt; &#xA;&lt;p&gt;For regression models, it includes 4 plotting functions (scatter, tiles, density, &amp;amp; Bland-Altman plots), and 48 prediction performance scores including error metrics (MBE, MAE, RAE, RMAE, MAPE, SMAPE, MSE, RMSE, RRMSE, RSR, PBE, iqRMSE), error decomposition (MLA, MLP, PLA, PLP, PAB, PPB, SB, SDSD, LCS, Ub, Uc, Ue), model efficiency (NSE, E1, Erel, KGE), indices of agreement (d, d1, d1r, RAC, AC, lambda), goodness of fit (r, R2, RSS, TSS, RSE), adjusted correlation coefficients (CCC, Xa, distance correlation-dcorr-, maximal information coefficient -MIC-), variability (uSD, var_u), and symmetric regression coefficients (B0_sma, B1_sma). Specifically for time-series predictions, &lt;code&gt;metrica&lt;/code&gt; also includes the Mean Absolute Scaled Error (MASE). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For classification (binomial and multinomial) tasks, it includes a function to visualize the confusion matrix using ggplot2, and 27 functions of prediction scores including: accuracy, error rate, precision, recall, specificity, balanced accuracy (balacc), F-score (fscore), adjusted F-score (agf), G-mean (gmean), Bookmaker Informedness (bmi, a.k.a. Youden’s J-index), Markedness (deltaP), Matthews Correlation Coefficient (mcc), Cohen’s Kappa (khat), negative predictive value (npv), positive and negative likelihood ratios (posLr, negLr), diagnostic odds ratio (dor), prevalence (preval), prevalence threshold (preval_t), critical success index (csi, a.k.a. threat score), false positive rate (FPR), false negative rate (FNR), false detection rate (FDR), false omission rate (FOR), and area under the ROC curve (AUC_roc). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;metrica&lt;/code&gt; also offers a function that allows users to run all prediction performance scores at once. The user just needs to specify the type of model (“regression” or “classification”). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For more details visit the vignettes &lt;a href=&#34;https://adriancorrendo.github.io/metrica/&#34;&gt;https://adriancorrendo.github.io/metrica/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Using the functions &lt;br&gt;&lt;/h2&gt; &#xA;&lt;p&gt;There are two basic arguments common to all &lt;code&gt;metrica&lt;/code&gt; functions: (i) &lt;code&gt;obs&lt;/code&gt;(Oi; observed, a.k.a. actual, measured, truth, target, label), and (ii) &lt;code&gt;pred&lt;/code&gt; (Pi; predicted, a.k.a. simulated, fitted, modeled, estimate) values. &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;Optional arguments include &lt;code&gt;data&lt;/code&gt; that allows to call an existing data frame containing both observed and predicted vectors, and &lt;code&gt;tidy&lt;/code&gt;, which controls the type of output as a list (tidy = FALSE) or as a data.frame (tidy = TRUE). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For regression, some specific functions for regression also require to define the axis &lt;code&gt;orientation&lt;/code&gt;. For example, the slope of the symmetric linear regression describing the bivariate scatter (SMA). &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For binary classification (two classes), functions also require to check the &lt;code&gt;pos_level&lt;/code&gt; arg., which indicates the alphanumeric order of the “positive level”. Normally, the most common binary denominations are c(0,1), c(“Negative”, “Positive”), c(“FALSE”, “TRUE”), so the default pos_level = 2 (1, “Positive”, “TRUE”). However, other cases are also possible, such as c(“Crop”, “NoCrop”) for which the user needs to specify pos_level = 1. &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;For multiclass classification tasks, some functions present the &lt;code&gt;atom&lt;/code&gt; arg. (logical TRUE / FALSE), which controls the output to be an overall average estimate across all classes, or a class-wise estimate. For example, user might be interested in obtaining estimates of precision and recall for each possible class of the prediction. &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;1. Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install the CRAN version of &lt;code&gt;metrica&lt;/code&gt; with: &lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#34;metrica&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can install the development version from &lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt; with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# install.packages(&#34;devtools&#34;)&#xA;devtools::install_github(&#34;adriancorrendo/metrica&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;2. Native datasets&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;em&gt;metrica&lt;/em&gt; package comes with four example datasets of continuous variables (regression) from the APSIM software: &lt;br&gt; 1. &lt;code&gt;wheat&lt;/code&gt;. 137 data-points of wheat grain N (grams per squared meter) &lt;br&gt; 2. &lt;code&gt;barley&lt;/code&gt;. 69 data-points of barley grain number (x1000 grains per squared meter) &lt;br&gt; 3. &lt;code&gt;sorghum&lt;/code&gt;. 36 data-points of sorghum grain number (x1000 grains per squared meter) &lt;br&gt; 4. &lt;code&gt;chickpea&lt;/code&gt;. 39 data-points of chickpea aboveground dry mass (kg per hectare) &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;These data correspond to the latest, up-to-date, documentation and validation of version number 2020.03.27.4956. Data available at: &lt;a href=&#34;https://doi.org/10.7910/DVN/EJS4M0&#34;&gt;https://doi.org/10.7910/DVN/EJS4M0&lt;/a&gt;. Further details can be found at the official APSIM Next Generation website: &lt;a href=&#34;https://APSIMnextgeneration.netlify.app/modeldocumentation&#34;&gt;https://APSIMnextgeneration.netlify.app/modeldocumentation&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;3. Example Code&lt;/h2&gt; &#xA;&lt;h3&gt;Libraries&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(metrica)&#xA;library(dplyr)&#xA;library(purrr)&#xA;library(ggplot2)&#xA;library(tidyr)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is a basic example which shows you the core regression and classification functions of &lt;em&gt;metrica&lt;/em&gt;: &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;3.1. REGRESSION&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# 1. A. Create a random dataset&#xA;# Set seed for reproducibility&#xA;set.seed(1)&#xA;# Create a random vector (X) with 100 values&#xA;X &amp;lt;- rnorm(n = 100, mean = 0, sd = 10)&#xA;# Create a second vector (Y) with 100 values by adding error with respect&#xA;# to the first vector (X).&#xA;Y &amp;lt;- X + rnorm(n=100, mean = 0, sd = 3)&#xA;# Merge vectors in a data frame, rename them as synonyms of observed (measured) and predicted (simulated)&#xA;example.data &amp;lt;- data.frame(measured = X, simulated = Y)&#xA;&#xA;# 1. B. Or call native example datasets&#xA;&#xA;example.data &amp;lt;- barley %&amp;gt;%  # or &#39;wheat&#39;, &#39;sorghum&#39;, or &#39;chickpea&#39;&#xA;# 1.b. create columns as synonyms of observed (measured) and predicted (simulated)&#xA;                mutate(measured = obs, simulated = pred)  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.1. Plot functions&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.1.1. Create a customizable scatter plot with PO orientation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barley.scat.plot &amp;lt;- &#xA;  metrica::scatter_plot(data = example.data, &#xA;                        obs = measured, &#xA;                        pred = simulated,&#xA;                        orientation = &#34;PO&#34;, &#xA;                        print_eq = TRUE,&#xA;                        position_eq = c(x=24, y =8), &#xA;                        # Optional arguments to customize the plot&#xA;                        shape_type = 21,&#xA;                        shape_color = &#34;steelblue&#34;,&#xA;                        shape_size = 3,&#xA;                        regline_type = &#34;F1&#34;,&#xA;                        regline_color = &#34;#9e0059&#34;,&#xA;                        regline_size = 2)+&#xA;  # Customize axis breaks&#xA;  scale_y_continuous(breaks = seq(0,30, by = 5))+&#xA;  scale_x_continuous(breaks = seq(0,30, by = 5))&#xA;&#xA;barley.scat.plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-4-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Alternative using vectors instead of dataframe&#xA;#metrica::scatter_plot(obs = example.data$obs, pred = example.data$pred)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.1.2. Create tiles plot with OP orientation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barley.tiles.plot &amp;lt;- &#xA;  tiles_plot(data = example.data, &#xA;                      obs = measured, &#xA;                      pred = simulated,&#xA;                      bins = 10, &#xA;                      orientation = &#34;PO&#34;,&#xA;                      colors = c(low = &#34;pink&#34;, high = &#34;steelblue&#34;))&#xA;&#xA;barley.tiles.plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-5-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.1.3. Create a density plot with OP orientation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barley.density.plot &amp;lt;-&#xA;metrica::density_plot(data = example.data, &#xA;                      obs = measured, pred = simulated,&#xA;                      n = 5, &#xA;                      orientation = &#34;PO&#34;, &#xA;           colors = c(low = &#34;white&#34;, high = &#34;steelblue&#34;) )+&#xA;  theme(legend.position = &#34;none&#34;)&#xA;&#xA;barley.density.plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-6-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.1.4. Create a Bland-Altman plot&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barley.ba.plot &amp;lt;- metrica::bland_altman_plot(data = example.data,&#xA;                                             obs = measured, pred = simulated)&#xA;&#xA;barley.ba.plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-7-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.2. Metrics functions&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.2.2. Single estimates&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# a. Estimate coefficient of determination (R2)&#xA;&#xA;metrica::R2(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $R2&#xA;#&amp;gt; [1] 0.4512998&#xA;&#xA;# b. Estimate root mean squared error (RMSE)&#xA;metrica::RMSE(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $RMSE&#xA;#&amp;gt; [1] 3.986028&#xA;&#xA;# c. Estimate mean bias error (MBE)&#xA;metrica::MBE(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $MBE&#xA;#&amp;gt; [1] 0.207378&#xA;&#xA;# c. Estimate index of agreement (d)&#xA;metrica::d(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $d&#xA;#&amp;gt; [1] 0.8191397&#xA;&#xA;# e. Estimate SMA regression intercept (B0)&#xA;metrica::B0_sma(data = example.data, obs = measured, pred = simulated, tidy = TRUE)&#xA;#&amp;gt;         B0&#xA;#&amp;gt; 1 1.128274&#xA;&#xA;# f. Estimate SMA regression slope (B1)&#xA;metrica::B1_sma(data = example.data, obs = measured, pred = simulated)&#xA;#&amp;gt; $B1&#xA;#&amp;gt; [1] 0.9288715&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.2.2. Metrics Summary&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;metrics.sum &amp;lt;- metrics_summary(data = example.data, &#xA;                               obs = measured, pred = simulated,&#xA;                               type = &#34;regression&#34;)  &#xA;# Print first 15&#xA;head(metrics.sum, n = 15)&#xA;#&amp;gt;    Metric      Score&#xA;#&amp;gt; 1      B0  1.1282743&#xA;#&amp;gt; 2      B1  0.9288715&#xA;#&amp;gt; 3       r  0.6717885&#xA;#&amp;gt; 4      R2  0.4512998&#xA;#&amp;gt; 5      Xa  0.9963915&#xA;#&amp;gt; 6     CCC  0.6693644&#xA;#&amp;gt; 7     MAE  3.0595501&#xA;#&amp;gt; 8    RMAE  0.1629325&#xA;#&amp;gt; 9    MAPE 16.8112673&#xA;#&amp;gt; 10  SMAPE 16.7848032&#xA;#&amp;gt; 11    RAE  0.7639151&#xA;#&amp;gt; 12    RSE  0.6164605&#xA;#&amp;gt; 13    MBE  0.2073780&#xA;#&amp;gt; 14    PBE  1.1043657&#xA;#&amp;gt; 15    PAB  0.2706729&#xA;&#xA;# Optional wrangling (WIDE)&#xA;metrics.sum.wide &amp;lt;- metrics.sum %&amp;gt;%&#xA;  tidyr::pivot_wider(tidyr::everything(),&#xA;                      names_from = &#34;Metric&#34;,&#xA;                      values_from = &#34;Score&#34;)&#xA;&#xA;metrics.sum.wide&#xA;#&amp;gt; # A tibble: 1 × 45&#xA;#&amp;gt;      B0    B1     r    R2    Xa   CCC   MAE  RMAE  MAPE SMAPE   RAE   RSE   MBE&#xA;#&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;&#xA;#&amp;gt; 1  1.13 0.929 0.672 0.451 0.996 0.669  3.06 0.163  16.8  16.8 0.764 0.616 0.207&#xA;#&amp;gt; # … with 32 more variables: PBE &amp;lt;dbl&amp;gt;, PAB &amp;lt;dbl&amp;gt;, PPB &amp;lt;dbl&amp;gt;, MSE &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   RMSE &amp;lt;dbl&amp;gt;, RRMSE &amp;lt;dbl&amp;gt;, RSR &amp;lt;dbl&amp;gt;, iqRMSE &amp;lt;dbl&amp;gt;, MLA &amp;lt;dbl&amp;gt;, MLP &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   RMLA &amp;lt;dbl&amp;gt;, RMLP &amp;lt;dbl&amp;gt;, SB &amp;lt;dbl&amp;gt;, SDSD &amp;lt;dbl&amp;gt;, LCS &amp;lt;dbl&amp;gt;, PLA &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   PLP &amp;lt;dbl&amp;gt;, Ue &amp;lt;dbl&amp;gt;, Uc &amp;lt;dbl&amp;gt;, Ub &amp;lt;dbl&amp;gt;, NSE &amp;lt;dbl&amp;gt;, E1 &amp;lt;dbl&amp;gt;, Erel &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   KGE &amp;lt;dbl&amp;gt;, d &amp;lt;dbl&amp;gt;, d1 &amp;lt;dbl&amp;gt;, d1r &amp;lt;dbl&amp;gt;, RAC &amp;lt;dbl&amp;gt;, AC &amp;lt;dbl&amp;gt;, lambda &amp;lt;dbl&amp;gt;,&#xA;#&amp;gt; #   dcorr &amp;lt;dbl&amp;gt;, MIC &amp;lt;dbl&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.3. Run multiple datasets at once&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.3.1. Nested data&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# a. Create nested df with the native examples&#xA;nested.examples &amp;lt;- bind_rows(list(wheat = metrica::wheat, &#xA;                                  barley = metrica::barley,&#xA;                                  sorghum = metrica::sorghum, &#xA;                                  chickpea = metrica::chickpea), &#xA;                             .id = &#34;id&#34;) %&amp;gt;%&#xA;  dplyr::group_by(id) %&amp;gt;% tidyr::nest() %&amp;gt;% dplyr::ungroup()&#xA;&#xA;head(nested.examples %&amp;gt;% group_by(id) %&amp;gt;% dplyr::slice_head(n=2))&#xA;#&amp;gt; # A tibble: 4 × 2&#xA;#&amp;gt; # Groups:   id [4]&#xA;#&amp;gt;   id       data              &#xA;#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;list&amp;gt;            &#xA;#&amp;gt; 1 barley   &amp;lt;tibble [69 × 2]&amp;gt; &#xA;#&amp;gt; 2 chickpea &amp;lt;tibble [39 × 2]&amp;gt; &#xA;#&amp;gt; 3 sorghum  &amp;lt;tibble [36 × 2]&amp;gt; &#xA;#&amp;gt; 4 wheat    &amp;lt;tibble [137 × 2]&amp;gt;&#xA;&#xA;# b. Run &#xA;multiple.sum &amp;lt;- nested.examples %&amp;gt;% &#xA;  # Store metrics in new.column &#34;performance&#34;&#xA;  mutate(performance = map(data, ~metrica::metrics_summary(data=., obs = obs, pred = pred, &#xA;                                                           type = &#34;regression&#34;)))&#xA;&#xA;head(multiple.sum)&#xA;#&amp;gt; # A tibble: 4 × 3&#xA;#&amp;gt;   id       data               performance  &#xA;#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;       &#xA;#&amp;gt; 1 wheat    &amp;lt;tibble [137 × 2]&amp;gt; &amp;lt;df [45 × 2]&amp;gt;&#xA;#&amp;gt; 2 barley   &amp;lt;tibble [69 × 2]&amp;gt;  &amp;lt;df [45 × 2]&amp;gt;&#xA;#&amp;gt; 3 sorghum  &amp;lt;tibble [36 × 2]&amp;gt;  &amp;lt;df [45 × 2]&amp;gt;&#xA;#&amp;gt; 4 chickpea &amp;lt;tibble [39 × 2]&amp;gt;  &amp;lt;df [45 × 2]&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.3.2. Non-nested data &lt;br&gt;&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;non_nested_summary &amp;lt;- nested.examples %&amp;gt;% unnest(cols = &#34;data&#34;) %&amp;gt;% &#xA;  group_by(id) %&amp;gt;% &#xA;  summarise(metrics_summary(obs = obs, pred = pred, type = &#34;regression&#34;)) %&amp;gt;% &#xA;  dplyr::arrange(Metric)&#xA;&#xA;head(non_nested_summary)&#xA;#&amp;gt; # A tibble: 6 × 3&#xA;#&amp;gt; # Groups:   id [4]&#xA;#&amp;gt;   id       Metric    Score&#xA;#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;&#xA;#&amp;gt; 1 barley   AC       0.253 &#xA;#&amp;gt; 2 chickpea AC       0.434 &#xA;#&amp;gt; 3 sorghum  AC       0.0889&#xA;#&amp;gt; 4 wheat    AC       0.842 &#xA;#&amp;gt; 5 barley   B0       1.13  &#xA;#&amp;gt; 6 chickpea B0     -99.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.4. Print metrics in a plot&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df &amp;lt;- metrica::wheat&#xA;&#xA;# Create list of selected metrics&#xA;selected.metrics &amp;lt;- c(&#34;MAE&#34;,&#34;RMSE&#34;, &#34;RRMSE&#34;, &#34;R2&#34;, &#34;NSE&#34;, &#34;KGE&#34;, &#34;PLA&#34;, &#34;PLP&#34;)&#xA;&#xA;&#xA;df &amp;lt;- metrica::wheat&#xA;# Create the plot&#xA;plot &amp;lt;- metrica::scatter_plot(data = df, &#xA;                              obs = obs, pred = pred,&#xA;                              # Activate print_metrics arg.&#xA;                              print_metrics = TRUE, &#xA;                              # Indicate metrics list&#xA;                              metrics_list = selected.metrics,&#xA;                              # Customize metrics position&#xA;                              position_metrics = c(x = 16 , y = 9),&#xA;                              # Customize equation position&#xA;                              position_eq = c(x = 16.2, y = 9.5))&#xA;&#xA;plot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-12-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h2&gt;3.1. CLASSIFICATION &lt;br&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Example datasets&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binomial_case &amp;lt;- data.frame(labels = sample(c(&#34;Pos&#34;,&#34;Neg&#34;), 100, replace = TRUE),&#xA;                            predictions = sample(c(&#34;Pos&#34;,&#34;Neg&#34;), 100, replace = TRUE)) %&amp;gt;% &#xA;  mutate(predictions = as.factor(predictions), labels = as.factor(labels))&#xA;&#xA;multinomial_case &amp;lt;- data.frame(labels = sample(c(&#34;Red&#34;,&#34;Green&#34;, &#34;Blue&#34;), 100, replace = TRUE),&#xA;                               predictions = sample(c(&#34;Red&#34;,&#34;Green&#34;, &#34;Blue&#34;), 100, replace = TRUE) ) %&amp;gt;% &#xA;  mutate(predictions = as.factor(predictions), labels = as.factor(labels))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.1.1. Confusion Matrix &lt;br&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.1.1. Binary&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# a. Print&#xA;binomial_case %&amp;gt;% confusion_matrix(obs = labels, pred = predictions, &#xA;                                            plot = FALSE, colors = c(low=&#34;#f9dbbd&#34; , high=&#34;#735d78&#34;), &#xA;                                            unit = &#34;count&#34;)&#xA;#&amp;gt;          OBSERVED&#xA;#&amp;gt; PREDICTED Neg Pos&#xA;#&amp;gt;       Neg  24  24&#xA;#&amp;gt;       Pos  21  31&#xA;&#xA;# b. Plot&#xA;binomial_case %&amp;gt;% confusion_matrix(obs = labels, pred = predictions, &#xA;                                            plot = TRUE, colors = c(low=&#34;#f9dbbd&#34; , high=&#34;#735d78&#34;), &#xA;                                            unit = &#34;count&#34;, print_metrics = TRUE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-14-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.1.2. Multiclass&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# a. Print&#xA;multinomial_case %&amp;gt;% confusion_matrix(obs = labels, &#xA;                                      pred = predictions, &#xA;                                      plot = FALSE, colors = c(low=&#34;#f9dbbd&#34; , high=&#34;#735d78&#34;),&#xA;                                      unit = &#34;count&#34;)&#xA;#&amp;gt;          OBSERVED&#xA;#&amp;gt; PREDICTED Blue Green Red&#xA;#&amp;gt;     Blue     9    11   9&#xA;#&amp;gt;     Green   11    12  11&#xA;#&amp;gt;     Red     13    13  11&#xA;&#xA;# b. Plot&#xA;multinomial_case %&amp;gt;% confusion_matrix(obs = labels, &#xA;                                      pred = predictions, &#xA;                                      plot = TRUE, colors = c(low=&#34;#d3dbbd&#34; , high=&#34;#885f78&#34;), &#xA;                                      unit = &#34;count&#34;, print_metrics = TRUE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/adriancorrendo/metrica/master/man/figures/README-unnamed-chunk-15-1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h3&gt;3.1.1. Classification Metrics &lt;br&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;3.1.1.1. Single dataset &lt;br&gt;&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Get classification metrics one by one&#xA;binomial_case %&amp;gt;% accuracy(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   accuracy&#xA;#&amp;gt; 1     0.55&#xA;binomial_case %&amp;gt;% error_rate(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   error_rate&#xA;#&amp;gt; 1       0.45&#xA;binomial_case %&amp;gt;% precision(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   precision&#xA;#&amp;gt; 1 0.5961538&#xA;binomial_case %&amp;gt;% recall(data = ., obs = labels, pred = predictions, atom = F, tidy=TRUE)&#xA;#&amp;gt;      recall&#xA;#&amp;gt; 1 0.5636364&#xA;binomial_case %&amp;gt;% specificity(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;        spec&#xA;#&amp;gt; 1 0.5333333&#xA;binomial_case %&amp;gt;% balacc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;      balacc&#xA;#&amp;gt; 1 0.5484848&#xA;binomial_case %&amp;gt;% fscore(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;      fscore&#xA;#&amp;gt; 1 0.5794393&#xA;binomial_case %&amp;gt;% agf(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         agf&#xA;#&amp;gt; 1 0.5795213&#xA;binomial_case %&amp;gt;% gmean(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       gmean&#xA;#&amp;gt; 1 0.5482755&#xA;binomial_case %&amp;gt;% khat(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         khat&#xA;#&amp;gt; 1 0.09638554&#xA;binomial_case %&amp;gt;% mcc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;          mcc&#xA;#&amp;gt; 1 0.09656091&#xA;binomial_case %&amp;gt;% fmi(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         fmi&#xA;#&amp;gt; 1 0.5796671&#xA;binomial_case %&amp;gt;% posLr(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;      posLr&#xA;#&amp;gt; 1 1.207792&#xA;binomial_case %&amp;gt;% negLr(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       negLr&#xA;#&amp;gt; 1 0.8181818&#xA;binomial_case %&amp;gt;% dor(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       dor&#xA;#&amp;gt; 1 1.47619&#xA;&#xA;# Get all at once with metrics_summary()&#xA;binomial_case %&amp;gt;% metrics_summary(data = ., obs = labels, pred = predictions, type = &#34;classification&#34;)&#xA;#&amp;gt;         Metric      Score&#xA;#&amp;gt; 1     accuracy 0.55000000&#xA;#&amp;gt; 2   error_rate 0.45000000&#xA;#&amp;gt; 3    precision 0.59615385&#xA;#&amp;gt; 4       recall 0.56363636&#xA;#&amp;gt; 5  specificity 0.53333333&#xA;#&amp;gt; 6       balacc 0.54848485&#xA;#&amp;gt; 7       fscore 0.57943925&#xA;#&amp;gt; 8          agf 0.57952126&#xA;#&amp;gt; 9        gmean 0.54827553&#xA;#&amp;gt; 10        khat 0.09638554&#xA;#&amp;gt; 11         mcc 0.09656091&#xA;#&amp;gt; 12         fmi 0.57966713&#xA;#&amp;gt; 13         bmi 0.09696970&#xA;#&amp;gt; 14         csi 0.40789474&#xA;#&amp;gt; 15      deltap 0.09615385&#xA;#&amp;gt; 16       posLr 1.20779221&#xA;#&amp;gt; 17       negLr 0.81818182&#xA;#&amp;gt; 18         dor 1.47619048&#xA;#&amp;gt; 19         npv 0.50000000&#xA;#&amp;gt; 20         FPR 0.46666667&#xA;#&amp;gt; 21         FNR 0.43636364&#xA;#&amp;gt; 22         FDR 0.40384615&#xA;#&amp;gt; 23         FOR 0.50000000&#xA;#&amp;gt; 24      preval 0.55000000&#xA;#&amp;gt; 25    preval_t 0.49309260&#xA;#&amp;gt; 26     AUC_roc 0.54848485&#xA;&#xA;# Multinomial&#xA;multinomial_case %&amp;gt;% metrics_summary(data = ., obs = labels, pred = predictions, type = &#34;classification&#34;)&#xA;#&amp;gt; Warning in metrica::fscore(data = ~., obs = ~labels, pred = ~predictions, :&#xA;#&amp;gt; For multiclass cases, the fscore should be estimated at a class level. Please,&#xA;#&amp;gt; consider using `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::agf(data = ~., obs = ~labels, pred = ~predictions, pos_level&#xA;#&amp;gt; = pos_level): For multiclass cases, the agf should be estimated at a class&#xA;#&amp;gt; level. Please, consider using `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::fmi(data = ~., obs = ~labels, pred = ~predictions, pos_level&#xA;#&amp;gt; = pos_level): The Fowlkes-Mallows Index is not available for multiclass cases.&#xA;#&amp;gt; The result has been recorded as NaN.&#xA;#&amp;gt; Warning in metrica::preval(data = ~., obs = ~labels, pred = ~predictions, : For&#xA;#&amp;gt; multiclass cases, prevalence should be estimated at a class level. A NaN has&#xA;#&amp;gt; been recorded as the result. Please, use `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::preval_t(data = ~., obs = ~labels, pred = ~predictions, : For multiclass cases, prevalence threshold should be estimated at a class level. &#xA;#&amp;gt;       A NaN has been recorded as the result. Please, use `atom = TRUE`.&#xA;#&amp;gt;         Metric       Score&#xA;#&amp;gt; 1     accuracy  0.32000000&#xA;#&amp;gt; 2   error_rate  0.68000000&#xA;#&amp;gt; 3    precision  0.32019443&#xA;#&amp;gt; 4       recall  0.32029977&#xA;#&amp;gt; 5  specificity  0.66031031&#xA;#&amp;gt; 6       balacc  0.49030504&#xA;#&amp;gt; 7       fscore  0.32024709&#xA;#&amp;gt; 8          agf  0.32024710&#xA;#&amp;gt; 9        gmean  0.45988829&#xA;#&amp;gt; 10        khat -0.01918465&#xA;#&amp;gt; 11         mcc -0.01926552&#xA;#&amp;gt; 12         fmi         NaN&#xA;#&amp;gt; 13         bmi -0.01938991&#xA;#&amp;gt; 14         csi  0.13793860&#xA;#&amp;gt; 15      deltap -0.01951385&#xA;#&amp;gt; 16       posLr  0.94291874&#xA;#&amp;gt; 17       negLr  1.02936485&#xA;#&amp;gt; 18         dor  0.91601996&#xA;#&amp;gt; 19         npv  0.66029172&#xA;#&amp;gt; 20         FPR  0.33968969&#xA;#&amp;gt; 21         FNR  0.67970023&#xA;#&amp;gt; 22         FDR  0.67980557&#xA;#&amp;gt; 23         FOR  0.33970828&#xA;#&amp;gt; 24      preval         NaN&#xA;#&amp;gt; 25    preval_t         NaN&#xA;#&amp;gt; 26     AUC_roc  0.49030504&#xA;&#xA;# Get a selected list at once with metrics_summary()&#xA;selected_class_metrics &amp;lt;- c(&#34;accuracy&#34;, &#34;recall&#34;, &#34;fscore&#34;)&#xA;&#xA;# Binary&#xA;binomial_case %&amp;gt;% metrics_summary(data = ., obs = labels, pred = predictions, type = &#34;classification&#34;,&#xA;                                  metrics_list = selected_class_metrics)&#xA;#&amp;gt;     Metric     Score&#xA;#&amp;gt; 1 accuracy 0.5500000&#xA;#&amp;gt; 2   recall 0.5636364&#xA;#&amp;gt; 3   fscore 0.5794393&#xA;&#xA;# Multiclass&#xA;multinomial_case %&amp;gt;% metrics_summary(data = ., obs = labels, pred = predictions, type = &#34;classification&#34;,&#xA;                                  metrics_list = selected_class_metrics)&#xA;#&amp;gt; Warning in metrica::fscore(data = ~., obs = ~labels, pred = ~predictions, :&#xA;#&amp;gt; For multiclass cases, the fscore should be estimated at a class level. Please,&#xA;#&amp;gt; consider using `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::agf(data = ~., obs = ~labels, pred = ~predictions, pos_level&#xA;#&amp;gt; = pos_level): For multiclass cases, the agf should be estimated at a class&#xA;#&amp;gt; level. Please, consider using `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::fmi(data = ~., obs = ~labels, pred = ~predictions, pos_level&#xA;#&amp;gt; = pos_level): The Fowlkes-Mallows Index is not available for multiclass cases.&#xA;#&amp;gt; The result has been recorded as NaN.&#xA;#&amp;gt; Warning in metrica::preval(data = ~., obs = ~labels, pred = ~predictions, : For&#xA;#&amp;gt; multiclass cases, prevalence should be estimated at a class level. A NaN has&#xA;#&amp;gt; been recorded as the result. Please, use `atom = TRUE`&#xA;#&amp;gt; Warning in metrica::preval_t(data = ~., obs = ~labels, pred = ~predictions, : For multiclass cases, prevalence threshold should be estimated at a class level. &#xA;#&amp;gt;       A NaN has been recorded as the result. Please, use `atom = TRUE`.&#xA;#&amp;gt;     Metric     Score&#xA;#&amp;gt; 1 accuracy 0.3200000&#xA;#&amp;gt; 2   recall 0.3202998&#xA;#&amp;gt; 3   fscore 0.3202471&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;multinomial_case %&amp;gt;% accuracy(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   accuracy&#xA;#&amp;gt; 1     0.32&#xA;multinomial_case %&amp;gt;% error_rate(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   error_rate&#xA;#&amp;gt; 1       0.68&#xA;multinomial_case %&amp;gt;% precision(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;   precision&#xA;#&amp;gt; 1 0.3201944&#xA;multinomial_case %&amp;gt;% recall(data = ., obs = labels, pred = predictions, atom = F, tidy=TRUE)&#xA;#&amp;gt;      recall&#xA;#&amp;gt; 1 0.3202998&#xA;multinomial_case %&amp;gt;% specificity(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;        spec&#xA;#&amp;gt; 1 0.6603103&#xA;multinomial_case %&amp;gt;% balacc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;     balacc&#xA;#&amp;gt; 1 0.490305&#xA;multinomial_case %&amp;gt;% fscore(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in fscore(data = ., obs = labels, pred = predictions, tidy = TRUE):&#xA;#&amp;gt; For multiclass cases, the fscore should be estimated at a class level. Please,&#xA;#&amp;gt; consider using `atom = TRUE`&#xA;#&amp;gt;      fscore&#xA;#&amp;gt; 1 0.3202471&#xA;multinomial_case %&amp;gt;% agf(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in agf(data = ., obs = labels, pred = predictions, tidy = TRUE): For&#xA;#&amp;gt; multiclass cases, the agf should be estimated at a class level. Please, consider&#xA;#&amp;gt; using `atom = TRUE`&#xA;#&amp;gt;         agf&#xA;#&amp;gt; 1 0.3202471&#xA;multinomial_case %&amp;gt;% gmean(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       gmean&#xA;#&amp;gt; 1 0.4598883&#xA;multinomial_case %&amp;gt;% khat(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;          khat&#xA;#&amp;gt; 1 -0.01918465&#xA;multinomial_case %&amp;gt;% mcc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;           mcc&#xA;#&amp;gt; 1 -0.01926552&#xA;multinomial_case %&amp;gt;% fmi(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in fmi(data = ., obs = labels, pred = predictions, tidy = TRUE): The&#xA;#&amp;gt; Fowlkes-Mallows Index is not available for multiclass cases. The result has been&#xA;#&amp;gt; recorded as NaN.&#xA;#&amp;gt;   fmi&#xA;#&amp;gt; 1 NaN&#xA;multinomial_case %&amp;gt;% posLr(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       posLr&#xA;#&amp;gt; 1 0.9429187&#xA;multinomial_case %&amp;gt;% negLr(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;      negLr&#xA;#&amp;gt; 1 1.029365&#xA;multinomial_case %&amp;gt;% dor(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;       dor&#xA;#&amp;gt; 1 0.91602&#xA;multinomial_case %&amp;gt;% deltap(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;        deltap&#xA;#&amp;gt; 1 -0.01951385&#xA;multinomial_case %&amp;gt;% csi(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         csi&#xA;#&amp;gt; 1 0.1379386&#xA;multinomial_case %&amp;gt;% FPR(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         FPR&#xA;#&amp;gt; 1 0.3396897&#xA;multinomial_case %&amp;gt;% FNR(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         FNR&#xA;#&amp;gt; 1 0.6797002&#xA;multinomial_case %&amp;gt;% FDR(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         FDR&#xA;#&amp;gt; 1 0.6798056&#xA;multinomial_case %&amp;gt;% FOR(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;         FOR&#xA;#&amp;gt; 1 0.3397083&#xA;multinomial_case %&amp;gt;% preval(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in preval(data = ., obs = labels, pred = predictions, tidy = TRUE): For&#xA;#&amp;gt; multiclass cases, prevalence should be estimated at a class level. A NaN has&#xA;#&amp;gt; been recorded as the result. Please, use `atom = TRUE`&#xA;#&amp;gt;   prev&#xA;#&amp;gt; 1  NaN&#xA;multinomial_case %&amp;gt;% preval_t(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt; Warning in preval_t(data = ., obs = labels, pred = predictions, tidy = TRUE): For multiclass cases, prevalence threshold should be estimated at a class level. &#xA;#&amp;gt;       A NaN has been recorded as the result. Please, use `atom = TRUE`.&#xA;#&amp;gt;   preval_t&#xA;#&amp;gt; 1      NaN&#xA;multinomial_case %&amp;gt;% AUC_roc(data = ., obs = labels, pred = predictions, tidy=TRUE)&#xA;#&amp;gt;    AUC_roc&#xA;#&amp;gt; 1 0.490305&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;4. Import data from APSIM&lt;/h2&gt; &#xA;&lt;p&gt;Please, visit the &lt;a href=&#34;https://adriancorrendo.github.io/metrica/articles/apsim_open.html&#34;&gt;vignette&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>