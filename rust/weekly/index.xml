<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-23T02:03:18Z</updated>
  <subtitle>Weekly Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ellie/atuin</title>
    <updated>2023-07-23T02:03:18Z</updated>
    <id>tag:github.com,2023-07-23:/ellie/atuin</id>
    <link href="https://github.com/ellie/atuin" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üê¢ Magical shell history&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;250&#34; src=&#34;https://user-images.githubusercontent.com/53315310/171035743-53991112-9477-4f3d-8811-5deee40c7879.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;em&gt;magical shell history&lt;/em&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/ellie/atuin/actions?query=workflow%3ARust&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/ellie/atuin/rust.yml?style=flat-square&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://crates.io/crates/atuin&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/v/atuin.svg?style=flat-square&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://crates.io/crates/atuin&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/d/atuin.svg?style=flat-square&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ellie/atuin/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/l/atuin.svg?style=flat-square&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/Fq8bJSKPHh&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/954121165239115808&#34;&gt;&lt;/a&gt; &lt;a rel=&#34;me&#34; href=&#34;https://hachyderm.io/@atuin&#34;&gt;&lt;img src=&#34;https://img.shields.io/mastodon/follow/109944632283122560?domain=https%3A%2F%2Fhachyderm.io&amp;amp;style=social&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/atuinsh&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/atuinsh?style=social&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/README.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/docs/zh-CN/README.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Atuin replaces your existing shell history with a SQLite database, and records additional context for your commands. Additionally, it provides optional and &lt;em&gt;fully encrypted&lt;/em&gt; synchronisation of your history between machines, via an Atuin server.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ellie/atuin/main/demo.gif&#34; alt=&#34;animated&#34; width=&#34;80%&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;em&gt;exit code, duration, time and command shown&lt;/em&gt; &lt;/p&gt; &#xA;&lt;p&gt;As well as the search UI, it can do things like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# search for all successful `make` commands, recorded after 3pm yesterday&#xA;atuin search --exit 0 --after &#34;yesterday 3pm&#34; make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may use either the server I host, or host your own! Or just don&#39;t use sync at all. As all history sync is encrypted, I couldn&#39;t access your data even if I wanted to. And I &lt;strong&gt;really&lt;/strong&gt; don&#39;t want to.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;rebind &lt;code&gt;ctrl-r&lt;/code&gt; and &lt;code&gt;up&lt;/code&gt; (configurable) to a full screen history search UI&lt;/li&gt; &#xA; &lt;li&gt;store shell history in a sqlite database&lt;/li&gt; &#xA; &lt;li&gt;backup and sync &lt;strong&gt;encrypted&lt;/strong&gt; shell history&lt;/li&gt; &#xA; &lt;li&gt;the same history across terminals, across sessions, and across machines&lt;/li&gt; &#xA; &lt;li&gt;log exit code, cwd, hostname, session, command duration, etc&lt;/li&gt; &#xA; &lt;li&gt;calculate statistics such as &#34;most used command&#34;&lt;/li&gt; &#xA; &lt;li&gt;old history file is not replaced&lt;/li&gt; &#xA; &lt;li&gt;quick-jump to previous items with &lt;kbd&gt;Alt-&amp;lt;num&amp;gt;&lt;/kbd&gt;&lt;/li&gt; &#xA; &lt;li&gt;switch filter modes via ctrl-r; search history just from the current session, directory, or globally&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#quickstart&#34;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atuin.sh/docs/commands/import&#34;&gt;Import&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atuin.sh/docs/config&#34;&gt;Configuration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atuin.sh/docs/commands/search&#34;&gt;Searching history&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atuin.sh/docs/commands/sync&#34;&gt;Cloud history sync&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atuin.sh/docs/commands/stats&#34;&gt;History stats&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atuin.sh/docs/self-hosting&#34;&gt;Self host Atuin server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atuin.sh/docs/config/key-binding&#34;&gt;Key binding&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atuin.sh/docs/commands/shell-completions&#34;&gt;Shell completions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Supported Shells&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;zsh&lt;/li&gt; &#xA; &lt;li&gt;bash&lt;/li&gt; &#xA; &lt;li&gt;fish&lt;/li&gt; &#xA; &lt;li&gt;nushell&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;Atuin has a community Discord, available &lt;a href=&#34;https://discord.gg/Fq8bJSKPHh&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Quickstart&lt;/h1&gt; &#xA;&lt;h2&gt;With the default sync server&lt;/h2&gt; &#xA;&lt;p&gt;This will sign you up for the default sync server, hosted by me. Everything is end-to-end encrypted, so your secrets are safe!&lt;/p&gt; &#xA;&lt;p&gt;Read more below for offline-only usage, or for hosting your own server.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash &amp;lt;(curl https://raw.githubusercontent.com/ellie/atuin/main/install.sh)&#xA;&#xA;atuin register -u &amp;lt;USERNAME&amp;gt; -e &amp;lt;EMAIL&amp;gt;&#xA;atuin import auto&#xA;atuin sync&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then restart your shell!&lt;/p&gt; &#xA;&lt;h3&gt;Opt-in to activity graph&lt;/h3&gt; &#xA;&lt;p&gt;Alongside the hosted Atuin server, there is also a service which generates activity graphs for your shell history! These are inspired by the GitHub graph.&lt;/p&gt; &#xA;&lt;p&gt;For example, here is mine:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ellie/atuin/main/docs/static/img/activity-graph-example.png&#34; alt=&#34;Activity Graph Example&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you wish to get your own, after signing up for the sync server, run this&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl https://api.atuin.sh/enable -d $(cat ~/.local/share/atuin/session)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The response includes the URL to your graph. Feel free to share and/or embed this URL, the token is &lt;em&gt;not&lt;/em&gt; a secret, and simply prevents user enumeration.&lt;/p&gt; &#xA;&lt;h2&gt;Offline only (no sync)&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash &amp;lt;(curl https://raw.githubusercontent.com/ellie/atuin/main/install.sh)&#xA;            &#xA;atuin import auto&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, Atuin will check for updates. You can &lt;a href=&#34;https://atuin.sh/docs/config/#update_check&#34;&gt;disable update checks by modifying&lt;/a&gt; &lt;code&gt;config.toml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Then restart your shell!&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;h3&gt;Script (recommended)&lt;/h3&gt; &#xA;&lt;p&gt;The install script will help you through the setup, ensuring your shell is properly configured. It will also use one of the below methods, preferring the system package manager where possible (pacman, homebrew, etc etc).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# do not run this as root, root will be asked for if required&#xA;bash &amp;lt;(curl https://raw.githubusercontent.com/ellie/atuin/main/install.sh)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then follow &lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#shell-plugin&#34;&gt;the shell setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;With cargo&lt;/h3&gt; &#xA;&lt;p&gt;It&#39;s best to use &lt;a href=&#34;https://rustup.rs/&#34;&gt;rustup&lt;/a&gt; to get setup with a Rust toolchain, then you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cargo install atuin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then follow &lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#shell-plugin&#34;&gt;the shell setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Homebrew&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install atuin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then follow &lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#shell-plugin&#34;&gt;the shell setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;MacPorts&lt;/h3&gt; &#xA;&lt;p&gt;Atuin is also available in &lt;a href=&#34;https://ports.macports.org/port/atuin/&#34;&gt;MacPorts&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo port install atuin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then follow &lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#shell-plugin&#34;&gt;the shell setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Nix&lt;/h3&gt; &#xA;&lt;p&gt;This repository is a flake, and can be installed using &lt;code&gt;nix profile&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;nix profile install &#34;github:ellie/atuin&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Atuin is also available in &lt;a href=&#34;https://github.com/NixOS/nixpkgs&#34;&gt;nixpkgs&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;nix-env -f &#39;&amp;lt;nixpkgs&amp;gt;&#39; -iA atuin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then follow &lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#shell-plugin&#34;&gt;the shell setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Pacman&lt;/h3&gt; &#xA;&lt;p&gt;Atuin is available in the Arch Linux &lt;a href=&#34;https://archlinux.org/packages/extra/x86_64/atuin/&#34;&gt;[extra] repository&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pacman -S atuin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then follow &lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#shell-plugin&#34;&gt;the shell setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Termux&lt;/h3&gt; &#xA;&lt;p&gt;Atuin is available in the Termux package repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pkg install atuin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then follow &lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#shell-plugin&#34;&gt;the shell setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;From source&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/ellie/atuin.git&#xA;cd atuin/atuin&#xA;cargo install --path .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then follow &lt;a href=&#34;https://raw.githubusercontent.com/ellie/atuin/main/#shell-plugin&#34;&gt;the shell setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Shell plugin&lt;/h2&gt; &#xA;&lt;p&gt;Once the binary is installed, the shell plugin requires installing. If you use the install script, this should all be done for you! After installing, remember to restart your shell.&lt;/p&gt; &#xA;&lt;h3&gt;zsh&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;echo &#39;eval &#34;$(atuin init zsh)&#34;&#39; &amp;gt;&amp;gt; ~/.zshrc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Zinit&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;zinit load ellie/atuin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Antigen&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;antigen bundle ellie/atuin@main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;bash&lt;/h3&gt; &#xA;&lt;p&gt;We need to setup some hooks, so first install bash-preexec:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl https://raw.githubusercontent.com/rcaloras/bash-preexec/master/bash-preexec.sh -o ~/.bash-preexec.sh&#xA;echo &#39;[[ -f ~/.bash-preexec.sh ]] &amp;amp;&amp;amp; source ~/.bash-preexec.sh&#39; &amp;gt;&amp;gt; ~/.bashrc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then setup Atuin&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;echo &#39;eval &#34;$(atuin init bash)&#34;&#39; &amp;gt;&amp;gt; ~/.bashrc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;PLEASE NOTE&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;bash-preexec currently has an issue where it will stop honoring &lt;code&gt;ignorespace&lt;/code&gt;. While Atuin will ignore commands prefixed with whitespace, they may still end up in your bash history. Please check your configuration! All other shells do not have this issue.&lt;/p&gt; &#xA;&lt;h3&gt;fish&lt;/h3&gt; &#xA;&lt;p&gt;Add&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;atuin init fish | source&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to your &lt;code&gt;is-interactive&lt;/code&gt; block in your &lt;code&gt;~/.config/fish/config.fish&lt;/code&gt; file&lt;/p&gt; &#xA;&lt;h3&gt;Fig&lt;/h3&gt; &#xA;&lt;p&gt;Install &lt;code&gt;atuin&lt;/code&gt; shell plugin in zsh, bash, or fish with &lt;a href=&#34;https://fig.io&#34;&gt;Fig&lt;/a&gt; in one click.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://fig.io/plugins/shell/atuin&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://fig.io/badges/install-with-fig.svg?sanitize=true&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Nushell&lt;/h3&gt; &#xA;&lt;p&gt;Run in &lt;em&gt;Nushell&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir ~/.local/share/atuin/&#xA;atuin init nu | save ~/.local/share/atuin/init.nu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add to &lt;code&gt;config.nu&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;source ~/.local/share/atuin/init.nu&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>ratatui-org/ratatui</title>
    <updated>2023-07-23T02:03:18Z</updated>
    <id>tag:github.com,2023-07-23:/ratatui-org/ratatui</id>
    <link href="https://github.com/ratatui-org/ratatui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Rust library to build rich terminal user interfaces (TUIs) and dashboards&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ratatui&lt;/h1&gt; &#xA;&lt;img align=&#34;left&#34; src=&#34;https://avatars.githubusercontent.com/u/125200832?s=128&amp;amp;v=4&#34;&gt; &#xA;&lt;p&gt;&lt;code&gt;ratatui&lt;/code&gt; is a &lt;a href=&#34;https://www.rust-lang.org&#34;&gt;Rust&lt;/a&gt; library to build rich terminal user interfaces and dashboards. It is a community fork of the original &lt;a href=&#34;https://github.com/fdehau/tui-rs&#34;&gt;tui-rs&lt;/a&gt; project.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://crates.io/crates/ratatui&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/v/ratatui?logo=rust&amp;amp;style=flat-square&#34; alt=&#34;Crates.io&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/l/ratatui?style=flat-square&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ratatui-org/ratatui/actions?query=workflow%3ACI+&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/ratatui-org/ratatui/ci.yml?style=flat-square&amp;amp;logo=github&#34; alt=&#34;GitHub CI Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.rs/crate/ratatui/&#34;&gt;&lt;img src=&#34;https://img.shields.io/docsrs/ratatui?logo=rust&amp;amp;style=flat-square&#34; alt=&#34;Docs.rs&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://deps.rs/repo/github/ratatui-org/ratatui&#34;&gt;&lt;img src=&#34;https://deps.rs/repo/github/ratatui-org/ratatui/status.svg?style=flat-square&#34; alt=&#34;Dependency Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/ratatui-org/ratatui&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/ratatui-org/ratatui?logo=codecov&amp;amp;style=flat-square&amp;amp;token=BAQ8SOKEST&#34; alt=&#34;Codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/pMCEU9hNEj&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1070692720437383208?label=discord&amp;amp;logo=discord&amp;amp;style=flat-square&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- See RELEASE.md for instructions on creating the demo gif ---&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/ratatui-org/ratatui/assets/24392180/93ab0e38-93e0-4ae0-a31b-91ae6c393185&#34; alt=&#34;Demo of Ratatui&#34;&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Table of Contents&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#ratatui&#34;&gt;Ratatui&lt;/a&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#quickstart&#34;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#status-of-this-fork&#34;&gt;Status of this fork&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#rust-version-requirements&#34;&gt;Rust version requirements&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#examples&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#widgets&#34;&gt;Widgets&lt;/a&gt; &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#built-in&#34;&gt;Built in&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#third-party-libraries-bootstrapping-templates-and-widgets&#34;&gt;Third-party libraries, bootstrapping templates and widgets&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#apps&#34;&gt;Apps&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#alternatives&#34;&gt;Alternatives&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#contributors&#34;&gt;Contributors&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#acknowledgments&#34;&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo add ratatui --features all-widgets&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or modify your &lt;code&gt;Cargo.toml&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dependencies]&#xA;ratatui = { version = &#34;0.22.0&#34;, features = [&#34;all-widgets&#34;]}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ratatui is mostly backwards compatible with &lt;code&gt;tui-rs&lt;/code&gt;. To migrate an existing project, it may be easier to rename the ratatui dependency to &lt;code&gt;tui&lt;/code&gt; rather than updating every usage of the crate. E.g.:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dependencies]&#xA;tui = { package = &#34;ratatui&#34;, version = &#34;0.22.0&#34;, features = [&#34;all-widgets&#34;]}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;ratatui&lt;/code&gt; is a terminal UI library that supports multiple backends:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crossterm-rs/crossterm&#34;&gt;crossterm&lt;/a&gt; [default]&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ticki/termion&#34;&gt;termion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wez/wezterm/tree/master/termwiz&#34;&gt;termwiz&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The library is based on the principle of immediate rendering with intermediate buffers. This means that at each new frame you should build all widgets that are supposed to be part of the UI. While providing a great flexibility for rich and interactive UI, this may introduce overhead for highly dynamic content. So, the implementation try to minimize the number of ansi escapes sequences generated to draw the updated UI. In practice, given the speed of &lt;code&gt;Rust&lt;/code&gt; the overhead rather comes from the terminal emulator than the library itself.&lt;/p&gt; &#xA;&lt;p&gt;Moreover, the library does not provide any input handling nor any event system and you may rely on the previously cited libraries to achieve such features.&lt;/p&gt; &#xA;&lt;p&gt;We keep a &lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/CHANGELOG.md&#34;&gt;CHANGELOG&lt;/a&gt; generated by &lt;a href=&#34;https://github.com/orhun/git-cliff&#34;&gt;git-cliff&lt;/a&gt; utilizing &lt;a href=&#34;https://www.conventionalcommits.org/&#34;&gt;Conventional Commits&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;The following example demonstrates the minimal amount of code necessary to setup a terminal and render &#34;Hello World!&#34;. The full code for this example which contains a little more detail is in &lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/examples/hello_world.rs&#34;&gt;hello_world.rs&lt;/a&gt;. For more guidance on how to create Ratatui apps, see the &lt;a href=&#34;https://docs.rs/ratatui&#34;&gt;Docs&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/#examples&#34;&gt;Examples&lt;/a&gt;. There is also a starter template available at &lt;a href=&#34;https://github.com/ratatui-org/rust-tui-template&#34;&gt;rust-tui-template&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn Error&amp;gt;&amp;gt; {&#xA;    let mut terminal = setup_terminal()?;&#xA;    run(&amp;amp;mut terminal)?;&#xA;    restore_terminal(&amp;amp;mut terminal)?;&#xA;    Ok(())&#xA;}&#xA;&#xA;fn setup_terminal() -&amp;gt; Result&amp;lt;Terminal&amp;lt;CrosstermBackend&amp;lt;Stdout&amp;gt;&amp;gt;, Box&amp;lt;dyn Error&amp;gt;&amp;gt; {&#xA;    let mut stdout = io::stdout();&#xA;    enable_raw_mode()?;&#xA;    execute!(stdout, EnterAlternateScreen)?;&#xA;    Ok(Terminal::new(CrosstermBackend::new(stdout))?)&#xA;}&#xA;&#xA;fn restore_terminal(&#xA;    terminal: &amp;amp;mut Terminal&amp;lt;CrosstermBackend&amp;lt;Stdout&amp;gt;&amp;gt;,&#xA;) -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn Error&amp;gt;&amp;gt; {&#xA;    disable_raw_mode()?;&#xA;    execute!(terminal.backend_mut(), LeaveAlternateScreen,)?;&#xA;    Ok(terminal.show_cursor()?)&#xA;}&#xA;&#xA;fn run(terminal: &amp;amp;mut Terminal&amp;lt;CrosstermBackend&amp;lt;Stdout&amp;gt;&amp;gt;) -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn Error&amp;gt;&amp;gt; {&#xA;    Ok(loop {&#xA;        terminal.draw(|frame| {&#xA;            let greeting = Paragraph::new(&#34;Hello World!&#34;);&#xA;            frame.render_widget(greeting, frame.size());&#xA;        })?;&#xA;        if event::poll(Duration::from_millis(250))? {&#xA;            if let Event::Key(key) = event::read()? {&#xA;                if KeyCode::Char(&#39;q&#39;) == key.code {&#xA;                    break;&#xA;                }&#xA;            }&#xA;        }&#xA;    })&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Status of this fork&lt;/h2&gt; &#xA;&lt;p&gt;In response to the original maintainer &lt;a href=&#34;https://github.com/fdehau&#34;&gt;&lt;strong&gt;Florian Dehau&lt;/strong&gt;&lt;/a&gt;&#39;s issue regarding the &lt;a href=&#34;https://github.com/fdehau/tui-rs/issues/654&#34;&gt;future of &lt;code&gt;tui-rs&lt;/code&gt;&lt;/a&gt;, several members of the community forked the project and created this crate. We look forward to continuing the work started by Florian üöÄ&lt;/p&gt; &#xA;&lt;p&gt;In order to organize ourselves, we currently use a &lt;a href=&#34;https://discord.gg/pMCEU9hNEj&#34;&gt;Discord server&lt;/a&gt;, feel free to join and come chat! There are also plans to implement a &lt;a href=&#34;https://matrix.org/&#34;&gt;Matrix&lt;/a&gt; bridge in the near future. &lt;strong&gt;Discord is not a MUST to contribute&lt;/strong&gt;. We follow a pretty standard github centered open source workflow keeping the most important conversations on GitHub, open an issue or PR and it will be addressed. üòÑ&lt;/p&gt; &#xA;&lt;p&gt;Please make sure you read the updated &lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/CONTRIBUTING.md&#34;&gt;contributing&lt;/a&gt; guidelines, especially if you are interested in working on a PR or issue opened in the previous repository.&lt;/p&gt; &#xA;&lt;h2&gt;Rust version requirements&lt;/h2&gt; &#xA;&lt;p&gt;Since version 0.21.0, The Minimum Supported Rust Version (MSRV) of &lt;code&gt;ratatui&lt;/code&gt; is 1.65.0.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The documentation can be found on &lt;a href=&#34;https://docs.rs/ratatui&#34;&gt;docs.rs.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;The demo shown in the gif above is available on all available backends.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# crossterm&#xA;cargo run --example demo&#xA;# termion&#xA;cargo run --example demo --no-default-features --features=termion&#xA;# termwiz&#xA;cargo run --example demo --no-default-features --features=termwiz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The UI code for this is in &lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/examples/demo/ui.rs&#34;&gt;examples/demo/ui.rs&lt;/a&gt; while the application state is in &lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/examples/demo/app.rs&#34;&gt;examples/demo/app.rs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If the user interface contains glyphs that are not displayed correctly by your terminal, you may want to run the demo without those symbols:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo run --example demo --release -- --tick-rate 200 --enhanced-graphics false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More examples are available in the &lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/examples/&#34;&gt;examples&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;Widgets&lt;/h2&gt; &#xA;&lt;h3&gt;Built in&lt;/h3&gt; &#xA;&lt;p&gt;The library comes with the following &lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/index.html&#34;&gt;widgets&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/canvas/struct.Canvas.html&#34;&gt;Canvas&lt;/a&gt; which allows rendering &lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/canvas/index.html&#34;&gt;points, lines, shapes and a world map&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/struct.BarChart.html&#34;&gt;BarChart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/struct.Block.html&#34;&gt;Block&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/calendar/index.html&#34;&gt;Calendar&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/struct.Chart.html&#34;&gt;Chart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/struct.Gauge.html&#34;&gt;Gauge&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/struct.List.html&#34;&gt;List&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/struct.Paragraph.html&#34;&gt;Paragraph&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/struct.Sparkline.html&#34;&gt;Sparkline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/struct.Table.html&#34;&gt;Table&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/ratatui/latest/ratatui/widgets/struct.Tabs.html&#34;&gt;Tabs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Each widget has an associated example which can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/examples/&#34;&gt;examples&lt;/a&gt; folder. Run each examples with cargo (e.g. to run the gauge example &lt;code&gt;cargo run --example gauge&lt;/code&gt;), and quit by pressing &lt;code&gt;q&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also run all examples by running &lt;code&gt;cargo make run-examples&lt;/code&gt; (requires &lt;code&gt;cargo-make&lt;/code&gt; that can be installed with &lt;code&gt;cargo install cargo-make&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;Third-party libraries, bootstrapping templates and widgets&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/uttarayan21/ansi-to-tui&#34;&gt;ansi-to-tui&lt;/a&gt; ‚Äî Convert ansi colored text to &lt;code&gt;tui::text::Text&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/uttarayan21/color-to-tui&#34;&gt;color-to-tui&lt;/a&gt; ‚Äî Parse hex colors to &lt;code&gt;tui::style::Color&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ratatui-org/rust-tui-template&#34;&gt;rust-tui-template&lt;/a&gt; ‚Äî A template for bootstrapping a Rust TUI application with Tui-rs &amp;amp; crossterm&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pmsanford/simple-tui-rs&#34;&gt;simple-tui-rs&lt;/a&gt; ‚Äî A simple example tui-rs app&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jkelleyrtp/tui-builder&#34;&gt;tui-builder&lt;/a&gt; ‚Äî Batteries-included MVC framework for Tui-rs + Crossterm apps&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kegesch/tui-clap-rs&#34;&gt;tui-clap&lt;/a&gt; ‚Äî Use clap-rs together with Tui-rs&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kegesch/tui-log-rs&#34;&gt;tui-log&lt;/a&gt; ‚Äî Example of how to use logging with Tui-rs&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gin66/tui-logger&#34;&gt;tui-logger&lt;/a&gt; ‚Äî Logger and Widget for Tui-rs&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/veeso/tui-realm&#34;&gt;tui-realm&lt;/a&gt; ‚Äî Tui-rs framework to build stateful applications with a React/Elm inspired approach&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/veeso/tui-realm-treeview&#34;&gt;tui-realm-treeview&lt;/a&gt; ‚Äî Treeview component for Tui-realm&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/EdJoPaTo/tui-rs-tree-widget&#34;&gt;tui-rs-tree-widgets&lt;/a&gt;: Widget for tree data structures.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/markatk/tui-windows-rs&#34;&gt;tui-windows&lt;/a&gt; ‚Äî Tui-rs abstraction to handle multiple windows and their rendering&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rhysd/tui-textarea&#34;&gt;tui-textarea&lt;/a&gt;: Simple yet powerful multi-line text editor widget supporting several key shortcuts, undo/redo, text search, etc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sayanarijit/tui-input&#34;&gt;tui-input&lt;/a&gt;: TUI input library supporting multiple backends and tui-rs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/a-kenji/tui-term&#34;&gt;tui-term&lt;/a&gt;: A pseudoterminal widget library that enables the rendering of terminal applications as ratatui widgets.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Apps&lt;/h2&gt; &#xA;&lt;p&gt;Check out the list of more than 50 &lt;a href=&#34;https://github.com/ratatui-org/ratatui/wiki/Apps-using-Ratatui&#34;&gt;Apps using &lt;code&gt;Ratatui&lt;/code&gt;&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Alternatives&lt;/h2&gt; &#xA;&lt;p&gt;You might want to checkout &lt;a href=&#34;https://github.com/gyscos/Cursive&#34;&gt;Cursive&lt;/a&gt; for an alternative solution to build text user interfaces in Rust.&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ratatui-org/ratatui/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=ratatui-org/ratatui&#34; alt=&#34;GitHub Contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;Special thanks to &lt;a href=&#34;https://github.com/nawok&#34;&gt;&lt;strong&gt;Pavel Fomchenkov&lt;/strong&gt;&lt;/a&gt; for his work in designing &lt;strong&gt;an awesome logo&lt;/strong&gt; for the ratatui project and ratatui-org organization.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ratatui-org/ratatui/main/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rustformers/llm</title>
    <updated>2023-07-23T02:03:18Z</updated>
    <id>tag:github.com,2023-07-23:/rustformers/llm</id>
    <link href="https://github.com/rustformers/llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An ecosystem of Rust libraries for working with large language models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;code&gt;llm&lt;/code&gt; - Large Language Models for Everyone, in Rust&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;llm&lt;/code&gt; is an ecosystem of Rust libraries for working with large language models - it&#39;s built on top of the fast, efficient &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/crates/ggml&#34;&gt;GGML&lt;/a&gt; library for machine learning.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rustformers/llm/main/doc/img/llm-crab-llama.png&#34; alt=&#34;A llama riding a crab, AI-generated&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;em&gt;Image by &lt;a href=&#34;https://github.com/darthdeus/&#34;&gt;@darthdeus&lt;/a&gt;, using Stable Diffusion&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://crates.io/crates/llm&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/v/llm.svg?sanitize=true&#34; alt=&#34;Latest version&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://shields.io/badge/license-MIT%2FApache--2.0-blue&#34; alt=&#34;MIT/Apache2&#34;&gt; &lt;a href=&#34;https://discord.gg/YB9WaXYAWU&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1085885067601137734&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The primary entrypoint &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/#using-llm-in-a-rust-project&#34;&gt;for developers&lt;/a&gt; is &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/crates/llm&#34;&gt;the &lt;code&gt;llm&lt;/code&gt; crate&lt;/a&gt;, which wraps &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/crates/llm-base&#34;&gt;&lt;code&gt;llm-base&lt;/code&gt;&lt;/a&gt; and the &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/crates/models&#34;&gt;supported model&lt;/a&gt; crates. &lt;a href=&#34;https://docs.rs/llm&#34;&gt;Documentation&lt;/a&gt; for released version is available on Docs.rs.&lt;/p&gt; &#xA;&lt;p&gt;For end-users, there is &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/#using-the-llm-cli&#34;&gt;a CLI application&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/binaries/llm-cli&#34;&gt;&lt;code&gt;llm-cli&lt;/code&gt;&lt;/a&gt;, which provides a convenient interface for interacting with supported models. &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/#running&#34;&gt;Text generation&lt;/a&gt; can be done as a one-off based on a prompt, or interactively, through &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/#does-the-llm-cli-support-chat-mode&#34;&gt;REPL or chat&lt;/a&gt; modes. The CLI can also be used to serialize (print) decoded models, &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/crates/ggml/README.md#quantization&#34;&gt;quantize&lt;/a&gt; GGML files, or compute the &lt;a href=&#34;https://huggingface.co/docs/transformers/perplexity&#34;&gt;perplexity&lt;/a&gt; of a model. It can be downloaded from &lt;a href=&#34;https://github.com/rustformers/llm/releases&#34;&gt;the latest GitHub release&lt;/a&gt; or by installing it from &lt;code&gt;crates.io&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;llm&lt;/code&gt; is powered by the &lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;&lt;code&gt;ggml&lt;/code&gt;&lt;/a&gt; tensor library, and aims to bring the robustness and ease of use of Rust to the world of large language models. At present, inference is only on the CPU, but we hope to support GPU inference in the future through alternate backends.&lt;/p&gt; &#xA;&lt;p&gt;Currently, the following models are supported:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/bloom&#34;&gt;BLOOM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/gpt2&#34;&gt;GPT-2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/gptj&#34;&gt;GPT-J&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/gpt_neox&#34;&gt;GPT-NeoX&lt;/a&gt; (includes &lt;a href=&#34;https://github.com/Stability-AI/StableLM&#34;&gt;StableLM&lt;/a&gt;, &lt;a href=&#34;https://www.together.xyz/blog/redpajama&#34;&gt;RedPajama&lt;/a&gt;, and &lt;a href=&#34;https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm&#34;&gt;Dolly 2.0&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/llama&#34;&gt;LLaMA&lt;/a&gt; (includes &lt;a href=&#34;https://crfm.stanford.edu/2023/03/13/alpaca.html&#34;&gt;Alpaca&lt;/a&gt;, &lt;a href=&#34;https://lmsys.org/blog/2023-03-30-vicuna/&#34;&gt;Vicuna&lt;/a&gt;, &lt;a href=&#34;https://bair.berkeley.edu/blog/2023/04/03/koala/&#34;&gt;Koala&lt;/a&gt;, &lt;a href=&#34;https://gpt4all.io/index.html&#34;&gt;GPT4All&lt;/a&gt;, and &lt;a href=&#34;https://github.com/nlpxucan/WizardLM&#34;&gt;Wizard&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mosaicml.com/blog/mpt-7b&#34;&gt;MPT&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/#getting-models&#34;&gt;getting models&lt;/a&gt; for more information on how to download supported models.&lt;/p&gt; &#xA;&lt;h2&gt;Using &lt;code&gt;llm&lt;/code&gt; in a Rust Project&lt;/h2&gt; &#xA;&lt;p&gt;This project depends on Rust v1.65.0 or above and a modern C toolchain.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;llm&lt;/code&gt; crate exports &lt;code&gt;llm-base&lt;/code&gt; and the model crates (e.g. &lt;code&gt;bloom&lt;/code&gt;, &lt;code&gt;gpt2&lt;/code&gt; &lt;code&gt;llama&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Add &lt;code&gt;llm&lt;/code&gt; to your project by listing it as a dependency in &lt;code&gt;Cargo.toml&lt;/code&gt;. To use the version of &lt;code&gt;llm&lt;/code&gt; you see in the &lt;code&gt;main&lt;/code&gt; branch of this repository, add it from GitHub (although keep in mind this is pre-release software):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dependencies]&#xA;llm = { git = &#34;https://github.com/rustformers/llm&#34; , branch = &#34;main&#34; }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use a &lt;a href=&#34;https://github.com/rustformers/llm/releases&#34;&gt;released&lt;/a&gt; version, add it from &lt;a href=&#34;https://crates.io/crates/llm&#34;&gt;crates.io&lt;/a&gt; by specifying the desired version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dependencies]&#xA;llm = &#34;0.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, &lt;code&gt;llm&lt;/code&gt; builds with support for remotely fetching the tokenizer from Hugging Face&#39;s model hub. To disable this, disable the default features for the crate, and turn on the &lt;code&gt;models&lt;/code&gt; feature to get &lt;code&gt;llm&lt;/code&gt; without the tokenizer:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dependencies]&#xA;llm = { version = &#34;0.1&#34;, default-features = false, features = [&#34;models&#34;] }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: To improve debug performance, exclude the transitive &lt;code&gt;ggml-sys&lt;/code&gt; dependency from being built in debug mode:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[profile.dev.package.ggml-sys]&#xA;opt-level = 3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Leverage Accelerators with &lt;code&gt;llm&lt;/code&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;llm&lt;/code&gt; library is engineered to take advantage of hardware accelerators such as &lt;code&gt;cuda&lt;/code&gt; and &lt;code&gt;metal&lt;/code&gt; for optimized performance.&lt;/p&gt; &#xA;&lt;p&gt;To enable &lt;code&gt;llm&lt;/code&gt; to harness these accelerators, some preliminary configuration steps are necessary, which vary based on your operating system. For comprehensive guidance, please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/doc/CONTRIBUTING.md#acceleration-support-for-building&#34;&gt;Acceleration Support for Building section&lt;/a&gt; in our documentation.&lt;/p&gt; &#xA;&lt;h2&gt;Using &lt;code&gt;llm&lt;/code&gt; from Other Languages&lt;/h2&gt; &#xA;&lt;p&gt;Bindings for this library are available in the following languages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python: &lt;a href=&#34;https://github.com/LLukas22/llm-rs-python&#34;&gt;LLukas22/llm-rs-python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Node: &lt;a href=&#34;https://github.com/Atome-FE/llama-node&#34;&gt;Atome-FE/llama-node&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Using the &lt;code&gt;llm&lt;/code&gt; CLI&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to get started with &lt;code&gt;llm-cli&lt;/code&gt; is to download a pre-built executable from a &lt;a href=&#34;https://github.com/rustformers/llm/releases&#34;&gt;released&lt;/a&gt; version of &lt;code&gt;llm&lt;/code&gt;, although this may not have all the features present on the &lt;code&gt;main&lt;/code&gt; branch. The following methods involve building &lt;code&gt;llm&lt;/code&gt;, which requires Rust v1.65.0 or above and a modern C toolchain.&lt;/p&gt; &#xA;&lt;h3&gt;Installing with &lt;code&gt;cargo&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;To install the most recently released version of &lt;code&gt;llm&lt;/code&gt; to your Cargo &lt;code&gt;bin&lt;/code&gt; directory, which &lt;code&gt;rustup&lt;/code&gt; is likely to have added to your &lt;code&gt;PATH&lt;/code&gt;, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo install llm-cli&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The CLI application can then be run through &lt;code&gt;llm&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Building from Source&lt;/h3&gt; &#xA;&lt;p&gt;To make use of the features on the &lt;code&gt;main&lt;/code&gt; branch, clone the repository and then build it with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone --recurse-submodules https://github.com/rustformers/llm&#xA;cd llm&#xA;cargo build --release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The resulting binary will be at &lt;code&gt;target/release/llm[.exe]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It can also be run directly through Cargo, with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo run --release -- $ARGS&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;p&gt;By default, &lt;code&gt;llm&lt;/code&gt; builds with support for remotely fetching the tokenizer from Hugging Face&#39;s model hub. This adds a dependency on your system&#39;s native SSL stack, which may not be available on all systems.&lt;/p&gt; &#xA;&lt;p&gt;To disable this, disable the default features for the build:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo build --release --no-default-features&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To enable hardware acceleration, see &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/doc/CONTRIBUTING.md#acceleration-support-for-building&#34;&gt;Acceleration Support for Building section&lt;/a&gt;, which is also applicable to the CLI.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Models&lt;/h2&gt; &#xA;&lt;p&gt;GGML models are easy to acquire. They are primarily located on Hugging Face (see &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/#from-hugging-face&#34;&gt;From Hugging Face&lt;/a&gt;), but can be obtained from elsewhere.&lt;/p&gt; &#xA;&lt;p&gt;Models are distributed as single files, and do not need any additional files to be downloaded. However, they are quantized with different levels of precision, so you will need to choose a quantization level that is appropriate for your application.&lt;/p&gt; &#xA;&lt;p&gt;Additionally, we support Hugging Face tokenizers to improve the quality of tokenization. These are separate files (&lt;code&gt;tokenizer.json&lt;/code&gt;) that can be used with the CLI using the &lt;code&gt;-v&lt;/code&gt; or &lt;code&gt;-r&lt;/code&gt; flags, or with the &lt;code&gt;llm&lt;/code&gt; crate by using the appropriate &lt;code&gt;TokenizerSource&lt;/code&gt; enum variant.&lt;/p&gt; &#xA;&lt;p&gt;For a list of models that have been tested, see the &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/doc/known-good-models.md&#34;&gt;known-good models&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Certain older GGML formats are not supported by this project, but the goal is to maintain feature parity with the upstream GGML project. For problems relating to loading models, or requesting support for &lt;a href=&#34;https://github.com/ggerganov/ggml#roadmap&#34;&gt;supported GGML model types&lt;/a&gt;, please &lt;a href=&#34;https://github.com/rustformers/llm/issues/new&#34;&gt;open an Issue&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;From Hugging Face&lt;/h3&gt; &#xA;&lt;p&gt;Hugging Face ü§ó is a leader in open-source machine learning and hosts hundreds of GGML models. &lt;a href=&#34;https://huggingface.co/models?search=ggml&#34;&gt;Search for GGML models on Hugging Face ü§ó&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;r/LocalLLaMA&lt;/h3&gt; &#xA;&lt;p&gt;This Reddit community maintains &lt;a href=&#34;https://www.reddit.com/r/LocalLLaMA/wiki/index/&#34;&gt;a wiki&lt;/a&gt; related to GGML models, including well organized lists of links for acquiring &lt;a href=&#34;https://www.reddit.com/r/LocalLLaMA/wiki/models/&#34;&gt;GGML models&lt;/a&gt; (mostly from Hugging Face ü§ó).&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Once the &lt;code&gt;llm&lt;/code&gt; executable has been built or is in a &lt;code&gt;$PATH&lt;/code&gt; directory, try running it. Here&#39;s an example that uses the open-source &lt;a href=&#34;https://huggingface.co/rustformers/redpajama-ggml/blob/main/RedPajama-INCITE-Base-3B-v1-q4_0.bin&#34;&gt;RedPajama&lt;/a&gt; language model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;llm infer -a gptneox -m RedPajama-INCITE-Base-3B-v1-q4_0.bin -p &#34;Rust is a cool programming language because&#34; -r togethercomputer/RedPajama-INCITE-Base-3B-v1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the example above, the first two arguments specify the model architecture and command, respectively. The required &lt;code&gt;-m&lt;/code&gt; argument specifies the local path to the model, and the required &lt;code&gt;-p&lt;/code&gt; argument specifies the evaluation prompt. The optional &lt;code&gt;-r&lt;/code&gt; argument is used to load the model&#39;s tokenizer from a remote Hugging Face ü§ó repository, which will typically improve results when compared to loading the tokenizer from the model file itself; there is also an optional &lt;code&gt;-v&lt;/code&gt; argument that can be used to specify the path to a local tokenizer file. For more information about the &lt;code&gt;llm&lt;/code&gt; CLI, use the &lt;code&gt;--help&lt;/code&gt; parameter.&lt;/p&gt; &#xA;&lt;p&gt;There is also a &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/crates/llm/examples/inference.rs&#34;&gt;simple inference example&lt;/a&gt; that is helpful for &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/.vscode/launch.json&#34;&gt;debugging&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo run --release --example inference gptneox RedPajama-INCITE-Base-3B-v1-q4_0.bin -r $OPTIONAL_VOCAB_REPO -p $OPTIONAL_PROMPT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Q&amp;amp;A&lt;/h2&gt; &#xA;&lt;h3&gt;Does the &lt;code&gt;llm&lt;/code&gt; CLI support chat mode?&lt;/h3&gt; &#xA;&lt;p&gt;Yes, but certain fine-tuned models (e.g. &lt;a href=&#34;https://crfm.stanford.edu/2023/03/13/alpaca.html&#34;&gt;Alpaca&lt;/a&gt;, &lt;a href=&#34;https://lmsys.org/blog/2023-03-30-vicuna/&#34;&gt;Vicuna&lt;/a&gt;, &lt;a href=&#34;https://docs.alpindale.dev/&#34;&gt;Pygmalion&lt;/a&gt;) are more suited to chat use-cases than so-called &#34;base models&#34;. Here&#39;s an example of using the &lt;code&gt;llm&lt;/code&gt; CLI in REPL (Read-Evaluate-Print Loop) mode with an Alpaca model - note that the &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/utils/prompts/alpaca.txt&#34;&gt;provided prompt format&lt;/a&gt; is tailored to the model that is being used:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;llm repl -a llama -m ggml-alpaca-7b-q4.bin -f utils/prompts/alpaca.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There is also a &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/crates/llm/examples/vicuna-chat.rs&#34;&gt;Vicuna chat example&lt;/a&gt; that demonstrates how to create a custom chatbot:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo run --release --example vicuna-chat llama ggml-vicuna-7b-q4.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Can &lt;code&gt;llm&lt;/code&gt; sessions be persisted for later use?&lt;/h3&gt; &#xA;&lt;p&gt;Sessions can be loaded (&lt;code&gt;--load-session&lt;/code&gt;) or saved (&lt;code&gt;--save-session&lt;/code&gt;) to file. To automatically load and save the same session, use &lt;code&gt;--persist-session&lt;/code&gt;. This can be used to cache prompts to reduce load time, too.&lt;/p&gt; &#xA;&lt;h3&gt;How do I use &lt;code&gt;llm&lt;/code&gt; to quantize a model?&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;llm&lt;/code&gt; can produce a &lt;code&gt;q4_0&lt;/code&gt;- or &lt;code&gt;q4_1&lt;/code&gt;-&lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/crates/ggml/README.md#quantization&#34;&gt;quantized&lt;/a&gt; model from an &lt;code&gt;f16&lt;/code&gt;-quantized GGML model&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo run --release quantize -a $MODEL_ARCHITECTURE $MODEL_IN $MODEL_OUT {q4_0,q4_1}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Do you provide support for Docker and NixOS?&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;llm&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/utils/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt; is in the &lt;code&gt;utils&lt;/code&gt; directory; the &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/flake.nix&#34;&gt;NixOS flake&lt;/a&gt; manifest and lockfile are in the project root.&lt;/p&gt; &#xA;&lt;h3&gt;What&#39;s the best way to get in touch with the &lt;code&gt;llm&lt;/code&gt; community?&lt;/h3&gt; &#xA;&lt;p&gt;GitHub &lt;a href=&#34;https://github.com/rustformers/llm/issues/new&#34;&gt;Issues&lt;/a&gt; and &lt;a href=&#34;https://github.com/rustformers/llm/discussions/new&#34;&gt;Discussions&lt;/a&gt; are welcome, or come chat on &lt;a href=&#34;https://discord.gg/YB9WaXYAWU&#34;&gt;Discord&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h3&gt;Do you accept contributions?&lt;/h3&gt; &#xA;&lt;p&gt;Absolutely! Please see the &lt;a href=&#34;https://raw.githubusercontent.com/rustformers/llm/main/doc/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;What applications and libraries use &lt;code&gt;llm&lt;/code&gt;?&lt;/h3&gt; &#xA;&lt;h4&gt;Applications&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rustformers/llmcord&#34;&gt;llmcord&lt;/a&gt;: Discord bot for generating messages using &lt;code&gt;llm&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/louisgv/local.ai&#34;&gt;local.ai&lt;/a&gt;: Desktop app for hosting an inference API on your local machine using &lt;code&gt;llm&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/juliooa/secondbrain&#34;&gt;secondbrain&lt;/a&gt;: Desktop app to download and run LLMs locally in your computer using &lt;code&gt;llm&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://floneum.com/&#34;&gt;floneum&lt;/a&gt;: A graph editor for local AI workflows.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Libraries&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sobelio/llm-chain&#34;&gt;llm-chain&lt;/a&gt;: Build chains in large language models for text summarization and completion of more complex tasks&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>