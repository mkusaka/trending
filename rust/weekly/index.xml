<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-12-01T01:49:28Z</updated>
  <subtitle>Weekly Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>HigherOrderCO/Bend</title>
    <updated>2024-12-01T01:49:28Z</updated>
    <id>tag:github.com,2024-12-01:/HigherOrderCO/Bend</id>
    <link href="https://github.com/HigherOrderCO/Bend" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A massively parallel, high-level programming language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Bend&lt;/h1&gt; &#xA;&lt;p&gt;A high-level, massively parallel programming language&lt;/p&gt; &#xA;&lt;h2&gt;Index&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HigherOrderCO/Bend/main/#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HigherOrderCO/Bend/main/#important-notes&#34;&gt;Important Notes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HigherOrderCO/Bend/main/#install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HigherOrderCO/Bend/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HigherOrderCO/Bend/main/#speedup-examples&#34;&gt;Speedup Example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HigherOrderCO/Bend/main/#additional-resources&#34;&gt;Additional Resources&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Bend offers the feel and features of expressive languages like Python and Haskell. This includes fast object allocations, full support for higher-order functions with closures, unrestricted recursion, and even continuations.&lt;br&gt; Bend scales like CUDA, it runs on massively parallel hardware like GPUs, with nearly linear acceleration based on core count, and without explicit parallelism annotations: no thread creation, locks, mutexes, or atomics.&lt;br&gt; Bend is powered by the &lt;a href=&#34;https://github.com/higherorderco/hvm&#34;&gt;HVM2&lt;/a&gt; runtime.&lt;/p&gt; &#xA;&lt;h2&gt;Important Notes&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bend is designed to excel in scaling performance with cores, supporting over 10000 concurrent threads.&lt;/li&gt; &#xA; &lt;li&gt;The current version may have lower single-core performance.&lt;/li&gt; &#xA; &lt;li&gt;You can expect substantial improvements in performance as we advance our code generation and optimization techniques.&lt;/li&gt; &#xA; &lt;li&gt;We are still working to support Windows. Use &lt;a href=&#34;https://learn.microsoft.com/en-us/windows/wsl/install&#34;&gt;WSL2&lt;/a&gt; as an alternative solution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/HigherOrderCO/Bend/issues/341&#34;&gt;We only support NVIDIA Gpus currently&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;h3&gt;Install dependencies&lt;/h3&gt; &#xA;&lt;h4&gt;On Linux&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Install Rust if you haven&#39;t already.&#xA;curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh&#xA;&#xA;# For the C version of Bend, use GCC. We recommend a version up to 12.x.&#xA;sudo apt install gcc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For the CUDA runtime &lt;a href=&#34;https://developer.nvidia.com/cuda-downloads?target_os=Linux&#34;&gt;install the CUDA toolkit for Linux&lt;/a&gt; version 12.x.&lt;/p&gt; &#xA;&lt;h4&gt;On Mac&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Install Rust if you haven&#39;t it already.&#xA;curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh&#xA;&#xA;# For the C version of Bend, use GCC. We recommend a version up to 12.x.&#xA;brew install gcc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install Bend&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install HVM2 by running:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# HVM2 is HOC&#39;s massively parallel Interaction Combinator evaluator.&#xA;cargo install hvm&#xA;&#xA;# This ensures HVM is correctly installed and accessible.&#xA;hvm --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install Bend by running:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# This command will install Bend&#xA;cargo install bend-lang&#xA;&#xA;# This ensures Bend is correctly installed and accessible.&#xA;bend --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Getting Started&lt;/h3&gt; &#xA;&lt;h4&gt;Running Bend Programs&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bend run    &amp;lt;file.bend&amp;gt; # uses the C interpreter by default (parallel)&#xA;bend run-rs &amp;lt;file.bend&amp;gt; # uses the Rust interpreter (sequential)&#xA;bend run-c  &amp;lt;file.bend&amp;gt; # uses the C interpreter (parallel)&#xA;bend run-cu &amp;lt;file.bend&amp;gt; # uses the CUDA interpreter (massively parallel)&#xA;&#xA;# Notes&#xA;# You can also compile Bend to standalone C/CUDA files using gen-c and gen-cu for maximum performance.&#xA;# The code generator is still in its early stages and not as mature as compilers like GCC and GHC.&#xA;# You can use the -s flag to have more information on&#xA;  # Reductions&#xA;  # Time the code took to run&#xA;  # Interaction per second (In millions)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Testing Bend Programs&lt;/h4&gt; &#xA;&lt;p&gt;The example below sums all the numbers in the range from &lt;code&gt;start&lt;/code&gt; to &lt;code&gt;target&lt;/code&gt;. It can be written in two different methods: one that is inherently sequential (and thus cannot be parallelized), and another that is easily parallelizable. (We will be using the &lt;code&gt;-s&lt;/code&gt;flag in most examples, for the sake of visibility)&lt;/p&gt; &#xA;&lt;h4&gt;Sequential version:&lt;/h4&gt; &#xA;&lt;p&gt;First, create a file named &lt;code&gt;sequential_sum.bend&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Write this command on your terminal&#xA;touch sequential_sum.bend&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then with your text editor, open the file &lt;code&gt;sequential_sum.bend&lt;/code&gt;, copy the code below and paste in the file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# Defines the function Sum with two parameters: start and target&#xA;def Sum(start, target):&#xA;  if start == target:&#xA;    # If the value of start is the same as target, returns start.&#xA;    return start&#xA;  else:&#xA;    # If start is not equal to target, recursively call Sum with&#xA;    # start incremented by 1, and add the result to start.&#xA;    return start + Sum(start + 1, target)  &#xA;&#xA;def main():&#xA;  # This translates to (1 + (2 + (3 + (...... + (999999 + 1000000)))))&#xA;  # Note that this will overflow the maximum value of a number in Bend&#xA;  return Sum(1, 1_000_000)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Running the file&lt;/h5&gt; &#xA;&lt;p&gt;You can run it using Rust interpreter (Sequential)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bend run sequential_sum.bend -s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or you can run it using C interpreter (Sequential)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bend run-c sequential_sum.bend -s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have a NVIDIA GPU, you can also run in CUDA (Sequential)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bend run-cu sequential_sum.bend -s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In this version, the next value to be calculated depends on the previous sum, meaning that it cannot proceed until the current computation is complete. Now, let&#39;s look at the easily parallelizable version.&lt;/p&gt; &#xA;&lt;h4&gt;Parallelizable version:&lt;/h4&gt; &#xA;&lt;p&gt;First close the old file and then proceed to your terminal to create &lt;code&gt;parallel_sum.bend&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Write this command on your terminal&#xA;touch parallel_sum.bend&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then with your text editor, open the file &lt;code&gt;parallel_sum.bend&lt;/code&gt;, copy the code below and paste in the file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# Defines the function Sum with two parameters: start and target&#xA;def Sum(start, target):&#xA;  if start == target:&#xA;    # If the value of start is the same as target, returns start.&#xA;    return start&#xA;  else:&#xA;    # If start is not equal to target, calculate the midpoint (half),&#xA;    # then recursively call Sum on both halves.&#xA;    half = (start + target) / 2&#xA;    left = Sum(start, half)  # (Start -&amp;gt; Half)&#xA;    right = Sum(half + 1, target)&#xA;    return left + right&#xA;&#xA;# A parallelizable sum of numbers from 1 to 1000000&#xA;def main():&#xA;  # This translates to (((1 + 2) + (3 + 4)) + ... (999999 + 1000000)...)&#xA;  return Sum(1, 1_000_000)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In this example, the (3 + 4) sum does not depend on the (1 + 2), meaning that it can run in parallel because both computations can happen at the same time.&lt;/p&gt; &#xA;&lt;h5&gt;Running the file&lt;/h5&gt; &#xA;&lt;p&gt;You can run it using Rust interpreter (Sequential)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bend run parallel_sum.bend -s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or you can run it using C interpreter (Parallel)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bend run-c parallel_sum.bend -s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have a NVIDIA GPU, you can also run in CUDA (Massively parallel)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bend run-cu parallel_sum.bend -s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In Bend, it can be parallelized by just changing the run command. If your code &lt;strong&gt;can&lt;/strong&gt; run in parallel it &lt;strong&gt;will&lt;/strong&gt; run in parallel.&lt;/p&gt; &#xA;&lt;h3&gt;Speedup Examples&lt;/h3&gt; &#xA;&lt;p&gt;The code snippet below implements a &lt;a href=&#34;https://en.wikipedia.org/wiki/Bitonic_sorter&#34;&gt;bitonic sorter&lt;/a&gt; with &lt;em&gt;immutable tree rotations&lt;/em&gt;. It&#39;s not the type of algorithm you would expect to run fast on GPUs. However, since it uses a divide and conquer approach, which is inherently parallel, Bend will execute it on multiple threads, no thread creation, no explicit lock management.&lt;/p&gt; &#xA;&lt;h4&gt;Bitonic Sorter Benchmark&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;bend run&lt;/code&gt;: CPU, Apple M3 Max: 12.15 seconds&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;bend run-c&lt;/code&gt;: CPU, Apple M3 Max: 0.96 seconds&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;bend run-cu&lt;/code&gt;: GPU, NVIDIA RTX 4090: 0.21 seconds&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Click here for the Bitonic Sorter code&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# Sorting Network = just rotate trees!&#xA;def sort(d, s, tree):&#xA;  switch d:&#xA;    case 0:&#xA;      return tree&#xA;    case _:&#xA;      (x,y) = tree&#xA;      lft   = sort(d-1, 0, x)&#xA;      rgt   = sort(d-1, 1, y)&#xA;      return rots(d, s, (lft, rgt))&#xA;&#xA;# Rotates sub-trees (Blue/Green Box)&#xA;def rots(d, s, tree):&#xA;  switch d:&#xA;    case 0:&#xA;      return tree&#xA;    case _:&#xA;      (x,y) = tree&#xA;      return down(d, s, warp(d-1, s, x, y))&#xA;&#xA;# Swaps distant values (Red Box)&#xA;def warp(d, s, a, b):&#xA;  switch d:&#xA;    case 0:&#xA;      return swap(s ^ (a &amp;gt; b), a, b)&#xA;    case _:&#xA;      (a.a, a.b) = a&#xA;      (b.a, b.b) = b&#xA;      (A.a, A.b) = warp(d-1, s, a.a, b.a)&#xA;      (B.a, B.b) = warp(d-1, s, a.b, b.b)&#xA;      return ((A.a,B.a),(A.b,B.b))&#xA;&#xA;# Propagates downwards&#xA;def down(d,s,t):&#xA;  switch d:&#xA;    case 0:&#xA;      return t&#xA;    case _:&#xA;      (t.a, t.b) = t&#xA;      return (rots(d-1, s, t.a), rots(d-1, s, t.b))&#xA;&#xA;# Swaps a single pair&#xA;def swap(s, a, b):&#xA;  switch s:&#xA;    case 0:&#xA;      return (a,b)&#xA;    case _:&#xA;      return (b,a)&#xA;&#xA;# Testing&#xA;# -------&#xA;&#xA;# Generates a big tree&#xA;def gen(d, x):&#xA;  switch d:&#xA;    case 0:&#xA;      return x&#xA;    case _:&#xA;      return (gen(d-1, x * 2 + 1), gen(d-1, x * 2))&#xA;&#xA;# Sums a big tree&#xA;def sum(d, t):&#xA;  switch d:&#xA;    case 0:&#xA;      return t&#xA;    case _:&#xA;      (t.a, t.b) = t&#xA;      return sum(d-1, t.a) + sum(d-1, t.b)&#xA;&#xA;# Sorts a big tree&#xA;def main:&#xA;  return sum(20, sort(20, 0, gen(20, 0)))&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;if you are interested in some other algorithms, you can check our &lt;a href=&#34;https://github.com/HigherOrderCO/Bend/tree/main/examples&#34;&gt;examples folder&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Additional Resources&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To understand the technology behind Bend, check out the HVM2 &lt;a href=&#34;https://paper.higherorderco.com/&#34;&gt;paper&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;We are working on an official documentation, meanwhile for a more in depth explanation check &lt;a href=&#34;https://github.com/HigherOrderCO/Bend/raw/main/GUIDE.md&#34;&gt;GUIDE.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Read about our features at &lt;a href=&#34;https://github.com/HigherOrderCO/Bend/raw/main/FEATURES.md&#34;&gt;FEATURES.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Bend is developed by &lt;a href=&#34;https://higherorderco.com/&#34;&gt;HigherOrderCO&lt;/a&gt; - join our &lt;a href=&#34;https://discord.higherorderco.com&#34;&gt;Discord&lt;/a&gt;!&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>awslabs/aws-lambda-web-adapter</title>
    <updated>2024-12-01T01:49:28Z</updated>
    <id>tag:github.com,2024-12-01:/awslabs/aws-lambda-web-adapter</id>
    <link href="https://github.com/awslabs/aws-lambda-web-adapter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Run web applications on AWS Lambda&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AWS Lambda Web Adapter&lt;/h1&gt; &#xA;&lt;p&gt;A tool to run web applications on AWS Lambda&lt;/p&gt; &#xA;&lt;p&gt;AWS Lambda Web Adapter allows developers to build web apps (http api) with familiar frameworks (e.g. Express.js, Next.js, Flask, SpringBoot, ASP.NET and Laravel, anything speaks HTTP 1.1/1.0) and run it on AWS Lambda. The same docker image can run on AWS Lambda, Amazon EC2, AWS Fargate, and local computers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/docs/images/lambda-adapter-overview.png&#34; alt=&#34;Lambda Web Adapter&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run web applications on AWS Lambda&lt;/li&gt; &#xA; &lt;li&gt;Supports Amazon API Gateway Rest API and Http API endpoints, Lambda Function URLs, and Application Load Balancer&lt;/li&gt; &#xA; &lt;li&gt;Supports Lambda managed runtimes, custom runtimes and docker OCI images&lt;/li&gt; &#xA; &lt;li&gt;Supports any web frameworks and languages, no new code dependency to include&lt;/li&gt; &#xA; &lt;li&gt;Automatic encode binary response&lt;/li&gt; &#xA; &lt;li&gt;Enables graceful shutdown&lt;/li&gt; &#xA; &lt;li&gt;Supports response payload compression&lt;/li&gt; &#xA; &lt;li&gt;Supports response streaming&lt;/li&gt; &#xA; &lt;li&gt;Supports non-http event triggers&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;AWS Lambda Web Adapter work with Lambda functions packaged as both docker images and Zip packages.&lt;/p&gt; &#xA;&lt;h3&gt;Lambda functions packaged as Docker Images or OCI Images&lt;/h3&gt; &#xA;&lt;p&gt;To use Lambda Web Adapter with docker images, package your web app (http api) in a Dockerfile, and add one line to copy Lambda Web Adapter binary to /opt/extensions inside your container:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;COPY --from=public.ecr.aws/awsguru/aws-lambda-adapter:0.8.4 /lambda-adapter /opt/extensions/lambda-adapter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/images-create.html&#34;&gt;Non-AWS base images&lt;/a&gt; may be used since the &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/images-create.html#images-ric&#34;&gt;Runtime Interface Client&lt;/a&gt; ships with the Lambda Web Adapter.&lt;/p&gt; &#xA;&lt;p&gt;By default, Lambda Web Adapter assumes the web app is listening on port 8080. If not, you can specify the port via &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/#configurations&#34;&gt;configuration&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Pre-compiled Lambda Web Adapter binaries are provided in ECR public repo: &lt;a href=&#34;https://gallery.ecr.aws/awsguru/aws-lambda-adapter&#34;&gt;public.ecr.aws/awsguru/aws-lambda-adapter&lt;/a&gt;. Multi-arch images are also provided in this repo. It works on both x86_64 and arm64 CPU architecture.&lt;/p&gt; &#xA;&lt;p&gt;Below is a Dockerfile for &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/expressjs&#34;&gt;an example nodejs application&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;FROM public.ecr.aws/docker/library/node:20-slim&#xA;COPY --from=public.ecr.aws/awsguru/aws-lambda-adapter:0.8.4 /lambda-adapter /opt/extensions/lambda-adapter&#xA;ENV PORT=7000&#xA;WORKDIR &#34;/var/task&#34;&#xA;ADD src/package.json /var/task/package.json&#xA;ADD src/package-lock.json /var/task/package-lock.json&#xA;RUN npm install --omit=dev&#xA;ADD src/ /var/task&#xA;CMD [&#34;node&#34;, &#34;index.js&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This works with any base images except AWS managed base images. To use AWS managed base images, you need to override the ENTRYPOINT to start your web app.&lt;/p&gt; &#xA;&lt;h3&gt;Lambda functions packaged as Zip package for AWS managed runtimes&lt;/h3&gt; &#xA;&lt;p&gt;AWS Lambda Web Adapter also works with AWS managed Lambda runtimes. You need to do three things:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;attach Lambda Web Adapter layer to your function.&lt;/p&gt; &lt;h4&gt;AWS Commercial Regions&lt;/h4&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;x86_64: &lt;code&gt;arn:aws:lambda:${AWS::Region}:753240598075:layer:LambdaAdapterLayerX86:23&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;arm64: &lt;code&gt;arn:aws:lambda:${AWS::Region}:753240598075:layer:LambdaAdapterLayerArm64:23&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;h4&gt;AWS China Regions&lt;/h4&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;cn-north-1 (Beijing) &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;x86_64: &lt;code&gt;arn:aws-cn:lambda:cn-north-1:041581134020:layer:LambdaAdapterLayerX86:23&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;cn-northwest-1 (Ningxia) &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;x86_64: &lt;code&gt;arn:aws-cn:lambda:cn-northwest-1:069767869989:layer:LambdaAdapterLayerX86:23&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;configure Lambda environment variable &lt;code&gt;AWS_LAMBDA_EXEC_WRAPPER&lt;/code&gt; to &lt;code&gt;/opt/bootstrap&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;set function handler to your web application start up script. e.g. &lt;code&gt;run.sh&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For details, please check out &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/expressjs-zip&#34;&gt;the example Node.js application&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Readiness Check&lt;/h2&gt; &#xA;&lt;p&gt;When a new Lambda Execution Environment starts up, Lambda Web Adapter will boot up as a Lambda Extension, followed by the web application.&lt;/p&gt; &#xA;&lt;p&gt;By default, Lambda Web Adapter will send HTTP GET requests to the web application at &lt;code&gt;http://127.0.0.1:8080/&lt;/code&gt;. The port and path can be customized with two environment variables: &lt;code&gt;AWS_LWA_READINESS_CHECK_PORT&lt;/code&gt; and &lt;code&gt;AWS_LWA_READINESS_CHECK_PATH&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Lambda Web Adapter will retry this request every 10 milliseconds until the web application returns an HTTP response (&lt;strong&gt;status code &amp;gt;= 100 and &amp;lt; 500&lt;/strong&gt;) or the function times out.&lt;/p&gt; &#xA;&lt;p&gt;In addition, you can configure the adapter to preform readiness check with TCP connect, by setting &lt;code&gt;AWS_LWA_READINESS_CHECK_PROTOCOL&lt;/code&gt; to &lt;code&gt;tcp&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;After passing readiness check, Lambda Web Adapter will start Lambda Runtime and forward the invokes to the web application.&lt;/p&gt; &#xA;&lt;h2&gt;Configurations&lt;/h2&gt; &#xA;&lt;p&gt;The readiness check port/path and traffic port can be configured using environment variables. These environment variables can be defined either within docker file or as Lambda function configuration.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Environment Variable&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Default&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_PORT / PORT*&lt;/td&gt; &#xA;   &lt;td&gt;traffic port&lt;/td&gt; &#xA;   &lt;td&gt;&#34;8080&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_READINESS_CHECK_PORT / READINESS_CHECK_PORT*&lt;/td&gt; &#xA;   &lt;td&gt;readiness check port, default to the traffic port&lt;/td&gt; &#xA;   &lt;td&gt;PORT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_READINESS_CHECK_PATH / READINESS_CHECK_PATH*&lt;/td&gt; &#xA;   &lt;td&gt;readiness check path&lt;/td&gt; &#xA;   &lt;td&gt;&#34;/&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_READINESS_CHECK_PROTOCOL / READINESS_CHECK_PROTOCOL*&lt;/td&gt; &#xA;   &lt;td&gt;readiness check protocol: &#34;http&#34; or &#34;tcp&#34;, default is &#34;http&#34;&lt;/td&gt; &#xA;   &lt;td&gt;&#34;http&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_READINESS_CHECK_MIN_UNHEALTHY_STATUS&lt;/td&gt; &#xA;   &lt;td&gt;The minimum HTTP status code that is considered unhealthy&lt;/td&gt; &#xA;   &lt;td&gt;&#34;500&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_ASYNC_INIT / ASYNC_INIT*&lt;/td&gt; &#xA;   &lt;td&gt;enable asynchronous initialization for long initialization functions&lt;/td&gt; &#xA;   &lt;td&gt;&#34;false&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_REMOVE_BASE_PATH / REMOVE_BASE_PATH*&lt;/td&gt; &#xA;   &lt;td&gt;the base path to be removed from request path&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_ENABLE_COMPRESSION&lt;/td&gt; &#xA;   &lt;td&gt;enable gzip compression for response body&lt;/td&gt; &#xA;   &lt;td&gt;&#34;false&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_INVOKE_MODE&lt;/td&gt; &#xA;   &lt;td&gt;Lambda function invoke mode: &#34;buffered&#34; or &#34;response_stream&#34;, default is &#34;buffered&#34;&lt;/td&gt; &#xA;   &lt;td&gt;&#34;buffered&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_PASS_THROUGH_PATH&lt;/td&gt; &#xA;   &lt;td&gt;the path for receiving event payloads that are passed through from non-http triggers&lt;/td&gt; &#xA;   &lt;td&gt;&#34;/events&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AWS_LWA_AUTHORIZATION_SOURCE&lt;/td&gt; &#xA;   &lt;td&gt;a header name to be replaced to &lt;code&gt;Authorization&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We use &#34;AWS_LWA_&#34; prefix to namespacing all environment variables used by Lambda Web Adapter. The original ones will be supported until we reach version 1.0.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;AWS_LWA_PORT / PORT&lt;/strong&gt; - Lambda Web Adapter will send traffic to this port. This is the port your web application listening on. Inside Lambda execution environment, the web application runs as a non-root user, and not allowed to listen on ports lower than 1024. Please also avoid port 9001 and 3000. Lambda Runtime API is on port 9001. CloudWatch Lambda Insight extension uses port 3000.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AWS_LWA_ASYNC_INIT / ASYNC_INIT&lt;/strong&gt; - Lambda managed runtimes offer up to 10 seconds for function initialization. During this period of time, Lambda functions have burst of CPU to accelerate initialization, and it is free. If a lambda function couldn&#39;t complete the initialization within 10 seconds, Lambda will restart the function, and bill for the initialization. To help functions to use this 10 seconds free initialization time and avoid the restart, Lambda Web Adapter supports asynchronous initialization. When this feature is enabled, Lambda Web Adapter performs readiness check up to 9.8 seconds. If the web app is not ready by then, Lambda Web Adapter signals to Lambda service that the init is completed, and continues readiness check in the handler. This feature is disabled by default. Enable it by setting environment variable &lt;code&gt;AWS_LWA_ASYNC_INIT&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AWS_LWA_REMOVE_BASE_PATH / REMOVE_BASE_PATH&lt;/strong&gt; - The value of this environment variable tells the adapter whether the application is running under a base path. For example, you could have configured your API Gateway to have a /orders/{proxy+} and a /catalog/{proxy+} resource. Each resource is handled by a separate Lambda functions. For this reason, the application inside Lambda may not be aware of the fact that the /orders path exists. Use REMOVE_BASE_PATH to remove the /orders prefix when routing requests to the application. Defaults to empty string. Checkout &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/springboot&#34;&gt;SpringBoot&lt;/a&gt; example.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AWS_LWA_ENABLE_COMPRESSION&lt;/strong&gt; - Lambda Web Adapter supports gzip compression for response body. This feature is disabled by default. Enable it by setting environment variable &lt;code&gt;AWS_LWA_ENABLE_COMPRESSION&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;. When enabled, this will compress responses unless it&#39;s an image as determined by the content-type starting with &lt;code&gt;image&lt;/code&gt; or the response is less than 32 bytes. This will also compress HTTP/1.1 chunked streaming response.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AWS_LWA_INVOKE_MODE&lt;/strong&gt; - Lambda function invoke mode, this should match Function Url invoke mode. The default is &#34;buffered&#34;. When configured as &#34;response_stream&#34;, Lambda Web Adapter will stream response to Lambda service &lt;a href=&#34;https://aws.amazon.com/blogs/compute/introducing-aws-lambda-response-streaming/&#34;&gt;blog&lt;/a&gt;. Please check out &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fastapi-response-streaming&#34;&gt;FastAPI with Response Streaming&lt;/a&gt; example.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AWS_LWA_READINESS_CHECK_MIN_UNHEALTHY_STATUS&lt;/strong&gt; - allows you to customize which HTTP status codes are considered healthy and which ones are not&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AWS_LWA_PASS_THROUGH_PATH&lt;/strong&gt; - Path to receive events payloads passed through from non-http event triggers. The default is &#34;/events&#34;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AWS_LWA_AUTHORIZATION_SOURCE&lt;/strong&gt; - When set, Lambda Web Adapter replaces the specified header name to &lt;code&gt;Authorization&lt;/code&gt; before proxying a request. This is useful when you use Lambda function URL with &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/urls-auth.html&#34;&gt;IAM auth type&lt;/a&gt;, which reserves Authorization header for IAM authentication, but you want to still use Authorization header for your backend apps. This feature is disabled by default.&lt;/p&gt; &#xA;&lt;h2&gt;Request Context&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Request Context&lt;/strong&gt; is metadata API Gateway sends to Lambda for a request. It usually contains requestId, requestTime, apiId, identity, and authorizer. Identity and authorizer are useful to get client identity for authorization. API Gateway Developer Guide contains more details &lt;a href=&#34;https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html#api-gateway-simple-proxy-for-lambda-input-format&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Lambda Web Adapter forwards this information to the web application in a Http Header named &#34;x-amzn-request-context&#34;. In the web application, you can retrieve the value of this http header and deserialize it into a JSON object. Check out &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/expressjs-zip&#34;&gt;Express.js in Zip&lt;/a&gt; on how to use it.&lt;/p&gt; &#xA;&lt;h2&gt;Lambda Context&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Lambda Context&lt;/strong&gt; is an object that Lambda passes to the function handler. This object provides information about the invocation, function, and execution environment. You can find a full list of properties accessible through the Lambda Context &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/nodejs-context.html&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Lambda Web Adapter forwards this information to the web application in a Http Header named &#34;x-amzn-lambda-context&#34;. In the web application, you can retrieve the value of this http header and deserialize it into a JSON object. Check out &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/expressjs-zip&#34;&gt;Express.js in Zip&lt;/a&gt; on how to use it.&lt;/p&gt; &#xA;&lt;h2&gt;Graceful Shutdown&lt;/h2&gt; &#xA;&lt;p&gt;For a function with Lambda Extensions registered, Lambda enables shutdown phase for the function. When Lambda service is about to shut down a Lambda execution environment, it sends a SIGTERM signal to the runtime and then a SHUTDOWN event to each registered external extensions. Developers could catch the SIGTERM signal in the lambda functions and perform graceful shutdown tasks. The &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/expressjs/app/src/index.js&#34;&gt;Express.js&lt;/a&gt; gives a simple example. More details in &lt;a href=&#34;https://github.com/aws-samples/graceful-shutdown-with-aws-lambda&#34;&gt;this repo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Local Debugging&lt;/h2&gt; &#xA;&lt;p&gt;Lambda Web Adapter allows developers to develop web applications locally with familiar tools and debuggers: just run the web app locally and test it. If you want to simulate Lambda Runtime environment locally, you can use AWS SAM CLI. The following command starts a local api gateway endpoint and simulate the Lambda runtime execution environment.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sam local start-api&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please note that &lt;code&gt;sam local&lt;/code&gt; starts a Lambda Runtime Interface Emulator on port 8080. So your web application should avoid port &lt;code&gt;8080&lt;/code&gt; if you plan to use &lt;code&gt;sam local&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Non-HTTP Event Triggers&lt;/h2&gt; &#xA;&lt;p&gt;The Lambda Web Adapter also supports all non-HTTP event triggers, such as SQS, SNS, S3, DynamoDB, Kinesis, Kafka, EventBridge, and Bedrock Agents. The adapter forwards the event payload to the web application via http post to a path defined by the &lt;code&gt;AWS_LWA_PASS_THROUGH_PATH&lt;/code&gt; environment variable. By default, this path is set to &lt;code&gt;/events&lt;/code&gt;. Upon receiving the event payload from the request body, the web application should processes it and returns the results as a JSON response. Please checkout &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/sqs-expressjs&#34;&gt;SQS Express.js&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/bedrock-agent-fastapi-zip&#34;&gt;Bedrock Agent FastAPI in Zip&lt;/a&gt; examples.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fastapi&#34;&gt;FastAPI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fastapi-zip&#34;&gt;FastAPI in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fastapi-background-tasks&#34;&gt;FastAPI with Background Tasks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fastapi-response-streaming&#34;&gt;FastAPI with Response Streaming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fastapi-response-streaming-zip&#34;&gt;FastAPI with Response Streaming in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fastapi-backend-only-response-streaming/&#34;&gt;FastAPI Response Streaming Backend with IAM Auth&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/flask&#34;&gt;Flask&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/flask-zip&#34;&gt;Flask in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aws-hebrew-book/serverless-django&#34;&gt;Serverless Django&lt;/a&gt; by &lt;a href=&#34;https://github.com/efi-mk&#34;&gt;@efi-mk&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/expressjs&#34;&gt;Express.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/expressjs-zip&#34;&gt;Express.js in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/nextjs&#34;&gt;Next.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/nextjs-zip&#34;&gt;Next.js in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/nextjs-response-streaming&#34;&gt;Next.js Response Streaming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/springboot&#34;&gt;SpringBoot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/springboot-zip&#34;&gt;SpringBoot in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/springboot-response-streaming-zip&#34;&gt;SpringBoot Response Streaming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/nginx&#34;&gt;Nginx&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/php&#34;&gt;PHP&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/rust-actix-web-zip&#34;&gt;Rust Actix Web in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/rust-axum-zip&#34;&gt;Rust Axum in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/gin&#34;&gt;Golang Gin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/gin-zip&#34;&gt;Golang Gin in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/deno-zip&#34;&gt;Deno Oak in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aws-samples/lambda-laravel&#34;&gt;Laravel on Lambda&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/aspnet-mvc&#34;&gt;ASP.NET MVC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/aspnet-mvc-zip&#34;&gt;ASP.NET MVC in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/aspnet-webapi-zip&#34;&gt;ASP.NET Web API in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/sqs-expressjs&#34;&gt;SQS Express.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/bedrock-agent-fastapi&#34;&gt;Bedrock Agent FastAPI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/bedrock-agent-fastapi-zip&#34;&gt;Bedrock Agent FastAPI in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fasthtml&#34;&gt;FastHTML&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fasthtml-zip&#34;&gt;FastHTML in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fasthtml-response-streaming&#34;&gt;FastHTML with Response Streaming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/fasthtml-response-streaming-zip&#34;&gt;FastHTML with Response Streaming in Zip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/remix/&#34;&gt;Remix&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/examples/remix-zip/&#34;&gt;Remix in Zip&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This project was inspired by several community projects.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/apparentorder/reweb&#34;&gt;re:Web&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glassechidna/serverlessish&#34;&gt;Serverlessish&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Similar Projects&lt;/h2&gt; &#xA;&lt;p&gt;Several projects also provide similar capabilities as language specific packages/frameworks.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/aws-serverless-java-container&#34;&gt;Serverless Java Container&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vendia/serverless-express&#34;&gt;Serverless Express&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zappa/Zappa&#34;&gt;Serverless Python - Zappa&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/customink/lamby&#34;&gt;Serverless Rails - Lamby&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/brefphp/bref&#34;&gt;Serverless PHP - Bref&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/aws-lambda-web-adapter/main/CONTRIBUTING.md#security-issue-notifications&#34;&gt;CONTRIBUTING&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache-2.0 License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>tensorzero/tensorzero</title>
    <updated>2024-12-01T01:49:28Z</updated>
    <id>tag:github.com,2024-12-01:/tensorzero/tensorzero</id>
    <link href="https://github.com/tensorzero/tensorzero" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TensorZero creates a feedback loop for optimizing LLM applications — turning production data into smarter, faster, and cheaper models.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9&#34; width=&#34;128&#34; height=&#34;128&#34;&gt; &#xA;&lt;h1&gt;TensorZero&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;TensorZero creates a feedback loop for optimizing LLM applications — turning production data into smarter, faster, and cheaper models.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Integrate our model gateway&lt;/li&gt; &#xA; &lt;li&gt;Send metrics or feedback&lt;/li&gt; &#xA; &lt;li&gt;Optimize prompts, models, and inference strategies&lt;/li&gt; &#xA; &lt;li&gt;Watch your LLMs improve over time&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;It provides a &lt;strong&gt;data &amp;amp; learning flywheel for LLMs&lt;/strong&gt; by unifying:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Inference:&lt;/strong&gt; one API for all LLMs, with &amp;lt;1ms P99 overhead&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Observability:&lt;/strong&gt; inference &amp;amp; feedback → your database&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Optimization:&lt;/strong&gt; from prompts to fine-tuning and RL (&amp;amp; even 🍓? &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations&#34;&gt;→&lt;/a&gt;&lt;/strong&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Experimentation:&lt;/strong&gt; built-in A/B testing, routing, fallbacks&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/&#34; target=&#34;_blank&#34;&gt;Website&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs&#34; target=&#34;_blank&#34;&gt;Docs&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href=&#34;https://www.x.com/tensorzero&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/slack&#34; target=&#34;_blank&#34;&gt;Slack&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/discord&#34; target=&#34;_blank&#34;&gt;Discord&lt;/a&gt;&lt;/b&gt; &lt;br&gt; &lt;br&gt; &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/quickstart&#34; target=&#34;_blank&#34;&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/tutorial&#34; target=&#34;_blank&#34;&gt;Comprehensive Tutorial&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/deployment&#34; target=&#34;_blank&#34;&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/api-reference&#34; target=&#34;_blank&#34;&gt;API Reference&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/deployment&#34; target=&#34;_blank&#34;&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.tensorzero.com/docs&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270&#34;&gt; &#xA;   &lt;img alt=&#34;TensorZero Flywheel&#34; src=&#34;https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6&#34; width=&#34;720&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/&#34;&gt;TensorZero Gateway&lt;/a&gt;&lt;/strong&gt; is a high-performance model gateway written in Rust 🦀 that provides a unified API interface for all major LLM providers, allowing for seamless cross-platform integration and fallbacks.&lt;/li&gt; &#xA; &lt;li&gt;It handles structured schema-based inference with &amp;lt;1ms P99 latency overhead (see &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/benchmarks&#34;&gt;Benchmarks&lt;/a&gt;&lt;/strong&gt;) and built-in observability, experimentation, and &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations&#34;&gt;inference-time optimizations&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;It also collects downstream metrics and feedback associated with these inferences, with first-class support for multi-step LLM systems.&lt;/li&gt; &#xA; &lt;li&gt;Everything is stored in a ClickHouse data warehouse that you control for real-time, scalable, and developer-friendly analytics.&lt;/li&gt; &#xA; &lt;li&gt;Over time, &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/recipes&#34;&gt;TensorZero Recipes&lt;/a&gt;&lt;/strong&gt; leverage this structured dataset to optimize your prompts and models: run pre-built recipes for common workflows like fine-tuning, or create your own with complete flexibility using any language and platform.&lt;/li&gt; &#xA; &lt;li&gt;Finally, the gateway&#39;s experimentation features and GitOps orchestration enable you to iterate and deploy with confidence, be it a single LLM or thousands of LLMs.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Our goal is to help engineers build, manage, and optimize the next generation of LLM applications: systems that learn from real-world experience. Read more about our &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/vision-roadmap/&#34;&gt;Vision &amp;amp; Roadmap&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Next steps?&lt;/strong&gt; The &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; shows it&#39;s easy to set up an LLM application with TensorZero. If you want to dive deeper, the &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/tutorial&#34;&gt;Tutorial&lt;/a&gt;&lt;/strong&gt; teaches how to build a simple chatbot, an email copilot, a weather RAG system, and a structured data extraction pipeline.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Questions?&lt;/strong&gt; Ask us on &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/slack&#34;&gt;Slack&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/discord&#34;&gt;Discord&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Using TensorZero at work?&lt;/strong&gt; Email us at &lt;strong&gt;&lt;a href=&#34;mailto:hello@tensorzero.com&#34;&gt;hello@tensorzero.com&lt;/a&gt;&lt;/strong&gt; to set up a Slack or Teams channel with your team (free).&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;We are working on a series of &lt;strong&gt;complete runnable examples&lt;/strong&gt; illustrating TensorZero&#39;s data &amp;amp; learning flywheel.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences&#34;&gt;Writing Haikus to Satisfy a Judge with Hidden Preferences&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste. You&#39;ll see TensorZero&#39;s &#34;data flywheel in a box&#34; in action: better variants leads to better data, and better data leads to better variants. You&#39;ll see progress by fine-tuning the LLM multiple times.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/ner-fine-tuning&#34;&gt;Improving Data Extraction (NER) by Fine-Tuning a Llama 3 Model&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example shows that an optimized Llama 3.1 8B model can be trained to outperform GPT-4o on a Named Entity Recognition (NER) task using a small amount of training data, and served by Fireworks at a fraction of the cost and latency.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles-best-of-n-sampling/&#34;&gt;Improving LLM Chess Ability with Best-of-N Sampling&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example showcases how best-of-N sampling can significantly enhance an LLM&#39;s chess-playing abilities by selecting the most promising moves from multiple generated options.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/ner-dicl&#34;&gt;Improving Data Extraction (NER) with Dynamic In-Context Learning&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example demonstrates how Dynamic In-Context Learning (DICL) can enhance Named Entity Recognition (NER) performance by leveraging relevant historical examples to improve data extraction accuracy and consistency without having to fine-tune a model.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy&#34;&gt;Improving Math Reasoning with a Custom Recipe for Automated Prompt Engineering (DSPy)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;TensorZero provides a number of pre-built optimization recipes covering common LLM engineering workflows. But you can also easily create your own recipes and workflows! This example shows how to optimize a TensorZero function using an arbitrary tool — here, DSPy.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;em&gt;&amp;amp; many more on the way!&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
</feed>