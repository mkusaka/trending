<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-25T01:53:57Z</updated>
  <subtitle>Weekly Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>astral-sh/uv</title>
    <updated>2024-02-25T01:53:57Z</updated>
    <id>tag:github.com,2024-02-25:/astral-sh/uv</id>
    <link href="https://github.com/astral-sh/uv" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An extremely fast Python package installer and resolver, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;uv&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/astral-sh/uv&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json&#34; alt=&#34;uv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/uv&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/uv.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/uv&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/l/uv.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/uv&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/astral-sh/uv/actions&#34;&gt;&lt;img src=&#34;https://github.com/astral-sh/uv/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;Actions status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/astral-sh&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;An extremely fast Python package installer and resolver, written in Rust. Designed as a drop-in replacement for &lt;code&gt;pip&lt;/code&gt; and &lt;code&gt;pip-compile&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;uv is backed by &lt;a href=&#34;https://astral.sh&#34;&gt;Astral&lt;/a&gt;, the creators of &lt;a href=&#34;https://github.com/astral-sh/ruff&#34;&gt;Ruff&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Highlights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚öñÔ∏è Drop-in replacement for common &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt; commands.&lt;/li&gt; &#xA; &lt;li&gt;‚ö°Ô∏è &lt;a href=&#34;https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md&#34;&gt;10-100x faster&lt;/a&gt; than &lt;code&gt;pip&lt;/code&gt; and &lt;code&gt;pip-tools&lt;/code&gt; (&lt;code&gt;pip-compile&lt;/code&gt; and &lt;code&gt;pip-sync&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;üíæ Disk-space efficient, with a global cache for dependency deduplication.&lt;/li&gt; &#xA; &lt;li&gt;üêç Installable via &lt;code&gt;curl&lt;/code&gt;, &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, etc. uv is a static binary that can be installed without Rust or Python.&lt;/li&gt; &#xA; &lt;li&gt;üß™ Tested at-scale against the top 10,000 PyPI packages.&lt;/li&gt; &#xA; &lt;li&gt;üñ•Ô∏è Support for macOS, Linux, and Windows.&lt;/li&gt; &#xA; &lt;li&gt;üß∞ Advanced features such as &lt;a href=&#34;https://raw.githubusercontent.com/astral-sh/uv/main/#dependency-overrides&#34;&gt;dependency version overrides&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/astral-sh/uv/main/#resolution-strategy&#34;&gt;alternative resolution strategies&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;‚ÅâÔ∏è Best-in-class error messages with a conflict-tracking resolver.&lt;/li&gt; &#xA; &lt;li&gt;ü§ù Support for a wide range of advanced &lt;code&gt;pip&lt;/code&gt; features, including editable installs, Git dependencies, direct URL dependencies, local dependencies, constraints, source distributions, HTML and JSON indexes, and more.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Install uv with our standalone installers, or from &lt;a href=&#34;https://pypi.org/project/uv/&#34;&gt;PyPI&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# On macOS and Linux.&#xA;curl -LsSf https://astral.sh/uv/install.sh | sh&#xA;&#xA;# On Windows.&#xA;powershell -c &#34;irm https://astral.sh/uv/install.ps1 | iex&#34;&#xA;&#xA;# With pip.&#xA;pip install uv&#xA;&#xA;# With pipx.&#xA;pipx install uv&#xA;&#xA;# With Homebrew.&#xA;brew install uv&#xA;&#xA;# With Pacman.&#xA;pacman -S uv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To create a virtual environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;uv venv  # Create a virtual environment at .venv.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To activate the virtual environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# On macOS and Linux.&#xA;source .venv/bin/activate&#xA;&#xA;# On Windows.&#xA;.venv\Scripts\activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install a package into the virtual environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;uv pip install flask                # Install Flask.&#xA;uv pip install -r requirements.txt  # Install from a requirements.txt file.&#xA;uv pip install -e .                 # Install the current project in editable mode.&#xA;uv pip install &#34;package @ .&#34;        # Install the current project from disk&#xA;uv pip install &#34;flask[dotenv]&#34;      # Install Flask with &#34;dotenv&#34; extra.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate a set of locked dependencies from an input file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;uv pip compile pyproject.toml -o requirements.txt   # Read a pyproject.toml file.&#xA;uv pip compile requirements.in -o requirements.txt  # Read a requirements.in file.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To sync a set of locked dependencies with the virtual environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;uv pip sync requirements.txt  # Install from a requirements.txt file.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;uv&#39;s &lt;code&gt;pip-install&lt;/code&gt; and &lt;code&gt;pip-compile&lt;/code&gt; commands support many of the same command-line arguments as existing tools, including &lt;code&gt;-r requirements.txt&lt;/code&gt;, &lt;code&gt;-c constraints.txt&lt;/code&gt;, &lt;code&gt;-e .&lt;/code&gt; (for editable installs), &lt;code&gt;--index-url&lt;/code&gt;, and more.&lt;/p&gt; &#xA;&lt;h2&gt;Limitations&lt;/h2&gt; &#xA;&lt;p&gt;uv does not support the entire &lt;code&gt;pip&lt;/code&gt; feature set. Namely, uv does not (and does not plan to) support the following &lt;code&gt;pip&lt;/code&gt; features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;.egg&lt;/code&gt; dependencies&lt;/li&gt; &#xA; &lt;li&gt;Editable installs for Git and direct URL dependencies (editable installs &lt;em&gt;are&lt;/em&gt; supported for local dependencies)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;On the other hand, uv plans to (but does not currently) support:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/astral-sh/uv/issues/474&#34;&gt;Hash-checking mode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/astral-sh/uv/issues/313&#34;&gt;URL requirements without package names&lt;/a&gt; (e.g., &lt;code&gt;https://...&lt;/code&gt; instead of &lt;code&gt;package @ https://...&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Like &lt;code&gt;pip-compile&lt;/code&gt;, uv generates a platform-specific &lt;code&gt;requirements.txt&lt;/code&gt; file (unlike, e.g., &lt;code&gt;poetry&lt;/code&gt; and &lt;code&gt;pdm&lt;/code&gt;, which generate platform-agnostic &lt;code&gt;poetry.lock&lt;/code&gt; and &lt;code&gt;pdm.lock&lt;/code&gt; files). As such, uv&#39;s &lt;code&gt;requirements.txt&lt;/code&gt; files may not be portable across platforms and Python versions.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;uv is an extremely fast Python package resolver and installer, designed as a drop-in replacement for &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt; (&lt;code&gt;pip-compile&lt;/code&gt; and &lt;code&gt;pip-sync&lt;/code&gt;), and &lt;code&gt;virtualenv&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;uv represents an intermediary goal in our pursuit of a &lt;a href=&#34;https://blog.rust-lang.org/2016/05/05/cargo-pillars.html#pillars-of-cargo&#34;&gt;&#34;Cargo for Python&#34;&lt;/a&gt;: a comprehensive project and package manager that is extremely fast, reliable, and easy to use.&lt;/p&gt; &#xA;&lt;p&gt;Think: a single binary that bootstraps your Python installation and gives you everything you need to be productive with Python, bundling not only &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt;, but also &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;tox&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;ruff&lt;/code&gt;, and more.&lt;/p&gt; &#xA;&lt;p&gt;Our goal is to evolve uv into such a tool.&lt;/p&gt; &#xA;&lt;p&gt;In the meantime, though, the narrower &lt;code&gt;pip-tools&lt;/code&gt; scope allows us to solve the low-level problems involved in building such a tool (like package installation) while shipping something immediately useful with a minimal barrier to adoption.&lt;/p&gt; &#xA;&lt;h2&gt;Advanced Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Python discovery&lt;/h3&gt; &#xA;&lt;p&gt;uv itself does not depend on Python, but it does need to locate a Python environment to (1) install dependencies into the environment and (2) build source distributions.&lt;/p&gt; &#xA;&lt;p&gt;When running &lt;code&gt;pip sync&lt;/code&gt; or &lt;code&gt;pip install&lt;/code&gt;, uv will search for a virtual environment in the following order:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;An activated virtual environment based on the &lt;code&gt;VIRTUAL_ENV&lt;/code&gt; environment variable.&lt;/li&gt; &#xA; &lt;li&gt;An activated Conda environment based on the &lt;code&gt;CONDA_PREFIX&lt;/code&gt; environment variable.&lt;/li&gt; &#xA; &lt;li&gt;A virtual environment at &lt;code&gt;.venv&lt;/code&gt; in the current directory, or in the nearest parent directory.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If no virtual environment is found, uv will prompt the user to create one in the current directory via &lt;code&gt;uv venv&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When running &lt;code&gt;pip compile&lt;/code&gt;, uv does not &lt;em&gt;require&lt;/em&gt; a virtual environment and will search for a Python interpreter in the following order:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;An activated virtual environment based on the &lt;code&gt;VIRTUAL_ENV&lt;/code&gt; environment variable.&lt;/li&gt; &#xA; &lt;li&gt;An activated Conda environment based on the &lt;code&gt;CONDA_PREFIX&lt;/code&gt; environment variable.&lt;/li&gt; &#xA; &lt;li&gt;A virtual environment at &lt;code&gt;.venv&lt;/code&gt; in the current directory, or in the nearest parent directory.&lt;/li&gt; &#xA; &lt;li&gt;The Python interpreter available as &lt;code&gt;python3&lt;/code&gt; on macOS and Linux, or &lt;code&gt;python.exe&lt;/code&gt; on Windows.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If a &lt;code&gt;--python-version&lt;/code&gt; is provided to &lt;code&gt;pip compile&lt;/code&gt; (e.g., &lt;code&gt;--python-version=3.7&lt;/code&gt;), uv will search for a Python interpreter matching that version in the following order:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;An activated virtual environment based on the &lt;code&gt;VIRTUAL_ENV&lt;/code&gt; environment variable.&lt;/li&gt; &#xA; &lt;li&gt;An activated Conda environment based on the &lt;code&gt;CONDA_PREFIX&lt;/code&gt; environment variable.&lt;/li&gt; &#xA; &lt;li&gt;A virtual environment at &lt;code&gt;.venv&lt;/code&gt; in the current directory, or in the nearest parent directory.&lt;/li&gt; &#xA; &lt;li&gt;The Python interpreter available as, e.g., &lt;code&gt;python3.7&lt;/code&gt; on macOS and Linux. On Windows, uv will use the same mechanism as &lt;code&gt;py --list-paths&lt;/code&gt; to discover all available Python interpreters, and will select the first interpreter matching the requested version.&lt;/li&gt; &#xA; &lt;li&gt;The Python interpreter available as &lt;code&gt;python3&lt;/code&gt; on macOS and Linux, or &lt;code&gt;python.exe&lt;/code&gt; on Windows.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Since uv has no dependency on Python, it can even install into virtual environments other than its own. For example, setting &lt;code&gt;VIRTUAL_ENV=/path/to/venv&lt;/code&gt; will cause uv to install into &lt;code&gt;/path/to/venv&lt;/code&gt;, no matter where uv is installed.&lt;/p&gt; &#xA;&lt;h3&gt;Git authentication&lt;/h3&gt; &#xA;&lt;p&gt;uv allows packages to be installed from Git and supports the following schemes for authenticating with private repositories.&lt;/p&gt; &#xA;&lt;p&gt;Using SSH:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;git+ssh://git@&amp;lt;hostname&amp;gt;/...&lt;/code&gt; (e.g. &lt;code&gt;git+ssh://git@github.com/astral-sh/uv&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;git+ssh://git@&amp;lt;host&amp;gt;/...&lt;/code&gt; (e.g. &lt;code&gt;git+ssh://git@github.com-key-2/astral-sh/uv&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://docs.github.com/en/authentication/connecting-to-github-with-ssh/about-ssh&#34;&gt;GitHub SSH documentation&lt;/a&gt; for more details on how to configure SSH.&lt;/p&gt; &#xA;&lt;p&gt;Using a password or token:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;git+https://&amp;lt;user&amp;gt;:&amp;lt;token&amp;gt;@&amp;lt;hostname&amp;gt;/...&lt;/code&gt; (e.g. &lt;code&gt;git+https://git:github_pat_asdf@github.com/astral-sh/uv&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;git+https://&amp;lt;token&amp;gt;@&amp;lt;hostname&amp;gt;/...&lt;/code&gt; (e.g. &lt;code&gt;git+https://github_pat_asdf@github.com/astral-sh/uv&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;git+https://&amp;lt;user&amp;gt;@&amp;lt;hostname&amp;gt;/...&lt;/code&gt; (e.g. &lt;code&gt;git+https://git@github.com/astral-sh/uv&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When using a GitHub personal access token, the username is arbitrary. GitHub does not support logging in with password directly, although other hosts may. If a username is provided without credentials, you will be prompted to enter them.&lt;/p&gt; &#xA;&lt;p&gt;If there are no credentials present in the URL and authentication is needed, the &lt;a href=&#34;https://git-scm.com/doc/credential-helpers&#34;&gt;Git credential helper&lt;/a&gt; will be queried.&lt;/p&gt; &#xA;&lt;h3&gt;Dependency caching&lt;/h3&gt; &#xA;&lt;p&gt;uv uses aggressive caching to avoid re-downloading (and re-building dependencies) that have already been accessed in prior runs.&lt;/p&gt; &#xA;&lt;p&gt;The specifics of uv&#39;s caching semantics vary based on the nature of the dependency:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;For registry dependencies&lt;/strong&gt; (like those downloaded from PyPI), uv respects HTTP caching headers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;For direct URL dependencies&lt;/strong&gt;, uv respects HTTP caching headers, and also caches based on the URL itself.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;For Git dependencies&lt;/strong&gt;, uv caches based on the fully-resolved Git commit hash. As such, &lt;code&gt;uv pip compile&lt;/code&gt; will pin Git dependencies to a specific commit hash when writing the resolved dependency set.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;For local dependencies&lt;/strong&gt;, uv caches based on the last-modified time of the &lt;code&gt;setup.py&lt;/code&gt; or &lt;code&gt;pyproject.toml&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you&#39;re running into caching issues, uv includes a few escape hatches:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To force uv to revalidate cached data for all dependencies, run &lt;code&gt;uv pip install --refresh ...&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;To force uv to revalidate cached data for a specific dependency, run, e.g., &lt;code&gt;uv pip install --refresh-package flask ...&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;To force uv to ignore existing installed versions, run &lt;code&gt;uv pip install --reinstall ...&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;To clear the global cache entirely, run &lt;code&gt;uv cache clean&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Resolution strategy&lt;/h3&gt; &#xA;&lt;p&gt;By default, uv follows the standard Python dependency resolution strategy of preferring the latest compatible version of each package. For example, &lt;code&gt;uv pip install flask&amp;gt;=2.0.0&lt;/code&gt; will install the latest version of Flask (at time of writing: &lt;code&gt;3.0.0&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;However, uv&#39;s resolution strategy can be configured to support alternative workflows. With &lt;code&gt;--resolution=lowest&lt;/code&gt;, uv will install the &lt;strong&gt;lowest&lt;/strong&gt; compatible versions for all dependencies, both &lt;strong&gt;direct&lt;/strong&gt; and &lt;strong&gt;transitive&lt;/strong&gt;. Alternatively, &lt;code&gt;--resolution=lowest-direct&lt;/code&gt; will opt for the &lt;strong&gt;lowest&lt;/strong&gt; compatible versions for all &lt;strong&gt;direct&lt;/strong&gt; dependencies, while using the &lt;strong&gt;latest&lt;/strong&gt; compatible versions for all &lt;strong&gt;transitive&lt;/strong&gt; dependencies. This distinction can be particularly useful for library authors who wish to test against the lowest supported versions of direct dependencies without restricting the versions of transitive dependencies.&lt;/p&gt; &#xA;&lt;p&gt;For example, given the following &lt;code&gt;requirements.in&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;flask&amp;gt;=2.0.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Running &lt;code&gt;uv pip compile requirements.in&lt;/code&gt; would produce the following &lt;code&gt;requirements.txt&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;# This file was autogenerated by uv via the following command:&#xA;#    uv pip compile requirements.in&#xA;blinker==1.7.0&#xA;    # via flask&#xA;click==8.1.7&#xA;    # via flask&#xA;flask==3.0.0&#xA;itsdangerous==2.1.2&#xA;    # via flask&#xA;jinja2==3.1.2&#xA;    # via flask&#xA;markupsafe==2.1.3&#xA;    # via&#xA;    #   jinja2&#xA;    #   werkzeug&#xA;werkzeug==3.0.1&#xA;    # via flask&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;However, &lt;code&gt;uv pip compile --resolution=lowest requirements.in&lt;/code&gt; would instead produce:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;# This file was autogenerated by uv via the following command:&#xA;#    uv pip compile requirements.in --resolution=lowest&#xA;click==7.1.2&#xA;    # via flask&#xA;flask==2.0.0&#xA;itsdangerous==2.0.0&#xA;    # via flask&#xA;jinja2==3.0.0&#xA;    # via flask&#xA;markupsafe==2.0.0&#xA;    # via jinja2&#xA;werkzeug==2.0.0&#xA;    # via flask&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pre-release handling&lt;/h3&gt; &#xA;&lt;p&gt;By default, uv will accept pre-release versions during dependency resolution in two cases:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;If the package is a direct dependency, and its version markers include a pre-release specifier (e.g., &lt;code&gt;flask&amp;gt;=2.0.0rc1&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;If &lt;em&gt;all&lt;/em&gt; published versions of a package are pre-releases.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If dependency resolution fails due to a transitive pre-release, uv will prompt the user to re-run with &lt;code&gt;--prerelease=allow&lt;/code&gt;, to allow pre-releases for all dependencies.&lt;/p&gt; &#xA;&lt;p&gt;Alternatively, you can add the transitive dependency to your &lt;code&gt;requirements.in&lt;/code&gt; file with pre-release specifier (e.g., &lt;code&gt;flask&amp;gt;=2.0.0rc1&lt;/code&gt;) to opt in to pre-release support for that specific dependency.&lt;/p&gt; &#xA;&lt;p&gt;Pre-releases are &lt;a href=&#34;https://pubgrub-rs-guide.netlify.app/limitations/prerelease_versions&#34;&gt;notoriously difficult&lt;/a&gt; to model, and are a frequent source of bugs in other packaging tools. uv&#39;s pre-release handling is &lt;em&gt;intentionally&lt;/em&gt; limited and &lt;em&gt;intentionally&lt;/em&gt; requires user intervention to opt in to pre-releases to ensure correctness, though pre-release handling will be revisited in future releases.&lt;/p&gt; &#xA;&lt;h3&gt;Dependency overrides&lt;/h3&gt; &#xA;&lt;p&gt;Historically, &lt;code&gt;pip&lt;/code&gt; has supported &#34;constraints&#34; (&lt;code&gt;-c constraints.txt&lt;/code&gt;), which allows users to narrow the set of acceptable versions for a given package.&lt;/p&gt; &#xA;&lt;p&gt;uv supports constraints, but also takes this concept further by allowing users to &lt;em&gt;override&lt;/em&gt; the acceptable versions of a package across the dependency tree via overrides (&lt;code&gt;--override overrides.txt&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;In short, overrides allow the user to lie to the resolver by overriding the declared dependencies of a package. Overrides are a useful last resort for cases in which the user knows that a dependency is compatible with a newer version of a package than the package declares, but the package has not yet been updated to declare that compatibility.&lt;/p&gt; &#xA;&lt;p&gt;For example, if a transitive dependency declares &lt;code&gt;pydantic&amp;gt;=1.0,&amp;lt;2.0&lt;/code&gt;, but the user knows that the package is compatible with &lt;code&gt;pydantic&amp;gt;=2.0&lt;/code&gt;, the user can override the declared dependency with &lt;code&gt;pydantic&amp;gt;=2.0,&amp;lt;3&lt;/code&gt; to allow the resolver to continue.&lt;/p&gt; &#xA;&lt;p&gt;While constraints are purely &lt;em&gt;additive&lt;/em&gt;, and thus cannot &lt;em&gt;expand&lt;/em&gt; the set of acceptable versions for a package, overrides &lt;em&gt;can&lt;/em&gt; expand the set of acceptable versions for a package, providing an escape hatch for erroneous upper version bounds.&lt;/p&gt; &#xA;&lt;h3&gt;Multi-version resolution&lt;/h3&gt; &#xA;&lt;p&gt;uv&#39;s &lt;code&gt;pip-compile&lt;/code&gt; command produces a resolution that&#39;s known to be compatible with the current platform and Python version. Unlike Poetry, PDM, and other package managers, uv does not yet produce a machine-agnostic lockfile.&lt;/p&gt; &#xA;&lt;p&gt;However, uv &lt;em&gt;does&lt;/em&gt; support resolving for alternate Python versions via the &lt;code&gt;--python-version&lt;/code&gt; command line argument. For example, if you&#39;re running uv on Python 3.9, but want to resolve for Python 3.8, you can run &lt;code&gt;uv pip compile --python-version=3.8 requirements.in&lt;/code&gt; to produce a Python 3.8-compatible resolution.&lt;/p&gt; &#xA;&lt;h2&gt;Platform support&lt;/h2&gt; &#xA;&lt;p&gt;uv has Tier 1 support for the following platforms:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;macOS (Apple Silicon)&lt;/li&gt; &#xA; &lt;li&gt;macOS (x86_64)&lt;/li&gt; &#xA; &lt;li&gt;Linux (x86_64)&lt;/li&gt; &#xA; &lt;li&gt;Windows (x86_64)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;uv is continuously built, tested, and developed against its Tier 1 platforms. Inspired by the Rust project, Tier 1 can be thought of as &lt;a href=&#34;https://doc.rust-lang.org/beta/rustc/platform-support.html&#34;&gt;&#34;guaranteed to work&#34;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;uv has Tier 2 support (&lt;a href=&#34;https://doc.rust-lang.org/beta/rustc/platform-support.html&#34;&gt;&#34;guaranteed to build&#34;&lt;/a&gt;) for the following platforms:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Linux (PPC64)&lt;/li&gt; &#xA; &lt;li&gt;Linux (PPC64LE)&lt;/li&gt; &#xA; &lt;li&gt;Linux (aarch64)&lt;/li&gt; &#xA; &lt;li&gt;Linux (armv7)&lt;/li&gt; &#xA; &lt;li&gt;Linux (i686)&lt;/li&gt; &#xA; &lt;li&gt;Linux (s390x)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;uv ships pre-built wheels to &lt;a href=&#34;https://pypi.org/project/uv/&#34;&gt;PyPI&lt;/a&gt; for its Tier 1 and Tier 2 platforms. However, while Tier 2 platforms are continuously built, they are not continuously tested or developed against, and so stability may vary in practice.&lt;/p&gt; &#xA;&lt;p&gt;Beyond the Tier 1 and Tier 2 platforms, uv is known to build on i686 Windows, and known &lt;em&gt;not&lt;/em&gt; to build on aarch64 Windows, but does not consider either platform to be supported at this time.&lt;/p&gt; &#xA;&lt;p&gt;uv supports and is tested against Python 3.8, 3.9, 3.10, 3.11, and 3.12.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;uv&#39;s dependency resolver uses &lt;a href=&#34;https://github.com/pubgrub-rs/pubgrub&#34;&gt;PubGrub&lt;/a&gt; under the hood. We&#39;re grateful to the PubGrub maintainers, especially &lt;a href=&#34;https://github.com/Eh2406&#34;&gt;Jacob Finkelman&lt;/a&gt;, for their support.&lt;/p&gt; &#xA;&lt;p&gt;uv&#39;s Git implementation is based on &lt;a href=&#34;https://github.com/rust-lang/cargo&#34;&gt;Cargo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Some of uv&#39;s optimizations are inspired by the great work we&#39;ve seen in &lt;a href=&#34;https://pnpm.io/&#34;&gt;pnpm&lt;/a&gt;, &lt;a href=&#34;https://github.com/orogene/orogene&#34;&gt;Orogene&lt;/a&gt;, and &lt;a href=&#34;https://github.com/oven-sh/bun&#34;&gt;Bun&lt;/a&gt;. We&#39;ve also learned a lot from Nathaniel J. Smith&#39;s &lt;a href=&#34;https://github.com/njsmith/posy&#34;&gt;Posy&lt;/a&gt; and adapted its &lt;a href=&#34;https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline&#34;&gt;trampoline&lt;/a&gt; for Windows support.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;uv is licensed under either of&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Apache License, Version 2.0, (&lt;a href=&#34;https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE&#34;&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;MIT license (&lt;a href=&#34;https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT&#34;&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;https://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;at your option.&lt;/p&gt; &#xA;&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a target=&#34;_blank&#34; href=&#34;https://astral.sh&#34; style=&#34;background:none&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true&#34; alt=&#34;Made by Astral&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>succinctlabs/sp1</title>
    <updated>2024-02-25T01:53:57Z</updated>
    <id>tag:github.com,2024-02-25:/succinctlabs/sp1</id>
    <link href="https://github.com/succinctlabs/sp1" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A performant, 100% open-source, contributor-friendly zkVM.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SP1&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://t.me/succinct_sp1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?color=neon&amp;amp;logo=telegram&amp;amp;label=chat&amp;amp;url=https://tg.sumanjay.workers.dev/succinct_sp1&#34; alt=&#34;Telegram Chat&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/succinctlabs/sp1/main/assets/sp1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;SP1 is a performant, 100% open-source, contributor-friendly zero-knowledge virtual machine (zkVM) that can prove the execution of arbitrary Rust (or any LLVM-compiled language) programs. SP1 democratizes access to ZKPs by allowing developers to use programmable truth with popular programming languages.&lt;/p&gt; &#xA;&lt;p&gt;SP1 is inspired by the open-source software movement and takes a collaborative approach towards building the best zkVM for rollups, coprocessors and other ZKP applications. We envision a diversity of contributors integrating the latest ZK innovations, creating a zkVM that is &lt;em&gt;performant&lt;/em&gt;, &lt;em&gt;customizable&lt;/em&gt; and will stand the &lt;em&gt;test of time&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://succinctlabs.github.io/sp1/getting-started/install.html&#34;&gt;Install&lt;/a&gt;&lt;/strong&gt; | &lt;a href=&#34;https://succinctlabs.github.io/sp1&#34;&gt;Docs&lt;/a&gt; | &lt;a href=&#34;https://github.com/succinctlabs/sp1/tree/main/examples&#34;&gt;Examples&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;For Developers: Build with SP1&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note that SP1 is still in alpha and is not yet ready for production use.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Today, developers can write programs, including complex, large programs like a ZK Tendermint light client, in Rust (with std support), generate proofs and verify them. Most Rust crates should be supported and can be used seamlessly by your program. Example programs can be found in the &lt;a href=&#34;https://github.com/succinctlabs/sp1/tree/main/examples&#34;&gt;examples&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;p&gt;To get started, make sure you have &lt;a href=&#34;https://www.rust-lang.org/tools/install&#34;&gt;Rust&lt;/a&gt; installed. Then follow the &lt;a href=&#34;https://succinctlabs.github.io/sp1/getting-started/install.html&#34;&gt;installation&lt;/a&gt; guide in the SP1 book and read the &lt;a href=&#34;https://succinctlabs.github.io/sp1/getting-started/quickstart.html&#34;&gt;getting started&lt;/a&gt; section.&lt;/p&gt; &#xA;&lt;p&gt;For developers looking for inspiration on what to build, check out the open issues with the &lt;a href=&#34;https://github.com/succinctlabs/sp1/issues?q=is%3Aopen+is%3Aissue+label%3Ashowcase&#34;&gt;showcase&lt;/a&gt; label to see what sorts of programs that showcase the capabilities of SP1 are interesting to hack on.&lt;/p&gt; &#xA;&lt;h2&gt;For Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Open-source is a core part of SP1&#39;s ethos and key to its advantages. We wish to cultivate a vibrant community of open-source contributors that span individuals, teams and geographies. If you want to contribute, or follow along with contributor discussion, you can use our main Telegram to chat with us. Our contributor guidelines can be found in &lt;a href=&#34;https://raw.githubusercontent.com/succinctlabs/sp1/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Find a list of &lt;a href=&#34;https://github.com/succinctlabs/sp1/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22+&#34;&gt;good first issues&lt;/a&gt; in the open issues of this repo. We are always looking for contributors interested in tasks big and small, including minor chores across the codebase, optimizing performance, adding precompiles for commonly used cryptographic operations, adding documentation, creating new example programs and more. Please reach out in the Telegram chat if interested!&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;Today, SP1 can generate and verify proofs for Rust programs that have been compiled to RISC-V. SP1 supports proving of programs of arbitrary length by using a unique &#34;shared challenges&#34; argument that allows the prover to shard a long computation into small shards, and then generate a global proof that these shards are properly connected together.&lt;/p&gt; &#xA;&lt;p&gt;The main priorities in the next few months are performance optimizations, getting the core zkVM constraint logic audited, as well as wrapping the SP1 STARK proof into a SNARK proof that is cheaply verifiable in the EVM (by adapting similar &lt;a href=&#34;https://github.com/succinctlabs/gnark-plonky2-verifier&#34;&gt;previous work&lt;/a&gt; done by the Succinct Team).&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;We would like to acknowledge the projects below whose previous work has been instrumental in making this project a reality:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Plonky3/Plonky3&#34;&gt;Plonky3&lt;/a&gt;: The SP1&#39;s prover is powered by the Plonky3 toolkit.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/valida-xyz/valida&#34;&gt;Valida&lt;/a&gt;: The SP1 cross-table lookup architecture, prover, borrow macro, and chip design are inspired by Valida.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/risc0/risc0&#34;&gt;RISC0&lt;/a&gt;: The SP1 Rust toolchain and install/build scripts for the toolchain borrow code from RISC0.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Tips&lt;/h2&gt; &#xA;&lt;p&gt;We recommend you install the &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=rust-lang.rust-analyzer&#34;&gt;rust-analyzer&lt;/a&gt; extension. Note that if you use &lt;code&gt;cargo prove new&lt;/code&gt; inside a monorepo, you will need to add the manifest file to &lt;code&gt;rust-analyzer.linkedProjects&lt;/code&gt; to get full IDE support.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>vosen/ZLUDA</title>
    <updated>2024-02-25T01:53:57Z</updated>
    <id>tag:github.com,2024-02-25:/vosen/ZLUDA</id>
    <link href="https://github.com/vosen/ZLUDA" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CUDA on AMD GPUs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ZLUDA&lt;/h1&gt; &#xA;&lt;p&gt;ZLUDA lets you run unmodified CUDA applications with near-native performance on &lt;del&gt;Intel&lt;/del&gt; AMD GPUs.&lt;/p&gt; &#xA;&lt;p&gt;ZLUDA is currently alpha quality, but it has been confirmed to work with a variety of native CUDA applications: Geekbench, 3DF Zephyr, Blender, Reality Capture, LAMMPS, NAMD, waifu2x, OpenFOAM, Arnold (proof of concept) and more.&lt;/p&gt; &#xA;&lt;p&gt;If you want to give it a try, download it from Release page to the right and read &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/#usage&#34;&gt;Usage&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/#known-issues&#34;&gt;Known Issues&lt;/a&gt; sections below. If you are interested in its history and future read &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/#faq&#34;&gt;FAQ&lt;/a&gt; section further below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/geekbench.svg?sanitize=true&#34; alt=&#34;geekbench.svg&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;p&gt;Using command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;ZLUDA_DIRECTORY&amp;gt;\zluda.exe -- &amp;lt;APPLICATION&amp;gt; &amp;lt;APPLICATION_ARGUMENTS&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you downloaded a ZIP file with the release and unpacked it, then &lt;code&gt;&amp;lt;ZLUDA_DIRECTORY&amp;gt;&lt;/code&gt; is the &lt;code&gt;zluda&lt;/code&gt; directory you have just unpacked.&lt;br&gt; If you are building from source, then &lt;code&gt;&amp;lt;ZLUDA_DIRECTORY&amp;gt;&lt;/code&gt; is subdirectory &lt;code&gt;target\release&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Linux&lt;/h3&gt; &#xA;&lt;p&gt;Using command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;LD_LIBRARY_PATH=&#34;&amp;lt;ZLUDA_DIRECTORY&amp;gt;:$LD_LIBRARY_PATH&#34; &amp;lt;APPLICATION&amp;gt; &amp;lt;APPLICATION_ARGUMENTS&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you downloaded a ZIP file with the release and unpacked it, then &lt;code&gt;&amp;lt;ZLUDA_DIRECTORY&amp;gt;&lt;/code&gt; is the &lt;code&gt;zluda&lt;/code&gt; directory you have just unpacked.&lt;br&gt; If you are building from source, then &lt;code&gt;&amp;lt;ZLUDA_DIRECTORY&amp;gt;&lt;/code&gt; is subdirectory &lt;code&gt;target\release&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Build&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;Make sure you have the following installed:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Git&lt;/li&gt; &#xA; &lt;li&gt;CMake&lt;/li&gt; &#xA; &lt;li&gt;Python 3&lt;/li&gt; &#xA; &lt;li&gt;Rust (1.66.1 or newer)&lt;/li&gt; &#xA; &lt;li&gt;C++ compiler&lt;/li&gt; &#xA; &lt;li&gt;(Linux only) ROCm 5.7+ (&lt;em&gt;not ROCm 6&lt;/em&gt;) (&lt;a href=&#34;https://rocm.docs.amd.com/en/latest/deploy/linux/install_overview.html&#34;&gt;https://rocm.docs.amd.com/en/latest/deploy/linux/install_overview.html&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;(Windows only) Recent AMD Radeon Software Adrenalin (&lt;a href=&#34;https://rocm.docs.amd.com/en/latest/deploy/linux/install_overview.html&#34;&gt;https://rocm.docs.amd.com/en/latest/deploy/linux/install_overview.html&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;(Recommended, optional) Ninja (&lt;a href=&#34;https://ninja-build.org/&#34;&gt;https://ninja-build.org/&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Alternatively, if you are building for Linux, &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/.devcontainer&#34;&gt;.devcontainer&lt;/a&gt; directory contains various developer Dockerfiles with all the required dependencies&lt;/p&gt; &#xA;&lt;h3&gt;Checkout&lt;/h3&gt; &#xA;&lt;p&gt;Checkout ZLUDA code with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone --recurse-submodules https://github.com/vosen/zluda.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Build&lt;/h3&gt; &#xA;&lt;p&gt;Build by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cargo xtask --release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Unknown issues&lt;/h2&gt; &#xA;&lt;p&gt;If an application fails to start under ZLUDA or crashes please check &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/#known-issues&#34;&gt;Known Issues&lt;/a&gt; section below. If nothing there applies, then please read &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/TROUBLESHOOTING.md&#34;&gt;TROUBLESHOOTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Known Issues&lt;/h2&gt; &#xA;&lt;h3&gt;Hardware&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;If both integrated AMD GPU and dedicated AMD GPU are present in the system, ZLUDA uses the integrated GPU.&lt;/p&gt; &lt;p&gt;This is a bug in underying ROCm/HIP runtime. You can work around it by disabling the integrated GPU.&lt;/p&gt; &lt;p&gt;On Windows we recommend you use environment variable &lt;code&gt;HIP_VISIBLE_DEVICES=1&lt;/code&gt; environment variable (more &lt;a href=&#34;https://rocmdocs.amd.com/en/latest/conceptual/gpu-isolation.html#hip-visible-devices&#34;&gt;here&lt;/a&gt;) or disable it system-wide in Device Manager.&lt;/p&gt; &lt;p&gt;On Linux we recommend you use environment variable &lt;code&gt;ROCR_VISIBLE_DEVICES=&amp;lt;UUID&amp;gt;&lt;/code&gt; where &lt;code&gt;&amp;lt;UUID&amp;gt;&lt;/code&gt; is the UUID of the dedicated GPU as reported by &lt;code&gt;rocminfo&lt;/code&gt; command line tool (you can also use &lt;code&gt;HIP_VISIBLE_DEVICES=1&lt;/code&gt;, but this does not seem to be stable). Alternatively you can disable integrated GPU system-wide by passing &lt;code&gt;pci-stub.ids=&amp;lt;DEVICE_VENDOR&amp;gt;:&amp;lt;DEVICE_CODE&amp;gt;&lt;/code&gt; to the kernel options. On Ubuntu you can pass additional kernel options by adding them to &lt;code&gt;/etc/default/grub&lt;/code&gt; to the option &lt;code&gt;GRUB_CMDLINE_LINUX_DEFAULT&lt;/code&gt;. You can find &lt;code&gt;&amp;lt;DEVICE_VENDOR&amp;gt;:&amp;lt;DEVICE_CODE&amp;gt;&lt;/code&gt; with the help of &lt;code&gt;lspci -nn&lt;/code&gt;. This will emit a series of lines with one of them matching you integrated GPU, for example:&lt;br&gt; &lt;code&gt;1b:00.0 VGA compatible controller [0300]: Advanced Micro Devices, Inc. [AMD/ATI] Device [1002:164e] (rev c1)&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;lt;DEVICE_VENDOR&amp;gt;:&amp;lt;DEVICE_CODE&amp;gt;&lt;/code&gt; ar at the end, in this case &lt;code&gt;1002:164e&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Integrated GPUs (as tested with Radeon 680M) work in a limited way. Some rarely used GPU operations (abort, printf, etc.) will hang or crash the application. Additionally, performance library support (cuBLAS, cuDNN, etc.) might be limited, rendering more complex applications inoperable.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ZLUDA can use AMD server GPUs (as tested with Instinct MI200) with a caveat.&lt;/p&gt; &lt;p&gt;On Server GPUs, ZLUDA can compile CUDA GPU code to run in one of two modes:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fast mode, which is faster, but can make exotic (but correct) GPU code hang.&lt;/li&gt; &#xA;   &lt;li&gt;Slow mode, which should make GPU code more stable, but can prevent some applications from running on ZLUDA.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;By default, ZLUDA uses fast mode. That&#39;s because:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;There&#39;s a huge performance difference, fast mode can be twice as fast.&lt;/li&gt; &#xA;   &lt;li&gt;The code patterns that can trip fast mode were not encountered across multiple projects (SPECFEM3D, QUDA, CHroma, MILC, Kokkos, LAMMPS, OpenFOAM, XGBoost, NAMD, LAMMPS).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;You can use environment variable &lt;code&gt;ZLUDA_WAVE64_SLOW_MODE=1&lt;/code&gt; to force compilation in slow mode.&lt;/p&gt; &lt;p&gt;Nothing of that applies to desktop and integrated GPUs (RDNA family).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Software&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Applications using ZLUDA are slow to start.&lt;/p&gt; &lt;p&gt;On the first start ZLUDA needs to compile GPU code for the application. This is a one-time cost, compiled GPU code is cached in &lt;code&gt;%LOCALAPPDATA%&lt;/code&gt; on Windows and in &lt;code&gt;$XDG_CACHE_HOME&lt;/code&gt; or &lt;code&gt;$HOME/.cache&lt;/code&gt; on Linux.&lt;br&gt; Some applications will gradually load the GPU code as it is used. If that is undesirable you can try setting environment variable &lt;code&gt;CUDA_MODULE_LOADING=EAGER&lt;/code&gt;. It depends on how the application was programmed, but it might force to load (and compile) all the kernels on startup, no matter if they are used or not.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Applications running ZLUDA might produce slightly different values&lt;/p&gt; &lt;p&gt;Firstly, ZLUDA ignores some of the floating point denormal and rounding mode information present in the kernels. Secondly, for certain approximate (not IEEE 754) NVIDIA floating point operations in CUDA, ZLUDA blindly uses approximate AMD floating point operations. The two might have a different precision.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;CUDA 12+&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Application built with CUDA 12 and using Thrust crashes with &lt;code&gt;LLVM ERROR: unsupported libcall legalization&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;This is a ROCm/HIP bug. Currently, CUDA applications built with CUDA versions pre-12 work the best. Building with CUDA 12 and a pre-CUDA 12 Thrust might also work.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;OptiX&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ZLUDA has a bare-minimum OptiX implementation for Arnold. See details in &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/#arnold&#34;&gt;Arnold&lt;/a&gt; section.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Windows&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Antivirus flags ZLUDA as malware.&lt;/p&gt; &lt;p&gt;ZLUDA launcher (&lt;code&gt;zluda.exe&lt;/code&gt;) uses some of the techniques used by malware, but for good. &lt;code&gt;zluda.exe&lt;/code&gt; hijacks the process and redirects all uses of the original NVIDIA&#39;s CUDA libraries to use ZLUDA&#39;s CUDA instead.&lt;/p&gt; &lt;p&gt;&lt;u&gt;Don&#39;t use &lt;code&gt;zluda.exe&lt;/code&gt; with games that use anti-cheat.&lt;/u&gt; ZLUDA does not support CUDA gaming workloads (PhysX or DLSS) and anti-cheat might mistake &lt;code&gt;zluda.exe&lt;/code&gt; for a malware or a cheat.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Following error when launching an application with &lt;code&gt;zluda.exe&lt;/code&gt;: &lt;code&gt;Error: OsError { function: &#34;DetourCreateProcessWithDllsW&#34;, error_code: 740, message: &#34;The requested operation requires elevation.&#34; }&lt;/code&gt;&lt;/p&gt; &lt;p&gt;You are launching an application that requires Administrator rights through &lt;code&gt;zluda.exe&lt;/code&gt;. Try launching &lt;code&gt;zluda.exe&lt;/code&gt; from an Administrator command line.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ZLUDA offers limited support for performance libraries (cuDNN, cuBLAS, cuSPARSE, cuFFT, OptiX, NCCL). Currently, this support is Linux-only and not available on Windows.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ZLUDA launcher (&lt;code&gt;zluda.exe&lt;/code&gt;) does not support 32 bit processes. If an application launches 32 bit subprocess &lt;code&gt;a.exe&lt;/code&gt; neither the 32 bit process &lt;code&gt;a.exe&lt;/code&gt;, nor its 64 bit subprocess &lt;code&gt;a64.exe&lt;/code&gt; will be able to use ZLUDA. This affects e.g. SiSoft Sandra.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Applications&lt;/h3&gt; &#xA;&lt;h4&gt;llama.cpp&lt;/h4&gt; &#xA;&lt;p&gt;If you are building llama.cpp with cmake and don&#39;t want it to crash on ZLUDA then you should use &lt;code&gt;CUDA_DOCKER_ARCH=compute_61&lt;/code&gt; like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make CUDA_DOCKER_ARCH=compute_61 &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, building with cmake should work with no changes.&lt;/p&gt; &#xA;&lt;p&gt;Performance is currently much lower than the native HIP backend, see the discussion in #102.&lt;/p&gt; &#xA;&lt;h4&gt;Arnold&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ZLUDA implements minimum of OptiX framework to support Arnold. ZLUDA&#39;s OptiX is buggy, unoptimized and incomplete. It&#39;s been tested with Arnold 7.1.4.1 command line rendering on Linux.&lt;/p&gt; &lt;p&gt;ZLUDA-OptiX is not built by default or redistributed in the release. To use it follow those steps:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Firstly build a newer version of ROCm LLVM. Version shipped with 5.7.1 is known to miscompile Arnold code. Get it here: &lt;a href=&#34;https://github.com/ROCm/llvm-project&#34;&gt;https://github.com/ROCm/llvm-project&lt;/a&gt;. Switch to a known good commit: &lt;code&gt;0c7fd5b6d1bbf471d2c068c2b6172d9cfd76b08d&lt;/code&gt; and build it.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Then build amd_comgr: &lt;a href=&#34;https://github.com/ROCm/ROCm-CompilerSupport&#34;&gt;https://github.com/ROCm/ROCm-CompilerSupport&lt;/a&gt; with the LLVM built in the previous step. I&#39;m using the last commit from &lt;a href=&#34;https://github.com/ROCm/ROCm-CompilerSupport&#34;&gt;https://github.com/ROCm/ROCm-CompilerSupport&lt;/a&gt; (&lt;code&gt;8276083301409001ec7643e68f5ad58b057c21fd&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Now build ZLUDA-OptiX:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;cargo ctask --release&#xA;cargo build -p zluda_rt --release&#xA;cd target/release&#xA;ln -s libnvoptix.so liboptix.so.6.6.0 &#xA;cp ../../hiprt-sys/lib/libhiprt64.so .&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;After those quick and easy steps you can use it with the command line Arnold renderer:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;LD_LIBRARY_PATH=&amp;lt;PATH_TO_ZLUDA&amp;gt;/target/release/ LD_PRELOAD=&#34;&amp;lt;PATH_TO_COMGR&amp;gt;/build/libamd_comgr.so.2 &amp;lt;PATH_TO_ZLUDA&amp;gt;/liboptix.so.6.6.0&#34; /usr/autodesk/arnold/maya2023/bin/kick attic.ass  -device gpu -o /tmp/attic.jpg -v 6 -sl&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Keep in mind that ZLUDA-OptiX can only successfully render the simplest Arnold scene (and possibly one more):&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Cornell box (from &lt;a href=&#34;https://help.autodesk.com/view/ARNOL/ENU/?guid=arnold_user_guide_ac_scene_source_ac_ass_examples_html&#34;&gt;here&lt;/a&gt;):&lt;br&gt; &lt;a href=&#34;https://imgur.com/4Vv3GO8&#34;&gt;&lt;img src=&#34;https://imgur.com/4Vv3GO8s.jpg&#34; alt=&#34;cornell&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;(used to work, broken now) Attic scene (from &lt;a href=&#34;https://github.com/wahn/export_multi/tree/master/17_attic&#34;&gt;here&lt;/a&gt;):&lt;br&gt; &lt;a href=&#34;https://imgur.com/a/2jF9Kb5&#34;&gt;&lt;img src=&#34;https://imgur.com/Sut2YMys.jpg&#34; alt=&#34;cornell&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;PyTorch&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;PyTorch received very little testing. ZLUDA&#39;s coverage of cuDNN APIs is very minimal (just enough to run ResNet-50) and realistically you won&#39;t get much running.&lt;br&gt; However if you are interested in trying it out you need to build it from sources with the settings below. Default PyTorch does not ship PTX and uses bundled NCCL which also builds without PTX:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;export TORCH_CUDA_ARCH_LIST=&#34;6.1+PTX&#34;&#xA;export CUDAARCHS=61&#xA;export CMAKE_CUDA_ARCHITECTURES=61&#xA;export USE_SYSTEM_NCCL=1&#xA;export NCCL_ROOT_DIR=/usr&#xA;export NCCL_INCLUDE_DIR=/usr/include&#xA;export NCCL_LIB_DIR=/usr/lib/x86_64-linux-gnu&#xA;export USE_EXPERIMENTAL_CUDNN_V8_API=OFF&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or (untested):&lt;/p&gt; &lt;pre&gt;&lt;code&gt;export TORCH_CUDA_ARCH_LIST=&#34;6.1+PTX&#34;&#xA;export CUDAARCHS=61&#xA;export CMAKE_CUDA_ARCHITECTURES=61&#xA;export USE_SYSTEM_NCCL=1&#xA;export USE_NCCL=0&#xA;export USE_EXPERIMENTAL_CUDNN_V8_API=OFF&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When running use the following environment variable:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;DISABLE_ADDMM_CUDA_LT=1&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;3DF Zephyr&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ZLUDA is much slower than CUDA.&lt;/p&gt; &lt;p&gt;3DF Zephyr is triggering an underlying ROCm/HIP performance issue.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Reality Capture&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ZLUDA is much slower than CUDA.&lt;/p&gt; &lt;p&gt;Reality Capture is triggering an underlying ROCm/HIP performance issue.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;CompuBench&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;When running multiple tests, first test passes and the subsequent tests fail with &lt;code&gt;CUDA_ERROR_UNKNOWN&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;This is a ROCm/HIP bug. Currently, CompuBench tests have to be run one at a time.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Some tests output black screen.&lt;/p&gt; &lt;p&gt;This is due to a bug (or an unintended hardware feature) in CompuBench that just happens to work on NVIDIA GPUs.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;V-Ray Benchmark&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Currently, ZLUDA crashes when running V-Ray benchmark. Nonetheless, certain &#34;lucky&#34; older combinations of ZLUDA and ROCm/HIP are known to run V-Ray Benchmark successfully.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Cinebench CUDA&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ZLUDA can&#39;t run it. Cinebench CUDA benchmark has not been fully compiled with PTX. It may be possible to run it (sans OptiX) if the OctaneBench developers re-compile it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;OctaneBench&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ZLUDA can&#39;t run it. OctaneBench has not been fully compiled with PTX. It may be possible to run it (sans OptiX) if the OctaneBench developers re-compile it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Why is this project suddenly back after 3 years? What happened to Intel GPU support?&lt;/p&gt; &lt;p&gt;In 2021 I was contacted by Intel about the development of ZLUDA. I was an Intel employee at the time. While we were building a case for ZLUDA internally, I was asked for a far-reaching discretion: not to advertise the fact that Intel was evaluating ZLUDA and definitely not to make any commits to the public ZLUDA repo. After some deliberation, Intel decided that there is no business case for running CUDA applications on Intel GPUs.&lt;/p&gt; &lt;p&gt;Shortly thereafter I got in contact with AMD and in early 2022 I have left Intel and signed a ZLUDA development contract with AMD. Once again I was asked for a far-reaching discretion: not to advertise the fact that AMD is evaluating ZLUDA and definitely not to make any commits to the public ZLUDA repo. After two years of development and some deliberation, AMD decided that there is no business case for running CUDA applications on AMD GPUs.&lt;/p&gt; &lt;p&gt;One of the terms of my contract with AMD was that if AMD did not find it fit for further development, I could release it. Which brings us to today.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;What&#39;s the future of the project?&lt;/p&gt; &lt;p&gt;With neither Intel nor AMD interested, we&#39;ve run out of GPU companies. I&#39;m open though to any offers of that could move the project forward.&lt;/p&gt; &lt;p&gt;Realistically, it&#39;s now abandoned and will only possibly receive updates to run workloads I am personally interested in (DLSS).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;What underlying GPU API does ZLUDA use? Is it OpenCL? ROCm? Vulkan?&lt;/p&gt; &lt;p&gt;ZLUDA is built purely on ROCm/HIP. On both Windows and Linux.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;I am a developer writing CUDA code, does this project help me port my code to ROCm/HIP?&lt;/p&gt; &lt;p&gt;Currently no, this project is strictly for end users. However this project could be used for a much more gradual porting from CUDA to HIP than anything else. You could start with an unmodified application running on ZLUDA, then have ZLUDA expose the underlying HIP objects (streams, modules, etc.), allowing to rewrite GPU kernels one at a time. Or you could have a mixed CUDA-HIP application where only the most performance sensitive GPU kernels are written in the native AMD language.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;For developers&lt;/h2&gt; &#xA;&lt;p&gt;If you are curious about ZLUDA&#39;s architecture, you can read a broad overview in &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/ARCHITECTURE.md&#34;&gt;ARCHITECTURE.md&lt;/a&gt;. If you want to debug ZLUDA check the &#34;Debugging&#34; section in &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/TROUBLESHOOTING.md#debugging&#34;&gt;TROUBLESHOOTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This software is dual-licensed under either the Apache 2.0 license or the MIT license. See &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/LICENSE-APACHE&#34;&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/vosen/ZLUDA/master/LICENSE-MIT&#34;&gt;LICENSE-MIT&lt;/a&gt; for details&lt;/p&gt;</summary>
  </entry>
</feed>