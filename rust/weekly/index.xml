<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-03-09T01:45:41Z</updated>
  <subtitle>Weekly Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lumina-ai-inc/chunkr</title>
    <updated>2025-03-09T01:45:41Z</updated>
    <id>tag:github.com,2025-03-09:/lumina-ai-inc/chunkr</id>
    <link href="https://github.com/lumina-ai-inc/chunkr" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Vision infrastructure to turn complex documents into RAG/LLM-ready data&lt;/p&gt;&lt;hr&gt;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/lumina-ai-inc/chunkr&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/images/logo.svg?sanitize=true&#34; alt=&#34;Logo&#34; width=&#34;80&#34; height=&#34;80&#34;&gt; &lt;/a&gt; &#xA; &lt;h3 align=&#34;center&#34;&gt;Chunkr | Open Source Document Intelligence API&lt;/h3&gt; &#xA; &lt;p align=&#34;center&#34;&gt; Production-ready API service for document layout analysis, OCR, and semantic chunking.&lt;br&gt;Convert PDFs, PPTs, Word docs &amp;amp; images into RAG/LLM-ready chunks. &lt;br&gt;&lt;br&gt; &lt;b&gt;Layout Analysis&lt;/b&gt; | &lt;b&gt;OCR + Bounding Boxes&lt;/b&gt; | &lt;b&gt;Structured HTML and markdown&lt;/b&gt; | &lt;b&gt;VLM Processing controls&lt;/b&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://www.chunkr.ai&#34;&gt;Try it out!&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/lumina-ai-inc/chunkr/issues/new&#34;&gt;Report Bug&lt;/a&gt; ¬∑ &lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#connect-with-us&#34;&gt;Contact&lt;/a&gt; ¬∑ &lt;a href=&#34;https://discord.gg/XzKWFByKzW&#34;&gt;Discord&lt;/a&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.chunkr.ai&#34; width=&#34;1200&#34; height=&#34;630&#34;&gt; &lt;img src=&#34;https://chunkr.ai/og-image.png&#34; style=&#34;bor&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#super-quick-start&#34;&gt;(Super) Quick Start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#llm-configuration&#34;&gt;LLM Configuration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#self-hosted-deployment-options&#34;&gt;Self-Hosted Deployment Options&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#quick-start-with-docker-compose&#34;&gt;Quick Start with Docker Compose&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#deployment-with-kubernetes&#34;&gt;Deployment with Kubernetes&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#licensing&#34;&gt;Licensing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#connect-with-us&#34;&gt;Connect With Us&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;(Super) Quick Start&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;https://www.chunkr.ai&#34;&gt;chunkr.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Make an account and copy your API key&lt;/li&gt; &#xA; &lt;li&gt;Install our Python SDK: &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install chunkr-ai&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Use the SDK to process your documents: &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from chunkr_ai import Chunkr&#xA;&#xA;# Initialize with your API key from chunkr.ai&#xA;chunkr = Chunkr(api_key=&#34;your_api_key&#34;)&#xA;&#xA;# Upload a document (URL or local file path)&#xA;url = &#34;https://chunkr-web.s3.us-east-1.amazonaws.com/landing_page/input/science.pdf&#34;&#xA;task = chunkr.upload(url)&#xA;&#xA;# Export results in various formats&#xA;task.html(output_file=&#34;output.html&#34;)&#xA;task.markdown(output_file=&#34;output.md&#34;)&#xA;task.content(output_file=&#34;output.txt&#34;)&#xA;task.json(output_file=&#34;output.json&#34;)&#xA;&#xA;# Clean up&#xA;chunkr.close()&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Visit our &lt;a href=&#34;https://docs.chunkr.ai&#34;&gt;docs&lt;/a&gt; for more information and examples.&lt;/p&gt; &#xA;&lt;h2&gt;LLM Configuration&lt;/h2&gt; &#xA;&lt;p&gt;You can use any OpenAI API compatible endpoint by setting the following variables in your .env file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;LLM__URL:&#xA;LLM__MODEL:&#xA;LLM__KEY:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Self-Hosted Deployment Options&lt;/h2&gt; &#xA;&lt;h3&gt;Quick Start with Docker Compose&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Prerequisites:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;Docker and Docker Compose&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html&#34;&gt;NVIDIA Container Toolkit&lt;/a&gt; (for GPU support, optional)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone the repo:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/lumina-ai-inc/chunkr&#xA;cd chunkr&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Set up environment variables:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Copy the example environment file&#xA;cp .env.example .env&#xA;&#xA;# Configure your environment variables&#xA;# Required: LLM_KEY as your OpenAI API key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Start the services:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;With GPU:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Access the services: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Web UI: &lt;code&gt;http://localhost:5173&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;API: &lt;code&gt;http://localhost:8000&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Requires an NVIDIA CUDA GPU&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Stop the services when done:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose down&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Deployment with Kubernetes&lt;/h3&gt; &#xA;&lt;p&gt;For production environments, we provide a Helm chart and detailed deployment instructions:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;See our detailed guide at &lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/kube/README.md&#34;&gt;&lt;code&gt;kube/README.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Includes configurations for high availability and scaling&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For enterprise support and deployment assistance, &lt;a href=&#34;mailto:mehul@lumina.sh&#34;&gt;contact us&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Licensing&lt;/h2&gt; &#xA;&lt;p&gt;The core of this project is dual-licensed:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/LICENSE&#34;&gt;GNU Affero General Public License v3.0 (AGPL-3.0)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Commercial License&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;To use Chunkr without complying with the AGPL-3.0 license terms you can &lt;a href=&#34;mailto:mehul@lumina.sh&#34;&gt;contact us&lt;/a&gt; or visit our &lt;a href=&#34;https://chunkr.ai&#34;&gt;website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Connect With Us&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìß Email: &lt;a href=&#34;mailto:mehul@chunkr.ai&#34;&gt;mehul@chunkr.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üìÖ Schedule a call: &lt;a href=&#34;https://cal.com/mehulc/30min&#34;&gt;Book a 30-minute meeting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üåê Visit our website: &lt;a href=&#34;https://chunkr.ai&#34;&gt;chunkr.ai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>