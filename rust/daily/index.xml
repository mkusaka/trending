<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-09-22T01:34:32Z</updated>
  <subtitle>Daily Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mediar-ai/screenpipe</title>
    <updated>2024-09-22T01:34:32Z</updated>
    <id>tag:github.com,2024-09-22:/mediar-ai/screenpipe</id>
    <link href="https://github.com/mediar-ai/screenpipe" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Library to build personalized AI powered by what you&#39;ve seen, said, or heard. Works with Ollama. Alternative to Rewind.ai. Open. Secure. You own your data. Rust.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://screenpi.pe&#34;&gt; &lt;img src=&#34;https://github.com/user-attachments/assets/d3b1de26-c3c0-4c84-b9c4-b03213b97a30&#34; alt=&#34;logo&#34; width=&#34;200&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;pre align=&#34;center&#34;&gt;&#xA;   ___  ___ _ __ ___  ___ _ __  _ __ (_)_ __   ___ &#xA;  / __|/ __| &#39;__/ _ \/ _ \ &#39;_ \| &#39;_ \| | &#39;_ \ / _ \&#xA;  \__ \ (__| | |  __/  __/ | | | |_) | | |_) |  __/&#xA;  |___/\___|_|  \___|\___|_| |_| .__/|_| .__/ \___|&#xA;                               |_|     |_|         &#xA;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://screenpi.pe&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Download%20The-Desktop%20App-blue?style=for-the-badge&#34; alt=&#34;Download the Desktop App&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.youtube.com/@mediar_ai&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/endpoint?style=for-the-badge&amp;amp;url=https%3A%2F%2Fyoutube-channel-badge.ngoldack.vercel.app%2Fapi%2Fsubscriber&#34; alt=&#34;Subs&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/dU9EBuw7Uq&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/823813159592001537?color=5865F2&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;Join us on Discord&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://twitter.com/screen_pipe&#34;&gt;&lt;img alt=&#34;X account&#34; src=&#34;https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&amp;amp;label=Follow%20%40screen_pipe&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://cal.com/louis030195/screenpipe&#34;&gt; &lt;img alt=&#34;Let&#39;s chat&#34; src=&#34;https://cal.com/book-with-cal-dark.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://screenpi.pe&#34;&gt; &lt;img alt=&#34;demo&#34; src=&#34;https://github.com/user-attachments/assets/39d27adc-e17e-4ca5-89c5-faf45a3ea20f&#34; width=&#34;800&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; üî•&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2024/09] Screenpipe hit 60 daily active users!&lt;/li&gt; &#xA; &lt;li&gt;[2024/09] Released a v0 of our &lt;a href=&#34;https://docs.screenpi.pe/&#34;&gt;documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] Anyone can now &lt;a href=&#34;https://youtu.be/iCqHgZgQHyA?si=DjKJir7HfZoQKItK&#34;&gt;create, share, install pipes&lt;/a&gt; (plugins) from the app interface based on a github repo/dir&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] We&#39;re running bounties! Contribute to screenpipe &amp;amp; make money, &lt;a href=&#34;https://github.com/mediar-ai/screenpipe/issues&#34;&gt;check issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] Audio input &amp;amp; output now works perfect on Windows, Linux, MacOS (&amp;lt;15.0). We also support multi monitor capture and defaulting STT to Whisper Distil large v3&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] We released video embedding. AI gives you links to your video recording in the chat!&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] We released the pipe store! Create, share, use plugins that get you the most out of your data in less than 30s, even if you are not technical.&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] We released Apple &amp;amp; Windows Native OCR.&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] &lt;strong&gt;The Linux desktop app is here!&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[2024/07] &lt;strong&gt;The Windows desktop app is here! &lt;a href=&#34;https://screenpi.pe&#34;&gt;Get it now!&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[2024/07] üéÅ Screenpipe won Friends (the AI necklace) hackathon at AGI House (integrations soon)&lt;/li&gt; &#xA; &lt;li&gt;[2024/07] &lt;strong&gt;We just launched the desktop app! &lt;a href=&#34;https://screenpi.pe&#34;&gt;Download now!&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;24/7 Screen &amp;amp; Audio Capture&lt;/h1&gt; &#xA;&lt;p&gt;Library to build personalized AI powered by what you&#39;ve seen, said, or heard. Works with Ollama. Alternative to Rewind.ai. Open. Secure. You own your data. Rust.&lt;br&gt; We are shipping daily, make suggestions, post bugs, &lt;a href=&#34;mailto:louis@screenpi.pe?subject=Screenpipe%20Feedback&amp;amp;body=I&#39;d%20like%20to%20use%20Screenpipe%20for%20...%0D%0A%0D%0AI%20cannot%20because%20of%20...%0D%0A%0D%0AWe%20can%20also%20have%20a%20call,%20book%20at%20https://cal.com/louis030195/screenpipe&#34;&gt;give feedback&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mediar-ai/screenpipe/main/content/diagram2.png&#34; alt=&#34;diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Why?&lt;/h1&gt; &#xA;&lt;p&gt;Building a reliable stream of audio and screenshot data, where a user simply clicks a button and the script runs in the background 24/7, collecting and extracting data from screen and audio input/output, can be frustrating.&lt;/p&gt; &#xA;&lt;p&gt;There are numerous use cases that can be built on top of this layer. To simplify life for other developers, we decided to solve this non-trivial problem. It&#39;s still in its early stages, but it works end-to-end. We&#39;re working on this full-time and would love to hear your feedback and suggestions.&lt;/p&gt; &#xA;&lt;h2&gt;Get started&lt;/h2&gt; &#xA;&lt;p&gt;There are multiple ways to install screenpipe:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;as a CLI (continue reading), for rather technical users&lt;/li&gt; &#xA; &lt;li&gt;as a &lt;a href=&#34;https://screenpi.pe&#34;&gt;paid desktop app&lt;/a&gt; with 1 year updates, priority support, and priority features&lt;/li&gt; &#xA; &lt;li&gt;as a free forever desktop app (but you need to build it yourself). We&#39;re 100% OSS.&lt;/li&gt; &#xA; &lt;li&gt;as a free forever desktop app - by sending a PR (&lt;a href=&#34;https://github.com/mediar-ai/screenpipe/issues/120#issuecomment-2275043418&#34;&gt;example&lt;/a&gt;) (or offer free app to a friend)&lt;/li&gt; &#xA; &lt;li&gt;as a Rust or WASM library (documentation WIP)&lt;/li&gt; &#xA; &lt;li&gt;as a business - check &lt;a href=&#34;https://github.com/mediar-ai/screenpipe?tab=readme-ov-file#use-cases&#34;&gt;use cases&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/louis030195/&#34;&gt;DM louis&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;we invest 80% of the paid app revenue in &lt;a href=&#34;https://github.com/mediar-ai/screenpipe/issues?q=is:open+is:issue+label:%22%F0%9F%92%8E+Bounty%22&#34;&gt;bounties&lt;/a&gt;, send PR, make money!&lt;/p&gt; &#xA;&lt;p&gt;think of screenpipe like a DAO, but without crypto&lt;/p&gt; &#xA;&lt;p&gt;This is the instructions to install the command line interface.&lt;/p&gt; &#xA;&lt;p&gt;Struggle to get it running? &lt;a href=&#34;https://cal.com/louis030195/screenpipe&#34;&gt;I&#39;ll install it with you in a 15 min call.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;CLI installation&lt;/summary&gt; &#xA; &lt;details&gt; &#xA;  &lt;summary&gt;MacOS&lt;/summary&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Option I: brew&lt;/summary&gt; &#xA;   &lt;ol&gt; &#xA;    &lt;li&gt;Install CLI&lt;/li&gt; &#xA;   &lt;/ol&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew tap mediar-ai/screenpipe https://github.com/mediar-ai/screenpipe.git&#xA;brew install screenpipe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;ol start=&#34;2&#34;&gt; &#xA;    &lt;li&gt;Run it:&lt;/li&gt; &#xA;   &lt;/ol&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screenpipe &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;if you don&#39;t want audio to be recorded&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screenpipe --disable-audio&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;if you want to save OCR data to text file in text_json folder in the root of your project (good for testing):&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screenpipe --save-text-files&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;if you want to run screenpipe in debug mode to show more logs in terminal:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screenpipe --debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;by default screenpipe is using Silero-VAD to identify speech and non-speech tokens to improve audio transcription, bu you can use WebRTC if needed by passing the following command:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screenpipe --vad-engine webrtc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;by default screenpipe is using whisper-large that runs LOCALLY to get better quality or lower compute you can use cloud model (we use Deepgram) via cloud api:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screenpipe --audio-transcription-engine deepgram&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;friend wearable integration, in order to link your wearable you need to pass user ID from friend app:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screenpipe --friend-wearable-uid AC...........................F3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;you can combine multiple flags if needed&lt;/p&gt; &#xA;   &lt;p&gt;&lt;a href=&#34;https://github.com/mediar-ai/screenpipe/issues/new?assignees=&amp;amp;labels=dislike&amp;amp;template=dislike.yml&amp;amp;title=brew+install+screenpipe+didnt+work&#34;&gt;Didn&#39;t work?&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;/details&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Option II: Install from the source&lt;/summary&gt; &#xA;   &lt;ol&gt; &#xA;    &lt;li&gt;Install dependencies:&lt;/li&gt; &#xA;   &lt;/ol&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh # takes 5 minutes&#xA;brew install pkg-config ffmpeg jq tesseract&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;ol start=&#34;2&#34;&gt; &#xA;    &lt;li&gt;Clone the repo:&lt;/li&gt; &#xA;   &lt;/ol&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/mediar-ai/screenpipe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;This runs a local SQLite DB + an API + screenshot, ocr, mic, stt, mp4 encoding&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd screenpipe # enter cloned repo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;Build the project, takes 5-10 minutes depending on your hardware&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# necessary to use apple native OCR&#xA;export RUSTFLAGS=&#34;-C link-arg=-Wl,-rpath,@executable_path/../../screenpipe-vision/bin -C link-arg=-Wl,-rpath,@loader_path/../../screenpipe-vision/lib&#34;&#xA;cargo build --release --features metal # takes 3 minuttes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;Then run it&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./target/release/screenpipe # add --ocr-engine apple-native to use apple native OCR&#xA;# add &#34;--disable-audio&#34; if you don&#39;t want audio to be recorded&#xA;# &#34;--save-text-files&#34; if you want to save OCR data to text file in text_json folder in the root of your project (good for testing)&#xA;# &#34;--debug&#34; if you want to run screenpipe in debug mode to show more logs in terminal&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;&lt;a href=&#34;https://github.com/mediar-ai/screenpipe/issues/new?assignees=&amp;amp;labels=dislike&amp;amp;template=dislike.yml&amp;amp;title=cloning+screenpipe+didnt+work&#34;&gt;Didn&#39;t work?&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;/details&gt; &#xA;  &lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA; &lt;/details&gt; &#xA; &lt;details&gt; &#xA;  &lt;summary&gt;Windows&lt;/summary&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;[!note] This is experimental support for Windows build. This assumes you already have the CUDA Toolkit installed and the CUDA_PATH set to my CUDA v12.6 folder. Replace &lt;code&gt;V:\projects&lt;/code&gt; and &lt;code&gt;V:\packages&lt;/code&gt; with your own folders.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &#xA;  &lt;p&gt;If this does not work for you, please &lt;a href=&#34;https://github.com/mediar-ai/screenpipe/issues/new?assignees=&amp;amp;labels=dislike&amp;amp;template=dislike.yml&amp;amp;title=windows+install+screenpipe+didnt+work&#34;&gt;open an issue&lt;/a&gt; or get the pre-built &lt;a href=&#34;https://screenpi.pe&#34;&gt;desktop app&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Install chocolatey&lt;/li&gt; &#xA;   &lt;li&gt;Install git&lt;/li&gt; &#xA;   &lt;li&gt;Install CUDA Toolkit (if using NVIDIA and building with cuda)&lt;/li&gt; &#xA;   &lt;li&gt;Install MS Visual Studio Build Tools (below are the components I have installed) &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Desktop development with C++ &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;MSVC v143&lt;/li&gt; &#xA;       &lt;li&gt;Windows 11 SDK&lt;/li&gt; &#xA;       &lt;li&gt;C++ Cmake tools for Windows&lt;/li&gt; &#xA;       &lt;li&gt;Testing tools core features - Build tools&lt;/li&gt; &#xA;       &lt;li&gt;C++ AddressSanitizer&lt;/li&gt; &#xA;       &lt;li&gt;C++ ATL for latest v143&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;Individual components &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;C++ ATL for latest v143 build tools (x86 &amp;amp; x64)&lt;/li&gt; &#xA;       &lt;li&gt;MSBuild support for LLVM (clang-c) toolset&lt;/li&gt; &#xA;       &lt;li&gt;C++ Clang Compiler for Windows&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;choco install pkgconfiglite rust&#xA;cd V:\projects&#xA;git clone https://github.com/mediar-ai/screenpipe&#xA;cd V:\packages&#xA;git clone https://github.com/microsoft/vcpkg.git&#xA;cd vcpkg&#xA;bootstrap-vcpkg.bat -disableMetrics&#xA;vcpkg.exe integrate install --disable-metrics&#xA;vcpkg.exe install ffmpeg&#xA;&#xA;SET PKG_CONFIG_PATH=V:\packages\vcpkg\packages\ffmpeg_x64-windows\lib\pkgconfig&#xA;SET VCPKG_ROOT=V:\packages\vcpkg&#xA;SET LIBCLANG_PATH=C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\Llvm\x64\bin&#xA;cd V:\projects\screen-pipe&#xA;&#xA;cargo build --release --features cuda&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;/details&gt; &#xA; &lt;details&gt; &#xA;  &lt;summary&gt;Linux&lt;/summary&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Option I: Install from source&lt;/summary&gt; &#xA;   &lt;ol&gt; &#xA;    &lt;li&gt;Install dependencies:&lt;/li&gt; &#xA;   &lt;/ol&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get update&#xA;sudo apt-get install -y libavformat-dev libavfilter-dev libavdevice-dev ffmpeg libasound2-dev tesseract-ocr libtesseract-dev&#xA;&#xA;# Install Rust programming language&#xA;curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;ol start=&#34;2&#34;&gt; &#xA;    &lt;li&gt;Clone the repo:&lt;/li&gt; &#xA;   &lt;/ol&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/mediar-ai/screenpipe&#xA;cd screenpipe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;ol start=&#34;3&#34;&gt; &#xA;    &lt;li&gt;Build and run:&lt;/li&gt; &#xA;   &lt;/ol&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo build --release --features cuda # remove &#34;--features cuda&#34; if you do not have a NVIDIA GPU&#xA;&#xA;# then run it&#xA;./target/release/screenpipe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Option II: Install through Nix&lt;/summary&gt; &#xA;   &lt;p&gt;Choose one of the following methods:&lt;/p&gt; &#xA;   &lt;p&gt;a. Using &lt;code&gt;nix-env&lt;/code&gt;:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nix-env -iA nixpkgs.screen-pipe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;b. In your &lt;code&gt;configuration.nix&lt;/code&gt; (for NixOS users): Add the following to your &lt;code&gt;configuration.nix&lt;/code&gt;:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-nix&#34;&gt;environment.systemPackages = with pkgs; [&#xA;  screen-pipe&#xA;];&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;Then rebuild your system with &lt;code&gt;sudo nixos-rebuild switch&lt;/code&gt;.&lt;/p&gt; &#xA;   &lt;p&gt;c. In a Nix shell:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nix-shell -p screen-pipe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;d. Using &lt;code&gt;nix run&lt;/code&gt; (for ad-hoc usage):&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nix run nixpkgs#screen-pipe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;Note: Make sure you&#39;re using a recent version of nixpkgs that includes the screen-pipe package.&lt;/p&gt; &#xA;  &lt;/details&gt; &#xA; &lt;/details&gt; &#xA; &lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;By default the data is stored in &lt;code&gt;$HOME/.screenpipe&lt;/code&gt; (&lt;code&gt;C:\AppData\Users\&amp;lt;user&amp;gt;\.screenpipe&lt;/code&gt; on Windows) you can change using &lt;code&gt;--data-dir &amp;lt;mydir&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;run example vercel/ai chatbot web interface&lt;/summary&gt; &#xA; &lt;p&gt;This example uses OpenAI. If you&#39;re looking for ollama example check the &lt;a href=&#34;https://github.com/mediar-ai/screenpipe/tree/main/examples/typescript&#34;&gt;examples folder&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;The &lt;a href=&#34;https://screenpi.pe/&#34;&gt;desktop app&lt;/a&gt; fully support OpenAI &amp;amp; Ollama by default.&lt;/p&gt; &#xA; &lt;p&gt;To run Vercel chatbot, try this:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/mediar-ai/screenpipe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Navigate to app directory&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd screenpipe/examples/typescript/vercel-ai-chatbot &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Set up you OPENAI API KEY in .env&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#34;OPENAI_API_KEY=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&#34; &amp;gt; .env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/mediar-ai/screenpipe/issues/new?assignees=&amp;amp;labels=dislike&amp;amp;template=dislike.yml&amp;amp;title=vercel+app+didnt+work&#34;&gt;Didn&#39;t work?&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;Install dependencies and run local web server&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mediar-ai/screenpipe/main/content/Vercel_app.png&#34; alt=&#34;Vercel App&#34;&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mediar-ai/screenpipe/main/content/Claude_prompt.png&#34; alt=&#34;Claude_prompt&#34;&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;You can use terminal commands to query and view your data as shown below. Also, we recommend Tableplus.com to view the database, it has a free tier.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s a pseudo code to illustrate how to use screenpipe, to summarize meetings:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// 1h ago&#xA;const startDate = &#34;&amp;lt;some time 1h ago..&amp;gt;&#34;&#xA;// 10m ago&#xA;const endDate = &#34;&amp;lt;some time 10m ago..&amp;gt;&#34;&#xA;&#xA;// get all the screen &amp;amp; mic data from roughly last hour &#xA;const results = fetchScreenpipe(startDate, endDate)&#xA;&#xA;// send it to an LLM and ask for a summary&#xA;const summary = fetchOllama(&#34;{results} create a summary from these transcriptions&#34;)&#xA;// or const summary = fetchOpenai(results)&#xA;&#xA;// add the meeting summary to your notes&#xA;addToNotion(summary)&#xA;// or your favourite note taking app&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or thousands of other usages of all your screen &amp;amp; mic data! &lt;a href=&#34;https://github.com/mediar-ai/screenpipe/tree/main/examples/typescript&#34;&gt;Check examples&lt;/a&gt;, screenpipes makes it easy to write plugins in JS for example that runs directly in the Rust code through Deno engine.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; Check which tables you have in the local database&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sqlite3 ~/.screenpipe/db.sqlite &#34;.tables&#34; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; Print a sample audio_transcriptions from the database&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sqlite3 ~/.screenpipe/db.sqlite &#34;.mode json&#34; &#34;.once /dev/stdout&#34; &#34;SELECT * FROM audio_transcriptions ORDER BY id DESC LIMIT 1;&#34; | jq .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mediar-ai/screenpipe/main/content/audio_transcriptions.png&#34; alt=&#34;audio_transcriptions&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; Print a sample frame_OCR_text from the database&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sqlite3 ~/.screenpipe/db.sqlite &#34;.mode json&#34; &#34;.once /dev/stdout&#34; &#34;SELECT * FROM ocr_text ORDER BY frame_id DESC LIMIT 1;&#34; | jq -r &#39;.[0].text&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mediar-ai/screenpipe/main/content/frame_text.png&#34; alt=&#34;frame_text&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; Play a sample frame_recording from the database&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ffplay &#34;data/2024-07-12_01-14-14.mp4&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; Play a sample audio_recording from the database&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ffplay &#34;data/Display 1 (output)_2024-07-12_01-14-11.mp4&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example to query the API&lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Basic search query&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl &#34;http://localhost:3030/search?q=Neuralink&amp;amp;limit=5&amp;amp;offset=0&amp;amp;content_type=ocr&#34; | jq&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&#34;Elon Musk&#34; prompt &lt;img src=&#34;https://raw.githubusercontent.com/mediar-ai/screenpipe/main/content/Elon_Musk_prompt.png&#34; alt=&#34;Elon_Musk_prompt&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Other Example to query the API&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 2. Search with content type filter (OCR)&#xA;curl &#34;http://localhost:3030/search?q=QUERY_HERE&amp;amp;limit=5&amp;amp;offset=0&amp;amp;content_type=ocr&#34;&#xA;&#xA;# 3. Search with content type filter (Audio)&#xA;curl &#34;http://localhost:3030/search?q=QUERY_HERE&amp;amp;limit=5&amp;amp;offset=0&amp;amp;content_type=audio&#34;&#xA;&#xA;# 4. Search with pagination&#xA;curl &#34;http://localhost:3030/search?q=QUERY_HERE&amp;amp;limit=10&amp;amp;offset=20&#34;&#xA;&#xA;# 6. Search with no query (should return all results)&#xA;curl &#34;http://localhost:3030/search?limit=5&amp;amp;offset=0&#34;&#xA;&#xA;# Display first frame from 30m to 25m ago (macos, translate to your OS with AI)&#xA;curl &#34;http://localhost:3030/search?limit=1&amp;amp;offset=0&amp;amp;content_type=ocr&amp;amp;include_frames=true&amp;amp;start_time=$(date -u -v-220M +%Y-%m-%dT%H:%M:%SZ)&amp;amp;end_time=$(date -u -v-120M +%Y-%m-%dT%H:%M:%SZ)&#34; | jq -r &#39;.data[0].content.frame&#39; | base64 --decode &amp;gt; /tmp/frame.png &amp;amp;&amp;amp; open /tmp/frame.png&#xA;&#xA;# filter by app (wll only return OCR results)&#xA;curl &#34;http://localhost:3030/search?app_name=cursor&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;br&gt;&#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/6025ef71-43b9-4151-a34c-155c30236a57&#34; alt=&#34;0910244&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Use cases:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Search &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Semantic and keyword search. Find information you&#39;ve forgotten or misplaced&lt;/li&gt; &#xA;   &lt;li&gt;Playback history of your desktop when searching for a specific info&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Automation: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Automatically generate documentation&lt;/li&gt; &#xA;   &lt;li&gt;Populate CRM systems with relevant data&lt;/li&gt; &#xA;   &lt;li&gt;Synchronize company knowledge across platforms&lt;/li&gt; &#xA;   &lt;li&gt;Automate repetitive tasks based on screen content&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Analytics: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Track personal productivity metrics&lt;/li&gt; &#xA;   &lt;li&gt;Organize and analyze educational materials&lt;/li&gt; &#xA;   &lt;li&gt;Gain insights into areas for personal improvement&lt;/li&gt; &#xA;   &lt;li&gt;Analyze work patterns and optimize workflows&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Personal assistant: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Summarize lengthy documents or videos&lt;/li&gt; &#xA;   &lt;li&gt;Provide context-aware reminders and suggestions&lt;/li&gt; &#xA;   &lt;li&gt;Assist with research by aggregating relevant information&lt;/li&gt; &#xA;   &lt;li&gt;Live captions, translation support&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Collaboration: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Share and annotate screen captures with team members&lt;/li&gt; &#xA;   &lt;li&gt;Create searchable archives of meetings and presentations&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Compliance and security: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Track what your employees are really up to&lt;/li&gt; &#xA;   &lt;li&gt;Monitor and log system activities for audit purposes&lt;/li&gt; &#xA;   &lt;li&gt;Detect potential security threats based on screen content&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mediar-ai/screenpipe/tree/main/examples/typescript&#34;&gt;&lt;strong&gt;Check other examples&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Status&lt;/h2&gt; &#xA;&lt;p&gt;Alpha: runs on my computer &lt;code&gt;Macbook pro m3 32 GB ram&lt;/code&gt; and a $400 Windows laptop, 24/7.&lt;/p&gt; &#xA;&lt;p&gt;Uses 600 MB, 10% CPU.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Integrations &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ollama&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; openai&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Friend wearable&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://github.com/different-ai/file-organizer-2000&#34;&gt;Fileorganizer2000&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; mem0&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Brilliant Frames&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Vercel AI SDK&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; supermemory&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; deepgram&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; unstructured&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; excalidraw&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Obsidian&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Apple shortcut&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; multion&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; iPhone&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Android&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Camera&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Keyboard&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Browser&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Pipe Store (a list of &#34;pipes&#34; you can build, share &amp;amp; easily install to get more value out of your screen &amp;amp; mic data without effort). It runs in Deno Typescript engine within screenpipe on your computer&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; screenshots + OCR with different engines to optimise privacy, quality, or energy consumption &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; tesseract&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Windows native OCR&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Apple native OCR&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; unstructured.io&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; screenpipe screen/audio specialised LLM&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; audio + STT (works with multi input devices, like your iPhone + mac mic, many STT engines) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Linux, MacOS, Windows input &amp;amp; output devices&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; iPhone microphone&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://github.com/mediar-ai/screenpipe/discussions/68&#34;&gt;remote capture&lt;/a&gt; (run screenpipe on your cloud and it capture your local machine, only tested on Linux) for example when you have low compute laptop&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; optimised screen &amp;amp; audio recording (mp4 encoding, estimating 30 gb/m with default settings)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; sqlite local db&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; local api&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Cross platform CLI, &lt;a href=&#34;https://screenpi.pe/&#34;&gt;desktop app&lt;/a&gt; (MacOS, Windows, Linux)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Metal, CUDA&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; TS SDK&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; multimodal embeddings&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; cloud storage options (s3, pgsql, etc.)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; cloud computing options (deepgram for audio, unstructured for OCR)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; custom storage settings: customizable capture settings (fps, resolution)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; security &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; window specific capture (e.g. can decide to only capture specific tab of cursor, chrome, obsidian, or only specific app)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; encryption&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; PII removal&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; fast, optimised, energy-efficient modes&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; webhooks/events (for automations)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; abstractions for multiplayer usage (e.g. aggregate sales team data, company team data, partner, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why open source?&lt;/h2&gt; &#xA;&lt;p&gt;Recent breakthroughs in AI have shown that context is the final frontier. AI will soon be able to incorporate the context of an entire human life into its &#39;prompt&#39;, and the technologies that enable this kind of personalisation should be available to all developers to accelerate access to the next stage of our evolution.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome! If you&#39;d like to contribute, please read &lt;a href=&#34;https://raw.githubusercontent.com/mediar-ai/screenpipe/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;What&#39;s the difference with adept.ai and rewind.ai?&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;adept.ai is a closed product, focused on automation while we are open and focused on enabling tooling &amp;amp; infra for a wide range of applications like adept&lt;/li&gt; &#xA;  &lt;li&gt;rewind.ai is a closed product, focused on a single use case (they only focus on meetings now), not customisable, your data is owned by them, and not extendable by developers&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Where is the data stored?&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;100% of the data stay local in a SQLite database and mp4/mp3 files. You own your data&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Do you encrypt the data?&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Not yet but we&#39;re working on it. We want to provide you the highest level of security.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;How can I customize capture settings to reduce storage and energy usage?&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;You can adjust frame rates and resolution in the configuration. Lower values will reduce storage and energy consumption. We&#39;re working on making this more user-friendly in future updates.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;What are some practical use cases for screenpipe?&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;- RAG &amp;amp; question answering&#xA;- Automation (write code somewhere else while watching you coding, write docs, fill your CRM, sync company&#39;s knowledge, etc.)&#xA;- Analytics (track human performance, education, become aware of how you can improve, etc.)&#xA;- etc.&#xA;- We&#39;re constantly exploring new use cases and welcome community input!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt;</summary>
  </entry>
</feed>