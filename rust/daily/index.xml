<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-05T01:36:16Z</updated>
  <subtitle>Daily Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>picahq/pica</title>
    <updated>2025-06-05T01:36:16Z</updated>
    <id>tag:github.com,2025-06-05:/picahq/pica</id>
    <link href="https://github.com/picahq/pica" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Complete Agentic Tooling Platform&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://picaos.com&#34;&gt; &lt;img alt=&#34;Pica Logo&#34; src=&#34;https://raw.githubusercontent.com/picahq/pica/main/resources/images/banner.svg?sanitize=true&#34; style=&#34;border-radius: 10px;&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;b&gt;Pica, The AI Integrations Solution&lt;/b&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt; &lt;a href=&#34;https://www.picaos.com/&#34;&gt;Website&lt;/a&gt; ¬∑ &lt;a href=&#34;https://docs.picaos.com&#34;&gt;Documentation&lt;/a&gt; ¬∑ &lt;a href=&#34;https://app.picaos.com&#34;&gt;Dashboard&lt;/a&gt; ¬∑ &lt;a href=&#34;https://docs.picaos.com/changelog&#34;&gt;Changelog&lt;/a&gt; ¬∑ &lt;a href=&#34;https://x.com/picahq&#34;&gt;X&lt;/a&gt; ¬∑ &lt;a href=&#34;https://www.linkedin.com/company/picahq&#34;&gt;LinkedIn&lt;/a&gt; &lt;/b&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Pica gives every builder instant, reliable access to the tools they need‚Äîno keys, no configs, no headaches.&lt;/p&gt; &#xA;&lt;h2&gt;Why Pica?&lt;/h2&gt; &#xA;&lt;p&gt;Pica simplifies AI agent development with our four core products:&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ OneTool ‚Äì Connect agents to &lt;a href=&#34;https://app.picaos.com/tools&#34;&gt;100+ APIs and tools&lt;/a&gt; with a single SDK. &lt;br&gt; ‚úÖ AuthKit ‚Äì Secure authentication for seamless tool integration. &lt;br&gt; ‚úÖ BuildKit - Empower vibe coding with integrations that work zero-shot.&lt;/p&gt; &#xA;&lt;p&gt;Pica also provides full logging and action traceability, giving developers complete visibility into their agents‚Äô decisions and activities. Our tools simplify building and running AI agents so developers can focus on results.&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;h3&gt;Install&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install @picahq/ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a new &lt;a href=&#34;https://app.picaos.com&#34;&gt;Pica account&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Create a Connection via the &lt;a href=&#34;https://app.picaos.com/connections&#34;&gt;Dashboard&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Create an &lt;a href=&#34;https://app.picaos.com/settings/api-keys&#34;&gt;API key&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Set the API key as an environment variable: &lt;code&gt;PICA_SECRET_KEY=&amp;lt;your-api-key&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Example Usage&lt;/h3&gt; &#xA;&lt;p&gt;Below is an example demonstrating how to integrate the &lt;a href=&#34;https://www.npmjs.com/package/@picahq/ai&#34;&gt;Pica OneTool&lt;/a&gt; with the &lt;a href=&#34;https://www.npmjs.com/package/ai&#34;&gt;Vercel AI SDK&lt;/a&gt; for a GitHub use case:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { openai } from &#34;@ai-sdk/openai&#34;;&#xA;import { generateText } from &#34;ai&#34;;&#xA;import { Pica } from &#34;@picahq/ai&#34;;&#xA;import * as dotenv from &#34;dotenv&#34;;&#xA;dotenv.config();&#xA;&#xA;const pica = new Pica(process.env.PICA_SECRET_KEY!, {&#xA;  connectors: [&#34;*&#34;]&#xA;});&#xA;&#xA;async function runAgentTask(message: string): Promise&amp;lt;string&amp;gt; {&#xA;  const system = await pica.generateSystemPrompt();&#xA;&#xA;  const { text } = await generateText({&#xA;    model: openai(&#34;gpt-4.1&#34;),&#xA;    system,&#xA;    prompt: message,&#xA;    tools: { ...pica.oneTool },&#xA;    maxSteps: 10,&#xA;  });&#xA;&#xA;  return text;&#xA;}&#xA;&#xA;runAgentTask(&#34;Star the repo picahq/pica with github&#34;)&#xA;  .then((text) =&amp;gt; {&#xA;    console.log(text);&#xA;  })&#xA;  .catch(console.error);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://replit.com/@picahq/Pica-or-GitHub-Star-Demo&#34;&gt;&lt;img src=&#34;https://replit.com/badge?caption=Try%20with%20Replit&#34; alt=&#34;Try with Replit Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For more use cases, visit our &lt;a href=&#34;https://www.picaos.com/community/use-cases&#34;&gt;Use Cases Library&lt;/a&gt; or our &lt;a href=&#34;https://github.com/picahq/awesome-pica&#34;&gt;Awesome Pica Repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Next.js Integration&lt;/h3&gt; &#xA;&lt;p&gt;‚≠êÔ∏è You can see a full Next.js demo &lt;a href=&#34;https://github.com/picahq/onetool-demo&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;For more examples and detailed documentation, check out our &lt;a href=&#34;https://docs.picaos.com/sdk/vercel-ai&#34;&gt;SDK documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Running Pica locally&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT] The Pica dashboard is going open source! Stay tuned for the big release üöÄ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.docker.com/compose/&#34;&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Step 1: Install the Pica CLI&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm install -g @picahq/cli&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 2: Initialize the Pica CLI&lt;/h3&gt; &#xA;&lt;p&gt;To generate the configuration file, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pica init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 3: Start the Pica Server&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pica start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;All the inputs are required. Seeding is optional, but recommended when running the command for the first time.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h5&gt;Example&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;# To start the docker containers&#xA;pica start&#xA;Enter the IOS Crypto Secret (32 characters long): xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&#xA;Do you want to seed? (Y/N) y&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Pica API will be available at &lt;code&gt;http://localhost:3005&lt;/code&gt; üöÄ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;To stop the docker containers, simply run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;pica stop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Pica is released under the &lt;a href=&#34;https://raw.githubusercontent.com/picahq/pica/main/LICENSE&#34;&gt;&lt;strong&gt;GPL-3.0 license&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ai-dynamo/dynamo</title>
    <updated>2025-06-05T01:36:16Z</updated>
    <id>tag:github.com,2025-06-05:/ai-dynamo/dynamo</id>
    <link href="https://github.com/ai-dynamo/dynamo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Datacenter Scale Distributed Inference Serving Framework&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NVIDIA Dynamo&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ai-dynamo/dynamo/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/ai-dynamo/dynamo&#34; alt=&#34;GitHub Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/nvidia-dynamo&#34;&gt;&lt;img src=&#34;https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;| &lt;strong&gt;&lt;a href=&#34;https://github.com/ai-dynamo/dynamo/issues/762&#34;&gt;Roadmap&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://docs.nvidia.com/dynamo/latest/index.html&#34;&gt;User Guides&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/support_matrix.md&#34;&gt;Support Matrix&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/architecture.md&#34;&gt;Architecture and Features&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ai-dynamo/dynamo/main/lib/bindings/python/README.md&#34;&gt;APIs&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ai-dynamo/dynamo/main/deploy/dynamo/sdk/README.md&#34;&gt;SDK&lt;/a&gt;&lt;/strong&gt; |&lt;/p&gt; &#xA;&lt;h3&gt;üì¢ &lt;strong&gt;Please join us for our&lt;/strong&gt; &lt;a href=&#34;https://events.nvidia.com/nvidiadynamousermeetups&#34;&gt; &lt;strong&gt;first Dynamo in-person meetup with vLLM and SGLang leads&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;on 6/5 (Thu) in SF!&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;NVIDIA Dynamo is a high-throughput low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments. Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Disaggregated prefill &amp;amp; decode inference&lt;/strong&gt; ‚Äì Maximizes GPU throughput and facilitates trade off between throughput and latency.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Dynamic GPU scheduling&lt;/strong&gt; ‚Äì Optimizes performance based on fluctuating demand&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LLM-aware request routing&lt;/strong&gt; ‚Äì Eliminates unnecessary KV cache re-computation&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Accelerated data transfer&lt;/strong&gt; ‚Äì Reduces inference response time using NIXL.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;KV cache offloading&lt;/strong&gt; ‚Äì Leverages multiple memory hierarchies for higher system throughput&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;The following examples require a few system level packages. Recommended to use Ubuntu 24.04 with a x86_64 CPU. See &lt;a href=&#34;https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/support_matrix.md&#34;&gt;docs/support_matrix.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;apt-get update&#xA;DEBIAN_FRONTEND=noninteractive apt-get install -yq python3-dev python3-pip python3-venv libucx0&#xA;python3 -m venv venv&#xA;source venv/bin/activate&#xA;&#xA;pip install &#34;ai-dynamo[all]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] To ensure compatibility, please refer to the examples in the release branch or tag that matches the version you installed.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Building the Dynamo Base Image&lt;/h3&gt; &#xA;&lt;p&gt;Although not needed for local development, deploying your Dynamo pipelines to Kubernetes will require you to build and push a Dynamo base image to your container registry. You can use any container registry of your choice, such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Docker Hub (docker.io)&lt;/li&gt; &#xA; &lt;li&gt;NVIDIA NGC Container Registry (nvcr.io)&lt;/li&gt; &#xA; &lt;li&gt;Any private registry&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Here&#39;s how to build it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./container/build.sh&#xA;docker tag dynamo:latest-vllm &amp;lt;your-registry&amp;gt;/dynamo-base:latest-vllm&#xA;docker login &amp;lt;your-registry&amp;gt;&#xA;docker push &amp;lt;your-registry&amp;gt;/dynamo-base:latest-vllm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Notes about builds for specific frameworks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For specific details on the &lt;code&gt;--framework vllm&lt;/code&gt; build, see &lt;a href=&#34;https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples/llm/README.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For specific details on the &lt;code&gt;--framework tensorrtllm&lt;/code&gt; build, see &lt;a href=&#34;https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples/tensorrt_llm/README.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note about AWS environments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If deploying Dynamo in AWS, make sure to build the container with EFA support using the &lt;code&gt;--make-efa&lt;/code&gt; flag.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;After building, you can use this image by setting the &lt;code&gt;DYNAMO_IMAGE&lt;/code&gt; environment variable to point to your built image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export DYNAMO_IMAGE=&amp;lt;your-registry&amp;gt;/dynamo-base:latest-vllm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] We are working on leaner base images that can be built using the targets in the top-level Earthfile.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Running and Interacting with an LLM Locally&lt;/h3&gt; &#xA;&lt;p&gt;To run a model and interact with it locally you can call &lt;code&gt;dynamo run&lt;/code&gt; with a hugging face model. &lt;code&gt;dynamo run&lt;/code&gt; supports several backends including: &lt;code&gt;mistralrs&lt;/code&gt;, &lt;code&gt;sglang&lt;/code&gt;, &lt;code&gt;vllm&lt;/code&gt;, and &lt;code&gt;tensorrtllm&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Example Command&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;dynamo run out=vllm deepseek-ai/DeepSeek-R1-Distill-Llama-8B&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;? User ‚Ä∫ Hello, how are you?&#xA;‚úî User ¬∑ Hello, how are you?&#xA;Okay, so I&#39;m trying to figure out how to respond to the user&#39;s greeting. They said, &#34;Hello, how are you?&#34; and then followed it with &#34;Hello! I&#39;m just a program, but thanks for asking.&#34; Hmm, I need to come up with a suitable reply. ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;LLM Serving&lt;/h3&gt; &#xA;&lt;p&gt;Dynamo provides a simple way to spin up a local set of inference components including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;OpenAI Compatible Frontend&lt;/strong&gt; ‚Äì High performance OpenAI compatible http api server written in Rust.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Basic and Kv Aware Router&lt;/strong&gt; ‚Äì Route and load balance traffic to a set of workers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt; ‚Äì Set of pre-configured LLM serving engines.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To run a minimal configuration you can use a pre-configured example.&lt;/p&gt; &#xA;&lt;h4&gt;Start Dynamo Distributed Runtime Services&lt;/h4&gt; &#xA;&lt;p&gt;First start the Dynamo Distributed Runtime services:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose -f deploy/metrics/docker-compose.yml up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Start Dynamo LLM Serving Components&lt;/h4&gt; &#xA;&lt;p&gt;Next serve a minimal configuration with an http server, basic round-robin router, and a single worker.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd examples/llm&#xA;dynamo serve graphs.agg:Frontend -f configs/agg.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Send a Request&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl localhost:8000/v1/chat/completions   -H &#34;Content-Type: application/json&#34;   -d &#39;{&#xA;    &#34;model&#34;: &#34;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&#34;,&#xA;    &#34;messages&#34;: [&#xA;    {&#xA;        &#34;role&#34;: &#34;user&#34;,&#xA;        &#34;content&#34;: &#34;Hello, how are you?&#34;&#xA;    }&#xA;    ],&#xA;    &#34;stream&#34;:false,&#xA;    &#34;max_tokens&#34;: 300&#xA;  }&#39; | jq&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Local Development&lt;/h3&gt; &#xA;&lt;p&gt;If you use vscode or cursor, we have a .devcontainer folder built on &lt;a href=&#34;https://code.visualstudio.com/docs/devcontainers/containers&#34;&gt;Microsofts Extension&lt;/a&gt;. For instructions see the &lt;a href=&#34;https://raw.githubusercontent.com/ai-dynamo/dynamo/main/.devcontainer/README.md&#34;&gt;ReadMe&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;Otherwise, to develop locally, we recommend working inside of the container&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./container/build.sh&#xA;./container/run.sh -it --mount-workspace&#xA;&#xA;cargo build --release&#xA;mkdir -p /workspace/deploy/sdk/src/dynamo/sdk/cli/bin&#xA;cp /workspace/target/release/http /workspace/deploy/sdk/src/dynamo/sdk/cli/bin&#xA;cp /workspace/target/release/llmctl /workspace/deploy/sdk/src/dynamo/sdk/cli/bin&#xA;cp /workspace/target/release/dynamo-run /workspace/deploy/sdk/src/dynamo/sdk/cli/bin&#xA;&#xA;uv pip install -e .&#xA;export PYTHONPATH=$PYTHONPATH:/workspace/deploy/sdk/src:/workspace/components/planner/src&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Conda Environment&lt;/h4&gt; &#xA;&lt;p&gt;Alternately, you can use a conda environment&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda activate &amp;lt;ENV_NAME&amp;gt;&#xA;&#xA;pip install nixl # Or install https://github.com/ai-dynamo/nixl from source&#xA;&#xA;cargo build --release&#xA;&#xA;# To install ai-dynamo-runtime from source&#xA;cd lib/bindings/python&#xA;pip install .&#xA;&#xA;cd ../../../&#xA;pip install &#34;.[all]&#34;&#xA;&#xA;# To test&#xA;docker compose -f deploy/metrics/docker-compose.yml up -d&#xA;cd examples/llm&#xA;dynamo serve graphs.agg:Frontend -f configs/agg.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>cocoindex-io/cocoindex</title>
    <updated>2025-06-05T01:36:16Z</updated>
    <id>tag:github.com,2025-06-05:/cocoindex-io/cocoindex</id>
    <link href="https://github.com/cocoindex-io/cocoindex" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Real-time data transformation framework for AI. Ultra performant, with incremental processing.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://cocoindex.io/images/github.svg?sanitize=true&#34; alt=&#34;CocoIndex&#34;&gt; &lt;/p&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Extract, Transform, Index Data. Easy and Fresh. üå¥&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/cocoindex-io/cocoindex&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cocoindex.io/docs/getting_started/quickstart&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;amp;logoColor=00B9FF&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/cocoindex/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/cocoindex?color=5B5BD6&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypistats.org/packages/cocoindex&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/cocoindex&#34; alt=&#34;PyPI - Downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml&#34;&gt;&lt;img src=&#34;https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;amp;color=5B5BD6&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml&#34;&gt;&lt;img src=&#34;https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;amp;color=5B5BD6&#34; alt=&#34;release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.com/invite/zpA9S2DR7s&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1314801574169673738?logo=discord&amp;amp;color=5B5BD6&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;strong&gt;CocoIndex&lt;/strong&gt; is an ultra performant data transformation framework, with its core engine written in Rust. The problem it tries to solve is to make it easy to prepare fresh data for AI - either creating embedding, building knowledge graphs, or performing other data transformations - and take real-time data pipelines beyond traditional SQL.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://cocoindex.io/images/cocoindex-features.png&#34; alt=&#34;CocoIndex Features&#34; width=&#34;500&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;The philosophy is to have the framework handle the source updates, and having developers only worry about defining a series of data transformation, inspired by spreadsheet.&lt;/p&gt; &#xA;&lt;h2&gt;Dataflow programming&lt;/h2&gt; &#xA;&lt;p&gt;Unlike a workflow orchestration framework where data is usually opaque, in CocoIndex, data and data operations are first class citizens. CocoIndex follows the idea of &lt;a href=&#34;https://en.wikipedia.org/wiki/Dataflow_programming&#34;&gt;Dataflow&lt;/a&gt; programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Particularly&lt;/strong&gt;, users don&#39;t explicitly mutate data by creating, updating and deleting. Rather, they define something like - for a set of source data, this is the transformation or formula. The framework takes care of the data operations such as when to create, update, or delete.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# import&#xA;data[&#39;content&#39;] = flow_builder.add_source(...) &#xA;&#xA;# transform&#xA;data[&#39;out&#39;] = data[&#39;content&#39;] &#xA;    .transform(...)&#xA;    .transform(...)&#xA;&#xA;# collect data&#xA;collector.collect(...)&#xA;&#xA;# export to db, vector db, graph db ...&#xA;collector.export(...)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Data Freshness&lt;/h2&gt; &#xA;&lt;p&gt;As a data framework, CocoIndex takes it to the next level on data freshness. &lt;strong&gt;Incremental processing&lt;/strong&gt; is one of the core values provided by CocoIndex.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6&#34; alt=&#34;Incremental Processing&#34; width=&#34;700&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;The frameworks takes care of&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Change data capture.&lt;/li&gt; &#xA; &lt;li&gt;Figure out what exactly needs to be updated, and only updating that without having to recompute everything.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This makes it fast to reflect any source updates to the target store. If you have concerns with surfacing stale data to AI agents and are spending lots of efforts working on infra piece to optimize the latency, the framework actually handles it for you.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start:&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;re new to CocoIndex, we recommend checking out&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìñ &lt;a href=&#34;https://cocoindex.io/docs&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;‚ö° &lt;a href=&#34;https://cocoindex.io/docs/getting_started/quickstart&#34;&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üé¨ &lt;a href=&#34;https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT&#34;&gt;Quick Start Video Tutorial&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install CocoIndex Python library&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -U cocoindex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cocoindex.io/docs/getting_started/installation#-install-postgres&#34;&gt;Install Postgres&lt;/a&gt; if you don&#39;t have one. CocoIndex uses it for incremental processing.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Define data flow&lt;/h3&gt; &#xA;&lt;p&gt;Follow &lt;a href=&#34;https://cocoindex.io/docs/getting_started/quickstart&#34;&gt;Quick Start Guide&lt;/a&gt; to define your first indexing flow. An example flow looks like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@cocoindex.flow_def(name=&#34;TextEmbedding&#34;)&#xA;def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):&#xA;    # Add a data source to read files from a directory&#xA;    data_scope[&#34;documents&#34;] = flow_builder.add_source(cocoindex.sources.LocalFile(path=&#34;markdown_files&#34;))&#xA;&#xA;    # Add a collector for data to be exported to the vector index&#xA;    doc_embeddings = data_scope.add_collector()&#xA;&#xA;    # Transform data of each document&#xA;    with data_scope[&#34;documents&#34;].row() as doc:&#xA;        # Split the document into chunks, put into `chunks` field&#xA;        doc[&#34;chunks&#34;] = doc[&#34;content&#34;].transform(&#xA;            cocoindex.functions.SplitRecursively(),&#xA;            language=&#34;markdown&#34;, chunk_size=2000, chunk_overlap=500)&#xA;&#xA;        # Transform data of each chunk&#xA;        with doc[&#34;chunks&#34;].row() as chunk:&#xA;            # Embed the chunk, put into `embedding` field&#xA;            chunk[&#34;embedding&#34;] = chunk[&#34;text&#34;].transform(&#xA;                cocoindex.functions.SentenceTransformerEmbed(&#xA;                    model=&#34;sentence-transformers/all-MiniLM-L6-v2&#34;))&#xA;&#xA;            # Collect the chunk into the collector.&#xA;            doc_embeddings.collect(filename=doc[&#34;filename&#34;], location=chunk[&#34;location&#34;],&#xA;                                   text=chunk[&#34;text&#34;], embedding=chunk[&#34;embedding&#34;])&#xA;&#xA;    # Export collected data to a vector index.&#xA;    doc_embeddings.export(&#xA;        &#34;doc_embeddings&#34;,&#xA;        cocoindex.storages.Postgres(),&#xA;        primary_key_fields=[&#34;filename&#34;, &#34;location&#34;],&#xA;        vector_indexes=[&#xA;            cocoindex.VectorIndexDef(&#xA;                field_name=&#34;embedding&#34;,&#xA;                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It defines an index flow like this:&lt;/p&gt; &#xA;&lt;img width=&#34;363&#34; alt=&#34;Data Flow&#34; src=&#34;https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463&#34;&gt; &#xA;&lt;h2&gt;üöÄ Examples and demo&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Example&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding&#34;&gt;Text Embedding&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Index text documents with embeddings for semantic search&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/code_embedding&#34;&gt;Code Embedding&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Index code embeddings for semantic search&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/pdf_embedding&#34;&gt;PDF Embedding&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Parse PDF and index text embeddings for semantic search&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/manuals_llm_extraction&#34;&gt;Manuals LLM Extraction&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Extract structured information from a manual using LLM&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/amazon_s3_embedding&#34;&gt;Amazon S3 Embedding&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Index text documents from Amazon S3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/gdrive_text_embedding&#34;&gt;Google Drive Text Embedding&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Index text documents from Google Drive&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/docs_to_knowledge_graph&#34;&gt;Docs to Knowledge Graph&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Extract relationships from Markdown documents and build a knowledge graph&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding_qdrant&#34;&gt;Embeddings to Qdrant&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Index documents in a Qdrant collection for semantic search&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/fastapi_server_docker&#34;&gt;FastAPI Server with Docker&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Run the semantic search server in a Dockerized FastAPI setup&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/product_recommendation&#34;&gt;Product Recommendation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Build real-time product recommendations with LLM and graph database&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/image_search&#34;&gt;Image Search with Vision API&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;More coming and stay tuned üëÄ!&lt;/p&gt; &#xA;&lt;h2&gt;üìñ Documentation&lt;/h2&gt; &#xA;&lt;p&gt;For detailed documentation, visit &lt;a href=&#34;https://cocoindex.io/docs&#34;&gt;CocoIndex Documentation&lt;/a&gt;, including a &lt;a href=&#34;https://cocoindex.io/docs/getting_started/quickstart&#34;&gt;Quickstart guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our &lt;a href=&#34;https://cocoindex.io/docs/about/contributing&#34;&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üë• Community&lt;/h2&gt; &#xA;&lt;p&gt;Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it&#39;s code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.&lt;/p&gt; &#xA;&lt;p&gt;Join our community here:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üåü &lt;a href=&#34;https://github.com/cocoindex-io/cocoindex&#34;&gt;Star us on GitHub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üëã &lt;a href=&#34;https://discord.com/invite/zpA9S2DR7s&#34;&gt;Join our Discord community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;‚ñ∂Ô∏è &lt;a href=&#34;https://www.youtube.com/@cocoindex-io&#34;&gt;Subscribe to our YouTube channel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üìú &lt;a href=&#34;https://cocoindex.io/blogs/&#34;&gt;Read our blog posts&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support us:&lt;/h2&gt; &#xA;&lt;p&gt;We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo &lt;a href=&#34;https://github.com/cocoindex-io/cocoindex&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; to stay tuned and help us grow.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;CocoIndex is Apache 2.0 licensed.&lt;/p&gt;</summary>
  </entry>
</feed>