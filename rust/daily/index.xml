<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-08-24T01:39:23Z</updated>
  <subtitle>Daily Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>intentee/paddler</title>
    <updated>2025-08-24T01:39:23Z</updated>
    <id>tag:github.com,2025-08-24:/intentee/paddler</id>
    <link href="https://github.com/intentee/paddler" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open-source LLMOps platform for hosting and scaling AI in your own infrastructure üèìü¶ô&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Paddler&lt;/h1&gt; &#xA;&lt;p&gt;Digital products and their users need privacy, reliability, cost control and an option to be independent from third party vendors.&lt;/p&gt; &#xA;&lt;p&gt;Paddler is an open-source LLMOps platform for organizations that host and scale open-source models in their own infrastructure.&lt;/p&gt; &#xA;&lt;h2&gt;Key features&lt;/h2&gt; &#xA;&lt;img align=&#34;right&#34; src=&#34;https://github.com/user-attachments/assets/19e74262-1918-4b1d-9b4c-bcb4f0ab79f5&#34; /&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Inference through a built-in &lt;a href=&#34;https://github.com/ggml-org/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; engine&lt;/li&gt; &#xA; &lt;li&gt;Load balancing&lt;/li&gt; &#xA; &lt;li&gt;Works through agents that can be added dynamically, allowing integration with autoscaling tools&lt;/li&gt; &#xA; &lt;li&gt;Request buffering, enabling scaling from zero hosts&lt;/li&gt; &#xA; &lt;li&gt;Dynamic model swapping&lt;/li&gt; &#xA; &lt;li&gt;Built-in web admin panel for management, monitoring and testing&lt;/li&gt; &#xA; &lt;li&gt;Observability metrics&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;For whom?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Product teams that need LLM inference and embeddings in their features&lt;/li&gt; &#xA; &lt;li&gt;DevOps/LLMOps teams that need to run and deploy LLMs at scale&lt;/li&gt; &#xA; &lt;li&gt;Organizations handling sensitive data with high compliance and privacy requirements (medical, financial, etc.)&lt;/li&gt; &#xA; &lt;li&gt;Organizations wanting to achieve predictable LLM costs instead of being exposed to per-token pricing&lt;/li&gt; &#xA; &lt;li&gt;Product leaders who need reliable model performance to maintain consistent user experience of their AI-based features&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Visit our &lt;a href=&#34;https://paddler.intentee.com/docs/introduction/what-is-paddler/&#34;&gt;documentation page&lt;/a&gt; to install Paddler and get started with it.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://paddler.intentee.com/api/introduction/using-paddler-api/&#34;&gt;API documentation&lt;/a&gt; is also available.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=aT6QCL8lk08&#34;&gt;Video overview&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;There are multiple ways to install Paddler, but the goal is to obtain the &lt;code&gt;paddler&lt;/code&gt; binary and make it available in your system.&lt;/p&gt; &#xA;&lt;p&gt;You can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Option 1: Download the latest release from our &lt;a href=&#34;https://github.com/intentee/paddler/releases&#34;&gt;GitHub releases&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Option 2: Build Paddler from source&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Using Paddler&lt;/h3&gt; &#xA;&lt;p&gt;The entire Paddler functionality is available through the &lt;code&gt;paddler&lt;/code&gt; command.&lt;/p&gt; &#xA;&lt;p&gt;You can run &lt;code&gt;paddler --help&lt;/code&gt; to see the available commands and options.&lt;/p&gt; &#xA;&lt;p&gt;Read more about &lt;a href=&#34;https://paddler.intentee.com/docs/introduction/installation/&#34;&gt;installation and initial setup&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How does it work?&lt;/h2&gt; &#xA;&lt;p&gt;Paddler is built for an easy set up. It comes as a self-contained binary with only two deployable components, the &lt;code&gt;balancer&lt;/code&gt; and the &lt;code&gt;agents&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The&amp;nbsp;&lt;code&gt;balancer&lt;/code&gt;&amp;nbsp;exposes the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Inference service (used by applications that connect to it to obtain tokens or embeddings)&lt;/li&gt; &#xA; &lt;li&gt;Management service, which manages the Paddler&#39;s setup internally&lt;/li&gt; &#xA; &lt;li&gt;Web admin panel that lets you view and test your Paddler setup&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;code&gt;Agents&lt;/code&gt; are usually deployed on separate instances. They further distribute the incoming requests to &lt;code&gt;slots&lt;/code&gt;, which are responsible for generating tokens and embeddings.&lt;/p&gt; &#xA;&lt;p&gt;Paddler uses a built-in llama.cpp engine for inference, but has its own implementation of llama.cpp slots which keep their own context and KV cache.&lt;/p&gt; &#xA;&lt;h3&gt;Web admin panel&lt;/h3&gt; &#xA;&lt;p&gt;Paddler comes with a built-in web admin panel.&lt;/p&gt; &#xA;&lt;p&gt;You can use it to monitor your Paddler fleet: &lt;img width=&#34;1587&#34; height=&#34;732&#34; alt=&#34;paddler-web-admin-panel&#34; src=&#34;https://github.com/user-attachments/assets/de26312e-e83e-4def-8326-0aa5d559396c&#34; /&gt;&lt;/p&gt; &#xA;&lt;p&gt;Add and update your model and customize the chat template and inference parameters: &lt;img width=&#34;1422&#34; height=&#34;1584&#34; alt=&#34;paddler-model&#34; src=&#34;https://github.com/user-attachments/assets/dd9d7eb0-a990-4b1c-b523-7286956baeb2&#34; /&gt;&lt;/p&gt; &#xA;&lt;p&gt;And use GUI to test the inference: &lt;img width=&#34;1413&#34; height=&#34;984&#34; alt=&#34;paddler-prompt&#34; src=&#34;https://github.com/user-attachments/assets/30b35b5a-c3de-4acc-a602-c7ffaa21d0a6&#34; /&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Starting out&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paddler.intentee.com/docs/starting-out/setup-a-basic-llm-cluster/&#34;&gt;Setup a basic LLM cluster&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paddler.intentee.com/docs/starting-out/using-web-admin-panel/&#34;&gt;Use Paddler&#39;s web admin panel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paddler.intentee.com/docs/starting-out/generating-tokens-and-embeddings/&#34;&gt;Generate tokens and embeddings&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paddler.intentee.com/docs/starting-out/using-function-calling/&#34;&gt;Use function calling&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paddler.intentee.com/docs/starting-out/multi-agent-fleet/&#34;&gt;Create a multi agent fleet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paddler.intentee.com/docs/starting-out/going-beyond-a-single-device/&#34;&gt;Go beyond a single device&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why the Name&lt;/h2&gt; &#xA;&lt;p&gt;We initially wanted to use &lt;a href=&#34;https://raft.github.io/&#34;&gt;Raft&lt;/a&gt; consensus algorithm (thus Paddler, because it paddles on a Raft), but eventually dropped that idea. The name stayed, though.&lt;/p&gt; &#xA;&lt;p&gt;Later, people started sending us the &#34;that&#39;s a paddlin&#39;&#34; clip from The Simpsons, and we just embraced it.&lt;/p&gt; &#xA;&lt;h2&gt;Community and contributions&lt;/h2&gt; &#xA;&lt;p&gt;We keep everything simple and on GitHub. Please use GitHub discussions for community conversations, and feel free to contribute.&lt;/p&gt;</summary>
  </entry>
</feed>