<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-26T01:36:32Z</updated>
  <subtitle>Daily Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Dicklesworthstone/fast_vector_similarity</title>
    <updated>2023-08-26T01:36:32Z</updated>
    <id>tag:github.com,2023-08-26:/Dicklesworthstone/fast_vector_similarity</id>
    <link href="https://github.com/Dicklesworthstone/fast_vector_similarity" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Fast Vector Similarity Library is designed to provide efficient computation of various similarity measures between vectors.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Fast Vector Similarity Library&lt;/h1&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;The Fast Vector Similarity Library is designed to provide efficient computation of various similarity measures between vectors. It is suitable for tasks such as data analysis, machine learning, and statistics, where measuring the relationship between vectors is essential. Written in Rust, the library offers a high-performance solution and can be easily integrated with Python through provided bindings.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt;Similarity Measures&lt;/h3&gt; &#xA;&lt;p&gt;The library implements several popular similarity measures, including:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Spearman&#39;s Rank-Order Correlation (&lt;code&gt;spearman_rho&lt;/code&gt;)&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Kendall&#39;s Tau Rank Correlation (&lt;code&gt;kendall_tau&lt;/code&gt;)&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Approximate Distance Correlation (&lt;code&gt;approximate_distance_correlation&lt;/code&gt;)&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Jensen-Shannon Similarity (&lt;code&gt;jensen_shannon_similarity&lt;/code&gt;)&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Hoeffding&#39;s D Measure (&lt;code&gt;hoeffding_d&lt;/code&gt;)&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Bootstrapping Technique&lt;/h3&gt; &#xA;&lt;p&gt;The library supports bootstrapping for robust similarity computation. This technique involves randomly resampling the dataset to estimate the distribution of the similarity measures, providing more confidence in the results.&lt;/p&gt; &#xA;&lt;h3&gt;Performance Optimizations&lt;/h3&gt; &#xA;&lt;p&gt;To achieve high efficiency, the library leverages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Parallel Computing&lt;/strong&gt;: Using the &lt;code&gt;rayon&lt;/code&gt; crate, computations are parallelized across available CPU cores.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vectorized Operations&lt;/strong&gt;: The library leverages efficient vectorized operations provided by the &lt;code&gt;ndarray&lt;/code&gt; crate.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Python Bindings&lt;/h2&gt; &#xA;&lt;p&gt;The library includes Python bindings to enable seamless integration with Python code. Functions &lt;code&gt;py_compute_vector_similarity_stats&lt;/code&gt; and &lt;code&gt;py_compute_bootstrapped_similarity_stats&lt;/code&gt; are exposed, allowing you to compute similarity statistics and bootstrapped similarity statistics, respectively.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Rust&lt;/h3&gt; &#xA;&lt;p&gt;Include the library in your Rust project by adding it to your Cargo.toml file.&lt;/p&gt; &#xA;&lt;h3&gt;Python&lt;/h3&gt; &#xA;&lt;p&gt;You can install the Python bindings for the Fast Vector Similarity Library directly from PyPI using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install fast_vector_similarity&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command will download and install the package, making it available for use in your Python projects.&lt;/p&gt; &#xA;&lt;h2&gt;Use with Text Embedding Vectors from LLMs&lt;/h2&gt; &#xA;&lt;p&gt;The Python demo code below introduces additional functionality that allows the Fast Vector Similarity Library to easily work with text embedding vectors from Language Models like LLMs (e.g., Llama2), such as those generated by my other library, the &lt;a href=&#34;https://github.com/Dicklesworthstone/llama_embeddings_fastapi_service&#34;&gt;Llama2 Embeddings FastAPI Service &lt;/a&gt; (particularly, the output of the &lt;code&gt;/get_all_embedding_vectors_for_document&lt;/code&gt; endpoint):&lt;/p&gt; &#xA;&lt;h3&gt;1. Converting Text Embeddings to Pandas DataFrame&lt;/h3&gt; &#xA;&lt;p&gt;The function &lt;code&gt;convert_embedding_json_to_pandas_df&lt;/code&gt; reads text embeddings from a JSON file and converts them into a Pandas DataFrame. Each embedding is associated with a specific text (e.g., a sentence from Shakespeare&#39;s Sonnets), and the DataFrame structure facilitates manipulation and analysis of these embeddings.&lt;/p&gt; &#xA;&lt;h3&gt;2. Applying Fast Vector Similarity to Text Embeddings&lt;/h3&gt; &#xA;&lt;p&gt;The function &lt;code&gt;apply_fvs_to_vector&lt;/code&gt; takes a row of embeddings and a query embedding, applies the chosen similarity measures, and returns the results as a JSON object. This function leverages the core similarity computation functionality provided by the Fast Vector Similarity Library, allowing it to be used directly on text embeddings.&lt;/p&gt; &#xA;&lt;h3&gt;3. Comparing Embeddings with Large Datasets&lt;/h3&gt; &#xA;&lt;p&gt;The main section of the code includes an example where text embeddings from Llama2 are loaded and analyzed. This part of the code demonstrates how to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Select a random query embedding from the dataset.&lt;/li&gt; &#xA; &lt;li&gt;Compute similarity measures between the query embedding and the rest of the dataset.&lt;/li&gt; &#xA; &lt;li&gt;Create a DataFrame to hold the similarity results.&lt;/li&gt; &#xA; &lt;li&gt;Sort and display the top 10 most similar embeddings by Hoeffding&#39;s D.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;4. Compatibility with Higher-Dimensional Embeddings&lt;/h3&gt; &#xA;&lt;p&gt;The example works with 4096-dimensional vectors, showcasing the library&#39;s ability to handle high-dimensional data typical of modern language models. This compatibility ensures that the library can be used with a wide range of language models and text embedding techniques. In fact, the library can easily handle even larger dimensions.&lt;/p&gt; &#xA;&lt;h3&gt;Example Python Code&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import time&#xA;import numpy as np&#xA;import json&#xA;import pandas as pd&#xA;from random import choice&#xA;import fast_vector_similarity as fvs&#xA;&#xA;def convert_embedding_json_to_pandas_df(file_path):&#xA;    # Read the JSON file&#xA;    with open(file_path, &#39;r&#39;) as file:&#xA;        data = json.load(file)&#xA;    # Extract the text and embeddings&#xA;    texts = [item[&#39;text&#39;] for item in data]&#xA;    embeddings = [item[&#39;embedding&#39;] for item in data]&#xA;    # Determine the total number of vectors and the dimensions of each vector&#xA;    total_vectors = len(embeddings)&#xA;    vector_dimensions = len(embeddings[0]) if total_vectors &amp;gt; 0 else 0&#xA;    # Print the total number of vectors and dimensions&#xA;    print(f&#34;Total number of vectors: {total_vectors}&#34;)&#xA;    print(f&#34;Dimensions of each vector: {vector_dimensions}&#34;)&#xA;    # Convert the embeddings into a DataFrame&#xA;    df = pd.DataFrame(embeddings, index=texts)&#xA;    return df&#xA;&#xA;def apply_fvs_to_vector(row_embedding, query_embedding):&#xA;    params = {&#xA;        &#34;vector_1&#34;: query_embedding.tolist(),&#xA;        &#34;vector_2&#34;: row_embedding.tolist(),&#xA;        &#34;similarity_measure&#34;: &#34;all&#34;&#xA;    }&#xA;    similarity_stats_str = fvs.py_compute_vector_similarity_stats(json.dumps(params))&#xA;    return json.loads(similarity_stats_str)&#xA;&#xA;def main():&#xA;    length_of_test_vectors = 15000&#xA;    print(f&#34;Generating 2 test vectors of length {length_of_test_vectors}...&#34;)&#xA;    vector_1 = np.linspace(0., length_of_test_vectors - 1, length_of_test_vectors)&#xA;    vector_2 = vector_1 ** 0.2 + np.random.rand(length_of_test_vectors)&#xA;    print(&#34;Generated vector_1 using linear spacing and vector_2 using vector_1 with a power of 0.2 and some random noise.\n&#34;)&#xA;&#xA;    similarity_measure = &#34;all&#34; # Or specify a particular measure&#xA;    params = {&#xA;        &#34;vector_1&#34;: vector_1.tolist(),&#xA;        &#34;vector_2&#34;: vector_2.tolist(),&#xA;        &#34;similarity_measure&#34;: similarity_measure&#xA;    }&#xA;    &#xA;    # Time the exact similarity calculation&#xA;    print(&#34;Computing Exact Similarity Measures...&#34;)&#xA;    start_time_exact = time.time()&#xA;    similarity_stats_str = fvs.py_compute_vector_similarity_stats(json.dumps(params))&#xA;    similarity_stats_json = json.loads(similarity_stats_str)&#xA;    elapsed_time_exact = time.time() - start_time_exact&#xA;    print(f&#34;Time taken for exact calculation: {elapsed_time_exact:.5f} seconds&#34;)&#xA;&#xA;    # Print results&#xA;    print(&#34;_______________________________________________________________________________________________________________________________________________\n&#34;)&#xA;    print(&#34;Spearman&#39;s rho:&#34;, similarity_stats_json[&#34;spearman_rho&#34;])&#xA;    print(&#34;Kendall&#39;s tau:&#34;, similarity_stats_json[&#34;kendall_tau&#34;])&#xA;    print(&#34;Distance Correlation:&#34;, similarity_stats_json[&#34;approximate_distance_correlation&#34;])&#xA;    print(&#34;Jensen-Shannon Similarity:&#34;, similarity_stats_json[&#34;jensen_shannon_similarity&#34;])&#xA;    print(&#34;Hoeffding&#39;s D:&#34;, similarity_stats_json[&#34;hoeffding_d&#34;])&#xA;    print(&#34;_______________________________________________________________________________________________________________________________________________\n&#34;)&#xA;&#xA;    # Bootstrapped calculations&#xA;    number_of_bootstraps = 2000&#xA;    n = 15&#xA;    sample_size = int(length_of_test_vectors / n)&#xA;&#xA;    print(f&#34;Computing Bootstrapped Similarity Measures with {number_of_bootstraps} bootstraps and a sample size of {sample_size}...&#34;)&#xA;    start_time_bootstrapped = time.time()&#xA;    params_bootstrapped = {&#xA;        &#34;x&#34;: vector_1.tolist(),&#xA;        &#34;y&#34;: vector_2.tolist(),&#xA;        &#34;sample_size&#34;: sample_size,&#xA;        &#34;number_of_bootstraps&#34;: number_of_bootstraps,&#xA;        &#34;similarity_measure&#34;: similarity_measure&#xA;    }&#xA;    bootstrapped_similarity_stats_str = fvs.py_compute_bootstrapped_similarity_stats(json.dumps(params_bootstrapped))&#xA;    bootstrapped_similarity_stats_json = json.loads(bootstrapped_similarity_stats_str)&#xA;    elapsed_time_bootstrapped = time.time() - start_time_bootstrapped&#xA;    print(f&#34;Time taken for bootstrapped calculation: {elapsed_time_bootstrapped:.5f} seconds&#34;)&#xA;&#xA;    time_difference = abs(elapsed_time_exact - elapsed_time_bootstrapped)&#xA;    print(f&#34;Time difference between exact and robust bootstrapped calculations: {time_difference:.5f} seconds&#34;)&#xA;    &#xA;    # Print bootstrapped results&#xA;    print(&#34;_______________________________________________________________________________________________________________________________________________\n&#34;)&#xA;    print(&#34;Number of Bootstrap Iterations:&#34;, bootstrapped_similarity_stats_json[&#34;number_of_bootstraps&#34;])&#xA;    print(&#34;Bootstrap Sample Size:&#34;, bootstrapped_similarity_stats_json[&#34;sample_size&#34;])&#xA;    print(&#34;\nRobust Spearman&#39;s rho:&#34;, bootstrapped_similarity_stats_json[&#34;spearman_rho&#34;])&#xA;    print(&#34;Robust Kendall&#39;s tau:&#34;, bootstrapped_similarity_stats_json[&#34;kendall_tau&#34;])&#xA;    print(&#34;Robust Distance Correlation:&#34;, bootstrapped_similarity_stats_json[&#34;approximate_distance_correlation&#34;])&#xA;    print(&#34;Robust Jensen-Shannon Similarity:&#34;, bootstrapped_similarity_stats_json[&#34;jensen_shannon_similarity&#34;])&#xA;    print(&#34;Robust Hoeffding&#39;s D:&#34;, bootstrapped_similarity_stats_json[&#34;hoeffding_d&#34;])&#xA;    print(&#34;_______________________________________________________________________________________________________________________________________________\n&#34;)&#xA;&#xA;    # Compute the differences between exact and bootstrapped results&#xA;    measures = [&#34;spearman_rho&#34;, &#34;kendall_tau&#34;, &#34;approximate_distance_correlation&#34;, &#34;jensen_shannon_similarity&#34;, &#34;hoeffding_d&#34;]&#xA;    for measure in measures:&#xA;        exact_value = similarity_stats_json[measure]&#xA;        bootstrapped_value = bootstrapped_similarity_stats_json[measure]&#xA;        absolute_difference = abs(exact_value - bootstrapped_value)&#xA;        percentage_difference = (absolute_difference / exact_value) * 100&#xA;&#xA;        print(f&#34;\nDifference between exact and bootstrapped {measure}: {absolute_difference}&#34;)&#xA;        print(f&#34;Difference as % of the exact value: {percentage_difference:.2f}%&#34;)&#xA;&#xA;    print(&#34;Now testing with a larger dataset, using sentence embedddings from Llama2 (4096-dimensional vectors) on some Shakespeare Sonnets...&#34;)&#xA;    # Load the embeddings into a DataFrame&#xA;    input_file_path = &#34;sample_input_files/Shakespeare_Sonnets_small.json&#34;&#xA;    embeddings_df = convert_embedding_json_to_pandas_df(input_file_path)&#xA;    &#xA;    # Select a random row for the query embedding&#xA;    query_embedding_index = choice(embeddings_df.index)&#xA;    query_embedding = embeddings_df.loc[query_embedding_index]&#xA;    print(f&#34;Selected query embedding for sentence: `{query_embedding_index}`&#34;)&#xA;&#xA;    # Remove the selected row from the DataFrame&#xA;    embeddings_df = embeddings_df.drop(index=query_embedding_index)&#xA;&#xA;    # Apply the function to each row of embeddings_df&#xA;    json_outputs = embeddings_df.apply(lambda row: apply_fvs_to_vector(row, query_embedding), axis=1)&#xA;&#xA;    # Create a DataFrame from the list of JSON outputs&#xA;    vector_similarity_results_df = pd.DataFrame.from_records(json_outputs)&#xA;    vector_similarity_results_df.index = embeddings_df.index&#xA;&#xA;    # Add the required columns to the DataFrame&#xA;    columns = [&#34;spearman_rho&#34;, &#34;kendall_tau&#34;, &#34;approximate_distance_correlation&#34;, &#34;jensen_shannon_similarity&#34;, &#34;hoeffding_d&#34;]&#xA;    vector_similarity_results_df = vector_similarity_results_df[columns]&#xA;    &#xA;    # Sort the DataFrame by the hoeffding_d column in descending order&#xA;    vector_similarity_results_df = vector_similarity_results_df.sort_values(by=&#34;hoeffding_d&#34;, ascending=False)&#xA;    &#xA;    print(&#34;\nTop 10 most similar embedding results by Hoeffding&#39;s D:&#34;)&#xA;    print(vector_similarity_results_df.head(10))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Screenshot of Output:&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Dicklesworthstone/fast_vector_similarity/assets/35050222/a3445767-f574-4627-808a-30c347271757&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;In Rust&lt;/h3&gt; &#xA;&lt;p&gt;You can utilize the core functionality in Rust by calling functions like &lt;code&gt;compute_vector_similarity_stats&lt;/code&gt; and &lt;code&gt;compute_bootstrapped_similarity_stats&lt;/code&gt; with appropriate parameters.&lt;/p&gt; &#xA;&lt;h3&gt;In Python&lt;/h3&gt; &#xA;&lt;p&gt;Install the provided Python package and use the functions as demonstrated in the example above.&lt;/p&gt; &#xA;&lt;h2&gt;About the Different Similarity Measures&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spearman&#39;s Rank-Order Correlation (&lt;code&gt;spearman_rho&lt;/code&gt;)&lt;/strong&gt;: Spearman&#39;s rho assesses the strength and direction of the monotonic relationship between two ranked variables. Unlike Pearson&#39;s correlation, it does not assume linearity and is less sensitive to outliers, making it suitable for non-linear relationships.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Kendall&#39;s Tau Rank Correlation (&lt;code&gt;kendall_tau&lt;/code&gt;)&lt;/strong&gt;: Kendall&#39;s tau measures the ordinal association between two variables. It&#39;s valuable for its ability to handle ties and its interpretability as a probability. Unlike other correlation measures, it&#39;s based on the difference between concordant and discordant pairs, making it robust and versatile.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Approximate Distance Correlation (&lt;code&gt;approximate_distance_correlation&lt;/code&gt;)&lt;/strong&gt;: Distance correlation quantifies both linear and non-linear dependencies between variables. It has the powerful property of being zero if and only if the variables are independent. This makes it a more comprehensive measure of association than traditional correlation metrics.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Jensen-Shannon Similarity (&lt;code&gt;jensen_shannon_similarity&lt;/code&gt;)&lt;/strong&gt;: Jensen-Shannon Similarity is derived from the Jensen-Shannon Divergence, a symmetrical and smoothed version of the Kullback-Leibler divergence. It quantifies the similarity between two probability distributions and is especially useful in comparing distributions that may have non-overlapping support.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hoeffding&#39;s D Measure (&lt;code&gt;hoeffding_d&lt;/code&gt;)&lt;/strong&gt;: Hoeffding&#39;s D is a non-parametric measure that detects complex non-linear relationships between variables. The D statistic is robust against various alternatives to independence, including non-monotonic relationships. It&#39;s particularly useful when the nature of the relationship between variables is unknown or unconventional.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Each of these measures has unique properties and applicability, providing a comprehensive toolkit for understanding the relationships between variables in different contexts. By including both classical and more specialized measures, the library offers flexibility and depth in analyzing vector similarities.&lt;/p&gt; &#xA;&lt;h2&gt;Bootstrapping Technique for Robust Estimators&lt;/h2&gt; &#xA;&lt;p&gt;Bootstrapping is a powerful statistical method that allows us to estimate the distribution of a statistic by repeatedly resampling with replacement from the observed data. In the context of the Fast Vector Similarity Library, bootstrapping is employed to obtain robust estimators of similarity measures between vectors. Here&#39;s how it works:&lt;/p&gt; &#xA;&lt;h3&gt;Process&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Random Subset Selection&lt;/strong&gt;: For each bootstrap iteration, a random subset of indices is selected from the original vectors. These indices are used to create resampled vectors that preserve the original data&#39;s structure and relationships.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Compute Similarity&lt;/strong&gt;: The selected random subset of indices is used to compute the similarity between the resampled vectors according to the chosen similarity measure. This process is repeated many times, resulting in a distribution of similarity estimates.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Robust Averaging&lt;/strong&gt;: To obtain a robust estimator that is less sensitive to outliers, the interquartile range (IQR) of the distribution of similarity estimates is considered. By keeping only the values within the IQR, the influence of extreme values is minimized. A robust average of the values within this range provides the final robust similarity estimate.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Why It&#39;s Useful&lt;/h3&gt; &#xA;&lt;p&gt;The bootstrapping technique offers several advantages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Robustness to Outliers&lt;/strong&gt;: By focusing on the interquartile range and using a robust average, bootstrapping minimizes the influence of outliers. This makes the estimator more reliable, especially when the original data may contain anomalous values.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model-Free Estimation&lt;/strong&gt;: Bootstrapping doesn&#39;t assume a specific underlying distribution, making it a non-parametric method. This flexibility allows it to be applied to various types of data and similarity measures.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Confidence Intervals&lt;/strong&gt;: Bootstrapping can also be used to construct confidence intervals for the similarity measures. These intervals provide insights into the uncertainty associated with the estimate, enhancing interpretability.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enhanced Understanding of Relationships&lt;/strong&gt;: By assessing the distribution of similarity measures, bootstrapping provides a more comprehensive view of the relationships between vectors. This deeper understanding can be vital in contexts like data analysis, where subtle differences in relationships may have significant implications.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The inclusion of the bootstrapping technique in the Fast Vector Similarity Library adds a layer of robustness and flexibility to the computation of similarity measures. It offers users a way to obtain more reliable and insightful estimates, accommodating various data characteristics and analytical needs. Whether dealing with potential outliers or seeking a more nuanced understanding of vector relationships, bootstrapping provides a valuable tool within the library&#39;s comprehensive suite of features.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kdash-rs/kdash</title>
    <updated>2023-08-26T01:36:32Z</updated>
    <id>tag:github.com,2023-08-26:/kdash-rs/kdash</id>
    <link href="https://github.com/kdash-rs/kdash" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A simple and fast dashboard for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;KDash - A fast and simple dashboard for Kubernetes&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/kdash-rs/kdash/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;ci&#34;&gt; &lt;img src=&#34;https://github.com/kdash-rs/kdash/actions/workflows/cd.yml/badge.svg?sanitize=true&#34; alt=&#34;cd&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/license-MIT-blueviolet.svg?sanitize=true&#34; alt=&#34;License&#34;&gt; &lt;img src=&#34;https://tokei.rs/b1/github/kdash-rs/kdash?category=code&#34; alt=&#34;LOC&#34;&gt; &lt;a href=&#34;https://crates.io/crates/kdash&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/v/kdash.svg?sanitize=true&#34; alt=&#34;crates.io link&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/docker/v/deepu105/kdash?label=Docker%20version&#34; alt=&#34;Docker Release&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/kdash-rs/kdash?color=%23c694ff&#34; alt=&#34;Release&#34;&gt; &lt;a href=&#34;https://coveralls.io/github/kdash-rs/kdash?branch=main&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/kdash-rs/kdash/badge.svg?branch=main&#34; alt=&#34;Coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kdash-rs/kdash/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/kdash-rs/kdash/total.svg?label=GitHub%20downloads&#34; alt=&#34;GitHub Downloads&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/deepu105/kdash?label=Docker%20downloads&#34; alt=&#34;Docker pulls&#34;&gt; &lt;img src=&#34;https://img.shields.io/crates/d/kdash?label=Crate%20downloads&#34; alt=&#34;Crate.io downloads&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/intent/follow?screen_name=deepu105&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/deepu105?label=Follow%20Deepu%20K%20Sasidharan%20%28deepu105%29&amp;amp;style=social&#34; alt=&#34;Follow Deepu K Sasidharan (deepu105)&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kdash-rs/kdash/main/artwork/logo.png&#34; alt=&#34;logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A simple terminal dashboard for Kubernetes built with Rust&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kdash-rs/kdash/main/screenshots/ui.gif&#34; alt=&#34;UI&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to the sponsors of &lt;a href=&#34;https://github.com/sponsors/deepu105&#34;&gt;@deepu105&lt;/a&gt; who makes maintaining projects like KDash sustainable. Consider &lt;a href=&#34;https://github.com/sponsors/deepu105&#34;&gt;sponsoring&lt;/a&gt; if you like the work.&lt;/p&gt; &#xA;&lt;!-- ### Gold&#xA;&#xA;### Silver --&gt; &#xA;&lt;h3&gt;Bronze&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://home.robusta.dev/&#34;&gt;Robusta - Kubernetes monitoring&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Gold and Silver tiers are open for &lt;a href=&#34;https://github.com/sponsors/deepu105&#34;&gt;Sponsors&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Homebrew (Mac &amp;amp; Linux)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew tap kdash-rs/kdash&#xA;brew install kdash&#xA;&#xA;# If you need to be more specific, use:&#xA;brew install kdash-rs/kdash/kdash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To upgrade&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew upgrade kdash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Scoop (Windows - Recommended way)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;scoop bucket add kdash-bucket https://github.com/kdash-rs/scoop-kdash&#xA;&#xA;scoop install kdash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Chocolatey (Windows)&lt;/h3&gt; &#xA;&lt;p&gt;Chocolatey package is located &lt;a href=&#34;https://chocolatey.org/packages/kdash&#34;&gt;here&lt;/a&gt;. Since validation of the package takes forever, it may take a long while to become available after a release. I would recommend using Scoop instead for Windows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;choco install kdash&#xA;&#xA;# Version number may be required for newer releases, if available:&#xA;choco install kdash --version=0.2.7&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To upgrade&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;choco upgrade kdash --version=0.2.7&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Nix&lt;/h3&gt; &#xA;&lt;p&gt;Try out kdash via &lt;code&gt;nix run nixpkgs#kdash&lt;/code&gt; or add &lt;code&gt;kdash&lt;/code&gt; to your &lt;code&gt;configuration.nix&lt;/code&gt; for permanent installation.&lt;/p&gt; &#xA;&lt;h3&gt;Install script&lt;/h3&gt; &#xA;&lt;p&gt;Run the below command to install the latest binary. Run with sudo if you don&#39;t have write access to &lt;code&gt;/usr/local/bin&lt;/code&gt;. Else the script will install to the current directory&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl https://raw.githubusercontent.com/kdash-rs/kdash/main/deployment/getLatest.sh | bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Manual&lt;/h3&gt; &#xA;&lt;p&gt;Binaries for macOS, Linux and Windows are available on the &lt;a href=&#34;https://github.com/kdash-rs/kdash/releases&#34;&gt;releases&lt;/a&gt; page&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the latest &lt;a href=&#34;https://github.com/kdash-rs/kdash/releases&#34;&gt;binary&lt;/a&gt; for your OS.&lt;/li&gt; &#xA; &lt;li&gt;For Linux/macOS: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;&lt;code&gt;cd&lt;/code&gt; to the file you just downloaded and run &lt;code&gt;tar -C /usr/local/bin -xzf downloaded-file-name&lt;/code&gt;. Use sudo if required.&lt;/li&gt; &#xA;   &lt;li&gt;Run with &lt;code&gt;kdash&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;For Windows: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Use 7-Zip or TarTool to unpack the tar file.&lt;/li&gt; &#xA;   &lt;li&gt;Run the executable file &lt;code&gt;kdash.exe&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;Run KDash as a Docker container by mounting your &lt;code&gt;KUBECONFIG&lt;/code&gt;. For example the below command for the default path&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm -it -v ~/.kube/config:/root/.kube/config deepu105/kdash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also clone this repo and run &lt;code&gt;make docker&lt;/code&gt; to build a docker image locally and run it using the above command&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This may not work properly if you run Kubernetes locally using Minikube or Kind&lt;/p&gt; &#xA;&lt;h3&gt;Cargo&lt;/h3&gt; &#xA;&lt;p&gt;If you have Cargo installed then you install KDash from crates.io&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo install kdash&#xA;&#xA;# if you face issues with k8s-openapi crate try the below&#xA;cargo install --locked kdash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: On Debian/Ubuntu you might need to install &lt;code&gt;libxcb-xfixes0-dev&lt;/code&gt; and &lt;code&gt;libxcb-shape0-dev&lt;/code&gt;. On Fedora &lt;code&gt;libxcb&lt;/code&gt; and &lt;code&gt;libxcb-devel&lt;/code&gt; would be needed.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: On Linux you might need to have package &lt;code&gt;xorg-dev&lt;/code&gt; (Debian/Ubuntu) or &lt;code&gt;xorg-x11-server-devel&lt;/code&gt; (Fedora) or equivalent installed for the copy to clipboard features to work&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: If you are getting compilation error from openSSL. Make sure perl and perl-core are installed for your OS.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;You can also clone the repo and run &lt;code&gt;cargo run&lt;/code&gt; or &lt;code&gt;make&lt;/code&gt; to build and run the app&lt;/p&gt; &#xA;&lt;h2&gt;USAGE:&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kdash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Press &lt;code&gt;?&lt;/code&gt; while running the app to see keybindings&lt;/p&gt; &#xA;&lt;h2&gt;FLAGS:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;-h, --help&lt;/code&gt;: Prints help information&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-V, --version&lt;/code&gt;: Prints version information&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-t, --tick-rate &amp;lt;tick-rate&amp;gt;&lt;/code&gt;: Set the tick rate (milliseconds): the lower the number the higher the FPS.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-p, --poll-rate &amp;lt;poll-rate&amp;gt;&lt;/code&gt;: Set the network call polling rate (milliseconds, should be multiples of tick-rate): the lower the number the higher the network calls.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Limitations/Known issues&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[Windows] KDash looks better on CMD since Powershell&#39;s default theme makes the colours look weird.&lt;/li&gt; &#xA; &lt;li&gt;[Windows] If using k3d for local clusters, set the server URL to 127.0.0.1 as 0.0.0.0 doesn&#39;t work with kube-rs. You can use &lt;code&gt;k3d cluster create --api-port 127.0.0.1:6550&lt;/code&gt; or change the &lt;code&gt;cluster.server&lt;/code&gt; value in your &lt;code&gt;.kube/config&lt;/code&gt; for the k3d cluster to &lt;code&gt;127.0.0.1:&amp;lt;port&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CLI info&lt;/li&gt; &#xA; &lt;li&gt;Node metrics&lt;/li&gt; &#xA; &lt;li&gt;Resource watch (configurable polling interval with &lt;code&gt;-p&lt;/code&gt; flag)&lt;/li&gt; &#xA; &lt;li&gt;Custom resource definitions&lt;/li&gt; &#xA; &lt;li&gt;Describe resources &amp;amp; copy the output&lt;/li&gt; &#xA; &lt;li&gt;Get YAML for resources &amp;amp; copy the output&lt;/li&gt; &#xA; &lt;li&gt;Stream container logs&lt;/li&gt; &#xA; &lt;li&gt;Context &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Context info&lt;/li&gt; &#xA;   &lt;li&gt;Context watch&lt;/li&gt; &#xA;   &lt;li&gt;Change namespace&lt;/li&gt; &#xA;   &lt;li&gt;Context switch&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Resources utilizations for nodes, pods and namespaces based on metrics server. Requires &lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/#metrics-server&#34;&gt;metrics-server&lt;/a&gt; to be deployed on the cluster.&lt;/li&gt; &#xA; &lt;li&gt;Dark/Light themes&lt;/li&gt; &#xA; &lt;li&gt;Sensible keyboard shortcuts&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;h3&gt;Overview screen&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kdash-rs/kdash/main/screenshots/overview.png&#34; alt=&#34;UI&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Container logs screen (light theme)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kdash-rs/kdash/main/screenshots/logs.png&#34; alt=&#34;UI&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Pod describe screen (light theme)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kdash-rs/kdash/main/screenshots/describe.png&#34; alt=&#34;UI&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Contexts screen&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kdash-rs/kdash/main/screenshots/contexts.png&#34; alt=&#34;UI&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Utilization screen&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kdash-rs/kdash/main/screenshots/utilization.png&#34; alt=&#34;UI&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Libraries used&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/fdehau/tui-rs&#34;&gt;tui-rs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crossterm-rs/crossterm&#34;&gt;crossterm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/clap-rs/clap&#34;&gt;clap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tokio-rs/tokio&#34;&gt;tokio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/oconnor663/duct.rs&#34;&gt;duct.rs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/clux/kube-rs&#34;&gt;kube-rs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/serde-rs/serde&#34;&gt;serde&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/davidB/kubectl-view-allocations&#34;&gt;kubectl-view-allocations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aweinstock314/rust-clipboard&#34;&gt;rust-clipboard&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How does this compare to K9S?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/derailed/k9s&#34;&gt;K9S&lt;/a&gt; is a beast compared to this as it offers way more features including CRUD actions.&lt;/p&gt; &#xA;&lt;p&gt;KDash only offers a view of the resources with a focus on speed and UX. Really, if something is slow or has bad UX then please raise a bug. Hence the UI/UX is designed to be more user-friendly and easier to navigate with contextual help everywhere and a tab system to switch between different resources easily.&lt;/p&gt; &#xA;&lt;p&gt;At least for now, there are no plans to add full CRUD for resources but in the future, we might.&lt;/p&gt; &#xA;&lt;h2&gt;Licence&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt; &#xA;&lt;h2&gt;Creator&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://deepu.tech/&#34;&gt;Deepu K Sasidharan&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/kdash-rs/kdash/graphs/contributors&#34;&gt;Contributors&lt;/a&gt;&lt;/h2&gt;</summary>
  </entry>
</feed>