<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-08T01:42:29Z</updated>
  <subtitle>Daily Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ArroyoSystems/arroyo</title>
    <updated>2023-04-08T01:42:29Z</updated>
    <id>tag:github.com,2023-04-08:/ArroyoSystems/arroyo</id>
    <link href="https://github.com/ArroyoSystems/arroyo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Arroyo is a distributed stream processing engine written in Rust&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ArroyoSystems/arroyo/master/docs/images/arroyo_logo.png&#34; width=&#34;400px&#34; alt=&#34;Arroyo&#34;&gt; &lt;/h1&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;a href=&#34;https://arroyo.dev/&#34;&gt;Arroyo Cloud&lt;/a&gt; | &lt;a href=&#34;https://doc.arroyo.dev/getting-started&#34;&gt;Getting started&lt;/a&gt; | &lt;a href=&#34;https://doc.arroyo.dev&#34;&gt;Docs&lt;/a&gt; | &lt;a href=&#34;https://discord.gg/cjCr5rVmyR&#34;&gt;Discord&lt;/a&gt; | &lt;a href=&#34;https://arroyo.dev&#34;&gt;Website&lt;/a&gt; &lt;/h4&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/ArroyoSystems/arroyo/raw/master/LICENSE-APACHE&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/license-MIT%2FApache--2.0-orange&#34; alt=&#34;Arroyo is dual-licensed under Apache 2 and MIT licenses.&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/ArroyoSystems/arroyo/raw/master/CONTRIBUTING.md&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/PRs-Welcome-brightgreen&#34; alt=&#34;PRs welcome!&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/ArroyoSystems/arroyo/commits&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/commit-activity/m/ArroyoSystems/arroyo&#34; alt=&#34;git commit activity&#34;&gt; &lt;/a&gt; &lt;img alt=&#34;CI&#34; src=&#34;https://github.com/ArroyoSystems/arroyo/actions/workflows/ci.yml/badge.svg?sanitize=true&#34;&gt; &lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arroyo.dev&#34;&gt;Arroyo&lt;/a&gt; is a distributed stream processing engine written in Rust, designed to efficiently perform stateful computations on streams of data. Unlike traditional batch processing, streaming engines can operate on both bounded and unbounded sources, emitting results as soon as they are available.&lt;/p&gt; &#xA;&lt;p&gt;In short: Arroyo lets you ask complex questions of high-volume real-time data with subsecond results.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ArroyoSystems/arroyo/master/docs/images/header_image.png&#34; alt=&#34;running job&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;ü¶Ä SQL and Rust pipelines&lt;/p&gt; &#xA;&lt;p&gt;üöÄ Scales up to millions of events per second&lt;/p&gt; &#xA;&lt;p&gt;ü™ü Stateful operations like windows and joins&lt;/p&gt; &#xA;&lt;p&gt;üî•State checkpointing for fault-tolerance and recovery of pipelines&lt;/p&gt; &#xA;&lt;p&gt;üïí Timely stream processing via the &lt;a href=&#34;https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/&#34;&gt;Dataflow model&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Use cases&lt;/h2&gt; &#xA;&lt;p&gt;Some example use cases include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Detecting fraud and security incidents&lt;/li&gt; &#xA; &lt;li&gt;Real-time product and business analytics&lt;/li&gt; &#xA; &lt;li&gt;Real-time ingestion into your data warehouse or data lake&lt;/li&gt; &#xA; &lt;li&gt;Real-time ML feature generation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why Arroyo&lt;/h2&gt; &#xA;&lt;p&gt;There are already a number of existing streaming engines out there, including &lt;a href=&#34;https://flink.apache.org&#34;&gt;Apache Flink&lt;/a&gt;, &lt;a href=&#34;https://spark.apache.org/docs/latest/streaming-programming-guide.html&#34;&gt;Spark Streaming&lt;/a&gt;, and &lt;a href=&#34;https://kafka.apache.org/documentation/streams/&#34;&gt;Kafka Streams&lt;/a&gt;. Why create a new one?&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Serverless operations&lt;/em&gt;: Arroyo pipelines are designed to run in modern cloud environments, supporting seamless scaling, recovery, and rescheduling&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;High performance SQL&lt;/em&gt;: SQL is a first-class concern, with consistently excellent performance&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Designed for non-experts&lt;/em&gt;: Arroyo cleanly separates the pipeline APIs from its internal implementation. You don&#39;t need to be a streaming expert to build real-time data pipelines.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Current state&lt;/h2&gt; &#xA;&lt;p&gt;Arroyo is currently alpha. It is missing features and has known bugs. At this stage, it is likely to primarily be of interest to the Rust data processing community and contributors.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;You can get started with a single node Arroyo cluster by running the following docker command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ docker run -p 8000:8000 -p 8001:8001 ghcr.io/arroyosystems/arroyo-single:multi-arch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, load the Web UI at &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For a more in-depth guide, see the &lt;a href=&#34;https://doc.arroyo.dev/getting-started&#34;&gt;getting started guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Once you have Arroyo running, follow the &lt;a href=&#34;https://doc.arroyo.dev/tutorial&#34;&gt;tutorial&lt;/a&gt; to create your first real-time pipeline.&lt;/p&gt; &#xA;&lt;h2&gt;Developing Arroyo&lt;/h2&gt; &#xA;&lt;p&gt;We love contributions from the community! See the &lt;a href=&#34;https://doc.arroyo.dev/developing/dev-setup&#34;&gt;developer setup&lt;/a&gt; guide to get started, and reach out to the team on &lt;a href=&#34;https://discord.gg/cjCr5rVmyR&#34;&gt;discord&lt;/a&gt; or create an issue.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/cjCr5rVmyR&#34;&gt;Discord&lt;/a&gt; ‚Äî support and project discussion&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ArroyoSystems/arroyo/issues&#34;&gt;GitHub issues&lt;/a&gt; ‚Äî bugs and feature requests&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arroyo.dev/blog&#34;&gt;Arroyo Blog&lt;/a&gt; ‚Äî updates from the Arroyo team&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Arroyo Cloud&lt;/h2&gt; &#xA;&lt;p&gt;Don&#39;t want to self-host? Arroyo Systems provides fully-managed cloud hosting for Arroyo. Sign up &lt;a href=&#34;https://arroyo.dev&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>sobelio/llm-chain</title>
    <updated>2023-04-08T01:42:29Z</updated>
    <id>tag:github.com,2023-04-08:/sobelio/llm-chain</id>
    <link href="https://github.com/sobelio/llm-chain" rel="alternate"></link>
    <summary type="html">&lt;p&gt;`llm-chain` is a powerful rust crate for building chains in large language models allowing you to summarise text and complete complex tasks&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;llm-chain üöÄ&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;llm-chain&lt;/code&gt; is a collection of Rust crates designed to help you work with Large Language Models (LLMs) more effectively. Our primary focus is on providing robust support for prompt templates and chaining together prompts in multi-step chains, enabling complex tasks that LLMs can&#39;t handle in a single step. This includes, but is not limited to, summarizing lengthy texts or performing advanced data processing tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/sobelio/llm-chain/cicd.yaml?branch=main?style=flat-square&#34; alt=&#34;GitHub Workflow Status&#34;&gt; &lt;img src=&#34;https://img.shields.io/crates/v/llm-chain?style=flat-square&#34; alt=&#34;Crates.io&#34;&gt; &lt;img src=&#34;https://img.shields.io/crates/l/llm-chain-openai?style=flat-square&#34; alt=&#34;Crates.io&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/sobelio/llm-chain&#34; alt=&#34;License&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Examples üí°&lt;/h2&gt; &#xA;&lt;p&gt;To help you get started, here is an example demonstrating how to use &lt;code&gt;llm-chain&lt;/code&gt;. You can find more examples in the &lt;a href=&#34;https://raw.githubusercontent.com/sobelio/llm-chain/main/llm-chain-openai/examples&#34;&gt;examples folder&lt;/a&gt; in the repository.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let exec = Executor::new_default();&#xA;let chain = Step::new(&#xA;    Model::ChatGPT3_5Turbo,&#xA;    [&#xA;        (Role::System, &#34;You are a bot for making personalized greetings&#34;),&#xA;        (Role::User, &#34;Make a personalied greet for Joe&#34;),&#xA;    ]&#xA;).to_chain();&#xA;let res = chain.run(Parameters::new(), exec).await.unwrap();&#xA;println!(&#34;{:?}&#34;, res);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Features üåü&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Prompt templates&lt;/strong&gt;: Create reusable and easily customizable prompt templates for consistent and structured interactions with LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chains&lt;/strong&gt;: Build powerful chains of prompts that allow you to execute more complex tasks, step by step, leveraging the full potential of LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ChatGPT support&lt;/strong&gt;: Currently supports ChatGPT models, with plans to add support for more LLMs in the future.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Extensibility&lt;/strong&gt;: Designed with extensibility in mind, making it easy to integrate additional LLMs as the ecosystem grows.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Community-driven&lt;/strong&gt;: We welcome and encourage contributions from the community to help improve and expand the capabilities of &lt;code&gt;llm-chain&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started üöÄ&lt;/h2&gt; &#xA;&lt;p&gt;To start using &lt;code&gt;llm-chain&lt;/code&gt;, add it as a dependency in your &lt;code&gt;Cargo.toml&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dependencies]&#xA;llm-chain = &#34;0.1.0&#34;&#xA;llm-chain-openai = &#34;0.1.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, refer to the &lt;a href=&#34;https://docs.rs/llm-chain&#34;&gt;documentation&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/sobelio/llm-chain/main/llm-chain-openai/examples&#34;&gt;examples&lt;/a&gt; to learn how to create prompt templates, chains, and more.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing ü§ù&lt;/h2&gt; &#xA;&lt;p&gt;We warmly welcome contributions from everyone! If you&#39;re interested in helping improve &lt;code&gt;llm-chain&lt;/code&gt;, please check out our &lt;a href=&#34;https://raw.githubusercontent.com/sobelio/llm-chain/main/docs/CONTRIBUTING.md&#34;&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; file for guidelines and best practices.&lt;/p&gt; &#xA;&lt;h2&gt;License üìÑ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;llm-chain&lt;/code&gt; is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/sobelio/llm-chain/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Connect with Us üåê&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, suggestions, or feedback, feel free to open an issue or join our community discussions. We&#39;re always excited to hear from our users and learn about your experiences with &lt;code&gt;llm-chain&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We hope you enjoy using &lt;code&gt;llm-chain&lt;/code&gt; to unlock the full potential of Large Language Models in your projects. Happy coding! üéâ&lt;/p&gt;</summary>
  </entry>
</feed>