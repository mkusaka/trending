<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-08-10T06:01:17Z</updated>
  <subtitle>Daily Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>guidance-ai/llguidance</title>
    <updated>2025-08-10T06:01:17Z</updated>
    <id>tag:github.com,2025-08-10:/guidance-ai/llguidance</id>
    <link href="https://github.com/guidance-ai/llguidance" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Super-fast Structured Outputs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Low-level Guidance (llguidance)&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/guidance-ai/jsonschemabench/raw/main/maskbench/plots/hero.png&#34; width=&#34;700&#34; /&gt; &lt;br /&gt; &lt;em&gt;Performance results from &lt;a href=&#34;https://github.com/guidance-ai/jsonschemabench/tree/main/maskbench&#34;&gt;MaskBench&lt;/a&gt;&lt;/em&gt; &lt;/p&gt; &#xA;&lt;hr /&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2025-06-23 llguidance is now deemed v1.0.0&lt;/li&gt; &#xA; &lt;li&gt;2025-06-11 &lt;a href=&#34;https://guidance-ai.github.io/llguidance/llg-go-brrr&#34;&gt;Making Structured Outputs Go Brrr&lt;/a&gt; blog post released&lt;/li&gt; &#xA; &lt;li&gt;2025-05-20 LLGuidance &lt;a href=&#34;https://x.com/OpenAIDevs/status/1924915341052019166&#34;&gt;shipped&lt;/a&gt; in &lt;a href=&#34;https://x.com/OpenAIDevs/status/1924915343677653014&#34;&gt;OpenAI&lt;/a&gt; for JSON Schema&lt;/li&gt; &#xA; &lt;li&gt;2025-04-11 integration &lt;a href=&#34;https://github.com/chromium/chromium/commit/07ca6337c2f714ba0477202414bd2b1692e70594&#34;&gt;merged&lt;/a&gt; into Chromium&lt;/li&gt; &#xA; &lt;li&gt;2025-03-25 integration &lt;a href=&#34;https://github.com/vllm-project/vllm/pull/14779&#34;&gt;merged&lt;/a&gt; into vLLM (v0.8.2)&lt;/li&gt; &#xA; &lt;li&gt;2025-02-26 integration &lt;a href=&#34;https://github.com/sgl-project/sglang/pull/3298&#34;&gt;merged&lt;/a&gt; into SGLang (v0.4.4)&lt;/li&gt; &#xA; &lt;li&gt;2025-02-01 integration &lt;a href=&#34;https://github.com/ggml-org/llama.cpp/pull/10224&#34;&gt;merged&lt;/a&gt; into llama.cpp (b4613)&lt;/li&gt; &#xA; &lt;li&gt;2025-01-21 &lt;a href=&#34;https://github.com/guidance-ai/jsonschemabench&#34;&gt;JSONSchemaBench&lt;/a&gt; released, including &lt;a href=&#34;https://arxiv.org/abs/2501.10868&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https://github.com/guidance-ai/jsonschemabench/tree/main/maskbench&#34;&gt;MaskBench&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;2025-01-07 Guidance &lt;a href=&#34;https://github.com/guidance-ai/guidance/releases/tag/0.2.0&#34;&gt;v0.2.0&lt;/a&gt; released, using llguidance as the grammar engine&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr /&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;This library implements constrained decoding (also called constrained sampling or structured outputs) for Large Langauge Models (LLMs). It can enforce arbitrary context-free grammar on the output of LLM and is fast - on the order of 50μs of CPU time per token (for 128k tokenizer) with negligible startup costs.&lt;/p&gt; &#xA;&lt;p&gt;Following grammar formats are supported:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/docs/json_schema.md&#34;&gt;a large subset&lt;/a&gt; of JSON schemas&lt;/li&gt; &#xA; &lt;li&gt;regular expressions&lt;/li&gt; &#xA; &lt;li&gt;context-free grammars in a &lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/docs/syntax.md&#34;&gt;variation of Lark format&lt;/a&gt;; with embedded JSON schemas and regular expressions&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;llguidance&lt;/code&gt; - &lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/parser/src/api.rs&#34;&gt;internal (JSON-based) format&lt;/a&gt;; slowly being deprecated in favor of the Lark-like format&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The internal format is most powerful (though Lark-like format is catching up, and there are plans to convert the libraries to use it) and can be generated by the following libraries:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/guidance-ai/guidance&#34;&gt;Guidance&lt;/a&gt; (Python)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mmoskal/guidance-ts&#34;&gt;guidance.ts&lt;/a&gt; (TypeScript)&lt;/li&gt; &#xA; &lt;li&gt;hopefully more to come!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The library can be used from:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/parser/README.md&#34;&gt;Rust&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/sample_parser/src/minimal.rs&#34;&gt;sample&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/parser/llguidance.h&#34;&gt;C and C++&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/c_sample/c_sample.cpp&#34;&gt;sample&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/python/llguidance/_lib.pyi&#34;&gt;Python&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Integrations&lt;/h2&gt; &#xA;&lt;p&gt;The library is currently integrated in:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/guidance-ai/guidance&#34;&gt;Guidance&lt;/a&gt; - library for interacting with LLMs&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://x.com/OpenAIDevs/status/1924915343677653014&#34;&gt;OpenAI models&lt;/a&gt; - LLGuidance powers &lt;a href=&#34;https://platform.openai.com/docs/guides/structured-outputs&#34;&gt;Structured Output&lt;/a&gt; (JSON Schema only)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/pull/10224&#34;&gt;llama.cpp&lt;/a&gt; - available via &lt;code&gt;-DLLAMA_LLGUIDANCE=ON&lt;/code&gt; option for &lt;code&gt;cmake&lt;/code&gt;; llama.cpp can be also used Guidance Python package&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chromium&lt;/strong&gt; - &lt;a href=&#34;https://github.com/chromium/chromium/commit/07ca6337c2f714ba0477202414bd2b1692e70594&#34;&gt;merged&lt;/a&gt;, to be used for &lt;a href=&#34;https://github.com/webmachinelearning/prompt-api?tab=readme-ov-file#structured-output-or-json-output&#34;&gt;JSON Schema enforcement&lt;/a&gt; for &lt;code&gt;window.ai&lt;/code&gt; in Chromium-based browsers&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sgl-project/sglang/pull/3298&#34;&gt;SGLang&lt;/a&gt; - use &lt;code&gt;--grammar-backend llguidance&lt;/code&gt;; when passing Lark grammar make sure to prefix them with &lt;code&gt;%llguidance {}&lt;/code&gt;, just as in llama.cpp&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;vLLM&lt;/strong&gt; - &lt;a href=&#34;https://github.com/vllm-project/vllm/pull/14589&#34;&gt;V0 PR&lt;/a&gt; and &lt;a href=&#34;https://github.com/vllm-project/vllm/pull/14779&#34;&gt;V1 PR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/guidance-ai/llgtrt&#34;&gt;LLGTRT&lt;/a&gt; - OpenAI-compatible REST server using NVIDIA&#39;s &lt;a href=&#34;https://github.com/NVIDIA/TensorRT-LLM&#34;&gt;TensorRT-LLM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/EricLBuehler/mistral.rs/pull/899&#34;&gt;mistral.rs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/onnxruntime-genai/pull/1381&#34;&gt;onnxruntime-genai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Technical details&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://guidance-ai.github.io/llguidance/llg-go-brrr&#34;&gt;Making Structured Outputs Go Brrr&lt;/a&gt; for an overview of the library, including the design decisions, performance, and how it compares to other approaches.&lt;/p&gt; &#xA;&lt;p&gt;Given a context-free grammar, a tokenizer, and a prefix of tokens, llguidance computes a token mask - a set of tokens from the tokenizer - that, when added to the current token prefix, can lead to a valid string in the language defined by the grammar. Mask computation takes approximately 50μs of single-core CPU time for a tokenizer with 128k tokens. While this timing depends on the exact grammar, it holds, for example, for grammars derived from JSON schemas. There is no significant startup cost.&lt;/p&gt; &#xA;&lt;p&gt;The library implements a context-free grammar parser using Earley’s algorithm on top of a lexer based on &lt;a href=&#34;https://github.com/microsoft/derivre&#34;&gt;derivatives of regular expressions&lt;/a&gt;. Mask computation is achieved by traversing the &lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/docs/toktrie.md&#34;&gt;prefix tree (trie)&lt;/a&gt; of all possible tokens, leveraging &lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/docs/optimizations.md&#34;&gt;highly optimized&lt;/a&gt; code.&lt;/p&gt; &#xA;&lt;p&gt;Grammars can be also used to speed up decode via &lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/docs/fast_forward.md&#34;&gt;fast-forward tokens&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Comparison and performance&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/guidance-ai/jsonschemabench/tree/main/maskbench&#34;&gt;MaskBench&lt;/a&gt; in &lt;a href=&#34;https://github.com/guidance-ai/jsonschemabench&#34;&gt;JSON Schema Bench&lt;/a&gt; for detailed performance comparisons.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/noamgat/lm-format-enforcer&#34;&gt;LM-format-enforcer&lt;/a&gt; and &lt;a href=&#34;https://github.com/ggerganov/llama.cpp/raw/master/grammars/README.md&#34;&gt;llama.cpp grammars&lt;/a&gt; are similar to llguidance in that they dynamically build token masks for every step of the decoding process. Both are significantly slower - the former due to clean Python code and the latter due to the lack of a lexer and use of a backtracking parser, which, while elegant, is inefficient.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/dottxt-ai/outlines&#34;&gt;Outlines&lt;/a&gt; builds an automaton from constraints and then pre-computes token masks for all automaton states, potentially making sampling fast but inherently limiting constraint complexity and introducing significant startup cost and memory overhead. Llguidance computes token masks on the fly and has essentially no startup cost. The lexer’s automata in llguidance are built lazily and are typically much smaller, as the context-free grammar imposes the top-level structure.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mlc-ai/xgrammar&#34;&gt;XGrammar&lt;/a&gt; follows an approach similar to llama.cpp (explicit stack-based, character-level parser) with additional pre-computation of certain token masks, similar to Outlines. The pre-computation often runs into seconds, and sometimes minutes. If the pre-computation works well for a given input, the masks are computed quickly (under 8μs in half of masks we tested), however if it doesn&#39;t fit the particular input, the mask computation times can run to tens or hundreds of milliseconds.&lt;/p&gt; &#xA;&lt;p&gt;In llguidance, the full mask computation for a typical JSON schema takes about 1.5ms (for 128k tokenizer). However, very often the &lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/docs/optimizations.md#slicer-optimization&#34;&gt;&#34;slicer&#34; optimization&lt;/a&gt; applies, and thus the avarage mask computation in &lt;a href=&#34;https://github.com/guidance-ai/jsonschemabench&#34;&gt;JSON Schema Bench&lt;/a&gt; (2.5M tokens, 10k schemas) is under 50μs, with less than 1% of masks taking longer than 1ms, and 0.001% taking longer than 10ms (but still shorter than 30ms). The optimization doesn&#39;t involve any significant pre-computation.&lt;/p&gt; &#xA;&lt;p&gt;Thus, with 16 cores and a 10ms forward pass, llguidance can handle batch sizes up to 3200 without slowing down the model. (Note that a 10ms forward pass for small batch sizes typically increases to 20ms+ for batch sizes of 100-200.)&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.rust-lang.org/tools/install&#34;&gt;install rust&lt;/a&gt;; 1.75 or later&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you just need the C or Rust library (&lt;code&gt;llguidance&lt;/code&gt;), check the &lt;a href=&#34;https://raw.githubusercontent.com/guidance-ai/llguidance/main/parser/README.md&#34;&gt;parser&lt;/a&gt; directory.&lt;/p&gt; &#xA;&lt;p&gt;For Python bindings:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;install python 3.9 or later; very likely you&#39;ll need a virtual env/conda&lt;/li&gt; &#xA; &lt;li&gt;run &lt;code&gt;./scripts/install-deps.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;to build and after any changes, run &lt;code&gt;./scripts/test-guidance.sh&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This builds the Python bindings for the library and runs the tests (which mostly live in the Guidance repo - it will clone it).&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>op-rs/kona</title>
    <updated>2025-08-10T06:01:17Z</updated>
    <id>tag:github.com,2025-08-10:/op-rs/kona</id>
    <link href="https://github.com/op-rs/kona" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Monorepo for OP Stack Types, Components, and Services built in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/op-rs/kona/main/assets/banner.png&#34; alt=&#34;Kona&#34; width=&#34;100%&#34; align=&#34;center&#34; /&gt; &lt;/h1&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; The Monorepo for &lt;a href=&#34;https://specs.optimism.io/&#34;&gt;OP Stack&lt;/a&gt; Types, Components, and Services built in Rust. &lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/op-rs/kona/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/op-rs/kona?style=flat&amp;amp;labelColor=1C2C2E&amp;amp;color=C96329&amp;amp;logo=GitHub&amp;amp;logoColor=white&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.rs/kona-derive/&#34;&gt;&lt;img src=&#34;https://img.shields.io/docsrs/kona-derive?style=flat&amp;amp;labelColor=1C2C2E&amp;amp;color=C96329&amp;amp;logo=Rust&amp;amp;logoColor=white&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/op-rs/kona/actions/workflows/rust_ci.yaml&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/op-rs/kona/rust_ci.yaml?style=flat&amp;amp;labelColor=1C2C2E&amp;amp;label=ci&amp;amp;color=BEC5C9&amp;amp;logo=GitHub%20Actions&amp;amp;logoColor=BEC5C9&#34; alt=&#34;CI&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/op-rs/kona&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/gh/op-rs/kona?style=flat&amp;amp;labelColor=1C2C2E&amp;amp;logo=Codecov&amp;amp;color=BEC5C9&amp;amp;logoColor=BEC5C9&#34; alt=&#34;Codecov&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/op-rs/kona/raw/main/LICENSE.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-d1d1f6.svg?style=flat&amp;amp;labelColor=1C2C2E&amp;amp;color=BEC5C9&amp;amp;logo=googledocs&amp;amp;label=license&amp;amp;logoColor=BEC5C9&#34; alt=&#34;License&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://rollup.yoga&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Docs-854a15?style=flat&amp;amp;labelColor=1C2C2E&amp;amp;color=BEC5C9&amp;amp;logo=mdBook&amp;amp;logoColor=BEC5C9&#34; alt=&#34;Docs&#34; /&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/#whats-kona&#34;&gt;What&#39;s Kona?&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/#overview&#34;&gt;Overview&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/#msrv&#34;&gt;MSRV&lt;/a&gt; • &lt;a href=&#34;https://rollup.yoga/intro/contributing&#34;&gt;Contributing&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/#credits&#34;&gt;Credits&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/#license&#34;&gt;License&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s Kona?&lt;/h2&gt; &#xA;&lt;p&gt;Originally a suite of portable implementations of the OP Stack rollup state transition, Kona has been extended to be &lt;em&gt;the monorepo&lt;/em&gt; for &lt;a href=&#34;https://specs.optimism.io/&#34;&gt;OP Stack&lt;/a&gt; types, components, and services built in Rust. Kona provides an ecosystem of extensible, low-level crates that compose into components and services required for the OP Stack.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://rollup.yoga&#34;&gt;docs&lt;/a&gt; contains a more in-depth overview of the project, contributor guidelines, tutorials for getting started with building your own programs, and a reference for the libraries and tools provided by Kona.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;Ethereum (Alloy) types modified for the OP Stack live in &lt;a href=&#34;https://github.com/alloy-rs/op-alloy&#34;&gt;op-alloy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;Binaries&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/bin/client&#34;&gt;&lt;code&gt;client&lt;/code&gt;&lt;/a&gt;: The bare-metal program that executes the state transition, to be ran on a prover.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/bin/host&#34;&gt;&lt;code&gt;host&lt;/code&gt;&lt;/a&gt;: The host program that runs natively alongside the prover, serving as the &lt;a href=&#34;https://specs.optimism.io/fault-proof/index.html#pre-image-oracle&#34;&gt;Preimage Oracle&lt;/a&gt; server.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/bin/node&#34;&gt;&lt;code&gt;node&lt;/code&gt;&lt;/a&gt;: [WIP] A &lt;a href=&#34;https://specs.optimism.io/protocol/rollup-node.html&#34;&gt;Rollup Node&lt;/a&gt; implementation, backed by &lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/protocol/derive&#34;&gt;&lt;code&gt;kona-derive&lt;/code&gt;&lt;/a&gt;. Supports flexible chain ID specification via &lt;code&gt;--l2-chain-id&lt;/code&gt; using either numeric IDs (&lt;code&gt;10&lt;/code&gt;) or chain names (&lt;code&gt;optimism&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/bin/supervisor&#34;&gt;&lt;code&gt;supervisor&lt;/code&gt;&lt;/a&gt;: [WIP] A &lt;a href=&#34;https://specs.optimism.io/interop/supervisor.html&#34;&gt;Supervisor&lt;/a&gt; implementation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Protocol&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/protocol/genesis&#34;&gt;&lt;code&gt;genesis&lt;/code&gt;&lt;/a&gt;: Genesis types for OP Stack chains.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/protocol/protocol&#34;&gt;&lt;code&gt;protocol&lt;/code&gt;&lt;/a&gt;: Core protocol types used across OP Stack rust crates.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/protocol/derive&#34;&gt;&lt;code&gt;derive&lt;/code&gt;&lt;/a&gt;: &lt;code&gt;no_std&lt;/code&gt; compatible implementation of the &lt;a href=&#34;https://specs.optimism.io/protocol/derivation.html#l2-chain-derivation-pipeline&#34;&gt;derivation pipeline&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/proof/driver&#34;&gt;&lt;code&gt;driver&lt;/code&gt;&lt;/a&gt;: Stateful derivation pipeline driver.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/protocol/interop&#34;&gt;&lt;code&gt;interop&lt;/code&gt;&lt;/a&gt;: Core functionality and primitives for the &lt;a href=&#34;https://specs.optimism.io/interop/overview.html&#34;&gt;Interop feature&lt;/a&gt; of the OP Stack.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/protocol/registry&#34;&gt;&lt;code&gt;registry&lt;/code&gt;&lt;/a&gt;: Rust bindings for the &lt;a href=&#34;https://github.com/ethereum-optimism/superchain-registry&#34;&gt;superchain-registry&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/protocol/comp&#34;&gt;&lt;code&gt;comp&lt;/code&gt;&lt;/a&gt;: Compression types for the OP Stack.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/protocol/hardforks&#34;&gt;&lt;code&gt;hardforks&lt;/code&gt;&lt;/a&gt;: Consensus layer hardfork types for the OP Stack including network upgrade transactions.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/proof/mpt&#34;&gt;&lt;code&gt;mpt&lt;/code&gt;&lt;/a&gt;: Utilities for interacting with the Merkle Patricia Trie in the client program.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/proof/executor&#34;&gt;&lt;code&gt;executor&lt;/code&gt;&lt;/a&gt;: &lt;code&gt;no_std&lt;/code&gt; stateless block executor for the &lt;a href=&#34;https://github.com/ethereum-optimism/optimism&#34;&gt;OP Stack&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/proof/proof&#34;&gt;&lt;code&gt;proof&lt;/code&gt;&lt;/a&gt;: High level OP Stack state transition proof SDK.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/proof/proof-interop&#34;&gt;&lt;code&gt;proof-interop&lt;/code&gt;&lt;/a&gt;: Extension of &lt;code&gt;kona-proof&lt;/code&gt; with interop support.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/proof/preimage&#34;&gt;&lt;code&gt;preimage&lt;/code&gt;&lt;/a&gt;: High level interfaces to the &lt;a href=&#34;https://specs.optimism.io/fault-proof/index.html&#34;&gt;&lt;code&gt;PreimageOracle&lt;/code&gt;&lt;/a&gt; ABI.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/proof/std-fpvm&#34;&gt;&lt;code&gt;std-fpvm&lt;/code&gt;&lt;/a&gt;: Platform specific &lt;a href=&#34;https://specs.optimism.io/experimental/fault-proof/index.html#fault-proof-vm&#34;&gt;Fault Proof VM&lt;/a&gt; kernel APIs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/proof/std-fpvm-proc&#34;&gt;&lt;code&gt;std-fpvm-proc&lt;/code&gt;&lt;/a&gt;: Proc macro for &lt;a href=&#34;https://specs.optimism.io/fault-proof/index.html&#34;&gt;Fault Proof Program&lt;/a&gt; entrypoints.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Node&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/node/service&#34;&gt;&lt;code&gt;service&lt;/code&gt;&lt;/a&gt;: The OP Stack rollup node service.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/node/engine&#34;&gt;&lt;code&gt;engine&lt;/code&gt;&lt;/a&gt;: An extensible implementation of the &lt;a href=&#34;https://github.com/ethereum-optimism/optimism&#34;&gt;OP Stack&lt;/a&gt; rollup node engine client&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/node/rpc&#34;&gt;&lt;code&gt;rpc&lt;/code&gt;&lt;/a&gt;: OP Stack RPC types and extensions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/node/p2p&#34;&gt;&lt;code&gt;p2p&lt;/code&gt;&lt;/a&gt;: OP Stack P2P Networking including Gossip and Discovery.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/node/sources&#34;&gt;&lt;code&gt;sources&lt;/code&gt;&lt;/a&gt;: Data source types and utilities for the kona-node.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Providers&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/providers/providers-alloy&#34;&gt;&lt;code&gt;providers-alloy&lt;/code&gt;&lt;/a&gt;: Provider implementations for &lt;code&gt;kona-derive&lt;/code&gt; backed by &lt;a href=&#34;https://github.com/alloy-rs/alloy&#34;&gt;Alloy&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Utilities&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/utilities/serde&#34;&gt;&lt;code&gt;serde&lt;/code&gt;&lt;/a&gt;: Serialization helpers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/utilities/cli&#34;&gt;&lt;code&gt;cli&lt;/code&gt;&lt;/a&gt;: Standard CLI utilities, used across &lt;code&gt;kona&lt;/code&gt;&#39;s binaries.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/crates/utilities/macros&#34;&gt;&lt;code&gt;macros&lt;/code&gt;&lt;/a&gt;: Utility macros.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Proof&lt;/h3&gt; &#xA;&lt;p&gt;Built on top of these libraries, this repository also features a &lt;a href=&#34;https://specs.optimism.io/fault-proof/index.html&#34;&gt;proof program&lt;/a&gt; designed to deterministically execute the rollup state transition in order to verify an &lt;a href=&#34;https://specs.optimism.io/glossary.html#l2-output-root&#34;&gt;L2 output root&lt;/a&gt; from the L1 inputs it was &lt;a href=&#34;https://specs.optimism.io/protocol/derivation.html#l2-chain-derivation-pipeline&#34;&gt;derived from&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Kona&#39;s libraries were built with alternative backend support and extensibility in mind - the repository features a fault proof virtual machine backend for use in the governance-approved OP Stack, but it&#39;s portable across provers! Kona is also used by:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/succinctlabs/op-succinct&#34;&gt;&lt;code&gt;op-succinct&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/risc0/kailua&#34;&gt;&lt;code&gt;kailua&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To build your own backend for kona, or build a new application on top of its libraries, see the &lt;a href=&#34;https://rollup.yoga/node/design/intro&#34;&gt;SDK section of the docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;MSRV&lt;/h2&gt; &#xA;&lt;p&gt;The current MSRV (minimum supported rust version) is &lt;code&gt;1.88&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The MSRV is not increased automatically, and will be updated only as part of a patch (pre-1.0) or minor (post-1.0) release.&lt;/p&gt; &#xA;&lt;h2&gt;Crate Releases&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;kona&lt;/code&gt; releases are done using the &lt;a href=&#34;https://crates.io/crates/cargo-release&#34;&gt;&lt;code&gt;cargo-release&lt;/code&gt;&lt;/a&gt; crate. A detailed guide is available in &lt;a href=&#34;https://raw.githubusercontent.com/op-rs/kona/main/RELEASES.md&#34;&gt;./RELEASES.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;kona&lt;/code&gt; is built by open source contributors like you, thank you for improving the project!&lt;/p&gt; &#xA;&lt;p&gt;A &lt;a href=&#34;https://rollup.yoga/intro/contributing&#34;&gt;contributing guide&lt;/a&gt; is available that sets guidelines for contributing.&lt;/p&gt; &#xA;&lt;p&gt;Pull requests will not be merged unless CI passes, so please ensure that your contribution follows the linting rules and passes clippy.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;kona&lt;/code&gt; is inspired by the work of several teams, namely &lt;a href=&#34;https://github.com/ethereum-optimism&#34;&gt;OP Labs&lt;/a&gt; and other contributors&#39; work on the &lt;a href=&#34;https://github.com/ethereum-optimism/optimism/tree/develop&#34;&gt;Optimism monorepo&lt;/a&gt; and &lt;a href=&#34;https://github.com/BadBoiLabs&#34;&gt;BadBoiLabs&lt;/a&gt;&#39;s work on &lt;a href=&#34;https://github.com/BadBoiLabs/cannon-rs&#34;&gt;Cannon-rs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;kona&lt;/code&gt; is also built on rust types in &lt;a href=&#34;https://github.com/alloy-rs/alloy&#34;&gt;alloy&lt;/a&gt;, &lt;a href=&#34;https://github.com/alloy-rs/op-alloy&#34;&gt;op-alloy&lt;/a&gt;, and &lt;a href=&#34;https://github.com/op-rs/maili&#34;&gt;maili&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Licensed under the &lt;a href=&#34;https://github.com/op-rs/kona/raw/main/LICENSE.md&#34;&gt;MIT license.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;Contributions intentionally submitted for inclusion in these crates by you shall be licensed as above, without any additional terms or conditions.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!-- Links --&gt;</summary>
  </entry>
</feed>