<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-30T01:33:10Z</updated>
  <subtitle>Daily Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>polachok/helix-gpui</title>
    <updated>2024-05-30T01:33:10Z</updated>
    <id>tag:github.com,2024-05-30:/polachok/helix-gpui</id>
    <link href="https://github.com/polachok/helix-gpui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;helix gpui frontend&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Helix gpui&lt;/h1&gt; &#xA;&lt;img width=&#34;1136&#34; alt=&#34;Screenshot 2024-05-26 at 20 57 39&#34; src=&#34;https://github.com/polachok/helix-gpui/assets/94035/0d5dbed5-77d9-4da0-88e0-6a0632cb6070&#34;&gt; &#xA;&lt;p&gt;This is a simple GUI for &lt;a href=&#34;https://helix-editor.com/&#34;&gt;helix&lt;/a&gt; editor. Most modal editors are terminal apps, I&#39;d like to change that and implement a good modal GUI editor.&lt;/p&gt; &#xA;&lt;h2&gt;State of things&lt;/h2&gt; &#xA;&lt;p&gt;Currently this project has &lt;em&gt;less&lt;/em&gt; features and more bugs than helix-term (&lt;code&gt;hx&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The first goal is to reach feature parity&lt;/li&gt; &#xA; &lt;li&gt;Second goal is refactoring helix to allow for implementing commands properly&lt;/li&gt; &#xA; &lt;li&gt;Third goal is adding things like builtin terminal and file tree&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>gabotechs/MusicGPT</title>
    <updated>2024-05-30T01:33:10Z</updated>
    <id>tag:github.com,2024-05-30:/gabotechs/MusicGPT</id>
    <link href="https://github.com/gabotechs/MusicGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Generate music based on natural language prompts using LLMs running locally&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;span&gt; MusicGPT&lt;/span&gt; &lt;img height=&#34;30&#34; src=&#34;https://raw.githubusercontent.com/gabotechs/MusicGPT/main/assets/music-icon.svg?sanitize=true&#34; alt=&#34;Signway logo&#34;&gt; &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Generate music based on natural language prompts using LLMs running locally. &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/gabotechs/MusicGPT/assets/45515538/f0276e7c-70e5-42fc-817a-4d9ee9095b4c&#34;&gt;https://github.com/gabotechs/MusicGPT/assets/45515538/f0276e7c-70e5-42fc-817a-4d9ee9095b4c&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;end&#34;&gt; ☝️ Turn up the volume! &lt;/p&gt; &#xA;&lt;h1&gt;Overview&lt;/h1&gt; &#xA;&lt;p&gt;MusicGPT is an application that allows running the latest music generation AI models locally in a performant way, in any platform and without installing heavy dependencies like Python or machine learning frameworks.&lt;/p&gt; &#xA;&lt;p&gt;Right now it only supports &lt;a href=&#34;https://audiocraft.metademolab.com/musicgen.html&#34;&gt;MusicGen by Meta&lt;/a&gt;, but the plan is to support different music generation models transparently to the user.&lt;/p&gt; &#xA;&lt;p&gt;The main milestones for the project are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Text conditioned music generation&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Melody conditioned music generation&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Indeterminately long / infinite music streams&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Install&lt;/h1&gt; &#xA;&lt;h3&gt;Mac and Linux&lt;/h3&gt; &#xA;&lt;p&gt;MusicGPT can be installed on Mac and Linux using &lt;code&gt;brew&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;brew install gabotechs/taps/musicgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or by directly downloading the precompiled binaries from &lt;a href=&#34;https://github.com/gabotechs/MusicGPT/releases/latest&#34;&gt;this link&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;p&gt;On Windows, the executable file can be downloaded from &lt;a href=&#34;https://github.com/gabotechs/MusicGPT/releases/latest/download/x86_64-pc-windows-msvc.tar.gz&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Docker (Recommend for running with CUDA)&lt;/h3&gt; &#xA;&lt;p&gt;If you want to run MusicGPT with a CUDA enabled GPU, this is the best way, as you only need to have &lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html&#34;&gt;the basic NVIDIA drivers&lt;/a&gt; installed in your system.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull gabotechs/musicgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the image is downloaded, you can run it with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -it --gpus all -p 8642:8642 -v ~/.musicgpt:/root/.local/share/musicgpt gabotechs/musicgpt --gpu --ui-expose&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;With cargo&lt;/h3&gt; &#xA;&lt;p&gt;If you have the &lt;a href=&#34;https://www.rust-lang.org/tools/install&#34;&gt;Rust toolchain&lt;/a&gt; installed in your system, you can install it with &lt;code&gt;cargo&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo install musicgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;There are two ways of interacting with MusicGPT: the UI mode and the CLI mode.&lt;/p&gt; &#xA;&lt;h2&gt;UI mode&lt;/h2&gt; &#xA;&lt;p&gt;This mode will display a chat-like web application for exchanging prompts with the LLM. It will:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;store your chat history&lt;/li&gt; &#xA; &lt;li&gt;allow you to play the generated music samples whenever you want&lt;/li&gt; &#xA; &lt;li&gt;generate music samples in the background&lt;/li&gt; &#xA; &lt;li&gt;allow you to use the UI in a device different from the one executing the LLMs&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can run the UI by just executing the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;musicgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also choose different models for running inference, and whether to use a GPU or not, for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;musicgpt --gpu --model medium&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING]&lt;br&gt; Most models require really powerful hardware for running inference&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you want to use a CUDA enabled GPU, it&#39;s recommended that you run MusicGPT with Docker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -it --gpus all -p 8642:8642 -v ~/.musicgpt:/root/.local/share/musicgpt gabotechs/musicgpt --ui-expose --gpu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;CLI mode&lt;/h2&gt; &#xA;&lt;p&gt;This mode will generate and play music directly in the terminal, allowing you to provide multiple prompts and playing audio as soon as it&#39;s generated. You can generate audio based on a prompt with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;musicgpt &#34;Create a relaxing LoFi song&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, it produces a sample of 10s, which can be configured up to 30s:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;musicgpt &#34;Create a relaxing LoFi song&#34; --secs 30&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There&#39;s multiple models available, it will use the smallest one by default, but you can opt into a bigger model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;musicgpt &#34;Create a relaxing LoFi song&#34; --model medium&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING]&lt;br&gt; Most models require really powerful hardware for running inference&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you want to use a CUDA enabled GPU, it&#39;s recommended that you run MusicGPT with Docker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -it --gpus all -v ~/.musicgpt:/root/.local/share/musicgpt gabotechs/musicgpt --gpu &#34;Create a relaxing LoFi song&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can review all the options available running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;musicgpt --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Benchmarks&lt;/h1&gt; &#xA;&lt;p&gt;The following graph shows the inference time taken for generating 10 seconds of audio using different models on a Mac M1 Pro. For comparison, it&#39;s Python equivalent using &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;https://github.com/huggingface/transformers&lt;/a&gt; is shown.&lt;/p&gt; &#xA;&lt;p&gt;The command used for generating the 10 seconds of audio was:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;musicgpt &#39;80s pop track with bassy drums and synth&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;This is the Python script used for generating the 10 seconds of audio&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import scipy&#xA;import time&#xA;from transformers import AutoProcessor, MusicgenForConditionalGeneration&#xA;&#xA;processor = AutoProcessor.from_pretrained(&#34;facebook/musicgen-small&#34;)&#xA;model = MusicgenForConditionalGeneration.from_pretrained(&#34;facebook/musicgen-small&#34;)&#xA;&#xA;inputs = processor(&#xA;    text=[&#34;80s pop track with bassy drums and synth&#34;],&#xA;    padding=True,&#xA;    return_tensors=&#34;pt&#34;,&#xA;)&#xA;&#xA;start = time.time()&#xA;audio_values = model.generate(**inputs, max_new_tokens=500)&#xA;print(time.time() - start) # Log time taken in generation&#xA;&#xA;sampling_rate = model.config.audio_encoder.sampling_rate&#xA;scipy.io.wavfile.write(&#34;musicgen_out.wav&#34;, rate=sampling_rate, data=audio_values[0, 0].numpy())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;400&#34; src=&#34;https://github.com/gabotechs/MusicGPT/assets/45515538/edae3c25-04e3-41c3-a2b5-c0829fa69ee3&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;The code is licensed under a &lt;a href=&#34;https://raw.githubusercontent.com/gabotechs/MusicGPT/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;, but the AI model weights that get downloaded at application startup are licensed under the &lt;a href=&#34;https://spdx.org/licenses/CC-BY-NC-4.0&#34;&gt;CC-BY-NC-4.0 License&lt;/a&gt; as they are generated based on the following repositories:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/facebook/musicgen-small&#34;&gt;https://huggingface.co/facebook/musicgen-small&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/facebook/musicgen-medium&#34;&gt;https://huggingface.co/facebook/musicgen-medium&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/facebook/musicgen-large&#34;&gt;https://huggingface.co/facebook/musicgen-large&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/facebook/musicgen-melody&#34;&gt;https://huggingface.co/facebook/musicgen-melody&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ynqa/sig</title>
    <updated>2024-05-30T01:33:10Z</updated>
    <id>tag:github.com,2024-05-30:/ynqa/sig</id>
    <link href="https://github.com/ynqa/sig" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Interactive grep (for streaming)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;sig&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ynqa/sig/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/ynqa/sig/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;ci&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Interactive grep&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;img src=&#34;https://github.com/ynqa/ynqa/raw/master/demo/sig.gif&#34; alt=&#34;sig.gif&#34;&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;img src=&#34;https://github.com/ynqa/ynqa/raw/master/demo/sig_archived.gif&#34; alt=&#34;sig_archived.gif&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Interactive grep (for streaming) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;em&gt;sig&lt;/em&gt; allows users to interactively search through (streaming) data, updating results in real-time.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Archived mode &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;In Archived mode, since there is no seeking capability for streaming data received through a pipe, it is not possible to search backwards without exiting the process. Therefore, in &lt;em&gt;sig&lt;/em&gt;, the latest N entries of streaming data are saved, and it is possible to switch to a mode where you can grep through these N entries based on key inputs at any given moment.&lt;/li&gt; &#xA;   &lt;li&gt;Additionally, by starting in this mode, it is also possible to grep through static data such as files.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Homebrew&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install ynqa/tap/sigrs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Cargo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo install sigrs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Nix (flakes)&lt;/h3&gt; &#xA;&lt;p&gt;Add it as an input to your flake:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-nix&#34;&gt;inputs = {&#xA;  sig.url = &#39;github:ynqa/sig/&amp;lt;optional-ref&amp;gt;&#39;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create a shell with it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-nix&#34;&gt;nix shell github:ynqa/sig&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or run it directly:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-nix&#34;&gt;cat README.md | nix run github:ynqa/sig -- --archived&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Nix (classic)&lt;/h3&gt; &#xA;&lt;p&gt;Fetch the source and use it, e.g. in your shell:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-nix&#34;&gt;let&#xA;  # At the time of writing this, pkgs need to be unstable for the package to build properly&#xA;  # (requires Rust 1.74, stable has 1.73)&#xA;  pkgs = import &amp;lt;nixpkgs-unstable&amp;gt; {};&#xA;&#xA;  sig = pkgs.callPackage (pkgs.fetchFromGitHub {&#xA;    owner = &#34;ynqa&#34;;&#xA;    repo = &#34;sig&#34;;&#xA;    rev = &#34;&amp;lt;revision, e.g. master/v0.1.0/etc.&amp;gt;&#34;;&#xA;    hash = &#34;&#34;; # Build first, put proper hash in place&#xA;  }) {};&#xA;in&#xA;  pkgs.mkShell {&#xA;    packages = [sig];&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Keymap&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Key&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Action&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Ctrl + C&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Exit &lt;code&gt;sig&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Ctrl + F&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Enter Archived mode&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;←&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Move the cursor one character to the left&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;→&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Move the cursor one character to the right&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Ctrl + A&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Move the cursor to the start of the filter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Ctrl + E&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Move the cursor to the end of the filter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Backspace&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Delete a character of filter at the cursor position&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Ctrl + U&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Delete all characters of filter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;(Archived mode)&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Key&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Action&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Ctrl + C&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Exit Archived mode&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;←&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Move the cursor one character to the left&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;→&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Move the cursor one character to the right&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Ctrl + A&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Move the cursor to the start of the filter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Ctrl + E&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Move the cursor to the end of the filter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Backspace&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Delete a character of filter at the cursor position&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;kbd&gt;Ctrl + U&lt;/kbd&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Delete all characters of filter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Interactive grep (for streaming)&#xA;&#xA;Usage: sig [OPTIONS]&#xA;&#xA;Options:&#xA;      --retrieval-timeout &amp;lt;RETRIEVAL_TIMEOUT_MILLIS&amp;gt;&#xA;          Timeout to read a next line from the stream in milliseconds. [default: 10]&#xA;      --render-interval &amp;lt;RENDER_INTERVAL_MILLIS&amp;gt;&#xA;          Interval to render a log line in milliseconds. [default: 10]&#xA;  -q, --queue-capacity &amp;lt;QUEUE_CAPACITY&amp;gt;&#xA;          Queue capacity to store the logs. [default: 1000]&#xA;      --archived&#xA;          Archived mode to grep through static data.&#xA;  -h, --help&#xA;          Print help (see more with &#39;--help&#39;)&#xA;  -V, --version&#xA;          Print version&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>