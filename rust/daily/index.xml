<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-22T01:43:23Z</updated>
  <subtitle>Daily Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>life4/textdistance.rs</title>
    <updated>2023-05-22T01:43:23Z</updated>
    <id>tag:github.com,2023-05-22:/life4/textdistance.rs</id>
    <link href="https://github.com/life4/textdistance.rs" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ü¶Äüìè Rust library to compare strings (or any sequences). 25+ algorithms, pure Rust, common interface, Unicode support.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;textdistance.rs&lt;/h1&gt; &#xA;&lt;p&gt;[ &lt;a href=&#34;https://github.com/life4/textdistance.rs&#34;&gt;github.com&lt;/a&gt; ] [ &lt;a href=&#34;https://docs.rs/textdistance/&#34;&gt;docs.rs&lt;/a&gt; ] [ &lt;a href=&#34;https://crates.io/crates/textdistance&#34;&gt;crates.io&lt;/a&gt; ]&lt;/p&gt; &#xA;&lt;p&gt;Rust library with lots of different algorithms to compare how similar two sequences are.&lt;/p&gt; &#xA;&lt;p&gt;Features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üí™ Based on popular and battle-tested &lt;a href=&#34;https://github.com/life4/textdistance&#34;&gt;textdistance&lt;/a&gt; Python library (and written by the same author).&lt;/li&gt; &#xA; &lt;li&gt;üìö Contains 20+ algorithms for all purposes.&lt;/li&gt; &#xA; &lt;li&gt;üî¨ Includes state-of-the-art algorithms like &lt;code&gt;EntropyNCD&lt;/code&gt; and &lt;code&gt;Sift4&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ü™∂ Zero-dependency.&lt;/li&gt; &#xA; &lt;li&gt;üî® Works with any iterators, including bytes, code points, Unicode grapheme clusters, words, and numbers.&lt;/li&gt; &#xA; &lt;li&gt;‚ù§Ô∏è Friendly and consistent API for all algorithms.&lt;/li&gt; &#xA; &lt;li&gt;üìè Optional normalization of the result on the 0.0-1.0 interval.&lt;/li&gt; &#xA; &lt;li&gt;üõ° No unsafe code.&lt;/li&gt; &#xA; &lt;li&gt;ü¶Ä Pure Rust.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Available algorithms&lt;/h2&gt; &#xA;&lt;p&gt;Edit-based:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;DamerauLevenshtein&lt;/code&gt;, both optimal string alignment and restricted.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Hamming&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Jaro&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;JaroWinkler&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Levenshtein&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Sift4Common&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Sift4Simple&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SmithWaterman&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Token-based:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;Bag&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Cosine&lt;/code&gt; (aka Orchini, Tucker, Otsuka‚ÄìOchiai)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EntropyNCD&lt;/code&gt; (Entropy-based Normalized Compression Distance)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Jaccard&lt;/code&gt; (aka Tanimoto, Critical Success Index)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Overlap&lt;/code&gt; (aka Szymkiewicz‚ÄìSimpson)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Roberts&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SorensenDice&lt;/code&gt; (aka F1, Czekanowski, Zijdenbos)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Tversky&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Sequence-based:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;LCSSeq&lt;/code&gt; (Longest Common SubSequence)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;LCSStr&lt;/code&gt; (Longest Common SubString)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;RatcliffObershelp&lt;/code&gt; (aka Gestalt pattern matching)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Naive:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;Prefix&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Suffix&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Length&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Normalization for other metrics:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;LIG3&lt;/code&gt; normalization for &lt;code&gt;Hamming&lt;/code&gt; by &lt;code&gt;Levenshtein&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MLIPNS&lt;/code&gt; normalization for &lt;code&gt;Hamming&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;YujianBo&lt;/code&gt; normalization for &lt;code&gt;Levenshtein&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo add textdistance&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;textdistance::str&lt;/code&gt; module provides shortcut functions for each algorithm for calculating the distance/similarity between two strings:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use textdistance::str::damerau_levenshtein;&#xA;assert!(damerau_levenshtein(&#34;abc&#34;, &#34;acbd&#34;) == 2);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;textdistance::nstr&lt;/code&gt; module is the same but all algorithms return a normalized value (between 0.0 and 1.0):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use textdistance::nstr::damerau_levenshtein;&#xA;assert!(damerau_levenshtein(&#34;abc&#34;, &#34;acbd&#34;) == 2./4.);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more advanced usage, each algorithm is provided as a struct implementing the &lt;code&gt;Algorithm&lt;/code&gt; trait:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use textdistance::{Algorithm, DamerauLevenshtein};&#xA;&#xA;let a = DamerauLevenshtein::default();&#xA;let r = a.for_str(&#34;abc&#34;, &#34;acbd&#34;);&#xA;assert!(r.val() == 2);&#xA;assert!(r.nval() == 2./4.);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The &lt;code&gt;Algorithm&lt;/code&gt; trait provides &lt;code&gt;for_str&lt;/code&gt;, &lt;code&gt;for_vec&lt;/code&gt;, and &lt;code&gt;for_iter&lt;/code&gt; to calculate the result for two strings, vectors (slices), or iterators respectively. In addition, there are &lt;code&gt;for_words&lt;/code&gt; and &lt;code&gt;for_bigrams&lt;/code&gt; methods that split the text into words or bigrams respectively before calculating the distance.&lt;/li&gt; &#xA; &lt;li&gt;Each method returns a &lt;code&gt;textdistance::Result&lt;/code&gt; that provides methods to get absolute (&lt;code&gt;val&lt;/code&gt;) or normalized (&lt;code&gt;nval&lt;/code&gt;) value of the metric, distance (&lt;code&gt;dist&lt;/code&gt; and &lt;code&gt;ndist&lt;/code&gt;), or similarity (&lt;code&gt;sim&lt;/code&gt; and &lt;code&gt;nsim&lt;/code&gt;).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Unicode support&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;for_str&lt;/code&gt; method (and so all functions in the &lt;code&gt;str&lt;/code&gt; and &lt;code&gt;nstr&lt;/code&gt; modules) uses &lt;code&gt;String.chars&lt;/code&gt; to split the string and then runs it through the &lt;code&gt;for_iter&lt;/code&gt; method. So, &lt;code&gt;√©&lt;/code&gt; will be considered two distinct characters (&#34;latin small letter e&#34; and &#34;combining acute accent&#34;). Usually, that&#39;s ok and this is how Python works. You can read more in &lt;a href=&#34;https://doc.rust-lang.org/std/primitive.char.html#representation&#34;&gt;the official Rust documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you want &lt;code&gt;√©&lt;/code&gt; to be considered as a single symbol, use the &lt;a href=&#34;https://crates.io/crates/unicode-segmentation&#34;&gt;unicode-segmentation&lt;/a&gt; crate:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use textdistance::{Algorithm, DamerauLevenshtein};&#xA;use unicode_segmentation::UnicodeSegmentation;&#xA;&#xA;let s1 = &#34;aÃê√©√∂Ã≤\r\n&#34;;&#xA;let s2 = &#34;√©aÃê√∂Ã≤\r\n&#34;;&#xA;let g1 = s1.graphemes(true);&#xA;let g2 = s2.graphemes(true);&#xA;let a = DamerauLevenshtein::default();&#xA;let r = a.for_iter(g1, g2);&#xA;assert!(r.val() == 1);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Choosing the algorithm&lt;/h2&gt; &#xA;&lt;p&gt;The algorithm to use depends on your use case. First, you need to decide on the algorithm category:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Edit-based algorithms work well on short sequences for detecting typos and minor changes.&lt;/li&gt; &#xA; &lt;li&gt;Token-based algorithms work well on longer sequences for comparing long texts with noticeable modifications.&lt;/li&gt; &#xA; &lt;li&gt;Sequence-based algorithms work well for calculating diff size between the original and the changed version of the sequence.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If you go with edit-based, the next thing is to decide what kind of changes you need to detect:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úèÔ∏è Substitution. One character is replaced by another.&lt;/li&gt; &#xA; &lt;li&gt;‚ûï Addition. A new character is added.&lt;/li&gt; &#xA; &lt;li&gt;üóë Deletion. A character is removed.&lt;/li&gt; &#xA; &lt;li&gt;üîÑ Transposition. Two sequential characters are swapped.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;alg&lt;/th&gt; &#xA;   &lt;th&gt;sub&lt;/th&gt; &#xA;   &lt;th&gt;add&lt;/th&gt; &#xA;   &lt;th&gt;del&lt;/th&gt; &#xA;   &lt;th&gt;trans&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Hamming&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Jaro&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;JaroWinkler&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Sift4&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Levenshtein&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;DamerauLevenshtein&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Hamming&lt;/code&gt; is the fastest one but detects only substitutions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Sift4&lt;/code&gt; is very fast but not as well-known and battle-tested as other algorithms.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Jaro&lt;/code&gt; is slower than &lt;code&gt;Sift4&lt;/code&gt; but well-known and battle-tested.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;JaroWinkler&lt;/code&gt; is like &lt;code&gt;Jaro&lt;/code&gt; but gives more weight to strings with a matching prefix.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Levenshtein&lt;/code&gt; detects everything but transpositions and faster than &lt;code&gt;DamerauLevenshtein&lt;/code&gt; (but slower than other algorithms).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;DamerauLevenshtein&lt;/code&gt; ticks all the boxes but very slow.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;There are some use cases:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;DamerauLevenshtein&lt;/code&gt; with some optimizations is &lt;a href=&#34;https://github.com/rust-lang/cargo/raw/master/src/cargo/util/edit_distance.rs&#34;&gt;used in cargo&lt;/a&gt; to correct typos in command names.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Jaro&lt;/code&gt; is included in the Elixir standard library (&lt;a href=&#34;https://hexdocs.pm/elixir/1.12/String.html#jaro_distance/2&#34;&gt;String.jaro_distance&lt;/a&gt;). It is used by the compiler and by mix (cargo for Elixir) to provide the &#34;did you mean?&#34; functionality for typos in module or command names.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;RatcliffObershelp&lt;/code&gt; variation is included in the Python standard library (&lt;a href=&#34;https://docs.python.org/3/library/difflib.html#difflib.SequenceMatcher&#34;&gt;difflib.SequenceMatcher&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;Legend:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üêå is very slow (&amp;gt; 5 ms)&lt;/li&gt; &#xA; &lt;li&gt;üê¢ is slow (&amp;gt; 1 ms)&lt;/li&gt; &#xA; &lt;li&gt;üêá is fast (&amp;gt; 500 ¬µs)&lt;/li&gt; &#xA; &lt;li&gt;üêé is very fast (&amp;lt; 500 ¬µs)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Edit-based (and their normalizations):&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;algorithm&lt;/th&gt; &#xA;   &lt;th&gt;time&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hamming&lt;/td&gt; &#xA;   &lt;td&gt;üêé 19.203 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mlipns&lt;/td&gt; &#xA;   &lt;td&gt;üêé 20.625 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;sift4_simple&lt;/td&gt; &#xA;   &lt;td&gt;üêé 143.69 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;sift4_common&lt;/td&gt; &#xA;   &lt;td&gt;üêé 238.86 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;jaro&lt;/td&gt; &#xA;   &lt;td&gt;üê¢ 1.7148 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;jaro_winkler&lt;/td&gt; &#xA;   &lt;td&gt;üê¢ 1.7174 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;levenshtein&lt;/td&gt; &#xA;   &lt;td&gt;üê¢ 4.5999 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;yujian_bo&lt;/td&gt; &#xA;   &lt;td&gt;üê¢ 4.6044 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;lig3&lt;/td&gt; &#xA;   &lt;td&gt;üêå 6.5563 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;smith_waterman&lt;/td&gt; &#xA;   &lt;td&gt;üêå 9.5146 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;damerau_levenshtein_restricted&lt;/td&gt; &#xA;   &lt;td&gt;üêå 10.301 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;damerau_levenshtein&lt;/td&gt; &#xA;   &lt;td&gt;üêå 41.938 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Token-based:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;algorithm&lt;/th&gt; &#xA;   &lt;th&gt;time&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;cosine&lt;/td&gt; &#xA;   &lt;td&gt;üêá 508.59 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;sorensen_dice&lt;/td&gt; &#xA;   &lt;td&gt;üêá 510.75 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;tversky&lt;/td&gt; &#xA;   &lt;td&gt;üêá 512.41 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;overlap&lt;/td&gt; &#xA;   &lt;td&gt;üêá 513.76 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;bag&lt;/td&gt; &#xA;   &lt;td&gt;üêá 523.06 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;jaccard&lt;/td&gt; &#xA;   &lt;td&gt;üêá 580.79 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;roberts&lt;/td&gt; &#xA;   &lt;td&gt;üêá 714.79 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;entropy_ncd&lt;/td&gt; &#xA;   &lt;td&gt;üêá 731.68 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Sequence-based:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;algorithm&lt;/th&gt; &#xA;   &lt;th&gt;time&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;lcsstr&lt;/td&gt; &#xA;   &lt;td&gt;üê¢ 3.2658 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;lcsseq&lt;/td&gt; &#xA;   &lt;td&gt;üêå 7.4349 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ratcliff_obershelp&lt;/td&gt; &#xA;   &lt;td&gt;üêå 36.308 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Naive:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;algorithm&lt;/th&gt; &#xA;   &lt;th&gt;time&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;length&lt;/td&gt; &#xA;   &lt;td&gt;üêé 2.5300 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;prefix&lt;/td&gt; &#xA;   &lt;td&gt;üêé 22.473 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;suffix&lt;/td&gt; &#xA;   &lt;td&gt;üêé 38.821 ¬µs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The benchmarks are powered by &lt;a href=&#34;https://github.com/bheisler/criterion.rs&#34;&gt;criterion&lt;/a&gt; and live in the &lt;a href=&#34;https://raw.githubusercontent.com/life4/textdistance.rs/master/benches/&#34;&gt;benches&lt;/a&gt; directory. They are quite simple: grab 10 &lt;a href=&#34;https://github.com/github/choosealicense.com/tree/gh-pages/_licenses&#34;&gt;open-source licenses&lt;/a&gt;, take a 200 chars prefix from each, and cross-compare these prefixes. The numbers might be very different for a different kind of input, length of the input, when comparing words rather than characters, or running the benchmarks on a different machine. The goal of these benchmarks is to provide basic guidance rather than give a definitive answer. If performance is critical for your application, I encourage you to make your benchmarks on the real data you have.&lt;/p&gt; &#xA;&lt;h2&gt;Versioning&lt;/h2&gt; &#xA;&lt;p&gt;We stick to &lt;a href=&#34;https://semver.org/&#34;&gt;SemVer&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The &lt;strong&gt;patch&lt;/strong&gt; number is for bug fixes. The results of an algorithm may change in some corner cases if we found that the previous implementation doesn&#39;t match the algorithm described in the original paper.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;strong&gt;minor&lt;/strong&gt; number is for new algorithms and features.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;strong&gt;major&lt;/strong&gt; number is for big changes in the API. We try to avoid breaking stuff but we prefer to provide a friendly and convenient API over keeping a backward compatibility.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Limitations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;In the original textdisance, most of the algorithms are adjusted to work on any number of the input sequences. However, Rust doesn&#39;t support variadic arguments, so all algorithms currently are implemented only for exactly two inputs.&lt;/li&gt; &#xA; &lt;li&gt;All algorithms in the crate implement the same &lt;code&gt;Algorithm&lt;/code&gt; trait. Hence metrics that have additional limitations on the input sequence elements beyond &lt;code&gt;Eq&lt;/code&gt; (like Editex and MRA that work only with ASCII letters) currently cannot be implemented.&lt;/li&gt; &#xA; &lt;li&gt;Most of the implemented algorithms have certain properties (like &lt;a href=&#34;https://en.wikipedia.org/wiki/Commutative_property&#34;&gt;commutative property&lt;/a&gt;) that make their behavior more like what you would expect and make normalization simple. So, I haven&#39;t implemented yet Needleman-Wunsch and Gotoh, mostly because they are tricky to normalize and I&#39;m still not 100% sure that I did it correctly in the original textdistance.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;There are the libraries that I used as a reference implementation and the source of test cases:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üêç Python: &lt;a href=&#34;https://github.com/life4/textdistance&#34;&gt;textdistance&lt;/a&gt;, &lt;a href=&#34;https://github.com/chrislit/abydos&#34;&gt;abydos&lt;/a&gt;, &lt;a href=&#34;https://github.com/jamesturk/jellyfish&#34;&gt;jellyfish&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;‚òïÔ∏è JS: &lt;a href=&#34;https://github.com/Yomguithereal/talisman&#34;&gt;talisman&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ü¶Ä Rust: &lt;a href=&#34;https://github.com/dguo/strsim-rs&#34;&gt;strsim&lt;/a&gt;, &lt;a href=&#34;https://github.com/mbrlabs/distance&#34;&gt;distance&lt;/a&gt;, &lt;a href=&#34;https://github.com/wooorm/levenshtein-rs&#34;&gt;levenshtein-rs&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Specials thanks to &lt;a href=&#34;https://github.com/tgross35&#34;&gt;Trevor Gross&lt;/a&gt; for transferring to me the ownership of the &lt;a href=&#34;https://crates.io/crates/textdistance&#34;&gt;textdistance&lt;/a&gt; name on crates.io.&lt;/p&gt; &#xA;&lt;h2&gt;Testing locally&lt;/h2&gt; &#xA;&lt;p&gt;To run everything locally, all you need is Rust, Python, and &lt;a href=&#34;https://taskfile.dev/installation/&#34;&gt;task&lt;/a&gt;. Execute &lt;code&gt;task all&lt;/code&gt; to run all code formatters, linters, and tests.&lt;/p&gt; &#xA;&lt;p&gt;Thank you ‚ù§Ô∏è&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>quickwit-oss/whichlang</title>
    <updated>2023-05-22T01:43:23Z</updated>
    <id>tag:github.com,2023-05-22:/quickwit-oss/whichlang</id>
    <link href="https://github.com/quickwit-oss/whichlang" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A blazingly fast and lightweight language detection library for Rust&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Whichlang&lt;/h1&gt; &#xA;&lt;p&gt;This is a language detection library, aiming for both precision and performance. You can read our &lt;a href=&#34;https://quickwit.io/blog/whichlang-language-detection-library&#34;&gt;blog post&lt;/a&gt; that introduces the algorithm behing Whichlang.&lt;/p&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;No dependency&lt;/li&gt; &#xA; &lt;li&gt;Throughput above 100 MB/s for short and long strings.&lt;/li&gt; &#xA; &lt;li&gt;Good accuracy (99.5% on my validation dataset, but it really depends on the size of your input.)&lt;/li&gt; &#xA; &lt;li&gt;Supported languages: Arabic, Dutch, English, French, German, Hindi, Italian, Japanese, Korean, Mandarin, Portuguese, Russian, Spanish, Swedish, Turkish, and Vietnamese.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;How does it work?&lt;/h1&gt; &#xA;&lt;p&gt;It uses a multiclass logistic regression model over:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2, 3, 4-grams of letters on ASCII&lt;/li&gt; &#xA; &lt;li&gt;codepoint / 128&lt;/li&gt; &#xA; &lt;li&gt;a slightly smarter projection of codepoints over a given class.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We use the hashing trick and project these features over a space of size &lt;code&gt;4_096&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The logistic regression is trained in the python notebook attached, and used to generate &lt;code&gt;weight.rs&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Comparison with &lt;a href=&#34;https://github.com/greyblake/whatlang-rs&#34;&gt;Whatlang&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;The following compares the throughput using the simple benchmark found in this repository and the accuracy using &lt;a href=&#34;https://github.com/evanxg852000/whatlang-accuracy-benchmark&#34;&gt;whatlang-accuracy-benchmark&lt;/a&gt; benchmark. Overall, Whichlang is about 10x faster and slightly more accurate than Whatlang.&lt;/p&gt; &#xA;&lt;h3&gt;Throughput&lt;/h3&gt; &#xA;&lt;p&gt;To generate the throughput benchmark, we ported the benchmark available in &lt;a href=&#34;https://github.com/quickwit-oss/whichlang/raw/main/benches/bench.rs&#34;&gt;this repository&lt;/a&gt;. Please, check this &lt;a href=&#34;https://github.com/evanxg852000/whatlang-accuracy-benchmark&#34;&gt;repository&lt;/a&gt; to see our changes.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Processing Time (¬µs)&lt;/th&gt; &#xA;   &lt;th&gt;Throughput (MiB/s)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;whatlang/short&lt;/td&gt; &#xA;   &lt;td&gt;16.62&lt;/td&gt; &#xA;   &lt;td&gt;1.66&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;whatlang/long&lt;/td&gt; &#xA;   &lt;td&gt;62.00&lt;/td&gt; &#xA;   &lt;td&gt;9.42&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;whichlang/short&lt;/td&gt; &#xA;   &lt;td&gt;0.26&lt;/td&gt; &#xA;   &lt;td&gt;105.69&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;whichlang/long&lt;/td&gt; &#xA;   &lt;td&gt;5.21&lt;/td&gt; &#xA;   &lt;td&gt;112.31&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Accuracy&lt;/h3&gt; &#xA;&lt;p&gt;To generate the accuracy benchmark, we have changed the &lt;a href=&#34;https://github.com/whatlang/whatlang-accuracy-benchmark&#34;&gt;whatlang-accuracy-benchmark&lt;/a&gt; to add support for Whichlang. Given that Whatlang supports more languages, we have used its FilterList feature to restrict its analysis to only languages that are supported in Whichlang. We also use the &lt;code&gt;trigram&lt;/code&gt; method in Whatlang. Please, check this &lt;a href=&#34;https://github.com/evanxg852000/whatlang-accuracy-benchmark&#34;&gt;repository&lt;/a&gt; to see our changes.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Crate: Whatlang&#xA;AVG: 91.69%&#xA;&#xA;| LANG       | AVG    | &amp;lt;= 20   | 21-50  | 51-100 | &amp;gt; 100   |&#xA;|------------|--------|---------|--------|--------|---------|&#xA;| Arabic     | 99.68% | 99.51%  | 99.64% | 99.83% | 99.76%  |&#xA;| Mandarin   | 96.09% | 97.54%  | 96.92% | 95.45% | 94.43%  |&#xA;| German     | 88.57% | 70.00%  | 88.53% | 96.61% | 99.16%  |&#xA;| English    | 85.99% | 57.82%  | 88.37% | 97.97% | 99.78%  |&#xA;| French     | 90.88% | 72.84%  | 92.51% | 98.54% | 99.65%  |&#xA;| Hindi      | 99.80% | 100.00% | 99.83% | 99.78% | 99.61%  |&#xA;| Italian    | 87.75% | 66.67%  | 87.74% | 97.04% | 99.54%  |&#xA;| Japanese   | 94.37% | 93.97%  | 96.04% | 94.30% | 93.18%  |&#xA;| Korean     | 99.17% | 98.88%  | 99.69% | 99.44% | 98.66%  |&#xA;| Dutch      | 89.68% | 72.13%  | 89.78% | 97.40% | 99.40%  |&#xA;| Portuguese | 88.08% | 72.90%  | 85.76% | 95.22% | 98.44%  |&#xA;| Russian    | 99.98% | 100.00% | 99.96% | 99.98% | 100.00% |&#xA;| Spanish    | 82.91% | 55.45%  | 82.24% | 94.85% | 99.10%  |&#xA;| Swedish    | 84.16% | 58.33%  | 83.78% | 96.35% | 98.18%  |&#xA;| Turkish    | 86.73% | 61.01%  | 88.94% | 97.32% | 99.63%  |&#xA;| Vietnamese | 93.23% | 82.84%  | 92.96% | 97.88% | 99.24%  |&#xA;| AVG        | 91.69% | 78.74%  | 92.04% | 97.37% | 98.61%  |&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Crate: Whichlang&#xA;AVG: 97.03%&#xA;&#xA;| LANG       | AVG     | &amp;lt;= 20   | 21-50   | 51-100  | &amp;gt; 100   |&#xA;|------------|---------|---------|---------|---------|---------|&#xA;| Arabic     | 100.00% | 100.00% | 100.00% | 100.00% | 100.00% |&#xA;| Mandarin   | 98.65%  | 98.69%  | 98.48%  | 98.55%  | 98.87%  |&#xA;| German     | 94.20%  | 80.00%  | 97.47%  | 99.49%  | 99.84%  |&#xA;| English    | 97.15%  | 91.84%  | 97.25%  | 99.57%  | 99.93%  |&#xA;| French     | 97.59%  | 93.83%  | 97.61%  | 99.20%  | 99.71%  |&#xA;| Hindi      | 100.00% | 100.00% | 100.00% | 100.00% | 100.00% |&#xA;| Italian    | 97.20%  | 93.06%  | 97.33%  | 98.85%  | 99.57%  |&#xA;| Japanese   | 94.92%  | 88.95%  | 95.14%  | 97.74%  | 97.85%  |&#xA;| Korean     | 99.83%  | 99.44%  | 99.98%  | 99.97%  | 99.94%  |&#xA;| Dutch      | 97.08%  | 92.84%  | 96.98%  | 98.91%  | 99.60%  |&#xA;| Portuguese | 94.07%  | 83.87%  | 94.89%  | 98.18%  | 99.36%  |&#xA;| Russian    | 99.92%  | 99.69%  | 99.99%  | 100.00% | 100.00% |&#xA;| Spanish    | 92.12%  | 76.36%  | 93.78%  | 98.65%  | 99.70%  |&#xA;| Swedish    | 95.37%  | 90.28%  | 94.94%  | 97.76%  | 98.51%  |&#xA;| Turkish    | 95.51%  | 88.24%  | 98.11%  | 98.38%  | 97.33%  |&#xA;| Vietnamese | 98.79%  | 96.57%  | 98.87%  | 99.77%  | 99.96%  |&#xA;| AVG        | 97.03%  | 92.10%  | 97.55%  | 99.06%  | 99.39%  |&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>