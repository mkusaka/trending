<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-07-01T01:54:38Z</updated>
  <subtitle>Monthly Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>tw93/Pake</title>
    <updated>2024-07-01T01:54:38Z</updated>
    <id>tag:github.com,2024-07-01:/tw93/Pake</id>
    <link href="https://github.com/tw93/Pake" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ü§±üèª Turn any webpage into a desktop app with Rust. ü§±üèª Âà©Áî® Rust ËΩªÊùæÊûÑÂª∫ËΩªÈáèÁ∫ßÂ§öÁ´ØÊ°åÈù¢Â∫îÁî®&lt;/p&gt;&lt;hr&gt;&lt;h4 align=&#34;right&#34;&gt;&lt;strong&gt;English&lt;/strong&gt; | &lt;a href=&#34;https://github.com/tw93/Pake/raw/master/README_CN.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&#34;https://github.com/tw93/Pake/raw/master/README_JP.md&#34;&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://gw.alipayobjects.com/zos/k/fa/logo-modified.png&#34; width=&#34;138/&#34;&gt; &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;Pake&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;strong&gt;Turn any webpage into a desktop app with Rust &lt;em&gt;with ease&lt;/em&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://twitter.com/HiTw93&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;twitter&#34; src=&#34;https://img.shields.io/badge/follow-Tw93-red?style=flat-square&amp;amp;logo=Twitter&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://t.me/+GclQS9ZnxyI2ODQ1&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;telegram&#34; src=&#34;https://img.shields.io/badge/chat-telegram-blueviolet?style=flat-square&amp;amp;logo=Telegram&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/tw93/Pake/releases&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;GitHub downloads&#34; src=&#34;https://img.shields.io/github/downloads/tw93/Pake/total.svg?style=flat-square&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/tw93/Pake/commits&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;GitHub commit&#34; src=&#34;https://img.shields.io/github/commit-activity/m/tw93/Pake?style=flat-square&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/tw93/Pake/issues?q=is%3Aissue+is%3Aclosed&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;GitHub closed issues&#34; src=&#34;https://img.shields.io/github/issues-closed/tw93/Pake.svg?style=flat-square&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://colab.research.google.com/drive/1bX345znvDZ30848xjRtpgtU8eypWwXrp?usp=sharing&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Open in Colab&#34; src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;left&#34;&gt;&#xA; Pake supports Mac, Windows, and Linux. Check out README for &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/tw93/Pake/master/#popular-packages&#34;&gt;Popular Packages&lt;/a&gt;, &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/tw93/Pake/master/#command-line-packaging&#34;&gt;Command-Line Packaging&lt;/a&gt;, and &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/tw93/Pake/master/#development&#34;&gt;Customized Development&lt;/a&gt; information. Feel free to share your suggestions in &#xA; &lt;a href=&#34;https://github.com/tw93/Pake/discussions&#34;&gt;Discussions&lt;/a&gt;.&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üéê Nearly 20 times smaller than an Electron package (around 5M!)&lt;/li&gt; &#xA; &lt;li&gt;üöÄ With Rust Tauri, Pake is much more lightweight and faster than JS-based frameworks.&lt;/li&gt; &#xA; &lt;li&gt;üì¶ Battery-included package ‚Äî shortcut pass-through, immersive windows, and minimalist customization.&lt;/li&gt; &#xA; &lt;li&gt;üëª Pake is just a simple tool ‚Äî replace the old bundle approach with Tauri (though PWA is good enough).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Popular Packages&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;WeRead &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/WeRead.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/WeRead_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/WeRead_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Twitter &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Twitter.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Twitter_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Twitter_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://cdn.fliggy.com/upic/17dC9I.jpg&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://cdn.fliggy.com/upic/mc41xq.jpg&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGPT &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/ChatGPT.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/ChatGPT_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/ChatGPT_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Poe &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Poe.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Poe_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Poe_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://cdn.fliggy.com/upic/5aO6yP.png&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://cdn.fliggy.com/upic/Ztsx23.png&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;YouTube Music &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/YouTubeMusic.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/YouTubeMusic_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/YouTubeMusic_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;YouTube &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/YouTube.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/YouTube_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/YouTube_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/tw93/static/master/pic/12.png&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/k/pn/1.jpg&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LiZhi &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/LiZhi.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/LiZhi_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/LiZhi_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;ProgramMusic &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/ProgramMusic.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/ProgramMusic_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/ProgramMusic_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://cdn.fliggy.com/upic/nYEKqN.jpg&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/k/r7/0C9lju.jpg&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwerty &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Qwerty.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Qwerty_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Qwerty_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;CodeRunner &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/CodeRunner.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/CodeRunner_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/CodeRunner_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://cdn.fliggy.com/upic/i2eg6G.png&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://cdn.fliggy.com/upic/mUzOek.jpg&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Flomo &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Flomo.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Flomo_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/Flomo_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;XiaoHongShu &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/XiaoHongShu.dmg&#34;&gt;Mac&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/XiaoHongShu_x64.msi&#34;&gt;Windows&lt;/a&gt; &lt;a href=&#34;https://github.com/tw93/Pake/releases/latest/download/XiaoHongShu_x86_64.deb&#34;&gt;Linux&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/k/30/RoUSUf.png&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/k/89/yJVwyi.png&#34; width=&#34;600/&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üèÇ You can download more applications from &lt;a href=&#34;https://github.com/tw93/Pake/releases&#34;&gt;Releases&lt;/a&gt;. &lt;b&gt;Click here to expand the shortcuts reference!&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Mac&lt;/th&gt; &#xA;    &lt;th&gt;Windows/Linux&lt;/th&gt; &#xA;    &lt;th&gt;Function&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;[&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;‚Üê&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Return to the previous page&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;]&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;‚Üí&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Go to the next page&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;‚Üë&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;‚Üë&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Auto scroll to top of page&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;‚Üì&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;‚Üì&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Auto scroll to bottom of page&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;r&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;r&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Refresh Page&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;w&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;w&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Hide window, not quite&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;-&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;-&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Zoom out the page&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;+&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;+&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Zoom in the page&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;=&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;=&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Zoom in the Page&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;‚åò&lt;/kbd&gt; + &lt;kbd&gt;0&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;0&lt;/kbd&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Reset the page zoom&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;In addition, double-click the title bar to switch to full-screen mode. For Mac users, you can also use the gesture to go to the previous or next page and drag the title bar to move the window.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Before starting&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;For beginners&lt;/strong&gt;: Play with Popular Packages to find out Pake&#39;s capabilities, or try to pack your application with &lt;a href=&#34;https://github.com/tw93/Pake/wiki/Online-Compilation-(used-by-ordinary-users)&#34;&gt;GitHub Actions&lt;/a&gt;. Don&#39;t hesitate to reach for assistance at &lt;a href=&#34;https://github.com/tw93/Pake/discussions&#34;&gt;Discussion&lt;/a&gt;!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;For developers&lt;/strong&gt;: ‚ÄúCommand-Line Packaging‚Äù supports macOS fully. For Windows/Linux users, it requires some tinkering. &lt;a href=&#34;https://tauri.app/v1/guides/getting-started/prerequisites&#34;&gt;Configure your environment&lt;/a&gt; before getting started.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;For hackers&lt;/strong&gt;: For people who are good at both front-end development and Rust, how about customizing your apps&#39; function more with the following &lt;a href=&#34;https://raw.githubusercontent.com/tw93/Pake/master/#development&#34;&gt;Customized Development&lt;/a&gt;?&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Command-Line Packaging&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/k/zd/pake.gif&#34; alt=&#34;Pake&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pake provides a command line tool, making the flow of package customization quicker and easier. See &lt;a href=&#34;https://raw.githubusercontent.com/tw93/Pake/master/bin/README.md&#34;&gt;documentation&lt;/a&gt; for more information.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Install with npm&#xA;npm install -g pake-cli&#xA;&#xA;# Command usage&#xA;pake url [OPTIONS]...&#xA;&#xA;# Feel free to play with Pake! It might take a while to prepare the environment the first time you launch Pake.&#xA;pake https://weekly.tw93.fun --name Weekly --hide-title-bar&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are new to the command line, you can compile packages online with &lt;em&gt;GitHub Actions&lt;/em&gt;. See the &lt;a href=&#34;https://github.com/tw93/Pake/wiki/Online-Compilation-(used-by-ordinary-users)&#34;&gt;Tutorial&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;Prepare your environment before starting. Make sure you have Rust &lt;code&gt;&amp;gt;=1.63&lt;/code&gt; and Node &lt;code&gt;&amp;gt;=16&lt;/code&gt; (e.g., &lt;code&gt;16.18.1&lt;/code&gt;) installed on your computer. For installation guidance, see &lt;a href=&#34;https://tauri.app/v1/guides/getting-started/prerequisites&#34;&gt;Tauri documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you are unfamiliar with these, it is better to try out the above tool to pack with one click.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Install Dependencies&#xA;npm i&#xA;&#xA;# Local development [Right-click to open debug mode.]&#xA;npm run dev&#xA;&#xA;# Pack application&#xA;npm run build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Advanced Usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;You can refer to the &lt;a href=&#34;https://github.com/tw93/Pake/wiki/Description-of-Pake&#39;s-code-structure&#34;&gt;codebase structure&lt;/a&gt; before working on Pake, which will help you much in development.&lt;/li&gt; &#xA; &lt;li&gt;Modify the &lt;code&gt;url&lt;/code&gt; and &lt;code&gt;productName&lt;/code&gt; fields in the &lt;code&gt;pake.json&lt;/code&gt; file under the src-tauri directory, the &#34;domain&#34; field in the &lt;code&gt;tauri.config.json&lt;/code&gt; file needs to be modified synchronously, as well as the &lt;code&gt;icon&lt;/code&gt; and &lt;code&gt;identifier&lt;/code&gt; fields in the &lt;code&gt;tauri.xxx.conf.json&lt;/code&gt; file. You can select an &lt;code&gt;icon&lt;/code&gt; from the &lt;code&gt;icons&lt;/code&gt; directory or download one from &lt;a href=&#34;https://macosicons.com/#/&#34;&gt;macOSicons&lt;/a&gt; to match your product needs.&lt;/li&gt; &#xA; &lt;li&gt;For configurations on window properties, you can modify the &lt;code&gt;pake.json&lt;/code&gt; file to change the value of &lt;code&gt;width&lt;/code&gt;, &lt;code&gt;height&lt;/code&gt;, &lt;code&gt;fullscreen&lt;/code&gt; (or not), &lt;code&gt;resizable&lt;/code&gt; (or not) of the &lt;code&gt;windows&lt;/code&gt; property. To adapt to the immersive header on Mac, change &lt;code&gt;hideTitleBar&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;, look for the &lt;code&gt;Header&lt;/code&gt; element, and add the &lt;code&gt;padding-top&lt;/code&gt; property.&lt;/li&gt; &#xA; &lt;li&gt;For advanced usages such as style rewriting, advertisement removal, JS injection, container message communication, and user-defined shortcut keys, see &lt;a href=&#34;https://github.com/tw93/Pake/wiki/Advanced-Usage-of-Pake&#34;&gt;Advanced Usage of Pake&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Developers&lt;/h2&gt; &#xA;&lt;p&gt;Pake&#39;s development can not be without these Hackers. They contributed a lot of capabilities for Pake. Also, welcome to follow them! ‚ù§Ô∏è&lt;/p&gt; &#xA;&lt;!-- readme: contributors -start --&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/tw93&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/8736212?v=4&#34; width=&#34;90;&#34; alt=&#34;tw93&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Tw93&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/Tlntin&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/28218658?v=4&#34; width=&#34;90;&#34; alt=&#34;Tlntin&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Tlntin&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/jeasonnow&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/16950207?v=4&#34; width=&#34;90;&#34; alt=&#34;jeasonnow&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Santree&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/pan93412&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/28441561?v=4&#34; width=&#34;90;&#34; alt=&#34;pan93412&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Pan93412&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/wanghanzhen&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/25301012?v=4&#34; width=&#34;90;&#34; alt=&#34;wanghanzhen&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Volare&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/liby&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/38807139?v=4&#34; width=&#34;90;&#34; alt=&#34;liby&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Bryan Lee&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/essesoul&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/58624474?v=4&#34; width=&#34;90;&#34; alt=&#34;essesoul&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Essesoul&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/YangguangZhou&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/61733195?v=4&#34; width=&#34;90;&#34; alt=&#34;YangguangZhou&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Jerry Zhou&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/AielloChan&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/7900765?v=4&#34; width=&#34;90;&#34; alt=&#34;AielloChan&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Aiello&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/m1911star&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/4948120?v=4&#34; width=&#34;90;&#34; alt=&#34;m1911star&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Horus&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/Pake-Actions&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/126550811?v=4&#34; width=&#34;90;&#34; alt=&#34;Pake-Actions&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Pake Actions&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/eltociear&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/22633385?v=4&#34; width=&#34;90;&#34; alt=&#34;eltociear&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Ikko Eltociear Ashimine&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/QingZ11&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/38887077?v=4&#34; width=&#34;90;&#34; alt=&#34;QingZ11&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Steam&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/exposir&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/33340988?v=4&#34; width=&#34;90;&#34; alt=&#34;exposir&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Â≠ü‰∏ñÂçö&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/2nthony&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/19513289?v=4&#34; width=&#34;90;&#34; alt=&#34;2nthony&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;2nthony&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/ACGNnsj&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/22112141?v=4&#34; width=&#34;90;&#34; alt=&#34;ACGNnsj&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Null&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/imabutahersiddik&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/138387257?v=4&#34; width=&#34;90;&#34; alt=&#34;imabutahersiddik&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Abu Taher Siddik&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/kidylee&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/841310?v=4&#34; width=&#34;90;&#34; alt=&#34;kidylee&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;An Li&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/nekomeowww&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/11081491?v=4&#34; width=&#34;90;&#34; alt=&#34;nekomeowww&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Ayaka Neko&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/turkyden&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/24560160?v=4&#34; width=&#34;90;&#34; alt=&#34;turkyden&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Dengju Deng&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/Fechin&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/2541482?v=4&#34; width=&#34;90;&#34; alt=&#34;Fechin&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Fechin&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/ImgBotApp&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/31427850?v=4&#34; width=&#34;90;&#34; alt=&#34;ImgBotApp&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Imgbot&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/droid-Q&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/708277?v=4&#34; width=&#34;90;&#34; alt=&#34;droid-Q&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Jiaqi Gu&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/Milo123459&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/50248166?v=4&#34; width=&#34;90;&#34; alt=&#34;Milo123459&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Milo&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/princemaple&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/1329716?v=4&#34; width=&#34;90;&#34; alt=&#34;princemaple&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Po Chen&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/geekvest&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/126322776?v=4&#34; width=&#34;90;&#34; alt=&#34;geekvest&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Null&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/houhoz&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/19684376?v=4&#34; width=&#34;90;&#34; alt=&#34;houhoz&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Hyzhao&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/lakca&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/16255922?v=4&#34; width=&#34;90;&#34; alt=&#34;lakca&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Null&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/liudonghua123&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/2276718?v=4&#34; width=&#34;90;&#34; alt=&#34;liudonghua123&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Liudonghua&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/liusishan&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/33129823?v=4&#34; width=&#34;90;&#34; alt=&#34;liusishan&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Liusishan&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/piaoyidage&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/5135405?v=4&#34; width=&#34;90;&#34; alt=&#34;piaoyidage&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Ranger&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/hetz&#34;&gt; &lt;img src=&#34;https://avatars.githubusercontent.com/u/820141?v=4&#34; width=&#34;90;&#34; alt=&#34;hetz&#34;&gt; &lt;br&gt; &lt;sub&gt;&lt;b&gt;Ë¥∫Â§©Âçì&lt;/b&gt;&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;!-- readme: contributors -end --&gt; &#xA;&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Right-clicking on an image element in the page to open the menu and select download image or other events does not work (common in MacOS systems). This issue is due to the MacOS built-in webview not supporting this feature.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;I have two cats, TangYuan and Coke. If you think Pake delights your life, you can feed them &lt;a href=&#34;https://miaoyan.app/cats.html?name=Pake&#34; target=&#34;_blank&#34;&gt;some canned food ü•©&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you like Pake, you can star it on GitHub. Also, welcome to &lt;a href=&#34;https://twitter.com/intent/tweet?url=https://github.com/tw93/Pake&amp;amp;text=%23Pake%20-%20A%20simple%20Rust%20packaged%20web%20pages%20to%20generate%20Mac%20App%20tool,%20compared%20to%20traditional%20Electron%20package,%20the%20size%20of%20nearly%2040%20times%20smaller,%20generally%20about%202M,%20the%20underlying%20use%20of%20Tauri,%20performance%20experience%20than%20the%20JS%20framework%20is%20much%20lighter~&#34;&gt;recommend Pake&lt;/a&gt; to your friends.&lt;/li&gt; &#xA; &lt;li&gt;You can follow my &lt;a href=&#34;https://twitter.com/HiTw93&#34;&gt;Twitter&lt;/a&gt; to get the latest news of Pake or join our &lt;a href=&#34;https://t.me/+GclQS9ZnxyI2ODQ1&#34;&gt;Telegram&lt;/a&gt; chat group.&lt;/li&gt; &#xA; &lt;li&gt;I hope that you enjoy playing with it. Let us know if you find a website that would be great for a Mac App!&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>erebe/wstunnel</title>
    <updated>2024-07-01T01:54:38Z</updated>
    <id>tag:github.com,2024-07-01:/erebe/wstunnel</id>
    <link href="https://github.com/erebe/wstunnel" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tunnel all your traffic over Websocket or HTTP2 - Bypass firewalls/DPI - Static binary available&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/erebe/wstunnel/raw/main/docs/logo_wstunnel.png&#34; alt=&#34;wstunnel logo&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;right&#34;&gt; &lt;a href=&#34;https://ko-fi.com/P5P4QCHMO&#34;&gt;&lt;img src=&#34;https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Summary&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#description&#34;&gt;Description&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#cmd&#34;&gt;Command line&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#examples&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#release&#34;&gt;Release&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#note&#34;&gt;Note&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#bench&#34;&gt;Benchmark&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#build&#34;&gt;How to build&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Description &lt;a name=&#34;description&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Most of the time when you are using a public network, you are behind some kind of firewall or proxy. One of their purpose is to constrain you to only use certain kind of protocols and consult only a subset of the web. Nowadays, the most widespread protocol is http and is de facto allowed by third party equipment.&lt;/p&gt; &#xA;&lt;p&gt;Wstunnel uses the websocket protocol which is compatible with http in order to bypass firewalls and proxies. Wstunnel allows you to tunnel whatever traffic you want and access whatever resources/site you need.&lt;/p&gt; &#xA;&lt;p&gt;My inspiration came from &lt;a href=&#34;https://www.npmjs.com/package/wstunnel&#34;&gt;this project&lt;/a&gt; but as I don&#39;t want to install npm and nodejs to use this tool, I remade it in &lt;del&gt;Haskell&lt;/del&gt; Rust and improved it.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What to expect:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Easy to use&lt;/li&gt; &#xA; &lt;li&gt;Good error messages and debug information&lt;/li&gt; &#xA; &lt;li&gt;Static forward and reverse tunneling (TCP, UDP, Unix socket, Stdio)&lt;/li&gt; &#xA; &lt;li&gt;Dynamic tunneling (TCP, UDP Socks5 proxy and Transparent Proxy)&lt;/li&gt; &#xA; &lt;li&gt;Support for http proxy (when behind one)&lt;/li&gt; &#xA; &lt;li&gt;Support of proxy protocol&lt;/li&gt; &#xA; &lt;li&gt;Support for tls/https server with certificates auto-reload (with embedded self-signed certificate, or your own)&lt;/li&gt; &#xA; &lt;li&gt;Support of mTLS with certificates auto-reload - &lt;a href=&#34;https://github.com/erebe/wstunnel/raw/main/docs/using_mtls.md&#34;&gt;documentation here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Support IPv6&lt;/li&gt; &#xA; &lt;li&gt;Support for Websocket and HTTP2 as transport protocol (websocket is more performant)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Standalone binaries&lt;/strong&gt; (so just cp it where you want) &lt;a href=&#34;https://github.com/erebe/wstunnel/releases&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Sponsors &lt;a name=&#34;sponsors&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Part of Wstunnel development has been sponsored by&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://serviceplanet.nl&#34;&gt; &lt;img width=&#34;200&#34; height=&#34;100&#34; src=&#34;https://github.com/erebe/wstunnel/raw/main/docs/logo_serviceplanet.png&#34; alt=&#34;service planet logo&#34;&gt; &lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Note &lt;a name=&#34;note&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;v7.0.0 is a complete rewrite of wstunnel in Rust and is not compatible with previous version. Previous code in Haskell can be found on branch &lt;a href=&#34;https://github.com/erebe/wstunnel/tree/haskell&#34;&gt;https://github.com/erebe/wstunnel/tree/haskell&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;What to expect from previous version:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;More throughput and less jitter due to Haskell GC. Most of you will not care, as it was performant enough already. But you can now saturate a gigabit ethernet card with a single connection&lt;/li&gt; &#xA; &lt;li&gt;Command line is more homogeneous/has better UX. All tunnel can be specified multiple times&lt;/li&gt; &#xA; &lt;li&gt;Tunnel protocol tries to look like normal traffic, to avoid being flagged&lt;/li&gt; &#xA; &lt;li&gt;Support of reverse tunneling&lt;/li&gt; &#xA; &lt;li&gt;New bug, it is a rewrite (‚ïØ&#39;‚ñ°&#39;)‚ïØÔ∏µ ‚îª‚îÅ‚îª ¬Ø\&lt;em&gt;(„ÉÑ)&lt;/em&gt;/¬Ø&lt;/li&gt; &#xA; &lt;li&gt;Mainly for me to ease the maintenance of the project. I don&#39;t do a lot of haskell nowadays and it was harder for me to keep maintening the project over time, as I get lost in touch of the Haskell ecosystem and new release.&lt;/li&gt; &#xA; &lt;li&gt;Armv7 build (aka raspberry pi), as new version of GHC (Haskell compiler) dropped its support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Command line &lt;a name=&#34;cmd&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;Usage: wstunnel client [OPTIONS] &amp;lt;ws[s]|http[s]://wstunnel.server.com[:port]&amp;gt;&#xA;&#xA;Arguments:&#xA;  &amp;lt;ws[s]|http[s]://wstunnel.server.com[:port]&amp;gt;&#xA;          Address of the wstunnel server&#xA;          You can either use websocket or http2 as transport protocol. Use websocket if you are unsure.&#xA;          Example: For websocket with TLS wss://wstunnel.example.com or without ws://wstunnel.example.com&#xA;                   For http2 with TLS https://wstunnel.example.com or without http://wstunnel.example.com&#xA;          &#xA;          *WARNING* HTTP2 as transport protocol is harder to make it works because:&#xA;            - If you are behind a (reverse) proxy/CDN they are going to buffer the whole request before forwarding it to the server&#xA;              Obviously, this is not going to work for tunneling traffic&#xA;            - if you have wstunnel behind a reverse proxy, most of them (i.e: nginx) are going to turn http2 request into http1&#xA;              This is not going to work, because http1 does not support streaming naturally&#xA;          The only way to make it works with http2 is to have wstunnel directly exposed to the internet without any reverse proxy in front of it&#xA;&#xA;Options:&#xA;  -L, --local-to-remote &amp;lt;{tcp,udp,socks5,stdio,unix}://[BIND:]PORT:HOST:PORT&amp;gt;&#xA;          Listen on local and forwards traffic from remote. Can be specified multiple times&#xA;          examples:&#xA;          &#39;tcp://1212:google.com:443&#39;      =&amp;gt;       listen locally on tcp on port 1212 and forward to google.com on port 443&#xA;          &#39;tcp://2:n.lan:4?proxy_protocol&#39; =&amp;gt;       listen locally on tcp on port 2 and forward to n.lan on port 4&#xA;                                                    Send a proxy protocol header v2 when establishing connection to n.lan&#xA;          &#xA;          &#39;udp://1212:1.1.1.1:53&#39;          =&amp;gt;       listen locally on udp on port 1212 and forward to cloudflare dns 1.1.1.1 on port 53&#xA;          &#39;udp://1212:1.1.1.1:53?timeout_sec=10&#39;    timeout_sec on udp force close the tunnel after 10sec. Set it to 0 to disable the timeout [default: 30]&#xA;          &#xA;          &#39;socks5://[::1]:1212&#39;            =&amp;gt;       listen locally with socks5 on port 1212 and forward dynamically requested tunnel&#xA;          &#xA;          &#39;tproxy+tcp://[::1]:1212&#39;        =&amp;gt;       listen locally on tcp on port 1212 as a *transparent proxy* and forward dynamically requested tunnel&#xA;          &#39;tproxy+udp://[::1]:1212?timeout_sec=10&#39;  listen locally on udp on port 1212 as a *transparent proxy* and forward dynamically requested tunnel&#xA;                                                    linux only and requires sudo/CAP_NET_ADMIN&#xA;          &#xA;          &#39;stdio://google.com:443&#39;         =&amp;gt;       listen for data from stdio, mainly for `ssh -o ProxyCommand=&#34;wstunnel client --log-lvl=off -L stdio://%h:%p ws://localhost:8080&#34; my-server`&#xA;          &#xA;          &#39;unix:///tmp/wstunnel.sock:g.com:443&#39; =&amp;gt;  listen for data from unix socket of path /tmp/wstunnel.sock and forward to g.com:443&#xA;&#xA;  -R, --remote-to-local &amp;lt;{tcp,udp,socks5,unix}://[BIND:]PORT:HOST:PORT&amp;gt;&#xA;          Listen on remote and forwards traffic from local. Can be specified multiple times. Only tcp is supported&#xA;          examples:&#xA;          &#39;tcp://1212:google.com:443&#39;      =&amp;gt;     listen on server for incoming tcp cnx on port 1212 and forward to google.com on port 443 from local machine&#xA;          &#39;udp://1212:1.1.1.1:53&#39;          =&amp;gt;     listen on server for incoming udp on port 1212 and forward to cloudflare dns 1.1.1.1 on port 53 from local machine&#xA;          &#39;socks5://[::1]:1212&#39;            =&amp;gt;     listen on server for incoming socks5 request on port 1212 and forward dynamically request from local machine&#xA;          &#39;unix://wstunnel.sock:g.com:443&#39; =&amp;gt;     listen on server for incoming data from unix socket of path wstunnel.sock and forward to g.com:443 from local machine&#xA;&#xA;      --no-color &amp;lt;NO_COLOR&amp;gt;&#xA;          Disable color output in logs&#xA;          &#xA;          [env: NO_COLOR=]&#xA;&#xA;      --socket-so-mark &amp;lt;INT&amp;gt;&#xA;          (linux only) Mark network packet with SO_MARK sockoption with the specified value.&#xA;          You need to use {root, sudo, capabilities} to run wstunnel when using this option&#xA;&#xA;  -c, --connection-min-idle &amp;lt;INT&amp;gt;&#xA;          Client will maintain a pool of open connection to the server, in order to speed up the connection process.&#xA;          This option set the maximum number of connection that will be kept open.&#xA;          This is useful if you plan to create/destroy a lot of tunnel (i.e: with socks5 to navigate with a browser)&#xA;          It will avoid the latency of doing tcp + tls handshake with the server&#xA;          &#xA;          [default: 0]&#xA;&#xA;      --nb-worker-threads &amp;lt;INT&amp;gt;&#xA;          *WARNING* The flag does nothing, you need to set the env variable *WARNING*&#xA;          Control the number of threads that will be used.&#xA;          By default, it is equal the number of cpus&#xA;          &#xA;          [env: TOKIO_WORKER_THREADS=]&#xA;&#xA;      --log-lvl &amp;lt;LOG_LEVEL&amp;gt;&#xA;          Control the log verbosity. i.e: TRACE, DEBUG, INFO, WARN, ERROR, OFF&#xA;          for more details: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html#example-syntax&#xA;          &#xA;          [env: RUST_LOG=]&#xA;          [default: INFO]&#xA;&#xA;      --tls-sni-override &amp;lt;DOMAIN_NAME&amp;gt;&#xA;          Domain name that will be used as SNI during TLS handshake&#xA;          Warning: If you are behind a CDN (i.e: Cloudflare) you must set this domain also in the http HOST header.&#xA;                   or it will be flagged as fishy and your request rejected&#xA;&#xA;      --tls-sni-disable&#xA;          Disable sending SNI during TLS handshake&#xA;          Warning: Most reverse proxies rely on it&#xA;&#xA;      --tls-verify-certificate&#xA;          Enable TLS certificate verification.&#xA;          Disabled by default. The client will happily connect to any server with self-signed certificate.&#xA;&#xA;  -p, --http-proxy &amp;lt;USER:PASS@HOST:PORT&amp;gt;&#xA;          If set, will use this http proxy to connect to the server&#xA;          &#xA;          [env: HTTP_PROXY=]&#xA;&#xA;      --http-proxy-login &amp;lt;LOGIN&amp;gt;&#xA;          If set, will use this login to connect to the http proxy. Override the one from --http-proxy&#xA;          &#xA;          [env: WSTUNNEL_HTTP_PROXY_LOGIN=]&#xA;&#xA;      --http-proxy-password &amp;lt;PASSWORD&amp;gt;&#xA;          If set, will use this password to connect to the http proxy. Override the one from --http-proxy&#xA;          &#xA;          [env: WSTUNNEL_HTTP_PROXY_PASSWORD=]&#xA;&#xA;  -P, --http-upgrade-path-prefix &amp;lt;HTTP_UPGRADE_PATH_PREFIX&amp;gt;&#xA;          Use a specific prefix that will show up in the http path during the upgrade request.&#xA;          Useful if you need to route requests server side but don&#39;t have vhosts&#xA;          &#xA;          [env: WSTUNNEL_HTTP_UPGRADE_PATH_PREFIX=]&#xA;          [default: v1]&#xA;&#xA;      --http-upgrade-credentials &amp;lt;USER[:PASS]&amp;gt;&#xA;          Pass authorization header with basic auth credentials during the upgrade request.&#xA;          If you need more customization, you can use the http_headers option.&#xA;&#xA;      --websocket-ping-frequency-sec &amp;lt;seconds&amp;gt;&#xA;          Frequency at which the client will send websocket ping to the server.&#xA;          &#xA;          [default: 30]&#xA;&#xA;      --websocket-mask-frame&#xA;          Enable the masking of websocket frames. Default is false&#xA;          Enable this option only if you use unsecure (non TLS) websocket server, and you see some issues. Otherwise, it is just overhead.&#xA;&#xA;  -H, --http-headers &amp;lt;HEADER_NAME: HEADER_VALUE&amp;gt;&#xA;          Send custom headers in the upgrade request&#xA;          Can be specified multiple time&#xA;&#xA;      --http-headers-file &amp;lt;FILE_PATH&amp;gt;&#xA;          Send custom headers in the upgrade request reading them from a file.&#xA;          It overrides http_headers specified from command line.&#xA;          File is read everytime and file format must contain lines with `HEADER_NAME: HEADER_VALUE`&#xA;&#xA;      --tls-certificate &amp;lt;FILE_PATH&amp;gt;&#xA;          [Optional] Certificate (pem) to present to the server when connecting over TLS (HTTPS).&#xA;          Used when the server requires clients to authenticate themselves with a certificate (i.e. mTLS).&#xA;          The certificate will be automatically reloaded if it changes&#xA;&#xA;      --tls-private-key &amp;lt;FILE_PATH&amp;gt;&#xA;          [Optional] The private key for the corresponding certificate used with mTLS.&#xA;          The certificate will be automatically reloaded if it changes&#xA;&#xA;      --dns-resolver &amp;lt;DNS_RESOLVER&amp;gt;&#xA;          Dns resolver to use to lookup ips of domain name. Can be specified multiple time&#xA;          Example:&#xA;           dns://1.1.1.1 for using udp&#xA;           dns+https://1.1.1.1?sni=cloudflare-dns.com for using dns over HTTPS&#xA;           dns+tls://8.8.8.8?sni=dns.google for using dns over TLS&#xA;          For Dns over HTTPS/TLS if an HTTP proxy is configured, it will be used also&#xA;          To use libc resolver, use&#xA;          system://0.0.0.0&#xA;&#xA;          **WARN** On windows you may want to specify explicitly the DNS resolver to avoid excessive DNS queries&#xA;&#xA;SERVER&#xA;Usage: wstunnel server [OPTIONS] &amp;lt;ws[s]://0.0.0.0[:port]&amp;gt;&#xA;&#xA;Arguments:&#xA;  &amp;lt;ws[s]://0.0.0.0[:port]&amp;gt;&#xA;          Address of the wstunnel server to bind to&#xA;          Example: With TLS wss://0.0.0.0:8080 or without ws://[::]:8080&#xA;          &#xA;          The server is capable of detecting by itself if the request is websocket or http2. So you don&#39;t need to specify it.&#xA;&#xA;Options:&#xA;      --socket-so-mark &amp;lt;INT&amp;gt;&#xA;          (linux only) Mark network packet with SO_MARK sockoption with the specified value.&#xA;          You need to use {root, sudo, capabilities} to run wstunnel when using this option&#xA;&#xA;      --websocket-ping-frequency-sec &amp;lt;seconds&amp;gt;&#xA;          Frequency at which the server will send websocket ping to client.&#xA;&#xA;      --no-color &amp;lt;NO_COLOR&amp;gt;&#xA;          Disable color output in logs&#xA;          &#xA;          [env: NO_COLOR=]&#xA;&#xA;      --websocket-mask-frame&#xA;          Enable the masking of websocket frames. Default is false&#xA;          Enable this option only if you use unsecure (non TLS) websocket server, and you see some issues. Otherwise, it is just overhead.&#xA;&#xA;      --nb-worker-threads &amp;lt;INT&amp;gt;&#xA;          *WARNING* The flag does nothing, you need to set the env variable *WARNING*&#xA;          Control the number of threads that will be used.&#xA;          By default, it is equal the number of cpus&#xA;          &#xA;          [env: TOKIO_WORKER_THREADS=]&#xA;&#xA;      --restrict-to &amp;lt;DEST:PORT&amp;gt;&#xA;          Server will only accept connection from the specified tunnel information.&#xA;          Can be specified multiple time&#xA;          Example: --restrict-to &#34;google.com:443&#34; --restrict-to &#34;localhost:22&#34;&#xA;&#xA;      --dns-resolver &amp;lt;DNS_RESOLVER&amp;gt;&#xA;          Dns resolver to use to lookup ips of domain name&#xA;          This option is not going to work if you use transparent proxy&#xA;          Can be specified multiple time&#xA;          Example:&#xA;           dns://1.1.1.1 for using udp&#xA;           dns+https://1.1.1.1?sni=loudflare-dns.com for using dns over HTTPS&#xA;           dns+tls://8.8.8.8?sni=dns.google for using dns over TLS&#xA;          To use libc resolver, use&#xA;          system://0.0.0.0&#xA;&#xA;      --log-lvl &amp;lt;LOG_LEVEL&amp;gt;&#xA;          Control the log verbosity. i.e: TRACE, DEBUG, INFO, WARN, ERROR, OFF&#xA;          for more details: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html#example-syntax&#xA;          &#xA;          [env: RUST_LOG=]&#xA;          [default: INFO]&#xA;&#xA;  -r, --restrict-http-upgrade-path-prefix &amp;lt;RESTRICT_HTTP_UPGRADE_PATH_PREFIX&amp;gt;&#xA;          Server will only accept connection from if this specific path prefix is used during websocket upgrade.&#xA;          Useful if you specify in the client a custom path prefix, and you want the server to only allow this one.&#xA;          The path prefix act as a secret to authenticate clients&#xA;          Disabled by default. Accept all path prefix. Can be specified multiple time&#xA;          &#xA;          [env: WSTUNNEL_RESTRICT_HTTP_UPGRADE_PATH_PREFIX=]&#xA;&#xA;      --restrict-config &amp;lt;RESTRICT_CONFIG&amp;gt;&#xA;          Path to the location of the restriction yaml config file.&#xA;          Restriction file is automatically reloaded if it changes&#xA;&#xA;      --tls-certificate &amp;lt;FILE_PATH&amp;gt;&#xA;          [Optional] Use custom certificate (pem) instead of the default embedded self-signed certificate.&#xA;          The certificate will be automatically reloaded if it changes&#xA;&#xA;      --tls-private-key &amp;lt;FILE_PATH&amp;gt;&#xA;          [Optional] Use a custom tls key (pem, ec, rsa) that the server will use instead of the default embedded one&#xA;          The private key will be automatically reloaded if it changes&#xA;&#xA;      --tls-client-ca-certs &amp;lt;FILE_PATH&amp;gt;&#xA;          [Optional] Enables mTLS (client authentication with certificate). Argument must be PEM file&#xA;          containing one or more certificates of CA&#39;s of which the certificate of clients needs to be signed with.&#xA;          The ca will be automatically reloaded if it changes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Release &lt;a name=&#34;release&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Static binaries are available in &lt;a href=&#34;https://github.com/erebe/wstunnel/releases&#34;&gt;release section&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;docker image are available at &lt;a href=&#34;https://github.com/erebe/wstunnel/pkgs/container/wstunnel&#34;&gt;https://github.com/erebe/wstunnel/pkgs/container/wstunnel&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull ghcr.io/erebe/wstunnel:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples &lt;a name=&#34;examples&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#syntax&#34;&gt;Understand command line syntax&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#simple&#34;&gt;Simplest one with socks5 - Good for browsing internet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#ssh&#34;&gt;Proxy SSH&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#corporate&#34;&gt;Bypass a corporate proxy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#wireguard&#34;&gt;Proxy Wireguard traffic&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#tproxy&#34;&gt;Proxy easily any traffic with transparent proxy (linux only)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#reverse&#34;&gt;Reverse tunneling&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#secure&#34;&gt;How to secure access of your wstunnel server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#http2&#34;&gt;Use HTTP2 instead of websocket for transport protocol&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/erebe/wstunnel/main/#stealth&#34;&gt;Maximize your stealthiness/Make your traffic discrete&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Understand command line syntax &lt;a name=&#34;syntax&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Wstunnel command line mimic ssh tunnel syntax. You can take reference to &lt;a href=&#34;https://iximiuz.com/en/posts/ssh-tunnels/&#34;&gt;this article&lt;/a&gt;, or this diagram to understand &lt;img src=&#34;https://iximiuz.com/ssh-tunnels/ssh-tunnels.png&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Simplest one &lt;a name=&#34;simple&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;On your remote host, start the wstunnel&#39;s server by typing this command in your terminal&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wstunnel server wss://[::]:8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will create a websocket server listening on any interface on port 8080. On the client side use this command to forward traffic through the websocket tunnel&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wstunnel client -L socks5://127.0.0.1:8888 --connection-min-idle 5 wss://myRemoteHost:8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command will create a socks5 server listening on port 8888 of the loopback interface and will forward traffic dynamically. &lt;code&gt;connection-min-idle 10&lt;/code&gt; is going an optimization to create a pool of 10 connection connected to the server, to speed-up the establishement of new tunnels.&lt;/p&gt; &#xA;&lt;p&gt;With firefox you can setup a proxy using this tunnel, by setting in networking preferences 127.0.0.1:8888 and selecting socks5 proxy. Be sure to check the option &lt;code&gt;Proxy DNS when using SOCKS v5&lt;/code&gt; for the server to resolve DNS name and not your local machine.&lt;/p&gt; &#xA;&lt;p&gt;or with curl&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -x socks5h://127.0.0.1:8888 http://google.com/&#xA;#Please note h after the 5, it is to avoid curl resolving DNS name locally&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;As proxy command for SSH &lt;a name=&#34;ssh&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;You can specify &lt;code&gt;stdio&lt;/code&gt; as source port on the client side if you wish to use wstunnel as part of a proxy command for ssh&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh -o ProxyCommand=&#34;wstunnel client --log-lvl=off -L stdio://%h:%p ws://myRemoteHost:8080&#34; my-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;When behind a corporate proxy &lt;a name=&#34;corporate&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;An other useful example is when you want to bypass an http proxy (a corporate proxy for example) The most reliable way to do it is to use wstunnel as described below&lt;/p&gt; &#xA;&lt;p&gt;Start your wstunnel server with tls activated&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wstunnel server wss://[::]:443 --restrict-to 127.0.0.1:22&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The server will listen on any interface using port 443 (https) and restrict traffic to be forwarded only to the ssh daemon.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Be aware that the server will use self signed certificate with weak cryptographic algorithm. It was made in order to add the least possible overhead while still being compliant with tls.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Do not rely on wstunnel to protect your privacy, if it is one of your concerns, you should only forwards traffic that is already secure by design (ie: https or vpn traffic)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now on the client side start the client with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wstunnel client -L tcp://9999:127.0.0.1:22 -p http://mycorporateproxy:8080 wss://myRemoteHost:443&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will start a tcp server on port 9999 that will contact the corporate proxy, negotiate a tls connection with the remote host and forward traffic to the ssh daemon on the remote host.&lt;/p&gt; &#xA;&lt;p&gt;You may now access your server from your local machine on ssh by using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh -p 9999 login@127.0.0.1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Wireguard and wstunnel &lt;a name=&#34;wireguard&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;You have a working wireguard client configuration called &lt;code&gt;wg0.conf&lt;/code&gt;. Let&#39;s say&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[Interface]&#xA;Address = 10.200.0.2/32, fd00:cafe::2/128&#xA;PrivateKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx=&#xA;&#xA;[Peer]&#xA;PublicKey = 9iicV7Stdl/U0RH1BNf3VvlVjaa4Eus6QPEfEz6cR0c=&#xA;AllowedIPs = 0.0.0.0/0, ::/0&#xA;Endpoint = my.server.com:51820&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Start wstunnel server on my.server.com like this&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;wstunnel server --restrict-to localhost:51820 wss://[::]:443&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;on your local machine start the client like this&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;wstunnel client -L &#39;udp://51820:localhost:51820?timeout_sec=0&#39; wss://my.server.com:443&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;change your wireguard client config to something&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[Interface]&#xA;Address = 10.200.0.2/32, fd00:cafe::2/128&#xA;PrivateKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx=&#xA;# Replace by a dns your server has access to&#xA;dns = 8.8.8.8&#xA;# https://github.com/nitred/nr-wg-mtu-finder to find best mtu for you&#xA;MTU = 1400 &#xA;&#xA;[Peer]&#xA;PublicKey = 9iicV7Stdl/U0RH1BNf3VvlVjaa4Eus6QPEfEz6cR0c=&#xA;AllowedIPs = 0.0.0.0/0, ::/0&#xA;# Should target port where wstunnel client is listenning to&#xA;Endpoint = localhost:51820&#xA;# Should not be necessary if you enable wstunnel client websocket ping&#xA;PersistentKeepalive = 20&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add a default route to your server, as your AllowedIps are catch-all, it is to avoid the traffic looping.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo ip route add ip.of.my.server.com dev eth0 via 192.168.0.1&#xA;# replace eth0 (interface) and 192.168.0.1 (router gateway) by the one given by `ip route get ip.of.my.server.com` &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;start your wireguard, and it should be working&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo wg-quick up wg0&#xA;ping 10.200.0.1 # ping another ip of your vpn network&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;FAQ&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Disable default udp tunnel timeout that will auto-close it after 30sec. &lt;code&gt;i.e: udp://1212:127.0.0.1:5201?timeout_sec=0&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you see some throughput issue, be sure to lower the MTU of your wireguard interface (you can do it via config file) to something like 1300 or you will endup fragmenting udp packet (due to overhead of other layer) which is always causing issues&lt;/li&gt; &#xA; &lt;li&gt;If wstunnel cannot connect to server while wireguard is on, be sure you have added a static route via your main gateway for the ip of wstunnel server. Else if you forward all the traffic without putting a static route, you will endup looping your traffic wireguard interface -&amp;gt; wstunnel client -&amp;gt; wireguard interface&lt;/li&gt; &#xA; &lt;li&gt;If you have trouble making it works on windows, please check this issue &lt;a href=&#34;https://github.com/erebe/wstunnel/issues/252&#34;&gt;https://github.com/erebe/wstunnel/issues/252&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Transparent proxy (linux only) &lt;a name=&#34;tproxy&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Transparent proxy allows to easily proxy any program. Start wstunnel with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo wstunnel client -L &#39;tproxy+tcp://1080&#39; -L &#39;tproxy+udp://1080&#39; wss://my.server.com:443&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;use this project to route traffic seamlessly &lt;a href=&#34;https://github.com/NOBLES5E/cproxy&#34;&gt;https://github.com/NOBLES5E/cproxy&lt;/a&gt;. It works with any program&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cproxy --port 1080 --mode tproxy -- curl https://google.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can even start a new shell, were all your commands will be proxyfied&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cproxy --port 1080 --mode tproxy -- bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Reverse tunneling &lt;a name=&#34;reverse&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Start wstunnel with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo wstunnel client -R &#39;tcp://[::]:8000:localhost:8000&#39; wss://my.server.com:443&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In another terminal, start a simple webserver on your local machine&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 -m http.server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;From your my.server.com machine/network you can now do&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl http://localhost:8000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;How to secure the access of your wstunnel server &lt;a name=&#34;secure&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Generate a secret, let&#39;s say &lt;code&gt;h3GywpDrP6gJEdZ6xbJbZZVFmvFZDCa4KcRd&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now start you server with the following command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wstunnel server --restrict-http-upgrade-path-prefix h3GywpDrP6gJEdZ6xbJbZZVFmvFZDCa4KcRd  wss://[::]:443 &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And start your client with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wstunnel client --http-upgrade-path-prefix h3GywpDrP6gJEdZ6xbJbZZVFmvFZDCa4KcRd ... wss://myRemoteHost&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now your wstunnel server, will only accept connection if the client specify the correct path prefix during the upgrade request.&lt;/p&gt; &#xA;&lt;p&gt;If you need more customization, you can use a config file to specify specific rules with &lt;code&gt;--restrict-config&lt;/code&gt;. You can find examples of restriction rules &lt;a href=&#34;https://github.com/erebe/wstunnel/raw/main/restrictions.yaml&#34;&gt;there&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Use HTTP2 instead of websocket for the transport protocol &lt;a name=&#34;http2&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Use this only if websocket is blocked by your firewall/proxy. Otherwise, it is less performant than websocket.&lt;/p&gt; &#xA;&lt;p&gt;Start your wstunnel server as usual with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wstunnel server wss://[::]:8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On the client the only difference is to specify https:// instead of wss://&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wstunnel client -L socks5://127.0.0.1:8888 https://myRemoteHost:8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt; HTTP2 as transport protocol is harder to make it works because:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you are behind a (reverse) proxy/CDN they may buffer the whole request before forwarding it to the server. Cloudflare is doing that, and obviously, this is not going to work for tunneling traffic&lt;/li&gt; &#xA; &lt;li&gt;if you have wstunnel behind a reverse proxy, most of them (i.e: nginx) are going to turn http2 request into http1 This is not going to work, because http1 does not support streaming naturally&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The only way to make it works with HTTP2 is to have wstunnel server directly exposed to the internet without any reverse proxy in front of it&lt;/p&gt; &#xA;&lt;p&gt;In addition, you may also want to play with the request headers (i.e: content-length and content-type) to make it looks like normal traffic to bypass your firewall/proxy. Some firewall may not like to see request with content-length not set, or with content-type set to application/octet-stream&lt;/p&gt; &#xA;&lt;h3&gt;Maximize your stealthiness/Make your traffic discrete &lt;a name=&#34;stealth&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use wstunnel with TLS activated (wss://) and use your own certificate &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Embedded certificate is self-signed and are the same for everyone, so can be easily fingerprinted/flagged&lt;/li&gt; &#xA;   &lt;li&gt;Use valid certificate (i.e: with Let&#39;s Encrypt), self-signed certificate are suspicious&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Use a custom http path prefix (see &lt;code&gt;--http-upgrade-path-prefix&lt;/code&gt; option) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;To avoid having the same url than every other wstunnel user&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Change your tls-sni-override to a domain is known to be allowed (i.e: google.com, baidu.com, etc...) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;this will not work if your wstunnel server is behind a reverse proxy (i.e: Nginx, Cloudflare, HAProxy, ...)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Benchmark &lt;a name=&#34;bench&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/erebe/wstunnel/assets/854278/6e3580b0-c4f8-449e-881e-64d1df56b0ce&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How to Build &lt;a name=&#34;build&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Install the Rust &lt;a href=&#34;https://www.rust-lang.org/tools/install&#34;&gt;https://www.rust-lang.org/tools/install&lt;/a&gt; or if you are a believer&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and run those commands at the root of the project&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cargo build&#xA;target/debug/wstunnel ...&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>EricLBuehler/mistral.rs</title>
    <updated>2024-07-01T01:54:38Z</updated>
    <id>tag:github.com,2024-07-01:/EricLBuehler/mistral.rs</id>
    <link href="https://github.com/EricLBuehler/mistral.rs" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Blazingly fast LLM inference.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; mistral.rs &lt;/h1&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; Blazingly fast LLM inference. &lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; | &lt;a href=&#34;https://ericlbuehler.github.io/mistral.rs/mistralrs/&#34;&gt;&lt;b&gt;Rust Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/EricLBuehler/mistral.rs/raw/master/mistralrs-pyo3/API.md&#34;&gt;&lt;b&gt;Python Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://discord.gg/SZrecqK8qw&#34;&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; &#xA;&lt;p&gt;Mistral.rs is a fast LLM inference platform supporting inference on a variety of devices, quantization, and easy-to-use application with an Open-AI API compatible HTTP server and Python bindings.&lt;/p&gt; &#xA;&lt;p&gt;Please submit requests for new models &lt;a href=&#34;https://github.com/EricLBuehler/mistral.rs/issues/156&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get started fast üöÄ&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/#installation-and-build&#34;&gt;Install&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/#getting-models&#34;&gt;Get models&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Deploy with our easy to use APIs&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/examples/python&#34;&gt;Python&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/mistralrs/examples&#34;&gt;Rust&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/examples/http.md&#34;&gt;OpenAI compatible HTTP server&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Quick examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;üíé Run the Gemma 2 model&lt;/p&gt; &lt;p&gt;&lt;em&gt;After following installation instructions&lt;/em&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./mistralrs_server -i plain -m google/gemma-2-9b-it -a gemma2&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;œÜ¬≥ Run the Phi 3 model with 128K context window&lt;/p&gt; &lt;p&gt;&lt;em&gt;After following installation instructions&lt;/em&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./mistralrs_server -i plain -m microsoft/Phi-3-mini-128k-instruct -a phi3&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;œÜ¬≥ üì∑ Run the Phi 3 vision model: &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/docs/PHI3V.md&#34;&gt;documentation and guide here&lt;/a&gt;&lt;/p&gt; &lt;img src=&#34;https://www.nhmagazine.com/content/uploads/2019/05/mtwashingtonFranconia-2-19-18-108-Edit-Edit.jpg&#34; alt=&#34;Mount Washington&#34; width=&#34;400&#34; height=&#34;267&#34;&gt; &lt;h6&gt;&lt;a href=&#34;https://www.nhmagazine.com/mount-washington/&#34;&gt;Credit&lt;/a&gt;&lt;/h6&gt; &lt;p&gt;&lt;em&gt;After following installation instructions&lt;/em&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./mistralrs_server --port 1234 vision-plain -m microsoft/Phi-3-vision-128k-instruct -a phi3v&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Other models: &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/#support-matrix&#34;&gt;see a support matrix&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/#run-with-the-cli&#34;&gt;how to run them&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Mistal.rs supports several model categories:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;text&lt;/li&gt; &#xA; &lt;li&gt;vision (see &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/docs/VISION_MODELS.md&#34;&gt;the docs&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Quantized model support: 2-bit, 3-bit, 4-bit, 5-bit, 6-bit and 8-bit for faster inference and optimized memory usage.&lt;/li&gt; &#xA; &lt;li&gt;Continuous batching.&lt;/li&gt; &#xA; &lt;li&gt;Prefix caching.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/docs/DEVICE_MAPPING.md&#34;&gt;Device mapping&lt;/a&gt;: load and run some layers on the device and the rest on the CPU.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerator support&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Apple silicon support with the Metal framework.&lt;/li&gt; &#xA; &lt;li&gt;CPU inference with &lt;code&gt;mkl&lt;/code&gt;, &lt;code&gt;accelerate&lt;/code&gt; support and optimized backend.&lt;/li&gt; &#xA; &lt;li&gt;CUDA support with flash attention and cuDNN.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Easy&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lightweight OpenAI API compatible HTTP server.&lt;/li&gt; &#xA; &lt;li&gt;Python API.&lt;/li&gt; &#xA; &lt;li&gt;Grammar support with Regex and Yacc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/docs/ISQ.md&#34;&gt;ISQ&lt;/a&gt; (In situ quantization): run &lt;code&gt;.safetensors&lt;/code&gt; models directly from Hugging Face Hub by quantizing them after loading instead of creating a GGUF file. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This loads the ISQ-able weights on CPU before quantizing with ISQ and then moving to the device to avoid memory spikes.&lt;/li&gt; &#xA;   &lt;li&gt;Extremely fast due to working in parallel&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Powerful&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fast LoRA support with weight merging.&lt;/li&gt; &#xA; &lt;li&gt;First X-LoRA inference platform with first class support.&lt;/li&gt; &#xA; &lt;li&gt;Speculative Decoding: Mix supported models as the draft model or the target model&lt;/li&gt; &#xA; &lt;li&gt;Dynamic LoRA adapter swapping at runtime with adapter preloading: &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/docs/ADAPTER_MODELS.md#adapter-model-dynamic-adapter-activation&#34;&gt;examples and docs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This is a demo of interactive mode with streaming running Phi 3 128k mini with quantization via ISQ to Q4K.&lt;/p&gt; &#xA;&lt;!-- Mistral GGUF demo, old API --&gt; &#xA;&lt;!-- https://github.com/EricLBuehler/mistral.rs/assets/65165915/3396abcd-8d44-4bf7-95e6-aa532db09415 --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/EricLBuehler/mistral.rs/assets/65165915/09d9a30f-1e22-4b9a-9006-4ec6ebc6473c&#34;&gt;https://github.com/EricLBuehler/mistral.rs/assets/65165915/09d9a30f-1e22-4b9a-9006-4ec6ebc6473c&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Support matrix&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: See &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/#supported-models&#34;&gt;supported models&lt;/a&gt; for more information&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Supports quantization&lt;/th&gt; &#xA;   &lt;th&gt;Supports adapters&lt;/th&gt; &#xA;   &lt;th&gt;Supports device mapping&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral v0.1/v0.2/v0.3&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemma&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 2/3&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mixtral&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi 2&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi 3&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen 2&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi 3 Vision&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Idefics 2&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemma 2&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;APIs and Integrations&lt;/h2&gt; &#xA;&lt;h3&gt;Rust Crate&lt;/h3&gt; &#xA;&lt;p&gt;Rust multithreaded/async API for easy integration into any application.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ericlbuehler.github.io/mistral.rs/mistralrs/&#34;&gt;Docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/mistralrs/examples/&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To install: Add &lt;code&gt;mistralrs = { git = &#34;https://github.com/EricLBuehler/mistral.rs.git&#34; }&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Python API&lt;/h3&gt; &#xA;&lt;p&gt;Python API for mistral.rs.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/mistralrs-pyo3/README.md&#34;&gt;Installation including PyPI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/mistralrs-pyo3/API.md&#34;&gt;Docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/examples/python&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/examples/python/cookbook.ipynb&#34;&gt;Cookbook&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;HTTP Server&lt;/h3&gt; &#xA;&lt;p&gt;OpenAI API compatible API server&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/examples/http.md&#34;&gt;API Docs&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/README.md#run&#34;&gt;Running&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/examples/server/chat.py&#34;&gt;Example&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Llama Index integration (Python)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Docs: &lt;a href=&#34;https://docs.llamaindex.ai/en/stable/examples/llm/mistral_rs/&#34;&gt;https://docs.llamaindex.ai/en/stable/examples/llm/mistral_rs/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Supported accelerators&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CUDA: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Enable with &lt;code&gt;cuda&lt;/code&gt; feature: &lt;code&gt;--features cuda&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Flash attention support with &lt;code&gt;flash-attn&lt;/code&gt; feature, only applicable to non-quantized models: &lt;code&gt;--features flash-attn&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;cuDNNsupport with &lt;code&gt;cudnn&lt;/code&gt; feature: &lt;code&gt;--features cudnn&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Metal: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Enable with &lt;code&gt;metal&lt;/code&gt; feature: &lt;code&gt;--features metal&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;CPU: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Intel MKL with &lt;code&gt;mkl&lt;/code&gt; feature: &lt;code&gt;--features mkl&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Apple Accelerate with &lt;code&gt;accelerate&lt;/code&gt; feature: &lt;code&gt;--features accelerate&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Enabling features is done by passing &lt;code&gt;--features ...&lt;/code&gt; to the build system. When using &lt;code&gt;cargo run&lt;/code&gt; or &lt;code&gt;maturin develop&lt;/code&gt;, pass the &lt;code&gt;--features&lt;/code&gt; flag before the &lt;code&gt;--&lt;/code&gt; separating build flags from runtime flags.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To enable a single feature like &lt;code&gt;metal&lt;/code&gt;: &lt;code&gt;cargo build --release --features metal&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;To enable multiple features, specify them in quotes: &lt;code&gt;cargo build --release --features &#34;cuda flash-attn cudnn&#34;&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Device&lt;/th&gt; &#xA;   &lt;th&gt;Mistral.rs Completion T/s&lt;/th&gt; &#xA;   &lt;th&gt;Llama.cpp Completion T/s&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Quant&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A10 GPU, CUDA&lt;/td&gt; &#xA;   &lt;td&gt;78&lt;/td&gt; &#xA;   &lt;td&gt;78&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/TheBloke/Mistral-7B-Instruct-v0.1-GGUF&#34;&gt;mistral-7b&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;4_K_M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Intel Xeon 8358 CPU, AVX&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;19&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/TheBloke/Mistral-7B-Instruct-v0.1-GGUF&#34;&gt;mistral-7b&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;4_K_M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Raspberry Pi 5 (8GB), Neon&lt;/td&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/TheBloke/Mistral-7B-Instruct-v0.1-GGUF&#34;&gt;mistral-7b&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2_K&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A100 GPU, CUDA&lt;/td&gt; &#xA;   &lt;td&gt;119&lt;/td&gt; &#xA;   &lt;td&gt;119&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/TheBloke/Mistral-7B-Instruct-v0.1-GGUF&#34;&gt;mistral-7b&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;4_K_M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Please submit more benchmarks via raising an issue!&lt;/p&gt; &#xA;&lt;h2&gt;Installation and Build&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: You can use our &lt;a href=&#34;https://github.com/EricLBuehler/mistral.rs/pkgs/container/mistral.rs&#34;&gt;Docker containers here&lt;/a&gt;. Learn more about running Docker containers: &lt;a href=&#34;https://docs.docker.com/engine/reference/run/&#34;&gt;https://docs.docker.com/engine/reference/run/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install the &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/mistralrs-pyo3/README.md&#34;&gt;Python package here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install required packages&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;OpenSSL&lt;/code&gt; (&lt;em&gt;Example on Ubuntu:&lt;/em&gt; &lt;code&gt;sudo apt install libssl-dev&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;b&gt;&lt;em&gt;Linux only:&lt;/em&gt;&lt;/b&gt; &lt;code&gt;pkg-config&lt;/code&gt; (&lt;em&gt;Example on Ubuntu:&lt;/em&gt; &lt;code&gt;sudo apt install pkg-config&lt;/code&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install Rust: &lt;a href=&#34;https://rustup.rs/&#34;&gt;https://rustup.rs/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;Example on Ubuntu:&lt;/em&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh&#xA;source $HOME/.cargo/env&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;em&gt;Optional:&lt;/em&gt;&lt;/b&gt; Set HF token correctly (skip if already set or your model is not gated, or if you want to use the &lt;code&gt;token_source&lt;/code&gt; parameters in Python or the command line.)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Note: you can install &lt;code&gt;huggingface-cli&lt;/code&gt; as documented &lt;a href=&#34;https://huggingface.co/docs/huggingface_hub/en/installation&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Download the code&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/EricLBuehler/mistral.rs.git&#xA;cd mistral.rs&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build or install&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Base build command&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo build --release&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Build with CUDA support&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo build --release --features cuda&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Build with CUDA and Flash Attention V2 support&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo build --release --features &#34;cuda flash-attn&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Build with Metal support&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo build --release --features metal&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Build with Accelerate support&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo build --release --features accelerate&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Build with MKL support&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo build --release --features mkl&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Install with &lt;code&gt;cargo install&lt;/code&gt; for easy command line usage&lt;/p&gt; &lt;p&gt;Pass the same values to &lt;code&gt;--features&lt;/code&gt; as you would for &lt;code&gt;cargo build&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo install --path mistralrs-server --features cuda&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The build process will output a binary &lt;code&gt;misralrs-server&lt;/code&gt; at &lt;code&gt;./target/release/mistralrs-server&lt;/code&gt; which may be copied into the working directory with the following command:&lt;/p&gt; &lt;p&gt;&lt;em&gt;Example on Ubuntu:&lt;/em&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;cp ./target/release/mistralrs-server ./mistralrs_server&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Use our APIs and integrations&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/#apis-and-integrations&#34;&gt;APIs and integrations list&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Getting models&lt;/h2&gt; &#xA;&lt;p&gt;There are 2 ways to run a model with mistral.rs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;From Hugging Face Hub (easiest)&lt;/li&gt; &#xA; &lt;li&gt;From local files &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Running a GGUF model fully locally&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Getting models from Hugging Face Hub&lt;/h3&gt; &#xA;&lt;p&gt;Mistral.rs can automatically download models from HF Hub. To access gated models, you should provide a token source. They may be one of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;literal:&amp;lt;value&amp;gt;&lt;/code&gt;: Load from a specified literal&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;env:&amp;lt;value&amp;gt;&lt;/code&gt;: Load from a specified environment variable&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;path:&amp;lt;value&amp;gt;&lt;/code&gt;: Load from a specified file&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cache&lt;/code&gt;: &lt;strong&gt;default&lt;/strong&gt;: Load from the HF token at ~/.cache/huggingface/token or equivalent.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;none&lt;/code&gt;: Use no HF token&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This is passed in the following ways:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Command line:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server --token-source none -i plain -m microsoft/Phi-3-mini-128k-instruct -a phi3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/examples/python/token_source.py&#34;&gt;Here&lt;/a&gt; is an example of setting the token source.&lt;/p&gt; &#xA;&lt;p&gt;If token cannot be loaded, no token will be used (i.e. effectively using &lt;code&gt;none&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;Loading models from local files:&lt;/h3&gt; &#xA;&lt;p&gt;You can also instruct mistral.rs to load models fully locally by modifying the &lt;code&gt;*_model_id&lt;/code&gt; arguments or options:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server --port 1234 plain -m . -a mistral&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Throughout mistral.rs, any model ID argument or option may be a local path and should contain the following files for each model ID option:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--model-id&lt;/code&gt; (server) or &lt;code&gt;model_id&lt;/code&gt; (python/rust) or &lt;code&gt;--tok-model-id&lt;/code&gt; (server) or &lt;code&gt;tok_model_id&lt;/code&gt; (python/rust): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;config.json&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;tokenizer_config.json&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;tokenizer.json&lt;/code&gt; (if not specified separately)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;.safetensors&lt;/code&gt; files.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;preprocessor_config.json&lt;/code&gt; (required for vision models).&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;processor_config.json&lt;/code&gt; (optional for vision models).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--quantized-model-id&lt;/code&gt; (server) or &lt;code&gt;quantized_model_id&lt;/code&gt; (python/rust): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Specified &lt;code&gt;.gguf&lt;/code&gt; or &lt;code&gt;.ggml&lt;/code&gt; file.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--x-lora-model-id&lt;/code&gt; (server) or &lt;code&gt;xlora_model_id&lt;/code&gt; (python/rust): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;xlora_classifier.safetensors&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;xlora_config.json&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Adapters &lt;code&gt;.safetensors&lt;/code&gt; and &lt;code&gt;adapter_config.json&lt;/code&gt; files in their respective directories&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--adapters-model-id&lt;/code&gt; (server) or &lt;code&gt;adapters_model_id&lt;/code&gt; (python/rust): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Adapters &lt;code&gt;.safetensors&lt;/code&gt; and &lt;code&gt;adapter_config.json&lt;/code&gt; files in their respective directories&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Running GGUF models locally&lt;/h3&gt; &#xA;&lt;p&gt;To run GGUF models fully locally, the only mandatory arguments are the quantized model ID and the quantized filename.&lt;/p&gt; &#xA;&lt;h4&gt;Chat template&lt;/h4&gt; &#xA;&lt;p&gt;The chat template can be automatically detected and loaded from the GGUF file if no other chat template source is specified including the tokenizer model ID.&lt;/p&gt; &#xA;&lt;p&gt;you do not need to specify the tokenizer model ID argument and instead should pass a path to the chat template JSON file (examples &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/chat_templates&#34;&gt;here&lt;/a&gt;, you will need to create your own by specifying the chat template and &lt;code&gt;bos&lt;/code&gt;/&lt;code&gt;eos&lt;/code&gt; tokens) as well as specifying a local model ID. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs-server --chat-template &amp;lt;chat_template&amp;gt; gguf -m . -f Phi-3-mini-128k-instruct-q4_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you do not specify a chat template, then the &lt;code&gt;--tok-model-id&lt;/code&gt;/&lt;code&gt;-t&lt;/code&gt; tokenizer model ID argument is expected where the &lt;code&gt;tokenizer_config.json&lt;/code&gt; file should be provided. If that model ID contains a &lt;code&gt;tokenizer.json&lt;/code&gt;, then that will be used over the GGUF tokenizer.&lt;/p&gt; &#xA;&lt;h4&gt;Tokenizer&lt;/h4&gt; &#xA;&lt;p&gt;The following tokenizer model types are currently supported. If you would like one to be added, please raise an issue. Otherwise, please consider using the method demonstrated in examples below, where the tokenizer is sourced from Hugging Face.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Supported GGUF tokenizer types&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;llama&lt;/code&gt; (sentencepiece)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;gpt2&lt;/code&gt; (BPE)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Run with the CLI&lt;/h2&gt; &#xA;&lt;p&gt;Mistral.rs uses subcommands to control the model type. They are generally of format &lt;code&gt;&amp;lt;XLORA/LORA&amp;gt;-&amp;lt;QUANTIZATION&amp;gt;&lt;/code&gt;. Please run &lt;code&gt;./mistralrs_server --help&lt;/code&gt; to see the subcommands.&lt;/p&gt; &#xA;&lt;p&gt;Additionally, for models without quantization, the model architecture should be provided as the &lt;code&gt;--arch&lt;/code&gt; or &lt;code&gt;-a&lt;/code&gt; argument in contrast to GGUF models which encode the architecture in the file.&lt;/p&gt; &#xA;&lt;h3&gt;Architecture for plain models&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: for plain models, you can specify the data type to load and run in. This must be one of &lt;code&gt;f32&lt;/code&gt;, &lt;code&gt;f16&lt;/code&gt;, &lt;code&gt;bf16&lt;/code&gt; or &lt;code&gt;auto&lt;/code&gt; to choose based on the device. This is specified in the &lt;code&gt;--dype&lt;/code&gt;/&lt;code&gt;-d&lt;/code&gt; parameter after the model architecture (&lt;code&gt;plain&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;mistral&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;gemma&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;mixtral&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;llama&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;phi2&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;phi3&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;qwen2&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;gemma2&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Architecture for vision models&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: for vision models, you can specify the data type to load and run in. This must be one of &lt;code&gt;f32&lt;/code&gt;, &lt;code&gt;f16&lt;/code&gt;, &lt;code&gt;bf16&lt;/code&gt; or &lt;code&gt;auto&lt;/code&gt; to choose based on the device. This is specified in the &lt;code&gt;--dype&lt;/code&gt;/&lt;code&gt;-d&lt;/code&gt; parameter after the model architecture (&lt;code&gt;vision-plain&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;phi3v&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;idefics2&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Interactive mode:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can launch interactive mode, a simple chat application running in the terminal, by passing &lt;code&gt;-i&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server -i plain -m microsoft/Phi-3-mini-128k-instruct -a phi3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Interactive mode for vision models:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can launch interactive mode for vision models, a simple chat application running in the terminal, by passing &lt;code&gt;-i&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server --vi plain -m microsoft/Phi-3-vision-128k-instruct -a phi3v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;More quick examples:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;X-LoRA with no quantization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To start an X-LoRA server with the exactly as presented in &lt;a href=&#34;https://arxiv.org/abs/2402.07148&#34;&gt;the paper&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server --port 1234 x-lora-plain -o orderings/xlora-paper-ordering.json -x lamm-mit/x-lora&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LoRA with a model from GGUF&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To start an LoRA server with adapters from the X-LoRA paper (you should modify the ordering file to use only one adapter, as the adapter static scalings are all 1 and so the signal will become distorted):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server --port 1234 lora-gguf -o orderings/xlora-paper-ordering.json -m TheBloke/zephyr-7B-beta-GGUF -f zephyr-7b-beta.Q8_0.gguf -a lamm-mit/x-lora&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Normally with a LoRA model you would use a custom ordering file. However, for this example we use the ordering from the X-LoRA paper because we are using the adapters from the X-LoRA paper.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;With a model from GGUF&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To start a server running Mistral from GGUF:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server --port 1234 gguf -t mistralai/Mistral-7B-Instruct-v0.1 -m TheBloke/Mistral-7B-Instruct-v0.1-GGUF -f mistral-7b-instruct-v0.1.Q4_K_M.gguf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;With a model from GGML&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To start a server running Llama from GGML:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server --port 1234 ggml -t meta-llama/Llama-2-13b-chat-hf -m TheBloke/Llama-2-13B-chat-GGML -f llama-2-13b-chat.ggmlv3.q4_K_M.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Plain model from safetensors&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To start a server running Mistral from safetensors.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server --port 1234 plain -m mistralai/Mistral-7B-Instruct-v0.1 -a mistral&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Structured selection with a &lt;code&gt;.toml&lt;/code&gt; file&lt;/h3&gt; &#xA;&lt;p&gt;We provide a method to select models with a &lt;code&gt;.toml&lt;/code&gt; file. The keys are the same as the command line, with &lt;code&gt;no_kv_cache&lt;/code&gt; and &lt;code&gt;tokenizer_json&lt;/code&gt; being &#34;global&#34; keys.&lt;/p&gt; &#xA;&lt;p&gt;Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mistralrs_server --port 1234 toml -f toml-selectors/gguf.toml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Supported models&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Quantization support&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;GGUF&lt;/th&gt; &#xA;   &lt;th&gt;GGML&lt;/th&gt; &#xA;   &lt;th&gt;ISQ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral 7B&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemma&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mixtral 8x7B&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi 2&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi 3&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen 2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi 3 Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Idefics 2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Device mapping support&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model category&lt;/th&gt; &#xA;   &lt;th&gt;Supported&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Plain&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GGUF&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GGML&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vision Plain&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;X-LoRA and LoRA support&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;X-LoRA&lt;/th&gt; &#xA;   &lt;th&gt;X-LoRA+GGUF&lt;/th&gt; &#xA;   &lt;th&gt;X-LoRA+GGML&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral 7B&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemma&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mixtral 8x7B&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi 2&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi 3&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen 2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi 3 Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Idefics 2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Using derivative model&lt;/h3&gt; &#xA;&lt;p&gt;To use a derivative model, select the model architecture using the correct subcommand. To see what can be passed for the architecture, pass &lt;code&gt;--help&lt;/code&gt; after the subcommand. For example, when using a different model than the default, specify the following for the following types of models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Plain&lt;/strong&gt;: Model id&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Quantized&lt;/strong&gt;: Quantized model id, quantized filename, and tokenizer id&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;X-LoRA&lt;/strong&gt;: Model id, X-LoRA ordering&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;X-LoRA quantized&lt;/strong&gt;: Quantized model id, quantized filename, tokenizer id, and X-LoRA ordering&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LoRA&lt;/strong&gt;: Model id, LoRA ordering&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LoRA quantized&lt;/strong&gt;: Quantized model id, quantized filename, tokenizer id, and LoRA ordering&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vision Plain&lt;/strong&gt;: Model id&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/#adapter-ordering-file&#34;&gt;this&lt;/a&gt; section to determine if it is necessary to prepare an X-LoRA/LoRA ordering file, it is always necessary if the target modules or architecture changed, or if the adapter order changed.&lt;/p&gt; &#xA;&lt;p&gt;It is also important to check the chat template style of the model. If the HF hub repo has a &lt;code&gt;tokenizer_config.json&lt;/code&gt; file, it is not necessary to specify. Otherwise, templates can be found in &lt;code&gt;chat_templates&lt;/code&gt; and should be passed before the subcommand. If the model is not instruction tuned, no chat template will be found and the APIs will only accept a prompt, no messages.&lt;/p&gt; &#xA;&lt;p&gt;For example, when using a Zephyr model:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./mistralrs_server --port 1234 --log output.txt gguf -t HuggingFaceH4/zephyr-7b-beta -m TheBloke/zephyr-7B-beta-GGUF -f zephyr-7b-beta.Q5_0.gguf&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Adapter model support: X-LoRA and LoRA&lt;/h3&gt; &#xA;&lt;p&gt;An adapter model is a model with X-LoRA or LoRA. X-LoRA support is provided by selecting the &lt;code&gt;x-lora-*&lt;/code&gt; architecture, and LoRA support by selecting the &lt;code&gt;lora-*&lt;/code&gt; architecture. Please find docs for adapter models &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/docs/ADAPTER_MODELS.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Chat Templates and Tokenizer&lt;/h3&gt; &#xA;&lt;p&gt;Mistral.rs will attempt to automatically load a chat template and tokenizer. This enables high flexibility across models and ensures accurate and flexible chat templating. However, this behavior can be customized. Please find detailed documentation &lt;a href=&#34;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/docs/CHAT_TOK.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Thank you for contributing! If you have any problems or want to contribute something, please raise an issue or pull request. If you want to add a new model, please contact us via an issue and we can coordinate how to do this.&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Debugging with the environment variable &lt;code&gt;MISTRALRS_DEBUG=1&lt;/code&gt; causes the following things &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;If loading a GGUF or GGML model, this will output a file containing the names, shapes, and types of each tensor. &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;code&gt;mistralrs_gguf_tensors.txt&lt;/code&gt; or &lt;code&gt;mistralrs_ggml_tensors.txt&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;More logging.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Setting the CUDA compiler path: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Set the &lt;code&gt;NVCC_CCBIN&lt;/code&gt; environment variable during build.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Error: &lt;code&gt;recompile with -fPIE&lt;/code&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Some Linux distributions require compiling with &lt;code&gt;-fPIE&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Set the &lt;code&gt;CUDA_NVCC_FLAGS&lt;/code&gt; environment variable to &lt;code&gt;-fPIE&lt;/code&gt; during build: &lt;code&gt;CUDA_NVCC_FLAGS=-fPIE&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Error &lt;code&gt;CUDA_ERROR_NOT_FOUND&lt;/code&gt; or symbol not found when using a normal or vison model: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;For non-quantized models, you can specify the data type to load and run in. This must be one of &lt;code&gt;f32&lt;/code&gt;, &lt;code&gt;f16&lt;/code&gt;, &lt;code&gt;bf16&lt;/code&gt; or &lt;code&gt;auto&lt;/code&gt; to choose based on the device.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;This project would not be possible without the excellent work at &lt;a href=&#34;https://github.com/huggingface/candle&#34;&gt;&lt;code&gt;candle&lt;/code&gt;&lt;/a&gt;. Additionally, thank you to all contributors! Contributing can range from raising an issue or suggesting a feature to adding some new functionality.&lt;/p&gt;</summary>
  </entry>
</feed>