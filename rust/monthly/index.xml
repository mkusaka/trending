<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Rust Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-01-01T01:55:43Z</updated>
  <subtitle>Monthly Trending of Rust in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>0xPlaygrounds/rig</title>
    <updated>2025-01-01T01:55:43Z</updated>
    <id>tag:github.com,2025-01-01:/0xPlaygrounds/rig</id>
    <link href="https://github.com/0xPlaygrounds/rig" rel="alternate"></link>
    <summary type="html">&lt;p&gt;‚öôÔ∏èü¶Ä Build portable, modular &amp; lightweight Fullstack Agents&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;img/rig-playgrounds-dark.svg&#34;&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;img/rig-playgrounds-light.svg&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/0xPlaygrounds/rig/main/img/rig-playgrounds-light.svg?sanitize=true&#34; style=&#34;width: 40%; height: 40%;&#34; alt=&#34;Rig logo&#34;&gt; &#xA; &lt;/picture&gt; &lt;br&gt; &lt;a href=&#34;https://docs.rig.rs&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%93%96%20docs-rig.rs-dca282.svg?sanitize=true&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://docs.rs/rig-core/latest/rig/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-API%20Reference-dca282.svg?sanitize=true&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://crates.io/crates/rig-core&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/v/rig-core.svg?color=dca282&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://crates.io/crates/rig-core&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/d/rig-core.svg?color=dca282&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://discord.gg/playgrounds&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/511303648119226382?color=%236d82cc&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://github.com/0xPlaygrounds/rig&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/0xPlaygrounds/rig?style=social&#34; alt=&#34;stars - rig&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/built_with-Rust-dca282.svg?logo=rust&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://twitter.com/Playgrounds0x&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/Playgrounds0x&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;br&gt; &lt;/p&gt; &amp;nbsp; &#xA;&lt;p&gt;‚ú® If you would like to help spread the word about Rig, please consider starring the repo!&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING] Here be dragons! As we plan to ship a torrent of features in the following months, future updates &lt;strong&gt;will&lt;/strong&gt; contain &lt;strong&gt;breaking changes&lt;/strong&gt;. With Rig evolving, we&#39;ll annotate changes and highlight migration paths as we encounter them.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;What is Rig?&lt;/h2&gt; &#xA;&lt;p&gt;Rig is a Rust library for building scalable, modular, and ergonomic &lt;strong&gt;LLM-powered&lt;/strong&gt; applications.&lt;/p&gt; &#xA;&lt;p&gt;More information about this crate can be found in the &lt;a href=&#34;https://docs.rig.rs&#34;&gt;official&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://docs.rs/rig-core/latest/rig/&#34;&gt;crate&lt;/a&gt; (API Reference) documentations.&lt;/p&gt; &#xA;&lt;p&gt;Help us improve Rig by contributing to our &lt;a href=&#34;https://bit.ly/Rig-Feeback-Form&#34;&gt;Feedback form&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#what-is-rig&#34;&gt;What is Rig?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#table-of-contents&#34;&gt;Table of contents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#high-level-features&#34;&gt;High-level features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#get-started&#34;&gt;Get Started&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#simple-example&#34;&gt;Simple example:&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#integrations&#34;&gt;Integrations&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;High-level features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Full support for LLM completion and embedding workflows&lt;/li&gt; &#xA; &lt;li&gt;Simple but powerful common abstractions over LLM providers (e.g. OpenAI, Cohere) and vector stores (e.g. MongoDB, in-memory)&lt;/li&gt; &#xA; &lt;li&gt;Integrate LLMs in your app with minimal boilerplate&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo add rig-core&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Simple example:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use rig::{completion::Prompt, providers::openai};&#xA;&#xA;#[tokio::main]&#xA;async fn main() {&#xA;    // Create OpenAI client and model&#xA;    // This requires the `OPENAI_API_KEY` environment variable to be set.&#xA;    let openai_client = openai::Client::from_env();&#xA;&#xA;    let gpt4 = openai_client.agent(&#34;gpt-4&#34;).build();&#xA;&#xA;    // Prompt the model and print its response&#xA;    let response = gpt4&#xA;        .prompt(&#34;Who are you?&#34;)&#xA;        .await&#xA;        .expect(&#34;Failed to prompt GPT-4&#34;);&#xA;&#xA;    println!(&#34;GPT-4: {response}&#34;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note using &lt;code&gt;#[tokio::main]&lt;/code&gt; requires you enable tokio&#39;s &lt;code&gt;macros&lt;/code&gt; and &lt;code&gt;rt-multi-thread&lt;/code&gt; features or just &lt;code&gt;full&lt;/code&gt; to enable all features (&lt;code&gt;cargo add tokio --features macros,rt-multi-thread&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;You can find more examples each crate&#39;s &lt;code&gt;examples&lt;/code&gt; (ie. &lt;a href=&#34;https://raw.githubusercontent.com/0xPlaygrounds/rig/main/rig-core/examples&#34;&gt;&lt;code&gt;rig-core/examples&lt;/code&gt;&lt;/a&gt;) directory. More detailed use cases walkthroughs are regularly published on our &lt;a href=&#34;https://dev.to/0thtachi&#34;&gt;Dev.to Blog&lt;/a&gt; and added to Rig&#39;s official documentation &lt;a href=&#34;http://docs.rig.rs&#34;&gt;(docs.rig.rs)&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Integrations&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Model Providers&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Vector Stores&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;br&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/1024px-ChatGPT_logo.svg.png&#34; alt=&#34;ChatGPT logo&#34; width=&#34;50em&#34;&gt; &#xA;    &lt;picture&gt;&#xA;     &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://www.fahimai.com/wp-content/uploads/2024/06/Untitled-design-7.png&#34;&gt;&#xA;     &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Claude_Ai.svg/1024px-Claude_Ai.svg.png&#34;&gt;&#xA;     &lt;img src=&#34;https://www.fahimai.com/wp-content/uploads/2024/06/Untitled-design-7.png&#34; alt=&#34;Claude Anthropic logo&#34; width=&#34;50em&#34;&gt;&#xA;    &lt;/picture&gt; &lt;br&gt; &lt;img src=&#34;https://cdn.sanity.io/images/rjtqmwfu/production/0adbf394439f4cd0ab8b5b3b6fe1da10c8099024-201x200.svg?sanitize=true&#34; alt=&#34;Cohere logo&#34; width=&#34;50em&#34;&gt; &lt;img src=&#34;https://logospng.org/download/google-gemini/google-gemini-1024.png&#34; style=&#34;background-color: white; border-radius: 10px; padding: 5px 5px ; width: 3em;&#34; alt=&#34;Gemini logo&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/XAI-Logo.svg/512px-XAI-Logo.svg.png?20240912222841&#34; style=&#34;background-color: white; border-radius: 10px; padding: 5px 5px ; width: 3em;&#34; alt=&#34;xAI logo&#34;&gt; &lt;img src=&#34;https://github.com/user-attachments/assets/4763ae96-ddc9-4f69-ab38-23592e6c4ead&#34; style=&#34;background-color: white; border-radius: 10px; padding: 5px 0px ; width: 4em;&#34; alt=&#34;perplexity logo&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;br&gt;&lt;img src=&#34;https://cdn.prod.website-files.com/6640cd28f51f13175e577c05/664e00a400e23f104ed2b6cd_3b3dd6e8-8a73-5879-84a9-a42d5b910c74.svg?sanitize=true&#34; alt=&#34;Mongo DB logo&#34; width=&#34;50em&#34;&gt; &lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/e/e5/Neo4j-logo_color.png&#34; alt=&#34;Neo4j logo&#34; style=&#34;background-color: white; border-radius: 1em; padding: 1em 1em ; width: 4em;&#34;&gt;&lt;br&gt;&lt;br&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/844/1*Jp6VwF0OcdeyRyW0Ln0RMQ@2x.png&#34; width=&#34;100em&#34; alt=&#34;Lance DB logo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Vector stores are available as separate companion-crates:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MongoDB vector store: &lt;a href=&#34;https://github.com/0xPlaygrounds/rig/tree/main/rig-mongodb&#34;&gt;&lt;code&gt;rig-mongodb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;LanceDB vector store: &lt;a href=&#34;https://github.com/0xPlaygrounds/rig/tree/main/rig-lancedb&#34;&gt;&lt;code&gt;rig-lancedb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Neo4j vector store: &lt;a href=&#34;https://github.com/0xPlaygrounds/rig/tree/main/rig-neo4j&#34;&gt;&lt;code&gt;rig-neo4j&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Qdrant vector store: &lt;a href=&#34;https://github.com/0xPlaygrounds/rig/tree/main/rig-qdrant&#34;&gt;&lt;code&gt;rig-qdrant&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/0xPlaygrounds/rig/main/img/built-by-playgrounds.svg?sanitize=true&#34; alt=&#34;Build by Playgrounds&#34; width=&#34;30%&#34;&gt; &lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>tensorzero/tensorzero</title>
    <updated>2025-01-01T01:55:43Z</updated>
    <id>tag:github.com,2025-01-01:/tensorzero/tensorzero</id>
    <link href="https://github.com/tensorzero/tensorzero" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9&#34; width=&#34;128&#34; height=&#34;128&#34;&gt; &#xA;&lt;h1&gt;TensorZero&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Integrate our model gateway&lt;/li&gt; &#xA; &lt;li&gt;Send metrics or feedback&lt;/li&gt; &#xA; &lt;li&gt;Optimize prompts, models, and inference strategies&lt;/li&gt; &#xA; &lt;li&gt;Watch your LLMs improve over time&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;It provides a &lt;strong&gt;data &amp;amp; learning flywheel for LLMs&lt;/strong&gt; by unifying:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Inference:&lt;/strong&gt; one API for all LLMs, with &amp;lt;1ms P99 overhead&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Observability:&lt;/strong&gt; inference &amp;amp; feedback ‚Üí your database&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Optimization:&lt;/strong&gt; from prompts to fine-tuning and RL (&amp;amp; even üçì? &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations&#34;&gt;‚Üí&lt;/a&gt;&lt;/strong&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Experimentation:&lt;/strong&gt; built-in A/B testing, routing, fallbacks&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/&#34; target=&#34;_blank&#34;&gt;Website&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs&#34; target=&#34;_blank&#34;&gt;Docs&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.x.com/tensorzero&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/slack&#34; target=&#34;_blank&#34;&gt;Slack&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/discord&#34; target=&#34;_blank&#34;&gt;Discord&lt;/a&gt;&lt;/b&gt; &lt;br&gt; &lt;br&gt; &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/quickstart&#34; target=&#34;_blank&#34;&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/tutorial&#34; target=&#34;_blank&#34;&gt;Comprehensive Tutorial&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/deployment&#34; target=&#34;_blank&#34;&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/api-reference&#34; target=&#34;_blank&#34;&gt;API Reference&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/deployment&#34; target=&#34;_blank&#34;&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Watch LLMs get better at data extraction in real time with TensorZero!&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl&#34;&gt;Dynamic in-context learning (DICL)&lt;/a&gt;&lt;/strong&gt; is a powerful inference-time optimization available out of the box with TensorZero. It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb&#34;&gt;https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.tensorzero.com/docs&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270&#34;&gt; &#xA;   &lt;img alt=&#34;TensorZero Flywheel&#34; src=&#34;https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6&#34; width=&#34;720&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/&#34;&gt;TensorZero Gateway&lt;/a&gt;&lt;/strong&gt; is a high-performance model gateway written in Rust ü¶Ä that provides a unified API interface for all major LLM providers, allowing for seamless cross-platform integration and fallbacks.&lt;/li&gt; &#xA; &lt;li&gt;It handles structured schema-based inference with &amp;lt;1ms P99 latency overhead (see &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/benchmarks&#34;&gt;Benchmarks&lt;/a&gt;&lt;/strong&gt;) and built-in observability, experimentation, and &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations&#34;&gt;inference-time optimizations&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;It also collects downstream metrics and feedback associated with these inferences, with first-class support for multi-step LLM systems.&lt;/li&gt; &#xA; &lt;li&gt;Everything is stored in a ClickHouse data warehouse that you control for real-time, scalable, and developer-friendly analytics.&lt;/li&gt; &#xA; &lt;li&gt;Over time, &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/recipes&#34;&gt;TensorZero Recipes&lt;/a&gt;&lt;/strong&gt; leverage this structured dataset to optimize your prompts and models: run pre-built recipes for common workflows like fine-tuning, or create your own with complete flexibility using any language and platform.&lt;/li&gt; &#xA; &lt;li&gt;Finally, the gateway&#39;s experimentation features and GitOps orchestration enable you to iterate and deploy with confidence, be it a single LLM or thousands of LLMs.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Our goal is to help engineers build, manage, and optimize the next generation of LLM applications: systems that learn from real-world experience. Read more about our &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/vision-roadmap/&#34;&gt;Vision &amp;amp; Roadmap&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Start building today.&lt;/strong&gt; The &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; shows it&#39;s easy to set up an LLM application with TensorZero. If you want to dive deeper, the &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/tutorial&#34;&gt;Tutorial&lt;/a&gt;&lt;/strong&gt; teaches how to build a simple chatbot, an email copilot, a weather RAG system, and a structured data extraction pipeline.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Questions?&lt;/strong&gt; Ask us on &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/slack&#34;&gt;Slack&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/discord&#34;&gt;Discord&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Using TensorZero at work?&lt;/strong&gt; Email us at &lt;strong&gt;&lt;a href=&#34;mailto:hello@tensorzero.com&#34;&gt;hello@tensorzero.com&lt;/a&gt;&lt;/strong&gt; to set up a Slack or Teams channel with your team (free).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Work with us.&lt;/strong&gt; We&#39;re &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/jobs&#34;&gt;hiring in NYC&lt;/a&gt;&lt;/strong&gt;. We&#39;d also welcome &lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/raw/main/CONTRIBUTING.md&#34;&gt;open-source contributions&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;We are working on a series of &lt;strong&gt;complete runnable examples&lt;/strong&gt; illustrating TensorZero&#39;s data &amp;amp; learning flywheel.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences&#34;&gt;Writing Haikus to Satisfy a Judge with Hidden Preferences&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste. You&#39;ll see TensorZero&#39;s &#34;data flywheel in a box&#34; in action: better variants leads to better data, and better data leads to better variants. You&#39;ll see progress by fine-tuning the LLM multiple times.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/ner-fine-tuning&#34;&gt;Improving Data Extraction (NER) by Fine-Tuning a Llama 3 Model&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example shows that an optimized Llama 3.1 8B model can be trained to outperform GPT-4o on a Named Entity Recognition (NER) task using a small amount of training data, and served by Fireworks at a fraction of the cost and latency.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles-best-of-n-sampling/&#34;&gt;Improving LLM Chess Ability with Best-of-N Sampling&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example showcases how best-of-N sampling can significantly enhance an LLM&#39;s chess-playing abilities by selecting the most promising moves from multiple generated options.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/ner-dicl&#34;&gt;Improving Data Extraction (NER) with Dynamic In-Context Learning&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example demonstrates how Dynamic In-Context Learning (DICL) can enhance Named Entity Recognition (NER) performance by leveraging relevant historical examples to improve data extraction accuracy and consistency without having to fine-tune a model.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy&#34;&gt;Improving Math Reasoning with a Custom Recipe for Automated Prompt Engineering (DSPy)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;TensorZero provides a number of pre-built optimization recipes covering common LLM engineering workflows. But you can also easily create your own recipes and workflows! This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;em&gt;&amp;amp; many more on the way!&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>nexus-xyz/nexus-zkvm</title>
    <updated>2025-01-01T01:55:43Z</updated>
    <id>tag:github.com,2025-01-01:/nexus-xyz/nexus-zkvm</id>
    <link href="https://github.com/nexus-xyz/nexus-zkvm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Nexus zkVM: The zero-knowledge virtual machine&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Nexus zkVM&lt;/h1&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;a href=&#34;https://t.me/nexus_zkvm&#34;&gt; &lt;img src=&#34;https://img.shields.io/endpoint?color=neon&amp;amp;logo=telegram&amp;amp;label=chat&amp;amp;url=https%3A%2F%2Fmogyo.ro%2Fquart-apis%2Ftgmembercount%3Fchat_id%3Dnexus_zkvm&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/nexus-xyz/nexus-zkvm/graphs/contributors&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/contributors/nexus-xyz/nexus-zkvm.svg?sanitize=true&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://twitter.com/NexusLabsHQ&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Twitter-black?logo=x&amp;amp;logoColor=white&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://nexus.xyz&#34;&gt; &lt;img src=&#34;https://img.shields.io/static/v1?label=Stage&amp;amp;message=Alpha&amp;amp;color=2BB4AB&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/nexus-xyz/nexus-zkvm/raw/main/LICENSE-MIT&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/nexus-xyz/nexus-zkvm/raw/main/LICENSE-APACHE&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/license-APACHE-blue&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;100%&#34; src=&#34;https://raw.githubusercontent.com/nexus-xyz/nexus-zkvm/main/assets/nexus_docs-header.png&#34; alt=&#34;Logo&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Nexus zkVM is a modular, extensible, open-source, and highly-parallelized zkVM, designed to run at &lt;em&gt;a trillion CPU cycles proved per second&lt;/em&gt; given enough machine power.&lt;/p&gt; &#xA;&lt;h2&gt;Folding schemes&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;re interested in our implementation of folding schemes, check the &lt;a href=&#34;https://raw.githubusercontent.com/nexus-xyz/nexus-zkvm/main/nova/&#34;&gt;&lt;code&gt;nexus-nova&lt;/code&gt;&lt;/a&gt; crate.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;1. Install the Nexus zkVM&lt;/h3&gt; &#xA;&lt;p&gt;First, install Rust: &lt;a href=&#34;https://www.rust-lang.org/tools/install&#34;&gt;https://www.rust-lang.org/tools/install&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Also, make sure you have a working version of &lt;a href=&#34;https://cmake.org/&#34;&gt;cmake&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note: cmake is a required dependency.&lt;/p&gt; &#xA;&lt;p&gt;Next, install the RISC-V target:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;rustup target add riscv32i-unknown-none-elf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, install the Nexus zkVM:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo install --git https://github.com/nexus-xyz/nexus-zkvm cargo-nexus --tag &#39;v0.2.4&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Verify the installation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo nexus --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This should print the available CLI commands.&lt;/p&gt; &#xA;&lt;h3&gt;2. Create a new Nexus project&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo nexus new nexus-project&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And change directory to the new project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd nexus-project&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will create a new Rust project directory with the following structure:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;./nexus-project&#xA;‚îú‚îÄ‚îÄ Cargo.lock&#xA;‚îú‚îÄ‚îÄ Cargo.toml&#xA;‚îî‚îÄ‚îÄ src&#xA;    ‚îî‚îÄ‚îÄ main.rs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As an example, you can change the content of &lt;code&gt;./src/main.rs&lt;/code&gt; to:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;#![cfg_attr(target_arch = &#34;riscv32&#34;, no_std, no_main)]&#xA; &#xA;use nexus_rt::write_log;&#xA; &#xA;#[nexus_rt::main]&#xA;fn main() {&#xA;    write_log(&#34;Hello, World!\n&#34;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Run your program&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo nexus run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see the program print:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#34;Hello, World!&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command should run successfully. To print the full step-by-step execution trace on the NVM, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cargo nexus run -v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;4. Prove your program&lt;/h3&gt; &#xA;&lt;p&gt;Generate a proof for your Rust program using the Nexus zkVM.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo nexus prove&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command will save the proof to &lt;code&gt;./nexus-proof&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;5. Verify your proof&lt;/h3&gt; &#xA;&lt;p&gt;Finally, load and verify the proof:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo nexus verify&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see the program print &#34;Verifying Proof...&#34; and finally &#34;Finished&#34; when complete.&lt;/p&gt; &#xA;&lt;h2&gt;Learn More&lt;/h2&gt; &#xA;&lt;p&gt;Run &lt;code&gt;cargo nexus --help&lt;/code&gt; to see all the available commands.&lt;/p&gt; &#xA;&lt;p&gt;Also check out the documentation at &lt;a href=&#34;https://docs.nexus.xyz&#34;&gt;docs.nexus.xyz&lt;/a&gt;, or join our &lt;a href=&#34;https://t.me/nexus_zkvm&#34;&gt;Telegram&lt;/a&gt; chat to discuss!&lt;/p&gt; &#xA;&lt;p&gt;Nexus is committed to open-source. All of our code is dual licensed under MIT and Apache licenses. We encourage and appreciate contributions.&lt;/p&gt;</summary>
  </entry>
</feed>