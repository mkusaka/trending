<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Kotlin Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-19T01:37:58Z</updated>
  <subtitle>Daily Trending of Kotlin in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>GetStream/webrtc-android</title>
    <updated>2023-02-19T01:37:58Z</updated>
    <id>tag:github.com,2023-02-19:/GetStream/webrtc-android</id>
    <link href="https://github.com/GetStream/webrtc-android" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üõ∞Ô∏è A WebRTC pre-compiled library for Android reflects the recent WebRTC updates to facilitate real-time video chat for Android and Compose.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/24237865/218683564-e4279cf9-51c2-4b48-9ca4-45a258a6898a.jpg&#34; alt=&#34;AndroidWebRTC-1200x630px&#34;&gt;&lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;WebRTC Android by Stream&lt;/h1&gt;&#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://android-arsenal.com/api?level=21&#34;&gt;&lt;img alt=&#34;API&#34; src=&#34;https://img.shields.io/badge/API-21%2B-brightgreen.svg?style=flat&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/GetStream/stream-webrtc-android/actions/workflows/android.yml&#34;&gt;&lt;img alt=&#34;Build Status&#34; src=&#34;https://github.com/GetStream/stream-webrtc-android/actions/workflows/android.yml/badge.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://getstream.io&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/HayesGordon/e7f3c4587859c17f3e593fd3ff5b13f4/raw/11d9d9385c9f34374ede25f6471dc743b977a914/badge.json&#34; alt=&#34;Stream Feeds&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;üõ∞Ô∏è &lt;strong&gt;WebRTC Android&lt;/strong&gt; is Google&#39;s WebRTC pre-compiled library for Android by &lt;a href=&#34;https://getstream.io?utm_source=Github&amp;amp;utm_medium=Github_Repo_Content_Ad&amp;amp;utm_content=Developer&amp;amp;utm_campaign=Github_Feb2023_Jaewoong_StreamWebRTCAndroid&amp;amp;utm_term=DevRelOss&#34;&gt;Stream&lt;/a&gt;. It reflects the recent &lt;a href=&#34;https://getstream.io/glossary/webrtc-protocol/&#34;&gt;WebRTC Protocol&lt;/a&gt; updates to facilitate real-time video chat using functional UI components, Kotlin extensions for Android, and Compose.&lt;/p&gt; &#xA;&lt;h2&gt;Agenda&lt;/h2&gt; &#xA;&lt;p&gt;Since Google no longer supported the &lt;a href=&#34;https://webrtc.github.io/webrtc-org/native-code/android/&#34;&gt;WebRTC library for Android&lt;/a&gt; for many years (even JCenter has been shut down, so the library is not available now), we decided to build our own pre-compiled WebRTC core library that reflects recent WebRTC commits with some improvements.&lt;/p&gt; &#xA;&lt;h2&gt;üì± Use Cases&lt;/h2&gt; &#xA;&lt;p&gt;You can see the use cases of this library in the repositories below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/GetStream/webrtc-in-jetpack-compose&#34;&gt;webrtc-in-jetpack-compose&lt;/a&gt;: üì± This project demonstrates WebRTC protocol to facilitate real-time video communications with Jetpack Compose.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚úçÔ∏è Technical Content&lt;/h2&gt; &#xA;&lt;p&gt;If you want to have a better grasp of how WebRTC works, such as basic concepts of WebRTC, relevant terminologies, and how to establish a peer-to-peer connection and communicate with the signaling server in Android, check out the articles below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://getstream.io/blog/webrtc-on-android/&#34;&gt;Building a Video Chat App: WebRTC on Android (Part1)&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://getstream.io/blog/communication-protocols/&#34;&gt;HTTP, WebSocket, gRPC or WebRTC: Which Communication Protocol is Best For Your App?&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://getstream.io/glossary/webrtc-protocol/&#34;&gt;WebRTC Protocol: What is it and how does it work?&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;a href=&#34;https://getstream.io/chat/sdk/compose?utm_source=Github&amp;amp;utm_medium=Github_Repo_Content_Ad&amp;amp;utm_content=Developer&amp;amp;utm_campaign=Github_Feb2023_Jaewoong_StreamWebRTCAndroid&amp;amp;utm_term=DevRelOss&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/24237865/138428440-b92e5fb7-89f8-41aa-96b1-71a5486c5849.png&#34; align=&#34;right&#34; width=&#34;12%&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;üõ• Stream Chat and Voice &amp;amp; Video calling SDK&lt;/h2&gt; &#xA;&lt;p&gt;If you‚Äôre interested in adding powerful In-App Messaging to your app, check out the &lt;strong&gt;&lt;a href=&#34;https://getstream.io/chat/sdk/compose?utm_source=Github&amp;amp;utm_medium=Github_Repo_Content_Ad&amp;amp;utm_content=Developer&amp;amp;utm_campaign=Github_Feb2023_Jaewoong_StreamWebRTCAndroid&amp;amp;utm_term=DevRelOss&#34;&gt;Compose Chat SDK for Messaging&lt;/a&gt;&lt;/strong&gt;! We&#39;re also planning to release voice &amp;amp; video calling SDK very soon! Check out the &lt;strong&gt;&lt;a href=&#34;https://getstream.io/video?utm_source=Github&amp;amp;utm_medium=Github_Repo_Content_Ad&amp;amp;utm_content=Developer&amp;amp;utm_campaign=Github_Feb2023_Jaewoong_StreamWebRTCAndroid&amp;amp;utm_term=DevRelOss&#34;&gt;Video &amp;amp; Voice Calling API on Stream&#39;s Global Edge Network&lt;/a&gt;&lt;/strong&gt;, if you want early access to our SDK.&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://search.maven.org/search?q=g:%22io.getstream%22%20AND%20a:%22stream-webrtc-android%22&#34;&gt;&lt;img src=&#34;https://img.shields.io/maven-central/v/io.getstream/stream-webrtc-android.svg?label=Maven%20Central&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Gradle&lt;/h3&gt; &#xA;&lt;p&gt;Add the below dependency to your &lt;strong&gt;module&lt;/strong&gt;&#39;s &lt;code&gt;build.gradle&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {&#xA;    implementation &#34;io.getstream:stream-webrtc-android:1.0.0&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;SNAPSHOT&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;See how to import the snapshot&lt;/summary&gt; &#xA; &lt;h3&gt;Including the SNAPSHOT&lt;/h3&gt; &#xA; &lt;p&gt;Snapshots of the current development version of AvatarView are available, which track &lt;a href=&#34;https://oss.sonatype.org/content/repositories/snapshots/io/getstream/stream-webrtc-android/&#34;&gt;the latest versions&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;To import snapshot versions on your project, add the code snippet below on your gradle file.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-Gradle&#34;&gt;repositories {&#xA;   maven { url &#39;https://oss.sonatype.org/content/repositories/snapshots/&#39; }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Next, add the below dependency to your &lt;strong&gt;module&lt;/strong&gt;&#39;s &lt;code&gt;build.gradle&lt;/code&gt; file.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {&#xA;    implementation &#34;io.getstream:stream-webrtc-android:1.0.1-SNAPSHOT&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Usages&lt;/h2&gt; &#xA;&lt;p&gt;Once you import this library, you can use all of the &lt;code&gt;org.webrtc&lt;/code&gt; packge functions, such as &lt;code&gt;org.webrtc.PeerConnection&lt;/code&gt; and &lt;code&gt;org.webrtc.VideoTrack&lt;/code&gt;. For more information, you can check out the &lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/&#34;&gt;API references for WebRTC packages&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Here are the most commonly used APIs in the WebRTC library, and you can reference the documentation below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-peer-connection/index.html?query=open%20class%20PeerConnection&#34;&gt;PeerConnection&lt;/a&gt;: Provides methods to create and set an SDP offer/answer, add ICE candidates, potentially connect to a remote peer, monitor the connection, and close the connection once it‚Äôs no longer needed.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-peer-connection-factory/index.html?query=open%20class%20PeerConnectionFactory&#34;&gt;PeerConnectionFactory&lt;/a&gt;: Create a &lt;code&gt;PeerConnection&lt;/code&gt; instance.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-egl-base/index.html?query=interface%20EglBase&#34;&gt;EglBase&lt;/a&gt;: Holds EGL state and utility methods for handling an egl 1.0 EGLContext, an EGLDisplay, and an EGLSurface.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-video-track/index.html?query=open%20class%20VideoTrack%20:%20MediaStreamTrack&#34;&gt;VideoTrack&lt;/a&gt;: Manages multiple &lt;code&gt;VideoSink&lt;/code&gt; objects, which receive a stream of video frames in real-time and it allows you to control the &lt;code&gt;VideoSink&lt;/code&gt; objects, such as adding, removing, enabling, and disabling.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-video-source/index.html?query=open%20class%20VideoSource%20:%20MediaSource&#34;&gt;VideoSource&lt;/a&gt;: Used to create video tracks and add VideoProcessor, which is a lightweight abstraction for an object that can receive video frames, process them, and pass them on to another object.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-audio-track/index.html&#34;&gt;AudioTrack&lt;/a&gt;: Manages multiple &lt;code&gt;AudioSink&lt;/code&gt; objects, which receive a stream of video frames in real-time and it allows you to control the &lt;code&gt;AudioSink&lt;/code&gt; objects, such as adding, removing, enabling, and disabling.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-audio-source/index.html?query=open%20class%20AudioSource%20:%20MediaSource&#34;&gt;AudioSource&lt;/a&gt;: Used to create audio tracks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-media-stream-track/index.html?query=open%20class%20MediaStreamTrack&#34;&gt;MediaStreamTrack&lt;/a&gt;: Java wrapper for a C++ &lt;code&gt;MediaStreamTrackInterface&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-ice-candidate/index.html?query=open%20class%20IceCandidate&#34;&gt;IceCandidate&lt;/a&gt;: Representation of a single ICE Candidate, mirroring &lt;code&gt;IceCandidateInterface&lt;/code&gt; in the C++ API.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-session-description/index.html?query=open%20class%20SessionDescription&#34;&gt;SessionDescription&lt;/a&gt;: Description of an RFC 4566 Session. SDPs are passed as serialized Strings in Java-land and are materialized to SessionDescriptionInterface as appropriate in the JNI layer.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-surface-view-renderer/index.html?query=open%20class%20SurfaceViewRenderer%20:%20SurfaceView,%20SurfaceHolder.Callback,%20VideoSink,%20RendererCommon.RendererEvents&#34;&gt;SurfaceViewRenderer&lt;/a&gt;: Display the video stream on a SurfaceView.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-camera2-capturer/index.html?query=open%20class%20Camera2Capturer%20:%20CameraCapturer&#34;&gt;Camera2Capturer&lt;/a&gt;: The &lt;code&gt;Camera2Capturer&lt;/code&gt; class is used to provide video frames for a &lt;code&gt;VideoTrack&lt;/code&gt; (typically local) from the provided cameraId. &lt;code&gt;Camera2Capturer&lt;/code&gt; must be run on devices &lt;code&gt;Build.VERSION_CODES.LOLLIPOP&lt;/code&gt; or higher.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-camera2-enumerator/index.html?query=open%20class%20Camera2Enumerator%20:%20CameraEnumerator&#34;&gt;Camera2Enumerator&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you want to learn more about building a video chat application for Android using WebRTC, check out the blog post below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://getstream.io/blog/webrtc-on-android/&#34;&gt;Building a Video Chat App: WebRTC on Android (Part1)&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;right&#34; width=&#34;15%&#34; src=&#34;https://user-images.githubusercontent.com/24237865/149445065-47c2506d-a738-4fb2-b4fb-eb6841b9e202.png&#34;&gt; &#xA;&lt;h2&gt;WebRTC for UI Components&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://search.maven.org/search?q=g:%22io.getstream%22%20AND%20a:%22stream-webrtc-android-ui%22&#34;&gt;&lt;img src=&#34;https://img.shields.io/maven-central/v/io.getstream/stream-webrtc-android-ui.svg?label=Maven%20Central&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stream WebRTC Android&lt;/strong&gt; supports some uesful UI components for WebRTC, such as &lt;code&gt;VideoTextureViewRenderer&lt;/code&gt;. First, add the dependency below to your &lt;strong&gt;module&#39;s&lt;/strong&gt; &lt;code&gt;build.gradle&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {&#xA;    implementation &#34;io.getstream:stream-webrtc-android-ui:$version&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;VideoTextureViewRenderer&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;VideoTextureViewRenderer&lt;/code&gt; is a custom &lt;a href=&#34;https://developer.android.com/reference/android/view/TextureView&#34;&gt;TextureView&lt;/a&gt; that implements &lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-video-sink/index.html?query=interface%20VideoSink&#34;&gt;VideoSink&lt;/a&gt; and &lt;a href=&#34;https://developer.android.com/reference/kotlin/android/view/TextureView.SurfaceTextureListener.html&#34;&gt;SurfaceTextureListener&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Usually, you can use &lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-surface-view-renderer/index.html?query=open%20class%20SurfaceViewRenderer%20:%20SurfaceView,%20SurfaceHolder.Callback,%20VideoSink,%20RendererCommon.RendererEvents&#34;&gt;SurfaceViewRenderer&lt;/a&gt; to display real-time video streams on a layout if you need a simple video call screen without overlaying video frames over another one. However, it might not work well as you expect if you suppose to need to design a complex video call screen, such as one video call layout should overlay another video call layout, such as the example below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/24237865/218671884-d027ef03-1ccc-4d12-8153-adc2964034cc.png&#34; alt=&#34;Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;For this case, we&#39;d recommend you use &lt;code&gt;VideoTextureViewRenderer&lt;/code&gt; like the example below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;io.getstream.webrtc.android.ui.VideoTextureViewRenderer&#xA;    android:id=&#34;@+id/participantVideoRenderer&#34;&#xA;    android:layout_width=&#34;match_parent&#34;&#xA;    android:layout_height=&#34;match_parent&#34;&#xA; /&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can add or remove &lt;a href=&#34;https://getstream.github.io/stream-webrtc-android/stream-webrtc-android/org.webrtc/-video-track/index.html?query=open%20class%20VideoTrack%20:%20MediaStreamTrack&#34;&gt;VideoTrack&lt;/a&gt; like the below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-kotlin&#34;&gt;videoTrack.video.addSink(participantVideoRenderer)&#xA;videoTrack.video.removeSink(participantVideoRenderer)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img align=&#34;right&#34; width=&#34;15%&#34; src=&#34;https://user-images.githubusercontent.com/24237865/149444862-961adb83-da2a-4179-9c27-37edb2f982f4.png&#34;&gt; &#xA;&lt;h2&gt;WebRTC for Jetpack Compose&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://search.maven.org/search?q=g:%22io.getstream%22%20AND%20a:%22stream-webrtc-android-compose%22&#34;&gt;&lt;img src=&#34;https://img.shields.io/maven-central/v/io.getstream/stream-webrtc-android-compose.svg?label=Maven%20Central&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stream WebRTC Android&lt;/strong&gt; supports some Jetpack Compose components for WebRTC, such as &lt;code&gt;VideoRenderer&lt;/code&gt; and &lt;code&gt;FloatingVideoRenderer&lt;/code&gt;. First, add the dependency below to your &lt;strong&gt;module&#39;s&lt;/strong&gt; &lt;code&gt;build.gradle&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {&#xA;    implementation &#34;io.getstream:stream-webrtc-android-compose:$version&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;VideoRenderer&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;VideoRenderer&lt;/code&gt; is a composable function that renders a single video track in Jetpack Compose.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-kotlin&#34;&gt;VideoRenderer(&#xA;    videoTrack = remoteVideoTrack,&#xA;    modifier = Modifier.fillMaxSize()&#xA;    eglBaseContext = eglBaseContext,&#xA;    rendererEvents = rendererEvents&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can observe the rendering state changes by giving &lt;code&gt;RendererEvents&lt;/code&gt; interface like the below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-kotlin&#34;&gt;val rendererEvents = object : RendererEvents {&#xA;      override fun onFirstFrameRendered() { .. }&#xA;      override fun onFrameResolutionChanged(videoWidth: Int, videoHeight: Int, rotation: Int) { .. }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;FloatingVideoRenderer&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;FloatingVideoRenderer&lt;/code&gt; represents a floating item that features a participant video, usually the local participant. You can use this composable function to overlay a single video track on another, and users can move the floating video track with user interactions.&lt;/p&gt; &#xA;&lt;p&gt;You can use &lt;code&gt;FloatingVideoRenderer&lt;/code&gt; with &lt;code&gt;VideoRenderer&lt;/code&gt; like the example below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-kotlin&#34;&gt;var parentSize: IntSize by remember { mutableStateOf(IntSize(0, 0)) }&#xA;&#xA;if (remoteVideoTrack != null) {&#xA;  VideoRenderer(&#xA;    videoTrack = remoteVideoTrack,&#xA;    modifier = Modifier&#xA;      .fillMaxSize()&#xA;      .onSizeChanged { parentSize = it },&#xA;    eglBaseContext = eglBaseContext,&#xA;    rendererEvents = rendererEvents&#xA;  )&#xA;}&#xA;&#xA;if (localVideoTrack != null) {&#xA;  FloatingVideoRenderer(&#xA;    modifier = Modifier&#xA;      .size(width = 150.dp, height = 210.dp)&#xA;      .clip(RoundedCornerShape(16.dp))&#xA;      .align(Alignment.TopEnd),&#xA;    videoTrack = localVideoTrack,&#xA;    parentBounds = parentSize,&#xA;    paddingValues = PaddingValues(0.dp),&#xA;    eglBaseContext = eglBaseContexteglBaseContext,&#xA;    rendererEvents = rendererEvents&#xA;  )&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img align=&#34;right&#34; width=&#34;90px&#34; src=&#34;https://user-images.githubusercontent.com/24237865/178630165-76855349-ac04-4474-8bcf-8eb5f8c41095.png&#34;&gt; &#xA;&lt;h2&gt;WebRTC KTX&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://search.maven.org/search?q=g:%22io.getstream%22%20AND%20a:%22stream-webrtc-android-ktx%22&#34;&gt;&lt;img src=&#34;https://img.shields.io/maven-central/v/io.getstream/stream-webrtc-android-ktx.svg?label=Maven%20Central&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stream WebRTC Android&lt;/strong&gt; supports some useful extensions for WebRTC based on &lt;a href=&#34;https://kotlinlang.org/docs/coroutines-overview.html&#34;&gt;Kotlin&#39;s Coroutines&lt;/a&gt;. First, add the dependency below to your &lt;strong&gt;module&#39;s&lt;/strong&gt; &lt;code&gt;build.gradle&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-gradle&#34;&gt;dependencies {&#xA;    implementation &#34;io.getstream:stream-webrtc-android-ktx:$version&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;addRtcIceCandidate&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;addRtcIceCandidate&lt;/code&gt; is a suspend function that allows you to add a given &lt;code&gt;IceCandidate&lt;/code&gt; to a &lt;code&gt;PeerConnection&lt;/code&gt;. So you can add an &lt;code&gt;IceCandidate&lt;/code&gt; to a &lt;code&gt;PeerConnection&lt;/code&gt; as Coroutines-style, not callback-style.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-kotlin&#34;&gt;pendingIceMutex.withLock {&#xA;    pendingIceCandidates.forEach { iceCandidate -&amp;gt;&#xA;    connection.addRtcIceCandidate(iceCandidate)&#xA;    }&#xA;    pendingIceCandidates.clear()&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;createSessionDescription&lt;/h3&gt; &#xA;&lt;p&gt;You can create a &lt;code&gt;SessionDescription&lt;/code&gt;, which delegates &lt;code&gt;SdpObserver&lt;/code&gt; with Coroutines styles:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-kotlin&#34;&gt;suspend fun createAnswer(): Result&amp;lt;SessionDescription&amp;gt; {&#xA;  return createSessionDescription { sdpObserver -&amp;gt; connection.createAnswer(sdpObserver, mediaConstraints) }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Instructions for Setting Up Chromium Dev Tool&lt;/h2&gt; &#xA;&lt;p&gt;This is an instruction for setting up Chromium Dev Tool if you need to compile the WebRTC core library by yourself with this project.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://commondatastorage.googleapis.com/chrome-infra-docs/flat/depot_tools/docs/html/depot_tools_tutorial.html#_setting_up&#34;&gt;Chromium Dev Tools&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;You need to set up depot tools to build &amp;amp; fetch Chromium codebase.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You should fetch the chromium WebRTC repository from the Google&#39;s repository against HEAD commits.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img width=&#34;449&#34; alt=&#34;Screenshot 2023-02-08 at 11 47 14 AM&#34; src=&#34;https://user-images.githubusercontent.com/24237865/218024381-7005bf74-cac9-4501-bbe8-e4258d3fa384.png&#34;&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Chromium WebRTC core libraries can be bulit only in Linux OS. Every step takes its own time based on the machine specs and internet speed, so make sure every step is completed without interruption.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;You need to set up AWS instance (pre-requiests):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ubuntu 14.04 LTS (trusty with EoL April 2022)&lt;/li&gt; &#xA; &lt;li&gt;8 GB memory ram&lt;/li&gt; &#xA; &lt;li&gt;At least 50 GB HDD/SSD storage&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To compile the pre-built WebRTC library for Android, you must follow the steps below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;1. git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git&#xA;    &#xA;2. export PATH=&#34;$PATH:${HOME}/depot_tools&#34;&#xA;    &#xA;3. mkdir webrtc_android &amp;amp;&amp;amp; cd webrtc_android&#xA;    &#xA;4. fetch --nohooks webrtc_android&#xA;        &#xA;5. gclient sync&#xA;    &#xA;6. cd src &amp;amp;&amp;amp; ./build/install-build-deps.sh&#xA;    &#xA;7. git branch -r&#xA;    &#xA;8. git checkout origin/master&#xA;    &#xA;# To check you&#39;re in origin/master branch and check out to a specific branch if you want.&#xA;9. git branch&#xA;&#xA;10. Replace Android sources &amp;amp; NDK/C/C++ files with this repository.&#xA;&#xA;11. tools_webrtc/android/build_aar.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install all required dependencies for linux, a script is provided for Ubuntu, which is unfortunately only available after your first gclient sync and make sure your current directory is &lt;code&gt;webrtc_android/src/&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd src &amp;amp;&amp;amp; ./build/install-build-deps.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can see the available latest branches looks like the screenshoos below:&lt;/p&gt; &#xA;&lt;img width=&#34;270&#34; alt=&#34;Screenshot 2023-02-14 at 5 26 32 PM&#34; src=&#34;https://user-images.githubusercontent.com/24237865/218680102-d7522dd5-1cf1-4c3b-ba61-463b75f5f714.png&#34;&gt; &#xA;&lt;p&gt;Now you can checkout to the latest branch which is &lt;code&gt;branch-heads/m79&lt;/code&gt; or something, using this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git checkout branch-heads/m79&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;However, this project reflects the latest updates for WebRTC, so you must check out to the master branch like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;8. git checkout origin/master&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will help you to resolve most of compilation issues. To get the details about your current branch you can simply use these commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;9. git branch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using Manual Compilation:&lt;/h3&gt; &#xA;&lt;p&gt;This process will manually compile the source code for each particular CPU type. Manual Compiling involves these two steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Generate projects using GN.&lt;/li&gt; &#xA; &lt;li&gt;Compile using Ninja.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This step will compile the library for Debug and Release modes of Development.&lt;/p&gt; &#xA;&lt;p&gt;Ensure your current working directory is webrtc_android/src/ of your workspace. Then run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;11. gn gen out/Debug --args=&#39;target_os=&#34;android&#34; target_cpu=&#34;arm&#34;&#39;&#xA;11. gn gen out/Release --args=&#39;is_debug=false is_component_build=false rtc_include_tests=false target_os=&#34;android&#34; target_cpu=&#34;arm&#34;&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can specify a directory of your own choice instead of out/Debug, to enable managing multiple configurations in parallel.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To build for ARM64: use target_cpu=&#34;arm64&#34;&lt;/li&gt; &#xA; &lt;li&gt;To build for 32-bit x86: use target_cpu=&#34;x86&#34;&lt;/li&gt; &#xA; &lt;li&gt;To build for 64-bit x64: use target_cpu=&#34;x64&#34;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For compilation you can simply use these following commands for (out/Debug, out/Release):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;11. ninja -C out/Debug&#xA;11. ninja -C out/Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using AAR Build Tools:&lt;/h3&gt; &#xA;&lt;p&gt;This is the most simple process, which compiles the source code for all supported CPU types such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;arm64-v8a&lt;/li&gt; &#xA; &lt;li&gt;armeabi-v7a&lt;/li&gt; &#xA; &lt;li&gt;x86&lt;/li&gt; &#xA; &lt;li&gt;x86_64&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;After compiling the package, it includes all these native libraries and &lt;code&gt;.jar&lt;/code&gt; library into &lt;code&gt;*.aar&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;Make sure your current working directory is &lt;code&gt;webrtc_android/src/&lt;/code&gt; of your workspace. Then run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;11. tools_webrtc/android/build_aar.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This process will take some time based on your machine specs and internet speed, so here we go:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/24237865/218025156-22fd6460-803a-4490-bbd5-48a1c4f1f452.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now, if you look in the &lt;code&gt;webrtc_android/src/&lt;/code&gt; directory, It turns out that you will end up with the compilation and building of &lt;code&gt;libwebrtc.aar&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://getstream.io/chat/sdk/compose?utm_source=Github&amp;amp;utm_medium=Github_Repo_Content_Ad&amp;amp;utm_content=Developer&amp;amp;utm_campaign=Github_Feb2023_Jaewoong_StreamWebRTCAndroid&amp;amp;utm_term=DevRelOss&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/24237865/146505581-a79e8f7d-6eda-4611-b41a-d60f0189e7d4.jpeg&#34; align=&#34;right&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Find this Android library useful? üíô&lt;/h2&gt; &#xA;&lt;p&gt;Support it by joining &lt;strong&gt;&lt;a href=&#34;https://github.com/getStream/stream-webrtc-android/stargazers&#34;&gt;stargazers&lt;/a&gt;&lt;/strong&gt; for this repository. ‚≠êÔ∏è &lt;br&gt; Also, follow &lt;strong&gt;&lt;a href=&#34;https://github.com/skydoves&#34;&gt;maintainers&lt;/a&gt;&lt;/strong&gt; on GitHub for our next creations! ü§©&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;Copyright 2023 Stream.IO, Inc. All Rights Reserved.&#xA;&#xA;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);&#xA;you may not use this file except in compliance with the License.&#xA;You may obtain a copy of the License at&#xA;&#xA;   http://www.apache.org/licenses/LICENSE-2.0&#xA;&#xA;Unless required by applicable law or agreed to in writing, software&#xA;distributed under the License is distributed on an &#34;AS IS&#34; BASIS,&#xA;WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&#xA;See the License for the specific language governing permissions and&#xA;limitations under the License.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>lyr408/Hotfix</title>
    <updated>2023-02-19T01:37:58Z</updated>
    <id>tag:github.com,2023-02-19:/lyr408/Hotfix</id>
    <link href="https://github.com/lyr408/Hotfix" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Hotfix&lt;/h1&gt; &#xA;&lt;p&gt;The Hotfix can dynamically fix online bugs for Android without republishing an app.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Lucchetto/SuperImage</title>
    <updated>2023-02-19T01:37:58Z</updated>
    <id>tag:github.com,2023-02-19:/Lucchetto/SuperImage</id>
    <link href="https://github.com/Lucchetto/SuperImage" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Sharpen your low-resolution pictures with the power of AI upscaling&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SuperImage&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Sharpen your low-resolution pictures with the power of AI upscaling&lt;/strong&gt;&lt;br&gt;&lt;br&gt; SuperImage is a neural network based image upscaling application for Android built with the &lt;a href=&#34;https://github.com/alibaba/MNN&#34;&gt;MNN deep learning framework&lt;/a&gt; and &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt;.&lt;br&gt;&lt;br&gt; &lt;a href=&#34;https://play.google.com/store/apps/details?id=com.zhenxiang.superimage&amp;amp;pcampaignid=pcampaignidMKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1&#34;&gt;&lt;img height=&#34;100&#34; alt=&#34;Get it on Google Play&#34; src=&#34;https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The input image is processed in tiles on the device GPU, using a pre-trained Real-ESRGAN model. The tiles are then merged into the final high-resolution image. This application requires Vulkan or OpenCL support and Android 7 or above&lt;/p&gt; &#xA;&lt;h2&gt;üñº Samples&lt;/h2&gt; &#xA;&lt;div&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Lucchetto/SuperImage/master/assets/sample_1.jpg&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Lucchetto/SuperImage/master/assets/sample_2.jpg&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Lucchetto/SuperImage/master/assets/sample_3.jpg&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üìä Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;Results on Qualcomm Snapdragon 855 (Vulkan)&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Mode&lt;/th&gt; &#xA;   &lt;th&gt;Input resolution&lt;/th&gt; &#xA;   &lt;th&gt;Output resolution&lt;/th&gt; &#xA;   &lt;th&gt;Execution time&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4x (generic)&lt;/td&gt; &#xA;   &lt;td&gt;1920x1080&lt;/td&gt; &#xA;   &lt;td&gt;3840x2160&lt;/td&gt; &#xA;   &lt;td&gt;3 minutes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8x (generic)&lt;/td&gt; &#xA;   &lt;td&gt;1920x1080&lt;/td&gt; &#xA;   &lt;td&gt;7680x4320&lt;/td&gt; &#xA;   &lt;td&gt;11 minutes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8x (drawing)&lt;/td&gt; &#xA;   &lt;td&gt;1920x1080&lt;/td&gt; &#xA;   &lt;td&gt;7680x4320&lt;/td&gt; &#xA;   &lt;td&gt;3 mins 42 seconds&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üì± Screenshots&lt;/h2&gt; &#xA;&lt;p&gt; &lt;span&gt;&amp;nbsp;&lt;/span&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Lucchetto/SuperImage/master/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_light.png&#34; width=&#34;230&#34;&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Lucchetto/SuperImage/master/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_dark.png&#34; width=&#34;230&#34;&gt; &lt;span&gt;&amp;nbsp;&lt;/span&gt; &lt;/p&gt; &#xA;&lt;h2&gt;üí¨ Community&lt;/h2&gt; &#xA;&lt;p&gt;You can join the &lt;a href=&#34;https://t.me/super_image&#34;&gt;Telegram group&lt;/a&gt; for support, discussions about AI image processing, and off-topic stuff&lt;/p&gt; &#xA;&lt;h2&gt;Âçî Contribute&lt;/h2&gt; &#xA;&lt;p&gt;You can submit feedbacks or bug reports by &lt;a href=&#34;https://github.com/Lucchetto/SuperImage/issues/new&#34;&gt;opening an issue&lt;/a&gt;. Pull requests are welcome !&lt;/p&gt; &#xA;&lt;h2&gt;üìö TODO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support images with transparency&lt;/li&gt; &#xA; &lt;li&gt;Batch processing&lt;/li&gt; &#xA; &lt;li&gt;Web and desktop versions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìù Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pre-trained models and original implementation from &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Pictures by &lt;a href=&#34;https://www.pexels.com/photo/yasaka-pagoda-in-kyoto-7526805&#34;&gt;Satoshi Hirayama&lt;/a&gt;, &lt;a href=&#34;https://www.pexels.com/photo/food-japanese-food-photography-sushi-9210&#34;&gt;Skitterphoto&lt;/a&gt;, &lt;a href=&#34;https://www.pixiv.net/en/artworks/103802719&#34;&gt;Â§©Ê±ü„Å≤„Å™„Åü&lt;/a&gt; and &lt;a href=&#34;https://www.pexels.com/photo/an-illuminated-lanterns-on-the-street-5745029&#34;&gt;Ryutaro Tsukata&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; &#xA;&lt;p&gt;SuperImage is licensed under the &lt;a href=&#34;https://www.gnu.org/licenses/gpl-3.0.html&#34;&gt;GNU General Public License v3.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>