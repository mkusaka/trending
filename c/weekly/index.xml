<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-11-17T01:37:13Z</updated>
  <subtitle>Weekly Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>open-telemetry/opentelemetry-ebpf-profiler</title>
    <updated>2024-11-17T01:37:13Z</updated>
    <id>tag:github.com,2024-11-17:/open-telemetry/opentelemetry-ebpf-profiler</id>
    <link href="https://github.com/open-telemetry/opentelemetry-ebpf-profiler" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The production-scale datacenter profiler (C/C++, Go, Rust, Python, Java, NodeJS, .NET, PHP, Ruby, Perl, ...)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Introduction&lt;/h1&gt; &#xA;&lt;p&gt;This repository implements a whole-system, cross-language profiler for Linux via eBPF.&lt;/p&gt; &#xA;&lt;h2&gt;Core features and strengths&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Implements the &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-proto/pull/534&#34;&gt;experimental OTel profiling signal&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Very low CPU and memory overhead (1% CPU and 250MB memory are our upper limits in testing and the agent typically manages to stay way below that)&lt;/li&gt; &#xA; &lt;li&gt;Support for native C/C++ executables without the need for DWARF debug information (by leveraging &lt;code&gt;.eh_frame&lt;/code&gt; data as described in &lt;a href=&#34;https://patents.google.com/patent/US11604718B1/en?inventor=thomas+dullien&amp;amp;oq=thomas+dullien&#34;&gt;US11604718B1&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Support profiling of system libraries &lt;strong&gt;without frame pointers&lt;/strong&gt; and &lt;strong&gt;without debug symbols on the host&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Support for mixed stacktraces between runtimes - stacktraces go from Kernel space through unmodified system libraries all the way into high-level languages.&lt;/li&gt; &#xA; &lt;li&gt;Support for native code (C/C++, Rust, Zig, Go, etc. without debug symbols on host)&lt;/li&gt; &#xA; &lt;li&gt;Support for a broad set of HLLs (Hotspot JVM, Python, Ruby, PHP, Node.JS, V8, Perl), .NET is in preparation.&lt;/li&gt; &#xA; &lt;li&gt;100% non-intrusive: there&#39;s no need to load agents or libraries into the processes that are being profiled.&lt;/li&gt; &#xA; &lt;li&gt;No need for any reconfiguration, instrumentation or restarts of HLL interpreters and VMs: the agent supports unwinding each of the supported languages in the default configuration.&lt;/li&gt; &#xA; &lt;li&gt;ARM64 support for all unwinders except NodeJS.&lt;/li&gt; &#xA; &lt;li&gt;Support for native &lt;code&gt;inline frames&lt;/code&gt;, which provide insights into compiler optimizations and offer a higher precision of function call chains.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;d like to quickly test the agent, you can skip to the &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-ebpf-profiler?tab=readme-ov-file#visualizing-data-locally&#34;&gt;&#34;Visualizing data locally&#34;&lt;/a&gt; section and launch devfiler. From there, follow the download links for prebuilt agent binaries.&lt;/p&gt; &#xA;&lt;h2&gt;Platform Requirements&lt;/h2&gt; &#xA;&lt;p&gt;The agent can be built with the provided make targets. Docker is required for containerized builds, and both amd64 and arm64 architectures are supported.&lt;/p&gt; &#xA;&lt;p&gt;For &lt;strong&gt;Linux&lt;/strong&gt;, the following steps apply:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Build the Docker image containing the build environment: &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make docker-image&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Build the agent for your current machine&#39;s architecture: &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make agent&#xA;&lt;/code&gt;&lt;/pre&gt; Or &lt;code&gt;make debug-agent&lt;/code&gt; for debug build.&lt;/li&gt; &#xA; &lt;li&gt;To cross-complie for a different architecture (e.g. arm64): &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make agent TARGET_ARCH=arm64&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The resulting binary will be named &#xA; &lt;ebpf-profiler&gt;&#xA;   in the current directory.&#xA; &lt;/ebpf-profiler&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Other OSes&lt;/h2&gt; &#xA;&lt;p&gt;Since the profiler is Linux-only, macOS and Windows users need to set up a Linux VM to build and run the agent. Ensure the appropriate architecture is specified if using cross-compilation. Use the same make targets as above after the Linux environment is configured in the VM.&lt;/p&gt; &#xA;&lt;h2&gt;Alternative Build (Without Docker)&lt;/h2&gt; &#xA;&lt;p&gt;You can build the agent without Docker by directly installing the dependencies listed in the Dockerfile. Once dependencies are set up, simply run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will build the profiler natively on your machine.&lt;/p&gt; &#xA;&lt;h2&gt;Running&lt;/h2&gt; &#xA;&lt;p&gt;You can start the agent with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo ./ebpf-profiler -collection-agent=127.0.0.1:11000 -disable-tls&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The agent comes with a functional but work-in-progress / evolving implementation of the recently released OTel profiling &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-proto/pull/534&#34;&gt;signal&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The agent loads the eBPF program and its maps, starts unwinding and reports captured traces to the backend.&lt;/p&gt; &#xA;&lt;h2&gt;Visualizing data locally&lt;/h2&gt; &#xA;&lt;p&gt;We created a desktop application called &#34;devfiler&#34; that allows visualizing the profiling agent&#39;s output locally, making it very convenient for development use. devfiler spins up a local server that listens on &lt;code&gt;0.0.0.0:11000&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/doc/devfiler.png&#34; alt=&#34;Screenshot of devfiler UI&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;To run it, simply download and unpack the archive from the following URL:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://upload.elastic.co/d/f8aa0c386baa808a616ca29f86b34c726edb5af36f8840a4cf28468ad534a4b5&#34;&gt;https://upload.elastic.co/d/f8aa0c386baa808a616ca29f86b34c726edb5af36f8840a4cf28468ad534a4b5&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Authentication token: &lt;code&gt;2635c0750bf8ea69&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The archive contains a build for each of the following platforms:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;macOS (Intel)&lt;/li&gt; &#xA; &lt;li&gt;macOS (Apple Silicon)&lt;/li&gt; &#xA; &lt;li&gt;Linux AppImage (x86_64)&lt;/li&gt; &#xA; &lt;li&gt;Linux AppImage (aarch64)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;/p&gt; &#xA; &lt;p&gt;The macOS application isn&#39;t properly signed with an Apple developer certificate: macOS will complain about the application being corrupted on start. To work around that, simply run the following command after downloading the archive:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;xattr -d com.apple.quarantine ~/Downloads/devfiler.app.zip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;If you did this correctly, the application should run just fine after unpacking the ZIP.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] devfiler is currently in an experimental preview stage.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;macOS&lt;/h3&gt; &#xA;&lt;p&gt;This build of devfiler is currently not signed with a globally trusted Apple developer ID, but with a developer certificate. If you simply double-click the application, you&#39;ll run into an error. Instead of opening it with a double click, simply do a &lt;strong&gt;right-click&lt;/strong&gt; on &lt;code&gt;devfiler.app&lt;/code&gt;, then choose &#34;Open&#34;. If you go this route, you&#39;ll instead be presented with the option to run it anyway.&lt;/p&gt; &#xA;&lt;h3&gt;Linux&lt;/h3&gt; &#xA;&lt;p&gt;The AppImages in the archive should run on any Linux distribution with a reasonably modern glibc and libgl installation. To run the application, simply extract the archive and then do:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;./devfiler-appimage-$(uname -m).AppImage&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Agent internals&lt;/h2&gt; &#xA;&lt;p&gt;The host agent is a Go application that is deployed to all machines customers wish to profile. It collects, processes and pushes observed stack traces and related meta-information to a backend collector.&lt;/p&gt; &#xA;&lt;h3&gt;Concepts&lt;/h3&gt; &#xA;&lt;h4&gt;File IDs&lt;/h4&gt; &#xA;&lt;p&gt;A file ID uniquely identifies an executable, kernel or script language source file.&lt;/p&gt; &#xA;&lt;p&gt;File IDs for native applications are created by taking the SHA256 checksum of a file&#39;s head, tail, and size, then truncating the hash digest to 16 bytes (128 bits):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Input  ← Concat(File[:4096], File[-4096:], BigEndianUInt64(Len(File)))&#xA;Digest ← SHA256(Input)&#xA;FileID ← Digest[:16]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;File IDs for script and JIT languages are created in an interpreter-specific fashion.&lt;/p&gt; &#xA;&lt;p&gt;File IDs for Linux kernels are calculated by taking the FNV128 hash of their GNU build ID.&lt;/p&gt; &#xA;&lt;h4&gt;Stack unwinding&lt;/h4&gt; &#xA;&lt;p&gt;Stack unwinding is the process of recovering the list of function calls that lead execution to the point in the program at which the profiler interrupted it.&lt;/p&gt; &#xA;&lt;p&gt;How stacks are unwound varies depending on whether a thread is running native, JITed or interpreted code, but the basic idea is always the same: every language that supports arbitrarily nested function calls needs a way to keep track of which function it needs to return to after the current function completes. Our unwinder uses that same information to repeatedly determine the caller until we reach the thread&#39;s entry point.&lt;/p&gt; &#xA;&lt;p&gt;In simplified pseudo-code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pc ← interrupted_process.cpu.pc&#xA;sp ← interrupted_process.cpu.sp&#xA;&#xA;while !is_entry_point(pc):&#xA;    file_id, start_addr, interp_type ← file_id_at_pc(pc)&#xA;    push_frame(interp_type, file_id, pc - start_addr)&#xA;    unwinder ← unwinder_for_interp(interp_type)&#xA;    pc, sp ← unwinder.next_frame(pc, sp)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Symbolization&lt;/h4&gt; &#xA;&lt;p&gt;Symbolization is the process of assigning source line information to the raw addresses extracted during stack unwinding.&lt;/p&gt; &#xA;&lt;p&gt;For script and JIT languages that always have symbol information available on the customer machines, the host agent is responsible for symbolizing frames.&lt;/p&gt; &#xA;&lt;p&gt;For native code the symbolization occurs in the backend. Stack frames are sent as file IDs and the offset within the file and the symbolization service is then responsible for assigning the correct function name, source file and lines in the background. Symbols for open-source software installed from OS package repos are pulled in from our global symbolization infrastructure and symbols for private executables can be manually uploaded by the customer.&lt;/p&gt; &#xA;&lt;p&gt;The primary reason for doing native symbolization in the backend is that native executables in production will often be stripped. Asking the customer to deploy symbols to production would be both wasteful in terms of disk usage and also a major friction point in initial adoption.&lt;/p&gt; &#xA;&lt;h4&gt;Stack trace representation&lt;/h4&gt; &#xA;&lt;p&gt;We have two major representations for our stack traces.&lt;/p&gt; &#xA;&lt;p&gt;The raw trace format produced by our BPF unwinders:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-ebpf-profiler/raw/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/host/host.go#L60-L66&#34;&gt;https://github.com/open-telemetry/opentelemetry-ebpf-profiler/blob/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/host/host.go#L60-L66&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The final format produced after additional processing in user-land:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-ebpf-profiler/raw/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/libpf/libpf.go#L458-L463&#34;&gt;https://github.com/open-telemetry/opentelemetry-ebpf-profiler/blob/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/libpf/libpf.go#L458-L463&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The two might look rather similar at first glance, but there are some important differences:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;the BPF variant uses truncated 64-bit file IDs to save precious kernel memory&lt;/li&gt; &#xA; &lt;li&gt;for interpreter frames the BPF variant uses the file ID and line number fields to store more or less arbitrary interpreter-specific data that is needed by the user-mode code to conduct symbolization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A third trace representation exists within our network protocol, but it essentially just a deduplicated, compressed representation of the user-land trace format.&lt;/p&gt; &#xA;&lt;h4&gt;Trace hashing&lt;/h4&gt; &#xA;&lt;p&gt;In profiling it is common to see the same trace many times. Traces can be up to 128 entries long, and repeatedly symbolizing and sending the same traces over the network would be very wasteful. We use trace hashing to avoid this. Different hashing schemes are used for the BPF and user-mode trace representations. Multiple 64 bit hashes can end up being mapped to the same 128 bit hash, but &lt;em&gt;not&lt;/em&gt; vice-versa.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;BPF trace hash (64 bit):&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;H(kernel_stack_id, frames_user, PID)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;User-land trace hash (128 bit)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;H(frames_user_kernel)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;User-land sub-components&lt;/h3&gt; &#xA;&lt;h4&gt;Tracer&lt;/h4&gt; &#xA;&lt;p&gt;The tracer is a central user-land component that loads and attaches our BPF programs to their corresponding BPF probes during startup and then continues to serve as the primary event pump for BPF &amp;lt;-&amp;gt; user-land communication. It further instantiates and owns other important subcomponents like the process manager.&lt;/p&gt; &#xA;&lt;h4&gt;Trace handler&lt;/h4&gt; &#xA;&lt;p&gt;The trace handler is responsible for converting traces from the BPF format to the user-space format. It receives raw traces &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/#tracer&#34;&gt;tracer&lt;/a&gt;, converts them to the user-space format and then sends them on to the &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/#reporter&#34;&gt;reporter&lt;/a&gt;. The majority of the conversion logic happens via a call into the process manager&#39;s &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-ebpf-profiler/raw/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/processmanager/manager.go#L208&#34;&gt;&lt;code&gt;ConvertTrace&lt;/code&gt;&lt;/a&gt; function.&lt;/p&gt; &#xA;&lt;p&gt;Since converting and enriching BPF-format traces is not a cheap operation, the trace handler is also responsible for keeping a cache (mapping) of trace hashes: from 64bit BPF hash to the user-space 128bit hash.&lt;/p&gt; &#xA;&lt;h4&gt;Reporter&lt;/h4&gt; &#xA;&lt;p&gt;The reporter receives traces and trace counts in the user-mode format from the &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/#trace-handler&#34;&gt;trace handler&lt;/a&gt;, converts them to the gRPC representation and then sends them out to a backend collector.&lt;/p&gt; &#xA;&lt;p&gt;It also receives additional meta-information (such as &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/metrics/metrics.json&#34;&gt;metrics&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/hostmetadata/hostmetadata.json&#34;&gt;host metadata&lt;/a&gt;) which it also converts and sends out to a backend collector over gRPC.&lt;/p&gt; &#xA;&lt;p&gt;The reporter does not offer strong guarantees regarding reliability of network operations and may drop data at any point, an &#34;eventual consistency&#34; model.&lt;/p&gt; &#xA;&lt;h4&gt;Process manager&lt;/h4&gt; &#xA;&lt;p&gt;The process manager receives process creation/termination events from &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/#tracer&#34;&gt;tracer&lt;/a&gt; and is responsible for making available any information to the BPF code that it needs to conduct unwinding. It maintains a map of the executables mapped into each process, loads stack unwinding deltas for native modules and creates interpreter handlers for each memory mapping that belongs to a supported language interpreter.&lt;/p&gt; &#xA;&lt;p&gt;During trace conversion the process manager is further responsible for routing symbolization requests to the correct interpreter handlers.&lt;/p&gt; &#xA;&lt;h4&gt;Interpreter handlers&lt;/h4&gt; &#xA;&lt;p&gt;Each interpreted or JITed language that we support has a corresponding type that implements the interpreter handler interface. It is responsible for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;detecting the interpreter&#39;s version and structure layouts&lt;/li&gt; &#xA; &lt;li&gt;placing information that the corresponding BPF interpreter unwinder needs into BPF maps&lt;/li&gt; &#xA; &lt;li&gt;translating interpreter frames from the BPF format to the user-land format by symbolizing them&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Stack delta provider&lt;/h4&gt; &#xA;&lt;p&gt;Unwinding the stack of native executables compiled without frame pointers requires stack deltas. These deltas are essentially a mapping from each PC in an executable to instructions describing how to find the caller and how to adjust the unwinder machine state in preparation of locating the next frame. Typically these instructions consist of a register that is used as a base address and an offset (delta) that needs to be added to it -- hence the name. The stack delta provider is responsible for analyzing executables and creating stack deltas for them.&lt;/p&gt; &#xA;&lt;p&gt;For most native executables, we rely on the information present in &lt;code&gt;.eh_frame&lt;/code&gt;. &lt;code&gt;.eh_frame&lt;/code&gt; was originally meant only for C++ exception unwinding, but it has since been repurposed for stack unwinding in general. Even applications written in many other native languages like C, Zig or Rust will typically come with &lt;code&gt;.eh_frame&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;One important exception to this general pattern is Go. As of writing, Go executables do not come with &lt;code&gt;.eh_frame&lt;/code&gt; sections unless they are built with CGo enabled. Even with CGo the &lt;code&gt;.eh_frame&lt;/code&gt; section will only contain information for a small subset of functions that are either written in C/C++ or part of the CGo runtime. For Go executables we extract the stack delta information from the Go-specific section called &lt;code&gt;.gopclntab&lt;/code&gt;. In-depth documentation on the format is available in &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/doc/gopclntab.md&#34;&gt;a separate document&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;BPF components&lt;/h3&gt; &#xA;&lt;p&gt;The BPF portion of the host agent implements the actual stack unwinding. It uses the eBPF virtual machine to execute our code directly in the Linux kernel. The components are implemented in BPF C and live in the &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/support/ebpf&#34;&gt;&lt;code&gt;opentelemetry-ebpf-profiler/support/ebpf&lt;/code&gt;&lt;/a&gt; directory.&lt;/p&gt; &#xA;&lt;h4&gt;Limitations&lt;/h4&gt; &#xA;&lt;p&gt;BPF programs must adhere to various restrictions imposed by the verifier. Many of these limitations are significantly relaxed in newer kernel versions, but we still have to stick to the old limits because we wish to continue supporting older kernels.&lt;/p&gt; &#xA;&lt;p&gt;The minimum supported Linux kernel versions are&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;4.19 for amd64/x86_64&lt;/li&gt; &#xA; &lt;li&gt;5.5 for arm64/aarch64&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The most notable limitations are the following two:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;4096 instructions per program&lt;/strong&gt;&lt;br&gt; A single BPF program can consist of a maximum of 4096 instructions, otherwise older kernels will refuse to load it. Since BPF does not allow for loops, they instead need to be unrolled.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;32 tail-calls&lt;/strong&gt;&lt;br&gt; Linux allows BPF programs to do a tail-call to another BPF program. A tail call is essentially a &lt;code&gt;jmp&lt;/code&gt; into another BPF program, ending execution of the current handler and starting a new one. This allows us to circumvent the 4096 instruction limit a bit by doing a tail-call before we run into the limit. There&#39;s a maximum of 32 tail calls that a BPF program can do.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These limitations mean that we generally try to prepare as much work as possible in user-land and then only do the minimal work necessary within BPF. We can only use $O(\log{n})$ algorithms at worst and try to stick with $O(1)$ for most things. All processing that cannot be implemented like this must be delegated to user-land. As a general rule of thumb, anything that needs more than 32 iterations in a loop is out of the question for BPF.&lt;/p&gt; &#xA;&lt;h4&gt;Unwinders&lt;/h4&gt; &#xA;&lt;p&gt;Unwinding always begins in &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-ebpf-profiler/raw/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/support/ebpf/native_stack_trace.ebpf.c#L875&#34;&gt;&lt;code&gt;native_tracer_entry&lt;/code&gt;&lt;/a&gt;. This entry point for our tracer starts by reading the register state of the thread that we just interrupted and initializes the &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-ebpf-profiler/raw/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/support/ebpf/types.h#L576&#34;&gt;&lt;code&gt;PerCPURecord&lt;/code&gt;&lt;/a&gt; structure. The per-CPU record persists data between tail-calls of the same unwinder invocation. The unwinder&#39;s current &lt;code&gt;PC&lt;/code&gt;, &lt;code&gt;SP&lt;/code&gt; etc. values are initialized from register values.&lt;/p&gt; &#xA;&lt;p&gt;After the initial setup the entry point consults a BPF map that is maintained by the user-land portion of the agent to determine which interpreter unwinder is responsible for unwinding the code at &lt;code&gt;PC&lt;/code&gt;. If a record for the memory region is found, we then tail-call to the corresponding interpreter unwinder.&lt;/p&gt; &#xA;&lt;p&gt;Each interpreter unwinder has their own BPF program. The interpreter unwinders typically have an unrolled main loop where they try to unwind as many frames for that interpreter as they can without going over the instruction limit. After each iteration the unwinders will typically check whether the current PC value still belongs to the current unwinder and tail-call to the right unwinder otherwise.&lt;/p&gt; &#xA;&lt;p&gt;When an unwinder detects that we&#39;ve reached the last frame in the trace, unwinding is terminated with a tail call to &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-ebpf-profiler/raw/0945fe628da5c4854d55dd95e5dc4b4cf46a3c76/support/ebpf/interpreter_dispatcher.ebpf.c#L125&#34;&gt;&lt;code&gt;unwind_stop&lt;/code&gt;&lt;/a&gt;. For most traces this call will happen in the native unwinder, since even JITed languages usually call through a few layers of native C/C++ code before entering the VM. We detect the end of a trace by heuristically marking certain functions with &lt;code&gt;PROG_UNWIND_STOP&lt;/code&gt; in the BPF maps prepared by user-land. &lt;code&gt;unwind_stop&lt;/code&gt; then sends the completed BPF trace to user-land.&lt;/p&gt; &#xA;&lt;p&gt;If any frame in the trace requires symbolization in user-mode, we additionally send a BPF event to request an expedited read from user-land. For all other traces user-land will simply read and then clear this map on a timer.&lt;/p&gt; &#xA;&lt;h4&gt;PID events&lt;/h4&gt; &#xA;&lt;p&gt;The BPF components are responsible for notifying user-land about new and exiting processes. An event about a new process is produced when we first interrupt it with the unwinders. Events about exiting processes are created with a &lt;code&gt;sched_process_exit&lt;/code&gt; probe. In both cases the BPF code sends a perf event to notify user-land. We also re-report a PID if we detect execution in previously unknown memory region to prompt re-scan of the mappings.&lt;/p&gt; &#xA;&lt;h3&gt;Network protocol&lt;/h3&gt; &#xA;&lt;p&gt;All collected information is reported to a backend collector via a push-based, stateless, one-way gRPC &lt;a href=&#34;https://github.com/open-telemetry/opentelemetry-proto/pull/534&#34;&gt;protocol&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;All data to be transmitted is stored in bounded FIFO queues (ring buffers). Old data is overwritten when the queues fill up (e.g. due to a lagging or offline backend collector). There is no explicit reliability or redundancy (besides retries internal to gRPC) and the assumption is that data will be resent (eventually consistent).&lt;/p&gt; &#xA;&lt;h3&gt;Trace processing pipeline&lt;/h3&gt; &#xA;&lt;p&gt;The host agent contains an internal pipeline that incrementally processes the raw traces that are produced by the BPF unwinders, enriches them with additional information (e.g. symbols for interpreter frames and container info), deduplicates known traces and combines trace counts that occurred in the same update period.&lt;/p&gt; &#xA;&lt;p&gt;The traces produced in BPF start out with the information shown in the following diagram.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Note: please read this if you wish to update the diagrams&lt;/summary&gt; &#xA; &lt;p&gt;The diagrams in this section were created via draw.io. The SVGs can be loaded into draw.io for editing. When you&#39;re done, make sure to export via &lt;kbd&gt;File&lt;/kbd&gt; -&amp;gt; &lt;kbd&gt;Export As&lt;/kbd&gt; -&amp;gt; &lt;kbd&gt;SVG&lt;/kbd&gt; and then select a zoom level of 200%. If you simply save the diagram via &lt;kbd&gt;CTRL+S&lt;/kbd&gt;, it won&#39;t fill the whole width of the documentation page. Also make sure that &#34;Include a copy of my diagram&#34; remains ticked to keep the diagram editable.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/doc/bpf-trace.drawio.svg?sanitize=true&#34; alt=&#34;bpf-trace-diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Our backend collector expects to receive trace information in a normalized and enriched format. This diagram below is relatively close to the data-structures that are actually sent over the network, minus the batching and domain-specific deduplication that we apply prior to sending it out.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/doc/network-trace.drawio.svg?sanitize=true&#34; alt=&#34;net-trace-diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The diagram below provides a detailed overview on how the various components of the host agent interact to transform raw traces into the network format. It is focused around our data structures and how data flows through them. Dotted lines represent indirect interaction with data structures, solid ones correspond to code flow. &#34;UM&#34; is short for &#34;user mode&#34;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/doc/trace-pipe.drawio.svg?sanitize=true&#34; alt=&#34;trace-pipe-diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Testing strategy&lt;/h3&gt; &#xA;&lt;p&gt;The host agent code is tested with three test suites:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Go unit tests&lt;/strong&gt;&lt;br&gt; Functionality of individual functions and types is tested with regular Go unit tests. This works great for the user-land portion of the agent, but is unable to test any of the unwinding logic and BPF interaction.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;coredump test suite&lt;/strong&gt;&lt;br&gt; The coredump test suite (&lt;code&gt;utils/coredump&lt;/code&gt;) we compile the whole BPF unwinder code into a user-mode executable, then use the information from a coredump to simulate a realistic environment to test the unwinder code in. The coredump suite essentially implements all required BPF helper functions in user-space, reading memory and thread contexts from the coredump. The resulting traces are then compared to a frame list in a JSON file, serving as regression tests.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;BPF integration tests&lt;/strong&gt;&lt;br&gt; A special build of the host agent with the &lt;code&gt;integration&lt;/code&gt; tag is created that enables specialized test cases that actually load BPF tracers into the kernel. These test cases require root privileges and thus cannot be part of the regular unit test suite. The test cases focus on covering the interaction and communication of BPF with user-mode code, as well as testing that our BPF code passes the BPF verifier. Our CI builds the integration test executable once and then executes it on a wide range of different Linux kernel versions via qemu.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Probabilistic profiling&lt;/h3&gt; &#xA;&lt;p&gt;Probabilistic profiling allows you to reduce storage costs by collecting a representative sample of profiling data. This method decreases storage costs with a visibility trade-off, as not all Profiling Host Agents will have profile collection enabled at all times.&lt;/p&gt; &#xA;&lt;p&gt;Profiling Events linearly correlate with the probabilistic profiling value. The lower the value, the fewer events are collected.&lt;/p&gt; &#xA;&lt;h4&gt;Configure probabilistic profiling&lt;/h4&gt; &#xA;&lt;p&gt;To configure probabilistic profiling, set the &lt;code&gt;-probabilistic-threshold&lt;/code&gt; and &lt;code&gt;-probabilistic-interval&lt;/code&gt; options.&lt;/p&gt; &#xA;&lt;p&gt;Set the &lt;code&gt;-probabilistic-threshold&lt;/code&gt; option to a unsigned integer between 1 and 99 to enable probabilistic profiling. At every probabilistic interval, a random number between 0 and 99 is chosen. If the probabilistic threshold that you&#39;ve set is greater than this random number, the agent collects profiles from this system for the duration of the interval. The default value is 100.&lt;/p&gt; &#xA;&lt;p&gt;Set the &lt;code&gt;-probabilistic-interval&lt;/code&gt; option to a time duration to define the time interval for which probabilistic profiling is either enabled or disabled. The default value is 1 minute.&lt;/p&gt; &#xA;&lt;h4&gt;Example&lt;/h4&gt; &#xA;&lt;p&gt;The following example shows how to configure the profiling agent with a threshold of 50 and an interval of 2 minutes and 30 seconds:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo ./ebpf-profiler -probabilistic-threshold=50 -probabilistic-interval=2m30s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Legal&lt;/h1&gt; &#xA;&lt;h2&gt;Licensing Information&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache License 2.0 (Apache-2.0). &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/LICENSE&#34;&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The eBPF source code is licensed under the GPL 2.0 license. &lt;a href=&#34;https://raw.githubusercontent.com/open-telemetry/opentelemetry-ebpf-profiler/main/support/ebpf/LICENSE&#34;&gt;GPL 2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Licenses of dependencies&lt;/h2&gt; &#xA;&lt;p&gt;To display a summary of the dependencies&#39; licenses:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make legal&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>xicodomingues/francinette</title>
    <updated>2024-11-17T01:37:13Z</updated>
    <id>tag:github.com,2024-11-17:/xicodomingues/francinette</id>
    <link href="https://github.com/xicodomingues/francinette" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An easy to use testing framework for the 42 projects&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Francinette&lt;/h1&gt; &#xA;&lt;p&gt;An easy to use testing framework for the 42 projects.&lt;/p&gt; &#xA;&lt;p&gt;Use &lt;code&gt;francinette&lt;/code&gt; or &lt;code&gt;paco&lt;/code&gt; inside a project folder to run it.&lt;/p&gt; &#xA;&lt;p&gt;Currently has tests for: &lt;code&gt;libft&lt;/code&gt;, &lt;code&gt;ft_printf&lt;/code&gt;, &lt;code&gt;get_next_line&lt;/code&gt;, &lt;code&gt;minitalk&lt;/code&gt; and &lt;code&gt;pipex&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Francinette&lt;/code&gt; is only tested and confirmed to work on MacOS on non ARM chips. Some testers may work on Linux and ARM, but I give no guaranties of any test working or even compiling.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;❗&lt;/span&gt; Important note:&lt;/h2&gt; &#xA;&lt;p&gt;If you have little to no experience programming, I highly highly highly recommend that you write your own tests first. For example, for &lt;code&gt;ft_split&lt;/code&gt; try to write a main that tests that your code works in most cases. It is also useful to think about corner cases, like what should it return if the string is &lt;code&gt;&#34;&#34;&lt;/code&gt; or &lt;code&gt;&#34; &#34;&lt;/code&gt; or &lt;code&gt;&#34;word&#34;&lt;/code&gt;. Don&#39;t rely just on &lt;code&gt;francinette&lt;/code&gt; or other tests.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;span&gt;⚠&lt;/span&gt; Write your own tests, It&#39;s a very essential part of programming. &lt;span&gt;⚠&lt;/span&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/xicodomingues/francinette/master/#purpose&#34;&gt;Purpose&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/xicodomingues/francinette/master/#install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/xicodomingues/francinette/master/#update&#34;&gt;Update&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/xicodomingues/francinette/master/#Running&#34;&gt;Running&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/xicodomingues/francinette/master/#uninstall&#34;&gt;Uninstall&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/xicodomingues/francinette/master/#faq&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/xicodomingues/francinette/master/#acknowledgments&#34;&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Purpose:&lt;/h2&gt; &#xA;&lt;p&gt;This is designed to function as a kind of &lt;code&gt;moulinette&lt;/code&gt; that you can execute in local.&lt;/p&gt; &#xA;&lt;p&gt;That means that by executing &lt;code&gt;francinette&lt;/code&gt; it will check &lt;code&gt;norminette&lt;/code&gt;, compile the code and execute the tests.&lt;/p&gt; &#xA;&lt;p&gt;You can use it as a local test battery, to test your code.&lt;/p&gt; &#xA;&lt;h4&gt;Example execution:&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/xicodomingues/francinette/master/doc/example.png&#34; alt=&#34;Example Image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Install:&lt;/h2&gt; &#xA;&lt;p&gt;Francinette has an automatic installer.&lt;/p&gt; &#xA;&lt;p&gt;Copy the line bellow to your console and execute it. It will automatically download the repo, create the necessary folders and alias, and install a python virtual environment dedicated to running this tool.&lt;/p&gt; &#xA;&lt;p&gt;In linux it will also download and install the necessary packages for it to run. It needs admin permission to do that.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash -c &#34;$(curl -fsSL https://raw.github.com/xicodomingues/francinette/master/bin/install.sh)&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The francinette folder will be under your &lt;code&gt;$HOME&lt;/code&gt; directory (&lt;code&gt;/Users/&amp;lt;your_username&amp;gt;/&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Update:&lt;/h2&gt; &#xA;&lt;p&gt;Normally francinette will prompt you when there is a new version, and you can then update it.&lt;/p&gt; &#xA;&lt;p&gt;You can also force it from francinette itself:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;~ $&amp;gt; francinette -u              # Forces francinette to update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the above does not work you can also execute the command bellow:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash -c &#34;$(curl -fsSL https://raw.github.com/xicodomingues/francinette/master/bin/update.sh)&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running:&lt;/h2&gt; &#xA;&lt;p&gt;If you are on a root of a project, &lt;code&gt;francinette&lt;/code&gt; should be able to tell which project it is and execute the corresponding tests.&lt;/p&gt; &#xA;&lt;p&gt;You can also use the shorter version of the command: &lt;code&gt;paco&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;To see all the available options execute &lt;code&gt;paco -h&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;/C00 $&amp;gt; francinette                  # Execute the tests for C00&#xA;&#xA;/C00/ex00 $&amp;gt; francinette             # Execute only the tests for ex00 in C00&#xA;&#xA;/libft $&amp;gt; francinette                # Execute the tests for libft&#xA;&#xA;~ $&amp;gt; francinette -h                  # Shows the help message&#xA;&#xA;libft $&amp;gt; paco memset isalpha memcpy  # Executes only the specified tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The name of the folder is not important. What is important is that you have a &lt;code&gt;Makefile&lt;/code&gt; that contains the name of the project (for example &lt;code&gt;libft&lt;/code&gt;), or the expected delivery files. If there is no &lt;code&gt;Makefile&lt;/code&gt; or delivery files are not present &lt;code&gt;francinette&lt;/code&gt; will not know what project to execute.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;~ $&amp;gt; francinette git@repo42.com/intra-uuid-234&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command clones the git repository present in &lt;code&gt;git@repo42.com/intra-uuid-234&lt;/code&gt; into the current folder and executes the corresponding tests&lt;/p&gt; &#xA;&lt;p&gt;All the files are copied to the folder &lt;code&gt;~/francinette/temp/&amp;lt;project&amp;gt;&lt;/code&gt;. In here is where the norminette is checked, the code compiled and the tests executed. Normally you do not need to access this directory for anything. But if you run into unexpected problems, this is where the magic happens.&lt;/p&gt; &#xA;&lt;p&gt;Log files can be found in: &lt;code&gt;~/francinette/logs&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Uninstall&lt;/h2&gt; &#xA;&lt;p&gt;To uninstall &lt;code&gt;francinette&lt;/code&gt; delete the &lt;code&gt;francinette&lt;/code&gt; folder. It should be located under your &lt;code&gt;$HOME&lt;/code&gt; directory (&lt;code&gt;/Users/&amp;lt;your_username&amp;gt;/&lt;/code&gt; or &lt;code&gt;/home/&amp;lt;your_username&amp;gt;/&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;p&gt;You also need to remove the automatically created aliases. For that open your &lt;code&gt;~/.zshrc&lt;/code&gt; file and delete the lines:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;alias francinette=&#34;$HOME&#34;/francinette/tester.sh&#xA;alias paco=&#34;$HOME&#34;/francinette/tester.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions you can create an issue or reach me on slack under &lt;code&gt;fsoares-&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h4&gt;I&#39;m more advanced than the tests you have available. When are you adding more tests?&lt;/h4&gt; &#xA;&lt;p&gt;When I reach that exercise or project. You can also add them. For that you need to create a &lt;code&gt;ProjectTester.py&lt;/code&gt; file. and change the function &lt;code&gt;guess_project&lt;/code&gt; in &lt;code&gt;main.py&lt;/code&gt; to recognize the project.&lt;/p&gt; &#xA;&lt;h4&gt;This test that you put up is incorrect!&lt;/h4&gt; &#xA;&lt;p&gt;Please create a new github issue, indicating for what exercise which test fails, and a description of what you think is wrong. You can also try to fix it and create a pull request for that change!&lt;/p&gt; &#xA;&lt;h4&gt;What is NULL_CHECK in strict?&lt;/h4&gt; &#xA;&lt;p&gt;This is a way to test if you are protecting your &lt;code&gt;malloc&lt;/code&gt; calls. This means that it will make every call to &lt;code&gt;malloc&lt;/code&gt; fail and return &lt;code&gt;NULL&lt;/code&gt; instead of a newly allocated pointer. You need to take this into account when programming so that you don&#39;t get segmentation faults.&lt;/p&gt; &#xA;&lt;h4&gt;The tester for get_next_line is giving me Timeout errors&lt;/h4&gt; &#xA;&lt;p&gt;This is something that is very common. My tester will get slower for every malloc that you do, so if you do a lot of mallocs it will probably timeout.&lt;/p&gt; &#xA;&lt;p&gt;If it timeouts while in the strict mode, don&#39;t worry, this one is very very inefficient. I have plans to change some things to not make it so horrible, but for the time being, don&#39;t worry if it gives a Timeout.&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;h4&gt;I&#39;ve installed francinette, but when I try to execute it I get the message: &lt;code&gt;command not found: francinette&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;p&gt;In the install script I try to set two alias to for &lt;code&gt;francinette&lt;/code&gt;: &lt;code&gt;francinette&lt;/code&gt; and &lt;code&gt;paco&lt;/code&gt;. If you are in MacOS I do that by adding two lines to the &lt;code&gt;.zshrc&lt;/code&gt; file, and to &lt;code&gt;.bashrc&lt;/code&gt; in linux. If by some chance you are using other shell, or for some other reason it does not work, You can try to set the aliases yourself, by adding:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;alias francinette=&#34;$HOME&#34;/francinette/tester.sh&#xA;alias paco=&#34;$HOME&#34;/francinette/tester.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now it should work. If it does not, don&#39;t be afraid to contact me.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To 42 for providing me this opportunity&lt;/li&gt; &#xA; &lt;li&gt;To &lt;a href=&#34;https://github.com/Tripouille&#34;&gt;Tripouille&lt;/a&gt; for &lt;a href=&#34;https://github.com/Tripouille/libftTester&#34;&gt;libftTester&lt;/a&gt;, &lt;a href=&#34;https://github.com/Tripouille/gnlTester&#34;&gt;gnlTester&lt;/a&gt; and &lt;a href=&#34;https://github.com/Tripouille/printfTester&#34;&gt;printfTester&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To &lt;a href=&#34;https://github.com/jtoty&#34;&gt;jtoty&lt;/a&gt; and &lt;a href=&#34;https://github.com/y3ll0w42&#34;&gt;y3ll0w42&lt;/a&gt; for &lt;a href=&#34;https://github.com/y3ll0w42/libft-war-machine&#34;&gt;libft-war-machine&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To &lt;a href=&#34;https://github.com/alelievr&#34;&gt;alelievr&lt;/a&gt; for &lt;a href=&#34;https://github.com/alelievr/libft-unit-test&#34;&gt;libft-unit-test&lt;/a&gt; and &lt;a href=&#34;https://github.com/alelievr/printf-unit-test&#34;&gt;printf-unit-test&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To &lt;a href=&#34;https://github.com/cacharle&#34;&gt;cacharle&lt;/a&gt; for &lt;a href=&#34;https://github.com/cacharle/ft_printf_test&#34;&gt;ft_printf_test&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To &lt;a href=&#34;https://github.com/ombhd&#34;&gt;ombhd&lt;/a&gt; for &lt;a href=&#34;https://github.com/ombhd/Cleaner_42&#34;&gt;Cleaner_42&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To &lt;a href=&#34;https://github.com/arsalas&#34;&gt;arsalas&lt;/a&gt; for the help in the minitalk tester&lt;/li&gt; &#xA; &lt;li&gt;To &lt;a href=&#34;https://github.com/vfurmane&#34;&gt;vfurmane&lt;/a&gt; for &lt;a href=&#34;https://github.com/vfurmane/pipex-tester&#34;&gt;pipex-tester&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To &lt;a href=&#34;https://github.com/gmarcha&#34;&gt;gmarcha&lt;/a&gt; for &lt;a href=&#34;https://github.com/gmarcha/pipexMedic&#34;&gt;pipexMedic&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>