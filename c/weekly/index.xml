<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-03-30T01:42:40Z</updated>
  <subtitle>Weekly Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>GuijiAI/HeyGem.ai</title>
    <updated>2025-03-30T01:42:40Z</updated>
    <id>tag:github.com,2025-03-30:/GuijiAI/HeyGem.ai</id>
    <link href="https://github.com/GuijiAI/HeyGem.ai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Heygem - Open Source Alternative to Heygen &lt;a href=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.md&#34;&gt;【切换中文】&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;h2&gt;Version Update Notice&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Lite version is officially released, you can download it &lt;a href=&#34;https://github.com/GuijiAI/HeyGem.ai/releases/tag/v1.0.3-Lite&#34;&gt;here&lt;/a&gt;. If you want to experience the standard version (original version), you can click &lt;a href=&#34;https://github.com/GuijiAI/HeyGem.ai/releases/tag/v1.0.3&#34;&gt;here&lt;/a&gt; to download&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The Lite version can reduce two services heygem-tts / heygem-asr, reducing the installation size from 70GB to 13.5GB&lt;/li&gt; &#xA; &lt;li&gt;The Lite version customizes avatars and video generation faster&lt;/li&gt; &#xA; &lt;li&gt;The Lite version does not have text-to-video functionality, it can only generate videos by uploading audio&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Important Notice to Developer Partners&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dear Heygem Open Source Community Members:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;We sincerely thank you for your enthusiastic attention and active participation in the Heygem digital human open source project! We have noticed that some developers face challenges during local deployment. To better meet the needs of different scenarios, we are now announcing two parallel service solutions:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Project&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;HeyGem Open Source Local Deployment&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Digital Human/Clone Voice API Service&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Usage&lt;/td&gt; &#xA;   &lt;td&gt;Open Source Local Deployment&lt;/td&gt; &#xA;   &lt;td&gt;Rapid Clone API Service&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Recommended&lt;/td&gt; &#xA;   &lt;td&gt;Technical Users&lt;/td&gt; &#xA;   &lt;td&gt;Business Users&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Technical Threshold&lt;/td&gt; &#xA;   &lt;td&gt;Developers with deep learning framework experience/pursuing deep customization/wishing to participate in community co-construction&lt;/td&gt; &#xA;   &lt;td&gt;Quick business integration/focus on upper-level application development/need enterprise-level SLA assurance for commercial scenarios&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Hardware Requirements&lt;/td&gt; &#xA;   &lt;td&gt;Need to purchase GPU server&lt;/td&gt; &#xA;   &lt;td&gt;No need to purchase GPU server&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Customization&lt;/td&gt; &#xA;   &lt;td&gt;Can modify and extend the code according to your needs, fully controlling the software&#39;s functions and behavior&lt;/td&gt; &#xA;   &lt;td&gt;Cannot directly modify the source code, can only extend functions through API-provided interfaces, less flexible than open source projects&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Technical Support&lt;/td&gt; &#xA;   &lt;td&gt;Community Support&lt;/td&gt; &#xA;   &lt;td&gt;Dynamic expansion support + professional technical response team&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Maintenance Cost&lt;/td&gt; &#xA;   &lt;td&gt;High maintenance cost&lt;/td&gt; &#xA;   &lt;td&gt;Simple maintenance&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lip Sync Effect&lt;/td&gt; &#xA;   &lt;td&gt;Usable effect&lt;/td&gt; &#xA;   &lt;td&gt;Stunning and higher definition effect&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Commercial Authorization&lt;/td&gt; &#xA;   &lt;td&gt;Supports global free commercial use (enterprises with more than 100,000 users or annual revenue exceeding 10 million USD need to sign a commercial license agreement)&lt;/td&gt; &#xA;   &lt;td&gt;Commercial use allowed&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Iteration Speed&lt;/td&gt; &#xA;   &lt;td&gt;Slow updates, bug fixes depend on the community&lt;/td&gt; &#xA;   &lt;td&gt;Latest models/algorithms are prioritized, fast problem resolution&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;We always adhere to the open source spirit, and the launch of the API service aims to provide a more complete solution matrix for developers with different needs. No matter which method you choose, you can always obtain technical support documents through &lt;a href=&#34;mailto:James@toolwiz.com&#34;&gt;James@toolwiz.com&lt;/a&gt;. We look forward to working with you to promote the inclusive development of digital human technology!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Silicon-based Intelligent Developer Team&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/vKiBR85E7JyRkr6CxLCppA?mpshare=1&amp;amp;scene=1&amp;amp;srcid=0319sszkopZO6870sGsU0TFc&amp;amp;sharer_shareinfo=cac5ec3bfa62ed558552c7c022821613&amp;amp;sharer_shareinfo_first=cac5ec3bfa62ed558552c7c022821613&amp;amp;from=industrynews#rd&#34; target=&#34;_blank&#34;&gt;From scratch, hand-in-hand to teach you how to create your own HeyGem open source AI digital human!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://app.guiji.cn/platform&#34;&gt;&lt;strong&gt;Rapid Clone API&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://guiji.cn/digital-docs/introduce/&#34;&gt;&lt;strong&gt;API Documentation Center&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://app.guiji.cn/platform&#34;&gt;&lt;strong&gt;Real-time Interaction SDK&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://guiji.cn/duix-light-document/introduce/&#34;&gt;&lt;strong&gt;SDK Documentation Center&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/GuijiAI/duix.ai&#34;&gt;&lt;strong&gt;Local Real-time Interaction (realtime) duix.ai Open Source Address&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/GuijiAI/duix.ai/raw/main/duix-android/dh_aigc_android/README.md&#34;&gt;&lt;strong&gt;Android Version&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/GuijiAI/duix.ai/raw/main/duix-ios/GJLocalDigitalDemo/GJLocalDigitalSDK.md&#34;&gt;&lt;strong&gt;IOS Version&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/1CB5196D-C989-4577-8C57-DCBA3E0871B2-51277-000008CE6CF0B87a.jpg&#34; width=&#34;50%&#34;&gt; &#xA;&lt;h2&gt;Open Source Co-Creation · Shared Glory&lt;/h2&gt; &#xA;&lt;p&gt;Since we open-sourced Heygem, global geeks have illuminated the digital avatar matrix in the code universe, with each commit reconstructing the future! But joy is better shared than enjoyed alone—now we invite all experts to join the &#34;Open Source Co-Creation Plan,&#34; empowering everyone with AI creativity and propelling the Chinese AI fleet towards the stars!&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Co-Creation Content Direction&lt;/p&gt; &lt;p&gt;Share high-quality videos or articles on Heygem deployment tutorials, optimization guides, and practical cases (Bilibili, Douyin, Xiaohongshu, WeChat Official Accounts, Zhihu, etc.)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open Source Co-Creation Special Reward Pool (Real Cash Rewards!)&lt;/p&gt; &lt;p&gt;(1) Basic Rewards&lt;/p&gt; &lt;p&gt;Content receiving 20-100 likes will be awarded the [Heygem.ai Master Award] and a 20 RMB cash red envelope.&lt;/p&gt; &lt;p&gt;Content receiving 100+ likes will be awarded the [Heygem.ai God Award] and a 50 RMB cash red envelope.&lt;/p&gt; &lt;p&gt;(2) Special Achievements:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;The monthly MVP will unlock the Open Source Hall of Fame digital badge (permanently on-chain).&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Participation Method&lt;/p&gt; &lt;p&gt;Send your creativity to the customer service lady, add a friend with the note &#34;Name+999&#34;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/2025-03-20_14-38-00.jpg&#34; width=&#34;50%&#34;&gt; &#xA;&lt;h2&gt;Outstanding Co-Creation Works Exhibition&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1awQqYZEqB/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=618f44772c5dafb47317bb728505d79c&#34;&gt;HeyGem Digital Human One-Click Start, 8G Video Memory Available, Model Size 10G, No Need for 100G Hard Disk Space, No Need for D Drive, Based on Docker Single Image, Silicon-Based Open Source&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1ACQSYEErF/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=618f44772c5dafb47317bb728505d79c&#34;&gt;Ai Digital Human 16 - Local Deployment! The Most Popular Open Source Digital Human HeyGem Zero-Basis Hands-On Teaching Setup Tutorial, 20% Generation Stuck Solution, Full Simplified Process with Supporting Files - T8 ComfyUI Tutorial&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1R3QpYsEY6/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=618f44772c5dafb47317bb728505d79c&#34;&gt;Heygem Open Source Witnessed History! Cyber Worker Revolution!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1eWQ6YgEcp/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=618f44772c5dafb47317bb728505d79c&#34;&gt;Digital Human Project Heygem Local Deployment Tutorial&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://xhslink.com/a/rQPYqoDSRih8&#34;&gt;So Tempting! From Paid to Open Source, AI Digital Humans Will Open a New Era&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://xhslink.com/a/tX3p5V5tajh8&#34;&gt;Open Source Free Digital Humans Are Here, Unlimited Times, Fast Cloning&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://xhslink.com/a/8UT1kQ7vxjh8&#34;&gt;AI Digital Humans Are Free! GitHub&#39;s Hot Project Can Run on Your Computer&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1SkoCYpEwh/?share_source=copy_web&amp;amp;vd_source=c38dcdb72a68f2a4e0b3c0f4f9a5a03c&#34;&gt;The Most Popular Free AI Digital Human, HeyGem V1.0.3, Latest Update, One-Click Integration Package! Super Strong Lip-Sync Effect, Speed Up, Supports Long Videos, Batch Generation, 8G Video Memory Available!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1ZgovYGE3u/&#34;&gt;&lt;strong&gt;HeyGem One-Click Package Windows Direct Run Without Docker Silicon-Based Open Source Digital Human&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/image-20250304114114272.png&#34;&gt; &#xA;&lt;p&gt;Heygem is a fully offline video synthesis tool designed for Windows systems that can precisely clone your appearance and voice, digitalizing your image. You can create videos by driving virtual avatars through text and voice. No internet connection is required, protecting your privacy while enjoying convenient and efficient digital experiences.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Core Features &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Precise Appearance and Voice Cloning: Using advanced AI algorithms to capture human facial features with high precision, including facial features, contours, etc., to build realistic virtual models. It can also precisely clone voices, capturing and reproducing subtle characteristics of human voices, supporting various voice parameter settings to create highly similar cloning effects.&lt;/li&gt; &#xA;   &lt;li&gt;Text and Voice-Driven Virtual Avatars: Understanding text content through natural language processing technology, converting text into natural and fluent speech to drive virtual avatars. Voice input can also be used directly, allowing virtual avatars to perform corresponding actions and facial expressions based on the rhythm and intonation of the voice, making the virtual avatar&#39;s performance more natural and vivid.&lt;/li&gt; &#xA;   &lt;li&gt;Efficient Video Synthesis: Highly synchronizing digital human video images with sound, achieving natural and smooth lip-syncing, intelligently optimizing audio-video synchronization effects.&lt;/li&gt; &#xA;   &lt;li&gt;Multi-language Support: Scripts support eight languages - English, Japanese, Korean, Chinese, French, German, Arabic, and Spanish.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Key Advantages &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fully Offline Operation: No internet connection required, effectively protecting user privacy, allowing users to create in a secure, independent environment, avoiding potential data leaks during network transmission.&lt;/li&gt; &#xA;   &lt;li&gt;User-Friendly: Clean and intuitive interface, easy to use even for beginners with no technical background, quickly mastering the software&#39;s usage to start their digital human creation journey.&lt;/li&gt; &#xA;   &lt;li&gt;Multiple Model Support: Supports importing multiple models and managing them through one-click startup packages, making it convenient for users to choose suitable models based on different creative needs and application scenarios.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Technical Support &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Voice Cloning Technology: Using advanced technologies like artificial intelligence to generate similar or identical voices based on given voice samples, covering context, intonation, speed, and other aspects of speech.&lt;/li&gt; &#xA;   &lt;li&gt;Automatic Speech Recognition: Technology that converts human speech vocabulary content into computer-readable input (text format), enabling computers to &#34;understand&#34; human speech.&lt;/li&gt; &#xA;   &lt;li&gt;Computer Vision Technology: Used in video synthesis for visual processing, including facial recognition and lip movement analysis, ensuring virtual avatar lip movements match voice and text content.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Nodejs 18&lt;/li&gt; &#xA; &lt;li&gt;Docker Images &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;docker pull guiji2025/fun-asr&lt;/li&gt; &#xA;   &lt;li&gt;docker pull guiji2025/fish-speech-ziming&lt;/li&gt; &#xA;   &lt;li&gt;docker pull guiji2025/heygem.ai&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Windows Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Must have D Drive: Mainly used for storing digital human and project data&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Free space requirement: More than 30GB&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;C Drive: Used for storing service image files&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Free space requirement: More than 100GB&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;If less than 100GB is available, after installing Docker, you can choose a different disk folder with more than 100GB of remaining space at the location shown below.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/output.png&#34; alt=&#34;output&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;System Requirements:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Currently supports Windows 10 19042.1526 or higher&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Recommended Configuration:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;CPU: 13th Gen Intel Core i5-13400F&lt;/li&gt; &#xA;   &lt;li&gt;Memory: 32GB&lt;/li&gt; &#xA;   &lt;li&gt;Graphics Card: RTX 4070&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ensure you have an NVIDIA graphics card with properly installed drivers&lt;/p&gt; &lt;p&gt;NVIDIA driver download link: &lt;a href=&#34;https://www.nvidia.cn/drivers/lookup/&#34;&gt;https://www.nvidia.cn/drivers/lookup/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/nvidia.png&#34; alt=&#34;nvidia&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Installing Windows Docker&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Use the command &lt;code&gt;wsl --list --verbose&lt;/code&gt; to check if WSL is installed. If it shows as below, it&#39;s already installed and no further installation is needed.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/wsl-list.png&#34; alt=&#34;wsl-list&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;WSL installation command: &lt;code&gt;wsl --install&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;May fail due to network issues, try multiple times&lt;/li&gt; &#xA;  &lt;li&gt;During installation, you&#39;ll need to set and remember a new username and password&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Update WSL using &lt;code&gt;wsl --update&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/updatewsl.png&#34; alt=&#34;updatewsl&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.docker.com/&#34;&gt;Download Docker for Windows&lt;/a&gt;, choose the appropriate installation package based on your CPU architecture.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;When you see this interface, installation is successful.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/61eb4c19-3e7a-4791-a266-de4209690cbd.png&#34; alt=&#34;61eb4c19-3e7a-4791-a266-de4209690cbd&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run Docker&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/shortcut.png&#34; alt=&#34;shortcut&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Accept the agreement and skip login on first run&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/accept.png&#34; alt=&#34;accept&#34;&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/576746d5-5215-4973-b1ca-c8d7409a6403.png&#34; alt=&#34;576746d5-5215-4973-b1ca-c8d7409a6403&#34;&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/9a10b7b2-1eea-48c1-b7af-34129fe04446.png&#34; alt=&#34;9a10b7b2-1eea-48c1-b7af-34129fe04446&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Installing the Server&lt;/h3&gt; &#xA;&lt;p&gt;Installation using Docker, docker-compose as follows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;docker-compose.yml&lt;/code&gt; file is in the &lt;code&gt;/deploy&lt;/code&gt; directory.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Execute &lt;code&gt;docker-compose up -d&lt;/code&gt; in the &lt;code&gt;/deploy&lt;/code&gt; directory, &lt;u&gt;if you want to use the lite version, execute &lt;code&gt;docker-compose -f docker-compose-lite.yml up -d&lt;/code&gt;&lt;/u&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Wait patiently (about half an hour, speed depends on network), download will consume about 70GB of traffic, make sure to use WiFi&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;When you see three services in Docker, it indicates success&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/README_zh.assets/e29d1922-7c58-46b4-b1e9-961f853f26d4.png&#34; alt=&#34;e29d1922-7c58-46b4-b1e9-961f853f26d4&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Client&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Directly download the &lt;a href=&#34;https://github.com/GuijiAI/HeyGem.ai/releases&#34;&gt;officially built installation package&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Double-click &lt;code&gt;HeyGem-x.x.x-setup.exe&lt;/code&gt; to install&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Open APIs&lt;/h2&gt; &#xA;&lt;p&gt;We have opened APIs for model training and video synthesis. After Docker starts, several ports will be exposed locally, accessible through &lt;code&gt;http://127.0.0.1&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For specific code, refer to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;src/main/service/model.js&lt;/li&gt; &#xA; &lt;li&gt;src/main/service/video.js&lt;/li&gt; &#xA; &lt;li&gt;src/main/service/voice.js&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Model Training&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Separate video into silent video + audio&lt;/li&gt; &#xA; &lt;li&gt;Place audio in &lt;code&gt;D:\heygem_data\voice\data&lt;/code&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;&lt;code&gt;D:\heygem_data\voice\data&lt;/code&gt; is agreed with the &lt;code&gt;guiji2025/fish-speech-ziming&lt;/code&gt; service, can be modified in docker-compose&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt;Call the &lt;code&gt;http://127.0.0.1:18180/v1/preprocess_and_tran&lt;/code&gt; interface &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;Parameter example:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;format&#34;: &#34;.wav&#34;,&#xA;  &#34;reference_audio&#34;: &#34;xxxxxx/xxxxx.wav&#34;,&#xA;  &#34;lang&#34;: &#34;zh&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;Response example:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;asr_format_audio_url&#34;: &#34;xxxx/x/xxx/xxx.wav&#34;,&#xA;  &#34;reference_audio_text&#34;: &#34;xxxxxxxxxxxx&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;&lt;strong&gt;Record the response results as they will be needed for subsequent audio synthesis&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Audio Synthesis&lt;/h3&gt; &#xA;&lt;p&gt;Interface: &lt;code&gt;http://127.0.0.1:18180/v1/invoke&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;// Request parameters&#xA;{&#xA;  &#34;speaker&#34;: &#34;{uuid}&#34;, // A unique UUID&#xA;  &#34;text&#34;: &#34;xxxxxxxxxx&#34;, // Text content to synthesize&#xA;  &#34;format&#34;: &#34;wav&#34;, // Fixed parameter&#xA;  &#34;topP&#34;: 0.7, // Fixed parameter&#xA;  &#34;max_new_tokens&#34;: 1024, // Fixed parameter&#xA;  &#34;chunk_length&#34;: 100, // Fixed parameter&#xA;  &#34;repetition_penalty&#34;: 1.2, // Fixed parameter&#xA;  &#34;temperature&#34;: 0.7, // Fixed parameter&#xA;  &#34;need_asr&#34;: false, // Fixed parameter&#xA;  &#34;streaming&#34;: false, // Fixed parameter&#xA;  &#34;is_fixed_seed&#34;: 0, // Fixed parameter&#xA;  &#34;is_norm&#34;: 0, // Fixed parameter&#xA;  &#34;reference_audio&#34;: &#34;{voice.asr_format_audio_url}&#34;, // Return value from previous &#34;Model Training&#34; step&#xA;  &#34;reference_text&#34;: &#34;{voice.reference_audio_text}&#34; // Return value from previous &#34;Model Training&#34; step&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Video Synthesis&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Synthesis interface: &lt;code&gt;http://127.0.0.1:8383/easy/submit&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;// Request parameters&#xA;{&#xA;  &#34;audio_url&#34;: &#34;{audioPath}&#34;, // Audio path&#xA;  &#34;video_url&#34;: &#34;{videoPath}&#34;, // Video path&#xA;  &#34;code&#34;: &#34;{uuid}&#34;, // Unique key&#xA;  &#34;chaofen&#34;: 0, // Fixed value&#xA;  &#34;watermark_switch&#34;: 0, // Fixed value&#xA;  &#34;pn&#34;: 1 // Fixed value&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Progress query: &lt;code&gt;http://127.0.0.1:8383/easy/query?code=${taskCode}&lt;/code&gt;&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;GET request, the parameter &lt;code&gt;taskCode&lt;/code&gt; is the &lt;code&gt;code&lt;/code&gt; from the synthesis interface input above&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Self-Check Steps Before Asking Questions&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Check if all three services are in Running status&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/doc/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98.assets/e29d1922-7c58-46b4-b1e9-961f853f26d4.png&#34; alt=&#34;e29d1922-7c58-46b4-b1e9-961f853f26d4&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Confirm that your machine has an NVIDIA graphics card and drivers are correctly installed.&lt;/p&gt; &lt;p&gt;All computing power for this project is local. The three services won&#39;t start without an NVIDIA graphics card or proper drivers.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ensure both server and client are updated to the latest version. The project is newly open-sourced, the community is very active, and updates are frequent. Your issue might have been resolved in a new version.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Server: Go to &lt;code&gt;/deploy&lt;/code&gt; directory and re-execute &lt;code&gt;docker-compose up -d&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Client: &lt;code&gt;pull&lt;/code&gt; code and re-&lt;code&gt;build&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/GuijiAI/HeyGem.ai/issues&#34;&gt;GitHub Issues&lt;/a&gt; are continuously updated, issues are being resolved and closed daily. Check frequently, your issue might already be resolved.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Question Template&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Problem Description&lt;/p&gt; &lt;p&gt;Describe the reproduction steps in detail, with screenshots if possible.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Provide Error Logs&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;How to get client logs:&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/doc/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98.assets/image-20250308205954494.png&#34; alt=&#34;image-20250308205954494&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Server logs:&lt;/p&gt; &lt;p&gt;Find the key location, or click on our three Docker services, and &#34;Copy&#34; as shown below.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/doc/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98.assets/image-20250308215812201.png&#34; alt=&#34;image-20250308215812201&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contact Us&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;  James@toolwiz.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GuijiAI/HeyGem.ai/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ASR based on &lt;a href=&#34;https://github.com/modelscope/FunASR&#34;&gt;fun-asr&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TTS based on &lt;a href=&#34;https://github.com/fishaudio/fish-speech&#34;&gt;fish-speech-ziming&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.star-history.com/#GuijiAI/HeyGem.ai&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=GuijiAI/HeyGem.ai&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/Windows-driver-samples</title>
    <updated>2025-03-30T01:42:40Z</updated>
    <id>tag:github.com,2025-03-30:/microsoft/Windows-driver-samples</id>
    <link href="https://github.com/microsoft/Windows-driver-samples" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repo contains driver samples prepared for use with Microsoft Visual Studio and the Windows Driver Kit (WDK). It contains both Universal Windows Driver and desktop-only driver samples.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Driver samples for Windows 11&lt;/h1&gt; &#xA;&lt;p&gt;These are the official Microsoft Windows Driver Kit (WDK) driver code samples for Windows 11. They provide a foundation for Universal Windows driver support of all hardware form factors, from phones to desktop PCs. Use these samples with Visual Studio 2022 and Windows Driver Kit (WDK) 11.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/windows-hardware/drivers/&#34;&gt;Windows Driver Kit documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Windows 11 driver development&lt;/h2&gt; &#xA;&lt;p&gt;Use Visual Studio 2022 and Windows Driver Kit (WDK) 11 to build, test, and deploy your drivers. With Windows 11, the driver development environment is integrated into Visual Studio. To get started, download the driver development kits and tools for Windows 11.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://developer.microsoft.com/windows/hardware/windows-driver-kit&#34;&gt;Download the WDK, WinDbg, and associated tools&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Windows Driver Kit (WDK)&lt;/h3&gt; &#xA;&lt;p&gt;Take a look at the compilation of the new and changed driver-related content for Windows 11. Areas of improvement include camera, print, display, Near Field Communication (NFC), WLAN, Bluetooth, and more.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/windows-hardware/drivers/what-s-new-in-driver-development&#34;&gt;Find out what&#39;s new in the WDK&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Universal Windows drivers&lt;/h3&gt; &#xA;&lt;p&gt;Write one driver that runs on Windows 11 for desktop editions, as well as other Windows editions that share a common set of interfaces.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/windows-hardware/drivers/develop/getting-started-with-universal-drivers&#34;&gt;Getting Started with Universal Windows drivers&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Windows Driver Frameworks&lt;/h3&gt; &#xA;&lt;p&gt;The Windows Driver Frameworks (WDF) are a set of libraries that make it simple to write high-quality device drivers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/windows-hardware/drivers/wdf/&#34;&gt;WDF driver development guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Samples&lt;/h3&gt; &#xA;&lt;p&gt;Use the samples in this repo to guide your Windows driver development. Whether you&#39;re just getting started or porting an older driver to the newest version of Windows, code samples are valuable guides on how to write drivers.&lt;/p&gt; &#xA;&lt;p&gt;For information about important changes that need to be made to the WDK sample drivers before releasing device drivers based on the sample code, see the following topic:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/windows-hardware/drivers/gettingstarted/from-sample-code-to-production-driver&#34;&gt;From Sample Code to Production Driver - What to Change in the Samples&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Build your first driver&lt;/h3&gt; &#xA;&lt;p&gt;If you&#39;re writing your first driver, use these exercises to get started. Each exercise is independent of the others, so you can do them in any order.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/windows-hardware/drivers/gettingstarted/writing-a-umdf-driver-based-on-a-template&#34;&gt;Write a UMDF driver based on a template&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/windows-hardware/drivers/gettingstarted/writing-a-very-small-kmdf--driver&#34;&gt;Write a KMDF Hello World driver&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/windows-hardware/drivers/gettingstarted/writing-a-kmdf-driver-based-on-a-template&#34;&gt;Write a KMDF driver based on a template&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Windows-driver-samples/main/.github/Build-with-GitHub.md&#34;&gt;Use GitHub Actions to build a simple driver project&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Microsoft Code of Conduct&lt;/h1&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>bitaxeorg/ESP-Miner</title>
    <updated>2025-03-30T01:42:40Z</updated>
    <id>tag:github.com,2025-03-30:/bitaxeorg/ESP-Miner</id>
    <link href="https://github.com/bitaxeorg/ESP-Miner" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A bitcoin ASIC miner for the ESP32&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://discord.gg/3E8ca2dkcC&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/3E8ca2dkcC&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/skot/esp-miner/total&#34; alt=&#34;GitHub Downloads (all assets, all releases)&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/commit-activity/t/skot/esp-miner&#34; alt=&#34;GitHub commit activity&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/contributors/skot/esp-miner&#34; alt=&#34;GitHub contributors&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;ESP-Miner&lt;/h1&gt; &#xA;&lt;p&gt;esp-miner is open source ESP32 firmware for the &lt;a href=&#34;https://github.com/skot/bitaxe&#34;&gt;Bitaxe&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you are looking for premade images to load on your Bitaxe, check out the &lt;a href=&#34;https://github.com/skot/ESP-Miner/releases&#34;&gt;releases&lt;/a&gt; page. Maybe you want &lt;a href=&#34;https://github.com/skot/ESP-Miner/raw/master/flashing.md&#34;&gt;instructions&lt;/a&gt; for loading factory images.&lt;/p&gt; &#xA;&lt;h1&gt;Bitaxetool&lt;/h1&gt; &#xA;&lt;p&gt;We also have a command line python tool for flashing Bitaxe and updating the config called Bitaxetool&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bitaxetool Requires Python3.4 or later and pip&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Install bitaxetool from pip. pip is included with Python 3.4 but if you need to install it check &lt;a href=&#34;https://pip.pypa.io/en/stable/installation/&#34;&gt;https://pip.pypa.io/en/stable/installation/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install --upgrade bitaxetool&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The bitaxetool includes all necessary library for flashing the binaries to the Bitaxe Hardware.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Flash a &#34;factory&#34; image to a Bitaxe to reset to factory settings. Make sure to choose an image built for your hardware version (401) in this case:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;bitaxetool --firmware ./esp-miner-factory-401-v2.4.2.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Flash just the NVS config to a bitaxe:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;bitaxetool --config ./config-401.cvs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Flash both a factory image &lt;em&gt;and&lt;/em&gt; a config to your Bitaxe: note the settings in the config file will overwrite the config already baked into the factory image:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;bitaxetool --config ./config-401.cvs --firmware ./esp-miner-factory-401-v2.4.2.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;AxeOS API&lt;/h2&gt; &#xA;&lt;p&gt;The esp-miner UI is called AxeOS and provides an API to expose actions and information.&lt;/p&gt; &#xA;&lt;p&gt;For more details take a look at &lt;code&gt;main/http_server/http_server.c&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Things that can be done are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Get System Info&lt;/li&gt; &#xA; &lt;li&gt;Get Swarm Info&lt;/li&gt; &#xA; &lt;li&gt;Update Swarm&lt;/li&gt; &#xA; &lt;li&gt;Swarm Options&lt;/li&gt; &#xA; &lt;li&gt;System Restart Action&lt;/li&gt; &#xA; &lt;li&gt;Update System Settings Action&lt;/li&gt; &#xA; &lt;li&gt;System Options&lt;/li&gt; &#xA; &lt;li&gt;Update OTA Firmware&lt;/li&gt; &#xA; &lt;li&gt;Update OTA WWW&lt;/li&gt; &#xA; &lt;li&gt;WebSocket&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Some API examples in curl:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Get system information&#xA;curl http://YOUR-BITAXE-IP/api/system/info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Get swarm information&#xA;curl http://YOUR-BITAXE-IP/api/swarm/info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# System restart action&#xA;curl -X POST http://YOUR-BITAXE-IP/api/system/restart&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Administration&lt;/h2&gt; &#xA;&lt;p&gt;The firmware hosts a small web server on port 80 for administrative purposes. Once the Bitaxe device is connected to the local network, the admin web front end may be accessed via a web browser connected to the same network at &lt;code&gt;http://&amp;lt;IP&amp;gt;&lt;/code&gt;, replacing &lt;code&gt;IP&lt;/code&gt; with the LAN IP address of the Bitaxe device, or &lt;code&gt;http://bitaxe&lt;/code&gt;, provided your network supports mDNS configuration.&lt;/p&gt; &#xA;&lt;h3&gt;Recovery&lt;/h3&gt; &#xA;&lt;p&gt;In the event that the admin web front end is inaccessible, for example because of an unsuccessful firmware update (&lt;code&gt;www.bin&lt;/code&gt;), a recovery page can be accessed at &lt;code&gt;http://&amp;lt;IP&amp;gt;/recovery&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install the ESP-IDF toolchain from &lt;a href=&#34;https://docs.espressif.com/projects/esp-idf/en/stable/esp32/get-started/&#34;&gt;https://docs.espressif.com/projects/esp-idf/en/stable/esp32/get-started/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install nodejs/npm from &lt;a href=&#34;https://nodejs.org/en/download&#34;&gt;https://nodejs.org/en/download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;(Optional) Install the ESP-IDF extension for VSCode from &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=espressif.esp-idf-extension&#34;&gt;https://marketplace.visualstudio.com/items?itemName=espressif.esp-idf-extension&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Building&lt;/h3&gt; &#xA;&lt;p&gt;At the root of the repository, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;idf.py build &amp;amp;&amp;amp; ./merge_bin.sh ./esp-miner-merged.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: the merge_bin.sh script is a custom script that merges the bootloader, partition table, and the application binary into a single file.&lt;/p&gt; &#xA;&lt;p&gt;Note: if using VSCode, you may have to configure the settings.json file to match your esp hardware version. For example, if your bitaxe has something other than an esp32-s3, you will need to change the version in the &lt;code&gt;.vscode/settings.json&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;h3&gt;Flashing&lt;/h3&gt; &#xA;&lt;p&gt;With the bitaxe connected to your computer via USB, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bitaxetool --config ./config-xxx.cvs --firmware ./esp-miner-merged.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where xxx is the config file for your hardware version. You can see the list of available config files in the root of the repository.&lt;/p&gt; &#xA;&lt;p&gt;Note: if you are developing within a dev container, you will need to run the bitaxetool command from outside the container. Otherwise, you will get an error about the device not being found.&lt;/p&gt; &#xA;&lt;h2&gt;Attributions&lt;/h2&gt; &#xA;&lt;p&gt;The display font is Portfolio 6x8 from &lt;a href=&#34;https://int10h.org/oldschool-pc-fonts/&#34;&gt;https://int10h.org/oldschool-pc-fonts/&lt;/a&gt; by VileR.&lt;/p&gt;</summary>
  </entry>
</feed>