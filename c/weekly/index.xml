<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-17T01:42:21Z</updated>
  <subtitle>Weekly Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>tianocore/edk2</title>
    <updated>2024-03-17T01:42:21Z</updated>
    <id>tag:github.com,2024-03-17:/tianocore/edk2</id>
    <link href="https://github.com/tianocore/edk2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;EDK II&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;============== EDK II Project&lt;/h1&gt; &#xA;&lt;p&gt;A modern, feature-rich, cross-platform firmware development environment for the UEFI and PI specifications from &lt;a href=&#34;http://www.uefi.org&#34;&gt;www.uefi.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Core CI Build Status&lt;/h2&gt; &#xA;&lt;p&gt;============================= ================= =============== =================== Host Type &amp;amp; Toolchain Build Status Test Status Code Coverage ============================= ================= =============== =================== Windows_VS2019_ |WindowsCiBuild| |WindowsCiTest| |WindowsCiCoverage| Ubuntu_GCC5_ |UbuntuCiBuild| |UbuntuCiTest| |UbuntuCiCoverage| ============================= ================= =============== ===================&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;More CI Build information &amp;lt;.pytool/Readme.md&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;h2&gt;Platform CI Build Status&lt;/h2&gt; &#xA;&lt;p&gt;Microsoft Windows VS2019&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;============================= ================= ============= ============= ==============&#xA; Toolchain                    CONFIG            DEBUG         RELEASE       NOOPT&#xA;============================= ================= ============= ============= ==============&#xA;EmulatorPkg_Win_VS2019_       | IA32            |em32d|       |em32r|       |em32n|&#xA;|                             | X64             |em64d|       |em64r|       |em64n|&#xA;|                             | IA32 FULL       |em32fd|      |em32fr|      |em32fn|&#xA;|                             | X64 FULL        |em64fd|      |em64fr|      |em64fn|&#xA;OvmfPkg_Win_VS2019_           | IA32            |op32d|       |op32r|       |op32n|&#xA;|                             | X64             |op64d|       |op64r|       |op64n|&#xA;|                             | IA32 X64        |op3264d|     |op3264r|     |op3264n|&#xA;|                             | IA32 X64 FULL   |op3264fd|    |op3264fr|    |op3264fn|&#xA;============================= ================= ============= ============= ==============&#xA;&#xA;Ubuntu 18.04 GCC5&#xA;`````````````````&#xA;&#xA;============================= ================= ============= ============= ==============&#xA; Toolchain                    CONFIG            DEBUG         RELEASE       NOOPT&#xA;============================= ================= ============= ============= ==============&#xA;ArmVirtPkg_Ubuntu_GCC5_       | AARCH64         |avAArch64du| |avAArch64ru| |avAArch64nu|&#xA;|                             | ARM             |avArmdu|     |avArmru|     |avArmnu|&#xA;EmulatorPkg_Ubuntu_GCC5_      | IA32            |em32du|      |em32ru|      |em32nu|&#xA;|                             | X64             |em64du|      |em64ru|      |em64nu|&#xA;|                             | IA32 FULL       |em32fdu|     |em32fru|     |em32fnu|&#xA;|                             | X64 FULL        |em64fdu|     |em64fru|     |em64fnu|&#xA;OvmfPkg_Ubuntu_GCC5_          | IA32            |op32du|      |op32ru|      |op32nu|&#xA;|                             | X64             |op64du|      |op64ru|      |op64nu|&#xA;|                             | IA32 X64        |op3264du|    |op3264ru|    |op3264nu|&#xA;|                             | IA32 X64 FULL   |op3264fdu|   |op3264fru|   |op3264fru|&#xA;============================= ================= ============= ============= ==============&#xA;&#xA;|TCBZ_2668|_ - EmulatorPkg Ubuntu GCC5 Segfaults during execution.&#xA;&#xA;|TCBZ_2639|_ - EmulatorPkg Ubuntu GCC5 Segfaults during execution.&#xA;&#xA;`More ArmVirtPkg CI Build Information &amp;lt;ArmVirtPkg/PlatformCI/ReadMe.md&amp;gt;`__&#xA;&#xA;`More EmulatorPkg CI Build Information &amp;lt;EmulatorPkg/PlatformCI/ReadMe.md&amp;gt;`__&#xA;&#xA;`More OvmfPkg CI Build Information &amp;lt;OvmfPkg/PlatformCI/ReadMe.md&amp;gt;`__&#xA;&#xA;&#xA;License Details&#xA;---------------&#xA;&#xA;The majority of the content in the EDK II open source project uses a&#xA;`BSD-2-Clause Plus Patent License &amp;lt;License.txt&amp;gt;`__. The EDK II open&#xA;source project contains the following components that are covered by additional&#xA;licenses:&#xA;&#xA;-  `BaseTools/Plugin/CodeQL/analyze &amp;lt;https://www.apache.org/licenses/LICENSE-2.0&amp;gt;`__&#xA;-  `BaseTools/Source/C/LzmaCompress &amp;lt;BaseTools/Source/C/LzmaCompress/LZMA-SDK-README.txt&amp;gt;`__&#xA;-  `BaseTools/Source/C/VfrCompile/Pccts &amp;lt;BaseTools/Source/C/VfrCompile/Pccts/RIGHTS&amp;gt;`__&#xA;-  `CryptoPkg\Library\BaseCryptLib\SysCall\inet_pton.c &amp;lt;CryptoPkg\Library\BaseCryptLib\SysCall\inet_pton.c&amp;gt;`__&#xA;-  `CryptoPkg\Library\Include\crypto\dso_conf.h &amp;lt;https://github.com/openssl/openssl/blob/e2e09d9fba1187f8d6aafaa34d4172f56f1ffb72/LICENSE&amp;gt;`__&#xA;-  `CryptoPkg\Library\Include\openssl\opensslconf.h &amp;lt;https://github.com/openssl/openssl/blob/e2e09d9fba1187f8d6aafaa34d4172f56f1ffb72/LICENSE&amp;gt;`__&#xA;-  `EmbeddedPkg/Library/FdtLib &amp;lt;EmbeddedPkg/Library/FdtLib/fdt.c&amp;gt;`__.  (EDK II uses BSD License)&#xA;-  `EmbeddedPkg/Include/fdt.h &amp;lt;EmbeddedPkg/Include/fdt.h&amp;gt;`__.  (EDK II uses BSD Licence)&#xA;-  `EmbeddedPkg/Include/libfdt.h &amp;lt;EmbeddedPkg/Include/libfdt.h&amp;gt;`__.  (EDK II uses BSD License)&#xA;-  `MdeModulePkg/Library/LzmaCustomDecompressLib &amp;lt;MdeModulePkg/Library/LzmaCustomDecompressLib/LZMA-SDK-README.txt&amp;gt;`__&#xA;-  `OvmfPkg &amp;lt;OvmfPkg/License.txt&amp;gt;`__&#xA;&#xA;The EDK II open source project uses content from upstream projects as git submodules&#xA;that are covered by additional licenses.&#xA;&#xA;-  `ArmPkg/Library/ArmSoftFloatLib/berkeley-softfloat-3 &amp;lt;https://github.com/ucb-bar/berkeley-softfloat-3/blob/b64af41c3276f97f0e181920400ee056b9c88037/COPYING.txt&amp;gt;`__&#xA;-  `BaseTools/Source/C/BrotliCompress/brotli &amp;lt;https://github.com/google/brotli/blob/666c3280cc11dc433c303d79a83d4ffbdd12cc8d/LICENSE&amp;gt;`__&#xA;-  `CryptoPkg/Library/OpensslLib/openssl &amp;lt;https://github.com/openssl/openssl/blob/e2e09d9fba1187f8d6aafaa34d4172f56f1ffb72/LICENSE&amp;gt;`__&#xA;-  `MdeModulePkg/Library/BrotliCustomDecompressLib/brotli &amp;lt;https://github.com/google/brotli/blob/666c3280cc11dc433c303d79a83d4ffbdd12cc8d/LICENSE&amp;gt;`__&#xA;-  `MdeModulePkg/Universal/RegularExpressionDxe/oniguruma &amp;lt;https://github.com/kkos/oniguruma/blob/abfc8ff81df4067f309032467785e06975678f0d/COPYING&amp;gt;`__&#xA;-  `UnitTestFrameworkPkg/Library/CmockaLib/cmocka &amp;lt;https://github.com/tianocore/edk2-cmocka/blob/f5e2cd77c88d9f792562888d2b70c5a396bfbf7a/COPYING&amp;gt;`__&#xA;-  `UnitTestFrameworkPkg/Library/GoogleTestLib/googletest &amp;lt;https://github.com/google/googletest/blob/86add13493e5c881d7e4ba77fb91c1f57752b3a4/LICENSE&amp;gt;`__&#xA;-  `UnitTestFrameworkPkg/Library/SubhookLib/subhook &amp;lt;https://github.com/Zeex/subhook/blob/83d4e1ebef3588fae48b69a7352cc21801cb70bc/LICENSE.txt&amp;gt;`__&#xA;-  `RedfishPkg/Library/JsonLib/jansson &amp;lt;https://github.com/akheron/jansson/blob/2882ead5bb90cf12a01b07b2c2361e24960fae02/LICENSE&amp;gt;`__&#xA;-  `MdePkg/Library/BaseFdtLib/libfdt &amp;lt;https://github.com/devicetree-org/pylibfdt/blob/f39368a217496d32c4091a2dba4045b60649e3a5/BSD-2-Clause&amp;gt;`__&#xA;-  `MdePkg/Library/MipiSysTLib/mipisyst &amp;lt;https://github.com/MIPI-Alliance/public-mipi-sys-t/blob/aae857d0d05ac65152ed24992a4acd834a0a107c/LICENSE&amp;gt;`__&#xA;&#xA;The EDK II Project is composed of packages. The maintainers for each package&#xA;are listed in `Maintainers.txt &amp;lt;Maintainers.txt&amp;gt;`__.&#xA;&#xA;Resources&#xA;---------&#xA;&#xA;-  `TianoCore &amp;lt;http://www.tianocore.org&amp;gt;`__&#xA;-  `EDK&#xA;   II &amp;lt;https://github.com/tianocore/tianocore.github.io/wiki/EDK-II&amp;gt;`__&#xA;-  `Getting Started with EDK&#xA;   II &amp;lt;https://github.com/tianocore/tianocore.github.io/wiki/Getting-Started-with-EDK-II&amp;gt;`__&#xA;-  `Mailing&#xA;   Lists &amp;lt;https://github.com/tianocore/tianocore.github.io/wiki/Mailing-Lists&amp;gt;`__&#xA;-  `TianoCore Bugzilla &amp;lt;https://bugzilla.tianocore.org&amp;gt;`__&#xA;-  `How To&#xA;   Contribute &amp;lt;https://github.com/tianocore/tianocore.github.io/wiki/How-To-Contribute&amp;gt;`__&#xA;-  `Release&#xA;   Planning &amp;lt;https://github.com/tianocore/tianocore.github.io/wiki/EDK-II-Release-Planning&amp;gt;`__&#xA;&#xA;Code Contributions&#xA;------------------&#xA;&#xA;To make a contribution to a TianoCore project, follow these steps.&#xA;&#xA;#. Create a change description in the format specified below to&#xA;    use in the source control commit log.&#xA;#. Your commit message must include your ``Signed-off-by`` signature&#xA;#. Submit your code to the TianoCore project using the process&#xA;    that the project documents on its web page. If the process is&#xA;    not documented, then submit the code on development email list&#xA;    for the project.&#xA;#. It is preferred that contributions are submitted using the same&#xA;    copyright license as the base project. When that is not possible,&#xA;    then contributions using the following licenses can be accepted:&#xA;&#xA;-  Apache License, Version 2.0: https://opensource.org/license/apache-2-0/&#xA;-  BSD (2-clause): https://opensource.org/license/BSD-2-Clause&#xA;-  BSD (3-clause): https://opensource.org/license/BSD-3-Clause&#xA;-  MIT: https://opensource.org/license/MIT&#xA;-  Python-2.0: https://opensource.org/license/Python-2.0&#xA;-  Zlib: https://opensource.org/license/Zlib&#xA;&#xA;For documentation:&#xA;&#xA;-  FreeBSD Documentation License&#xA;    https://www.freebsd.org/copyright/freebsd-doc-license.html&#xA;&#xA;Contributions of code put into the public domain can also be accepted.&#xA;&#xA;Contributions using other licenses might be accepted, but further&#xA;review will be required.&#xA;&#xA;Developer Certificate of Origin&#xA;-------------------------------&#xA;&#xA;Your change description should use the standard format for a&#xA;commit message, and must include your ``Signed-off-by`` signature.&#xA;&#xA;In order to keep track of who did what, all patches contributed must&#xA;include a statement that to the best of the contributor&#39;s knowledge&#xA;they have the right to contribute it under the specified license.&#xA;&#xA;The test for this is as specified in the `Developer&#39;s Certificate of&#xA;Origin (DCO) 1.1 &amp;lt;https://developercertificate.org/&amp;gt;`__. The contributor&#xA;certifies compliance by adding a line saying&#xA;&#xA;Signed-off-by: Developer Name developer@example.org&#xA;&#xA;where ``Developer Name`` is the contributor&#39;s real name, and the email&#xA;address is one the developer is reachable through at the time of&#xA;contributing.&#xA;&#xA;::&#xA;&#xA;    Developer&#39;s Certificate of Origin 1.1&#xA;&#xA;    By making a contribution to this project, I certify that:&#xA;&#xA;    (a) The contribution was created in whole or in part by me and I&#xA;        have the right to submit it under the open source license&#xA;        indicated in the file; or&#xA;&#xA;    (b) The contribution is based upon previous work that, to the best&#xA;        of my knowledge, is covered under an appropriate open source&#xA;        license and I have the right under that license to submit that&#xA;        work with modifications, whether created in whole or in part&#xA;        by me, under the same open source license (unless I am&#xA;        permitted to submit under a different license), as indicated&#xA;        in the file; or&#xA;&#xA;    (c) The contribution was provided directly to me by some other&#xA;        person who certified (a), (b) or (c) and I have not modified&#xA;        it.&#xA;&#xA;    (d) I understand and agree that this project and the contribution&#xA;        are public and that a record of the contribution (including all&#xA;        personal information I submit with it, including my sign-off) is&#xA;        maintained indefinitely and may be redistributed consistent with&#xA;        this project or the open source license(s) involved.&#xA;&#xA;Sample Change Description / Commit Message&#xA;------------------------------------------&#xA;&#xA;::&#xA;&#xA;    From: Contributor Name &amp;lt;contributor@example.com&amp;gt;&#xA;    Subject: [Repository/Branch PATCH] Pkg-Module: Brief-single-line-summary&#xA;&#xA;    Full-commit-message&#xA;&#xA;    Signed-off-by: Contributor Name &amp;lt;contributor@example.com&amp;gt;&#xA;&#xA;Notes for sample patch email&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The first line of commit message is taken from the email&#39;s subject line following &lt;code&gt;[Repository/Branch PATCH]&lt;/code&gt;. The remaining portion of the commit message is the email&#39;s content.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;git format-patch&lt;/code&gt; is one way to create this format&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Definitions for sample patch email&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;-  ``Repository`` is the identifier of the repository the patch applies.&#xA;    This identifier should only be provided for repositories other than&#xA;    ``edk2``. For example ``edk2-BuildSpecification`` or ``staging``.&#xA;-  ``Branch`` is the identifier of the branch the patch applies. This&#xA;    identifier should only be provided for branches other than&#xA;   ``edk2/master``.&#xA;    For example ``edk2/UDK2015``,&#xA;   ``edk2-BuildSpecification/release/1.27``, or&#xA;    ``staging/edk2-test``.&#xA;-  ``Module`` is a short identifier for the affected code or&#xA;   documentation. For example ``MdePkg``, ``MdeModulePkg/UsbBusDxe``, ``Introduction``, or&#xA;    ``EDK II INF File Format``.&#xA;-  ``Brief-single-line-summary`` is a short summary of the change.&#xA;-  The entire first line should be less than ~70 characters.&#xA;-  ``Full-commit-message`` a verbose multiple line comment describing&#xA;    the change. Each line should be less than ~70 characters.&#xA;-  ``Signed-off-by`` is the contributor&#39;s signature identifying them&#xA;    by their real/legal name and their email address.&#xA;&#xA;Submodules&#xA;----------&#xA;&#xA;The current submodules used in EDK II are in `.gitmodules &amp;lt;.gitmodules&amp;gt;`__.&#xA;&#xA;To get a full, buildable EDK II repository, use following steps of git&#xA;command&#xA;&#xA;.. code-block:: bash&#xA;&#xA;  git clone https://github.com/tianocore/edk2.git&#xA;  cd edk2&#xA;  git submodule update --init&#xA;  cd ..&#xA;&#xA;If there&#39;s update for submodules, use following git commands to get&#xA;the latest submodules code.&#xA;&#xA;.. code-block:: bash&#xA;&#xA;  cd edk2&#xA;  git pull&#xA;  git submodule update&#xA;&#xA;Note: When cloning submodule repos, &#39;--recursive&#39; option is not&#xA;recommended. EDK II itself will not use any code/feature from&#xA;submodules in above submodules. So using &#39;--recursive&#39; adds a&#xA;dependency on being able to reach servers we do not actually want&#xA;any code from, as well as needlessly downloading code we will not&#xA;use.&#xA;&#xA;**Submodule Notes**&#xA;&#xA;ArmSoftFloatLib is required by OpensslLib. It&#39;s inevitable in openssl-1.1.1&#xA;(since stable201905) for floating point parameter conversion, but should be&#xA;dropped once there&#39;s no such need in future release of openssl.&#xA;&#xA;.. ===================================================================&#xA;.. This is a bunch of directives to make the README file more readable&#xA;.. ===================================================================&#xA;&#xA;.. CoreCI&#xA;&#xA;.. _Windows_VS2019: https://dev.azure.com/tianocore/edk2-ci/_build/latest?definitionId=32&amp;amp;branchName=master&#xA;.. |WindowsCiBuild| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/Windows%20VS2019%20CI?branchName=master&#xA;.. |WindowsCiTest| image:: https://img.shields.io/azure-devops/tests/tianocore/edk2-ci/32.svg&#xA;.. |WindowsCiCoverage| image:: https://img.shields.io/badge/coverage-coming_soon-blue&#xA;&#xA;.. _Ubuntu_GCC5: https://dev.azure.com/tianocore/edk2-ci/_build/latest?definitionId=31&amp;amp;branchName=master&#xA;.. |UbuntuCiBuild| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/Ubuntu%20GCC5%20CI?branchName=master&#xA;.. |UbuntuCiTest| image:: https://img.shields.io/azure-devops/tests/tianocore/edk2-ci/31.svg&#xA;.. |UbuntuCiCoverage| image:: https://img.shields.io/badge/coverage-coming_soon-blue&#xA;&#xA;.. ArmVirtPkg&#xA;&#xA;.. _ArmVirtPkg_Ubuntu_GCC5: https://dev.azure.com/tianocore/edk2-ci/_build/latest?definitionId=46&amp;amp;branchName=master&#xA;.. |avAArch64du| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_ArmVirtPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20QEMU_AARCH64_DEBUG&#xA;.. |avAArch64ru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_ArmVirtPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20QEMU_AARCH64_RELEASE&#xA;.. |avAArch64nu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_ArmVirtPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20QEMU_AARCH64_NOOPT&#xA;&#xA;.. |avArmdu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_ArmVirtPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20QEMU_ARM_DEBUG&#xA;.. |avArmru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_ArmVirtPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20QEMU_ARM_RELEASE&#xA;.. |avArmnu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_ArmVirtPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20QEMU_ARM_NOOPT&#xA;&#xA;.. EmulatorPkg&#xA;&#xA;.. |TCBZ_2668| image:: https://img.shields.io/bugzilla/2668?baseUrl=https%3A%2F%2Fbugzilla.tianocore.org&#xA;.. _TCBZ_2668: https://bugzilla.tianocore.org/show_bug.cgi?id=2668&#xA;&#xA;.. |TCBZ_2639| image:: https://img.shields.io/bugzilla/2639?baseUrl=https%3A%2F%2Fbugzilla.tianocore.org&#xA;.. _TCBZ_2639: https://bugzilla.tianocore.org/show_bug.cgi?id=2639&#xA;&#xA;.. _EmulatorPkg_Win_VS2019:  https://dev.azure.com/tianocore/edk2-ci/_build/latest?definitionId=44&amp;amp;branchName=master&#xA;.. _EmulatorPkg_Ubuntu_GCC5: https://dev.azure.com/tianocore/edk2-ci/_build/latest?definitionId=43&amp;amp;branchName=master&#xA;&#xA;.. |em32d| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_DEBUG&#xA;.. |em32du| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_DEBUG&#xA;.. |em32r| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_RELEASE&#xA;.. |em32ru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_RELEASE&#xA;.. |em32n| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_NOOPT&#xA;.. |em32nu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_NOOPT&#xA;&#xA;.. |em32fd| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_FULL_DEBUG&#xA;.. |em32fdu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_FULL_DEBUG&#xA;.. |em32fr| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_FULL_RELEASE&#xA;.. |em32fru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_FULL_RELEASE&#xA;.. |em32fn| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_FULL_NOOPT&#xA;.. |em32fnu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_IA32_FULL_NOOPT&#xA;&#xA;.. |em64d| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_DEBUG&#xA;.. |em64du| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_DEBUG&#xA;.. |em64r| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_RELEASE&#xA;.. |em64ru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_RELEASE&#xA;.. |em64n| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_NOOPT&#xA;.. |em64nu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_NOOPT&#xA;&#xA;.. |em64fd| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_FULL_DEBUG&#xA;.. |em64fdu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_FULL_DEBUG&#xA;.. |em64fr| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_FULL_RELEASE&#xA;.. |em64fru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_FULL_RELEASE&#xA;.. |em64fn| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_FULL_NOOPT&#xA;.. |em64fnu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_EmulatorPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20EmulatorPkg_X64_FULL_NOOPT&#xA;&#xA;.. OvmfPkg&#xA;&#xA;.. |TCBZ_2661| image:: https://img.shields.io/bugzilla/2661?baseUrl=https%3A%2F%2Fbugzilla.tianocore.org&#xA;.. _TCBZ_2661: https://bugzilla.tianocore.org/show_bug.cgi?id=2661&#xA;&#xA;.. _OvmfPkg_Win_VS2019:  https://dev.azure.com/tianocore/edk2-ci/_build/latest?definitionId=50&amp;amp;branchName=master&#xA;.. _OvmfPkg_Ubuntu_GCC5: https://dev.azure.com/tianocore/edk2-ci/_build/latest?definitionId=48&amp;amp;branchName=master&#xA;&#xA;.. |op32d| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32_DEBUG&#xA;.. |op32du| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32_DEBUG&#xA;.. |op32r| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32_RELEASE&#xA;.. |op32ru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32_RELEASE&#xA;.. |op32n| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32_NOOPT&#xA;.. |op32nu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32_NOOPT&#xA;&#xA;.. |op64d| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_X64_DEBUG&#xA;.. |op64du| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_X64_DEBUG&#xA;.. |op64r| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_X64_RELEASE&#xA;.. |op64ru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_X64_RELEASE&#xA;.. |op64n| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_X64_NOOPT&#xA;.. |op64nu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_X64_NOOPT&#xA;&#xA;&#xA;.. |op3264d| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_DEBUG&#xA;.. |op3264du| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_DEBUG&#xA;.. |op3264r| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_RELEASE&#xA;.. |op3264ru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_RELEASE&#xA;.. |op3264n| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_NOOPT&#xA;.. |op3264nu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_NOOPT&#xA;&#xA;.. |op3264fd| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_FULL_DEBUG&#xA;.. |op3264fdu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_FULL_DEBUG&#xA;.. |op3264fr| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Windows_VS2019_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_FULL_RELEASE&#xA;.. |op3264fru| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_FULL_RELEASE&#xA;.. |op3264fn| replace:: |TCBZ_2661|_&#xA;.. |op3264fnu| image:: https://dev.azure.com/tianocore/edk2-ci/_apis/build/status/PlatformCI_OvmfPkg_Ubuntu_GCC5_CI?branchName=master&amp;amp;jobName=Platform_CI&amp;amp;configuration=Platform_CI%20OVMF_IA32X64_FULL_NOOPT&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>greenplum-db/gpdb</title>
    <updated>2024-03-17T01:42:21Z</updated>
    <id>tag:github.com,2024-03-17:/greenplum-db/gpdb</id>
    <link href="https://github.com/greenplum-db/gpdb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Greenplum Database - Massively Parallel PostgreSQL for Analytics. An open-source massively parallel data platform for analytics, machine learning and AI.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;Concourse Pipeline&lt;/strong&gt; &lt;a href=&#34;https://prod.ci.gpdb.pivotal.io/teams/main/pipelines/gpdb_main&#34;&gt;&lt;img src=&#34;https://prod.ci.gpdb.pivotal.io/api/v1/teams/main/pipelines/gpdb_main/badge&#34; alt=&#34;Concourse Build Status&#34;&gt;&lt;/a&gt; | &lt;strong&gt;Travis Build&lt;/strong&gt; &lt;a href=&#34;https://travis-ci.org/greenplum-db/gpdb&#34;&gt;&lt;img src=&#34;https://travis-ci.org/greenplum-db/gpdb.svg?branch=main&#34; alt=&#34;Travis Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/greenplum-db/gpdb/main/logo-greenplum.svg?sanitize=true&#34; alt=&#34;Greenplum&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Greenplum Database (GPDB) is an advanced, fully featured, open source data warehouse, based on PostgreSQL. It provides powerful and rapid analytics on petabyte scale data volumes. Uniquely geared toward big data analytics, Greenplum Database is powered by the worldâ€™s most advanced cost-based query optimizer delivering high analytical query performance on large data volumes.&lt;/p&gt; &#xA;&lt;p&gt;The Greenplum project is released under the &lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache 2 license&lt;/a&gt;. We want to thank all our past and present community contributors and are really interested in all new potential contributions. For the Greenplum Database community no contribution is too small, we encourage all types of contributions.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;A Greenplum cluster consists of a &lt;strong&gt;coordinator&lt;/strong&gt; server, and multiple &lt;strong&gt;segment&lt;/strong&gt; servers. All user data resides in the segments, the coordinator contains only metadata. The coordinator server, and all the segments, share the same schema.&lt;/p&gt; &#xA;&lt;p&gt;Users always connect to the coordinator server, which divides up the query into fragments that are executed in the segments, and collects the results.&lt;/p&gt; &#xA;&lt;p&gt;More information can be found on the &lt;a href=&#34;https://greenplum.org/&#34;&gt;project website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Building Greenplum Database with GPORCA&lt;/h2&gt; &#xA;&lt;p&gt;GPORCA is a cost-based optimizer which is used by Greenplum Database in conjunction with the PostgreSQL planner. It is also known as just ORCA, and Pivotal Optimizer. The code for GPORCA resides src/backend/gporca. It is built automatically by default.&lt;/p&gt; &#xA;&lt;h3&gt;Installing dependencies (for macOS developers)&lt;/h3&gt; &#xA;&lt;p&gt;Follow &lt;a href=&#34;https://raw.githubusercontent.com/greenplum-db/gpdb/main/README.macOS.md&#34;&gt;these macOS steps&lt;/a&gt; for getting your system ready for GPDB&lt;/p&gt; &#xA;&lt;h3&gt;Installing dependencies (for Linux developers)&lt;/h3&gt; &#xA;&lt;p&gt;Follow &lt;a href=&#34;https://raw.githubusercontent.com/greenplum-db/gpdb/main/README.Linux.md&#34;&gt;appropriate linux steps&lt;/a&gt; for getting your system ready for GPDB&lt;/p&gt; &#xA;&lt;h3&gt;Build the database&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Initialize and update submodules in the repository&#xA;git submodule update --init&#xA;&#xA;# Configure build environment to install at /usr/local/gpdb&#xA;./configure --with-perl --with-python --with-libxml --with-gssapi --prefix=/usr/local/gpdb&#xA;&#xA;# Compile and install&#xA;make -j8&#xA;make -j8 install&#xA;&#xA;# Bring in greenplum environment into your running shell&#xA;source /usr/local/gpdb/greenplum_path.sh&#xA;&#xA;# Start demo cluster&#xA;make create-demo-cluster&#xA;# (gpdemo-env.sh contains __PGPORT__ and __COORDINATOR_DATA_DIRECTORY__ values)&#xA;source gpAux/gpdemo/gpdemo-env.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The directory, the TCP ports, the number of segments, and the existence of standbys for segments and coordinator for the demo cluster can be changed on the fly. Instead of &lt;code&gt;make create-demo-cluster&lt;/code&gt;, consider:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;DATADIRS=/tmp/gpdb-cluster PORT_BASE=5555 NUM_PRIMARY_MIRROR_PAIRS=1 WITH_MIRRORS=false make create-demo-cluster&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The TCP port for the regression test can be changed on the fly:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PGPORT=5555 make installcheck-world&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To turn GPORCA off and use Postgres planner for query optimization:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;set optimizer=off;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to clean all generated files&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make distclean&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running tests&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The default regression tests&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;make installcheck-world&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The top-level target &lt;strong&gt;installcheck-world&lt;/strong&gt; will run all regression tests in GPDB against the running cluster. For testing individual parts, the respective targets can be run separately.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The PostgreSQL &lt;strong&gt;check&lt;/strong&gt; target does not work. Setting up a Greenplum cluster is more complicated than a single-node PostgreSQL installation, and no-one&#39;s done the work to have &lt;strong&gt;make check&lt;/strong&gt; create a cluster. Create a cluster manually or use gpAux/gpdemo/ (example below) and run the toplevel &lt;strong&gt;make installcheck-world&lt;/strong&gt; against that. Patches are welcome!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The PostgreSQL &lt;strong&gt;installcheck&lt;/strong&gt; target does not work either, because some tests are known to fail with Greenplum. The &lt;strong&gt;installcheck-good&lt;/strong&gt; schedule in &lt;strong&gt;src/test/regress&lt;/strong&gt; excludes those tests.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;When adding a new test, please add it to one of the GPDB-specific tests, in greenplum_schedule, rather than the PostgreSQL tests inherited from the upstream. We try to keep the upstream tests identical to the upstream versions, to make merging with newer PostgreSQL releases easier.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Alternative Configurations&lt;/h2&gt; &#xA;&lt;h3&gt;Building GPDB without GPORCA&lt;/h3&gt; &#xA;&lt;p&gt;Currently, GPDB is built with GPORCA by default. If you want to build GPDB without GPORCA, configure requires &lt;code&gt;--disable-orca&lt;/code&gt; flag to be set.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Clean environment&#xA;make distclean&#xA;&#xA;# Configure build environment to install at /usr/local/gpdb&#xA;./configure --disable-orca --with-perl --with-python --with-libxml --prefix=/usr/local/gpdb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Building GPDB with Python3 enabled&lt;/h3&gt; &#xA;&lt;p&gt;GPDB supports Python3 with plpython3u UDF&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/greenplum-db/gpdb/main/src/pl/plpython/README.md&#34;&gt;how to enable Python3&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h3&gt;Building GPDB client tools on Windows&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/greenplum-db/gpdb/main/README.Windows.md&#34;&gt;Building GPDB client tools on Windows&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Development with Vagrant&lt;/h2&gt; &#xA;&lt;p&gt;There is a Vagrant-based &lt;a href=&#34;https://raw.githubusercontent.com/greenplum-db/gpdb/main/src/tools/vagrant/README.md&#34;&gt;quickstart guide for developers&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Code layout&lt;/h2&gt; &#xA;&lt;p&gt;The directory layout of the repository follows the same general layout as upstream PostgreSQL. There are changes compared to PostgreSQL throughout the codebase, but a few larger additions worth noting:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;gpMgmt/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Contains Greenplum-specific command-line tools for managing the cluster. Scripts like gpinit, gpstart, gpstop live here. They are mostly written in Python.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;gpAux/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Contains Greenplum-specific release management scripts, and vendored dependencies. Some additional directories are submodules and will be made available over time.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;gpcontrib/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Much like the PostgreSQL contrib/ directory, this directory contains extensions such as gpfdist which are Greenplum-specific.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;doc/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;In PostgreSQL, the user manual lives here. In Greenplum, the user manual is maintained separately and only the reference pages used to build man pages are here.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;gpdb-doc/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Contains the Greenplum documentation in DITA XML format. Refer to &lt;code&gt;gpdb-doc/README.md&lt;/code&gt; for information on how to build, and work with the documentation.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ci/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Contains configuration files for the GPDB continuous integration system.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;src/backend/cdb/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Contains larger Greenplum-specific backend modules. For example, communication between segments, turning plans into parallelizable plans, mirroring, distributed transaction and snapshot management, etc. &lt;strong&gt;cdb&lt;/strong&gt; stands for &lt;strong&gt;Cluster Database&lt;/strong&gt; - it was a workname used in the early days. That name is no longer used, but the &lt;strong&gt;cdb&lt;/strong&gt; prefix remains.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;src/backend/gpopt/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Contains the so-called &lt;strong&gt;translator&lt;/strong&gt; library, for using the GPORCA optimizer with Greenplum. The translator library is written in C++ code, and contains glue code for translating plans and queries between the DXL format used by GPORCA, and the PostgreSQL internal representation.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;src/backend/gporca/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Contains the GPORCA optimizer code and tests. This is written in C++. See &lt;a href=&#34;https://raw.githubusercontent.com/greenplum-db/gpdb/main/src/backend/gporca/README.md&#34;&gt;README.md&lt;/a&gt; for more information and how to unit-test GPORCA.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;src/backend/fts/&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;FTS is a process that runs in the coordinator node, and periodically polls the segments to maintain the status of each segment.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Greenplum is maintained by a core team of developers with commit rights to the &lt;a href=&#34;https://github.com/greenplum-db/gpdb&#34;&gt;main gpdb repository&lt;/a&gt; on GitHub. At the same time, we are very eager to receive contributions from anybody in the wider Greenplum community. This section covers all you need to know if you want to see your code or documentation changes be added to Greenplum and appear in the future releases.&lt;/p&gt; &#xA;&lt;h3&gt;Getting started&lt;/h3&gt; &#xA;&lt;p&gt;Greenplum is developed on GitHub, and anybody wishing to contribute to it will have to &lt;a href=&#34;https://github.com/signup/free&#34;&gt;have a GitHub account&lt;/a&gt; and be familiar with &lt;a href=&#34;https://wiki.postgresql.org/wiki/Working_with_Git&#34;&gt;Git tools and workflow&lt;/a&gt;. It is also recommend that you follow the &lt;a href=&#34;https://greenplum.org/community/&#34;&gt;developer&#39;s mailing list&lt;/a&gt; since some of the contributions may generate more detailed discussions there.&lt;/p&gt; &#xA;&lt;p&gt;Once you have your GitHub account, &lt;a href=&#34;https://github.com/greenplum-db/gpdb/fork&#34;&gt;fork&lt;/a&gt; this repository so that you can have your private copy to start hacking on and to use as source of pull requests.&lt;/p&gt; &#xA;&lt;p&gt;Anybody contributing to Greenplum has to be covered by either the Corporate or the Individual Contributor License Agreement. If you have not previously done so, please fill out and submit the &lt;a href=&#34;https://cla.pivotal.io/sign/greenplum&#34;&gt;Contributor License Agreement&lt;/a&gt;. Note that we do allow for really trivial changes to be contributed without a CLA if they fall under the rubric of &lt;a href=&#34;https://cla.pivotal.io/about#obvious-fixes&#34;&gt;obvious fixes&lt;/a&gt;. However, since our GitHub workflow checks for CLA by default you may find it easier to submit one instead of claiming an &#34;obvious fix&#34; exception.&lt;/p&gt; &#xA;&lt;h3&gt;Licensing of Greenplum contributions&lt;/h3&gt; &#xA;&lt;p&gt;If the contribution you&#39;re submitting is original work, you can assume that Pivotal will release it as part of an overall Greenplum release available to the downstream consumers under the Apache License, Version 2.0. However, in addition to that, Pivotal may also decide to release it under a different license (such as &lt;a href=&#34;https://www.postgresql.org/about/licence/&#34;&gt;PostgreSQL License&lt;/a&gt; to the upstream consumers that require it. A typical example here would be Pivotal upstreaming your contribution back to PostgreSQL community (which can be done either verbatim or your contribution being upstreamed as part of the larger changeset).&lt;/p&gt; &#xA;&lt;p&gt;If the contribution you&#39;re submitting is NOT original work you have to indicate the name of the license and also make sure that it is similar in terms to the Apache License 2.0. Apache Software Foundation maintains a list of these licenses under &lt;a href=&#34;https://www.apache.org/legal/resolved.html#category-a&#34;&gt;Category A&lt;/a&gt;. In addition to that, you may be required to make proper attribution in the &lt;a href=&#34;https://github.com/greenplum-db/gpdb/raw/main/NOTICE&#34;&gt;NOTICE file&lt;/a&gt; similar to &lt;a href=&#34;https://github.com/greenplum-db/gpdb/raw/main/NOTICE#L278&#34;&gt;these examples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Finally, keep in mind that it is NEVER a good idea to remove licensing headers from the work that is not your original one. Even if you are using parts of the file that originally had a licensing header at the top you should err on the side of preserving it. As always, if you are not quite sure about the licensing implications of your contributions, feel free to reach out to us on the developer mailing list.&lt;/p&gt; &#xA;&lt;h3&gt;Coding guidelines&lt;/h3&gt; &#xA;&lt;p&gt;Your chances of getting feedback and seeing your code merged into the project greatly depend on how granular your changes are. If you happen to have a bigger change in mind, we highly recommend engaging on the developer&#39;s mailing list first and sharing your proposal with us before you spend a lot of time writing code. Even when your proposal gets validated by the community, we still recommend doing the actual work as a series of small, self-contained commits. This makes the reviewer&#39;s job much easier and increases the timeliness of feedback.&lt;/p&gt; &#xA;&lt;p&gt;When it comes to C and C++ parts of Greenplum, we try to follow &lt;a href=&#34;https://www.postgresql.org/docs/devel/source.html&#34;&gt;PostgreSQL Coding Conventions&lt;/a&gt;. In addition to that we require that:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All Python code passes &lt;a href=&#34;https://www.pylint.org/&#34;&gt;Pylint&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;All Go code is formatted according to &lt;a href=&#34;https://golang.org/cmd/gofmt/&#34;&gt;gofmt&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We recommend using &lt;code&gt;git diff --color&lt;/code&gt; when reviewing your changes so that you don&#39;t have any spurious whitespace issues in the code that you submit.&lt;/p&gt; &#xA;&lt;p&gt;All new functionality that is contributed to Greenplum should be covered by regression tests that are contributed alongside it. If you are uncertain on how to test or document your work, please raise the question on the gpdb-dev mailing list and the developer community will do its best to help you.&lt;/p&gt; &#xA;&lt;p&gt;At the very minimum you should always be running &lt;code&gt;make installcheck-world&lt;/code&gt; to make sure that you&#39;re not breaking anything.&lt;/p&gt; &#xA;&lt;h3&gt;Changes applicable to upstream PostgreSQL&lt;/h3&gt; &#xA;&lt;p&gt;If the change you&#39;re working on touches functionality that is common between PostgreSQL and Greenplum, you may be asked to forward-port it to PostgreSQL. This is not only so that we keep reducing the delta between the two projects, but also so that any change that is relevant to PostgreSQL can benefit from a much broader review of the upstream PostgreSQL community. In general, it is a good idea to keep both code bases handy so you can be sure whether your changes may need to be forward-ported.&lt;/p&gt; &#xA;&lt;h3&gt;Submission timing&lt;/h3&gt; &#xA;&lt;p&gt;To improve the odds of the right discussion of your patch or idea happening, pay attention to what the community work cycle is. For example, if you send in a brand new idea in the beta phase of a release, we may defer review or target its inclusion for a later version. Feel free to ask on the mailing list to learn more about the Greenplum release policy and timing.&lt;/p&gt; &#xA;&lt;h3&gt;Patch submission&lt;/h3&gt; &#xA;&lt;p&gt;Once you are ready to share your work with the Greenplum core team and the rest of the Greenplum community, you should push all the commits to a branch in your own repository forked from the official Greenplum and &lt;a href=&#34;https://help.github.com/articles/about-pull-requests/&#34;&gt;send us a pull request&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We welcome submissions which are work in-progress in order to get feedback early in the development process. When opening the pull request, select &#34;Draft&#34; in the dropdown menu when creating the PR to clearly mark the intent of the pull request. Prefixing the title with &#34;WIP:&#34; is also good practice.&lt;/p&gt; &#xA;&lt;p&gt;All new features should be submitted against the main branch. Bugfixes should too be submitted against main unless they only exist in a supported back-branch. If the bug exists in both main and back-branches, explain this in the PR description.&lt;/p&gt; &#xA;&lt;h3&gt;Validation checks and CI&lt;/h3&gt; &#xA;&lt;p&gt;Once you submit your pull request, you will immediately see a number of validation checks performed by our automated CI pipelines. There also will be a CLA check telling you whether your CLA was recognized. If any of these checks fails, you will need to update your pull request to take care of the issue. Pull requests with failed validation checks are very unlikely to receive any further peer review from the community members.&lt;/p&gt; &#xA;&lt;p&gt;Keep in mind that the most common reason for a failed CLA check is a mismatch between an email on file and an email recorded in the commits submitted as part of the pull request.&lt;/p&gt; &#xA;&lt;p&gt;If you cannot figure out why a certain validation check failed, feel free to ask on the developer&#39;s mailing list, but make sure to include a direct link to a pull request in your email.&lt;/p&gt; &#xA;&lt;h3&gt;Patch review&lt;/h3&gt; &#xA;&lt;p&gt;A submitted pull request with passing validation checks is assumed to be available for peer review. Peer review is the process that ensures that contributions to Greenplum are of high quality and align well with the road map and community expectations. Every member of the Greenplum community is encouraged to review pull requests and provide feedback. Since you don&#39;t have to be a core team member to be able to do that, we recommend following a stream of pull reviews to anybody who&#39;s interested in becoming a long-term contributor to Greenplum. As &lt;a href=&#34;https://en.wikipedia.org/wiki/Linus&#39;s_Law&#34;&gt;Linus would say&lt;/a&gt; &#34;given enough eyeballs, all bugs are shallow&#34;.&lt;/p&gt; &#xA;&lt;p&gt;One outcome of the peer review could be a consensus that you need to modify your pull request in certain ways. GitHub allows you to push additional commits into a branch from which a pull request was sent. Those additional commits will be then visible to all of the reviewers.&lt;/p&gt; &#xA;&lt;p&gt;A peer review converges when it receives at least one +1 and no -1s votes from the participants. At that point you should expect one of the core team members to pull your changes into the project.&lt;/p&gt; &#xA;&lt;p&gt;Greenplum prides itself on being a collaborative, consensus-driven environment. We do not believe in vetoes and any -1 vote casted as part of the peer review has to have a detailed technical explanation of what&#39;s wrong with the change. Should a strong disagreement arise it may be advisable to take the matter onto the mailing list since it allows for a more natural flow of the conversation.&lt;/p&gt; &#xA;&lt;p&gt;At any time during the patch review, you may experience delays based on the availability of reviewers and core team members. Please be patient. That being said, don&#39;t get discouraged either. If you&#39;re not getting expected feedback for a few days add a comment asking for updates on the pull request itself or send an email to the mailing list.&lt;/p&gt; &#xA;&lt;h3&gt;Direct commits to the repository&lt;/h3&gt; &#xA;&lt;p&gt;On occasion you will see core team members committing directly to the repository without going through the pull request workflow. This is reserved for small changes only and the rule of thumb we use is this: if the change touches any functionality that may result in a test failure, then it has to go through a pull request workflow. If, on the other hand, the change is in the non-functional part of the code base (such as fixing a typo inside of a comment block) core team members can decide to just commit to the repository directly.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;For Greenplum Database documentation, please check the &lt;a href=&#34;http://docs.greenplum.org/&#34;&gt;online documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For further information beyond the scope of this README, please see &lt;a href=&#34;https://github.com/greenplum-db/gpdb/wiki&#34;&gt;our wiki&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>citusdata/citus</title>
    <updated>2024-03-17T01:42:21Z</updated>
    <id>tag:github.com,2024-03-17:/citusdata/citus</id>
    <link href="https://github.com/citusdata/citus" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Distributed PostgreSQL as an extension&lt;/p&gt;&lt;hr&gt;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;&lt;br&gt;The Citus database is 100% open source.&lt;br&gt;&lt;img width=&#34;1000/&#34;&gt;&lt;br&gt;Learn what&#39;s new in the &lt;a href=&#34;https://www.citusdata.com/blog/2023/09/22/adding-postgres-16-support-to-citus-12-1/&#34;&gt;Citus 12.1 release blog&lt;/a&gt; and the &lt;a href=&#34;https://www.citusdata.com/updates/&#34;&gt;Citus Updates page&lt;/a&gt;.&lt;br&gt;&lt;br&gt;&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/citusdata/citus/main/images/citus-readme-banner.png&#34; alt=&#34;Citus Banner&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.citusdata.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-latest-brightgreen.svg?sanitize=true&#34; alt=&#34;Latest Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://stackoverflow.com/questions/tagged/citus&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Stack%20Overflow-%20-545353?logo=Stack%20Overflow&#34; alt=&#34;Stack Overflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://slack.citusdata.com/&#34;&gt;&lt;img src=&#34;https://cituscdn.azureedge.net/images/social/slack-badge.svg?sanitize=true&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/citusdata/citus&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/citusdata/citus/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;Code Coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/follow?screen_name=citusdata&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/citusdata.svg?label=Follow%20@citusdata&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://packagecloud.io/app/citusdata/community/search?q=&amp;amp;filter=debs&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/deb-packagecloud.io-844fec.svg?sanitize=true&#34; alt=&#34;Citus Deb Packages&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagecloud.io/app/citusdata/community/search?q=&amp;amp;filter=rpms&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/rpm-packagecloud.io-844fec.svg?sanitize=true&#34; alt=&#34;Citus Rpm Packages&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Citus?&lt;/h2&gt; &#xA;&lt;p&gt;Citus is a &lt;a href=&#34;https://www.citusdata.com/blog/2017/10/25/what-it-means-to-be-a-postgresql-extension/&#34;&gt;PostgreSQL extension&lt;/a&gt; that transforms Postgres into a distributed databaseâ€”so you can achieve high performance at any scale.&lt;/p&gt; &#xA;&lt;p&gt;With Citus, you extend your PostgreSQL database with new superpowers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Distributed tables&lt;/strong&gt; are sharded across a cluster of PostgreSQL nodes to combine their CPU, memory, storage and I/O capacity.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;References tables&lt;/strong&gt; are replicated to all nodes for joins and foreign keys from distributed tables and maximum read performance.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Distributed query engine&lt;/strong&gt; routes and parallelizes SELECT, DML, and other operations on distributed tables across the cluster.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Columnar storage&lt;/strong&gt; compresses data, speeds up scans, and supports fast projections, both on regular and distributed tables.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Query from any node&lt;/strong&gt; enables you to utilize the full capacity of your cluster for distributed queries&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can use these Citus superpowers to make your Postgres database scale-out ready on a single Citus node. Or you can build a large cluster capable of handling &lt;strong&gt;high transaction throughputs&lt;/strong&gt;, especially in &lt;strong&gt;multi-tenant apps&lt;/strong&gt;, run &lt;strong&gt;fast analytical queries&lt;/strong&gt;, and process large amounts of &lt;strong&gt;time series&lt;/strong&gt; or &lt;strong&gt;IoT data&lt;/strong&gt; for &lt;strong&gt;real-time analytics&lt;/strong&gt;. When your data size and volume grow, you can easily add more worker nodes to the cluster and rebalance the shards.&lt;/p&gt; &#xA;&lt;p&gt;Our &lt;a href=&#34;https://2021.sigmod.org/&#34;&gt;SIGMOD &#39;21&lt;/a&gt; paper &lt;a href=&#34;https://doi.org/10.1145/3448016.3457551&#34;&gt;Citus: Distributed PostgreSQL for Data-Intensive Applications&lt;/a&gt; gives a more detailed look into what Citus is, how it works, and why it works that way.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/citusdata/citus/main/images/citus-scale-out.png&#34; alt=&#34;Citus scales out from a single node&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Since Citus is an extension to Postgres, you can use Citus with the latest Postgres versions. And Citus works seamlessly with the PostgreSQL tools and extensions you are already familiar with.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#why-citus&#34;&gt;Why Citus?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#using-citus&#34;&gt;Using Citus&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#schema-based-sharding&#34;&gt;Schema-based sharding&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#setting-up-with-high-availability&#34;&gt;Setting up with High Availability&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#architecture&#34;&gt;Architecture&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#when-to-use-citus&#34;&gt;When to Use Citus&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#need-help&#34;&gt;Need Help?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/#stay-connected&#34;&gt;Stay Connected&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why Citus?&lt;/h2&gt; &#xA;&lt;p&gt;Developers choose Citus for two reasons:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Your application is outgrowing a single PostgreSQL node&lt;/p&gt; &lt;p&gt;If the size and volume of your data increases over time, you may start seeing any number of performance and scalability problems on a single PostgreSQL node. For example: High CPU utilization and I/O wait times slow down your queries, SQL queries return out of memory errors, autovacuum cannot keep up and increases table bloat, etc.&lt;/p&gt; &lt;p&gt;With Citus you can distribute and optionally compress your tables to always have enough memory, CPU, and I/O capacity to achieve high performance at scale. The distributed query engine can efficiently route transactions across the cluster, while parallelizing analytical queries and batch operations across all cores. Moreover, you can still use the PostgreSQL features and tools you know and love.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;PostgreSQL can do things other systems canâ€™t&lt;/p&gt; &lt;p&gt;There are many data processing systems that are built to scale out, but few have as many powerful capabilities as PostgreSQL, including: Advanced joins and subqueries, user-defined functions, update/delete/upsert, constraints and foreign keys, powerful extensions (e.g. PostGIS, HyperLogLog), many types of indexes, time-partitioning, and sophisticated JSON support.&lt;/p&gt; &lt;p&gt;Citus makes PostgreSQLâ€™s most powerful capabilities work at any scale, allowing you to handle complex data-intensive workloads on a single database system.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The quickest way to get started with Citus is to use the &lt;a href=&#34;https://learn.microsoft.com/azure/cosmos-db/postgresql/quickstart-create-portal&#34;&gt;Azure Cosmos DB for PostgreSQL&lt;/a&gt; managed service in the cloudâ€”or &lt;a href=&#34;https://docs.citusdata.com/en/stable/installation/single_node.html&#34;&gt;set up Citus locally&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Citus Managed Service on Azure&lt;/h3&gt; &#xA;&lt;p&gt;You can get a fully-managed Citus cluster in minutes through the &lt;a href=&#34;https://azure.microsoft.com/products/cosmos-db/&#34;&gt;Azure Cosmos DB for PostgreSQL portal&lt;/a&gt;. Azure will manage your backups, high availability through auto-failover, software updates, monitoring, and more for all of your servers. To get started Citus on Azure, use the &lt;a href=&#34;https://learn.microsoft.com/azure/cosmos-db/postgresql/quickstart-create-portal&#34;&gt;Azure Cosmos DB for PostgreSQL Quickstart&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Running Citus using Docker&lt;/h3&gt; &#xA;&lt;p&gt;The smallest possible Citus cluster is a single PostgreSQL node with the Citus extension, which means you can try out Citus by running a single Docker container.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# run PostgreSQL with Citus on port 5500&#xA;docker run -d --name citus -p 5500:5432 -e POSTGRES_PASSWORD=mypassword citusdata/citus&#xA;&#xA;# connect using psql within the Docker container&#xA;docker exec -it citus psql -U postgres&#xA;&#xA;# or, connect using local psql&#xA;psql -U postgres -d postgres -h localhost -p 5500&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install Citus locally&lt;/h3&gt; &#xA;&lt;p&gt;If you already have a local PostgreSQL installation, the easiest way to install Citus is to use our packaging repo&lt;/p&gt; &#xA;&lt;p&gt;Install packages on Ubuntu / Debian:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl https://install.citusdata.com/community/deb.sh &amp;gt; add-citus-repo.sh&#xA;sudo bash add-citus-repo.sh&#xA;sudo apt-get -y install postgresql-16-citus-12.1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install packages on CentOS / Red Hat:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl https://install.citusdata.com/community/rpm.sh &amp;gt; add-citus-repo.sh&#xA;sudo bash add-citus-repo.sh&#xA;sudo yum install -y citus121_16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To add Citus to your local PostgreSQL database, add the following to &lt;code&gt;postgresql.conf&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;shared_preload_libraries = &#39;citus&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After restarting PostgreSQL, connect using &lt;code&gt;psql&lt;/code&gt; and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE EXTENSION citus;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Youâ€™re now ready to get started and use Citus tables on a single node.&lt;/p&gt; &#xA;&lt;h3&gt;Install Citus on multiple nodes&lt;/h3&gt; &#xA;&lt;p&gt;If you want to set up a multi-node cluster, you can also set up additional PostgreSQL nodes with the Citus extensions and add them to form a Citus cluster:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- before adding the first worker node, tell future worker nodes how to reach the coordinator&#xA;SELECT citus_set_coordinator_host(&#39;10.0.0.1&#39;, 5432);&#xA;&#xA;-- add worker nodes&#xA;SELECT citus_add_node(&#39;10.0.0.2&#39;, 5432);&#xA;SELECT citus_add_node(&#39;10.0.0.3&#39;, 5432);&#xA;&#xA;-- rebalance the shards over the new worker nodes&#xA;SELECT rebalance_table_shards();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more details, see our &lt;a href=&#34;https://docs.citusdata.com/en/stable/installation/multi_node.html&#34;&gt;documentation on how to set up a multi-node Citus cluster&lt;/a&gt; on various operating systems.&lt;/p&gt; &#xA;&lt;h2&gt;Using Citus&lt;/h2&gt; &#xA;&lt;p&gt;Once you have your Citus cluster, you can start creating distributed tables, reference tables and use columnar storage.&lt;/p&gt; &#xA;&lt;h3&gt;Creating Distributed Tables&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;create_distributed_table&lt;/code&gt; UDF will transparently shard your table locally or across the worker nodes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE events (&#xA;  device_id bigint,&#xA;  event_id bigserial,&#xA;  event_time timestamptz default now(),&#xA;  data jsonb not null,&#xA;  PRIMARY KEY (device_id, event_id)&#xA;);&#xA;&#xA;-- distribute the events table across shards placed locally or on the worker nodes&#xA;SELECT create_distributed_table(&#39;events&#39;, &#39;device_id&#39;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After this operation, queries for a specific device ID will be efficiently routed to a single worker node, while queries across device IDs will be parallelized across the cluster.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- insert some events&#xA;INSERT INTO events (device_id, data)&#xA;SELECT s % 100, (&#39;{&#34;measurement&#34;:&#39;||random()||&#39;}&#39;)::jsonb FROM generate_series(1,1000000) s;&#xA;&#xA;-- get the last 3 events for device 1, routed to a single node&#xA;SELECT * FROM events WHERE device_id = 1 ORDER BY event_time DESC, event_id DESC LIMIT 3;&#xA;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”&#xA;â”‚ device_id â”‚ event_id â”‚          event_time           â”‚                 data                  â”‚&#xA;â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤&#xA;â”‚         1 â”‚  1999901 â”‚ 2021-03-04 16:00:31.189963+00 â”‚ {&#34;measurement&#34;: 0.88722643925054}     â”‚&#xA;â”‚         1 â”‚  1999801 â”‚ 2021-03-04 16:00:31.189963+00 â”‚ {&#34;measurement&#34;: 0.6512231304621992}   â”‚&#xA;â”‚         1 â”‚  1999701 â”‚ 2021-03-04 16:00:31.189963+00 â”‚ {&#34;measurement&#34;: 0.019368766051897524} â”‚&#xA;â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜&#xA;(3 rows)&#xA;&#xA;Time: 4.588 ms&#xA;&#xA;-- explain plan for a query that is parallelized across shards, which shows the plan for&#xA;-- a query one of the shards and how the aggregation across shards is done&#xA;EXPLAIN (VERBOSE ON) SELECT count(*) FROM events;&#xA;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”&#xA;â”‚                                     QUERY PLAN                                     â”‚&#xA;â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤&#xA;â”‚ Aggregate                                                                          â”‚&#xA;â”‚   Output: COALESCE((pg_catalog.sum(remote_scan.count))::bigint, &#39;0&#39;::bigint)       â”‚&#xA;â”‚   -&amp;gt;  Custom Scan (Citus Adaptive)                                                 â”‚&#xA;â”‚         ...                                                                        â”‚&#xA;â”‚         -&amp;gt;  Task                                                                   â”‚&#xA;â”‚               Query: SELECT count(*) AS count FROM events_102008 events WHERE true â”‚&#xA;â”‚               Node: host=localhost port=5432 dbname=postgres                       â”‚&#xA;â”‚               -&amp;gt;  Aggregate                                                        â”‚&#xA;â”‚                     -&amp;gt;  Seq Scan on public.events_102008 events                    â”‚&#xA;â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Creating Distributed Tables with Co-location&lt;/h3&gt; &#xA;&lt;p&gt;Distributed tables that have the same distribution column can be co-located to enable high performance distributed joins and foreign keys between distributed tables. By default, distributed tables will be co-located based on the type of the distribution column, but you define co-location explicitly with the &lt;code&gt;colocate_with&lt;/code&gt; argument in &lt;code&gt;create_distributed_table&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE devices (&#xA;  device_id bigint primary key,&#xA;  device_name text,&#xA;  device_type_id int&#xA;);&#xA;CREATE INDEX ON devices (device_type_id);&#xA;&#xA;-- co-locate the devices table with the events table&#xA;SELECT create_distributed_table(&#39;devices&#39;, &#39;device_id&#39;, colocate_with := &#39;events&#39;);&#xA;&#xA;-- insert device metadata&#xA;INSERT INTO devices (device_id, device_name, device_type_id)&#xA;SELECT s, &#39;device-&#39;||s, 55 FROM generate_series(0, 99) s;&#xA;&#xA;-- optionally: make sure the application can only insert events for a known device&#xA;ALTER TABLE events ADD CONSTRAINT device_id_fk&#xA;FOREIGN KEY (device_id) REFERENCES devices (device_id);&#xA;&#xA;-- get the average measurement across all devices of type 55, parallelized across shards&#xA;SELECT avg((data-&amp;gt;&amp;gt;&#39;measurement&#39;)::double precision)&#xA;FROM events JOIN devices USING (device_id)&#xA;WHERE device_type_id = 55;&#xA;&#xA;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”&#xA;â”‚        avg         â”‚&#xA;â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤&#xA;â”‚ 0.5000191877513974 â”‚&#xA;â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜&#xA;(1 row)&#xA;&#xA;Time: 209.961 ms&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Co-location also helps you scale &lt;a href=&#34;https://docs.citusdata.com/en/stable/articles/aggregation.html&#34;&gt;INSERT..SELECT&lt;/a&gt;, &lt;a href=&#34;https://www.citusdata.com/blog/2020/11/21/making-postgres-stored-procedures-9x-faster-in-citus/&#34;&gt;stored procedures&lt;/a&gt;, and &lt;a href=&#34;https://www.citusdata.com/blog/2017/06/02/scaling-complex-sql-transactions/&#34;&gt;distributed transactions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Distributing Tables without interrupting the application&lt;/h3&gt; &#xA;&lt;p&gt;Some of you already start with Postgres, and decide to distribute tables later on while your application using the tables. In that case, you want to avoid downtime for both reads and writes. &lt;code&gt;create_distributed_table&lt;/code&gt; command block writes (e.g., DML commands) on the table until the command is finished. Instead, with &lt;code&gt;create_distributed_table_concurrently&lt;/code&gt; command, your application can continue to read and write the data even during the command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE device_logs (&#xA;  device_id bigint primary key,&#xA;  log text&#xA;);&#xA;&#xA;-- insert device logs&#xA;INSERT INTO device_logs (device_id, log)&#xA;SELECT s, &#39;device log:&#39;||s FROM generate_series(0, 99) s;&#xA;&#xA;-- convert device_logs into a distributed table without interrupting the application&#xA;SELECT create_distributed_table_concurrently(&#39;device_logs&#39;, &#39;device_id&#39;, colocate_with := &#39;devices&#39;);&#xA;&#xA;&#xA;-- get the count of the logs, parallelized across shards&#xA;SELECT count(*) FROM device_logs;&#xA;&#xA;â”Œâ”€â”€â”€â”€â”€â”€â”€â”&#xA;â”‚ count â”‚&#xA;â”œâ”€â”€â”€â”€â”€â”€â”€â”¤&#xA;â”‚   100 â”‚&#xA;â””â”€â”€â”€â”€â”€â”€â”€â”˜&#xA;(1 row)&#xA;&#xA;Time: 48.734 ms&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Creating Reference Tables&lt;/h3&gt; &#xA;&lt;p&gt;When you need fast joins or foreign keys that do not include the distribution column, you can use &lt;code&gt;create_reference_table&lt;/code&gt; to replicate a table across all nodes in the cluster.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE device_types (&#xA;  device_type_id int primary key,&#xA;  device_type_name text not null unique&#xA;);&#xA;&#xA;-- replicate the table across all nodes to enable foreign keys and joins on any column&#xA;SELECT create_reference_table(&#39;device_types&#39;);&#xA;&#xA;-- insert a device type&#xA;INSERT INTO device_types (device_type_id, device_type_name) VALUES (55, &#39;laptop&#39;);&#xA;&#xA;-- optionally: make sure the application can only insert devices with known types&#xA;ALTER TABLE devices ADD CONSTRAINT device_type_fk&#xA;FOREIGN KEY (device_type_id) REFERENCES device_types (device_type_id);&#xA;&#xA;-- get the last 3 events for devices whose type name starts with laptop, parallelized across shards&#xA;SELECT device_id, event_time, data-&amp;gt;&amp;gt;&#39;measurement&#39; AS value, device_name, device_type_name&#xA;FROM events JOIN devices USING (device_id) JOIN device_types USING (device_type_id)&#xA;WHERE device_type_name LIKE &#39;laptop%&#39; ORDER BY event_time DESC LIMIT 3;&#xA;&#xA;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”&#xA;â”‚ device_id â”‚          event_time           â”‚        value        â”‚ device_name â”‚ device_type_name â”‚&#xA;â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤&#xA;â”‚        60 â”‚ 2021-03-04 16:00:31.189963+00 â”‚ 0.28902084163415864 â”‚ device-60   â”‚ laptop           â”‚&#xA;â”‚         8 â”‚ 2021-03-04 16:00:31.189963+00 â”‚ 0.8723803076285073  â”‚ device-8    â”‚ laptop           â”‚&#xA;â”‚        20 â”‚ 2021-03-04 16:00:31.189963+00 â”‚ 0.8177634801548557  â”‚ device-20   â”‚ laptop           â”‚&#xA;â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜&#xA;(3 rows)&#xA;&#xA;Time: 146.063 ms&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Reference tables enable you to scale out complex data models and take full advantage of relational database features.&lt;/p&gt; &#xA;&lt;h3&gt;Creating Tables with Columnar Storage&lt;/h3&gt; &#xA;&lt;p&gt;To use columnar storage in your PostgreSQL database, all you need to do is add &lt;code&gt;USING columnar&lt;/code&gt; to your &lt;code&gt;CREATE TABLE&lt;/code&gt; statements and your data will be automatically compressed using the columnar access method.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE events_columnar (&#xA;  device_id bigint,&#xA;  event_id bigserial,&#xA;  event_time timestamptz default now(),&#xA;  data jsonb not null&#xA;)&#xA;USING columnar;&#xA;&#xA;-- insert some data&#xA;INSERT INTO events_columnar (device_id, data)&#xA;SELECT d, &#39;{&#34;hello&#34;:&#34;columnar&#34;}&#39; FROM generate_series(1,10000000) d;&#xA;&#xA;-- create a row-based table to compare&#xA;CREATE TABLE events_row AS SELECT * FROM events_columnar;&#xA;&#xA;-- see the huge size difference!&#xA;\d+&#xA;                                          List of relations&#xA;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”&#xA;â”‚ Schema â”‚             Name             â”‚   Type   â”‚ Owner â”‚ Persistence â”‚    Size    â”‚ Description â”‚&#xA;â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤&#xA;â”‚ public â”‚ events_columnar              â”‚ table    â”‚ marco â”‚ permanent   â”‚ 25 MB      â”‚             â”‚&#xA;â”‚ public â”‚ events_row                   â”‚ table    â”‚ marco â”‚ permanent   â”‚ 651 MB     â”‚             â”‚&#xA;â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can use columnar storage by itself, or in a distributed table to combine the benefits of compression and the distributed query engine.&lt;/p&gt; &#xA;&lt;p&gt;When using columnar storage, you should only load data in batch using &lt;code&gt;COPY&lt;/code&gt; or &lt;code&gt;INSERT..SELECT&lt;/code&gt; to achieve good compression. Update, delete, and foreign keys are currently unsupported on columnar tables. However, you can use partitioned tables in which newer partitions use row-based storage, and older partitions are compressed using columnar storage.&lt;/p&gt; &#xA;&lt;p&gt;To learn more about columnar storage, check out the &lt;a href=&#34;https://github.com/citusdata/citus/raw/master/src/backend/columnar/README.md&#34;&gt;columnar storage README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Schema-based sharding&lt;/h2&gt; &#xA;&lt;p&gt;Available since Citus 12.0, &lt;a href=&#34;https://docs.citusdata.com/en/stable/get_started/concepts.html#schema-based-sharding&#34;&gt;schema-based sharding&lt;/a&gt; is the shared database, separate schema model, the schema becomes the logical shard within the database. Multi-tenant apps can a use a schema per tenant to easily shard along the tenant dimension. Query changes are not required and the application usually only needs a small modification to set the proper search_path when switching tenants. Schema-based sharding is an ideal solution for microservices, and for ISVs deploying applications that cannot undergo the changes required to onboard row-based sharding.&lt;/p&gt; &#xA;&lt;h3&gt;Creating distributed schemas&lt;/h3&gt; &#xA;&lt;p&gt;You can turn an existing schema into a distributed schema by calling &lt;code&gt;citus_schema_distribute&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT citus_schema_distribute(&#39;user_service&#39;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can set &lt;code&gt;citus.enable_schema_based_sharding&lt;/code&gt; to have all newly created schemas be automatically converted into distributed schemas:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SET citus.enable_schema_based_sharding TO ON;&#xA;&#xA;CREATE SCHEMA AUTHORIZATION user_service;&#xA;CREATE SCHEMA AUTHORIZATION time_service;&#xA;CREATE SCHEMA AUTHORIZATION ping_service;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running queries&lt;/h3&gt; &#xA;&lt;p&gt;Queries will be properly routed to schemas based on &lt;code&gt;search_path&lt;/code&gt; or by explicitly using the schema name in the query.&lt;/p&gt; &#xA;&lt;p&gt;For &lt;a href=&#34;https://docs.citusdata.com/en/stable/get_started/tutorial_microservices.html&#34;&gt;microservices&lt;/a&gt; you would create a USER per service matching the schema name, hence the default &lt;code&gt;search_path&lt;/code&gt; would contain the schema name. When connected the user queries would be automatically routed and no changes to the microservice would be required.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE USER user_service;&#xA;CREATE SCHEMA AUTHORIZATION user_service;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For typical multi-tenant applications, you would set the search path to the tenant schema name in your application:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SET search_path = tenant_name, public;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Setting up with High Availability&lt;/h2&gt; &#xA;&lt;p&gt;One of the most popular high availability solutions for PostgreSQL, &lt;a href=&#34;https://github.com/zalando/patroni&#34;&gt;Patroni 3.0&lt;/a&gt;, has &lt;a href=&#34;https://patroni.readthedocs.io/en/latest/citus.html#citus&#34;&gt;first class support for Citus 10.0 and above&lt;/a&gt;, additionally since Citus 11.2 ships with improvements for smoother node switchover in Patroni.&lt;/p&gt; &#xA;&lt;p&gt;An example of patronictl list output for the Citus cluster:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;postgres@coord1:~$ patronictl list demo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;+ Citus cluster: demo ----------+--------------+---------+----+-----------+&#xA;| Group | Member  | Host        | Role         | State   | TL | Lag in MB |&#xA;+-------+---------+-------------+--------------+---------+----+-----------+&#xA;|     0 | coord1  | 172.27.0.10 | Replica      | running |  1 |         0 |&#xA;|     0 | coord2  | 172.27.0.6  | Sync Standby | running |  1 |         0 |&#xA;|     0 | coord3  | 172.27.0.4  | Leader       | running |  1 |           |&#xA;|     1 | work1-1 | 172.27.0.8  | Sync Standby | running |  1 |         0 |&#xA;|     1 | work1-2 | 172.27.0.2  | Leader       | running |  1 |           |&#xA;|     2 | work2-1 | 172.27.0.5  | Sync Standby | running |  1 |         0 |&#xA;|     2 | work2-2 | 172.27.0.7  | Leader       | running |  1 |           |&#xA;+-------+---------+-------------+--------------+---------+----+-----------+&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;If youâ€™re ready to get started with Citus or want to know more, we recommend reading the &lt;a href=&#34;https://docs.citusdata.com/en/stable/&#34;&gt;Citus open source documentation&lt;/a&gt;. Or, if you are using Citus on Azure, then the &lt;a href=&#34;https://learn.microsoft.com/azure/cosmos-db/postgresql/introduction&#34;&gt;Azure Cosmos DB for PostgreSQL&lt;/a&gt; is the place to start.&lt;/p&gt; &#xA;&lt;p&gt;Our Citus docs contain comprehensive use case guides on how to build a &lt;a href=&#34;https://docs.citusdata.com/en/stable/use_cases/multi_tenant.html&#34;&gt;multi-tenant SaaS application&lt;/a&gt;, &lt;a href=&#34;https://docs.citusdata.com/en/stable/use_cases/realtime_analytics.html&#34;&gt;real-time analytics dashboard&lt;/a&gt;, or work with &lt;a href=&#34;https://docs.citusdata.com/en/stable/use_cases/timeseries.html&#34;&gt;time series data&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;A Citus database cluster grows from a single PostgreSQL node into a cluster by adding worker nodes. In a Citus cluster, the original node to which the application connects is referred to as the coordinator node. The Citus coordinator contains both the metadata of distributed tables and reference tables, as well as regular (local) tables, sequences, and other database objects (e.g. foreign tables).&lt;/p&gt; &#xA;&lt;p&gt;Data in distributed tables is stored in â€œshardsâ€, which are actually just regular PostgreSQL tables on the worker nodes. When querying a distributed table on the coordinator node, Citus will send regular SQL queries to the worker nodes. That way, all the usual PostgreSQL optimizations and extensions can automatically be used with Citus.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/citusdata/citus/main/images/citus-architecture.png&#34; alt=&#34;Citus architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;When you send a query in which all (co-located) distributed tables have the same filter on the distribution column, Citus will automatically detect that and send the whole query to the worker node that stores the data. That way, arbitrarily complex queries are supported with minimal routing overhead, which is especially useful for scaling transactional workloads. If queries do not have a specific filter, each shard is queried in parallel, which is especially useful in analytical workloads. The Citus distributed executor is adaptive and is designed to handle both query types at the same time on the same system under high concurrency, which enables large-scale mixed workloads.&lt;/p&gt; &#xA;&lt;p&gt;The schema and metadata of distributed tables and reference tables are automatically synchronized to all the nodes in the cluster. That way, you can connect to any node to run distributed queries. Schema changes and cluster administration still need to go through the coordinator.&lt;/p&gt; &#xA;&lt;p&gt;Detailed descriptions of the implementation for Citus developers are provided in the &lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/src/backend/distributed/README.md&#34;&gt;Citus Technical Documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;When to use Citus&lt;/h2&gt; &#xA;&lt;p&gt;Citus is uniquely capable of scaling both analytical and transactional workloads with up to petabytes of data. Use cases in which Citus is commonly used:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://docs.citusdata.com/en/stable/use_cases/realtime_analytics.html&#34;&gt;Customer-facing analytics dashboards&lt;/a&gt;&lt;/strong&gt;: Citus enables you to build analytics dashboards that simultaneously ingest and process large amounts of data in the database and give sub-second response times even with a large number of concurrent users.&lt;/p&gt; &lt;p&gt;The advanced parallel, distributed query engine in Citus combined with PostgreSQL features such as &lt;a href=&#34;https://www.postgresql.org/docs/current/arrays.html&#34;&gt;array types&lt;/a&gt;, &lt;a href=&#34;https://www.postgresql.org/docs/current/datatype-json.html&#34;&gt;JSONB&lt;/a&gt;, &lt;a href=&#34;https://heap.io/blog/engineering/postgresqls-powerful-new-join-type-lateral&#34;&gt;lateral joins&lt;/a&gt;, and extensions like &lt;a href=&#34;https://github.com/citusdata/postgresql-hll&#34;&gt;HyperLogLog&lt;/a&gt; and &lt;a href=&#34;https://github.com/citusdata/postgresql-topn&#34;&gt;TopN&lt;/a&gt; allow you to build responsive analytics dashboards no matter how many customers or how much data you have.&lt;/p&gt; &lt;p&gt;Example real-time analytics users: &lt;a href=&#34;https://www.citusdata.com/customers/algolia&#34;&gt;Algolia&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://docs.citusdata.com/en/stable/use_cases/timeseries.html&#34;&gt;Time series data&lt;/a&gt;&lt;/strong&gt;: Citus enables you to process and analyze very large amounts of time series data. The biggest Citus clusters store well over a petabyte of time series data and ingest terabytes per day.&lt;/p&gt; &lt;p&gt;Citus integrates seamlessly with &lt;a href=&#34;https://www.postgresql.org/docs/current/ddl-partitioning.html&#34;&gt;Postgres table partitioning&lt;/a&gt; and has &lt;a href=&#34;https://www.citusdata.com/blog/2021/10/22/how-to-scale-postgres-for-time-series-data-with-citus/&#34;&gt;built-in functions for partitioning by time&lt;/a&gt;, which can speed up queries and writes on time series tables. You can take advantage of Citusâ€™s parallel, distributed query engine for fast analytical queries, and use the built-in &lt;em&gt;columnar storage&lt;/em&gt; to compress old partitions.&lt;/p&gt; &lt;p&gt;Example users: &lt;a href=&#34;https://www.citusdata.com/customers/mixrank&#34;&gt;MixRank&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://docs.citusdata.com/en/stable/use_cases/multi_tenant.html&#34;&gt;Software-as-a-service (SaaS) applications&lt;/a&gt;&lt;/strong&gt;: SaaS and other multi-tenant applications need to be able to scale their database as the number of tenants/customers grows. Citus enables you to transparently shard a complex data model by the tenant dimension, so your database can grow along with your business.&lt;/p&gt; &lt;p&gt;By distributing tables along a tenant ID column and co-locating data for the same tenant, Citus can horizontally scale complex (tenant-scoped) queries, transactions, and foreign key graphs. Reference tables and distributed DDL commands make database management a breeze compared to manual sharding. On top of that, you have a built-in distributed query engine for doing cross-tenant analytics inside the database.&lt;/p&gt; &lt;p&gt;Example multi-tenant SaaS users: &lt;a href=&#34;https://fivetran.com/case-studies/replicating-sharded-databases-a-case-study-of-salesloft-citus-data-and-fivetran&#34;&gt;Salesloft&lt;/a&gt;, &lt;a href=&#34;https://www.citusdata.com/customers/convertflow&#34;&gt;ConvertFlow&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.citusdata.com/en/stable/get_started/tutorial_microservices.html&#34;&gt;Microservices&lt;/a&gt;&lt;/strong&gt;: Citus supports schema based sharding, which allows distributing regular database schemas across many machines. This sharding methodology fits nicely with typical Microservices architecture, where storage is fully owned by the service hence canâ€™t share the same schema definition with other tenants. Citus allows distributing horizontally scalable state across services, solving one of the &lt;a href=&#34;https://stackoverflow.blog/2020/11/23/the-macro-problem-with-microservices/&#34;&gt;main problems&lt;/a&gt; of microservices.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Geospatial&lt;/strong&gt;: Because of the powerful &lt;a href=&#34;https://postgis.net/&#34;&gt;PostGIS&lt;/a&gt; extension to Postgres that adds support for geographic objects into Postgres, many people run spatial/GIS applications on top of Postgres. And since spatial location information has become part of our daily life, well, there are more geospatial applications than ever. When your Postgres database needs to scale out to handle an increased workload, Citus is a good fit.&lt;/p&gt; &lt;p&gt;Example geospatial users: &lt;a href=&#34;https://customers.microsoft.com/story/845146-transit-authority-improves-traffic-monitoring-with-azure-database-for-postgresql-hyperscale&#34;&gt;Helsinki Regional Transportation Authority (HSL)&lt;/a&gt;, &lt;a href=&#34;https://www.citusdata.com/blog/2020/11/09/analyzing-gps-trajectories-at-scale-with-postgres-mobilitydb/&#34;&gt;MobilityDB&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Need Help?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Slack&lt;/strong&gt;: Ask questions in our Citus community &lt;a href=&#34;https://slack.citusdata.com&#34;&gt;Slack channel&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GitHub issues&lt;/strong&gt;: Please submit issues via &lt;a href=&#34;https://github.com/citusdata/citus/issues&#34;&gt;GitHub issues&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Our &lt;a href=&#34;https://docs.citusdata.com&#34;&gt;Citus docs&lt;/a&gt; have a wealth of resources, including sections on &lt;a href=&#34;https://docs.citusdata.com/en/stable/performance/performance_tuning.html&#34;&gt;query performance tuning&lt;/a&gt;, &lt;a href=&#34;https://docs.citusdata.com/en/stable/admin_guide/diagnostic_queries.html&#34;&gt;useful diagnostic queries&lt;/a&gt;, and &lt;a href=&#34;https://docs.citusdata.com/en/stable/reference/common_errors.html&#34;&gt;common error messages&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Docs issues&lt;/strong&gt;: You can also submit documentation issues via &lt;a href=&#34;https://github.com/citusdata/citus_docs/issues&#34;&gt;GitHub issues for our Citus docs&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Updates &amp;amp; Release Notes&lt;/strong&gt;: Learn about what&#39;s new in each Citus version on the &lt;a href=&#34;https://www.citusdata.com/updates/&#34;&gt;Citus Updates page&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Citus is built on and of open source, and we welcome your contributions. The &lt;a href=&#34;https://raw.githubusercontent.com/citusdata/citus/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; file explains how to get started developing the Citus extension itself and our code quality guidelines.&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Stay Connected&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Twitter&lt;/strong&gt;: Follow us &lt;a href=&#34;https://twitter.com/citusdata&#34;&gt;@citusdata&lt;/a&gt; to track the latest posts &amp;amp; updates on whatâ€™s happening.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Citus Blog&lt;/strong&gt;: Read our popular &lt;a href=&#34;https://www.citusdata.com/blog/&#34;&gt;Citus Open Source Blog&lt;/a&gt; for posts about PostgreSQL and Citus.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Citus Newsletter&lt;/strong&gt;: Subscribe to our monthly technical &lt;a href=&#34;https://www.citusdata.com/join-newsletter&#34;&gt;Citus Newsletter&lt;/a&gt; to get a curated collection of our favorite posts, videos, docs, talks, &amp;amp; other Postgres goodies.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Slack&lt;/strong&gt;: Our &lt;a href=&#34;https://slack.citusdata.com/&#34;&gt;Citus Public slack&lt;/a&gt; is a good way to stay connected, not just with us but with other Citus users.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Sister Blog&lt;/strong&gt;: Read the PostgreSQL posts on the &lt;a href=&#34;https://devblogs.microsoft.com/cosmosdb/category/postgresql/&#34;&gt;Azure Cosmos DB for PostgreSQL blog&lt;/a&gt; about our managed service on Azure.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Videos&lt;/strong&gt;: Check out this &lt;a href=&#34;https://www.youtube.com/playlist?list=PLixnExCn6lRq261O0iwo4ClYxHpM9qfVy&#34;&gt;YouTube playlist&lt;/a&gt; of some of our favorite Citus videos and demos. If you want to deep dive into how Citus extends PostgreSQL, you might want to check out Marco Slotâ€™s talk at Carnegie Mellon titled &lt;a href=&#34;https://youtu.be/X-aAgXJZRqM&#34;&gt;Citus: Distributed PostgreSQL as an Extension&lt;/a&gt; that was part of Andy Pavloâ€™s Vaccination Database Talks series at CMUDB.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Our other Postgres projects&lt;/strong&gt;: Our team also works on other awesome PostgreSQL open source extensions &amp;amp; projects, including: &lt;a href=&#34;https://github.com/citusdata/pg_cron&#34;&gt;pg_cron&lt;/a&gt;, &lt;a href=&#34;https://github.com/citusdata/postgresql-hll&#34;&gt;HyperLogLog&lt;/a&gt;, &lt;a href=&#34;https://github.com/citusdata/postgresql-topn&#34;&gt;TopN&lt;/a&gt;, &lt;a href=&#34;https://github.com/citusdata/pg_auto_failover&#34;&gt;pg_auto_failover&lt;/a&gt;, &lt;a href=&#34;https://github.com/citusdata/activerecord-multi-tenant&#34;&gt;activerecord-multi-tenant&lt;/a&gt;, and &lt;a href=&#34;https://github.com/citusdata/django-multitenant&#34;&gt;django-multitenant&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Copyright Â© Citus Data, Inc.&lt;/p&gt;</summary>
  </entry>
</feed>