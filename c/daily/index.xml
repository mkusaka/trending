<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-08T01:17:20Z</updated>
  <subtitle>Daily Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>deepinsight/insightface</title>
    <updated>2024-05-08T01:17:20Z</updated>
    <id>tag:github.com,2024-05-08:/deepinsight/insightface</id>
    <link href="https://github.com/deepinsight/insightface" rel="alternate"></link>
    <summary type="html">&lt;p&gt;State-of-the-art 2D and 3D Face Analysis Project&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;InsightFace: 2D and 3D Face Analysis Project&lt;/h1&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;img src=&#34;https://insightface.ai/assets/img/custom/logo3.jpg&#34; width=&#34;240&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;InsightFace project is mainly maintained By &lt;a href=&#34;mailto:guojia@gmail.com?subject=%5BGitHub%5D%20InsightFace%20Project&#34;&gt;Jia Guo&lt;/a&gt; and &lt;a href=&#34;https://jiankangdeng.github.io/&#34;&gt;Jiankang Deng&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For all main contributors, please check &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/#contributing&#34;&gt;contributing&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code of InsightFace is released under the MIT License. There is no limitation for both academic and commercial usage.&lt;/p&gt; &#xA;&lt;p&gt;The training data containing the annotation (and the models trained with these data) are available for non-commercial research purposes only.&lt;/p&gt; &#xA;&lt;p&gt;Both manual-downloading models from our github repo and auto-downloading models with our &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/python-package&#34;&gt;python-library&lt;/a&gt; follow the above license policy(which is for non-commercial research purposes only).&lt;/p&gt; &#xA;&lt;h2&gt;Top News&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2024-05-04&lt;/code&gt;&lt;/strong&gt; We have added &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/cpp-package/inspireface&#34;&gt;InspireFace&lt;/a&gt;, which is a cross-platform face recognition SDK developed in C/C++, supporting multiple operating systems and various backends.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2024-04-17&lt;/code&gt;&lt;/strong&gt;: &lt;a href=&#34;https://arxiv.org/abs/2404.00301&#34;&gt;Monocular Identity-Conditioned Facial Reflectance Reconstruction&lt;/a&gt; accepted by &lt;a href=&#34;https://cvpr.thecvf.com/Conferences/2024&#34;&gt;CVPR-2024&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2023-04-01&lt;/code&gt;&lt;/strong&gt;: We move the swapping demo to Discord bot, which support editing on Midjourney generated images, see detail at &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/web-demos/swapping_discord&#34;&gt;web-demos/swapping_discord&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2022-08-12&lt;/code&gt;&lt;/strong&gt;: We achieved Rank-1st of &lt;a href=&#34;https://tianchi.aliyun.com/competition/entrance/531961/introduction&#34;&gt;Perspective Projection Based Monocular 3D Face Reconstruction Challenge&lt;/a&gt; of &lt;a href=&#34;https://sites.google.com/view/wcpa2022&#34;&gt;ECCV-2022 WCPA Workshop&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2208.07142&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/reconstruction/jmlr&#34;&gt;code&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2021-11-30&lt;/code&gt;&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/challenges/mfr&#34;&gt;MFR-Ongoing&lt;/a&gt; challenge launched(same with IFRT), which is an extended version of &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/challenges/iccv21-mfr&#34;&gt;iccv21-mfr&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2021-10-29&lt;/code&gt;&lt;/strong&gt;: We achieved 1st place on the &lt;a href=&#34;https://pages.nist.gov/frvt/plots/11/visa.html&#34;&gt;VISA track&lt;/a&gt; of &lt;a href=&#34;https://pages.nist.gov/frvt/html/frvt11.html&#34;&gt;NIST-FRVT 1:1&lt;/a&gt; by using Partial FC (Xiang An, Jiankang Deng, Jia Guo).&lt;/p&gt; &#xA;&lt;h2&gt;ChangeLogs&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2024-05-04&lt;/code&gt;&lt;/strong&gt; We have added &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/cpp-package/inspireface&#34;&gt;InspireFace&lt;/a&gt;, which is a cross-platform face recognition SDK developed in C/C++, supporting multiple operating systems and various backends.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2024-04-17&lt;/code&gt;&lt;/strong&gt;: &lt;a href=&#34;https://arxiv.org/abs/2404.00301&#34;&gt;Monocular Identity-Conditioned Facial Reflectance Reconstruction&lt;/a&gt; accepted by &lt;a href=&#34;https://cvpr.thecvf.com/Conferences/2024&#34;&gt;CVPR-2024&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2023-08-08&lt;/code&gt;&lt;/strong&gt;: We released the implementation of &lt;a href=&#34;https://arxiv.org/abs/2212.02997&#34;&gt;Generalizing Gaze Estimation with Weak-Supervision from Synthetic Views&lt;/a&gt; at &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/reconstruction/gaze&#34;&gt;reconstruction/gaze&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2023-05-03&lt;/code&gt;&lt;/strong&gt;: We have launched the ongoing version of wild face anti-spoofing challenge. See details &lt;a href=&#34;https://github.com/deepinsight/insightface/tree/master/challenges/cvpr23-fas-wild#updates&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2023-04-01&lt;/code&gt;&lt;/strong&gt;: We move the swapping demo to Discord bot, which support editing on Midjourney generated images, see detail at &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/web-demos/swapping_discord&#34;&gt;web-demos/swapping_discord&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2023-02-13&lt;/code&gt;&lt;/strong&gt;: We launch a large scale in the wild face anti-spoofing challenge on CVPR23 Workshop, see details at &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/challenges/cvpr23-fas-wild&#34;&gt;challenges/cvpr23-fas-wild&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2022-11-28&lt;/code&gt;&lt;/strong&gt;: Single line code for facial identity swapping in our python packge ver 0.7, please check the example &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/examples/in_swapper&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2022-10-28&lt;/code&gt;&lt;/strong&gt;: &lt;a href=&#34;http://iccv21-mfr.com&#34;&gt;MFR-Ongoing&lt;/a&gt; website is refactored, please create issues if there&#39;s any bug.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2022-09-22&lt;/code&gt;&lt;/strong&gt;: Now we have &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/web-demos&#34;&gt;web-demos&lt;/a&gt;: &lt;a href=&#34;http://demo.insightface.ai:7007/&#34;&gt;face-localization&lt;/a&gt;, &lt;a href=&#34;http://demo.insightface.ai:7008/&#34;&gt;face-recognition&lt;/a&gt;, and &lt;a href=&#34;http://demo.insightface.ai:7009/&#34;&gt;face-swapping&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2022-08-12&lt;/code&gt;&lt;/strong&gt;: We achieved Rank-1st of &lt;a href=&#34;https://tianchi.aliyun.com/competition/entrance/531961/introduction&#34;&gt;Perspective Projection Based Monocular 3D Face Reconstruction Challenge&lt;/a&gt; of &lt;a href=&#34;https://sites.google.com/view/wcpa2022&#34;&gt;ECCV-2022 WCPA Workshop&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2208.07142&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/reconstruction/jmlr&#34;&gt;code&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2022-03-30&lt;/code&gt;&lt;/strong&gt;: &lt;a href=&#34;https://arxiv.org/abs/2203.15565&#34;&gt;Partial FC&lt;/a&gt; accepted by CVPR-2022.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2022-02-23&lt;/code&gt;&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/detection/scrfd&#34;&gt;SCRFD&lt;/a&gt; accepted by &lt;a href=&#34;https://iclr.cc/Conferences/2022&#34;&gt;ICLR-2022&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2021-11-30&lt;/code&gt;&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/challenges/mfr&#34;&gt;MFR-Ongoing&lt;/a&gt; challenge launched(same with IFRT), which is an extended version of &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/challenges/iccv21-mfr&#34;&gt;iccv21-mfr&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2021-10-29&lt;/code&gt;&lt;/strong&gt;: We achieved 1st place on the &lt;a href=&#34;https://pages.nist.gov/frvt/plots/11/visa.html&#34;&gt;VISA track&lt;/a&gt; of &lt;a href=&#34;https://pages.nist.gov/frvt/html/frvt11.html&#34;&gt;NIST-FRVT 1:1&lt;/a&gt; by using Partial FC (Xiang An, Jiankang Deng, Jia Guo).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2021-10-11&lt;/code&gt;&lt;/strong&gt;: &lt;a href=&#34;https://insightface.ai/mfr21&#34;&gt;Leaderboard&lt;/a&gt; of &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/challenges/iccv21-mfr&#34;&gt;ICCV21 - Masked Face Recognition Challenge&lt;/a&gt; released. Video: &lt;a href=&#34;https://www.youtube.com/watch?v=lL-7l5t6x2w&#34;&gt;Youtube&lt;/a&gt;, &lt;a href=&#34;https://www.bilibili.com/video/BV15b4y1h79N/&#34;&gt;Bilibili&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;2021-06-05&lt;/code&gt;&lt;/strong&gt;: We launch a &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/challenges/iccv21-mfr&#34;&gt;Masked Face Recognition Challenge &amp;amp; Workshop&lt;/a&gt; on ICCV 2021.&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://insightface.ai&#34;&gt;InsightFace&lt;/a&gt; is an open source 2D&amp;amp;3D deep face analysis toolbox, mainly based on PyTorch and MXNet.&lt;/p&gt; &#xA;&lt;p&gt;Please check our &lt;a href=&#34;https://insightface.ai&#34;&gt;website&lt;/a&gt; for detail.&lt;/p&gt; &#xA;&lt;p&gt;The master branch works with &lt;strong&gt;PyTorch 1.6+&lt;/strong&gt; and/or &lt;strong&gt;MXNet=1.6-1.8&lt;/strong&gt;, with &lt;strong&gt;Python 3.x&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;InsightFace efficiently implements a rich variety of state of the art algorithms of face recognition, face detection and face alignment, which optimized for both training and deployment.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Please start with our &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/python-package/&#34;&gt;python-package&lt;/a&gt;, for testing detection, recognition and alignment models on input images.&lt;/p&gt; &#xA;&lt;h3&gt;ArcFace Video Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=y-D1tReryGA&amp;amp;t=81s&#34;&gt;&lt;img src=&#34;https://insightface.ai/assets/img/github/facerecognitionfromvideo.PNG&#34; width=&#34;760&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please click the image to watch the Youtube video. For Bilibili users, click &lt;a href=&#34;https://www.bilibili.com/video/av38041494?from=search&amp;amp;seid=11501833604850032313&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Projects&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://insightface.ai/projects&#34;&gt;page&lt;/a&gt; on InsightFace website also describes all supported projects in InsightFace.&lt;/p&gt; &#xA;&lt;p&gt;You may also interested in some &lt;a href=&#34;https://insightface.ai/challenges&#34;&gt;challenges&lt;/a&gt; hold by InsightFace.&lt;/p&gt; &#xA;&lt;h2&gt;Face Recognition&lt;/h2&gt; &#xA;&lt;h3&gt;Introduction&lt;/h3&gt; &#xA;&lt;p&gt;In this module, we provide training data, network settings and loss designs for deep face recognition.&lt;/p&gt; &#xA;&lt;p&gt;The supported methods are as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/arcface_mxnet&#34;&gt;ArcFace_mxnet (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/arcface_torch&#34;&gt;ArcFace_torch (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/subcenter_arcface&#34;&gt;SubCenter ArcFace (ECCV&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/partial_fc&#34;&gt;PartialFC_mxnet (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/arcface_torch&#34;&gt;PartialFC_torch (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/vpl&#34;&gt;VPL (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/arcface_oneflow&#34;&gt;Arcface_oneflow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/arcface_paddle&#34;&gt;ArcFace_Paddle (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Commonly used network backbones are included in most of the methods, such as IResNet, MobilefaceNet, MobileNet, InceptionResNet_v2, DenseNet, etc..&lt;/p&gt; &#xA;&lt;h3&gt;Datasets&lt;/h3&gt; &#xA;&lt;p&gt;The training data includes, but not limited to the cleaned MS1M, VGG2 and CASIA-Webface datasets, which were already packed in MXNet binary format. Please &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/_datasets_&#34;&gt;dataset&lt;/a&gt; page for detail.&lt;/p&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;We provide standard IJB and Megaface evaluation pipelines in &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/recognition/_evaluation_&#34;&gt;evaluation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Pretrained Models&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please check &lt;a href=&#34;https://github.com/deepinsight/insightface/wiki/Model-Zoo&#34;&gt;Model-Zoo&lt;/a&gt; for more pretrained models.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Third-party Re-implementation of ArcFace&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;TensorFlow: &lt;a href=&#34;https://github.com/auroua/InsightFace_TF&#34;&gt;InsightFace_TF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TensorFlow: &lt;a href=&#34;https://github.com/AIInAi/tf-insightface&#34;&gt;tf-insightface&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TensorFlow:&lt;a href=&#34;https://github.com/Fei-Wang/insightface&#34;&gt;insightface&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;PyTorch: &lt;a href=&#34;https://github.com/TreB1eN/InsightFace_Pytorch&#34;&gt;InsightFace_Pytorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;PyTorch: &lt;a href=&#34;https://github.com/ronghuaiyang/arcface-pytorch&#34;&gt;arcface-pytorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Caffe: &lt;a href=&#34;https://github.com/xialuxi/arcface-caffe&#34;&gt;arcface-caffe&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Caffe: &lt;a href=&#34;https://github.com/gehaocool/CombinedMargin-caffe&#34;&gt;CombinedMargin-caffe&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Tensorflow: &lt;a href=&#34;https://github.com/luckycallor/InsightFace-tensorflow&#34;&gt;InsightFace-tensorflow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TensorRT: &lt;a href=&#34;https://github.com/wang-xinyu/tensorrtx&#34;&gt;wang-xinyu/tensorrtx&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TensorRT: &lt;a href=&#34;https://github.com/SthPhoenix/InsightFace-REST&#34;&gt;InsightFace-REST&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ONNXRuntime C++: &lt;a href=&#34;https://github.com/DefTruth/lite.ai.toolkit/raw/main/lite/ort/cv/glint_arcface.cpp&#34;&gt;ArcFace-ONNXRuntime&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ONNXRuntime Go: &lt;a href=&#34;https://github.com/jack139/arcface-go&#34;&gt;arcface-go&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;MNN: &lt;a href=&#34;https://github.com/DefTruth/lite.ai.toolkit/raw/main/lite/mnn/cv/mnn_glint_arcface.cpp&#34;&gt;ArcFace-MNN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TNN: &lt;a href=&#34;https://github.com/DefTruth/lite.ai.toolkit/raw/main/lite/tnn/cv/tnn_glint_arcface.cpp&#34;&gt;ArcFace-TNN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;NCNN: &lt;a href=&#34;https://github.com/DefTruth/lite.ai.toolkit/raw/main/lite/ncnn/cv/ncnn_glint_arcface.cpp&#34;&gt;ArcFace-NCNN&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Face Detection&lt;/h2&gt; &#xA;&lt;h3&gt;Introduction&lt;/h3&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;img src=&#34;https://insightface.ai/assets/img/github/11513D05.jpg&#34; width=&#34;640&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;In this module, we provide training data with annotation, network settings and loss designs for face detection training, evaluation and inference.&lt;/p&gt; &#xA;&lt;p&gt;The supported methods are as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/detection/retinaface&#34;&gt;RetinaFace (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/detection/scrfd&#34;&gt;SCRFD (Arxiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/detection/blazeface_paddle&#34;&gt;blazeface_paddle&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/detection/retinaface&#34;&gt;RetinaFace&lt;/a&gt; is a practical single-stage face detector which is accepted by &lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/html/Deng_RetinaFace_Single-Shot_Multi-Level_Face_Localisation_in_the_Wild_CVPR_2020_paper.html&#34;&gt;CVPR 2020&lt;/a&gt;. We provide training code, training dataset, pretrained models and evaluation scripts.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/detection/scrfd&#34;&gt;SCRFD&lt;/a&gt; is an efficient high accuracy face detection approach which is initialy described in &lt;a href=&#34;https://arxiv.org/abs/2105.04714&#34;&gt;Arxiv&lt;/a&gt;. We provide an easy-to-use pipeline to train high efficiency face detectors with NAS supporting.&lt;/p&gt; &#xA;&lt;h2&gt;Face Alignment&lt;/h2&gt; &#xA;&lt;h3&gt;Introduction&lt;/h3&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;img src=&#34;https://insightface.ai/assets/img/custom/thumb_sdunet.png&#34; width=&#34;600&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;In this module, we provide datasets and training/inference pipelines for face alignment.&lt;/p&gt; &#xA;&lt;p&gt;Supported methods:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/alignment/heatmap&#34;&gt;SDUNets (BMVC&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/alignment/coordinate_reg&#34;&gt;SimpleRegression&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/alignment/heatmap&#34;&gt;SDUNets&lt;/a&gt; is a heatmap based method which accepted on &lt;a href=&#34;http://bmvc2018.org/contents/papers/0051.pdf&#34;&gt;BMVC&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepinsight/insightface/master/alignment/coordinate_reg&#34;&gt;SimpleRegression&lt;/a&gt; provides very lightweight facial landmark models with fast coordinate regression. The input of these models is loose cropped face image while the output is the direct landmark coordinates.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find &lt;em&gt;InsightFace&lt;/em&gt; useful in your research, please consider to cite the following related papers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{ren2023pbidr,&#xA;  title={Facial Geometric Detail Recovery via Implicit Representation},&#xA;  author={Ren, Xingyu and Lattas, Alexandros and Gecer, Baris and Deng, Jiankang and Ma, Chao and Yang, Xiaokang},&#xA;  booktitle={2023 IEEE 17th International Conference on Automatic Face and Gesture Recognition (FG)},  &#xA;  year={2023}&#xA; }&#xA;&#xA;@article{guo2021sample,&#xA;  title={Sample and Computation Redistribution for Efficient Face Detection},&#xA;  author={Guo, Jia and Deng, Jiankang and Lattas, Alexandros and Zafeiriou, Stefanos},&#xA;  journal={arXiv preprint arXiv:2105.04714},&#xA;  year={2021}&#xA;}&#xA;&#xA;@inproceedings{gecer2021ostec,&#xA;  title={OSTeC: One-Shot Texture Completion},&#xA;  author={Gecer, Baris and Deng, Jiankang and Zafeiriou, Stefanos},&#xA;  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},&#xA;  year={2021}&#xA;}&#xA;&#xA;@inproceedings{an2020partical_fc,&#xA;  title={Partial FC: Training 10 Million Identities on a Single Machine},&#xA;  author={An, Xiang and Zhu, Xuhan and Xiao, Yang and Wu, Lan and Zhang, Ming and Gao, Yuan and Qin, Bin and&#xA;  Zhang, Debing and Fu Ying},&#xA;  booktitle={Arxiv 2010.05222},&#xA;  year={2020}&#xA;}&#xA;&#xA;@inproceedings{deng2020subcenter,&#xA;  title={Sub-center ArcFace: Boosting Face Recognition by Large-scale Noisy Web Faces},&#xA;  author={Deng, Jiankang and Guo, Jia and Liu, Tongliang and Gong, Mingming and Zafeiriou, Stefanos},&#xA;  booktitle={Proceedings of the IEEE Conference on European Conference on Computer Vision},&#xA;  year={2020}&#xA;}&#xA;&#xA;@inproceedings{Deng2020CVPR,&#xA;title = {RetinaFace: Single-Shot Multi-Level Face Localisation in the Wild},&#xA;author = {Deng, Jiankang and Guo, Jia and Ververas, Evangelos and Kotsia, Irene and Zafeiriou, Stefanos},&#xA;booktitle = {CVPR},&#xA;year = {2020}&#xA;}&#xA;&#xA;@inproceedings{guo2018stacked,&#xA;  title={Stacked Dense U-Nets with Dual Transformers for Robust Face Alignment},&#xA;  author={Guo, Jia and Deng, Jiankang and Xue, Niannan and Zafeiriou, Stefanos},&#xA;  booktitle={BMVC},&#xA;  year={2018}&#xA;}&#xA;&#xA;@article{deng2018menpo,&#xA;  title={The Menpo benchmark for multi-pose 2D and 3D facial landmark localisation and tracking},&#xA;  author={Deng, Jiankang and Roussos, Anastasios and Chrysos, Grigorios and Ververas, Evangelos and Kotsia, Irene and Shen, Jie and Zafeiriou, Stefanos},&#xA;  journal={IJCV},&#xA;  year={2018}&#xA;}&#xA;&#xA;@inproceedings{deng2018arcface,&#xA;title={ArcFace: Additive Angular Margin Loss for Deep Face Recognition},&#xA;author={Deng, Jiankang and Guo, Jia and Niannan, Xue and Zafeiriou, Stefanos},&#xA;booktitle={CVPR},&#xA;year={2019}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Main contributors:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nttstar&#34;&gt;Jia Guo&lt;/a&gt;, &lt;code&gt;guojia[at]gmail.com&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jiankangdeng&#34;&gt;Jiankang Deng&lt;/a&gt; &lt;code&gt;jiankangdeng[at]gmail.com&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/anxiangsir&#34;&gt;Xiang An&lt;/a&gt; &lt;code&gt;anxiangsir[at]gmail.com&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/szad670401&#34;&gt;Jack Yu&lt;/a&gt; &lt;code&gt;jackyu961127[at]gmail.com&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://barisgecer.github.io/&#34;&gt;Baris Gecer&lt;/a&gt; &lt;code&gt;barisgecer[at]msn.com&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>