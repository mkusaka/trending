<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-31T01:29:59Z</updated>
  <subtitle>Daily Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>UberGuidoZ/Flipper</title>
    <updated>2022-12-31T01:29:59Z</updated>
    <id>tag:github.com,2022-12-31:/UberGuidoZ/Flipper</id>
    <link href="https://github.com/UberGuidoZ/Flipper" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Playground (and dump) of stuff I make or modify for the Flipper Zero&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Playground (and dump) of stuff I made, modified, researched, or found for the Flipper Zero.&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Looking for Infrared (IR) codes? Head over to &lt;a href=&#34;https://github.com/UberGuidoZ/Flipper-IRDB&#34;&gt;the IRDB&lt;/a&gt;! Just want to download part of any repo? &lt;a href=&#34;https://uberguidoz.github.io/DownGit/&#34;&gt;Try over here&lt;/a&gt;!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re new to github in general, there is a rough/basic guide over on the Official Discord &lt;a href=&#34;https://discord.com/channels/740930220399525928/986635575664726026/1042979075905556520&#34;&gt;in this thread&lt;/a&gt;. Link not available? &lt;a href=&#34;https://discord.com/invite/flipper&#34;&gt;Try this first&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Donation Information&lt;/h2&gt; &#xA;&lt;p&gt;Nothing is ever expected for the hoarding of digital files, creations I have made, or the people I may have helped.&lt;/p&gt; &#xA;&lt;h2&gt;Ordering from Lab401? &lt;a href=&#34;https://lab401.com/r?id=vsmgoc&#34;&gt;USE THIS LINK FOR 5% OFF!&lt;/a&gt; (Or code &lt;code&gt;UberGuidoZ&lt;/code&gt; at checkout.)&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;ve had so many asking for me to add this.&lt;br&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/57457139/183561666-4424a3cc-679b-4016-a368-24f7e7ad0a88.jpg&#34; alt=&#34;Flipper_Blush&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/57457139/183561692-381d37bd-264f-4c88-8877-e58d60d9be6e.jpg&#34; alt=&#34;Flipper_Love&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;BTC&lt;/strong&gt;: &lt;code&gt;3AWgaL3FxquakP15ZVDxr8q8xVTc5Q75dS&lt;/code&gt;&lt;br&gt; &lt;strong&gt;BCH&lt;/strong&gt;: &lt;code&gt;17nWCvf2YPMZ3F3H1seX8T149Z9E3BMKXk&lt;/code&gt;&lt;br&gt; &lt;strong&gt;ETH&lt;/strong&gt;: &lt;code&gt;0x0f0003fCB0bD9355Ad7B124c30b9F3D860D5E191&lt;/code&gt;&lt;br&gt; &lt;strong&gt;LTC&lt;/strong&gt;: &lt;code&gt;M8Ujk52U27bkm1ksiWUyteL8b3rRQVMke2&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;So, here it is. All donations of &lt;em&gt;any&lt;/em&gt; size are humbly appreciated.&lt;br&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/57457139/183561789-2e853ede-8ef7-41e8-a67c-716225177e5d.jpg&#34; alt=&#34;Flipper_Clap&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/57457139/183561787-e21bdc1e-b316-4e67-b327-5129503d0313.jpg&#34; alt=&#34;Flipper_OMG&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Donations will be used for hardware (and maybe caffeine) to further testing!&lt;br&gt; &lt;img src=&#34;https://cdn.discordapp.com/emojis/1000632669622767686.gif&#34; alt=&#34;UberGuidoZ&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>SalahAssana/Lethe</title>
    <updated>2022-12-31T01:29:59Z</updated>
    <id>tag:github.com,2022-12-31:/SalahAssana/Lethe</id>
    <link href="https://github.com/SalahAssana/Lethe" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Project Lethe is a privacy-preserving indoor localization system designed to allow for room-level localization of individuals in a home or building.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Project Lethe: Privacy-Preserving Indoor Localization System&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/SalahAssana/Lethe/raw/master/md_files/figures/Lethe_Animation.gif&#34; alt=&#34;Animation summary of Lethe system.&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Named after &lt;a href=&#34;https://en.wikipedia.org/wiki/Lethe&#34;&gt;the river Lethe&lt;/a&gt; from Greek mythology, project Lethe is a privacy-preserving indoor localization system designed to allow for room-level localization of individuals in a home or building. The system preserves user anonymity by using a novel detection algorithm that limits both the memory available onboard the camera and the data rate of camera communication to prevent a full image from being extracted. Briefly, the algorithm detects the direction of movement by breaking the camera&#39;s FOV into three quadrants and tracking the order in which the person enters and exits each quadrant.&lt;/p&gt; &#xA;&lt;h1&gt;System Design&lt;/h1&gt; &#xA;&lt;p&gt;Lethe consists of both a custom-built hardware system and a novel data processing pipeline.&lt;/p&gt; &#xA;&lt;h2&gt;Hardware Components&lt;/h2&gt; &#xA;&lt;h3&gt;FLIR Thermal Sensor&lt;/h3&gt; &#xA;&lt;p&gt;The system utilizes a &lt;a href=&#34;https://www.sparkfun.com/products/16465&#34;&gt;FLIR Lepton Thermal Imaging Module&lt;/a&gt; as the main component of its detection module. The thermal imager captures infrared radiation input in its nominal response wavelength band (from 8 to 14 microns) and has a thermal sensitivity of 50 milli-Kelvins. The imager has an effective frame rate of 8.6 Hz and a resolution of 60 (w) × 80 (h) active pixels (each 17 μm in size and covering a 0.6375-degree angle).&lt;/p&gt; &#xA;&lt;h3&gt;Breakout Board&lt;/h3&gt; &#xA;&lt;p&gt;The thermal imager is embedded in a breakout board which provides the socket for the Lepton, on-board power supplies, 25Mhz reference clock (can be by-passed), power-efficient 1.2v core voltage (can be by-passed), dual low noise LDO for 2.8V voltage (can be by-passed), 100 mil header for use in a breadboard or wiring to any host system. A few things to consider about this kit: the breakout board will accept a 3-5.5V input and regulate it to what the Lepton® wants, to read an image from the lepton module all you need is an SPI port, and to configure the camera settings you also need an I2C port, although this is not required.&lt;/p&gt; &#xA;&lt;h3&gt;Raspberry Pi 1&lt;/h3&gt; &#xA;&lt;p&gt;Frames obtained by the thermal imager are sent over an SPI port to the Pi, where each pixel is processed independently and then permanently deleted. The stream of pixel values is processed by a novel algorithm that determines the direction of the crossing.&lt;/p&gt; &#xA;&lt;h2&gt;Software Components&lt;/h2&gt; &#xA;&lt;h3&gt;Customized Driver&lt;/h3&gt; &#xA;&lt;p&gt;The FLIR Thermal Module is operated using a custom written driver which uses a limited memory buffer to transfer one pixel at a time.&lt;/p&gt; &#xA;&lt;h3&gt;Presence Detection&lt;/h3&gt; &#xA;&lt;p&gt;We detect the presence of a person in the field of view based on their temperature. Indoor environments are typically air-conditioned to a 20°C to 22°C range and most objects in the environment conform to this temperature. Human skin temperature ranges between 32°C and 34°C. Additionally, hair and clothing tend to absorb the skin’s heat and retain a temperature lower than skin temperature, but higher than the surrounding environment (e.g., 25°C to 30°C). Hence, a person can be detected in the view of a thermal camera by identifying pixels that are warmer than the background temperature. . In Lethe, we determine the background temperature &lt;img src=&#34;https://latex.codecogs.com/svg.image?r_%7Bback%7D&#34; alt=&#34;&#34;&gt; as the average temperature of the last frame absent human presence. This value is updated with each new human-less frame to adjust the background temperature to changes in the environment temperature. We detect a human in a pixel whenever that pixel has a value &lt;img src=&#34;https://latex.codecogs.com/svg.image?r_%7Bthresh%7D&#34; alt=&#34;&#34;&gt; degrees higher than the background reference &lt;img src=&#34;https://latex.codecogs.com/svg.image?r_%7Bback%7D&#34; alt=&#34;&#34;&gt; . If at any point in the streaming evaluation of a frame a pixel passes this threshold, the frame is declared as having a presence. If this is the beginning of an event, &lt;img src=&#34;https://latex.codecogs.com/svg.image?t_s&#34; alt=&#34;&#34;&gt; is updated. Once a person is detected, we consider all frames 0.366 seconds after the last frame with a presence ( &lt;img src=&#34;https://latex.codecogs.com/svg.image?t_last&#34; alt=&#34;&#34;&gt;) to be part of the event. This aims to cover any gap caused by lost frames in an event, without merging two events in succession. This lag time value is conservatively based on the average walking speed of a person (1.39 m/s) and the average shoulder span of an adult male (0.508 m)&lt;/p&gt; &#xA;&lt;h3&gt;Direction Detection&lt;/h3&gt; &#xA;&lt;p&gt;Once presence detection has ended an event with the creation of the ( &lt;img src=&#34;https://latex.codecogs.com/svg.image?t_s&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?t_e&#34; alt=&#34;&#34;&gt;) tuple, direction detection either assigns a direction d to that event or removes that event as a non-crossing interaction. Direction detection collects the information needed to make this determination in parallel to presence detection. Each streaming pixel evaluated by presence detection is also used by direction. Direction detection uses the same &lt;img src=&#34;https://latex.codecogs.com/svg.image?r_%7Bback%7D&#34; alt=&#34;&#34;&gt; and &lt;img src=&#34;https://latex.codecogs.com/svg.image?r_%7Bthresh%7D&#34; alt=&#34;&#34;&gt; as presence to determine if someone is present in a pixel. However, direction detection goes beyond presence to use this information to determine a person’s location in the frame and how that location changes over time. When a person crosses through the field of view they first appear on one side of the frame and then progress in intervals to the other side before leaving the field of view. A canonical example of this behavior can be seen in the figure above. Lethe captures the progress of the person over time through the field of view by leftmost sector and rightmost sector location of the person in frame &lt;img src=&#34;https://latex.codecogs.com/svg.image?i&#34; alt=&#34;&#34;&gt;. If the pixels of a frame are processed from left to right, this means Lethe sets &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc&#34; alt=&#34;&#34;&gt; to the column of the first pixel with a human presence and loci to the column of the last pixel with a human presence. In this way, Lethe identifies the region a person is located in for each frame.&lt;/p&gt; &#xA;&lt;h1&gt;Privacy Preserving Algorithm&lt;/h1&gt; &#xA;&lt;p&gt;The Lethe thermal camera requires only 21 values in memory for it&#39;s operation. For the detection algorithms, 4 values are required for presence detection ( &lt;img src=&#34;https://latex.codecogs.com/svg.image?t_s&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?t_e&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?r_%7Bback%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?t_last&#34; alt=&#34;&#34;&gt;), 12 values for direction ( &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Bl1%7D%5Ei&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Br1%7D%5Ei&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Bl1%7D%5E%7Bi-1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Br1%7D%5E%7Bi-1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bind1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Bl2%7D%5Ei&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Br2%7D%5Ei&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Bl2%7D%5E%7Bi-1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Br2%7D%5E%7Bi-1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bind2%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum2%7D&#34; alt=&#34;&#34;&gt;), and a single value for pixel height detection ( &lt;img src=&#34;https://latex.codecogs.com/svg.image?h_%7Bpixel%7D&#34; alt=&#34;&#34;&gt;). Additionally, the thermal camera requires space to store the current pixel temperature the current location of the pixel (row and column), and the current time of the device. Reference information, such as the height and width of the image, the lag time allowed in frames, and the &lt;img src=&#34;https://latex.codecogs.com/svg.image?r_%7Bthresh%7D&#34; alt=&#34;&#34;&gt; value can be kept statically. Many of the dynamic values, depending on the size of the image, can be represented using a single byte. Only the timestamps require a larger storage space at 4 bytes a piece. Hence the memory requirement for the Lethe thermal camera is only &lt;img src=&#34;https://latex.codecogs.com/svg.image?M=33&#34; alt=&#34;&#34;&gt; bytes. In the 60x80 pixel thermal camera used in this work, that means only 33 pixels (0.69%) of the image can ever be stored on the device.&lt;/p&gt; &#xA;&lt;h1&gt;Cross Detection&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/SalahAssana/Lethe/raw/master/md_files/figures/noncrossings_experiment.png&#34; alt=&#34;Examples of non-crossing events Lethe can distinguish.&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Once presence detection has ended an event with the creation of the ( &lt;img src=&#34;https://latex.codecogs.com/svg.image?t_s&#34; alt=&#34;&#34;&gt;,&lt;img src=&#34;https://latex.codecogs.com/svg.image?t_e&#34; alt=&#34;&#34;&gt;) tuple, direction detection either assigns a direction &lt;img src=&#34;https://latex.codecogs.com/svg.image?d&#34; alt=&#34;&#34;&gt; to that event or removes that event as a non-crossing interaction. Direction detection collects the information needed to make this determination in parallel to presence detection. Each streaming pixel evaluated by presence detection is also used by direction. Direction detection uses the same &lt;img src=&#34;https://latex.codecogs.com/svg.image?r_%7Bback%7D&#34; alt=&#34;&#34;&gt; and &lt;img src=&#34;https://latex.codecogs.com/svg.image?r_%7Bthresh%7D&#34; alt=&#34;&#34;&gt; as presence to determine if someone is present in a pixel. However, direction detection goes beyond presence to use this information to determine a person&#39;s location in the frame and how that location changes over time. When a person crosses through the field of view they first appear on one side of the frame and then progress in intervals to the other side before leaving the field of view. A canonical example of this behavior can be seen in the figure above. Lethe captures the progress of the person over time through the field of view by leftmost, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_l%5Ei&#34; alt=&#34;&#34;&gt;, and rightmost, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_r%5Ei&#34; alt=&#34;&#34;&gt;, the location of the person in frame &lt;img src=&#34;https://latex.codecogs.com/svg.image?i&#34; alt=&#34;&#34;&gt;. If the pixels of a frame are processed from left to right, this means Lethe sets &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_l%5Ei&#34; alt=&#34;&#34;&gt; to the column of the first pixel with a human presence and &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_r%5Ei&#34; alt=&#34;&#34;&gt; to the column of the last pixel with a human presence. In this way, Lethe identifies the region a person is located in for each frame.&lt;/p&gt; &#xA;&lt;p&gt;Once &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_l%5Ei&#34; alt=&#34;&#34;&gt; and &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_r%5Ei&#34; alt=&#34;&#34;&gt; for a human region have been identified the challenge becomes turning this information into a direction using limited memory. While we could retain each region for every frame and process the information once the event is over -- this would mean storing values double the number of frames in an event in memory. Since there is no limit on the number of frames in an event (a person could stand in the doorway for multiple minutes before walking through), this would not allow Lethe to maintain memory limitations. Instead, Lethe accumulates information about crossing direction by comparing only two regions at any given time. Each frame&#39;s region is compared to the stored region of the previous frame and assigned a direction indicator value: 1 if the region has shifted to the right, -1 if it has shifted to the left. Lethe retains only the sum of these direction indicators, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum%7D&#34; alt=&#34;&#34;&gt;, over multiple frames and assigns a direction, either left or right, based on the negative or positive value of &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum%7D&#34; alt=&#34;&#34;&gt; respectively at the end of the event.&lt;/p&gt; &#xA;&lt;p&gt;To detect and remove non-crossing events, Lethe identifies &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum%7D=0&#34; alt=&#34;&#34;&gt; as an event where a person entered and left from the same side of the field of view. However, the basic direction algorithm described above will fail in two scenarios: variable walking speeds and non-crossing events with a person on either side of the door. In the case of variable speed events, a person might walk slowly into the door and then quickly out the same side. Here, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum%7D&#34; alt=&#34;&#34;&gt; might equal &lt;img src=&#34;https://latex.codecogs.com/svg.image?1+1+1+1+1-1-1-1%20=%202&#34; alt=&#34;&#34;&gt; as the first five frame pairs indicated right and only the last three indicated left. Hence, the event would be mislabeled as a rightward crossing through the frame. To prevent this, only direction indicators that are different from the last indicator, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bind%7D&#34; alt=&#34;&#34;&gt;, are added to &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum%7D&#34; alt=&#34;&#34;&gt;. In our example, &lt;img src=&#34;https://latex.codecogs.com/svg.image?1+1+1+1+1-1-1-1%20=%202&#34; alt=&#34;&#34;&gt; would become &lt;img src=&#34;https://latex.codecogs.com/svg.image?1-1=0&#34; alt=&#34;&#34;&gt; and the event would be correctly identified as a non-crossing. This makes the algorithm agnostic to walking speed. Non-crossing events with a person on either side of the doorway are more complex. An example of such an event, where two people walk into the field of view to chat across the doorway, can be seen in the figure above. To identify these non-crossing events, we split the direction detection algorithm into two and determine a direction for each side of the doorway independently. Each side detects human regions and accumulates a direction sum (i.e. &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum1%7D&#34; alt=&#34;&#34;&gt; or &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum2%7D&#34; alt=&#34;&#34;&gt;). If &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum1%7D&#34; alt=&#34;&#34;&gt; and &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum2%7D&#34; alt=&#34;&#34;&gt; both indicate left or both indicate right, the event is given a direction. If both direction sums are 0 or different directions, then Lethe dismisses the event as a non-crossing event. Hence, Lethe now retains 12 pieces of information for any pair of frames: &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Bl1%7D%5Ei&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Br1%7D%5Ei&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Bl1%7D%5E%7Bi-1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Br1%7D%5E%7Bi-1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bind1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Bl2%7D%5Ei&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Br2%7D%5Ei&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Bl2%7D%5E%7Bi-1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?loc_%7Br2%7D%5E%7Bi-1%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bind2%7D&#34; alt=&#34;&#34;&gt;, &lt;img src=&#34;https://latex.codecogs.com/svg.image?d_%7Bsum2%7D&#34; alt=&#34;&#34;&gt;. With this information, Lethe determines the direction of crossing events and detects when a person has passed through the field of view but has not crossed the threshold.&lt;/p&gt; &#xA;&lt;h1&gt;Applications&lt;/h1&gt; &#xA;&lt;p&gt;Lethe is an adaptive system that could be utilized for multipule purposes.&lt;/p&gt; &#xA;&lt;h3&gt;Occupancy Monitoring&lt;/h3&gt; &#xA;&lt;p&gt;A simple application of the Lethe would be to use it to monitor the occupancy level of any multiroom building. For example, a hospital or clinic could use Lethe to quickly determine which rooms are available for use.&lt;/p&gt; &#xA;&lt;h3&gt;Smart Buildings&lt;/h3&gt; &#xA;&lt;p&gt;Smart buildings would benefit from a room-level occupancy monitoring system. While existing systems, such as motion detectors, could provide binary information on which rooms have occupants, Lethe provides a quantitative value. This allows buildings to go beyond simply turning lights on and off and would allow for dynamically setting HVAC usage.&lt;/p&gt; &#xA;&lt;h1&gt;Limitations &amp;amp; Future Works&lt;/h1&gt; &#xA;&lt;p&gt;While the Lethe prototype shows the potential of privacy-preserving image processing, there is still work to be done.&lt;/p&gt; &#xA;&lt;h3&gt;False Detections&lt;/h3&gt; &#xA;&lt;p&gt;While our experiments found a fairly uniform background temperature that was not disturbed by the floor-to-ceiling window in its field of view, the background may not be as uniform in all environments. Non-human hot objects, such as computers or laptops, may present a challenge in in-situ environments. They could either raise the average background temperature or mistakenly be identified as people. Furthermore, Lethe’s use of thermal cameras limits its use to environments that are cooler than human temperatures.&lt;/p&gt; &#xA;&lt;h3&gt;Limited Resolution&lt;/h3&gt; &#xA;&lt;p&gt;Due to thermal cameras only recently being made available for public domain use they have a limited resolution. Future work would include testing Lethe with a higher resolution and higher frame rate camera to see if our predictions of increased accuracy hold true. A 3 or greater camera system, as opposed to Lethe’s two, could also provide an increase in the accuracy of the system.&lt;/p&gt; &#xA;&lt;h3&gt;Multi-person Crossings&lt;/h3&gt; &#xA;&lt;p&gt;All testing was performed with a single person crossing through the sensors&#39; field of view. Multi-user occlusion also presents a limitation for Lethe, where people walking side-by-side or in quick succession are mislabeled as only a single crossing. For Lethe, 0.366 seconds must pass before another person can cross the doorway and be accurately detected. Further sensing from multiple viewpoints may mitigate this problem. For example, a camera placed at the top of the doorway could identify when two people cross side by side. Work in this direction may also lead towards solutions to multi-user phenomena, such as a person sitting in the field of view of the cameras while another person crosses through the doorway. An initial two object expansion to tracking in Lethe, where the recorded values in memory are doubled, could be the first step in that direction.&lt;/p&gt; &#xA;&lt;h3&gt;Virtual Barriers&lt;/h3&gt; &#xA;&lt;p&gt;In our testing, the sensor was mounted to the side of a door and tested to detect the crossing of a physical barrier such as doorways. However, the system could also be modified to detect a crossing inside of a room by limiting the sensors&#39; field of view and creating a &#34;virtual barrier&#34;.&lt;/p&gt; &#xA;&lt;h3&gt;Multi-sensor System&lt;/h3&gt; &#xA;&lt;p&gt;Just as the two binocular cameras in Lethe can localize a person’s heights, future work may look at localizing a person using a privacy-preserving image process in a space using cameras on two or more walls. Finally, would we be able to detect other human movements, such as coarse or fine-grained gestures, with this approach to provide privacy preservation to existing thermal imaging technologies?&lt;/p&gt; &#xA;&lt;h1&gt;Publications&lt;/h1&gt; &#xA;&lt;p&gt;Griffiths, Erin, Salah Assana, and Kamin Whitehouse. &#34;Privacy-preserving image processing with binocular thermal cameras.&#34; &lt;em&gt;Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies&lt;/em&gt; 1.4 (2018): 1-25. &lt;a href=&#34;https://web.archive.org/web/20190727022605id_/https://dam-prod.media.mit.edu/x/2018/10/17/a133-Griffiths_n3mIM1W.pdf&#34;&gt;[PDF]&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Citing&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{griffiths2018privacy,&#xA;  title={Privacy-preserving image processing with binocular thermal cameras},&#xA;  author={Griffiths, Erin and Assana, Salah and Whitehouse, Kamin},&#xA;  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},&#xA;  volume={1},&#xA;  number={4},&#xA;  pages={1--25},&#xA;  year={2018},&#xA;  publisher={ACM New York, NY, USA}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>