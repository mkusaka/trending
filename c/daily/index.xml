<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-18T01:31:31Z</updated>
  <subtitle>Daily Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>yhzhang0128/egos-2000</title>
    <updated>2023-05-18T01:31:31Z</updated>
    <id>tag:github.com,2023-05-18:/yhzhang0128/egos-2000</id>
    <link href="https://github.com/yhzhang0128/egos-2000" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A minimal operating system (2K LOC) on QEMU and a RISC-V board&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Vision&lt;/h2&gt; &#xA;&lt;p&gt;This project&#39;s vision is to help &lt;strong&gt;every&lt;/strong&gt; college student read &lt;strong&gt;all&lt;/strong&gt; the code of an operating system.&lt;/p&gt; &#xA;&lt;p&gt;With only &lt;strong&gt;2000&lt;/strong&gt; lines of code, egos-2000 implements every component of an operating system for education. It can run on a RISC-V board and also the QEMU software emulator.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yhzhang0128/egos-2000/main/references/screenshots/egos-2000.jpg&#34; alt=&#34;This is an image&#34;&gt; Note: &lt;a href=&#34;https://github.com/AlDanial/cloc&#34;&gt;&lt;strong&gt;cloc&lt;/strong&gt;&lt;/a&gt; was used to count the lines of code. The command below uses &lt;code&gt;cloc&lt;/code&gt; to count LOC of the whole repository, excluding text documents.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; cloc egos-2000 --exclude-ext=md,txt&#xA;...&#xA;github.com/AlDanial/cloc v 1.94  T=0.05 s (949.3 files/s, 62349.4 lines/s)&#xA;-------------------------------------------------------------------------------&#xA;Language                     files          blank        comment           code&#xA;-------------------------------------------------------------------------------&#xA;C                               37            510            665           1579&#xA;C/C++ Header                    10             68            105            285&#xA;Assembly                         4              6             31             72&#xA;make                             1             12              0             64&#xA;-------------------------------------------------------------------------------&#xA;SUM:                            52            596            801           2000 (exactly 2000 lines)&#xA;-------------------------------------------------------------------------------&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Earth and Grass Operating System&lt;/h2&gt; &#xA;&lt;p&gt;We use egos-2000 as a new teaching OS for &lt;a href=&#34;https://www.cs.cornell.edu/courses/cs4411/2022fa/schedule/&#34;&gt;CS5411/4411 at Cornell&lt;/a&gt;. It adopts a 3-layer architecture.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;strong&gt;earth layer&lt;/strong&gt; implements hardware-specific abstractions. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;tty and disk device interfaces&lt;/li&gt; &#xA;   &lt;li&gt;interrupt and memory management interfaces&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;The &lt;strong&gt;grass layer&lt;/strong&gt; implements hardware-independent abstractions. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;processes, system calls and inter-process communications&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;The &lt;strong&gt;application layer&lt;/strong&gt; implements file system, shell and user commands.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The definitions of &lt;code&gt;struct earth&lt;/code&gt; and &lt;code&gt;struct grass&lt;/code&gt; in &lt;a href=&#34;https://raw.githubusercontent.com/yhzhang0128/egos-2000/main/library/egos.h&#34;&gt;this header file&lt;/a&gt; specify the interfaces.&lt;/p&gt; &#xA;&lt;h3&gt;Usages and Documentation&lt;/h3&gt; &#xA;&lt;p&gt;For compiling and running egos-2000, please read &lt;a href=&#34;https://raw.githubusercontent.com/yhzhang0128/egos-2000/main/references/USAGES.md&#34;&gt;USAGES.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/yhzhang0128/egos-2000/main/references/riscv-privileged-v1.10.pdf&#34;&gt;RISC-V instruction set manual&lt;/a&gt; introduces the privileged ISA. The &lt;a href=&#34;https://raw.githubusercontent.com/yhzhang0128/egos-2000/main/references/sifive-fe310-v19p04.pdf&#34;&gt;SiFive FE310 manual&lt;/a&gt; introduces the memory map, especially the GPIO, UART and SPI bus controllers. &lt;a href=&#34;https://raw.githubusercontent.com/yhzhang0128/egos-2000/main/references/README.md&#34;&gt;This document&lt;/a&gt; further introduces the teaching plans, architecture and development history of egos-2000.&lt;/p&gt; &#xA;&lt;p&gt;For any questions, please contact &lt;a href=&#34;https://dolobyte.net/&#34;&gt;Yunhao Zhang&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Many thanks to &lt;a href=&#34;https://www.cs.cornell.edu/home/rvr/&#34;&gt;Robbert van Renesse&lt;/a&gt;, &lt;a href=&#34;https://www.cs.cornell.edu/lorenzo/&#34;&gt;Lorenzo Alvisi&lt;/a&gt;, &lt;a href=&#34;https://people.cs.uchicago.edu/~shanlu/&#34;&gt;Shan Lu&lt;/a&gt; and &lt;a href=&#34;https://www.cs.cornell.edu/~hweather/&#34;&gt;Hakim Weatherspoon&lt;/a&gt; for supporting this project. Many thanks to Meta for a &lt;a href=&#34;https://research.facebook.com/fellows/zhang-yunhao/&#34;&gt;Meta fellowship&lt;/a&gt;. Many thanks to all CS5411/4411 students at Cornell over the years for helping improve this course.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>toverainc/willow</title>
    <updated>2023-05-18T01:31:31Z</updated>
    <id>tag:github.com,2023-05-18:/toverainc/willow</id>
    <link href="https://github.com/toverainc/willow" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open source, local, and self-hosted Amazon Echo/Google Home competitive Voice Assistant alternative&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Hello Willow Users!&lt;/h1&gt; &#xA;&lt;p&gt;Many users across various forums, social media, etc are starting to receive their hardware! I have enabled Github &lt;a href=&#34;https://github.com/toverainc/willow/discussions&#34;&gt;discussions&lt;/a&gt; to centralize these great conversations - stop by, introduce yourself, and let us know how things are going with Willow! Between Github discussions and issues we can all work together to make sure our early adopters have the best experience possible!&lt;/p&gt; &#xA;&lt;h1&gt;Willow - A Practical, Open Source, Privacy-Focused Platform for Voice Assistants and other Applications&lt;/h1&gt; &#xA;&lt;p&gt;Willow is an &lt;a href=&#34;https://github.com/espressif/esp-idf&#34;&gt;ESP IDF&lt;/a&gt; based project primarily targetting the &lt;a href=&#34;https://github.com/espressif/esp-box&#34;&gt;ESP BOX&lt;/a&gt; hardware from Espressif. Our goal is to provide Amazon Echo/Google Home competitive performance, accuracy, cost, and functionality with &lt;a href=&#34;https://www.home-assistant.io/&#34;&gt;Home Assistant&lt;/a&gt; and other platforms - 100% open source and completely self-hosted by the user with &#34;ready for the kitchen counter&#34; low cost commercially available hardware.&lt;/p&gt; &#xA;&lt;img src=&#34;https://github.com/espressif/esp-box/raw/master/docs/_static/esp32_s3_box.png&#34; width=&#34;400px&#34;&gt; &#xA;&lt;p&gt;&lt;strong&gt;FAST&lt;/strong&gt; - &lt;a href=&#34;https://www.youtube.com/watch?v=8ETQaLfoImc&#34;&gt;Watch the demo&lt;/a&gt;. Response times faster than Alexa/Echo or Google Home. From end of speech to action completed in 500ms or less.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ACCURATE&lt;/strong&gt; - High wake word accuracy, low false activation, and powered by a server you host and control using Whisper or command recognition solely on the device.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;RELIABLE&lt;/strong&gt; - We&#39;ve tested thousands of cycles of voice commands with a &amp;lt; 1% failure rate. No one likes to repeat themselves!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;FLEXIBLE&lt;/strong&gt; - Use a server anywhere or don&#39;t use a server at all with command recognition on the device. Have the results go anywhere you want. Integrate with whatever you want. Completely open source so it does what you want, only what you want, and only how you want it. No more annoying extra prompts or sales pitches to upsell you. Supports multiple wake words with more coming soon.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PRIVATE&lt;/strong&gt; - Check the source. Build and flash yourself. Proxy through another server to inspect traffic. Use on your own server. Use only local commands. Use on a network without access to the internet. Dig as deep as you want because you&#39;re not going to find anything fishy here!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PRACTICAL AND NOT UGLY&lt;/strong&gt; - Ready to go! Take it out of the box, flash, and put it in your home or office in minutes without getting looks from people wondering what that &#34;thing&#34; is. Install as many as you like.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CHEAP&lt;/strong&gt; - Approximately $50 hardware cost (plus USB-C power supply). Fully assembled. Done.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LOW POWER&lt;/strong&gt; - 100mW power usage.&lt;/p&gt; &#xA;&lt;p&gt;Current supported features include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Wake Word Engine. Say &#34;Hi ESP&#34; or &#34;Alexa&#34; (user configurable) and start talking!&lt;/li&gt; &#xA; &lt;li&gt;Voice Activity Detection. When you stop talking it will stop recording and take action.&lt;/li&gt; &#xA; &lt;li&gt;Support for Home Assistant! Simply configure Willow with your Home Assistant server address and access token.&lt;/li&gt; &#xA; &lt;li&gt;Support for other platforms. As long as your configured endpoint can take an HTTP POST you can do anything with the speech output!&lt;/li&gt; &#xA; &lt;li&gt;Good far-field performance. We&#39;ve tested wake and speech recognition from roughly 25 feet away in challenging environments with good results.&lt;/li&gt; &#xA; &lt;li&gt;Good audio quality - Willow provides features such as automatic gain control, noise separation, etc.&lt;/li&gt; &#xA; &lt;li&gt;Support for challenging Wi-Fi environments. Willow can (optionally) use audio compression to reduce airtime on 2.4 GHz Wi-Fi in cases where it&#39;s very busy.&lt;/li&gt; &#xA; &lt;li&gt;LCD and touchscreen. The ESP BOX has color LCD and capacitive mult-point touchscreen. We support them with an initial user interface.&lt;/li&gt; &#xA; &lt;li&gt;Completely on device speech command recognition and support for our (soon to be released) open source Whisper-powered inference server (Tovera hosted best-effort example inference server provided). Configure up to 400 commands completely on device or self-host our (coming soon) inference server to transcribe any speech!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All with hardware you can order today from Amazon, Adafruit, The Pi Hut, Mouser, or other preferred vendor for (approximately) $50 USD. Add a USB-C power supply and go!&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Configuring and building Willow for the ESP BOX is a multi-step process. We&#39;re working on improving that but for now...&lt;/p&gt; &#xA;&lt;h3&gt;System Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/tio/tio&#34;&gt;tio&lt;/a&gt; as a serial monitor so you will need to install that.&lt;/p&gt; &#xA;&lt;p&gt;Ubuntu/Debian:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;sudo apt-get install tio&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Arch Linux:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;sudo yay -S tio&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Mac (with homebrew):&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;brew install tio&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Clone this repo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;git clone https://github.com/toverainc/willow.git &amp;amp;&amp;amp; cd willow&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Container&lt;/h3&gt; &#xA;&lt;p&gt;We use Docker (also supports podman) for the build container. To build the container with docker:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh build-docker&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Once the container has finished building you will need to enter it for all following commands:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh docker&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Install&lt;/h3&gt; &#xA;&lt;p&gt;Once inside the container install the environment:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh install&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Start Configuration&lt;/h3&gt; &#xA;&lt;p&gt;Start the config process:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh config&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ESP BOX LITE NOTE: FOR USERS WHO PURCHASED THE ESP BOX LITE&lt;/h2&gt; &#xA;&lt;p&gt;You will need to build for the ESP BOX LITE. From the main menu, select: Audio HAL ---&amp;gt; Audio Board ---&amp;gt; ESP32-S3-BOX-Lite&lt;/p&gt; &#xA;&lt;p&gt;Return to main menu and continue.&lt;/p&gt; &#xA;&lt;h3&gt;Willow Configuration&lt;/h3&gt; &#xA;&lt;p&gt;Navigate to &#34;Willow Configuration&#34; to fill in your Wi-Fi SSID, Wi-Fi password (supports WPA/WPA2/WPA3), and your Willow server URI (best-effort Tovera hosted example provided).&lt;/p&gt; &#xA;&lt;p&gt;For Home Assistant you will also need to create a &lt;a href=&#34;https://developers.home-assistant.io/docs/auth_api/#:~:text=Long%2Dlived%20access%20tokens%20can,access%20token%20for%20current%20user.&#34;&gt;long lived access token&lt;/a&gt; and configure your server address. By default we use &lt;code&gt;homeassistant.local&lt;/code&gt; which should use mDNS to resolve your local Home Assistant instance. Put your long lived access token in the text input area. We recommend testing both your Home Assistant server address and token before flashing.&lt;/p&gt; &#xA;&lt;p&gt;If your Home Assistant server requires TLS make sure to select it.&lt;/p&gt; &#xA;&lt;p&gt;There are also various other configuration options for speaker volume, display brightness, NTP, etc.&lt;/p&gt; &#xA;&lt;p&gt;If you want to change the wake word from the default &#34;Hi ESP&#34; you can navigate from the main menu to &lt;code&gt;ESP Speech Recognition --&amp;gt; Select wake words ---&amp;gt;&lt;/code&gt; and select Alexa or whichever. NOTE: If changing the wake word &lt;em&gt;ALWAYS&lt;/em&gt; use the &lt;code&gt;wn9&lt;/code&gt; variants.&lt;/p&gt; &#xA;&lt;p&gt;Once you&#39;ve provided those press &#39;q&#39;. When prompted to save, do that.&lt;/p&gt; &#xA;&lt;h3&gt;Build and exit container&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh build&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;When the build completes successfully you can exit the container.&lt;/p&gt; &#xA;&lt;h3&gt;Connect the ESP BOX&lt;/h3&gt; &#xA;&lt;p&gt;It&#39;s getting real now - plug it in!&lt;/p&gt; &#xA;&lt;h3&gt;Back on the host - set serial port&lt;/h3&gt; &#xA;&lt;p&gt;To do anything involving the serial port you will need to set the &lt;code&gt;PORT&lt;/code&gt; environment variable for all further invocations of &lt;code&gt;utils.sh&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;With recent versions of &lt;code&gt;tio&lt;/code&gt; you can use &lt;code&gt;tio -L&lt;/code&gt; to list available ports. On Linux you can check &lt;code&gt;dmesg&lt;/code&gt; and look for the path of the recently connected ESP BOX (furthest at the bottom, hopefully). On Linux it&#39;s &lt;code&gt;/dev/ACM*&lt;/code&gt; and on Mac it&#39;s &lt;code&gt;/dev/usbmodem*&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Examples:&lt;/p&gt; &#xA;&lt;p&gt;Linux:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;export PORT=/dev/ttyACM0&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Mac:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;export PORT=/dev/cu.usbmodem2101&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Flash&lt;/h3&gt; &#xA;&lt;p&gt;For out of the box/factory new ESP BOX hardware you will need to (one time) erase the factory flash before flashing Willow:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh erase-flash&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Once you have done that you can flash:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh flash&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;It should flash and connect you to the serial monitor.&lt;/p&gt; &#xA;&lt;h3&gt;Let&#39;s talk!&lt;/h3&gt; &#xA;&lt;p&gt;If you have made it this far - congratulations! You will see serial monitor output ending like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;I (10414) AFE_SR: afe interface for speech recognition&#xA;&#xA;I (10424) AFE_SR: AFE version: SR_V220727&#xA;&#xA;I (10424) AFE_SR: Initial auido front-end, total channel: 3, mic num: 2, ref num: 1&#xA;&#xA;I (10434) AFE_SR: aec_init: 1, se_init: 1, vad_init: 1&#xA;&#xA;I (10434) AFE_SR: wakenet_init: 1&#xA;&#xA;MC Quantized wakenet9: wakeNet9_v1h24_hiesp_3_0.63_0.635, tigger:v3, mode:2, p:0, (May  5 2023 20:32:52)&#xA;I (10704) AFE_SR: wake num: 3, mode: 1, (May  5 2023 20:32:52)&#xA;&#xA;I (13:26:42.433) AUDIO_THREAD: The feed_task task allocate stack on external memory&#xA;I (13:26:42.434) AUDIO_THREAD: The fetch_task task allocate stack on external memory&#xA;I (13:26:42.442) AUDIO_THREAD: The recorder_task task allocate stack on external memory&#xA;I (13:26:42.451) WILLOW: app_main() - start_rec() finished&#xA;I (13:26:42.457) AUDIO_THREAD: The at_read task allocate stack on external memory&#xA;I (13:26:42.466) WILLOW: esp_netif_get_nr_of_ifs: 1&#xA;I (13:26:42.471) WILLOW: Startup complete. Waiting for wake word.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see some help text on the display to use your configured wake word. Try some built in Home Assistant &lt;a href=&#34;https://www.home-assistant.io/integrations/conversation/&#34;&gt;intents&lt;/a&gt; like:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&#34;(Your wake word) Turn on bedroom lights&#34;&lt;/li&gt; &#xA; &lt;li&gt;&#34;(Your wake word) Turn off kitchen lights&#34;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The available commands and specific names, etc will depend on your Home Assistant configuration.&lt;/p&gt; &#xA;&lt;p&gt;You can also provide free-form speech to get an idea of the accuracy and speed provided by our inference server implementation. The commands will fail unless you&#39;ve defined them in Home Assistant but the display will show the speech recognition results to get your imagination going.&lt;/p&gt; &#xA;&lt;p&gt;You can now repeat the erase and flash process for as many devices as you want!&lt;/p&gt; &#xA;&lt;h3&gt;Exit serial monitor&lt;/h3&gt; &#xA;&lt;p&gt;To exit &lt;code&gt;tio&lt;/code&gt; you need to press &#39;CTRL+t&#39; and then &#39;q&#39;. Or you can unplug your device and &lt;code&gt;tio&lt;/code&gt; will wait until you reconnect it.&lt;/p&gt; &#xA;&lt;h3&gt;Start serial monitor&lt;/h3&gt; &#xA;&lt;p&gt;If you want to see what your device is up to you can start the serial monitor anytime:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh monitor&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Things went sideways - reset&lt;/h2&gt; &#xA;&lt;p&gt;In the event your environment gets out of whack we have a helper to reset:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh destroy&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;As the plentiful messages indicate it&#39;s a destructive process but it will reset your environment. After it completes you can start from the top and try again.&lt;/p&gt; &#xA;&lt;h2&gt;Recover from a bad flash&lt;/h2&gt; &#xA;&lt;p&gt;ESP devices are very robust to flashing failures but it can happen! If you end up &#34;bricking&#34; your device you can erase the flash:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh erase-flash&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;NOTE: Depending on how tight of a boot loop your device is in you may need to run &lt;code&gt;erase-flash&lt;/code&gt; multiple times to get the timing right. It will eventually &#34;catch&#34; and successfully erase the flash. When it reports successful erase you can flash again:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh flash&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Advanced Usage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;utils.sh&lt;/code&gt; will attempt to load environment variables from &lt;code&gt;.env&lt;/code&gt;. You can define your &lt;code&gt;PORT&lt;/code&gt; here to avoid needing to define it over and over.&lt;/p&gt; &#xA;&lt;p&gt;The ESP-IDF, ESP-ADF, ESP-SR, LVGL, etc libraries have a plethora of configuration options. DO NOT change anything outside of &#34;Willow Configuration&#34; (other than wake word) unless you know what you are doing.&lt;/p&gt; &#xA;&lt;p&gt;If you want to quickly and easily flash multiple devices or distribute a combined firmware image you can use the &lt;code&gt;dist&lt;/code&gt; arguments to &lt;code&gt;utils.sh&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh dist&lt;/code&gt; - builds the combined flash image (&lt;code&gt;willow-dist.bin&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh flash-dist&lt;/code&gt; - flashes the combined flash image&lt;/p&gt; &#xA;&lt;p&gt;This combined firmware image can be used with any ESP flashing tool like the web flasher &lt;a href=&#34;https://espressif.github.io/esptool-js/&#34;&gt;ESP Tool&lt;/a&gt; so you can send firmware images to your less technical friends! Just make sure to erase the flash first and use offset 0x0 with those tools as we include the bootloader.&lt;/p&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;Development usually involves a few steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Code - do your thing!&lt;/li&gt; &#xA; &lt;li&gt;Build&lt;/li&gt; &#xA; &lt;li&gt;Flash&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Unless you change the wake word and/or are using local command recognition (Multinet) you can selectively flash only the application partition. This avoids long flash times with the wakenet and multinet model partition, etc:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh build&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./utils.sh flash-app&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;The Future (in no particular order)&lt;/h2&gt; &#xA;&lt;h3&gt;Multiple Languages&lt;/h3&gt; &#xA;&lt;p&gt;Willow supports UTF characters and our inference server implementation supports all the languages of Whisper. We have some polishing to do here but it is coming very soon. For the interface language on device we&#39;re looking for translation help!&lt;/p&gt; &#xA;&lt;h3&gt;Performance Improvements&lt;/h3&gt; &#xA;&lt;p&gt;Willow and air-infer-api/Multinet already provide &#34;faster-than-Alexa&#34; responsiveness for a voice user interface. However, there are multiple obvious optimizations we&#39;re aware of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ESP ADF pipeline handing (we&#39;re waiting on ESP-ADF 2.6 with ESP-IDF 5)&lt;/li&gt; &#xA; &lt;li&gt;Websockets for inference server (avoids TLS handshake and connection establishment for each session)&lt;/li&gt; &#xA; &lt;li&gt;Code in general (we&#39;re new to ESP IDF and it could use review)&lt;/li&gt; &#xA; &lt;li&gt;Various performance-related sdkconfig parameters (again, we&#39;re new to ESP IDF)&lt;/li&gt; &#xA; &lt;li&gt;Likely many, many more&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These enhancements alone should dramatically improve responsiveness.&lt;/p&gt; &#xA;&lt;h3&gt;No CUDA&lt;/h3&gt; &#xA;&lt;p&gt;The air-infer-api inference server (open source release soon) will run CPU only but the performance on CPU is not comparable to heavily optimized implementations like &lt;a href=&#34;https://github.com/ggerganov/whisper.cpp&#34;&gt;whisper.cpp&lt;/a&gt;. For an Alexa/Echo competitive voice interface we currently believe that our implementation with CUDA or local Multinet (for limited commands) is the best approach. However, we also understand that isn&#39;t practical or preferred for many users. Between on device Multinet command recognition and further development on CPU-only Whisper implementations, ROCm, etc we will get there. That said, if you can make the audio streaming API work you can use any speech to text and text to speech implementation you want!&lt;/p&gt; &#xA;&lt;h3&gt;TTS Output&lt;/h3&gt; &#xA;&lt;p&gt;Given the capabilities of Whisper speech commands like &#34;What is the weather in Sofia, Bulgaria?&#34; are transcribed but need to match a command (like a Home Assistant intent) on the destination. Our inference server implementation has a text to speech engine and Home Assistant has a variety of options as well. In the event the final response to a given command results in audio output we can play that via the speakers in the ESP BOX (not yet supported).&lt;/p&gt; &#xA;&lt;h3&gt;Higher Quality Audio Output&lt;/h3&gt; &#xA;&lt;p&gt;The ESP BOX supports bluetooth. In applications where higher quality audio is desired (music streaming, etc) we can support pairing to bluetooth speaker devices. Who knows? Eventually we may even design our own device with better internal speakers...&lt;/p&gt; &#xA;&lt;h3&gt;LCD and Touchscreen Improvements&lt;/h3&gt; &#xA;&lt;p&gt;The ESP BOX has a multi-point capacitive touchscreen and support for many GUI elements. We currently only provide basic features like touch screen to wake up, a little finger cursor thing, and a Cancel button to cancel/interrupt command streaming. There&#39;s a lot more work to do here!&lt;/p&gt; &#xA;&lt;h3&gt;Buttons&lt;/h3&gt; &#xA;&lt;p&gt;The ESP BOX has buttons and who doesn&#39;t like configuring buttons to do things?!&lt;/p&gt; &#xA;&lt;h3&gt;Audio on device&lt;/h3&gt; &#xA;&lt;p&gt;We currently beep once for success and twice for failure. It&#39;s not the most annoying beep in the world but it&#39;s not exactly pleasant either. We&#39;re going to include some pleasant chimes for success and failure as well as some basic status reporting like &#34;Could not connect to server&#34;, etc.&lt;/p&gt; &#xA;&lt;h3&gt;Easy Start&lt;/h3&gt; &#xA;&lt;p&gt;Docker, building, configuring, flashing, etc is a pain. There are several approaches we plan to take to avoid this and ease the barrier to entry for users to get started.&lt;/p&gt; &#xA;&lt;h3&gt;Dynamic Configuration&lt;/h3&gt; &#xA;&lt;p&gt;With something like a Willow Home Assistant component and websocket support we can enable all kinds of interesting dynamic configuration updates and tighter overall configurations.&lt;/p&gt; &#xA;&lt;h3&gt;Over the Air Firmware Updates&lt;/h3&gt; &#xA;&lt;p&gt;ESP IDF and ESP BOX has robust support for over the air firmware (OTA) updates. Down the road we will support them.&lt;/p&gt; &#xA;&lt;h3&gt;Multiple Devices&lt;/h3&gt; &#xA;&lt;p&gt;The good news is the far-field wake word recognition and speech recognition performance is very good. The bad news is if you have multiple devices in proximity they are all likely to wake and process speech simultaneously. Commands will still work but multiple confirmation/error beeps and hammering your destination command endpoint is less than ideal. We have a few ideas about dealing with this too.&lt;/p&gt; &#xA;&lt;h3&gt;Custom Wake Word&lt;/h3&gt; &#xA;&lt;p&gt;Espressif has a &lt;a href=&#34;https://docs.espressif.com/projects/esp-sr/en/latest/esp32s3/wake_word_engine/ESP_Wake_Words_Customization.html&#34;&gt;wake word customization service&lt;/a&gt; that enables us (and commercial users) to create custom wake words. We plan to create a &#34;Hi Willow&#34; or similar wake word and potentially others depending on input from the community.&lt;/p&gt; &#xA;&lt;h3&gt;GPIO&lt;/h3&gt; &#xA;&lt;p&gt;The ESP BOX provides 16 GPIOs to the user that are readily accessed from sockets on the rear of the device. We plan to make these configurable by the user to enable all kinds of interesting maker/DIY functions.&lt;/p&gt;</summary>
  </entry>
</feed>