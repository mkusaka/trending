<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-17T01:23:08Z</updated>
  <subtitle>Daily Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>leejet/stable-diffusion.cpp</title>
    <updated>2023-08-17T01:23:08Z</updated>
    <id>tag:github.com,2023-08-17:/leejet/stable-diffusion.cpp</id>
    <link href="https://github.com/leejet/stable-diffusion.cpp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stable Diffusion in pure C/C++&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/a%20lovely%20cat.png&#34; width=&#34;256x&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;stable-diffusion.cpp&lt;/h1&gt; &#xA;&lt;p&gt;Inference of &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt; in pure C/C++&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Plain C/C++ implementation based on &lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;ggml&lt;/a&gt;, working in the same way as &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;16-bit, 32-bit float support&lt;/li&gt; &#xA; &lt;li&gt;4-bit, 5-bit and 8-bit integer quantization support&lt;/li&gt; &#xA; &lt;li&gt;Accelerated memory-efficient CPU inference &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Only requires ~2.3GB when using txt2img with fp16 precision to generate a 512x512 image&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;AVX, AVX2 and AVX512 support for x86 architectures&lt;/li&gt; &#xA; &lt;li&gt;Original &lt;code&gt;txt2img&lt;/code&gt; and &lt;code&gt;img2img&lt;/code&gt; mode&lt;/li&gt; &#xA; &lt;li&gt;Negative prompt&lt;/li&gt; &#xA; &lt;li&gt;Sampling method &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;Euler A&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Supported platforms &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Linux&lt;/li&gt; &#xA;   &lt;li&gt;Mac OS&lt;/li&gt; &#xA;   &lt;li&gt;Windows&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;TODO&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; More sampling methods&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; GPU support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Make inference faster &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The current implementation of ggml_conv_2d is slow and has high memory usage&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Continuing to reduce memory usage (quantizing the weights of ggml_conv_2d)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;stable-diffusion-webui&lt;/a&gt; style tokenizer (eg: token weighting, ...)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; LoRA support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; k-quants support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Cross-platform reproducibility (perhaps ensuring consistency with the original SD)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Get the Code&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone --recursive https://github.com/leejet/stable-diffusion.cpp&#xA;cd stable-diffusion.cpp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you have already cloned the repository, you can use the following command to update the repository to the latest code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd stable-diffusion.cpp&#xA;git pull origin master&#xA;git submodule update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Convert weights&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;download original weights(.ckpt or .safetensors). For example&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Stable Diffusion v1.4 from &lt;a href=&#34;https://huggingface.co/CompVis/stable-diffusion-v-1-4-original&#34;&gt;https://huggingface.co/CompVis/stable-diffusion-v-1-4-original&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Stable Diffusion v1.5 from &lt;a href=&#34;https://huggingface.co/runwayml/stable-diffusion-v1-5&#34;&gt;https://huggingface.co/runwayml/stable-diffusion-v1-5&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -L -O https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt&#xA;# curl -L -O https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;convert weights to ggml model format&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd models&#xA;pip install -r requirements.txt&#xA;python convert.py [path to weights] --out_type [output precision]&#xA;# For example, python convert.py sd-v1-4.ckpt --out_type f16&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quantization&lt;/h3&gt; &#xA;&lt;p&gt;You can specify the output model format using the --out_type parameter&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;f16&lt;/code&gt; for 16-bit floating-point&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;f32&lt;/code&gt; for 32-bit floating-point&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q8_0&lt;/code&gt; for 8-bit integer quantization&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q5_0&lt;/code&gt; or &lt;code&gt;q5_1&lt;/code&gt; for 5-bit integer quantization&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q4_0&lt;/code&gt; or &lt;code&gt;q4_1&lt;/code&gt; for 4-bit integer quantization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Build&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir build&#xA;cd build&#xA;cmake ..&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Using OpenBLAS&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmake .. -DGGML_OPENBLAS=ON&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;usage: ./sd [arguments]&#xA;&#xA;arguments:&#xA;  -h, --help                         show this help message and exit&#xA;  -M, --mode [txt2img or img2img]    generation mode (default: txt2img)&#xA;  -t, --threads N                    number of threads to use during computation (default: -1).&#xA;                                     If threads &amp;lt;= 0, then threads will be set to the number of CPU physical cores&#xA;  -m, --model [MODEL]                path to model&#xA;  -i, --init-img [IMAGE]             path to the input image, required by img2img&#xA;  -o, --output OUTPUT                path to write result image to (default: .\output.png)&#xA;  -p, --prompt [PROMPT]              the prompt to render&#xA;  -n, --negative-prompt PROMPT       the negative prompt (default: &#34;&#34;)&#xA;  --cfg-scale SCALE                  unconditional guidance scale: (default: 7.0)&#xA;  --strength STRENGTH                strength for noising/unnoising (default: 0.75)&#xA;                                     1.0 corresponds to full destruction of information in init image&#xA;  -H, --height H                     image height, in pixel space (default: 512)&#xA;  -W, --width W                      image width, in pixel space (default: 512)&#xA;  --sample-method SAMPLE_METHOD      sample method (default: &#34;eular a&#34;)&#xA;  --steps  STEPS                     number of sample steps (default: 20)&#xA;  -s SEED, --seed SEED               RNG seed (default: 42, use random seed for &amp;lt; 0)&#xA;  -v, --verbose                      print extra info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;txt2img example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sd -m ../models/sd-v1-4-ggml-model-f16.bin -p &#34;a lovely cat&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Using formats of different precisions will yield results of varying quality.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;f32&lt;/th&gt; &#xA;   &lt;th&gt;f16&lt;/th&gt; &#xA;   &lt;th&gt;q8_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_1&lt;/th&gt; &#xA;   &lt;th&gt;q4_0&lt;/th&gt; &#xA;   &lt;th&gt;q4_1&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/f32.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/f16.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q8_0.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q5_0.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q5_1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q4_0.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q4_1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;img2img example&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;./output.png&lt;/code&gt; is the image generated from the above txt2img pipeline&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sd --mode img2img -m ../models/sd-v1-4-ggml-model-f16.bin -p &#34;cat with blue eyes&#34; -i ./output.png -o ./img2img_output.png --strength 0.4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/img2img_output.png&#34; width=&#34;256x&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Memory/Disk Requirements&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;precision&lt;/th&gt; &#xA;   &lt;th&gt;f32&lt;/th&gt; &#xA;   &lt;th&gt;f16&lt;/th&gt; &#xA;   &lt;th&gt;q8_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_1&lt;/th&gt; &#xA;   &lt;th&gt;q4_0&lt;/th&gt; &#xA;   &lt;th&gt;q4_1&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Disk&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2.7G&lt;/td&gt; &#xA;   &lt;td&gt;2.0G&lt;/td&gt; &#xA;   &lt;td&gt;1.7G&lt;/td&gt; &#xA;   &lt;td&gt;1.6G&lt;/td&gt; &#xA;   &lt;td&gt;1.6G&lt;/td&gt; &#xA;   &lt;td&gt;1.5G&lt;/td&gt; &#xA;   &lt;td&gt;1.5G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;(txt2img - 512 x 512)&lt;/td&gt; &#xA;   &lt;td&gt;~2.8G&lt;/td&gt; &#xA;   &lt;td&gt;~2.3G&lt;/td&gt; &#xA;   &lt;td&gt;~2.1G&lt;/td&gt; &#xA;   &lt;td&gt;~2.0G&lt;/td&gt; &#xA;   &lt;td&gt;~2.0G&lt;/td&gt; &#xA;   &lt;td&gt;~2.0G&lt;/td&gt; &#xA;   &lt;td&gt;~2.0G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;ggml&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;stable-diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;stable-diffusion-webui&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crowsonkb/k-diffusion&#34;&gt;k-diffusion&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>deepinstinct/NoFilter</title>
    <updated>2023-08-17T01:23:08Z</updated>
    <id>tag:github.com,2023-08-17:/deepinstinct/NoFilter</id>
    <link href="https://github.com/deepinstinct/NoFilter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NoFilter&lt;/h1&gt; &#xA;&lt;p&gt;Tool for abusing the Windows Filtering Platform for privilege escalation. It can launch a new console as &#34;NT AUTHORITY\SYSTEM&#34; or as another user that is logged on to the machine.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;Usage: NoFilter.exe [-s] [SESSION_ID]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/RonB_Y&#34;&gt;Ron Ben Yizhak&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://media.defcon.org/DEF%20CON%2031/DEF%20CON%2031%20presentations/Ron%20Ben-Yizhak%20-%20NoFilter%20Abusing%20Windows%20Filtering%20Platform%20for%20privilege%20escalation.pdf&#34;&gt;https://media.defcon.org/DEF%20CON%2031/DEF%20CON%2031%20presentations/Ron%20Ben-Yizhak%20-%20NoFilter%20Abusing%20Windows%20Filtering%20Platform%20for%20privilege%20escalation.pdf&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googleprojectzero.blogspot.com/2021/08/understanding-network-access-windows-app.html&#34;&gt;https://googleprojectzero.blogspot.com/2021/08/understanding-network-access-windows-app.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scorpiosoftware.net/2022/12/25/introduction-to-the-windows-filtering-platform/&#34;&gt;https://scorpiosoftware.net/2022/12/25/introduction-to-the-windows-filtering-platform/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/windows/win32/fwp/windows-filtering-platform-architecture-overview&#34;&gt;https://learn.microsoft.com/en-us/windows/win32/fwp/windows-filtering-platform-architecture-overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/cc759130(v=ws.10)&#34;&gt;https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/cc759130(v=ws.10)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>