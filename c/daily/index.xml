<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-30T01:31:20Z</updated>
  <subtitle>Daily Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>google/rune</title>
    <updated>2022-11-30T01:31:20Z</updated>
    <id>tag:github.com,2022-11-30:/google/rune</id>
    <link href="https://github.com/google/rune" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Rune is a programming language developed to test ideas for improving security and efficiency.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;áš£ The Rune Programming Language&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;A faster, safer, and more productive systems programming language&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is not an officially supported Google product.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE: Rune is an unfinished language. Feel free to kick tires and evaluate the cool new security and efficiency features of Rune, but, for now, it is not recommended for any production use case.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Rune is a Python-inspired efficient systems programming language designed to interact well with C and C++ libraries. Rune has many security features such as memory safety, and constant-time processing of secrets. Rune aims to be faster than C++ for most memory-intensive applications, due to its Structure-of-Array (&lt;a href=&#34;https://en.wikipedia.org/wiki/AoS_and_SoA#:~:text=AoS%20vs.,AoS%20case%20easier%20to%20handle.&#34;&gt;SoA&lt;/a&gt;) memory management.&lt;/p&gt; &#xA;&lt;p&gt;Additional documentation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/rune/main/doc/index.md&#34;&gt;Rune Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/rune/main/doc/rune4python.md&#34;&gt;Rune for Python programmers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Consider the following example for treatment of secrets:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;// Check the MAC (message authentication code) for a message.  A MAC is derived&#xA;// from a hash over the `macSecret` and message.  It ensures the message has not&#xA;// been modified, and was sent by someone who knows `macSecret`.&#xA;func checkMac(macSecret: secret(string), message: string, mac: string) -&amp;gt; bool {&#xA;    computedMac = computeMac(macSecret, message)&#xA;    return mac == computedMac&#xA;}&#xA;&#xA;func computeMac(macSecret: string, message:string) -&amp;gt; string {&#xA;  // A popular MAC algorithm.&#xA;  return hmacSha256(macSecret, message)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Can you see the potential security flaw? In most languages, an attacker with accurate timing data can forge a MAC on a message of their choice, causing a server to accept it as genuine.&lt;/p&gt; &#xA;&lt;p&gt;Assume the attacker can tell how long it takes for &lt;code&gt;mac == computedMac&lt;/code&gt; to run. If the first byte of an attacker-chosen &lt;code&gt;mac&lt;/code&gt; is wrong for the attacker-chosen &lt;code&gt;message&lt;/code&gt;, the loop terminates after just one comparison. With 256 attempts, the attacker can find the first byte of the expected MAC for the attacker-controlled &lt;code&gt;message&lt;/code&gt;. Repeating this process, the attacker can forge an entire MAC.&lt;/p&gt; &#xA;&lt;p&gt;Users of Rune are protected, because the compiler sees that &lt;code&gt;macSecret&lt;/code&gt; is secret, and thus the result of &lt;code&gt;hmacSha256&lt;/code&gt; is secret. The string comparison operator, when either operand is secret, will run in constant time, revealing no timing information to the attacker. Care must still be taken in Rune, but many common mistakes like this are detected by the compiler, and either fixed or flagged as an error.&lt;/p&gt; &#xA;&lt;p&gt;As for the speed and safety of Rune&#39;s memory management, consider a simple &lt;code&gt;Human&lt;/code&gt; class. This can be tricky to model in some languages, yet is trivial in both SQL and Rune.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;class Human(self, name: string, mother: Human = null, father: Human = null) {&#xA;  self.name = name&#xA;  if !isnull(mother) {&#xA;    mother.appendMotheredHuman(self)&#xA;  }&#xA;  if !isnull(father) {&#xA;    father.appendFatheredHuman(self)&#xA;  }&#xA;&#xA;  func printFamilyTree(self, level: u32) {&#xA;    for i in range(level) {&#xA;      print &#34;    &#34;&#xA;    }&#xA;    println self.name&#xA;    for child in self.motheredHumans() {&#xA;      child.printFamilyTree(level + 1)&#xA;    }&#xA;    for child in self.fatheredHumans() {&#xA;      child.printFamilyTree(level + 1)&#xA;    }&#xA;  }&#xA;}&#xA;&#xA;relation DoublyLinked Human:&#34;Mother&#34; Human:&#34;Mothered&#34; cascade&#xA;relation DoublyLinked Human:&#34;Father&#34; Human:&#34;Fathered&#34; cascade&#xA;&#xA;adam = Human(&#34;Adam&#34;)&#xA;eve = Human(&#34;Eve&#34;)&#xA;cain = Human(&#34;Cain&#34;, eve, adam)&#xA;abel = Human(&#34;Abel&#34;, eve, adam)&#xA;alice = Human(&#34;Alice&#34;, eve, adam)&#xA;bob = Human (&#34;Bob&#34;, eve, adam)&#xA;malory = Human(&#34;Malory&#34;, alice, abel)&#xA;abel.destroy()&#xA;adam.printFamilyTree(0u32)&#xA;eve.printFamilyTree(0u32)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When run, this prints:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Adam&#xA;    Cain&#xA;    Alice&#xA;    Bob&#xA;Eve&#xA;    Cain&#xA;    Alice&#xA;    Bob&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that Abel and Malory are not listed. This is because we didn&#39;t just kill Abel, we destroyed Abel, and this caused all of Abel&#39;s children to be recursively destroyed.&lt;/p&gt; &#xA;&lt;p&gt;Relation statements are similar to columns in SQL tables. A table with a Mother and Father column has two many-to-one relations in a database.&lt;/p&gt; &#xA;&lt;p&gt;Relation statements give the Rune compiler critical hints for memory optimization. Objects which the compiler can prove are always in cascade-delete relationships do not need to be reference counted. The relation statements also inform the compiler to update Node&#39;s destructor to recursively destroy children. &lt;strong&gt;Rune programmers never write destructors&lt;/strong&gt;, removing this footgun from the language.&lt;/p&gt; &#xA;&lt;p&gt;To understand why Rune&#39;s generated SoA code is so efficient, consider the arrays of properties created for the Human example above:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  nextFree = [null(Human)]&#xA;  motherHuman = [null(Human)]&#xA;  prevHumanMotheredHuman = [null(Human)]&#xA;  nextHumanMotheredHuman = [null(Human)]&#xA;  firstMotheredHuman = [null(Human)]&#xA;  lastMotheredHuman = [null(Human)]&#xA;  fatherHuman = [null(Human)]&#xA;  prevHumanFatheredHuman = [null(Human)]&#xA;  nextHumanFatheredHuman = [null(Human)]&#xA;  firstFatheredHuman = [null(Human)]&#xA;  lastFatheredHuman = [null(Human)]&#xA;  name = [&#34;&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A total of 12 arrays are allocated for the Human class in SoA memory layout. In &lt;code&gt;printFamilyTree&lt;/code&gt;, we only access 5 of them. In AoS memory layout, all 12 fields would be loaded into cache during the tree traversal, and all fields would be 64 bits on a 64-bit machine. In Rune, only the string references are 64-bits by default. As a result, &lt;strong&gt;Rune loads only 25% as much data into cache&lt;/strong&gt; during the traversal, improving memory load times, while simultaneously improving cache hit rates.&lt;/p&gt; &#xA;&lt;p&gt;This is why Rune&#39;s &lt;code&gt;binarytree.rn&lt;/code&gt; code already runs faster than any other single-threaded result in the &lt;a href=&#34;https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html&#34;&gt;Benchmark Games&lt;/a&gt;. (Rune is not yet multi-threaded). The only close competitor is C++, where the author uses the little-known &lt;code&gt;MemoryPool&lt;/code&gt; class from the &lt;code&gt;&amp;lt;memory&amp;gt;&lt;/code&gt; library. Not only is Rune&#39;s SoA memory layout faster, but its solution is more generic: we can create/destroy Node objects arbitrarily, unlike the C++ benchmark based on &lt;code&gt;MemoryPool&lt;/code&gt;. When completed, we expect Rune to win most memory-intensive benchmarks.&lt;/p&gt; &#xA;&lt;h2&gt;Compiling the Rune compiler:&lt;/h2&gt; &#xA;&lt;p&gt;You&#39;ll need 6 dependencies installed to compile Rune:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bison (parser generator)&lt;/li&gt; &#xA; &lt;li&gt;Flex (lexer generator)&lt;/li&gt; &#xA; &lt;li&gt;GNU multi-precision package gmp&lt;/li&gt; &#xA; &lt;li&gt;Clang version 10&lt;/li&gt; &#xA; &lt;li&gt;Datadraw, an SoA data-structure generator for C&lt;/li&gt; &#xA; &lt;li&gt;CTTK, a constant-time big integer arithmetic library The first four can be installed with one command:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ sudo apt-get install bison flex libgmp-dev clang-14&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Installing Datadraw requires cloning &lt;a href=&#34;https://github.com/waywardgeek/datadraw&#34;&gt;the source from github&lt;/a&gt;, or getting it from //third_party/datadraw.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git clone https://github.com/waywardgeek/datadraw.git&#xA;$ sudo apt-get install build-essential&#xA;$ cd datadraw&#xA;$ ./autogen.sh&#xA;$ ./configure&#xA;$ make&#xA;$ sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Hopefully that all goes well... After dependencies are installed, to build rune:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git clone https://github.com/google/rune.git&#xA;$ git clone https://github.com/pornin/CTTK.git&#xA;$ cp CTTK/inc/cttk.h CTTK&#xA;$ cd rune&#xA;$ make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;CTTK was written by Thomas Pornin. It provides constant-time big-integer arithmetic.&lt;/p&gt; &#xA;&lt;p&gt;If &lt;code&gt;make&lt;/code&gt; succeeds, test the Rune compiler in the rune directory with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ ./runtests.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some tests are currently expected to fail, but most should pass. To install rune under /usr/local/rune:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Test your installation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ echo &#39;println &#34;Hello, World!&#34;&#39; &amp;gt; hello.rn&#xA;$ rune -g hello.rn&#xA;$ ./hello&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can debug your binary executable with gdb:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ gdb ./hello&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;TODO: add instructions on how to debug the compiler itself, especially the datadraw debug functionality.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cockpit-project/cockpit</title>
    <updated>2022-11-30T01:31:20Z</updated>
    <id>tag:github.com,2022-11-30:/cockpit-project/cockpit</id>
    <link href="https://github.com/cockpit-project/cockpit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cockpit is a web-based graphical interface for servers.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Cockpit&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;A sysadmin login session in a web browser&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cockpit-project.org/&#34;&gt;cockpit-project.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Cockpit is an interactive server admin interface. It is easy to use and very lightweight. Cockpit interacts directly with the operating system from a real Linux session in a browser.&lt;/p&gt; &#xA;&lt;h3&gt;Using Cockpit&lt;/h3&gt; &#xA;&lt;p&gt;You can &lt;a href=&#34;https://cockpit-project.org/running.html&#34;&gt;install Cockpit&lt;/a&gt; on many Linux operating systems including Debian, Fedora and RHEL.&lt;/p&gt; &#xA;&lt;p&gt;Cockpit makes Linux discoverable, allowing sysadmins to easily perform tasks such as starting containers, storage administration, network configuration, inspecting logs and so on.&lt;/p&gt; &#xA;&lt;p&gt;Jumping between the terminal and the web tool is no problem. A service started via Cockpit can be stopped via the terminal. Likewise, if an error occurs in the terminal, it can be seen in the Cockpit journal interface.&lt;/p&gt; &#xA;&lt;p&gt;You can also easily add other machines that have Cockpit installed and are accessible via SSH and jump between these hosts.&lt;/p&gt; &#xA;&lt;h3&gt;Development&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cockpit-project/cockpit/main/HACKING.md&#34;&gt;Making changes to Cockpit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cockpit-project/cockpit/wiki/Contributing&#34;&gt;How to contribute, developer documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;IRC Channel: #cockpit on &lt;a href=&#34;https://libera.chat/&#34;&gt;libera.chat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lists.fedorahosted.org/admin/lists/cockpit-devel.lists.fedorahosted.org/&#34;&gt;Mailing List&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cockpit-project.org/ideals.html&#34;&gt;Guiding Principles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cockpit-project.org/blog/category/release.html&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cockpit-project.org/privacy.html&#34;&gt;Privacy Policy&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>DualCoder/vgpu_unlock</title>
    <updated>2022-11-30T01:31:20Z</updated>
    <id>tag:github.com,2022-11-30:/DualCoder/vgpu_unlock</id>
    <link href="https://github.com/DualCoder/vgpu_unlock" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Unlock vGPU functionality for consumer grade GPUs.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;vgpu_unlock&lt;/h1&gt; &#xA;&lt;p&gt;Unlock vGPU functionality for consumer-grade Nvidia GPUs.&lt;/p&gt; &#xA;&lt;h2&gt;Important!&lt;/h2&gt; &#xA;&lt;p&gt;This tool is not guarenteed to work out of the box in some cases, so use it at your own risk.&lt;/p&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;This tool enables the use of Geforce and Quadro GPUs with the NVIDIA vGPU graphics virtualization technology. NVIDIA vGPU normally only supports a few datacenter Teslas and professional Quadro GPUs by design, but not consumer graphics cards through a software limitation. This vgpu_unlock tool aims to remove this limitation on Linux based systems, thus enabling most Maxwell, Pascal, Volta (untested), and Turing based GPUs to use the vGPU technology. Ampere support is currently a work in progress.&lt;/p&gt; &#xA;&lt;p&gt;A community maintained Wiki written by Krutav Shah with a lot more information is &lt;a href=&#34;https://docs.google.com/document/d/1pzrWJ9h-zANCtyqRgS7Vzla0Y8Ea2-5z2HEi4X75d2Q/edit?usp=sharing&#34;&gt;available here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Dependencies:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This tool requires Python3 and Python3-pip; the latest version is recommended.&lt;/li&gt; &#xA; &lt;li&gt;The python package &#34;frida&#34; is required. &lt;code&gt;pip3 install frida&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The tool requires the NVIDIA GRID vGPU driver.&lt;/li&gt; &#xA; &lt;li&gt;&#34;dkms&#34; is required as it simplifies the process of rebuilding the driver alot. Install DKMS with the package manager in your OS.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation:&lt;/h2&gt; &#xA;&lt;p&gt;In the following instructions &lt;code&gt;&amp;lt;path_to_vgpu_unlock&amp;gt;&lt;/code&gt; need to be replaced with the path to this repository on the target system and &lt;code&gt;&amp;lt;version&amp;gt;&lt;/code&gt; need to be replaced with the version of the NVIDIA GRID vGPU driver.&lt;/p&gt; &#xA;&lt;p&gt;Install the NVIDIA GRID vGPU driver, make sure to install it as a dkms module.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./nvidia-installer --dkms&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Modify the line begining with &lt;code&gt;ExecStart=&lt;/code&gt; in &lt;code&gt;/lib/systemd/system/nvidia-vgpud.service&lt;/code&gt; and &lt;code&gt;/lib/systemd/system/nvidia-vgpu-mgr.service&lt;/code&gt; to use &lt;code&gt;vgpu_unlock&lt;/code&gt; as the executable and pass the original executable as the first argument. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ExecStart=&amp;lt;path_to_vgpu_unlock&amp;gt;/vgpu_unlock /usr/bin/nvidia-vgpud&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Reload the systemd daemons:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;systemctl daemon-reload&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Modify the file &lt;code&gt;/usr/src/nvidia-&amp;lt;version&amp;gt;/nvidia/os-interface.c&lt;/code&gt; and add the following line after the lines begining with &lt;code&gt;#include&lt;/code&gt; at the beginning of the file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#include &#34;&amp;lt;path_to_vgpu_unlock&amp;gt;/vgpu_unlock_hooks.c&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Modify the file &lt;code&gt;/usr/src/nvidia-&amp;lt;version&amp;gt;/nvidia/nvidia.Kbuild&lt;/code&gt; and add the following line at the bottom of the file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ldflags-y += -T &amp;lt;path_to_vgpu_unlock&amp;gt;/kern.ld&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Remove the nvidia kernel module using dkms:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dkms remove -m nvidia -v &amp;lt;version&amp;gt; --all&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Rebuild and reinstall the nvidia kernel module using dkms:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dkms install -m nvidia -v &amp;lt;version&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Reboot.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;This script only works with graphics cards in the same generation as their professional Tesla counterparts. As a result, only Maxwell and newer generation Nvidia GPUs are supported. It is not designed to be used with low end graphics card models, so not all cards are guarenteed to work smoothly with vGPU. For the best experience, it is recommended to use graphics cards with the same chip model as the Tesla cards. The same applies to the operating system as well, as certain bleeding-edge Linux distributions may not work well with vGPU software.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;How it works&lt;/h2&gt; &#xA;&lt;h3&gt;vGPU supported?&lt;/h3&gt; &#xA;&lt;p&gt;In order to determine if a certain GPU supports the vGPU functionality the driver looks at the PCI device ID. This identifier together with the PCI vendor ID is unique for each type of PCI device. In order to enable vGPU support we need to tell the driver that the PCI device ID of the installed GPU is one of the device IDs used by a vGPU capable GPU.&lt;/p&gt; &#xA;&lt;h3&gt;Userspace script: vgpu_unlock&lt;/h3&gt; &#xA;&lt;p&gt;The userspace services nvidia-vgpud and nvidia-vgpu-mgr uses the ioctl syscall to communicate with the kernel module. Specifically they read the PCI device ID and determines if the installed GPU is vGPU capable.&lt;/p&gt; &#xA;&lt;p&gt;The python script vgpu_unlock intercepts all ioctl syscalls between the executable specified as the first argument and the kernel. The script then modifies the kernel responses to indicate a PCI device ID with vGPU support and a vGPU capable GPU.&lt;/p&gt; &#xA;&lt;h3&gt;Kernel module hooks: vgpu_unlock_hooks.c&lt;/h3&gt; &#xA;&lt;p&gt;In order to exchange data with the GPU the kernel module maps the physical address space of the PCI bus into its own virtual address space. This is done using the ioremap* kernel functions. The kernel module then reads and writes data into that mapped address space. This is done using the memcpy kernel function.&lt;/p&gt; &#xA;&lt;p&gt;By including the vgpu_unlock_hooks.c file into the os-interface.c file we can use C preprocessor macros to replace and intercept calls to the iormeap and memcpy functions. Doing this allows us to maintain a view of what is mapped where and what data that is being accessed.&lt;/p&gt; &#xA;&lt;h3&gt;Kernel module linker script: kern.ld&lt;/h3&gt; &#xA;&lt;p&gt;This is a modified version of the default linker script provided by gcc. The script is modified to place the .rodata section of nv-kernel.o into .data section instead of .rodata, making it writable. The script also provide the symbols &lt;code&gt;vgpu_unlock_nv_kern_rodata_beg&lt;/code&gt; and &lt;code&gt;vgpu_unlock_nv_kern_rodata_end&lt;/code&gt; to let us know where that section begins and ends.&lt;/p&gt; &#xA;&lt;h3&gt;How it all comes together&lt;/h3&gt; &#xA;&lt;p&gt;After boot the nvidia-vgpud service queries the kernel for all installed GPUs and checks for vGPU capability. This call is intercepted by the vgpu_unlock python script and the GPU is made vGPU capable. If a vGPU capable GPU is found then nvidia-vgpu creates an MDEV device and the /sys/class/mdev_bus directory is created by the system.&lt;/p&gt; &#xA;&lt;p&gt;vGPU devices can now be created by echoing UUIDs into the &lt;code&gt;create&lt;/code&gt; files in the mdev bus representation. This will create additional structures representing the new vGPU device on the MDEV bus. These devices can then be assigned to VMs, and when the VM starts it will open the MDEV device. This causes nvidia-vgpu-mgr to start communicating with the kernel using ioctl. Again these calls are intercepted by the vgpu_unlock python script and when nvidia-vgpu-mgr asks if the GPU is vGPU capable the answer is changed to yes. After that check it attempts to initialize the vGPU device instance.&lt;/p&gt; &#xA;&lt;p&gt;Initialization of the vGPU device is handled by the kernel module and it performs its own check for vGPU capability, this one is a bit more complicated.&lt;/p&gt; &#xA;&lt;p&gt;The kernel module maps the physical PCI address range 0xf0000000-0xf1000000 into its virtual address space, it then performs some magical operations which we don&#39;t really know what they do. What we do know is that after these operations it accesses a 128 bit value at physical address 0xf0029624, which we call the magic value. The kernel module also accessses a 128 bit value at physical address 0xf0029634, which we call the key value.&lt;/p&gt; &#xA;&lt;p&gt;The kernel module then has a couple of lookup tables for the magic value, one for vGPU capable GPUs and one for the others. So the kernel module looks for the magic value in both of these lookup tables, and if it is found that table entry also contains a set of AES-128 encrypted data blocks and a HMAC-SHA256 signature.&lt;/p&gt; &#xA;&lt;p&gt;The signature is then validated by using the key value mentioned earlier to calculate the HMAC-SHA256 signature over the encrypted data blocks. If the signature is correct, then the blocks are decrypted using AES-128 and the same key.&lt;/p&gt; &#xA;&lt;p&gt;Inside of the decrypted data is once again the PCI device ID.&lt;/p&gt; &#xA;&lt;p&gt;So in order for the kernel module to accept the GPU as vGPU capable the magic value will have to be in the table of vGPU capable magic values, the key has to generate a valid HMAC-SHA256 signature and the AES-128 decrypted data blocks has to contain a vGPU capable PCI device ID. If any of these checks fail, then the error code 0x56 &#34;Call not supported&#34; is returned.&lt;/p&gt; &#xA;&lt;p&gt;In order to make these checks pass the hooks in vgpu_unlock_hooks.c will look for a ioremap call that maps the physical address range that contain the magic and key values, recalculate the addresses of those values into the virtual address space of the kernel module, monitor memcpy operations reading at those addresses, and if such an operation occurs, keep a copy of the value until both are known, locate the lookup tables in the .rodata section of nv-kernel.o, find the signature and data bocks, validate the signature, decrypt the blocks, edit the PCI device ID in the decrypted data, reencrypt the blocks, regenerate the signature and insert the magic, blocks and signature into the table of vGPU capable magic values. And that&#39;s what they do.&lt;/p&gt;</summary>
  </entry>
</feed>