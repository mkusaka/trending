<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-08T01:30:38Z</updated>
  <subtitle>Daily Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>libusb/hidapi</title>
    <updated>2023-04-08T01:30:38Z</updated>
    <id>tag:github.com,2023-04-08:/libusb/hidapi</id>
    <link href="https://github.com/libusb/hidapi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Simple cross-platform library for communicating with HID devices&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;HIDAPI library for Windows, Linux, FreeBSD and macOS&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;CI instance&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Linux/macOS/Windows master&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/libusb/hidapi/actions/workflows/builds.yml?query=branch%3Amaster&#34;&gt;&lt;img src=&#34;https://github.com/libusb/hidapi/workflows/GitHub%20Builds/badge.svg?branch=master&#34; alt=&#34;GitHub Builds&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Windows master&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ci.appveyor.com/project/libusb/hidapi/branch/master&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/xfmr5fo8w0re8ded/branch/master?svg=true&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Linux/BSD, last build (branch/PR)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://builds.sr.ht/~z3ntu/hidapi&#34;&gt;&lt;img src=&#34;https://builds.sr.ht/~z3ntu/hidapi.svg?sanitize=true&#34; alt=&#34;builds.sr.ht status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;HIDAPI is a multi-platform library which allows an application to interface with USB and Bluetooth HID-Class devices on Windows, Linux, FreeBSD, and macOS. HIDAPI can be either built as a shared library (&lt;code&gt;.so&lt;/code&gt;, &lt;code&gt;.dll&lt;/code&gt; or &lt;code&gt;.dylib&lt;/code&gt;) or can be embedded directly into a target application by adding a &lt;em&gt;single source&lt;/em&gt; file (per platform) and a single header.&lt;br&gt; See &lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/BUILD.md#embedding-hidapi-directly-into-your-source-tree&#34;&gt;remarks&lt;/a&gt; on embedding &lt;em&gt;directly&lt;/em&gt; into your build system.&lt;/p&gt; &#xA;&lt;p&gt;HIDAPI library was originally developed by Alan Ott (&lt;a href=&#34;https://github.com/signal11&#34;&gt;signal11&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;It was moved to &lt;a href=&#34;https://github.com/libusb/hidapi&#34;&gt;libusb/hidapi&lt;/a&gt; on June 4th, 2019, in order to merge important bugfixes and continue development of the library.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/#about&#34;&gt;About&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/#test-gui&#34;&gt;Test GUI&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/#console-test-app&#34;&gt;Console Test App&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/#what-does-the-api-look-like&#34;&gt;What Does the API Look Like?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/#installing-hidapi&#34;&gt;Installing HIDAPI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/#build-from-source&#34;&gt;Build from Source&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;h3&gt;HIDAPI has four back-ends:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows (using &lt;code&gt;hid.dll&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Linux/hidraw (using the Kernel&#39;s hidraw driver)&lt;/li&gt; &#xA; &lt;li&gt;libusb (using libusb-1.0 - Linux/BSD/other UNIX-like systems)&lt;/li&gt; &#xA; &lt;li&gt;macOS (using IOHidManager)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;On Linux, either the hidraw or the libusb back-end can be used. There are tradeoffs, and the functionality supported is slightly different. Both are built by default. It is up to the application linking to hidapi to choose the backend at link time by linking to either &lt;code&gt;libhidapi-libusb&lt;/code&gt; or &lt;code&gt;libhidapi-hidraw&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note that you will need to install an udev rule file with your application for unprivileged users to be able to access HID devices with hidapi. Refer to the &lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/udev/69-hid.rules&#34;&gt;69-hid.rules&lt;/a&gt; file in the &lt;code&gt;udev&lt;/code&gt; directory for an example.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;strong&gt;Linux/hidraw&lt;/strong&gt; (&lt;code&gt;linux/hid.c&lt;/code&gt;):&lt;/h4&gt; &#xA;&lt;p&gt;This back-end uses the hidraw interface in the Linux kernel, and supports both USB and Bluetooth HID devices. It requires kernel version at least 2.6.39 to build. In addition, it will only communicate with devices which have hidraw nodes associated with them. Keyboards, mice, and some other devices which are blacklisted from having hidraw nodes will not work. Fortunately, for nearly all the uses of hidraw, this is not a problem.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;strong&gt;Linux/FreeBSD/libusb&lt;/strong&gt; (&lt;code&gt;libusb/hid.c&lt;/code&gt;):&lt;/h4&gt; &#xA;&lt;p&gt;This back-end uses libusb-1.0 to communicate directly to a USB device. This back-end will of course not work with Bluetooth devices.&lt;/p&gt; &#xA;&lt;h3&gt;Test GUI&lt;/h3&gt; &#xA;&lt;p&gt;HIDAPI also comes with a Test GUI. The Test GUI is cross-platform and uses Fox Toolkit &lt;a href=&#34;http://www.fox-toolkit.org&#34;&gt;http://www.fox-toolkit.org&lt;/a&gt;. It will build on every platform which HIDAPI supports. Since it relies on a 3rd party library, building it is optional but it is useful when debugging hardware.&lt;/p&gt; &#xA;&lt;p&gt;NOTE: Test GUI based on Fox Toolkit is not actively developed nor supported by HIDAPI team. It is kept as a historical artifact. It may even work sometime or on some platforms, but it is not going to get any new features or bugfixes.&lt;/p&gt; &#xA;&lt;p&gt;Instructions for installing Fox-Toolkit on each platform is not provided. Make sure to use Fox-Toolkit v1.6 if you choose to use it.&lt;/p&gt; &#xA;&lt;h3&gt;Console Test App&lt;/h3&gt; &#xA;&lt;p&gt;If you want to play around with your HID device before starting any development with HIDAPI and using a GUI app is not an option for you, you may try &lt;a href=&#34;https://github.com/todbot/hidapitester&#34;&gt;&lt;code&gt;hidapitester&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This app has a console interface for most of the features supported by HIDAPI library.&lt;/p&gt; &#xA;&lt;h2&gt;What Does the API Look Like?&lt;/h2&gt; &#xA;&lt;p&gt;The API provides the most commonly used HID functions including sending and receiving of input, output, and feature reports. The sample program, which communicates with a heavily hacked up version of the Microchip USB Generic HID sample looks like this (with error checking removed for simplicity):&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Warning: Only run the code you understand, and only when it conforms to the device spec. Writing data (&lt;code&gt;hid_write&lt;/code&gt;) at random to your HID devices can break them.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt; // printf&#xA;#include &amp;lt;wchar.h&amp;gt; // wchar_t&#xA;&#xA;#include &amp;lt;hidapi.h&amp;gt;&#xA;&#xA;#define MAX_STR 255&#xA;&#xA;int main(int argc, char* argv[])&#xA;{&#xA;&#x9;int res;&#xA;&#x9;unsigned char buf[65];&#xA;&#x9;wchar_t wstr[MAX_STR];&#xA;&#x9;hid_device *handle;&#xA;&#x9;int i;&#xA;&#xA;&#x9;// Initialize the hidapi library&#xA;&#x9;res = hid_init();&#xA;&#xA;&#x9;// Open the device using the VID, PID,&#xA;&#x9;// and optionally the Serial number.&#xA;&#x9;handle = hid_open(0x4d8, 0x3f, NULL);&#xA;&#x9;if (!handle) {&#xA;&#x9;&#x9;printf(&#34;Unable to open device\n&#34;);&#xA;&#x9;&#x9;hid_exit();&#xA; &#x9;&#x9;return 1;&#xA;&#x9;}&#xA;&#xA;&#x9;// Read the Manufacturer String&#xA;&#x9;res = hid_get_manufacturer_string(handle, wstr, MAX_STR);&#xA;&#x9;printf(&#34;Manufacturer String: %ls\n&#34;, wstr);&#xA;&#xA;&#x9;// Read the Product String&#xA;&#x9;res = hid_get_product_string(handle, wstr, MAX_STR);&#xA;&#x9;printf(&#34;Product String: %ls\n&#34;, wstr);&#xA;&#xA;&#x9;// Read the Serial Number String&#xA;&#x9;res = hid_get_serial_number_string(handle, wstr, MAX_STR);&#xA;&#x9;printf(&#34;Serial Number String: (%d) %ls\n&#34;, wstr[0], wstr);&#xA;&#xA;&#x9;// Read Indexed String 1&#xA;&#x9;res = hid_get_indexed_string(handle, 1, wstr, MAX_STR);&#xA;&#x9;printf(&#34;Indexed String 1: %ls\n&#34;, wstr);&#xA;&#xA;&#x9;// Toggle LED (cmd 0x80). The first byte is the report number (0x0).&#xA;&#x9;buf[0] = 0x0;&#xA;&#x9;buf[1] = 0x80;&#xA;&#x9;res = hid_write(handle, buf, 65);&#xA;&#xA;&#x9;// Request state (cmd 0x81). The first byte is the report number (0x0).&#xA;&#x9;buf[0] = 0x0;&#xA;&#x9;buf[1] = 0x81;&#xA;&#x9;res = hid_write(handle, buf, 65);&#xA;&#xA;&#x9;// Read requested state&#xA;&#x9;res = hid_read(handle, buf, 65);&#xA;&#xA;&#x9;// Print out the returned buffer.&#xA;&#x9;for (i = 0; i &amp;lt; 4; i++)&#xA;&#x9;&#x9;printf(&#34;buf[%d]: %d\n&#34;, i, buf[i]);&#xA;&#xA;&#x9;// Close the device&#xA;&#x9;hid_close(handle);&#xA;&#xA;&#x9;// Finalize the hidapi library&#xA;&#x9;res = hid_exit();&#xA;&#xA;&#x9;return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use &lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/hidtest/test.c&#34;&gt;hidtest/test.c&lt;/a&gt; as a starting point for your applications.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;HIDAPI may be used by one of three licenses as outlined in &lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/LICENSE.txt&#34;&gt;LICENSE.txt&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installing HIDAPI&lt;/h2&gt; &#xA;&lt;p&gt;If you want to build your own application that uses HID devices with HIDAPI, you need to get HIDAPI development package.&lt;/p&gt; &#xA;&lt;p&gt;Depending on what your development environment is, HIDAPI likely to be provided by your package manager.&lt;/p&gt; &#xA;&lt;p&gt;For instance on Ubuntu, HIDAPI is available via APT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt install libhidapi-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;HIDAPI package name for other systems/package managers may differ. Check the documentation/package list of your package manager.&lt;/p&gt; &#xA;&lt;h2&gt;Build from Source&lt;/h2&gt; &#xA;&lt;p&gt;Check &lt;a href=&#34;https://raw.githubusercontent.com/libusb/hidapi/master/BUILD.md&#34;&gt;BUILD.md&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>google/XNNPACK</title>
    <updated>2023-04-08T01:30:38Z</updated>
    <id>tag:github.com,2023-04-08:/google/XNNPACK</id>
    <link href="https://github.com/google/XNNPACK" rel="alternate"></link>
    <summary type="html">&lt;p&gt;High-efficiency floating-point neural network inference operators for mobile, server, and Web&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;XNNPACK&lt;/h1&gt; &#xA;&lt;p&gt;XNNPACK is a highly optimized solution for neural network inference on ARM, x86, WebAssembly, and RISC-V platforms. XNNPACK is not intended for direct use by deep learning practitioners and researchers; instead it provides low-level performance primitives for accelerating high-level machine learning frameworks, such as &lt;a href=&#34;https://www.tensorflow.org/lite&#34;&gt;TensorFlow Lite&lt;/a&gt;, &lt;a href=&#34;https://www.tensorflow.org/js&#34;&gt;TensorFlow.js&lt;/a&gt;, &lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;, &lt;a href=&#34;https://onnxruntime.ai&#34;&gt;ONNX Runtime&lt;/a&gt;, and &lt;a href=&#34;https://mediapipe.dev&#34;&gt;MediaPipe&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Architectures&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ARM64 on Android, iOS, macOS, Linux, and Windows&lt;/li&gt; &#xA; &lt;li&gt;ARMv7 (with NEON) on Android&lt;/li&gt; &#xA; &lt;li&gt;ARMv6 (with VFPv2) on Linux&lt;/li&gt; &#xA; &lt;li&gt;x86 and x86-64 (up to AVX512) on Windows, Linux, macOS, Android, and iOS simulator&lt;/li&gt; &#xA; &lt;li&gt;WebAssembly MVP&lt;/li&gt; &#xA; &lt;li&gt;WebAssembly SIMD&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/WebAssembly/relaxed-simd&#34;&gt;WebAssembly Relaxed SIMD&lt;/a&gt; (experimental)&lt;/li&gt; &#xA; &lt;li&gt;RISC-V (RV32GC and RV64GC)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Operator Coverage&lt;/h2&gt; &#xA;&lt;p&gt;XNNPACK implements the following neural network operators:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2D Convolution (including grouped and depthwise)&lt;/li&gt; &#xA; &lt;li&gt;2D Deconvolution (AKA Transposed Convolution)&lt;/li&gt; &#xA; &lt;li&gt;2D Average Pooling&lt;/li&gt; &#xA; &lt;li&gt;2D Max Pooling&lt;/li&gt; &#xA; &lt;li&gt;2D ArgMax Pooling (Max Pooling + indices)&lt;/li&gt; &#xA; &lt;li&gt;2D Unpooling&lt;/li&gt; &#xA; &lt;li&gt;2D Bilinear Resize&lt;/li&gt; &#xA; &lt;li&gt;2D Depth-to-Space (AKA Pixel Shuffle)&lt;/li&gt; &#xA; &lt;li&gt;Add (including broadcasting, two inputs only)&lt;/li&gt; &#xA; &lt;li&gt;Subtract (including broadcasting)&lt;/li&gt; &#xA; &lt;li&gt;Divide (including broadcasting)&lt;/li&gt; &#xA; &lt;li&gt;Maximum (including broadcasting)&lt;/li&gt; &#xA; &lt;li&gt;Minimum (including broadcasting)&lt;/li&gt; &#xA; &lt;li&gt;Multiply (including broadcasting)&lt;/li&gt; &#xA; &lt;li&gt;Squared Difference (including broadcasting)&lt;/li&gt; &#xA; &lt;li&gt;Global Average Pooling&lt;/li&gt; &#xA; &lt;li&gt;Channel Shuffle&lt;/li&gt; &#xA; &lt;li&gt;Fully Connected&lt;/li&gt; &#xA; &lt;li&gt;Abs (absolute value)&lt;/li&gt; &#xA; &lt;li&gt;Bankers&#39; Rounding (rounding to nearest, ties to even)&lt;/li&gt; &#xA; &lt;li&gt;Ceiling (rounding to integer above)&lt;/li&gt; &#xA; &lt;li&gt;Clamp (includes ReLU and ReLU6)&lt;/li&gt; &#xA; &lt;li&gt;Convert (includes fixed-point and half-precision quantization and dequantization)&lt;/li&gt; &#xA; &lt;li&gt;Copy&lt;/li&gt; &#xA; &lt;li&gt;ELU&lt;/li&gt; &#xA; &lt;li&gt;Floor (rounding to integer below)&lt;/li&gt; &#xA; &lt;li&gt;HardSwish&lt;/li&gt; &#xA; &lt;li&gt;Leaky ReLU&lt;/li&gt; &#xA; &lt;li&gt;Negate&lt;/li&gt; &#xA; &lt;li&gt;Sigmoid&lt;/li&gt; &#xA; &lt;li&gt;Softmax&lt;/li&gt; &#xA; &lt;li&gt;Square&lt;/li&gt; &#xA; &lt;li&gt;Tanh&lt;/li&gt; &#xA; &lt;li&gt;Transpose&lt;/li&gt; &#xA; &lt;li&gt;Truncation (rounding to integer towards zero)&lt;/li&gt; &#xA; &lt;li&gt;PReLU&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All operators in XNNPACK support NHWC layout, but additionally allow custom stride along the &lt;strong&gt;C&lt;/strong&gt;hannel dimension. Thus, operators can consume a subset of channels in the input tensor, and produce a subset of channels in the output tensor, providing a zero-cost Channel Split and Channel Concatenation operations.&lt;/p&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;h3&gt;Mobile phones&lt;/h3&gt; &#xA;&lt;p&gt;The table below presents &lt;strong&gt;single-threaded&lt;/strong&gt; performance of XNNPACK library on three generations of MobileNet models and three generations of Pixel phones.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pixel, ms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pixel 2, ms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pixel 3a, ms&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v1 1.0X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;82&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;86&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;88&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v2 1.0X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;55&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v3 Large&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v3 Small&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The following table presents &lt;strong&gt;multi-threaded&lt;/strong&gt; (using as many threads as there are big cores) performance of XNNPACK library on three generations of MobileNet models and three generations of Pixel phones.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pixel, ms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pixel 2, ms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pixel 3a, ms&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v1 1.0X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v2 1.0X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v3 Large&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v3 Small&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Benchmarked on March 27, 2020 with &lt;code&gt;end2end_bench --benchmark_min_time=5&lt;/code&gt; on an Android/ARM64 build with Android NDK r21 (&lt;code&gt;bazel build -c opt --config android_arm64 :end2end_bench&lt;/code&gt;) and neural network models with randomized weights and inputs.&lt;/p&gt; &#xA;&lt;h3&gt;Raspberry Pi&lt;/h3&gt; &#xA;&lt;p&gt;The table below presents &lt;strong&gt;multi-threaded&lt;/strong&gt; performance of XNNPACK library on three generations of MobileNet models and three generations of Raspberry Pi boards.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;RPi Zero W (BCM2835), ms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;RPi 2 (BCM2836), ms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;RPi 3+ (BCM2837B0), ms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;RPi 4 (BCM2711), ms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;RPi 4 (BCM2711, ARM64), ms&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v1 1.0X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3919&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;302&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;114&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;72&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v2 1.0X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1987&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;191&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;79&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v3 Large&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1658&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;161&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;67&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP32 MobileNet v3 Small&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;474&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;INT8 MobileNet v1 1.0X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2589&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;128&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;INT8 MobileNet v2 1.0X&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1495&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;82&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Benchmarked on Feb 8, 2022 with &lt;code&gt;end2end-bench --benchmark_min_time=5&lt;/code&gt; on a Raspbian Buster build with CMake (&lt;code&gt;./scripts/build-local.sh&lt;/code&gt;) and neural network models with randomized weights and inputs. INT8 inference was evaluated on per-channel quantization schema.&lt;/p&gt; &#xA;&lt;h2&gt;Minimum build requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;C11&lt;/li&gt; &#xA; &lt;li&gt;C++14&lt;/li&gt; &#xA; &lt;li&gt;Python 3&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Publications&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Marat Dukhan &#34;The Indirect Convolution Algorithm&#34;. Presented on &lt;a href=&#34;https://sites.google.com/corp/view/ecv2019/&#34;&gt;Efficient Deep Learning for Compute Vision (ECV) 2019&lt;/a&gt; workshop (&lt;a href=&#34;https://drive.google.com/file/d/1ZayB3By5ZxxQIRtN7UDq_JvPg1IYd3Ac/view&#34;&gt;slides&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/1907.02129&#34;&gt;paper on ArXiv&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Erich Elsen, Marat Dukhan, Trevor Gale, Karen Simonyan &#34;Fast Sparse ConvNets&#34;. &lt;a href=&#34;https://arxiv.org/abs/1911.09723&#34;&gt;Paper on ArXiv&lt;/a&gt;, &lt;a href=&#34;https://github.com/google-research/google-research/tree/master/fastconvnets&#34;&gt;pre-trained sparse models&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Marat Dukhan, Artsiom Ablavatski &#34;The Two-Pass Softmax Algorithm&#34;. &lt;a href=&#34;https://arxiv.org/abs/2001.04438&#34;&gt;Paper on ArXiv&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Yury Pisarchyk, Juhyun Lee &#34;Efficient Memory Management for Deep Neural Net Inference&#34;. &lt;a href=&#34;https://arxiv.org/abs/2001.03288&#34;&gt;Paper on ArXiv&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Ecosystem&lt;/h2&gt; &#xA;&lt;h3&gt;Machine Learning Frameworks&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.tensorflow.org/2020/07/accelerating-tensorflow-lite-xnnpack-integration.html&#34;&gt;TensorFlow Lite&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.tensorflow.org/2020/03/introducing-webassembly-backend-for-tensorflow-js.html&#34;&gt;TensorFlow.js WebAssembly backend&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pytorch.org/mobile&#34;&gt;PyTorch Mobile&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://onnxruntime.ai/docs/execution-providers/Xnnpack-ExecutionProvider.html&#34;&gt;ONNX Runtime Mobile&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.googleblog.com/2020/01/mediapipe-on-web.html&#34;&gt;MediaPipe for the Web&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/alibaba/heterogeneity-aware-lowering-and-optimization&#34;&gt;Alibaba HALO (Heterogeneity-Aware Lowering and Optimization)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Samsung/ONE&#34;&gt;Samsung ONE (On-device Neural Engine)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;XNNPACK is a based on &lt;a href=&#34;https://github.com/pytorch/QNNPACK&#34;&gt;QNNPACK&lt;/a&gt; library. Over time its codebase diverged a lot, and XNNPACK API is no longer compatible with QNNPACK.&lt;/p&gt;</summary>
  </entry>
</feed>