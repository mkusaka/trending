<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-19T01:31:58Z</updated>
  <subtitle>Daily Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Liuk3r/CVE-2023-32233</title>
    <updated>2023-05-19T01:31:58Z</updated>
    <id>tag:github.com,2023-05-19:/Liuk3r/CVE-2023-32233</id>
    <link href="https://github.com/Liuk3r/CVE-2023-32233" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CVE-2023-32233: LinuxÂÜÖÊ†∏‰∏≠ÁöÑÂÆâÂÖ®ÊºèÊ¥û&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Building And Configuring&lt;/h1&gt; &#xA;&lt;p&gt;The instructions below were tested under Ubuntu 23.04 (Lunar Lobster).&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Liuk3r/CVE-2023-32233/assets/62884435/71a3784d-f7f1-40c0-9c9f-10db60a42b36&#34; alt=&#34;GIF 2023-5-16 12-28-46&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installing Build Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;Run the following command to install the build dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt install gcc libmnl-dev libnftnl-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Building Binary&lt;/h2&gt; &#xA;&lt;p&gt;Run the following command to build the PoC binary:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gcc -Wall -o exploit exploit.c -lmnl -lnftnl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Updating Profile&lt;/h2&gt; &#xA;&lt;p&gt;Built-in profile contains parameters specific to the Linux kernel distributed in binary form as the following packages from Ubuntu 23.04 (Lunar Lobster):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&#34;linux-image-6.2.0-20-generic&#34;, version &#34;6.2.0-20.20&#34;, and&lt;/li&gt; &#xA; &lt;li&gt;&#34;linux-modules-6.2.0-20-generic&#34;, version &#34;6.2.0-20.20&#34;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The built-in profile looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;1                   race_set_slab                   # {0,1}&#xA;1572                race_set_elem_count             # k&#xA;4000                initial_sleep                   # ms&#xA;100                 race_lead_sleep                 # ms&#xA;600                 race_lag_sleep                  # ms&#xA;100                 reuse_sleep                     # ms&#xA;39d240              free_percpu                     # hex&#xA;2a8b900             modprobe_path                   # hex&#xA;23700               nft_counter_destroy             # hex&#xA;347a0               nft_counter_ops                 # hex&#xA;a                   nft_counter_destroy_call_offset # hex&#xA;ffffffff            nft_counter_destroy_call_mask   # hex&#xA;e8e58948            nft_counter_destroy_call_check  # hex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Kernel Symbols&lt;/h3&gt; &#xA;&lt;p&gt;Optional steps to override the built-in profile when testing with other Linux kernels:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;modprobe nf_tables&#xA;egrep &#39; (nft_counter_ops|nft_counter_destroy|free_percpu|modprobe_path)(\s|$)&#39; /proc/kallsyms &amp;gt; profile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Machine Code&lt;/h3&gt; &#xA;&lt;p&gt;In order to find the kernel base we examine the &lt;code&gt;nf_tables.ko&lt;/code&gt; image in the kernel memory. And specifically, we analyse the machine code of nft_counter_destroy() subroutine. This means that our method is sensitive to the compiler as well as the compilation options. However, all the usual cases can be handled by overriding the built-in profile.&lt;/p&gt; &#xA;&lt;p&gt;For example, the machine code of nft_counter_destroy() subroutine may look like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;000000000001e310 &amp;lt;nft_counter_destroy&amp;gt;:&#xA;   1e310:       f3 0f 1e fa             endbr64&#xA;   1e314:       48 8b 7e 08             mov    rdi,QWORD PTR [rsi+0x8]&#xA;   1e318:       e9 00 00 00 00          jmp    &amp;lt;free_percpu&amp;gt;&#xA;   1e31d:       0f 1f 00                nop    DWORD PTR [rax]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the above case we can specify a few parameters by appending the three lines below to the configuration file &#34;profile&#34;.&lt;/p&gt; &#xA;&lt;p&gt;First, we redefine the offset of the dword preceding the &lt;code&gt;free_percpu&lt;/code&gt; displacement:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;5                   nft_counter_destroy_call_offset # hex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where the value &lt;code&gt;5&lt;/code&gt; was computed using the expression &lt;code&gt;(1e31d - 1e310) - 8&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;As a sanity check, we then validate the dword at the above offset using the following mask:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffffffff            nft_counter_destroy_call_mask   # hex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;expecting the following value:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;e9087e8b            nft_counter_destroy_call_check  # hex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Race Tuning&lt;/h3&gt; &#xA;&lt;p&gt;Exploiting the vulnerability requires winning a race with background worker thread from the Linux kernel. The built-in profile has been tuned to maximise the chance of winning that race on a broad range of Intel microprocessors including mobile Sandy Bridge and desktop Comet Lake. However, some microprocessors require additional tuning. For example, we observed increased latency to switch tasks under Alder Lake in certain setups, where it may be necessary to append the following line to &#34;profile&#34;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;400                 race_lead_sleep&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We measured probability of 80% or better to successfully exploit the vulnerability in our tests that used idle bare-metal systems.&lt;/p&gt; &#xA;&lt;h2&gt;Testing Recommendations&lt;/h2&gt; &#xA;&lt;p&gt;Once the PoC is started on a vulnerable system, it may leave that system in an unstable state with corrupted kernel memory. We strongly recommend to test the PoC on a dedicated system to avoid potential data corruptions.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>robdelacruz/lkwebserver</title>
    <updated>2023-05-19T01:31:58Z</updated>
    <id>tag:github.com,2023-05-19:/robdelacruz/lkwebserver</id>
    <link href="https://github.com/robdelacruz/lkwebserver" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Little Kitten Webserver&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Little Kitten Web Server&lt;/h2&gt; &#xA;&lt;p&gt;A little web server written in C for Linux.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;No external library dependencies&lt;/li&gt; &#xA; &lt;li&gt;Single threaded using I/O multiplexing (select)&lt;/li&gt; &#xA; &lt;li&gt;Supports CGI interface&lt;/li&gt; &#xA; &lt;li&gt;Supports reverse proxy&lt;/li&gt; &#xA; &lt;li&gt;lklib and lknet code available to create your own http server or client&lt;/li&gt; &#xA; &lt;li&gt;Free to use and modify (MIT License)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;To compile:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make lkws&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;lkws [homedir] [port] [host] [-f configfile] [--cgidir=cgifolder]&#xA;&#xA;configfile = configuration file containing site settings&#xA;             see sample configuration file below&#xA;homedir    = absolute or relative path to a home directory&#xA;             defaults to current working directory if not specified&#xA;port       = port number to bind to server&#xA;             defaults to 8000&#xA;host       = IP address to bind to server&#xA;             defaults to localhost&#xA;cgifolder  = parent directory of cgi scripts&#xA;             defaults to cgi-bin if not specified&#xA;&#xA;Examples:&#xA;lkws ./testsite/ 8080&#xA;lkws /var/www/testsite/ 8080 127.0.0.1&#xA;lkws /var/www/testsite/ --cgidir=cgi-bin&#xA;lkws -f sites.conf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Sample configuration file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;serverhost=127.0.0.1&#xA;port=5000&#xA;&#xA;# Matches all other hostnames&#xA;hostname *&#xA;homedir=/var/www/testsite&#xA;alias latest=latest.html&#xA;&#xA;# Matches http://localhost&#xA;hostname localhost&#xA;homedir=/var/www/testsite&#xA;&#xA;# http://littlekitten.xyz&#xA;hostname littlekitten.xyz&#xA;homedir=/var/www/testsite&#xA;cgidir=cgi-bin&#xA;alias latest=latest.html&#xA;alias about=about.html&#xA;alias guestbook=cgi-bin/guestbook.pl&#xA;alias blog=cgi-bin/blog.pl&#xA;&#xA;# http://newsboard.littlekitten.xyz&#xA;hostname newsboard.littlekitten.xyz&#xA;proxyhost=localhost:8001&#xA;&#xA;# Format description:&#xA;#&#xA;# The host and port number is defined first, followed by one or more&#xA;# host config sections.&#xA;#&#xA;# The host config section always starts with the &#39;hostname &amp;lt;domain&amp;gt;&#39;&#xA;# line followed by the settings for that hostname. The section ends&#xA;# on either EOF or when a new &#39;hostname &amp;lt;domain&amp;gt;&#39; line is read,&#xA;# indicating the start of the next host config section.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Compiles and runs only on Linux (sorry, no Windows version... yet)&lt;/p&gt; &#xA;&lt;h2&gt;Todo&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;add logging&lt;/li&gt; &#xA; &lt;li&gt;add perf tests for many simultaneous clients&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>bigcode-project/starcoder.cpp</title>
    <updated>2023-05-19T01:31:58Z</updated>
    <id>tag:github.com,2023-05-19:/bigcode-project/starcoder.cpp</id>
    <link href="https://github.com/bigcode-project/starcoder.cpp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;C++ implementation for üí´StarCoder&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üí´StarCoder in C++&lt;/h1&gt; &#xA;&lt;p&gt;This is a C++ example running üí´ StarCoder inference using the &lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;ggml&lt;/a&gt; library.&lt;/p&gt; &#xA;&lt;p&gt;The program can run on the CPU - no video card is required.&lt;/p&gt; &#xA;&lt;p&gt;The example supports the following üí´ StarCoder models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;bigcode/starcoder&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;bigcode/gpt_bigcode-santacoder&lt;/code&gt; aka the smol StarCoder&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Sample performance on MacBook M1 Pro:&lt;/p&gt; &#xA;&lt;p&gt;TODO&lt;/p&gt; &#xA;&lt;p&gt;Sample output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./bin/starcoder -h&#xA;usage: ./bin/starcoder [options]&#xA;&#xA;options:&#xA;  -h, --help            show this help message and exit&#xA;  -s SEED, --seed SEED  RNG seed (default: -1)&#xA;  -t N, --threads N     number of threads to use during computation (default: 8)&#xA;  -p PROMPT, --prompt PROMPT&#xA;                        prompt to start generation with (default: random)&#xA;  -n N, --n_predict N   number of tokens to predict (default: 200)&#xA;  --top_k N             top-k sampling (default: 40)&#xA;  --top_p N             top-p sampling (default: 0.9)&#xA;  --temp N              temperature (default: 1.0)&#xA;  -b N, --batch_size N  batch size for prompt processing (default: 8)&#xA;  -m FNAME, --model FNAME&#xA;                        model path (default: models/starcoder-117M/ggml-model.bin)&#xA;&#xA;$ ./bin/starcoder -m ../models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin -p &#34;def fibonnaci(&#34; -t 4 --top_k 0 --top_p 0.95 --temp 0.2      &#xA;main: seed = 1683881276&#xA;starcoder_model_load: loading model from &#39;../models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin&#39;&#xA;starcoder_model_load: n_vocab = 49280&#xA;starcoder_model_load: n_ctx   = 2048&#xA;starcoder_model_load: n_embd  = 2048&#xA;starcoder_model_load: n_head  = 16&#xA;starcoder_model_load: n_layer = 24&#xA;starcoder_model_load: ftype   = 3&#xA;starcoder_model_load: ggml ctx size = 1794.90 MB&#xA;starcoder_model_load: memory size =   768.00 MB, n_mem = 49152&#xA;starcoder_model_load: model size  =  1026.83 MB&#xA;main: prompt: &#39;def fibonnaci(&#39;&#xA;main: number of tokens in prompt = 7, first 8 tokens: 563 24240 78 2658 64 2819 7 &#xA;&#xA;def fibonnaci(n):&#xA;    if n == 0:&#xA;        return 0&#xA;    elif n == 1:&#xA;        return 1&#xA;    else:&#xA;        return fibonacci(n-1) + fibonacci(n-2)&#xA;&#xA;print(fibo(10))&#xA;&#xA;main: mem per token =  9597928 bytes&#xA;main:     load time =   480.43 ms&#xA;main:   sample time =    26.21 ms&#xA;main:  predict time =  3987.95 ms / 19.36 ms per token&#xA;main:    total time =  4580.56 ms&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/bigcode-project/starcoder.cpp&#xA;cd starcoder.cpp&#xA;&#xA;# Convert HF model to ggml&#xA;python convert-hf-to-ggml.py bigcode/gpt_bigcode-santacoder&#xA;&#xA;# Build ggml libraries&#xA;make&#xA;&#xA;# quantize the model&#xA;./quantize models/bigcode/gpt_bigcode-santacoder-ggml.bin models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin 3&#xA;&#xA;# run inference&#xA;./main -m models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin -p &#34;def fibonnaci(&#34; --top_k 0 --top_p 0.95 --temp 0.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Downloading and converting the original models (üí´ StarCoder)&lt;/h2&gt; &#xA;&lt;p&gt;You can download the original model and convert it to &lt;code&gt;ggml&lt;/code&gt; format using the script &lt;code&gt;convert-hf-to-ggml.py&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Convert HF model to ggml&#xA;python convert-hf-to-ggml.py bigcode/gpt_bigcode-santacoder&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This conversion requires that you have python and Transformers installed on your computer.&lt;/p&gt; &#xA;&lt;h2&gt;Quantizing the models&lt;/h2&gt; &#xA;&lt;p&gt;You can also try to quantize the &lt;code&gt;ggml&lt;/code&gt; models via 4-bit integer quantization.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# quantize the model&#xA;./quantize models/bigcode/gpt_bigcode-santacoder-ggml.bin models/bigcode/gpt_bigcode-santacoder-ggml-q4_1.bin 3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Original size&lt;/th&gt; &#xA;   &lt;th&gt;Quantized size&lt;/th&gt; &#xA;   &lt;th&gt;Quantization type&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;bigcode/gpt_bigcode-santacoder&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;5396.45 MB&lt;/td&gt; &#xA;   &lt;td&gt;1026.83 MB&lt;/td&gt; &#xA;   &lt;td&gt;4-bit integer (q4_1)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;bigcode/starcoder&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;71628.23 MB&lt;/td&gt; &#xA;   &lt;td&gt;13596.23 MB&lt;/td&gt; &#xA;   &lt;td&gt;4-bit integer (q4_1)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;iOS App&lt;/h2&gt; &#xA;&lt;p&gt;The repo includes a proof-of-concept iOS app in the &lt;code&gt;StarCoderApp&lt;/code&gt; directory. You need to provide the converted (and possibly quantized) model weights, placing a file called &lt;code&gt;bigcode_ggml_model.bin.bin&lt;/code&gt; inside that folder. This is what it looks like on an iPhone:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bigcode-project/starcoder.cpp/main/assets/starcoder-ios.jpg&#34; alt=&#34;starcoder-ios-screenshot&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>