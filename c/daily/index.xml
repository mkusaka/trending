<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-26T01:30:44Z</updated>
  <subtitle>Daily Trending of C in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>pret/pokeemerald</title>
    <updated>2022-11-26T01:30:44Z</updated>
    <id>tag:github.com,2022-11-26:/pret/pokeemerald</id>
    <link href="https://github.com/pret/pokeemerald" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Decompilation of Pokémon Emerald&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pokémon Emerald&lt;/h1&gt; &#xA;&lt;p&gt;This is a decompilation of Pokémon Emerald.&lt;/p&gt; &#xA;&lt;p&gt;It builds the following ROM:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datomatic.no-intro.org/index.php?page=show_record&amp;amp;s=23&amp;amp;n=1961&#34;&gt;&lt;strong&gt;pokeemerald.gba&lt;/strong&gt;&lt;/a&gt; &lt;code&gt;sha1: f3ae088181bf583e55daf962a92bb46f4f1d07b7&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To set up the repository, see &lt;a href=&#34;https://raw.githubusercontent.com/pret/pokeemerald/master/INSTALL.md&#34;&gt;INSTALL.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;See also&lt;/h2&gt; &#xA;&lt;p&gt;Other disassembly and/or decompilation projects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokered&#34;&gt;&lt;strong&gt;Pokémon Red and Blue&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokegold-spaceworld&#34;&gt;&lt;strong&gt;Pokémon Gold and Silver (Space World &#39;97 demo)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokeyellow&#34;&gt;&lt;strong&gt;Pokémon Yellow&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/poketcg&#34;&gt;&lt;strong&gt;Pokémon Trading Card Game&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokepinball&#34;&gt;&lt;strong&gt;Pokémon Pinball&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokestadium&#34;&gt;&lt;strong&gt;Pokémon Stadium&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokegold&#34;&gt;&lt;strong&gt;Pokémon Gold and Silver&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokecrystal&#34;&gt;&lt;strong&gt;Pokémon Crystal&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokeruby&#34;&gt;&lt;strong&gt;Pokémon Ruby and Sapphire&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokepinballrs&#34;&gt;&lt;strong&gt;Pokémon Pinball: Ruby &amp;amp; Sapphire&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pokefirered&#34;&gt;&lt;strong&gt;Pokémon FireRed and LeafGreen&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pret/pmd-red&#34;&gt;&lt;strong&gt;Pokémon Mystery Dungeon: Red Rescue Team&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contacts&lt;/h2&gt; &#xA;&lt;p&gt;You can find us on &lt;a href=&#34;https://discord.gg/d5dubZ3&#34;&gt;Discord&lt;/a&gt; and &lt;a href=&#34;https://web.libera.chat/?#pret&#34;&gt;IRC&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>NVIDIA/MAXINE-AR-SDK</title>
    <updated>2022-11-26T01:30:44Z</updated>
    <id>tag:github.com,2022-11-26:/NVIDIA/MAXINE-AR-SDK</id>
    <link href="https://github.com/NVIDIA/MAXINE-AR-SDK" rel="alternate"></link>
    <summary type="html">&lt;p&gt;NVIDIA AR SDK - API headers and sample applications&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;README&lt;/h1&gt; &#xA;&lt;h2&gt;NVIDIA MAXINE AR SDK: API Source Code and Sample Applications&lt;/h2&gt; &#xA;&lt;p&gt;NVIDIA MAXINE AR SDK offers AI-based, real-time 3D face tracking and modeling, as well as body pose estimation based on a standard web camera feed. Developers can create unique AR effects such as overlaying 3D content on a face, driving 3D characters and virtual interactions in real time. The SDK is powered by NVIDIA graphics processing units (GPUs) with Tensor Cores, and as a result, the algorithm throughput is greatly accelerated, and latency is reduced.&lt;/p&gt; &#xA;&lt;p&gt;The SDK has the following features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Face tracking&lt;/strong&gt;, which detects, localizes, and tracks human faces in images or videos by using bounding boxes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Face landmark tracking&lt;/strong&gt;, which predicts and tracks the pixel locations of human facial landmark points using 68 or 126 landmark points. The 68 detected facial landmarks follow the Multi-PIE 68 point mark-ups information in &lt;a href=&#34;https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/&#34;&gt;facial point annotations&lt;/a&gt;. The 126 landmark points detector can predict more points on the cheeks, the eyes, and on laugh lines. Additionally, it tracks head pose and facial deformation due to head movement and expression in three degrees of freedom in real time.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Face mesh&lt;/strong&gt;, which reconstructs and tracks a human face via a 3D mesh, as well as its head pose, from the provided facial landmarks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Body Pose Estimation&lt;/strong&gt;, which predicts and tracks 34 key points of the human body, with joint angles, in 2D and 3D. It also supports multi-person tracking.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Eye contact&lt;/strong&gt;, which simulates eye contact by estimating and aligning gaze with the camera to enhance engagement in video communication.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Face Expression Estimation&lt;/strong&gt;, which estimates face expression (blendshape) coefficients from the provided facial landmarks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/NVIDIA/MAXINE-AR-SDK/raw/master/resources/ar_001.png&#34; alt=&#34;Face tracking&#34; width=&#34;320&#34; height=&#34;180&#34;&gt; &lt;img src=&#34;https://github.com/NVIDIA/MAXINE-AR-SDK/raw/master/resources/ar_002.png&#34; alt=&#34;Face landmark tracking - 68 pts&#34; width=&#34;320&#34; height=&#34;180&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/NVIDIA/MAXINE-AR-SDK/raw/master/resources/ar_003.png&#34; alt=&#34;Face landmark tracking - 126 pts&#34; width=&#34;320&#34; height=&#34;180&#34;&gt; &lt;img src=&#34;https://github.com/NVIDIA/MAXINE-AR-SDK/raw/master/resources/ar_004.png&#34; alt=&#34;Face mesh&#34; width=&#34;320&#34; height=&#34;180&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/NVIDIA/MAXINE-AR-SDK/raw/master/resources/ar_005.png&#34; alt=&#34;Body Pose estimation&#34; width=&#34;480&#34; height=&#34;270&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/NVIDIA/MAXINE-AR-SDK/raw/master/resources/ar_006.png&#34; alt=&#34;Eye contact&#34; width=&#34;640&#34; height=&#34;237&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/NVIDIA/MAXINE-AR-SDK/raw/master/resources/ar_007.png&#34; alt=&#34;Face Expression Estimation&#34; width=&#34;640&#34; height=&#34;175&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;The SDK provides four sample applications that demonstrate the features listed above in real time by using a webcam or offline videos.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;FaceTrack App&lt;/strong&gt; which demonstrates the face tracking, landmark tracking and face mesh tracking features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;BodyTrack App&lt;/strong&gt; which demonstrates the Body Pose estimation feature.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GazeRedirect App&lt;/strong&gt; which demonstrates the Eye Contact feature.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ExpressionApp&lt;/strong&gt; which demonstrates the Face Expression Estimation feature.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;NVIDIA MAXINE AR SDK is distributed in the following parts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This open source repository that includes the &lt;a href=&#34;https://github.com/NVIDIA/MAXINE-AR-SDK/tree/master/nvar&#34;&gt;SDK API and proxy linking source code&lt;/a&gt;, and &lt;a href=&#34;https://github.com/NVIDIA/MAXINE-AR-SDK/tree/master/samples&#34;&gt;sample applications and their dependency libraries&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;An installer hosted on &lt;a href=&#34;https://www.nvidia.com/broadcast-sdk-resources&#34;&gt;NVIDIA Maxine End-user Redistributables page&lt;/a&gt; that installs the SDK DLLs, the models, and the SDK dependency libraries.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://docs.nvidia.com/deeplearning/maxine/ar-sdk-system-guide/index.html&#34;&gt;SDK System guide&lt;/a&gt; for configuring and integrating the SDK, compiling and running the sample applications. Please visit the &lt;a href=&#34;https://developer.nvidia.com/maxine-getting-started&#34;&gt;NVIDIA MAXINE AR SDK&lt;/a&gt; webpage for more information about the SDK.&lt;/p&gt; &#xA;&lt;h2&gt;System requirements&lt;/h2&gt; &#xA;&lt;p&gt;The SDK is supported on NVIDIA GPUs that are based on the NVIDIA® Turing™, Ampere™ or Ada™ architecture and have Tensor Cores.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows OS supported: 64-bit Windows 10 or later&lt;/li&gt; &#xA; &lt;li&gt;Microsoft Visual Studio: 2017 (MSVC15.0) or later&lt;/li&gt; &#xA; &lt;li&gt;CMake: v3.12 or later&lt;/li&gt; &#xA; &lt;li&gt;NVIDIA Graphics Driver for Windows: 511.65 or later&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;NVIDIA MAXINE Branding Guidelines&lt;/h2&gt; &#xA;&lt;p&gt;If you integrate an NVIDIA MAXINE SDK within your product, please follow the required branding guidelines that are available &lt;a href=&#34;https://www.nvidia.com/maxine-sdk-guidelines&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Compiling the sample app&lt;/h2&gt; &#xA;&lt;h3&gt;Steps&lt;/h3&gt; &#xA;&lt;p&gt;The open source repository includes the source code to build the sample application, and a proxy file nvARProxy.cpp to enable compilation without explicitly linking against the SDK DLL.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: To download the models and runtime dependencies required by the features, you need to run the &lt;a href=&#34;https://www.nvidia.com/broadcast-sdk-resources&#34;&gt;SDK Installer&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;In the root folder of the downloaded source code, start the CMake GUI and specify the source folder and a build folder for the binary files.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For the source folder, ensure that the path ends in OSS.&lt;/li&gt; &#xA; &lt;li&gt;For the build folder, ensure that the path ends in OSS/build.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Use CMake to configure and generate the Visual Studio solution file.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Click Configure.&lt;/li&gt; &#xA; &lt;li&gt;When prompted to confirm that CMake can create the build folder, click OK.&lt;/li&gt; &#xA; &lt;li&gt;Select Visual Studio for the generator and x64 for the platform.&lt;/li&gt; &#xA; &lt;li&gt;To complete configuring the Visual Studio solution file, click Finish.&lt;/li&gt; &#xA; &lt;li&gt;To generate the Visual Studio Solution file, click Generate.&lt;/li&gt; &#xA; &lt;li&gt;Verify that the build folder contains the NvAR_SDK.sln file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Use Visual Studio to generate the FaceTrack.exe, BodyTrack.exe, GazeRedirect.exe or ExpressionApp.exe file from the NvAR_SDK.sln file.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;In CMake, to open Visual Studio, click Open Project.&lt;/li&gt; &#xA; &lt;li&gt;In Visual Studio, select Build &amp;gt; Build Solution.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the online documentation guides -&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/maxine/ar-sdk-programming-guide/index.html&#34;&gt;NVIDIA AR SDK Programming Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/maxine/ar-sdk-system-guide/index.html&#34;&gt;NVIDIA AR SDK System Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/maxine/nvcvimage-api-guide/index.html&#34;&gt;NvCVImage API Guide&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;PDF versions of these guides are also available at the following locations -&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/maxine/pdf/ar-sdk-programming-guide.pdf&#34;&gt;NVIDIA AR SDK Programming Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/maxine/pdf/ar-sdk-system-guide.pdf&#34;&gt;NVIDIA AR SDK System Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/maxine/pdf/nvcvimage-api-guide.pdf&#34;&gt;NvCVImage API Guide&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>alibaba/tengine</title>
    <updated>2022-11-26T01:30:44Z</updated>
    <id>tag:github.com,2022-11-26:/alibaba/tengine</id>
    <link href="https://github.com/alibaba/tengine" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A distribution of Nginx with some advanced features&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Introduction &lt;a href=&#34;https://github.com/alibaba/tengine/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/alibaba/tengine/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Tengine is a web server originated by &lt;a href=&#34;http://en.wikipedia.org/wiki/Taobao&#34;&gt;Taobao&lt;/a&gt;, the largest e-commerce website in Asia. It is based on the &lt;a href=&#34;http://nginx.org&#34;&gt;Nginx&lt;/a&gt; HTTP server and has many advanced features. Tengine has proven to be very stable and efficient on some of the top 100 websites in the world, including &lt;a href=&#34;http://www.taobao.com&#34;&gt;taobao.com&lt;/a&gt; and &lt;a href=&#34;http://www.tmall.com&#34;&gt;tmall.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Tengine has been an open source project since December 2011. It is being actively developed by the Tengine team, whose core members are from Taobao, Sogou and other Internet companies. Tengine is a community effort and everyone is encouraged to &lt;a href=&#34;https://github.com/alibaba/tengine&#34;&gt;get involved&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All features of nginx-1.18.0 are inherited, i.e., it is 100% compatible with nginx.&lt;/li&gt; &#xA; &lt;li&gt;Support the CONNECT HTTP method for forward proxy.&lt;/li&gt; &#xA; &lt;li&gt;Support asynchronous OpenSSL, using hardware such as QAT for HTTPS acceleration.&lt;/li&gt; &#xA; &lt;li&gt;Enhanced operations monitoring, such as asynchronous log &amp;amp; rollback, DNS caching, memory usage, etc.&lt;/li&gt; &#xA; &lt;li&gt;Support server_name in Stream module.&lt;/li&gt; &#xA; &lt;li&gt;More load balancing methods, e.g., consistent hashing, and session persistence.&lt;/li&gt; &#xA; &lt;li&gt;Input body filter support. It&#39;s quite handy to write Web Application Firewalls using this mechanism.&lt;/li&gt; &#xA; &lt;li&gt;Dynamic scripting language (Lua) support, which is very efficient and makes it easy to extend core functionalities.&lt;/li&gt; &#xA; &lt;li&gt;Limits retries for upstream servers (proxy, memcached, fastcgi, scgi, uwsgi).&lt;/li&gt; &#xA; &lt;li&gt;Includes a mechanism to support standalone processes.&lt;/li&gt; &#xA; &lt;li&gt;Protects the server in case system load or memory use goes too high.&lt;/li&gt; &#xA; &lt;li&gt;Multiple CSS or JavaScript requests can be combined into one request to reduce download time.&lt;/li&gt; &#xA; &lt;li&gt;Removes unnecessary white spaces and comments to reduce the size of a page.&lt;/li&gt; &#xA; &lt;li&gt;Proactive health checks of upstream servers can be performed.&lt;/li&gt; &#xA; &lt;li&gt;The number of worker processes and CPU affinities can be set automatically.&lt;/li&gt; &#xA; &lt;li&gt;The limit_req module is enhanced with whitelist support and more conditions are allowed in a single location.&lt;/li&gt; &#xA; &lt;li&gt;Enhanced diagnostic information makes it easier to troubleshoot errors.&lt;/li&gt; &#xA; &lt;li&gt;More user-friendly command lines, e.g., showing all compiled-in modules and supported directives.&lt;/li&gt; &#xA; &lt;li&gt;Expiration times can be specified for certain MIME types.&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;Tengine can be downloaded at &lt;a href=&#34;http://tengine.taobao.org/download/tengine.tar.gz&#34;&gt;http://tengine.taobao.org/download/tengine.tar.gz&lt;/a&gt;. You can also checkout the latest source code from GitHub at &lt;a href=&#34;https://github.com/alibaba/tengine&#34;&gt;https://github.com/alibaba/tengine&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To install Tengine, just follow these three steps:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./configure&#xA;$ make&#xA;# make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, it will be installed to &lt;em&gt;/usr/local/nginx&lt;/em&gt;. You can use the &lt;strong&gt;&#39;--prefix&#39;&lt;/strong&gt; option to specify the root directory. If you want to know all the &lt;em&gt;&#39;configure&#39;&lt;/em&gt; options, you should run &lt;strong&gt;&#39;./configure --help&#39;&lt;/strong&gt; for help.&lt;/p&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p&gt;The homepage of Tengine is at &lt;a href=&#34;http://tengine.taobao.org/&#34;&gt;http://tengine.taobao.org/&lt;/a&gt; You can access &lt;a href=&#34;http://tengine.taobao.org/documentation.html&#34;&gt;http://tengine.taobao.org/documentation.html&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h1&gt;Contact&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/alibaba/tengine/issues&#34;&gt;https://github.com/alibaba/tengine/issues&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Dingtalk user group: 23394285&lt;/p&gt;</summary>
  </entry>
</feed>