<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-19T01:53:28Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>NVIDIA/spark-rapids</title>
    <updated>2022-06-19T01:53:28Z</updated>
    <id>tag:github.com,2022-06-19:/NVIDIA/spark-rapids</id>
    <link href="https://github.com/NVIDIA/spark-rapids" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Spark RAPIDS plugin - accelerate Apache Spark with GPUs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RAPIDS Accelerator For Apache Spark&lt;/h1&gt; &#xA;&lt;p&gt;NOTE: For the latest stable &lt;a href=&#34;https://github.com/nvidia/spark-rapids/raw/main/README.md&#34;&gt;README.md&lt;/a&gt; ensure you are on the main branch. The RAPIDS Accelerator for Apache Spark provides a set of plugins for Apache Spark that leverage GPUs to accelerate processing via the RAPIDS libraries and UCX. Documentation on the current release can be found &lt;a href=&#34;https://nvidia.github.io/spark-rapids/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The RAPIDS Accelerator for Apache Spark provides a set of plugins for &lt;a href=&#34;https://spark.apache.org&#34;&gt;Apache Spark&lt;/a&gt; that leverage GPUs to accelerate processing via the &lt;a href=&#34;https://rapids.ai&#34;&gt;RAPIDS&lt;/a&gt; libraries and &lt;a href=&#34;https://www.openucx.org/&#34;&gt;UCX&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To get started and try the plugin out use the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/docs/get-started/getting-started.md&#34;&gt;getting started guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Compatibility&lt;/h2&gt; &#xA;&lt;p&gt;The SQL plugin tries to produce results that are bit for bit identical with Apache Spark. Operator compatibility is documented &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/docs/compatibility.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Tuning&lt;/h2&gt; &#xA;&lt;p&gt;To get started tuning your job and get the most performance out of it please start with the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/docs/tuning-guide.md&#34;&gt;tuning guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;The plugin has a set of Spark configs that control its behavior and are documented &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/docs/configs.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Issues &amp;amp; Questions&lt;/h2&gt; &#xA;&lt;p&gt;We use github to track bugs, feature requests, and answer questions. File an &lt;a href=&#34;https://github.com/NVIDIA/spark-rapids/issues/new/choose&#34;&gt;issue&lt;/a&gt; for a bug or feature request. Ask or answer a question on the &lt;a href=&#34;https://github.com/NVIDIA/spark-rapids/discussions&#34;&gt;discussion board&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;The jar files for the most recent release can be retrieved from the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/docs/download.md&#34;&gt;download&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;h2&gt;Building From Source&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/CONTRIBUTING.md#building-from-source&#34;&gt;build instructions in the contributing guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;p&gt;Tests are described &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/tests/README.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Integration&lt;/h2&gt; &#xA;&lt;p&gt;The RAPIDS Accelerator For Apache Spark does provide some APIs for doing zero copy data transfer into other GPU enabled applications. It is described &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/docs/additional-functionality/ml-integration.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Currently, we are working with XGBoost to try to provide this integration out of the box.&lt;/p&gt; &#xA;&lt;p&gt;You may need to disable RMM caching when exporting data to an ML library as that library will likely want to use all of the GPU&#39;s memory and if it is not aware of RMM it will not have access to any of the memory that RMM is holding.&lt;/p&gt; &#xA;&lt;h2&gt;Qualification and Profiling tools&lt;/h2&gt; &#xA;&lt;p&gt;The Qualification tool is used to look at a set of applications to determine if the RAPIDS Accelerator for Apache Spark might be a good fit for those applications.&lt;/p&gt; &#xA;&lt;p&gt;The Profiling tool generates information which can be used for debugging and profiling applications. Information such as Spark version, executor information, properties and so on. This runs on either CPU or GPU generated event logs.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/docs/spark-qualification-tool.md&#34;&gt;Qualification tool documentation&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-22.08/docs/spark-profiling-tool.md&#34;&gt;Profiling tool documentation&lt;/a&gt; for more details on how to use the tools.&lt;/p&gt; &#xA;&lt;h2&gt;Dependency for External Projects&lt;/h2&gt; &#xA;&lt;p&gt;If you need to develop some functionality on top of RAPIDS Accelerator For Apache Spark (we currently limit support to GPU-accelerated UDFs) we recommend you declare our distribution artifact as a &lt;code&gt;provided&lt;/code&gt; dependency.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;&#xA;    &amp;lt;groupId&amp;gt;com.nvidia&amp;lt;/groupId&amp;gt;&#xA;    &amp;lt;artifactId&amp;gt;rapids-4-spark_2.12&amp;lt;/artifactId&amp;gt;&#xA;    &amp;lt;version&amp;gt;22.08.0-SNAPSHOT&amp;lt;/version&amp;gt;&#xA;    &amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt;&#xA;&amp;lt;/dependency&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>zio/zio-quill</title>
    <updated>2022-06-19T01:53:28Z</updated>
    <id>tag:github.com,2022-06-19:/zio/zio-quill</id>
    <link href="https://github.com/zio/zio-quill" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Compile-time Language Integrated Queries for Scala&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;IMPORTANT: This is the documentation for the latest &lt;code&gt;SNAPSHOT&lt;/code&gt; version. Please refer to the website at &lt;a href=&#34;http://getquill.io&#34;&gt;http://getquill.io&lt;/a&gt; for the latest release&#39;s documentation.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/getquill/quill/master/quill.png&#34; alt=&#34;quill&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Compile-time Language Integrated Query for Scala&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/getquill/quill&#34;&gt;&lt;img src=&#34;https://travis-ci.org/getquill/quill.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/getquill/quill?branch=master&#34;&gt;&lt;img src=&#34;https://codecov.io/github/getquill/quill/coverage.svg?branch=master&#34; alt=&#34;codecov.io&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/getquill/quill?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/gitter-join%20chat-green.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/getquill/quill&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/io.getquill/quill-core_2.13&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/io.getquill/quill-core_2.13/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.javadoc.io/doc/io.getquill/quill-core_2.13&#34;&gt;&lt;img src=&#34;https://www.javadoc.io/badge/io.getquill/quill-core_2.13.svg?sanitize=true&#34; alt=&#34;Javadocs&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;What is Quill?&lt;/h1&gt; &#xA;&lt;p&gt;Quill provides a Quoted Domain Specific Language (&lt;a href=&#34;http://homepages.inf.ed.ac.uk/wadler/papers/qdsl/qdsl.pdf&#34;&gt;QDSL&lt;/a&gt;) to express queries in Scala and execute them in a target language. The library&#39;s core is designed to support multiple target languages, currently featuring specializations for Structured Query Language (&lt;a href=&#34;https://en.wikipedia.org/wiki/SQL&#34;&gt;SQL&lt;/a&gt;) and Cassandra Query Language (&lt;a href=&#34;https://cassandra.apache.org/doc/latest/cql/&#34;&gt;CQL&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;h3&gt;Scala 3 Support&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/zio/zio-protoquill&#34;&gt;ProtoQuill&lt;/a&gt; provides Scala 3 support for Quill rebuilding on top of new metaprogramming capabilities from the ground &amp;gt; up! It is published to maven-central as the &lt;code&gt;quill-&amp;lt;module&amp;gt;_3&lt;/code&gt; line of artifacts.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;h3&gt;Doobie Support&lt;/h3&gt; &#xA; &lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#quill-doobie&#34;&gt;here&lt;/a&gt; for Doobie integration instructions.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/getquill/quill/master/example.gif&#34; alt=&#34;example&#34;&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Boilerplate-free mapping&lt;/strong&gt;: The database schema is mapped using simple case classes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Quoted DSL&lt;/strong&gt;: Queries are defined inside a &lt;code&gt;quote&lt;/code&gt; block. Quill parses each quoted block of code (quotation) at compile time and translates them to an internal Abstract Syntax Tree (AST)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Compile-time query generation&lt;/strong&gt;: The &lt;code&gt;ctx.run&lt;/code&gt; call reads the quotation&#39;s AST and translates it to the target language at compile time, emitting the query string as a compilation message. As the query string is known at compile time, the runtime overhead is very low and similar to using the database driver directly.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Compile-time query validation&lt;/strong&gt;: If configured, the query is verified against the database at compile time and the compilation fails if it is not valid. The query validation &lt;strong&gt;does not&lt;/strong&gt; alter the database state.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: The GIF example uses Eclipse, which shows compilation messages to the user.&lt;/p&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;h3&gt;&lt;a href=&#34;https://scastie.scala-lang.org/&#34;&gt;Scastie&lt;/a&gt; is a great tool to try out Quill without having to prepare a local environment. It works with &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#mirror-context&#34;&gt;mirror contexts&lt;/a&gt;, see &lt;a href=&#34;https://scastie.scala-lang.org/QwOewNEiR3mFlKIM7v900A&#34;&gt;this&lt;/a&gt; snippet as an example.&lt;/h3&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Quill has integrations with many libraries. If you are using a regular RDBMS e.g. PostgreSQL and want to use Quill to query it with an asychronous, non-blocking, reactive application, the easiest way to get started is by using an awesome library called ZIO.&lt;/p&gt; &#xA;&lt;p&gt;A simple ZIO + Quill application looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Person(name: String, age: Int)&#xA;&#xA;object QuillContext extends PostgresZioJdbcContext(SnakeCase)&#xA;&#xA;object DataService {&#xA;  import QuillContext._&#xA;  def getPeople = run(query[Person])&#xA;}&#xA;&#xA;object Main extends App {&#xA;  override def run(args: List[String]) =&#xA;    DataService.getPeople&#xA;      .inject(DataSourceLayer.fromPrefix(&#34;myDatabaseConfig&#34;).orDie)&#xA;      .debug(&#34;Results&#34;)&#xA;      .exitCode&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add the following to build.sbt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34;          %% &#34;quill-jdbc-zio&#34; % &#34;3.12.0&#34;,&#xA;  &#34;io.github.kitlangton&#34; %% &#34;zio-magic&#34;      % &#34;0.3.11&#34;,&#xA;  &#34;org.postgresql&#34;       %  &#34;postgresql&#34;     % &#34;42.3.1&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find this code (with some more examples) complete with a docker-provided Postgres database &lt;a href=&#34;https://github.com/deusaquilus/zio-quill-gettingstarted&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Choosing a Module&lt;/h2&gt; &#xA;&lt;p&gt;Choose the quill module that works for you!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you are starting from scratch with a regular RDBMS try using the &lt;code&gt;quill-jdbc-zio&lt;/code&gt; module as shown above.&lt;/li&gt; &#xA; &lt;li&gt;If you are developing a legacy Java project and don&#39;t want/need reactive, use &lt;code&gt;quill-jdbc&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you are developing a project with Cats and/or Monix, try &lt;code&gt;quill-jdbc-monix&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you like to &#34;live dangerously&#34; and want to try a socket-level async library, try &lt;code&gt;quill-jasync-postgres&lt;/code&gt; or &lt;code&gt;quill-jasync-mysql&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you are using Cassandra, Spark, or OrientDB, try the corresponding modules for each of them.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Writing Queries&lt;/h1&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;The QDSL allows the user to write plain Scala code, leveraging Scala&#39;s syntax and type system. Quotations are created using the &lt;code&gt;quote&lt;/code&gt; method and can contain any excerpt of code that uses supported operations. To create quotations, first create a context instance. Please see the &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#contexts&#34;&gt;context&lt;/a&gt; section for more details on the different context available.&lt;/p&gt; &#xA;&lt;p&gt;For this documentation, a special type of context that acts as a &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#mirror-context&#34;&gt;mirror&lt;/a&gt; is used:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import io.getquill._&#xA;&#xA;val ctx = new SqlMirrorContext(MirrorSqlDialect, Literal)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The context instance provides all the types, methods, and encoders/decoders needed for quotations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import ctx._&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A quotation can be a simple value:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val pi = quote(3.14159)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And be used within another quotation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Circle(radius: Float)&#xA;&#xA;val areas = quote {&#xA;  query[Circle].map(c =&amp;gt; pi * c.radius * c.radius)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Quotations can also contain high-order functions and inline values:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val area = quote {&#xA;  (c: Circle) =&amp;gt; {&#xA;    val r2 = c.radius * c.radius&#xA;    pi * r2&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val areas = quote {&#xA;  query[Circle].map(c =&amp;gt; area(c))&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Quill&#39;s normalization engine applies reduction steps before translating the quotation to the target language. The correspondent normalized quotation for both versions of the &lt;code&gt;areas&lt;/code&gt; query is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val areas = quote {&#xA;  query[Circle].map(c =&amp;gt; 3.14159 * c.radius * c.radius)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Scala doesn&#39;t have support for high-order functions with type parameters. It&#39;s possible to use a method type parameter for this purpose:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def existsAny[T] = quote {&#xA;  (xs: Query[T]) =&amp;gt; (p: T =&amp;gt; Boolean) =&amp;gt;&#xA;    &#x9;xs.filter(p(_)).nonEmpty&#xA;}&#xA;&#xA;val q = quote {&#xA;  query[Circle].filter { c1 =&amp;gt;&#xA;    existsAny(query[Circle])(c2 =&amp;gt; c2.radius &amp;gt; c1.radius)&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use implicit classes to extend things in quotations.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit class Ext(q: Query[Person]) {&#xA;  def olderThan(age: Int) = quote {&#xA;    query[Person].filter(p =&amp;gt; p.age &amp;gt; lift(age))&#xA;  }&#xA;}&#xA;&#xA;run(query[Person].olderThan(44))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(see &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#implicit-extensions&#34;&gt;implicit-extensions&lt;/a&gt; for additional information.)&lt;/p&gt; &#xA;&lt;h2&gt;Compile-time quotations&lt;/h2&gt; &#xA;&lt;p&gt;Quotations are both compile-time and runtime values. Quill uses a type refinement to store the quotation&#39;s AST as an annotation available at compile-time and the &lt;code&gt;q.ast&lt;/code&gt; method exposes the AST as runtime value.&lt;/p&gt; &#xA;&lt;p&gt;It is important to avoid giving explicit types to quotations when possible. For instance, this quotation can&#39;t be read at compile-time as the type refinement is lost:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Avoid type widening (Quoted[Query[Circle]]), or else the quotation will be dynamic.&#xA;val q: Quoted[Query[Circle]] = quote {&#xA;  query[Circle].filter(c =&amp;gt; c.radius &amp;gt; 10)&#xA;}&#xA;&#xA;ctx.run(q) // Dynamic query&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Quill falls back to runtime normalization and query generation if the quotation&#39;s AST can&#39;t be read at compile-time. Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#dynamic-queries&#34;&gt;dynamic queries&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h4&gt;Inline queries&lt;/h4&gt; &#xA;&lt;p&gt;Quoting is implicit when writing a query in a &lt;code&gt;run&lt;/code&gt; statement.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;ctx.run(query[Circle].map(_.radius))&#xA;// SELECT r.radius FROM Circle r&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Bindings&lt;/h2&gt; &#xA;&lt;p&gt;Quotations are designed to be self-contained, without references to runtime values outside their scope. There are two mechanisms to explicitly bind runtime values to a quotation execution.&lt;/p&gt; &#xA;&lt;h3&gt;Lifted values&lt;/h3&gt; &#xA;&lt;p&gt;A runtime value can be lifted to a quotation through the method &lt;code&gt;lift&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def biggerThan(i: Float) = quote {&#xA;  query[Circle].filter(r =&amp;gt; r.radius &amp;gt; lift(i))&#xA;}&#xA;ctx.run(biggerThan(10)) // SELECT r.radius FROM Circle r WHERE r.radius &amp;gt; ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that literal-constants do not need to be lifted, they can be used in queries directly. Literal constants are supported starting Scala 2.12.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;final val minAge = 21  // This is the same as: final val minAge: 21 = 21&#xA;ctx.run(query[Person].filter(p =&amp;gt; p.age &amp;gt; minAge)) // SELECT p.name, p.age FROM Person p WHERE p.name &amp;gt; 21&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Lifted queries&lt;/h3&gt; &#xA;&lt;p&gt;A &lt;code&gt;Iterable&lt;/code&gt; instance can be lifted as a &lt;code&gt;Query&lt;/code&gt;. There are two main usages for lifted queries:&lt;/p&gt; &#xA;&lt;h4&gt;contains&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def find(radiusList: List[Float]) = quote {&#xA;  query[Circle].filter(r =&amp;gt; liftQuery(radiusList).contains(r.radius))&#xA;}&#xA;ctx.run(find(List(1.1F, 1.2F)))&#xA;// SELECT r.radius FROM Circle r WHERE r.radius IN (?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;batch action&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def insertValues(circles: List[Circle]) = quote {&#xA;  liftQuery(circles).foreach(c =&amp;gt; query[Circle].insertValue(c))&#xA;}&#xA;ctx.run(insertValues(List(Circle(1.1F), Circle(1.2F))))&#xA;// INSERT INTO Circle (radius) VALUES (?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Schema&lt;/h2&gt; &#xA;&lt;p&gt;The database schema is represented by case classes. By default, quill uses the class and field names as the database identifiers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Circle(radius: Float)&#xA;&#xA;val q = quote {&#xA;  query[Circle].filter(c =&amp;gt; c.radius &amp;gt; 1)&#xA;}&#xA;&#xA;ctx.run(q) // SELECT c.radius FROM Circle c WHERE c.radius &amp;gt; 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Schema customization&lt;/h3&gt; &#xA;&lt;p&gt;Alternatively, the identifiers can be customized:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val circles = quote {&#xA;  querySchema[Circle](&#34;circle_table&#34;, _.radius -&amp;gt; &#34;radius_column&#34;)&#xA;}&#xA;&#xA;val q = quote {&#xA;  circles.filter(c =&amp;gt; c.radius &amp;gt; 1)&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT c.radius_column FROM circle_table c WHERE c.radius_column &amp;gt; 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If multiple tables require custom identifiers, it is good practice to define a &lt;code&gt;schema&lt;/code&gt; object with all table queries to be reused across multiple queries:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Circle(radius: Int)&#xA;case class Rectangle(length: Int, width: Int)&#xA;object schema {&#xA;  val circles = quote {&#xA;    querySchema[Circle](&#xA;        &#34;circle_table&#34;,&#xA;        _.radius -&amp;gt; &#34;radius_column&#34;)&#xA;  }&#xA;  val rectangles = quote {&#xA;    querySchema[Rectangle](&#xA;        &#34;rectangle_table&#34;,&#xA;        _.length -&amp;gt; &#34;length_column&#34;,&#xA;        _.width -&amp;gt; &#34;width_column&#34;)&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Database-generated values&lt;/h3&gt; &#xA;&lt;h4&gt;returningGenerated&lt;/h4&gt; &#xA;&lt;p&gt;Database generated values can be returned from an insert query by using &lt;code&gt;.returningGenerated&lt;/code&gt;. These properties will also be excluded from the insertion since they are database generated.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Product(id: Int, description: String, sku: Long)&#xA;&#xA;val q = quote {&#xA;  query[Product].insertValue(lift(Product(0, &#34;My Product&#34;, 1011L))).returningGenerated(_.id)&#xA;}&#xA;&#xA;val returnedIds = ctx.run(q) //: List[Int]&#xA;// INSERT INTO Product (description,sku) VALUES (?, ?) -- NOTE that &#39;id&#39; is not being inserted.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Multiple properties can be returned in a Tuple or Case Class and all of them will be excluded from insertion.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;NOTE: Using multiple properties is currently supported by Postgres, Oracle and SQL Server&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Assuming sku is generated by the database.&#xA;val q = quote {&#xA;  query[Product].insertValue(lift(Product(0, &#34;My Product&#34;, 1011L))).returningGenerated(r =&amp;gt; (id, sku))&#xA;}&#xA;&#xA;val returnedIds = ctx.run(q) //: List[(Int, Long)]&#xA;// INSERT INTO Product (description) VALUES (?) RETURNING id, sku -- NOTE that &#39;id&#39; and &#39;sku&#39; are not being inserted.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;returning&lt;/h4&gt; &#xA;&lt;p&gt;In certain situations, we might want to return fields that are not auto generated as well. In this case we do not want the fields to be automatically excluded from the insertion. The &lt;code&gt;returning&lt;/code&gt; method is used for that.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].insertValue(lift(Product(0, &#34;My Product&#34;, 1011L))).returning(r =&amp;gt; (id, description))&#xA;}&#xA;&#xA;val returnedIds = ctx.run(q) //: List[(Int, String)]&#xA;// INSERT INTO Product (id, description, sku) VALUES (?, ?, ?) RETURNING id, description&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Wait a second! Why did we just insert &lt;code&gt;id&lt;/code&gt; into the database? That is because &lt;code&gt;returning&lt;/code&gt; does not exclude values from the insertion! We can fix this situation by manually specifying the columns to insert:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].insert(_.description -&amp;gt; &#34;My Product&#34;, _.sku -&amp;gt; 1011L))).returning(r =&amp;gt; (id, description))&#xA;}&#xA;&#xA;val returnedIds = ctx.run(q) //: List[(Int, String)]&#xA;// INSERT INTO Product (description, sku) VALUES (?, ?) RETURNING id, description&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can also fix this situation by using an insert-meta.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit val productInsertMeta = insertMeta[Product](_.id)&#xA;val q = quote {&#xA;  query[Product].insertValue(lift(Product(0L, &#34;My Product&#34;, 1011L))).returning(r =&amp;gt; (id, description))&#xA;}&#xA;&#xA;val returnedIds = ctx.run(q) //: List[(Int, String)]&#xA;// INSERT INTO Product (description, sku) VALUES (?, ?) RETURNING id, description&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;returning&lt;/code&gt; can also be used after &lt;code&gt;updateValue&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].updateValue(lift(Product(42, &#34;Updated Product&#34;, 2022L))).returning(r =&amp;gt; (r.id, r.description))&#xA;}&#xA;&#xA;val updated = ctx.run(q) //: List[(Int, String)]&#xA;// UPDATE Product SET id = ?, description = ?, sku = ? RETURNING id, description&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or even after &lt;code&gt;delete&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].delete.returning(r =&amp;gt; (r.id, r.description))&#xA;}&#xA;&#xA;val deleted = ctx.run(q) //: List[(Int, String)]&#xA;// DELETE FROM Product RETURNING id, description&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;customized returning&lt;/h4&gt; &#xA;&lt;p&gt;Values returned can be further customized in some databases.&lt;/p&gt; &#xA;&lt;h5&gt;Postgres&lt;/h5&gt; &#xA;&lt;p&gt;The &lt;code&gt;returning&lt;/code&gt; and &lt;code&gt;returningGenerated&lt;/code&gt; methods also support arithmetic operations, SQL UDFs and even entire queries. These are inserted directly into the SQL &lt;code&gt;RETURNING&lt;/code&gt; clause.&lt;/p&gt; &#xA;&lt;p&gt;Assuming this basic query:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].insert(_.description -&amp;gt; &#34;My Product&#34;, _.sku -&amp;gt; 1011L)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add 100 to the value of &lt;code&gt;id&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;ctx.run(q.returning(r =&amp;gt; r.id + 100)) //: List[Int]&#xA;// INSERT INTO Product (description, sku) VALUES (?, ?) RETURNING id + 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Pass the value of &lt;code&gt;id&lt;/code&gt; into a UDF:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val udf = quote { (i: Long) =&amp;gt; infix&#34;myUdf($i)&#34;.as[Int] }&#xA;ctx.run(q.returning(r =&amp;gt; udf(r.id))) //: List[Int]&#xA;// INSERT INTO Product (description, sku) VALUES (?, ?) RETURNING myUdf(id)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use the return value of &lt;code&gt;sku&lt;/code&gt; to issue a query:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Supplier(id: Int, clientSku: Long)&#xA;ctx.run {&#xA;  q.returning(r =&amp;gt; query[Supplier].filter(s =&amp;gt; s.sku == r.sku).map(_.id).max)&#xA;} //: List[Option[Long]]&#xA;// INSERT INTO Product (description,sku) VALUES (&#39;My Product&#39;, 1011) RETURNING (SELECT MAX(s.id) FROM Supplier s WHERE s.sku = clientSku)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As is typically the case with Quill, you can use all of these features together.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;ctx.run {&#xA;  q.returning(r =&amp;gt;&#xA;    (r.id + 100, udf(r.id), query[Supplier].filter(s =&amp;gt; s.sku == r.sku).map(_.id).max)&#xA;  )&#xA;} // List[(Int, Int, Option[Long])]&#xA;// INSERT INTO Product (description,sku) VALUES (&#39;My Product&#39;, 1011)&#xA;// RETURNING id + 100, myUdf(id), (SELECT MAX(s.id) FROM Supplier s WHERE s.sku = sku)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;NOTE: Queries used inside of return clauses can only return a single row per insert. Otherwise, Postgres will throw: &lt;code&gt;ERROR: more than one row returned by a subquery used as an expression&lt;/code&gt;. This is why is it strongly recommended that you use aggregators such as &lt;code&gt;max&lt;/code&gt; or &lt;code&gt;min&lt;/code&gt;inside of quill returning-clause queries. In the case that this is impossible (e.g. when using Postgres booleans), you can use the &lt;code&gt;.value&lt;/code&gt; method: &lt;code&gt;q.returning(r =&amp;gt; query[Supplier].filter(s =&amp;gt; s.sku == r.sku).map(_.id).value)&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h5&gt;SQL Server&lt;/h5&gt; &#xA;&lt;p&gt;The &lt;code&gt;returning&lt;/code&gt; and &lt;code&gt;returningGenerated&lt;/code&gt; methods are more restricted when using SQL Server; they only support arithmetic operations. These are inserted directly into the SQL &lt;code&gt;OUTPUT INSERTED.*&lt;/code&gt; or &lt;code&gt;OUTPUT DELETED.*&lt;/code&gt; clauses.&lt;/p&gt; &#xA;&lt;p&gt;Assuming the query:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].insert(_.description -&amp;gt; &#34;My Product&#34;, _.sku -&amp;gt; 1011L)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add 100 to the value of &lt;code&gt;id&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;ctx.run(q.returning(r =&amp;gt; id + 100)) //: List[Int]&#xA;// INSERT INTO Product (description, sku) OUTPUT INSERTED.id + 100 VALUES (?, ?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Update returning:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].update(_.description -&amp;gt; &#34;Updated Product&#34;, _.sku -&amp;gt; 2022L).returning(r =&amp;gt; (r.id, r.description))&#xA;}&#xA;&#xA;val updated = ctx.run(q)&#xA;// UPDATE Product SET description = &#39;Updated Product&#39;, sku = 2022 OUTPUT INSERTED.id, INSERTED.description&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Delete returning:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].delete.returning(r =&amp;gt; (r.id, r.description))&#xA;}&#xA;&#xA;val updated = ctx.run(q)&#xA;// DELETE FROM Product OUTPUT DELETED.id, DELETED.description&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Embedded case classes&lt;/h3&gt; &#xA;&lt;p&gt;Quill supports nested &lt;code&gt;Embedded&lt;/code&gt; case classes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Contact(phone: String, address: String) extends Embedded&#xA;case class Person(id: Int, name: String, contact: Contact)&#xA;&#xA;ctx.run(query[Person])&#xA;// SELECT x.id, x.name, x.phone, x.address FROM Person x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that default naming behavior uses the name of the nested case class properties. It&#39;s possible to override this default behavior using a custom &lt;code&gt;schema&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Contact(phone: String, address: String) extends Embedded&#xA;case class Person(id: Int, name: String, homeContact: Contact, workContact: Option[Contact])&#xA;&#xA;val q = quote {&#xA;  querySchema[Person](&#xA;    &#34;Person&#34;,&#xA;    _.homeContact.phone          -&amp;gt; &#34;homePhone&#34;,&#xA;    _.homeContact.address        -&amp;gt; &#34;homeAddress&#34;,&#xA;    _.workContact.map(_.phone)   -&amp;gt; &#34;workPhone&#34;,&#xA;    _.workContact.map(_.address) -&amp;gt; &#34;workAddress&#34;&#xA;  )&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT x.id, x.name, x.homePhone, x.homeAddress, x.workPhone, x.workAddress FROM Person x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Queries&lt;/h2&gt; &#xA;&lt;p&gt;The overall abstraction of quill queries uses database tables as if they were in-memory collections. Scala for-comprehensions provide syntactic sugar to deal with these kinds of monadic operations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Person(id: Int, name: String, age: Int)&#xA;case class Contact(personId: Int, phone: String)&#xA;&#xA;val q = quote {&#xA;  for {&#xA;    p &amp;lt;- query[Person] if(p.id == 999)&#xA;    c &amp;lt;- query[Contact] if(c.personId == p.id)&#xA;  } yield {&#xA;    (p.name, c.phone)&#xA;  }&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.name, c.phone FROM Person p, Contact c WHERE (p.id = 999) AND (c.personId = p.id)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Quill normalizes the quotation and translates the monadic joins to applicative joins, generating a database-friendly query that avoids nested queries.&lt;/p&gt; &#xA;&lt;p&gt;Any of the following features can be used together with the others and/or within a for-comprehension:&lt;/p&gt; &#xA;&lt;h3&gt;filter&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.age &amp;gt; 18)&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.id, p.name, p.age FROM Person p WHERE p.age &amp;gt; 18&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;map&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].map(p =&amp;gt; p.name)&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.name FROM Person p&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;flatMap&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.age &amp;gt; 18).flatMap(p =&amp;gt; query[Contact].filter(c =&amp;gt; c.personId == p.id))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT c.personId, c.phone FROM Person p, Contact c WHERE (p.age &amp;gt; 18) AND (c.personId = p.id)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;concatMap&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// similar to `flatMap` but for transformations that return a traversable instead of `Query`&#xA;&#xA;val q = quote {&#xA;  query[Person].concatMap(p =&amp;gt; p.name.split(&#34; &#34;))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT UNNEST(SPLIT(p.name, &#34; &#34;)) FROM Person p&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;sortBy&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q1 = quote {&#xA;  query[Person].sortBy(p =&amp;gt; p.age)&#xA;}&#xA;&#xA;ctx.run(q1)&#xA;// SELECT p.id, p.name, p.age FROM Person p ORDER BY p.age ASC NULLS FIRST&#xA;&#xA;val q2 = quote {&#xA;  query[Person].sortBy(p =&amp;gt; p.age)(Ord.descNullsLast)&#xA;}&#xA;&#xA;ctx.run(q2)&#xA;// SELECT p.id, p.name, p.age FROM Person p ORDER BY p.age DESC NULLS LAST&#xA;&#xA;val q3 = quote {&#xA;  query[Person].sortBy(p =&amp;gt; (p.name, p.age))(Ord(Ord.asc, Ord.desc))&#xA;}&#xA;&#xA;ctx.run(q3)&#xA;// SELECT p.id, p.name, p.age FROM Person p ORDER BY p.name ASC, p.age DESC&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;drop/take&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].drop(2).take(1)&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT x.id, x.name, x.age FROM Person x LIMIT 1 OFFSET 2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;groupBy&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].groupBy(p =&amp;gt; p.age).map {&#xA;    case (age, people) =&amp;gt;&#xA;      (age, people.size)&#xA;  }&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.age, COUNT(*) FROM Person p GROUP BY p.age&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;union&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.age &amp;gt; 18).union(query[Person].filter(p =&amp;gt; p.age &amp;gt; 60))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT x.id, x.name, x.age FROM (SELECT id, name, age FROM Person p WHERE p.age &amp;gt; 18&#xA;// UNION SELECT id, name, age FROM Person p1 WHERE p1.age &amp;gt; 60) x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;unionAll/++&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.age &amp;gt; 18).unionAll(query[Person].filter(p =&amp;gt; p.age &amp;gt; 60))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT x.id, x.name, x.age FROM (SELECT id, name, age FROM Person p WHERE p.age &amp;gt; 18&#xA;// UNION ALL SELECT id, name, age FROM Person p1 WHERE p1.age &amp;gt; 60) x&#xA;&#xA;val q2 = quote {&#xA;  query[Person].filter(p =&amp;gt; p.age &amp;gt; 18) ++ query[Person].filter(p =&amp;gt; p.age &amp;gt; 60)&#xA;}&#xA;&#xA;ctx.run(q2)&#xA;// SELECT x.id, x.name, x.age FROM (SELECT id, name, age FROM Person p WHERE p.age &amp;gt; 18&#xA;// UNION ALL SELECT id, name, age FROM Person p1 WHERE p1.age &amp;gt; 60) x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;aggregation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val r = quote {&#xA;  query[Person].map(p =&amp;gt; p.age)&#xA;}&#xA;&#xA;ctx.run(r.min) // SELECT MIN(p.age) FROM Person p&#xA;ctx.run(r.max) // SELECT MAX(p.age) FROM Person p&#xA;ctx.run(r.avg) // SELECT AVG(p.age) FROM Person p&#xA;ctx.run(r.sum) // SELECT SUM(p.age) FROM Person p&#xA;ctx.run(r.size) // SELECT COUNT(p.age) FROM Person p&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;isEmpty/nonEmpty&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter{ p1 =&amp;gt;&#xA;    query[Person].filter(p2 =&amp;gt; p2.id != p1.id &amp;amp;&amp;amp; p2.age == p1.age).isEmpty&#xA;  }&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p1.id, p1.name, p1.age FROM Person p1 WHERE&#xA;// NOT EXISTS (SELECT * FROM Person p2 WHERE (p2.id &amp;lt;&amp;gt; p1.id) AND (p2.age = p1.age))&#xA;&#xA;val q2 = quote {&#xA;  query[Person].filter{ p1 =&amp;gt;&#xA;    query[Person].filter(p2 =&amp;gt; p2.id != p1.id &amp;amp;&amp;amp; p2.age == p1.age).nonEmpty&#xA;  }&#xA;}&#xA;&#xA;ctx.run(q2)&#xA;// SELECT p1.id, p1.name, p1.age FROM Person p1 WHERE&#xA;// EXISTS (SELECT * FROM Person p2 WHERE (p2.id &amp;lt;&amp;gt; p1.id) AND (p2.age = p1.age))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;contains&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; liftQuery(Set(1, 2)).contains(p.id))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.id, p.name, p.age FROM Person p WHERE p.id IN (?, ?)&#xA;&#xA;val q1 = quote { (ids: Query[Int]) =&amp;gt;&#xA;  query[Person].filter(p =&amp;gt; ids.contains(p.id))&#xA;}&#xA;&#xA;ctx.run(q1(liftQuery(List(1, 2))))&#xA;// SELECT p.id, p.name, p.age FROM Person p WHERE p.id IN (?, ?)&#xA;&#xA;val peopleWithContacts = quote {&#xA;  query[Person].filter(p =&amp;gt; query[Contact].filter(c =&amp;gt; c.personId == p.id).nonEmpty)&#xA;}&#xA;val q2 = quote {&#xA;  query[Person].filter(p =&amp;gt; peopleWithContacts.contains(p.id))&#xA;}&#xA;&#xA;ctx.run(q2)&#xA;// SELECT p.id, p.name, p.age FROM Person p WHERE p.id IN (SELECT p1.* FROM Person p1 WHERE EXISTS (SELECT c.* FROM Contact c WHERE c.personId = p1.id))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;distinct&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].map(p =&amp;gt; p.age).distinct&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT DISTINCT p.age FROM Person p&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;distinct on&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note that &lt;code&gt;DISTINCT ON&lt;/code&gt; is currently only supported in Postgres and H2.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].distinctOn(p =&amp;gt; p.name)&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT DISTINCT ON (p.name) p.name, p.age FROM Person&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Typically, &lt;code&gt;DISTINCT ON&lt;/code&gt; is used with &lt;code&gt;SORT BY&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].distinctOn(p =&amp;gt; p.name).sortBy(p =&amp;gt; p.age)&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT DISTINCT ON (p.name) p.name, p.age FROM Person ORDER BY p.age ASC NULLS FIRST&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use multiple fields in the &lt;code&gt;DISTINCT ON&lt;/code&gt; criteria:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// case class Person(firstName: String, lastName: String, age: Int)&#xA;val q = quote {&#xA;  query[Person].distinctOn(p =&amp;gt; (p.firstName, p.lastName))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT DISTINCT ON (p.firstName, p.lastName) p.firstName, p.lastName, p.age FROM Person p&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;nested&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.name == &#34;John&#34;).nested.map(p =&amp;gt; p.age)&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.age FROM (SELECT p.age FROM Person p WHERE p.name = &#39;John&#39;) p&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;joins&lt;/h3&gt; &#xA;&lt;p&gt;Joins are arguably the largest source of complexity in most SQL queries. Quill offers a few different syntaxes so you can choose the right one for your use-case!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class A(id: Int)&#xA;case class B(fk: Int)&#xA;&#xA;// Applicative Joins:&#xA;quote {&#xA;  query[A].join(query[B]).on(_.id == _.fk)&#xA;}&#xA;&#xA;// Implicit Joins:&#xA;quote {&#xA;  for {&#xA;    a &amp;lt;- query[A]&#xA;    b &amp;lt;- query[B] if (a.id == b.fk)&#xA;  } yield (a, b)&#xA;}&#xA;&#xA;// Flat Joins:&#xA;quote {&#xA;  for {&#xA;    a &amp;lt;- query[A]&#xA;    b &amp;lt;- query[B].join(_.fk == a.id)&#xA;  } yield (a, b)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Let&#39;s see them one by one assuming the following schema:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Person(id: Int, name: String)&#xA;case class Address(street: String, zip: Int, fk: Int)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(Note: If your use case involves lots and lots of joins, both inner and outer. Skip right to the flat-joins section!)&lt;/p&gt; &#xA;&lt;h4&gt;applicative joins&lt;/h4&gt; &#xA;&lt;p&gt;Applicative joins are useful for joining two tables together, they are straightforward to understand, and typically look good on one line. Quill supports inner, left-outer, right-outer, and full-outer (i.e. cross) applicative joins.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Inner Join&#xA;val q = quote {&#xA;  query[Person].join(query[Address]).on(_.id == _.fk)&#xA;}&#xA;&#xA;ctx.run(q) //: List[(Person, Address)]&#xA;// SELECT x1.id, x1.name, x2.street, x2.zip, x2.fk&#xA;// FROM Person x1 INNER JOIN Address x2 ON x1.id = x2.fk&#xA;&#xA;// Left (Outer) Join&#xA;val q = quote {&#xA;  query[Person].leftJoin(query[Address]).on((p, a) =&amp;gt; p.id == a.fk)&#xA;}&#xA;&#xA;ctx.run(q) //: List[(Person, Option[Address])]&#xA;// Note that when you use named-variables in your comprehension, Quill does its best to honor them in the query.&#xA;// SELECT p.id, p.name, a.street, a.zip, a.fk&#xA;// FROM Person p LEFT JOIN Address a ON p.id = a.fk&#xA;&#xA;// Right (Outer) Join&#xA;val q = quote {&#xA;  query[Person].rightJoin(query[Address]).on((p, a) =&amp;gt; p.id == a.fk)&#xA;}&#xA;&#xA;ctx.run(q) //: List[(Option[Person], Address)]&#xA;// SELECT p.id, p.name, a.street, a.zip, a.fk&#xA;// FROM Person p RIGHT JOIN Address a ON p.id = a.fk&#xA;&#xA;// Full (Outer) Join&#xA;val q = quote {&#xA;  query[Person].fullJoin(query[Address]).on((p, a) =&amp;gt; p.id == a.fk)&#xA;}&#xA;&#xA;ctx.run(q) //: List[(Option[Person], Option[Address])]&#xA;// SELECT p.id, p.name, a.street, a.zip, a.fk&#xA;// FROM Person p FULL JOIN Address a ON p.id = a.fk&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;What about joining more than two tables with the applicative syntax? Here&#39;s how to do that:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Company(zip: Int)&#xA;&#xA;// All is well for two tables but for three or more, the nesting mess begins:&#xA;val q = quote {&#xA;  query[Person]&#xA;    .join(query[Address]).on({case (p, a) =&amp;gt; p.id == a.fk}) // Let&#39;s use `case` here to stay consistent&#xA;    .join(query[Company]).on({case ((p, a), c) =&amp;gt; a.zip == c.zip})&#xA;}&#xA;&#xA;ctx.run(q) //: List[((Person, Address), Company)]&#xA;// (Unfortunately when you use `case` statements, Quill can&#39;t help you with the variables names either!)&#xA;// SELECT x01.id, x01.name, x11.street, x11.zip, x11.fk, x12.name, x12.zip&#xA;// FROM Person x01 INNER JOIN Address x11 ON x01.id = x11.fk INNER JOIN Company x12 ON x11.zip = x12.zip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;No worries though, implicit joins and flat joins have your other use-cases covered!&lt;/p&gt; &#xA;&lt;h4&gt;implicit joins&lt;/h4&gt; &#xA;&lt;p&gt;Quill&#39;s implicit joins use a monadic syntax making them pleasant to use for joining many tables together. They look a lot like Scala collections when used in for-comprehensions making them familiar to a typical Scala developer. What&#39;s the catch? They can only do inner-joins.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  for {&#xA;    p &amp;lt;- query[Person]&#xA;    a &amp;lt;- query[Address] if (p.id == a.fk)&#xA;  } yield (p, a)&#xA;}&#xA;&#xA;run(q) //: List[(Person, Address)]&#xA;// SELECT p.id, p.name, a.street, a.zip, a.fk&#xA;// FROM Person p, Address a WHERE p.id = a.fk&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now, this is great because you can keep adding more and more joins without having to do any pesky nesting.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  for {&#xA;    p &amp;lt;- query[Person]&#xA;    a &amp;lt;- query[Address] if (p.id == a.fk)&#xA;    c &amp;lt;- query[Company] if (c.zip == a.zip)&#xA;  } yield (p, a, c)&#xA;}&#xA;&#xA;run(q) //: List[(Person, Address, Company)]&#xA;// SELECT p.id, p.name, a.street, a.zip, a.fk, c.name, c.zip&#xA;// FROM Person p, Address a, Company c WHERE p.id = a.fk AND c.zip = a.zip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Well that looks nice but wait! What If I need to inner, &lt;strong&gt;and&lt;/strong&gt; outer join lots of tables nicely? No worries, flat-joins are here to help!&lt;/p&gt; &#xA;&lt;h3&gt;flat joins&lt;/h3&gt; &#xA;&lt;p&gt;Flat Joins give you the best of both worlds! In the monadic syntax, you can use both inner joins, and left-outer joins together without any of that pesky nesting.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Inner Join&#xA;val q = quote {&#xA;  for {&#xA;    p &amp;lt;- query[Person]&#xA;    a &amp;lt;- query[Address].join(a =&amp;gt; a.fk == p.id)&#xA;  } yield (p,a)&#xA;}&#xA;&#xA;ctx.run(q) //: List[(Person, Address)]&#xA;// SELECT p.id, p.name, a.street, a.zip, a.fk&#xA;// FROM Person p INNER JOIN Address a ON a.fk = p.id&#xA;&#xA;// Left (Outer) Join&#xA;val q = quote {&#xA;  for {&#xA;    p &amp;lt;- query[Person]&#xA;    a &amp;lt;- query[Address].leftJoin(a =&amp;gt; a.fk == p.id)&#xA;  } yield (p,a)&#xA;}&#xA;&#xA;ctx.run(q) //: List[(Person, Option[Address])]&#xA;// SELECT p.id, p.name, a.street, a.zip, a.fk&#xA;// FROM Person p LEFT JOIN Address a ON a.fk = p.id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you can keep adding both right and left joins without nesting!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  for {&#xA;    p &amp;lt;- query[Person]&#xA;    a &amp;lt;- query[Address].join(a =&amp;gt; a.fk == p.id)&#xA;    c &amp;lt;- query[Company].leftJoin(c =&amp;gt; c.zip == a.zip)&#xA;  } yield (p,a,c)&#xA;}&#xA;&#xA;ctx.run(q) //: List[(Person, Address, Option[Company])]&#xA;// SELECT p.id, p.name, a.street, a.zip, a.fk, c.name, c.zip&#xA;// FROM Person p&#xA;// INNER JOIN Address a ON a.fk = p.id&#xA;// LEFT JOIN Company c ON c.zip = a.zip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Can&#39;t figure out what kind of join you want to use? Who says you have to choose?&lt;/p&gt; &#xA;&lt;p&gt;With Quill the following multi-join queries are equivalent, use them according to preference:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;&#xA;case class Employer(id: Int, personId: Int, name: String)&#xA;&#xA;val qFlat = quote {&#xA;  for{&#xA;    (p,e) &amp;lt;- query[Person].join(query[Employer]).on(_.id == _.personId)&#xA;       c  &amp;lt;- query[Contact].leftJoin(_.personId == p.id)&#xA;  } yield(p, e, c)&#xA;}&#xA;&#xA;val qNested = quote {&#xA;  for{&#xA;    ((p,e),c) &amp;lt;-&#xA;      query[Person].join(query[Employer]).on(_.id == _.personId)&#xA;      .leftJoin(query[Contact]).on(&#xA;        _._1.id == _.personId&#xA;      )&#xA;  } yield(p, e, c)&#xA;}&#xA;&#xA;ctx.run(qFlat)&#xA;ctx.run(qNested)&#xA;// SELECT p.id, p.name, p.age, e.id, e.personId, e.name, c.id, c.phone&#xA;// FROM Person p INNER JOIN Employer e ON p.id = e.personId LEFT JOIN Contact c ON c.personId = p.id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that in some cases implicit and flat joins cannot be used together, for example, the following query will fail.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  for {&#xA;    p &amp;lt;- query[Person]&#xA;    p1 &amp;lt;- query[Person] if (p1.name == p.name)&#xA;    c &amp;lt;- query[Contact].leftJoin(_.personId == p.id)&#xA;  } yield (p, c)&#xA;}&#xA;&#xA;// ctx.run(q)&#xA;// java.lang.IllegalArgumentException: requirement failed: Found an `ON` table reference of a table that is&#xA;// not available: Set(p). The `ON` condition can only use tables defined through explicit joins.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This happens because an explicit join typically cannot be done after an implicit join in the same query.&lt;/p&gt; &#xA;&lt;p&gt;A good guideline is in any query or subquery, choose one of the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use flat-joins + applicative joins or&lt;/li&gt; &#xA; &lt;li&gt;Use implicit joins&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Also, note that not all Option operations are available on outer-joined tables (i.e. tables wrapped in an &lt;code&gt;Option&lt;/code&gt; object), only a specific subset. This is mostly due to the inherent limitations of SQL itself. For more information, see the &#39;Optional Tables&#39; section.&lt;/p&gt; &#xA;&lt;h3&gt;Optionals / Nullable Fields&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note that the behavior of Optionals has recently changed to include stricter null-checks. See the &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#ornull--getornull&#34;&gt;orNull / getOrNull&lt;/a&gt; section for more details.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Option objects are used to encode nullable fields. Say you have the following schema:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE Person(&#xA;  id INT NOT NULL PRIMARY KEY,&#xA;  name VARCHAR(255) -- This is nullable!&#xA;);&#xA;CREATE TABLE Address(&#xA;  fk INT, -- This is nullable!&#xA;  street VARCHAR(255) NOT NULL,&#xA;  zip INT NOT NULL,&#xA;  CONSTRAINT a_to_p FOREIGN KEY (fk) REFERENCES Person(id)&#xA;);&#xA;CREATE TABLE Company(&#xA;  name VARCHAR(255) NOT NULL,&#xA;  zip INT NOT NULL&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This would encode to the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Person(id:Int, name:Option[String])&#xA;case class Address(fk:Option[Int], street:String, zip:Int)&#xA;case class Company(name:String, zip:Int)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some important notes regarding Optionals and nullable fields.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;In many cases, Quill tries to rely on the null-fallthrough behavior that is ANSI standard:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;code&gt;null == null := false&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;null == [true | false] := false&lt;/code&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;This allows the generated SQL for most optional operations to be simple. For example, the expression &lt;code&gt;Option[String].map(v =&amp;gt; v + &#34;foo&#34;)&lt;/code&gt; can be expressed as the SQL &lt;code&gt;v || &#39;foo&#39;&lt;/code&gt; as opposed to &lt;code&gt;CASE IF (v is not null) v || &#39;foo&#39; ELSE null END&lt;/code&gt; so long as the concatenation operator &lt;code&gt;||&lt;/code&gt; &#34;falls-through&#34; and returns &lt;code&gt;null&lt;/code&gt; when the input is null. This is not true of all databases (e.g. &lt;a href=&#34;https://community.oracle.com/ideas/19866&#34;&gt;Oracle&lt;/a&gt;), forcing Quill to return the longer expression with explicit null-checking. Also, if there are conditionals inside of an Option operation (e.g. &lt;code&gt;o.map(v =&amp;gt; if (v == &#34;x&#34;) &#34;y&#34; else &#34;z&#34;)&lt;/code&gt;) this creates SQL with case statements, which will never fall-through when the input value is null. This forces Quill to explicitly null-check such statements in every SQL dialect.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Let&#39;s go through the typical operations of optionals.&lt;/p&gt; &#xA;&lt;h4&gt;isDefined / isEmpty&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;isDefined&lt;/code&gt; method is generally a good way to null-check a nullable field:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Address].filter(a =&amp;gt; a.fk.isDefined)&#xA;}&#xA;ctx.run(q)&#xA;// SELECT a.fk, a.street, a.zip FROM Address a WHERE a.fk IS NOT NULL&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;isEmpty&lt;/code&gt; method works the same way:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Address].filter(a =&amp;gt; a.fk.isEmpty)&#xA;}&#xA;ctx.run(q)&#xA;// SELECT a.fk, a.street, a.zip FROM Address a WHERE a.fk IS NULL&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;exists&lt;/h4&gt; &#xA;&lt;p&gt;This method is typically used for inspecting nullable fields inside of boolean conditions, most notably joining!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].join(query[Address]).on((p, a)=&amp;gt; a.fk.exists(_ == p.id))&#xA;}&#xA;ctx.run(q)&#xA;// SELECT p.id, p.name, a.fk, a.street, a.zip FROM Person p INNER JOIN Address a ON a.fk = p.id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that in the example above, the &lt;code&gt;exists&lt;/code&gt; method does not cause the generated SQL to do an explicit null-check in order to express the &lt;code&gt;False&lt;/code&gt; case. This is because Quill relies on the typical database behavior of immediately falsifying a statement that has &lt;code&gt;null&lt;/code&gt; on one side of the equation.&lt;/p&gt; &#xA;&lt;h4&gt;forall&lt;/h4&gt; &#xA;&lt;p&gt;Use this method in boolean conditions that should succeed in the null case.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].join(query[Address]).on((p, a) =&amp;gt; a.fk.forall(_ == p.id))&#xA;}&#xA;ctx.run(q)&#xA;// SELECT p.id, p.name, a.fk, a.street, a.zip FROM Person p INNER JOIN Address a ON a.fk IS NULL OR a.fk = p.id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Typically this is useful when doing negative conditions, e.g. when a field is &lt;strong&gt;not&lt;/strong&gt; some specified value (e.g. &lt;code&gt;&#34;Joe&#34;&lt;/code&gt;). Being &lt;code&gt;null&lt;/code&gt; in this case is typically a matching result.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.name.forall(_ != &#34;Joe&#34;))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.id, p.name FROM Person p WHERE p.name IS NULL OR p.name &amp;lt;&amp;gt; &#39;Joe&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;filterIfDefined&lt;/h4&gt; &#xA;&lt;p&gt;Use this to filter by a optional field that you want to ignore when None. This is useful when you want to filter by a map-key that may or may not exist.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val fieldFilters: Map[String, String] = Map(&#34;name&#34; -&amp;gt; &#34;Joe&#34;, &#34;age&#34; -&amp;gt; &#34;123&#34;)&#xA;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; lift(fieldFilters.get(&#34;name)).filterIfDefined(_ == p.name))&#xA;}&#xA; &#xA;ctx.run(q)&#xA;// SELECT p.id, p.name, p.title FROM Person p WHERE p.title IS NULL OR p.title = &#39;The Honorable&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It also works for regular fields.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// case class Person(name: String, age: Int, title: Option[String])&#xA;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.title.filterIfDefined(_ == &#34;The Honorable&#34;))&#xA;}&#xA; &#xA;ctx.run(q)&#xA;// SELECT p.id, p.name, p.title FROM Person p WHERE p.title IS NULL OR p.title = &#39;The Honorable&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;map&lt;/h4&gt; &#xA;&lt;p&gt;As in regular Scala code, performing any operation on an optional value typically requires using the &lt;code&gt;map&lt;/code&gt; function.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA; for {&#xA;    p &amp;lt;- query[Person]&#xA;  } yield (p.id, p.name.map(&#34;Dear &#34; + _))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.id, &#39;Dear &#39; || p.name FROM Person p&#xA;// * In Dialects where `||` does not fall-through for nulls (e.g. Oracle):&#xA;// * SELECT p.id, CASE WHEN p.name IS NOT NULL THEN &#39;Dear &#39; || p.name ELSE null END FROM Person p&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additionally, this method is useful when you want to get a non-optional field out of an outer-joined table (i.e. a table wrapped in an &lt;code&gt;Option&lt;/code&gt; object).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Company].leftJoin(query[Address])&#xA;    .on((c, a) =&amp;gt; c.zip == a.zip)&#xA;    .map {case(c,a) =&amp;gt;                          // Row type is (Company, Option[Address])&#xA;      (c.name, a.map(_.street), a.map(_.zip))   // Use `Option.map` to get `street` and `zip` fields&#xA;    }&#xA;}&#xA;&#xA;run(q)&#xA;// SELECT c.name, a.street, a.zip FROM Company c LEFT JOIN Address a ON c.zip = a.zip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more details about this operation (and some caveats), see the &#39;Optional Tables&#39; section.&lt;/p&gt; &#xA;&lt;h4&gt;flatMap and flatten&lt;/h4&gt; &#xA;&lt;p&gt;Use these when the &lt;code&gt;Option.map&lt;/code&gt; functionality is not sufficient. This typically happens when you need to manipulate multiple nullable fields in a way which would otherwise result in &lt;code&gt;Option[Option[T]]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  for {&#xA;    a &amp;lt;- query[Person]&#xA;    b &amp;lt;- query[Person] if (a.id &amp;gt; b.id)&#xA;  } yield (&#xA;    // If this was `a.name.map`, resulting record type would be Option[Option[String]]&#xA;    a.name.flatMap(an =&amp;gt;&#xA;      b.name.map(bn =&amp;gt;&#xA;        an+&#34; comes after &#34;+bn)))&#xA;}&#xA;&#xA;ctx.run(q) //: List[Option[String]]&#xA;// SELECT (a.name || &#39; comes after &#39;) || b.name FROM Person a, Person b WHERE a.id &amp;gt; b.id&#xA;// * In Dialects where `||` does not fall-through for nulls (e.g. Oracle):&#xA;// * SELECT CASE WHEN a.name IS NOT NULL AND b.name IS NOT NULL THEN (a.name || &#39; comes after &#39;) || b.name ELSE null END FROM Person a, Person b WHERE a.id &amp;gt; b.id&#xA;&#xA;// Alternatively, you can use `flatten`&#xA;val q = quote {&#xA;  for {&#xA;    a &amp;lt;- query[Person]&#xA;    b &amp;lt;- query[Person] if (a.id &amp;gt; b.id)&#xA;  } yield (&#xA;    a.name.map(an =&amp;gt;&#xA;      b.name.map(bn =&amp;gt;&#xA;        an + &#34; comes after &#34; + bn)).flatten)&#xA;}&#xA;&#xA;ctx.run(q) //: List[Option[String]]&#xA;// SELECT (a.name || &#39; comes after &#39;) || b.name FROM Person a, Person b WHERE a.id &amp;gt; b.id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is also very useful when selecting from outer-joined tables i.e. where the entire table is inside of an &lt;code&gt;Option&lt;/code&gt; object. Note how below we get the &lt;code&gt;fk&lt;/code&gt; field from &lt;code&gt;Option[Address]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].leftJoin(query[Address])&#xA;    .on((p, a) =&amp;gt; a.fk.exists(_ == p.id))&#xA;    .map {case (p /*Person*/, a /*Option[Address]*/) =&amp;gt; (p.name, a.flatMap(_.fk))}&#xA;}&#xA;&#xA;ctx.run(q) //: List[(Option[String], Option[Int])]&#xA;// SELECT p.name, a.fk FROM Person p LEFT JOIN Address a ON a.fk = p.id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;orNull / getOrNull&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;orNull&lt;/code&gt; method can be used to convert an Option-enclosed row back into a regular row. Since &lt;code&gt;Option[T].orNull&lt;/code&gt; does not work for primitive types (e.g. &lt;code&gt;Int&lt;/code&gt;, &lt;code&gt;Double&lt;/code&gt;, etc...), you can use the &lt;code&gt;getOrNull&lt;/code&gt; method inside of quoted blocks to do the same thing.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note that since the presence of null columns can cause queries to break in some data sources (e.g. Spark), so use this operation very carefully.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].join(query[Address])&#xA;    .on((p, a) =&amp;gt; a.fk.exists(_ == p.id))&#xA;    .filter {case (p /*Person*/, a /*Option[Address]*/) =&amp;gt;&#xA;      a.fk.getOrNull != 123 } // Exclude a particular value from the query.&#xA;                              // Since we already did an inner-join on this value, we know it is not null.&#xA;}&#xA;&#xA;ctx.run(q) //: List[(Address, Person)]&#xA;// SELECT p.id, p.name, a.fk, a.street, a.zip FROM Person p INNER JOIN Address a ON a.fk IS NOT NULL AND a.fk = p.id WHERE a.fk &amp;lt;&amp;gt; 123&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In certain situations, you may wish to pretend that a nullable-field is not actually nullable and perform regular operations (e.g. arithmetic, concatenation, etc...) on the field. You can use a combination of &lt;code&gt;Option.apply&lt;/code&gt; and &lt;code&gt;orNull&lt;/code&gt; (or &lt;code&gt;getOrNull&lt;/code&gt; where needed) in order to do this.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].map(p =&amp;gt; Option(p.name.orNull + &#34; suffix&#34;))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.name || &#39; suffix&#39; FROM Person p&#xA;// i.e. same as the previous behavior&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In all other situations, since Quill strictly checks nullable values, and &lt;code&gt;case.. if&lt;/code&gt; conditionals will work correctly in all Optional constructs. However, since they may introduce behavior changes in your codebase, the following warning has been introduced:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Conditionals inside of Option.[map | flatMap | exists | forall] will create a &lt;code&gt;CASE&lt;/code&gt; statement in order to properly null-check the sub-query (...)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code&gt;val q = quote {&#xA;  query[Person].map(p =&amp;gt; p.name.map(n =&amp;gt; if (n == &#34;Joe&#34;) &#34;foo&#34; else &#34;bar&#34;).getOrElse(&#34;baz&#34;))&#xA;}&#xA;// Information:(16, 15) Conditionals inside of Option.map will create a `CASE` statement in order to properly null-check the sub-query: `p.name.map((n) =&amp;gt; if(n == &#34;Joe&#34;) &#34;foo&#34; else &#34;bar&#34;)`.&#xA;// Expressions like Option(if (v == &#34;foo&#34;) else &#34;bar&#34;).getOrElse(&#34;baz&#34;) will now work correctly, but expressions that relied on the broken behavior (where &#34;bar&#34; would be returned instead) need to be modified  (see the &#34;orNull / getOrNull&#34; section of the documentation of more detail).&#xA;&#xA;ctx.run(a)&#xA;// Used to be this:&#xA;// SELECT CASE WHEN CASE WHEN p.name = &#39;Joe&#39; THEN &#39;foo&#39; ELSE &#39;bar&#39; END IS NOT NULL THEN CASE WHEN p.name = &#39;Joe&#39; THEN &#39;foo&#39; ELSE &#39;bar&#39; END ELSE &#39;baz&#39; END FROM Person p&#xA;// Now is this:&#xA;// SELECT CASE WHEN p.name IS NOT NULL AND CASE WHEN p.name = &#39;Joe&#39; THEN &#39;foo&#39; ELSE &#39;bar&#39; END IS NOT NULL THEN CASE WHEN p.name = &#39;Joe&#39; THEN &#39;foo&#39; ELSE &#39;bar&#39; END ELSE &#39;baz&#39; END FROM Person p&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;equals&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;==&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, and &lt;code&gt;.equals&lt;/code&gt; methods can be used to compare regular types as well Option types in a scala-idiomatic way. That is to say, either &lt;code&gt;T == T&lt;/code&gt; or &lt;code&gt;Option[T] == Option[T]&lt;/code&gt; is supported and the following &#34;truth-table&#34; is observed:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Left&lt;/th&gt; &#xA;   &lt;th&gt;Right&lt;/th&gt; &#xA;   &lt;th&gt;Equality&lt;/th&gt; &#xA;   &lt;th&gt;Result&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;a&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;b&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;==&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;a == b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T](a)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T](b)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;==&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;a == b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T](a)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;==&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;None &lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T](b)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;==&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;None &lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;==&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T] &lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[R] &lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;==&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Exception thrown.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;a&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;b&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;!=&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;a != b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T](a)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T](b)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;!=&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;a != b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T](a)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;!=&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;None &lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T](b)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;!=&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[T] &lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;Some[R] &lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;!=&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Exception thrown.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;None &lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;!=&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Node(id:Int, status:Option[String], otherStatus:Option[String])&#xA;&#xA;val q = quote { query[Node].filter(n =&amp;gt; n.id == 123) }&#xA;ctx.run(q)&#xA;// SELECT n.id, n.status, n.otherStatus FROM Node n WHERE p.id = 123&#xA;&#xA;val q = quote { query[Node].filter(r =&amp;gt; r.status == r.otherStatus) }&#xA;ctx.run(q)&#xA;// SELECT r.id, r.status, r.otherStatus FROM Node r WHERE r.status IS NULL AND r.otherStatus IS NULL OR r.status = r.otherStatus&#xA;&#xA;val q = quote { query[Node].filter(n =&amp;gt; n.status == Option(&#34;RUNNING&#34;)) }&#xA;ctx.run(q)&#xA;// SELECT n.id, n.status, n.otherStatus FROM node n WHERE n.status IS NOT NULL AND n.status = &#39;RUNNING&#39;&#xA;&#xA;val q = quote { query[Node].filter(n =&amp;gt; n.status != Option(&#34;RUNNING&#34;)) }&#xA;ctx.run(q)&#xA;// SELECT n.id, n.status, n.otherStatus FROM node n WHERE n.status IS NULL OR n.status &amp;lt;&amp;gt; &#39;RUNNING&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you would like to use an equality operator that follows that ansi-idiomatic approach, failing the comparison if either side is null as well as the principle that &lt;code&gt;null = null := false&lt;/code&gt;, you can import &lt;code&gt;===&lt;/code&gt; (and &lt;code&gt;=!=&lt;/code&gt;) from &lt;code&gt;Context.extras&lt;/code&gt;. These operators work across &lt;code&gt;T&lt;/code&gt; and &lt;code&gt;Option[T]&lt;/code&gt; allowing comparisons like &lt;code&gt;T === Option[T]&lt;/code&gt;, &lt;code&gt;Option[T] == T&lt;/code&gt; etc... to be made. You can use also &lt;code&gt;===&lt;/code&gt; directly in Scala code and it will have the same behavior, returning &lt;code&gt;false&lt;/code&gt; when other the left-hand or right-hand side is &lt;code&gt;None&lt;/code&gt;. This is particularity useful in paradigms like Spark where you will typically transition inside and outside of Quill code.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;When using &lt;code&gt;a === b&lt;/code&gt; or &lt;code&gt;a =!= b&lt;/code&gt; sometimes you will see the extra &lt;code&gt;a IS NOT NULL AND b IS NOT NULL&lt;/code&gt; comparisons and sometimes you will not. This depends on &lt;code&gt;equalityBehavior&lt;/code&gt; in &lt;code&gt;SqlIdiom&lt;/code&gt; which determines whether the given SQL dialect already does ansi-idiomatic comparison to &lt;code&gt;a&lt;/code&gt;, and &lt;code&gt;b&lt;/code&gt; when an &lt;code&gt;=&lt;/code&gt; operator is used, this allows us to omit the extra &lt;code&gt;a IS NOT NULL AND b IS NOT NULL&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import ctx.extras._&#xA;&#xA;// === works the same way inside of a quotation&#xA;val q = run( query[Node].filter(n =&amp;gt; n.status === &#34;RUNNING&#34;) )&#xA;// SELECT n.id, n.status FROM node n WHERE n.status IS NOT NULL AND n.status = &#39;RUNNING&#39;&#xA;&#xA;// as well as outside&#xA;(nodes:List[Node]).filter(n =&amp;gt; n.status === &#34;RUNNING&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Optional Tables&lt;/h4&gt; &#xA;&lt;p&gt;As we have seen in the examples above, only the &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;flatMap&lt;/code&gt; methods are available on outer-joined tables (i.e. tables wrapped in an &lt;code&gt;Option&lt;/code&gt; object).&lt;/p&gt; &#xA;&lt;p&gt;Since you cannot use &lt;code&gt;Option[Table].isDefined&lt;/code&gt;, if you want to null-check a whole table (e.g. if a left-join was not matched), you have to &lt;code&gt;map&lt;/code&gt; to a specific field on which you can do the null-check.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Company].leftJoin(query[Address])&#xA;    .on((c, a) =&amp;gt; c.zip == a.zip)         // Row type is (Company, Option[Address])&#xA;    .filter({case(c,a) =&amp;gt; a.isDefined})   // You cannot null-check a whole table!&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Instead, map the row-variable to a specific field and then check that field.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Company].leftJoin(query[Address])&#xA;    .on((c, a) =&amp;gt; c.zip == a.zip)                     // Row type is (Company, Option[Address])&#xA;    .filter({case(c,a) =&amp;gt; a.map(_.street).isDefined}) // Null-check a non-nullable field instead&#xA;}&#xA;ctx.run(q)&#xA;// SELECT c.name, c.zip, a.fk, a.street, a.zip&#xA;// FROM Company c&#xA;// LEFT JOIN Address a ON c.zip = a.zip&#xA;// WHERE a.street IS NOT NULL&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, it is worth noting that a whole table can be wrapped into an &lt;code&gt;Option&lt;/code&gt; object. This is particularly useful when doing a union on table-sets that are both right-joined and left-joined together.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val aCompanies = quote {&#xA;  for {&#xA;    c &amp;lt;- query[Company] if (c.name like &#34;A%&#34;)&#xA;    a &amp;lt;- query[Address].join(_.zip == c.zip)&#xA;  } yield (c, Option(a))  // change (Company, Address) to (Company, Option[Address])&#xA;}&#xA;val bCompanies = quote {&#xA;  for {&#xA;    c &amp;lt;- query[Company] if (c.name like &#34;A%&#34;)&#xA;    a &amp;lt;- query[Address].leftJoin(_.zip == c.zip)&#xA;  } yield (c, a) // (Company, Option[Address])&#xA;}&#xA;val union = quote {&#xA;  aCompanies union bCompanies&#xA;}&#xA;ctx.run(union)&#xA;// SELECT x.name, x.zip, x.fk, x.street, x.zip FROM (&#xA;// (SELECT c.name name, c.zip zip, x1.zip zip, x1.fk fk, x1.street street&#xA;// FROM Company c INNER JOIN Address x1 ON x1.zip = c.zip WHERE c.name like &#39;A%&#39;)&#xA;// UNION&#xA;// (SELECT c1.name name, c1.zip zip, x2.zip zip, x2.fk fk, x2.street street&#xA;// FROM Company c1 LEFT JOIN Address x2 ON x2.zip = c1.zip WHERE c1.name like &#39;A%&#39;)&#xA;// ) x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Ad-Hoc Case Classes&lt;/h3&gt; &#xA;&lt;p&gt;Case Classes can also be used inside quotations as output values:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Person(id: Int, name: String, age: Int)&#xA;case class Contact(personId: Int, phone: String)&#xA;case class ReachablePerson(name:String, phone: String)&#xA;&#xA;val q = quote {&#xA;  for {&#xA;    p &amp;lt;- query[Person] if(p.id == 999)&#xA;    c &amp;lt;- query[Contact] if(c.personId == p.id)&#xA;  } yield {&#xA;    ReachablePerson(p.name, c.phone)&#xA;  }&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.name, c.phone FROM Person p, Contact c WHERE (p.id = 999) AND (c.personId = p.id)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As well as in general:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class IdFilter(id:Int)&#xA;&#xA;val q = quote {&#xA;  val idFilter = new IdFilter(999)&#xA;  for {&#xA;    p &amp;lt;- query[Person] if(p.id == idFilter.id)&#xA;    c &amp;lt;- query[Contact] if(c.personId == p.id)&#xA;  } yield {&#xA;    ReachablePerson(p.name, c.phone)&#xA;  }&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.name, c.phone FROM Person p, Contact c WHERE (p.id = 999) AND (c.personId = p.id)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/em&gt; however that this functionality has the following restrictions:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The Ad-Hoc Case Class can only have one constructor with one set of parameters.&lt;/li&gt; &#xA; &lt;li&gt;The Ad-Hoc Case Class must be constructed inside the quotation using one of the following methods: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Using the &lt;code&gt;new&lt;/code&gt; keyword: &lt;code&gt;new Person(&#34;Joe&#34;, &#34;Bloggs&#34;)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Using a companion object&#39;s apply method: &lt;code&gt;Person(&#34;Joe&#34;, &#34;Bloggs&#34;)&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Using a companion object&#39;s apply method explicitly: &lt;code&gt;Person.apply(&#34;Joe&#34;, &#34;Bloggs&#34;)&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Any custom logic in a constructor/apply-method of an Ad-Hoc case class will not be invoked when it is &#39;constructed&#39; inside a quotation. To construct an Ad-Hoc case class with custom logic inside a quotation, you can use a quoted method.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Query probing&lt;/h2&gt; &#xA;&lt;p&gt;Query probing validates queries against the database at compile time, failing the compilation if it is not valid. The query validation does not alter the database state.&lt;/p&gt; &#xA;&lt;p&gt;This feature is disabled by default. To enable it, mix the &lt;code&gt;QueryProbing&lt;/code&gt; trait to the database configuration:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;object myContext extends YourContextType with QueryProbing&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The context must be created in a separate compilation unit in order to be loaded at compile time. Please use &lt;a href=&#34;http://www.scala-sbt.org/0.13/docs/Macro-Projects.html&#34;&gt;this guide&lt;/a&gt; that explains how to create a separate compilation unit for macros, that also serves to the purpose of defining a query-probing-capable context. &lt;code&gt;context&lt;/code&gt; could be used instead of &lt;code&gt;macros&lt;/code&gt; as the name of the separate compilation unit.&lt;/p&gt; &#xA;&lt;p&gt;The configurations correspondent to the config key must be available at compile time. You can achieve it by adding this line to your project settings:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;unmanagedClasspath in Compile += baseDirectory.value / &#34;src&#34; / &#34;main&#34; / &#34;resources&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If your project doesn&#39;t have a standard layout, e.g. a play project, you should configure the path to point to the folder that contains your config file.&lt;/p&gt; &#xA;&lt;h2&gt;Actions&lt;/h2&gt; &#xA;&lt;p&gt;Database actions are defined using quotations as well. These actions don&#39;t have a collection-like API but rather a custom DSL to express inserts, deletes, and updates.&lt;/p&gt; &#xA;&lt;h3&gt;insertValue / insert&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote(query[Contact].insertValue(lift(Contact(999, &#34;+1510488988&#34;))))&#xA;&#xA;ctx.run(a) // = 1 if the row was inserted 0 otherwise&#xA;// INSERT INTO Contact (personId,phone) VALUES (?, ?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;It is also possible to insert specific columns (via insert):&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Contact].insert(_.personId -&amp;gt; lift(999), _.phone -&amp;gt; lift(&#34;+1510488988&#34;))&#xA;}&#xA;&#xA;ctx.run(a)&#xA;// INSERT INTO Contact (personId,phone) VALUES (?, ?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;batch insert&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  liftQuery(List(Person(0, &#34;John&#34;, 31),Person(2, &#34;name2&#34;, 32))).foreach(e =&amp;gt; query[Person].insertValue(e))&#xA;}&#xA;&#xA;ctx.run(a) //: List[Long] size = 2. Contains 1 @ positions, where row was inserted E.g List(1,1)&#xA;// INSERT INTO Person (id,name,age) VALUES (?, ?, ?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Just as in regular queries use the extended insert/update syntaxes to achieve finer-grained control of the data being created/modified modified. For example, if the ID is a generated value you can skip ID insertion like this: (This can also be accomplied with an insert-meta).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// case class Person(id: Int, name: String, age: Int)&#xA;val a = quote {&#xA;  liftQuery(List(Person(0, &#34;John&#34;, 31),Person(0, &#34;name2&#34;, 32))).foreach(e =&amp;gt; query[Person].insert(_.name -&amp;gt; p.name, _.age -&amp;gt; p.age))&#xA;}&#xA;&#xA;ctx.run(a)&#xA;// INSERT INTO Person (name,age) VALUES (?, ?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Batch queries can also have a returning/returningGenerate clause:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// case class Person(id: Int, name: String, age: Int)&#xA;val a = quote {&#xA;  liftQuery(List(Person(0, &#34;John&#34;, 31),Person(0, &#34;name2&#34;, 32))).foreach(e =&amp;gt; query[Person].insert(_.name -&amp;gt; p.name, _.age -&amp;gt; p.age)).returning(_.id)&#xA;}&#xA;&#xA;ctx.run(a)&#xA;// INSERT INTO Person (name,age) VALUES (?, ?) RETURNING id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the &lt;code&gt;liftQuery[Something]&lt;/code&gt; and the query[Something]` values do not necessarily need to be the same object-type. (In fact the liftQuery value can even be a constant!) For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// case class Person(name: String, age: Int)&#xA;// case class Vip(first: String, last: String, age: Int)&#xA;// val vips: List[Vip] = ...&#xA;val q = quote {&#xA;  liftQuery(vips).foreach(v =&amp;gt; query[Person].insertValue(Person(v.first + v.last, v.age)))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// INSERT INTO Person (name,age) VALUES ((? || ?), ?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that UPDATE queries can also be done in batches (as well as DELETE queries).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  liftQuery(vips).foreach(v =&amp;gt; query[Person].filter(p =&amp;gt; p.age &amp;gt; 22).updateValue(Person(v.first + v.last, v.age)))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// UPDATE Person SET name = (? || ?), age = ? WHERE age &amp;gt; 22&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;updateValue / update&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Person].filter(_.id == 999).updateValue(lift(Person(999, &#34;John&#34;, 22)))&#xA;}&#xA;&#xA;ctx.run(a) // = Long number of rows updated&#xA;// UPDATE Person SET id = ?, name = ?, age = ? WHERE id = 999&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Using specific columns (via update):&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Person].filter(p =&amp;gt; p.id == lift(999)).update(_.age -&amp;gt; lift(18))&#xA;}&#xA;&#xA;ctx.run(a)&#xA;// UPDATE Person SET age = ? WHERE id = ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Using columns as part of the update:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Person].filter(p =&amp;gt; p.id == lift(999)).update(p =&amp;gt; p.age -&amp;gt; (p.age + 1))&#xA;}&#xA;&#xA;ctx.run(a)&#xA;// UPDATE Person SET age = (age + 1) WHERE id = ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;batch update&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  liftQuery(List(Person(1, &#34;name&#34;, 31),Person(2, &#34;name2&#34;, 32))).foreach { person =&amp;gt;&#xA;     query[Person].filter(_.id == person.id).update(_.name -&amp;gt; person.name, _.age -&amp;gt; person.age)&#xA;  }&#xA;}&#xA;&#xA;ctx.run(a) // : List[Long] size = 2. Contains 1 @ positions, where row was inserted E.g List(1,0)&#xA;// UPDATE Person SET name = ?, age = ? WHERE id = ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;delete&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Person].filter(p =&amp;gt; p.name == &#34;&#34;).delete&#xA;}&#xA;&#xA;ctx.run(a) // = Long the number of rows deleted&#xA;// DELETE FROM Person WHERE name = &#39;&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;insert or update (upsert, conflict)&lt;/h3&gt; &#xA;&lt;p&gt;Upsert is supported by Postgres, SQLite, MySQL and H2 &lt;code&gt;onConflictIgnore&lt;/code&gt; only (since v1.4.200 in PostgreSQL compatibility mode)&lt;/p&gt; &#xA;&lt;h4&gt;Postgres and SQLite&lt;/h4&gt; &#xA;&lt;h5&gt;Ignore conflict&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Product].insert(_.id -&amp;gt; 1, _.sku -&amp;gt; 10).onConflictIgnore&#xA;}&#xA;&#xA;// INSERT INTO Product AS t (id,sku) VALUES (1, 10) ON CONFLICT DO NOTHING&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ignore conflict by explicitly setting conflict target&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Product].insert(_.id -&amp;gt; 1, _.sku -&amp;gt; 10).onConflictIgnore(_.id)&#xA;}&#xA;&#xA;// INSERT INTO Product AS t (id,sku) VALUES (1, 10) ON CONFLICT (id) DO NOTHING&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Multiple properties can be used as well.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Product].insert(_.id -&amp;gt; 1, _.sku -&amp;gt; 10).onConflictIgnore(_.id, _.description)&#xA;}&#xA;&#xA;// INSERT INTO Product (id,sku) VALUES (1, 10) ON CONFLICT (id,description) DO NOTHING&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Update on Conflict&lt;/h5&gt; &#xA;&lt;p&gt;Resolve conflict by updating existing row if needed. In &lt;code&gt;onConflictUpdate(target)((t, e) =&amp;gt; assignment)&lt;/code&gt;: &lt;code&gt;target&lt;/code&gt; refers to conflict target, &lt;code&gt;t&lt;/code&gt; - to existing row and &lt;code&gt;e&lt;/code&gt; - to excluded, e.g. row proposed for insert.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Product]&#xA;    .insert(_.id -&amp;gt; 1, _.sku -&amp;gt; 10)&#xA;    .onConflictUpdate(_.id)((t, e) =&amp;gt; t.sku -&amp;gt; (t.sku + e.sku))&#xA;}&#xA;&#xA;// INSERT INTO Product AS t (id,sku) VALUES (1, 10) ON CONFLICT (id) DO UPDATE SET sku = (t.sku + EXCLUDED.sku)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Multiple properties can be used with &lt;code&gt;onConflictUpdate&lt;/code&gt; as well.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Product]&#xA;    .insert(_.id -&amp;gt; 1, _.sku -&amp;gt; 10)&#xA;    .onConflictUpdate(_.id, _.description)((t, e) =&amp;gt; t.sku -&amp;gt; (t.sku + e.sku))&#xA;}&#xA;&#xA;INSERT INTO Product AS t (id,sku) VALUES (1, 10) ON CONFLICT (id,description) DO UPDATE SET sku = (t.sku + EXCLUDED.sku)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;MySQL&lt;/h4&gt; &#xA;&lt;p&gt;Ignore any conflict, e.g. &lt;code&gt;insert ignore&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Product].insert(_.id -&amp;gt; 1, _.sku -&amp;gt; 10).onConflictIgnore&#xA;}&#xA;&#xA;// INSERT IGNORE INTO Product (id,sku) VALUES (1, 10)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ignore duplicate key conflict by explicitly setting it&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Product].insert(_.id -&amp;gt; 1, _.sku -&amp;gt; 10).onConflictIgnore(_.id)&#xA;}&#xA;&#xA;// INSERT INTO Product (id,sku) VALUES (1, 10) ON DUPLICATE KEY UPDATE id=id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Resolve duplicate key by updating existing row if needed. In &lt;code&gt;onConflictUpdate((t, e) =&amp;gt; assignment)&lt;/code&gt;: &lt;code&gt;t&lt;/code&gt; refers to existing row and &lt;code&gt;e&lt;/code&gt; - to values, e.g. values proposed for insert.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a = quote {&#xA;  query[Product]&#xA;    .insert(_.id -&amp;gt; 1, _.sku -&amp;gt; 10)&#xA;    .onConflictUpdate((t, e) =&amp;gt; t.sku -&amp;gt; (t.sku + e.sku))&#xA;}&#xA;&#xA;// INSERT INTO Product (id,sku) VALUES (1, 10) ON DUPLICATE KEY UPDATE sku = (sku + VALUES(sku))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Printing Queries&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;translate&lt;/code&gt; method is used to convert a Quill query into a string which can then be printed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val str = ctx.translate(query[Person])&#xA;println(str)&#xA;// SELECT x.id, x.name, x.age FROM Person x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Insert queries can also be printed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val str = ctx.translate(query[Person].insertValue(lift(Person(0, &#34;Joe&#34;, 45))))&#xA;println(str)&#xA;// INSERT INTO Person (id,name,age) VALUES (0, &#39;Joe&#39;, 45)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As well as batch insertions:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  liftQuery(List(Person(0, &#34;Joe&#34;,44), Person(1, &#34;Jack&#34;,45)))&#xA;    .foreach(e =&amp;gt; query[Person].insertValue(e))&#xA;}&#xA;val strs: List[String] = ctx.translate(q)&#xA;strs.map(println)&#xA;// INSERT INTO Person (id, name,age) VALUES (0, &#39;Joe&#39;, 44)&#xA;// INSERT INTO Person (id, name,age) VALUES (1, &#39;Jack&#39;, 45)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;translate&lt;/code&gt; method is available in every Quill context as well as the Cassandra and OrientDB contexts, the latter two, however, do not support Insert and Batch Insert query printing.&lt;/p&gt; &#xA;&lt;h2&gt;IO Monad&lt;/h2&gt; &#xA;&lt;p&gt;Quill provides an IO monad that allows the user to express multiple computations and execute them separately. This mechanism is also known as a free monad, which provides a way of expressing computations as referentially-transparent values and isolates the unsafe IO operations into a single operation. For instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// this code using Future&#xA;&#xA;case class Person(id: Int, name: String, age: Int)&#xA;&#xA;val p = Person(0, &#34;John&#34;, 22)&#xA;ctx.run(query[Person].insertValue(lift(p))).flatMap { _ =&amp;gt;&#xA;  ctx.run(query[Person])&#xA;}&#xA;&#xA;// isn&#39;t referentially transparent because if you refactor the second database&#xA;// interaction into a value, the result will be different:&#xA;&#xA;val allPeople = ctx.run(query[Person])&#xA;ctx.run(query[Person].insertValue(lift(p))).flatMap { _ =&amp;gt;&#xA;  allPeople&#xA;}&#xA;&#xA;// this happens because `ctx.run` executes the side-effect (database IO) immediately&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// The IO monad doesn&#39;t perform IO immediately, so both computations:&#xA;&#xA;val p = Person(0, &#34;John&#34;, 22)&#xA;&#xA;val a =&#xA;  ctx.runIO(query[Person].insertValue(lift(p))).flatMap { _ =&amp;gt;&#xA;    ctx.runIO(query[Person])&#xA;  }&#xA;&#xA;&#xA;val allPeople = ctx.runIO(query[Person])&#xA;&#xA;val b =&#xA;  ctx.runIO(query[Person].insertValue(lift(p))).flatMap { _ =&amp;gt;&#xA;    allPeople&#xA;  }&#xA;&#xA;// produce the same result when executed&#xA;&#xA;performIO(a) == performIO(b)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The IO monad has an interface similar to &lt;code&gt;Future&lt;/code&gt;; please refer to &lt;a href=&#34;https://github.com/getquill/quill/raw/master/quill-core/src/main/scala/io/getquill/monad/IOMonad.scala#L39&#34;&gt;the class&lt;/a&gt; for more information regarding the available operations.&lt;/p&gt; &#xA;&lt;p&gt;The return type of &lt;code&gt;performIO&lt;/code&gt; varies according to the context. For instance, async contexts return &lt;code&gt;Future&lt;/code&gt;s while JDBC returns values synchronously.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/em&gt;: Avoid using the variable name &lt;code&gt;io&lt;/code&gt; since it conflicts with Quill&#39;s package &lt;code&gt;io.getquill&lt;/code&gt;, otherwise you will get the following error.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;recursive value io needs type&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;IO Monad and transactions&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;IO&lt;/code&gt; also provides the &lt;code&gt;transactional&lt;/code&gt; method that delimits a transaction:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a =&#xA;  ctx.runIO(query[Person].insertValue(lift(p))).flatMap { _ =&amp;gt;&#xA;    ctx.runIO(query[Person])&#xA;  }&#xA;&#xA;performIO(a.transactional) // note: transactional can be used outside of `performIO`&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Getting a ResultSet&lt;/h3&gt; &#xA;&lt;p&gt;Quill JDBC Contexts allow you to use &lt;code&gt;prepare&lt;/code&gt; in order to get a low-level &lt;code&gt;ResultSet&lt;/code&gt; that is useful for interacting with legacy APIs. This function returns a &lt;code&gt;f: (Connection) =&amp;gt; (PreparedStatement)&lt;/code&gt; closure as opposed to a &lt;code&gt;PreparedStatement&lt;/code&gt; in order to guarantee that JDBC Exceptions are not thrown until you can wrap them into the appropriate Exception-handling mechanism (e.g. &lt;code&gt;try&lt;/code&gt;/&lt;code&gt;catch&lt;/code&gt;, &lt;code&gt;Try&lt;/code&gt; etc...).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].filter(_.id == 1)&#xA;}&#xA;val preparer: (Connection) =&amp;gt; (PreparedStatement)  = ctx.prepare(q)&#xA;// SELECT x1.id, x1.description, x1.sku FROM Product x1 WHERE x1.id = 1&#xA;&#xA;// Use ugly stateful code, bracketed effects, or try-with-resources here:&#xA;var preparedStatement: PreparedStatement = _&#xA;var resultSet: ResultSet = _&#xA;&#xA;try {&#xA;  preparedStatement = preparer(myCustomDataSource.getConnection)&#xA;  resultSet = preparedStatement.executeQuery()&#xA;} catch {&#xA;  case e: Exception =&amp;gt;&#xA;    // Close the preparedStatement and catch possible exceptions&#xA;    // Close the resultSet and catch possible exceptions&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;prepare&lt;/code&gt; function can also be used with &lt;code&gt;insertValue&lt;/code&gt;, and &lt;code&gt;updateValue&lt;/code&gt; actions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Product].insertValue(lift(Product(1, &#34;Desc&#34;, 123))&#xA;}&#xA;val preparer: (Connection) =&amp;gt; (PreparedStatement)  = ctx.prepare(q)&#xA;// INSERT INTO Product (id,description,sku) VALUES (?, ?, ?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As well as with batch queries.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Make sure to first quote your batch query and then pass the result into the &lt;code&gt;prepare&lt;/code&gt; function (as is done in the example below) or the Scala compiler may not type the output correctly &lt;a href=&#34;https://github.com/getquill/quill/issues/1518&#34;&gt;#1518&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  liftQuery(products).foreach(e =&amp;gt; query[Product].insertValue(e))&#xA;}&#xA;val preparers: Connection =&amp;gt; List[PreparedStatement] = ctx.prepare(q)&#xA;val preparedStatement: List[PreparedStatement] = preparers(jdbcConf.dataSource.getConnection)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Effect tracking&lt;/h3&gt; &#xA;&lt;p&gt;The IO monad tracks the effects that a computation performs in its second type parameter:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val a: IO[ctx.RunQueryResult[Person], Effect.Write with Effect.Read] =&#xA;  ctx.runIO(query[Person].insertValue(lift(p))).flatMap { _ =&amp;gt;&#xA;    ctx.runIO(query[Person])&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This mechanism is useful to limit the kind of operations that can be performed. See this &lt;a href=&#34;http://danielwestheide.com/blog/2015/06/28/put-your-writes-where-your-master-is-compile-time-restriction-of-slick-effect-types.html&#34;&gt;blog post&lt;/a&gt; as an example.&lt;/p&gt; &#xA;&lt;h2&gt;Implicit query&lt;/h2&gt; &#xA;&lt;p&gt;Quill provides implicit conversions from case class companion objects to &lt;code&gt;query[T]&lt;/code&gt; through an additional trait:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new SqlMirrorContext(MirrorSqlDialect, Literal) with ImplicitQuery&#xA;&#xA;import ctx._&#xA;&#xA;val q = quote {&#xA;  for {&#xA;    p &amp;lt;- Person if(p.id == 999)&#xA;    c &amp;lt;- Contact if(c.personId == p.id)&#xA;  } yield {&#xA;    (p.name, c.phone)&#xA;  }&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT p.name, c.phone FROM Person p, Contact c WHERE (p.id = 999) AND (c.personId = p.id)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note the usage of &lt;code&gt;Person&lt;/code&gt; and &lt;code&gt;Contact&lt;/code&gt; instead of &lt;code&gt;query[Person]&lt;/code&gt; and &lt;code&gt;query[Contact]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;SQL-specific operations&lt;/h2&gt; &#xA;&lt;p&gt;Some operations are SQL-specific and not provided with the generic quotation mechanism. The SQL contexts provide implicit classes for this kind of operation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new SqlMirrorContext(MirrorSqlDialect, Literal)&#xA;import ctx._&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;like&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.name like &#34;%John%&#34;)&#xA;}&#xA;ctx.run(q)&#xA;// SELECT p.id, p.name, p.age FROM Person p WHERE p.name like &#39;%John%&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;forUpdate&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.name == &#34;Mary&#34;).forUpdate()&#xA;}&#xA;ctx.run(q)&#xA;// SELECT p.id, p.name, p.age FROM Person p WHERE p.name = &#39;Mary&#39; FOR UPDATE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;SQL-specific encoding&lt;/h2&gt; &#xA;&lt;h3&gt;Arrays&lt;/h3&gt; &#xA;&lt;p&gt;Quill provides SQL Arrays support. In Scala we represent them as any collection that implements &lt;code&gt;Seq&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import java.util.Date&#xA;&#xA;case class Book(id: Int, notes: List[String], pages: Vector[Int], history: Seq[Date])&#xA;&#xA;ctx.run(query[Book])&#xA;// SELECT x.id, x.notes, x.pages, x.history FROM Book x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that not all drivers/databases provides such feature hence only &lt;code&gt;PostgresJdbcContext&lt;/code&gt; and &lt;code&gt;PostgresAsyncContext&lt;/code&gt; support SQL Arrays.&lt;/p&gt; &#xA;&lt;h2&gt;Cassandra-specific encoding&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new CassandraMirrorContext(Literal)&#xA;import ctx._&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Collections&lt;/h3&gt; &#xA;&lt;p&gt;The Cassandra context provides List, Set, and Map encoding:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;&#xA;case class Book(id: Int, notes: Set[String], pages: List[Int], history: Map[Int, Boolean])&#xA;&#xA;ctx.run(query[Book])&#xA;// SELECT id, notes, pages, history FROM Book&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;User-Defined Types&lt;/h3&gt; &#xA;&lt;p&gt;The cassandra context provides encoding of UDT (user-defined types).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;&#xA;case class Name(firstName: String, lastName: String) extends Udt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To encode the UDT and bind it into the query (insert/update queries), the context needs to retrieve UDT metadata from the cluster object. By default, the context looks for UDT metadata within the currently logged keyspace, but it&#39;s also possible to specify a concrete keyspace with &lt;code&gt;udtMeta&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit val nameMeta = udtMeta[Name](&#34;keyspace2.my_name&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When a keyspace is not set in &lt;code&gt;udtMeta&lt;/code&gt; then the currently logged one is used.&lt;/p&gt; &#xA;&lt;p&gt;Since it&#39;s possible to create a context without specifying a keyspace, (e.g. the keyspace parameter is null and the session is not bound to any keyspace), the UDT metadata will be resolved throughout the entire cluster.&lt;/p&gt; &#xA;&lt;p&gt;It is also possible to rename UDT columns with &lt;code&gt;udtMeta&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit val nameMeta = udtMeta[Name](&#34;name&#34;, _.firstName -&amp;gt; &#34;first&#34;, _.lastName -&amp;gt; &#34;last&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Cassandra-specific operations&lt;/h2&gt; &#xA;&lt;p&gt;The cassandra context also provides a few additional operations:&lt;/p&gt; &#xA;&lt;h3&gt;allowFiltering&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.age &amp;gt; 10).allowFiltering&#xA;}&#xA;ctx.run(q)&#xA;// SELECT id, name, age FROM Person WHERE age &amp;gt; 10 ALLOW FILTERING&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ifNotExists&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].insert(_.age -&amp;gt; 10, _.name -&amp;gt; &#34;John&#34;).ifNotExists&#xA;}&#xA;ctx.run(q)&#xA;// INSERT INTO Person (age,name) VALUES (10, &#39;John&#39;) IF NOT EXISTS&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ifExists&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].filter(p =&amp;gt; p.name == &#34;John&#34;).delete.ifExists&#xA;}&#xA;ctx.run(q)&#xA;// DELETE FROM Person WHERE name = &#39;John&#39; IF EXISTS&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;usingTimestamp&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q1 = quote {&#xA;  query[Person].insert(_.age -&amp;gt; 10, _.name -&amp;gt; &#34;John&#34;).usingTimestamp(99)&#xA;}&#xA;ctx.run(q1)&#xA;// INSERT INTO Person (age,name) VALUES (10, &#39;John&#39;) USING TIMESTAMP 99&#xA;&#xA;val q2 = quote {&#xA;  query[Person].usingTimestamp(99).update(_.age -&amp;gt; 10)&#xA;}&#xA;ctx.run(q2)&#xA;// UPDATE Person USING TIMESTAMP 99 SET age = 10&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;usingTtl&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q1 = quote {&#xA;  query[Person].insert(_.age -&amp;gt; 10, _.name -&amp;gt; &#34;John&#34;).usingTtl(11)&#xA;}&#xA;ctx.run(q1)&#xA;// INSERT INTO Person (age,name) VALUES (10, &#39;John&#39;) USING TTL 11&#xA;&#xA;val q2 = quote {&#xA;  query[Person].usingTtl(11).update(_.age -&amp;gt; 10)&#xA;}&#xA;ctx.run(q2)&#xA;// UPDATE Person USING TTL 11 SET age = 10&#xA;&#xA;val q3 = quote {&#xA;  query[Person].usingTtl(11).filter(_.name == &#34;John&#34;).delete&#xA;}&#xA;ctx.run(q3)&#xA;// DELETE FROM Person USING TTL 11 WHERE name = &#39;John&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;using&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q1 = quote {&#xA;  query[Person].insert(_.age -&amp;gt; 10, _.name -&amp;gt; &#34;John&#34;).using(ts = 99, ttl = 11)&#xA;}&#xA;ctx.run(q1)&#xA;// INSERT INTO Person (age,name) VALUES (10, &#39;John&#39;) USING TIMESTAMP 99 AND TTL 11&#xA;&#xA;val q2 = quote {&#xA;  query[Person].using(ts = 99, ttl = 11).update(_.age -&amp;gt; 10)&#xA;}&#xA;ctx.run(q2)&#xA;// UPDATE Person USING TIMESTAMP 99 AND TTL 11 SET age = 10&#xA;&#xA;val q3 = quote {&#xA;  query[Person].using(ts = 99, ttl = 11).filter(_.name == &#34;John&#34;).delete&#xA;}&#xA;ctx.run(q3)&#xA;// DELETE FROM Person USING TIMESTAMP 99 AND TTL 11 WHERE name = &#39;John&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ifCond&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q1 = quote {&#xA;  query[Person].update(_.age -&amp;gt; 10).ifCond(_.name == &#34;John&#34;)&#xA;}&#xA;ctx.run(q1)&#xA;// UPDATE Person SET age = 10 IF name = &#39;John&#39;&#xA;&#xA;val q2 = quote {&#xA;  query[Person].filter(_.name == &#34;John&#34;).delete.ifCond(_.age == 10)&#xA;}&#xA;ctx.run(q2)&#xA;// DELETE FROM Person WHERE name = &#39;John&#39; IF age = 10&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;delete column&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person].map(p =&amp;gt; p.age).delete&#xA;}&#xA;ctx.run(q)&#xA;// DELETE p.age FROM Person&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;list.contains / set.contains&lt;/h3&gt; &#xA;&lt;p&gt;requires &lt;code&gt;allowFiltering&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Book].filter(p =&amp;gt; p.pages.contains(25)).allowFiltering&#xA;}&#xA;ctx.run(q)&#xA;// SELECT id, notes, pages, history FROM Book WHERE pages CONTAINS 25 ALLOW FILTERING&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;map.contains&lt;/h3&gt; &#xA;&lt;p&gt;requires &lt;code&gt;allowFiltering&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Book].filter(p =&amp;gt; p.history.contains(12)).allowFiltering&#xA;}&#xA;ctx.run(q)&#xA;// SELECT id, notes, pages, history FROM book WHERE history CONTAINS 12 ALLOW FILTERING&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;map.containsValue&lt;/h3&gt; &#xA;&lt;p&gt;requires &lt;code&gt;allowFiltering&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Book].filter(p =&amp;gt; p.history.containsValue(true)).allowFiltering&#xA;}&#xA;ctx.run(q)&#xA;// SELECT id, notes, pages, history FROM book WHERE history CONTAINS true ALLOW FILTERING&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Dynamic queries&lt;/h2&gt; &#xA;&lt;p&gt;Quill&#39;s default operation mode is compile-time, but there are queries that have their structure defined only at runtime. Quill automatically falls back to runtime normalization and query generation if the query&#39;s structure is not static. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new SqlMirrorContext(MirrorSqlDialect, Literal)&#xA;&#xA;import ctx._&#xA;&#xA;sealed trait QueryType&#xA;case object Minor extends QueryType&#xA;case object Senior extends QueryType&#xA;&#xA;def people(t: QueryType): Quoted[Query[Person]] =&#xA;  t match {&#xA;    case Minor =&amp;gt; quote {&#xA;      query[Person].filter(p =&amp;gt; p.age &amp;lt; 18)&#xA;    }&#xA;    case Senior =&amp;gt; quote {&#xA;      query[Person].filter(p =&amp;gt; p.age &amp;gt; 65)&#xA;    }&#xA;  }&#xA;&#xA;ctx.run(people(Minor))&#xA;// SELECT p.id, p.name, p.age FROM Person p WHERE p.age &amp;lt; 18&#xA;&#xA;ctx.run(people(Senior))&#xA;// SELECT p.id, p.name, p.age FROM Person p WHERE p.age &amp;gt; 65&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dynamic query API&lt;/h3&gt; &#xA;&lt;p&gt;Additionally, Quill provides a separate query API to facilitate the creation of dynamic queries. This API allows users to easily manipulate quoted values instead of working only with quoted transformations.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: A few of the dynamic query methods accept runtime string values. It&#39;s important to keep in mind that these methods could be a vector for SQL injection.&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s use the &lt;code&gt;filter&lt;/code&gt; transformation as an example. In the regular API, this method has no implementation since it&#39;s an abstract member of a trait:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;def filter(f: T =&amp;gt; Boolean): EntityQuery[T]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the dynamic API, &lt;code&gt;filter&lt;/code&gt; is has a different signature and a body that is executed at runtime:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;def filter(f: Quoted[T] =&amp;gt; Quoted[Boolean]): DynamicQuery[T] =&#xA;  transform(f, Filter)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It takes a &lt;code&gt;Quoted[T]&lt;/code&gt; as input and produces a &lt;code&gt;Quoted[Boolean]&lt;/code&gt;. The user is free to use regular scala code within the transformation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def people(onlyMinors: Boolean) =&#xA;  dynamicQuery[Person].filter(p =&amp;gt; if(onlyMinors) quote(p.age &amp;lt; 18) else quote(true))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In order to create a dynamic query, use one of the following methods:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;dynamicQuery[Person]&#xA;dynamicQuerySchema[Person](&#34;people&#34;, alias(_.name, &#34;pname&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It&#39;s also possible to transform a &lt;code&gt;Quoted&lt;/code&gt; into a dynamic query:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Person]&#xA;}&#xA;q.dynamic.filter(p =&amp;gt; quote(p.name == &#34;John&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The dynamic query API is very similar to the regular API but has a few differences:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Queries&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// schema queries use `alias` instead of tuples&#xA;dynamicQuerySchema[Person](&#34;people&#34;, alias(_.name, &#34;pname&#34;))&#xA;&#xA;// this allows users to use a dynamic list of aliases&#xA;val aliases = List(alias[Person](_.name, &#34;pname&#34;), alias[Person](_.age, &#34;page&#34;))&#xA;dynamicQuerySchema[Person](&#34;people&#34;, aliases:_*)&#xA;&#xA;// a few methods have an overload with the `Opt` suffix,&#xA;// which apply the transformation only if the option is defined:&#xA;&#xA;def people(minAge: Option[Int]) =&#xA;  dynamicQuery[Person].filterOpt(minAge)((person, minAge) =&amp;gt; quote(person.age &amp;gt;= minAge))&#xA;&#xA;def people(maxRecords: Option[Int]) =&#xA;  dynamicQuery[Person].takeOpt(maxRecords)&#xA;&#xA;def people(dropFirst: Option[Int]) =&#xA;  dynamicQuery[Person].dropOpt(dropFirst)&#xA;&#xA;// method with `If` suffix, for better chaining&#xA;def people(userIds: Seq[Int]) =&#xA;  dynamicQuery[Person].filterIf(userIds.nonEmpty)(person =&amp;gt; quote(liftQuery(userIds).contains(person.id)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Actions&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// actions use `set`&#xA;dynamicQuery[Person].filter(_.id == 1).update(set(_.name, quote(&#34;John&#34;)))&#xA;&#xA;// or `setValue` if the value is not quoted&#xA;dynamicQuery[Person].insert(setValue(_.name, &#34;John&#34;))&#xA;&#xA;// or `setOpt` that will be applied only the option is defined&#xA;dynamicQuery[Person].insert(setOpt(_.name, Some(&#34;John&#34;)))&#xA;&#xA;// it&#39;s also possible to use a runtime string value as the column name&#xA;dynamicQuery[Person].filter(_.id == 1).update(set(&#34;name&#34;, quote(&#34;John&#34;)))&#xA;&#xA;// to insert or update a case class instance, use `insertValue`/`updateValue`&#xA;val p = Person(0, &#34;John&#34;, 21)&#xA;dynamicQuery[Person].insertValue(p)&#xA;dynamicQuery[Person].filter(_.id == 1).updateValue(p)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dynamic query normalization cache&lt;/h3&gt; &#xA;&lt;p&gt;Quill is super fast for static queries (almost zero runtime overhead compared to directly sql executing).&lt;/p&gt; &#xA;&lt;p&gt;But there is significant impact for dynamic queries.&lt;/p&gt; &#xA;&lt;p&gt;Normalization caching was introduced to improve the situation, which will speedup dynamic queries significantly. It is enabled by default.&lt;/p&gt; &#xA;&lt;p&gt;To disable dynamic normalization caching, pass following property to sbt during compile time&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sbt -Dquill.query.cacheDaynamic=false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Extending quill&lt;/h1&gt; &#xA;&lt;h2&gt;Infix&lt;/h2&gt; &#xA;&lt;p&gt;Infix is a very flexible mechanism to use non-supported features without having to use plain queries in the target language. It allows the insertion of arbitrary strings within quotations.&lt;/p&gt; &#xA;&lt;p&gt;For instance, quill doesn&#39;t support the &lt;code&gt;FOR UPDATE&lt;/code&gt; SQL feature. It can still be used through infix and implicit classes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit class ForUpdate[T](q: Query[T]) {&#xA;  def forUpdate = quote(infix&#34;$q FOR UPDATE&#34;.as[Query[T]])&#xA;}&#xA;&#xA;val a = quote {&#xA;  query[Person].filter(p =&amp;gt; p.age &amp;lt; 18).forUpdate&#xA;}&#xA;&#xA;ctx.run(a)&#xA;// SELECT p.name, p.age FROM person p WHERE p.age &amp;lt; 18 FOR UPDATE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;forUpdate&lt;/code&gt; quotation can be reused for multiple queries.&lt;/p&gt; &#xA;&lt;p&gt;Queries that contain &lt;code&gt;infix&lt;/code&gt; will generally not be flattened since it is not assumed that the contents of the infix are a pure function.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Since SQL is typically less performant when there are many nested queries, be careful with the use of &lt;code&gt;infix&lt;/code&gt; in queries that have multiple &lt;code&gt;map&lt;/code&gt;+&lt;code&gt;filter&lt;/code&gt; clauses.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Data(id: Int)&#xA;case class DataAndRandom(id: Int, value: Int)&#xA;&#xA;// This should be alright:&#xA;val q = quote {&#xA;  query[Data].map(e =&amp;gt; DataAndRandom(e.id, infix&#34;RAND()&#34;.as[Int])).filter(r =&amp;gt; r.value &amp;lt;= 10)&#xA;}&#xA;run(q)&#xA;// SELECT e.id, e.value FROM (SELECT RAND() AS value, e.id AS id FROM Data e) AS e WHERE e.value &amp;lt;= 10&#xA;&#xA;// This might not be:&#xA;val q = quote {&#xA;  query[Data]&#xA;    .map(e =&amp;gt; DataAndRandom(e.id, infix&#34;SOME_UDF(${e.id})&#34;.as[Int]))&#xA;    .filter(r =&amp;gt; r.value &amp;lt;= 10)&#xA;    .map(e =&amp;gt; DataAndRandom(e.id, infix&#34;SOME_OTHER_UDF(${e.value})&#34;.as[Int]))&#xA;    .filter(r =&amp;gt; r.value &amp;lt;= 100)&#xA;}&#xA;// Produces too many layers of nesting!&#xA;run(q)&#xA;// SELECT e.id, e.value FROM (&#xA;//   SELECT SOME_OTHER_UDF(e.value) AS value, e.id AS id FROM (&#xA;//     SELECT SOME_UDF(e.id) AS value, e.id AS id FROM Data e&#xA;//   ) AS e WHERE e.value &amp;lt;= 10&#xA;// ) AS e WHERE e.value &amp;lt;= 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are sure that the the content of your infix is a pure function, you canse use the &lt;code&gt;pure&lt;/code&gt; method in order to indicate to Quill that the infix clause can be copied in the query. This gives Quill much more leeway to flatten your query, possibly improving performance.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q = quote {&#xA;  query[Data]&#xA;    .map(e =&amp;gt; DataAndRandom(e.id, infix&#34;SOME_UDF(${e.id})&#34;.pure.as[Int]))&#xA;    .filter(r =&amp;gt; r.value &amp;lt;= 10)&#xA;    .map(e =&amp;gt; DataAndRandom(e.id, infix&#34;SOME_OTHER_UDF(${e.value})&#34;.pure.as[Int]))&#xA;    .filter(r =&amp;gt; r.value &amp;lt;= 100)&#xA;}&#xA;// Copying SOME_UDF and SOME_OTHER_UDF allows the query to be completely flattened.&#xA;run(q)&#xA;// SELECT e.id, SOME_OTHER_UDF(SOME_UDF(e.id)) FROM Data e&#xA;// WHERE SOME_UDF(e.id) &amp;lt;= 10 AND SOME_OTHER_UDF(SOME_UDF(e.id)) &amp;lt;= 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Infixes With Conditions&lt;/h3&gt; &#xA;&lt;h4&gt;Summary&lt;/h4&gt; &#xA;&lt;p&gt;Use &lt;code&gt;infix&#34;...&#34;.asCondition&lt;/code&gt; to express an infix that represents a conditional expression.&lt;/p&gt; &#xA;&lt;h4&gt;Explination&lt;/h4&gt; &#xA;&lt;p&gt;When synthesizing queries for databases which do not have proper boolean-type support (e.g. SQL Server, Oracle etc...) boolean infix clauses inside projections must become values. Typically this requires a &lt;code&gt;CASE WHERE ... END&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Take the following example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Node(name: String, isUp: Boolean, uptime:Long)&#xA;case class Status(name: String, allowed: Boolean)&#xA;val allowedStatus:Boolean = getState&#xA;&#xA;quote {&#xA;  query[Node].map(n =&amp;gt; Status(n.name, n.isUp == lift(allowedStatus)))&#xA;}&#xA;run(q)&#xA;// This is invalid in most databases:&#xA;//   SELECT n.name, n.isUp = ?, uptime FROM Node n&#xA;// It will be converted to this:&#xA;//   SELECT n.name, CASE WHEN (n.isUp = ?) THEN 1 ELSE 0, uptime FROM Node n&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;However, in certain cases, infix clauses that express conditionals should actually represent boolean expressions for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Node(name: String, isUp: Boolean)&#xA;val maxUptime:Boolean = getState&#xA;&#xA;quote {&#xA;  query[Node].filter(n =&amp;gt; infix&#34;${n.uptime} &amp;gt; ${lift(maxUptime)}&#34;.as[Boolean])&#xA;}&#xA;run(q)&#xA;// Should be this:&#xA;//  SELECT n.name, n.isUp, n.uptime WHERE n.uptime &amp;gt; ?&#xA;// However since infix&#34;...&#34;.as[Boolean] is treated as a Boolean Value (as opposed to an expression) it will be converted to this:&#xA;//  SELECT n.name, n.isUp, n.uptime WHERE 1 == n.uptime &amp;gt; ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In order to avoid this problem, use infix&#34;...&#34;.asCondition so that Quill understands that the boolean is an expression:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;quote {&#xA;  query[Node].filter(n =&amp;gt; infix&#34;${n.uptime} &amp;gt; ${lift(maxUptime)}&#34;.asCondition)&#xA;}&#xA;run(q) // SELECT n.name, n.isUp, n.uptime WHERE n.uptime &amp;gt; ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dynamic infix&lt;/h3&gt; &#xA;&lt;p&gt;Infix supports runtime string values through the &lt;code&gt;#$&lt;/code&gt; prefix. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def test(functionName: String) =&#xA;  ctx.run(query[Person].map(p =&amp;gt; infix&#34;#$functionName(${p.name})&#34;.as[Int]))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Implicit Extensions&lt;/h3&gt; &#xA;&lt;p&gt;You can use implicit extensions in quill in several ways.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;NOTE. In ProtoQuill extensions must be written using the Scala 3 &lt;code&gt;extension&lt;/code&gt; syntax and implicit class extensions are not supported. Please see &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#extensions-in-protoquillscala3&#34;&gt;Extensions in ProtoQuill/Scala3&lt;/a&gt; below for more info.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h5&gt;Standard quoted extension:&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit class Ext(q: Query[Person]) {&#xA;  def olderThan(age: Int) = quote {&#xA;    query[Person].filter(p =&amp;gt; p.age &amp;gt; lift(age))&#xA;  }&#xA;}&#xA;run(query[Person].olderThan(44))&#xA;// SELECT p.name, p.age FROM Person p WHERE p.age &amp;gt; ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Higher-order quoted extension:&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit class Ext(q: Query[Person]) {&#xA;  def olderThan = quote {&#xA;    (age: Int) =&amp;gt;&#xA;      query[Person].filter(p =&amp;gt; p.age &amp;gt; lift(age))&#xA;  }&#xA;}&#xA;run(query[Person].olderThan(44))&#xA;// SELECT p.name, p.age FROM Person p WHERE p.age &amp;gt; 44&#xA;&#xA;run(query[Person].olderThan(lift(44)))&#xA;// SELECT p.name, p.age FROM Person p WHERE p.age &amp;gt; ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The advantage of this approach is that you can choose to either lift or use a constant.&lt;/p&gt; &#xA;&lt;h5&gt;Scalar quoted extension:&lt;/h5&gt; &#xA;&lt;p&gt;Just as &lt;code&gt;Query&lt;/code&gt; can be extended, scalar values can be similarly extended.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit class Ext(i: Int) {&#xA;  def between = quote {&#xA;    (a: Int, b:Int) =&amp;gt;&#xA;      i &amp;gt; a &amp;amp;&amp;amp; i &amp;lt; b&#xA;  }&#xA;}&#xA;run(query[Person].filter(p =&amp;gt; p.age.between(33, 44)))&#xA;// SELECT p.name, p.age FROM Person p WHERE p.age &amp;gt; 33 AND p.age &amp;lt; 44&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Extensions in ProtoQuill/Scala3:&lt;/h5&gt; &#xA;&lt;p&gt;In ProtoQuill, the implicit class pattern for extensions is not supported. Please switch to using Scala 3 extension methods combined with inline definitions to achieve the same functionality.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;extension (q: Query[Person]) {&#xA;  inline def olderThan(inline age: Int) = quote {&#xA;    query[Person].filter(p =&amp;gt; p.age &amp;gt; lift(age))&#xA;  }&#xA;}&#xA;run(query[Person].olderThan(44))&#xA;// SELECT p.name, p.age FROM Person p WHERE p.age &amp;gt; ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Raw SQL queries&lt;/h3&gt; &#xA;&lt;p&gt;You can also use infix to port raw SQL queries to Quill and map it to regular Scala tuples.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val rawQuery = quote {&#xA;  (id: Int) =&amp;gt; infix&#34;&#34;&#34;SELECT id, name FROM my_entity WHERE id = $id&#34;&#34;&#34;.as[Query[(Int, String)]]&#xA;}&#xA;ctx.run(rawQuery(1))&#xA;//SELECT x._1, x._2 FROM (SELECT id AS &#34;_1&#34;, name AS &#34;_2&#34; FROM my_entity WHERE id = 1) x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that in this case the result query is nested. It&#39;s required since Quill is not aware of a query tree and cannot safely unnest it. This is different from the example above because infix starts with the query &lt;code&gt;infix&#34;$q...&lt;/code&gt; where its tree is already compiled&lt;/p&gt; &#xA;&lt;h3&gt;Database functions&lt;/h3&gt; &#xA;&lt;p&gt;A custom database function can also be used through infix:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val myFunction = quote {&#xA;  (i: Int) =&amp;gt; infix&#34;MY_FUNCTION($i)&#34;.as[Int]&#xA;}&#xA;&#xA;val q = quote {&#xA;  query[Person].map(p =&amp;gt; myFunction(p.age))&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT MY_FUNCTION(p.age) FROM Person p&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Comparison operators&lt;/h3&gt; &#xA;&lt;p&gt;You can implement comparison operators by defining implicit conversion and using infix.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import java.util.Date&#xA;&#xA;implicit class DateQuotes(left: Date) {&#xA;  def &amp;gt;(right: Date) = quote(infix&#34;$left &amp;gt; $right&#34;.as[Boolean])&#xA;&#xA;  def &amp;lt;(right: Date) = quote(infix&#34;$left &amp;lt; $right&#34;.as[Boolean])&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;batch with infix&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit class OnDuplicateKeyIgnore[T](q: Insert[T]) {&#xA;  def ignoreDuplicate = quote(infix&#34;$q ON DUPLICATE KEY UPDATE id=id&#34;.as[Insert[T]])&#xA;}&#xA;&#xA;ctx.run(&#xA;  liftQuery(List(&#xA;    Person(1, &#34;Test1&#34;, 30),&#xA;    Person(2, &#34;Test2&#34;, 31)&#xA;  )).foreach(row =&amp;gt; query[Person].insertValue(row).ignoreDuplicate)&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Custom encoding&lt;/h2&gt; &#xA;&lt;p&gt;Quill uses &lt;code&gt;Encoder&lt;/code&gt;s to encode query inputs and &lt;code&gt;Decoder&lt;/code&gt;s to read values returned by queries. The library provides a few built-in encodings and two mechanisms to define custom encodings: mapped encoding and raw encoding.&lt;/p&gt; &#xA;&lt;h3&gt;Mapped Encoding&lt;/h3&gt; &#xA;&lt;p&gt;If the correspondent database type is already supported, use &lt;code&gt;MappedEncoding&lt;/code&gt;. In this example, &lt;code&gt;String&lt;/code&gt; is already supported by Quill and the &lt;code&gt;UUID&lt;/code&gt; encoding from/to &lt;code&gt;String&lt;/code&gt; is defined through mapped encoding:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import ctx._&#xA;import java.util.UUID&#xA;&#xA;implicit val encodeUUID = MappedEncoding[UUID, String](_.toString)&#xA;implicit val decodeUUID = MappedEncoding[String, UUID](UUID.fromString(_))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A mapped encoding also can be defined without a context instance by importing &lt;code&gt;io.getquill.MappedEncoding&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import io.getquill.MappedEncoding&#xA;import java.util.UUID&#xA;&#xA;implicit val encodeUUID = MappedEncoding[UUID, String](_.toString)&#xA;implicit val decodeUUID = MappedEncoding[String, UUID](UUID.fromString(_))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that can it be also used to provide mapping for element types of collection (SQL Arrays or Cassandra Collections).&lt;/p&gt; &#xA;&lt;h3&gt;Raw Encoding&lt;/h3&gt; &#xA;&lt;p&gt;If the database type is not supported by Quill, it is possible to provide &#34;raw&#34; encoders and decoders:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;trait UUIDEncodingExample {&#xA;  val jdbcContext: PostgresJdbcContext[Literal] // your context should go here&#xA;&#xA;  import jdbcContext._&#xA;&#xA;  implicit val uuidDecoder: Decoder[UUID] =&#xA;    decoder((index, row) =&amp;gt;&#xA;      UUID.fromString(row.getObject(index).toString)) // database-specific implementation&#xA;&#xA;  implicit val uuidEncoder: Encoder[UUID] =&#xA;    encoder(java.sql.Types.OTHER, (index, value, row) =&amp;gt;&#xA;        row.setObject(index, value, java.sql.Types.OTHER)) // database-specific implementation&#xA;&#xA;  // Only for postgres&#xA;  implicit def arrayUUIDEncoder[Col &amp;lt;: Seq[UUID]]: Encoder[Col] = arrayRawEncoder[UUID, Col](&#34;uuid&#34;)&#xA;  implicit def arrayUUIDDecoder[Col &amp;lt;: Seq[UUID]](implicit bf: CBF[UUID, Col]): Decoder[Col] =&#xA;    arrayRawDecoder[UUID, Col]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;code&gt;AnyVal&lt;/code&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Quill automatically encodes &lt;code&gt;AnyVal&lt;/code&gt;s (value classes):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class UserId(value: Int) extends AnyVal&#xA;case class User(id: UserId, name: String)&#xA;&#xA;val q = quote {&#xA;  for {&#xA;    u &amp;lt;- query[User] if u.id == lift(UserId(1))&#xA;  } yield u&#xA;}&#xA;&#xA;ctx.run(q)&#xA;// SELECT u.id, u.name FROM User u WHERE (u.id = 1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Table/Column Customizations&lt;/h2&gt; &#xA;&lt;p&gt;The meta DSL allows the user to customize how Quill handles column/table naming and behavior.&lt;/p&gt; &#xA;&lt;h3&gt;Changing Table and Column Names&lt;/h3&gt; &#xA;&lt;p&gt;You can change how Quill queries handle table and column names for a record case class.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def example = {&#xA;  implicit val personSchemaMeta = schemaMeta[Person](&#34;people&#34;, _.id -&amp;gt; &#34;person_id&#34;)&#xA;&#xA;  ctx.run(query[Person])&#xA;  // SELECT x.person_id, x.name, x.age FROM people x&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, quill expands &lt;code&gt;query[Person]&lt;/code&gt; to &lt;code&gt;querySchema[Person](&#34;Person&#34;)&lt;/code&gt;. It&#39;s possible to customize this behavior using an implicit instance of &lt;code&gt;SchemaMeta&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;h3&gt;Excluding Columns from Insert&lt;/h3&gt; &#xA;&lt;p&gt;You can exclude columns (e.g. Auto-Generated ones) from insertion in &lt;code&gt;q.insertValue(...)&lt;/code&gt; by using an &lt;code&gt;InsertMeta&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit val personInsertMeta = insertMeta[Person](_.id)&#xA;&#xA;ctx.run(query[Person].insertValue(lift(Person(-1, &#34;John&#34;, 22))))&#xA;// INSERT INTO Person (name,age) VALUES (?, ?)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the parameter of &lt;code&gt;insertMeta&lt;/code&gt; is called &lt;code&gt;exclude&lt;/code&gt;, but it isn&#39;t possible to use named parameters for macro invocations.&lt;/p&gt; &#xA;&lt;h3&gt;Excluding Columns from Update&lt;/h3&gt; &#xA;&lt;p&gt;You can exclude columns (e.g. Auto-Generated ones) from updates in &lt;code&gt;q.insertValue(...)&lt;/code&gt; by using an &lt;code&gt;UpdateMeta&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit val personUpdateMeta = updateMeta[Person](_.id)&#xA;&#xA;ctx.run(query[Person].filter(_.id == 1).updateValue(lift(Person(1, &#34;John&#34;, 22))))&#xA;// UPDATE Person SET name = ?, age = ? WHERE id = 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the parameter of &lt;code&gt;updateMeta&lt;/code&gt; is called &lt;code&gt;exclude&lt;/code&gt;, but it isn&#39;t possible to use named parameters for macro invocations.&lt;/p&gt; &#xA;&lt;h2&gt;Mapped Records&lt;/h2&gt; &#xA;&lt;p&gt;The QueryMeta customizes the expansion of query types and extraction of the final value. For instance, it&#39;s possible to use this feature to normalize values before reading them from the database:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;implicit val personQueryMeta =&#xA;  queryMeta(&#xA;    (q: Query[Person]) =&amp;gt;&#xA;      q.map(p =&amp;gt; (p.id, infix&#34;CONVERT(${p.name} USING utf8)&#34;.as[String], p.age))&#xA;  ) {&#xA;    case (id, name, age) =&amp;gt;&#xA;      Person(id, name, age)&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The query meta definition is open and allows the user to even join values from other tables before reading the final value. This kind of usage is not encouraged.&lt;/p&gt; &#xA;&lt;h1&gt;Contexts&lt;/h1&gt; &#xA;&lt;p&gt;Contexts represent the database and provide an execution interface for queries.&lt;/p&gt; &#xA;&lt;h2&gt;Mirror context&lt;/h2&gt; &#xA;&lt;p&gt;Quill provides a mirror context for testing purposes. Instead of running the query, the mirror context returns a structure with the information that would be used to run the query. There are three mirror context instances:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;io.getquill.MirrorContext&lt;/code&gt;: Mirrors the quotation AST&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;io.getquill.SqlMirrorContext&lt;/code&gt;: Mirrors the SQL query&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;io.getquill.CassandraMirrorContext&lt;/code&gt;: Mirrors the CQL query&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Dependent contexts&lt;/h2&gt; &#xA;&lt;p&gt;The context instance provides all methods and types to interact with quotations and the database. Depending on how the context import happens, Scala won&#39;t be able to infer that the types are compatible.&lt;/p&gt; &#xA;&lt;p&gt;For instance, this example &lt;strong&gt;will not&lt;/strong&gt; compile:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;class MyContext extends SqlMirrorContext(MirrorSqlDialect, Literal)&#xA;&#xA;case class MySchema(c: MyContext) {&#xA;&#xA;  import c._&#xA;  val people = quote {&#xA;    querySchema[Person](&#34;people&#34;)&#xA;  }&#xA;}&#xA;&#xA;case class MyDao(c: MyContext, schema: MySchema) {&#xA;&#xA;  def allPeople =&#xA;    c.run(schema.people)&#xA;// ERROR: [T](quoted: MyDao.this.c.Quoted[MyDao.this.c.Query[T]])MyDao.this.c.QueryResult[T]&#xA; cannot be applied to (MyDao.this.schema.c.Quoted[MyDao.this.schema.c.EntityQuery[Person]]{def quoted: io.getquill.ast.ConfiguredEntity; def ast: io.getquill.ast.ConfiguredEntity; def id1854281249(): Unit; val bindings: Object})&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;In ProtoQuill/Scala3 the above pattern will work as expected because the types Quoted, EntityQuery, etc... are no longer path dependent. Have a look at the following &lt;a href=&#34;https://scastie.scala-lang.org/TO5dF87jQQegUGqmIQtbew&#34;&gt;scastie example&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Context Traits&lt;/h3&gt; &#xA;&lt;p&gt;One way to compose applications with this kind of context is to use traits with an abstract context variable:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;class MyContext extends SqlMirrorContext(MirrorSqlDialect, Literal)&#xA;&#xA;trait MySchema {&#xA;&#xA;  val c: MyContext&#xA;  import c._&#xA;&#xA;  val people = quote {&#xA;    querySchema[Person](&#34;people&#34;)&#xA;  }&#xA;}&#xA;&#xA;case class MyDao(c: MyContext) extends MySchema {&#xA;  import c._&#xA;&#xA;  def allPeople =&#xA;    c.run(people)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Modular Contexts&lt;/h3&gt; &#xA;&lt;p&gt;Another simple way to modularize Quill code is by extending &lt;code&gt;Context&lt;/code&gt; as a self-type and applying mixins. Using this strategy, it is possible to create functionality that is fully portable across databases and even different types of databases (e.g. creating common queries for both Postgres and Spark).&lt;/p&gt; &#xA;&lt;p&gt;For example, create the following abstract context:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;trait ModularContext[I &amp;lt;: Idiom, N &amp;lt;: NamingStrategy] { this: Context[I, N] =&amp;gt;&#xA;  def peopleOlderThan = quote {&#xA;    (age:Int, q:Query[Person]) =&amp;gt; q.filter(p =&amp;gt; p.age &amp;gt; age)&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Let&#39;s see how this can be used across different kinds of databases and Quill contexts.&lt;/p&gt; &#xA;&lt;h4&gt;Use &lt;code&gt;ModularContext&lt;/code&gt; in a mirror context:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Note: In some cases need to explicitly specify [MirrorSqlDialect, Literal].&#xA;val ctx =&#xA;  new SqlMirrorContext[MirrorSqlDialect, Literal](MirrorSqlDialect, Literal)&#xA;    with ModularContext[MirrorSqlDialect, Literal]&#xA;&#xA;import ctx._&#xA;println( run(peopleOlderThan(22, query[Person])).string )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Use &lt;code&gt;ModularContext&lt;/code&gt; to query a Postgres Database&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx =&#xA;  new PostgresJdbcContext[Literal](Literal, ds)&#xA;    with ModularContext[PostgresDialect, Literal]&#xA;&#xA;import ctx._&#xA;val results = run(peopleOlderThan(22, query[Person]))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Use &lt;code&gt;ModularContext&lt;/code&gt; to query a Spark Dataset&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;object CustomQuillSparkContext extends QuillSparkContext&#xA;  with ModularContext[SparkDialect, Literal]&#xA;&#xA;val results = run(peopleOlderThan(22, liftQuery(dataset)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Spark Integration&lt;/h2&gt; &#xA;&lt;p&gt;Quill provides a fully type-safe way to use Spark&#39;s highly-optimized SQL engine. It&#39;s an alternative to &lt;code&gt;Dataset&lt;/code&gt;&#39;s weakly-typed API.&lt;/p&gt; &#xA;&lt;h3&gt;Importing Quill Spark&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-spark&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Unlike the other modules, the Spark context is a companion object. Also, it does not depend on a spark session. To use it, add the following import:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.apache.spark.sql.SparkSession&#xA;&#xA;// Create your Spark Context&#xA;val session =&#xA;  SparkSession.builder()&#xA;    .master(&#34;local&#34;)&#xA;    .appName(&#34;spark test&#34;)&#xA;    .getOrCreate()&#xA;&#xA;// The Spark SQL Context must be provided by the user through an implicit value:&#xA;implicit val sqlContext = session&#xA;import sqlContext.implicits._      // Also needed...&#xA;&#xA;// Import the Quill Spark Context&#xA;import io.getquill.QuillSparkContext._&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note Unlike the other modules, the Spark context is a companion object. Also, it does not depend on a spark session.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Also Note: Quill decoders and meta instances are not used by the quill-spark module, Spark&#39;s &lt;code&gt;Encoder&lt;/code&gt;s are used instead.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Using Quill-Spark&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;run&lt;/code&gt; method returns a &lt;code&gt;Dataset&lt;/code&gt; transformed by the Quill query using the SQL engine.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Typically you start with some type dataset.&#xA;val peopleDS: Dataset[Person] = spark.read.parquet(&#34;path/to/people&#34;)&#xA;val addressesDS: Dataset[Address] = spark.read.parquet(&#34;path/to/addresses&#34;)&#xA;&#xA;// The liftQuery method converts Datasets to Quill queries:&#xA;val people: Query[Person] = quote { liftQuery(peopleDS) }&#xA;val addresses: Query[Address] = quote { liftQuery(addressesDS) }&#xA;&#xA;val people: Query[(Person] = quote {&#xA;  people.join(addresses).on((p, a) =&amp;gt; p.id == a.ownerFk)&#xA;}&#xA;&#xA;val peopleAndAddressesDS: Dataset[(Person, Address)] = run(people)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Simplify it&lt;/h4&gt; &#xA;&lt;p&gt;Since the &lt;code&gt;run&lt;/code&gt; method allows for Quill queries to be specified directly, and &lt;code&gt;liftQuery&lt;/code&gt; can be used inside of any Quoted block, you can shorten various steps of the above workflow:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val peopleDS: Dataset[Person] = spark.read.parquet(&#34;path/to/people&#34;)&#xA;val addressesDS: Dataset[Address] = spark.read.parquet(&#34;path/to/addresses&#34;)&#xA;&#xA;val peopleAndAddressesDS: Dataset[(Person, Address)] = run {&#xA;  liftQuery(peopleDS)&#xA;    .join(liftQuery(addressesDS))&#xA;    .on((p, a) =&amp;gt; p.id == a.ownerFk)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here is an example of a Dataset being converted into Quill, filtered, and then written back out.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.apache.spark.sql.Dataset&#xA;&#xA;def filter(myDataset: Dataset[Person], name: String): Dataset[Int] =&#xA;  run {&#xA;    liftQuery(myDataset).filter(_.name == lift(name)).map(_.age)&#xA;  }&#xA;// SELECT x1.age _1 FROM (?) x1 WHERE x1.name = ?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Workflow&lt;/h4&gt; &#xA;&lt;p&gt;Due to the design of Quill-Spark, it can be used interchangeably throughout your Spark workflow:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lift a Dataset to Query to do some filtering and sub-selecting (with &lt;a href=&#34;https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-Optimizer-PushDownPredicate.html&#34;&gt;Predicate and Filter Pushdown!&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Then covert it back to a Dataset to do Spark-Specific operations.&lt;/li&gt; &#xA; &lt;li&gt;Then convert it back to a Query to use Quills great Join DSL...&lt;/li&gt; &#xA; &lt;li&gt;Then convert it back to a Dataset to write it to a file or do something else with it...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Custom Functions&lt;/h3&gt; &#xA;&lt;p&gt;TODO UDFs and UDAFs&lt;/p&gt; &#xA;&lt;h3&gt;Restrictions&lt;/h3&gt; &#xA;&lt;h4&gt;Top Level Classes&lt;/h4&gt; &#xA;&lt;p&gt;Spark only supports using top-level classes as record types. That means that when using &lt;code&gt;quill-spark&lt;/code&gt; you can only use a top-level case class for &lt;code&gt;T&lt;/code&gt; in &lt;code&gt;Query[T]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;TODO Get the specific error&lt;/p&gt; &#xA;&lt;h4&gt;Lifted Variable Interpolation&lt;/h4&gt; &#xA;&lt;p&gt;The queries printed from &lt;code&gt;run(myQuery)&lt;/code&gt; during compile time escape question marks via a backslash them in order to be able to substitute liftings properly. They are then returned back to their original form before running.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.apache.spark.sql.Dataset&#xA;&#xA;def filter(myDataset: Dataset[Person]): Dataset[Int] =&#xA;  run {&#xA;    liftQuery(myDataset).filter(_.name == &#34;?&#34;).map(_.age)&#xA;  }&#xA;// This is generated during compile time:&#xA;// SELECT x1.age _1 FROM (?) x1 WHERE x1.name = &#39;\?&#39;&#xA;// It is reverted upon run-time:&#xA;// SELECT x1.age _1 FROM (ds1) x1 WHERE x1.name = &#39;?&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;SQL Contexts&lt;/h2&gt; &#xA;&lt;p&gt;Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new MysqlJdbcContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dialect&lt;/h3&gt; &#xA;&lt;p&gt;The SQL dialect parameter defines the specific database dialect to be used. Some context types are specific to a database and thus not require it.&lt;/p&gt; &#xA;&lt;p&gt;Quill has five built-in dialects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;io.getquill.H2Dialect&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;io.getquill.MySQLDialect&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;io.getquill.PostgresDialect&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;io.getquill.SqliteDialect&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;io.getquill.SQLServerDialect&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;io.getquill.OracleDialect&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Naming strategy&lt;/h3&gt; &#xA;&lt;p&gt;The naming strategy parameter defines the behavior when translating identifiers (table and column names) to SQL.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;strategy&lt;/th&gt; &#xA;   &lt;th&gt;example&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;io.getquill.naming.Literal&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;some_ident -&amp;gt; some_ident&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;io.getquill.naming.Escape&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;some_ident -&amp;gt; &#34;some_ident&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;io.getquill.naming.UpperCase&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;some_ident -&amp;gt; SOME_IDENT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;io.getquill.naming.LowerCase&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;SOME_IDENT -&amp;gt; some_ident&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;io.getquill.naming.SnakeCase&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;someIdent -&amp;gt; some_ident&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;io.getquill.naming.CamelCase&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;some_ident -&amp;gt; someIdent&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;io.getquill.naming.MysqlEscape&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;some_ident -&amp;gt; `some_ident`&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;io.getquill.naming.PostgresEscape&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;$some_ident -&amp;gt; $some_ident&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Multiple transformations can be defined using &lt;code&gt;NamingStrategy()&lt;/code&gt;. For instance, the naming strategy&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;NamingStrategy(SnakeCase, UpperCase)&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;produces the following transformation:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;someIdent -&amp;gt; SOME_IDENT&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The transformations are applied from left to right.&lt;/p&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;The string passed to the context is used as the key in order to obtain configurations using the &lt;a href=&#34;http://github.com/typesafehub/config&#34;&gt;typesafe config&lt;/a&gt; library.&lt;/p&gt; &#xA;&lt;p&gt;Additionally, the contexts provide multiple constructors. For instance, with &lt;code&gt;JdbcContext&lt;/code&gt; it&#39;s possible to specify a &lt;code&gt;DataSource&lt;/code&gt; directly, without using the configuration:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def createDataSource: javax.sql.DataSource with java.io.Closeable = ???&#xA;&#xA;lazy val ctx = new MysqlJdbcContext(SnakeCase, createDataSource)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-jdbc&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;quill-jdbc&lt;/code&gt; module provides a simple blocking JDBC context for standard use-cases. For transactions, the JDBC connection is kept in a thread-local variable.&lt;/p&gt; &#xA;&lt;p&gt;Quill uses &lt;a href=&#34;https://github.com/brettwooldridge/HikariCP&#34;&gt;HikariCP&lt;/a&gt; for connection pooling. Please refer to HikariCP&#39;s &lt;a href=&#34;https://github.com/brettwooldridge/HikariCP#configuration-knobs-baby&#34;&gt;documentation&lt;/a&gt; for a detailed explanation of the available configurations.&lt;/p&gt; &#xA;&lt;p&gt;Note that there are &lt;code&gt;dataSource&lt;/code&gt; configurations, that go under &lt;code&gt;dataSource&lt;/code&gt;, like &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;password&lt;/code&gt;, but some pool settings may go under the root config, like &lt;code&gt;connectionTimeout&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;transactions&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;JdbcContext&lt;/code&gt; provides thread-local transaction support:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.transaction {&#xA;  ctx.run(query[Person].delete)&#xA;  // other transactional code&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The body of &lt;code&gt;transaction&lt;/code&gt; can contain calls to other methods and multiple &lt;code&gt;run&lt;/code&gt; calls since the transaction is propagated through a thread-local.&lt;/p&gt; &#xA;&lt;h3&gt;MySQL (quill-jdbc)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;mysql&#34; % &#34;mysql-connector-java&#34; % &#34;8.0.17&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new MysqlJdbcContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=com.mysql.cj.jdbc.MysqlDataSource&#xA;ctx.dataSource.url=jdbc:mysql://host/database&#xA;ctx.dataSource.user=root&#xA;ctx.dataSource.password=root&#xA;ctx.dataSource.cachePrepStmts=true&#xA;ctx.dataSource.prepStmtCacheSize=250&#xA;ctx.dataSource.prepStmtCacheSqlLimit=2048&#xA;ctx.connectionTimeout=30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Postgres (quill-jdbc)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;org.postgresql&#34; % &#34;postgresql&#34; % &#34;42.2.8&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new PostgresJdbcContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=org.postgresql.ds.PGSimpleDataSource&#xA;ctx.dataSource.user=root&#xA;ctx.dataSource.password=root&#xA;ctx.dataSource.databaseName=database&#xA;ctx.dataSource.portNumber=5432&#xA;ctx.dataSource.serverName=host&#xA;ctx.connectionTimeout=30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Sqlite (quill-jdbc)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;org.xerial&#34; % &#34;sqlite-jdbc&#34; % &#34;3.28.0&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new SqliteJdbcContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.driverClassName=org.sqlite.JDBC&#xA;ctx.jdbcUrl=jdbc:sqlite:/path/to/db/file.db&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;H2 (quill-jdbc)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;com.h2database&#34; % &#34;h2&#34; % &#34;1.4.199&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new H2JdbcContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=org.h2.jdbcx.JdbcDataSource&#xA;ctx.dataSource.url=jdbc:h2:mem:yourdbname&#xA;ctx.dataSource.user=sa&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;SQL Server (quill-jdbc)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;com.microsoft.sqlserver&#34; % &#34;mssql-jdbc&#34; % &#34;7.4.1.jre8&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new SqlServerJdbcContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Oracle (quill-jdbc)&lt;/h3&gt; &#xA;&lt;p&gt;Quill supports Oracle version 12c and up although due to licensing restrictions, version 18c XE is used for testing.&lt;/p&gt; &#xA;&lt;p&gt;Note that the latest Oracle JDBC drivers are not publicly available. In order to get them, you will need to connect to Oracle&#39;s private maven repository as instructed &lt;a href=&#34;https://docs.oracle.com/middleware/1213/core/MAVEN/config_maven_repo.htm#MAVEN9012&#34;&gt;here&lt;/a&gt;. Unfortunately, this procedure currently does not work for SBT. There are various workarounds available for this situation &lt;a href=&#34;https://stackoverflow.com/questions/1074869/find-oracle-jdbc-driver-in-maven-repository?rq=1&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;com.oracle.jdbc&#34; % &#34;ojdbc8&#34; % &#34;18.3.0.0.0&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new OracleJdbcContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=com.microsoft.sqlserver.jdbc.SQLServerDataSource&#xA;ctx.dataSource.user=user&#xA;ctx.dataSource.password=YourStrongPassword&#xA;ctx.dataSource.databaseName=database&#xA;ctx.dataSource.portNumber=1433&#xA;ctx.dataSource.serverName=host&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ZIO (quill-jdbc-zio)&lt;/h2&gt; &#xA;&lt;p&gt;Quill context that executes JDBC queries inside of ZIO. Unlike most other contexts that require passing in a &lt;code&gt;java.sql.DataSource&lt;/code&gt; when the context is created, this context&#39;s run methods return a ZIO that has a DataSource resource dependency. Naturally, this should be provided later on in your application (see &lt;code&gt;ZioJdbc&lt;/code&gt; for helper methods that assist in doing this).&lt;/p&gt; &#xA;&lt;p&gt;Since resource dependency is &lt;code&gt;Has[DataSource]&lt;/code&gt; the result of a &lt;code&gt;run&lt;/code&gt; call is &lt;code&gt;ZIO[Has[DataSource], SQLException, T]&lt;/code&gt;. This means that if you have a &lt;code&gt;DataSource&lt;/code&gt; object, you can just provide it!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def ds: DataSource = _&#xA;run(people).provide(Has(ds))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Since most quill-zio methods return &lt;code&gt;ZIO[Has[DataSource], SQLException, T]&lt;/code&gt; the type &lt;code&gt;QIO[T]&lt;/code&gt; i.e. Quill-IO has been defined as an alias.&lt;/p&gt; &#xA; &lt;p&gt;For underlying-contexts (see below) that depend on &lt;code&gt;Has[Connection]&lt;/code&gt;, the alias &lt;code&gt;QCIO[T]&lt;/code&gt; (i.e. Quill-Connection-IO) has been defined for &lt;code&gt;ZIO[Has[Connection], SQLException, T]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Since in most JDBC use-cases, a connection-pool datasource (e.g. Hikari) is used, constructor-methods &lt;code&gt;fromPrefix&lt;/code&gt;, &lt;code&gt;fromConfig&lt;/code&gt;, &lt;code&gt;fromJdbcConfig&lt;/code&gt; are available on &lt;code&gt;DataSourceLayer&lt;/code&gt; to construct instances of a &lt;code&gt;ZLayer[Any, SQLException, Has[DataSource]]&lt;/code&gt; which can be easily used to provide a DataSource dependency. You can use them like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import ZioJdbc._&#xA;val zioDs = DataSourceLayer.fromPrefix(&#34;testPostgresDB&#34;)&#xA;MyZioContext.run(query[Person]).provideCustomLayer(zioDS)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If in some rare cases, you wish to provide a &lt;code&gt;java.sql.Connection&lt;/code&gt; to a &lt;code&gt;run&lt;/code&gt; method directly, you can delegate to the underlying-context. This is a more low-level context whose &lt;code&gt;run&lt;/code&gt; methods have a &lt;code&gt;Has[Connection]&lt;/code&gt; resource. Here is an example of how this can be done.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def conn: Connection = _ // If you are starting with a connection object&#xA;&#xA;import io.getquill.context.ZioJdbc._&#xA;// Import encoders/decoders of the underlying context. Do not import quote/run/prepare methods to avoid conflicts.&#xA;import MyZioContext.underlying.{ quote =&amp;gt; _, run =&amp;gt; _, prepare =&amp;gt; _,  _ }&#xA;&#xA;MyZioContext.underlying.run(people).provide(Has(conn))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are working with an underlying-context and want to provide a DataSource instead of a connection, you can use the &lt;code&gt;onDataSource&lt;/code&gt; method. Note however that this is &lt;em&gt;only&lt;/em&gt; needed when working with an underlying-context. When working with a normal context, &lt;code&gt;onDataSource&lt;/code&gt; is not available or necessary (since for a normal contexts &lt;code&gt;R&lt;/code&gt; will be &lt;code&gt;Has[DataSource]&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ds: DataSource = _&#xA;&#xA;import io.getquill.context.ZioJdbc._&#xA;// Import encoders/decoders of the underlying context. Do not import quote/run/prepare methods to avoid conflicts.&#xA;import MyZioContext.underlying.{ quote =&amp;gt; _, run =&amp;gt; _, prepare =&amp;gt; _,  _ }&#xA;&#xA;MyZioContext.underlying.run(people).onDataSource.provide(Has(ds))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Also note that if you are using a Plain Scala app however, you will need to manually run it i.e. using zio.Runtime&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;Runtime.default.unsafeRun(MyZioContext.run(query[Person]).provideLayer(zioDS))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;DAO helper&lt;/h4&gt; &#xA;&lt;p&gt;One additional useful pattern is to use &lt;code&gt;import io.getquill.context.qzio.ImplicitSyntax.Implicit&lt;/code&gt; to provide an implicit DataSource to one or multiple &lt;code&gt;run(qry)&lt;/code&gt; calls in a context. This is very useful when creating DAO patterns that will reuse a DataSource many times:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class MyQueryService(ds: DataSource with Closeable) { // I.e. our DAO&#xA; import Ctx._&#xA; implicit val env = Implicit(Has(ds)) // This will be looked up in each `.implicitDS` call&#xA;&#xA; val joes = Ctx.run(query[Person].filter(p =&amp;gt; p.name == &#34;Joe&#34;)).implicitDS&#xA; val jills = Ctx.run(query[Person].filter(p =&amp;gt; p.name == &#34;Jill&#34;)).implicitDS&#xA; val alexes = Ctx.run(query[Person].filter(p =&amp;gt; p.name == &#34;Alex&#34;)).implicitDS&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More examples of a Quill-JDBC-ZIO app &lt;a href=&#34;https://github.com/getquill/quill/tree/master/quill-jdbc-zio/src/test/scala/io/getquill/examples&#34;&gt;quill-jdbc-zio/src/test/scala/io/getquill/examples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;streaming&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;ZioJdbcContext&lt;/code&gt; can stream using zio.ZStream:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.stream(query[Person])             // returns: ZStream[Has[Connection], Throwable, Person]&#xA;  .run(Sink.collectAll).map(_.toList) // returns: ZIO[Has[Connection], Throwable, List[T]]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;transactions&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;ZioJdbcContext&lt;/code&gt;s provide support for transactions without needing thread-local storage or similar because they propagate the resource dependency in the ZIO effect itself (i.e. the &lt;code&gt;Has[Connection]&lt;/code&gt; in &lt;code&gt;Zio[Has[Connection], _, _]&lt;/code&gt;). As with the other contexts, if an exception is thrown anywhere inside a task or sub-task within a &lt;code&gt;transaction&lt;/code&gt; block, the entire block will be rolled back by the database.&lt;/p&gt; &#xA;&lt;p&gt;Basic syntax:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;val trans =&#xA;  ctx.transaction {&#xA;    for {&#xA;      _ &amp;lt;- ctx.run(query[Person].delete)&#xA;      _ &amp;lt;- ctx.run(query[Person].insertValue(Person(&#34;Joe&#34;, 123)))&#xA;      p &amp;lt;- ctx.run(query[Person])&#xA;    } yield p&#xA;  } //returns: ZIO[Has[Connection], Throwable, List[Person]]&#xA;&#xA;val result = Runtime.default.unsafeRun(trans.onDataSource.provide(ds)) //returns: List[Person]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;MySQL (quill-jdbc-zio)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;mysql&#34; % &#34;mysql-connector-java&#34; % &#34;8.0.17&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-zio&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new MysqlZioJdbcContext(SnakeCase)&#xA;// Also can be static:&#xA;object MyContext extends MysqlZioJdbcContext(SnakeCase)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=com.mysql.cj.jdbc.MysqlDataSource&#xA;ctx.dataSource.url=jdbc:mysql://host/database&#xA;ctx.dataSource.user=root&#xA;ctx.dataSource.password=root&#xA;ctx.dataSource.cachePrepStmts=true&#xA;ctx.dataSource.prepStmtCacheSize=250&#xA;ctx.dataSource.prepStmtCacheSqlLimit=2048&#xA;ctx.connectionTimeout=30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Postgres (quill-jdbc-zio)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;org.postgresql&#34; % &#34;postgresql&#34; % &#34;42.2.8&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-zio&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new PostgresZioJdbcContext(SnakeCase)&#xA;// Also can be static:&#xA;object MyContext extends PostgresZioJdbcContext(SnakeCase)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=org.postgresql.ds.PGSimpleDataSource&#xA;ctx.dataSource.user=root&#xA;ctx.dataSource.password=root&#xA;ctx.dataSource.databaseName=database&#xA;ctx.dataSource.portNumber=5432&#xA;ctx.dataSource.serverName=host&#xA;ctx.connectionTimeout=30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Sqlite (quill-jdbc-zio)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;org.xerial&#34; % &#34;sqlite-jdbc&#34; % &#34;3.28.0&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-zio&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new SqlitezioJdbcContext(SnakeCase)&#xA;// Also can be static:&#xA;object MyContext extends SqlitezioJdbcContext(SnakeCase)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.driverClassName=org.sqlite.JDBC&#xA;ctx.jdbcUrl=jdbc:sqlite:/path/to/db/file.db&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;H2 (quill-jdbc-zio)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;com.h2database&#34; % &#34;h2&#34; % &#34;1.4.199&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-zio&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new H2ZioJdbcContext(SnakeCase)&#xA;// Also can be static:&#xA;object MyContext extends H2ZioJdbcContext(SnakeCase)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=org.h2.jdbcx.JdbcDataSource&#xA;ctx.dataSource.url=jdbc:h2:mem:yourdbname&#xA;ctx.dataSource.user=sa&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;SQL Server (quill-jdbc-zio)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;com.microsoft.sqlserver&#34; % &#34;mssql-jdbc&#34; % &#34;7.4.1.jre8&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-zio&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new SqlServerZioJdbcContext(SnakeCase)&#xA;// Also can be static:&#xA;object MyContext extends SqlServerZioJdbcContext(SnakeCase)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=com.microsoft.sqlserver.jdbc.SQLServerDataSource&#xA;ctx.dataSource.user=user&#xA;ctx.dataSource.password=YourStrongPassword&#xA;ctx.dataSource.databaseName=database&#xA;ctx.dataSource.portNumber=1433&#xA;ctx.dataSource.serverName=host&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Oracle (quill-jdbc-zio)&lt;/h3&gt; &#xA;&lt;p&gt;Quill supports Oracle version 12c and up although due to licensing restrictions, version 18c XE is used for testing.&lt;/p&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;com.oracle.jdbc&#34; % &#34;ojdbc8&#34; % &#34;18.3.0.0.0&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-zio&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val ctx = new OracleZioJdbcContext(SnakeCase)&#xA;// Also can be static:&#xA;object MyContext extends OracleZioJdbcContext(SnakeCase)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=oracle.jdbc.xa.client.OracleXADataSource&#xA;ctx.dataSource.databaseName=xe&#xA;ctx.dataSource.user=database&#xA;ctx.dataSource.password=YourStrongPassword&#xA;ctx.dataSource.driverType=thin&#xA;ctx.dataSource.portNumber=1521&#xA;ctx.dataSource.serverName=host&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-jdbc-monix&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;quill-jdbc-monix&lt;/code&gt; module integrates the Monix asynchronous programming framework with Quill, supporting all of the database vendors of the &lt;code&gt;quill-jdbc&lt;/code&gt; module. The Quill Monix contexts encapsulate JDBC Queries and Actions into Monix &lt;code&gt;Task&lt;/code&gt;s and also include support for streaming queries via &lt;code&gt;Observable&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;streaming&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;MonixJdbcContext&lt;/code&gt; can stream using Monix Observables:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.stream(query[Person]) // returns: Observable[Person]&#xA;  .foreachL(println(_))&#xA;  .runSyncUnsafe()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;transactions&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;MonixJdbcContext&lt;/code&gt; provides support for transactions by storing the connection into a Monix &lt;code&gt;Local&lt;/code&gt;. This process is designed to be completely transparent to the user. As with the other contexts, if an exception is thrown anywhere inside a task or sub-task within a &lt;code&gt;transaction&lt;/code&gt; block, the entire block will be rolled back by the database.&lt;/p&gt; &#xA;&lt;p&gt;Basic syntax:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;val trans =&#xA;  ctx.transaction {&#xA;    for {&#xA;      _ &amp;lt;- ctx.run(query[Person].delete)&#xA;      _ &amp;lt;- ctx.run(query[Person].insertValue(Person(&#34;Joe&#34;, 123)))&#xA;      p &amp;lt;- ctx.run(query[Person])&#xA;    } yield p&#xA;  } //returns: Task[List[Person]]&#xA;&#xA;val result = trans.runSyncUnsafe() //returns: List[Person]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Streaming can also be done inside of &lt;code&gt;transaction&lt;/code&gt; block so long as the result is converted to a task beforehand.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;val trans =&#xA;  ctx.transaction {&#xA;    for {&#xA;      _   &amp;lt;- ctx.run(query[Person].insertValue(Person(&#34;Joe&#34;, 123)))&#xA;      ppl &amp;lt;- ctx&#xA;              .stream(query[Person])                               // Observable[Person]&#xA;              .foldLeftL(List[Person]())({case (l, p) =&amp;gt; p +: l})  // ... becomes Task[List[Person]]&#xA;    } yield ppl&#xA;  } //returns: Task[List[Person]]&#xA;&#xA;val result = trans.runSyncUnsafe() //returns: List[Person]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;runners&lt;/h4&gt; &#xA;&lt;p&gt;Use a &lt;code&gt;Runner&lt;/code&gt; object to create the different &lt;code&gt;MonixJdbcContext&lt;/code&gt;s. The Runner does the actual wrapping of JDBC calls into Monix Tasks.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;&#xA;import monix.execution.Scheduler&#xA;import io.getquill.context.monix.Runner&#xA;&#xA;// You can use the default Runner when constructing a Monix jdbc contexts.&#xA;// The resulting tasks will be wrapped with whatever Scheduler is&#xA;// defined when you do task.syncRunUnsafe(), typically a global implicit.&#xA;lazy val ctx = new MysqlMonixJdbcContext(SnakeCase, &#34;ctx&#34;, EffectWrapper.default)&#xA;&#xA;// However...&#xA;// Monix strongly suggests that you use a separate thread pool for database IO&#xA;// operations. `Runner` provides a convenience method in order to do this.&#xA;lazy val ctx = new MysqlMonixJdbcContext(SnakeCase, &#34;ctx&#34;, Runner.using(Scheduler.io()))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;MySQL (quill-jdbc-monix)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;mysql&#34; % &#34;mysql-connector-java&#34; % &#34;8.0.17&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-monix&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new MysqlMonixJdbcContext(SnakeCase, &#34;ctx&#34;, EffectWrapper.default)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=com.mysql.cj.jdbc.MysqlDataSource&#xA;ctx.dataSource.url=jdbc:mysql://host/database&#xA;ctx.dataSource.user=root&#xA;ctx.dataSource.password=root&#xA;ctx.dataSource.cachePrepStmts=true&#xA;ctx.dataSource.prepStmtCacheSize=250&#xA;ctx.dataSource.prepStmtCacheSqlLimit=2048&#xA;ctx.connectionTimeout=30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Postgres (quill-jdbc-monix)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;org.postgresql&#34; % &#34;postgresql&#34; % &#34;42.2.8&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-monix&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new PostgresMonixJdbcContext(SnakeCase, &#34;ctx&#34;, EffectWrapper.default)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=org.postgresql.ds.PGSimpleDataSource&#xA;ctx.dataSource.user=root&#xA;ctx.dataSource.password=root&#xA;ctx.dataSource.databaseName=database&#xA;ctx.dataSource.portNumber=5432&#xA;ctx.dataSource.serverName=host&#xA;ctx.connectionTimeout=30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Sqlite (quill-jdbc-monix)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;org.xerial&#34; % &#34;sqlite-jdbc&#34; % &#34;3.28.0&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-monix&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new SqliteMonixJdbcContext(SnakeCase, &#34;ctx&#34;, EffectWrapper.default)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.driverClassName=org.sqlite.JDBC&#xA;ctx.jdbcUrl=jdbc:sqlite:/path/to/db/file.db&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;H2 (quill-jdbc-monix)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;com.h2database&#34; % &#34;h2&#34; % &#34;1.4.199&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-monix&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new H2MonixJdbcContext(SnakeCase, &#34;ctx&#34;, EffectWrapper.default)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=org.h2.jdbcx.JdbcDataSource&#xA;ctx.dataSource.url=jdbc:h2:mem:yourdbname&#xA;ctx.dataSource.user=sa&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;SQL Server (quill-jdbc-monix)&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;com.microsoft.sqlserver&#34; % &#34;mssql-jdbc&#34; % &#34;7.4.1.jre8&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-monix&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new SqlServerMonixJdbcContext(SnakeCase, &#34;ctx&#34;, EffectWrapper.default)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=com.microsoft.sqlserver.jdbc.SQLServerDataSource&#xA;ctx.dataSource.user=user&#xA;ctx.dataSource.password=YourStrongPassword&#xA;ctx.dataSource.databaseName=database&#xA;ctx.dataSource.portNumber=1433&#xA;ctx.dataSource.serverName=host&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Oracle (quill-jdbc-monix)&lt;/h3&gt; &#xA;&lt;p&gt;Quill supports Oracle version 12c and up although due to licensing restrictions, version 18c XE is used for testing.&lt;/p&gt; &#xA;&lt;p&gt;Note that the latest Oracle JDBC drivers are not publicly available. In order to get them, you will need to connect to Oracle&#39;s private maven repository as instructed &lt;a href=&#34;https://docs.oracle.com/middleware/1213/core/MAVEN/config_maven_repo.htm#MAVEN9012&#34;&gt;here&lt;/a&gt;. Unfortunately, this procedure currently does not work for SBT. There are various workarounds available for this situation &lt;a href=&#34;https://stackoverflow.com/questions/1074869/find-oracle-jdbc-driver-in-maven-repository?rq=1&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;com.oracle.jdbc&#34; % &#34;ojdbc8&#34; % &#34;18.3.0.0.0&#34;,&#xA;  &#34;io.getquill&#34; %% &#34;quill-jdbc-monix&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new OracleJdbcContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dataSourceClassName=oracle.jdbc.xa.client.OracleXADataSource&#xA;ctx.dataSource.databaseName=xe&#xA;ctx.dataSource.user=database&#xA;ctx.dataSource.password=YourStrongPassword&#xA;ctx.dataSource.driverType=thin&#xA;ctx.dataSource.portNumber=1521&#xA;ctx.dataSource.serverName=host&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;NDBC Context&lt;/h2&gt; &#xA;&lt;p&gt;Async support via &lt;a href=&#34;https://ndbc.io/&#34;&gt;NDBC driver&lt;/a&gt; is available with Postgres database.&lt;/p&gt; &#xA;&lt;h3&gt;quill-ndbc-postgres&lt;/h3&gt; &#xA;&lt;h4&gt;transactions&lt;/h4&gt; &#xA;&lt;p&gt;Transaction support is provided out of the box by NDBC:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;ctx.transaction {&#xA;  ctx.run(query[Person].delete)&#xA;  // other transactional code&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The body of transaction can contain calls to other methods and multiple run calls since the transaction is automatically handled.&lt;/p&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-ndbc-postgres&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new NdbcPostgresContext(Literal, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.ndbc.dataSourceSupplierClass=io.trane.ndbc.postgres.netty4.DataSourceSupplier&#xA;ctx.ndbc.host=host&#xA;ctx.ndbc.port=1234&#xA;ctx.ndbc.user=root&#xA;ctx.ndbc.password=root&#xA;ctx.ndbc.database=database&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-async&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;quill-async&lt;/code&gt; module provides simple async support for MySQL and Postgres databases.&lt;/p&gt; &#xA;&lt;h4&gt;transactions&lt;/h4&gt; &#xA;&lt;p&gt;The async module provides transaction support based on a custom implicit execution context:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.transaction { implicit ec =&amp;gt;&#xA;  ctx.run(query[Person].delete)&#xA;  // other transactional code&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The body of &lt;code&gt;transaction&lt;/code&gt; can contain calls to other methods and multiple &lt;code&gt;run&lt;/code&gt; calls, but the transactional code must be done using the provided implicit execution context. For instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;def deletePerson(name: String)(implicit ec: ExecutionContext) =&#xA;  ctx.run(query[Person].filter(_.name == lift(name)).delete)&#xA;&#xA;ctx.transaction { implicit ec =&amp;gt;&#xA;  deletePerson(&#34;John&#34;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Depending on how the main execution context is imported, it is possible to produce an ambiguous implicit resolution. A way to solve this problem is shadowing the multiple implicits by using the same name:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import scala.concurrent.ExecutionContext.Implicits.{ global =&amp;gt; ec }&#xA;&#xA;def deletePerson(name: String)(implicit ec: ExecutionContext) =&#xA;  ctx.run(query[Person].filter(_.name == lift(name)).delete)&#xA;&#xA;ctx.transaction { implicit ec =&amp;gt;&#xA;  deletePerson(&#34;John&#34;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the global execution context is renamed to ec.&lt;/p&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;h5&gt;connection configuration&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.host=host&#xA;ctx.port=1234&#xA;ctx.user=root&#xA;ctx.password=root&#xA;ctx.database=database&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or use connection URL with database-specific scheme (see below):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.url=scheme://host:5432/database?user=root&amp;amp;password=root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;connection pool configuration&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.poolMaxQueueSize=4&#xA;ctx.poolMaxObjects=4&#xA;ctx.poolMaxIdle=999999999&#xA;ctx.poolValidationInterval=10000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Also see &lt;a href=&#34;https://github.com/mauricio/postgresql-async/raw/master/db-async-common/src/main/scala/com/github/mauricio/async/db/pool/PoolConfiguration.scala&#34;&gt;&lt;code&gt;PoolConfiguration&lt;/code&gt; documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h5&gt;SSL configuration&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.sslmode=disable # optional, one of [disable|prefer|require|verify-ca|verify-full]&#xA;ctx.sslrootcert=./path/to/cert/file # optional, required for sslmode=verify-ca or verify-full&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;other&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.charset=UTF-8&#xA;ctx.maximumMessageSize=16777216&#xA;ctx.connectTimeout=5s&#xA;ctx.testTimeout=5s&#xA;ctx.queryTimeout=10m&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;quill-async-mysql&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-async-mysql&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new MysqlAsyncContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#applicationproperties-5&#34;&gt;above&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For &lt;code&gt;url&lt;/code&gt; property use &lt;code&gt;mysql&lt;/code&gt; scheme:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.url=mysql://host:3306/database?user=root&amp;amp;password=root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;quill-async-postgres&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-async-postgres&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new PostgresAsyncContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#applicationproperties-5&#34;&gt;common properties&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For &lt;code&gt;url&lt;/code&gt; property use &lt;code&gt;postgresql&lt;/code&gt; scheme:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.url=postgresql://host:5432/database?user=root&amp;amp;password=root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-jasync&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;quill-jasync&lt;/code&gt; module provides simple async support for Postgres databases.&lt;/p&gt; &#xA;&lt;h4&gt;transactions&lt;/h4&gt; &#xA;&lt;p&gt;The async module provides transaction support based on a custom implicit execution context:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.transaction { implicit ec =&amp;gt;&#xA;  ctx.run(query[Person].delete)&#xA;  // other transactional code&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The body of &lt;code&gt;transaction&lt;/code&gt; can contain calls to other methods and multiple &lt;code&gt;run&lt;/code&gt; calls, but the transactional code must be done using the provided implicit execution context. For instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;def deletePerson(name: String)(implicit ec: ExecutionContext) =&#xA;  ctx.run(query[Person].filter(_.name == lift(name)).delete)&#xA;&#xA;ctx.transaction { implicit ec =&amp;gt;&#xA;  deletePerson(&#34;John&#34;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Depending on how the main execution context is imported, it is possible to produce an ambiguous implicit resolution. A way to solve this problem is shadowing the multiple implicits by using the same name:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import scala.concurrent.ExecutionContext.Implicits.{ global =&amp;gt; ec }&#xA;&#xA;def deletePerson(name: String)(implicit ec: ExecutionContext) =&#xA;  ctx.run(query[Person].filter(_.name == lift(name)).delete)&#xA;&#xA;ctx.transaction { implicit ec =&amp;gt;&#xA;  deletePerson(&#34;John&#34;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the global execution context is renamed to ec.&lt;/p&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;h5&gt;connection configuration&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.host=host&#xA;ctx.port=1234&#xA;ctx.username=root&#xA;ctx.password=root&#xA;ctx.database=database&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or use connection URL with database-specific scheme (see below):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.url=scheme://host:5432/database?user=root&amp;amp;password=root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Also see full settings &lt;code&gt;ConnectionPoolConfiguration&lt;/code&gt; &lt;a href=&#34;https://github.com/jasync-sql/jasync-sql/raw/master/db-async-common/src/main/java/com/github/jasync/sql/db/ConnectionPoolConfiguration.kt&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h5&gt;SSL configuration&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.sslmode=disable # optional, one of [disable|prefer|require|verify-ca|verify-full]&#xA;ctx.sslrootcert=./path/to/cert/file # optional, required for sslmode=verify-ca or verify-full&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;quill-jasync-mysql&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-jasync-mysql&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new MysqlJAsyncContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#applicationproperties-5&#34;&gt;above&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For &lt;code&gt;url&lt;/code&gt; property use &lt;code&gt;mysql&lt;/code&gt; scheme:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.url=mysql://host:3306/database?user=root&amp;amp;password=root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;quill-jasync-postgres&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-jasync-postgres&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new PostgresJAsyncContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#applicationproperties-5&#34;&gt;common properties&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For &lt;code&gt;url&lt;/code&gt; property use &lt;code&gt;postgresql&lt;/code&gt; scheme:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.url=postgresql://host:5432/database?user=root&amp;amp;password=root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-jasync-zio&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;quill-jasync-zio&lt;/code&gt; module provides ZIO async support for Postgres databases.&lt;/p&gt; &#xA;&lt;h5&gt;connection configuration&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.host=host&#xA;ctx.port=1234&#xA;ctx.username=root&#xA;ctx.password=root&#xA;ctx.database=database&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or use connection URL with database-specific scheme (see below):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.url=scheme://host:5432/database?user=root&amp;amp;password=root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Also see full settings &lt;code&gt;ConnectionPoolConfiguration&lt;/code&gt; &lt;a href=&#34;https://github.com/jasync-sql/jasync-sql/raw/master/db-async-common/src/main/java/com/github/jasync/sql/db/ConnectionPoolConfiguration.kt&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h5&gt;SSL configuration&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.sslmode=disable # optional, one of [disable|prefer|require|verify-ca|verify-full]&#xA;ctx.sslrootcert=./path/to/cert/file # optional, required for sslmode=verify-ca or verify-full&#xA;ctx.sslcert=./path/to/cert/file # optional, required to only allow connections from trusted clients&#xA;ctx.sslkey=./path/to/key/file # optional, required to only allow connections from trusted clients&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;quill-jasync-zio-postgres&lt;/h3&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-jasync-zio-postgres&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new PostgresZioJAsyncContext(SnakeCase)&#xA;// Also can be static:&#xA;object MyContext extends PostgresZioJAsyncContext(Literal)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In order to run operation in this context we need to provide &lt;code&gt;ZioJAsyncConnection&lt;/code&gt; instance.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;object MyApp extends zio.App {&#xA;  object DBContext extends PostgresZioJAsyncContext(Literal)&#xA;  import DBContext._&#xA;&#xA;  val dependencies =&#xA;    PostgresJAsyncContextConfig.loadConfig(&#34;testPostgresDB&#34;) &amp;gt;&amp;gt;&amp;gt;&#xA;    ZioJAsyncConnection.live[PostgreSQLConnection]&#xA;&#xA;  val program = run(query[Person])&#xA;&#xA;  def run(args: List[String]) = program.provideLayer(dependencies).exitCode&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio-quill/master/#applicationproperties-5&#34;&gt;common properties&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For &lt;code&gt;url&lt;/code&gt; property use &lt;code&gt;postgresql&lt;/code&gt; scheme:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.url=postgresql://host:5432/database?user=root&amp;amp;password=root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-doobie&lt;/h2&gt; &#xA;&lt;p&gt;Quill 3.16.5 and above supports Doobie starting 1.0.0-RC1. You can use quill quotes to construct &lt;code&gt;ConnectionIO&lt;/code&gt; programs. Quill provides statement construction and type mapping, and doobie takes care of statement execution.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note that if you are migrating from the original &lt;code&gt;doobie-quill&lt;/code&gt; integration (e.g. &lt;a href=&#34;https://search.maven.org/search?q=a:doobie-quill_2.12&#34;&gt;here&lt;/a&gt;) just add the below dependency and replace the &lt;code&gt;doobie.quill&lt;/code&gt; package with &lt;code&gt;io.getquill.doobie&lt;/code&gt;. (If you are using the package provided by kubukoz (i.e. &lt;a href=&#34;https://github.com/polyvariant/doobie-quill&#34;&gt;here&lt;/a&gt;), then replace &lt;code&gt;org.polyvariant&lt;/code&gt; with &lt;code&gt;io.getquill.doobie&lt;/code&gt;.)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;In order to use this feature, add the following dependency.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies += &#34;io.getquill&#34; %% &#34;quill-doobie&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The examples below require the following imports.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import io.getquill.{ idiom =&amp;gt; _, _ }&#xA;import io.getquill.DoobieContext&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can now construct a &lt;code&gt;DoobieContext&lt;/code&gt; for our back-end database and import its members, as we would with a traditional Quill context. The options are &lt;code&gt;H2&lt;/code&gt;, &lt;code&gt;MySQL&lt;/code&gt;, &lt;code&gt;Oracle&lt;/code&gt;, &lt;code&gt;Postgres&lt;/code&gt;, &lt;code&gt;SQLite&lt;/code&gt;, and &lt;code&gt;SQLServer&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;val dc = new DoobieContext.Postgres(Literal) // Literal naming scheme&#xA;import dc._&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We will be using the &lt;code&gt;country&lt;/code&gt; table from our test database, so we need a data type of that name, with fields whose names and types line up with the table definition.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Country(code: String, name: String, population: Int)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We&#39;re now ready to construct doobie programs using Quill quotes. Note the return types from &lt;code&gt;run&lt;/code&gt;, which are normal doobie types. You can freely mix Quill quotes into existing doobie programs.&lt;/p&gt; &#xA;&lt;h4&gt;running and streaming&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val q1 = quote { query[Country].filter(_.code == &#34;GBR&#34;) }&#xA;&#xA;// Select all at once&#xA;run(q1)&#xA;&#xA;// Stream in chunks of 16&#xA;stream(q1, 16)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;actions&lt;/h4&gt; &#xA;&lt;p&gt;A simple update.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val u1 = quote { query[Country].filter(_.name like &#34;U%&#34;).update(_.name -&amp;gt; &#34;foo&#34;) }&#xA;&#xA;// Update yielding count of affected rows&#xA;run(u1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A batch update.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val u2 = quote {&#xA;  liftQuery(List(&#34;U%&#34;, &#34;A%&#34;)).foreach { pat =&amp;gt;&#xA;    query[Country].filter(_.name like pat).update(_.name -&amp;gt; &#34;foo&#34;)&#xA;  }&#xA;}&#xA;&#xA;// Update yielding list of counts of affected rows&#xA;run(u2)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now we will look at batch updates with generated keys. For this we will create a new table.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE Foo (&#xA;  id    SERIAL,&#xA;  value VARCHAR(42)&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And a related data type.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Foo(id: Int, value: String)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can now write an update returning generated keys.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val u3 = quote {&#xA;  query[Foo].insert(lift(Foo(0, &#34;Joe&#34;))).returning(_.id)&#xA;}&#xA;&#xA;// Update yielding a single id&#xA;run(u3)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And a batch update returning generated keys.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val u4 = quote {&#xA;  liftQuery(List(Foo(0, &#34;Joe&#34;), Foo(0, &#34;Bob&#34;))).foreach { a =&amp;gt;&#xA;    query[Foo].insert(a).returning(_.id)&#xA;  }&#xA;}&#xA;&#xA;// Update yielding a list of ids&#xA;run(u4)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Finagle Contexts&lt;/h2&gt; &#xA;&lt;p&gt;Support for the Twitter Finagle library is available with MySQL and Postgres databases.&lt;/p&gt; &#xA;&lt;h3&gt;quill-finagle-mysql&lt;/h3&gt; &#xA;&lt;h4&gt;transactions&lt;/h4&gt; &#xA;&lt;p&gt;The finagle context provides transaction support through a &lt;code&gt;Local&lt;/code&gt; value. See twitter util&#39;s &lt;a href=&#34;https://github.com/twitter/util/raw/ee8d3140ba0ecc16b54591bd9d8961c11b999c0d/util-core/src/main/scala/com/twitter/util/Local.scala#L96&#34;&gt;scaladoc&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.transaction {&#xA;  ctx.run(query[Person].delete)&#xA;  // other transactional code&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;streaming&lt;/h4&gt; &#xA;&lt;p&gt;The finagle context allows streaming a query response, returning an &lt;code&gt;AsyncStream&lt;/code&gt; value.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.stream(query[Person]) // returns: Future[AsyncStream[Person]]&#xA;  .flatMap(_.toSeq())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The body of &lt;code&gt;transaction&lt;/code&gt; can contain calls to other methods and multiple &lt;code&gt;run&lt;/code&gt; calls since the transaction is automatically propagated through the &lt;code&gt;Local&lt;/code&gt; value.&lt;/p&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-finagle-mysql&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new FinagleMysqlContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dest=localhost:3306&#xA;ctx.user=root&#xA;ctx.password=root&#xA;ctx.database=database&#xA;ctx.pool.watermark.low=0&#xA;ctx.pool.watermark.high=10&#xA;ctx.pool.idleTime=5 # seconds&#xA;ctx.pool.bufferSize=0&#xA;ctx.pool.maxWaiters=2147483647&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;quill-finagle-postgres&lt;/h3&gt; &#xA;&lt;h4&gt;transactions&lt;/h4&gt; &#xA;&lt;p&gt;The finagle context provides transaction support through a &lt;code&gt;Local&lt;/code&gt; value. See twitter util&#39;s &lt;a href=&#34;https://github.com/twitter/util/raw/ee8d3140ba0ecc16b54591bd9d8961c11b999c0d/util-core/src/main/scala/com/twitter/util/Local.scala#L96&#34;&gt;scaladoc&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.transaction {&#xA;  ctx.run(query[Person].delete)&#xA;  // other transactional code&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The body of &lt;code&gt;transaction&lt;/code&gt; can contain calls to other methods and multiple &lt;code&gt;run&lt;/code&gt; calls since the transaction is automatically propagated through the &lt;code&gt;Local&lt;/code&gt; value.&lt;/p&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-finagle-postgres&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;context definition&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new FinaglePostgresContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.host=localhost:3306&#xA;ctx.user=root&#xA;ctx.password=root&#xA;ctx.database=database&#xA;ctx.useSsl=false&#xA;ctx.hostConnectionLimit=1&#xA;ctx.numRetries=4&#xA;ctx.binaryResults=false&#xA;ctx.binaryParams=false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-cassandra&lt;/h2&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-cassandra&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;synchronous context&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new CassandraSyncContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;asynchronous context&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new CassandraAsyncContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The configurations are set using runtime reflection on the &lt;a href=&#34;https://docs.datastax.com/en/drivers/java/2.1/com/datastax/driver/core/Cluster.Builder.html&#34;&gt;&lt;code&gt;Cluster.builder&lt;/code&gt;&lt;/a&gt; instance. It is possible to set nested structures like &lt;code&gt;queryOptions.consistencyLevel&lt;/code&gt;, use enum values like &lt;code&gt;LOCAL_QUORUM&lt;/code&gt;, and set multiple parameters like in &lt;code&gt;credentials&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.keyspace=quill_test&#xA;ctx.preparedStatementCacheSize=1000&#xA;ctx.session.contactPoint=127.0.0.1&#xA;ctx.session.withPort=9042&#xA;ctx.session.queryOptions.consistencyLevel=LOCAL_QUORUM&#xA;ctx.session.withoutMetrics=true&#xA;ctx.session.withoutJMXReporting=false&#xA;ctx.session.credentials.0=root&#xA;ctx.session.credentials.1=pass&#xA;ctx.session.maxSchemaAgreementWaitSeconds=1&#xA;ctx.session.addressTranslator=com.datastax.driver.core.policies.IdentityTranslator&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-cassandra-zio&lt;/h2&gt; &#xA;&lt;p&gt;Quill context that executes Cassandra queries inside of ZIO. Unlike most other contexts that require passing in a Data Source, this context takes in a &lt;code&gt;CassandraZioSession&lt;/code&gt; as a resource dependency which can be provided later (see the &lt;code&gt;CassandraZioSession&lt;/code&gt; object for helper methods that assist in doing this).&lt;/p&gt; &#xA;&lt;p&gt;The resource dependency itself is just a &lt;code&gt;Has[CassandraZioSession]&lt;/code&gt; hence &lt;code&gt;run(qry)&lt;/code&gt; and other methods in this context will return &lt;code&gt;ZIO[Has[CassandraZioSession], Throwable, T]&lt;/code&gt;. The type &lt;code&gt;CIO[T]&lt;/code&gt; i.e. Cassandra-IO is an alias for this. Providing a &lt;code&gt;CassandraZioSession&lt;/code&gt; dependency is now very simple:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val session: CassandraZioSession = _&#xA;run(people)&#xA;  .provide(Has(session))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Various methods in the &lt;code&gt;io.getquill.CassandraZioSession&lt;/code&gt; can assist in simplifying it&#39;s creation, for example, you can provide a &lt;code&gt;Config&lt;/code&gt; object instead of a &lt;code&gt;CassandraZioSession&lt;/code&gt; like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt; val zioSessionLayer: ZLayer[Any, Throwable, Has[CassandraZioSession]] =&#xA;   CassandraZioSession.fromPrefix(&#34;testStreamDB&#34;)&#xA;run(query[Person])&#xA;  .provideCustomLayer(zioSessionLayer)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;(Note that the resulting CassandraZioSession has a closing bracket)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you are using a Plain Scala app, you will need to manually run it e.g. using zio.Runtime&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt; Runtime.default.unsafeRun(MyZioContext.run(query[Person]).provideCustomLayer(zioSessionLayer))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;DAO helper&lt;/h4&gt; &#xA;&lt;p&gt;One additional useful pattern is to use &lt;code&gt;import io.getquill.context.qzio.ImplicitSyntax.Implicit&lt;/code&gt; to provide an implicit CassandraZioSession to one or multiple &lt;code&gt;run(qry)&lt;/code&gt; calls in a context. This is very useful when creating DAO patterns that will reuse a CassandraZioSession many times:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class MyQueryService(cs: CassandraZioSession) {&#xA;  import Ctx._&#xA;  implicit val env = Implicit(Has(cs))&#xA;&#xA;  def joes = Ctx.run { query[Person].filter(p =&amp;gt; p.name == &#34;Joe&#34;) }.implicitly&#xA;  def jills = Ctx.run { query[Person].filter(p =&amp;gt; p.name == &#34;Jill&#34;) }.implicitly&#xA;  def alexes = Ctx.run { query[Person].filter(p =&amp;gt; p.name == &#34;Alex&#34;) }.implicitly&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More examples of a Quill-Cassandra-ZIO app &lt;a href=&#34;https://github.com/getquill/quill/tree/master/quill-cassandra-zio/src/test/scala/io/getquill/context/cassandra/zio/examples&#34;&gt;quill-cassandra-zio/src/test/scala/io/getquill/context/cassandra/zio/examples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-cassandra-zio&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-cassandra-monix&lt;/h2&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-cassandra-monix&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;monix context&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new CassandraMonixContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;stream context&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new CassandraStreamContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;quill-cassandra-alpakka&lt;/h2&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-cassandra-alpakka&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://doc.akka.io/docs/alpakka/current/cassandra.html&#34;&gt;Alpakka Cassandra&lt;/a&gt; documentation page for more information.&lt;/p&gt; &#xA;&lt;h4&gt;context&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import akka.actor.ActorSystem&#xA;import akka.stream.alpakka.cassandra.CassandraSessionSettings&#xA;import akka.stream.alpakka.cassandra.scaladsl.{CassandraSession, CassandraSessionRegistry}&#xA;import io.getquill.CassandraAlpakkaContext&#xA;&#xA;val system: ActorSystem = ???&#xA;val alpakkaSessionSettings = CassandraSessionSettings(&#34;quill-test.alpakka.cassandra&#34;)&#xA;val alpakkaSession: CassandraSession = CassandraSessionRegistry.get(system).sessionFor(alpakkaSessionSettings)&#xA;&#xA;lazy val ctx = new CassandraAlpakkaContext(SnakeCase, alpakkaSession, preparedStatementCacheSize = 100)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;// alpakka cassandra session with keyspace&#xA;quill-test.alpakka.cassandra: ${alpakka.cassandra} { // inheritance of alpakka.cassandra session configuration&#xA;  // custom datastax driver setup&#xA;  datastax-java-driver-config = quill-test-datastax-java-driver&#xA;}&#xA;&#xA;quill-test-datastax-java-driver {&#xA;  basic {&#xA;    // keyspace at datastax driver setup, as there is not different option now&#xA;    session-keyspace = &#34;quill_test&#34;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;OrientDB Contexts&lt;/h2&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-orientdb&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;synchronous context&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;lazy val ctx = new OrientDBSyncContext(SnakeCase, &#34;ctx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The configurations are set using &lt;a href=&#34;http://orientdb.com/javadoc/latest/com/orientechnologies/orient/core/db/OPartitionedDatabasePool.html&#34;&gt;&lt;code&gt;OPartitionedDatabasePool&lt;/code&gt;&lt;/a&gt; which creates a pool of DB connections from which an instance of connection can be acquired. It is possible to set DB credentials using the parameter called &lt;code&gt;username&lt;/code&gt; and &lt;code&gt;password&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;application.properties&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctx.dbUrl=remote:127.0.0.1:2424/GratefulDeadConcerts&#xA;ctx.username=root&#xA;ctx.password=root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Code Generation&lt;/h1&gt; &#xA;&lt;p&gt;Quill now has a highly customizable code generator. Currently, it only supports JDBC but it will soon be extended to other contexts. With a minimal amount of configuration, the code generator takes schemas like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- Using schema &#39;public&#39;&#xA;&#xA;create table public.Person (&#xA;  id int primary key auto_increment,&#xA;  first_name varchar(255),&#xA;  last_name varchar(255),&#xA;  age int not null&#xA;);&#xA;&#xA;create table public.Address (&#xA;  person_fk int not null,&#xA;  street varchar(255),&#xA;  zip int&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Producing objects like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// src/main/scala/com/my/project/public/Person.scala&#xA;package com.my.project.public&#xA;&#xA;case class Person(id: Int, firstName: Option[String], lastName: Option[String], age: Int)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// src/main/scala/com/my/project/public/Address.scala&#xA;package com.my.project.public&#xA;&#xA;case class Address(personFk: Int, street: Option[String], zip: Option[Int])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Have a look at the &lt;a href=&#34;https://github.com/getquill/quill/raw/master/CODEGEN.md&#34;&gt;CODEGEN.md&lt;/a&gt; manual page for more details.&lt;/p&gt; &#xA;&lt;h4&gt;sbt dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies ++= Seq(&#xA;  &#34;io.getquill&#34; %% &#34;quill-codegen-jdbc&#34; % &#34;3.18.1-SNAPSHOT&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Logging&lt;/h1&gt; &#xA;&lt;h2&gt;Logging to a File at Compile-Time&lt;/h2&gt; &#xA;&lt;p&gt;To write compile-time queries to a log, use the &lt;code&gt;-Dquill.log.file=queries.sql&lt;/code&gt; and specify the file to be written (e.g. &lt;code&gt;queries.sql&lt;/code&gt;). The path is based on the build root (i.e. the current-working-directory of the Java build).&lt;/p&gt; &#xA;&lt;p&gt;When using SBT, this parameter can be set either in your SBT_OPTS, the project-specific .sbtopts file or directly passed to the SBT command. In Intellij this can be set under settings -&amp;gt; sbt -&amp;gt; VM Parameters.&lt;/p&gt; &#xA;&lt;p&gt;(Also make sure that &lt;code&gt;use for: &#34;Builds&#34;&lt;/code&gt; is selected otherwise Intellij will not use SBT for the build in the first place.)&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1369480/163513653-b5266cd6-1bff-4792-b0d2-936d24b7e0f1.png&#34; alt=&#34;Screenshot from 2022-04-14 23-28-47&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Also note that the &lt;code&gt;-Dquill.macro.log.pretty=true&lt;/code&gt; parameter works together with &lt;code&gt;-Dquill.log.file&lt;/code&gt; and will output pretty-printed queries to the specified file.&lt;/p&gt; &#xA;&lt;p&gt;For a file that looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;// Example.scala&#xA;package io.getquill&#xA;&#xA;object Example {&#xA;  case class Person(id: Int, name: String, age: Int)&#xA;  case class Address(owner:Int, street: String)&#xA;  val ctx = new SqlMirrorContext(PostgresDialect, Literal)&#xA;  import ctx._&#xA;&#xA;  val people = run(query[Person])&#xA;  val addresses = run(query[Person])&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The following log will be produced:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;&#xA;-- file: /home/me/quill-example/src/main/scala/io/getquill/Example.scala:9:19&#xA;-- time: 2022-04-14T23:18:19.533&#xA;&#xA; SELECT&#xA;   x.id,&#xA;   x.name,&#xA;   x.age&#xA; FROM&#xA;   Person x&#xA;&#xA;;&#xA;&#xA;&#xA;-- file: /home/me/quill-example/src/main/scala/io/getquill/Example.scala:10:22&#xA;-- time: 2022-04-14T23:18:19.9&#xA;&#xA; SELECT&#xA;   x.id,&#xA;   x.name,&#xA;   x.age&#xA; FROM&#xA;   Person x&#xA;&#xA;;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Disable Compile-Time Console Logging&lt;/h2&gt; &#xA;&lt;p&gt;To disable the console logging of queries during compilation use &lt;code&gt;quill.macro.log&lt;/code&gt; option:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sbt -Dquill.macro.log=false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Runtime&lt;/h2&gt; &#xA;&lt;p&gt;Quill uses SLF4J for logging. Each context logs queries which are currently executed. It also logs the list of parameters that are bound into a prepared statement if any. To enable that use &lt;code&gt;quill.binds.log&lt;/code&gt; option:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;java -Dquill.binds.log=true -jar myapp.jar&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Pretty Printing&lt;/h2&gt; &#xA;&lt;p&gt;Quill can pretty print compile-time produced queries by leveraging a great library produced by &lt;a href=&#34;https://github.com/vertical-blank&#34;&gt;@vertical-blank&lt;/a&gt; which is compatible with both Scala and ScalaJS. To enable this feature use the &lt;code&gt;quill.macro.log.pretty&lt;/code&gt; option:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sbt -Dquill.macro.log.pretty=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Before:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[info] /home/me/project/src/main/scala/io/getquill/MySqlTestPerson.scala:20:18: SELECT p.id, p.name, p.age, a.ownerFk, a.street, a.state, a.zip FROM Person p INNER JOIN Address a ON a.ownerFk = p.id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[info] /home/me/project/src/main/scala/io/getquill/MySqlTestPerson.scala:20:18:&#xA;[info]   | SELECT&#xA;[info]   |   p.id,&#xA;[info]   |   p.name,&#xA;[info]   |   p.age,&#xA;[info]   |   a.ownerFk,&#xA;[info]   |   a.street,&#xA;[info]   |   a.state,&#xA;[info]   |   a.zip&#xA;[info]   | FROM&#xA;[info]   |   Person p&#xA;[info]   |   INNER JOIN Address a ON a.ownerFk = p.id&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Additional resources&lt;/h1&gt; &#xA;&lt;h2&gt;Templates&lt;/h2&gt; &#xA;&lt;p&gt;In order to quickly start with Quill, we have setup some template projects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/getquill/play-quill-jdbc&#34;&gt;Play Framework with Quill JDBC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jeffmath/play-quill-async-postgres-example&#34;&gt;Play Framework with Quill async-postgres&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Slick comparison&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://github.com/getquill/quill/raw/master/SLICK.md&#34;&gt;SLICK.md&lt;/a&gt; for a detailed comparison between Quill and Slick.&lt;/p&gt; &#xA;&lt;h2&gt;Cassandra libraries comparison&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://github.com/getquill/quill/raw/master/CASSANDRA.md&#34;&gt;CASSANDRA.md&lt;/a&gt; for a detailed comparison between Quill and other main alternatives for interaction with Cassandra in Scala.&lt;/p&gt; &#xA;&lt;h2&gt;Related Projects&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ajozwik/quill-generic&#34;&gt;quill-generic&lt;/a&gt; - Generic DAO Support for Quill.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/olafurpg/scala-db-codegen&#34;&gt;scala-db-codegen&lt;/a&gt; - Code/boilerplate generator from db schema&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mslinn/quill-cache/&#34;&gt;quill-cache&lt;/a&gt; - Caching layer for Quill&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mslinn/quill-gen/&#34;&gt;quill-gen&lt;/a&gt; - a DAO generator for &lt;code&gt;quill-cache&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;External content&lt;/h2&gt; &#xA;&lt;h3&gt;Talks&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[Dotty/Scala 3]&lt;/strong&gt; Functional Scala 2020 - &lt;a href=&#34;https://www.youtube.com/watch?v=SmBpGkIsJIU&#34;&gt;Quill, Dotty, And The Awesome Power of &#39;Inline&#39;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[Intro]&lt;/strong&gt; ScalaDays Berlin 2016 - &lt;a href=&#34;https://www.youtube.com/watch?v=nqSYccoSeio&#34;&gt;Scylla, Charybdis, and the mystery of Quill&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[Intro]&lt;/strong&gt; Postgres Philly 2019 - &lt;a href=&#34;https://www.youtube.com/watch?v=RVs-T5iFdQI&#34;&gt;Introduction to Quill&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ScalaUA 2020 - &lt;a href=&#34;https://www.youtube.com/watch?v=aY8DrjE9lIY&#34;&gt;Manipulating Abstract Syntax Trees (ASTs) to generate safe SQL Queries with Quill&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;BeeScala 2019 - &lt;a href=&#34;https://www.youtube.com/watch?v=EXISmUXBXu8&#34;&gt;Quill + Spark = Better Together&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Scale By the Bay 2019 - &lt;a href=&#34;https://www.youtube.com/watch?v=1WVjkP_G2cA&#34;&gt;Quill + Doobie = Better Together&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ScQuilL, Porting Quill to Dotty (Ongoing) - &lt;a href=&#34;https://www.youtube.com/playlist?list=PLqky8QybCVQYNZY_MNJpkjFKT-dAdHQDX&#34;&gt;Quill, Dotty, and Macros&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Blog posts&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[Intro]&lt;/strong&gt; Haoyi&#39;s Programming Blog - &lt;a href=&#34;http://www.lihaoyi.com/post/WorkingwithDatabasesusingScalaandQuill.html&#34;&gt;Working with Databases using Scala and Quill&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Juliano Alves&#39;s Blog - &lt;a href=&#34;https://juliano-alves.com/2020/06/15/streaming-all-the-way-zio-doobie-quill-http4s-fs2/&#34;&gt;Streaming all the way with ZIO, Doobie, Quill, http4s and fs2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Juliano Alves&#39;s Blog - &lt;a href=&#34;https://juliano-alves.com/2020/09/14/quill-translating-boolean-literals/&#34;&gt;Quill: Translating Boolean Literals&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Juliano Alves&#39;s Blog - &lt;a href=&#34;https://juliano-alves.com/2019/11/29/quill-ndbc-postgres-a-new-async-module/&#34;&gt;Quill NDBC Postgres: A New Async Module&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Juliano Alves&#39;s Blog - &lt;a href=&#34;https://juliano-alves.com/2019/11/18/contributing-to-quill-a-pairing-session/&#34;&gt;Contributing to Quill, a Pairing Session&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Medium @ Fwbrasil - &lt;a href=&#34;https://medium.com/@fwbrasil/quill-spark-a-type-safe-scala-api-for-spark-sql-2672e8582b0d&#34;&gt;quill-spark: A type-safe Scala API for Spark SQL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Scalac.io blog - &lt;a href=&#34;http://blog.scalac.io/2016/07/21/compile-time-queries-with-quill.html&#34;&gt;Compile-time Queries with Quill&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;Please note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms. See &lt;a href=&#34;https://github.com/getquill/quill/raw/master/CODE_OF_CONDUCT.md&#34;&gt;CODE_OF_CONDUCT.md&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://github.com/getquill/quill/raw/master/LICENSE.txt&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; &#xA;&lt;h1&gt;Maintainers&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;@deusaquilus (lead maintainer)&lt;/li&gt; &#xA; &lt;li&gt;@fwbrasil (creator)&lt;/li&gt; &#xA; &lt;li&gt;@jilen&lt;/li&gt; &#xA; &lt;li&gt;@juliano&lt;/li&gt; &#xA; &lt;li&gt;@mentegy&lt;/li&gt; &#xA; &lt;li&gt;@mdedetrich&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Former maintainers:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;@gustavoamigo&lt;/li&gt; &#xA; &lt;li&gt;@godenji&lt;/li&gt; &#xA; &lt;li&gt;@lvicentesanchez&lt;/li&gt; &#xA; &lt;li&gt;@mxl&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can notify all current maintainers using the handle &lt;code&gt;@getquill/maintainers&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Acknowledgments&lt;/h1&gt; &#xA;&lt;p&gt;The project was created having Philip Wadler&#39;s talk &lt;a href=&#34;http://www.infoq.com/presentations/theory-language-integrated-query&#34;&gt;&#34;A practical theory of language-integrated query&#34;&lt;/a&gt; as its initial inspiration. The development was heavily influenced by the following papers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://homepages.inf.ed.ac.uk/slindley/papers/practical-theory-of-linq.pdf&#34;&gt;A Practical Theory of Language-Integrated Query&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://homepages.inf.ed.ac.uk/wadler/papers/qdsl/qdsl.pdf&#34;&gt;Everything old is new again: Quoted Domain Specific Languages&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://db.inf.uni-tuebingen.de/staticfiles/publications/the-flatter-the-better.pdf&#34;&gt;The Flatter, the Better&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ShiftForward/icfpc2012</title>
    <updated>2022-06-19T01:53:28Z</updated>
    <id>tag:github.com,2022-06-19:/ShiftForward/icfpc2012</id>
    <link href="https://github.com/ShiftForward/icfpc2012" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ICFP Contest 2012&lt;/p&gt;&lt;hr&gt;&lt;pre&gt;&lt;code&gt;// ****************************************************************&#xA;// *   Software Failure.  Press left mouse button to continue.    *&#xA;// *             Guru Meditation #00000000.00000000               *&#xA;// ****************************************************************&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;What is this?&lt;/h2&gt; &#xA;&lt;p&gt;This is Guru Meditation&#39;s entry to the &lt;a href=&#34;http://icfpcontest2012.wordpress.com/&#34;&gt;ICFP 2012 Contest&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Who are you?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;André Silva (ShiftForward)&lt;/li&gt; &#xA; &lt;li&gt;Hugo Sereno Ferreira (ShiftForward, FEUP)&lt;/li&gt; &#xA; &lt;li&gt;Joao Azevedo (ShiftForward)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How did you do this?&lt;/h2&gt; &#xA;&lt;p&gt;We are big fans of the object-functional language Scala, and that&#39;s what we used for coding. We also used SBT, Emacs, Ensime and IntelliJ.&lt;/p&gt; &#xA;&lt;h2&gt;What was your score?&lt;/h2&gt; &#xA;&lt;p&gt;We actually never submitted :-) We deemed our scores not good-enough™ for a modest classification. However, judging from IRC and Twitter reactions, we might have been wrong. At aproximately 12h before the end of the contest, our scores were (ignoring maps with trampolines, which our solver wasn&#39;t properly processing):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;contest1.map: 210&#xA;contest2.map: 278&#xA;contest3.map: 275&#xA;contest4.map: 575&#xA;contest5.map: 1291&#xA;contest6.map: 677&#xA;contest7.map: 867&#xA;contest8.map: 1269&#xA;contest9.map: 1917&#xA;contest10.map: 1931&#xA;flood1.map: 355&#xA;flood2.map: 278&#xA;flood3.map: 747&#xA;flood4.map: 957&#xA;flood5.map: 571&#xA;beard1.map: 437&#xA;beard2.map: 4507&#xA;beard4.map: 1460&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Ok... so... why did you release the code?&lt;/h2&gt; &#xA;&lt;p&gt;Two reasons. First, the number of Scala entries are very low. Opening the code &lt;em&gt;might&lt;/em&gt; attract more people to use the language.&lt;/p&gt; &#xA;&lt;p&gt;The second reason is because we think the Pattern Matching algorithm we used in the simulator is cool. We know there are lots of ways to enhance it, including the design of an external DSL to capture the patterns more &#34;graphically&#34;, and it&#39;s probably slower when compared to an in-place, mutable, switch-case based C implementation... but it&#39;s still cool :-)&lt;/p&gt; &#xA;&lt;h2&gt;Could you talk a little on your solving strategy?&lt;/h2&gt; &#xA;&lt;h3&gt;Patterns&lt;/h3&gt; &#xA;&lt;p&gt;A pattern looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val MvUpRazor = Pattern(OpcodePred(&#39;MoveUp),&#xA;                  Seq((0, -1) -&amp;gt; &#39;Razor, (0, 0) -&amp;gt; &#39;Robot),&#xA;                  Seq((0, -1) -&amp;gt; &#39;Robot, (0, 0) -&amp;gt; &#39;Empty),&#xA;                  { s =&amp;gt; s.copy(nRazors = s.nRazors + 1, robotPos = s.robotPos + Coordinate(0, -1)) } )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There&#39;s a predicate to test if the pattern is applicable (based on the opcode and board), in this case this pattern is only applicable when the &#39;MoveUp opcode is triggered. The pattern is composed of two matrices which are centered on the target Tile. The source matrix is used to match a pattern scenario on the board, and if it passes, the board is updated according to the transformation matrix. Additionally we can pass a function to capture additional side-effects on the Board (e.g. like changing the number of razors).&lt;/p&gt; &#xA;&lt;p&gt;This allowed us to quickly implement all the game rules as they were announced. It also allowed the solver to independently test all of the possible move patterns &#34;blindly&#34;, which allowed the bot to automatically adapt to new movements as they were implemented on the simulator (of course the heuristic still had to be changed to take into account new rules).&lt;/p&gt; &#xA;&lt;h3&gt;Solver&lt;/h3&gt; &#xA;&lt;p&gt;We started by a greedy best-first approach, just trying to fetch the lambdas that were closer to the bot. This quickly revealed itself as a bad strategy, specially in tricky maps where either the lambdas or the lift would become unreachable (such as contest8.map). We then evolved into a generic A* that would try the available opcodes in each state. The state was identified by the hash code of the map tiles, in order to reduce space. Our heuristic was based on the map score, penalizing the number of moves and prioritizing the number of lambdas gathered. We would also benefit states where we were closer to a lambda or to the lift (in case all lambdas were gathered) and penalize states where either a lambda or the lift was unreachable. In order to check for reachability, we would perform a flood fill starting on the bot position. For every interesting element (lambda or lift) outside the fill area, we would attempt to compute a path from the bot&#39;s current position to the element. We would also keep a cache of paths (which, in the end, I didn&#39;t think it was correctly implemented). We spent a generous amount of time tweaking the heuristic, and didn&#39;t consider flooding, beards, trampolines or higher order rocks in it.&lt;/p&gt; &#xA;&lt;h3&gt;WTF is it with Tile and Opcode?!&lt;/h3&gt; &#xA;&lt;p&gt;We started by representing tiles and opcodes as case classes which allowed for all the pattern matching goodness. Unfortunately it was slow(ish) and had an higher memory consumption, so the move to Symbol was a cheap performance optimization. Looking back on it, I forgot to try case objects instead...&lt;/p&gt;</summary>
  </entry>
</feed>