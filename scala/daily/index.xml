<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-01T01:39:33Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>smart-data-lake/smart-data-lake</title>
    <updated>2023-11-01T01:39:33Z</updated>
    <id>tag:github.com,2023-11-01:/smart-data-lake/smart-data-lake</id>
    <link href="https://github.com/smart-data-lake/smart-data-lake" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Smart Automation Tool for building modern Data Lakes and Data Pipelines&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Smart Data Lake&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/smart-data-lake/smart-data-lake/actions/workflows/snapshot_builds.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Smart Data Lake Builder is a data lake automation framework that makes loading and transforming data a breeze. It is implemented in Scala and builds on top of open-source big data technologies like &lt;a href=&#34;https://hadoop.apache.org/&#34;&gt;Apache Hadoop&lt;/a&gt; and &lt;a href=&#34;https://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt;, including connectors for diverse data sources (HadoopFS, Hive, DeltaLake, JDBC, Splunk, Webservice, SFTP, JMS, Excel, Access) and file formats.&lt;/p&gt; &#xA;&lt;h3&gt;A Data Lake&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;is a central raw data store for analytics&lt;/li&gt; &#xA; &lt;li&gt;facilitates cheap raw storage to handle growing volumes of data&lt;/li&gt; &#xA; &lt;li&gt;enables topnotch artificial intelligence (AI) and machine learning (ML) technologies for data-driven enterprises&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;The Smart Data Lake adds&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;a layered data architecture to provide not only raw data, but prepared, secured, high quality data according to business entities, ready to use for analytical use cases, also called «Smart Data». This is comparable to Databricks Lake House architecture, in fact Smart Data Lake Builder is a very good choice to automate a Lake House, also on Databricks.&lt;/li&gt; &#xA; &lt;li&gt;a declarative, configuration-driven approach to creating data pipelines. Metadata about data pipelines allows for efficient operations, maintenance and more business self-service.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Benefits of Smart Data Lake Builder&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cheaper implementation of data lakes&lt;/li&gt; &#xA; &lt;li&gt;Increased productivity of data scientists&lt;/li&gt; &#xA; &lt;li&gt;Higher level of self-service&lt;/li&gt; &#xA; &lt;li&gt;Decreased operations and maintenance costs&lt;/li&gt; &#xA; &lt;li&gt;Fully open source, no vendor lock-in&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;When should you consider using Smart Data Lake Builder ?&lt;/h3&gt; &#xA;&lt;p&gt;Some common use cases include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Building Data Lakes, drastically increasing productivity and usability&lt;/li&gt; &#xA; &lt;li&gt;Data Apps - building complex data processing apps&lt;/li&gt; &#xA; &lt;li&gt;DWH automation - reading and writing to relational databases via SQL&lt;/li&gt; &#xA; &lt;li&gt;Data migration - Efficiently create one-time data pipelines&lt;/li&gt; &#xA; &lt;li&gt;Data Catalog / Data Lineage - Generated automatically from metadata&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/smart-data-lake/smart-data-lake/raw/documentation/docs/features.md&#34;&gt;Features&lt;/a&gt; for a comprehensive list of Smart Data Lake Builder features.&lt;/p&gt; &#xA;&lt;h2&gt;How it works&lt;/h2&gt; &#xA;&lt;p&gt;The following diagram shows the core concepts:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/smart-data-lake/smart-data-lake/raw/documentation/docs/images/feed.png&#34; alt=&#34;How it works&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Data object&lt;/h3&gt; &#xA;&lt;p&gt;A data object defines the location and format of data. Some data objects require a connection to access remote data (e.g. a database connection).&lt;/p&gt; &#xA;&lt;h3&gt;Action&lt;/h3&gt; &#xA;&lt;p&gt;The &#34;data processors&#34; are called actions. An action requires at least one input and output data object. An action reads the data from the input data object, processes and writes it to the output data object. Many actions are predefined e.g. transform data from json to csv but you can also define your custom transformer action.&lt;/p&gt; &#xA;&lt;h3&gt;Feed&lt;/h3&gt; &#xA;&lt;p&gt;Actions connect different Data Object and implicitly define a directed acyclic graph, as they model the dependencies needed to fill a Data Object. This automatically generated, arbitrary complex data flow can be divided up into Feed&#39;s (subgraphs) for execution and monitoring.&lt;/p&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;All metadata i.e. connections, data objects and actions are defined in a central configuration file, usually called application.conf. The file format used is &lt;a href=&#34;https://github.com/lightbend/config/raw/master/HOCON.md&#34;&gt;HOCON&lt;/a&gt; which makes it easy to edit.&lt;/p&gt; &#xA;&lt;h3&gt;Getting Started&lt;/h3&gt; &#xA;&lt;p&gt;To see how all this works in action, head over to the &lt;a href=&#34;https://smartdatalake.ch/docs/getting-started/setup&#34;&gt;Getting Started&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;h1&gt;Major Contributors&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/smart-data-lake/smart-data-lake/raw/documentation/docs/images/SBB_logo.png&#34; alt=&#34;SBB&#34;&gt;&lt;br&gt; &lt;a href=&#34;http://www.sbb.ch&#34;&gt;www.sbb.ch&lt;/a&gt; : Provided the previously developed software as a foundation for the open source project&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/smart-data-lake/smart-data-lake/raw/documentation/docs/images/ELCA_logo.png&#34; alt=&#34;ELCA&#34;&gt;&lt;br&gt; &lt;a href=&#34;http://www.elca.ch&#34;&gt;www.elca.ch&lt;/a&gt; : Did the comprehensive revision and provision as open source project&lt;/p&gt; &#xA;&lt;h1&gt;Additional Documentation&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://smartdatalake.ch/docs/getting-started/setup&#34;&gt;Getting Started&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://smartdatalake.ch/docs/reference/build&#34;&gt;Reference&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://smartdatalake.ch/docs/architecture&#34;&gt;Architecture&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/smart-data-lake/smart-data-lake/raw/documentation/docs/reference/testing.md&#34;&gt;Testing&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/smart-data-lake/smart-data-lake/raw/documentation/docs/reference/glossary.md&#34;&gt;Glossary&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://smartdatalake.ch/docs/getting-started/troubleshooting/common-problems&#34;&gt;Troubleshooting&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/smart-data-lake/smart-data-lake/develop-spark3/docs/FAQ.md&#34;&gt;FAQ&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/smart-data-lake/smart-data-lake/develop-spark3/CONTRIBUTING.MD&#34;&gt;Contributing&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/smart-data-lake/smart-data-lake/develop-spark3/docs/PublicCloud.md&#34;&gt;Running in the Public Cloud&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>