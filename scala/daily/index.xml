<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-30T01:45:31Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>galaxy-data-cn/chitu-sdp</title>
    <updated>2023-04-30T01:45:31Z</updated>
    <id>tag:github.com,2023-04-30:/galaxy-data-cn/chitu-sdp</id>
    <link href="https://github.com/galaxy-data-cn/chitu-sdp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;赤兔实时计算平台是基于 Apache Flink 构建的企业级、一站式、高性能、低门槛大数据实时计算平台，广泛适用于流式数据应用开发场景。&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;开源社区的朋友们大家好：&lt;/h2&gt; &#xA;&lt;p&gt;收到 Apache StreamPark 社区反馈，赤兔实时计算平台使用到了部分 Apache StreamPark 和 Dinky 源代码，&lt;/p&gt; &#xA;&lt;p&gt;经确认确实存在文章截图中反馈的问题，我们进行了内部审查：&lt;a href=&#34;https://github.com/galaxy-data-cn/chitu-sdp/raw/master/docs/%E5%AE%A1%E6%9F%A5%E7%BB%93%E6%9E%9C%E5%8F%8A%E8%87%B4%E6%AD%89%E4%BF%A1.md&#34;&gt;审查结果及致歉信&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;后续我们会采取必要措施，以避免此类错误行为再次发生，包括加强团队成员的意识和培养正确的代码使用规范，&lt;/p&gt; &#xA;&lt;p&gt;由此给 Apache StreamPark 和 Dinky 带来的影响我们深感抱歉！&lt;/p&gt; &#xA;&lt;p&gt;目前项目已删除了赤兔本身代码，保留了之前未规范引用的代码及整改结果，后续我们会完全关闭项目整改。&lt;/p&gt; &#xA;&lt;p&gt;如果有任何问题可以扫码添加小助手联系我们或者在Issues里进行反馈，我们会及时回复。&lt;/p&gt; &#xA;&lt;img src=&#34;docs/md/image/客服二维码.png&#34;&gt; &#xA;&lt;p&gt;赤兔实时计算团队&lt;/p&gt; &#xA;&lt;h2&gt;联系我们&lt;/h2&gt; &#xA;&lt;h3&gt;PMC&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;商渭清 (PMC Chair), sang.williams#gmail.com&lt;/li&gt; &#xA; &lt;li&gt;刘斌 (Vice Chair), sunnykaka0721#gmail.com&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;引用的部分开源项目，在此表示感谢&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Flink SQL校验和提交：&lt;a href=&#34;https://github.com/apache/incubator-streampark&#34;&gt;Apache StreamPark&lt;/a&gt;、&lt;a href=&#34;https://github.com/DataLinkDC/dinky&#34;&gt;Dinky&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://github.com/galaxy-data-cn/chitu-sdp/raw/master/LICENSE&#34;&gt;Apache License 2.0 LICENSE&lt;/a&gt; document.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jm-g/sbt-example</title>
    <updated>2023-04-30T01:45:31Z</updated>
    <id>tag:github.com,2023-04-30:/jm-g/sbt-example</id>
    <link href="https://github.com/jm-g/sbt-example" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An example to show my problem with issue #200 if sbt-idea&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>softwaremill/kmq</title>
    <updated>2023-04-30T01:45:31Z</updated>
    <id>tag:github.com,2023-04-30:/softwaremill/kmq</id>
    <link href="https://github.com/softwaremill/kmq" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Kafka-based message queue&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kafka Message Queue&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/softwaremill/kmq?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/softwaremill/kmq.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/softwaremill/kmq&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.softwaremill.kmq/core_2.12&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/com.softwaremill.kmq/core_2.12/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Using &lt;code&gt;kmq&lt;/code&gt; you can acknowledge processing of individual messages in Kafka, and have unacknowledged messages re-delivered after a timeout.&lt;/p&gt; &#xA;&lt;p&gt;This is in contrast to the usual Kafka offset-committing mechanism, using which you can acknowledge all messages up to a given offset only.&lt;/p&gt; &#xA;&lt;p&gt;If you are familiar with &lt;a href=&#34;https://aws.amazon.com/sqs/&#34;&gt;Amazon SQS&lt;/a&gt;, &lt;code&gt;kmq&lt;/code&gt; implements a similar message processing model.&lt;/p&gt; &#xA;&lt;h1&gt;How does this work?&lt;/h1&gt; &#xA;&lt;p&gt;For a more in-depth overview see the blog: &lt;a href=&#34;https://softwaremill.com/using-kafka-as-a-message-queue/&#34;&gt;Using Kafka as a message queue&lt;/a&gt;, and for performance benchmarks: &lt;a href=&#34;https://softwaremill.com/kafka-with-selective-acknowledgments-performance/&#34;&gt;Kafka with selective acknowledgments (kmq) performance &amp;amp; latency benchmark&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The acknowledgment mechanism uses a &lt;code&gt;marker&lt;/code&gt; topic, which should have the same number of partitions as the &#34;main&#34; data topic (called the &lt;code&gt;queue&lt;/code&gt; topic). The marker topic is used to track which messages have been processed, by writing start/end markers for every message.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/softwaremill/kmq/raw/master/kmq.png?raw=true&#34; alt=&#34;message flow diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Using kmq&lt;/h1&gt; &#xA;&lt;p&gt;An application using &lt;code&gt;kmq&lt;/code&gt; should consist of the following components:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;a number of &lt;code&gt;RedeliveryTracker&lt;/code&gt;s. This components consumes the &lt;code&gt;marker&lt;/code&gt; topic and redelivers messages if appropriate. Multiple copies should be started in a cluster for fail-over. Uses automatic partition assignment.&lt;/li&gt; &#xA; &lt;li&gt;components which send data to the &lt;code&gt;queue&lt;/code&gt; topic to be processed&lt;/li&gt; &#xA; &lt;li&gt;queue clients, either custom or using the &lt;code&gt;KmqClient&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Maven/SBT dependency&lt;/h1&gt; &#xA;&lt;p&gt;SBT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;com.softwaremill.kmq&#34; %% &#34;core&#34; % &#34;0.3.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Maven:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;&#xA;    &amp;lt;groupId&amp;gt;com.softwaremill.kmq&amp;lt;/groupId&amp;gt;&#xA;    &amp;lt;artifactId&amp;gt;core_2.13&amp;lt;/artifactId&amp;gt;&#xA;    &amp;lt;version&amp;gt;0.3.1&amp;lt;/version&amp;gt;&#xA;&amp;lt;/dependency&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: The supported Scala versions are: 2.12, 2.13.&lt;/p&gt; &#xA;&lt;h1&gt;Client flow&lt;/h1&gt; &#xA;&lt;p&gt;The flow of processing a message is as follows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;read messages from the &lt;code&gt;queue&lt;/code&gt; topic, in batches&lt;/li&gt; &#xA; &lt;li&gt;write a &lt;code&gt;start&lt;/code&gt; marker to the &lt;code&gt;markers&lt;/code&gt; topic for each message, wait until the markers are written&lt;/li&gt; &#xA; &lt;li&gt;commit the biggest message offset to the &lt;code&gt;queue&lt;/code&gt; topic&lt;/li&gt; &#xA; &lt;li&gt;process messages&lt;/li&gt; &#xA; &lt;li&gt;for each message, write an &lt;code&gt;end&lt;/code&gt; marker. No need to wait until the markers are written.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This ensures at-least-once processing of each message. Note that the acknowledgment of each message (writing the &lt;code&gt;end&lt;/code&gt; marker) can be done for each message separately, out-of-order, from a different thread, server or application.&lt;/p&gt; &#xA;&lt;h1&gt;Example code&lt;/h1&gt; &#xA;&lt;p&gt;There are three example applications:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;example-java/embedded&lt;/code&gt;: a single java application that starts all three components (sender, client, redelivery tracker)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;example-java/standalone&lt;/code&gt;: three separate runnable classes to start the different components&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;example-scala&lt;/code&gt;: an implementation of the client using &lt;a href=&#34;https://github.com/akka/reactive-kafka&#34;&gt;reactive-kafka&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Time &amp;amp; timestamps&lt;/h1&gt; &#xA;&lt;p&gt;How time is handled is crucial for message redelivery, as messages are redelivered after a given amount of time passes since the &lt;code&gt;start&lt;/code&gt; marker was sent.&lt;/p&gt; &#xA;&lt;p&gt;To track what was sent when, &lt;code&gt;kmq&lt;/code&gt; uses Kafka&#39;s message timestamp. By default, this is messages create time (&lt;code&gt;message.timestamp.type=CreateTime&lt;/code&gt;), but for the &lt;code&gt;markers&lt;/code&gt; topic, it is advisable to switch this to &lt;code&gt;LogAppendTime&lt;/code&gt;. That way, the timestamps more closely reflect when the markers are really written to the log, and are guaranteed to be monotonic in each partition (which is important for redelivery - see below).&lt;/p&gt; &#xA;&lt;p&gt;To calculate which messages should be redelivered, we need to know the value of &#34;now&#34;, to check which &lt;code&gt;start&lt;/code&gt; markers have been sent later than the configured timeout. When a marker has been received from a partition recently, the maximum such timestamp is used as the value of &#34;now&#34; - as it indicates exactly how far we are in processing the partition. What &#34;recently&#34; means depends on the &lt;code&gt;useNowForRedeliverDespiteNoMarkerSeenForMs&lt;/code&gt; config setting. Otherwise, the current system time is used, as we assume that all markers from the partition have been processed.&lt;/p&gt; &#xA;&lt;h1&gt;Dead letter queue (DMQ)&lt;/h1&gt; &#xA;&lt;p&gt;The redelivery of the message is attempted only a configured number of times. By default, it&#39;s 3. You can change that number by setting &lt;code&gt;maxRedeliveryCount&lt;/code&gt; value in &lt;code&gt;KmqConfig&lt;/code&gt;. After that number is exceeded messages will be forwarded to a topic working as a &lt;em&gt;dead letter queue&lt;/em&gt;. By default, the name of that topic is name of the message topic concatenated with the suffix &lt;code&gt;__undelivered&lt;/code&gt;. You can configure the name by setting &lt;code&gt;deadLetterTopic&lt;/code&gt; in &lt;code&gt;KmqConfig&lt;/code&gt;. The number of redeliveries is tracked by &lt;code&gt;kmq&lt;/code&gt; with a special header. The default the name of that header is &lt;code&gt;kmq-redelivery-count&lt;/code&gt;. You can change it by setting &lt;code&gt;redeliveryCountHeader&lt;/code&gt; in &lt;code&gt;KmqConfig&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>