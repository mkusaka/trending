<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-05-29T01:53:43Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>delta-io/delta</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/delta-io/delta</id>
    <link href="https://github.com/delta-io/delta" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An open-source storage framework that enables building a Lakehouse architecture with compute engines including Spark, PrestoDB, Flink, Trino, and Hive and APIs for Scala, Java, Rust, Ruby, and Python.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://docs.delta.io/latest/_static/delta-lake-white.png&#34; width=&#34;200&#34; alt=&#34;Delta Lake Logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/delta-io/delta/actions/workflows/test.yaml&#34;&gt;&lt;img src=&#34;https://github.com/delta-io/delta/actions/workflows/test.yaml/badge.svg?sanitize=true&#34; alt=&#34;Test&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/delta-io/delta/raw/master/LICENSE.txt&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-brightgreen.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/delta-spark/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/delta-spark.svg?sanitize=true&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Delta Lake is an open-source storage framework that enables building a &lt;a href=&#34;http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf&#34;&gt;Lakehouse architecture&lt;/a&gt; with compute engines including Spark, PrestoDB, Flink, Trino, and Hive and APIs for Scala, Java, Rust, Ruby, and Python.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;See the &lt;a href=&#34;https://docs.delta.io&#34;&gt;Delta Lake Documentation&lt;/a&gt; for details.&lt;/li&gt; &#xA; &lt;li&gt;See the &lt;a href=&#34;https://docs.delta.io/latest/quick-start.html&#34;&gt;Quick Start Guide&lt;/a&gt; to get started with Scala, Java and Python.&lt;/li&gt; &#xA; &lt;li&gt;Note, this repo is one of many Delta Lake repositories in the &lt;a href=&#34;https://github.com/delta-io&#34;&gt;delta.io&lt;/a&gt; organizations including &lt;a href=&#34;https://github.com/delta-io/connectors&#34;&gt;connectors&lt;/a&gt;, &lt;a href=&#34;https://github.com/delta-io/delta&#34;&gt;delta&lt;/a&gt;, &lt;a href=&#34;https://github.com/delta-io/delta-rs&#34;&gt;delta-rs&lt;/a&gt;, &lt;a href=&#34;https://github.com/delta-io/delta-sharing&#34;&gt;delta-sharing&lt;/a&gt;, &lt;a href=&#34;https://github.com/delta-io/kafka-delta-ingest&#34;&gt;kafka-delta-ingest&lt;/a&gt;, and &lt;a href=&#34;https://github.com/delta-io/website&#34;&gt;website&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following are some of the more popular Delta Lake integrations, refer to &lt;a href=&#34;https://delta.io/integrations/&#34;&gt;delta.io/integrations&lt;/a&gt; for the complete list:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.delta.io/&#34;&gt;Apache Sparkâ„¢&lt;/a&gt;: This connector allows Apache Sparkâ„¢ to read from and write to Delta Lake.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/delta-io/connectors/tree/master/flink&#34;&gt;Apache Flink (Preview)&lt;/a&gt;: This connector allows Apache Flink to write to Delta Lake.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://prestodb.io/docs/current/connector/deltalake.html&#34;&gt;PrestoDB&lt;/a&gt;: This connector allows PrestoDB to read from Delta Lake.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://trino.io/docs/current/connector/delta-lake.html&#34;&gt;Trino&lt;/a&gt;: This connector allows Trino to read from and write to Delta Lake.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.delta.io/latest/delta-standalone.html&#34;&gt;Delta Standalone&lt;/a&gt;: This library allows Scala and Java-based projects (including Apache Flink, Apache Hive, Apache Beam, and PrestoDB) to read from and write to Delta Lake.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.delta.io/latest/hive-integration.html&#34;&gt;Apache Hive&lt;/a&gt;: This connector allows Apache Hive to read from Delta Lake.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rs/deltalake/latest/deltalake/&#34;&gt;Delta Rust API&lt;/a&gt;: This library allows Rust (with Python and Ruby bindings) low level access to Delta tables and is intended to be used with data processing frameworks like datafusion, ballista, rust-dataframe, vega, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;&lt;em&gt;Table of Contents&lt;/em&gt;&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#latest-binaries&#34;&gt;Latest binaries&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#api-documentation&#34;&gt;API Documentation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#compatibility&#34;&gt;Compatibility&lt;/a&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#api-compatibility&#34;&gt;API Compatibility&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#data-storage-compatibility&#34;&gt;Data Storage Compatibility&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#roadmap&#34;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#building&#34;&gt;Building&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#transaction-protocol&#34;&gt;Transaction Protocol&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#requirements-for-underlying-storage-systems&#34;&gt;Requirements for Underlying Storage Systems&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#concurrency-control&#34;&gt;Concurrency Control&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#reporting-issues&#34;&gt;Reporting issues&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#community&#34;&gt;Community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Latest Binaries&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://docs.delta.io/latest/&#34;&gt;online documentation&lt;/a&gt; for the latest release.&lt;/p&gt; &#xA;&lt;h2&gt;API Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.delta.io/latest/delta-apidoc.html&#34;&gt;Scala API docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.delta.io/latest/api/java/index.html&#34;&gt;Java API docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.delta.io/latest/api/python/index.html&#34;&gt;Python API docs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Compatibility&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.delta.io/latest/delta-standalone.html&#34;&gt;Delta Standalone&lt;/a&gt; library is a single-node Java library that can be used to read from and write to Delta tables. Specifically, this library provides APIs to interact with a tableâ€™s metadata in the transaction log, implementing the Delta Transaction Log Protocol to achieve the transactional guarantees of the Delta Lake format.&lt;/p&gt; &#xA;&lt;h3&gt;API Compatibility&lt;/h3&gt; &#xA;&lt;p&gt;There are two types of APIs provided by the Delta Lake project.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Direct Java/Scala/Python APIs - The classes and methods documented in the &lt;a href=&#34;https://docs.delta.io/latest/delta-apidoc.html&#34;&gt;API docs&lt;/a&gt; are considered as stable public APIs. All other classes, interfaces, methods that may be directly accessible in code are considered internal, and they are subject to change across releases.&lt;/li&gt; &#xA; &lt;li&gt;Spark-based APIs - You can read Delta tables through the &lt;code&gt;DataFrameReader&lt;/code&gt;/&lt;code&gt;Writer&lt;/code&gt; (i.e. &lt;code&gt;spark.read&lt;/code&gt;, &lt;code&gt;df.write&lt;/code&gt;, &lt;code&gt;spark.readStream&lt;/code&gt; and &lt;code&gt;df.writeStream&lt;/code&gt;). Options to these APIs will remain stable within a major release of Delta Lake (e.g., 1.x.x).&lt;/li&gt; &#xA; &lt;li&gt;See the &lt;a href=&#34;https://docs.delta.io/latest/releases.html&#34;&gt;online documentation&lt;/a&gt; for the releases and their compatibility with Apache Spark versions.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Data Storage Compatibility&lt;/h3&gt; &#xA;&lt;p&gt;Delta Lake guarantees backward compatibility for all Delta Lake tables (i.e., newer versions of Delta Lake will always be able to read tables written by older versions of Delta Lake). However, we reserve the right to break forward compatibility as new features are introduced to the transaction protocol (i.e., an older version of Delta Lake may not be able to read a table produced by a newer version).&lt;/p&gt; &#xA;&lt;p&gt;Breaking changes in the protocol are indicated by incrementing the minimum reader/writer version in the &lt;code&gt;Protocol&lt;/code&gt; &lt;a href=&#34;https://github.com/delta-io/delta/raw/master/core/src/test/scala/org/apache/spark/sql/delta/ActionSerializerSuite.scala&#34;&gt;action&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For the high-level Delta Lake roadmap, see &lt;a href=&#34;http://delta.io/roadmap&#34;&gt;Delta Lake 2022H1 roadmap&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For the detailed timeline, see the &lt;a href=&#34;https://github.com/delta-io/delta/milestones&#34;&gt;project roadmap&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Transaction Protocol&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/PROTOCOL.md&#34;&gt;Delta Transaction Log Protocol&lt;/a&gt; document provides a specification of the transaction protocol.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements for Underlying Storage Systems&lt;/h2&gt; &#xA;&lt;p&gt;Delta Lake ACID guarantees are predicated on the atomicity and durability guarantees of the storage system. Specifically, we require the storage system to provide the following.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Atomic visibility&lt;/strong&gt;: There must be a way for a file to be visible in its entirety or not visible at all.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Mutual exclusion&lt;/strong&gt;: Only one writer must be able to create (or rename) a file at the final destination.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Consistent listing&lt;/strong&gt;: Once a file has been written in a directory, all future listings for that directory must return that file.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://docs.delta.io/latest/delta-storage.html&#34;&gt;online documentation on Storage Configuration&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Concurrency Control&lt;/h2&gt; &#xA;&lt;p&gt;Delta Lake ensures &lt;em&gt;serializability&lt;/em&gt; for concurrent reads and writes. Please see &lt;a href=&#34;https://docs.delta.io/latest/delta-concurrency.html&#34;&gt;Delta Lake Concurrency Control&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Reporting issues&lt;/h2&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/delta-io/delta/issues&#34;&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta/master/#community&#34;&gt;contact&lt;/a&gt; the community for getting answers.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions to Delta Lake. See our &lt;a href=&#34;https://github.com/delta-io/delta/raw/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;We also adhere to the &lt;a href=&#34;https://github.com/delta-io/delta/raw/master/CODE_OF_CONDUCT.md&#34;&gt;Delta Lake Code of Conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;Delta Lake is compiled using &lt;a href=&#34;https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html&#34;&gt;SBT&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To compile, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt compile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate artifacts, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt package&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To execute tests, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To execute a single test suite, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt &#39;testOnly org.apache.spark.sql.delta.optimize.OptimizeCompactionSuite&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To execute a single test within and a single test suite, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt &#39;testOnly *.OptimizeCompactionSuite -- -z &#34;optimize command: on partitioned table - all partitions&#34;&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Refer to &lt;a href=&#34;https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html&#34;&gt;SBT docs&lt;/a&gt; for more commands.&lt;/p&gt; &#xA;&lt;h2&gt;IntelliJ Setup&lt;/h2&gt; &#xA;&lt;p&gt;IntelliJ is the recommended IDE to use when developing Delta Lake. To import Delta Lake as a new project:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone Delta Lake into, for example, &lt;code&gt;~/delta&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;In IntelliJ, select &lt;code&gt;File&lt;/code&gt; &amp;gt; &lt;code&gt;New Project&lt;/code&gt; &amp;gt; &lt;code&gt;Project from Existing Sources...&lt;/code&gt; and select &lt;code&gt;~/delta&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Under &lt;code&gt;Import project from external model&lt;/code&gt; select &lt;code&gt;sbt&lt;/code&gt;. Click &lt;code&gt;Next&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Under &lt;code&gt;Project JDK&lt;/code&gt; specify a valid Java &lt;code&gt;1.8&lt;/code&gt; JDK and opt to use SBT shell for &lt;code&gt;project reload&lt;/code&gt; and &lt;code&gt;builds&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Click &lt;code&gt;Finish&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Setup Verification&lt;/h3&gt; &#xA;&lt;p&gt;After waiting for IntelliJ to index, verify your setup by running a test suite in IntelliJ.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Search for and open &lt;code&gt;DeltaLogSuite&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Next to the class declaration, right click on the two green arrows and select &lt;code&gt;Run &#39;DeltaLogSuite&#39;&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Troubleshooting&lt;/h3&gt; &#xA;&lt;p&gt;If you see errors of the form&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Error:(46, 28) object DeltaSqlBaseParser is not a member of package io.delta.sql.parser&#xA;import io.delta.sql.parser.DeltaSqlBaseParser._&#xA;...&#xA;Error:(91, 22) not found: type DeltaSqlBaseParser&#xA;    val parser = new DeltaSqlBaseParser(tokenStream)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;then follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Compile using the SBT CLI: &lt;code&gt;build/sbt compile&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Go to &lt;code&gt;File&lt;/code&gt; &amp;gt; &lt;code&gt;Project Structure...&lt;/code&gt; &amp;gt; &lt;code&gt;Modules&lt;/code&gt; &amp;gt; &lt;code&gt;delta-core&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;In the right panel under &lt;code&gt;Source Folders&lt;/code&gt; remove any &lt;code&gt;target&lt;/code&gt; folders, e.g. &lt;code&gt;target/scala-2.12/src_managed/main [generated]&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Click &lt;code&gt;Apply&lt;/code&gt; and then re-run your test.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Apache License 2.0, see &lt;a href=&#34;https://github.com/delta-io/delta/raw/master/LICENSE.txt&#34;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;There are two mediums of communication within the Delta Lake community.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Public Slack Channel &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://join.slack.com/t/delta-users/shared_invite/zt-165gcm2g7-0Sc57w7dX0FbfilR9EPwVQ&#34;&gt;Register here&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://delta-users.slack.com/&#34;&gt;Login here&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/company/deltalake&#34;&gt;Linkedin page&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/c/deltalake&#34;&gt;Youtube channel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Public &lt;a href=&#34;https://groups.google.com/forum/#!forum/delta-users&#34;&gt;Mailing list&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>zio/zio</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/zio/zio</id>
    <link href="https://github.com/zio/zio" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ZIO â€” A type-safe, composable library for async and concurrent programming in Scala&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/ZIO.png&#34; alt=&#34;ZIO Logo&#34;&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Project Stage&lt;/th&gt; &#xA;   &lt;th&gt;CI&lt;/th&gt; &#xA;   &lt;th&gt;Release&lt;/th&gt; &#xA;   &lt;th&gt;Snapshot&lt;/th&gt; &#xA;   &lt;th&gt;Issues&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/zio/zio/wiki/Project-Stages&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project%20Stage-Production%20Ready-brightgreen.svg?sanitize=true&#34; alt=&#34;Project stage&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/zio/zio/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://oss.sonatype.org/content/repositories/releases/dev/zio/zio_2.12/&#34; title=&#34;Sonatype Releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/nexus/r/https/oss.sonatype.org/dev.zio/zio_2.12.svg?sanitize=true&#34; alt=&#34;Release Artifacts&#34; title=&#34;Sonatype Releases&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://oss.sonatype.org/content/repositories/snapshots/dev/zio/zio_2.12/&#34; title=&#34;Sonatype Snapshots&#34;&gt;&lt;img src=&#34;https://img.shields.io/nexus/s/https/oss.sonatype.org/dev.zio/zio_2.12.svg?sanitize=true&#34; alt=&#34;Snapshot Artifacts&#34; title=&#34;Sonatype Snapshots&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://isitmaintained.com/project/zio/zio&#34; title=&#34;Average time to resolve an issue&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/resolution/zio/zio.svg?sanitize=true&#34; alt=&#34;Average time to resolve an issue&#34; title=&#34;Average time to resolve an issue&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Scaladoc&lt;/th&gt; &#xA;   &lt;th&gt;Scaladex&lt;/th&gt; &#xA;   &lt;th&gt;Discord&lt;/th&gt; &#xA;   &lt;th&gt;Twitter&lt;/th&gt; &#xA;   &lt;th&gt;Gitpod&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://javadoc.io/doc/dev.zio/zio_2.12/latest/zio/index.html&#34;&gt;Scaladoc&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://index.scala-lang.org/zio/zio/zio&#34; title=&#34;Scaladex&#34;&gt;&lt;img src=&#34;https://index.scala-lang.org/zio/zio/zio/latest.svg?sanitize=true&#34; alt=&#34;Badge-Scaladex-page&#34; title=&#34;Scaladex&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://discord.gg/2ccFBr4&#34; title=&#34;Discord&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/629491597070827530?logo=discord&#34; alt=&#34;Badge-Discord&#34; title=&#34;chat on discord&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://twitter.com/zioscala&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/zioscala.svg?style=plastic&amp;amp;label=follow&amp;amp;logo=twitter&#34; alt=&#34;Badge-Twitter&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gitpod.io/#https://github.com/zio/zio&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&#34; alt=&#34;Gitpod ready-to-code&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Welcome to ZIO&lt;/h1&gt; &#xA;&lt;p&gt;ZIO is a zero-dependency Scala library for asynchronous and concurrent programming.&lt;/p&gt; &#xA;&lt;p&gt;Powered by highly-scalable, non-blocking fibers that never waste or leak resources, ZIO lets you build scalable, resilient, and reactive applications that meet the needs of your business.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;High-performance&lt;/strong&gt;. Build scalable applications with 100x the performance of Scala&#39;s &lt;code&gt;Future&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Type-safe&lt;/strong&gt;. Use the full power of the Scala compiler to catch bugs at compile time.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Concurrent&lt;/strong&gt;. Easily build concurrent apps without deadlocks, race conditions, or complexity.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Asynchronous&lt;/strong&gt;. Write sequential code that looks the same whether it&#39;s asynchronous or synchronous.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Resource-safe&lt;/strong&gt;. Build apps that never leak resources (including threads!), even when they fail.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Testable&lt;/strong&gt;. Inject test services into your app for fast, deterministic, and type-safe testing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Resilient&lt;/strong&gt;. Build apps that never lose errors, and which respond to failure locally and flexibly.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Functional&lt;/strong&gt;. Rapidly compose solutions to complex problems from simple building blocks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To learn more about ZIO, see the following references:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zio.dev/&#34;&gt;Homepage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zio/zio/master/docs/about/contributing.md&#34;&gt;Contributor&#39;s Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zio/zio/master/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zio/zio/issues&#34;&gt;Issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zio/zio/pulls&#34;&gt;Pull Requests&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Adopters&lt;/h1&gt; &#xA;&lt;p&gt;Following is a partial list of companies happily using ZIO in production to craft concurrent applications.&lt;/p&gt; &#xA;&lt;p&gt;Want to see your company here? &lt;a href=&#34;https://github.com/zio/zio/edit/master/README.md&#34;&gt;Submit a PR&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adgear.com/en/&#34;&gt;AdGear / Samsung Ads&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.adidas.com/&#34;&gt;Adidas&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.adpulse.io/&#34;&gt;adpulse.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.adsquare.com/&#34;&gt;adsquare&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.anduintransact.com/&#34;&gt;Anduin Transactions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ayolab.com/&#34;&gt;Ayolab&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://asana.com/&#34;&gt;Asana&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.aurinko.io/&#34;&gt;Aurinko&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://auto.ru&#34;&gt;auto.ru&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.autoscout24.de&#34;&gt;AutoScout24&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.avast.com&#34;&gt;Avast&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bofa.com&#34;&gt;Bank of America&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bpp.it/&#34;&gt;Bpp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://broad.app&#34;&gt;Broad&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.caesars.com/sportsbook-and-casino&#34;&gt;Caesars Digital&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.calcbank.com.br&#34;&gt;CalcBank&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.callhandling.co.uk/&#34;&gt;Call Handling&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.carvana.com&#34;&gt;Carvana&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cellular.de&#34;&gt;Cellular&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cloudfarms.com&#34;&gt;Cloudfarms&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://codecomprehension.com&#34;&gt;CodeComprehension&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.codept.de/&#34;&gt;Codept&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.colisweb.com/en&#34;&gt;Colisweb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.collibra.com/&#34;&gt;Collibra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.compellon.com/&#34;&gt;Compellon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.complicatedrobot.com/&#34;&gt;Complicated Robot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.conduktor.io&#34;&gt;Conduktor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.contramap.dev&#34;&gt;Contramap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://coralogix.com&#34;&gt;Coralogix&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://creditkarma.com&#34;&gt;Credit Karma&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.currencycloud.com/&#34;&gt;CurrencyCloud&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://de-solution.com/&#34;&gt;D.E.Solution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datachef.co&#34;&gt;DataChef&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.demandbase.com&#34;&gt;Demandbase&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://demyst.com&#34;&gt;Demyst&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://devsisters.com/&#34;&gt;Devsisters&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.werkenbijdhl.nl/it&#34;&gt;DHL Parcel The Netherlands&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.disneyplus.com/&#34;&gt;Disney+ Streaming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://doomoolmori.com/&#34;&gt;Doomoolmori&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.dowjones.com&#34;&gt;Dow Jones&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.dpgrecruitment.nl&#34;&gt;DPG recruitment&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dream11.com&#34;&gt;Dream11&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://iot.telekom.com/en&#34;&gt;Deutsche Telekom IoT GmbH&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ebay.com&#34;&gt;eBay&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.eaglescience.nl&#34;&gt;Eaglescience&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.edf.fr/&#34;&gt;ElectricitÃ© de France (EDF)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.enelx.com&#34;&gt;EnelX&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://evolution.engineering&#34;&gt;Evolution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://evo.company&#34;&gt;Evo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://flipp.com/&#34;&gt;Flipp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.fugo.ai&#34;&gt;Fugo.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.garnercorp.com/&#34;&gt;Garner Distributed Workflow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gleancompany.com&#34;&gt;Glean&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://grandparade.co.uk&#34;&gt;GrandParade&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://greyflower.media&#34;&gt;greyflower.media GmbH&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hunters.ai&#34;&gt;Hunters.AI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hypefactors.com/&#34;&gt;Hypefactors&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.iheart.com/&#34;&gt;iHeartRadio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ihsmarkit.com/&#34;&gt;IHS Markit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://investsuite.com/&#34;&gt;Investsuite&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kaizen-solutions.net/&#34;&gt;Kaizen Solutions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kamon.io/&#34;&gt;Kamon APM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kodmagi.se&#34;&gt;Kodmagi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kensu.io&#34;&gt;Kensu&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lambdaworks.io/&#34;&gt;LambdaWorks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://leadiq.com&#34;&gt;LeadIQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.lernkunst.com/&#34;&gt;Lernkunst&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://liveintent.com&#34;&gt;LiveIntent Inc.&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lottoland.com&#34;&gt;Lottoland&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://matechs.com&#34;&gt;MATECHS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://megogo.net&#34;&gt;Megogo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mylivn.com/&#34;&gt;Mylivn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://newmotion.com&#34;&gt;NewMotion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nexxchange.com&#34;&gt;Nexxchange&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nike.com&#34;&gt;Nike&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nslookup.io&#34;&gt;NsLookup&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ocadotechnology.com&#34;&gt;Ocado Technology&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://olyro.de&#34;&gt;Olyro GmbH&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://optrak.com&#34;&gt;Optrak&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.performance-immo.com/&#34;&gt;Performance Immo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playtika.com&#34;&gt;Playtika&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ppcsamurai.com/&#34;&gt;PPC Samurai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://prezi.com/&#34;&gt;Prezi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.radix.bio/&#34;&gt;Radix Labs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.railroad19.com&#34;&gt;Railroad19&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.werkenbijrandstad.nl&#34;&gt;Randstad Groep Nederland&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.rapidor.co&#34;&gt;Rapidor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pimsolutions.ru/&#34;&gt;PIM Solutions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://rewe-digital.com/&#34;&gt;REWE Digital&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://riskident.com/&#34;&gt;Risk Ident&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rocker.com/&#34;&gt;Rocker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.rudder.io/&#34;&gt;Rudder&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sanjagh.pro/&#34;&gt;Sanjagh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scalac.io/&#34;&gt;Scalac&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.securityscorecard.io/&#34;&gt;SecurityScorecard&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.sentinelone.com/&#34;&gt;SentinelOne&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.signicat.com/&#34;&gt;Signicat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://info.sgmarkets.com/en/&#34;&gt;SociÃ©tÃ© GÃ©nÃ©rale Corporate and Investment Banking&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://softwaremill.com/&#34;&gt;SoftwareMill&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.streamweaver.com/&#34;&gt;StreamWeaver&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://stuart.com/&#34;&gt;Stuart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://teads.com&#34;&gt;Teads&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pokemon.com/us/about-pokemon/&#34;&gt;The Pokemon Company International&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tomtom.com&#34;&gt;TomTom&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.tinka.com/&#34;&gt;Tinka&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tinkoff.ru&#34;&gt;Tinkoff&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://trackabus.com&#34;&gt;Trackabus&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.trainor.no&#34;&gt;Trainor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tranzzo.com&#34;&gt;Tranzzo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://treutech.io&#34;&gt;TreuTech&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tweddle.com&#34;&gt;Tweddle Group&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.undo.app&#34;&gt;Undo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://unit.co&#34;&gt;Unit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://univalence.io&#34;&gt;Univalence&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.unzer.com&#34;&gt;Unzer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.vakantiediscounter.nl&#34;&gt;Vakantiediscounter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.verbund.com&#34;&gt;Verbund AG&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.waylay.io/&#34;&gt;Waylay&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.wehkamp.nl&#34;&gt;Wehkamp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.wolt.com/&#34;&gt;Wolt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://o.yandex.ru&#34;&gt;Yandex.Classifieds&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://audela.ca&#34;&gt;Audela&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://valamis.com&#34;&gt;Valamis Group&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://valsea.com&#34;&gt;Valsea&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://virtuslab.com/&#34;&gt;VirtusLab&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getvish.com&#34;&gt;Vish&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vivid.money&#34;&gt;Vivid Money&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zalando.com/&#34;&gt;Zalando&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zooz.com/&#34;&gt;Zooz&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Sponsors&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ziverge.com&#34; title=&#34;Ziverge&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/ziverge.png&#34; alt=&#34;Ziverge&#34; title=&#34;Ziverge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ziverge.com&#34; title=&#34;Ziverge&#34;&gt;Ziverge&lt;/a&gt; is a leading contributor to ZIO.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://scalac.io&#34; title=&#34;Scalac&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/scalac.svg?sanitize=true&#34; alt=&#34;Scalac&#34; title=&#34;Scalac&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://scalac.io&#34; title=&#34;Scalac&#34;&gt;Scalac&lt;/a&gt; sponsors ZIO Hackathons and contributes work to multiple projects in ZIO ecosystem.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://7mind.io&#34; title=&#34;Septimal Mind&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/septimal_mind.svg?sanitize=true&#34; alt=&#34;Septimal Mind&#34; title=&#34;Septimal Mind&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://7mind.io&#34; title=&#34;Septimal Mind&#34;&gt;Septimal Mind&lt;/a&gt; sponsors work on ZIO Tracing and continuous maintenance.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://softwaremill.com&#34; title=&#34;SoftwareMill&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/softwaremill.svg?sanitize=true&#34; alt=&#34;SoftwareMill&#34; title=&#34;SoftwareMill&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://softwaremill.com&#34; title=&#34;SoftwareMill&#34;&gt;SoftwareMill&lt;/a&gt; generously provides ZIO with paid-for CircleCI build infrastructure.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.yourkit.com&#34; title=&#34;YourKit&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/yourkit.png&#34; alt=&#34;YourKit&#34; title=&#34;YourKit&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.yourkit.com&#34; title=&#34;YourKit&#34;&gt;YourKit&lt;/a&gt; generously provides use of their monitoring and profiling tools to maximize the performance of ZIO applications.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://zio.dev/&#34;&gt;Learn More on the ZIO Homepage&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio/master/docs/about/code_of_conduct.md&#34;&gt;Code of Conduct&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;Come chat with us on &lt;a href=&#34;https://discord.gg/2ccFBr4&#34; title=&#34;Discord&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/629491597070827530?logo=discord&#34; alt=&#34;Badge-Discord&#34; title=&#34;chat on discord&#34;&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Legal&lt;/h3&gt; &#xA;&lt;p&gt;Copyright 2017 - 2020 John A. De Goes and the ZIO Contributors. All rights reserved.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rtyley/bfg-repo-cleaner</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/rtyley/bfg-repo-cleaner</id>
    <link href="https://github.com/rtyley/bfg-repo-cleaner" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Removes large or troublesome blobs like git-filter-branch does, but faster. And written in Scala&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BFG Repo-Cleaner &lt;a href=&#34;https://travis-ci.com/rtyley/bfg-repo-cleaner&#34;&gt;&lt;img src=&#34;https://travis-ci.com/rtyley/bfg-repo-cleaner.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Removes large or troublesome blobs like git-filter-branch does, but faster - and written in Scala&lt;/em&gt; - &lt;a href=&#34;https://j.mp/fund-bfg&#34;&gt;Fund the BFG&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bfg --strip-blobs-bigger-than 1M --replace-text banned.txt repo.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The BFG is a simpler, faster (&lt;a href=&#34;https://docs.google.com/spreadsheet/ccc?key=0AsR1d5Zpes8HdER3VGU1a3dOcmVHMmtzT2dsS2xNenc&#34;&gt;10 - 720x&lt;/a&gt; faster) alternative to &lt;code&gt;git-filter-branch&lt;/code&gt; for cleansing bad data out of your Git repository:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Removing &lt;strong&gt;Crazy Big Files&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Removing &lt;strong&gt;Passwords, Credentials&lt;/strong&gt; &amp;amp; other &lt;strong&gt;Private data&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Main documentation for The BFG is here : &lt;strong&gt;&lt;a href=&#34;https://rtyley.github.io/bfg-repo-cleaner/&#34;&gt;https://rtyley.github.io/bfg-repo-cleaner/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>chipsalliance/rocket-chip</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/chipsalliance/rocket-chip</id>
    <link href="https://github.com/chipsalliance/rocket-chip" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Rocket Chip Generator&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Rocket Chip Generator &lt;span&gt;ðŸš€&lt;/span&gt; &lt;img src=&#34;https://github.com/chipsalliance/rocket-chip/workflows/Continuous%20Integration/badge.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the Rocket chip generator necessary to instantiate the RISC-V Rocket Core. For more information on Rocket Chip, please consult our &lt;a href=&#34;http://www.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.html&#34;&gt;technical report&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#quick&#34;&gt;Quick instructions&lt;/a&gt; for those who want to dive directly into the details without knowing exactly what&#39;s in the repository.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#what&#34;&gt;What&#39;s in the Rocket chip generator repository?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#how&#34;&gt;How should I use the Rocket chip generator?&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#emulator&#34;&gt;Using the cycle-accurate Verilator simulation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#fpga&#34;&gt;Mapping a Rocket core down to an FPGA&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#vlsi&#34;&gt;Pushing a Rocket core through the VLSI tools&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#param&#34;&gt;How can I parameterize my Rocket chip?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#debug&#34;&gt;Debugging with GDB&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#ide&#34;&gt;Building Rocket Chip with an IDE&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#contributors&#34;&gt;Contributors&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;quick&#34;&gt;&lt;/a&gt; Quick Instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Checkout The Code&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ucb-bar/rocket-chip.git&#xA;$ cd rocket-chip&#xA;$ git submodule update --init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Setting up the RISCV environment variable&lt;/h3&gt; &#xA;&lt;p&gt;To build the rocket-chip repository, you must point the RISCV environment variable to your rocket-tools installation directory.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ export RISCV=/path/to/riscv/toolchain/installation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The rocket-tools repository known to work with rocket-chip is noted in the file riscv-tools.hash. However, any recent rocket-tools should work. You can build rocket-tools as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/freechipsproject/rocket-tools&#xA;$ cd rocket-tools&#xA;$ git submodule update --init --recursive&#xA;$ export RISCV=/path/to/install/riscv/toolchain&#xA;$ export MAKEFLAGS=&#34;$MAKEFLAGS -jN&#34; # Assuming you have N cores on your host system&#xA;$ ./build.sh&#xA;$ ./build-rv32ima.sh (if you are using RV32).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install Necessary Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;You may need to install some additional packages to use this repository. Rather than list all dependencies here, please see the appropriate section of the READMEs for each of the subprojects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/freechipsproject/rocket-tools/raw/master/README.md&#34;&gt;rocket-tools &#34;Ubuntu Packages Needed&#34;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ucb-bar/chisel3#installation&#34;&gt;chisel3 &#34;Installation&#34;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Building The Project&lt;/h3&gt; &#xA;&lt;p&gt;First, to build the C simulator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd emulator&#xA;$ make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or to build the VCS simulator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd vsim&#xA;$ make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In either case, you can run a set of assembly tests or simple benchmarks (Assuming you have N cores on your host system):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make -jN run-asm-tests&#xA;$ make -jN run-bmark-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To build a C simulator that is capable of VCD waveform generation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd emulator&#xA;$ make debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And to run the assembly tests on the C simulator and generate waveforms:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make -jN run-asm-tests-debug&#xA;$ make -jN run-bmark-tests-debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate FPGA- or VLSI-synthesizable Verilog (output will be in &lt;code&gt;vsim/generated-src&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd vsim&#xA;$ make verilog&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the Scala tests (&lt;code&gt;sbt test&lt;/code&gt;) or linter (&lt;code&gt;sbt scalafix&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd regression&#xA;&#xA;# Scala tests&#xA;$ make scalatest SUITE=foo&#xA;&#xA;# Scala linter, automatically modifying files to correct issues&#xA;$ make scalafix SUITE=foo&#xA;&#xA;# Scala linter, only printing out issues&#xA;$ make scalafix-check SUITE=foo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Keeping Your Repo Up-to-Date&lt;/h3&gt; &#xA;&lt;p&gt;If you are trying to keep your repo up to date with this GitHub repo, you also need to keep the submodules and tools up to date.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ # Get the newest versions of the files in this repo&#xA;$ git pull origin master&#xA;$ # Make sure the submodules have the correct versions&#xA;$ git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If rocket-tools version changes, you should recompile and install rocket-tools according to the directions in the &lt;a href=&#34;https://github.com/freechipsproject/rocket-tools/raw/master/README.md&#34;&gt;rocket-tools/README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd rocket-tools&#xA;$ ./build.sh&#xA;$ ./build-rv32ima.sh (if you are using RV32)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;what&#34;&gt;&lt;/a&gt; What&#39;s in the Rocket chip generator repository?&lt;/h2&gt; &#xA;&lt;p&gt;The rocket-chip repository is a meta-repository that points to several sub-repositories using &lt;a href=&#34;http://git-scm.com/book/en/Git-Tools-Submodules&#34;&gt;Git submodules&lt;/a&gt;. Those repositories contain tools needed to generate and test SoC designs. This respository also contains code that is used to generate RTL. Hardware generation is done using &lt;a href=&#34;http://chisel.eecs.berkeley.edu&#34;&gt;Chisel&lt;/a&gt;, a hardware construction language embedded in Scala. The rocket-chip generator is a Scala program that invokes the Chisel compiler in order to emit RTL describing a complete SoC. The following sections describe the components of this repository.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;what_submodules&#34;&gt;&lt;/a&gt;Git Submodules&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Tools-Submodules&#34;&gt;Git submodules&lt;/a&gt; allow you to keep a Git repository as a subdirectory of another Git repository. For projects being co-developed with the Rocket Chip Generator, we have often found it expedient to track them as submodules, allowing for rapid exploitation of new features while keeping commit histories separate. As submoduled projects adopt stable public APIs, we transition them to external dependencies. Here are the submodules that are currently being tracked in the rocket-chip repository:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;chisel3&lt;/strong&gt; (&lt;a href=&#34;https://github.com/ucb-bar/chisel3&#34;&gt;https://github.com/ucb-bar/chisel3&lt;/a&gt;): The Rocket Chip Generator uses &lt;a href=&#34;http://chisel.eecs.berkeley.edu&#34;&gt;Chisel&lt;/a&gt; to generate RTL.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;firrtl&lt;/strong&gt; (&lt;a href=&#34;https://github.com/ucb-bar/firrtl&#34;&gt;https://github.com/ucb-bar/firrtl&lt;/a&gt;): &lt;a href=&#34;http://bar.eecs.berkeley.edu/projects/2015-firrtl.html&#34;&gt;Firrtl (Flexible Internal Representation for RTL)&lt;/a&gt; is the intermediate representation of RTL constructions used by Chisel3. The Chisel3 compiler generates a Firrtl representation, from which the final product (Verilog code, C code, etc) is generated.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;hardfloat&lt;/strong&gt; (&lt;a href=&#34;https://github.com/ucb-bar/berkeley-hardfloat&#34;&gt;https://github.com/ucb-bar/berkeley-hardfloat&lt;/a&gt;): Hardfloat holds Chisel code that generates parameterized IEEE 754-2008 compliant floating-point units used for fused multiply-add operations, conversions between integer and floating-point numbers, and conversions between floating-point conversions with different precision.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;rocket-tools&lt;/strong&gt; (&lt;a href=&#34;https://github.com/freechipsproject/rocket-tools&#34;&gt;https://github.com/freechipsproject/rocket-tools&lt;/a&gt;): We tag a version of RISC-V software tools that work with the RTL committed in this repository.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;torture&lt;/strong&gt; (&lt;a href=&#34;https://github.com/ucb-bar/riscv-torture&#34;&gt;https://github.com/ucb-bar/riscv-torture&lt;/a&gt;): This module is used to generate and execute constrained random instruction streams that can be used to stress-test both the core and uncore portions of the design.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;what_packages&#34;&gt;&lt;/a&gt;Scala Packages&lt;/h3&gt; &#xA;&lt;p&gt;In addition to submodules that track independent Git repositories, the rocket-chip code base is itself factored into a number of Scala packages. These packages are all found within the src/main/scala directory. Some of these packages provide Scala utilities for generator configuration, while other contain the actual Chisel RTL generators themselves. Here is a brief description of what can be found in each package:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;amba&lt;/strong&gt; This RTL package uses diplomacy to generate bus implementations of AMBA protocols, including AXI4, AHB-lite, and APB.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;config&lt;/strong&gt; This utility package provides Scala interfaces for configuring a generator via a dynamically-scoped parameterization library.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;coreplex&lt;/strong&gt; This RTL package generates a complete coreplex by gluing together a variety of components from other packages, including: tiled Rocket cores, a system bus network, coherence agents, debug devices, interrupt handlers, externally-facing peripherals, clock-crossers and converters from TileLink to external bus protocols (e.g. AXI or AHB).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;devices&lt;/strong&gt; This RTL package contains implementations for peripheral devices, including the Debug module and various TL slaves.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;diplomacy&lt;/strong&gt; This utility package extends Chisel by allowing for two-phase hardware elaboration, in which certain parameters are dynamically negotiated between modules. For more information about diplomacy, see &lt;a href=&#34;https://carrv.github.io/2017/papers/cook-diplomacy-carrv2017.pdf&#34;&gt;this paper&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;groundtest&lt;/strong&gt; This RTL package generates synthesizable hardware testers that emit randomized memory access streams in order to stress-tests the uncore memory hierarchy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;jtag&lt;/strong&gt; This RTL package provides definitions for generating JTAG bus interfaces.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;regmapper&lt;/strong&gt; This utility package generates slave devices with a standardized interface for accessing their memory-mapped registers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;rocket&lt;/strong&gt; This RTL package generates the Rocket in-order pipelined core, as well as the L1 instruction and data caches. This library is intended to be used by a chip generator that instantiates the core within a memory system and connects it to the outside world.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;tile&lt;/strong&gt; This RTL package contains components that can be combined with cores to construct tiles, such as FPUs and accelerators.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;tilelink&lt;/strong&gt; This RTL package uses diplomacy to generate bus implementations of the TileLink protocol. It also contains a variety of adapters and protocol converters.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;system&lt;/strong&gt; This top-level utility package invokes Chisel to elaborate a particular configuration of a coreplex, along with the appropriate testing collateral.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;unittest&lt;/strong&gt; This utility package contains a framework for generateing synthesizable hardware testers of individual modules.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;util&lt;/strong&gt; This utility package provides a variety of common Scala and Chisel constructs that are re-used across multiple other packages,&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;what_else&#34;&gt;&lt;/a&gt;Other Resources&lt;/h3&gt; &#xA;&lt;p&gt;Outside of Scala, we also provide a variety of resources to create a complete SoC implementation and test the generated designs.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;bootrom&lt;/strong&gt; Sources for the first-stage bootloader included in the BootROM.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;csrc&lt;/strong&gt; C sources for use with Verilator simulation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;docs&lt;/strong&gt; Documentation, tutorials, etc for specific parts of the codebase.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;emulator&lt;/strong&gt; Directory in which Verilator simulations are compiled and run.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;project&lt;/strong&gt; Directory used by SBT for Scala compilation and build.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;regression&lt;/strong&gt; Defines continuous integration and nightly regression suites.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;scripts&lt;/strong&gt; Utilities for parsing the output of simulations or manipulating the contents of source files.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;vsim&lt;/strong&gt; Directory in which Synopsys VCS simulations are compiled and run.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;vsrc&lt;/strong&gt; Verilog sources containing interfaces, harnesses and VPI.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;what_toplevel&#34;&gt;&lt;/a&gt;Extending the Top-Level Design&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/ucb-bar/project-template&#34;&gt;this description&lt;/a&gt; of how to create you own top-level design with custom devices.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;how&#34;&gt;&lt;/a&gt; How should I use the Rocket chip generator?&lt;/h2&gt; &#xA;&lt;p&gt;Chisel can generate code for three targets: a high-performance cycle-accurate Verilator, Verilog optimized for FPGAs, and Verilog for VLSI. The rocket-chip generator can target all three backends. You will need a Java runtime installed on your machine, since Chisel is overlaid on top of &lt;a href=&#34;http://www.scala-lang.org/&#34;&gt;Scala&lt;/a&gt;. Chisel RTL (i.e. rocket-chip source code) is a Scala program executing on top of your Java runtime. To begin, ensure that the ROCKETCHIP environment variable points to the rocket-chip repository.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ucb-bar/rocket-chip.git&#xA;$ cd rocket-chip&#xA;$ export ROCKETCHIP=`pwd`&#xA;$ git submodule update --init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Before going any further, you must point the RISCV environment variable to your rocket-tools installation directory. If you do not yet have rocket-tools installed, follow the directions in the &lt;a href=&#34;https://github.com/freechipsproject/rocket-tools/raw/master/README.md&#34;&gt;rocket-tools/README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export RISCV=/path/to/install/riscv/toolchain&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Otherwise, you will see the following error message while executing any command in the rocket-chip generator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;*** Please set environment variable RISCV. Please take a look at README.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;emulator&#34;&gt;&lt;/a&gt; 1) Using the high-performance cycle-accurate Verilator&lt;/h3&gt; &#xA;&lt;p&gt;Your next step is to get the Verilator working. Assuming you have N cores on your host system, do the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/emulator&#xA;$ make -jN run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By doing so, the build system will generate C++ code for the cycle-accurate emulator, compile the emulator, compile all RISC-V assembly tests and benchmarks, and run both tests and benchmarks on the emulator. If Make finished without any errors, it means that the generated Rocket chip has passed all assembly tests and benchmarks!&lt;/p&gt; &#xA;&lt;p&gt;You can also run assembly tests and benchmarks separately:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make -jN run-asm-tests&#xA;$ make -jN run-bmark-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate vcd waveforms, you can run one of the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make -jN run-debug&#xA;$ make -jN run-asm-tests-debug&#xA;$ make -jN run-bmark-tests-debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or call out individual assembly tests or benchmarks:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make output/rv64ui-p-add.out&#xA;$ make output/rv64ui-p-add.vcd&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now take a look in the emulator/generated-src directory. You will find Chisel generated Verilog code and its associated C++ code generated by Verilator.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ls $ROCKETCHIP/emulator/generated-src&#xA;freechips.rocketchip.system.DefaultConfig&#xA;freechips.rocketchip.system.DefaultConfig.0x0.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x0.1.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x2000000.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x40.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0xc000000.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.anno.json&#xA;freechips.rocketchip.system.DefaultConfig.behav_srams.v&#xA;freechips.rocketchip.system.DefaultConfig.conf&#xA;freechips.rocketchip.system.DefaultConfig.d&#xA;freechips.rocketchip.system.DefaultConfig.dts&#xA;freechips.rocketchip.system.DefaultConfig.fir&#xA;freechips.rocketchip.system.DefaultConfig.graphml&#xA;freechips.rocketchip.system.DefaultConfig.json&#xA;freechips.rocketchip.system.DefaultConfig.memmap.json&#xA;freechips.rocketchip.system.DefaultConfig.plusArgs&#xA;freechips.rocketchip.system.DefaultConfig.rom.conf&#xA;freechips.rocketchip.system.DefaultConfig.v&#xA;TestHarness.anno.json&#xA;$ ls $ROCKETCHIP/emulator/generated-src/freechips.rocketchip.system.DefaultConfig&#xA;VTestHarness__1.cpp&#xA;VTestHarness__2.cpp&#xA;VTestHarness__3.cpp&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Also, output of the executed assembly tests and benchmarks can be found at emulator/output/*.out. Each file has a cycle-by-cycle dump of write-back stage of the pipeline. Here&#39;s an excerpt of emulator/output/rv64ui-p-add.out:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;C0: 483 [1] pc=[00000002138] W[r 3=000000007fff7fff][1] R[r 1=000000007fffffff] R[r 2=ffffffffffff8000] inst=[002081b3] add s1, ra, s0&#xA;C0: 484 [1] pc=[0000000213c] W[r29=000000007fff8000][1] R[r31=ffffffff80007ffe] R[r31=0000000000000005] inst=[7fff8eb7] lui t3, 0x7fff8&#xA;C0: 485 [0] pc=[00000002140] W[r 0=0000000000000000][0] R[r 0=0000000000000000] R[r 0=0000000000000000] inst=[00000000] unknown&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The first [1] at cycle 483, core 0, shows that there&#39;s a valid instruction at PC 0x2138 in the writeback stage, which is 0x002081b3 (add s1, ra, s0). The second [1] tells us that the register file is writing r3 with the corresponding value 0x7fff7fff. When the add instruction was in the decode stage, the pipeline had read r1 and r2 with the corresponding values next to it. Similarly at cycle 484, there&#39;s a valid instruction (lui instruction) at PC 0x213c in the writeback stage. At cycle 485, there isn&#39;t a valid instruction in the writeback stage, perhaps, because of a instruction cache miss at PC 0x2140.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;fpga&#34;&gt;&lt;/a&gt; 2) Mapping a Rocket core to an FPGA&lt;/h3&gt; &#xA;&lt;p&gt;You can generate synthesizable Verilog with the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make verilog CONFIG=freechips.rocketchip.system.DefaultFPGAConfig&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The Verilog used for the FPGA tools will be generated in vsim/generated-src. Please proceed further with the directions shown in the &lt;a href=&#34;https://github.com/sifive/freedom/raw/master/README.md&#34;&gt;README&lt;/a&gt; of the freedom repository. You can also run Rocket Chip on Amazon EC2 F1 with &lt;a href=&#34;https://github.com/firesim/firesim&#34;&gt;FireSim&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you have access to VCS, you will be able to run assembly tests and benchmarks in simulation with the following commands (again assuming you have N cores on your host machine):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make -jN run CONFIG=freechips.rocketchip.system.DefaultFPGAConfig&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The generated output looks similar to those generated from the emulator. Look into vsim/output/*.out for the output of the executed assembly tests and benchmarks.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;vlsi&#34;&gt;&lt;/a&gt; 3) Pushing a Rocket core through the VLSI tools&lt;/h3&gt; &#xA;&lt;p&gt;You can generate Verilog for your VLSI flow with the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make verilog&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now take a look at vsim/generated-src, and the contents of the Top.DefaultConfig.conf file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim/generated-src&#xA;freechips.rocketchip.system.DefaultConfig&#xA;freechips.rocketchip.system.DefaultConfig.0x0.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x0.1.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x2000000.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x40.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0xc000000.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.anno.json&#xA;freechips.rocketchip.system.DefaultConfig.behav_srams.v&#xA;freechips.rocketchip.system.DefaultConfig.conf&#xA;freechips.rocketchip.system.DefaultConfig.d&#xA;freechips.rocketchip.system.DefaultConfig.dts&#xA;freechips.rocketchip.system.DefaultConfig.fir&#xA;freechips.rocketchip.system.DefaultConfig.graphml&#xA;freechips.rocketchip.system.DefaultConfig.json&#xA;freechips.rocketchip.system.DefaultConfig.memmap.json&#xA;freechips.rocketchip.system.DefaultConfig.plusArgs&#xA;freechips.rocketchip.system.DefaultConfig.rom.conf&#xA;freechips.rocketchip.system.DefaultConfig.v&#xA;TestHarness.anno.json&#xA;$ cat $ROCKETCHIP/vsim/generated-src/*.conf&#xA;name data_arrays_0_ext depth 512 width 256 ports mrw mask_gran 8&#xA;name tag_array_ext depth 64 width 88 ports mrw mask_gran 22&#xA;name tag_array_0_ext depth 64 width 84 ports mrw mask_gran 21&#xA;name data_arrays_0_1_ext depth 512 width 128 ports mrw mask_gran 32&#xA;name mem_ext depth 33554432 width 64 ports mwrite,read mask_gran 8&#xA;name mem_2_ext depth 512 width 64 ports mwrite,read mask_gran 8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The conf file contains information for all SRAMs instantiated in the flow. If you take a close look at the $ROCKETCHIP/Makefrag, you will see that during Verilog generation, the build system calls a $(mem_gen) script with the generated configuration file as an argument, which will fill in the Verilog for the SRAMs. Currently, the $(mem_gen) script points to vsim/vlsi_mem_gen, which simply instantiates behavioral SRAMs. You will see those SRAMs being appended at the end of vsim/generated-src/Top.DefaultConfig.v. To target vendor-specific SRAMs, you will need to make necessary changes to vsim/vlsi_mem_gen.&lt;/p&gt; &#xA;&lt;p&gt;Similarly, if you have access to VCS, you can run assembly tests and benchmarks with the following commands (again assuming you have N cores on your host machine):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make -jN run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The generated output looks similar to those generated from the emulator. Look into vsim/output/*.out for the output of the executed assembly tests and benchmarks.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;param&#34;&gt;&lt;/a&gt; How can I parameterize my Rocket chip?&lt;/h2&gt; &#xA;&lt;p&gt;By now, you probably figured out that all generated files have a configuration name attached, e.g. &lt;code&gt;freechips.rocketchip.system.DefaultConfig&lt;/code&gt;. Take a look at &lt;code&gt;src/main/scala/system/Configs.scala&lt;/code&gt;. Search for &lt;code&gt;NSets&lt;/code&gt; and &lt;code&gt;NWays&lt;/code&gt; defined in &lt;code&gt;BaseConfig&lt;/code&gt;. You can change those numbers to get a Rocket core with different cache parameters. For example, by changing L1I, NWays to 4, you will get a 32KB 4-way set-associative L1 instruction cache rather than a 16KB 2-way set-associative L1 instruction cache. Towards the end, you can also find that &lt;code&gt;DefaultSmallConfig&lt;/code&gt; inherits all parameters from &lt;code&gt;BaseConfig&lt;/code&gt; but overrides the same parameters of &lt;code&gt;WithNSmallCores&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Now take a look at &lt;code&gt;vsim/Makefile&lt;/code&gt;. Search for the &lt;code&gt;CONFIG&lt;/code&gt; variable. By default, it is set to &lt;code&gt;freechips.rocketchip.system.DefaultConfig&lt;/code&gt;. You can also change the CONFIG variable on the make command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make -jN CONFIG=freechips.rocketchip.system.DefaultSmallConfig run-asm-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, even by defining CONFIG as an environment variable:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ export CONFIG=freechips.rocketchip.system.DefaultSmallConfig&#xA;$ make -jN run-asm-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This parameterization is one of the many strengths of processor generators written in Chisel, and will be more detailed in a future blog post, so please stay tuned.&lt;/p&gt; &#xA;&lt;p&gt;To override specific configuration items, such as the number of external interrupts, you can create your own Configuration(s) and compose them with Config&#39;s ++ operator&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;class WithNExtInterrupts(nExt: Int) extends Config {&#xA;    (site, here, up) =&amp;gt; {&#xA;        case NExtInterrupts =&amp;gt; nExt&#xA;    }&#xA;}&#xA;class MyConfig extends Config (new WithNExtInterrupts(16) ++ new DefaultSmallConfig)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then you can build as usual with &lt;code&gt;CONFIG=&amp;lt;MyConfigPackage&amp;gt;.MyConfig&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;debug&#34;&gt;&lt;/a&gt; Debugging with GDB&lt;/h2&gt; &#xA;&lt;h3&gt;1) Generating the Remote Bit-Bang (RBB) Emulator&lt;/h3&gt; &#xA;&lt;p&gt;The objective of this section is to use GNU debugger to debug RISC-V programs running on the emulator in the same fashion as in &lt;a href=&#34;https://github.com/riscv/riscv-isa-sim#debugging-with-gdb&#34;&gt;Spike&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For that we need to add a Remote Bit-Bang client to the emulator. We can do so by extending our Config with JtagDTMSystem, which will add a DebugTransportModuleJTAG to the DUT and connect a SimJTAG module in the Test Harness. This will allow OpenOCD to interface with the emulator, and GDB can interface with OpenOCD. In the following example we add this Config alteration to &lt;code&gt;src/main/scala/system/Configs.scala&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;class DefaultConfigRBB extends Config(&#xA;new WithJtagDTMSystem ++ new WithNBigCores(1) ++ new WithCoherentBusTopology ++ new BaseConfig)&#xA;&#xA;class QuadCoreConfigRBB extends Config(&#xA;new WithJtagDTMSystem ++ new WithNBigCores(4) ++ new WithCoherentBusTopology ++ new BaseConfig)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To build the emulator with &lt;code&gt;DefaultConfigRBB&lt;/code&gt; configuration we use the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;rocket-chip$ cd emulator&#xA;emulator$ CONFIG=freechips.rocketchip.system.DefaultConfigRBB make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can also build a debug version capable of generating VCD waveforms using the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;emulator$ CONFIG=freechips.rocketchip.system.DefaultConfigRBB make debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default the emulator is generated under the name &lt;code&gt;emulator-freechips.rocketchip.system-DefaultConfigRBB&lt;/code&gt; in the first case and &lt;code&gt;emulator-freechips.rocketchip.system-DefaultConfigRBB-debug&lt;/code&gt; in the second.&lt;/p&gt; &#xA;&lt;h3&gt;2) Compiling and executing a custom program using the emulator&lt;/h3&gt; &#xA;&lt;p&gt;We suppose that &lt;code&gt;helloworld&lt;/code&gt; is our program, you can use &lt;code&gt;crt.S&lt;/code&gt;, &lt;code&gt;syscalls.c&lt;/code&gt; and the linker script &lt;code&gt;test.ld&lt;/code&gt; to construct your own program, check examples stated in &lt;a href=&#34;https://github.com/riscv/riscv-tests&#34;&gt;riscv-tests&lt;/a&gt;. Note that &lt;code&gt;test.ld&lt;/code&gt; loads the program at 0x80000000 so you will need to use &lt;code&gt;-mcmodel=medany&lt;/code&gt; otherwise you will get relocation errors. See &lt;a href=&#34;https://www.sifive.com/blog/2017/09/11/all-aboard-part-4-risc-v-code-models/&#34;&gt;All Aboard, Part 4: The RISC-V Code Models&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;In our case we will use the following example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;char text[] = &#34;Vafgehpgvba frgf jnag gb or serr!&#34;;&#xA;&#xA;// Don&#39;t use the stack, because sp isn&#39;t set up.&#xA;volatile int wait = 1;&#xA;&#xA;int main()&#xA;{&#xA;    while (wait)&#xA;        ;&#xA;&#xA;    // Doesn&#39;t actually go on the stack, because there are lots of GPRs.&#xA;    int i = 0;&#xA;    while (text[i]) {&#xA;        char lower = text[i] | 32;&#xA;        if (lower &amp;gt;= &#39;a&#39; &amp;amp;&amp;amp; lower &amp;lt;= &#39;m&#39;)&#xA;            text[i] += 13;&#xA;        else if (lower &amp;gt; &#39;m&#39; &amp;amp;&amp;amp; lower &amp;lt;= &#39;z&#39;)&#xA;            text[i] -= 13;&#xA;        i++;&#xA;    }&#xA;&#xA;    while (!wait)&#xA;        ;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;First we can test if your program executes well in the simple version of emulator before moving to debugging in step 3 :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig helloworld &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additional verbose information (clock cycle, pc, instruction being executed) can be printed using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig +verbose helloworld 2&amp;gt;&amp;amp;1 | spike-dasm &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;VCD output files can be obtained using the &lt;code&gt;-debug&lt;/code&gt; version of the emulator and are specified using &lt;code&gt;-v&lt;/code&gt; or &lt;code&gt;--vcd=FILE&lt;/code&gt; arguments. A detailed log file of all executed instructions can also be obtained from the emulator, this is an example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig-debug +verbose -v output.vcd  helloworld 2&amp;gt;&amp;amp;1 | spike-dasm &amp;gt; output.log&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please note that generated VCD waveforms and execution log files can be very voluminous depending on the size of the .elf file (i.e. code size + debugging symbols).&lt;/p&gt; &#xA;&lt;p&gt;Please note also that the time it takes the emulator to load your program depends on executable size. Stripping the .elf executable will unsurprisingly make it run faster. For this you can use &lt;code&gt;$RISCV/bin/riscv64-unknown-elf-strip&lt;/code&gt; tool to reduce the size. This is good for accelerating your simulation but not for debugging. Keep in mind that the HTIF communication interface between our system and the emulator relies on &lt;code&gt;tohost&lt;/code&gt; and &lt;code&gt;fromhost&lt;/code&gt; symbols to communicate. This is why you may get the following error when you try to run a totally stripped executable on the emulator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig totally-stripped-helloworld &#xA;This emulator compiled with JTAG Remote Bitbang client. To enable, use +jtag_rbb_enable=1.&#xA;Listening on port 46529&#xA;warning: tohost and fromhost symbols not in ELF; can&#39;t communicate with target&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To resolve this, we need to strip all the .elf executable but keep &lt;code&gt;tohost&lt;/code&gt; and &lt;code&gt;fromhost&lt;/code&gt; symbols using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$riscv64-unknown-elf-strip -s -Kfromhost -Ktohost helloworld&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More details on the GNU strip tool can be found &lt;a href=&#34;https://www.thegeekstuff.com/2012/09/strip-command-examples/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The interest of this step is to make sure your program executes well. To perform debugging you need the original unstripped version, as explained in step 3.&lt;/p&gt; &#xA;&lt;h3&gt;3) Launch the emulator&lt;/h3&gt; &#xA;&lt;p&gt;First, do not forget to compile your program with &lt;code&gt;-g -Og&lt;/code&gt; flags to provide debugging support as explained &lt;a href=&#34;https://github.com/riscv/riscv-isa-sim#debugging-with-gdb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We can then launch the Remote Bit-Bang enabled emulator with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./emulator-freechips.rocketchip.system-DefaultConfigRBB +jtag_rbb_enable=1 --rbb-port=9823 helloworld&#xA;This emulator compiled with JTAG Remote Bitbang client. To enable, use +jtag_rbb_enable=1.&#xA;Listening on port 9823&#xA;Attempting to accept client socket&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use the &lt;code&gt;emulator-freechips.rocketchip.system-DefaultConfigRBB-debug&lt;/code&gt; version instead if you would like to generate VCD waveforms.&lt;/p&gt; &#xA;&lt;p&gt;Please note that if the argument &lt;code&gt;--rbb-port&lt;/code&gt; is not passed, a default free TCP port on your computer will be chosen randomly.&lt;/p&gt; &#xA;&lt;p&gt;Please note also that when debugging with GDB, the .elf file is not actually loaded by the FESVR. In contrast with Spike, it must be loaded from GDB as explained in step 5. So the &lt;code&gt;helloworld&lt;/code&gt; argument may be replaced by any dummy name.&lt;/p&gt; &#xA;&lt;h3&gt;4) Launch OpenOCD&lt;/h3&gt; &#xA;&lt;p&gt;You will need a RISC-V Enabled OpenOCD binary. This is installed with rocket-tools in &lt;code&gt;$(RISCV)/bin/openocd&lt;/code&gt;, or can be compiled manually from riscv-openocd. OpenOCD requires a configuration file, in which we define the RBB port we will use, which is in our case &lt;code&gt;9823&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cat cemulator.cfg &#xA;interface remote_bitbang&#xA;remote_bitbang_host localhost&#xA;remote_bitbang_port 9823&#xA;&#xA;set _CHIPNAME riscv&#xA;jtag newtap $_CHIPNAME cpu -irlen 5&#xA;&#xA;set _TARGETNAME $_CHIPNAME.cpu&#xA;target create $_TARGETNAME riscv -chain-position $_TARGETNAME&#xA;&#xA;gdb_report_data_abort enable&#xA;&#xA;init&#xA;halt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then we launch OpenOCD in another terminal using the command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$(RISCV)/bin/openocd -f ./cemulator.cfg&#xA;Open On-Chip Debugger 0.10.0+dev-00112-g3c1c6e0 (2018-04-12-10:40)&#xA;Licensed under GNU GPL v2&#xA;For bug reports, read&#xA;http://openocd.org/doc/doxygen/bugs.html&#xA;Warn : Adapter driver &#39;remote_bitbang&#39; did not declare which transports it allows; assuming legacy JTAG-only&#xA;Info : only one transport option; autoselect &#39;jtag&#39;&#xA;Info : Initializing remote_bitbang driver&#xA;Info : Connecting to localhost:9823&#xA;Info : remote_bitbang driver initialized&#xA;Info : This adapter doesn&#39;t support configurable speed&#xA;Info : JTAG tap: riscv.cpu tap/device found: 0x00000001 (mfg: 0x000 (&amp;lt;invalid&amp;gt;), part: 0x0000, ver: 0x0)&#xA;Info : datacount=2 progbufsize=16&#xA;Info : Disabling abstract command reads from CSRs.&#xA;Info : Disabling abstract command writes to CSRs.&#xA;Info : [0] Found 1 triggers&#xA;Info : Examined RISC-V core; found 1 harts&#xA;Info :  hart 0: XLEN=64, 1 triggers&#xA;Info : Listening on port 3333 for gdb connections&#xA;Info : Listening on port 6666 for tcl connections&#xA;Info : Listening on port 4444 for telnet connections&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A &lt;code&gt;-d&lt;/code&gt; flag can be added to the command to show further debug information.&lt;/p&gt; &#xA;&lt;h3&gt;5) Launch GDB&lt;/h3&gt; &#xA;&lt;p&gt;In another terminal launch GDB and point to the elf file you would like to load then run it with the debugger (in this example, &lt;code&gt;helloworld&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ riscv64-unknown-elf-gdb helloworld&#xA;GNU gdb (GDB) 8.0.50.20170724-git&#xA;Copyright (C) 2017 Free Software Foundation, Inc.&#xA;License GPLv3+: GNU GPL version 3 or later &amp;lt;http://gnu.org/licenses/gpl.html&amp;gt;&#xA;This is free software: you are free to change and redistribute it.&#xA;There is NO WARRANTY, to the extent permitted by law.  Type &#34;show copying&#34;&#xA;and &#34;show warranty&#34; for details.&#xA;This GDB was configured as &#34;--host=x86_64-pc-linux-gnu --target=riscv64-unknown-elf&#34;.&#xA;Type &#34;show configuration&#34; for configuration details.&#xA;For bug reporting instructions, please see:&#xA;&amp;lt;http://www.gnu.org/software/gdb/bugs/&amp;gt;.&#xA;Find the GDB manual and other documentation resources online at:&#xA;&amp;lt;http://www.gnu.org/software/gdb/documentation/&amp;gt;.&#xA;For help, type &#34;help&#34;.&#xA;Type &#34;apropos word&#34; to search for commands related to &#34;word&#34;...&#xA;Reading symbols from ./proj1.out...done.&#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Compared to Spike, the C Emulator is very slow, so several problems may be encountered due to timeouts between issuing commands and response from the emulator. To solve this problem, we increase the timeout with the GDB &lt;code&gt;set remotetimeout&lt;/code&gt; command.&lt;/p&gt; &#xA;&lt;p&gt;After that we load our program by performing a &lt;code&gt;load&lt;/code&gt; command. This automatically sets the &lt;code&gt;$PC&lt;/code&gt; to the &lt;code&gt;_start&lt;/code&gt; symbol in our .elf file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(gdb) set remotetimeout 2000&#xA;(gdb) target remote localhost:3333&#xA;Remote debugging using localhost:3333&#xA;0x0000000000010050 in ?? ()&#xA;(gdb) load&#xA;Loading section .text.init, size 0x2cc lma 0x80000000&#xA;Loading section .tohost, size 0x48 lma 0x80001000&#xA;Loading section .text, size 0x98c lma 0x80001048&#xA;Loading section .rodata, size 0x158 lma 0x800019d4&#xA;Loading section .rodata.str1.8, size 0x20 lma 0x80001b30&#xA;Loading section .data, size 0x22 lma 0x80001b50&#xA;Loading section .sdata, size 0x4 lma 0x80001b74&#xA;Start address 0x80000000, load size 3646&#xA;Transfer rate: 40 bytes/sec, 520 bytes/write.&#xA;(gdb) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now we can proceed as with Spike, debugging works in a similar way:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(gdb) print wait&#xA;$1 = 1&#xA;(gdb) print wait=0&#xA;$2 = 0&#xA;(gdb) print text&#xA;$3 = &#34;Vafgehpgvba frgf jnag gb or serr!&#34;&#xA;(gdb) c&#xA;Continuing.&#xA;&#xA;^C&#xA;Program received signal SIGINT, Interrupt.&#xA;main (argc=0, argv=&amp;lt;optimized out&amp;gt;) at src/main.c:33&#xA;33&#x9;    while (!wait)&#xA;(gdb) print wait&#xA;$4 = 0&#xA;(gdb) print text&#xA;$5 = &#34;Instruction sets want to be free!&#34;&#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Further information about GDB debugging is available &lt;a href=&#34;https://sourceware.org/gdb/onlinedocs/gdb/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://sourceware.org/gdb/onlinedocs/gdb/Remote-Debugging.html#Remote-Debugging&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;ide&#34;&gt;&lt;/a&gt; Building Rocket Chip with an IDE&lt;/h2&gt; &#xA;&lt;p&gt;The Rocket Chip Scala build uses the standard Scala build tool SBT. IDEs like &lt;a href=&#34;https://www.jetbrains.com/idea/&#34;&gt;IntelliJ&lt;/a&gt; and &lt;a href=&#34;https://code.visualstudio.com/&#34;&gt;VSCode&lt;/a&gt; are popular in the Scala community and work with Rocket Chip. To use one of these IDEs, there is one minor peculiarity of the Rocket Chip build that must be addressed.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;contributors&#34;&gt;&lt;/a&gt; Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Contributing guidelines can be found in &lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;A list of contributors can be found &lt;a href=&#34;https://github.com/chipsalliance/rocket-chip/graphs/contributors&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;attribution&#34;&gt;&lt;/a&gt; Attribution&lt;/h2&gt; &#xA;&lt;p&gt;If used for research, please cite Rocket Chip by the technical report:&lt;/p&gt; &#xA;&lt;p&gt;Krste AsanoviÄ‡, Rimas AviÅ¾ienis, Jonathan Bachrach, Scott Beamer, David Biancolin, Christopher Celio, Henry Cook, Palmer Dabbelt, John Hauser, Adam Izraelevitz, Sagar Karandikar, Benjamin Keller, Donggyu Kim, John Koenig, Yunsup Lee, Eric Love, Martin Maas, Albert Magyar, Howard Mao, Miquel Moreto, Albert Ou, David Patterson, Brian Richards, Colin Schmidt, Stephen Twigg, Huy Vo, and Andrew Waterman, &lt;em&gt;&lt;a href=&#34;http://www.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.html&#34;&gt;The Rocket Chip Generator&lt;/a&gt;&lt;/em&gt;, Technical Report UCB/EECS-2016-17, EECS Department, University of California, Berkeley, April 2016&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>softwaremill/tapir</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/softwaremill/tapir</id>
    <link href="https://github.com/softwaremill/tapir" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Declarative, type-safe web endpoints library&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/banner.png&#34; alt=&#34;tapir, or Typed API descRiptions&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/softwaremill/tapir?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/Join%20Chat.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/softwaremill/tapir&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/softwaremill/tapir/actions?query=workflow%3A%22CI%22&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.softwaremill.sttp.tapir/tapir-core_2.13&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/com.softwaremill.sttp.tapir/tapir-core_2.13/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Why tapir?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;type-safety&lt;/strong&gt;: compile-time guarantees, develop-time completions, read-time information&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;declarative&lt;/strong&gt;: separate the shape of the endpoint (the &#34;what&#34;), from the server logic (the &#34;how&#34;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;OpenAPI / Swagger integration&lt;/strong&gt;: generate documentation from endpoint descriptions&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;observability&lt;/strong&gt;: leverage the metadata to report rich metrics and tracing information&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;abstraction&lt;/strong&gt;: re-use common endpoint definitions, as well as individual inputs/outputs&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;library, not a framework&lt;/strong&gt;: integrates with your stack&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Intro&lt;/h2&gt; &#xA;&lt;p&gt;With tapir, you can describe HTTP API endpoints as immutable Scala values. Each endpoint can contain a number of input parameters, error-output parameters, and normal-output parameters. An endpoint specification can be interpreted as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;a server, given the &#34;business logic&#34;: a function, which computes output parameters based on input parameters. Currently supported: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/akkahttp.html&#34;&gt;Akka HTTP&lt;/a&gt; &lt;code&gt;Route&lt;/code&gt;s/&lt;code&gt;Directive&lt;/code&gt;s&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/http4s.html&#34;&gt;Http4s&lt;/a&gt; &lt;code&gt;HttpRoutes[F]&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/netty.html&#34;&gt;Netty&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/finatra.html&#34;&gt;Finatra&lt;/a&gt; &lt;code&gt;FinatraRoute&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/play.html&#34;&gt;Play&lt;/a&gt; &lt;code&gt;Route&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/ziohttp.html&#34;&gt;ZIO Http&lt;/a&gt; &lt;code&gt;Http&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/armeria.html&#34;&gt;Armeria&lt;/a&gt; &lt;code&gt;HttpServiceWithRoutes&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/aws.html&#34;&gt;aws&lt;/a&gt; through Lambda/SAM/Terraform&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;a client, which is a function from input parameters to output parameters. Currently supported: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/client/sttp.html&#34;&gt;sttp&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/client/play.html&#34;&gt;Play&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/client/http4s.html&#34;&gt;http4s&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;documentation. Currently supported: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/docs/openapi.html&#34;&gt;OpenAPI&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/docs/asyncapi.html&#34;&gt;AsyncAPI&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Adopters&lt;/h2&gt; &#xA;&lt;p&gt;Is your company already using tapir? We&#39;re continually expanding the &#34;adopters&#34; section in the documentation; the more the merrier! It would be great to feature your company&#39;s logo, but in order to do that, we&#39;ll need written permission to avoid any legal misunderstandings.&lt;/p&gt; &#xA;&lt;p&gt;Please email us at &lt;a href=&#34;mailto:tapir@softwaremill.com&#34;&gt;tapir@softwaremill.com&lt;/a&gt; from your company&#39;s email with a link to your logo (if we can use it, of course!) or with details who to kindly ask for permission to feature the logo in tapir&#39;s documentation. We&#39;ll handle the rest.&lt;/p&gt; &#xA;&lt;p&gt;We&#39;re seeing tapir&#39;s download numbers going steadily up; as we&#39;re nearing 1.0, the additional confidence boost for newcomers will help us to build tapir&#39;s ecosystem and make it thrive. Thank you! :)&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.adobe.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/adobe.png&#34; alt=&#34;Adobe&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.colisweb.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/colisweb.png&#34; alt=&#34;Colisweb&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://swissborg.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/swissborg.png&#34; alt=&#34;Swissborg&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://kaizo.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/kaizo.png&#34; alt=&#34;Kaizo&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.process.st/&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/process_street.png&#34; alt=&#34;Process Street&#34; width=&#34;100&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.tranzzo.com/&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/tranzzo.svg?sanitize=true&#34; alt=&#34;Tranzzo&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.kelkoogroup.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/kelkoogroup.png&#34; alt=&#34;Kelkoo group&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.softwaremill.com/&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/softwaremill.png&#34; alt=&#34;SoftwareMill&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.carvana.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/carvana.svg?sanitize=true&#34; alt=&#34;Carvana&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.moneyfarm.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/moneyfarm.png&#34; alt=&#34;Moneyfarm&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.ocadogroup.com/about-us/ocado-technology&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/ocado.png&#34; alt=&#34;Ocado Technology&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.wegtam.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/wegtam.svg?sanitize=true&#34; alt=&#34;Wegtam&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Teaser&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import sttp.tapir._&#xA;import sttp.tapir.generic.auto._&#xA;import sttp.tapir.json.circe._&#xA;import io.circe.generic.auto._&#xA;&#xA;type Limit = Int&#xA;type AuthToken = String&#xA;case class BooksFromYear(genre: String, year: Int)&#xA;case class Book(title: String)&#xA;&#xA;&#xA;// Define an endpoint&#xA;&#xA;val booksListing: PublicEndpoint[(BooksFromYear, Limit, AuthToken), String, List[Book], Any] = &#xA;  endpoint&#xA;    .get&#xA;    .in((&#34;books&#34; / path[String](&#34;genre&#34;) / path[Int](&#34;year&#34;)).mapTo[BooksFromYear])&#xA;    .in(query[Limit](&#34;limit&#34;).description(&#34;Maximum number of books to retrieve&#34;))&#xA;    .in(header[AuthToken](&#34;X-Auth-Token&#34;))&#xA;    .errorOut(stringBody)&#xA;    .out(jsonBody[List[Book]])&#xA;&#xA;&#xA;// Generate OpenAPI documentation&#xA;&#xA;import sttp.apispec.openapi.circe.yaml._&#xA;import sttp.tapir.docs.openapi.OpenAPIDocsInterpreter&#xA;&#xA;val docs = OpenAPIDocsInterpreter().toOpenAPI(booksListing, &#34;My Bookshop&#34;, &#34;1.0&#34;)&#xA;println(docs.toYaml)&#xA;&#xA;&#xA;// Convert to akka-http Route&#xA;&#xA;import sttp.tapir.server.akkahttp.AkkaHttpServerInterpreter&#xA;import akka.http.scaladsl.server.Route&#xA;import scala.concurrent.Future&#xA;import scala.concurrent.ExecutionContext.Implicits.global&#xA;&#xA;def bookListingLogic(bfy: BooksFromYear,&#xA;                     limit: Limit,&#xA;                     at: AuthToken): Future[Either[String, List[Book]]] =&#xA;  Future.successful(Right(List(Book(&#34;The Sorrows of Young Werther&#34;))))&#xA;  &#xA;val booksListingRoute: Route = AkkaHttpServerInterpreter()&#xA;  .toRoute(booksListing.serverLogic((bookListingLogic _).tupled))&#xA;&#xA;&#xA;// Convert to sttp Request&#xA;&#xA;import sttp.tapir.client.sttp.SttpClientInterpreter&#xA;import sttp.client3._&#xA;&#xA;val booksListingRequest: Request[DecodeResult[Either[String, List[Book]]], Any] = &#xA;  SttpClientInterpreter()&#xA;    .toRequest(booksListing, Some(uri&#34;http://localhost:8080&#34;))&#xA;    .apply((BooksFromYear(&#34;SF&#34;, 2016), 20, &#34;xyz-abc-123&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;tapir documentation is available at &lt;a href=&#34;http://tapir.softwaremill.com&#34;&gt;tapir.softwaremill.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart with sbt&lt;/h2&gt; &#xA;&lt;p&gt;Add the following dependency:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sbt&#34;&gt;&#34;com.softwaremill.sttp.tapir&#34; %% &#34;tapir-core&#34; % &#34;1.0.0-RC1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Partial unification is now enabled by default from Scala 2.13. However, if you&#39;re using Scala 2.12 or older, then you&#39;ll need partial unification enabled in the compiler (alternatively, you&#39;ll need to manually provide type arguments in some cases):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sbt&#34;&gt;scalacOptions += &#34;-Ypartial-unification&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, import:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import sttp.tapir._&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And finally, type &lt;code&gt;endpoint.&lt;/code&gt; and see where auto-complete gets you!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Sidenote for scala 2.12.4 and higher: if you encounter an issue with compiling your project because of a &lt;code&gt;StackOverflowException&lt;/code&gt; related to &lt;a href=&#34;https://github.com/scala/bug/issues/10604&#34;&gt;this&lt;/a&gt; scala bug, please increase your stack memory. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sbt -J-Xss4M clean compile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Other sttp projects&lt;/h2&gt; &#xA;&lt;p&gt;sttp is a family of Scala HTTP-related projects, and currently includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/softwaremill/sttp&#34;&gt;sttp client&lt;/a&gt;: the Scala HTTP client you always wanted!&lt;/li&gt; &#xA; &lt;li&gt;sttp tapir: this project&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/softwaremill/sttp-model&#34;&gt;sttp model&lt;/a&gt;: simple HTTP model classes (used by client &amp;amp; tapir)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/softwaremill/sttp-shared&#34;&gt;sttp shared&lt;/a&gt;: shared web socket, FP abstractions, capabilities and streaming code.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/softwaremill/sttp-apispec&#34;&gt;sttp apispec&lt;/a&gt;: OpenAPI, AsyncAPI and JSON Schema models.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Tapir is an early stage project. Everything might change. All suggestions welcome :)&lt;/p&gt; &#xA;&lt;p&gt;See the list of &lt;a href=&#34;https://github.com/softwaremill/tapir/issues&#34;&gt;issues&lt;/a&gt; and pick one! Or report your own.&lt;/p&gt; &#xA;&lt;p&gt;If you are having doubts on the &lt;em&gt;why&lt;/em&gt; or &lt;em&gt;how&lt;/em&gt; something works, don&#39;t hesitate to ask a question on &lt;a href=&#34;https://gitter.im/softwaremill/tapir&#34;&gt;gitter&lt;/a&gt; or via github. This probably means that the documentation, scaladocs or code is unclear and be improved for the benefit of all.&lt;/p&gt; &#xA;&lt;h3&gt;Testing locally&lt;/h3&gt; &#xA;&lt;p&gt;The JS tests use &lt;a href=&#34;https://github.com/scala-js/scala-js-env-selenium/issues/119&#34;&gt;Gecko instead of Chrome&lt;/a&gt;, although this causes another problem: out of memory when running JS tests for multiple modules. Work-arounds:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run only JVM tests for a specific Scala version using &lt;code&gt;testJVM2_13&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;test single JS projects&lt;/li&gt; &#xA; &lt;li&gt;use CI (GitHub Actions) to test all projects - the &lt;code&gt;.github/workflows/ci.yml&lt;/code&gt; enumerates them one by one&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can test only server/client/doc/other projects using &lt;code&gt;testServers&lt;/code&gt;, &lt;code&gt;testClients&lt;/code&gt;, &lt;code&gt;testDocs&lt;/code&gt; and &lt;code&gt;testOther&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To verify that the code snippet in docs compile, run &lt;code&gt;compileDocumentation&lt;/code&gt;. A full mdoc run is done during a release (when the documentation is generated).&lt;/p&gt; &#xA;&lt;h2&gt;Commercial Support&lt;/h2&gt; &#xA;&lt;p&gt;We offer commercial support for tapir and related technologies, as well as development services. &lt;a href=&#34;https://softwaremill.com&#34;&gt;Contact us&lt;/a&gt; to learn more about our offer!&lt;/p&gt; &#xA;&lt;h2&gt;Copyright&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (C) 2018-2022 SoftwareMill &lt;a href=&#34;https://softwaremill.com&#34;&gt;https://softwaremill.com&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>twitter/scrooge</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/twitter/scrooge</id>
    <link href="https://github.com/twitter/scrooge" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Thrift parser/generator&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Scrooge&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/twitter/scrooge/actions?query=workflow%3A%22continuous+integration%22+branch%3Adevelop&#34;&gt;&lt;img src=&#34;https://github.com/twitter/scrooge/workflows/continuous%20integration/badge.svg?branch=develop&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/twitter/scrooge&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/twitter/scrooge/branch/develop/graph/badge.svg?sanitize=true&#34; alt=&#34;Codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/twitter/scrooge/develop/#status&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/status-active-brightgreen.svg?sanitize=true&#34; alt=&#34;Project status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/twitter/finagle?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/twitter/finagle.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.twitter/scrooge-core_2.12&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/com.twitter/scrooge-core_2.12/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Scrooge is a &lt;a href=&#34;https://thrift.apache.org/&#34;&gt;thrift&lt;/a&gt; code generator written in Scala, which currently generates code for Scala, Java, Cocoa, Android and Lua.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s meant to be a replacement for the apache thrift code generator, and generates conforming, compatible binary codecs by building on top of libthrift. It integrates with the &lt;a href=&#34;https://github.com/twitter/finagle&#34;&gt;finagle&lt;/a&gt; project, exporting stats and finagle APIs, and makes it easy to build high throughput, low latency, robust thrift servers and clients.&lt;/p&gt; &#xA;&lt;p&gt;Part of the motivation behind scrooge&#39;s scala implementation is that since Scala is API-compatible with Java, you can use the apache thrift code generator to generate Java files and use them from within Scala, but the generated code uses Java collections and mutable &#34;bean&#34; classes, causing some annoying boilerplate conversions to be hand-written. Scrooge bypasses the problem by generating Scala code directly. It also uses Scala syntax so the generated code is much more compact.&lt;/p&gt; &#xA;&lt;p&gt;There is a comprehensive set of unit tests, which generate code, compile it, and execute it to verify expectations, as well as gold files to make it easy to review the effects of changes to the generator.&lt;/p&gt; &#xA;&lt;h2&gt;Status&lt;/h2&gt; &#xA;&lt;p&gt;This project is used in production at Twitter (and many other organizations), and is actively developed and maintained.&lt;/p&gt; &#xA;&lt;h2&gt;Building the develop branch locally&lt;/h2&gt; &#xA;&lt;p&gt;We are not currently publishing snapshots for Scrooge&#39;s dependencies, which means that it may be necessary to publish the &lt;code&gt;develop&lt;/code&gt; branches of these libraries locally in order to work on Scrooge&#39;s &lt;code&gt;develop&lt;/code&gt; branch. To do so you can use our build tool, &lt;a href=&#34;https://github.com/twitter/dodo&#34;&gt;dodo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -s https://raw.githubusercontent.com/twitter/dodo/develop/bin/build | bash -s -- --no-test scrooge&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have any questions or run into any problems, please create an issue here, tweet at us at &lt;a href=&#34;https://twitter.com/finagle&#34;&gt;@finagle&lt;/a&gt;, or email the Finaglers mailing list.&lt;/p&gt; &#xA;&lt;h2&gt;Full Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.github.io/scrooge/&#34;&gt;https://twitter.github.io/scrooge/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright 2013 Twitter, Inc.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0: &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>playframework/playframework</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/playframework/playframework</id>
    <link href="https://github.com/playframework/playframework" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Play Framework&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Play Framework - The High Velocity Web Framework&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/playframework?label=follow&amp;amp;style=flat&amp;amp;logo=twitter&amp;amp;color=brightgreen&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/g5s2vtZ4Fa&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/931647755942776882?logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/playframework/playframework/discussions&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/discussions/playframework/playframework?&amp;amp;logo=github&amp;amp;color=brightgreen&#34; alt=&#34;GitHub Discussions&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://stackoverflow.com/tags/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=stackoverflow&amp;amp;logo=stackoverflow&amp;amp;logoColor=fe7a16&amp;amp;color=brightgreen&amp;amp;message=playframework&#34; alt=&#34;StackOverflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCRp6QDm5SDjbIuisUpxV9cg&#34;&gt;&lt;img src=&#34;https://img.shields.io/youtube/channel/views/UCRp6QDm5SDjbIuisUpxV9cg?label=watch&amp;amp;logo=youtube&amp;amp;style=flat&amp;amp;color=brightgreen&amp;amp;logoColor=ff0000&#34; alt=&#34;YouTube&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.twitch.tv/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitch/status/playframework?logo=twitch&amp;amp;logoColor=white&amp;amp;color=brightgreen&amp;amp;label=live%20stream&#34; alt=&#34;Twitch Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/opencollective/all/playframework?label=financial%20contributors&amp;amp;logo=open-collective&#34; alt=&#34;OpenCollective&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/playframework/playframework/actions/workflows/build-test.yml&#34;&gt;&lt;img src=&#34;https://github.com/playframework/playframework/actions/workflows/build-test.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mvnrepository.com/artifact/com.typesafe.play/play_2.13&#34;&gt;&lt;img src=&#34;https://img.shields.io/maven-central/v/com.typesafe.play/play_2.13.svg?logo=apache-maven&#34; alt=&#34;Maven&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/playframework/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/repo-size/playframework/playframework.svg?logo=git&#34; alt=&#34;Repository size&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://scala-steward.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Scala_Steward-helping-blue.svg?style=flat&amp;amp;logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAQCAMAAAARSr4IAAAAVFBMVEUAAACHjojlOy5NWlrKzcYRKjGFjIbp293YycuLa3pYY2LSqql4f3pCUFTgSjNodYRmcXUsPD/NTTbjRS+2jomhgnzNc223cGvZS0HaSD0XLjbaSjElhIr+AAAAAXRSTlMAQObYZgAAAHlJREFUCNdNyosOwyAIhWHAQS1Vt7a77/3fcxxdmv0xwmckutAR1nkm4ggbyEcg/wWmlGLDAA3oL50xi6fk5ffZ3E2E3QfZDCcCN2YtbEWZt+Drc6u6rlqv7Uk0LdKqqr5rk2UCRXOk0vmQKGfc94nOJyQjouF9H/wCc9gECEYfONoAAAAASUVORK5CYII=&#34; alt=&#34;Scala Steward badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mergify.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://api.mergify.com/v1/badges/playframework/playframework&amp;amp;style=flat&#34; alt=&#34;Mergify Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Play Framework combines productivity and performance making it easy to build scalable web applications with Java and Scala. Play is developer friendly with a &#34;just hit refresh&#34; workflow and built-in testing support. With Play, applications scale predictably due to a stateless and non-blocking architecture. By being RESTful by default, including assets compilers, JSON &amp;amp; WebSocket support, Play is a perfect fit for modern web &amp;amp; mobile applications.&lt;/p&gt; &#xA;&lt;h2&gt;Learn More&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com&#34;&gt;www.playframework.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/download&#34;&gt;Download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/Installing&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/NewApplication&#34;&gt;Create a new application&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/ScalaHome&#34;&gt;Play for Scala developers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/JavaHome&#34;&gt;Play for Java developers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/BuildingFromSource&#34;&gt;Build from source&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/playframework/playframework/issues&#34;&gt;Search or create issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/tagged/playframework&#34;&gt;Get help&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/contributing&#34;&gt;Contribute&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Sponsors &amp;amp; Backers&lt;/h2&gt; &#xA;&lt;p&gt;If you find Play useful for work, please consider asking your company to support this Open Source project by &lt;a href=&#34;https://www.playframework.com/sponsors&#34;&gt;becoming a sponsor&lt;/a&gt;.&lt;br&gt; You can also individually sponsor the project by &lt;a href=&#34;https://www.playframework.com/sponsors&#34;&gt;becoming a backer&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://opencollective.com/playframework&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://opencollective.com/playframework/donate/button@2x.png?color=blue&#34; width=&#34;250&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Thank you to our premium sponsors!&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://informaticon.com/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/61220b8306493af6a21b7db17de7f4b2-informaticon-logo-full-color.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://cedarlakeventures.com/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/bec2b526c9ce52c051f9089a10044867-cedar-lake-ventures.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://iterable.com/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/61ddb4c3665b621e6672181f97196748-iterable.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://pronto.net/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/c77b1d664f10a1c9cb19b97c6d8bd204-pronto-software.png&#34; width=&#34;250&#34;&gt; &lt;/a&gt;&#xA; &lt;a href=&#34;https://civiform.us/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/cb047b3782866c962c4d6a35b056b809-civiform.png&#34; width=&#34;250&#34;&gt; &lt;/a&gt;&#xA;&lt;/div&gt;&#xA;&lt;a href=&#34;https://civiform.us/&#34;&gt; &lt;h3&gt;Thank you to all our backers!&lt;/h3&gt; &lt;/a&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://civiform.us/&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://opencollective.com/playframework#section-contributors&#34;&gt;&lt;img src=&#34;https://opencollective.com/playframework/organizations.svg?width=890&amp;amp;button=false&amp;amp;avatarHeight=46&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/playframework#section-contributors&#34;&gt;&lt;img src=&#34;https://opencollective.com/playframework/individuals.svg?width=890&amp;amp;button=false&amp;amp;avatarHeight=46&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (C) Lightbend Inc. (&lt;a href=&#34;https://www.lightbend.com&#34;&gt;https://www.lightbend.com&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this project except in compliance with the License. You may obtain a copy of the License at &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>twitter/util</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/twitter/util</id>
    <link href="https://github.com/twitter/util" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Wonderful reusable code from Twitter&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Twitter Util&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/twitter/util/actions?query=workflow%3A%22continuous+integration%22+branch%3Adevelop&#34;&gt;&lt;img src=&#34;https://github.com/twitter/util/workflows/continuous%20integration/badge.svg?branch=develop&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/twitter/util&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/twitter/util/branch/develop/graph/badge.svg?sanitize=true&#34; alt=&#34;Codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/twitter/util/develop/#status&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/status-active-brightgreen.svg?sanitize=true&#34; alt=&#34;Project status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/twitter/finagle?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/twitter/finagle.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.twitter/util-core_2.12&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/com.twitter/util-core_2.12/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A bunch of idiomatic, small, general purpose tools.&lt;/p&gt; &#xA;&lt;p&gt;See the Scaladoc &lt;a href=&#34;https://twitter.github.io/util/docs/#com.twitter.util.package&#34;&gt;here&lt;/a&gt; or check out the &lt;a href=&#34;https://twitter.github.io/util&#34;&gt;user guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Status&lt;/h2&gt; &#xA;&lt;p&gt;This project is used in production at Twitter (and many other organizations), and is being actively developed and maintained.&lt;/p&gt; &#xA;&lt;h2&gt;Releases&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.twitter/util_2.12&#34;&gt;Releases&lt;/a&gt; are done on an approximately monthly schedule. While &lt;a href=&#34;https://semver.org/&#34;&gt;semver&lt;/a&gt; is not followed, the &lt;a href=&#34;https://raw.githubusercontent.com/twitter/util/develop/CHANGELOG.rst&#34;&gt;changelogs&lt;/a&gt; are detailed and include sections on public API breaks and changes in runtime behavior.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We feel that a welcoming community is important and we ask that you follow Twitter&#39;s &lt;a href=&#34;https://github.com/twitter/.github/raw/main/code-of-conduct.md&#34;&gt;Open Source Code of Conduct&lt;/a&gt; in all interactions with the community.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;release&lt;/code&gt; branch of this repository contains the latest stable release of Util, and weekly snapshots are published to the &lt;code&gt;develop&lt;/code&gt; branch. In general pull requests should be submitted against &lt;code&gt;develop&lt;/code&gt;. See &lt;a href=&#34;https://github.com/twitter/util/raw/release/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for more details about how to contribute.&lt;/p&gt; &#xA;&lt;h1&gt;Using in your project&lt;/h1&gt; &#xA;&lt;p&gt;An example SBT dependency string for the &lt;code&gt;util-core&lt;/code&gt; library would look like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val utilCore = &#34;com.twitter&#34; %% &#34;util-core&#34; % &#34;22.4.0&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Units&lt;/h1&gt; &#xA;&lt;h2&gt;Time&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.twitter.conversions.DurationOps._&#xA;&#xA;val duration1 = 1.second&#xA;val duration2 = 2.minutes&#xA;duration1.inMillis // =&amp;gt; 1000L&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Space&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.twitter.conversions.StorageUnitOps._&#xA;val amount = 8.megabytes&#xA;amount.inBytes // =&amp;gt; 8388608L&#xA;amount.inKilobytes // =&amp;gt; 8192L&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Futures&lt;/h1&gt; &#xA;&lt;p&gt;A Non-actor re-implementation of Scala Futures.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.twitter.conversions.DurationOps._&#xA;import com.twitter.util.{Await, Future, Promise}&#xA;&#xA;val f = new Promise[Int]&#xA;val g = f.map { result =&amp;gt; result + 1 }&#xA;f.setValue(1)&#xA;Await.result(g, 1.second) // =&amp;gt; this blocks for the futures result (and eventually returns 2)&#xA;&#xA;// Another option:&#xA;g.onSuccess { result =&amp;gt;&#xA;  println(result) // =&amp;gt; prints &#34;2&#34;&#xA;}&#xA;&#xA;// Using for expressions:&#xA;val xFuture = Future(1)&#xA;val yFuture = Future(2)&#xA;&#xA;for {&#xA;  x &amp;lt;- xFuture&#xA;  y &amp;lt;- yFuture&#xA;} {&#xA;  println(x + y) // =&amp;gt; prints &#34;3&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Future interrupts&lt;/h2&gt; &#xA;&lt;p&gt;Method &lt;code&gt;raise&lt;/code&gt; on &lt;code&gt;Future&lt;/code&gt; (&lt;code&gt;def raise(cause: Throwable)&lt;/code&gt;) raises the interrupt described by &lt;code&gt;cause&lt;/code&gt; to the producer of this &lt;code&gt;Future&lt;/code&gt;. Interrupt handlers are installed on a &lt;code&gt;Promise&lt;/code&gt; using &lt;code&gt;setInterruptHandler&lt;/code&gt;, which takes a partial function:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val p = new Promise[T]&#xA;p.setInterruptHandler {&#xA;  case exc: MyException =&amp;gt;&#xA;    // deal with interrupt..&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Interrupts differ in semantics from cancellation in important ways: there can only be one interrupt handler per promise, and interrupts are only delivered if the promise is not yet complete.&lt;/p&gt; &#xA;&lt;h1&gt;Object Pool&lt;/h1&gt; &#xA;&lt;p&gt;The pool order is FIFO.&lt;/p&gt; &#xA;&lt;h2&gt;A pool of constants&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import scala.collection.mutable&#xA;import com.twitter.util.{Await, SimplePool}&#xA;&#xA;val queue = new mutable.Queue[Int] ++ List(1, 2, 3)&#xA;val pool = new SimplePool(queue)&#xA;&#xA;// Note that the pool returns Futures, it doesn&#39;t block on exhaustion.&#xA;assert(Await.result(pool.reserve()) == 1)&#xA;pool.reserve().onSuccess { item =&amp;gt;&#xA;  println(item) // prints &#34;2&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;A pool of dynamically created objects&lt;/h2&gt; &#xA;&lt;p&gt;Here is a pool of even-number generators. It stores 4 numbers at a time:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.twitter.util.{Future, FactoryPool}&#xA;&#xA;val pool = new FactoryPool[Int](4) {&#xA;  var count = 0&#xA;  def makeItem() = { count += 1; Future(count) }&#xA;  def isHealthy(i: Int) = i % 2 == 0&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It checks the health when you successfully reserve an object (i.e., when the Future yields).&lt;/p&gt; &#xA;&lt;h1&gt;Hashing&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;util-hashing&lt;/code&gt; is a collection of hash functions and hashing distributors (eg. ketama).&lt;/p&gt; &#xA;&lt;p&gt;To use one of the available hash functions:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.twitter.hashing.KeyHasher&#xA;&#xA;KeyHasher.FNV1_32.hashKey(&#34;string&#34;.getBytes)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Available hash functions are:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;FNV1_32&#xA;FNV1A_32&#xA;FNV1_64&#xA;FNV1A_64&#xA;KETAMA&#xA;CRC32_ITU&#xA;HSIEH&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use &lt;code&gt;KetamaDistributor&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.twitter.hashing.{KetamaDistributor, KetamaNode, KeyHasher}&#xA;&#xA;val nodes = List(KetamaNode(&#34;host:port&#34;, 1 /* weight */, &#34;foo&#34; /* handle */))&#xA;val distributor = new KetamaDistributor(nodes, 1 /* num reps */)&#xA;distributor.nodeForHash(&#34;abc&#34;.##) // =&amp;gt; client&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Time and Duration&lt;/h1&gt; &#xA;&lt;p&gt;Like arithmetic on doubles, &lt;code&gt;Time&lt;/code&gt; and &lt;code&gt;Duration&lt;/code&gt; arithmetic is now free of overflows. Instead, they overflow to &lt;code&gt;Top&lt;/code&gt; and &lt;code&gt;Bottom&lt;/code&gt; values, which are analogous to positive and negative infinity.&lt;/p&gt; &#xA;&lt;p&gt;Since the resolution of &lt;code&gt;Time.now&lt;/code&gt; has been reduced (and is also more expensive due to its use of system time), a new &lt;code&gt;Stopwatch&lt;/code&gt; API has been introduced in order to calculate durations of time.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s used simply:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.twitter.util.{Duration, Stopwatch}&#xA;val elapsed: () =&amp;gt; Duration = Stopwatch.start()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;which is read by applying &lt;code&gt;elapsed&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val duration: Duration = elapsed()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright 2010 Twitter, Inc.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0: &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>scala/scala</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/scala/scala</id>
    <link href="https://github.com/scala/scala" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Scala 2 compiler and standard library. For bugs, see scala/bug&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome!&lt;/h1&gt; &#xA;&lt;p&gt;This is the home of the &lt;a href=&#34;https://www.scala-lang.org&#34;&gt;Scala 2&lt;/a&gt; standard library, compiler, and language spec.&lt;/p&gt; &#xA;&lt;h1&gt;How to contribute&lt;/h1&gt; &#xA;&lt;p&gt;Issues and bug reports for Scala 2 are located in &lt;a href=&#34;https://github.com/scala/bug&#34;&gt;scala/bug&lt;/a&gt;. That tracker is also where new contributors may find issues to work on: &lt;a href=&#34;https://github.com/scala/bug/labels/good%20first%20issue&#34;&gt;good first issues&lt;/a&gt;, &lt;a href=&#34;https://github.com/scala/bug/labels/help%20wanted&#34;&gt;help wanted&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For coordinating broader efforts, we also use the &lt;a href=&#34;https://github.com/scala/scala-dev/issues&#34;&gt;scala/scala-dev tracker&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To contribute here, please open a &lt;a href=&#34;https://help.github.com/articles/using-pull-requests/#fork--pull&#34;&gt;pull request&lt;/a&gt; from your fork of this repository.&lt;/p&gt; &#xA;&lt;p&gt;Be aware that we can&#39;t accept additions to the standard library, only modifications to existing code. Binary compatibility forbids adding new public classes or public methods. Additions are made to &lt;a href=&#34;https://github.com/scala/scala-library-next&#34;&gt;scala-library-next&lt;/a&gt; instead.&lt;/p&gt; &#xA;&lt;p&gt;We require that you sign the &lt;a href=&#34;https://www.lightbend.com/contribute/cla/scala&#34;&gt;Scala CLA&lt;/a&gt; before we can merge any of your work, to protect Scala&#39;s future as open source software.&lt;/p&gt; &#xA;&lt;p&gt;The general workflow is as follows.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Find/file an issue in scala/bug (or submit a well-documented PR right away!).&lt;/li&gt; &#xA; &lt;li&gt;Fork the scala/scala repo.&lt;/li&gt; &#xA; &lt;li&gt;Push your changes to a branch in your forked repo. For coding guidelines, go &lt;a href=&#34;https://github.com/scala/scala#coding-guidelines&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Submit a pull request to scala/scala from your forked repo.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For more information on building and developing the core of Scala, read the rest of this README, especially for &lt;a href=&#34;https://github.com/scala/scala#get-ready-to-contribute&#34;&gt;setting up your machine&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h1&gt;Get in touch!&lt;/h1&gt; &#xA;&lt;p&gt;In order to get in touch with other Scala contributors, join the #scala-contributors channel on the &lt;a href=&#34;https://discord.com/invite/scala&#34;&gt;Scala Discord&lt;/a&gt; chat, or post on &lt;a href=&#34;https://contributors.scala-lang.org&#34;&gt;contributors.scala-lang.org&lt;/a&gt; (Discourse).&lt;/p&gt; &#xA;&lt;p&gt;If you need some help with your PR at any time, please feel free to @-mention anyone from the list below, and we will do our best to help you out:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;username&lt;/th&gt; &#xA;   &lt;th&gt;talk to me about...&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/lrytz&#34; height=&#34;50px&#34; title=&#34;Lukas Rytz&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lrytz&#34;&gt;&lt;code&gt;@lrytz&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;back end, optimizer, named &amp;amp; default arguments, reporters&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/retronym&#34; height=&#34;50px&#34; title=&#34;Jason Zaugg&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/retronym&#34;&gt;&lt;code&gt;@retronym&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2.12.x branch, compiler performance, weird compiler bugs, lambdas&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/SethTisue&#34; height=&#34;50px&#34; title=&#34;Seth Tisue&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/SethTisue&#34;&gt;&lt;code&gt;@SethTisue&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;getting started, build, CI, community build, Jenkins, docs, library, REPL&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/dwijnand&#34; height=&#34;50px&#34; title=&#34;Dale Wijnand&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/dwijnand&#34;&gt;&lt;code&gt;@dwijnand&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;pattern matcher, MiMa, partest&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/Ichoran&#34; height=&#34;50px&#34; title=&#34;Rex Kerr&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Ichoran&#34;&gt;&lt;code&gt;@Ichoran&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;collections library, performance&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/viktorklang&#34; height=&#34;50px&#34; title=&#34;Viktor Klang&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/viktorklang&#34;&gt;&lt;code&gt;@viktorklang&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;concurrency, futures&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/sjrd&#34; height=&#34;50px&#34; title=&#34;SÃ©bastien Doeraene&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/sjrd&#34;&gt;&lt;code&gt;@sjrd&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;interactions with Scala.js&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/NthPortal&#34; height=&#34;50px&#34; title=&#34;Princess | April&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NthPortal&#34;&gt;&lt;code&gt;@NthPortal&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;library, concurrency, &lt;code&gt;scala.math&lt;/code&gt;, &lt;code&gt;LazyList&lt;/code&gt;, &lt;code&gt;Using&lt;/code&gt;, warnings&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/bishabosha&#34; height=&#34;50px&#34; title=&#34;Jamie Thompson&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/bishabosha&#34;&gt;&lt;code&gt;@bishabosha&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TASTy reader&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/joroKr21&#34; height=&#34;50px&#34; title=&#34;Georgi Krastev&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/joroKr21&#34;&gt;&lt;code&gt;@joroKr21&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;higher-kinded types, implicits, variance&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;P.S.: If you have some spare time to help out around here, we would be delighted to add your name to this list!&lt;/p&gt; &#xA;&lt;h1&gt;Branches&lt;/h1&gt; &#xA;&lt;p&gt;Target the oldest branch you would like your changes to end up in. We periodically merge forward from older release branches (e.g., 2.12.x) to new ones (e.g. 2.13.x).&lt;/p&gt; &#xA;&lt;p&gt;If your change is difficult to merge forward, you may be asked to also submit a separate PR targeting the newer branch.&lt;/p&gt; &#xA;&lt;p&gt;If your change is version-specific and shouldn&#39;t be merged forward, put &lt;code&gt;[nomerge]&lt;/code&gt; in the PR name.&lt;/p&gt; &#xA;&lt;p&gt;If your change is a backport from a newer branch and thus doesn&#39;t need to be merged forward, put &lt;code&gt;[backport]&lt;/code&gt; in the PR name.&lt;/p&gt; &#xA;&lt;h2&gt;Choosing a branch&lt;/h2&gt; &#xA;&lt;p&gt;Most changes should target 2.13.x. We are increasingly reluctant to target 2.12.x unless there is a special reason (e.g. if an especially bad bug is found, or if there is commercial sponsorship).&lt;/p&gt; &#xA;&lt;p&gt;The 2.11.x branch is now &lt;a href=&#34;https://github.com/scala/scala-dev/issues/451&#34;&gt;inactive&lt;/a&gt; and no further 2.11.x releases are planned (unless unusual, unforeseeable circumstances arise). You should not target 2.11.x without asking maintainers first.&lt;/p&gt; &#xA;&lt;h1&gt;Repository structure&lt;/h1&gt; &#xA;&lt;p&gt;Most importantly:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;scala/&#xA;+--build.sbt                 The main sbt build definition&#xA;+--project/                  The rest of the sbt build&#xA;+--src/                      All sources&#xA;   +---/library              Scala Standard Library&#xA;   +---/reflect              Scala Reflection&#xA;   +---/compiler             Scala Compiler&#xA;+--test/                     The Scala test suite&#xA;   +---/files                Partest tests&#xA;   +---/junit                JUnit tests&#xA;   +---/scalacheck           ScalaCheck tests&#xA;+--spec/                     The Scala language specification&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;but also:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;scala/&#xA;   +---/library-aux          Scala Auxiliary Library, for bootstrapping and documentation purposes&#xA;   +---/interactive          Scala Interactive Compiler, for clients such as an IDE (aka Presentation Compiler)&#xA;   +---/intellij             IntelliJ project templates&#xA;   +---/manual               Scala&#39;s runner scripts &#34;man&#34; (manual) pages&#xA;   +---/partest              Scala&#39;s internal parallel testing framework&#xA;   +---/partest-javaagent    Partest&#39;s helper java agent&#xA;   +---/repl                 Scala REPL core&#xA;   +---/repl-frontend        Scala REPL frontend&#xA;   +---/scaladoc             Scala&#39;s documentation tool&#xA;   +---/scalap               Scala&#39;s class file decompiler&#xA;   +---/testkit              Scala&#39;s unit-testing kit&#xA;+--admin/                    Scripts for the CI jobs and releasing&#xA;+--doc/                      Additional licenses and copyrights&#xA;+--scripts/                  Scripts for the CI jobs and releasing&#xA;+--tools/                    Scripts useful for local development&#xA;+--build/                    Build products&#xA;+--dist/                     Build products&#xA;+--target/                   Build products&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Get ready to contribute&lt;/h1&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;You need the following tools:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Java SDK. The baseline version is 8 for both 2.12.x and 2.13.x. It is almost always fine to use a later SDK such as 11 or 15 for local development. CI will verify against the baseline version.&lt;/li&gt; &#xA; &lt;li&gt;sbt&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;MacOS and Linux work. Windows may work if you use Cygwin. Community help with keeping the build working on Windows and documenting any needed setup is appreciated.&lt;/p&gt; &#xA;&lt;h2&gt;Tools we use&lt;/h2&gt; &#xA;&lt;p&gt;We are grateful for the following OSS licenses:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ej-technologies.com/products/jprofiler/overview.html&#34;&gt;JProfiler Java profiler&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.yourkit.com/java/profiler/&#34;&gt;YourKit Java Profiler&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jetbrains.com/idea/download/&#34;&gt;IntelliJ IDEA&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Build setup&lt;/h2&gt; &#xA;&lt;h3&gt;Basics&lt;/h3&gt; &#xA;&lt;p&gt;During ordinary development, a new Scala build is built by the previously released version, known as the &#34;reference compiler&#34; or, slangily, as &#34;STARR&#34; (stable reference release). Building with STARR is sufficient for most kinds of changes.&lt;/p&gt; &#xA;&lt;p&gt;However, a full build of Scala is &lt;em&gt;bootstrapped&lt;/em&gt;. Bootstrapping has two steps: first, build with STARR; then, build again using the freshly built compiler, leaving STARR behind. This guarantees that every Scala version can build itself.&lt;/p&gt; &#xA;&lt;p&gt;If you change the code generation part of the Scala compiler, your changes will only show up in the bytecode of the library and compiler after a bootstrap. Our CI does a bootstrapped build.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bootstrapping locally&lt;/strong&gt;: To perform a bootstrap, run &lt;code&gt;restarrFull&lt;/code&gt; within an sbt session. This will build and publish the Scala distribution to your local artifact repository and then switch sbt to use that version as its new &lt;code&gt;scalaVersion&lt;/code&gt;. You may then revert back with &lt;code&gt;reload&lt;/code&gt;. Note &lt;code&gt;restarrFull&lt;/code&gt; will also write the STARR version to &lt;code&gt;buildcharacter.properties&lt;/code&gt; so you can switch back to it with &lt;code&gt;restarr&lt;/code&gt; without republishing. This will switch the sbt session to use the &lt;code&gt;build-restarr&lt;/code&gt; and &lt;code&gt;target-restarr&lt;/code&gt; directories instead of &lt;code&gt;build&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;, which avoids wiping out classfiles and incremental metadata. IntelliJ will continue to be configured to compile and run tests using the starr version in &lt;code&gt;versions.properties&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For history on how the current scheme was arrived at, see &lt;a href=&#34;https://groups.google.com/d/topic/scala-internals/gp5JsM1E0Fo/discussion&#34;&gt;https://groups.google.com/d/topic/scala-internals/gp5JsM1E0Fo/discussion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Building with fatal warnings&lt;/strong&gt;: To make warnings in the project fatal (i.e. turn them into errors), run &lt;code&gt;set Global / fatalWarnings := true&lt;/code&gt; in sbt (replace &lt;code&gt;Global&lt;/code&gt; with the name of a moduleâ€”such as &lt;code&gt;reflect&lt;/code&gt;â€”to only make warnings fatal for that module). To disable fatal warnings again, either &lt;code&gt;reload&lt;/code&gt; sbt, or run &lt;code&gt;set Global / fatalWarnings := false&lt;/code&gt; (again, replace &lt;code&gt;Global&lt;/code&gt; with the name of a module if you only enabled fatal warnings for that module). CI always has fatal warnings enabled.&lt;/p&gt; &#xA;&lt;h3&gt;Using the sbt build&lt;/h3&gt; &#xA;&lt;p&gt;Once you&#39;ve started an &lt;code&gt;sbt&lt;/code&gt; session you can run one of the core commands:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;compile&lt;/code&gt; compiles all sub-projects (library, reflect, compiler, scaladoc, etc)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scala&lt;/code&gt; / &lt;code&gt;scalac&lt;/code&gt; run the REPL / compiler directly from sbt (accept options / arguments)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;enableOptimizer&lt;/code&gt; reloads the build with the Scala optimizer enabled. Our releases are built this way. Enable this when working on compiler performance improvements. When the optimizer is enabled the build will be slower and incremental builds can be incorrect.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;setupPublishCore&lt;/code&gt; runs &lt;code&gt;enableOptimizer&lt;/code&gt; and configures a version number based on the current Git SHA. Often used as part of bootstrapping: &lt;code&gt;sbt setupPublishCore publishLocal &amp;amp;&amp;amp; sbt -Dstarr.version=&amp;lt;VERSION&amp;gt; testAll&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;dist/mkBin&lt;/code&gt; generates runner scripts (&lt;code&gt;scala&lt;/code&gt;, &lt;code&gt;scalac&lt;/code&gt;, etc) in &lt;code&gt;build/quick/bin&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;dist/mkPack&lt;/code&gt; creates a build in the Scala distribution format in &lt;code&gt;build/pack&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;junit/test&lt;/code&gt; runs the JUnit tests; &lt;code&gt;junit/testOnly *Foo&lt;/code&gt; runs a subset&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scalacheck/test&lt;/code&gt; runs scalacheck tests, use &lt;code&gt;testOnly&lt;/code&gt; to run a subset&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;partest&lt;/code&gt; runs partest tests (accepts options, try &lt;code&gt;partest --help&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;publishLocal&lt;/code&gt; publishes a distribution locally (can be used as &lt;code&gt;scalaVersion&lt;/code&gt; in other sbt projects) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Optionally &lt;code&gt;set baseVersionSuffix := &#34;bin-abcd123-SNAPSHOT&#34;&lt;/code&gt; where &lt;code&gt;abcd123&lt;/code&gt; is the git hash of the revision being published. You can also use something custom like &lt;code&gt;&#34;bin-mypatch&#34;&lt;/code&gt;. This changes the version number from &lt;code&gt;2.13.2-SNAPSHOT&lt;/code&gt; to something more stable (&lt;code&gt;2.13.2-bin-abcd123-SNAPSHOT&lt;/code&gt;).&lt;/li&gt; &#xA;   &lt;li&gt;Note that the &lt;code&gt;-bin&lt;/code&gt; string marks the version binary compatible. Using it in sbt will cause the &lt;code&gt;scalaBinaryVersion&lt;/code&gt; to be &lt;code&gt;2.13&lt;/code&gt;. If the version is not binary compatible, we recommend using &lt;code&gt;-pre&lt;/code&gt;, e.g., &lt;code&gt;2.14.0-pre-abcd123-SNAPSHOT&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Optionally &lt;code&gt;set publishArtifact in (Compile, packageDoc) in ThisBuild := false&lt;/code&gt; to skip generating / publishing API docs (speeds up the process).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If a command results in an error message like &lt;code&gt;a module is not authorized to depend on itself&lt;/code&gt;, it may be that a global sbt plugin is causing a cyclical dependency. Try disabling global sbt plugins (perhaps by temporarily commenting them out in &lt;code&gt;~/.sbt/1.0/plugins/plugins.sbt&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h4&gt;Sandbox&lt;/h4&gt; &#xA;&lt;p&gt;We recommend keeping local test files in the &lt;code&gt;sandbox&lt;/code&gt; directory which is listed in the &lt;code&gt;.gitignore&lt;/code&gt; of the Scala repo.&lt;/p&gt; &#xA;&lt;h4&gt;Incremental compilation&lt;/h4&gt; &#xA;&lt;p&gt;Note that sbt&#39;s incremental compilation is often too coarse for the Scala compiler codebase and re-compiles too many files, resulting in long build times (check &lt;a href=&#34;https://github.com/sbt/sbt/issues/1104&#34;&gt;sbt#1104&lt;/a&gt; for progress on that front). In the meantime you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use IntelliJ IDEA for incremental compiles (see &lt;a href=&#34;https://raw.githubusercontent.com/scala/scala/2.13.x/#ide-setup&#34;&gt;IDE Setup&lt;/a&gt; below) - its incremental compiler is a bit less conservative, but usually correct.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;IDE setup&lt;/h3&gt; &#xA;&lt;p&gt;We suggest using IntelliJ IDEA (see &lt;a href=&#34;https://raw.githubusercontent.com/scala/scala/2.13.x/src/intellij/README.md&#34;&gt;src/intellij/README.md&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://scalameta.org/metals/&#34;&gt;Metals&lt;/a&gt; may also work, but we don&#39;t yet have instructions or sample configuration for that. A pull request in this area would be exceedingly welcome. In the meantime, we are collecting guidance at &lt;a href=&#34;https://github.com/scala/scala-dev/issues/668&#34;&gt;scala/scala-dev#668&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In order to use IntelliJ&#39;s incremental compiler:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run &lt;code&gt;dist/mkBin&lt;/code&gt; in sbt to get a build and the runner scripts in &lt;code&gt;build/quick/bin&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;run &#34;Build&#34; - &#34;Make Project&#34; in IntelliJ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Now you can edit and build in IntelliJ and use the scripts (compiler, REPL) to directly test your changes. You can also run the &lt;code&gt;scala&lt;/code&gt;, &lt;code&gt;scalac&lt;/code&gt; and &lt;code&gt;partest&lt;/code&gt; commands in sbt. Enable &#34;Ant mode&#34; (explained above) to prevent sbt&#39;s incremental compiler from re-compiling (too many) files before each &lt;code&gt;partest&lt;/code&gt; invocation.&lt;/p&gt; &#xA;&lt;h1&gt;Coding guidelines&lt;/h1&gt; &#xA;&lt;p&gt;Our guidelines for contributing are explained in &lt;a href=&#34;https://raw.githubusercontent.com/scala/scala/2.13.x/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;. It contains useful information on our coding standards, testing, documentation, how we use git and GitHub and how to get your code reviewed.&lt;/p&gt; &#xA;&lt;p&gt;You may also want to check out the following resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://scala-lang.org/contribute/hacker-guide.html&#34;&gt;&#34;Scala Hacker Guide&#34;&lt;/a&gt; covers some of the same ground as this README, but in greater detail and in a more tutorial style, using a running example.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.scala-lang.org&#34;&gt;Scala documentation site&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Scala CI&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.com/scala/scala&#34;&gt;&lt;img src=&#34;https://travis-ci.com/scala/scala.svg?branch=2.13.x&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Once you submit a PR your commits will be automatically tested by the Scala CI.&lt;/p&gt; &#xA;&lt;p&gt;Our CI setup is always evolving. See &lt;a href=&#34;https://github.com/scala/scala-dev/issues/751&#34;&gt;scala/scala-dev#751&lt;/a&gt; for more details on how things currently work and how we expect they might change.&lt;/p&gt; &#xA;&lt;p&gt;If you see a spurious failure on Jenkins, you can post &lt;code&gt;/rebuild&lt;/code&gt; as a PR comment. The &lt;a href=&#34;https://github.com/scala/scabot&#34;&gt;scabot README&lt;/a&gt; lists all available commands.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d like to test your patch before having everything polished for review, you can have Travis CI build your branch (make sure you have a fork and have Travis CI enabled for branch builds on it first, and then push your branch). Also feel free to submit a draft PR. In case your draft branch contains a large number of commits (that you didn&#39;t clean up / squash yet for review), consider adding &lt;code&gt;[ci: last-only]&lt;/code&gt; to the PR title. That way only the last commit will be tested, saving some energy and CI-resources. Note that inactive draft PRs will be closed eventually, which does not mean the change is being rejected.&lt;/p&gt; &#xA;&lt;p&gt;CI performs a compiler bootstrap. The first task, &lt;code&gt;validatePublishCore&lt;/code&gt;, publishes a build of your commit to the temporary repository &lt;a href=&#34;https://scala-ci.typesafe.com/artifactory/scala-pr-validation-snapshots&#34;&gt;https://scala-ci.typesafe.com/artifactory/scala-pr-validation-snapshots&lt;/a&gt;. Note that this build is not yet bootstrapped, its bytecode is built using the current STARR. The version number is &lt;code&gt;2.13.2-bin-abcd123-SNAPSHOT&lt;/code&gt; where &lt;code&gt;abcd123&lt;/code&gt; is the commit hash. For binary incompatible builds, the version number is &lt;code&gt;2.14.0-pre-abcd123-SNAPSHOT&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can use Scala builds in the validation repository locally by adding a resolver and specifying the corresponding &lt;code&gt;scalaVersion&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sbt&#xA;&amp;gt; set resolvers += &#34;pr&#34; at &#34;https://scala-ci.typesafe.com/artifactory/scala-pr-validation-snapshots/&#34;&#xA;&amp;gt; set scalaVersion := &#34;2.12.2-bin-abcd123-SNAPSHOT&#34;&#xA;&amp;gt; console&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&#34;Nightly&#34; builds&lt;/h2&gt; &#xA;&lt;p&gt;The Scala CI builds nightly download releases and publishes them to &lt;a href=&#34;https://scala-ci.typesafe.com/artifactory/scala-integration/&#34;&gt;https://scala-ci.typesafe.com/artifactory/scala-integration/&lt;/a&gt; .&lt;/p&gt; &#xA;&lt;p&gt;Using a nightly build in sbt is explained in &lt;a href=&#34;https://stackoverflow.com/questions/40622878&#34;&gt;this Stack Overflow answer&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Although we casually refer to these as &#34;nightly&#34; builds, they aren&#39;t actually built nightly, but &#34;mergely&#34;. That is to say, a build is published for every merged PR.&lt;/p&gt; &#xA;&lt;h2&gt;Scala CI internals&lt;/h2&gt; &#xA;&lt;p&gt;The Scala CI runs as a Jenkins instance on &lt;a href=&#34;https://scala-ci.typesafe.com/&#34;&gt;scala-ci.typesafe.com&lt;/a&gt;, configured by a chef cookbook at &lt;a href=&#34;https://github.com/scala/scala-jenkins-infra&#34;&gt;scala/scala-jenkins-infra&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The build bot that watches PRs, triggers testing builds and applies the &#34;reviewed&#34; label after an LGTM comment is in the &lt;a href=&#34;https://github.com/scala/scabot&#34;&gt;scala/scabot&lt;/a&gt; repo.&lt;/p&gt; &#xA;&lt;h2&gt;Community build&lt;/h2&gt; &#xA;&lt;p&gt;The Scala community build is an important method for testing Scala releases. A community build can be launched for any Scala commit, even before the commit&#39;s PR has been merged. That commit is then used to build a large number of open-source projects from source and run their test suites.&lt;/p&gt; &#xA;&lt;p&gt;To request a community build run on your PR, just ask in a comment on the PR and a Scala team member (probably @SethTisue) will take care of it. (&lt;a href=&#34;https://github.com/scala/community-builds/wiki#can-i-run-it-against-a-pull-request-in-scalascala&#34;&gt;details&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;p&gt;Community builds run on the Scala Jenkins instance. The jobs are named &lt;code&gt;..-integrate-community-build&lt;/code&gt;. See the &lt;a href=&#34;https://github.com/scala/community-builds&#34;&gt;scala/community-builds&lt;/a&gt; repo.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apache/spark</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/apache/spark</id>
    <link href="https://github.com/apache/spark" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache Spark - A unified analytics engine for large-scale data processing&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache Spark&lt;/h1&gt; &#xA;&lt;p&gt;Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Scala, Java, Python, and R, and an optimized engine that supports general computation graphs for data analysis. It also supports a rich set of higher-level tools including Spark SQL for SQL and DataFrames, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for stream processing.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://spark.apache.org/&#34;&gt;https://spark.apache.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/spark/actions/workflows/build_and_test.yml?query=branch%3Amaster+event%3Apush&#34;&gt;&lt;img src=&#34;https://github.com/apache/spark/actions/workflows/build_and_test.yml/badge.svg?branch=master&amp;amp;event=push&#34; alt=&#34;GitHub Action Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ci.appveyor.com/project/ApacheSoftwareFoundation/spark&#34;&gt;&lt;img src=&#34;https://img.shields.io/appveyor/ci/ApacheSoftwareFoundation/spark/master.svg?style=plastic&amp;amp;logo=appveyor&#34; alt=&#34;AppVeyor Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/apache/spark&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/apache/spark/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;PySpark Coverage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Online Documentation&lt;/h2&gt; &#xA;&lt;p&gt;You can find the latest Spark documentation, including a programming guide, on the &lt;a href=&#34;https://spark.apache.org/documentation.html&#34;&gt;project web page&lt;/a&gt;. This README file only contains basic setup instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Building Spark&lt;/h2&gt; &#xA;&lt;p&gt;Spark is built using &lt;a href=&#34;https://maven.apache.org/&#34;&gt;Apache Maven&lt;/a&gt;. To build Spark and its example programs, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./build/mvn -DskipTests clean package&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(You do not need to do this if you downloaded a pre-built package.)&lt;/p&gt; &#xA;&lt;p&gt;More detailed documentation is available from the project site, at &lt;a href=&#34;https://spark.apache.org/docs/latest/building-spark.html&#34;&gt;&#34;Building Spark&#34;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For general development tips, including info on developing Spark using an IDE, see &lt;a href=&#34;https://spark.apache.org/developer-tools.html&#34;&gt;&#34;Useful Developer Tools&#34;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Interactive Scala Shell&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to start using Spark is through the Scala shell:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/spark-shell&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Try the following command, which should return 1,000,000,000:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;scala&amp;gt; spark.range(1000 * 1000 * 1000).count()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Interactive Python Shell&lt;/h2&gt; &#xA;&lt;p&gt;Alternatively, if you prefer Python, you can use the Python shell:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/pyspark&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And run the following command, which should also return 1,000,000,000:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; spark.range(1000 * 1000 * 1000).count()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example Programs&lt;/h2&gt; &#xA;&lt;p&gt;Spark also comes with several sample programs in the &lt;code&gt;examples&lt;/code&gt; directory. To run one of them, use &lt;code&gt;./bin/run-example &amp;lt;class&amp;gt; [params]&lt;/code&gt;. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/run-example SparkPi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;will run the Pi example locally.&lt;/p&gt; &#xA;&lt;p&gt;You can set the MASTER environment variable when running examples to submit examples to a cluster. This can be a mesos:// or spark:// URL, &#34;yarn&#34; to run on YARN, and &#34;local&#34; to run locally with one thread, or &#34;local[N]&#34; to run locally with N threads. You can also use an abbreviated class name if the class is in the &lt;code&gt;examples&lt;/code&gt; package. For instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;MASTER=spark://host:7077 ./bin/run-example SparkPi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Many of the example programs print usage help if no params are given.&lt;/p&gt; &#xA;&lt;h2&gt;Running Tests&lt;/h2&gt; &#xA;&lt;p&gt;Testing first requires &lt;a href=&#34;https://raw.githubusercontent.com/apache/spark/master/#building-spark&#34;&gt;building Spark&lt;/a&gt;. Once Spark is built, tests can be run using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./dev/run-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please see the guidance on how to &lt;a href=&#34;https://spark.apache.org/developer-tools.html#individual-tests&#34;&gt;run tests for a module, or individual tests&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There is also a Kubernetes integration test, see resource-managers/kubernetes/integration-tests/README.md&lt;/p&gt; &#xA;&lt;h2&gt;A Note About Hadoop Versions&lt;/h2&gt; &#xA;&lt;p&gt;Spark uses the Hadoop core library to talk to HDFS and other Hadoop-supported storage systems. Because the protocols have changed in different versions of Hadoop, you must build Spark against the same version that your cluster runs.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to the build documentation at &lt;a href=&#34;https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn&#34;&gt;&#34;Specifying the Hadoop Version and Enabling YARN&#34;&lt;/a&gt; for detailed guidance on building for a particular distribution of Hadoop, including building for particular Hive and Hive Thriftserver distributions.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://spark.apache.org/docs/latest/configuration.html&#34;&gt;Configuration Guide&lt;/a&gt; in the online documentation for an overview on how to configure Spark.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please review the &lt;a href=&#34;https://spark.apache.org/contributing.html&#34;&gt;Contribution to Spark guide&lt;/a&gt; for information on how to get started contributing to the project.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>datastax/spark-cassandra-connector</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/datastax/spark-cassandra-connector</id>
    <link href="https://github.com/datastax/spark-cassandra-connector" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DataStax Spark Cassandra Connector&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Spark Cassandra Connector&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/actions?query=branch%3Amaster&#34;&gt;&lt;img src=&#34;https://github.com/datastax/spark-cassandra-connector/actions/workflows/main.yml/badge.svg?branch=master&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Links&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;What&lt;/th&gt; &#xA;   &lt;th&gt;Where&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Community&lt;/td&gt; &#xA;   &lt;td&gt;Chat with us at &lt;a href=&#34;https://community.datastax.com/index.html&#34;&gt;Datastax and Cassandra Q&amp;amp;A&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Scala Docs&lt;/td&gt; &#xA;   &lt;td&gt;Most Recent Release (3.2.0): &lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.2.0/connector/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;, &lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.2.0/driver/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector-Driver&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Latest Production Release&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://search.maven.org/artifact/com.datastax.spark/spark-cassandra-connector_2.12/3.2.0/jar&#34;&gt;3.2.0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Lightning-fast cluster computing with Apache Sparkâ„¢ and Apache CassandraÂ®.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;This library lets you expose Cassandra tables as Spark RDDs and Datasets/DataFrames, write Spark RDDs and Datasets/DataFrames to Cassandra tables, and execute arbitrary CQL queries in your Spark applications.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Compatible with Apache Cassandra version 2.1 or higher (see table below)&lt;/li&gt; &#xA; &lt;li&gt;Compatible with Apache Spark 1.0 through 3.2 (&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/#version-compatibility&#34;&gt;see table below&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Compatible with Scala 2.11 and 2.12&lt;/li&gt; &#xA; &lt;li&gt;Exposes Cassandra tables as Spark RDDs and Datasets/DataFrames&lt;/li&gt; &#xA; &lt;li&gt;Maps table rows to CassandraRow objects or tuples&lt;/li&gt; &#xA; &lt;li&gt;Offers customizable object mapper for mapping rows to objects of user-defined classes&lt;/li&gt; &#xA; &lt;li&gt;Saves RDDs back to Cassandra by implicit &lt;code&gt;saveToCassandra&lt;/code&gt; call&lt;/li&gt; &#xA; &lt;li&gt;Delete rows and columns from cassandra by implicit &lt;code&gt;deleteFromCassandra&lt;/code&gt; call&lt;/li&gt; &#xA; &lt;li&gt;Join with a subset of Cassandra data using &lt;code&gt;joinWithCassandraTable&lt;/code&gt; call for RDDs, and optimizes join with data in Cassandra when using Datasets/DataFrames&lt;/li&gt; &#xA; &lt;li&gt;Partition RDDs according to Cassandra replication using &lt;code&gt;repartitionByCassandraReplica&lt;/code&gt; call&lt;/li&gt; &#xA; &lt;li&gt;Converts data types between Cassandra and Scala&lt;/li&gt; &#xA; &lt;li&gt;Supports all Cassandra data types including collections&lt;/li&gt; &#xA; &lt;li&gt;Filters rows on the server side via the CQL &lt;code&gt;WHERE&lt;/code&gt; clause&lt;/li&gt; &#xA; &lt;li&gt;Allows for execution of arbitrary CQL statements&lt;/li&gt; &#xA; &lt;li&gt;Plays nice with Cassandra Virtual Nodes&lt;/li&gt; &#xA; &lt;li&gt;Could be used in all languages supporting Datasets/DataFrames API: Python, R, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Version Compatibility&lt;/h2&gt; &#xA;&lt;p&gt;The connector project has several branches, each of which map into different supported versions of Spark and Cassandra. For previous releases the branch is named &#34;bX.Y&#34; where X.Y is the major+minor version; for example the &#34;b1.6&#34; branch corresponds to the 1.6 release. The &#34;master&#34; branch will normally contain development for the next connector release in progress.&lt;/p&gt; &#xA;&lt;p&gt;Currently, the following branches are actively supported: 3.2.x (&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/tree/master&#34;&gt;master&lt;/a&gt;), 3.1.x (&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/tree/b3.1&#34;&gt;b3.1&lt;/a&gt;), 3.0.x (&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/tree/b3.0&#34;&gt;b3.0&lt;/a&gt;) and 2.5.x (&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/tree/b2.5&#34;&gt;b2.5&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Connector&lt;/th&gt; &#xA;   &lt;th&gt;Spark&lt;/th&gt; &#xA;   &lt;th&gt;Cassandra&lt;/th&gt; &#xA;   &lt;th&gt;Cassandra Java Driver&lt;/th&gt; &#xA;   &lt;th&gt;Minimum Java Version&lt;/th&gt; &#xA;   &lt;th&gt;Supported Scala Versions&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3.2&lt;/td&gt; &#xA;   &lt;td&gt;3.2&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x, 4.0&lt;/td&gt; &#xA;   &lt;td&gt;4.13&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3.1&lt;/td&gt; &#xA;   &lt;td&gt;3.1&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x, 4.0&lt;/td&gt; &#xA;   &lt;td&gt;4.12&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x, 4.0&lt;/td&gt; &#xA;   &lt;td&gt;4.12&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.5&lt;/td&gt; &#xA;   &lt;td&gt;2.4&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x, 4.0&lt;/td&gt; &#xA;   &lt;td&gt;4.12&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.11, 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.4.2&lt;/td&gt; &#xA;   &lt;td&gt;2.4&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.11, 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.4&lt;/td&gt; &#xA;   &lt;td&gt;2.4&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.3&lt;/td&gt; &#xA;   &lt;td&gt;2.3&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;   &lt;td&gt;2.0, 2.1, 2.2&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.6&lt;/td&gt; &#xA;   &lt;td&gt;1.6&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.5&lt;/td&gt; &#xA;   &lt;td&gt;1.5, 1.6&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.4&lt;/td&gt; &#xA;   &lt;td&gt;1.4&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*&lt;/td&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.3&lt;/td&gt; &#xA;   &lt;td&gt;1.3&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*&lt;/td&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.2&lt;/td&gt; &#xA;   &lt;td&gt;1.2&lt;/td&gt; &#xA;   &lt;td&gt;2.1, 2.0&lt;/td&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.1&lt;/td&gt; &#xA;   &lt;td&gt;1.1, 1.0&lt;/td&gt; &#xA;   &lt;td&gt;2.1, 2.0&lt;/td&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.0&lt;/td&gt; &#xA;   &lt;td&gt;1.0, 0.9&lt;/td&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;*&lt;em&gt;Compatible with 2.1.X where X &amp;gt;= 5&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Hosted API Docs&lt;/h2&gt; &#xA;&lt;p&gt;API documentation for the Scala and Java interfaces are available online:&lt;/p&gt; &#xA;&lt;h3&gt;3.2.0&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.2.0/connector/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;3.1.0&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.1.0/connector/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;3.0.1&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.0.1/connector/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2.5.2&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/2.5.2/connector/#package&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2.4.2&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.4.2/spark-cassandra-connector/&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.4.2/spark-cassandra-connector-embedded/&#34;&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;This project is available on the Maven Central Repository. For SBT to download the connector binaries, sources and javadoc, put this in your project SBT config:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies += &#34;com.datastax.spark&#34; %% &#34;spark-cassandra-connector&#34; % &#34;3.2.0&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The default Scala version for Spark 3.0+ is 2.12 please choose the appropriate build. See the &lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/FAQ.md&#34;&gt;FAQ&lt;/a&gt; for more information.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/12_building_and_artifacts.md&#34;&gt;Building And Artifacts&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/0_quick_start.md&#34;&gt;Quick-start guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/1_connecting.md&#34;&gt;Connecting to Cassandra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/2_loading.md&#34;&gt;Loading datasets from Cassandra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/3_selection.md&#34;&gt;Server-side data selection and filtering&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/4_mapper.md&#34;&gt;Working with user-defined case classes and tuples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/5_saving.md&#34;&gt;Saving and deleting datasets to/from Cassandra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/6_advanced_mapper.md&#34;&gt;Customizing the object mapping&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/7_java_api.md&#34;&gt;Using Connector in Java&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/8_streaming.md&#34;&gt;Spark Streaming with Cassandra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/10_embedded.md&#34;&gt;The spark-cassandra-connector-embedded Artifact&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/11_metrics.md&#34;&gt;Performance monitoring&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/12_building_and_artifacts.md&#34;&gt;Building And Artifacts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/13_spark_shell.md&#34;&gt;The Spark Shell&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/14_data_frames.md&#34;&gt;DataFrames&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/15_python.md&#34;&gt;Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/16_partitioning.md&#34;&gt;Partitioner&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/17_submitting.md&#34;&gt;Submitting applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/FAQ.md&#34;&gt;Frequently Asked Questions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/reference.md&#34;&gt;Configuration Parameter Reference Table&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/developers.md&#34;&gt;Tips for Developing the Spark Cassandra Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Online Training&lt;/h2&gt; &#xA;&lt;h3&gt;DataStax Academy&lt;/h3&gt; &#xA;&lt;p&gt;DataStax Academy provides free online training for Apache Cassandra and DataStax Enterprise. In &lt;a href=&#34;https://academy.datastax.com/courses/ds320-analytics-with-apache-spark&#34;&gt;DS320: Analytics with Spark&lt;/a&gt;, you will learn how to effectively and efficiently solve analytical problems with Apache Spark, Apache Cassandra, and DataStax Enterprise. You will learn about Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;h3&gt;Reporting Bugs&lt;/h3&gt; &#xA;&lt;p&gt;New issues may be reported using &lt;a href=&#34;https://datastax-oss.atlassian.net/browse/SPARKC/&#34;&gt;JIRA&lt;/a&gt;. Please include all relevant details including versions of Spark, Spark Cassandra Connector, Cassandra and/or DSE. A minimal reproducible case with sample code is ideal.&lt;/p&gt; &#xA;&lt;h3&gt;Mailing List&lt;/h3&gt; &#xA;&lt;p&gt;Questions and requests for help may be submitted to the &lt;a href=&#34;https://groups.google.com/a/lists.datastax.com/forum/#!forum/spark-connector-user&#34;&gt;user mailing list&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Q/A Exchange&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://community.datastax.com/index.html&#34;&gt;DataStax Community&lt;/a&gt; provides a free question and answer website for any and all questions relating to any DataStax Related technology. Including the Spark Cassandra Connector. Both DataStax engineers and community members frequent this board and answer questions.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;To protect the community, all contributors are required to sign the &lt;a href=&#34;http://spark-cassandra-connector-cla.datastax.com/&#34;&gt;DataStax Spark Cassandra Connector Contribution License Agreement&lt;/a&gt;. The process is completely electronic and should only take a few minutes.&lt;/p&gt; &#xA;&lt;p&gt;To develop this project, we recommend using IntelliJ IDEA. Make sure you have installed and enabled the Scala Plugin. Open the project with IntelliJ IDEA and it will automatically create the project structure from the provided SBT configuration.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/developers.md&#34;&gt;Tips for Developing the Spark Cassandra Connector&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Checklist for contributing changes to the project:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a &lt;a href=&#34;https://datastax-oss.atlassian.net/projects/SPARKC/issues&#34;&gt;SPARKC JIRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Make sure that all unit tests and integration tests pass&lt;/li&gt; &#xA; &lt;li&gt;Add an appropriate entry at the top of CHANGES.txt&lt;/li&gt; &#xA; &lt;li&gt;If the change has any end-user impacts, also include changes to the ./doc files as needed&lt;/li&gt; &#xA; &lt;li&gt;Prefix the pull request description with the JIRA number, for example: &#34;SPARKC-123: Fix the ...&#34;&lt;/li&gt; &#xA; &lt;li&gt;Open a pull-request on GitHub and await review&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;p&gt;To run unit and integration tests:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sbt/sbt test&#xA;./sbt/sbt it:test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the integration tests require &lt;a href=&#34;https://github.com/riptano/ccm&#34;&gt;CCM&lt;/a&gt; to be installed on your machine. See &lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/developers.md&#34;&gt;Tips for Developing the Spark Cassandra Connector&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;By default, integration tests start up a separate, single Cassandra instance and run Spark in local mode. It is possible to run integration tests with your own Cassandra and/or Spark cluster. First, prepare a jar with testing code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sbt/sbt test:package&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then copy the generated test jar to your Spark nodes and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export IT_TEST_CASSANDRA_HOST=&amp;lt;IP of one of the Cassandra nodes&amp;gt;&#xA;export IT_TEST_SPARK_MASTER=&amp;lt;Spark Master URL&amp;gt;&#xA;./sbt/sbt it:test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Generating Documents&lt;/h2&gt; &#xA;&lt;p&gt;To generate the Reference Document use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sbt/sbt spark-cassandra-connector-unshaded/run (outputLocation)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;outputLocation defaults to doc/reference.md&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright 2014-2017, DataStax, Inc.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lampepfl/dotty</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/lampepfl/dotty</id>
    <link href="https://github.com/lampepfl/dotty" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Scala 3 compiler, also known as Dotty.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dotty&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lampepfl/dotty/actions?query=branch%3Amain&#34;&gt;&lt;img src=&#34;https://github.com/lampepfl/dotty/workflows/Dotty/badge.svg?branch=master&#34; alt=&#34;Dotty CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.com/invite/scala&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/632150470000902164&#34; alt=&#34;Join the chat at https://discord.com/invite/scala&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.scala-lang.org/scala3/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Try it out&lt;/h1&gt; &#xA;&lt;p&gt;To try it in your project see also the &lt;a href=&#34;https://docs.scala-lang.org/scala3/getting-started.html&#34;&gt;Getting Started User Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Building a Local Distribution&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;sbt dist/packArchive&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Find the newly-built distributions in &lt;code&gt;dist/target/&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Code of Conduct&lt;/h1&gt; &#xA;&lt;p&gt;Dotty uses the &lt;a href=&#34;https://www.scala-lang.org/conduct.html&#34;&gt;Scala Code of Conduct&lt;/a&gt; for all communication and discussion. This includes both GitHub, Discord and other more direct lines of communication such as email.&lt;/p&gt; &#xA;&lt;h1&gt;How to Contribute&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.scala-lang.org/scala3/guides/contribution/contribution-intro.html&#34;&gt;Getting Started as Contributor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lampepfl/dotty/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22&#34;&gt;Issues&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;Dotty is licensed under the &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License Version 2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kah109xq/GSS-Cogss</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/kah109xq/GSS-Cogss</id>
    <link href="https://github.com/kah109xq/GSS-Cogss" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implement CSV validation following the W3C&#39;s CSV on the Web standard.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Validate CSV-W based on tests provided by W3C (&lt;a href=&#34;https://w3c.github.io/csvw/tests/#manifest-validation&#34;&gt;https://w3c.github.io/csvw/tests/#manifest-validation&lt;/a&gt;)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ucb-bar/riscv-torture</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/ucb-bar/riscv-torture</id>
    <link href="https://github.com/ucb-bar/riscv-torture" rel="alternate"></link>
    <summary type="html">&lt;p&gt;RISC-V Torture Test&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;=========================================================================== RISC-V Torture Test Generator&lt;/h1&gt; &#xA;&lt;h1&gt;Author: Yunsup Lee and Henry Cook&lt;/h1&gt; &#xA;&lt;h1&gt;Date: January 29th, 2012&lt;/h1&gt; &#xA;&lt;h1&gt;Version: (under version control)&lt;/h1&gt; &#xA;&lt;p&gt;This is the RISC-V torture test generator and framework. This repository contains three sub-projects that build upon one another. The first, [generator], is used to create a single random torture test. The second, [testrun], is used to run a particular test on particular simulators, diffing the resulting signature with the ISA simulator and optionally creating a derivative test subset that pinpoints the divergence. The third, [overnight], wraps testrun, allowing tests to be run repeatedly for a given duration or until a failure count.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Instructions&lt;/h2&gt; &#xA;&lt;p&gt;Modify &#34;config/default.config&#34; to set the parameters desired for building tests (e.g., setting which instructions to use and in which ratio).&lt;/p&gt; &#xA;&lt;p&gt;Modify &#34;Makefile&#34; as desired to execute the C simulator or RTL simulator of your choice, and to set the other parameters as you require.&lt;/p&gt; &#xA;&lt;p&gt;To build a single test and test it on Spike:&lt;/p&gt; &#xA;&lt;p&gt;$ make igentest&lt;/p&gt; &#xA;&lt;p&gt;To build single test and run it on the C simulator or RTL simulator, use &#34;make cgentest&#34; or &#34;make rgentest&#34;.&lt;/p&gt; &#xA;&lt;p&gt;To run overnight tests, you can use &#34;make cnight&#34; and &#34;make rnight&#34;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Signatures&lt;/h2&gt; &#xA;&lt;p&gt;Torture works by dumping the register state out to memory at the end of the test program execution. This output is then compared against the output from the Spike ISA simulator.&lt;/p&gt; &#xA;&lt;p&gt;The torture program writes the register state to the memory address specified by &#34;xreg_output_data&#34;, which is located in the memory section &#34;.global begin_signature&#34;. The Spike ISA simulator will write out the data found in the &#34;begin_signature&#34; section on exit if provided with the &#34;+signature=&#34; argument:&lt;/p&gt; &#xA;&lt;p&gt;$ spike +signature=my_spike_signature.txt test_binary&lt;/p&gt; &#xA;&lt;p&gt;The Rocket-chip infrastructure uses the &#34;riscv-fesvr&#34; program to control the execution of the C and RTL simulators. The &#34;riscv-fesvr&#34; also accepts the +signature argument too.&lt;/p&gt; &#xA;&lt;p&gt;$ ./csim-rocket-chip +signature=my_rocket_signature.txt test_binary&lt;/p&gt; &#xA;&lt;p&gt;A simple diff between the Spike and chip simulator signatures will tell you if any errors have occurred.&lt;/p&gt; &#xA;&lt;p&gt;$ diff my_spike_signature.txt my_rocket_signature.txt&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PORTING TORTURE TO YOUR OWN RISC-V PROCESSOR:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you would like to use riscv-torture with your own RISC-V processor, you will need to provide a way to dump the &#34;begin_signature&#34; section to a file.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Low-level Usage&lt;/h2&gt; &#xA;&lt;p&gt;Some basic use cases are illustrated here (note the Makefile abstracts this for you).&lt;/p&gt; &#xA;&lt;p&gt;Make a single test: % ./sbt generator/run % cd output % make % spike +signature=test.sig test&lt;/p&gt; &#xA;&lt;p&gt;Take an existing test and diff the signatures of ISA and C simulators: % ./sbt &#39;testrun/run -a output/test.S -c /path/to/reference-chip/emulator/emulator&#39;&lt;/p&gt; &#xA;&lt;p&gt;*** Currently, due to the limiation of scala process library, you cannot torture the RTL simulator ***&lt;/p&gt; &#xA;&lt;h1&gt;Generate a random test and diff the signatures of ISA and RTL simulators:&lt;/h1&gt; &#xA;&lt;h1&gt;% ./sbt &#39;testrun/run -r /path/to/reference-chip/vlsi/build/vcs-sim-rtl/simv&#39;&lt;/h1&gt; &#xA;&lt;p&gt;Run tests for 30 minutes, email hcook when done, and save failures to dir: % ./sbt &#39;overnight/run -m 30 -e &lt;a href=&#34;mailto:hcook@eecs.berkeley.edu&#34;&gt;hcook@eecs.berkeley.edu&lt;/a&gt; -p dir&#39;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Installing&lt;/h2&gt; &#xA;&lt;p&gt;% git submodule update --init&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Overnight Overview&lt;/h2&gt; &#xA;&lt;p&gt;This framework utilizes both the test runner and test generator to perform a long terms serach for failing test cases. It takes the following command line arguments:&lt;/p&gt; &#xA;&lt;p&gt;Usage: overnight/run [options] -C &#xA; &lt;file&gt;&#xA;   | --config &#xA;  &lt;file&gt;&#xA;    config file -p &#xA;  &lt;/file&gt;&#xA; &lt;/file&gt;&lt;/p&gt;&#xA;&lt;dir&gt;&#xA;  | --permdir &#xA; &lt;dir&gt;&#xA;   dir to store failing tests -c &#xA;  &lt;file&gt;&#xA;    | --csim &#xA;   &lt;file&gt;&#xA;     C simulator -r &#xA;    &lt;file&gt;&#xA;      | --rtlsim &#xA;     &lt;file&gt;&#xA;       RTL simulator -e &#xA;      &lt;address&gt; | --email &lt;address&gt; email to report to -t &#xA;        &lt;count&gt;&#xA;          | --threshold &#xA;         &lt;count&gt;&#xA;           number of failures to trigger email -m &#xA;          &lt;int&gt;&#xA;            | --minutes &#xA;           &lt;int&gt;&#xA;             number of minutes to run tests&#xA;            &lt;p&gt;&lt;/p&gt; &#xA;            &lt;p&gt;You can only generate tests with one instruction mix at a time (based on the setting in the config file). It doesn&#39;t matter what simulator you use with the -r and -c flags, they just determines the name used to describe whose diff failed.&lt;/p&gt; &#xA;            &lt;hr&gt; &#xA;            &lt;h2&gt;Testrun Overview&lt;/h2&gt; &#xA;            &lt;p&gt;This utility compares the signatures generated by passing the -testsig flag to the specified simulators. If it encounters a difference, it subdivides the test into many subtests and searches for which exact program segment reveals the failure. It takes the following command line arguments:&lt;/p&gt; &#xA;            &lt;p&gt;Usage: testrun/run [options] -C &#xA;             &lt;file&gt;&#xA;               | --config &#xA;              &lt;file&gt;&#xA;                config file -a &#xA;               &lt;file&gt;&#xA;                 | --asm &#xA;                &lt;file&gt;&#xA;                  input ASM file -c &#xA;                 &lt;file&gt;&#xA;                   | --csim &#xA;                  &lt;file&gt;&#xA;                    C simulator -r &#xA;                   &lt;file&gt;&#xA;                     | --rtlsim &#xA;                    &lt;file&gt;&#xA;                      RTL simulator -s &#xA;                     &lt;boolean&gt;&#xA;                       | --seek &#xA;                      &lt;boolean&gt;&#xA;                        Seek for failing pseg -d &#xA;                       &lt;boolean&gt;&#xA;                         | --dump &#xA;                        &lt;boolean&gt;&#xA;                          Dump mismatched signatures&#xA;                        &lt;/boolean&gt;&#xA;                       &lt;/boolean&gt;&#xA;                      &lt;/boolean&gt;&#xA;                     &lt;/boolean&gt;&#xA;                    &lt;/file&gt;&#xA;                   &lt;/file&gt;&#xA;                  &lt;/file&gt;&#xA;                 &lt;/file&gt;&#xA;                &lt;/file&gt;&#xA;               &lt;/file&gt;&#xA;              &lt;/file&gt;&#xA;             &lt;/file&gt;&lt;/p&gt; &#xA;            &lt;p&gt;If you don&#39;t specify a asm file, a random one will be generated for you. You can only generate tests with one instruction mix at a time (based on the setting in the config file). It doesn&#39;t matter what simulator you use with the -r and -c flags, they just determines the name used to describe whose diff failed. By default, a failed diff will result in the subtest sweep occuring, but this search can be diasbled. Note that the pseg ID reported is actually the pseg following the pseg containing the error. You can optionally dump mistmatched signatures to the dir containing the asm file under test.&lt;/p&gt; &#xA;            &lt;hr&gt; &#xA;            &lt;h2&gt;Generator Overview&lt;/h2&gt; &#xA;            &lt;p&gt;To generate a random test, the torture test generator randomly generates many test sequences from a set of test sequences that are written by hand, performs a random register allocation for all test sequences, and finally randomly interleaves instructions from these test sequences. To extend the set of tests or coverage, the programmer needs to write new test sequences. It takes the following command line arguments:&lt;/p&gt; &#xA;            &lt;p&gt;Usage: generator/run [options] -o &#xA;             &lt;filename&gt;&#xA;               | --output &#xA;              &lt;filename&gt;&#xA;                output filename -C &#xA;               &lt;file&gt;&#xA;                 | --config &#xA;                &lt;file&gt;&#xA;                  config file&#xA;                &lt;/file&gt;&#xA;               &lt;/file&gt;&#xA;              &lt;/filename&gt;&#xA;             &lt;/filename&gt;&lt;/p&gt; &#xA;            &lt;p&gt;The following sections describe adding new functionality to the generator.&lt;/p&gt; &#xA;            &lt;hr&gt; &#xA;            &lt;h2&gt;Test sequence example&lt;/h2&gt; &#xA;            &lt;p&gt;Before we talk about how to write a test sequence, let&#39;s look at a very simple example. The following example is a test sequence, which emits an add instruction.&lt;/p&gt; &#xA;            &lt;p&gt;class SeqADD extends Seq { val src1 = reg_read_any() val src2 = reg_read_any() val dest = reg_write(src1, src2) insts += ADD(dest, src1, src2) }&lt;/p&gt; &#xA;            &lt;p&gt;As I hinted in the overview that the test generator will do register allocation you don&#39;t write a string of instructions with architectural registers. You request a virtual registers (i.e., registers that are yet tied down to architectural registers) when you need them, save them in scala values, and use them when you need to (e.g., in an instruction).&lt;/p&gt; &#xA;            &lt;hr&gt; &#xA;            &lt;h2&gt;Types of virtual registers&lt;/h2&gt; &#xA;            &lt;ul&gt; &#xA;             &lt;li&gt; &lt;p&gt;Hidden (position dependent registers): Registers that will have different values when the code is positioned at a different address. An example is registers that hold addresses. Registers that are hidden should be excluded from the output signature.&lt;/p&gt; &lt;/li&gt; &#xA;             &lt;li&gt; &lt;p&gt;Visible (position independent registers): Registers that are not hidden, therefore will have the same values when the code is positioned at a different address. These registers should be included as part of the output signature.&lt;/p&gt; &lt;/li&gt; &#xA;            &lt;/ul&gt; &#xA;            &lt;hr&gt; &#xA;            &lt;h2&gt;How to write a sequence&lt;/h2&gt; &#xA;            &lt;p&gt;Use the following functions to request a register, and generate a string of instructions (look at Inst.scala to see what instructions are available) that uses these virtual registers, and add them to the insts array.&lt;/p&gt; &#xA;            &lt;ul&gt; &#xA;             &lt;li&gt;reg_read_zero(): returns register x0&lt;/li&gt; &#xA;             &lt;li&gt;reg_read_any(): returns any type of register (hidden or visible)&lt;/li&gt; &#xA;             &lt;li&gt;reg_read_visible(): returns a visible register&lt;/li&gt; &#xA;             &lt;li&gt;reg_write_ra(): returns register ra for write&lt;/li&gt; &#xA;             &lt;li&gt;reg_write_visible(): returns a visible register for write&lt;/li&gt; &#xA;             &lt;li&gt;reg_write_hidden(): returns a hidden register for write&lt;/li&gt; &#xA;             &lt;li&gt;reg_write(regs: Reg*): returns a register that matches the type of regs (if any reg in regs are hidden, the output type is hidden)&lt;/li&gt; &#xA;            &lt;/ul&gt; &#xA;            &lt;p&gt;Note that the torture test framework is written in scala, you can use any scala functionality to generate instructions. Look at SeqALU.scala, SeqMem.scala, and SeqBranch.scala to get inspired.&lt;/p&gt; &#xA;            &lt;hr&gt; &#xA;            &lt;h2&gt;Future TODO&lt;/h2&gt; &#xA;            &lt;ul&gt; &#xA;             &lt;li&gt; &lt;p&gt;provide support for loops&lt;/p&gt; &lt;/li&gt; &#xA;             &lt;li&gt; &lt;p&gt;generate statistics of a test to get a sense of coverage&lt;/p&gt; &#xA;              &lt;ul&gt; &#xA;               &lt;li&gt;statistics should include instruction count of each type&lt;/li&gt; &#xA;               &lt;li&gt;statistics should include register usage&lt;/li&gt; &#xA;              &lt;/ul&gt; &lt;/li&gt; &#xA;             &lt;li&gt; &lt;p&gt;complete floating point tests&lt;/p&gt; &#xA;              &lt;ul&gt; &#xA;               &lt;li&gt;add floating point memory move tests&lt;/li&gt; &#xA;               &lt;li&gt;improve floating point init randomization&lt;/li&gt; &#xA;               &lt;li&gt;add rounding modes tests&lt;/li&gt; &#xA;              &lt;/ul&gt; &lt;/li&gt; &#xA;             &lt;li&gt; &lt;p&gt;complete vector tests&lt;/p&gt; &#xA;              &lt;ul&gt; &#xA;               &lt;li&gt;better randomization&lt;/li&gt; &#xA;               &lt;li&gt;add SeqVOnly: Tests special vf-only instructions&lt;/li&gt; &#xA;              &lt;/ul&gt; &lt;/li&gt; &#xA;             &lt;li&gt; &lt;p&gt;code refactoring&lt;/p&gt; &#xA;              &lt;ul&gt; &#xA;               &lt;li&gt;consolidate RegPool logic&lt;/li&gt; &#xA;               &lt;li&gt;detect and suppress unallocatable sequences&lt;/li&gt; &#xA;              &lt;/ul&gt; &lt;/li&gt; &#xA;            &lt;/ul&gt; &#xA;           &lt;/int&gt;&#xA;          &lt;/int&gt;&#xA;         &lt;/count&gt;&#xA;        &lt;/count&gt;&lt;/address&gt;&lt;/address&gt;&#xA;     &lt;/file&gt;&#xA;    &lt;/file&gt;&#xA;   &lt;/file&gt;&#xA;  &lt;/file&gt;&#xA; &lt;/dir&gt;&#xA;&lt;/dir&gt;</summary>
  </entry>
  <entry>
    <title>twitter/twitter-server</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/twitter/twitter-server</id>
    <link href="https://github.com/twitter/twitter-server" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Twitter-Server defines a template from which services at Twitter are built&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TwitterServer&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/twitter/twitter-server/actions?query=workflow%3A%22continuous+integration%22+branch%3Adevelop&#34;&gt;&lt;img src=&#34;https://github.com/twitter/twitter-server/workflows/continuous%20integration/badge.svg?branch=develop&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/twitter/twitter-server&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/twitter/twitter-server/branch/develop/graph/badge.svg?sanitize=true&#34; alt=&#34;Codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/twitter/twitter-server/develop/#status&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/status-active-brightgreen.svg?sanitize=true&#34; alt=&#34;Project status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/twitter/finagle?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/twitter/finagle.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.twitter/twitter-server_2.12&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/com.twitter/twitter-server_2.12/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;TwitterServer defines a template from which servers at Twitter are built. It provides common application components such as an administrative HTTP server, tracing, stats, etc. These features are wired in correctly for use in production at Twitter.&lt;/p&gt; &#xA;&lt;h2&gt;Status&lt;/h2&gt; &#xA;&lt;p&gt;This project is used in production at Twitter (and many other organizations), and is being actively developed and maintained.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Browse the &lt;a href=&#34;https://twitter.github.io/twitter-server/&#34;&gt;user guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Releases&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.twitter/twitter-server_2.12&#34;&gt;Releases&lt;/a&gt; are done on an approximately monthly schedule. While &lt;a href=&#34;https://semver.org/&#34;&gt;semver&lt;/a&gt; is not followed, the &lt;a href=&#34;https://raw.githubusercontent.com/twitter/twitter-server/develop/CHANGELOG.rst&#34;&gt;changelogs&lt;/a&gt; are detailed and include sections on public API breaks and changes in runtime behavior.&lt;/p&gt; &#xA;&lt;h2&gt;Getting involved&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Website: &lt;a href=&#34;https://twitter.github.io/twitter-server/&#34;&gt;https://twitter.github.io/twitter-server/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Source: &lt;a href=&#34;https://github.com/twitter/twitter-server/&#34;&gt;https://github.com/twitter/twitter-server/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Mailing List: &lt;a href=&#34;https://groups.google.com/forum/#!forum/finaglers&#34;&gt;finaglers@googlegroups.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Chat: &lt;a href=&#34;https://gitter.im/twitter/finagle&#34;&gt;https://gitter.im/twitter/finagle&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We feel that a welcoming community is important and we ask that you follow Twitter&#39;s &lt;a href=&#34;https://github.com/twitter/.github/raw/main/code-of-conduct.md&#34;&gt;Open Source Code of Conduct&lt;/a&gt; in all interactions with the community.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;release&lt;/code&gt; branch of this repository contains the latest stable release of TwitterServer, and weekly snapshots are published to the &lt;code&gt;develop&lt;/code&gt; branch. In general pull requests should be submitted against &lt;code&gt;develop&lt;/code&gt;. See &lt;a href=&#34;https://github.com/twitter/twitter-server/raw/release/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for more details about how to contribute.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright 2013 Twitter, Inc.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0: &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>deng0515001/lnglat2Geo</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/deng0515001/lnglat2Geo</id>
    <link href="https://github.com/deng0515001/lnglat2Geo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ç»çº¬åº¦è½¬çœå¸‚åŒºåŽ¿ä¹¡é•‡ç¦»çº¿åŒ…ï¼Œé‡‡ç”¨ç©ºé—´æŸ¥è¯¢ç®—æ³•ï¼Œé€Ÿåº¦å¿«(å•çº¿ç¨‹5wæ¬¡/s)ï¼Œçœå¸‚åŒºåŽ¿100%å‡†ç¡®çŽ‡ã€‚&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;lnglat2Geo&lt;/h1&gt; &#xA;&lt;p&gt;ç»çº¬åº¦è½¬çœå¸‚åŒºåŽ¿ä¹¡é•‡ï¼Œé€Ÿåº¦å¿« -- å•çº¿ç¨‹50000æ¬¡/ç§’ï¼›ç²¾åº¦é«˜ -- å‡†ç¡®çŽ‡99.9999%&lt;/p&gt; &#xA;&lt;p&gt;è¿˜åŒ…å«å¦‚ä¸‹åŠŸèƒ½ï¼š&lt;/p&gt; &#xA;&lt;p&gt;1ï¼šæŸ¥è¯¢æŸä¸ªç»çº¬åº¦é™„è¿‘æ‰€æœ‰å•†åœˆï¼ŒæŒ‰è·ç¦»æŽ’åº&lt;/p&gt; &#xA;&lt;p&gt;2ï¼šç»™å®šåŸŽå¸‚ï¼Œè¾“å‡ºåŸŽå¸‚çº§åˆ«&lt;/p&gt; &#xA;&lt;p&gt;3ï¼šè¾“å…¥ä»»ä½•åœ°åŒºçš„å…¨ç§°/ç®€ç§°/codeï¼Œè¾“å‡ºè¯¥åœ°åŒºçš„å…¨éƒ¨ä¿¡æ¯&lt;/p&gt; &#xA;&lt;p&gt;4ï¼šèŽ·å–æ‰€æœ‰è¡Œæ”¿åŒºåˆ’å…³ç³»æ•°æ®ç­‰&lt;/p&gt; &#xA;&lt;p&gt;ä½¿ç”¨æ–¹æ³•ï¼š import com.dengxq.lnglat2Geo.GeoTrans é‡Œé¢çš„æ‰€æœ‰æ–¹æ³•å‡ä¸ºå…¬æœ‰æŽ¥å£&lt;/p&gt; &#xA;&lt;p&gt;æŽ¥å£æ–‡æ¡£ï¼Œå‚è€ƒåšå®¢ï¼š &lt;a href=&#34;https://blog.csdn.net/deng0515001/article/details/99606156&#34;&gt;https://blog.csdn.net/deng0515001/article/details/99606156&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;jaråŒ…ä¾èµ–ï¼š&lt;a href=&#34;https://mvnrepository.com/artifact/com.github.deng0515001/lnglat2Geo&#34;&gt;https://mvnrepository.com/artifact/com.github.deng0515001/lnglat2Geo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;æœ‰é—®é¢˜ç›´æŽ¥è”ç³»ï¼šQQï¼š&lt;a href=&#34;mailto:451408963@qq.com&#34;&gt;451408963@qq.com&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ucb-bar/testchipip</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/ucb-bar/testchipip</id>
    <link href="https://github.com/ucb-bar/testchipip" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;testchipip&lt;/h1&gt; &#xA;&lt;p&gt;Useful IP components for chips. BAR projects generally use these components with &lt;a href=&#34;https://github.com/freechipsproject/rocket-chip&#34;&gt;rocket-chip&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Blocks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Block device model&lt;/li&gt; &#xA; &lt;li&gt;Clock utilities for Chisel, e.g. clock mux, clock divider, etc.&lt;/li&gt; &#xA; &lt;li&gt;SERDES &amp;lt;-&amp;gt; TileLink&lt;/li&gt; &#xA; &lt;li&gt;Custom serial interface for debug with simulator interface&lt;/li&gt; &#xA; &lt;li&gt;TileLink splitter, switcher&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Testchipip can be used in your project in one of two ways:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;As an sbt subproject that depends on rocket-chip, as in &lt;a href=&#34;https://github.com/ucb-bar/chipyard/&#34;&gt;chipyard&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;As a maven dependency (e.g. write&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies += &#34;edu.berkeley.cs&#34; %% &#34;testchipip&#34; % &#34;1.0-020719-SNAPSHOT&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;in your build.sbt). Check &lt;a href=&#34;https://oss.sonatype.org/content/repositories/snapshots/edu/berkeley/cs/testchipip_2.12/&#34;&gt;sonatype&lt;/a&gt; to see the latest published version.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>chipsalliance/chisel3</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/chipsalliance/chisel3</id>
    <link href="https://github.com/chipsalliance/chisel3" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Chisel 3: A Modern Hardware Design Language&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/docs/src/images/chisel_logo.svg?sanitize=true&#34; alt=&#34;Chisel 3&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Upcoming Events&lt;/h2&gt; &#xA;&lt;h3&gt;Chisel Dev Meeting&lt;/h3&gt; &#xA;&lt;p&gt;Chisel/FIRRTL development meetings happen every Monday and Tuesday from 1100--1200 PT.&lt;/p&gt; &#xA;&lt;p&gt;Call-in info and meeting notes are available &lt;a href=&#34;https://docs.google.com/document/d/1BLP2DYt59DqI-FgFCcjw8Ddl4K-WU0nHmQu0sZ_wAGo/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Chisel Community Conference 2021, Shanghai, China.&lt;/h3&gt; &#xA;&lt;p&gt;CCC is an annual gathering of Chisel community enthusiasts and technical exchange workshop. This year with the support of the Chisel development community and RISC-V World Conference China 2021 Committee, we have brought together designers and developers with hands-on experience in Chisel from home and abroad to share cutting-edge results and experiences from both the open source community as well as industry.&lt;br&gt; English translated recordings version will be updated soon.&lt;br&gt; Looking forward to CCC 2022! See you then!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/freechipsproject/chisel3?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/chipsalliance/chisel3.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/freechipsproject/chisel3&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://github.com/chipsalliance/chisel3/actions/workflows/test.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt; &lt;a href=&#34;https://github.com/chipsalliance/chisel3/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/tag/chipsalliance/chisel3.svg?include_prereleases&amp;amp;sort=semver&#34; alt=&#34;GitHub tag (latest SemVer)&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.chisel-lang.org&#34;&gt;&lt;strong&gt;Chisel&lt;/strong&gt;&lt;/a&gt; is a hardware design language that facilitates &lt;strong&gt;advanced circuit generation and design reuse for both ASIC and FPGA digital logic designs&lt;/strong&gt;. Chisel adds hardware construction primitives to the &lt;a href=&#34;https://www.scala-lang.org&#34;&gt;Scala&lt;/a&gt; programming language, providing designers with the power of a modern programming language to write complex, parameterizable circuit generators that produce synthesizable Verilog. This generator methodology enables the creation of re-usable components and libraries, such as the FIFO queue and arbiters in the &lt;a href=&#34;https://www.chisel-lang.org/api/latest/#chisel3.util.package&#34;&gt;Chisel Standard Library&lt;/a&gt;, raising the level of abstraction in design while retaining fine-grained control.&lt;/p&gt; &#xA;&lt;p&gt;For more information on the benefits of Chisel see: &lt;a href=&#34;https://stackoverflow.com/questions/53007782/what-benefits-does-chisel-offer-over-classic-hardware-description-languages&#34;&gt;&#34;What benefits does Chisel offer over classic Hardware Description Languages?&#34;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Chisel is powered by &lt;a href=&#34;https://github.com/chipsalliance/firrtl&#34;&gt;FIRRTL (Flexible Intermediate Representation for RTL)&lt;/a&gt;, a hardware compiler framework that performs optimizations of Chisel-generated circuits and supports custom user-defined circuit transformations.&lt;/p&gt; &#xA;&lt;h2&gt;What does Chisel code look like?&lt;/h2&gt; &#xA;&lt;p&gt;Consider an FIR filter that implements a convolution operation, as depicted in this block diagram:&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/docs/src/images/fir_filter.svg?sanitize=true&#34; width=&#34;512&#34;&gt; &#xA;&lt;p&gt;While Chisel provides similar base primitives as synthesizable Verilog, and &lt;em&gt;could&lt;/em&gt; be used as such:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// 3-point moving sum implemented in the style of a FIR filter&#xA;class MovingSum3(bitWidth: Int) extends Module {&#xA;  val io = IO(new Bundle {&#xA;    val in = Input(UInt(bitWidth.W))&#xA;    val out = Output(UInt(bitWidth.W))&#xA;  })&#xA;&#xA;  val z1 = RegNext(io.in)&#xA;  val z2 = RegNext(z1)&#xA;&#xA;  io.out := (io.in * 1.U) + (z1 * 1.U) + (z2 * 1.U)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;the power of Chisel comes from the ability to create generators, such as an FIR filter that is defined by the list of coefficients:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Generalized FIR filter parameterized by the convolution coefficients&#xA;class FirFilter(bitWidth: Int, coeffs: Seq[UInt]) extends Module {&#xA;  val io = IO(new Bundle {&#xA;    val in = Input(UInt(bitWidth.W))&#xA;    val out = Output(UInt(bitWidth.W))&#xA;  })&#xA;  // Create the serial-in, parallel-out shift register&#xA;  val zs = Reg(Vec(coeffs.length, UInt(bitWidth.W)))&#xA;  zs(0) := io.in&#xA;  for (i &amp;lt;- 1 until coeffs.length) {&#xA;    zs(i) := zs(i-1)&#xA;  }&#xA;&#xA;  // Do the multiplies&#xA;  val products = VecInit.tabulate(coeffs.length)(i =&amp;gt; zs(i) * coeffs(i))&#xA;&#xA;  // Sum up the products&#xA;  io.out := products.reduce(_ + _)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and use and re-use them across designs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val movingSum3Filter = Module(new FirFilter(8, Seq(1.U, 1.U, 1.U)))  // same 3-point moving sum filter as before&#xA;val delayFilter = Module(new FirFilter(8, Seq(0.U, 1.U)))  // 1-cycle delay as a FIR filter&#xA;val triangleFilter = Module(new FirFilter(8, Seq(1.U, 2.U, 3.U, 2.U, 1.U)))  // 5-point FIR filter with a triangle impulse response&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above can be converted to Verilog using &lt;code&gt;ChiselStage&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import chisel3.stage.{ChiselStage, ChiselGeneratorAnnotation}&#xA;&#xA;(new chisel3.stage.ChiselStage).execute(&#xA;  Array(&#34;-X&#34;, &#34;verilog&#34;),&#xA;  Seq(ChiselGeneratorAnnotation(() =&amp;gt; new FirFilter(8, Seq(1.U, 1.U, 1.U)))))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you may generate some Verilog directly for inspection:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val verilogString = chisel3.emitVerilog(new FirFilter(8, Seq(0.U, 1.U)))&#xA;println(verilogString)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Bootcamp Interactive Tutorial&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://mybinder.org/v2/gh/freechipsproject/chisel-bootcamp/master&#34;&gt;&lt;strong&gt;online Chisel Bootcamp&lt;/strong&gt;&lt;/a&gt; is the recommended way to get started with and learn Chisel. &lt;strong&gt;No setup is required&lt;/strong&gt; (it runs in the browser), nor does it assume any prior knowledge of Scala.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/ucb-bar/chisel-tutorial&#34;&gt;&lt;strong&gt;classic Chisel tutorial&lt;/strong&gt;&lt;/a&gt; contains small exercises and runs on your computer.&lt;/p&gt; &#xA;&lt;h3&gt;A Textbook on Chisel&lt;/h3&gt; &#xA;&lt;p&gt;If you like a textbook to learn Chisel and also a bit of digital design in general, you may be interested in reading &lt;a href=&#34;http://www.imm.dtu.dk/~masca/chisel-book.html&#34;&gt;&lt;strong&gt;Digital Design with Chisel&lt;/strong&gt;&lt;/a&gt;. It is available in English, Chinese, Japanese, and Vietnamese.&lt;/p&gt; &#xA;&lt;h3&gt;Build Your Own Chisel Projects&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/SETUP.md&#34;&gt;the setup instructions&lt;/a&gt; for how to set up your environment to build Chisel locally.&lt;/p&gt; &#xA;&lt;p&gt;When you&#39;re ready to build your own circuits in Chisel, &lt;strong&gt;we recommend starting from the &lt;a href=&#34;https://github.com/freechipsproject/chisel-template&#34;&gt;Chisel Template&lt;/a&gt; repository&lt;/strong&gt;, which provides a pre-configured project, example design, and testbench. Follow the &lt;a href=&#34;https://github.com/freechipsproject/chisel-template&#34;&gt;chisel-template README&lt;/a&gt; to get started.&lt;/p&gt; &#xA;&lt;p&gt;If you insist on setting up your own project from scratch, your project needs to depend on both the chisel3-plugin (Scalac plugin) and the chisel3 library. For example, in SBT this could be expressed as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// build.sbt&#xA;scalaVersion := &#34;2.13.7&#34;&#xA;addCompilerPlugin(&#34;edu.berkeley.cs&#34; % &#34;chisel3-plugin&#34; % &#34;3.5.0&#34; cross CrossVersion.full)&#xA;libraryDependencies += &#34;edu.berkeley.cs&#34; %% &#34;chisel3&#34; % &#34;3.5.0&#34;&#xA;// We also recommend using chiseltest for writing unit tests &#xA;libraryDependencies += &#34;edu.berkeley.cs&#34; %% &#34;chiseltest&#34; % &#34;0.5.0&#34; % &#34;test&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Guide For New Contributors&lt;/h3&gt; &#xA;&lt;p&gt;If you are trying to make a contribution to this project, please read &lt;a href=&#34;https://github.com/Burnleydev1/chisel3/raw/recent_PR/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Design Verification&lt;/h3&gt; &#xA;&lt;p&gt;These simulation-based verification tools are available for Chisel:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/freechipsproject/chisel-testers&#34;&gt;&lt;strong&gt;iotesters&lt;/strong&gt;&lt;/a&gt;, specifically &lt;a href=&#34;https://github.com/freechipsproject/chisel-testers/wiki/Using%20the%20PeekPokeTester&#34;&gt;PeekPokeTester&lt;/a&gt;, provides constructs (&lt;code&gt;peek&lt;/code&gt;, &lt;code&gt;poke&lt;/code&gt;, &lt;code&gt;expect&lt;/code&gt;) similar to a non-synthesizable Verilog testbench.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ucb-bar/chisel-testers2&#34;&gt;&lt;strong&gt;testers2&lt;/strong&gt;&lt;/a&gt; is an in-development replacement for PeekPokeTester, providing the same base constructs but with a streamlined interface and concurrency support with &lt;code&gt;fork&lt;/code&gt; and &lt;code&gt;join&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;h3&gt;Useful Resources&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/freechipsproject/chisel-cheatsheet/releases/latest/download/chisel_cheatsheet.pdf&#34;&gt;&lt;strong&gt;Cheat Sheet&lt;/strong&gt;&lt;/a&gt;, a 2-page reference of the base Chisel syntax and libraries&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.chisel-lang.org/api/latest/chisel3/index.html&#34;&gt;&lt;strong&gt;ScalaDoc&lt;/strong&gt;&lt;/a&gt;, a listing, description, and examples of the functionality exposed by Chisel&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gitter.im/freechipsproject/chisel3&#34;&gt;&lt;strong&gt;Gitter&lt;/strong&gt;&lt;/a&gt;, where you can ask questions or discuss anything Chisel&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.chisel-lang.org&#34;&gt;&lt;strong&gt;Website&lt;/strong&gt;&lt;/a&gt; (&lt;a href=&#34;https://github.com/freechipsproject/www.chisel-lang.org/&#34;&gt;source&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scastie.scala-lang.org/9ga9i2DvQymKlA5JjS1ieA&#34;&gt;&lt;strong&gt;Scastie (3.5.0)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.asic-world.com/verilog/veritut.html&#34;&gt;&lt;strong&gt;asic-world&lt;/strong&gt;&lt;/a&gt; If you aren&#39;t familiar with verilog, this is a good tutorial.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you are migrating from Chisel2, see &lt;a href=&#34;https://www.chisel-lang.org/chisel3/chisel3-vs-chisel2.html&#34;&gt;the migration guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Data Types Overview&lt;/h3&gt; &#xA;&lt;p&gt;These are the base data types for defining circuit components:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/docs/src/images/type_hierarchy.svg?sanitize=true&#34; alt=&#34;Image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributor Documentation&lt;/h2&gt; &#xA;&lt;p&gt;This section describes how to get started contributing to Chisel itself, including how to test your version locally against other projects that pull in Chisel using &lt;a href=&#34;https://www.scala-sbt.org/1.x/docs/Library-Dependencies.html&#34;&gt;sbt&#39;s managed dependencies&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Useful Resources for Contributors&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/#useful-resources&#34;&gt;Useful Resources&lt;/a&gt; for users are also helpful for contributors.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/114YihixFBPCfUnv1inqAL8UjsiWfcNWdPHX7SeqlRQc&#34;&gt;&lt;strong&gt;Chisel Breakdown Slides&lt;/strong&gt;&lt;/a&gt;, an introductory talk about Chisel&#39;s internals&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Compiling and Testing Chisel&lt;/h3&gt; &#xA;&lt;p&gt;You must first install required dependencies to build Chisel locally, please see &lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/SETUP.md&#34;&gt;the setup instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Clone and build the Chisel library:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/chipsalliance/chisel3.git&#xA;cd chisel3&#xA;sbt compile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In order to run the following unit tests, you will need several tools on your &lt;code&gt;PATH&lt;/code&gt;, namely &lt;a href=&#34;https://www.veripool.org/verilator/&#34;&gt;verilator&lt;/a&gt;, &lt;a href=&#34;http://www.clifford.at/yosys/&#34;&gt;yosys&lt;/a&gt;, &lt;a href=&#34;https://github.com/chipsalliance/espresso&#34;&gt;espresso&lt;/a&gt;, and &lt;a href=&#34;https://github.com/Z3Prover/z3&#34;&gt;z3&lt;/a&gt;. Check that each is installed on your &lt;code&gt;PATH&lt;/code&gt; by running &lt;code&gt;which verilator&lt;/code&gt; and so on.&lt;/p&gt; &#xA;&lt;p&gt;If the compilation succeeded and the dependencies noted above are installed, you can then run the included unit tests by invoking:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sbt test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running Projects Against Local Chisel&lt;/h3&gt; &#xA;&lt;p&gt;To use the development version of Chisel (&lt;code&gt;master&lt;/code&gt; branch), you will need to build from source and &lt;code&gt;publishLocal&lt;/code&gt;. The repository version can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/build.sbt&#34;&gt;build.sbt&lt;/a&gt; file. As of the time of writing it was:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;version := &#34;3.6-SNAPSHOT&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To publish your version of Chisel to the local Ivy (sbt&#39;s dependency manager) repository, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sbt publishLocal&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The compiled version gets placed in &lt;code&gt;~/.ivy2/local/edu.berkeley.cs/&lt;/code&gt;. If you need to un-publish your local copy of Chisel, remove the directory generated in &lt;code&gt;~/.ivy2/local/edu.berkeley.cs/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In order to have your projects use this version of Chisel, you should update the &lt;code&gt;libraryDependencies&lt;/code&gt; setting in your project&#39;s build.sbt file to:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies += &#34;edu.berkeley.cs&#34; %% &#34;chisel3&#34; % &#34;3.6-SNAPSHOT&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Building Chisel with FIRRTL in the same SBT Project&lt;/h3&gt; &#xA;&lt;p&gt;While we recommend using the library dependency approach as described above, it is possible to build Chisel and FIRRTL in a single SBT project.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Caveats&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This only works for the &#34;main&#34; configuration; you cannot build the Chisel tests this way because &lt;code&gt;treadle&lt;/code&gt; is only supported as a library dependency.&lt;/li&gt; &#xA; &lt;li&gt;Do not &lt;code&gt;publishLocal&lt;/code&gt; when building this way. The published artifact will be missing the FIRRTL dependency.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This works by using &lt;a href=&#34;http://eed3si9n.com/hot-source-dependencies-using-sbt-sriracha&#34;&gt;sbt-sriracha&lt;/a&gt;, an SBT plugin for toggling between source and library dependencies. It provides two JVM system properties that, when set, will tell SBT to include FIRRTL as a source project:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;sbt.sourcemode&lt;/code&gt; - when set to true, SBT will look for FIRRTL in the workspace&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sbt.workspace&lt;/code&gt; - sets the root directory of the workspace&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# From root of this repo&#xA;git clone git@github.com:chipsalliance/firrtl.git&#xA;sbt -Dsbt.sourcemode=true -Dsbt.workspace=$PWD&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is primarily useful for building projects that themselves want to include Chisel as a source dependency. As an example, see &lt;a href=&#34;https://github.com/chipsalliance/rocket-chip&#34;&gt;Rocket Chip&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Chisel3 Architecture Overview&lt;/h3&gt; &#xA;&lt;p&gt;The Chisel3 compiler consists of these main parts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;The frontend&lt;/strong&gt;, &lt;code&gt;chisel3.*&lt;/code&gt;, which is the publicly visible &#34;API&#34; of Chisel and what is used in Chisel RTL. These just add data to the...&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;The Builder&lt;/strong&gt;, &lt;code&gt;chisel3.internal.Builder&lt;/code&gt;, which maintains global state (like the currently open Module) and contains commands, generating...&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;The intermediate data structures&lt;/strong&gt;, &lt;code&gt;chisel3.firrtl.*&lt;/code&gt;, which are syntactically very similar to Firrtl. Once the entire circuit has been elaborated, the top-level object (a &lt;code&gt;Circuit&lt;/code&gt;) is then passed to...&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;The Firrtl emitter&lt;/strong&gt;, &lt;code&gt;chisel3.firrtl.Emitter&lt;/code&gt;, which turns the intermediate data structures into a string that can be written out into a Firrtl file for further processing.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Also included is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;The standard library&lt;/strong&gt; of circuit generators, &lt;code&gt;chisel3.util.*&lt;/code&gt;. These contain commonly used interfaces and constructors (like &lt;code&gt;Decoupled&lt;/code&gt;, which wraps a signal with a ready-valid pair) as well as fully parameterizable circuit generators (like arbiters and multiplexors).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chisel Stage&lt;/strong&gt;, &lt;code&gt;chisel3.stage.*&lt;/code&gt;, which contains compilation and test functions that are invoked in the standard Verilog generation and simulation testing infrastructure. These can also be used as part of custom flows.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Chisel Sub-Projects&lt;/h3&gt; &#xA;&lt;p&gt;Chisel consists of 4 Scala projects; each is its own separate compilation unit:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/core&#34;&gt;&lt;code&gt;core&lt;/code&gt;&lt;/a&gt; is the bulk of the source code of Chisel, depends on &lt;code&gt;macros&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/src/main&#34;&gt;&lt;code&gt;src/main&lt;/code&gt;&lt;/a&gt; is the &#34;main&#34; that brings it all together and includes a &lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/src/main/scala/chisel3/util&#34;&gt;&lt;code&gt;util&lt;/code&gt;&lt;/a&gt; library, which depends on &lt;code&gt;core&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/plugin&#34;&gt;&lt;code&gt;plugin&lt;/code&gt;&lt;/a&gt; is the compiler plugin, no internal dependencies&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/chisel3/master/macros&#34;&gt;&lt;code&gt;macros&lt;/code&gt;&lt;/a&gt; is most of the macros used in Chisel, no internal dependencies&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Code that touches lots of APIs that are private to the &lt;code&gt;chisel3&lt;/code&gt; package should belong in &lt;code&gt;core&lt;/code&gt;, while code that is pure Chisel should belong in &lt;code&gt;src/main&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Which version should I use?&lt;/h3&gt; &#xA;&lt;p&gt;We encourage Chisel users (as opposed to Chisel developers), to use the latest release version of Chisel. This &lt;a href=&#34;https://github.com/freechipsproject/chisel-template&#34;&gt;chisel-template&lt;/a&gt; repository is kept up-to-date, depending on the most recent version of Chisel. The recommended version is also captured near the top of this README, and in the &lt;a href=&#34;https://github.com/chipsalliance/chisel3/releases&#34;&gt;Github releases&lt;/a&gt; section of this repo. If you encounter an issue with a released version of Chisel, please file an issue on GitHub mentioning the Chisel version and provide a simple test case (if possible). Try to reproduce the issue with the associated latest minor release (to verify that the issue hasn&#39;t been addressed).&lt;/p&gt; &#xA;&lt;p&gt;For more information on our versioning policy and what versions of the various Chisel ecosystem projects work together, see &lt;a href=&#34;https://www.chisel-lang.org/chisel3/docs/appendix/versioning.html&#34;&gt;Chisel Project Versioning&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re developing a Chisel library (or &lt;code&gt;chisel3&lt;/code&gt; itself), you&#39;ll probably want to work closer to the tip of the development trunk. By default, the master branches of the chisel repositories are configured to build and publish their version of the code as &lt;code&gt;Z.Y-SNAPSHOT&lt;/code&gt;. Updated SNAPSHOTs are publised on every push to master. You are encouraged to do your development against the latest SNAPSHOT, but note that neither API nor ABI compatibility is guaranteed so your code may break at any time.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>snowplow/snowplow</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/snowplow/snowplow</id>
    <link href="https://github.com/snowplow/snowplow" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The enterprise-grade behavioral data engine (web, mobile, server-side, webhooks), running cloud-natively on AWS and GCP&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Snowplow&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/releases/tag/22.01&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Snowplow-22.01%20Western%20Ghats-6638b8&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache--2-blue.svg?style=flat&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://discourse.snowplowanalytics.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/discourse/posts?server=https%3A%2F%2Fdiscourse.snowplowanalytics.com%2F&#34; alt=&#34;Discourse posts&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://snowplowanalytics.com&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/snowplow/snowplow/master/media/snowplow_logo.png&#34; alt=&#34;Snowplow logo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Snowplow is an enterprise-strength marketing and product analytics platform. It does three things:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Identifies your users, and tracks the way they engage with your website or application&lt;/li&gt; &#xA; &lt;li&gt;Stores your users&#39; behavioral data in a scalable &#34;event data warehouse&#34; you control: Amazon Redshift, Google BigQuery, Snowflake or Elasticsearch&lt;/li&gt; &#xA; &lt;li&gt;Lets you leverage the biggest range of tools to analyze that data, including big data tools (e.g. Spark) via EMR or more traditional tools e.g. Looker, Mode, Superset, Re:dash to analyze that behavioral data&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;To find out more, please check out the &lt;a href=&#34;https://snowplowanalytics.com&#34;&gt;Snowplow website&lt;/a&gt; and the &lt;a href=&#34;https://docs.snowplowanalytics.com/open-source-docs/&#34;&gt;docs website&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Version Compatibility Matrix&lt;/h3&gt; &#xA;&lt;p&gt;For compatibility assurance, the version compatibility matrix offers clarity on our recommended stack. It is strongly recommended when setting up a Snowplow pipeline to use the versions listed in the version compatibility matrix which can be found &lt;a href=&#34;https://docs.snowplowanalytics.com/docs/pipeline-components-and-applications/version-compatibility-matrix/&#34;&gt;within our docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Public Roadmap&lt;/h3&gt; &#xA;&lt;p&gt;This repository also contains the &lt;a href=&#34;https://github.com/snowplow/snowplow/projects&#34;&gt;Snowplow Public Roadmap&lt;/a&gt;. The Public Roadmap lets you stay up to date and find out what&#39;s happening on the Snowplow Platform. Help us prioritize our cards: open the issue and leave a ðŸ‘ to vote for your favorites. Want us to build a feature or function? Tell us by heading to our &lt;a href=&#34;http://discourse.snowplowanalytics.com/&#34;&gt;Discourse forum&lt;/a&gt; ðŸ’¬.&lt;/p&gt; &#xA;&lt;h3&gt;Try Snowplow&lt;/h3&gt; &#xA;&lt;p&gt;Setting up a full open-source Snowplow pipeline requires a non-trivial amount of engineering expertise and time investment. You might be interested in finding out what Snowplow can do first, by setting up &lt;a href=&#34;https://try.snowplowanalytics.com/?utm_source=github&amp;amp;utm_medium=post&amp;amp;utm_campaign=try-snowplow&#34;&gt;Try Snowplow&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Open Source Quick Start&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://docs.snowplowanalytics.com/docs/open-source-quick-start/&#34;&gt;Open Source Quick Start&lt;/a&gt; will help you get up and running with a Snowplow open source pipeline. Snowplow publishes a &lt;a href=&#34;https://registry.terraform.io/modules/snowplow-devops&#34;&gt;set of terraform modules&lt;/a&gt;, which automate the setting up &amp;amp; deployment of the required infrastructure &amp;amp; applications for an operational Snowplow open source pipeline, with just a handful of input variables required on your side.&lt;/p&gt; &#xA;&lt;h3&gt;Join the Snowplow Research Panel and help shape the future of open source&lt;/h3&gt; &#xA;&lt;p&gt;As part of our ongoing efforts to improve the Snowplow Open Source experience, we&#39;re looking for users of our open-source software and members of our community to take part in research studies. &lt;a href=&#34;https://forms.gle/pCtYx8naum7A8vvw5&#34;&gt;Join here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Our Commercial Offering&lt;/h3&gt; &#xA;&lt;p&gt;If you wish to get everything setup and managed for you, you can consider &lt;a href=&#34;https://snowplowanalytics.com/products/snowplow-bdp/&#34;&gt;Snowplow BDP&lt;/a&gt;. You can also &lt;a href=&#34;https://go.snowplowanalytics.com/l/571483/2021-05-04/3sv1pg8&#34;&gt;request a demo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Snowplow technology 101&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/snowplow/snowplow/master/ARCHITECTURE.md&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/snowplow/snowplow/master/media/snowplow_architecture.png&#34; alt=&#34;Snowplow architecture&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The repository structure follows the conceptual architecture of Snowplow, which consists of six loosely-coupled sub-systems connected by five standardized data protocols/formats.&lt;/p&gt; &#xA;&lt;p&gt;To briefly explain these six sub-systems:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/1-trackers&#34;&gt;Trackers&lt;/a&gt;&lt;/strong&gt; fire Snowplow events. Currently we have 15 trackers, covering web, mobile, desktop, server and IoT&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/2-collectors&#34;&gt;Collector&lt;/a&gt;&lt;/strong&gt; receives Snowplow events from trackers. Currently we have one official collector implementation with different sinks: Amazon Kinesis, Google PubSub, Amazon SQS, Apache Kafka and NSQ&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/3-enrich&#34;&gt;Enrich&lt;/a&gt;&lt;/strong&gt; cleans up the raw Snowplow events, enriches them and puts them into storage. Currently we have several implementations, built for different environments (GCP, AWS, Apache Kafka) and one core library&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/4-storage&#34;&gt;Storage&lt;/a&gt;&lt;/strong&gt; is where the Snowplow events live. Currently we store the Snowplow events in a flat file structure on S3, and in the Redshift, Postgres, Snowflake and BigQuery databases&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/5-data-modeling&#34;&gt;Data modeling&lt;/a&gt;&lt;/strong&gt; is where event-level data is joined with other data sets and aggregated into smaller data sets, and business logic is applied. This produces a clean set of tables which make it easier to perform analysis on the data. We officially support data models for Redshift, Snowflake and BigQuery.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.snowplowanalytics.com/docs/modeling-your-data/analytics-sdk/&#34;&gt;Analytics&lt;/a&gt;&lt;/strong&gt; are performed on the Snowplow events or on the aggregate tables.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;For more information on the current Snowplow architecture, please see the &lt;a href=&#34;https://raw.githubusercontent.com/snowplow/snowplow/master/ARCHITECTURE.md&#34;&gt;Technical architecture&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;About this repository&lt;/h2&gt; &#xA;&lt;p&gt;This repository is an umbrella repository for all loosely-coupled Snowplow components and is updated on each component release.&lt;/p&gt; &#xA;&lt;p&gt;Since June 2020, all components have been extracted into their dedicated repositories (more info &lt;a href=&#34;https://snowplowanalytics.com/blog/2020/07/16/changing-releasing/&#34;&gt;here&lt;/a&gt;) and this repository serves as an entry point for Snowplow users, the home of our public roadmap and as a historical artifact.&lt;/p&gt; &#xA;&lt;p&gt;Components that have been extracted to their own repository are still here as &lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Tools-Submodules&#34;&gt;git submodules&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Trackers&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Web&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Mobile&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Gaming&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;TV&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Desktop &amp;amp; Server&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-javascript-tracker&#34;&gt;JavaScript&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-android-tracker&#34;&gt;Android&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-unity-tracker&#34;&gt;Unity&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-roku-tracker&#34;&gt;Roku&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-tracking-cli&#34;&gt;Command line&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://docs.snowplowanalytics.com/docs/collecting-data/collecting-from-own-applications/google-amp-tracker/&#34;&gt;AMP&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-objc-tracker&#34;&gt;iOS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-dotnet-tracker&#34;&gt;.NET&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-react-native-tracker&#34;&gt;React Native&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-golang-tracker&#34;&gt;Go&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-flutter-tracker&#34;&gt;Flutter&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-java-tracker&#34;&gt;Java&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-javascript-tracker&#34;&gt;Node.js&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-php-tracker&#34;&gt;PHP&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-python-tracker&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-ruby-tracker&#34;&gt;Ruby&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-scala-tracker&#34;&gt;Scala&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/snowplow/stream-collector&#34;&gt;Collector&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/snowplow/enrich&#34;&gt;Enrich&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;Loaders&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-bigquery-loader&#34;&gt;BigQuery (streaming)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-rdb-loader&#34;&gt;Redshift (batch)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-snowflake-loader&#34;&gt;Snowflake (batch)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-google-cloud-storage-loader&#34;&gt;Google Cloud Storage (streaming)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-s3-loader&#34;&gt;Amazon S3 (streaming)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-postgres-loader&#34;&gt;Postgres (streaming)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-elasticsearch-loader&#34;&gt;Elasticsearch (streaming)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Iglu&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/iglu-server/&#34;&gt;Iglu Server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/igluctl/&#34;&gt;igluctl&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/iglu-central/&#34;&gt;Iglu Central&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Data modeling&lt;/h3&gt; &#xA;&lt;h4&gt;Web&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/data-models/tree/master/web/v1&#34;&gt;Web model: SQL-Runner version&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/dbt-snowplow-web&#34;&gt;Web model: dbt version&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Mobile&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/data-models/tree/master/mobile/v1&#34;&gt;Mobile model: SQL-Runner version&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Testing&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-mini&#34;&gt;Mini&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-micro&#34;&gt;Micro&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Parsing enriched event&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-scala-analytics-sdk&#34;&gt;Analytics SDK Scala&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-python-analytics-sdk&#34;&gt;Analytics SDK Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-dotnet-analytics-sdk&#34;&gt;Analytics SDK .NET&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-js-analytics-sdk/&#34;&gt;Analytics SDK Javascript&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-golang-analytics-sdk&#34;&gt;Analytics SDK Golang&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-badrows&#34;&gt;Bad rows&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://registry.terraform.io/modules/snowplow-devops&#34;&gt;Terraform Modules&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;Need help?&lt;/h2&gt; &#xA;&lt;p&gt;We want to make it super-easy for Snowplow users and contributors to talk to us and connect with each other, to share ideas, solve problems and help make Snowplow awesome. Here are the main channels we&#39;re running currently, we&#39;d love to hear from you on one of them:&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://discourse.snowplowanalytics.com/&#34;&gt;Discourse&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;This is for all Snowplow users: engineers setting up Snowplow, data modelers structuring the data and data consumers building insights. You can find guides, recipes, questions and answers from Snowplow users including the Snowplow team.&lt;/p&gt; &#xA;&lt;p&gt;We welcome all questions and contributions!&lt;/p&gt; &#xA;&lt;h3&gt;Twitter&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/SnowplowData&#34;&gt;@SnowplowData&lt;/a&gt; for official news or &lt;a href=&#34;https://twitter.com/SnowplowLabs&#34;&gt;@SnowplowLabs&lt;/a&gt; for engineering-heavy conversations and release updates.&lt;/p&gt; &#xA;&lt;h3&gt;GitHub&lt;/h3&gt; &#xA;&lt;p&gt;If you spot a bug, then please raise an issue in the GitHub repository of the component in question. Likewise if you have developed a cool new feature or an improvement, please open a pull request, we&#39;ll be glad to integrate it in the codebase!&lt;/p&gt; &#xA;&lt;p&gt;If you want to brainstorm a potential new feature, then &lt;a href=&#34;http://discourse.snowplowanalytics.com/&#34;&gt;Discourse&lt;/a&gt; is the best place to start.&lt;/p&gt; &#xA;&lt;h3&gt;Email&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;mailto:community@snowplowanalytics.com&#34;&gt;community@snowplowanalytics.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to talk directly to us (e.g. about a commercially sensitive issue), email is the easiest way.&lt;/p&gt; &#xA;&lt;h2&gt;Copyright and license&lt;/h2&gt; &#xA;&lt;p&gt;Snowplow is copyright 2012-2022 Snowplow Analytics Ltd.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the &lt;strong&gt;&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License, Version 2.0&lt;/a&gt;&lt;/strong&gt; (the &#34;License&#34;); you may not use this software except in compliance with the License.&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>awslabs/deequ</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/awslabs/deequ</id>
    <link href="https://github.com/awslabs/deequ" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Deequ is a library built on top of Apache Spark for defining &#34;unit tests for data&#34;, which measure data quality in large datasets.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deequ - Unit Tests for Data&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/deequ/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/awslabs/deequ.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/awslabs/deequ/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/awslabs/deequ.svg?sanitize=true&#34; alt=&#34;GitHub issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.com/awslabs/deequ&#34;&gt;&lt;img src=&#34;https://travis-ci.com/awslabs/deequ.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.amazon.deequ/deequ&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/com.amazon.deequ/deequ/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Deequ is a library built on top of Apache Spark for defining &#34;unit tests for data&#34;, which measure data quality in large datasets. We are happy to receive feedback and &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/deequ/master/CONTRIBUTING.md&#34;&gt;contributions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Python users may also be interested in PyDeequ, a Python interface for Deequ. You can find PyDeequ on &lt;a href=&#34;https://github.com/awslabs/python-deequ&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://pydeequ.readthedocs.io/en/latest/README.html&#34;&gt;readthedocs&lt;/a&gt;, and &lt;a href=&#34;https://pypi.org/project/pydeequ/&#34;&gt;PyPI&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements and Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deequ&lt;/strong&gt; depends on Java 8. Deequ version 2.x only runs with Spark 3.1, and vice versa. If you rely on a previous Spark version, please use a Deequ 1.x version (legacy version is maintained in legacy-spark-3.0 branch). We provide legacy releases compatible with Apache Spark versions 2.2.x to 3.0.x. The Spark 2.2.x and 2.3.x releases depend on Scala 2.11 and the Spark 2.4.x, 3.0.x, and 3.1.x releases depend on Scala 2.12.&lt;/p&gt; &#xA;&lt;p&gt;Available via &lt;a href=&#34;http://mvnrepository.com/artifact/com.amazon.deequ/deequ&#34;&gt;maven central&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Choose the latest release that matches your Spark version from the &lt;a href=&#34;https://repo1.maven.org/maven2/com/amazon/deequ/deequ/&#34;&gt;available versions&lt;/a&gt;. Add the release as a dependency to your project. For example, for Spark 3.1.x:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Maven&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;&#xA;  &amp;lt;groupId&amp;gt;com.amazon.deequ&amp;lt;/groupId&amp;gt;&#xA;  &amp;lt;artifactId&amp;gt;deequ&amp;lt;/artifactId&amp;gt;&#xA;  &amp;lt;version&amp;gt;2.0.0-spark-3.1&amp;lt;/version&amp;gt;&#xA;&amp;lt;/dependency&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;sbt&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies += &#34;com.amazon.deequ&#34; % &#34;deequ&#34; % &#34;2.0.0-spark-3.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deequ&lt;/strong&gt;&#39;s purpose is to &#34;unit-test&#34; data to find errors early, before the data gets fed to consuming systems or machine learning algorithms. In the following, we will walk you through a toy example to showcase the most basic usage of our library. An executable version of the example is available &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/deequ/master/src/main/scala/com/amazon/deequ/examples/BasicExample.scala&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deequ&lt;/strong&gt; works on tabular data, e.g., CSV files, database tables, logs, flattened json files, basically anything that you can fit into a Spark dataframe. For this example, we assume that we work on some kind of &lt;code&gt;Item&lt;/code&gt; data, where every item has an id, a productName, a description, a priority and a count of how often it has been viewed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;case class Item(&#xA;  id: Long,&#xA;  productName: String,&#xA;  description: String,&#xA;  priority: String,&#xA;  numViews: Long&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Our library is built on &lt;a href=&#34;https://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt; and is designed to work with very large datasets (think billions of rows) that typically live in a distributed filesystem or a data warehouse. For the sake of simplicity in this example, we just generate a few toy records though.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val rdd = spark.sparkContext.parallelize(Seq(&#xA;  Item(1, &#34;Thingy A&#34;, &#34;awesome thing.&#34;, &#34;high&#34;, 0),&#xA;  Item(2, &#34;Thingy B&#34;, &#34;available at http://thingb.com&#34;, null, 0),&#xA;  Item(3, null, null, &#34;low&#34;, 5),&#xA;  Item(4, &#34;Thingy D&#34;, &#34;checkout https://thingd.ca&#34;, &#34;low&#34;, 10),&#xA;  Item(5, &#34;Thingy E&#34;, null, &#34;high&#34;, 12)))&#xA;&#xA;val data = spark.createDataFrame(rdd)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Most applications that work with data have implicit assumptions about that data, e.g., that attributes have certain types, do not contain NULL values, and so on. If these assumptions are violated, your application might crash or produce wrong outputs. The idea behind &lt;strong&gt;deequ&lt;/strong&gt; is to explicitly state these assumptions in the form of a &#34;unit-test&#34; for data, which can be verified on a piece of data at hand. If the data has errors, we can &#34;quarantine&#34; and fix it, before we feed it to an application.&lt;/p&gt; &#xA;&lt;p&gt;The main entry point for defining how you expect your data to look is the &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/deequ/master/src/main/scala/com/amazon/deequ/VerificationSuite.scala&#34;&gt;VerificationSuite&lt;/a&gt; from which you can add &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/deequ/master/src/main/scala/com/amazon/deequ/checks/Check.scala&#34;&gt;Checks&lt;/a&gt; that define constraints on attributes of the data. In this example, we test for the following properties of our data:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;there are 5 rows in total&lt;/li&gt; &#xA; &lt;li&gt;values of the &lt;code&gt;id&lt;/code&gt; attribute are never NULL and unique&lt;/li&gt; &#xA; &lt;li&gt;values of the &lt;code&gt;productName&lt;/code&gt; attribute are never NULL&lt;/li&gt; &#xA; &lt;li&gt;the &lt;code&gt;priority&lt;/code&gt; attribute can only contain &#34;high&#34; or &#34;low&#34; as value&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;numViews&lt;/code&gt; should not contain negative values&lt;/li&gt; &#xA; &lt;li&gt;at least half of the values in &lt;code&gt;description&lt;/code&gt; should contain a url&lt;/li&gt; &#xA; &lt;li&gt;the median of &lt;code&gt;numViews&lt;/code&gt; should be less than or equal to 10&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In code this looks as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.amazon.deequ.VerificationSuite&#xA;import com.amazon.deequ.checks.{Check, CheckLevel, CheckStatus}&#xA;&#xA;&#xA;val verificationResult = VerificationSuite()&#xA;  .onData(data)&#xA;  .addCheck(&#xA;    Check(CheckLevel.Error, &#34;unit testing my data&#34;)&#xA;      .hasSize(_ == 5) // we expect 5 rows&#xA;      .isComplete(&#34;id&#34;) // should never be NULL&#xA;      .isUnique(&#34;id&#34;) // should not contain duplicates&#xA;      .isComplete(&#34;productName&#34;) // should never be NULL&#xA;      // should only contain the values &#34;high&#34; and &#34;low&#34;&#xA;      .isContainedIn(&#34;priority&#34;, Array(&#34;high&#34;, &#34;low&#34;))&#xA;      .isNonNegative(&#34;numViews&#34;) // should not contain negative values&#xA;      // at least half of the descriptions should contain a url&#xA;      .containsURL(&#34;description&#34;, _ &amp;gt;= 0.5)&#xA;      // half of the items should have less than 10 views&#xA;      .hasApproxQuantile(&#34;numViews&#34;, 0.5, _ &amp;lt;= 10))&#xA;    .run()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After calling &lt;code&gt;run&lt;/code&gt;, &lt;strong&gt;deequ&lt;/strong&gt; translates your test to a series of Spark jobs, which it executes to compute metrics on the data. Afterwards it invokes your assertion functions (e.g., &lt;code&gt;_ == 5&lt;/code&gt; for the size check) on these metrics to see if the constraints hold on the data. We can inspect the &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/deequ/master/src/main/scala/com/amazon/deequ/VerificationResult.scala&#34;&gt;VerificationResult&lt;/a&gt; to see if the test found errors:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.amazon.deequ.constraints.ConstraintStatus&#xA;&#xA;&#xA;if (verificationResult.status == CheckStatus.Success) {&#xA;  println(&#34;The data passed the test, everything is fine!&#34;)&#xA;} else {&#xA;  println(&#34;We found errors in the data:\n&#34;)&#xA;&#xA;  val resultsForAllConstraints = verificationResult.checkResults&#xA;    .flatMap { case (_, checkResult) =&amp;gt; checkResult.constraintResults }&#xA;&#xA;  resultsForAllConstraints&#xA;    .filter { _.status != ConstraintStatus.Success }&#xA;    .foreach { result =&amp;gt; println(s&#34;${result.constraint}: ${result.message.get}&#34;) }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If we run the example, we get the following output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;We found errors in the data:&#xA;&#xA;CompletenessConstraint(Completeness(productName)): Value: 0.8 does not meet the requirement!&#xA;PatternConstraint(containsURL(description)): Value: 0.4 does not meet the requirement!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The test found that our assumptions are violated! Only 4 out of 5 (80%) of the values of the &lt;code&gt;productName&lt;/code&gt; attribute are non-null and only 2 out of 5 (40%) values of the &lt;code&gt;description&lt;/code&gt; attribute did contain a url. Fortunately, we ran a test and found the errors, somebody should immediately fix the data :)&lt;/p&gt; &#xA;&lt;h2&gt;More examples&lt;/h2&gt; &#xA;&lt;p&gt;Our library contains much more functionality than what we showed in the basic example. We are in the process of adding &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/deequ/master/src/main/scala/com/amazon/deequ/examples/&#34;&gt;more examples&lt;/a&gt; for its advanced features. So far, we showcase the following functionality:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/deequ/raw/master/src/main/scala/com/amazon/deequ/examples/metrics_repository_example.md&#34;&gt;Persistence and querying of computed metrics of the data with a MetricsRepository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/deequ/raw/master/src/main/scala/com/amazon/deequ/examples/data_profiling_example.md&#34;&gt;Data profiling&lt;/a&gt; of large data sets&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/deequ/raw/master/src/main/scala/com/amazon/deequ/examples/anomaly_detection_example.md&#34;&gt;Anomaly detection&lt;/a&gt; on data quality metrics over time&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/deequ/raw/master/src/main/scala/com/amazon/deequ/examples/constraint_suggestion_example.md&#34;&gt;Automatic suggestion of constraints&lt;/a&gt; for large datasets&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/deequ/raw/master/src/main/scala/com/amazon/deequ/examples/algebraic_states_example.md&#34;&gt;Incremental metrics computation on growing data and metric updates on partitioned data&lt;/a&gt; (advanced)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you would like to reference this package in a research paper, please cite:&lt;/p&gt; &#xA;&lt;p&gt;Sebastian Schelter, Dustin Lange, Philipp Schmidt, Meltem Celikel, Felix Biessmann, and Andreas Grafberger. 2018. &lt;a href=&#34;http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf&#34;&gt;Automating large-scale data quality verification&lt;/a&gt;. Proc. VLDB Endow. 11, 12 (August 2018), 1781-1794.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This library is licensed under the Apache 2.0 License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apache/incubator-kyuubi</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/apache/incubator-kyuubi</id>
    <link href="https://github.com/apache/incubator-kyuubi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache Kyuubi is a distributed multi-tenant JDBC server for large-scale data processing and analytics, built on top of Apache Spark&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache Kyuubi (Incubating)&lt;/h1&gt; &#xA;&lt;img src=&#34;https://svn.apache.org/repos/asf/comdev/project-logos/originals/kyuubi-1.svg?sanitize=true&#34; alt=&#34;Kyuubi logo&#34; height=&#34;120px&#34; align=&#34;right&#34;&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/incubator-kyuubi/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/apache/incubator-kyuubi?label=release&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://tokei.rs/b1/github.com/apache/incubator-kyuubi&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/apache/incubator-kyuubi/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/workflow/status/apache/incubator-kyuubi/Kyuubi/master?style=plastic&#34; alt=&#34;GitHub Workflow Status&#34;&gt; &lt;a href=&#34;https://travis-ci.com/apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://api.travis-ci.com/apache/incubator-kyuubi.svg?branch=master&#34; alt=&#34;Travis&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://kyuubi.apache.org/docs/latest/&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/kyuubi/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/languages/top/apache/incubator-kyuubi&#34; alt=&#34;GitHub top language&#34;&gt; &lt;a href=&#34;https://github.com/apache/incubator-kyuubi/graphs/commit-activity&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/m/apache/incubator-kyuubi&#34; alt=&#34;Commit activity&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://isitmaintained.com/project/apache/incubator-kyuubi&#34; title=&#34;Average time to resolve an issue&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/resolution/apache/incubator-kyuubi.svg?sanitize=true&#34; alt=&#34;Average time to resolve an issue&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://isitmaintained.com/project/apache/incubator-kyuubi&#34; title=&#34;Percentage of issues still open&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/open/apache/incubator-kyuubi.svg?sanitize=true&#34; alt=&#34;Percentage of issues still open&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Kyuubi?&lt;/h2&gt; &#xA;&lt;p&gt;Kyuubi is a distributed multi-tenant Thrift JDBC/ODBC server for large-scale data management, processing, and analytics, built on top of Apache Spark and designed to support more engines (i.e., Flink). It has been open-sourced by NetEase since 2018. We are aiming to make Kyuubi an &#34;out-of-the-box&#34; tool for data warehouses and data lakes.&lt;/p&gt; &#xA;&lt;p&gt;Kyuubi provides a pure SQL gateway through Thrift JDBC/ODBC interface for end-users to manipulate large-scale data with pre-programmed and extensible Spark SQL engines. This &#34;out-of-the-box&#34; model minimizes the barriers and costs for end-users to use Spark at the client side. At the server-side, Kyuubi server and engines&#39; multi-tenant architecture provides the administrators a way to achieve computing resource isolation, data security, high availability, high client concurrency, etc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/docs/imgs/kyuubi_positioning.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; A HiveServer2-like API&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multi-tenant Spark Support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Running Spark in a serverless way&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Target Users&lt;/h3&gt; &#xA;&lt;p&gt;Kyuubi&#39;s goal is to make it easy and efficient for &lt;code&gt;anyone&lt;/code&gt; to use Spark(maybe other engines soon) and facilitate users to handle big data like ordinary data. Here, &lt;code&gt;anyone&lt;/code&gt; means that users do not need to have a Spark technical background but a human language, SQL only. Sometimes, SQL skills are unnecessary when integrating Kyuubi with Apache Superset, which supports rich visualizations and dashboards.&lt;/p&gt; &#xA;&lt;p&gt;In typical big data production environments with Kyuubi, there should be system administrators and end-users.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;System administrators: A small group consists of Spark experts responsible for Kyuubi deployment, configuration, and tuning.&lt;/li&gt; &#xA; &lt;li&gt;End-users: Focus on business data of their own, not where it stores, how it computes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Additionally, the Kyuubi community will continuously optimize the whole system with various features, such as History-Based Optimizer, Auto-tuning, Materialized View, SQL Dialects, Functions, e.t.c.&lt;/p&gt; &#xA;&lt;h3&gt;Usage scenarios&lt;/h3&gt; &#xA;&lt;h4&gt;Port workloads from HiveServer2 to Spark SQL&lt;/h4&gt; &#xA;&lt;p&gt;In typical big data production environments, especially secured ones, all bundled services manage access control lists to restricting access to authorized users. For example, Hadoop YARN divides compute resources into queues. With Queue ACLs, it can identify and control which users/groups can take actions on particular queues. Similarly, HDFS ACLs control access of HDFS files by providing a way to set different permissions for specific users/groups.&lt;/p&gt; &#xA;&lt;p&gt;Apache Spark is a unified analytics engine for large-scale data processing. It provides a Distributed SQL Engine, a.k.a, the Spark Thrift Server(STS), designed to be seamlessly compatible with HiveServer2 and get even better performance.&lt;/p&gt; &#xA;&lt;p&gt;HiveServer2 can identify and authenticate a caller, and then if the caller also has permissions for the YARN queue and HDFS files, it succeeds. Otherwise, it fails. However, on the one hand, STS is a single Spark application. The user and queue to which STS belongs are uniquely determined at startup. Consequently, STS cannot leverage cluster managers such as YARN and Kubernetes for resource isolation and sharing or control the access for callers by the single user inside the whole system. On the other hand, the Thrift Server is coupled in the Spark driver&#39;s JVM process. This coupled architect puts a high risk on server stability and makes it unable to handle high client concurrency or apply high availability such as load balancing as it is stateful.&lt;/p&gt; &#xA;&lt;p&gt;Kyuubi extends the use of STS in a multi-tenant model based on a unified interface and relies on the concept of multi-tenancy to interact with cluster managers to finally gain the ability of resources sharing/isolation and data security. The loosely coupled architecture of the Kyuubi server and engine dramatically improves the client concurrency and service stability of the service itself.&lt;/p&gt; &#xA;&lt;h4&gt;DataLake/LakeHouse Support&lt;/h4&gt; &#xA;&lt;p&gt;The vision of Kyuubi is to unify the portal and become an easy-to-use data lake management platform. Different kinds of workloads, such as ETL processing and BI analytics, can be supported by one platform, using one copy of data, with one SQL interface.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Logical View support via Kyuubi DataLake Metadata APIs&lt;/li&gt; &#xA; &lt;li&gt;Multiple Catalogs support&lt;/li&gt; &#xA; &lt;li&gt;SQL Standard Authorization support for DataLake(coming)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Cloud Native Support&lt;/h4&gt; &#xA;&lt;p&gt;Kyuubi can deploy its engines on different kinds of Cluster Managers, such as, Hadoop YARN, Kubernetes, etc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/docs/imgs/kyuubi_migrating_yarn_to_k8s.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;The Kyuubi Ecosystem(present and future)&lt;/h3&gt; &#xA;&lt;p&gt;The figure below shows our vision for the Kyuubi Ecosystem. Some of them have been realized, some in development, and others would not be possible without your help.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/docs/imgs/kyuubi_ecosystem.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Online Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Since Kyuubi 1.3.0-incubating, the Kyuubi online documentation is hosted by &lt;a href=&#34;https://kyuubi.apache.org/&#34;&gt;https://kyuubi.apache.org/&lt;/a&gt;. You can find the latest Kyuubi documentation on &lt;a href=&#34;https://kyuubi.apache.org/docs/latest/&#34;&gt;this web page&lt;/a&gt;. For 1.2 and earlier versions, please check the &lt;a href=&#34;https://kyuubi.readthedocs.io/en/v1.2.0/&#34;&gt;Readthedocs&lt;/a&gt; directly.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Ready? &lt;a href=&#34;https://kyuubi.apache.org/docs/latest/quick_start/quick_start.html&#34;&gt;Getting Started&lt;/a&gt; with Kyuubi.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;Contributor over time&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://api7.ai/contributor-graph?chart=contributorOverTime&amp;amp;repo=apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://contributor-graph-api.apiseven.com/contributors-svg?chart=contributorOverTime&amp;amp;repo=apache/incubator-kyuubi&#34; alt=&#34;Contributor over time&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Aside&lt;/h2&gt; &#xA;&lt;p&gt;The project took its name from a character of a popular Japanese manga - &lt;code&gt;Naruto&lt;/code&gt;. The character is named &lt;code&gt;Kyuubi Kitsune/Kurama&lt;/code&gt;, which is a nine-tailed fox in mythology. &lt;code&gt;Kyuubi&lt;/code&gt; spread the power and spirit of fire, which is used here to represent the powerful &lt;a href=&#34;http://spark.apache.org&#34;&gt;Apache Spark&lt;/a&gt;. Its nine tails stand for end-to-end multi-tenancy support of this project.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache 2.0 License. See the &lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>zio/zio-schema</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/zio/zio-schema</id>
    <link href="https://github.com/zio/zio-schema" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Compositional, type-safe schema definitions, which enable auto-derivation of codecs and migrations.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ZIO-SCHEMA&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Project Stage&lt;/th&gt; &#xA;   &lt;th&gt;CI&lt;/th&gt; &#xA;   &lt;th&gt;Release&lt;/th&gt; &#xA;   &lt;th&gt;Issues&lt;/th&gt; &#xA;   &lt;th&gt;Discord&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/zio/zio/wiki/Project-Stages&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project%20Stage-Development-yellowgreen.svg?sanitize=true&#34; alt=&#34;Project stage&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/zio/zio-schema/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://oss.sonatype.org/content/repositories/releases/dev/zio/zio-schema_2.12/&#34; title=&#34;Sonatype Releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/nexus/r/https/oss.sonatype.org/dev.zio/zio-schema_2.12.svg?sanitize=true&#34; alt=&#34;Release Artifacts&#34; title=&#34;Sonatype Releases&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://isitmaintained.com/project/zio/zio-schema&#34;&gt;&lt;img src=&#34;https://isitmaintained.com/badge/resolution/zio/zio-schema.svg?sanitize=true&#34; alt=&#34;Average time to resolve an issue&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://discord.gg/2ccFBr4&#34; title=&#34;Discord&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/629491597070827530?logo=discord&#34; alt=&#34;badge-discord&#34; title=&#34;chat on discord&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;em&gt;ZIO Schema&lt;/em&gt; is a &lt;a href=&#34;https://zio.dev&#34;&gt;ZIO&lt;/a&gt;-based library for modeling the schema of data structures as first-class values.&lt;/p&gt; &#xA;&lt;p&gt;With schema descriptions that can be automatically derived for case classes and sealed traits, &lt;em&gt;ZIO Schema&lt;/em&gt; provide powerful features for free:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Codecs for any supported protocol (JSON, protobuf, etc.), so data structures can be serialized and deserialized in a principled way&lt;/li&gt; &#xA; &lt;li&gt;Diffing, patching, merging, and other generic-data-based operations&lt;/li&gt; &#xA; &lt;li&gt;Migration of data structures from one schema to another compatible schema&lt;/li&gt; &#xA; &lt;li&gt;Derivation of arbitrary type classes (&lt;code&gt;Eq&lt;/code&gt;, &lt;code&gt;Show&lt;/code&gt;, &lt;code&gt;Ord&lt;/code&gt;, etc.) from the structure of the data&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When your data structures need to be serialized, deserialized, persisted, or transported across the wire, then &lt;em&gt;ZIO Schema&lt;/em&gt; lets you focus on data modeling and automatically tackle all the low-level, messy details for you.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;ZIO Schema&lt;/em&gt; is used by a growing number of ZIO libraries, including &lt;em&gt;ZIO Flow&lt;/em&gt;, &lt;em&gt;ZIO Redis&lt;/em&gt;, &lt;em&gt;ZIO Web&lt;/em&gt;, &lt;em&gt;ZIO SQL&lt;/em&gt; and &lt;em&gt;ZIO DynamoDB&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Add in your &lt;code&gt;build.sbt&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies ++= Seq(&#xA;  &#34;dev.zio&#34; %% &#34;zio-schema&#34; % &#34;&amp;lt;version&amp;gt;&#34;,&#xA;  // Required for automatic generic derivation of schemas&#xA;  &#34;dev.zio&#34; %% &#34;zio-schema-derivation&#34; % &#34;&amp;lt;version&amp;gt;&#34;,&#xA;  &#34;org.scala-lang&#34; % &#34;scala-reflect&#34;  % scalaVersion.value % &#34;provided&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;For the general guidelines, see ZIO &lt;a href=&#34;https://github.com/zio/zio/raw/master/docs/about/contributing.md&#34;&gt;contributor&#39;s guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;TL;DR&lt;/h4&gt; &#xA;&lt;p&gt;Before you submit a PR, make sure your tests are passing, and that the code is properly formatted&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sbt prepare&#xA;&#xA;sbt test&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>ucb-bar/plsi-mdf</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/ucb-bar/plsi-mdf</id>
    <link href="https://github.com/ucb-bar/plsi-mdf" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Macro description format&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MDF&lt;/h1&gt; &#xA;&lt;h2&gt;Scala library for the MDF format&lt;/h2&gt;</summary>
  </entry>
  <entry>
    <title>lhartikk/ArnoldC</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/lhartikk/ArnoldC</id>
    <link href="https://github.com/lhartikk/ArnoldC" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Arnold Schwarzenegger based programming language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ArnoldC&lt;/h1&gt; &#xA;&lt;p&gt;Programming language based on the one-liners of Arnold Schwarzenegger.&lt;/p&gt; &#xA;&lt;h2&gt;Motivation&lt;/h2&gt; &#xA;&lt;p&gt;Although the one-liners of Arnold Schwarzenegger are fairly well known the true semantics of the uttering is yet to be understood. This project tries to discover new meanings from the Arnold movies with the means of computer science.&lt;/p&gt; &#xA;&lt;h2&gt;HelloWorld.arnoldc&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;IT&#39;S SHOWTIME&#xA;TALK TO THE HAND &#34;hello world&#34;&#xA;YOU HAVE BEEN TERMINATED&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;wget http://lhartikk.github.io/ArnoldC.jar&#xA;echo -e &#34;IT&#39;S SHOWTIME\nTALK TO THE HAND \&#34;hello world\&#34;\nYOU HAVE BEEN TERMINATED&#34; &amp;gt; hello.arnoldc&#xA;java -jar ArnoldC.jar hello.arnoldc&#xA;java hello&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To create some &#34;audible&#34; output you can try the -declaim option:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;java -jar ArnoldC.jar -declaim hello.arnoldc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Brief overview of the keywords&lt;/h2&gt; &#xA;&lt;p&gt;Check the &lt;a href=&#34;http://github.com/lhartikk/ArnoldC/wiki/ArnoldC&#34;&gt;wiki&lt;/a&gt; for more details&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=_wk-jT9rn-8&#34;&gt;False&lt;/a&gt; &lt;code&gt;I LIED&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=CtNb1dnEaSQ&#34;&gt;True&lt;/a&gt; &lt;code&gt;NO PROBLEMO&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=MiB7GLyvvJQ&#34;&gt;If&lt;/a&gt; &lt;code&gt;BECAUSE I&#39;M GOING TO SAY PLEASE&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=c4psKYpfnYs&#34;&gt;Else&lt;/a&gt; &lt;code&gt;BULLSHIT&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://youtu.be/uGstM8QMCjQ?t=1m23s&#34;&gt;EndIf&lt;/a&gt; &lt;code&gt;YOU HAVE NO RESPECT FOR LOGIC&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=wDztrw_0N8M&#34;&gt;While&lt;/a&gt; &lt;code&gt;STICK AROUND&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=R39e30FL37U&#34;&gt;EndWhile&lt;/a&gt; &lt;code&gt;CHILL&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;PlusOperator &lt;code&gt;GET UP&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=7Ox0Ehq-FRQ&#34;&gt;MinusOperator&lt;/a&gt; &lt;code&gt;GET DOWN&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=lf3Kyv_iaNs&#34;&gt;MultiplicationOperator&lt;/a&gt; &lt;code&gt;YOU&#39;RE FIRED&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=9VHtuqXZQeo&#34;&gt;DivisionOperator&lt;/a&gt; &lt;code&gt;HE HAD TO SPLIT&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=ybJWKZB0Erk&amp;amp;feature=youtu.be&amp;amp;t=6m59s&#34;&gt;ModuloOperator&lt;/a&gt; &lt;code&gt;I LET HIM GO&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=A1-wUV0-_JY&#34;&gt;EqualTo&lt;/a&gt; &lt;code&gt;YOU ARE NOT YOU YOU ARE ME&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=19R2fDXCzcM&#34;&gt;GreaterThan&lt;/a&gt; &lt;code&gt;LET OFF SOME STEAM BENNET&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=RYtQMhnBtTw&#34;&gt;Or&lt;/a&gt; &lt;code&gt;CONSIDER THAT A DIVORCE&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=ZQ_Q2b_aXjk&#34;&gt;And&lt;/a&gt; &lt;code&gt;KNOCK KNOCK&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=uCwrOpnyXeo&#34;&gt;DeclareMethod&lt;/a&gt; &lt;code&gt;LISTEN TO ME VERY CAREFULLY&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=WANa9Oku-JM&#34;&gt;NonVoidMethod&lt;/a&gt; &lt;code&gt;GIVE THESE PEOPLE AIR&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=FWmH9ylqYYQ&#34;&gt;MethodArguments&lt;/a&gt; &lt;code&gt;I NEED YOUR CLOTHES YOUR BOOTS AND YOUR MOTORCYCLE&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=-YEG9DgRHhA&#34;&gt;Return&lt;/a&gt; &lt;code&gt;I&#39;LL BE BACK&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=Hhm7aWp8gvc&#34;&gt;EndMethodDeclaration&lt;/a&gt; &lt;code&gt;HASTA LA VISTA, BABY&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=HGhP3p6lI3U&#34;&gt;CallMethod&lt;/a&gt; &lt;code&gt;DO IT NOW&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=HkkibBYm2WI&#34;&gt;AssignVariableFromMethodCall&lt;/a&gt; &lt;code&gt;GET YOUR ASS TO MARS&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=PZwwqjcEDUQ&#34;&gt;DeclareInt&lt;/a&gt; &lt;code&gt;HEY CHRISTMAS TREE&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=lwqzA6F7nws&#34;&gt;SetInitialValue&lt;/a&gt; &lt;code&gt;YOU SET US UP&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=TKTL2EDTFSo&#34;&gt;BeginMain&lt;/a&gt; &lt;code&gt;IT&#39;S SHOWTIME&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=iy_BBBGBpqA&#34;&gt;EndMain&lt;/a&gt; &lt;code&gt;YOU HAVE BEEN TERMINATED&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=dQ6m8ztEzfA&#34;&gt;Print&lt;/a&gt; &lt;code&gt;TALK TO THE HAND&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=1mC9eOqsyTg&#34;&gt;ReadInteger&lt;/a&gt; &lt;code&gt;I WANT TO ASK YOU A BUNCH OF QUESTIONS AND I WANT TO HAVE THEM ANSWERED IMMEDIATELY&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=-9-Te-DPbSE&#34;&gt;AssignVariable&lt;/a&gt; &lt;code&gt;GET TO THE CHOPPER&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=RrPXRkJ_P90&#34;&gt;SetValue&lt;/a&gt; &lt;code&gt;HERE IS MY INVITATION&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=rk9WHasIZk0&#34;&gt;EndAssignVariable&lt;/a&gt; &lt;code&gt;ENOUGH TALK&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=oGcRTJK43OM&#34;&gt;ParseError&lt;/a&gt; &lt;code&gt;WHAT THE FUCK DID I DO WRONG&lt;/code&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>streamxhub/streamx</title>
    <updated>2022-05-29T01:53:43Z</updated>
    <id>tag:github.com,2022-05-29:/streamxhub/streamx</id>
    <link href="https://github.com/streamxhub/streamx" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Make stream processing easier! Flink &amp; Spark development scaffold, The original intention of StreamX is to make the development of Flink easier. StreamX focuses on the management of development phases and tasks. Our ultimate goal is to build a one-stop big data solution integrating stream processing, batch processing, data warehouse and data laker.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;h1&gt; &lt;a href=&#34;http://www.streamxhub.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img width=&#34;600&#34; src=&#34;https://user-images.githubusercontent.com/13284744/166133644-ed3cc4f5-aae5-45bc-bfbe-29c540612446.png&#34; alt=&#34;StreamX logo&#34;&gt; &lt;/a&gt; &lt;/h1&gt; &#xA; &lt;strong style=&#34;font-size: 1.5rem&#34;&gt;Make stream processing easier!!!&lt;/strong&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-4EB1BA.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://tokei.rs/b1/github/streamxhub/streamx&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/streamxhub/streamx.svg?sanitize=true&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/streamxhub/streamx&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/streamxhub/streamx&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/languages/count/streamxhub/streamx&#34;&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.streamxhub.com&#34;&gt;Official Website&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/streamxhub/streamx/dev/#&#34;&gt;Change Log&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://www.streamxhub.com/docs/intro&#34;&gt;Document&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h4&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/streamxhub/streamx/dev/README_CN.md&#34;&gt;ä¸­æ–‡&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;h1&gt;StreamX&lt;/h1&gt; &#xA;&lt;p&gt;Make stream processing easier&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;A magical framework that make stream processing easier!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;ðŸš€ Introduction&lt;/h2&gt; &#xA;&lt;p&gt;The original intention of &lt;code&gt;StreamX&lt;/code&gt; is to make stream processing easier. &lt;code&gt;StreamX&lt;/code&gt; focuses on the management of development phases and tasks. Our ultimate goal is to build a one-stop big data solution integrating stream processing, batch processing, data warehouse and data laker.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://assets.streamxhub.com/streamx-video.mp4&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/166101616-50a44d38-3ffb-4296-8a77-92f76a4c21b5.png&#34; alt=&#34;StreamX video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ðŸŽ‰ Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scaffolding&lt;/li&gt; &#xA; &lt;li&gt;Out-of-the-box connectors&lt;/li&gt; &#xA; &lt;li&gt;Support maven compilation&lt;/li&gt; &#xA; &lt;li&gt;Configuration&lt;/li&gt; &#xA; &lt;li&gt;Multi version flink support(1.12.x,1.13.x,1.14.x, 1.15.x)&lt;/li&gt; &#xA; &lt;li&gt;Scala 2.11 / 2.12 support&lt;/li&gt; &#xA; &lt;li&gt;restapi support.&lt;/li&gt; &#xA; &lt;li&gt;All Flink deployment mode support(&lt;code&gt;Remote&lt;/code&gt;/&lt;code&gt;K8s-Native-Application&lt;/code&gt;/&lt;code&gt;K8s-Native-Session&lt;/code&gt;/&lt;code&gt;YARN-Application&lt;/code&gt;/&lt;code&gt;YARN-Per-Job&lt;/code&gt;/&lt;code&gt;YARN-Session&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;start&lt;/code&gt;, &lt;code&gt;stop&lt;/code&gt;, &lt;code&gt;savepoint&lt;/code&gt;, resume from &lt;code&gt;savepoint&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Various companies and organizations use &lt;code&gt;StreamX&lt;/code&gt; for production and commercial products.&lt;/li&gt; &#xA; &lt;li&gt;Flame graph&lt;/li&gt; &#xA; &lt;li&gt;Notebook&lt;/li&gt; &#xA; &lt;li&gt;Project configuration and dependency version management&lt;/li&gt; &#xA; &lt;li&gt;Task backup and rollback&lt;/li&gt; &#xA; &lt;li&gt;Manage dependencies&lt;/li&gt; &#xA; &lt;li&gt;UDF&lt;/li&gt; &#xA; &lt;li&gt;Flink SQL Connector&lt;/li&gt; &#xA; &lt;li&gt;Flink SQL WebIDE&lt;/li&gt; &#xA; &lt;li&gt;Catalogã€Hive&lt;/li&gt; &#xA; &lt;li&gt;Full support from task &lt;code&gt;development&lt;/code&gt; to &lt;code&gt;deployment&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746863-856ef1cd-fa0e-4010-b359-c16ca2ad2fb7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746864-d807d728-423f-41c3-b90d-45ce2c21936b.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ðŸ³â€ðŸŒˆ Components&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;Streamx&lt;/code&gt; consists of three parts,&lt;code&gt;streamx-core&lt;/code&gt;,&lt;code&gt;streamx-pump&lt;/code&gt; and &lt;code&gt;streamx-console&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746859-f6a4dedc-ec42-4ed5-933b-c27d559b9988.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;1ï¸âƒ£ streamx-core&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;streamx-core&lt;/code&gt; is a framework that focuses on coding, standardizes configuration, and develops in a way that is better than configuration by convention. Also it provides a development-time &lt;code&gt;RunTime Content&lt;/code&gt; and a series of &lt;code&gt;Connector&lt;/code&gt; out of the box. At the same time, it extends &lt;code&gt;DataStream&lt;/code&gt; some methods, and integrates &lt;code&gt;DataStream&lt;/code&gt; and &lt;code&gt;Flink sql&lt;/code&gt; api to simplify tedious operations, focus on the business itself, and improve development efficiency and development experience.&lt;/p&gt; &#xA;&lt;h3&gt;2ï¸âƒ£ streamx-pump&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;streamx-pump&lt;/code&gt; is a planned data extraction component, similar to &lt;code&gt;flinkx&lt;/code&gt;. Based on the various &lt;code&gt;connector&lt;/code&gt; provided in &lt;code&gt;streamx-core&lt;/code&gt;, the purpose is to create a convenient, fast, out-of-the-box real-time data extraction and migration component for big data, and it will be integrated into the &lt;code&gt;streamx-console&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;3ï¸âƒ£ streamx-console&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;streamx-console&lt;/code&gt; is a stream processing and &lt;code&gt;Low Code&lt;/code&gt; platform, capable of managing &lt;code&gt;Flink&lt;/code&gt; tasks, integrating project compilation, deploy, configuration, startup, &lt;code&gt;savepoint&lt;/code&gt;, &lt;code&gt;flame graph&lt;/code&gt;, &lt;code&gt;Flink SQL&lt;/code&gt;, monitoring and many other features. Simplify the daily operation and maintenance of the &lt;code&gt;Flink&lt;/code&gt; task.&lt;/p&gt; &#xA;&lt;p&gt;Our ultimate goal is to build a one-stop big data solution integrating stream processing, batch processing, data warehouse and data laker.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://flink.apache.org&#34;&gt;Apache Flink&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://hadoop.apache.org&#34;&gt;Apache YARN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://spring.io/projects/spring-boot/&#34;&gt;Spring Boot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.mybatis.org&#34;&gt;Mybatis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://mp.baomidou.com&#34;&gt;Mybatis-Plus&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.brendangregg.com/FlameGraphs&#34;&gt;Flame Graph&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/uber-common/jvm-profiler&#34;&gt;JVM-Profiler&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cn.vuejs.org/&#34;&gt;Vue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vuepress.vuejs.org/&#34;&gt;VuePress&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://antdv.com/&#34;&gt;Ant Design of Vue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pro.antdv&#34;&gt;ANTD PRO VUE&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xtermjs.org/&#34;&gt;xterm.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoft.github.io/monaco-editor/&#34;&gt;Monaco Editor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Thanks to the above excellent open source projects and many outstanding open source projects that are not mentioned, for giving the greatest respect,Thanks to &lt;a href=&#34;http://flink.apache.org&#34;&gt;Apache Flink&lt;/a&gt; for creating a great project! Thanks to the &lt;a href=&#34;http://zeppelin.apache.org&#34;&gt;Apache Zeppelin&lt;/a&gt; project for the early inspiration.&lt;/p&gt; &#xA;&lt;h3&gt;ðŸš€ Quick Start&lt;/h3&gt; &#xA;&lt;p&gt;click &lt;a href=&#34;http://www.streamxhub.com/zh-CN/docs/intro/&#34;&gt;Document&lt;/a&gt; for more information&lt;/p&gt; &#xA;&lt;h2&gt;ðŸ’‹ our users&lt;/h2&gt; &#xA;&lt;p&gt;Various companies and organizations use StreamX for research, production and commercial products. Are you using this project ? &lt;a href=&#34;https://github.com/streamxhub/streamx/issues/163&#34;&gt;you can add your company&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/160220085-11f1e011-e7a0-421f-9294-c14213c0bc22.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ðŸ† Our honor&lt;/h2&gt; &#xA;&lt;p&gt;We have received some precious honors, which belong to everyone who contributes to StreamX, Thank you !&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746797-85ebf7b4-4105-4b5b-a023-0689c7fd1d2d.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/163530071-a5b6f334-9af5-439c-96c9-2bb9b4eec6a6.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ðŸ¤ Contribution&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/streamxhub/streamx/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can submit any ideas as &lt;a href=&#34;https://github.com/streamxhub/streamx/pulls&#34;&gt;pull requests&lt;/a&gt; or as &lt;a href=&#34;https://github.com/streamxhub/streamx/issues/new/choose&#34;&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;If you&#39;re new to posting issues, we ask that you read &lt;a href=&#34;http://www.catb.org/~esr/faqs/smart-questions.html&#34;&gt;&lt;em&gt;How To Ask Questions The Smart Way&lt;/em&gt;&lt;/a&gt; (&lt;strong&gt;This guide does not provide actual support services for this project!&lt;/strong&gt;), &lt;a href=&#34;http://www.chiark.greenend.org.uk/~sgtatham/bugs.html&#34;&gt;How to Report Bugs Effectively&lt;/a&gt; prior to posting. Well written bug reports help us help you!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Thank you to all the people who already contributed to StreamX!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/streamxhub/streamx/graphs/contributors&#34;&gt;&lt;img src=&#34;https://opencollective.com/streamx/contributors.svg?width=890&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;â° Contributor Over Time&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://git-contributor.com?chart=contributorOverTime&amp;amp;repo=streamxhub/streamx&#34;&gt;&lt;img src=&#34;https://contributor-overtime-api.git-contributor.com/contributors-svg?chart=contributorOverTime&amp;amp;repo=streamxhub/streamx&#34; alt=&#34;Contributor Over Time&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ðŸ’° Donation&lt;/h2&gt; &#xA;&lt;p&gt;Are you &lt;strong&gt;enjoying this project&lt;/strong&gt; ? ðŸ‘‹&lt;/p&gt; &#xA;&lt;p&gt;If you like this framework, and appreciate the work done for it to exist, you can still support the developers by donating â˜€ï¸ ðŸ‘Š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;WeChat Pay&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Alipay&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746857-35e7f823-7160-4505-be3f-e748a2d0a233.png&#34; alt=&#34;Buy Me A Coffee&#34; width=&#34;150&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746860-e14a8183-d973-44ca-83bf-e5f9d4da1510.png&#34; alt=&#34;Buy Me A Coffee&#34; width=&#34;150&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ðŸ† Our sponsors (Coffee Suppliers)&lt;/h2&gt; &#xA;&lt;h3&gt;ðŸ’œ Monthly Supplier&lt;/h3&gt; &#xA;&lt;p&gt;Welcome individuals and enterprises to sponsor, your support will help us better develop the project&lt;/p&gt; &#xA;&lt;h3&gt;ðŸ¥‡ Gold Supplier&lt;/h3&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://github.com/wolfboys&#34; alt=&#34;benjobs&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/13284744?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Kitming25&#34; alt=&#34;Kitming25&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/11773106?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Narcasserun&#34; alt=&#34;Narcasserun&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/39329477?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h3&gt;ðŸ¥ˆ Platinum Supplier&lt;/h3&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://github.com/lianxiaobao&#34; alt=&#34;lianxiaobao&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/36557317?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/su94998&#34; alt=&#34;su94998&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/33316193?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h3&gt;ðŸ¥ˆ Silver Supplier&lt;/h3&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://github.com/CrazyJugger&#34; alt=&#34;leohantaoluo&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/30514978?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/zhaizhirui&#34; alt=&#34;zhaizhirui&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/39609947?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://www.jetbrains.com/?from=streamx&#34;&gt;JetBrains&lt;/a&gt; for supporting us free open source licenses.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.jetbrains.com/?from=streamx&#34;&gt;&lt;img src=&#34;https://img.alicdn.com/tfs/TB1sSomo.z1gK0jSZLeXXb9kVXa-120-130.svg?sanitize=true&#34; alt=&#34;JetBrains&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;ðŸ… Backers&lt;/h3&gt; &#xA;&lt;p&gt;Thank you to all our backers!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ðŸ’¬ Join us&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/streamxhub/streamx/dev/(http://www.streamxhub.com/#/)&#34;&gt;StreamX&lt;/a&gt; enters the high-speed development stage, we need your contribution.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://starchart.cc/streamxhub/streamx.svg?sanitize=true&#34; alt=&#34;Stargazers over time&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/13284744/152627523-de455a4d-97c7-46cd-815f-3328a3fe3663.png&#34; alt=&#34;Join the Group&#34; height=&#34;300px&#34;&gt;&#xA; &lt;br&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
</feed>