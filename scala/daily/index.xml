<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-03T01:44:02Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>jrudolph/llama2.scala</title>
    <updated>2023-08-03T01:44:02Z</updated>
    <id>tag:github.com,2023-08-03:/jrudolph/llama2.scala</id>
    <link href="https://github.com/jrudolph/llama2.scala" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Inference Llama 2 in one file of hideous Scala (A port of llama2.c from Andrej Karpathy)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;A Scala 2 port of Andrej Karpathy&#39;s llama2.c&lt;/h1&gt; &#xA;&lt;p&gt;This is a Scala port of Andrej Karpathy&#39;s &lt;a href=&#34;https://github.com/karpathy/llama2.c&#34;&gt;llama2.c&lt;/a&gt;, a bare bones implementation to run inference of models with a &lt;a href=&#34;https://arxiv.org/pdf/2302.13971.pdf&#34;&gt;Llama&lt;/a&gt;-like transformer-based LLM architecture.&lt;/p&gt; &#xA;&lt;p&gt;The code expects &lt;a href=&#34;https://github.com/karpathy/llama2.c/raw/master/tokenizer.bin&#34;&gt;&lt;code&gt;tokenizer.bin&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin&#34;&gt;&lt;code&gt;stories15M.bin&lt;/code&gt;&lt;/a&gt; in the current directory.&lt;/p&gt; &#xA;&lt;p&gt;So far, there&#39;s nothing original to see here, just a port of the original code. I&#39;m planning to do some experiments, to raise the abstraction layer to a more reasonable level (e.g. remove all of the while-loops) but I wanted to start with an almost verbatim port to get some intial performance numbers to see if it even makes sense to continue on the JVM.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://asciinema.org/a/h7dJq7SOkmlCHmgI3DLRQBp58&#34;&gt;&lt;img src=&#34;https://asciinema.org/a/h7dJq7SOkmlCHmgI3DLRQBp58.svg?sanitize=true&#34; alt=&#34;asciicast&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Implementation details&lt;/h2&gt; &#xA;&lt;p&gt;There are currently two implementations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Llama2SimpleTransformer&lt;/code&gt; which is a direct port of the original C code&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Llama2TensorTransformer&lt;/code&gt; which uses a &lt;code&gt;Tensor&lt;/code&gt; abstraction to make the code more readable&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;Current numbers on my AMD Ryzen 7 4800H laptop:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Implementation&lt;/th&gt; &#xA;   &lt;th&gt;Tokens per second&lt;/th&gt; &#xA;   &lt;th&gt;Speedup&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama2.c single-thread&lt;/td&gt; &#xA;   &lt;td&gt;65&lt;/td&gt; &#xA;   &lt;td&gt;1.0x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama2.c multi-thread (OMP)&lt;/td&gt; &#xA;   &lt;td&gt;~350&lt;/td&gt; &#xA;   &lt;td&gt;5.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2SimpleTransformer on scala-native 0.4.14 vanilla&lt;/td&gt; &#xA;   &lt;td&gt;14&lt;/td&gt; &#xA;   &lt;td&gt;0.22x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2SimpleTransformer on scala-native 0.4.14 (native mmaps)&lt;/td&gt; &#xA;   &lt;td&gt;80&lt;/td&gt; &#xA;   &lt;td&gt;0.77x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2SimpleTransformer on OpenJDK 11 single-thread&lt;/td&gt; &#xA;   &lt;td&gt;50&lt;/td&gt; &#xA;   &lt;td&gt;0.77x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2SimpleTransformer on GraalVM JDK 17 single-thread&lt;/td&gt; &#xA;   &lt;td&gt;61&lt;/td&gt; &#xA;   &lt;td&gt;0.94x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;So, with a fast JVM, there&#39;s little slowdown compared to the original C code, even if the Scala code has not been optimized at all yet (aside from being written in a hardly bearable C-like fashion...).&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
</feed>