<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-22T01:32:38Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mspnp/spark-monitoring</title>
    <updated>2024-03-22T01:32:38Z</updated>
    <id>tag:github.com,2024-03-22:/mspnp/spark-monitoring</id>
    <link href="https://github.com/mspnp/spark-monitoring" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Monitoring Azure Databricks jobs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Monitoring Azure Databricks in an Azure Log Analytics Workspace&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;span&gt;❗&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;This branch of the library supports Azure Databricks Runtimes 10.x (Spark 3.2.x) and earlier (see &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/#supported-configurations&#34;&gt;Supported configurations&lt;/a&gt;).&lt;br&gt;Databricks has contributed an updated version to support Azure Databricks Runtimes 11.0 (Spark 3.3.x) and above on the &lt;code&gt;l4jv2&lt;/code&gt; branch at: &lt;a href=&#34;https://github.com/mspnp/spark-monitoring/tree/l4jv2&#34;&gt;https://github.com/mspnp/spark-monitoring/tree/l4jv2&lt;/a&gt;.&lt;br&gt;Be sure to use the correct branch and version for your Databricks Runtime.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;span&gt;⚠&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;This library and GitHub repository are in &lt;em&gt;maintenance mode&lt;/em&gt;. There are no plans for further releases, and issue support will be best-effort only. For any additional questions regarding this library or the roadmap for monitoring and logging of your Azure Databricks environments, please contact &lt;a href=&#34;mailto:azure-spark-monitoring-help@databricks.com&#34;&gt;azure-spark-monitoring-help@databricks.com&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;This repository extends the core monitoring functionality of Azure Databricks to send streaming query event information to Azure Monitor. For more information about using this library to monitor Azure Databricks, see &lt;a href=&#34;https://learn.microsoft.com/azure/architecture/databricks-monitoring&#34;&gt;Monitoring Azure Databricks&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The project has the following directory structure:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/src&#xA;    /spark-listeners-loganalytics&#xA;    /spark-listeners&#xA;    /pom.xml&#xA;/sample&#xA;    /spark-sample-job&#xA;/perftools&#xA;     /spark-sample-job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;strong&gt;spark-listeners-loganalytics&lt;/strong&gt; and &lt;strong&gt;spark-listeners&lt;/strong&gt; directories contain the code for building the two JAR files that are deployed to the Databricks cluster. The &lt;strong&gt;spark-listeners&lt;/strong&gt; directory includes a &lt;strong&gt;scripts&lt;/strong&gt; directory that contains a cluster node initialization script to copy the JAR files from a staging directory in the Azure Databricks file system to execution nodes. The &lt;strong&gt;pom.xml&lt;/strong&gt; file is the main Maven project object model build file for the entire project.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;strong&gt;spark-sample-job&lt;/strong&gt; directory is a sample Spark application demonstrating how to implement a Spark application metric counter.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;strong&gt;perftools&lt;/strong&gt; directory contains details on how to use Azure Monitor with Grafana to monitor Spark performance.&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Before you begin, ensure you have the following prerequisites in place:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Clone or download this GitHub repository.&lt;/li&gt; &#xA; &lt;li&gt;An active Azure Databricks workspace. For instructions on how to deploy an Azure Databricks workspace, see &lt;a href=&#34;https://learn.microsoft.com/azure/databricks/getting-started/&#34;&gt;get started with Azure Databricks&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Install the &lt;a href=&#34;https://learn.microsoft.com/azure/databricks/dev-tools/cli/install&#34;&gt;Azure Databricks CLI&lt;/a&gt;. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An Azure Databricks personal access token or Microsoft Entra access token is required to use the CLI. For instructions, see &lt;a href=&#34;https://learn.microsoft.com/azure/databricks/dev-tools/cli/authentication&#34;&gt;Set up authentication&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;You can also use the Azure Databricks CLI from the Azure Cloud Shell.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;A Java IDE, with the following resources: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.oracle.com/technetwork/java/javase/downloads/index.html&#34;&gt;Java Development Kit (JDK) version 1.8&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.scala-lang.org/download/&#34;&gt;Scala language SDK 2.12&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://maven.apache.org/download.html&#34;&gt;Apache Maven 3.6.3&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Supported configurations&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Databricks Runtime(s)&lt;/th&gt; &#xA;   &lt;th&gt;Maven Profile&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;7.3 LTS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;scala-2.12_spark-3.0.1&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;9.1 LTS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;scala-2.12_spark-3.1.2&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;10.3&lt;/code&gt; - &lt;code&gt;10.5&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;scala-2.12_spark-3.2.1&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;11.0&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;See &lt;a href=&#34;https://github.com/mspnp/spark-monitoring/tree/l4jv2&#34;&gt;https://github.com/mspnp/spark-monitoring/tree/l4jv2&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Logging Event Size Limit&lt;/h2&gt; &#xA;&lt;p&gt;This library currently has a size limit per event of 25MB, based on the &lt;a href=&#34;https://learn.microsoft.com/rest/api/loganalytics/create-request#data-limits&#34;&gt;Log Analytics limit of 30MB per API Call&lt;/a&gt; with additional overhead for formatting. The default behavior when hitting this limit is to throw an exception. This can be changed by modifying the value of &lt;code&gt;EXCEPTION_ON_FAILED_SEND&lt;/code&gt; in &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/src/spark-listeners/src/main/java/com/microsoft/pnp/client/GenericSendBuffer.java&#34;&gt;GenericSendBuffer.java&lt;/a&gt; to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: You will see an error like: &lt;code&gt;java.lang.RuntimeException: Failed to schedule batch because first message size nnn exceeds batch size limit 26214400 (bytes).&lt;/code&gt; in the Spark logs if your workload is generating logging messages of greater than 25MB, and your workload may not proceed. You can query Log Analytics for this error condition with:&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-kusto&#34;&gt;SparkLoggingEvent_CL&#xA;| where TimeGenerated &amp;gt; ago(24h)&#xA;| where Message contains &#34;java.lang.RuntimeException: Failed to schedule batch because first message size&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Build the Azure Databricks monitoring library&lt;/h2&gt; &#xA;&lt;p&gt;You can build the library using either Docker or Maven. All commands are intended to be run from the base directory of the repository.&lt;/p&gt; &#xA;&lt;p&gt;The jar files that will be produced are:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;spark-listeners_&amp;lt;Spark Version&amp;gt;_&amp;lt;Scala Version&amp;gt;-&amp;lt;Version&amp;gt;.jar&lt;/code&gt;&lt;/strong&gt; - This is the generic implementation of the Spark Listener framework that provides capability for collecting data from the running cluster for forwarding to another logging system.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;spark-listeners-loganalytics_&amp;lt;Spark Version&amp;gt;_&amp;lt;Scala Version&amp;gt;-&amp;lt;Version&amp;gt;.jar&lt;/code&gt;&lt;/strong&gt; - This is the specific implementation that extends &lt;strong&gt;spark-listeners&lt;/strong&gt;. This project provides the implementation for connecting to Log Analytics and formatting and passing data via the Log Analytics API.&lt;/p&gt; &#xA;&lt;h3&gt;Option 1: Docker&lt;/h3&gt; &#xA;&lt;p&gt;Linux:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# To build all profiles:&#xA;docker run -it --rm -v `pwd`:/spark-monitoring -v &#34;$HOME/.m2&#34;:/root/.m2 mcr.microsoft.com/java/maven:8-zulu-debian10 /spark-monitoring/build.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# To build a single profile (example for latest long term support version 10.4 LTS):&#xA;docker run -it --rm -v `pwd`:/spark-monitoring -v &#34;$HOME/.m2&#34;:/root/.m2 -w /spark-monitoring/src mcr.microsoft.com/java/maven:8-zulu-debian10 mvn install -P &#34;scala-2.12_spark-3.2.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Windows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# To build all profiles:&#xA;docker run -it --rm -v %cd%:/spark-monitoring -v &#34;%USERPROFILE%/.m2&#34;:/root/.m2 mcr.microsoft.com/java/maven:8-zulu-debian10 /spark-monitoring/build.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# To build a single profile (example for latest long term support version 10.4 LTS):&#xA;docker run -it --rm -v %cd%:/spark-monitoring -v &#34;%USERPROFILE%/.m2&#34;:/root/.m2 -w /spark-monitoring/src mcr.microsoft.com/java/maven:8-zulu-debian10 mvn install -P &#34;scala-2.12_spark-3.2.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Option 2: Maven&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Import the Maven project project object model file, &lt;em&gt;pom.xml&lt;/em&gt;, located in the &lt;strong&gt;/src&lt;/strong&gt; folder into your project. This will import two projects:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;spark-listeners&lt;/li&gt; &#xA;   &lt;li&gt;spark-listeners-loganalytics&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Activate a &lt;strong&gt;single&lt;/strong&gt; Maven profile that corresponds to the versions of the Scala/Spark combination that is being used. By default, the Scala 2.12 and Spark 3.0.1 profile is active.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Execute the Maven &lt;strong&gt;package&lt;/strong&gt; phase in your Java IDE to build the JAR files for each of the these projects:&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th&gt;Project&lt;/th&gt; &#xA;     &lt;th&gt;JAR file&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;spark-listeners&lt;/td&gt; &#xA;     &lt;td&gt;&lt;code&gt;spark-listeners_&amp;lt;Spark Version&amp;gt;_&amp;lt;Scala Version&amp;gt;-&amp;lt;Version&amp;gt;.jar&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;spark-listeners-loganalytics&lt;/td&gt; &#xA;     &lt;td&gt;&lt;code&gt;spark-listeners-loganalytics_&amp;lt;Spark Version&amp;gt;_&amp;lt;Scala Version&amp;gt;-&amp;lt;Version&amp;gt;.jar&lt;/code&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Configure the Databricks workspace&lt;/h2&gt; &#xA;&lt;p&gt;Copy the JAR files and init scripts to Databricks.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Use the Azure Databricks CLI to create a directory named &lt;strong&gt;dbfs:/databricks/spark-monitoring&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dbfs mkdirs dbfs:/databricks/spark-monitoring&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open the &lt;strong&gt;/src/spark-listeners/scripts/spark-monitoring.sh&lt;/strong&gt; script file and add your &lt;a href=&#34;https://learn.microsoft.com/azure/azure-monitor/agents/agent-windows#workspace-id-and-key&#34;&gt;Log Analytics Workspace ID and Key&lt;/a&gt; to the lines below:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export LOG_ANALYTICS_WORKSPACE_ID=&#xA;export LOG_ANALYTICS_WORKSPACE_KEY=&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If you do not want to add your Log Analytics workspace id and key into the init script in plaintext, you can also &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/docs/keyvault-backed-secrets.md&#34;&gt;create an Azure Key Vault backed secret scope&lt;/a&gt; and reference those secrets through your cluster&#39;s environment variables.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;In order to add &lt;code&gt;x-ms-AzureResourceId&lt;/code&gt; &lt;a href=&#34;https://learn.microsoft.com/azure/azure-monitor/platform/data-collector-api#request-headers&#34;&gt;header&lt;/a&gt; as part of the http request, modify the following environment variables on &lt;strong&gt;/src/spark-listeners/scripts/spark-monitoring.sh&lt;/strong&gt;. For instance:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export AZ_SUBSCRIPTION_ID=11111111-5c17-4032-ae54-fc33d56047c2&#xA;export AZ_RSRC_GRP_NAME=myAzResourceGroup&#xA;export AZ_RSRC_PROV_NAMESPACE=Microsoft.Databricks&#xA;export AZ_RSRC_TYPE=workspaces&#xA;export AZ_RSRC_NAME=myDatabricks&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now the _ResourceId &lt;strong&gt;/subscriptions/11111111-5c17-4032-ae54-fc33d56047c2/resourceGroups/myAzResourceGroup/providers/Microsoft.Databricks/workspaces/myDatabricks&lt;/strong&gt; will be part of the header. (&lt;em&gt;Note: If at least one of them is not set the header won&#39;t be included.&lt;/em&gt;)&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Use the Azure Databricks CLI to copy &lt;strong&gt;src/spark-listeners/scripts/spark-monitoring.sh&lt;/strong&gt; to the directory created in step 3:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dbfs cp src/spark-listeners/scripts/spark-monitoring.sh dbfs:/databricks/spark-monitoring/spark-monitoring.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Use the Azure Databricks CLI to copy all of the jar files from the &lt;strong&gt;src/target&lt;/strong&gt; folder to the directory created in step 3:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dbfs cp --overwrite --recursive src/target/ dbfs:/databricks/spark-monitoring/&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Create and configure the Azure Databricks cluster&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Navigate to your Azure Databricks workspace in the Azure Portal.&lt;/li&gt; &#xA; &lt;li&gt;Under &#34;Compute&#34;, click &#34;Create Cluster&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Choose a name for your cluster and enter it in &#34;Cluster name&#34; text box.&lt;/li&gt; &#xA; &lt;li&gt;In the &#34;Databricks Runtime Version&#34; dropdown, select &lt;strong&gt;Runtime: 10.4 LTS (Scala 2.12, Spark 3.2.1)&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Under &#34;Advanced Options&#34;, click on the &#34;Init Scripts&#34; tab. Go to the last line under the &#34;Init Scripts section&#34; Under the &#34;destination&#34; dropdown, select &#34;DBFS&#34;. Enter &#34;dbfs:/databricks/spark-monitoring/spark-monitoring.sh&#34; in the text box. Click the &#34;add&#34; button.&lt;/li&gt; &#xA; &lt;li&gt;Click the &#34;Create Cluster&#34; button to create the cluster. Next, click on the &#34;start&#34; button to start the cluster.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Run the sample job (optional)&lt;/h2&gt; &#xA;&lt;p&gt;The repository includes a sample application that shows how to send application metrics and application logs to Azure Monitor.&lt;/p&gt; &#xA;&lt;p&gt;When building the sample job, specify a maven profile compatible with your databricks runtime from the &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/#supported-configurations&#34;&gt;supported configurations section&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Use Maven to build the POM located at &lt;code&gt;sample/spark-sample-job/pom.xml&lt;/code&gt; or run the following Docker command:&lt;/p&gt; &lt;p&gt;Linux:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -it --rm -v `pwd`/sample/spark-sample-job:/spark-sample-job -v &#34;$HOME/.m2&#34;:/root/.m2 -w /spark-sample-job mcr.microsoft.com/java/maven:8-zulu-debian10 mvn install -P &amp;lt;maven-profile&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Windows:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -it --rm -v %cd%/sample/spark-sample-job:/spark-sample-job -v &#34;%USERPROFILE%/.m2&#34;:/root/.m2 -w /spark-sample-job mcr.microsoft.com/java/maven:8-zulu-debian10 mvn install -P &amp;lt;maven-profile&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to your Databricks workspace and create a new job, as described &lt;a href=&#34;https://learn.microsoft.com/azure/databricks/workflows/jobs/jobs#--create-a-job&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In the job detail page, set &lt;strong&gt;Type&lt;/strong&gt; to &lt;code&gt;JAR&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For &lt;strong&gt;Main class&lt;/strong&gt;, enter &lt;code&gt;com.microsoft.pnp.samplejob.StreamingQueryListenerSampleJob&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Upload the JAR file from &lt;code&gt;/src/spark-jobs/target/spark-jobs-1.0-SNAPSHOT.jar&lt;/code&gt; in the &lt;strong&gt;Dependent Libraries&lt;/strong&gt; section.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Select the cluster you created previously in the &lt;strong&gt;Cluster&lt;/strong&gt; section.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Select &lt;strong&gt;Create&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Click the &lt;strong&gt;Run Now&lt;/strong&gt; button to launch the job.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;When the job runs, you can view the application logs and metrics in your Log Analytics workspace. After you verify the metrics appear, stop the sample application job.&lt;/p&gt; &#xA;&lt;h3&gt;Viewing the Sample Job&#39;s Logs in Log Analytics&lt;/h3&gt; &#xA;&lt;p&gt;After your sample job has run for a few minutes, you should be able to query for these event types in Log Analytics:&lt;/p&gt; &#xA;&lt;h4&gt;SparkListenerEvent_CL&lt;/h4&gt; &#xA;&lt;p&gt;This custom log will contain Spark events that are serialized to JSON. You can limit the volume of events in this log with &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/docs/filtering.md#limiting-events-in-sparklistenerevent_cl&#34;&gt;filtering&lt;/a&gt;. If filtering is not employed, this can be a large volume of data.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: There is a known issue when the Spark framework or workload generates events that have more than 500 fields, or where data for an individual field is larger than 32kb. Log Analytics will generate an error indicating that data has been dropped. This is an incompatibility between the data being generated by Spark, and the current limitations of the Log Analytics API.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Example for querying &lt;strong&gt;SparkListenerEvent_CL&lt;/strong&gt; for job throughput over the last 7 days:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-kusto&#34;&gt;let results=SparkListenerEvent_CL&#xA;| where TimeGenerated &amp;gt; ago(7d)&#xA;| where  Event_s == &#34;SparkListenerJobStart&#34;&#xA;| extend metricsns=column_ifexists(&#34;Properties_spark_metrics_namespace_s&#34;,Properties_spark_app_id_s)&#xA;| extend apptag=iif(isnotempty(metricsns),metricsns,Properties_spark_app_id_s)&#xA;| project Job_ID_d,apptag,Properties_spark_databricks_clusterUsageTags_clusterName_s,TimeGenerated&#xA;| order by TimeGenerated asc nulls last&#xA;| join kind= inner (&#xA;    SparkListenerEvent_CL&#xA;    | where Event_s == &#34;SparkListenerJobEnd&#34;&#xA;    | where Job_Result_Result_s == &#34;JobSucceeded&#34;&#xA;    | project Event_s,Job_ID_d,TimeGenerated&#xA;) on Job_ID_d;&#xA;results&#xA;| extend slice=strcat(&#34;#JobsCompleted &#34;,Properties_spark_databricks_clusterUsageTags_clusterName_s,&#34;-&#34;,apptag)&#xA;| summarize count() by bin(TimeGenerated, 1h),slice&#xA;| order by TimeGenerated asc nulls last&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;SparkLoggingEvent_CL&lt;/h4&gt; &#xA;&lt;p&gt;This custom log will contain data forwarded from Log4j (the standard logging system in Spark). The volume of logging can be controlled by &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/docs/filtering.md#limiting-logs-in-sparkloggingevent_cl-basic&#34;&gt;altering the level of logging&lt;/a&gt; to forward or with &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/docs/filtering.md#limiting-logs-in-sparkloggingevent_cl-advanced&#34;&gt;filtering&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Example for querying &lt;strong&gt;SparkLoggingEvent_CL&lt;/strong&gt; for logged errors over the last day:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-kusto&#34;&gt;SparkLoggingEvent_CL&#xA;| where TimeGenerated &amp;gt; ago(1d)&#xA;| where Level == &#34;ERROR&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;SparkMetric_CL&lt;/h4&gt; &#xA;&lt;p&gt;This custom log will contain metrics events as generated by the Spark framework or workload. You can adjust the time period or sources included by modifying &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/src/spark-listeners/scripts/spark-monitoring.sh#L63-L76&#34;&gt;the &lt;code&gt;METRICS_PROPERTIES&lt;/code&gt; section of the spark-monitoring.sh&lt;/a&gt; script or by &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/docs/filtering.md#limiting-metrics-in-sparkmetric_cl&#34;&gt;enabling filtering&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Example of querying &lt;strong&gt;SparkMetric_CL&lt;/strong&gt; for the number of active executors per application over the last 7 days summarized every 15 minutes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-kusto&#34;&gt;SparkMetric_CL&#xA;| where TimeGenerated &amp;gt; ago(7d)&#xA;| extend sname=split(name_s, &#34;.&#34;)&#xA;| where sname[2] == &#34;executor&#34;&#xA;| extend executor=strcat(sname[1]) &#xA;| extend app=strcat(sname[0])&#xA;| summarize NumExecutors=dcount(executor) by bin(TimeGenerated,  15m),app&#xA;| order by TimeGenerated asc nulls last&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: For more details on how to use the saved search queries in &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/perftools/deployment/loganalytics/logAnalyticsDeploy.json&#34;&gt;logAnalyticsDeploy.json&lt;/a&gt; to understand and troubleshoot performance, see &lt;a href=&#34;https://learn.microsoft.com/azure/architecture/databricks-monitoring/databricks-observability&#34;&gt;Observability patterns and metrics for performance tuning&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Filtering&lt;/h2&gt; &#xA;&lt;p&gt;The library is configurable to limit the volume of logs that are sent to each of the different Azure Monitor log types. See &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/docs/filtering.md&#34;&gt;filtering&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Debugging&lt;/h2&gt; &#xA;&lt;p&gt;If you encounter any issues with the init script, you can refer to the docs on &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/docs/debugging.md&#34;&gt;debugging&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;See: &lt;a href=&#34;https://raw.githubusercontent.com/mspnp/spark-monitoring/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>