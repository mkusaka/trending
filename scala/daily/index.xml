<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-07T01:37:29Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>metarank/metarank</title>
    <updated>2022-09-07T01:37:29Z</updated>
    <id>tag:github.com,2022-09-07:/metarank/metarank</id>
    <link href="https://github.com/metarank/metarank" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A low code Machine Learning service that personalizes articles, listings, search results, recommendations to boost user engagement. A friendly Learn-to-Rank engine&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;a style=&#34;text-decoration: none&#34; href=&#34;https://www.metarank.ai&#34;&gt; &lt;img width=&#34;120&#34; src=&#34;https://raw.githubusercontent.com/metarank/metarank/master/doc/img/logo.svg?sanitize=true&#34;&gt; &lt;p align=&#34;center&#34;&gt;Metarank: real time personalization as a service&lt;/p&gt; &lt;/a&gt; &lt;/h1&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt; &lt;a href=&#34;https://docs.metarank.ai&#34;&gt;Docs&lt;/a&gt; | &lt;a href=&#34;https://metarank.ai&#34;&gt;Website&lt;/a&gt; | &lt;a href=&#34;https://metarank.ai/slack&#34;&gt;Community Slack&lt;/a&gt; | &lt;a href=&#34;https://blog.metarank.ai&#34;&gt;Blog&lt;/a&gt; | &lt;a href=&#34;https://demo.metarank.ai&#34;&gt;Demo&lt;/a&gt; &lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/metarank/metarank/actions&#34;&gt;&lt;img src=&#34;https://github.com/metarank/metarank/workflows/Tests/badge.svg?sanitize=true&#34; alt=&#34;CI Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache2-green.svg?sanitize=true&#34; alt=&#34;License: Apache 2&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/last-commit/metarank/metarank&#34; alt=&#34;Last commit&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/release/metarank/metarank&#34; alt=&#34;Last release&#34;&gt; &lt;a href=&#34;https://metarank.ai/slack&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Slack-join%20the%20community-blue?logo=slack&amp;amp;style=social&#34; alt=&#34;Join our slack&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Metarank?&lt;/h2&gt; &#xA;&lt;p&gt;Metarank is a personalization service that can be easily integrated into existing systems and used to personalize different types of content.&lt;/p&gt; &#xA;&lt;p&gt;Like Instagram‚Äôs personalized feed that is based on the posts that you‚Äôve seen and liked, Facebook‚Äôs new friends recommendation widget or Amazon‚Äôs personalized results, you can add personalization to your application. You can combine different features, both user-based like location or gender and item-based like tags with different actions: clicks, likes, purchases to create a personalized experience for your users.&lt;/p&gt; &#xA;&lt;p&gt;Thanks to Metarank‚Äôs simple API and YAML configuration, you don‚Äôt need any prio machine learning experience to start improving your key metrics and run experiments.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/metarank/metarank/master/doc/img//demo.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Personalization is showing items that have unique order for each and every user. Personalization can be done based on user properties: location, gender, preferences and user actions: clicks, likes and other interactions. You can see personalized widgets everywhere: Facebook uses personalization to suggest you new friends and show posts that will most likely get your attention first; AirBnB uses personalization for their experiences offering, suggesting new experiences based on your location and previous actions.&lt;/p&gt; &#xA;&lt;p&gt;With Metarank you implement similar systems thanks to flexible configuration and keep control of your user data.&lt;/p&gt; &#xA;&lt;h2&gt;Metarank in One Minute&lt;/h2&gt; &#xA;&lt;p&gt;Let us show how you can start personalizing content in just under a minute (depends on your internet speed!).&lt;/p&gt; &#xA;&lt;h3&gt;Step 1: Prepare data&lt;/h3&gt; &#xA;&lt;p&gt;We will use the &lt;a href=&#34;https://github.com/metarank/ranklens&#34;&gt;ranklens dataset&lt;/a&gt;, which is used in our &lt;a href=&#34;https://demo.metarank.ai&#34;&gt;Demo&lt;/a&gt;, so just download the data file&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -O -L https://github.com/metarank/metarank/raw/master/src/test/resources/ranklens/events/events.jsonl.gz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 2: Prepare configuration file&lt;/h3&gt; &#xA;&lt;p&gt;We will again use the configuration file from our &lt;a href=&#34;https://demo.metarank.ai&#34;&gt;Demo&lt;/a&gt;. It utilizes in-memory store, so no other dependencies are needed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -O -L https://raw.githubusercontent.com/metarank/metarank/master/src/test/resources/ranklens/config.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 3: Start Metarank!&lt;/h3&gt; &#xA;&lt;p&gt;With the final step we will use Metarank‚Äôs &lt;code&gt;standalone&lt;/code&gt; mode that combines training and running the API into one command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -i -t -p 8080:8080 -v $(pwd):/opt/metarank metarank/metarank:latest standalone\&#xA;    --config /opt/metarank/config.yml\&#xA;    --data /opt/metarank/events.jsonl.gz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You will see some useful output while Metarank is starting and grinding through the data. Once this is done, you can send requests to &lt;code&gt;localhost:8080&lt;/code&gt; to get personalized results.&lt;/p&gt; &#xA;&lt;p&gt;Here we will interact with several movies by clicking on one of them and observing the results.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;First, let&#39;s see the initial output provided by Metarank without before we interact with it&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# get initial ranking for some items&#xA;curl http://localhost:8080/rank/xgboost \&#xA;    -d &#39;{&#xA;    &#34;event&#34;: &#34;ranking&#34;,&#xA;    &#34;id&#34;: &#34;id1&#34;,&#xA;    &#34;items&#34;: [&#xA;        {&#34;id&#34;:&#34;72998&#34;}, {&#34;id&#34;:&#34;67197&#34;}, {&#34;id&#34;:&#34;77561&#34;},&#xA;        {&#34;id&#34;:&#34;68358&#34;}, {&#34;id&#34;:&#34;79132&#34;}, {&#34;id&#34;:&#34;103228&#34;}, &#xA;        {&#34;id&#34;:&#34;72378&#34;}, {&#34;id&#34;:&#34;85131&#34;}, {&#34;id&#34;:&#34;94864&#34;}, &#xA;        {&#34;id&#34;:&#34;68791&#34;}, {&#34;id&#34;:&#34;93363&#34;}, {&#34;id&#34;:&#34;112623&#34;}&#xA;    ],&#xA;    &#34;user&#34;: &#34;alice&#34;,&#xA;    &#34;session&#34;: &#34;alice1&#34;,&#xA;    &#34;timestamp&#34;: 1661431886711&#xA;}&#39;&#xA;&#xA;# {&#34;item&#34;:&#34;72998&#34;,&#34;score&#34;:0.9602446652021992},{&#34;item&#34;:&#34;79132&#34;,&#34;score&#34;:0.7819134441404151},{&#34;item&#34;:&#34;68358&#34;,&#34;score&#34;:0.33377910321385645},{&#34;item&#34;:&#34;112623&#34;,&#34;score&#34;:0.32591281190727805},{&#34;item&#34;:&#34;103228&#34;,&#34;score&#34;:0.31640256043322723},{&#34;item&#34;:&#34;77561&#34;,&#34;score&#34;:0.3040782705414116},{&#34;item&#34;:&#34;94864&#34;,&#34;score&#34;:0.17659007036183608},{&#34;item&#34;:&#34;72378&#34;,&#34;score&#34;:0.06164568676567339},{&#34;item&#34;:&#34;93363&#34;,&#34;score&#34;:0.058120639770243385},{&#34;item&#34;:&#34;68791&#34;,&#34;score&#34;:0.026919880032451306},{&#34;item&#34;:&#34;85131&#34;,&#34;score&#34;:-0.35794106000271037},{&#34;item&#34;:&#34;67197&#34;,&#34;score&#34;:-0.48735167237049154}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# tell Metarank which items were presented to the user and in which order from the previous request&#xA;# optionally, we can include the score calculated by Metarank or your internal retrieval system&#xA;curl http://localhost:8080/feedback \&#xA; -d &#39;{&#xA;  &#34;event&#34;: &#34;ranking&#34;,&#xA;  &#34;fields&#34;: [],&#xA;  &#34;id&#34;: &#34;test-ranking&#34;,&#xA;  &#34;items&#34;: [&#xA;    {&#34;id&#34;:&#34;72998&#34;,&#34;score&#34;:0.9602446652021992},{&#34;id&#34;:&#34;79132&#34;,&#34;score&#34;:0.7819134441404151},{&#34;id&#34;:&#34;68358&#34;,&#34;score&#34;:0.33377910321385645},&#xA;    {&#34;id&#34;:&#34;112623&#34;,&#34;score&#34;:0.32591281190727805},{&#34;id&#34;:&#34;103228&#34;,&#34;score&#34;:0.31640256043322723},{&#34;id&#34;:&#34;77561&#34;,&#34;score&#34;:0.3040782705414116},&#xA;    {&#34;id&#34;:&#34;94864&#34;,&#34;score&#34;:0.17659007036183608},{&#34;id&#34;:&#34;72378&#34;,&#34;score&#34;:0.06164568676567339},{&#34;id&#34;:&#34;93363&#34;,&#34;score&#34;:0.058120639770243385},&#xA;    {&#34;id&#34;:&#34;68791&#34;,&#34;score&#34;:0.026919880032451306},{&#34;id&#34;:&#34;85131&#34;,&#34;score&#34;:-0.35794106000271037},{&#34;id&#34;:&#34;67197&#34;,&#34;score&#34;:-0.48735167237049154}&#xA;  ],&#xA;  &#34;user&#34;: &#34;test2&#34;,&#xA;  &#34;session&#34;: &#34;test2&#34;,&#xA;  &#34;timestamp&#34;: 1661431888711&#xA;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Now, let&#39;s intereact with the items &lt;code&gt;93363&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# click on the item with id 93363&#xA;curl http://localhost:8080/feedback \&#xA; -d &#39;{&#xA;  &#34;event&#34;: &#34;interaction&#34;,&#xA;  &#34;type&#34;: &#34;click&#34;,&#xA;  &#34;fields&#34;: [],&#xA;  &#34;id&#34;: &#34;test-interaction&#34;,&#xA;  &#34;ranking&#34;: &#34;test-ranking&#34;,&#xA;  &#34;item&#34;: &#34;93363&#34;,&#xA;  &#34;user&#34;: &#34;test&#34;,&#xA;  &#34;session&#34;: &#34;test&#34;,&#xA;  &#34;timestamp&#34;: 1661431890711&#xA;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Now, Metarank will personalize the items, the order of the items in the response will be different&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# personalize the same list of items&#xA;# they will be returned in a different order by Metarank&#xA;curl http://localhost:8080/rank/xgboost \&#xA; -d &#39;{&#xA;  &#34;event&#34;: &#34;ranking&#34;,&#xA;  &#34;fields&#34;: [],&#xA;  &#34;id&#34;: &#34;test-personalized&#34;,&#xA;  &#34;items&#34;: [&#xA;    {&#34;id&#34;:&#34;72998&#34;}, {&#34;id&#34;:&#34;67197&#34;}, {&#34;id&#34;:&#34;77561&#34;},&#xA;    {&#34;id&#34;:&#34;68358&#34;}, {&#34;id&#34;:&#34;79132&#34;}, {&#34;id&#34;:&#34;103228&#34;}, &#xA;    {&#34;id&#34;:&#34;72378&#34;}, {&#34;id&#34;:&#34;85131&#34;}, {&#34;id&#34;:&#34;94864&#34;}, &#xA;    {&#34;id&#34;:&#34;68791&#34;}, {&#34;id&#34;:&#34;93363&#34;}, {&#34;id&#34;:&#34;112623&#34;}&#xA;  ],&#xA;  &#34;user&#34;: &#34;test&#34;,&#xA;  &#34;session&#34;: &#34;test&#34;,&#xA;  &#34;timestamp&#34;: 1661431892711&#xA;}&#39;&#xA;&#xA;# {&#34;items&#34;:[{&#34;item&#34;:&#34;93363&#34;,&#34;score&#34;:2.2013986484185124},{&#34;item&#34;:&#34;72998&#34;,&#34;score&#34;:1.1542776301073876},{&#34;item&#34;:&#34;68358&#34;,&#34;score&#34;:0.9828904282341605},{&#34;item&#34;:&#34;112623&#34;,&#34;score&#34;:0.9521647429731446},{&#34;item&#34;:&#34;79132&#34;,&#34;score&#34;:0.9258841742518286},{&#34;item&#34;:&#34;77561&#34;,&#34;score&#34;:0.8990921381835769},{&#34;item&#34;:&#34;103228&#34;,&#34;score&#34;:0.8990921381835769},{&#34;item&#34;:&#34;94864&#34;,&#34;score&#34;:0.7131600718467729},{&#34;item&#34;:&#34;68791&#34;,&#34;score&#34;:0.624462038351694},{&#34;item&#34;:&#34;72378&#34;,&#34;score&#34;:0.5269765094008626},{&#34;item&#34;:&#34;85131&#34;,&#34;score&#34;:0.29198666089255343},{&#34;item&#34;:&#34;67197&#34;,&#34;score&#34;:0.16412780810560743}]}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Useful Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.metarank.ai&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/metarank/ranklens&#34;&gt;Ranklens Dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/metarank/metarank/master/CONTRIBUTING.md&#34;&gt;Contribution guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/metarank/metarank/master/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What&#39;s next?&lt;/h2&gt; &#xA;&lt;p&gt;Check out a more in-depth &lt;a href=&#34;https://raw.githubusercontent.com/metarank/metarank/master/doc/quickstart/quickstart.md&#34;&gt;Quickstart&lt;/a&gt; full &lt;a href=&#34;https://raw.githubusercontent.com/metarank/metarank/master/doc/installation.md&#34;&gt;Reference&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you have any questions, don&#39;t hesitate to join our &lt;a href=&#34;https://communityinviter.com/apps/metarank/metarank&#34;&gt;Slack&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;This project is released under the Apache 2.0 license, as specified in the &lt;a href=&#34;https://raw.githubusercontent.com/metarank/metarank/master/LICENSE&#34;&gt;License&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>knoldus/Studio-9</title>
    <updated>2022-09-07T01:37:29Z</updated>
    <id>tag:github.com,2022-09-07:/knoldus/Studio-9</id>
    <link href="https://github.com/knoldus/Studio-9" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Stars-5-blue&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/knoldus/Studio-9/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Contributors-6-yellow&#34; alt=&#34;GitHub contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/knoldus/Studio-9/raw/master/LICENSE.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/digitalocean/nginxconfig.io.svg?color=blue&#34; alt=&#34;MIT License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.linkpicture.com/q/banner_1.png&#34; alt=&#34;STUDIO-9&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;What is Studio-9?&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Studio9 is an open source platform for doing collaborative Data Management &amp;amp; AI/ML anywhere Whether your data is trapped in silos or you‚Äôre generating data at the edge, Studio9 gives you the flexibility to create AI and data engineering pipelines wherever your data is. And you can share your AI, Data, and Pipelines with anyone anywhere. With Studio9, you can achieve newfound agility to effortlessly move between compute environments, while all your data and your work replicates automatically to wherever you want.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Below are described the major components of Studio-9.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;1. *ORION* - A service further consisting of three components namely Job Dispatcher, Job Supervisor and Job Resource Cleaner. Job Dispatcher mainly forwards messages from RabbitMQ to the proper Job Supervisor, instantiating it for each new job request. Job Supervisor is responsible for instantiating job master for each new job which will have a new job supervisor setup. Job Resource Cleaner consumes messages from RabbitMQ and spins a new JobResourcesCleanerWorker for handling each message which then executes tasks for cleaning the resources. &#xA;&#xA;2. *ARIES* - A microservice that allows read/write access to ElasticSearch. It stores Job Metadata, Heartbeats and Job Results in ElasticSearch as documents. &#xA;&#xA;3. *TAURUS* - This service works as a message dispatcher using SQS/SNS.&#xA;&#xA;4. *BAILE* - It receives messages from the UI service called Salsa and then sends them to Cortex if its not Online Prediction. In case of Online Prediction, Salsa sends messages to Taurus which then sends them to Cortex.&#xA;&#xA;5. *ARGO* - A service designed to capture all configuration parameters for all job types or services. These parameters are saved by Argo in ElasticSearch. &#xA;&#xA;6. *PEGASUS* - A prediction storage service that receives messages from Taurus via Orion to upload data to RedShift. The messages contain metadata for online prediction job and CSV file with prediction results. &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;What are use cases?&lt;/h1&gt; &#xA;&lt;h2&gt;Computational Data Core that Automatically Scales and Adapts to You&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Imagine never having to worry about how to keep your data organized, keep track of how, when, and where it was manipulated, keep track of where it came from, or keep track of all its meta-data. Now imagine being able to effortlessly and securely share your data and its lineage with your colleagues. Finally, imagine being able to do any Analytics or Machine Learning right where your data is. The Studio9 Computational Data Core makes this all possible.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;The Data Science Replication Engine&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Every step you perform in the Analytics &amp;amp; AI Lifecycle results in a valuable asset ‚Äì a snippet of code, or a data transformation pipeline, or a table of newly engineered data, or an album of images or a new algorithm. Imagine having the power to instantly use any asset anyone creates to build bigger and better AI models that constantly expand your power to generate breakthroughs. Studio9 gives your team the frictionless ability to organize, track, share, and re-use all your Analytics &amp;amp; AI assets.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Automated Model Governance &amp;amp; Compliance&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Studio9 allows Model Risk Management, Regulatory Constraints, and Documentation Policies that your models must abide by to be encoded right into Pipeline and automatically reproduced every time a model is refreshed by Studio9. This includes Model Explainability, Model Fairness &amp;amp; Bias Analytics, Model Uncertainty, and Model Drift analytics ‚Äì all of which are performed automatically. We don‚Äôt think AI makes machines smarter. It exists to make you smarter. The easier it is for you to make AI, the greater your ability to make breakthroughs. Whether you have unlimited compute resources in the cloud, or you are limited at the edge, your ability to make breakthroughs should be unencumbered. We are committed to giving you the breakthrough Data Management &amp;amp; AI/ML capabilities you need so you can create the breakthroughs you want ‚Äì anywhere, anytime, and with anyone.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;What Studio9 can do?&lt;/h1&gt; &#xA;&lt;h2&gt;Reduce Your AI Workload 120x&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Studio9 provides a large inventory of building blocks from which you can stitch together custom AI and Data Engineering pipelines. Rapidly assemble and test many different pipelines to create the AI you need. Turn your data into AI with near-zero effort and cost. Since Studio9 is an open platform, newer cutting-edge AI building blocks that are emerging every day are put right at your fingertips.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Studio9 helps you find the breakthroughs hidden in your data&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Studio9 streamlines your burden of wrangling data. With its continuously expanding portfolio of building blocks, Studio9 makes it easier for you to clean, integrate, enrich, and harmonize your data. Do it all within your own infinitely scalable database environment without any of the hassle of managing your own database.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Push-button Model Deployment&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;You now have the power to deploy and run your Data Processing pipelines, Models, and AI anywhere ‚Äì from infinitely scalable Cloud computing infrastructure to your own laptop to ultra-low power edge computing devices ‚Äì with no additional programming or engineering effort required. We designed Studio9 for deployment flexibility so you can build, train, share, and execute your AI anywhere you want.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;Flow of Studio-9&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/86958663/171150086-22fb8783-bc07-45a0-a989-d100a3f50de8.png&#34; alt=&#34;Studio-9_flow&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;How to deploy Studio9 on Local?&lt;/h1&gt; &#xA;&lt;p&gt;So for deploying the Studio-9 on local, we have to understand the sequence of the services to be deployed. But before deployment of services we need to see some prerequisites for application.&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;OS: Ubuntu 16.04 LTS - 4vCPUs and 16GB memory.&lt;/li&gt; &#xA; &lt;li&gt;Mesos-marathon Cluster&lt;/li&gt; &#xA; &lt;li&gt;AWS account&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create.html&#34;&gt;AWS IAM Role&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-bucket.html&#34;&gt;AWS S3 buckets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/premiumsupport/knowledge-center/copy-s3-objects-account/&#34;&gt;AWS S3 buckets accessible to AWS IAM&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Mesos-Marathon Cluster Setup&lt;/h2&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Apache Zookeeper&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;     Version: 3.7.1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://phoenixnap.com/kb/install-apache-zookeeper&#34;&gt;Deploying Zookeeper on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Apache Mesos&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;     Version: 1.7.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mesos.apache.org/documentation/latest/building/&#34;&gt;Deploying Mesos on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Marathon&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;     Version: 1.5.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mesosphere.github.io/marathon/docs/&#34;&gt;Deploying Marathon on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here we need one more machine so for this we will create a VM on local machine by using Vagrant because mesos-marathon cluster work on master slave architecture.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Vagrant&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://blog.knoldus.com/creating-virtual-machines-using-vagrant-2/&#34;&gt;Deploying Vagrant on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note: We will run Mesos-Master on base machine and Marathon as well as Mesos-Slave on VM.&lt;/p&gt; &#xA;&lt;h2&gt;Mesos-Slave:&lt;/h2&gt; &#xA;&lt;p&gt;Process to run mesos-slave on slave is same as specified above only difference is the command we will use to run.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./bin/mesos-slave.sh --master=&amp;lt;base-machine IP&amp;gt;:5050  --work_dir=/var/run/mesos --log_dir=/var/log/mesos --    containerizers=docker,mesos --image_providers=appc,docker --isolation=filesystem/linux,docker/runtime&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Now, we will deploy the below services:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Elastic Search&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://phoenixnap.com/kb/install-elasticsearch-ubuntu&#34;&gt;Deploying Elastic Search on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;MongoDB&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/&#34;&gt;Deploying MongoDB on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;RabbutMQ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.rabbitmq.com/install-debian.html&#34;&gt;Deploying RabbitMQ on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Postgress&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.postgresql.org/download/linux/ubuntu/&#34;&gt;Deploying Postgres on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;After the deployment of above services, we will deploy the below services in the same sequence as they are listed below:&lt;/p&gt; &#xA;&lt;h2&gt;Aries&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/tree/mono-repo/codebase/aries/README.md&#34;&gt;Deploying Aries Service on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Argo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/tree/mono-repo/codebase/argo/README.md&#34;&gt;Deploying Argo Service on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Orion&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/tree/mono-repo/codebase/orion/README.md&#34;&gt;Deploying Orion Service on loal&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Cortex&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/tree/mono-repo/codebase/cortexREADME.md&#34;&gt;Deploying Cortex Service on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Pegasus&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/tree/mono-repo/codebase/pegasus/README.md&#34;&gt;Deploying Pegasus Service on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Taurus&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/tree/mono-repo/codebase/taurus/README.md&#34;&gt;Deploying Taurus Service on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;UM-Service&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/tree/mono-repo/codebase/user-management/README.md&#34;&gt;Deploying UM-Service on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Baile&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/tree/mono-repo/codebase/Baile/README.md&#34;&gt;Deploying Baile Service on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Salsa&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/knoldus/Studio-9/tree/mono-repo/codebase/salsa/README.md&#34;&gt;Deploying Salsa Service on local&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;How to Create a docker images ?&lt;/h1&gt; &#xA;&lt;h3&gt;Step1: When we change something in the code then we need to build a new docker image.&lt;/h3&gt; &#xA;&lt;h3&gt;Step 2 : We just need to run the below command to build the image from the dockerfile.&lt;/h3&gt; &#xA;&lt;p&gt;If you are in the same directory where you have docker file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;     docker build -t &amp;lt;image_name&amp;gt;:&amp;lt;version&amp;gt; .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;EX-&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;    docker build -t python:1.0 .         &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are buling a image from the other side of your dockerfile &#39;s Path then you can simply pass the path at the end of command :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;    docker build -t &amp;lt;image_name&amp;gt;:&amp;lt;version&amp;gt; ./&amp;lt;PATH to file&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ex-&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;    docker build -t python:1.0 ./&amp;lt;PATH to dockerfile&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 3: First you should tag the image accourding to your preferance:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;    docker tag &amp;lt;image_name&amp;gt;:&amp;lt;version&amp;gt; &amp;lt;user_name&amp;gt;/repo_name&amp;gt;:&amp;lt;version&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ex:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;    docker tag python:latest username/python:1.0  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 4: Now we can push the image to the dockerhub or other cotainer registory:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;    docker push username/python:1.0 &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step5 : Now we can change the image name in the code or where we are using this perticular image.&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;How to deploy Studio9 using Docker-Compose?&lt;/h1&gt; &#xA;&lt;p&gt;We&#39;ll be deploying Studio9 on local using a docker-compose file.&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;OS: Ubuntu 16.04 LTS - 4vCPUs and 16GB memory.&lt;/li&gt; &#xA; &lt;li&gt;Mesos-marathon Cluster&lt;/li&gt; &#xA; &lt;li&gt;AWS account&lt;/li&gt; &#xA; &lt;li&gt;AWS IAM&lt;/li&gt; &#xA; &lt;li&gt;AWS S3 buckets&lt;/li&gt; &#xA; &lt;li&gt;AWS S3 buckets accessible to AWS IAM&lt;/li&gt; &#xA; &lt;li&gt;Docker should be installed on your local system.&lt;/li&gt; &#xA; &lt;li&gt;If you don&#39;t have docker installed in your system, kindly refer to this &lt;a href=&#34;https://docs.docker.com/engine/install/ubuntu/&#34;&gt;link&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;After successfully installing Docker, clone the &lt;a href=&#34;https://github.com/knoldus/Studio-9.git&#34;&gt;Repository&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run the Docker Compose file by running the below command:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;code&gt;sh docker-compose up -d&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;sh docker compose up -d&lt;/code&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you want to see the logs, use the below command:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;code&gt;sh docker-compose up&lt;/code&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To stop the services, use the below commands:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;code&gt;sh docker compose down&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;NOTE: Use the above commands in the directory where the docker compose file exists.&lt;/p&gt; &#xA;&lt;h2&gt;Explanation of Docker Compose&lt;/h2&gt; &#xA;&lt;p&gt;For running the Studio-9 on local, we are using docker-compose.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We are using a single network i.e. &#39;studio9&#39; for all the services that&#39;ll run for studio-9.&lt;/li&gt; &#xA; &lt;li&gt;Here we have 17 services that will be deployed on local machine to run the Studio-9.&lt;/li&gt; &#xA; &lt;li&gt;There are four volumes being used in Studio-9, three for elastic-search and one for mongoDB.&lt;/li&gt; &#xA; &lt;li&gt;The elastic-search master node is accessible at the port 9200.&lt;/li&gt; &#xA; &lt;li&gt;Kibana service will run after the Elastic-search nodes are up and will be accessible at port 5601.&lt;/li&gt; &#xA; &lt;li&gt;Mongo express service depends on mongo and will be accessible at 8081.&lt;/li&gt; &#xA; &lt;li&gt;Zookeeper is using the same network i.e. &#39;studio9&#39; and will be accessible 2181.&lt;/li&gt; &#xA; &lt;li&gt;RabbitMQ is accessible at ports 5672 and 15672.&lt;/li&gt; &#xA; &lt;li&gt;Next we have Aries service and it depends on Elastic-search nodes and will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;The Cortex service depends on Aries RabbitMQ and will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;The Argo service also depends on Elastic-search nodes and will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;Gemini service depends on zookeeper and sql-server and will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;Taurus service depends on RabbitMQ, Cortex, Baile, Argo and Aries and will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;Orion service depends on Cortex, Zookeeper and RabbitMQ and will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;Pegasus service depends on Taurus RabbitMQ and Postgres nad will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;UM service depends on Mongo and will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;Baile service depends on Mongo, UM service, Aries, Cortex, SQL-server and Zookeeper and will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;SQL-Server depends on UM Service and will be accessible at 9000.&lt;/li&gt; &#xA; &lt;li&gt;Salsa service is responsible for the UI of Studio-9 and it depends on Baile with port 80.&lt;/li&gt; &#xA; &lt;li&gt;Postgres service depends on postgres-db and will be accessible at 8080.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üë®‚Äçüíª Author&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/knoldus/Studio-9/master/bhavya@knoldus.com&#34;&gt;Bhavya Aggarwal&lt;/a&gt;, CTO, &lt;a href=&#34;https://www.knoldus.com&#34;&gt;knoldus, Inc (https://www.knoldus.com)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/knoldus/Studio-9/master/rahul.miglani@knoldus.com&#34;&gt;Rahul Miglani&lt;/a&gt;, VP-Engineering-DevOps, &lt;a href=&#34;https://www.knoldus.com&#34;&gt;knoldus, Inc (https://www.knoldus.com)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/knoldus/Studio-9/master/abhishek.dwivedi@knoldus.com&#34;&gt;Abhishek Dwivedi&lt;/a&gt;, Sr. Software Consultant-DevOps, &lt;a href=&#34;https://www.knoldus.com&#34;&gt;knoldus, Inc (https://www.knoldus.com)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are &lt;strong&gt;greatly appreciated&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork the Project&lt;/li&gt; &#xA; &lt;li&gt;Create your Feature Branch (&lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Commit your Changes (&lt;code&gt;git commit -m &#39;Add some AmazingFeature&#39;&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Push to the Branch (&lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Open a Pull Request&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;‚≠êÔ∏è Show your support&lt;/h2&gt; &#xA;&lt;p&gt;Give a ‚≠êÔ∏è if this project helped you!&lt;/p&gt; &#xA;&lt;h2&gt;üìù License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright ¬© 2022 &lt;a href=&#34;https://www.knoldus.com&#34;&gt;knoldus, Inc (https://www.knoldus.com)&lt;/a&gt;. &lt;br&gt; This project is licensed under the &lt;a href=&#34;https://github.com/knoldus/Studio-9/raw/master/LICENSE.md&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;</summary>
  </entry>
</feed>