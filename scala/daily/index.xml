<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-03T01:52:00Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>rtyley/bfg-repo-cleaner</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/rtyley/bfg-repo-cleaner</id>
    <link href="https://github.com/rtyley/bfg-repo-cleaner" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Removes large or troublesome blobs like git-filter-branch does, but faster. And written in Scala&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BFG Repo-Cleaner &lt;a href=&#34;https://travis-ci.com/rtyley/bfg-repo-cleaner&#34;&gt;&lt;img src=&#34;https://travis-ci.com/rtyley/bfg-repo-cleaner.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Removes large or troublesome blobs like git-filter-branch does, but faster - and written in Scala&lt;/em&gt; - &lt;a href=&#34;https://j.mp/fund-bfg&#34;&gt;Fund the BFG&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bfg --strip-blobs-bigger-than 1M --replace-text banned.txt repo.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The BFG is a simpler, faster (&lt;a href=&#34;https://docs.google.com/spreadsheet/ccc?key=0AsR1d5Zpes8HdER3VGU1a3dOcmVHMmtzT2dsS2xNenc&#34;&gt;10 - 720x&lt;/a&gt; faster) alternative to &lt;code&gt;git-filter-branch&lt;/code&gt; for cleansing bad data out of your Git repository:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Removing &lt;strong&gt;Crazy Big Files&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Removing &lt;strong&gt;Passwords, Credentials&lt;/strong&gt; &amp;amp; other &lt;strong&gt;Private data&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Main documentation for The BFG is here : &lt;strong&gt;&lt;a href=&#34;https://rtyley.github.io/bfg-repo-cleaner/&#34;&gt;https://rtyley.github.io/bfg-repo-cleaner/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>geekyouth/SZT-bigdata</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/geekyouth/SZT-bigdata</id>
    <link href="https://github.com/geekyouth/SZT-bigdata" rel="alternate"></link>
    <summary type="html">&lt;p&gt;æ·±åœ³åœ°é“å¤§æ•°æ®å®¢æµåˆ†æç³»ç»ŸğŸš‡ğŸš„ğŸŒŸ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SZT-bigdata æ·±åœ³åœ°é“å¤§æ•°æ®å®¢æµåˆ†æç³»ç»Ÿ ğŸš‡ğŸš‡ğŸš‡&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth/SZT-bigdata&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.doc/full-logo.png&#34; alt=&#34;logo&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth/SZT-bigdata/stargazers&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/geekyouth/SZT-bigdata?style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth/SZT-bigdata/network/members&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/geekyouth/SZT-bigdata?style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth/SZT-bigdata/watchers&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/watchers/geekyouth/SZT-bigdata?style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth/SZT-bigdata/releases&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/geekyouth/SZT-bigdata?style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth/SZT-bigdata/issues&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues/geekyouth/SZT-bigdata?style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth/SZT-bigdata/raw/master/LICENSE&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/geekyouth/SZT-bigdata?style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://java666.cn&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/åšå®¢ï¼š-https://java666.cn-red?style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;pre&gt;&lt;code&gt;   ___     ____   _____           _         _      __ _      _             _&#xA;  / __|   |_  /  |_   _|   ___   | |__     (_)    / _` |  __| |   __ _    | |_    __ _&#xA;  \__ \    / /     | |    |___|  | &#39;_ \    | |    \__, | / _` |  / _` |   |  _|  / _` |&#xA;  |___/   /___|   _|_|_   _____  |_.__/   _|_|_   |___/  \__,_|  \__,_|   _\__|  \__,_|&#xA;_|&#34;&#34;&#34;&#34;&#34;|_|&#34;&#34;&#34;&#34;&#34;|_|&#34;&#34;&#34;&#34;&#34;|_|     |_|&#34;&#34;&#34;&#34;&#34;|_|&#34;&#34;&#34;&#34;&#34;|_|&#34;&#34;&#34;&#34;&#34;|_|&#34;&#34;&#34;&#34;&#34;|_|&#34;&#34;&#34;&#34;&#34;|_|&#34;&#34;&#34;&#34;&#34;|_|&#34;&#34;&#34;&#34;&#34;|&#xA;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#34;`-0-0-&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;é¡¹ç›®è¯´æ˜ğŸš©ï¼š&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸˆ è¯¥é¡¹ç›®ä¸»è¦åˆ†ææ·±åœ³é€šåˆ·å¡æ•°æ®ï¼Œé€šè¿‡å¤§æ•°æ®æŠ€æœ¯è§’åº¦æ¥ç ”ç©¶æ·±åœ³åœ°é“å®¢è¿èƒ½åŠ›ï¼Œæ¢ç´¢æ·±åœ³åœ°é“ä¼˜åŒ–æœåŠ¡çš„æ–¹å‘ï¼›&lt;/li&gt; &#xA; &lt;li&gt;âœ¨ å¼ºè°ƒå­¦ä»¥è‡´ç”¨ï¼Œæœ¬é¡¹ç›®çš„åŸåˆ™æ˜¯å°½å¯èƒ½ä½¿ç”¨è¾ƒå¤šçš„å¸¸ç”¨æŠ€æœ¯æ¡†æ¶ï¼ŒåŠ æ·±å¯¹å„æŠ€æœ¯æ ˆçš„ç†è§£å’Œè¿ç”¨ï¼Œåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­ä½“éªŒå„æ¡†æ¶çš„å·®å¼‚å’Œä¼˜åŠ£ï¼Œä¸ºä»¥åçš„é¡¹ç›®å¼€å‘æŠ€æœ¯é€‰å‹åšåŸºç¡€ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‘‘ è§£å†³åŒä¸€ä¸ªé—®é¢˜ï¼Œå¯èƒ½æœ‰å¤šç§æŠ€æœ¯å®ç°ï¼Œå®é™…çš„ä¼ä¸šå¼€å‘åº”å½“éµå®ˆæœ€ä½³å®è·µåŸåˆ™ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‰ å­¦ä¹ è¿‡ç¨‹ä¼˜å…ˆé€‰æ‹©è¾ƒæ–°çš„è½¯ä»¶ç‰ˆæœ¬ï¼Œå› ä¸ºæ–°ç‰ˆè¸©å‘ä¸€å®šæ¯”è€ç‰ˆæ›´å¤šï¼Œå‘è¸©çš„å¤šäº†ï¼ŒæŠ€èƒ½ä¹Ÿå°±æé«˜äº†ï¼Œé‡åˆ°æ–°é—®é¢˜å¯ä»¥è§æ‹›æ‹†æ‹›ã€å¯¹ç—‡ä¸‹è¯ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ğŸš€ ...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ç¬¬ä¸€æœŸæ¶æ„å›¾&lt;/h2&gt; &#xA;&lt;p&gt;åŸå›¾ &lt;a href=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.doc/SZT-bigdata-2.png&#34;&gt;.file/.doc/SZT-bigdata-2.png&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.doc/SZT-bigdata-2+.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;æ•°å­—æ ‡è®°ä¸åˆ†å…ˆåé¡ºåºï¼Œå¯¹åº”ä»£ç ï¼š&#xA;1-cn.java666.sztcommon.util.SZTData&#xA;2-cn.java666.etlflink.app.Jsons2Redis&#xA;3-cn.java666.etlspringboot.controller.RedisController#get&#xA;4-cn.java666.etlflink.app.Redis2ES&#xA;5-cn.java666.etlflink.app.Redis2Csv&#xA;6-Hive sql è„šæœ¬ï¼ˆå¼€å‘ç»´æŠ¤æˆæœ¬æœ€ä½ï¼‰&#xA;7-Saprk ç¨‹åºï¼ˆå¼€å‘ç»´æŠ¤æˆæœ¬æœ€é«˜ï¼Œä½†æ˜¯åŠŸèƒ½æ›´å¼ºï¼‰&#xA;8-HUE æ–¹ä¾¿æŸ¥è¯¢å’Œå±•ç¤º Hive æ•°æ®&#xA;9-cn.java666.etlflink.app.Redis2HBase&#xA;10ã€14-cn.java666.szthbase.controller.KafkaListen#sink2Hbase&#xA;11-cn.java666.etlflink.app.Redis2HBase&#xA;12-CDH HDFS+HUE+Hbase+Hive ä¸€ç«™å¼æŸ¥è¯¢&#xA;13-cn.java666.etlflink.app.Redis2Kafka&#xA;15-cn.java666.sztflink.realtime.Kafka2MyCH&#xA;16-cn.java666.sztflink.realtime.sink.MyClickhouseSinkFun&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;ä¸‹ä¸€æ­¥ï¼Œè®¡åˆ’å¼€å‘æ•°æ®æ¹–ä¸­å°è§£å†³æ–¹æ¡ˆ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;æ ¸å¿ƒæŠ€æœ¯æ ˆ + ç‰ˆæœ¬é€‰æ‹© + ç‚¹è¯„ (æŒç»­æ›´æ–°)âš¡ï¼š&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.doc/stack2.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Java-1.8/Scala-2.11ï¼Œç”Ÿæ€ä¸°å¯Œï¼Œè½®å­å¤Ÿå¤šï¼›&lt;/li&gt; &#xA; &lt;li&gt;Flink-1.10ï¼Œæµå¼ä¸šåŠ¡ã€ETL é¦–é€‰ã€‚å‘å±•åŠ¿å¤´å¦‚æ—¥ä¸­å¤©ï¼Œé˜¿é‡Œå·´å·´èƒŒä¹¦ï¼Œè½»å¿«çµæ´»ã€å¥æ­¥å¦‚é£ï¼›å°±é—®ä½ ä¿¡ä¸ä¿¡é©¬äº‘ï¼Ÿï¼Ÿï¼ŸğŸ˜šğŸ˜šğŸ˜š&lt;/li&gt; &#xA; &lt;li&gt;Redis-3.2ï¼Œå¤©ç„¶å»é‡ï¼Œè‡ªåŠ¨æ’åºï¼Œé™¤äº†å¿«è¿˜æ˜¯å¿«ã€‚å»‰ä»·ç‰ˆç¡¬ç›˜å®ç°åŒç±»äº§å“ SSDBã€‚Win10|CentOS7|Docker Redis-3.2 ä¸‰é€‰ä¸€ï¼ŒCentOS REPL yum å®‰è£…é»˜è®¤ä½¿ç”¨3.2ç‰ˆæœ¬ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Kafka-2.1ï¼Œæ¶ˆæ¯é˜Ÿåˆ—ä¸šåŠ¡è§£è€¦ã€æµé‡æ¶ˆå³°ã€è®¢é˜…å‘å¸ƒåœºæ™¯é¦–é€‰ã€‚æœ€ä½³ CPï¼škafka-eagle-1.4.5ï¼Œé›†ç”Ÿäº§ã€æ¶ˆè´¹ã€Ksqlã€å¤§å±ã€ç›‘æ§ã€æŠ¥è­¦äºä¸€èº«ï¼ŒåŒæ—¶ç›‘æ§ zkã€‚å…¶ä»–æˆ‘ç”¨è¿‡çš„ Kafka ç›‘æ§ç»„ä»¶æœ€åéƒ½æ”¾å¼ƒäº†ï¼š &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;KafkaOffsetMonitor é—®é¢˜å¤ªå¤šï¼Œä¸‘æ‹’ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;Kafka Managerï¼Œå·²æ›´åä¸º CMAKï¼Œè€å¤–å†™çš„è½¯ä»¶ç”¨èµ·æ¥å°±è§‰å¾—å¾ˆåˆ«æ‰­ï¼Œè€Œä¸”æœ€é«˜åªå…¼å®¹ Kafka 0.11ï¼Œä½†æ˜¯ Kafka å®˜æ–¹å·²ç»å‡çº§åˆ° 2.4 äº†å•Šå–‚ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å…¶ä»–å„ç§å¼€æºçš„ Kafka ç›‘æ§åŸºæœ¬éƒ½è¯•è¿‡ï¼Œä¸€ä¸ªèƒ½æ‰“çš„éƒ½æ²¡æœ‰ã€‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Zookeeper-3.4.5ï¼Œé›†ç¾¤åŸºç¡€ä¾èµ–ï¼Œé€‰ä¸¾æ—¶ ID è¶Šå¤§è¶Šä¼˜åŠ¿ï¼Œé€šè¿‡ä¼šè¯æœºåˆ¶ç»´æŠ¤å„ç»„ä»¶åœ¨çº¿çŠ¶æ€ï¼›&lt;/li&gt; &#xA; &lt;li&gt;CDH-6.2ï¼Œè§£å†³äº†ç¨‹åºå‘˜æœ€éš¾æçš„è½¯ä»¶å…¼å®¹æ€§é—®é¢˜ï¼Œå…¨å®¶æ¡¶æœåŠ¡ä¸€é”®å®‰è£…ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Docker-19ï¼Œæœ€å¿«é€Ÿåº¦éƒ¨ç½²ä¸€æ¬¾æ–°è½¯ä»¶ï¼Œæ— ä¾µå…¥ã€æ— æ±¡æŸ“ã€å¿«é€Ÿæ‰©å®¹ã€æœåŠ¡æ‰“åŒ…ã€‚å¦‚æœå½“å‰æ²¡æœ‰åˆé€‚çš„è¿è¡Œç¯å¢ƒï¼Œé‚£ä¹ˆ docker ä¸€å®šæ˜¯é¦–é€‰ï¼›&lt;/li&gt; &#xA; &lt;li&gt;SpringBoot-2.13ï¼Œé€šç”¨ JAVA ç”Ÿæ€ï¼Œæ•æ·å¼€å‘å¿…å¤‡ï¼›&lt;/li&gt; &#xA; &lt;li&gt;knife4j-2.0ï¼Œå‰èº«ä¸º swagger-bootstrap-uiï¼ŒREST API é¡¹ç›®è°ƒè¯•ç®€ç›´ä¸è¦å¤ªæ–¹ä¾¿ï¼Œç§’æ€åŸç‰ˆä¸è¢œå“¥åä¸ªæ•°é‡çº§ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Elasticsearch-7ï¼Œå…¨æ–‡æ£€ç´¢é¢†åŸŸå”¯ä¸€é è°±çš„æ•°æ®åº“ï¼Œæœç´¢å¼•æ“æ ¸å¿ƒæœåŠ¡ï¼Œäº¿çº§æ•°æ®æ¯«ç§’å“åº”ï¼ŒçœŸå®æ—¶ï¼Œå‘ä¹Ÿå¤šğŸ”ŠğŸ”ŠğŸ”Šï¼›&lt;/li&gt; &#xA; &lt;li&gt;Kibana-7.4ï¼ŒELK å…¨å®¶æ¡¶æˆå‘˜ï¼Œå‰ç«¯å¯è§†åŒ–ï¼Œå°ç™½ä¹Ÿä¸æ€•ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ClickHouseï¼Œå®¶å–»æˆ·æ™“çš„ nginx æœåŠ¡å™¨å°±æ˜¯ä¿„ç½—æ–¯çš„ä»£è¡¨ä½œï¼Œæ¥ä¸‹æ¥å¤§çº¢å¤§ç´«çš„ clickhouse åŒæ ·èº«è½»å¦‚ç‡•ï¼Œä½†æ˜¯æ€§èƒ½è¿œè¶…ç›®å‰å¸‚é¢æ‰€æœ‰åŒç±»æ•°æ®åº“ï¼Œå­˜å‚¨å®¹é‡å¯è¾¾PBçº§åˆ«ã€‚ç›®å‰èµ„æ–™è¿˜ä¸å¤šï¼Œæ­£åœ¨å­¦ä¹ ä¸­ï¼›&lt;/li&gt; &#xA; &lt;li&gt;MongoDB-4.0ï¼Œæ–‡æ¡£æ•°æ®åº“ï¼Œå¯¹ Json æ•°æ®æ¯”è¾ƒå‹å¥½ï¼Œä¸»è¦ç”¨äºçˆ¬è™«æ•°æ®åº“ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Spark-2.3ï¼Œç›®å‰å›½å†…å¤§æ•°æ®æ¡†æ¶å®æ—¶å¾®æ‰¹å¤„ç†ã€ç¦»çº¿æ‰¹å¤„ç†ä¸»æµæ–¹æ¡ˆã€‚è¿™ä¸ªç»„ä»¶å¤ªåƒèµ„æºäº†ï¼Œæ›¾ç»åœ¨æˆ‘å¼€å‘æ—¶ï¼ŒæŠŠæˆ‘çš„ç¬”è®°æœ¬æåˆ°è“å±ï¼Œäºæ˜¯æˆ‘ç›´æ¥è¿œç¨‹æäº¤åˆ° spark é›†ç¾¤äº†ã€‚æ¥ä¸‹æ¥é¢„è®¡ Flink å¼€å§‹è¡¨æ¼”äº†ğŸ¦˜ï¼ŒçœŸçš„ç”¨äº†æ›´å¿«çš„æ¡†æ¶å°±çˆ±ä¸Šäº†ğŸ˜ğŸ˜ğŸ˜ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Hive-2.1ï¼ŒHadoop ç”Ÿæ€æ•°ä»“å¿…å¤‡ï¼Œå¤§æ•°æ®ç¦»çº¿å¤„ç† OLAP ç»“æ„åŒ–æ•°æ®åº“ï¼Œå‡†ç¡®æ¥è¯´æ˜¯ä¸ª HQL è§£æå™¨ï¼ŒæŸ¥è¯¢è¯­æ³•æ¥è¿‘ Mysqlï¼Œå°±æ˜¯çª—å£å‡½æ•°æ¯”è¾ƒå¤æ‚ğŸ˜­ğŸ˜­ğŸ˜­ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Impala-3.2ï¼Œåƒç¾šç¾Šä¸€æ ·è½»å¿«çŸ«å¥ï¼ŒåŒæ ·çš„ hive sql å¤æ‚æŸ¥è¯¢ï¼Œimpala æ¯«ç§’çº§è¿”å›ï¼Œhive å´éœ€è¦80ç§’å·¦å³ç”šè‡³æ›´å¤šï¼›&lt;/li&gt; &#xA; &lt;li&gt;HBase-2.1 + Phoenixï¼ŒHadoop ç”Ÿæ€ä¸‹çš„éç»“æ„åŒ–æ•°æ®åº“ï¼ŒHBase çš„çµé­‚è®¾è®¡å°±æ˜¯ rowkey å’Œå¤šç‰ˆæœ¬æ§åˆ¶ï¼Œå‡¤å‡°å«æ¥ hbase å¯ä»¥å®ç°æ›´å¤æ‚çš„ä¸šåŠ¡ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Kylin-2.5ï¼Œéº’éºŸå¤šç»´é¢„åˆ†æç³»ç»Ÿï¼Œä¾èµ–å†…å­˜å¿«é€Ÿè®¡ç®—ï¼Œä½†æ˜¯å±€é™æ€§æœ‰ç‚¹å¤šå•Šï¼Œé€‚ç”¨äºä¸šåŠ¡ç‰¹åˆ«ç¨³å®šï¼Œçº¬åº¦å›ºå®šå°‘å˜çš„åœºæ™¯ï¼Œæ¸£æ¸£æœºå™¨å°±åˆ«è¯•äº†ï¼Œå†…å­˜å¤ªå°å¸¦ä¸èµ·ï¼›&lt;/li&gt; &#xA; &lt;li&gt;HUE-4.3ï¼ŒCDH å…¨å®¶æ¡¶èµ é€çš„ï¼Œå¼ºè°ƒç”¨æˆ·ä½“éªŒï¼Œæ“ä½œæ•°ä»“å¾ˆæ–¹ä¾¿ï¼Œæƒé™æ§åˆ¶ã€hive + impala æŸ¥è¯¢ã€hdfs æ–‡ä»¶ç®¡ç†ã€oozie ä»»åŠ¡è°ƒåº¦è„šæœ¬ç¼–å†™å…¨é ä»–äº†ï¼›&lt;/li&gt; &#xA; &lt;li&gt;é˜¿é‡Œå·´å·´ DataXï¼Œå¼‚æ„æ•°æ®æºåŒæ­¥å·¥å…·ï¼Œä¸»æŒå¤§éƒ¨åˆ†ä¸»æµæ•°æ®åº“ï¼Œç”šè‡³å¯ä»¥è‡ªå·±å¼€å‘æ’ä»¶ï¼Œé©¬äº‘å®¶çš„ä¸œè¥¿ï¼Œæˆ‘é€‰ä½ ï¼ï¼ï¼å¦‚æœä½ è§‰å¾—è¿™è¿˜æ»¡è¶³ä¸äº†ä½ çš„ç‰¹æ®Šä¸šåŠ¡éœ€æ±‚ï¼Œé‚£ä¹ˆæ¨èä½ ç”¨ FlinkXï¼ŒåŸºäº Flink çš„åˆ†å¸ƒå¼æ•°æ®åŒæ­¥å·¥å…·ã€‚ç†è®ºä¸Šä½ ä¹Ÿå¯ä»¥è‡ªå·±å¼€å‘æ’ä»¶ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Oozie-5.1ï¼Œæœ¬èº« UI å¥‡ä¸‘ï¼Œä½†æ˜¯é…åˆ HUE é£Ÿç”¨å°šå¯æ¥å—ï¼Œä¸»è¦ç”¨æ¥ç¼–å†™å’Œè¿è¡Œä»»åŠ¡è°ƒåº¦è„šæœ¬ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Sqoop-1.4ï¼Œä¸»è¦ç”¨æ¥ä» Mysql å¯¼å‡ºä¸šåŠ¡æ•°æ®åˆ° HDFS æ•°ä»“ï¼Œåè¿‡æ¥ä¹Ÿè¡Œï¼›&lt;/li&gt; &#xA; &lt;li&gt;Mysql-5.7ï¼Œç¨‹åºå‘˜éƒ½è¦ç”¨çš„å§ï¼Œå¦‚æœè¯´å…¨ä¸–ç•Œç¨‹åºå‘˜éƒ½ä¼šç”¨çš„è¯­è¨€ï¼Œé‚£ä¸€å®šæ˜¯ SQLã€‚Mysql 8.0 æ™®åŠç‡ä¸å¤Ÿé«˜ï¼ŒMariaDB æš‚ä¸æ¨èï¼Œå¤æ‚çš„å‡½æ•°ä¸å…¼å®¹ Mysqlï¼Œæ•°æ®åº“è¿™ä¹ˆåŸºç¡€çš„ä¾èµ–ç»„ä»¶å‡ºäº†é—®é¢˜ä½ å°±å“­å§ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Hadoop3.0ï¼ˆHDFS+Yarnï¼‰ï¼ŒHDFS æ˜¯ç›®å‰å¤§æ•°æ®é¢†åŸŸæœ€ä¸»æµçš„åˆ†å¸ƒå¼æµ·é‡æ•°æ®å­˜å‚¨ç³»ç»Ÿï¼Œè¿™é‡Œçš„ Yarn ç‰¹æŒ‡ hadoop ç”Ÿæ€ï¼Œä¸»è¦ç”¨æ¥åˆ†é…é›†ç¾¤èµ„æºï¼Œè‡ªå¸¦æ‰§è¡Œå¼•æ“ MRï¼›&lt;/li&gt; &#xA; &lt;li&gt;é˜¿é‡Œå·´å·´ DataV å¯è§†åŒ–å±•ç¤ºï¼›&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;æˆ‘å‘ç°è¶Šæ¥è¶Šå¤šçš„å›½äº§å¼€æºè½¯ä»¶ç”¨æˆ·ä½“éªŒå€¼å¾—è‚¯å®šã€‚ã€‚ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;å‡†å¤‡å·¥ä½œğŸ¬ï¼š&lt;/h2&gt; &#xA;&lt;p&gt;ä»¥ä¸‹æ˜¯æˆ‘çš„å¼€å‘ç¯å¢ƒï¼Œä»…ä½œå‚è€ƒï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Win10 IDEA 2019.3 æ——èˆ°ç‰ˆï¼ŒJAVA|Scala å¼€å‘å¿…å¤‡ï¼Œé›†ä¸‡èˆ¬åŠŸèƒ½äºä¸€èº«ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Win10 DBeaver ä¼ä¸šç‰ˆ 6.3ï¼Œç§’æ€å…¨å®‡å®™æ‰€æœ‰æ•°æ®åº“å®¢æˆ·ç«¯ï¼Œå‡ ä¹ä¸€åˆ‡å¸¸ç”¨æ•°æ®åº“éƒ½å¯ä»¥è¿ï¼Œé€‰å¥½é©±åŠ¨æ˜¯å…³é”®ï¼›&lt;/li&gt; &#xA; &lt;li&gt;Win10 Sublime Text3ï¼Œåœ°è¡¨æœ€å¼ºè½»é‡çº§ç¼–è¾‘å™¨ï¼Œå…‰é€Ÿå¯åŠ¨ï¼Œæ— é™é‡æ’ä»¶ï¼Œä¸»è¦ç”¨æ¥ç¼–è¾‘é›¶æ•£æ–‡ä»¶ã€markdown å®æ—¶é¢„è§ˆã€å†™å‰ç«¯ç‰¹åˆ«å‹å¥½ï¼ˆè™½ç„¶æˆ‘ä¸æ“…é•¿ğŸ–ğŸ–ğŸ–ï¼‰ï¼Œé€Ÿåº¦å¿«åˆ°å®Œå…¨ä¸ç”¨æ‹…å¿ƒè½¯ä»¶è·Ÿä¸ä¸Šä½ çš„æ‰‹é€Ÿï¼›&lt;/li&gt; &#xA; &lt;li&gt;å…¶ä»–ä¸€äº›å®ç”¨å·¥å…·å‚è€ƒæˆ‘çš„åšå®¢ï¼š&lt;a href=&#34;https://java666.cn/#/AboutMe&#34; target=&#34;_blank&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://java666.cn/#/AboutMe&#34;&gt;https://java666.cn/#/AboutMe&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CentOS7 CDH-6.2 é›†ç¾¤ï¼ŒåŒ…å«å¦‚ä¸‹ç»„ä»¶ï¼Œå¯¹åº”çš„ä¸»æœºè§’è‰²å’Œé…ç½®å¦‚å›¾ï¼Œé›†ç¾¤è‡³å°‘éœ€è¦40 GB æ€»å†…å­˜ï¼Œæ‰å¯ä»¥æ»¡è¶³åŸºæœ¬ä½¿ç”¨ï¼Œä¸å·®é’±çš„å‰æä¸‹ï¼ŒRAM å½“ç„¶æ˜¯åˆç†èŒƒå›´å†…è¶Šå¤§è¶Šå¥½å•¦ï¼Œé²è¿…éƒ½è¯´â€œå¤©ä¸‹æ­¦åŠŸå”¯å¿«ä¸ç ´â€ï¼›æˆ‘ä»¬çš„è¿½æ±‚æ˜¯è¶Šå¿«è¶Šå¥½ï¼›&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/0-cdh-view.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/0-cdh-host.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/0-cdh-role.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;å¦‚æœä½ é€‰ç”¨åŸç‰ˆ Apache ç»„ä»¶æ­å»ºå¤§æ•°æ®é›†ç¾¤ï¼Œé‚£ä¹ˆä½ ä¼šæœ‰è¸©ä¸å®Œçš„å‘ã€‚æˆ‘çš„å¤´å‘ä¸å¤Ÿæ‰äº†ï¼Œæ‰€ä»¥æˆ‘é€‰ CDHï¼ï¼ï¼âš™ğŸ› ğŸ˜ğŸ˜ğŸ˜&lt;/p&gt; &#xA;&lt;h2&gt;ç‰©ç†æœºé…ç½®ğŸ’ï¼š&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ä»¥ä¸Šè½¯ä»¶åˆ†å¼€éƒ¨ç½²åœ¨æˆ‘çš„ä¸‰å°ç”µè„‘ä¸Šï¼ŒWin10 ç¬”è®°æœ¬ VMware + Win10 å°å¼æœº VMware + å¤è‘£ç¬”è®°æœ¬ CentOS7ã€‚ç‰©ç†æœºå…¨éƒ½é…ç½® SSD + åƒå…†ä»¥å¤ªç½‘å¡ï¼ŒHDFS éœ€è¦æœ€å¿«çš„ç½‘å¡ã€‚å¥½é©¬é…å¥½éï¼Œå½“ç„¶ä½ å¾—æœ‰ä¸ªåƒå…†äº¤æ¢æœºé…åˆåƒå…†ç½‘çº¿ï¼Œæœ¨æ¡¶åŸç†è­¦å‘Šï¼ï¼ï¼ğŸˆğŸˆğŸˆ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æœ‰ä¸ªæœºæ¶å½“ç„¶å†å¥½ä¸è¿‡äº†ï¼Œå“ˆå“ˆå“ˆã€‚ã€‚ã€‚ &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/0-pcs.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¦‚æœä½ æƒ³é¿å…ç½‘çº¿ç‰µæ¥ç‰µå»ï¼Œå¯ä»¥é‡‡ç”¨ç”µåŠ›çŒ«å®ç°åˆ†å¸ƒå¼å®¶åº­ç»„ç½‘æ–¹æ¡ˆï¼›&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;æ•°æ®æºğŸŒï¼š&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ·±åœ³å¸‚æ”¿åºœæ•°æ®å¼€æ”¾å¹³å°ï¼Œæ·±åœ³é€šåˆ·å¡æ•°æ® 133.7 ä¸‡æ¡ã€ç¦»çº¿æ•°æ®ã€‘è²Œä¼¼å·²ç»åœæ­¢æœåŠ¡ğŸ˜’ï¼š&lt;br&gt; &lt;a href=&#34;https://opendata.sz.gov.cn/data/api/toApiDetails/29200_00403601&#34;&gt;https://opendata.sz.gov.cn/data/api/toApiDetails/29200_00403601&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;å¤‡ç”¨æ•°æ®æº(ä¹‹å‰ä¸Šä¼ çš„ä¸€æ‰¹ jsons æ•°æ®æœ‰äº›çº°æ¼ï¼Œäºæ˜¯é‡æ–°æ•´ç†å‹ç¼©åæ”¾åˆ°æœ¬ä»“åº“ä¸­ï¼Œé€Ÿåº¦æ…¢çš„åŒå­¦å¯ä»¥å°è¯•ç äº‘ &lt;a href=&#34;https://gitee.com/geekyouth/SZT-bigdata&#34;&gt;https://gitee.com/geekyouth/SZT-bigdata&lt;/a&gt; )ï¼š&lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/2018record3.zip&#34;&gt;.file/2018record3.zip&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ç†è®ºä¸Šå¯ä»¥å½“ä½œå®æ—¶æ•°æ®ï¼Œä½†æ˜¯è¿™ä¸ªæ¥å£å“åº”å¤ªæ…¢äº†ï¼Œå¦‚æœé‡‡ç”¨ kafka é˜Ÿåˆ—æ–¹å¼ï¼Œä¹Ÿå¯ä»¥æ¨¡æ‹Ÿå‡ºå®æ—¶æ•ˆæœã€‚&lt;/p&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®é‡‡ç”¨ç¦»çº¿ + å®æ—¶æ€è·¯ å¤šç§æ–¹æ¡ˆå¤„ç†ã€‚&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;å¼€å‘è¿›åº¦ğŸ¥‡ï¼š&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;å‡†å¤‡å¥½ javaã€scalaã€å¤§æ•°æ®å¼€å‘å¸¸ç”¨çš„ç¯å¢ƒï¼Œæ¯”å¦‚ IDEAã€VMware è™šæ‹Ÿæœºã€CDHç­‰ï¼Œç„¶åæ‰‹æœºé™éŸ³ç›–ä¸Šï¼Œè·Ÿæˆ‘ä¸€èµ·å·¦æ‰‹ç”»ä¸ªé¾™ï¼Œå³æ‰‹åˆ’ä¸€é“å½©è™¹ï¼Œå¼€å§‹è¡¨æ¼”å§ğŸ¤ª&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;1- è·å–æ•°æ®æºçš„ appKeyï¼š&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://opendata.sz.gov.cn/data/api/toApiDetails/29200_00403601&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;2- ä»£ç å¼€å‘ï¼š&lt;/h3&gt; &#xA;&lt;h4&gt;2.1- è°ƒç”¨ &lt;code&gt;cn.java666.etlspringboot.source.SZTData#saveData&lt;/code&gt; è·å–åŸå§‹æ•°æ®å­˜ç›˜ &lt;code&gt;/tmp/szt-data/szt-data-page.jsons&lt;/code&gt;ï¼Œæ ¸å¯¹æ•°æ®é‡ 1337ï¼Œæ³¨æ„è¿™é‡Œæ¯æ¡æ•°æ®åŒ…å«1000æ¡å­æ•°æ®ï¼›&lt;/h4&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.2- è°ƒç”¨ &lt;code&gt;cn.java666.etlflink.sink.RedisSinkPageJson#main&lt;/code&gt; å®ç° etl æ¸…æ´—ï¼Œå»é™¤é‡å¤æ•°æ®ï¼Œredis å¤©ç„¶å»é‡æ’åºï¼Œä¿è¯æ•°æ®å¹²å‡€æœ‰åºï¼Œè·‘å®Œåæ ¸å¯¹ redis æ•°æ®é‡ 1337ã€‚&lt;/h4&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.3- redis æŸ¥è¯¢ï¼Œredis-cli ç™»å½•åæ‰§è¡Œ &lt;code&gt;hget szt:pageJson 1&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;p&gt;æˆ–è€… dbeaver å¯è§†åŒ–æŸ¥è¯¢ï¼š&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/redis-szt-pageJson.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.4- &lt;code&gt;cn.java666.etlspringboot.EtlSApp#main&lt;/code&gt; å¯åŠ¨åï¼Œä¹Ÿå¯ä»¥ç”¨ knife4j åœ¨çº¿è°ƒè¯• REST APIï¼š&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/api-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/api-debug.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.5- &lt;code&gt;cn.java666.etlflink.source.MyRedisSourceFun#run&lt;/code&gt; æ¸…æ´—æ•°æ®å‘ç° 133.7 ä¸‡æ•°æ®ä¸­ï¼Œæœ‰å°éƒ¨åˆ†æºæ•°æ®å­—æ®µæ•°ä¸º9ï¼Œç¼ºå°‘ä¸¤ä¸ªå­—æ®µï¼šstationã€car_noï¼›ä¸¢å¼ƒè„æ•°æ®ã€‚&lt;/h4&gt; &#xA;&lt;p&gt;åˆæ ¼æºæ•°æ®ç¤ºä¾‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;&#x9;&#34;deal_date&#34;: &#34;2018-08-31 21:15:55&#34;,&#xA;&#x9;&#34;close_date&#34;: &#34;2018-09-01 00:00:00&#34;,&#xA;&#x9;&#34;card_no&#34;: &#34;CBHGDEEJB&#34;,&#xA;&#x9;&#34;deal_value&#34;: &#34;0&#34;,&#xA;&#x9;&#34;deal_type&#34;: &#34;åœ°é“å…¥ç«™&#34;,&#xA;&#x9;&#34;company_name&#34;: &#34;åœ°é“äº”å·çº¿&#34;,&#xA;&#x9;&#34;car_no&#34;: &#34;IGT-104&#34;,&#xA;&#x9;&#34;station&#34;: &#34;å¸ƒå‰&#34;,&#xA;&#x9;&#34;conn_mark&#34;: &#34;0&#34;,&#xA;&#x9;&#34;deal_money&#34;: &#34;0&#34;,&#xA;&#x9;&#34;equ_no&#34;: &#34;263032104&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ä¸åˆæ ¼çš„æºæ•°æ®ç¤ºä¾‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;&#x9;&#34;deal_date&#34;: &#34;2018-09-01 05:24:22&#34;,&#xA;&#x9;&#34;close_date&#34;: &#34;2018-09-01 00:00:00&#34;,&#xA;&#x9;&#34;card_no&#34;: &#34;HHAAABGEH&#34;,&#xA;&#x9;&#34;deal_value&#34;: &#34;0&#34;,&#xA;&#x9;&#34;deal_type&#34;: &#34;åœ°é“å…¥ç«™&#34;,&#xA;&#x9;&#34;company_name&#34;: &#34;åœ°é“ä¸€å·çº¿&#34;,&#xA;&#x9;&#34;conn_mark&#34;: &#34;0&#34;,&#xA;&#x9;&#34;deal_money&#34;: &#34;0&#34;,&#xA;&#x9;&#34;equ_no&#34;: &#34;268005140&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.6- &lt;code&gt;cn.java666.etlflink.app.Redis2Kafka#main&lt;/code&gt; æ ¹æ®éœ€æ±‚æ¨é€æ»¡è¶³ä¸šåŠ¡è¦æ±‚çš„æºæ•°æ®åˆ° kafkaï¼Œ&lt;code&gt;topic-flink-szt-all&lt;/code&gt; ä¿ç•™äº†æ‰€æœ‰æºæ•°æ® 1337000 æ¡ï¼Œ &lt;code&gt;topic-flink-szt&lt;/code&gt; ä»…åŒ…å«æ¸…æ´—åˆæ ¼çš„æºæ•°æ® 1266039 æ¡ã€‚&lt;/h4&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.7- kafka-eagle ç›‘æ§æŸ¥çœ‹ topicï¼ŒåŸºäºåŸç‰ˆå»æ‰äº†èƒŒæ™¯å›¾ï¼Œæ¼‚äº®å¤šäº†ï¼š&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/kafka-eagle02.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/kafka-eagle01.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ksql å‘½ä»¤æŸ¥è¯¢ï¼š &lt;code&gt;select * from &#34;topic-flink-szt&#34; where &#34;partition&#34; in (0) limit 1000&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/ksql.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.8- &lt;code&gt;cn.java666.etlflink.app.Redis2Csv#main&lt;/code&gt; å®ç°äº† flink sink csv æ ¼å¼æ–‡ä»¶ï¼Œå¹¶ä¸”æ”¯æŒæŒ‰å¤©åˆ†å—ä¿å­˜ã€‚&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/csv.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.9- &lt;code&gt;cn.java666.etlflink.app.Redis2ES#main&lt;/code&gt; å®ç°äº† ES å­˜å‚¨æºæ•°æ®ã€‚å®ç°å®æ—¶å…¨æ–‡æ£€ç´¢ï¼Œå®æ—¶è·Ÿè¸ªæ·±åœ³é€šåˆ·å¡æ•°æ®ã€‚&lt;/h4&gt; &#xA;&lt;p&gt;è¿™ä¸ªæ¨¡å—æ¶‰åŠæŠ€æœ¯ç»†èŠ‚æ¯”è¾ƒå¤šï¼Œå¦‚æœæ²¡æœ‰ ES ä½¿ç”¨ç»éªŒï¼Œå¯ä»¥å…ˆåšä¸‹åŠŸè¯¾ï¼Œä¸ç„¶çš„è¯ä¼šå¾ˆæ‡µã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘ä¹‹å‰åœ¨å¤„ç† ES å„ç§é—®é¢˜è¸©äº†ä¸å°‘å‘ï¼Œç†¬äº†ä¸å°‘é€šå®µï¼Œæ‰äº†å¾ˆå¤šå¤´å‘ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;é‡åˆ°é—®é¢˜å¿ƒæ€è¦ç¨³ï¼Œå› ä¸ºä½ ä»Šå¤©å¤„ç†äº†ä¸€ä¸ªé—®é¢˜ï¼Œæ˜å¤©æ¥è§¦æ–°çš„ç‰ˆæœ¬æ–°çš„æ¡†æ¶å¤§æ¦‚ç‡åˆä¼šå‡ºç°æ–°çš„é—®é¢˜&lt;/strong&gt;ã€‚ã€‚ğŸ¥ºğŸ¥ºğŸ¥º&lt;/p&gt; &#xA;&lt;p&gt;æ‰€ä»¥æœ€ä½³å®è·µå¾ˆé‡è¦ï¼ï¼ï¼&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;ğŸ‘‡ğŸ‘‡ğŸ‘‡è¿™éƒ¨åˆ†å†…å®¹æœ‰æ›´æ–°ï¼šä¿®æ­£äº†ä¸Šä¸€ä¸ªç‰ˆæœ¬æ—¶åŒºé—®é¢˜ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;ğŸ¬æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬æ—¶å…‰å€’æµï¼Œå›åˆ° 2018-09-01è¿™ä¸€å¤©ï¼Œè°ƒæ•´ kibana é¢æ¿æ—¶é—´èŒƒå›´ &lt;code&gt;2018-09-01 00:00:00.000~2018-09-01 23:59:59.999&lt;/code&gt;ï¼Œçœ‹çœ‹å½“å¤©æ·±åœ³é€šåˆ·å¡è®°å½•çš„ç»Ÿè®¡å›¾æ›²çº¿èµ°å‘æ˜¯å¦ç§‘å­¦ï¼Œé—´æ¥éªŒè¯æ•°æ®æºçš„å®Œæ•´æ€§ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä¿®æ­£æ—¶åŒºåç»Ÿè®¡æ•°é‡ï¼Œå­—æ®µå®Œæ•´çš„åˆæ ¼æºæ•°æ® 1266039 æ¡ï¼Œ2018-09-01å…¨å¤© 1229180 æ¡ã€‚&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/2018-09-01.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;å›¾ä¸­å¯ä»¥çœ‹å‡º 2018-09-01 è¿™ä¸€å¤©åˆ·å¡è®°å½•é›†ä¸­åœ¨ä¸Šåˆ6ç‚¹~12ç‚¹ä¹‹é—´ï¼Œæ—©é«˜å³°æ•°æ®æ¯”è¾ƒå»åˆï¼Œè™½ç„¶è¿™ä¸€å¤©æ˜¯å‘¨å…­ï¼Œé«˜å³°æœŸä¸æ˜¯ç‰¹åˆ«æ˜æ˜¾ã€‚æˆ‘ä»¬ç»§ç»­ç¼©æ”¾ kibana æ—¶é—´è½´çœ‹çœ‹æ›´è¯¦ç»†çš„æ›²çº¿ï¼š &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/2018-09-01-am.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;å›é¡¾ä¸€ä¸‹æœ¬é¡¹ç›® ETL å¤„ç†æµç¨‹ï¼š&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;1337000 æ¡æºæ•°æ®æ¸…æ´—å»é™¤å­—æ®µä¸å…¨çš„è„æ•°æ®ï¼Œå‰©ä½™çš„åˆæ ¼æ•°æ®æ¡æ•° 1266039 å·²ç»è¿›å…¥ ES ç´¢å¼• &lt;code&gt;szt-data&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;åœ¨ 1266039 æ¡åˆæ ¼æ•°æ®ä¸­ï¼Œæœ‰ 1227234 æ¡æ•°æ®é›†ä¸­åœ¨ 2018-09-01 è¿™ä¸€å¤©çš„ä¸Šåˆæ—¶æ®µï¼›&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;æˆ‘ä»¬æš‚ä¸”ç›¸ä¿¡ä¸Šåˆæ—¶æ®µçš„æ•°æ®æ˜¯çœŸå®çš„ï¼Œé‚£ä¹ˆæ˜¯å¦è¯´æ˜å®˜æ–¹æä¾›çš„æ•°æ®å¹¶ä¸æ˜¯å…¨éƒ¨çš„å½“å¤©å®Œæ•´åˆ·å¡æ•°æ®ï¼Ÿï¼Ÿï¼Ÿ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;å¦‚æœæŒ‰ç…§ä¸Šåˆçš„åˆ·å¡é‡æ¥ä¼°æµ‹å…¨å¤©çš„åˆ·å¡é‡ï¼Œè€ƒè™‘åˆ°æ˜¯å‘¨å…­ï¼Œé‚£ä¹ˆæ·±åœ³é€šå…¨å¤©çš„åˆ·å¡è®°å½•æ•°æ®åº”è¯¥åœ¨ 122ä¸‡ X 2 å·¦å³ï¼Œå½“ç„¶è¿™ä¹ˆæ­¦æ–­çš„åˆ¤æ–­æ–¹å¼ä¸æ˜¯ç¨‹åºå‘˜çš„é£æ ¼ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬ç”¨ç§‘å­¦çš„å¤§æ•°æ®åˆ†ææ–¹å¼æ¥ç ”ç©¶è¿™äº›æ•°æ®èƒŒåçš„æ„ä¹‰ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;æ³¨æ„ï¼ŒES å¤§å‘ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ES å­˜æ•°æ®æ—¶ï¼Œå¸¦æœ‰æ—¶é—´å­—æ®µçš„æ•°æ®å¦‚ä½•å®æ—¶å±•ç¤ºåˆ° kibana çš„å›¾è¡¨é¢æ¿ä¸Šï¼Ÿ&lt;br&gt; ğŸ¤£éœ€è¦åœ¨å­˜å…¥ index ä¹‹å‰è®¾ç½®å­—æ®µæ˜ å°„ã€‚å‚è€ƒæ ¼å¼ï¼Œä¸è¦ç…§æŠ„ï¼ï¼ï¼&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;properties&#34;: {&#xA;&#x9;&#34;deal_date&#34;: {&#xA;&#x9;  &#34;format&#34;: &#34;yyyy-MM-dd HH:mm:ss&#34;,&#xA;&#x9;  &#34;type&#34;: &#34;date&#34;&#xA;&#x9;}&#xA;  }&#xA;}  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è¿™é‡Œå¹¶æ²¡æœ‰æŒ‡å®šæ—¶åŒºä¿¡æ¯ï¼Œä½†æ˜¯ ES é»˜è®¤ä½¿ç”¨ 0 æ—¶åŒºï¼Œè¿™ä¸ªè½¯ä»¶å¾ˆå‘ï¼Œæ— æ³•è®¾ç½®å…¨å±€é»˜è®¤æ—¶åŒºã€‚ä½†æ˜¯å¾ˆå¤šè½¯ä»¶äº§ç”Ÿçš„æ•°æ®éƒ½æ˜¯é»˜è®¤æœºå™¨æ‰€åœ¨æ—¶åŒºï¼Œå›½å†…å°±æ˜¯ä¸œå…«åŒºã€‚å› ä¸ºæˆ‘ä»¬çš„æºå§‹æ•°æ®æœ¬èº«ä¹Ÿæ²¡æœ‰åŒ…å«æ—¶åŒºä¿¡æ¯ï¼Œè¿™é‡Œæˆ‘ä¸æƒ³æ”¹æºæ•°æ®ï¼Œé‚£å°±å‡è£…è‡ªå·±åœ¨ ES çš„ 0 æ—¶åŒºã€‚åŒæ—¶éœ€è¦ä¿®æ”¹ kibana é»˜è®¤æ—¶åŒºä¸º UTCï¼Œæ‰å¯ä»¥ä¿è¯ kibana ç´¢å¼•å›¾è¡¨æ—¶é—´è½´æ­£ç¡®å¯¹ä½ã€‚ä¸è¿‡è¿™å¹¶ä¸æ˜¯ä¸€ä¸ªç§‘å­¦çš„è§£å†³æ–¹æ¡ˆã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;å¦‚æœæ˜¯ä¼ä¸šé¡¹ç›®ï¼Œå¿…é¡»è¦ç”¨æ•°æ®è´¨é‡ç›‘æ§è½¯ä»¶ï¼ï¼ï¼è¦ä¸ç„¶å¾—æœ‰å¤šå°‘èƒŒé”…ä¾ è¦æ€å»ç¥­å¤©ğŸ˜‚ğŸ˜‚ğŸ˜‚ï¼Œæ•°æ®å¯ä»¥æ²¡æœ‰ä½†æ˜¯åƒä¸‡ä¸èƒ½é”™ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ES å­˜æ•°æ®æ—¶ï¼Œéœ€è¦ä½¿ç”¨ json æ ¼å¼åŒ…è£…æ•°æ®ï¼Œä¸ç¬¦åˆjson è¯­æ³•çš„çº¯å­—ç¬¦æ— æ³•ä¿å­˜ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ES åºåˆ—åŒ–å¤æ‚çš„ bean å¯¹è±¡æ—¶ï¼Œå¦‚æœ fastjson æŠ¥é”™ï¼Œæ¨èä½¿ç”¨ Gsonï¼Œå¾ˆå¼ºï¼&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;TIPSğŸ˜™ğŸ˜™ğŸ˜™ï¼š&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Gson ç›¸æ¯” fastjsonï¼šGson åºåˆ—åŒ–èƒ½åŠ›æ›´å¼ºï¼Œä½†æ˜¯ ååºåˆ—åŒ–æ—¶ï¼Œfastjson é€Ÿåº¦æ›´å¿«ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.10- æŸ¥çœ‹ ES æ•°æ®åº“å¡å·ï¼Œå¯¹æ¯”è‡ªå·±çš„æ·±åœ³é€šåœ°é“å¡ï¼Œé€æ¸å‘ç°äº†ä¸€äº›è„±æ•è§„å¾‹ã€‚&lt;/h4&gt; &#xA;&lt;p&gt;æ—¥å¿—å½“ä¸­å¡å·è„±æ•å­—æ®µå¯†æ–‡åè§£çŒœæƒ³ï¼š&lt;br&gt; ç”±è„±æ•çš„å¯†æ–‡å¡å·åæ¨çœŸå®å¡å·ï¼Œå› ä¸ºæ‰€æœ‰å¡å·å¯†æ–‡å½“ä¸­æ²¡æœ‰Jå¼€å¤´çš„æ•°æ®ï¼Œ ä½†æ˜¯æœ‰Aå¼€å¤´çš„æ•°æ®ï¼ŒA != 0ï¼Œè€Œä¸”å‡ºç°äº† BCDEFGHIJ æ²¡æœ‰ Kï¼Œæ‰€ä»¥çŒœæƒ³å¡å·æ˜ å°„å…³ç³»å¦‚å›¾ï¼ï¼ï¼&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/parse_card_no.png&#34; alt=&#34;&#34;&gt;&lt;br&gt; ç±»ä¼¼æ‘©æ–¯ç”µç è§£å¯†ã€‚ã€‚ã€‚æˆ‘ç°åœ¨è¿˜ä¸ç¡®å®šè¿™ä¸ªè§£å¯†æ–¹å¼æ˜¯å¦æ­£ç¡®ğŸ™„ğŸ™„ğŸ™„&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;2.11- &lt;code&gt;cn.java666.sztcommon.util.ParseCardNo#parse&lt;/code&gt; å®ç°äº†æ”¯æŒè‡ªåŠ¨è¯†åˆ«å¡å·æ˜æ–‡å’Œå¯†æ–‡ã€ä¸€é”®äº’è½¬åŠŸèƒ½ã€‚ &lt;code&gt;cn.java666.etlspringboot.controller.CardController#get&lt;/code&gt; å®ç°äº†å¡å·æ˜æ–‡å’Œå¯†æ–‡äº’è½¬ REST APIã€‚&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/parse_no.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;3- æ­å»ºæ•°ä»“ï¼šæ·±åœ³åœ°é“æ•°ä»“å»ºæ¨¡&lt;/h3&gt; &#xA;&lt;h4&gt;3.1- ç¬¬ä¸€æ­¥ï¼Œåˆ†æä¸šåŠ¡&lt;/h4&gt; &#xA;&lt;p&gt;ç¡®å®šä¸šåŠ¡æµç¨‹ ---&amp;gt; å£°æ˜ç²’åº¦ ---&amp;gt; ç¡®å®šç»´åº¦ ---&amp;gt; ç¡®å®šäº‹å®&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.doc/dim.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;3.2- ç¬¬äºŒæ­¥ï¼Œè§„åˆ’æ•°ä»“ç»“æ„&lt;/h4&gt; &#xA;&lt;p&gt;å‚è€ƒè¡Œä¸šé€šç”¨çš„æ•°ä»“åˆ†å±‚æ¨¡å¼ï¼šODSã€DWDã€DWSã€ADSï¼Œè™½ç„¶åŸå§‹æ•°æ®å¾ˆç®€å•ï¼Œä½†æ˜¯æˆ‘ä»¬ä¾ç„¶ä½¿ç”¨è§„èŒƒçš„æµç¨‹è®¾è®¡æ•°æ®ä»“åº“ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ç¬¬ä¸€å±‚ï¼šODS åŸå§‹æ•°æ®å±‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;ods/ods_szt_data/day=2018-09-01/   &#xA;# szt_szt_page/day=2018-09-01/  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ç¬¬äºŒå±‚ï¼šDWD æ¸…æ´—é™ç»´å±‚&lt;br&gt; åŒºåˆ†ç»´è¡¨ dim_ å’Œäº‹å®è¡¨ fact_ï¼Œä¸ºäº†ä½¿ç²’åº¦æ›´åŠ ç»†åŒ–ï¼Œæˆ‘ä»¬æŠŠè¿›ç«™å’Œå‡ºç«™è®°å½•åˆ†å¼€ï¼Œå·´å£«æ•°æ®æš‚ä¸è€ƒè™‘ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;dwd_fact_szt_in_detail      è¿›ç«™äº‹å®è¯¦æƒ…è¡¨&#xA;dwd_fact_szt_out_detail     å‡ºç«™äº‹å®è¯¦æƒ…è¡¨&#xA;dwd_fact_szt_in_out_detail  åœ°é“è¿›å‡ºç«™æ€»è¡¨&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ç¬¬ä¸‰å±‚ï¼šDWS å®½è¡¨å±‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;dws_card_record_day_wide  æ¯å¡æ¯æ—¥è¡Œç¨‹è®°å½•å®½è¡¨ã€å•å¡å•æ—¥æ‰€æœ‰å‡ºè¡Œè®°å½•ã€‘&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ç¬¬å››å±‚ï¼šADS ä¸šåŠ¡æŒ‡æ ‡å±‚ã€å¾…è¡¥å……ã€‘&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;ã€ä½“ç°è¿›ç«™å‹åŠ›ã€‘ æ¯ç«™è¿›ç«™äººæ¬¡æ’è¡Œæ¦œ      &#xA;&#x9;ads_in_station_day_top&#xA;ã€ä½“ç°å‡ºç«™å‹åŠ›ã€‘ æ¯ç«™å‡ºç«™äººæ¬¡æ’è¡Œæ¦œ      &#xA;&#x9;ads_out_station_day_top&#xA;ã€ä½“ç°è¿›å‡ºç«™å‹åŠ›ã€‘ æ¯ç«™è¿›å‡ºç«™äººæ¬¡æ’è¡Œæ¦œ      &#xA;&#x9;ads_in_out_station_day_top&#xA;ã€ä½“ç°é€šå‹¤è½¦è´¹æœ€å¤šã€‘ æ¯å¡æ—¥æ¶ˆè´¹æ’è¡Œ      &#xA;&#x9;ads_card_deal_day_top  &#xA;ã€ä½“ç°çº¿è·¯è¿è¾“è´¡çŒ®åº¦ã€‘ æ¯çº¿è·¯å•æ—¥è¿è¾“ä¹˜å®¢æ€»æ¬¡æ•°æ’è¡Œæ¦œï¼Œè¿›ç«™ç®—ä¸€æ¬¡ï¼Œå‡ºç«™å¹¶ä¸”è”ç¨‹ç®—ä¸€æ¬¡     &#xA;&#x9;ads_line_send_passengers_day_top  &#xA;ã€ä½“ç°åˆ©ç”¨ç‡æœ€é«˜çš„è½¦ç«™åŒºé—´ã€‘ æ¯æ—¥è¿è¾“ä¹˜å®¢æœ€å¤šçš„è½¦ç«™åŒºé—´æ’è¡Œæ¦œ       &#xA;&#x9;ads_stations_send_passengers_day_top&#xA;ã€ä½“ç°çº¿è·¯çš„å¹³å‡é€šå‹¤æ—¶é—´ï¼Œè¿è¾“æ•ˆç‡ã€‘ æ¯æ¡çº¿è·¯å•ç¨‹ç›´è¾¾ä¹˜å®¢è€—æ—¶å¹³å‡å€¼æ’è¡Œæ¦œ     &#xA;&#x9;ads_line_single_ride_average_time_day_top&#xA;ã€ä½“ç°æ·±åœ³åœ°é“å…¨å¸‚ä¹˜å®¢å¹³å‡é€šå‹¤æ—¶é—´ã€‘ æ‰€æœ‰ä¹˜å®¢ä»ä¸Šè½¦åˆ°ä¸‹è½¦é—´éš”æ—¶é—´å¹³å‡å€¼    &#xA;&#x9;ads_all_passengers_single_ride_spend_time_average&#xA;ã€ä½“ç°é€šå‹¤æ—¶é—´æœ€é•¿çš„ä¹˜å®¢ã€‘ å•æ—¥ä»ä¸Šè½¦åˆ°ä¸‹è½¦é—´éš”æ—¶é—´æ’è¡Œæ¦œ     &#xA;&#x9;ads_passenger_spend_time_day_top&#xA;ã€ä½“ç°è½¦ç«™é…ç½®ã€‘ æ¯ä¸ªç«™ç‚¹è¿›å‡ºç«™é—¸æœºæ•°é‡æ’è¡Œæ¦œ&#xA;&#x9;æ¯ä¸ªç«™ç‚¹å…¥ç«™é—¸æœºæ•°é‡  &#x9;&#x9;ads_station_in_equ_num_top&#xA;&#x9;æ¯ä¸ªç«™ç‚¹å‡ºç«™é—¸æœºæ•°é‡    &#x9;&#x9;ads_station_out_equ_num_top&#xA;ã€ä½“ç°å„çº¿è·¯ç»¼åˆæœåŠ¡æ°´å¹³ã€‘ å„çº¿è·¯è¿›å‡ºç«™é—¸æœºæ•°æ’è¡Œæ¦œ&#xA;&#x9;å„çº¿è·¯è¿›ç«™é—¸æœºæ•°æ’è¡Œæ¦œ &#x9;&#x9;ads_line_in_equ_num_top.png&#xA;&#x9;å„çº¿è·¯å‡ºç«™é—¸æœºæ•°æ’è¡Œæ¦œ &#x9;&#x9;ads_line_out_equ_num_top&#xA;ã€ä½“ç°æ”¶å…¥æœ€å¤šçš„è½¦ç«™ã€‘ å‡ºç«™äº¤æ˜“æ”¶å…¥æ’è¡Œæ¦œ   &#xA;&#x9;ads_station_deal_day_top&#xA;ã€ä½“ç°æ”¶å…¥æœ€å¤šçš„çº¿è·¯ã€‘ å‡ºç«™äº¤æ˜“æ‰€åœ¨çº¿è·¯æ”¶å…¥æ’è¡Œæ¦œ   &#xA;&#x9;ads_line_deal_day_top&#xA;ã€ä½“ç°æ¢ä¹˜æ¯”ä¾‹ã€ä¹˜è½¦ä½“éªŒã€‘ æ¯å¤©æ¯çº¿è·¯æ¢ä¹˜å‡ºç«™ä¹˜å®¢ç™¾åˆ†æ¯”æ’è¡Œæ¦œ  &#xA;&#x9;ads_conn_ratio_day_top&#xA;ã€ä½“ç°æ¯æ¡çº¿çš„æ·±åœ³é€šä¹˜è½¦å¡æ™®åŠç¨‹åº¦ 9.5 æŠ˜ä¼˜æƒ ã€‘ å‡ºç«™äº¤æ˜“ä¼˜æƒ äººæ•°ç™¾åˆ†æ¯”æ’è¡Œæ¦œ     &#xA;&#x9;ads_line_sale_ratio_top&#xA;ã€ä½“ç°æ¢ä¹˜çš„å¿ƒé…¸ã€‘ æ¢ä¹˜è€—æ—¶æœ€ä¹…çš„ä¹˜å®¢æ’è¡Œæ¦œ&#x9;&#xA;&#x9;ads_conn_spend_time_top&#xA;ã€ä½“ç°çº¿è·¯æ‹¥æŒ¤ç¨‹åº¦ã€‘ ä¸Šè½¦ä»¥åè¿˜æ²¡ä¸‹è½¦ï¼Œæ¯åˆ†é’Ÿã€å°æ—¶æ¯æ¡çº¿åœ¨çº¿äººæ•°   &#xA;&#x9;ads_on_line_min_top&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;3.3- ç¬¬ä¸‰æ­¥ï¼šå»ºåº“å»ºè¡¨è®¡ç®—æŒ‡æ ‡&lt;/h4&gt; &#xA;&lt;p&gt;hdfs å…³é—­æƒé™æ£€æŸ¥ã€‚hive è®¾ç½®ä¿å­˜ç›®å½• /warehouseï¼›&lt;br&gt; hue åˆ›å»º hue ç”¨æˆ·ï¼Œèµ‹äºˆè¶…çº§ç»„ã€‚hue åˆ‡æ¢åˆ° hue ç”¨æˆ·ï¼Œæ‰§è¡Œ hive sql å»ºåº“ sztï¼›&lt;br&gt; åº“ä¸‹é¢å»ºç›®å½• ods dwd dws adsï¼›&lt;/p&gt; &#xA;&lt;p&gt;ä¸Šä¼ åŸå§‹æ•°æ®åˆ° /warehouse/szt.db/ods/&lt;br&gt; szt-etl-data.csv szt-etl-data_2018-09-01.csv szt-page.jsons&lt;/p&gt; &#xA;&lt;p&gt;æŸ¥çœ‹ï¼š &lt;code&gt;hdfs dfs -ls -h hdfs://cdh231:8020/warehouse/szt.db/ods/&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;æ¥ä¸‹æ¥ä½¿ç”¨ HUE æŒ‰ç…§ &lt;code&gt;sql/hive.sql&lt;/code&gt; ä¾æ¬¡æ‰§è¡Œ HQL è¯­å¥.....&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ä¹Ÿå¯ä»¥ä½¿ç”¨ IDEA Database å·¥å…·æ æ“ä½œï¼Œé™„é€idea cdh hive å®Œç¾é©±åŠ¨ &lt;a href=&#34;https://github.com/timveil/hive-jdbc-uber-jar/releases&#34;&gt;https://github.com/timveil/hive-jdbc-uber-jar/releases&lt;/a&gt;ï¼š&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/idea-dev+hive.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ä¹Ÿå¯ä»¥ä½¿ç”¨ DBeaver ï¼ˆæˆ‘åªæƒ³è¯´ï¼Œ ä¸Šå¤äº§å“ Sqlyogã€navicatã€heidisqlã€workbench å…¨éƒ½æ˜¯æˆ˜äº”æ¸£ï¼‰ï¼Œå› ä¸ºæœ‰æ—¶å€™å¤æ‚çš„æŸ¥è¯¢å¯ä»¥ä¸€è¾¹æ‰§è¡Œä¸€è¾¹åœ¨å¦ä¸€ä¸ªå®¢æˆ·ç«¯å·¥å…·æŸ¥çœ‹ç»“æœï¼Œè¿™å¯¹äºå¤æ‚çš„åµŒå¥—æŸ¥è¯¢ debug éå¸¸æœ‰åŠ©äºåˆ†æå’Œè·Ÿè¸ªé—®é¢˜ã€‚DBeaver å®¢æˆ·ç«¯è‡ªå¸¦å›¾è¡¨ï¼Œä¸è¿‡æ²¡æœ‰ HUE å¥½çœ‹ï¼š&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/dbeaver-dev+hive.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;å·²ç»å®Œæˆçš„æŒ‡æ ‡åˆ†æï¼š&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.1 - æ·±åœ³åœ°é“è¿›ç«™äººæ¬¡æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©ä¾æ¬¡ä¸ºï¼šäº”å’Œã€å¸ƒå‰ã€ä¸¹ç«¹å¤´ï¼Œæ•°æ®è¯´æ˜å½“å¤©è¿™å‡ ä¸ªç«™ç‚¹è¿›ç«™äººæ•°æœ€å¤šã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_in_station_day_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_in_station_day_top2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.2 - æ·±åœ³åœ°é“å‡ºç«™äººæ¬¡æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©å‡ºç«™ä¹˜å®¢ä¸»è¦å»å‘åˆ†åˆ«ä¸ºï¼šæ·±åœ³åŒ—é«˜é“ç«™ã€ç½—æ¹–ç«è½¦ç«™ã€ç¦ç”°å£å²¸ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_out_station_day_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_out_station_day_top2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.3- æ·±åœ³åœ°é“è¿›å‡ºç«™æ€»äººæ¬¡æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©è½¦ç«™ååé‡æ’è¡Œæ¦œï¼š&lt;br&gt; äº”å’Œç«™ï¼Ÿï¼Ÿï¼Ÿã€å¸ƒå‰ç«™ï¼ˆæ·±åœ³ä¸œç«è½¦ç«™ï¼‰ã€ç½—æ¹–ç«™ï¼ˆæ·±åœ³ç«è½¦ç«™ï¼‰ã€æ·±åœ³åŒ—ï¼ˆæ·±åœ³åŒ—é«˜é“ç«™ï¼‰ã€‚ã€‚ã€‚&lt;br&gt; äº”å’Œç«™ä¸ºä»€ä¹ˆè¿™ä¹ˆç§€ï¼Ÿï¼Ÿï¼Ÿ ğŸš€&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_in_out_station_day_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.4- æ·±åœ³åœ°é“ä¹˜å®¢è½¦è´¹æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©è½¦è´¹æœ€é«˜çš„ä¹˜å®¢èŠ±äº† 48 å…ƒäººæ°‘å¸&lt;br&gt; ğŸš„ğŸš„ğŸš„ è¯´æ˜ï¼šæ·±åœ³é€šåœ°é“å¡ä¸è®°åï¼Œæœªæ¶‰åŠä¸ªäººéšç§ï¼ï¼ï¼&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_card_deal_day_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.5- æ·±åœ³åœ°é“å„çº¿è·¯å•æ—¥å‘é€æ—…å®¢æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©äº”å·çº¿å®¢è¿é‡é¥é¥é¢†å…ˆï¼Œé¾™å²—çº¿ç¢¾å‹ä¸€å·çº¿ï¼Œå¿ƒç–¼é¾™å²—äººæ°‘ï¼ğŸ˜³&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_line_send_passengers_day_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.6- æ·±åœ³åœ°é“æ¯æ—¥è¿è¾“ä¹˜å®¢æœ€å¤šçš„åŒºé—´æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01å½“å¤©å‰ä¸‰ååˆ†åˆ«æ˜¯ï¼šèµ¤å°¾&amp;gt;åå¼ºåŒ—ï¼Œç¦æ°‘&amp;gt;ç¦ç”°å£å²¸ï¼Œäº”å’Œ&amp;gt;æ·±åœ³åŒ—&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_stations_send.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.7- æ·±åœ³åœ°é“æ¯æ¡çº¿è·¯å•ç¨‹ç›´è¾¾ä¹˜å®¢è€—æ—¶å¹³å‡å€¼æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©äº”å·çº¿å•ç¨‹ç›´è¾¾ä¹˜å®¢å¹³å‡è€—æ—¶1500sï¼Œçº¦åˆ25åˆ†é’Ÿï¼Œå¹³å‡å€¼æœ€é•¿çš„æ˜¯ 11å·çº¿ï¼Œå¹³å‡è€—æ—¶ 40 åˆ†é’Ÿ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_line_single_ride_average_time_day_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.8- æ·±åœ³åœ°é“æ‰€æœ‰ä¹˜å®¢é€šå‹¤æ—¶é—´å¹³å‡å€¼ï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©æ‰€æœ‰ä¹˜å®¢é€šå‹¤æ—¶é—´å¹³å‡å€¼ 1791 sï¼Œçº¦åˆ 30 åˆ†é’Ÿ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_all_passengers_single_ride_spend_time_average.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.9- æ·±åœ³åœ°é“æ‰€æœ‰ä¹˜å®¢é€šå‹¤æ—¶é—´æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©æ‰€æœ‰ä¹˜å®¢é€šå‹¤æ—¶é—´æ’è¡Œæ¦œï¼Œç«™å†…æ»ç•™æœ€ä¹…çš„ä¹˜å®¢é—´éš” 17123 ç§’ï¼Œçº¦åˆ 4.75 å°æ—¶ï¼Œå®é™…æƒ…å†µåªéœ€è¦ 20 åˆ†é’Ÿè½¦ç¨‹ï¼Œéš¾é“æ˜¯è¿›ç«™æäº‹æƒ…ï¼Ÿï¼Ÿï¼Ÿ&lt;/strong&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/kibana-search-card-1.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/baiduMap1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_passenger_spend_time_day_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.10- æ·±åœ³åœ°é“æ¯ä¸ªç«™ç‚¹è¿›å‡ºç«™é—¸æœºæ•°é‡æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©ç¦ç”°ç«™åŒé¡¹ç¬¬ä¸€&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_station_in_equ_num_top.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_station_out_equ_num_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.11- æ·±åœ³åœ°é“å„çº¿è·¯è¿›å‡ºç«™é—¸æœºæ•°é‡æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©æ·±åœ³åœ°é“ä¸€å·çº¿é•¿è„¸äº†@_@ï¼Œä¸¤ä¸ªæŒ‡æ ‡éƒ½æ˜¯ç¬¬ä¸€ï¼Œæ¸¯é“å››å·çº¿å…¨éƒ¨å«åº•ï¼Œåå¦ˆå…»çš„ï¼Ÿï¼Ÿï¼Ÿ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_line_in_equ_num_top.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_line_out_equ_num_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.12- æ·±åœ³åœ°é“å„ç«™æ”¶å…¥æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œå½“å¤©ä¸Šåˆæ·±åœ³åŒ—ç«™æ”¶å…¥ 4 ä¸‡å…ƒäººæ°‘å¸ï¼Œæ’åç¬¬ä¸€&lt;/strong&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_station_deal_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.12- æ·±åœ³åœ°é“å„çº¿è·¯æ”¶å…¥æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;2018-09-01ï¼Œæ•°æ®æ˜¾ç¤ºä¸€å·çº¿ä¾ç„¶æ˜¯æ·±åœ³åœ°é“æœ€å¤šæ”¶å…¥çš„çº¿è·¯ï¼Œ1å·çº¿ä¸Šåˆæ”¶å…¥ 30 ä¸‡å…ƒäººæ°‘å¸ï¼Œå…¶æ¬¡æ˜¯äº”å·çº¿ç´§éšå…¶å&lt;/strong&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_line_deal_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.13- æ·±åœ³åœ°é“å„çº¿è·¯æ¢ä¹˜å‡ºç«™ä¹˜å®¢ç™¾åˆ†æ¯”æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;æ¢ä¹˜åä»äº”å·çº¿å‡ºæ¥çš„ä¹˜å®¢æ˜¯å æ¯”æœ€é«˜çš„ 15.6%ï¼Œä»ä¹å·çº¿å‡ºç«™çš„ä¹˜å®¢ï¼Œæ¢ä¹˜æ¯”ä¾‹æœ€ä½ï¼Œä»… 9.42%&lt;/strong&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_conn_ratio_day_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.14- æ·±åœ³åœ°é“å„çº¿è·¯ç›´è¾¾ä¹˜å®¢ä¼˜æƒ äººæ¬¡ç™¾åˆ†æ¯”æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;ç›®å‰å¯ä»¥ç¡®å®šçš„æ˜¯ï¼ŒæŒæœ‰æ·±åœ³é€šåœ°é“å¡å¯ä»¥äº«å—9.5æŠ˜ä¼˜æƒ ä¹˜ååœ°é“ï¼Œä»ç»Ÿè®¡ç»“æœçœ‹ï¼Œ2018-09-01å½“å¤©ï¼Œä¸ƒå·çº¿ä½¿ç”¨åœ°é“å¡ä¼˜æƒ çš„ä¹˜å®¢äººæ¬¡å æ¯”æœ€é«˜ï¼Œè¾¾åˆ° 90.36%ï¼Œæ’åæœ€ä½çš„æ˜¯äº”å·çº¿ï¼Œå æ¯” 84.3%&lt;/strong&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_line_sale_ratio_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h5&gt;3.3.15- æ·±åœ³åœ°é“æ¢ä¹˜æ—¶é—´æœ€ä¹…çš„ä¹˜å®¢æ’è¡Œæ¦œï¼š&lt;/h5&gt; &#xA;&lt;p&gt;&lt;strong&gt;ç»Ÿè®¡è¿‡ç¨‹å‘ç°éš¾ä»¥ç†è§£çš„ç°è±¡ï¼Œæœ‰å‡ ä¸ªä¹˜å®¢è¿›ç«™ä»¥åï¼Œæ²¡æœ‰åˆ·å¡å‡ºç«™å°±æ¢ä¹˜äº†å…¬äº¤è½¦ï¼Œäºæ˜¯å‡ºç°äº†åŒä¸€ä¸ªåœ°é“ç«™è¿›å‡ºç«™ï¼Œä½†æ˜¯æ ‡è®°ä¸ºè”ç¨‹çš„è®°å½•&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/WTF.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/.ads/ads_conn_spend_time_top.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;4- æ–°å¢æ¨¡å—ï¼šSZT-kafka-hbase&lt;/h3&gt; &#xA;&lt;p&gt;SZT-kafka-hbase project for Spring Boot2&lt;br&gt; çœ‹è¿‡å¼€æºçš„ spring-boot-starter-hbaseã€spring-data-hadoop-hbaseï¼ŒåŸºç¡€ä¾èµ–è¿‡äºè€æ—§ï¼Œé•¿æœŸä¸æ›´æ–°ï¼›å¼•å…¥è¿‡ç¨‹ç¹çï¼Œè€Œä¸” API ç²’åº¦å—é™ï¼›æ•°æ®åº“è¿æ¥æ²¡æœ‰å¤ç”¨ï¼Œå¯¼è‡´æ•°æ®åº“æœåŠ¡è¯»å†™æˆæœ¬å¤ªé«˜ã€‚&lt;/p&gt; &#xA;&lt;p&gt;äºæ˜¯è‡ªå·±å®ç°äº† hbase-2.1 + springboot-2.1.13 + kafka-2.0 çš„é›†æˆï¼Œä¸€ä¸ªé•¿ä¼šè¯å®Œæˆ hbase è¿ç»­çš„å¢åˆ æ”¹æŸ¥ğŸ‘‘ğŸ‘‘ğŸ‘‘ï¼Œé™ä½æœåŠ¡å™¨èµ„æºçš„å¼€é”€ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/SZT-kafka-hbase/.pic/hbase666.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä¸»è¦ç‰¹è‰²ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;knife4j åœ¨çº¿è°ƒè¯•ï¼Œç‚¹å‡»é¼ æ ‡å³å¯å®Œæˆ hbase å†™å…¥å’ŒæŸ¥è¯¢ï¼Œå†ä¹Ÿä¸ç”¨è®°ä½ç¹ççš„å‘½ä»¤ğŸ˜ğŸ˜ğŸ˜ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;hbase åˆ—æ—ç‰ˆæœ¬å†å²è®¾ç½®ä¸º 10ï¼Œæ”¯æŒé…ç½®æ–‡ä»¶çº§åˆ«çš„ä¿®æ”¹ã€‚å¯ä»¥æŸ¥è¯¢æŸå¡å·æœ€è¿‘ 10 æ¬¡äº¤æ˜“è®°å½•ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;hbase rowkey è®¾è®¡ä¸ºå¡å·åè½¬ï¼Œä½¿å¾—å­—å…¸æ’åºè¿‡ç¨‹æ¶ˆè€—çš„æœåŠ¡å™¨ç®—åŠ›åœ¨åˆ†å¸ƒå¼ç¯å¢ƒæ›´åŠ å‡è¡¡ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å…¨è‡ªåŠ¨çš„å»ºåº“å»ºè¡¨ã€æœ¬é¡¹ç›®çš„ hbase å‘½åç©ºé—´ä¸º sztã€‘ï¼Œå®ç°å¹‚ç­‰æ“ä½œï¼Œæ— éœ€æ‹…å¿ƒ hbase æ•°æ®åº“çš„æ±¡æŸ“ã€‚&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æ•ˆæœå±•ç¤ºï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å‡†å¤‡éƒ¨ç½²å®Œæˆçš„ hbaseï¼Œé€‚å½“ä¿®æ”¹æœ¬é¡¹ç›®é…ç½®æ–‡ä»¶ï¼Œè¿è¡Œ SZT-kafka-hbase é¡¹ç›®ï¼Œæ•ˆæœå¦‚ä¸‹ï¼š&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;å¯åŠ¨ï¼š&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/SZT-kafka-hbase/.pic/hbase-run.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;api-debugï¼Œéšä¾¿å†™ç‚¹ä¸œè¥¿è¿›å»ï¼Œç‹‚ç‚¹å‘é€ã€‚èƒ½å†™å¤šå¿«å°±è€ƒéªŒä½ çš„æ‰‹é€Ÿäº†ğŸ˜ğŸ˜ğŸ˜ï¼š&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/SZT-kafka-hbase/.pic/hbase-api-debug.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;hue-hbase æŸ¥è¡¨ï¼š&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/SZT-kafka-hbase/.pic/hue-hbase-szt.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;hue-hbase æŸ¥çœ‹å†å²ç‰ˆæœ¬ï¼š&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/SZT-kafka-hbase/.pic/hue-hbase-szt-versions-10.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;hbase-shell å‘½ä»¤ï¼š&lt;br&gt; å…¨è¡¨æ‰«æï¼Œè¿”å›åä¸ªç‰ˆæœ¬æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²æ˜¾ç¤ºï¼Œå‹æ¦¨æœåŠ¡å™¨æ€§èƒ½çš„æ—¶å€™åˆ°å•¦ï¼ï¼ï¼ğŸ˜ğŸ˜ğŸ˜&lt;br&gt; &lt;code&gt;scan &#39;szt:data&#39;, {FORMATTER =&amp;gt; &#39;toString&#39;,VERSIONS=&amp;gt;10}&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/SZT-kafka-hbase/.pic/hbase-shell-toString.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ¥ä¸‹æ¥æ¥å…¥ kafka ğŸ¯ğŸ¯ğŸ¯&lt;br&gt; å¯åŠ¨ &lt;code&gt;cn.java666.etlflink.app.Redis2Kafka&lt;/code&gt;ï¼Œç”Ÿäº§æ¶ˆæ¯ï¼Œé€‚å½“è°ƒæ…¢ç”Ÿäº§é€Ÿåº¦ï¼Œä»¥å…æœºå™¨å´©æºƒã€‚&lt;br&gt; ä¸å‡ºæ„å¤–çš„è¯ï¼Œä½ ä¼šçœ‹åˆ° SZT-kafka-hbase é¡¹ç›®çš„æ§åˆ¶å°æ‰“å°äº†æ—¥å¿—ï¼š&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/kafka2hbase.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;å¦‚æœ hbase å´©æºƒäº†ï¼Œçœ‹çœ‹å†…å­˜å¤Ÿä¸å¤Ÿï¼Œæˆ‘å°±ç›´æ¥æ€¼ä¸Š 2GB X 3 ä¸ªèŠ‚ç‚¹ğŸŒŸğŸŒŸğŸŒŸï¼š&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/SZT-kafka-hbase/.pic/hbase-2GB.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;5- &lt;code&gt;SZT-flink&lt;/code&gt; æ¨¡å—æ–°å¢ &lt;code&gt;cn.java666.etlflink.app.Json2HBase&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;å®ç°äº†ä» redis æˆ–è€…å…¶ä»–æ•°æ®æºå–å‡º json ä¸²ï¼Œä¿å­˜åˆ° hbase è¡¨ã€‚æœ¬é¡¹ç›®ä¸­ä» redis è·å– jsonï¼ˆå½“ç„¶æ›´æ¨è kafkaï¼‰ï¼Œé€šè¿‡ flink æ¸…æ´—å­˜åˆ° hbase flink:flink2hbase è¡¨ä¸­ã€‚ç”¨äºå®æ—¶ä¿å­˜æ·±åœ³é€šåˆ·å¡è®°å½•ï¼Œé€šè¿‡å¡å·æŸ¥è¯¢å¯ä»¥è·å–å¡å·æœ€è¿‘10æ¬¡ï¼ˆå¦‚æœæœ‰10æ¬¡ï¼‰äº¤æ˜“è®°å½•ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/flink2hbase.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ç®€åŒ–äº†ä¸Šä¸€ç‰ˆ hbase å†™å…¥ bean çš„æ–¹å¼ï¼ŒJSON å†ä¸€æ¬¡èµ¢å¾—æŒå£°ğŸ˜ğŸ˜ğŸ˜ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val keys = jsonObj.keySet().toList&#xA;val size = keys.size()&#xA;&#xA;for (i &amp;lt;- 0 until size) {&#xA;&#x9;val key = keys.get(i)&#xA;&#x9;val value = jsonObj.getStr(key)&#xA;&#x9;putCell(card_no_re, cf, key, value)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;6- æ–°å¢å®æ—¶å¤„ç†æ¨¡å— SZT-flink&lt;/h3&gt; &#xA;&lt;p&gt;å®Œæˆ flink è¯»å– kafkaï¼Œå­˜åˆ° clickhouse åŠŸèƒ½ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/clickhouse-tabix.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/clickhouse-sql.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;...ç»§ç»­å¼€å‘ä¸­ğŸ› ğŸ› ğŸ› ...&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;TODOğŸ””ğŸ””ğŸ””:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; è§£æ redis pageJsonï¼Œè½¬æ¢æ•°æ®æ ¼å¼ä¸ºæœ€å°æ•°æ®å•å…ƒå­˜åˆ° csvï¼Œå‡å°‘åŸå§‹æ•°æ®çš„å†—ä½™å­—ç¬¦ï¼Œæ–¹ä¾¿å­˜å–å’Œä¼ è¾“ã€‚ä¸°å¯Œæ•°æ®æºçš„æ ¼å¼ï¼Œå…¼å®¹æ›´å¤šçš„å®ç°æ–¹æ¡ˆï¼›&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; æ¨é€ kafkaï¼Œä½¿ç”¨é˜Ÿåˆ—ä¼ è¾“æ•°æ®ï¼›&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; å­˜å…¥ elasticsearchï¼Œä½¿ç”¨å…¨æ–‡æ£€ç´¢å®ç°å®æ—¶æœç´¢ï¼Œkibana å¯è§†åŒ–å±•ç¤ºï¼›&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; æ•°ä»“å»ºæ¨¡ï¼šODSã€DWDã€DWSã€ADS&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; hive on spark æ•°ä»“å»ºæ¨¡ã€åˆ†æè®¡ç®—ï¼›&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; spark on hiveï¼Œæœ¬åœ°å¼€å‘ spark ç¨‹åºï¼Œæ“ä½œè¿œç¨‹ hive æ•°æ®åº“ï¼›&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; åˆ·å¡è®°å½•å®æ—¶å†™å…¥ hbaseï¼Œæ”¯æŒæœ€è¿‘äº¤æ˜“è®°å½•çš„æŸ¥è¯¢ï¼›&lt;/li&gt; &#xA; &lt;li&gt;[-] &lt;del&gt;oozie è°ƒåº¦ï¼Œæ•°æ®å¤ªå°‘å•Š å˜¤å˜¤å˜¤&lt;/del&gt;ğŸ˜®ğŸ˜®ğŸ˜®;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; å®æ—¶æ€è·¯åˆ†ææ•°æ®ï¼šflink æµå¼å®æ—¶åˆ†ææ—©æ™šé«˜å³°ç«™ç‚¹å‹åŠ›æ’è¡Œï¼›&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; ç¦»çº¿æ€è·¯åˆ†ææ•°æ®ï¼šspark å¾®æ‰¹å¤„ç†ï¼›&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; DataV å¯è§†åŒ–å¤§å±å±•ç¤ºï¼›&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;æ›´æ–°æ—¥å¿—ğŸŒ¥ï¼š&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;2022-05-28:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ›´æ–° fastjsonï¼Œä¿®å¤é«˜å±æ¼æ´&lt;/li&gt; &#xA;   &lt;li&gt;æ ¼å¼åŒ–ä»£ç ï¼Œä½¿ç”¨ç©ºæ ¼æ›¿æ¢åˆ¶è¡¨ç¬¦&lt;/li&gt; &#xA;   &lt;li&gt;æ·»åŠ  â€œå996â€ã€apache-2.0 å¼€æºè®¸å¯è¯&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-05-25ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;flink å®æ—¶æµå¤„ç†åŠŸèƒ½éƒ¨åˆ†ä¸Šçº¿ã€‚å®Œæˆ flink è¯»å– kafkaï¼Œå­˜åˆ° clickhouse æ¨¡å—ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;è¡¥å……ç¬¬ä¸€æœŸå¼€å‘è®¡åˆ’æ¶æ„å›¾ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;ä¸‹ä¸€æ­¥ï¼Œè®¡åˆ’å¼€å‘æ•°æ®æ¹–ä¸­å°è§£å†³æ–¹æ¡ˆï¼Œè§„æ¨¡æ¯”è¾ƒå¤§ã€‚ç›®å‰è¿™ä¸ªé¡¹ç›®å·²ç»åˆç°é›å½¢ï¼ŒçŸ­æœŸå†…ä»¥ç»´æŠ¤å’Œä¼˜åŒ–ä¸ºä¸»ã€åŸåˆ™å°±æ˜¯å…ˆä¸Šçº¿åè¿­ä»£ã€‘ï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-05-22:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;è¡¥å……ç¬¬ä¸€æœŸå¼€å‘è®¡åˆ’çš„æ¶æ„å›¾ï¼Œå¸®åŠ©ç†è§£æ•´ä¸ªä¸šåŠ¡æµç¨‹ï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-05-14ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;RedisSinkPageJson&lt;/code&gt; ä» &lt;code&gt;package cn.java666.etlflink.sink&lt;/code&gt; ç§»åˆ° &lt;code&gt;package cn.java666.etlflink.app&lt;/code&gt; æ›´åä¸º &lt;code&gt;Jsons2Redis&lt;/code&gt;ï¼Œæ–¹ä¾¿å½’ç±»ï¼Œè¯¥æ¨¡å—ç”¨äºè§£æåŸå§‹æ•°æ®å¤šè¡Œjsonåˆ°redisï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-05-01ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å®ç°äº†ä» redis æˆ–è€…å…¶ä»–æ•°æ®æºå–å‡º json ä¸²ï¼Œä¿å­˜åˆ° hbase è¡¨ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®ç°äº† hbase-2.1 + springboot-2.1.13 + kafka-2.0 çš„é›†æˆï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®æ—¶æ¶ˆè´¹ kafka æ¶ˆæ¯å­˜åˆ° hbase æ•°æ®åº“ï¼Œæ”¯æŒå®æ—¶æŸ¥è¯¢æŸå¡å·æœ€è¿‘ n æ¬¡äº¤æ˜“è®°å½•ï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-30ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å®ç°äº† hbase-2.1 + springboot-2.1.13 çš„é›†æˆï¼Œä¸€ä¸ªé•¿ä¼šè¯å®Œæˆ hbase è¿ç»­çš„å¢åˆ æ”¹æŸ¥ğŸ‘‘ğŸ‘‘ğŸ‘‘ï¼Œé™ä½æœåŠ¡å™¨èµ„æºçš„å¼€é”€ã€‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-27ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å½»åº•çš„è§£å†³äº†é™æ€èµ„æºæ— æ³•çƒ­éƒ¨ç½²çš„é—®é¢˜ï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;&#xA;&#x9;&amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;&#xA;&#x9;&amp;lt;artifactId&amp;gt;spring-boot-devtools&amp;lt;/artifactId&amp;gt;&#xA;&#x9;&amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt;&#xA;&#x9;&amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;&#xA;&amp;lt;/dependency&amp;gt;&#xA;&#xA;######################### å®æ—¶çƒ­éƒ¨ç½² ###################################&#xA;#&#34;å…³é—­ç¼“å­˜, å³æ—¶åˆ·æ–°&#34;&#xA;spring.freemarker.cache=false&#xA;spring.thymeleaf.cache=false&#xA;&#xA;#çƒ­éƒ¨ç½²ç”Ÿæ•ˆ&#xA;spring.devtools.restart.enabled=true&#xA;#æ˜¯å¦æ”¯æŒlivereload&#xA;spring.devtools.livereload.enabled=true&#xA;#è®¾ç½®é‡å¯çš„ç›®å½•,æ·»åŠ é‚£ä¸ªç›®å½•çš„æ–‡ä»¶éœ€è¦restart&#xA;spring.devtools.restart.additional-paths=src/main/*&#xA;#è®¾ç½®ä¸éœ€è¦é‡å¯çš„ç›®å½•&#xA;#spring.devtools.restart.exclude=static/**,public/**&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;202-04-27: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å®Œæˆæ‰€æœ‰çº¿è·¯è§„åˆ’+æ¢ä¹˜æ–¹æ¡ˆçš„æŠ“å–å…¥åº“ï¼Œåˆè®¡ 45932 æ¡ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;è§£å†³äº† hive æ³¨é‡Šä¹±ç é—®é¢˜ï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;alter table COLUMNS_V2 modify column COMMENT varchar(256) character set utf8;&#xA;alter table TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;&#xA;alter table PARTITION_PARAMS  modify column PARAM_VALUE varchar(4000) character set utf8;&#xA;alter table PARTITION_KEYS  modify column PKEY_COMMENT varchar(4000) character set utf8;&#xA;alter table  INDEX_PARAMS  modify column PARAM_VALUE  varchar(4000) character set utf8;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-24ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å®Œæˆæ–°çš„æŒ‡æ ‡è®¡ç®—ä»»åŠ¡ï¼šæ·±åœ³åœ°é“å„çº¿è·¯æ¢ä¹˜å‡ºç«™ä¹˜å®¢ç™¾åˆ†æ¯”æ’è¡Œæ¦œï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆæ–°çš„æŒ‡æ ‡è®¡ç®—ä»»åŠ¡ï¼šæ·±åœ³åœ°é“å„çº¿è·¯ç›´è¾¾ä¹˜å®¢ä¼˜æƒ äººæ¬¡ç™¾åˆ†æ¯”æ’è¡Œæ¦œï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-23ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å®Œæˆæ–°çš„æŒ‡æ ‡è®¡ç®—ä»»åŠ¡ï¼šæ·±åœ³åœ°é“å„çº¿è·¯å•ç¨‹ç›´è¾¾ä¹˜å®¢è€—æ—¶å¹³å‡å€¼æ’è¡Œæ¦œï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆæ–°çš„æŒ‡æ ‡è®¡ç®—ä»»åŠ¡ï¼šæ·±åœ³åœ°é“æ‰€æœ‰ä¹˜å®¢é€šå‹¤æ—¶é—´å¹³å‡å€¼ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆæ–°çš„æŒ‡æ ‡è®¡ç®—ä»»åŠ¡ï¼šæ·±åœ³åœ°é“æ‰€æœ‰ä¹˜å®¢é€šå‹¤æ—¶é—´æ’è¡Œæ¦œï¼ˆå€’åºï¼‰ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆæ–°çš„æŒ‡æ ‡è®¡ç®—ä»»åŠ¡ï¼šæ·±åœ³åœ°é“å„ç«™ç‚¹ã€çº¿è·¯ï¼Œè¿›ç«™ã€å‡ºç«™é—¸æœºæ•°æ’è¡Œæ¦œï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆæ–°çš„æŒ‡æ ‡è®¡ç®—ä»»åŠ¡ï¼šæ·±åœ³åœ°é“å„ç«™ç‚¹ã€çº¿è·¯ï¼Œæ”¶å…¥æ’è¡Œæ¦œï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-22ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ›´æ–°æ–‡æ¡£ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆæ–°çš„æŒ‡æ ‡è®¡ç®—ä»»åŠ¡ï¼šæ¯æ—¥è¿è¾“ä¹˜å®¢æœ€å¤šçš„åŒºé—´æ’è¡Œæ¦œï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-21:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ–°å¢æ¨¡å—ï¼šSZT-spark-hiveï¼Œæœ¬åœ°å¼€å‘ spark ç¨‹åºï¼Œæ“ä½œè¿œç¨‹ Hive æ•°æ®åº“ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;Debugï¼šspark on hive æœ¬åœ°å¼€å‘ï¼Œè¿œç¨‹æäº¤ yarn è¸©å‘ï¼Œä¸»è¦æ˜¯ä¸ºäº†ç¼“è§£å¼€å‘ä¸»æœºçš„å‹åŠ›ï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-20ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ›´æ–°é¡¹ç›®æ–‡æ¡£ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;è‡ªåˆ¶é¡¹ç›® logoï¼›&lt;/li&gt; &#xA;   &lt;li&gt;ç»§ç»­å†™ SQL è®¡ç®—æ–°æŒ‡æ ‡ï¼Œæœ¬æ‰“ç®—åˆ‡åˆ° hive 3.1 ä½¿ç”¨ TEZ å¼•æ“ï¼Œä½†æ˜¯ hive on spark é€Ÿåº¦å·²ç»å¾ˆç»™åŠ›äº†ï¼Œè‡³å°‘æ˜¯ MR å¼•æ“çš„ 10 å€é€Ÿåº¦ï¼Œå…ˆç”¨ç€ï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-19ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;vmware è™šæ‹Ÿæœºæ‰©å®¹æ—¶è¯¯åˆ ç³»ç»Ÿæ–‡ä»¶&lt;code&gt;rm -rf /usr/&lt;/code&gt; ğŸ¥µï¼Œå¥½åœ¨ HDFSã€Kafkaã€ES è‡ªå¸¦å‰¯æœ¬æœºåˆ¶ï¼Œè€Œä¸”å¤§éƒ¨åˆ†ä¸šåŠ¡æ•°æ®éƒ½æ˜¯æŒ‚è½½åˆ°å¤–éƒ¨ç£ç›˜ï¼Œæ‰€ä»¥é‡è¦æ•°æ®å’Œç»„ä»¶æ—¥å¿—åŸºæœ¬æ²¡ä¸¢ã€‚cdh é›†ç¾¤æ·»åŠ äº†æ–°çš„èŠ‚ç‚¹ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;æ¢å¤å·¥ä½œç¯å¢ƒï¼Œä» hive on MR åˆ‡æ¢åˆ° hive on sparkï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-18ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;è§„åˆ’æ•°ä»“ï¼Œæ­å»ºæ•°ä»“ç¯å¢ƒï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-17&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ä¿®æ­£é”™åˆ«å­—ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å‘å¸ƒv0.12;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-16&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;é‡æ„é¡¹ç›®ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;è¡¥å……æ–‡æ¡£&lt;/li&gt; &#xA;   &lt;li&gt;å‘å¸ƒv0.1&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-15&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å¢åŠ  common æ¨¡å—ï¼Œæ‹†åˆ†è§£è€¦ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;æ”¯æŒè‡ªåŠ¨è¯†åˆ«å¡å·æ˜æ–‡å’Œå¯†æ–‡ï¼Œä¸€é”®äº’è½¬ï¼Œæä¾› REST APIï¼›&lt;/li&gt; &#xA;   &lt;li&gt;ä¿®å¤ ES æ—¶åŒºå¯¼è‡´çš„é”™è¯¯ç»Ÿè®¡æ•°é‡ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;Redis2Csv å®ç°äº†æŒ‰å¤©è½¬æ¢ csv å­˜ç›˜ï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-14&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;é‡æ„ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆ csv æ ¼å¼æ–‡ä»¶çš„æŠ½å–ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;æ·»åŠ  GPL-3 å¼€æºè¯ä¹¦ï¼Œé¼“åŠ±å¼€æºåˆ†å‘ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;æ·»åŠ å¾½æ ‡ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆå†™å…¥ ES æ•°æ®åº“ï¼Œæ·»åŠ æ—¶é—´æ˜ å°„,kibana å®æ—¶æŸ¥çœ‹åˆ·å¡æ•°æ®ç»Ÿè®¡æ›²çº¿çš„å˜åŒ–ï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2020-04-13&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;é¡¹ç›®åˆå§‹åŒ–ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆæ•°æ®æºæ¸…æ´—å»é‡ï¼Œå­˜åˆ° redisï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆ redis æŸ¥è¯¢ REST API çš„å¼€å‘ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆ flink è‡ªå®šä¹‰ source redis çš„å¼€å‘ï¼Œå¹¶ä¸”æ›´ç»†ç²’åº¦æ¸…æ´—æºæ•°æ®ï¼›&lt;/li&gt; &#xA;   &lt;li&gt;å®Œæˆ æ¨é€æºæ•°æ®åˆ° kafkaï¼›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;è”ç³»ğŸ˜ªï¼š&lt;/h2&gt; &#xA;&lt;p&gt;æ¬¢è¿äº¤æµæŠ€æœ¯ï¼Œæ¥å¤´æš—å·&lt;code&gt;github&lt;/code&gt;&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyouth/SZT-bigdata/master/.file/.pic/0-wexin.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ç™¾åº¦å’Œè°·æ­Œèƒ½æ‰¾åˆ°çš„é—®é¢˜å°±ä¸è¦å†é—®äº†ï¼å¾ˆç´¯çš„ğŸ˜•ğŸ˜•ğŸ˜•&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;è¡¥å……ğŸ’ŒğŸ’ŒğŸ’Œï¼š&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ä¸å¼€å°å¯†åœˆï¼›&lt;/li&gt; &#xA; &lt;li&gt;ä¸å–è¯¾ã€ä¸å–æ•™ç¨‹ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ä¸æ±‚èµï¼Œä¸æ±‚ç²‰ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ä¸å‘å¹¿å‘Šã€ä¸éªšæ‰°ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ä¸å‰²éŸ­èœ&lt;/li&gt; &#xA; &lt;li&gt;ä¸æ°é¥­&lt;/li&gt; &#xA; &lt;li&gt;å¶å°”å‘ç‚¹è§†é¢‘æ•™ç¨‹&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;åšæŒåŸåˆ™å’Œåº•çº¿ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;æ¯”å¿ƒğŸ¤ğŸ¤ğŸ¤&lt;/p&gt; &#xA;&lt;h2&gt;åä¸ªæ§½ğŸ¦ğŸ¦ğŸ¦ï¼š&lt;/h2&gt; &#xA;&lt;p&gt;ç¨‹åºå‘˜è¿™è¾ˆå­ä¸€å®šä¼šé‡åˆ°çš„ä¸‰ä¸ªé—®é¢˜ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ä¹±ç é—®é¢˜ğŸŒšï¼›&lt;/li&gt; &#xA; &lt;li&gt;æ—¶åŒºä¸ä¸€è‡´é—®é¢˜ğŸŒ—ï¼›&lt;/li&gt; &#xA; &lt;li&gt;è½¯ä»¶ç‰ˆæœ¬ä¸å…¼å®¹é—®é¢˜â„ï¼›&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;æ•™è®­ï¼š&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å¤§æ•°æ®ç¨‹åºå‘˜åƒä¸‡ä¸èƒ½ç”Ÿäº§é”™è¯¯çš„æ•°æ®ï¼Œå®¹å¿ç¨‹åºè¿è¡Œå¤±è´¥ã€ç”šè‡³æ²¡æœ‰è¾“å‡ºæ•°æ®ï¼Œå¤±è´¥äº†å¯ä»¥è·Ÿè¸ªåŸå› ï¼Œè‡³å°‘ä¸ä¼šæœ‰è„æ•°æ®ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ä¸€æ—¦æ•°æ®é”™è¯¯ï¼Œä¼šå½±å“åé¢çš„æ‰€æœ‰è®¡ç®—æµç¨‹ï¼Œç”šè‡³å¯¼è‡´é”™è¯¯å†³ç­–ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ç»Ÿè®¡ä¿¡æ¯ï¼š&lt;/h2&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth/SZT-bigdata&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://starchart.cc/geekyouth/SZT-bigdata.svg?sanitize=true&#34; alt=&#34;å…³æ³¨æ›²çº¿&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://github-readme-stats.vercel.app/api?username=geekyouth&amp;amp;show_icons=true&amp;amp;theme=monokai&#34; alt=&#34;ä¸ªäººæ¦‚å†µ&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/geekyouth/SZT-bigdata&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://github-readme-stats.vercel.app/api/pin?username=geekyouth&amp;amp;repo=SZT-bigdata&amp;amp;show_icons=true&amp;amp;theme=monokai&amp;amp;show_owner=true&#34; alt=&#34;ä»“åº“æ¦‚å†µ&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://www.jetbrains.com/?from=https://github.com/geekyouth/SZT-bigdata&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://www.jetbrains.com/company/brand/img/logo1.svg?sanitize=true&#34; alt=&#34;èµåŠ©ä¼™ä¼´&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>akka/akka-http</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/akka/akka-http</id>
    <link href="https://github.com/akka/akka-http" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Streaming-first HTTP server/module of Akka&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Akka HTTP&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://index.scala-lang.org/akka/akka-http/akka-http-core&#34;&gt;&lt;img src=&#34;https://index.scala-lang.org/akka/akka-http/akka-http-core/latest-by-scala-version.svg?sanitize=true&#34; alt=&#34;akka-http-core Scala version support&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Akka HTTP modules implement a full server- and client-side HTTP stack on top of akka-actor and akka-stream. It&#39;s not a web-framework but rather a more general toolkit for providing and consuming HTTP-based services. While interaction with a browser is of course also in scope it is not the primary focus of Akka HTTP.&lt;/p&gt; &#xA;&lt;p&gt;Akka HTTP follows a rather open design and many times offers several different API levels for &#34;doing the same thing&#34;. You get to pick the API level of abstraction that is most suitable for your application. This means that, if you have trouble achieving something using a high-level API, there&#39;s a good chance that you can get it done with a low-level API, which offers more flexibility but might require you to write more application code.&lt;/p&gt; &#xA;&lt;p&gt;Learn more at &lt;a href=&#34;https://akka.io/&#34;&gt;akka.io&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The documentation is available at &lt;a href=&#34;https://doc.akka.io/docs/akka-http/current/&#34;&gt;doc.akka.io&lt;/a&gt;, for &lt;a href=&#34;https://doc.akka.io/docs/akka-http/current/scala/http/&#34;&gt;Scala&lt;/a&gt; and &lt;a href=&#34;https://doc.akka.io/docs/akka-http/current/java/http/&#34;&gt;Java&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;You can join these groups and chats to discuss and ask Akka related questions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Forums: &lt;a href=&#34;https://discuss.akka.io&#34;&gt;discuss.akka.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Chat room about &lt;em&gt;using&lt;/em&gt; Akka HTTP: &lt;a href=&#34;https://gitter.im/akka/akka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/gitter%3A-akka%2Fakka-blue.svg?style=flat-square&#34; alt=&#34;gitter: akka/akka&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Q&amp;amp;A: &lt;a href=&#34;https://stackoverflow.com/questions/tagged/akka-http&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/stackoverflow%3A-akka--http-blue.svg?style=flat-square&#34; alt=&#34;stackoverflow: #akka-http&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Issue tracker: &lt;a href=&#34;https://github.com/akka/akka-http/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/github%3A-issues-blue.svg?style=flat-square&#34; alt=&#34;github: akka/akka-http&#34;&gt;&lt;/a&gt; (Please use the issue tracker for bugs and reasonable feature requests. Please ask usage questions on the other channels.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All of our forums, chat rooms, and issue trackers are governed by our &lt;a href=&#34;https://www.lightbend.com/conduct&#34;&gt;Code Of Conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In addition to that, you may enjoy following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://akka.io/blog/news-archive.html&#34;&gt;news&lt;/a&gt; section of the page, which is updated whenever a new version is released&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://akka.io/blog&#34;&gt;Akka Team Blog&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/akkateam&#34;&gt;@akkateam&lt;/a&gt; on Twitter&lt;/li&gt; &#xA; &lt;li&gt;Projects built with Akka HTTP: &lt;a href=&#34;https://index.scala-lang.org/search?q=dependencies:akka/akka-http*&#34;&gt;&lt;img src=&#34;https://index.scala-lang.org/count.svg?q=dependencies:akka/akka-http*&amp;amp;subject=scaladex:&amp;amp;color=blue&amp;amp;style=flat-square&#34; alt=&#34;Built with Akka HTTP&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are &lt;em&gt;very&lt;/em&gt; welcome!&lt;/p&gt; &#xA;&lt;p&gt;If you see an issue that you&#39;d like to see fixed, the best way to make it happen is to help out by submitting a pull request. For ideas of where to contribute, &lt;a href=&#34;https://github.com/akka/akka-http/labels/help%20wanted&#34;&gt;tickets marked as &#34;help wanted&#34;&lt;/a&gt; are a good starting point.&lt;/p&gt; &#xA;&lt;p&gt;Refer to the &lt;a href=&#34;https://raw.githubusercontent.com/akka/akka-http/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; file for more details about the workflow, and general hints on how to prepare your pull request. You can also ask for clarifications or guidance in GitHub issues directly, or in the &lt;a href=&#34;https://gitter.im/akka/dev&#34;&gt;akka/dev&lt;/a&gt; chat if a more real-time communication would be of benefit.&lt;/p&gt; &#xA;&lt;p&gt;A chat room is available for all questions related to &lt;em&gt;developing and contributing&lt;/em&gt; to Akka: &lt;a href=&#34;https://gitter.im/akka/dev&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/gitter%3A-akka%2Fdev-blue.svg?style=flat-square&#34; alt=&#34;gitter: akka/dev&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Maintenance&lt;/h2&gt; &#xA;&lt;p&gt;This project is maintained by Lightbend&#39;s core Akka Team as well as the extended Akka HTTP Team, consisting of excellent and experienced developers who have shown their dedication and knowledge about HTTP and the codebase. This team may grow dynamically, and it is possible to propose new members to it.&lt;/p&gt; &#xA;&lt;p&gt;Joining the extended team in such form gives you, in addition to street-cred, of course committer rights to this repository as well as higher impact onto the roadmap of the project. Come and join us!&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Akka HTTP is Open Source and available under the Apache 2 License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>TheHive-Project/TheHive</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/TheHive-Project/TheHive</id>
    <link href="https://github.com/TheHive-Project/TheHive" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TheHive: a Scalable, Open Source and Free Security Incident Response Platform&lt;/p&gt;&lt;hr&gt;&lt;div&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TheHive-Project/TheHive/main/images/thehive-logo.png&#34; width=&#34;600&#34;&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://chat.thehive-project.org&#34; target&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/chat-on%20discord-7289da.svg?sanitize=true&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href&gt;&lt;img src=&#34;https://drone.strangebee.com/api/badges/TheHive-Project/TheHive/status.svg?ref=refs/heads/master-th4&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TheHive-Project/TheHive/main/LICENSE&#34; target&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/TheHive-Project/TheHive&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://thehive-project.org/&#34;&gt;TheHive&lt;/a&gt; is a scalable 3-in-1 open source and free Security Incident Response Platform designed to make life easier for SOCs, CSIRTs, CERTs and any information security practitioner dealing with security incidents that need to be investigated and acted upon swiftly. It is the perfect companion to &lt;a href=&#34;http://www.misp-project.org/&#34;&gt;MISP&lt;/a&gt;. You can synchronize it with one or multiple MISP instances to start investigations out of MISP events. You can also export an investigation&#39;s results as a MISP event to help your peers detect and react to attacks you&#39;ve dealt with. Additionally, when TheHive is used in conjunction with &lt;a href=&#34;https://github.com/TheHive-Project/Cortex/&#34;&gt;Cortex&lt;/a&gt;, security analysts and researchers can easily analyze tens if not hundred of observables.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/TheHive-Project/TheHive/main/images/Current_cases.png&#34; alt=&#34;Current Cases View&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Collaborate&lt;/h2&gt; &#xA;&lt;p&gt;Collaboration is at the heart of TheHive.&lt;/p&gt; &#xA;&lt;p&gt;Multiple analysts from one organisations can work together on the same case simultaneously. For example, an analyst may deal with malware analysis while another may work on tracking C2 beaconing activity on proxy logs as soon as IOCs have been added by their coworker. Using TheHive&#39;s live stream, everyone can keep an eye on what&#39;s happening on the platform, in real time.&lt;/p&gt; &#xA;&lt;p&gt;Multi-tenancy and fine grained user profiles let organisations and analysts work and collaborate on a same case accross organisations. For example, one case can be created by a first organisation who start investigating and ask for contribution from other teams or escalate to another organisation.&lt;/p&gt; &#xA;&lt;h2&gt;Elaborate&lt;/h2&gt; &#xA;&lt;p&gt;Within TheHive, every investigation corresponds to a case. Cases can be created from scratch or from &lt;a href=&#34;http://www.misp-project.org/&#34;&gt;MISP&lt;/a&gt; events, SIEM alerts, email reports and any other noteworthy source of security events.&lt;/p&gt; &#xA;&lt;p&gt;Each case can be broken down into one or more tasks. Instead of adding the same tasks to a given type of case every time one is created, analysts can use TheHive&#39;s template engine to create them once and for all. Case templates can also be used to associate metrics to specific case types in order to drive the team&#39;s activity, identify the type of investigations that take significant time and seek to automate tedious tasks.&lt;/p&gt; &#xA;&lt;p&gt;Each task can be assigned to a given analyst. Team members can also take charge of a task without waiting for someone to assign it to them.&lt;/p&gt; &#xA;&lt;p&gt;Tasks may contain multiple work logs that contributing analysts can use to describe what they are up to, what was the outcome, attach pieces of evidence or noteworthy files and so on. Logs can be written using a rich text editor or Markdown.&lt;/p&gt; &#xA;&lt;h2&gt;Analyze&lt;/h2&gt; &#xA;&lt;p&gt;You can add one or hundreds if not thousands of observables to each case you create. You can also create a case out of a &lt;a href=&#34;http://www.misp-project.org/&#34;&gt;MISP&lt;/a&gt; event. TheHive can be very easily linked to one or several MISP instances and MISP events can be previewed to decide whether they warrant an investigation or not. If an investigation is in order, the analyst can then add the event to an existing case or import it as a new case using a customizable template.&lt;/p&gt; &#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://thehive-project.org/#section_thehive4py&#34;&gt;TheHive4py&lt;/a&gt;, TheHive&#39;s Python API client, it is possible to send SIEM alerts, phishing and other suspicious emails and other security events to TheHive. They will appear in its &lt;code&gt;Alerts&lt;/code&gt; panel along with new or updated MISP events, where they can be previewed, imported into cases or ignored.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/TheHive-Project/TheHive/main/images/Alerts_Panel.png&#34; alt=&#34;The Alerts Pane&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;TheHive has the ability to automatically identify observables that have been already seen in previous cases. Observables can also be associated with a TLP and the source which provided or generated them using tags. The analyst can also easily mark observables as IOCs and isolate those using a search query then export them for searching in a SIEM or other data stores.&lt;/p&gt; &#xA;&lt;p&gt;Analysts can analyze tens or hundreds of observables in a few clicks by leveraging the analyzers of one or several &lt;a href=&#34;https://github.com/TheHive-Project/Cortex/&#34;&gt;Cortex&lt;/a&gt; instances depending on your OPSEC needs: DomainTools, VirusTotal, PassiveTotal, Joe Sandbox, geolocation, threat feed lookups and so on.&lt;/p&gt; &#xA;&lt;p&gt;Security analysts with a knack for scripting can easily add their own analyzers to Cortex in order to automate actions that must be performed on observables or IOCs. They can also decide how analyzers behave according to the TLP. For example, a file added as observable can be submitted to VirusTotal if the associated TLP is WHITE or GREEN. If it&#39;s AMBER, its hash is computed and submitted to VT but not the file. If it&#39;s RED, no VT lookup is done.&lt;/p&gt; &#xA;&lt;h1&gt;Try it&lt;/h1&gt; &#xA;&lt;p&gt;To try TheHive, you can use the &lt;a href=&#34;https://www.strangebee.com/tryit&#34;&gt;training VM&lt;/a&gt; or install it by reading the &lt;a href=&#34;https://docs.thehive-project.org/thehive/installation-and-configuration/installation/step-by-step-guide/&#34;&gt;Installation Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Details&lt;/h1&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;We have made several guides available in the &lt;a href=&#34;https://docs.thehive-project.org/thehive/&#34;&gt;Documentation repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Main features&lt;/h2&gt; &#xA;&lt;h3&gt;Multi-tenancy&lt;/h3&gt; &#xA;&lt;p&gt;TheHive comes with a special multi-tenancy support. It allows the following strategies:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use a siloed multi-tenancy: many organisations can be defined without allowing them to share data;&lt;/li&gt; &#xA; &lt;li&gt;Use a collaborative multi-tenancy: a set of organisations can be allowed to collaborate on specific cases/tasks/observables, using custom defined user profiles (RBAC).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;RBAC&lt;/h3&gt; &#xA;&lt;p&gt;TheHive comes with a set of permissions and several pre-configured user profiles:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;admin&lt;/code&gt;: full administrative permissions on the platform ; can&#39;t manage any Cases or other data related to investigations;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;org-admin&lt;/code&gt;: manage users and all organisation-level configuration, can create and edit Cases, Tasks, Observables and run Analyzers and Responders;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;analyst&lt;/code&gt;: can create and edit &lt;em&gt;Cases&lt;/em&gt;, &lt;em&gt;Tasks&lt;/em&gt;, &lt;em&gt;Observables&lt;/em&gt; and run &lt;em&gt;Analyzers&lt;/em&gt; &amp;amp; &lt;em&gt;Responders&lt;/em&gt;;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;read-only&lt;/code&gt;: Can only read, Cases, Tasks and Observables details;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;New profiles can be created by administrators of the platform.&lt;/p&gt; &#xA;&lt;h3&gt;Authentication&lt;/h3&gt; &#xA;&lt;p&gt;TheHive 4 supports authentication methods:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;local accounts&lt;/li&gt; &#xA; &lt;li&gt;Active Directory&lt;/li&gt; &#xA; &lt;li&gt;LDAP&lt;/li&gt; &#xA; &lt;li&gt;Basic Auth&lt;/li&gt; &#xA; &lt;li&gt;API keys&lt;/li&gt; &#xA; &lt;li&gt;OAUTH2&lt;/li&gt; &#xA; &lt;li&gt;Multi Factor Authentication&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Statistics &amp;amp; Dashboards&lt;/h3&gt; &#xA;&lt;p&gt;TheHive comes with a powerful statistics module that allows you to create meaningful dashboards to drive your activity and support your budget requests.&lt;/p&gt; &#xA;&lt;h2&gt;Integrations&lt;/h2&gt; &#xA;&lt;h3&gt;MISP and Cortex&lt;/h3&gt; &#xA;&lt;p&gt;TheHive can be configured to import events from one or multiple &lt;a href=&#34;http://www.misp-project.org/&#34;&gt;MISP&lt;/a&gt; instances. You can also use TheHive to export cases as MISP events to one or several MISP servers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/TheHive-Project/Cortex/&#34;&gt;Cortex&lt;/a&gt; is the perfect companion for TheHive. Use one or several to analyze observables at scale.&lt;/p&gt; &#xA;&lt;h3&gt;Integration with Digital Shadows&lt;/h3&gt; &#xA;&lt;p&gt;TheHive Project provides &lt;a href=&#34;https://github.com/TheHive-Project/DigitalShadows2TH&#34;&gt;DigitalShadows2TH&lt;/a&gt;, a free, open source &lt;a href=&#34;https://www.digitalshadows.com/&#34;&gt;Digital Shadows&lt;/a&gt; alert feeder for TheHive. You can use it to import Digital Shadows &lt;em&gt;incidents&lt;/em&gt; and &lt;em&gt;intel-incidents&lt;/em&gt; as alerts in TheHive, where they can be previewed and transformed into new cases using pre-defined incident response templates or added into existing ones.&lt;/p&gt; &#xA;&lt;h3&gt;Integration with Zerofox&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/TheHive-Project/Zerofox2TH&#34;&gt;Zerofox2TH&lt;/a&gt; is a free, open source &lt;a href=&#34;https://www.zerofox.com/&#34;&gt;ZeroFOX&lt;/a&gt; alert feeder for TheHive, written by TheHive Project. You can use it to feed ZeroFOX alerts into TheHive, where they can be previewed and transformed into new cases using pre-defined incident response templates or added into existing ones.&lt;/p&gt; &#xA;&lt;h3&gt;And many more&lt;/h3&gt; &#xA;&lt;p&gt;Lots of &lt;strong&gt;awesome&lt;/strong&gt; integrations shared by the community could be listed there. If you&#39;re looking for a specific one, &lt;strong&gt;a dedicated repository&lt;/strong&gt; containing all known details and references about existing integrations is updated frequently, and can be found here: &lt;a href=&#34;https://github.com/TheHive-Project/awesome&#34;&gt;https://github.com/TheHive-Project/awesome&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;TheHive is an open source and free software released under the &lt;a href=&#34;https://github.com/TheHive-Project/TheHive/raw/master/LICENSE&#34;&gt;AGPL&lt;/a&gt; (Affero General Public License). We, TheHive Project, are committed to ensure that TheHive will remain a free and open source project on the long-run.&lt;/p&gt; &#xA;&lt;h1&gt;Updates&lt;/h1&gt; &#xA;&lt;p&gt;Information, news and updates are regularly posted on &lt;a href=&#34;https://twitter.com/thehive_project&#34;&gt;TheHive Project Twitter account&lt;/a&gt; and on &lt;a href=&#34;https://blog.thehive-project.org/&#34;&gt;the blog&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;Please see our &lt;a href=&#34;https://raw.githubusercontent.com/TheHive-Project/TheHive/main/code_of_conduct.md&#34;&gt;Code of conduct&lt;/a&gt;. We welcome your contributions. Please feel free to fork the code, play with it, make some patches and send us pull requests via &lt;a href=&#34;https://github.com/TheHive-Project/TheHive/issues&#34;&gt;issues&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Support&lt;/h1&gt; &#xA;&lt;p&gt;Please &lt;a href=&#34;https://github.com/TheHive-Project/TheHive/issues&#34;&gt;open an issue on GitHub&lt;/a&gt; if you&#39;d like to report a bug or request a feature. We are also available on &lt;a href=&#34;https://chat.thehive-project.org&#34;&gt;Discord&lt;/a&gt; to help you out.&lt;/p&gt; &#xA;&lt;p&gt;If you need to contact the project team, send an email to &lt;a href=&#34;mailto:support@thehive-project.org&#34;&gt;support@thehive-project.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Important Note&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you have problems with &lt;a href=&#34;https://github.com/TheHive-Project/TheHive4py&#34;&gt;TheHive4py&lt;/a&gt;, please &lt;a href=&#34;https://github.com/TheHive-Project/TheHive4py/issues/new&#34;&gt;open an issue on its dedicated repository&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you encounter an issue with Cortex or would like to request a Cortex-related feature, please &lt;a href=&#34;https://github.com/TheHive-Project/Cortex/issues/new&#34;&gt;open an issue on its dedicated GitHub repository&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you have troubles with a Cortex analyzer or would like to request a new one or an improvement to an existing analyzer, please open an issue on the &lt;a href=&#34;https://github.com/TheHive-Project/cortex-analyzers/issues/new&#34;&gt;analyzers&#39; dedicated GitHub repository&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Community Discussions&lt;/h1&gt; &#xA;&lt;p&gt;We have set up a Google forum at &lt;a href=&#34;https://groups.google.com/a/thehive-project.org/d/forum/users&#34;&gt;https://groups.google.com/a/thehive-project.org/d/forum/users&lt;/a&gt;. To request access, you need a Google account. You may create one &lt;a href=&#34;https://accounts.google.com/SignUp?hl=en&#34;&gt;using a Gmail address&lt;/a&gt; or &lt;a href=&#34;https://accounts.google.com/SignUpWithoutGmail?hl=en&#34;&gt;without it&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Website&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://thehive-project.org/&#34;&gt;https://thehive-project.org/&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>softwaremill/tapir</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/softwaremill/tapir</id>
    <link href="https://github.com/softwaremill/tapir" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Declarative, type-safe web endpoints library&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/banner.png&#34; alt=&#34;tapir, or Typed API descRiptions&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/softwaremill/tapir?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/Join%20Chat.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/softwaremill/tapir&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/softwaremill/tapir/actions?query=workflow%3A%22CI%22&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.softwaremill.sttp.tapir/tapir-core_2.13&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/com.softwaremill.sttp.tapir/tapir-core_2.13/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Intro&lt;/h2&gt; &#xA;&lt;p&gt;With tapir, you can describe HTTP API endpoints as immutable Scala values. Each endpoint can contain a number of input and output parameters. An endpoint specification can be interpreted as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;a server, given the &#34;business logic&#34;: a function, which computes output parameters based on input parameters. Currently supported: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/akkahttp.html&#34;&gt;Akka HTTP&lt;/a&gt; &lt;code&gt;Route&lt;/code&gt;s/&lt;code&gt;Directive&lt;/code&gt;s&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/http4s.html&#34;&gt;Http4s&lt;/a&gt; &lt;code&gt;HttpRoutes[F]&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/netty.html&#34;&gt;Netty&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/finatra.html&#34;&gt;Finatra&lt;/a&gt; &lt;code&gt;FinatraRoute&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/play.html&#34;&gt;Play&lt;/a&gt; &lt;code&gt;Route&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/vertx.html&#34;&gt;Vert.X&lt;/a&gt; &lt;code&gt;Router =&amp;gt; Route&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/ziohttp.html&#34;&gt;ZIO Http&lt;/a&gt; &lt;code&gt;Http&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/armeria.html&#34;&gt;Armeria&lt;/a&gt; &lt;code&gt;HttpServiceWithRoutes&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/server/aws.html&#34;&gt;aws&lt;/a&gt; through Lambda/SAM/Terraform&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;a client, which is a function from input parameters to output parameters. Currently supported: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/client/sttp.html&#34;&gt;sttp&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/client/play.html&#34;&gt;Play&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/client/http4s.html&#34;&gt;http4s&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;documentation. Currently supported: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/docs/openapi.html&#34;&gt;OpenAPI&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://tapir.softwaremill.com/en/latest/docs/asyncapi.html&#34;&gt;AsyncAPI&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Depending on how you prefer to explore the library, take a look at one of the &lt;a href=&#34;https://tapir.softwaremill.com/en/latest/examples.html&#34;&gt;examples&lt;/a&gt; or &lt;a href=&#34;https://tapir.softwaremill.com/en/latest/index.html&#34;&gt;head over to the docs&lt;/a&gt; for a more detailed description of how tapir works!&lt;/p&gt; &#xA;&lt;h2&gt;Why tapir?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;type-safety&lt;/strong&gt;: compile-time guarantees, develop-time completions, read-time information&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;declarative&lt;/strong&gt;: separate the shape of the endpoint (the &#34;what&#34;), from the server logic (the &#34;how&#34;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;OpenAPI / Swagger integration&lt;/strong&gt;: generate documentation from endpoint descriptions&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;observability&lt;/strong&gt;: leverage the metadata to report rich metrics and tracing information&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;abstraction&lt;/strong&gt;: re-use common endpoint definitions, as well as individual inputs/outputs&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;library, not a framework&lt;/strong&gt;: integrates with your stack&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Adopters&lt;/h2&gt; &#xA;&lt;p&gt;Is your company already using tapir? We&#39;re continually expanding the &#34;adopters&#34; section in the documentation; the more the merrier! It would be great to feature your company&#39;s logo, but in order to do that, we&#39;ll need written permission to avoid any legal misunderstandings.&lt;/p&gt; &#xA;&lt;p&gt;Please email us at &lt;a href=&#34;mailto:tapir@softwaremill.com&#34;&gt;tapir@softwaremill.com&lt;/a&gt; from your company&#39;s email with a link to your logo (if we can use it, of course!) or with details who to kindly ask for permission to feature the logo in tapir&#39;s documentation. We&#39;ll handle the rest.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.adobe.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/adobe.png&#34; alt=&#34;Adobe&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.colisweb.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/colisweb.png&#34; alt=&#34;Colisweb&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://swissborg.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/swissborg.png&#34; alt=&#34;Swissborg&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://kaizo.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/kaizo.png&#34; alt=&#34;Kaizo&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.process.st/&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/process_street.png&#34; alt=&#34;Process Street&#34; width=&#34;100&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.tranzzo.com/&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/tranzzo.svg?sanitize=true&#34; alt=&#34;Tranzzo&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.kelkoogroup.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/kelkoogroup.png&#34; alt=&#34;Kelkoo group&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.softwaremill.com/&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/softwaremill.png&#34; alt=&#34;SoftwareMill&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.carvana.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/carvana.svg?sanitize=true&#34; alt=&#34;Carvana&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.moneyfarm.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/moneyfarm.png&#34; alt=&#34;Moneyfarm&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.ocadogroup.com/about-us/ocado-technology&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/ocado.png&#34; alt=&#34;Ocado Technology&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.wegtam.com&#34;&gt;&lt;img src=&#34;https://github.com/softwaremill/tapir/raw/master/doc/adopters/wegtam.svg?sanitize=true&#34; alt=&#34;Wegtam&#34; width=&#34;160&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Teaser&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import sttp.tapir._&#xA;import sttp.tapir.generic.auto._&#xA;import sttp.tapir.json.circe._&#xA;import io.circe.generic.auto._&#xA;&#xA;type Limit = Int&#xA;type AuthToken = String&#xA;case class BooksQuery(genre: String, year: Int)&#xA;case class Book(title: String)&#xA;&#xA;&#xA;// Define an endpoint&#xA;&#xA;val booksListing: PublicEndpoint[(BooksQuery, Limit, AuthToken), String, List[Book], Any] = &#xA;  endpoint&#xA;    .get&#xA;    .in((&#34;books&#34; / path[String](&#34;genre&#34;) / path[Int](&#34;year&#34;)).mapTo[BooksQuery])&#xA;    .in(query[Limit](&#34;limit&#34;).description(&#34;Maximum number of books to retrieve&#34;))&#xA;    .in(header[AuthToken](&#34;X-Auth-Token&#34;))&#xA;    .errorOut(stringBody)&#xA;    .out(jsonBody[List[Book]])&#xA;&#xA;&#xA;// Generate OpenAPI documentation&#xA;&#xA;import sttp.apispec.openapi.circe.yaml._&#xA;import sttp.tapir.docs.openapi.OpenAPIDocsInterpreter&#xA;&#xA;val docs = OpenAPIDocsInterpreter().toOpenAPI(booksListing, &#34;My Bookshop&#34;, &#34;1.0&#34;)&#xA;println(docs.toYaml)&#xA;&#xA;&#xA;// Convert to akka-http Route&#xA;&#xA;import sttp.tapir.server.akkahttp.AkkaHttpServerInterpreter&#xA;import akka.http.scaladsl.server.Route&#xA;import scala.concurrent.Future&#xA;import scala.concurrent.ExecutionContext.Implicits.global&#xA;&#xA;def bookListingLogic(bfy: BooksQuery,&#xA;                     limit: Limit,&#xA;                     at: AuthToken): Future[Either[String, List[Book]]] =&#xA;  Future.successful(Right(List(Book(&#34;The Sorrows of Young Werther&#34;))))&#xA;  &#xA;val booksListingRoute: Route = AkkaHttpServerInterpreter()&#xA;  .toRoute(booksListing.serverLogic((bookListingLogic _).tupled))&#xA;&#xA;&#xA;// Convert to sttp Request&#xA;&#xA;import sttp.tapir.client.sttp.SttpClientInterpreter&#xA;import sttp.client3._&#xA;&#xA;val booksListingRequest: Request[DecodeResult[Either[String, List[Book]]], Any] = &#xA;  SttpClientInterpreter()&#xA;    .toRequest(booksListing, Some(uri&#34;http://localhost:8080&#34;))&#xA;    .apply((BooksQuery(&#34;SF&#34;, 2016), 20, &#34;xyz-abc-123&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;tapir documentation is available at &lt;a href=&#34;http://tapir.softwaremill.com&#34;&gt;tapir.softwaremill.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart with sbt&lt;/h2&gt; &#xA;&lt;p&gt;Add the following dependency:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sbt&#34;&gt;&#34;com.softwaremill.sttp.tapir&#34; %% &#34;tapir-core&#34; % &#34;1.0.0-RC2&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, import:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import sttp.tapir._&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And finally, type &lt;code&gt;endpoint.&lt;/code&gt; and see where auto-complete gets you!&lt;/p&gt; &#xA;&lt;h3&gt;Scala 2.12&lt;/h3&gt; &#xA;&lt;p&gt;Partial unification is now enabled by default from Scala 2.13. However, if you&#39;re using Scala 2.12 or older, then you&#39;ll need partial unification enabled in the compiler (alternatively, you&#39;ll need to manually provide type arguments in some cases):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sbt&#34;&gt;scalacOptions += &#34;-Ypartial-unification&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Sidenote for scala 2.12.4 and higher: if you encounter an issue with compiling your project because of a &lt;code&gt;StackOverflowException&lt;/code&gt; related to &lt;a href=&#34;https://github.com/scala/bug/issues/10604&#34;&gt;this&lt;/a&gt; scala bug, please increase your stack memory. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sbt -J-Xss4M clean compile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Other sttp projects&lt;/h2&gt; &#xA;&lt;p&gt;sttp is a family of Scala HTTP-related projects, and currently includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/softwaremill/sttp&#34;&gt;sttp client&lt;/a&gt;: the Scala HTTP client you always wanted!&lt;/li&gt; &#xA; &lt;li&gt;sttp tapir: this project&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/softwaremill/sttp-model&#34;&gt;sttp model&lt;/a&gt;: simple HTTP model classes (used by client &amp;amp; tapir)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/softwaremill/sttp-shared&#34;&gt;sttp shared&lt;/a&gt;: shared web socket, FP abstractions, capabilities and streaming code.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/softwaremill/sttp-apispec&#34;&gt;sttp apispec&lt;/a&gt;: OpenAPI, AsyncAPI and JSON Schema models.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;All suggestions welcome :)&lt;/p&gt; &#xA;&lt;p&gt;See the list of &lt;a href=&#34;https://github.com/softwaremill/tapir/issues&#34;&gt;issues&lt;/a&gt; and pick one! Or report your own.&lt;/p&gt; &#xA;&lt;p&gt;If you are having doubts on the &lt;em&gt;why&lt;/em&gt; or &lt;em&gt;how&lt;/em&gt; something works, don&#39;t hesitate to ask a question on &lt;a href=&#34;https://gitter.im/softwaremill/tapir&#34;&gt;gitter&lt;/a&gt; or via github. This probably means that the documentation, scaladocs or code is unclear and be improved for the benefit of all.&lt;/p&gt; &#xA;&lt;h3&gt;Testing locally&lt;/h3&gt; &#xA;&lt;p&gt;The JS tests use &lt;a href=&#34;https://github.com/scala-js/scala-js-env-selenium/issues/119&#34;&gt;Gecko instead of Chrome&lt;/a&gt;, although this causes another problem: out of memory when running JS tests for multiple modules. Work-arounds:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run only JVM tests for a specific Scala version using &lt;code&gt;testJVM2_13&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;test single JS projects&lt;/li&gt; &#xA; &lt;li&gt;use CI (GitHub Actions) to test all projects - the &lt;code&gt;.github/workflows/ci.yml&lt;/code&gt; enumerates them one by one&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can test only server/client/doc/other projects using &lt;code&gt;testServers&lt;/code&gt;, &lt;code&gt;testClients&lt;/code&gt;, &lt;code&gt;testDocs&lt;/code&gt; and &lt;code&gt;testOther&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To verify that the code snippet in docs compile, run &lt;code&gt;compileDocumentation&lt;/code&gt;. A full mdoc run is done during a release (when the documentation is generated).&lt;/p&gt; &#xA;&lt;h2&gt;Commercial Support&lt;/h2&gt; &#xA;&lt;p&gt;We offer commercial support for tapir and related technologies, as well as development services. &lt;a href=&#34;https://softwaremill.com&#34;&gt;Contact us&lt;/a&gt; to learn more about our offer!&lt;/p&gt; &#xA;&lt;h2&gt;Copyright&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (C) 2018-2022 SoftwareMill &lt;a href=&#34;https://softwaremill.com&#34;&gt;https://softwaremill.com&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>HariSekhon/Nagios-Plugin-Kafka</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/HariSekhon/Nagios-Plugin-Kafka</id>
    <link href="https://github.com/HariSekhon/Nagios-Plugin-Kafka" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Kafka Scala API CLI / Advanced Nagios Plugin, with Kerberos support (uses Kafka 0.9+ native Java API)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kafka Scala API - Advanced Nagios Plugin / CLI Tool with Kerberos support&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/harisekhon/Nagios-Plugin-Kafka?logo=github&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/network&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/harisekhon/Nagios-Plugin-Kafka?logo=github&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/HariSekhon/Nagios-Plugin-Kafka&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/commits/master&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/last-commit/HariSekhon/Nagios-Plugin-Kafka?logo=github&#34; alt=&#34;GitHub Last Commit&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!--&#xA;[![Dependency Status](https://www.versioneye.com/user/projects/57616d340a82b200276f6669/badge.svg)](https://www.versioneye.com/user/projects/57616d340a82b200276f6669)&#xA;--&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.codacy.com/gh/HariSekhon/Nagios-Plugin-Kafka/dashboard&#34;&gt;&lt;img src=&#34;https://app.codacy.com/project/badge/Grade/2f6cc8cba0ef4007a3f736bf45ae60f8&#34; alt=&#34;Codacy&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.codefactor.io/repository/github/harisekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://www.codefactor.io/repository/github/harisekhon/Nagios-Plugin-Kafka/badge&#34; alt=&#34;CodeFactor&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sonarcloud.io/dashboard?id=HariSekhon_Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=HariSekhon_Nagios-Plugin-Kafka&amp;amp;metric=alert_status&#34; alt=&#34;Quality Gate Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sonarcloud.io/dashboard?id=HariSekhon_Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=HariSekhon_Nagios-Plugin-Kafka&amp;amp;metric=sqale_rating&#34; alt=&#34;Maintainability Rating&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sonarcloud.io/dashboard?id=HariSekhon_Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=HariSekhon_Nagios-Plugin-Kafka&amp;amp;metric=reliability_rating&#34; alt=&#34;Reliability Rating&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sonarcloud.io/dashboard?id=HariSekhon_Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=HariSekhon_Nagios-Plugin-Kafka&amp;amp;metric=security_rating&#34; alt=&#34;Security Rating&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/OS-Linux-blue?logo=linux&#34; alt=&#34;Linux&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/OS-Mac-blue?logo=apple&#34; alt=&#34;Mac&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/harisekhon/nagios-plugin-kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/container-Docker-blue?logo=docker&amp;amp;logoColor=white&#34; alt=&#34;Docker&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Dockerfiles&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/repo-Dockerfiles-blue?logo=docker&amp;amp;logoColor=white&#34; alt=&#34;Dockerfile&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/harisekhon/nagios-plugin-kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/harisekhon/nagios-plugin-kafka?label=DockerHub%20pulls&amp;amp;logo=docker&amp;amp;logoColor=white&#34; alt=&#34;DockerHub Pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/harisekhon/nagios-plugin-kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/automated/harisekhon/nagios-plugin-kafka?logo=docker&amp;amp;logoColor=white&#34; alt=&#34;DockerHub Build Automated&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- these badges don&#39;t work any more&#xA;[![Docker Build Status](https://img.shields.io/docker/cloud/build/harisekhon/nagios-plugin-kafka?logo=docker&amp;logoColor=white)](https://hub.docker.com/r/harisekhon/nagios-plugin-kafka/builds)&#xA;[![MicroBadger](https://images.microbadger.com/badges/image/harisekhon/nagios-plugin-kafka.svg)](http://microbadger.com/#/images/harisekhon/nagios-plugin-kafka)&#xA;--&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://harisekhon.github.io/CI-CD/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/CI%20Builds-Overview%20Page-blue?logo=circleci&#34; alt=&#34;CI Builds Overview&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/raw/master/Jenkinsfile&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Jenkins-ready-blue?logo=jenkins&amp;amp;logoColor=white&#34; alt=&#34;Jenkins&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/raw/master/.concourse.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Concourse-ready-blue?logo=concourse&#34; alt=&#34;Concourse&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/raw/master/.gocd.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GoCD-ready-blue?logo=go&#34; alt=&#34;GoCD&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/TeamCity-CI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/TeamCity-ready-blue?logo=teamcity&#34; alt=&#34;TeamCity&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://circleci.com/gh/HariSekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/HariSekhon/Nagios-Plugin-Kafka.svg?style=svg&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://buildkite.com/hari-sekhon/nagios-plugin-kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/buildkite/835ba032422b5aa6c1df641e6a7989ac93bb8a34fcca735243/master?label=BuildKite&amp;amp;logo=buildkite&#34; alt=&#34;BuildKite&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ci.appveyor.com/project/HariSekhon/Nagios-Plugin-Kafka/branch/master&#34;&gt;&lt;img src=&#34;https://img.shields.io/appveyor/build/harisekhon/Nagios-Plugin-Kafka/master?logo=appveyor&amp;amp;label=AppVeyor&#34; alt=&#34;AppVeyor&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cloud.drone.io/HariSekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/drone/build/HariSekhon/Nagios-Plugin-Kafka/master?logo=drone&amp;amp;label=Drone&#34; alt=&#34;Drone&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codeship.com/projects/387257&#34;&gt;&lt;img src=&#34;https://app.codeship.com/projects/faff7930-3c5f-0138-8a0b-32bf6ef9714a/status?branch=master&#34; alt=&#34;Codeship Status for HariSekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://g.codefresh.io/pipelines/edit/new/builds?id=5e58e3573953b779e04b7907&amp;amp;pipeline=Nagios%20Plugin%20Kafka&amp;amp;projects=GitHub&amp;amp;projectId=5e52ca8ea284e00f882ea992&amp;amp;context=github&amp;amp;filter=page:1;pageSize:10;timeFrameStart:week&#34;&gt;&lt;img src=&#34;https://g.codefresh.io/api/badges/pipeline/harisekhon/GitHub%2FNagios%20Plugin%20Kafka?branch=master&amp;amp;key=eyJhbGciOiJIUzI1NiJ9.NWU1MmM5OGNiM2FiOWUzM2Y3ZDZmYjM3.O69674cW7vYom3v5JOGKXDbYgCVIJU9EWhXUMHl3zwA&amp;amp;type=cf-1&#34; alt=&#34;Codefresh&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cirrus-ci.com/github/HariSekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/cirrus/github/HariSekhon/Nagios-Plugin-Kafka/master?logo=Cirrus%20CI&amp;amp;label=Cirrus%20CI&#34; alt=&#34;Cirrus CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://harisekhon.semaphoreci.com/projects/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://harisekhon.semaphoreci.com/badges/Nagios-Plugin-Kafka.svg?sanitize=true&#34; alt=&#34;Semaphore&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.wercker.com/harisekhon/nagios-plugin-kafka/runs&#34;&gt;&lt;img src=&#34;https://app.wercker.com/status/fe4f87bf98f31e4c22a3041c0966644b/s/master&#34; alt=&#34;Wercker&#34; title=&#34;wercker status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/raw/master/buddy.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Buddy-ready-1A86FD?logo=buddy&#34; alt=&#34;Buddy&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/raw/master/shippable.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Shippable-legacy-lightgrey?logo=jfrog&amp;amp;label=Shippable&#34; alt=&#34;Shippable&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/raw/master/.travis.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/TravisCI-ready-blue?logo=travis&amp;amp;label=Travis%20CI&#34; alt=&#34;Travis CI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!--[![Wercker](https://img.shields.io/wercker/ci/5e58efdecdec020800455736/master?label=Wercker&amp;logo=oracle)](https://app.wercker.com/harisekhon/nagios-plugin-kafka/runs)--&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://dev.azure.com/harisekhon/GitHub/_build/latest?definitionId=11&amp;amp;branchName=master&#34;&gt;&lt;img src=&#34;https://dev.azure.com/harisekhon/GitHub/_apis/build/status/HariSekhon.Nagios-Plugin-Kafka?branchName=master&#34; alt=&#34;Azure DevOps Pipeline&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitlab.com/HariSekhon/Nagios-Plugin-Kafka/pipelines&#34;&gt;&lt;img src=&#34;https://img.shields.io/gitlab/pipeline/harisekhon/Nagios-Plugin-Kafka?logo=gitlab&amp;amp;label=GitLab%20CI&#34; alt=&#34;GitLab Pipeline&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://bitbucket.org/harisekhon/nagios-plugin-kafka/addon/pipelines/home#!/&#34;&gt;&lt;img src=&#34;https://img.shields.io/bitbucket/pipelines/harisekhon/nagios-plugin-kafka/master?logo=bitbucket&amp;amp;label=BitBucket%20CI&#34; alt=&#34;BitBucket Pipeline&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/raw/master/buildspec.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/AWS%20CodeBuild-ready-blue?logo=amazon%20aws&#34; alt=&#34;AWS CodeBuild&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/raw/master/cloudbuild.yaml&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GCP%20Cloud%20Build-ready-blue?logo=google%20cloud&amp;amp;logoColor=white&#34; alt=&#34;GCP Cloud Build&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://dev.azure.com/harisekhon/GitHub/_git/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/repo-Azure%20DevOps-0078D7?logo=azure%20devops&#34; alt=&#34;Repo on Azure DevOps&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/repo-GitHub-2088FF?logo=github&#34; alt=&#34;Repo on GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitlab.com/HariSekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/repo-GitLab-FCA121?logo=gitlab&#34; alt=&#34;Repo on GitLab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://bitbucket.org/HariSekhon/Nagios-Plugin-Kafka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/repo-BitBucket-0052CC?logo=bitbucket&#34; alt=&#34;Repo on BitBucket&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions/workflows/validate.yaml&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions/workflows/validate.yaml/badge.svg?sanitize=true&#34; alt=&#34;Validation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions/workflows/semgrep.yaml&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions/workflows/semgrep.yaml/badge.svg?sanitize=true&#34; alt=&#34;Semgrep&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions/workflows/kics.yaml&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions/workflows/kics.yaml/badge.svg?sanitize=true&#34; alt=&#34;Kics&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22GitHub+Actions+Ubuntu%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/GitHub%20Actions%20Ubuntu/badge.svg?sanitize=true&#34; alt=&#34;GitHub Actions Ubuntu&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Mac%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Mac/badge.svg?sanitize=true&#34; alt=&#34;Mac&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Mac+10.15%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Mac%2010.15/badge.svg?sanitize=true&#34; alt=&#34;Mac 10.15&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Ubuntu%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Ubuntu/badge.svg?sanitize=true&#34; alt=&#34;Ubuntu&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Ubuntu+16.04%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Ubuntu%2016.04/badge.svg?sanitize=true&#34; alt=&#34;Ubuntu 16.04&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Ubuntu+18.04%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Ubuntu%2018.04/badge.svg?sanitize=true&#34; alt=&#34;Ubuntu 18.04&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Ubuntu+20.04%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Ubuntu%2020.04/badge.svg?sanitize=true&#34; alt=&#34;Ubuntu 20.04&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Debian%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Debian/badge.svg?sanitize=true&#34; alt=&#34;Debian&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Debian+9%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Debian%209/badge.svg?sanitize=true&#34; alt=&#34;Debian 9&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Debian+10%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Debian%2010/badge.svg?sanitize=true&#34; alt=&#34;Debian 10&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22CentOS%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/CentOS/badge.svg?sanitize=true&#34; alt=&#34;CentOS&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22CentOS+7%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/CentOS%207/badge.svg?sanitize=true&#34; alt=&#34;CentOS 7&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22CentOS+8%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/CentOS%208/badge.svg?sanitize=true&#34; alt=&#34;CentOS 8&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Fedora%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Fedora/badge.svg?sanitize=true&#34; alt=&#34;Fedora&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Alpine%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Alpine/badge.svg?sanitize=true&#34; alt=&#34;Alpine&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Alpine+3%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Alpine%203/badge.svg?sanitize=true&#34; alt=&#34;Alpine 3&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Maven%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Maven/badge.svg?sanitize=true&#34; alt=&#34;Maven&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22SBT%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/SBT/badge.svg?sanitize=true&#34; alt=&#34;SBT&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/actions?query=workflow%3A%22Gradle%22&#34;&gt;&lt;img src=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/workflows/Gradle/badge.svg?sanitize=true&#34; alt=&#34;Gradle&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://git.io/nagios-plugin-kafka&#34;&gt;git.io/nagios-plugin-kafka&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Kafka 0.9+ API CLI Tester &amp;amp; Advanced Nagios Plugin with Kerberos support, written in Scala.&lt;/p&gt; &#xA;&lt;p&gt;Tested on Hortonworks HDP 2.4.0 with Kerberos + Ranger ACLs and Apache Kafka 0.8.x / 0.9.0.1 &lt;a href=&#34;https://hub.docker.com/r/harisekhon/kafka&#34;&gt;docker images&lt;/a&gt; with regular ACLs.&lt;/p&gt; &#xA;&lt;p&gt;You may need to change the Kafka library version in &lt;code&gt;pom.xml&lt;/code&gt; / &lt;code&gt;build.sbt&lt;/code&gt; / &lt;code&gt;build.gradle&lt;/code&gt; before building to match your deployed Kafka server / cluster otherwise it may hang when run due to version / protocol mismatch.&lt;/p&gt; &#xA;&lt;!--&#xA;Testing shows it does take an extra second to negotiate the Kerberos authentication so make sure not to set ```--timeout``` to less than 2 secs if using Kerberos.&#xA;--&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugins#advanced-nagios-plugins-collection&#34;&gt;The Advanced Nagios Plugins Collection&lt;/a&gt; for many more related enterprise monitoring programs.&lt;/p&gt; &#xA;&lt;p&gt;Hari Sekhon&lt;/p&gt; &#xA;&lt;p&gt;Cloud &amp;amp; Big Data Contractor, United Kingdom&lt;/p&gt; &#xA;&lt;p&gt;(ex-Cloudera, former Hortonworks Consultant)&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/HariSekhon/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/LinkedIn%20Profile-HariSekhon-blue?logo=linkedin&#34; alt=&#34;My LinkedIn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h6&gt;(you&#39;re welcome to connect with me on LinkedIn)&lt;/h6&gt; &#xA;&lt;h2&gt;Intro&lt;/h2&gt; &#xA;&lt;p&gt;This project builds a single self-contained Java jar file with all dependencies included and can simply be run on the command line with full switch option support:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;java -jar check_kafka.jar --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and there is an optional convenience shell wrapper script at the top level to make commands shorter:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./check_kafka --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run against one or more Kafka brokers, comma separated:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./check_kafka --brokers localhost:9092 --topic test&#xA;OK: Kafka broker successfully returned unique message via topic &#39;test&#39; partition &#39;0&#39;, write time = 0.185s, read time = 0.045s, total time = 1.729s | write_time=0.185s read_time=0.045s total_time=1.729s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use the &lt;code&gt;--verbose&lt;/code&gt; switch to also show the brokers list that were tested. If you have specified one of the kerberos switches (or edited the consumer/producer properties files to do so) then the output will additionally contain the marker &lt;code&gt;with sasl authentication&lt;/code&gt; to let you know that it was a secure configuration that was tested (originally I called this &lt;code&gt;with kerberos&lt;/code&gt; but technically it may not be in future).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;OK: Kafka broker &#39;&amp;lt;hortonworks_host&amp;gt;:6667&#39; successfully returned unique message via topic &#39;topic3&#39; partition &#39;0&#39; with sasl authentication, write time = 0.148s, read time = 0.043s, total time = 0.691s | write_time=0.148s read_time=0.043s total_time=0.691s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Kafka 0.9+ API Caveats&lt;/h5&gt; &#xA;&lt;p&gt;This program only supports Kafka 0.9+ as the API changed (again) and Kerberos security was only added in the 0.9 API. For Kafka versions before 0.9 you can find Python and Perl versions of this program in the &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugins#advanced-nagios-plugins-collection&#34;&gt;Advanced Nagios Plugins Collection&lt;/a&gt; that support 0.8 onwards (they dosn&#39;t support Kafka &amp;lt;= 0.7 as the API changed in 0.8 too and the underlying libraries in those languages don&#39;t support Kafka &amp;lt;= 0.7).&lt;/p&gt; &#xA;&lt;p&gt;It appears that several errors are caught too early in the new Kafka Java API and result in embedded looping retry behaviour on encountering errors (visible in debug level logging of the base library).&lt;/p&gt; &#xA;&lt;p&gt;I haven&#39;t found a great way of handle that behaviour as it&#39;s not exposed to the client code so it ends up being handled via my generic default self timeout mechanism that I apply to all my tools. Hence if you specify an incorrect &lt;code&gt;--brokers &amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;&lt;/code&gt; or the Kafka brokers are down or you fail to negotiate the protocol due to security settings you will only receive a generic &lt;code&gt;UNKNOWN: self timed out after 10 secs&lt;/code&gt; message as the code self terminates.&lt;/p&gt; &#xA;&lt;p&gt;Otherwise the Kafka API would just hang there indefintely as it keeps retrying deeper in the library. I&#39;ve tried various settings to get it to time out but nothing worked and I even posted to the Kafka users mailing list without an answer. If you know of a setting that will make the Kafka Client library time out and return the more specific error then please let me know and I&#39;ll update this code accordingly.&lt;/p&gt; &#xA;&lt;h4&gt;Kerberos Support&lt;/h4&gt; &#xA;&lt;p&gt;See the &lt;code&gt;conf/&lt;/code&gt; directory for JAAS kerberos configurations.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re running the code on a Hortonworks Kafka broker it&#39;ll auto-detect the HDP configuration and use that.&lt;/p&gt; &#xA;&lt;h3&gt;Build&lt;/h3&gt; &#xA;&lt;h4&gt;Quick Start - Docker&lt;/h4&gt; &#xA;&lt;p&gt;A Dockerized pre-built version is available on &lt;a href=&#34;https://hub.docker.com/r/harisekhon/nagios-plugin-kafka&#34;&gt;DockerHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you have docker installed this one command will download and run it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run harisekhon/nagios-plugin-kafka check_kafka --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Automated Build from Source&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl -L https://git.io/nagios-plugin-kafka-bootstrap | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;OR&lt;/p&gt; &#xA;&lt;p&gt;Maven, Gradle and SBT automated builds are all provided.&lt;/p&gt; &#xA;&lt;p&gt;A self-contained jar file with all dependencies will be created and symlinked to &lt;code&gt;check_kafka.jar&lt;/code&gt; at the top level.&lt;/p&gt; &#xA;&lt;p&gt;The Maven and Gradle builds are best as they will auto bootstap and run with no prior installed dependencies other than Java and &lt;code&gt;make&lt;/code&gt; to kick it off.&lt;/p&gt; &#xA;&lt;p&gt;The default &lt;code&gt;make&lt;/code&gt; build will trigger a Gradle bootstrap from scratch with an embedded checksum for security:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can call any one of the 3 major build systems explicitly instead, which will recurse to build the library submodule using the same mechanism:&lt;/p&gt; &#xA;&lt;p&gt;Maven:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make mvn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Gradle:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make gradle&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;SBT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make sbt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Custom TLDs&lt;/h5&gt; &#xA;&lt;p&gt;If using bespoke internal domains such as &lt;code&gt;.local&lt;/code&gt;, &lt;code&gt;.intranet&lt;/code&gt;, &lt;code&gt;.vm&lt;/code&gt;, &lt;code&gt;.cloud&lt;/code&gt; etc. that aren&#39;t part of the official IANA TLD list then this is additionally supported via a custom configuration file &lt;a href=&#34;https://github.com/HariSekhon/lib-java/raw/master/src/main/resources/tlds-alpha-by-domain.txt&#34;&gt;lib/resources/custom_tlds.txt&lt;/a&gt; containing one TLD per line, with support for # comment prefixes. Just add your bespoke internal TLD to the file and it will then pass the host/domain/fqdn validations.&lt;/p&gt; &#xA;&lt;h4&gt;Testing&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/HariSekhon/nagios-plugin-kafka&#34;&gt;Continuous Integration&lt;/a&gt; is run on this repo with tests for success and failure scenarios:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;unit tests for the custom supporting &lt;a href=&#34;https://github.com/HariSekhon/lib-java&#34;&gt;java library&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;integration tests of the top level programs using the libraries for things like option parsing&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugin-Kafka/tree/master/tests&#34;&gt;functional tests&lt;/a&gt; for the top level programs using &lt;a href=&#34;https://hub.docker.com/u/harisekhon/&#34;&gt;Docker containers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To trigger all tests run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;which will start with the underlying libraries, then move on to top level integration tests and functional tests using docker containers if docker is available.&lt;/p&gt; &#xA;&lt;h3&gt;Kafka 0.8 support - Alternative Perl &amp;amp; Python Kafka API Nagios Plugins&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugins#advanced-nagios-plugins-collection&#34;&gt;Advanced Nagios Plugins Collection&lt;/a&gt; has both Perl and Python predecessors to this program which work with Kafka 0.8+. The main differenitator with this Scala version is that it uses the new native 0.9+ Java API which has Kerberos support (the dynamic language versions were built on libraries for Kafka 0.8).&lt;/p&gt; &#xA;&lt;h3&gt;See Also&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/DevOps-Bash-tools&#34;&gt;DevOps Bash Tools&lt;/a&gt; - 700+ DevOps Bash Scripts, Advanced &lt;code&gt;.bashrc&lt;/code&gt;, &lt;code&gt;.vimrc&lt;/code&gt;, &lt;code&gt;.screenrc&lt;/code&gt;, &lt;code&gt;.tmux.conf&lt;/code&gt;, &lt;code&gt;.gitconfig&lt;/code&gt;, CI configs &amp;amp; Utility Code Library - AWS, GCP, Kubernetes, Docker, Kafka, Hadoop, SQL, BigQuery, Hive, Impala, PostgreSQL, MySQL, LDAP, DockerHub, Jenkins, Spotify API &amp;amp; MP3 tools, Git tricks, GitHub API, GitLab API, BitBucket API, Code &amp;amp; build linting, package management for Linux / Mac / Python / Perl / Ruby / NodeJS / Golang, and lots more random goodies&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/SQL-scripts&#34;&gt;SQL Scripts&lt;/a&gt; - 100+ SQL Scripts - PostgreSQL, MySQL, AWS Athena, Google BigQuery&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/Templates&#34;&gt;Templates&lt;/a&gt; - dozens of Code &amp;amp; Config templates - AWS, GCP, Docker, Jenkins, Terraform, Vagrant, Puppet, Python, Bash, Go, Perl, Java, Scala, Groovy, Maven, SBT, Gradle, Make, GitHub Actions Workflows, CircleCI, Jenkinsfile, Makefile, Dockerfile, docker-compose.yml, M4 etc.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/Kubernetes-configs&#34;&gt;Kubernetes configs&lt;/a&gt; - Kubernetes YAML configs - Best Practices, Tips &amp;amp; Tricks are baked right into the templates for future deployments&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/DevOps-Python-tools&#34;&gt;DevOps Python Tools&lt;/a&gt; - 80+ DevOps CLI tools for AWS, GCP, Hadoop, HBase, Spark, Log Anonymizer, Ambari Blueprints, AWS CloudFormation, Linux, Docker, Spark Data Converters &amp;amp; Validators (Avro / Parquet / JSON / CSV / INI / XML / YAML), Elasticsearch, Solr, Travis CI, Pig, IPython&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/Nagios-Plugins&#34;&gt;The Advanced Nagios Plugins Collection&lt;/a&gt; - 450+ programs for Nagios monitoring your Hadoop &amp;amp; NoSQL clusters. Covers every Hadoop vendor&#39;s management API and every major NoSQL technology (HBase, Cassandra, MongoDB, Elasticsearch, Solr, Riak, Redis etc.) as well as message queues (Kafka, RabbitMQ), continuous integration (Jenkins, Travis CI) and traditional infrastructure (SSL, Whois, DNS, Linux)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/harisekhon/perl-tools&#34;&gt;DevOps Perl Tools&lt;/a&gt; - 25+ DevOps CLI tools for Hadoop, HDFS, Hive, Solr/SolrCloud CLI, Log Anonymizer, Nginx stats &amp;amp; HTTP(S) URL watchers for load balanced web farms, Dockerfiles &amp;amp; SQL ReCaser (MySQL, PostgreSQL, AWS Redshift, Snowflake, Apache Drill, Hive, Impala, Cassandra CQL, Microsoft SQL Server, Oracle, Couchbase N1QL, Dockerfiles, Pig Latin, Neo4j, InfluxDB), Ambari FreeIPA Kerberos, Datameer, Linux...&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/HAProxy-configs&#34;&gt;HAProxy Configs&lt;/a&gt; - 80+ HAProxy Configs for Hadoop, Big Data, NoSQL, Docker, Elasticsearch, SolrCloud, HBase, Cloudera, Hortonworks, MapR, MySQL, PostgreSQL, Apache Drill, Hive, Presto, Impala, ZooKeeper, OpenTSDB, InfluxDB, Prometheus, Kibana, Graphite, SSH, RabbitMQ, Redis, Riak, Rancher etc.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/HariSekhon/Dockerfiles&#34;&gt;Dockerfiles&lt;/a&gt; - 50+ DockerHub public images for Docker &amp;amp; Kubernetes - Hadoop, Kafka, ZooKeeper, HBase, Cassandra, Solr, SolrCloud, Presto, Apache Drill, Nifi, Spark, Mesos, Consul, Riak, OpenTSDB, Jython, Advanced Nagios Plugins &amp;amp; DevOps Tools repos on Alpine, CentOS, Debian, Fedora, Ubuntu, Superset, H2O, Serf, Alluxio / Tachyon, FakeS3&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://git.io/nagios-plugin-kafka&#34;&gt;git.io/nagios-plugin-kafka&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>allenai/common</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/allenai/common</id>
    <link href="https://github.com/allenai/common" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A collection of useful utility classes and functions.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;common&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://circleci.com/gh/allenai/common/tree/master&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/allenai/common/tree/master.svg?style=svg&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A collection of useful utility classes and functions. Slowly on the path to deprecation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;testkit&lt;/code&gt; - Unit test classes and utilities.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;guice&lt;/code&gt; - Guice-specific libraries.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;core&lt;/code&gt; - Catchall collection of utilities.&lt;/p&gt; &#xA;&lt;h2&gt;Using this project as a library&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;common&lt;/code&gt; is published to &lt;a href=&#34;https://us-west-2.console.aws.amazon.com/codesuite/codeartifact/d/896129387501/org-allenai-s2/r/private?region=us-west-2&#34;&gt;CodeArtifact&lt;/a&gt;. You will need to add a resolver via the &lt;a href=&#34;https://github.com/bbstilson/sbt-codeartifact/&#34;&gt;&lt;code&gt;sbt-codeartifact&lt;/code&gt;&lt;/a&gt; plugin to use these libraries.&lt;/p&gt; &#xA;&lt;h2&gt;Releasing new versions&lt;/h2&gt; &#xA;&lt;p&gt;To make a release:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sbt&#34;&gt;&amp;gt; release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Guideline for Contributing to &lt;code&gt;common&lt;/code&gt;&lt;/h2&gt; &#xA;&lt;p&gt;There is no strict process for contributing to &lt;code&gt;common&lt;/code&gt;. However, following are some general guidelines.&lt;/p&gt; &#xA;&lt;h3&gt;Discuss in Pull Request Code Reviews&lt;/h3&gt; &#xA;&lt;p&gt;If you have implemented something in a repository other than &lt;code&gt;common&lt;/code&gt; and that you think could be a candidate to be migrated into &lt;code&gt;common&lt;/code&gt;, ask reviewers for feedback when issuing your pull request.&lt;/p&gt; &#xA;&lt;h3&gt;Create a GitHub Issue&lt;/h3&gt; &#xA;&lt;p&gt;Feel free create a GitHub issue in the &lt;code&gt;common&lt;/code&gt; project to provide traceability and a forum for discussion.&lt;/p&gt; &#xA;&lt;h3&gt;Use TODO Comments&lt;/h3&gt; &#xA;&lt;p&gt;While working on a task, go ahead and implement the functionality that you think would be a good fit for &lt;code&gt;common&lt;/code&gt;, and comment the implementation with a TODO suggesting it belongs in &lt;code&gt;common&lt;/code&gt;. An example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;// TODO(mygithubusername): migrate to common&#xA;object ResourceHandling {&#xA;  type Resource = { def close(): Unit }&#xA;  def using[A](resource: =&amp;gt; Resource)(f: Resource =&amp;gt; A) {&#xA;    try {&#xA;      f(resource)&#xA;    finally {&#xA;      resource.close()&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have created a GitHub issue for the &lt;code&gt;common&lt;/code&gt; candidate, it is a good idea for traceability to reference the issue number in your TODO comment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;// TODO(mygithubusername): migrate to common. See https://github.com/allenai/common/issues/123&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Have Two Code Reviewers to &lt;code&gt;common&lt;/code&gt; Pull Requests&lt;/h3&gt; &#xA;&lt;p&gt;Try and always have at least two reviewers for a pull request to &lt;code&gt;common&lt;/code&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>datastax/spark-cassandra-connector</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/datastax/spark-cassandra-connector</id>
    <link href="https://github.com/datastax/spark-cassandra-connector" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DataStax Spark Cassandra Connector&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Spark Cassandra Connector&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/actions?query=branch%3Amaster&#34;&gt;&lt;img src=&#34;https://github.com/datastax/spark-cassandra-connector/actions/workflows/main.yml/badge.svg?branch=master&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Links&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;What&lt;/th&gt; &#xA;   &lt;th&gt;Where&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Community&lt;/td&gt; &#xA;   &lt;td&gt;Chat with us at &lt;a href=&#34;https://community.datastax.com/index.html&#34;&gt;Datastax and Cassandra Q&amp;amp;A&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Scala Docs&lt;/td&gt; &#xA;   &lt;td&gt;Most Recent Release (3.2.0): &lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.2.0/connector/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;, &lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.2.0/driver/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector-Driver&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Latest Production Release&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://search.maven.org/artifact/com.datastax.spark/spark-cassandra-connector_2.12/3.2.0/jar&#34;&gt;3.2.0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Lightning-fast cluster computing with Apache Sparkâ„¢ and Apache CassandraÂ®.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;This library lets you expose Cassandra tables as Spark RDDs and Datasets/DataFrames, write Spark RDDs and Datasets/DataFrames to Cassandra tables, and execute arbitrary CQL queries in your Spark applications.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Compatible with Apache Cassandra version 2.1 or higher (see table below)&lt;/li&gt; &#xA; &lt;li&gt;Compatible with Apache Spark 1.0 through 3.2 (&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/#version-compatibility&#34;&gt;see table below&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Compatible with Scala 2.11 and 2.12&lt;/li&gt; &#xA; &lt;li&gt;Exposes Cassandra tables as Spark RDDs and Datasets/DataFrames&lt;/li&gt; &#xA; &lt;li&gt;Maps table rows to CassandraRow objects or tuples&lt;/li&gt; &#xA; &lt;li&gt;Offers customizable object mapper for mapping rows to objects of user-defined classes&lt;/li&gt; &#xA; &lt;li&gt;Saves RDDs back to Cassandra by implicit &lt;code&gt;saveToCassandra&lt;/code&gt; call&lt;/li&gt; &#xA; &lt;li&gt;Delete rows and columns from cassandra by implicit &lt;code&gt;deleteFromCassandra&lt;/code&gt; call&lt;/li&gt; &#xA; &lt;li&gt;Join with a subset of Cassandra data using &lt;code&gt;joinWithCassandraTable&lt;/code&gt; call for RDDs, and optimizes join with data in Cassandra when using Datasets/DataFrames&lt;/li&gt; &#xA; &lt;li&gt;Partition RDDs according to Cassandra replication using &lt;code&gt;repartitionByCassandraReplica&lt;/code&gt; call&lt;/li&gt; &#xA; &lt;li&gt;Converts data types between Cassandra and Scala&lt;/li&gt; &#xA; &lt;li&gt;Supports all Cassandra data types including collections&lt;/li&gt; &#xA; &lt;li&gt;Filters rows on the server side via the CQL &lt;code&gt;WHERE&lt;/code&gt; clause&lt;/li&gt; &#xA; &lt;li&gt;Allows for execution of arbitrary CQL statements&lt;/li&gt; &#xA; &lt;li&gt;Plays nice with Cassandra Virtual Nodes&lt;/li&gt; &#xA; &lt;li&gt;Could be used in all languages supporting Datasets/DataFrames API: Python, R, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Version Compatibility&lt;/h2&gt; &#xA;&lt;p&gt;The connector project has several branches, each of which map into different supported versions of Spark and Cassandra. For previous releases the branch is named &#34;bX.Y&#34; where X.Y is the major+minor version; for example the &#34;b1.6&#34; branch corresponds to the 1.6 release. The &#34;master&#34; branch will normally contain development for the next connector release in progress.&lt;/p&gt; &#xA;&lt;p&gt;Currently, the following branches are actively supported: 3.2.x (&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/tree/master&#34;&gt;master&lt;/a&gt;), 3.1.x (&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/tree/b3.1&#34;&gt;b3.1&lt;/a&gt;), 3.0.x (&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/tree/b3.0&#34;&gt;b3.0&lt;/a&gt;) and 2.5.x (&lt;a href=&#34;https://github.com/datastax/spark-cassandra-connector/tree/b2.5&#34;&gt;b2.5&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Connector&lt;/th&gt; &#xA;   &lt;th&gt;Spark&lt;/th&gt; &#xA;   &lt;th&gt;Cassandra&lt;/th&gt; &#xA;   &lt;th&gt;Cassandra Java Driver&lt;/th&gt; &#xA;   &lt;th&gt;Minimum Java Version&lt;/th&gt; &#xA;   &lt;th&gt;Supported Scala Versions&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3.2&lt;/td&gt; &#xA;   &lt;td&gt;3.2&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x, 4.0&lt;/td&gt; &#xA;   &lt;td&gt;4.13&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3.1&lt;/td&gt; &#xA;   &lt;td&gt;3.1&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x, 4.0&lt;/td&gt; &#xA;   &lt;td&gt;4.12&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x, 4.0&lt;/td&gt; &#xA;   &lt;td&gt;4.12&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.5&lt;/td&gt; &#xA;   &lt;td&gt;2.4&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x, 4.0&lt;/td&gt; &#xA;   &lt;td&gt;4.12&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.11, 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.4.2&lt;/td&gt; &#xA;   &lt;td&gt;2.4&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.11, 2.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.4&lt;/td&gt; &#xA;   &lt;td&gt;2.4&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.3&lt;/td&gt; &#xA;   &lt;td&gt;2.3&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;   &lt;td&gt;2.0, 2.1, 2.2&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.x&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.6&lt;/td&gt; &#xA;   &lt;td&gt;1.6&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.5&lt;/td&gt; &#xA;   &lt;td&gt;1.5, 1.6&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.4&lt;/td&gt; &#xA;   &lt;td&gt;1.4&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*&lt;/td&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.3&lt;/td&gt; &#xA;   &lt;td&gt;1.3&lt;/td&gt; &#xA;   &lt;td&gt;2.1.5*&lt;/td&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.2&lt;/td&gt; &#xA;   &lt;td&gt;1.2&lt;/td&gt; &#xA;   &lt;td&gt;2.1, 2.0&lt;/td&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.1&lt;/td&gt; &#xA;   &lt;td&gt;1.1, 1.0&lt;/td&gt; &#xA;   &lt;td&gt;2.1, 2.0&lt;/td&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.0&lt;/td&gt; &#xA;   &lt;td&gt;1.0, 0.9&lt;/td&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;2.10, 2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;*&lt;em&gt;Compatible with 2.1.X where X &amp;gt;= 5&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Hosted API Docs&lt;/h2&gt; &#xA;&lt;p&gt;API documentation for the Scala and Java interfaces are available online:&lt;/p&gt; &#xA;&lt;h3&gt;3.2.0&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.2.0/connector/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;3.1.0&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.1.0/connector/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;3.0.1&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/3.0.1/connector/com/datastax/spark/connector/index.html&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2.5.2&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datastax.github.io/spark-cassandra-connector/ApiDocs/2.5.2/connector/#package&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2.4.2&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.4.2/spark-cassandra-connector/&#34;&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.4.2/spark-cassandra-connector-embedded/&#34;&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;This project is available on the Maven Central Repository. For SBT to download the connector binaries, sources and javadoc, put this in your project SBT config:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;libraryDependencies += &#34;com.datastax.spark&#34; %% &#34;spark-cassandra-connector&#34; % &#34;3.2.0&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The default Scala version for Spark 3.0+ is 2.12 please choose the appropriate build. See the &lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/FAQ.md&#34;&gt;FAQ&lt;/a&gt; for more information.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/12_building_and_artifacts.md&#34;&gt;Building And Artifacts&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/0_quick_start.md&#34;&gt;Quick-start guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/1_connecting.md&#34;&gt;Connecting to Cassandra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/2_loading.md&#34;&gt;Loading datasets from Cassandra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/3_selection.md&#34;&gt;Server-side data selection and filtering&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/4_mapper.md&#34;&gt;Working with user-defined case classes and tuples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/5_saving.md&#34;&gt;Saving and deleting datasets to/from Cassandra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/6_advanced_mapper.md&#34;&gt;Customizing the object mapping&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/7_java_api.md&#34;&gt;Using Connector in Java&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/8_streaming.md&#34;&gt;Spark Streaming with Cassandra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/10_embedded.md&#34;&gt;The spark-cassandra-connector-embedded Artifact&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/11_metrics.md&#34;&gt;Performance monitoring&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/12_building_and_artifacts.md&#34;&gt;Building And Artifacts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/13_spark_shell.md&#34;&gt;The Spark Shell&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/14_data_frames.md&#34;&gt;DataFrames&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/15_python.md&#34;&gt;Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/16_partitioning.md&#34;&gt;Partitioner&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/17_submitting.md&#34;&gt;Submitting applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/FAQ.md&#34;&gt;Frequently Asked Questions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/reference.md&#34;&gt;Configuration Parameter Reference Table&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/developers.md&#34;&gt;Tips for Developing the Spark Cassandra Connector&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Online Training&lt;/h2&gt; &#xA;&lt;h3&gt;DataStax Academy&lt;/h3&gt; &#xA;&lt;p&gt;DataStax Academy provides free online training for Apache Cassandra and DataStax Enterprise. In &lt;a href=&#34;https://academy.datastax.com/courses/ds320-analytics-with-apache-spark&#34;&gt;DS320: Analytics with Spark&lt;/a&gt;, you will learn how to effectively and efficiently solve analytical problems with Apache Spark, Apache Cassandra, and DataStax Enterprise. You will learn about Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;h3&gt;Reporting Bugs&lt;/h3&gt; &#xA;&lt;p&gt;New issues may be reported using &lt;a href=&#34;https://datastax-oss.atlassian.net/browse/SPARKC/&#34;&gt;JIRA&lt;/a&gt;. Please include all relevant details including versions of Spark, Spark Cassandra Connector, Cassandra and/or DSE. A minimal reproducible case with sample code is ideal.&lt;/p&gt; &#xA;&lt;h3&gt;Mailing List&lt;/h3&gt; &#xA;&lt;p&gt;Questions and requests for help may be submitted to the &lt;a href=&#34;https://groups.google.com/a/lists.datastax.com/forum/#!forum/spark-connector-user&#34;&gt;user mailing list&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Q/A Exchange&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://community.datastax.com/index.html&#34;&gt;DataStax Community&lt;/a&gt; provides a free question and answer website for any and all questions relating to any DataStax Related technology. Including the Spark Cassandra Connector. Both DataStax engineers and community members frequent this board and answer questions.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;To protect the community, all contributors are required to sign the &lt;a href=&#34;http://spark-cassandra-connector-cla.datastax.com/&#34;&gt;DataStax Spark Cassandra Connector Contribution License Agreement&lt;/a&gt;. The process is completely electronic and should only take a few minutes.&lt;/p&gt; &#xA;&lt;p&gt;To develop this project, we recommend using IntelliJ IDEA. Make sure you have installed and enabled the Scala Plugin. Open the project with IntelliJ IDEA and it will automatically create the project structure from the provided SBT configuration.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/developers.md&#34;&gt;Tips for Developing the Spark Cassandra Connector&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Checklist for contributing changes to the project:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a &lt;a href=&#34;https://datastax-oss.atlassian.net/projects/SPARKC/issues&#34;&gt;SPARKC JIRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Make sure that all unit tests and integration tests pass&lt;/li&gt; &#xA; &lt;li&gt;Add an appropriate entry at the top of CHANGES.txt&lt;/li&gt; &#xA; &lt;li&gt;If the change has any end-user impacts, also include changes to the ./doc files as needed&lt;/li&gt; &#xA; &lt;li&gt;Prefix the pull request description with the JIRA number, for example: &#34;SPARKC-123: Fix the ...&#34;&lt;/li&gt; &#xA; &lt;li&gt;Open a pull-request on GitHub and await review&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;p&gt;To run unit and integration tests:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sbt/sbt test&#xA;./sbt/sbt it:test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the integration tests require &lt;a href=&#34;https://github.com/riptano/ccm&#34;&gt;CCM&lt;/a&gt; to be installed on your machine. See &lt;a href=&#34;https://raw.githubusercontent.com/datastax/spark-cassandra-connector/master/doc/developers.md&#34;&gt;Tips for Developing the Spark Cassandra Connector&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;By default, integration tests start up a separate, single Cassandra instance and run Spark in local mode. It is possible to run integration tests with your own Cassandra and/or Spark cluster. First, prepare a jar with testing code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sbt/sbt test:package&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then copy the generated test jar to your Spark nodes and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export IT_TEST_CASSANDRA_HOST=&amp;lt;IP of one of the Cassandra nodes&amp;gt;&#xA;export IT_TEST_SPARK_MASTER=&amp;lt;Spark Master URL&amp;gt;&#xA;./sbt/sbt it:test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Generating Documents&lt;/h2&gt; &#xA;&lt;p&gt;To generate the Reference Document use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sbt/sbt spark-cassandra-connector-unshaded/run (outputLocation)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;outputLocation defaults to doc/reference.md&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright 2014-2017, DataStax, Inc.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>allenai/nlpstack</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/allenai/nlpstack</id>
    <link href="https://github.com/allenai/nlpstack" rel="alternate"></link>
    <summary type="html">&lt;p&gt;NLP toolkit (tokenizer, POS-tagger, parser, etc.)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NLP Stack&lt;/h1&gt; &#xA;&lt;p&gt;This contains our basic stack of NLP tools. You can play with them &lt;a href=&#34;http://nlpstack.dev.allenai.org:8062/tools.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We have general interfaces on each tool so we have a clear definition of the inputs and outputs of each tool and so we can change the underlying implementation of a tool.&lt;/p&gt; &#xA;&lt;p&gt;Each tool also has a serialization format for its output. For example, there is a dependency string format and a chunked sentence string format.&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Add NLPStack to your dependencies. NLPStack comes as a collection of multiple tools (see below). To declare dependencies, you can use this code in your Build.scala file:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies += &#34;org.allenai.nlpstack&#34; %% &#34;nlpstack-core&#34; % &#34;0.x&#34;&#xA;&#xA;libraryDependencies += &#34;org.allenai.nlpstack&#34; %% &#34;nlpstack-parse&#34; % &#34;0.x&#34;&#xA;&#xA;libraryDependencies += &#34;org.allenai.nlpstack&#34; %% &#34;nlpstack-postag&#34; % &#34;0.x&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As an option, you can define a function for the various nlpstack components, and use them like this:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def nlpstackModule(id: String) = &#34;org.allenai.nlpstack&#34; %% s&#34;nlpstack-${id}&#34; % &#34;0.x&#34;&#xA;&#xA;libraryDependencies += nlpstackModule(&#34;parse&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start using NLPStack. Here is a quick code snippet that parses a sentence:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.allenai.nlpstack.tokenize.defaultTokenizer&#xA;import org.allenai.nlpstack.postag.defaultPostagger&#xA;import org.allenai.nlpstack.parse.defaultDependencyParser&#xA;&#xA;/* ... */&#xA;&#xA;val tokens = defaultTokenizer.tokenize(&#xA;  &#34;I was wondering why the ball kept getting bigger and bigger, and then it hit me.&#34;)&#xA;val postaggedTokens = defaultPostagger.postagTokenized(tokens)&#xA;val dependencyGraph = defaultDependencyParser.dependencyGraphPostagged(postaggedTokens)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Folder Layout&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;tools: this project contains the main Nlpstack code.&lt;/li&gt; &#xA; &lt;li&gt;webapp: a web application for running tools and visualizing serialized representations.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Tools in the Kit&lt;/h2&gt; &#xA;&lt;p&gt;Presently the AI Toolkit includes the following tools.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tokenizer&lt;/strong&gt;. Break a sentence into &#34;word&#34; tokens.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Lemmatizer&lt;/strong&gt;. Associate a base form to a token or a Part-of-Speech (POS) tagged token. The results will be more accurate if POS tags are available.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Postagger&lt;/strong&gt;. Associate a POS tag with a token.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chunker&lt;/strong&gt;. Associate chunk ranges with POS-tagged tokens.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Dependency Parser&lt;/strong&gt;. Construct dependencies between POS-tagged tokens.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Segmenter&lt;/strong&gt;. Split a body of text into sentences.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Each tool includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;An API so it can be called programatically.&lt;/li&gt; &#xA; &lt;li&gt;A CLI application so it can be run in batch.&lt;/li&gt; &#xA; &lt;li&gt;A simple REST server so it can be called remotely.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Tool Subprojects&lt;/h2&gt; &#xA;&lt;p&gt;Nlpstack is split up into multiple subprojects to minimize the number of dependencies needed to install components. The source for each of these is in &lt;code&gt;tools/${projectName}&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;tools-core&lt;/code&gt;: This contains all of the APIs needed for interoperating with Nlpstack, but none of the implementations. &lt;code&gt;tools-segment&lt;/code&gt;: Implementation of the segmenter. Depends on &lt;code&gt;core&lt;/code&gt;. &lt;code&gt;tools-lemmatize&lt;/code&gt;: Implementation of the lemmatizer. Depends on &lt;code&gt;core&lt;/code&gt;. &lt;code&gt;tools-tokenize&lt;/code&gt;: Implementation of the tokenizer. Depends on &lt;code&gt;core&lt;/code&gt;. &lt;code&gt;tools-postag&lt;/code&gt;: Implementation of the POS tagger. Depends on &lt;code&gt;tokenize&lt;/code&gt;. &lt;code&gt;tools-chunk&lt;/code&gt;: Implementation of the sentence chunker. Depends on &lt;code&gt;postag&lt;/code&gt;. &lt;code&gt;tools-parse&lt;/code&gt;: Implementation of the dependency parser. Depends on &lt;code&gt;postag&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;These each produce a single artifact, named &lt;code&gt;nlptools-${projectName}&lt;/code&gt;. A client should depend on every implementation they will be using, as well as &lt;code&gt;nlpstack-core&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;These all use the group &lt;code&gt;org.allenai.nlpstack&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;So, if you wanted to use the tokenizer, you should have the dependencies (in sbt):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;org.allenai.nlpstack&#34; %% &#34;nlpstack-core&#34; % &#34;2014.6.23-1-SNAPSHOT&#34;&#xA;&#34;org.allenai.nlpstack&#34; %% &#34;nlpstack-tokenize&#34; % &#34;2014.6.23-1-SNAPSHOT&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The current version is in &lt;a href=&#34;https://raw.githubusercontent.com/allenai/nlpstack/master/version.sbt&#34;&gt;version.sbt&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Parsing API Details&lt;/h3&gt; &#xA;&lt;p&gt;The example in &#34;Getting Started&#34; shows how to generate a &lt;a href=&#34;https://github.com/allenai/nlpstack/raw/master/tools/core/src/main/scala/org/allenai/nlpstack/core/parse/graph/DependencyGraph.scala&#34;&gt;dependency graph&lt;/a&gt; from a sentence. The graph object itself contains &lt;a href=&#34;https://github.com/allenai/nlpstack/raw/master/tools/core/src/main/scala/org/allenai/nlpstack/core/parse/graph/DependencyNode.scala&#34;&gt;dependency nodes&lt;/a&gt; with integer IDs. These IDs can be used to index the original tokens given to the parser.&lt;/p&gt; &#xA;&lt;p&gt;If you want to have lemmatized token information, you&#39;ll want to run the tokens through a lemmatizer:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import org.allenai.nlpstack.lemmatize.MorphaStemmer&#xA;&#xA;val lemmatizer = new MorphaStemmer()&#xA;val lemmatizedTokens = postaggedTokens map { lemmatizer.lemmatizePostaggedToken }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once you have lemmatized tokens, you can build a new dependency graph with token information contained in the nodes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;val dependencyGraphWithTokenInfo = dependencyGraph.tokenized(lemmatizedTokens)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Releasing new versions&lt;/h2&gt; &#xA;&lt;p&gt;This project releases to Maven Central rather than to our own repository. To do this, you need a bit of setup.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;You need the signing keys to publish software with. You can find them in the &lt;code&gt;ai2-secure&lt;/code&gt; bucket in S3 under the key &lt;code&gt;Sonatype Key Pair.zip&lt;/code&gt;. Copy that file to &lt;code&gt;~/.sbt/gpg/&lt;/code&gt; and extract it there.&lt;/li&gt; &#xA; &lt;li&gt;You need the passphrase for that key pair. It&#39;s defined as an array, which is a little weird, and goes into another location in &lt;code&gt;~/.sbt&lt;/code&gt;. The line defining it is in &lt;code&gt;passwords.txt&lt;/code&gt; in the &lt;code&gt;ai2-secure&lt;/code&gt; bucket. Copy that line into &lt;code&gt;~/.sbt/0.13/allenai.sbt&lt;/code&gt; (or into some other &lt;code&gt;.sbt&lt;/code&gt; if you like).&lt;/li&gt; &#xA; &lt;li&gt;To use the passphrase, we have to enable the &lt;code&gt;sbt-pgp&lt;/code&gt; plugin. Put the following line into &lt;code&gt;~/.sbt/0.13/plugins/gpg.sbt&lt;/code&gt;: &lt;code&gt;addSbtPlugin(&#34;com.jsuereth&#34; % &#34;sbt-pgp&#34; % &#34;1.0.0&#34;)&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;We also need credentials to the sonatype repository. We get those with the following line in &lt;code&gt;~/.sbt/0.13/sonatypt.sbt&lt;/code&gt;: &lt;code&gt;credentials += Credentials(&#34;Sonatype Nexus Repository Manager&#34;, &#34;oss.sonatype.org&#34;, &#34;allenai-role&#34;, &#34;&amp;lt;password&amp;gt;&#34;)&lt;/code&gt;. You find this password in the same &lt;code&gt;password.txt&lt;/code&gt; file from above.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Now, you need to register your GPG key.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Start SBT in the nlpstack project&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;At the SBT prompt, type:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; pgp-cmd send-key [TAB]&#xA;Paul Allen Institute for Artificial Intelligence &amp;lt;account&amp;gt;&#xA;abcdefg&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When you hit [TAB], SBT should print out the available key and its ID on the second line (in the example above, &lt;code&gt;abcdefg&lt;/code&gt;. Enter the id:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; pgp-cmd send-key abcdefg hkp://keyserver.ubuntu.com [ENTER]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;With this, you should be ready to run &lt;code&gt;sbt release&lt;/code&gt; on the common project. When you do, it will upload the build artifacts to a staging repository on &lt;a href=&#34;http://oss.sonatype.org&#34;&gt;http://oss.sonatype.org&lt;/a&gt;. When it&#39;s done, you have to go there and first close, and then release, the staging repository. That initiates the upload to Maven Central, which will take about 10 minutes.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;http://oss.sonatype.org&#34;&gt;http://oss.sonatype.org&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Log in with username &lt;code&gt;allenai-role&lt;/code&gt;, and the password from the &lt;code&gt;password.txt&lt;/code&gt; file. This is the same password you used in step 4 above.&lt;/li&gt; &#xA; &lt;li&gt;Click &#34;staging repositories&#34; on the left.&lt;/li&gt; &#xA; &lt;li&gt;Use the search bar at the top right to search for &#34;allenai&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Find your staging repository and confirm that it has the contents you expect. Then, select it and click &#34;Close&#34;. Closing takes a few minutes. Then you can see how the closing process went under &#34;Activity&#34;. It sends an email to &lt;code&gt;dev-role@allenai.org&lt;/code&gt; when it&#39;s done.&lt;/li&gt; &#xA; &lt;li&gt;When it is done, select the repository again and hit &#34;Release&#34;.&lt;/li&gt; &#xA; &lt;li&gt;You should see the new version appear under &lt;a href=&#34;https://oss.sonatype.org/content/repositories/releases/org/allenai/nlpstack/&#34;&gt;https://oss.sonatype.org/content/repositories/releases/org/allenai/nlpstack/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You are done!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>allenai/taggers</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/allenai/taggers</id>
    <link href="https://github.com/allenai/taggers" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Easily identify and label sentence intervals using various taggers.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Taggers&lt;/h1&gt; &#xA;&lt;p&gt;A tagger is a function from a sentence to a list of &lt;code&gt;Type&lt;/code&gt;s. A &lt;code&gt;Type&lt;/code&gt; consists of a name and the token interval it came from in the source sentence.&lt;/p&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;For example, you might have a tagger that identifies animals. Following is the string serialized form of a tagger. To the left of &lt;code&gt;:=&lt;/code&gt; is the name of the tagger - when the tagger finds a type it will have this name. To the right of &lt;code&gt;:=&lt;/code&gt; is the tagger class. This is a Java/Scala class; if no package is specified &lt;code&gt;taggers&lt;/code&gt; will look in &lt;code&gt;org.allenai.taggers.tag&lt;/code&gt;. Between the braces &lt;code&gt;{}&lt;/code&gt; are the arguments to the tagger.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Animal := LemmatizedKeywordTagger {&#xA;  cat&#xA;  kitten&#xA;  dog&#xA;  puppy&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If this tagger were to run over the following sentence, we would get some types.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Kittens are very cute , but they turn into cats .&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code&gt;Type(name=Animal, text=&#34;Kittens&#34;, interval=[0, 1))&#xA;Type(name=Animal, text=&#34;cats&#34;, interval=[10, 11))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;taggers&lt;/code&gt; project is composed of three subprojects: &lt;code&gt;core&lt;/code&gt;, which contains the algorithms, &lt;code&gt;cli&lt;/code&gt; which has a small cli application, and &lt;code&gt;webapp&lt;/code&gt;, which contains the web demo. The project is built with &lt;code&gt;sbt&lt;/code&gt;. For example, to run the web demo, you can execute the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sbt compile &#39;project webapp&#39; run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also run taggers as a cli.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sbt compile &#39;project cli&#39; &#39;run examples/reverb.taggers&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want an example of how to use the taggers project as a dependency, please look at &lt;code&gt;taggers-webapp&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Cascades&lt;/h2&gt; &#xA;&lt;p&gt;Taggers can be organized into a cascade with multiple levels. A cascade is defined by a cascade file which contains a list of taggers files (separated by newline) followed by any number of extractor definitions (see the &#34;Extractors&#34; section).&lt;/p&gt; &#xA;&lt;p&gt;For example, we might have &lt;code&gt;hello.cascade&lt;/code&gt; as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;first.taggers&#xA;second.taggers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can use the multiple files to organize our tagger definitions. Cascades can also share tagger definition files between them.&lt;/p&gt; &#xA;&lt;h2&gt;Types of Taggers&lt;/h2&gt; &#xA;&lt;h3&gt;OpenRegex&lt;/h3&gt; &#xA;&lt;p&gt;This tagger compiles regular expressions over the tokens in a sentence into an NFA (for more information, see the &lt;a href=&#34;https://github.com/knowitall/openregex&#34;&gt;Open Regex&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/allenai/taggers/master/git@github.com:knowitall/openregex-scala.git&#34;&gt;Open Regex Scala&lt;/a&gt; libraries). A token is describedas a logical formula between angled brackets &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt;. There are a number of fields that can be matched upon for each token.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;string&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;lemma&lt;/strong&gt;: the lemmatized form of the token string (see MorphaStemmer in nlpstack)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;pos&lt;/strong&gt;: the part-of-speech tag&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;chunk&lt;/strong&gt;: the chunk tag&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;type&lt;/strong&gt;: any type that intersects this token&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;typeStart&lt;/strong&gt;: any type that starts at this token&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;typeEnd&lt;/strong&gt;: any type that ends at this token&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;typeCont&lt;/strong&gt;: any type that intersects at this token but does not start or end there&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A field can be matched in one of three ways.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;With double quotes &lt;code&gt;&#34;&lt;/code&gt;. Strings are interpreted the same was as Java strings (backslash is the escape character).&lt;/li&gt; &#xA; &lt;li&gt;With single quotes &lt;code&gt;&#39;&lt;/code&gt;. The text between two single quotes will be taken verbatim (there is no escape character).&lt;/li&gt; &#xA; &lt;li&gt;With slashes &lt;code&gt;/&lt;/code&gt;. The text between the slashes will be interpreted as a regular expression. Backslash is the escape character so &lt;code&gt;\\&lt;/code&gt; becomes a single backslash and &lt;code&gt;\/&lt;/code&gt; escapes the forward slash.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If a quotation prefixed by &#34;i&#34; then the match will be case-insensitive (i.e. &lt;code&gt;string = i&#34;cat&#34;&lt;/code&gt; will match &#34;cAt&#34;).&lt;/p&gt; &#xA;&lt;p&gt;A pattern tagger makes types with the tagger name, but also &lt;code&gt;LinkedType&lt;/code&gt;s for each matching group. A &lt;code&gt;LinkedType&lt;/code&gt; has an Optional &lt;code&gt;Type&lt;/code&gt; field that points to its parent &lt;code&gt;Type&lt;/code&gt; and a name field with a special syntax. If the tagger is named &lt;code&gt;T&lt;/code&gt; and a matching group is named &lt;code&gt;G1&lt;/code&gt; for example, the tagger will create a &lt;code&gt;LinkedType&lt;/code&gt; with the name &lt;code&gt;T.G1&lt;/code&gt;. If there is an unnamed matching group a &lt;code&gt;LinkedType&lt;/code&gt; will be created with the group number (i.e. &lt;code&gt;T.1&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;There is a lot of redundancy in their expressiveness. For example, OpenRegex supports pattern matching on the fields .This is not necessary but is an optimization and a shorthand. For example, the following two&#39; patterns match the same text.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;pos=/NNPS?/&amp;gt;&#xA;&amp;lt;pos=&#34;NNP&#34;&amp;gt; | &amp;lt;pos=&#34;NNPS&#34;&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here are some more equivalent examples:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;pos=&#34;JJ&#34;&amp;gt;* &amp;lt;pos=/NNP./&amp;gt;+&#xA;&amp;lt;pos=&#34;JJ&#34;&amp;gt;* &amp;lt;pos=/NNPS?/&amp;gt;+&#xA;&amp;lt;pos=&#34;JJ&#34;&amp;gt;* &amp;lt;pos=&#34;NNP&#34; | pos=&#34;NNPS&#34;&amp;gt;+&#xA;&amp;lt;pos=&#34;JJ&#34;&amp;gt;* (?:&amp;lt;pos=&#34;NNP&#34;&amp;gt; | &amp;lt;pos=&#34;NNPS&#34;&amp;gt;)+&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that (3) and (4) are not preferred for efficiency reasons. Regex OR (in example (4)) should only be used on multi-token sequences.&lt;/p&gt; &#xA;&lt;p&gt;The Regular Expressions support named groups &lt;code&gt;(&amp;lt;name&amp;gt;: ... )&lt;/code&gt;, unnamed groups &lt;code&gt;(?: ... )&lt;/code&gt;, and capturing groups &lt;code&gt;( ... )&lt;/code&gt;. The operators allowed are &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;?&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, and &lt;code&gt;|&lt;/code&gt;. The Logic Expressions (that describe each token) allow grouping &lt;code&gt;( ... )&lt;/code&gt;, not &lt;code&gt;!&lt;/code&gt;, or &lt;code&gt;|&lt;/code&gt;, and and &lt;code&gt;&amp;amp;&lt;/code&gt;. To learn more about the regular expression language, see &lt;a href=&#34;https://github.com/knowitall/openregex&#34;&gt;https://github.com/knowitall/openregex&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Named groups create output subtypes. For example, if we had the following &lt;code&gt;OpenRegex&lt;/code&gt; applied to the example below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;DescribedNoun := OpenRegex {&#xA;    (&amp;lt;Description&amp;gt;:&amp;lt;pos=&#39;JJ&#39;&amp;gt;+) (&amp;lt;Noun&amp;gt;:&amp;lt;pos=&#39;NN&#39;&amp;gt;+)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The huge fat cat lingered in the hallway.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;We would get the following output types.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;DescribedNoun(huge fat cat)&#xA;DescribedNoun.Description(huge fat)&#xA;DescribedNoun.Noun(cat)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;TypedOpenRegex&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;TypedOpenRegex&lt;/code&gt; extends the &lt;code&gt;OpenRegex&lt;/code&gt; with added syntax to match types. Since a type can span multiple tokens but the pattern language operates on the token level, matching types can be tedious and error prone. For example, if you want to match the type &lt;code&gt;Animal&lt;/code&gt;, you need the following pattern.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(?:(?:&amp;lt;typeStart=&#39;Animal&#39; &amp;amp; typeEnd=&#39;Animal&#39;&amp;gt;) | (?: &amp;lt;typeStart=&#39;Animal&#39; &amp;amp; !typeEnd=&#39;Animal&#39;&amp;gt; &amp;lt;typeCont=&#39;Animal&#39; &amp;amp; !typeEnd=&#39;Animal&#39;&amp;gt;* &amp;lt;typeEnd=&#39;Animal&#39;&amp;gt;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Matching many types in this manner quickly makes unreadable patterns, so the &lt;code&gt;TypedOpenRegex&lt;/code&gt; adds the syntax &lt;code&gt;@Type&lt;/code&gt; which, if the type is Animal (&lt;code&gt;@Animal&lt;/code&gt;) it would expand into the above expression. With this syntax, it&#39;s easy to match on types. For an implementation of &lt;code&gt;ReVerb&lt;/code&gt;, see &lt;code&gt;examples/reverb.taggers&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Extractors&lt;/h2&gt; &#xA;&lt;p&gt;You can define extractors which build a structured string from a matched type. Extractors look similar to a Scala anonymous function.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;x: NestedExtraction =&amp;gt; (${x.Arg1}, ${x.NestedRelation}, (${x.BaseArg1}, ${x.BaseRelation}, ${x.BaseArg2}))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The left part (split it by &lt;code&gt;=&amp;gt;&lt;/code&gt;) says we should apply this pattern to any &lt;code&gt;NestedExtraction&lt;/code&gt; type. The right part tells us what string we should build from that &lt;code&gt;NestedExtraction&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;String substitutions are used to build an interesting string. If the bound variable (look all the way to the left) is &lt;code&gt;x&lt;/code&gt;, A string substitution looks like &lt;code&gt;${x.expr|expr|...}&lt;/code&gt; where &lt;code&gt;expr&lt;/code&gt; is either just a subtype, or a subtype with a matching expression. Expressions can be chained with &lt;code&gt;|&lt;/code&gt; in case one might fail. The last part of a fallback chain may be a string.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;${x.Arg1|x.Arg2|&#39;fallback&#39;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the last fallback option fails, an exception is thrown.&lt;/p&gt; &#xA;&lt;p&gt;Sometimes you want to move to another type. In this case, the &lt;code&gt;x.subtype1:matching.subtype2&lt;/code&gt; pattern is used. Here matching is the type that overlaps &lt;code&gt;x.subtype1&lt;/code&gt; and &lt;code&gt;subtype2&lt;/code&gt; is a subtype of `matching. You may chain matching expressions.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>allenai/deep_qa_experiments</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/allenai/deep_qa_experiments</id>
    <link href="https://github.com/allenai/deep_qa_experiments" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Scala framework for running experiments with allenai/deep_qa&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://semaphoreci.com/allenai/deep_qa_experiments&#34;&gt;&lt;img src=&#34;https://semaphoreci.com/api/v1/allenai/deep_qa_experiments/branches/master/shields_badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Deep QA Experiments&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains scala code for setting up and running experiments with &lt;a href=&#34;https://github.com/allenai/deep_qa&#34;&gt;DeepQA&lt;/a&gt;. The main point here is to have reasonable pipeline management for setting up data and running comparison experiments between several models on some dataset.&lt;/p&gt; &#xA;&lt;h1&gt;Usage Guide&lt;/h1&gt; &#xA;&lt;p&gt;To use this code, you set up an experiment in scala, then run it using &lt;code&gt;sbt&lt;/code&gt;. Some documentation on how to do this is found in the &lt;a href=&#34;https://raw.githubusercontent.com/allenai/deep_qa_experiments/master/src/main/scala/org/allenai/deep_qa/experiments/&#34;&gt;README for the &lt;code&gt;org.allenai.deep_qa.experiments&lt;/code&gt; package&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;If you use this code and think something could be improved, pull requests are very welcome. Opening an issue is ok, too, but we&#39;re a lot more likely to respond to a PR. The primary maintainer of this code is &lt;a href=&#34;https://matt-gardner.github.io/&#34;&gt;Matt Gardner&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;This code is released under the terms of the &lt;a href=&#34;https://www.gnu.org/licenses/gpl-3.0.en.html&#34;&gt;GNU General Public License&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>allenai/pnp</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/allenai/pnp</id>
    <link href="https://github.com/allenai/pnp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Probabilistic Neural Programming&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Probabilistic Neural Programs&lt;/h1&gt; &#xA;&lt;p&gt;Probabilistic Neural Programming (PNP) is a Scala library for expressing, training and running inference in neural network models that &lt;strong&gt;include discrete choices&lt;/strong&gt;. The enhanced expressivity of PNP is useful for structured prediction, reinforcement learning, and latent variable models.&lt;/p&gt; &#xA;&lt;p&gt;Probabilistic neural programs have several advantages over computation graph libraries for neural networks, such as TensorFlow:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Probabilistic inference&lt;/strong&gt; is implemented within the library. For example, running a beam search to (approximately) generate the highest-scoring output sequence of a sequence-to-sequence model takes 1 line of code in PNP.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Additional training algorithms&lt;/strong&gt; that require running inference during training are part of the library. This includes learning-to-search algorithms, such as LaSO, reinforcement learning, and training latent variable models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Computation graphs&lt;/strong&gt; are a subset of probabilistic neural programs. We use &lt;a href=&#34;https://github.com/clab/dynet&#34;&gt;DyNet&lt;/a&gt; to express neural networks, which provides a rich set of operations and efficient training.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;This library depends on DyNet with the &lt;a href=&#34;https://github.com/clab/dynet/tree/master/contrib/swig&#34;&gt;Scala DyNet bindings&lt;/a&gt;. See the link for build instructions. After building this library, run the following commands from the &lt;code&gt;pnp&lt;/code&gt; root directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd lib&#xA;ln -s &amp;lt;PATH_TO_DYNET&amp;gt;/build/contrib/swig/dynet_swigJNI_scala.jar .&#xA;ln -s &amp;lt;PATH_TO_DYNET&amp;gt;/build/contrib/swig/dynet_swigJNI_dylib.jar .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it! Verify that your installation works by running &lt;code&gt;sbt test&lt;/code&gt; in the root directory.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;This section describes how to use probabilistic neural programs to define and train a model. The typical usage has three steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Define a model.&lt;/strong&gt; Models are implemented by writing a function that takes your problem input and outputs &lt;code&gt;Pnp[X]&lt;/code&gt; objects. The probabilistic neural program type &lt;code&gt;Pnp[X]&lt;/code&gt; represents a function from neural network parameters to probability distributions over values of type &lt;code&gt;X&lt;/code&gt;. Each program describes a (possibly infinite) space of executions, each of which returns a value of type &lt;code&gt;X&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Train.&lt;/strong&gt; Training is performed by passing a list of examples to a &lt;code&gt;Trainer&lt;/code&gt;, where each example consists of a &lt;code&gt;Pnp[X]&lt;/code&gt; object and a label. Labels are implemented as functions that assign costs to program executions or as conditional distributions over correct executions. Many training algorithms can be used, from loglikelihood to learning-to-search algorithms.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Run the model.&lt;/strong&gt; A model can be run on a new input by constructing the appropriate &lt;code&gt;Pnp[X]&lt;/code&gt; object, then running inference on this object with trained parameters.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;These steps are illustrated in detail for a sequence-to-sequence model in &lt;a href=&#34;https://raw.githubusercontent.com/allenai/pnp/master/src/main/scala/org/allenai/pnp/examples/Seq2Seq.scala&#34;&gt;Seq2Seq2.scala&lt;/a&gt;. For a more complex example, run the &lt;a href=&#34;https://raw.githubusercontent.com/allenai/pnp/master/experiments/geoquery/scripts/example.sh&#34;&gt;GeoQuery semantic parsing experiment&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Defining Probabilistic Neural Programs&lt;/h2&gt; &#xA;&lt;p&gt;Probabilistic neural programs are specified by writing the forward computation of a neural network, using the &lt;code&gt;choose&lt;/code&gt; operation to represent discrete choices. Roughly, we can write:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val pnp = for {&#xA;  scores1 &amp;lt;- ... some neural net operations ...&#xA;  // Make a discrete choice&#xA;  x1 &amp;lt;- choose(values, scores1)&#xA;  scores2 &amp;lt;- ... more neural net operations, may depend on x1 ...&#xA;  ...&#xA;  xn &amp;lt;- choose(values, scoresn)&#xA;} yield {&#xA;  xn&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;pnp&lt;/code&gt; then represents a function that takes some neural network parameters and returns a distribution over possible values of &lt;code&gt;xn&lt;/code&gt; (which in turn depends on the values of intermediate choices). We evaluate &lt;code&gt;pnp&lt;/code&gt; by running inference, which simultaneously runs the forward pass of the network and performs probabilistic inference:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;nnParams = ... &#xA;val dist = pnp.beamSearch(10, nnParams)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Choose&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;choose&lt;/code&gt; operator defines a distribution over a list of values:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val flip: Pnp[Boolean] = choose(Array(true, false), Array(0.5, 0.5))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This snippet creates a probability distribution that returns either true or false with 50% probability. &lt;code&gt;flip&lt;/code&gt; has type &lt;code&gt;Pnp[Boolean]&lt;/code&gt;, which represents a function from neural network parameters to probability distributions over values of type &lt;code&gt;Boolean&lt;/code&gt;. (In this case it&#39;s just a probability distribution since we haven&#39;t referenced any parameters.) Note that &lt;code&gt;flip&lt;/code&gt; is not a draw from the distribution, rather, &lt;em&gt;it is the distribution itself&lt;/em&gt;. The probability of each choice can be given to &lt;code&gt;choose&lt;/code&gt; either in an explicit list (as above) or via an &lt;code&gt;Expression&lt;/code&gt; of a neural network.&lt;/p&gt; &#xA;&lt;p&gt;We compose distributions using &lt;code&gt;for {...} yield {...}&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val twoFlips: Pnp[Boolean] = for {&#xA;  x &amp;lt;- flip&#xA;  y &amp;lt;- flip&#xA;} yield {&#xA;  x &amp;amp;&amp;amp; y&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This program returns &lt;code&gt;true&lt;/code&gt; if two independent draws from &lt;code&gt;flip&lt;/code&gt; both return &lt;code&gt;true&lt;/code&gt;. The notation &lt;code&gt;x &amp;lt;- flip&lt;/code&gt; can be thought of as drawing a value from &lt;code&gt;flip&lt;/code&gt; and assigning it to &lt;code&gt;x&lt;/code&gt;. However, we can only use the value within the for/yield block to construct another probability distribution. We can now run inference on this object:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val marginals3 = twoFlips.beamSearch(5)&#xA;println(marginals3.marginals().getProbabilityMap)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This prints out the expected probabilities:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{false=0.75, true=0.25}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Neural Networks&lt;/h3&gt; &#xA;&lt;p&gt;Probabilistic neural programs have access to an underlying computation graph that is used to define neural networks:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def mlp(x: FloatVector): Pnp[Boolean] = {&#xA;  for {&#xA;    // Get the computation graph&#xA;    cg &amp;lt;- computationGraph()&#xA;&#xA;    // Get the parameters of a multilayer perceptron by name.&#xA;    // The dimensionalities and values of these parameters are &#xA;    // defined in a PnpModel that is passed to inference.&#xA;    weights1 &amp;lt;- param(&#34;layer1Weights&#34;)&#xA;    bias1 &amp;lt;- param(&#34;layer1Bias&#34;)&#xA;    weights2 &amp;lt;- param(&#34;layer2Weights&#34;)&#xA;&#xA;    // Input the feature vector to the computation graph and&#xA;    // run the multilayer perceptron to produce scores.&#xA;    inputExpression = input(cg.cg, Seq(FEATURE_VECTOR_DIM), x)&#xA;    scores = weights2 * tanh((weights1 * inputExpression) + bias1)&#xA;&#xA;     // Choose a label given the scores. Scores is expected to&#xA;     // be a 2-element vector, where the first element is the score&#xA;     // of true, etc.&#xA;     y &amp;lt;- choose(Array(true, false), scores)&#xA;  } yield {&#xA;    y&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can then evaluate the network on an example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val model = PnpModel.init(true)&#xA;// Initialize the network parameters. The values are&#xA;// chosen randomly.&#xA;model.addParameter(&#34;layer1Weights&#34;, Seq(HIDDEN_DIM, FEATURE_VECTOR_DIM))&#xA;model.addParameter(&#34;layer1Bias&#34;, Seq(HIDDEN_DIM))&#xA;model.addParameter(&#34;layer2Weights&#34;, Seq(2, HIDDEN_DIM))&#xA;&#xA;// Run the multilayer perceptron on featureVector&#xA;val featureVector = new FloatVector(Seq(1.0f, 2.0f, 3.0f))&#xA;val dist = mlp(featureVector)&#xA;val marginals = dist.beamSearch(2, model)&#xA; &#xA;for (x &amp;lt;- marginals.executions) {&#xA;  println(x)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This prints something like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[Execution true -0.4261836111545563]&#xA;[Execution false -1.058420181274414]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Each execution has a single value that is an output of our program and a score derived from the neural network computation. In this case, the scores are log probabilities, but the scores may have different semantics depending on the way the model is defined and its parameters are trained.&lt;/p&gt; &#xA;&lt;p&gt;Pnp uses Dynet as the underlying neural network library, which provides a rich set of operations (e.g., LSTMs). See the &lt;a href=&#34;http://dynet.readthedocs.io/en/latest/operations.html&#34;&gt;Dynet documentation&lt;/a&gt; for details, along with the documentation for &lt;a href=&#34;https://github.com/allenai/dynet/tree/master/swig&#34;&gt;Dynet Scala bindings&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;TODO: document usage of RNNBuilders, which have to be used statelessly.&lt;/p&gt; &#xA;&lt;h3&gt;Defining Richer Models&lt;/h3&gt; &#xA;&lt;p&gt;Probabilistic neural programs can be easily composed to construct richer models using &lt;code&gt;for {...} yield {...}&lt;/code&gt;. For example, we can define a CRF sequence tagger using the multilayer perceptron above:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def sequenceTag(xs: Seq[FloatVector]): Pnp[List[Boolean]] = {&#xA;  xs.foldLeft(Pnp.value(List[Boolean]()))((x, y) =&amp;gt; for {&#xA;    cur &amp;lt;- mlp(y)&#xA;    rest &amp;lt;- x&#xA;&#xA;    cg &amp;lt;- computationGraph()&#xA;    _ &amp;lt;- if (rest.length &amp;gt; 0) {&#xA;      // Add a factor to the model that scores adjacent labels&#xA;      // in the sequence. Here, labelNn runs a neural network&#xA;      // whose inputs are cur and the next label, and whose output&#xA;      // is a 1-element vector containing the score.&#xA;      score(labelNn(cur, rest.head, cg.cg))&#xA;    } else {&#xA;      value(())&#xA;    }&#xA;  } yield {&#xA;    cur :: rest&#xA;  })&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can now run this model on a sequence of feature vectors in the same way as the multilayer perceptron:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Same model as before, but make it globally normalized &#xA;// and add some more parameters for labelNn&#xA;model.locallyNormalized = false&#xA;model.addLookupParameter(&#34;left&#34;, 2, Seq(LABEL_DIM))&#xA;model.addLookupParameter(&#34;right&#34;, 2, Seq(LABEL_DIM))&#xA;&#xA;val featureVectors = Seq(new FloatVector(...), new FloatVector(...), new FloatVector(...))&#xA;val dist = sequenceTag(featureVectors)&#xA;val marginals = dist.beamSearch(5, model)&#xA;for (x &amp;lt;- marginals.executions) {&#xA;  println(x)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This prints something like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[Execution List(true, true, true) 5.28779661655426]&#xA;[Execution List(false, true, true) 1.7529568672180176]&#xA;[Execution List(true, true, false) 1.4970757961273193]&#xA;[Execution List(true, false, false) -0.007531404495239258]&#xA;[Execution List(true, false, true) -0.42748916149139404]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;TODO&lt;/p&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;TODO&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>windymelt/FNFIS</title>
    <updated>2022-06-03T01:52:00Z</updated>
    <id>tag:github.com,2022-06-03:/windymelt/FNFIS</id>
    <link href="https://github.com/windymelt/FNFIS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;FNFIS - FreeNet File Indexing on Scala Testing.&lt;/p&gt;</summary>
  </entry>
</feed>