<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-01T01:53:09Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>apache/incubator-kyuubi</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/apache/incubator-kyuubi</id>
    <link href="https://github.com/apache/incubator-kyuubi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache Kyuubi is a distributed multi-tenant JDBC server for large-scale data processing and analytics, built on top of Apache Spark&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache Kyuubi (Incubating)&lt;/h1&gt; &#xA;&lt;img src=&#34;https://svn.apache.org/repos/asf/comdev/project-logos/originals/kyuubi-1.svg?sanitize=true&#34; alt=&#34;Kyuubi logo&#34; height=&#34;120px&#34; align=&#34;right&#34;&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/incubator-kyuubi/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/apache/incubator-kyuubi?label=release&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://tokei.rs/b1/github.com/apache/incubator-kyuubi&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/apache/incubator-kyuubi/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/workflow/status/apache/incubator-kyuubi/Kyuubi/master?style=plastic&#34; alt=&#34;GitHub Workflow Status&#34;&gt; &lt;a href=&#34;https://travis-ci.com/apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://api.travis-ci.com/apache/incubator-kyuubi.svg?branch=master&#34; alt=&#34;Travis&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://kyuubi.apache.org/docs/latest/&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/kyuubi/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/languages/top/apache/incubator-kyuubi&#34; alt=&#34;GitHub top language&#34;&gt; &lt;a href=&#34;https://github.com/apache/incubator-kyuubi/graphs/commit-activity&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/m/apache/incubator-kyuubi&#34; alt=&#34;Commit activity&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://isitmaintained.com/project/apache/incubator-kyuubi&#34; title=&#34;Average time to resolve an issue&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/resolution/apache/incubator-kyuubi.svg?sanitize=true&#34; alt=&#34;Average time to resolve an issue&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://isitmaintained.com/project/apache/incubator-kyuubi&#34; title=&#34;Percentage of issues still open&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/open/apache/incubator-kyuubi.svg?sanitize=true&#34; alt=&#34;Percentage of issues still open&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Kyuubi?&lt;/h2&gt; &#xA;&lt;p&gt;Kyuubi is a distributed multi-tenant Thrift JDBC/ODBC server for large-scale data management, processing, and analytics, built on top of Apache Spark and designed to support more engines (i.e., Flink). It has been open-sourced by NetEase since 2018. We are aiming to make Kyuubi an &#34;out-of-the-box&#34; tool for data warehouses and data lakes.&lt;/p&gt; &#xA;&lt;p&gt;Kyuubi provides a pure SQL gateway through Thrift JDBC/ODBC interface for end-users to manipulate large-scale data with pre-programmed and extensible Spark SQL engines. This &#34;out-of-the-box&#34; model minimizes the barriers and costs for end-users to use Spark at the client side. At the server-side, Kyuubi server and engines&#39; multi-tenant architecture provides the administrators a way to achieve computing resource isolation, data security, high availability, high client concurrency, etc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/docs/imgs/kyuubi_positioning.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; A HiveServer2-like API&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multi-tenant Spark Support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Running Spark in a serverless way&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Target Users&lt;/h3&gt; &#xA;&lt;p&gt;Kyuubi&#39;s goal is to make it easy and efficient for &lt;code&gt;anyone&lt;/code&gt; to use Spark(maybe other engines soon) and facilitate users to handle big data like ordinary data. Here, &lt;code&gt;anyone&lt;/code&gt; means that users do not need to have a Spark technical background but a human language, SQL only. Sometimes, SQL skills are unnecessary when integrating Kyuubi with Apache Superset, which supports rich visualizations and dashboards.&lt;/p&gt; &#xA;&lt;p&gt;In typical big data production environments with Kyuubi, there should be system administrators and end-users.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;System administrators: A small group consists of Spark experts responsible for Kyuubi deployment, configuration, and tuning.&lt;/li&gt; &#xA; &lt;li&gt;End-users: Focus on business data of their own, not where it stores, how it computes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Additionally, the Kyuubi community will continuously optimize the whole system with various features, such as History-Based Optimizer, Auto-tuning, Materialized View, SQL Dialects, Functions, e.t.c.&lt;/p&gt; &#xA;&lt;h3&gt;Usage scenarios&lt;/h3&gt; &#xA;&lt;h4&gt;Port workloads from HiveServer2 to Spark SQL&lt;/h4&gt; &#xA;&lt;p&gt;In typical big data production environments, especially secured ones, all bundled services manage access control lists to restricting access to authorized users. For example, Hadoop YARN divides compute resources into queues. With Queue ACLs, it can identify and control which users/groups can take actions on particular queues. Similarly, HDFS ACLs control access of HDFS files by providing a way to set different permissions for specific users/groups.&lt;/p&gt; &#xA;&lt;p&gt;Apache Spark is a unified analytics engine for large-scale data processing. It provides a Distributed SQL Engine, a.k.a, the Spark Thrift Server(STS), designed to be seamlessly compatible with HiveServer2 and get even better performance.&lt;/p&gt; &#xA;&lt;p&gt;HiveServer2 can identify and authenticate a caller, and then if the caller also has permissions for the YARN queue and HDFS files, it succeeds. Otherwise, it fails. However, on the one hand, STS is a single Spark application. The user and queue to which STS belongs are uniquely determined at startup. Consequently, STS cannot leverage cluster managers such as YARN and Kubernetes for resource isolation and sharing or control the access for callers by the single user inside the whole system. On the other hand, the Thrift Server is coupled in the Spark driver&#39;s JVM process. This coupled architect puts a high risk on server stability and makes it unable to handle high client concurrency or apply high availability such as load balancing as it is stateful.&lt;/p&gt; &#xA;&lt;p&gt;Kyuubi extends the use of STS in a multi-tenant model based on a unified interface and relies on the concept of multi-tenancy to interact with cluster managers to finally gain the ability of resources sharing/isolation and data security. The loosely coupled architecture of the Kyuubi server and engine dramatically improves the client concurrency and service stability of the service itself.&lt;/p&gt; &#xA;&lt;h4&gt;DataLake/LakeHouse Support&lt;/h4&gt; &#xA;&lt;p&gt;The vision of Kyuubi is to unify the portal and become an easy-to-use data lake management platform. Different kinds of workloads, such as ETL processing and BI analytics, can be supported by one platform, using one copy of data, with one SQL interface.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Logical View support via Kyuubi DataLake Metadata APIs&lt;/li&gt; &#xA; &lt;li&gt;Multiple Catalogs support&lt;/li&gt; &#xA; &lt;li&gt;SQL Standard Authorization support for DataLake(coming)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Cloud Native Support&lt;/h4&gt; &#xA;&lt;p&gt;Kyuubi can deploy its engines on different kinds of Cluster Managers, such as, Hadoop YARN, Kubernetes, etc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/docs/imgs/kyuubi_migrating_yarn_to_k8s.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;The Kyuubi Ecosystem(present and future)&lt;/h3&gt; &#xA;&lt;p&gt;The figure below shows our vision for the Kyuubi Ecosystem. Some of them have been realized, some in development, and others would not be possible without your help.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/docs/imgs/kyuubi_ecosystem.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Online Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Since Kyuubi 1.3.0-incubating, the Kyuubi online documentation is hosted by &lt;a href=&#34;https://kyuubi.apache.org/&#34;&gt;https://kyuubi.apache.org/&lt;/a&gt;. You can find the latest Kyuubi documentation on &lt;a href=&#34;https://kyuubi.apache.org/docs/latest/&#34;&gt;this web page&lt;/a&gt;. For 1.2 and earlier versions, please check the &lt;a href=&#34;https://kyuubi.readthedocs.io/en/v1.2.0/&#34;&gt;Readthedocs&lt;/a&gt; directly.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Ready? &lt;a href=&#34;https://kyuubi.apache.org/docs/latest/quick_start/quick_start.html&#34;&gt;Getting Started&lt;/a&gt; with Kyuubi.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;Contributor over time&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://api7.ai/contributor-graph?chart=contributorOverTime&amp;amp;repo=apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://contributor-graph-api.apiseven.com/contributors-svg?chart=contributorOverTime&amp;amp;repo=apache/incubator-kyuubi&#34; alt=&#34;Contributor over time&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Aside&lt;/h2&gt; &#xA;&lt;p&gt;The project took its name from a character of a popular Japanese manga - &lt;code&gt;Naruto&lt;/code&gt;. The character is named &lt;code&gt;Kyuubi Kitsune/Kurama&lt;/code&gt;, which is a nine-tailed fox in mythology. &lt;code&gt;Kyuubi&lt;/code&gt; spread the power and spirit of fire, which is used here to represent the powerful &lt;a href=&#34;http://spark.apache.org&#34;&gt;Apache Spark&lt;/a&gt;. Its nine tails stand for end-to-end multi-tenancy support of this project.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache 2.0 License. See the &lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apache/openwhisk</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/apache/openwhisk</id>
    <link href="https://github.com/apache/openwhisk" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache OpenWhisk is an open source serverless cloud platform&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenWhisk&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.com/github/apache/openwhisk&#34;&gt;&lt;img src=&#34;https://travis-ci.com/apache/openwhisk.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache--2.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://openwhisk-team.slack.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/join-slack-9B69A0.svg?sanitize=true&#34; alt=&#34;Join Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/apache/openwhisk&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/apache/openwhisk/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/follow?screen_name=openwhisk&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/openwhisk.svg?style=social&amp;amp;logo=twitter&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;OpenWhisk is a serverless functions platform for building cloud applications. OpenWhisk offers a rich programming model for creating serverless APIs from functions, composing functions into serverless workflows, and connecting events to functions using rules and triggers. Learn more at &lt;a href=&#34;http://openwhisk.apache.org&#34;&gt;http://openwhisk.apache.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/#quick-start&#34;&gt;Quick Start&lt;/a&gt; (Deploy and Use OpenWhisk on your machine)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/#deploy-to-kubernetes&#34;&gt;Deploy to Kubernetes&lt;/a&gt; (For development and production)&lt;/li&gt; &#xA; &lt;li&gt;For project contributors and Docker deployments: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/tools/macos/README.md&#34;&gt;Deploy to Docker for Mac&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/tools/ubuntu-setup/README.md&#34;&gt;Deploy to Docker for Ubuntu&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/#learn-concepts-and-commands&#34;&gt;Learn Concepts and Commands&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/#openwhisk-community-and-support&#34;&gt;OpenWhisk Community and Support&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/#project-repository-structure&#34;&gt;Project Repository Structure&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quick Start&lt;/h3&gt; &#xA;&lt;p&gt;The easiest way to start using OpenWhisk is to install the &#34;Standalone&#34; OpenWhisk stack. This is a full-featured OpenWhisk stack running as a Java process for convenience. Serverless functions run within Docker containers. You will need &lt;a href=&#34;https://docs.docker.com/install&#34;&gt;Docker&lt;/a&gt;, &lt;a href=&#34;https://java.com/en/download/help/download_options.xml&#34;&gt;Java&lt;/a&gt; and &lt;a href=&#34;https://nodejs.org&#34;&gt;Node.js&lt;/a&gt; available on your machine.&lt;/p&gt; &#xA;&lt;p&gt;To get started:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/apache/openwhisk.git&#xA;cd openwhisk&#xA;./gradlew core:standalone:bootRun&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;When the OpenWhisk stack is up, it will open your browser to a functions &lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/images/playground-ui.png&#34;&gt;Playground&lt;/a&gt;, typically served from &lt;a href=&#34;http://localhost:3232&#34;&gt;http://localhost:3232&lt;/a&gt;. The Playground allows you create and run functions directly from your browser.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To make use of all OpenWhisk features, you will need the OpenWhisk command line tool called &lt;code&gt;wsk&lt;/code&gt; which you can download from &lt;a href=&#34;https://s.apache.org/openwhisk-cli-download&#34;&gt;https://s.apache.org/openwhisk-cli-download&lt;/a&gt;. Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/cli.md&#34;&gt;CLI configuration&lt;/a&gt; for additional details. Typically you configure the CLI for Standalone OpenWhisk as follows:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;wsk property set \&#xA;  --apihost &#39;http://localhost:3233&#39; \&#xA;  --auth &#39;23bc46b1-71f6-4ed5-8c54-816aa4f8c502:123zO3xZCLrMN6v2BKK1dXYFpXlPkccOFqm12CdAsMgRU4VrNZ9lyGVCGuMDGIwP&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Standalone OpenWhisk can be configured to deploy additional capabilities when that is desirable. Additional resources are available &lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/core/standalone/README.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Deploy to Kubernetes&lt;/h3&gt; &#xA;&lt;p&gt;OpenWhisk can also be installed on a Kubernetes cluster. You can use a managed Kubernetes cluster provisioned from a public cloud provider (e.g., AKS, EKS, IKS, GKE), or a cluster you manage yourself. Additionally for local development, OpenWhisk is compatible with Minikube, and Kubernetes for Mac using the support built into Docker 18.06 (or higher).&lt;/p&gt; &#xA;&lt;p&gt;To get started:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/apache/openwhisk-deploy-kube.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then follow the instructions in the &lt;a href=&#34;https://github.com/apache/openwhisk-deploy-kube/raw/master/README.md&#34;&gt;OpenWhisk on Kubernetes README.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Learn Concepts and Commands&lt;/h3&gt; &#xA;&lt;p&gt;Browse the &lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/&#34;&gt;documentation&lt;/a&gt; to learn more. Here are some topics you may be interested in:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/about.md&#34;&gt;System overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/README.md&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/actions.md&#34;&gt;Create and invoke actions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/triggers_rules.md&#34;&gt;Create triggers and rules&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/packages.md&#34;&gt;Use and create packages&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/catalog.md&#34;&gt;Browse and use the catalog&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/reference.md&#34;&gt;OpenWhisk system details&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/feeds.md&#34;&gt;Implementing feeds&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/actions-actionloop.md&#34;&gt;Developing a runtime for a new language&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;OpenWhisk Community and Support&lt;/h3&gt; &#xA;&lt;p&gt;Report bugs, ask questions and request features &lt;a href=&#34;https://raw.githubusercontent.com/apache/issues&#34;&gt;here on GitHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also join the OpenWhisk Team on Slack &lt;a href=&#34;https://openwhisk-team.slack.com&#34;&gt;https://openwhisk-team.slack.com&lt;/a&gt; and chat with developers. To get access to our public Slack team, request an invite &lt;a href=&#34;https://openwhisk.apache.org/slack.html&#34;&gt;https://openwhisk.apache.org/slack.html&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Project Repository Structure&lt;/h3&gt; &#xA;&lt;p&gt;The OpenWhisk system is built from a &lt;a href=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/dev/modules.md&#34;&gt;number of components&lt;/a&gt;. The picture below groups the components by their GitHub repos. Please open issues for a component against the appropriate repo (if in doubt just open against the main openwhisk repo).&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/openwhisk/master/docs/images/components_to_repos.png&#34; alt=&#34;component/repo mapping&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>zio/zio</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/zio/zio</id>
    <link href="https://github.com/zio/zio" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ZIO — A type-safe, composable library for async and concurrent programming in Scala&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/ZIO.png&#34; alt=&#34;ZIO Logo&#34;&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Project Stage&lt;/th&gt; &#xA;   &lt;th&gt;CI&lt;/th&gt; &#xA;   &lt;th&gt;Release&lt;/th&gt; &#xA;   &lt;th&gt;Snapshot&lt;/th&gt; &#xA;   &lt;th&gt;Issues&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/zio/zio/wiki/Project-Stages&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project%20Stage-Production%20Ready-brightgreen.svg?sanitize=true&#34; alt=&#34;Project stage&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/zio/zio/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://oss.sonatype.org/content/repositories/releases/dev/zio/zio_2.12/&#34; title=&#34;Sonatype Releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/nexus/r/https/oss.sonatype.org/dev.zio/zio_2.12.svg?sanitize=true&#34; alt=&#34;Release Artifacts&#34; title=&#34;Sonatype Releases&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://oss.sonatype.org/content/repositories/snapshots/dev/zio/zio_2.12/&#34; title=&#34;Sonatype Snapshots&#34;&gt;&lt;img src=&#34;https://img.shields.io/nexus/s/https/oss.sonatype.org/dev.zio/zio_2.12.svg?sanitize=true&#34; alt=&#34;Snapshot Artifacts&#34; title=&#34;Sonatype Snapshots&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://isitmaintained.com/project/zio/zio&#34; title=&#34;Average time to resolve an issue&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/resolution/zio/zio.svg?sanitize=true&#34; alt=&#34;Average time to resolve an issue&#34; title=&#34;Average time to resolve an issue&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Scaladoc&lt;/th&gt; &#xA;   &lt;th&gt;Scaladex&lt;/th&gt; &#xA;   &lt;th&gt;Discord&lt;/th&gt; &#xA;   &lt;th&gt;Twitter&lt;/th&gt; &#xA;   &lt;th&gt;Gitpod&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://javadoc.io/doc/dev.zio/zio_2.12/latest/zio/index.html&#34;&gt;Scaladoc&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://index.scala-lang.org/zio/zio/zio&#34; title=&#34;Scaladex&#34;&gt;&lt;img src=&#34;https://index.scala-lang.org/zio/zio/zio/latest.svg?sanitize=true&#34; alt=&#34;Badge-Scaladex-page&#34; title=&#34;Scaladex&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://discord.gg/2ccFBr4&#34; title=&#34;Discord&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/629491597070827530?logo=discord&#34; alt=&#34;Badge-Discord&#34; title=&#34;chat on discord&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://twitter.com/zioscala&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/zioscala.svg?style=plastic&amp;amp;label=follow&amp;amp;logo=twitter&#34; alt=&#34;Badge-Twitter&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gitpod.io/#https://github.com/zio/zio&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&#34; alt=&#34;Gitpod ready-to-code&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Welcome to ZIO&lt;/h1&gt; &#xA;&lt;p&gt;ZIO is a zero-dependency Scala library for asynchronous and concurrent programming.&lt;/p&gt; &#xA;&lt;p&gt;Powered by highly-scalable, non-blocking fibers that never waste or leak resources, ZIO lets you build scalable, resilient, and reactive applications that meet the needs of your business.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;High-performance&lt;/strong&gt;. Build scalable applications with 100x the performance of Scala&#39;s &lt;code&gt;Future&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Type-safe&lt;/strong&gt;. Use the full power of the Scala compiler to catch bugs at compile time.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Concurrent&lt;/strong&gt;. Easily build concurrent apps without deadlocks, race conditions, or complexity.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Asynchronous&lt;/strong&gt;. Write sequential code that looks the same whether it&#39;s asynchronous or synchronous.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Resource-safe&lt;/strong&gt;. Build apps that never leak resources (including threads!), even when they fail.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Testable&lt;/strong&gt;. Inject test services into your app for fast, deterministic, and type-safe testing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Resilient&lt;/strong&gt;. Build apps that never lose errors, and which respond to failure locally and flexibly.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Functional&lt;/strong&gt;. Rapidly compose solutions to complex problems from simple building blocks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To learn more about ZIO, see the following references:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zio.dev/&#34;&gt;Homepage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zio/zio/master/docs/about/contributing.md&#34;&gt;Contributor&#39;s Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zio/zio/master/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zio/zio/issues&#34;&gt;Issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zio/zio/pulls&#34;&gt;Pull Requests&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Adopters&lt;/h1&gt; &#xA;&lt;p&gt;Following is a partial list of companies happily using ZIO in production to craft concurrent applications.&lt;/p&gt; &#xA;&lt;p&gt;Want to see your company here? &lt;a href=&#34;https://github.com/zio/zio/edit/master/README.md&#34;&gt;Submit a PR&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adgear.com/en/&#34;&gt;AdGear / Samsung Ads&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.adidas.com/&#34;&gt;Adidas&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.adpulse.io/&#34;&gt;adpulse.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.adsquare.com/&#34;&gt;adsquare&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.anduintransact.com/&#34;&gt;Anduin Transactions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ayolab.com/&#34;&gt;Ayolab&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://asana.com/&#34;&gt;Asana&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.aurinko.io/&#34;&gt;Aurinko&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://auto.ru&#34;&gt;auto.ru&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.autoscout24.de&#34;&gt;AutoScout24&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.avast.com&#34;&gt;Avast&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bofa.com&#34;&gt;Bank of America&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bpp.it/&#34;&gt;Bpp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://broad.app&#34;&gt;Broad&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.caesars.com/sportsbook-and-casino&#34;&gt;Caesars Digital&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.calcbank.com.br&#34;&gt;CalcBank&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.callhandling.co.uk/&#34;&gt;Call Handling&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.carvana.com&#34;&gt;Carvana&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cellular.de&#34;&gt;Cellular&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cloudfarms.com&#34;&gt;Cloudfarms&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://codecomprehension.com&#34;&gt;CodeComprehension&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.codept.de/&#34;&gt;Codept&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.colisweb.com/en&#34;&gt;Colisweb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.collibra.com/&#34;&gt;Collibra&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.compellon.com/&#34;&gt;Compellon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.complicatedrobot.com/&#34;&gt;Complicated Robot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.conduktor.io&#34;&gt;Conduktor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.contramap.dev&#34;&gt;Contramap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://coralogix.com&#34;&gt;Coralogix&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://creditkarma.com&#34;&gt;Credit Karma&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.currencycloud.com/&#34;&gt;CurrencyCloud&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://de-solution.com/&#34;&gt;D.E.Solution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datachef.co&#34;&gt;DataChef&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.demandbase.com&#34;&gt;Demandbase&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://demyst.com&#34;&gt;Demyst&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://devsisters.com/&#34;&gt;Devsisters&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.werkenbijdhl.nl/it&#34;&gt;DHL Parcel The Netherlands&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.disneyplus.com/&#34;&gt;Disney+ Streaming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://doomoolmori.com/&#34;&gt;Doomoolmori&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.dowjones.com&#34;&gt;Dow Jones&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.dpgrecruitment.nl&#34;&gt;DPG recruitment&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dream11.com&#34;&gt;Dream11&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://iot.telekom.com/en&#34;&gt;Deutsche Telekom IoT GmbH&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ebay.com&#34;&gt;eBay&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.eaglescience.nl&#34;&gt;Eaglescience&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.edf.fr/&#34;&gt;Electricité de France (EDF)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.enelx.com&#34;&gt;EnelX&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://evolution.engineering&#34;&gt;Evolution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://evo.company&#34;&gt;Evo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://flipp.com/&#34;&gt;Flipp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.fugo.ai&#34;&gt;Fugo.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.garnercorp.com/&#34;&gt;Garner Distributed Workflow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gleancompany.com&#34;&gt;Glean&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://grandparade.co.uk&#34;&gt;GrandParade&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://greyflower.media&#34;&gt;greyflower.media GmbH&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hunters.ai&#34;&gt;Hunters.AI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hypefactors.com/&#34;&gt;Hypefactors&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.iheart.com/&#34;&gt;iHeartRadio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ihsmarkit.com/&#34;&gt;IHS Markit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://investsuite.com/&#34;&gt;Investsuite&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kaizen-solutions.net/&#34;&gt;Kaizen Solutions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kamon.io/&#34;&gt;Kamon APM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kodmagi.se&#34;&gt;Kodmagi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kensu.io&#34;&gt;Kensu&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lambdaworks.io/&#34;&gt;LambdaWorks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://leadiq.com&#34;&gt;LeadIQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.lernkunst.com/&#34;&gt;Lernkunst&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://liveintent.com&#34;&gt;LiveIntent Inc.&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lottoland.com&#34;&gt;Lottoland&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://matechs.com&#34;&gt;MATECHS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://megogo.net&#34;&gt;Megogo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mylivn.com/&#34;&gt;Mylivn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://newmotion.com&#34;&gt;NewMotion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nexxchange.com&#34;&gt;Nexxchange&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nike.com&#34;&gt;Nike&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nslookup.io&#34;&gt;NsLookup&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ocadotechnology.com&#34;&gt;Ocado Technology&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://olyro.de&#34;&gt;Olyro GmbH&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://optrak.com&#34;&gt;Optrak&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.performance-immo.com/&#34;&gt;Performance Immo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playtika.com&#34;&gt;Playtika&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ppcsamurai.com/&#34;&gt;PPC Samurai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://prezi.com/&#34;&gt;Prezi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.radix.bio/&#34;&gt;Radix Labs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.railroad19.com&#34;&gt;Railroad19&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.werkenbijrandstad.nl&#34;&gt;Randstad Groep Nederland&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.rapidor.co&#34;&gt;Rapidor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pimsolutions.ru/&#34;&gt;PIM Solutions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://rewe-digital.com/&#34;&gt;REWE Digital&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://riskident.com/&#34;&gt;Risk Ident&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rocker.com/&#34;&gt;Rocker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.rudder.io/&#34;&gt;Rudder&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sanjagh.pro/&#34;&gt;Sanjagh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scalac.io/&#34;&gt;Scalac&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.securityscorecard.io/&#34;&gt;SecurityScorecard&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.sentinelone.com/&#34;&gt;SentinelOne&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.signicat.com/&#34;&gt;Signicat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://info.sgmarkets.com/en/&#34;&gt;Société Générale Corporate and Investment Banking&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://softwaremill.com/&#34;&gt;SoftwareMill&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.streamweaver.com/&#34;&gt;StreamWeaver&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://stuart.com/&#34;&gt;Stuart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://teads.com&#34;&gt;Teads&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pokemon.com/us/about-pokemon/&#34;&gt;The Pokemon Company International&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tomtom.com&#34;&gt;TomTom&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.tinka.com/&#34;&gt;Tinka&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tinkoff.ru&#34;&gt;Tinkoff&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://trackabus.com&#34;&gt;Trackabus&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.trainor.no&#34;&gt;Trainor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tranzzo.com&#34;&gt;Tranzzo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://treutech.io&#34;&gt;TreuTech&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tweddle.com&#34;&gt;Tweddle Group&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.undo.app&#34;&gt;Undo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://unit.co&#34;&gt;Unit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://univalence.io&#34;&gt;Univalence&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.unzer.com&#34;&gt;Unzer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.vakantiediscounter.nl&#34;&gt;Vakantiediscounter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.verbund.com&#34;&gt;Verbund AG&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.waylay.io/&#34;&gt;Waylay&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.wehkamp.nl&#34;&gt;Wehkamp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.wolt.com/&#34;&gt;Wolt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://o.yandex.ru&#34;&gt;Yandex.Classifieds&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://audela.ca&#34;&gt;Audela&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://valamis.com&#34;&gt;Valamis Group&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://valsea.com&#34;&gt;Valsea&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://virtuslab.com/&#34;&gt;VirtusLab&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://getvish.com&#34;&gt;Vish&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vivid.money&#34;&gt;Vivid Money&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zalando.com/&#34;&gt;Zalando&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zooz.com/&#34;&gt;Zooz&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Sponsors&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ziverge.com&#34; title=&#34;Ziverge&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/ziverge.png&#34; alt=&#34;Ziverge&#34; title=&#34;Ziverge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ziverge.com&#34; title=&#34;Ziverge&#34;&gt;Ziverge&lt;/a&gt; is a leading contributor to ZIO.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://scalac.io&#34; title=&#34;Scalac&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/scalac.svg?sanitize=true&#34; alt=&#34;Scalac&#34; title=&#34;Scalac&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://scalac.io&#34; title=&#34;Scalac&#34;&gt;Scalac&lt;/a&gt; sponsors ZIO Hackathons and contributes work to multiple projects in ZIO ecosystem.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://7mind.io&#34; title=&#34;Septimal Mind&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/septimal_mind.svg?sanitize=true&#34; alt=&#34;Septimal Mind&#34; title=&#34;Septimal Mind&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://7mind.io&#34; title=&#34;Septimal Mind&#34;&gt;Septimal Mind&lt;/a&gt; sponsors work on ZIO Tracing and continuous maintenance.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://softwaremill.com&#34; title=&#34;SoftwareMill&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/softwaremill.svg?sanitize=true&#34; alt=&#34;SoftwareMill&#34; title=&#34;SoftwareMill&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://softwaremill.com&#34; title=&#34;SoftwareMill&#34;&gt;SoftwareMill&lt;/a&gt; generously provides ZIO with paid-for CircleCI build infrastructure.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.yourkit.com&#34; title=&#34;YourKit&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zio/zio/master/website/static/img/yourkit.png&#34; alt=&#34;YourKit&#34; title=&#34;YourKit&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.yourkit.com&#34; title=&#34;YourKit&#34;&gt;YourKit&lt;/a&gt; generously provides use of their monitoring and profiling tools to maximize the performance of ZIO applications.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://zio.dev/&#34;&gt;Learn More on the ZIO Homepage&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/zio/zio/master/docs/about/code_of_conduct.md&#34;&gt;Code of Conduct&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;Come chat with us on &lt;a href=&#34;https://discord.gg/2ccFBr4&#34; title=&#34;Discord&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/629491597070827530?logo=discord&#34; alt=&#34;Badge-Discord&#34; title=&#34;chat on discord&#34;&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Legal&lt;/h3&gt; &#xA;&lt;p&gt;Copyright 2017 - 2020 John A. De Goes and the ZIO Contributors. All rights reserved.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lampepfl/dotty</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/lampepfl/dotty</id>
    <link href="https://github.com/lampepfl/dotty" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Scala 3 compiler, also known as Dotty.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dotty&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lampepfl/dotty/actions?query=branch%3Amain&#34;&gt;&lt;img src=&#34;https://github.com/lampepfl/dotty/workflows/Dotty/badge.svg?branch=master&#34; alt=&#34;Dotty CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.com/invite/scala&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/632150470000902164&#34; alt=&#34;Join the chat at https://discord.com/invite/scala&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.scala-lang.org/scala3/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Try it out&lt;/h1&gt; &#xA;&lt;p&gt;To try it in your project see also the &lt;a href=&#34;https://docs.scala-lang.org/scala3/getting-started.html&#34;&gt;Getting Started User Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Building a Local Distribution&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;sbt dist/packArchive&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Find the newly-built distributions in &lt;code&gt;dist/target/&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Code of Conduct&lt;/h1&gt; &#xA;&lt;p&gt;Dotty uses the &lt;a href=&#34;https://www.scala-lang.org/conduct.html&#34;&gt;Scala Code of Conduct&lt;/a&gt; for all communication and discussion. This includes both GitHub, Discord and other more direct lines of communication such as email.&lt;/p&gt; &#xA;&lt;h1&gt;How to Contribute&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.scala-lang.org/scala3/guides/contribution/contribution-intro.html&#34;&gt;Getting Started as Contributor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lampepfl/dotty/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22&#34;&gt;Issues&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;Dotty is licensed under the &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License Version 2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>streamxhub/streamx</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/streamxhub/streamx</id>
    <link href="https://github.com/streamxhub/streamx" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Make stream processing easier! Flink &amp; Spark development scaffold, The original intention of StreamX is to make the development of Flink easier. StreamX focuses on the management of development phases and tasks. Our ultimate goal is to build a one-stop big data solution integrating stream processing, batch processing, data warehouse and data laker.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;h1&gt; &lt;a href=&#34;http://www.streamxhub.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img width=&#34;600&#34; src=&#34;https://user-images.githubusercontent.com/13284744/166133644-ed3cc4f5-aae5-45bc-bfbe-29c540612446.png&#34; alt=&#34;StreamX logo&#34;&gt; &lt;/a&gt; &lt;/h1&gt; &#xA; &lt;strong style=&#34;font-size: 1.5rem&#34;&gt;Make stream processing easier!!!&lt;/strong&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-4EB1BA.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://tokei.rs/b1/github/streamxhub/streamx&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/streamxhub/streamx.svg?sanitize=true&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/streamxhub/streamx&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/streamxhub/streamx&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/languages/count/streamxhub/streamx&#34;&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.streamxhub.com&#34;&gt;Official Website&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/streamxhub/streamx/dev/#&#34;&gt;Change Log&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://www.streamxhub.com/docs/intro&#34;&gt;Document&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h4&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/streamxhub/streamx/dev/README_CN.md&#34;&gt;中文&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;h1&gt;StreamX&lt;/h1&gt; &#xA;&lt;p&gt;Make stream processing easier&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;A magical framework that make stream processing easier!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;🚀 Introduction&lt;/h2&gt; &#xA;&lt;p&gt;The original intention of &lt;code&gt;StreamX&lt;/code&gt; is to make stream processing easier. &lt;code&gt;StreamX&lt;/code&gt; focuses on the management of development phases and tasks. Our ultimate goal is to build a one-stop big data solution integrating stream processing, batch processing, data warehouse and data laker.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://assets.streamxhub.com/streamx-video.mp4&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/166101616-50a44d38-3ffb-4296-8a77-92f76a4c21b5.png&#34; alt=&#34;StreamX video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🎉 Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scaffolding&lt;/li&gt; &#xA; &lt;li&gt;Out-of-the-box connectors&lt;/li&gt; &#xA; &lt;li&gt;Support maven compilation&lt;/li&gt; &#xA; &lt;li&gt;Configuration&lt;/li&gt; &#xA; &lt;li&gt;Multi version flink support(1.12.x,1.13.x,1.14.x, 1.15.x)&lt;/li&gt; &#xA; &lt;li&gt;Scala 2.11 / 2.12 support&lt;/li&gt; &#xA; &lt;li&gt;restapi support.&lt;/li&gt; &#xA; &lt;li&gt;All Flink deployment mode support(&lt;code&gt;Remote&lt;/code&gt;/&lt;code&gt;K8s-Native-Application&lt;/code&gt;/&lt;code&gt;K8s-Native-Session&lt;/code&gt;/&lt;code&gt;YARN-Application&lt;/code&gt;/&lt;code&gt;YARN-Per-Job&lt;/code&gt;/&lt;code&gt;YARN-Session&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;start&lt;/code&gt;, &lt;code&gt;stop&lt;/code&gt;, &lt;code&gt;savepoint&lt;/code&gt;, resume from &lt;code&gt;savepoint&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Various companies and organizations use &lt;code&gt;StreamX&lt;/code&gt; for production and commercial products.&lt;/li&gt; &#xA; &lt;li&gt;Flame graph&lt;/li&gt; &#xA; &lt;li&gt;Notebook&lt;/li&gt; &#xA; &lt;li&gt;Project configuration and dependency version management&lt;/li&gt; &#xA; &lt;li&gt;Task backup and rollback&lt;/li&gt; &#xA; &lt;li&gt;Manage dependencies&lt;/li&gt; &#xA; &lt;li&gt;UDF&lt;/li&gt; &#xA; &lt;li&gt;Flink SQL Connector&lt;/li&gt; &#xA; &lt;li&gt;Flink SQL WebIDE&lt;/li&gt; &#xA; &lt;li&gt;Catalog、Hive&lt;/li&gt; &#xA; &lt;li&gt;Full support from task &lt;code&gt;development&lt;/code&gt; to &lt;code&gt;deployment&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746863-856ef1cd-fa0e-4010-b359-c16ca2ad2fb7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746864-d807d728-423f-41c3-b90d-45ce2c21936b.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🏳‍🌈 Components&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;Streamx&lt;/code&gt; consists of three parts,&lt;code&gt;streamx-core&lt;/code&gt;,&lt;code&gt;streamx-pump&lt;/code&gt; and &lt;code&gt;streamx-console&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746859-f6a4dedc-ec42-4ed5-933b-c27d559b9988.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;1️⃣ streamx-core&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;streamx-core&lt;/code&gt; is a framework that focuses on coding, standardizes configuration, and develops in a way that is better than configuration by convention. Also it provides a development-time &lt;code&gt;RunTime Content&lt;/code&gt; and a series of &lt;code&gt;Connector&lt;/code&gt; out of the box. At the same time, it extends &lt;code&gt;DataStream&lt;/code&gt; some methods, and integrates &lt;code&gt;DataStream&lt;/code&gt; and &lt;code&gt;Flink sql&lt;/code&gt; api to simplify tedious operations, focus on the business itself, and improve development efficiency and development experience.&lt;/p&gt; &#xA;&lt;h3&gt;2️⃣ streamx-pump&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;streamx-pump&lt;/code&gt; is a planned data extraction component, similar to &lt;code&gt;flinkx&lt;/code&gt;. Based on the various &lt;code&gt;connector&lt;/code&gt; provided in &lt;code&gt;streamx-core&lt;/code&gt;, the purpose is to create a convenient, fast, out-of-the-box real-time data extraction and migration component for big data, and it will be integrated into the &lt;code&gt;streamx-console&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;3️⃣ streamx-console&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;streamx-console&lt;/code&gt; is a stream processing and &lt;code&gt;Low Code&lt;/code&gt; platform, capable of managing &lt;code&gt;Flink&lt;/code&gt; tasks, integrating project compilation, deploy, configuration, startup, &lt;code&gt;savepoint&lt;/code&gt;, &lt;code&gt;flame graph&lt;/code&gt;, &lt;code&gt;Flink SQL&lt;/code&gt;, monitoring and many other features. Simplify the daily operation and maintenance of the &lt;code&gt;Flink&lt;/code&gt; task.&lt;/p&gt; &#xA;&lt;p&gt;Our ultimate goal is to build a one-stop big data solution integrating stream processing, batch processing, data warehouse and data laker.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://flink.apache.org&#34;&gt;Apache Flink&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://hadoop.apache.org&#34;&gt;Apache YARN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://spring.io/projects/spring-boot/&#34;&gt;Spring Boot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.mybatis.org&#34;&gt;Mybatis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://mp.baomidou.com&#34;&gt;Mybatis-Plus&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.brendangregg.com/FlameGraphs&#34;&gt;Flame Graph&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/uber-common/jvm-profiler&#34;&gt;JVM-Profiler&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cn.vuejs.org/&#34;&gt;Vue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vuepress.vuejs.org/&#34;&gt;VuePress&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://antdv.com/&#34;&gt;Ant Design of Vue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pro.antdv&#34;&gt;ANTD PRO VUE&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xtermjs.org/&#34;&gt;xterm.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoft.github.io/monaco-editor/&#34;&gt;Monaco Editor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Thanks to the above excellent open source projects and many outstanding open source projects that are not mentioned, for giving the greatest respect,Thanks to &lt;a href=&#34;http://flink.apache.org&#34;&gt;Apache Flink&lt;/a&gt; for creating a great project! Thanks to the &lt;a href=&#34;http://zeppelin.apache.org&#34;&gt;Apache Zeppelin&lt;/a&gt; project for the early inspiration.&lt;/p&gt; &#xA;&lt;h3&gt;🚀 Quick Start&lt;/h3&gt; &#xA;&lt;p&gt;click &lt;a href=&#34;http://www.streamxhub.com/zh-CN/docs/intro/&#34;&gt;Document&lt;/a&gt; for more information&lt;/p&gt; &#xA;&lt;h2&gt;💋 our users&lt;/h2&gt; &#xA;&lt;p&gt;Various companies and organizations use StreamX for research, production and commercial products. Are you using this project ? &lt;a href=&#34;https://github.com/streamxhub/streamx/issues/163&#34;&gt;you can add your company&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/160220085-11f1e011-e7a0-421f-9294-c14213c0bc22.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🏆 Our honor&lt;/h2&gt; &#xA;&lt;p&gt;We have received some precious honors, which belong to everyone who contributes to StreamX, Thank you !&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746797-85ebf7b4-4105-4b5b-a023-0689c7fd1d2d.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/163530071-a5b6f334-9af5-439c-96c9-2bb9b4eec6a6.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🤝 Contribution&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/streamxhub/streamx/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can submit any ideas as &lt;a href=&#34;https://github.com/streamxhub/streamx/pulls&#34;&gt;pull requests&lt;/a&gt; or as &lt;a href=&#34;https://github.com/streamxhub/streamx/issues/new/choose&#34;&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;If you&#39;re new to posting issues, we ask that you read &lt;a href=&#34;http://www.catb.org/~esr/faqs/smart-questions.html&#34;&gt;&lt;em&gt;How To Ask Questions The Smart Way&lt;/em&gt;&lt;/a&gt; (&lt;strong&gt;This guide does not provide actual support services for this project!&lt;/strong&gt;), &lt;a href=&#34;http://www.chiark.greenend.org.uk/~sgtatham/bugs.html&#34;&gt;How to Report Bugs Effectively&lt;/a&gt; prior to posting. Well written bug reports help us help you!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Thank you to all the people who already contributed to StreamX!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/streamxhub/streamx/graphs/contributors&#34;&gt;&lt;img src=&#34;https://opencollective.com/streamx/contributors.svg?width=890&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;⏰ Contributor Over Time&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://git-contributor.com?chart=contributorOverTime&amp;amp;repo=streamxhub/streamx&#34;&gt;&lt;img src=&#34;https://contributor-overtime-api.git-contributor.com/contributors-svg?chart=contributorOverTime&amp;amp;repo=streamxhub/streamx&#34; alt=&#34;Contributor Over Time&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;💰 Donation&lt;/h2&gt; &#xA;&lt;p&gt;Are you &lt;strong&gt;enjoying this project&lt;/strong&gt; ? 👋&lt;/p&gt; &#xA;&lt;p&gt;If you like this framework, and appreciate the work done for it to exist, you can still support the developers by donating ☀️ 👊&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;WeChat Pay&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Alipay&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746857-35e7f823-7160-4505-be3f-e748a2d0a233.png&#34; alt=&#34;Buy Me A Coffee&#34; width=&#34;150&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13284744/142746860-e14a8183-d973-44ca-83bf-e5f9d4da1510.png&#34; alt=&#34;Buy Me A Coffee&#34; width=&#34;150&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;🏆 Our sponsors (Coffee Suppliers)&lt;/h2&gt; &#xA;&lt;h3&gt;💜 Monthly Supplier&lt;/h3&gt; &#xA;&lt;p&gt;Welcome individuals and enterprises to sponsor, your support will help us better develop the project&lt;/p&gt; &#xA;&lt;h3&gt;🥇 Gold Supplier&lt;/h3&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://github.com/wolfboys&#34; alt=&#34;benjobs&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/13284744?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Kitming25&#34; alt=&#34;Kitming25&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/11773106?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Narcasserun&#34; alt=&#34;Narcasserun&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/39329477?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h3&gt;🥈 Platinum Supplier&lt;/h3&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://github.com/lianxiaobao&#34; alt=&#34;lianxiaobao&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/36557317?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/su94998&#34; alt=&#34;su94998&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/33316193?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h3&gt;🥈 Silver Supplier&lt;/h3&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://github.com/CrazyJugger&#34; alt=&#34;leohantaoluo&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/30514978?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/zhaizhirui&#34; alt=&#34;zhaizhirui&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/39609947?v=4&#34; height=&#34;50&#34; width=&#34;50&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://www.jetbrains.com/?from=streamx&#34;&gt;JetBrains&lt;/a&gt; for supporting us free open source licenses.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.jetbrains.com/?from=streamx&#34;&gt;&lt;img src=&#34;https://img.alicdn.com/tfs/TB1sSomo.z1gK0jSZLeXXb9kVXa-120-130.svg?sanitize=true&#34; alt=&#34;JetBrains&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;🏅 Backers&lt;/h3&gt; &#xA;&lt;p&gt;Thank you to all our backers!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;💬 Join us&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/streamxhub/streamx/dev/(http://www.streamxhub.com/#/)&#34;&gt;StreamX&lt;/a&gt; enters the high-speed development stage, we need your contribution.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://starchart.cc/streamxhub/streamx.svg?sanitize=true&#34; alt=&#34;Stargazers over time&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/13284744/152627523-de455a4d-97c7-46cd-815f-3328a3fe3663.png&#34; alt=&#34;Join the Group&#34; height=&#34;300px&#34;&gt;&#xA; &lt;br&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>databricks/LearningSparkV2</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/databricks/LearningSparkV2</id>
    <link href="https://github.com/databricks/LearningSparkV2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This is the github repo for Learning Spark: Lightning-Fast Data Analytics [2nd Edition]&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Learning Spark 2nd Edition&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to the GitHub repo for Learning Spark 2nd Edition.&lt;/p&gt; &#xA;&lt;p&gt;Chapters &lt;a href=&#34;https://raw.githubusercontent.com/databricks/LearningSparkV2/master/chapter2/README.md&#34;&gt;2&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/databricks/LearningSparkV2/master/chapter3/README.md&#34;&gt;3&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/databricks/LearningSparkV2/master/chapter6/README.md&#34;&gt;6&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/databricks/LearningSparkV2/master/chapter7/README.md&#34;&gt;7&lt;/a&gt; contain stand-alone Spark applications. You can build all the JAR files for each chapter by running the Python script: &lt;code&gt;python build_jars.py&lt;/code&gt;. Or you can cd to the chapter directory and build jars as specified in each README. Also, include &lt;code&gt;$SPARK_HOME/bin&lt;/code&gt; in &lt;code&gt;$PATH&lt;/code&gt; so that you don&#39;t have to prefix &lt;code&gt;SPARK_HOME/bin/spark-submit&lt;/code&gt; for these standalone applications.&lt;/p&gt; &#xA;&lt;p&gt;For all the other chapters, we have provided notebooks in the &lt;a href=&#34;https://raw.githubusercontent.com/databricks/LearningSparkV2/master/notebooks&#34;&gt;notebooks&lt;/a&gt; folder. We have also included notebook equivalents for a few of the stand-alone Spark applications in the aforementioned chapters.&lt;/p&gt; &#xA;&lt;p&gt;Have Fun, Cheers!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>crealytics/spark-excel</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/crealytics/spark-excel</id>
    <link href="https://github.com/crealytics/spark-excel" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Spark plugin for reading Excel files via Apache POI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Spark Excel Library&lt;/h1&gt; &#xA;&lt;p&gt;A library for querying Excel files with Apache Spark, for Spark SQL and DataFrames.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/crealytics/spark-excel/actions&#34;&gt;&lt;img src=&#34;https://github.com/crealytics/spark-excel/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.crealytics/spark-excel_2.12&#34;&gt;&lt;img src=&#34;https://maven-badges.herokuapp.com/maven-central/com.crealytics/spark-excel_2.12/badge.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitpod.io/#https://github.com/crealytics/spark-excel&#34;&gt;&lt;img src=&#34;https://gitpod.io/button/open-in-gitpod.svg?sanitize=true&#34; alt=&#34;Open in Gitpod&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Co-maintainers wanted&lt;/h2&gt; &#xA;&lt;p&gt;Due to personal and professional constraints, the development of this library has been rather slow. If you find value in this library, please consider stepping up as a co-maintainer by leaving a comment &lt;a href=&#34;https://github.com/crealytics/spark-excel/issues/191&#34;&gt;here&lt;/a&gt;. Help is very welcome e.g. in the following areas:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Additional features&lt;/li&gt; &#xA; &lt;li&gt;Code improvements and reviews&lt;/li&gt; &#xA; &lt;li&gt;Bug analysis and fixing&lt;/li&gt; &#xA; &lt;li&gt;Documentation improvements&lt;/li&gt; &#xA; &lt;li&gt;Build / test infrastructure&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;This library requires Spark 2.0+.&lt;/p&gt; &#xA;&lt;p&gt;List of spark versions, those are automatically tested:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;spark: [&#34;2.4.1&#34;, &#34;2.4.7&#34;, &#34;2.4.8&#34;, &#34;3.0.1&#34;, &#34;3.0.3&#34;, &#34;3.1.1&#34;, &#34;3.1.2&#34;, &#34;3.2.1&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more detail, please refer to project CI: &lt;a href=&#34;https://github.com/crealytics/spark-excel/raw/main/.github/workflows/ci.yml#L10&#34;&gt;ci.yml&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Linking&lt;/h2&gt; &#xA;&lt;p&gt;You can link against this library in your program at the following coordinates:&lt;/p&gt; &#xA;&lt;h3&gt;Scala 2.12&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;groupId: com.crealytics&#xA;artifactId: spark-excel_2.12&#xA;version: &amp;lt;spark-version&amp;gt;_0.17.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Scala 2.11&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;groupId: com.crealytics&#xA;artifactId: spark-excel_2.11&#xA;version: &amp;lt;spark-version&amp;gt;_0.13.7&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using with Spark shell&lt;/h2&gt; &#xA;&lt;p&gt;This package can be added to Spark using the &lt;code&gt;--packages&lt;/code&gt; command line option. For example, to include it when starting the spark shell:&lt;/p&gt; &#xA;&lt;h3&gt;Spark compiled with Scala 2.12&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$SPARK_HOME/bin/spark-shell --packages com.crealytics:spark-excel_2.12:&amp;lt;spark-version&amp;gt;_0.17.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Spark compiled with Scala 2.11&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$SPARK_HOME/bin/spark-shell --packages com.crealytics:spark-excel_2.11:&amp;lt;spark-version&amp;gt;_0.13.7&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This package allows querying Excel spreadsheets as &lt;a href=&#34;https://spark.apache.org/docs/latest/sql-programming-guide.html&#34;&gt;Spark DataFrames&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;From spark-excel &lt;a href=&#34;https://github.com/crealytics/spark-excel/releases/tag/v0.14.0&#34;&gt;0.14.0&lt;/a&gt; (August 24, 2021), there are two implementation of spark-excel &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Original Spark-Excel with Spark data source API 1.0&lt;/li&gt; &#xA;   &lt;li&gt;Spark-Excel V2 with data source API V2.0+, which supports loading from multiple files, corrupted record handling and some improvement on handling data types. See below for further details&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To use V2 implementation, just change your .format from &lt;code&gt;.format(&#34;com.crealytics.spark.excel&#34;)&lt;/code&gt; to &lt;code&gt;.format(&#34;excel&#34;)&lt;/code&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/crealytics/spark-excel/main/#excel-api-based-on-datasourcev2&#34;&gt;below&lt;/a&gt; for some details&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/crealytics/spark-excel/main/CHANGELOG.md&#34;&gt;changelog&lt;/a&gt; for latest features, fixes etc.&lt;/p&gt; &#xA;&lt;h3&gt;Scala API&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Spark 2.0+:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Create a DataFrame from an Excel file&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.apache.spark.sql._&#xA;&#xA;val spark: SparkSession = ???&#xA;val df = spark.read&#xA;    .format(&#34;com.crealytics.spark.excel&#34;) // Or .format(&#34;excel&#34;) for V2 implementation&#xA;    .option(&#34;dataAddress&#34;, &#34;&#39;My Sheet&#39;!B3:C35&#34;) // Optional, default: &#34;A1&#34;&#xA;    .option(&#34;header&#34;, &#34;true&#34;) // Required&#xA;    .option(&#34;treatEmptyValuesAsNulls&#34;, &#34;false&#34;) // Optional, default: true&#xA;    .option(&#34;setErrorCellsToFallbackValues&#34;, &#34;true&#34;) // Optional, default: false, where errors will be converted to null. If true, any ERROR cell values (e.g. #N/A) will be converted to the zero values of the column&#39;s data type.&#xA;    .option(&#34;usePlainNumberFormat&#34;, &#34;false&#34;) // Optional, default: false, If true, format the cells without rounding and scientific notations&#xA;    .option(&#34;inferSchema&#34;, &#34;false&#34;) // Optional, default: false&#xA;    .option(&#34;addColorColumns&#34;, &#34;true&#34;) // Optional, default: false&#xA;    .option(&#34;timestampFormat&#34;, &#34;MM-dd-yyyy HH:mm:ss&#34;) // Optional, default: yyyy-mm-dd hh:mm:ss[.fffffffff]&#xA;    .option(&#34;maxRowsInMemory&#34;, 20) // Optional, default None. If set, uses a streaming reader which can help with big files (will fail if used with xls format files)&#xA;    .option(&#34;excerptSize&#34;, 10) // Optional, default: 10. If set and if schema inferred, number of rows to infer schema from&#xA;    .option(&#34;workbookPassword&#34;, &#34;pass&#34;) // Optional, default None. Requires unlimited strength JCE for older JVMs&#xA;    .schema(myCustomSchema) // Optional, default: Either inferred schema, or all columns are Strings&#xA;    .load(&#34;Worktime.xlsx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For convenience, there is an implicit that wraps the &lt;code&gt;DataFrameReader&lt;/code&gt; returned by &lt;code&gt;spark.read&lt;/code&gt; and provides a &lt;code&gt;.excel&lt;/code&gt; method which accepts all possible options and provides default values:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.apache.spark.sql._&#xA;import com.crealytics.spark.excel._&#xA;&#xA;val spark: SparkSession = ???&#xA;val df = spark.read.excel(&#xA;    header = true,  // Required&#xA;    dataAddress = &#34;&#39;My Sheet&#39;!B3:C35&#34;, // Optional, default: &#34;A1&#34;&#xA;    treatEmptyValuesAsNulls = false,  // Optional, default: true&#xA;    setErrorCellsToFallbackValues = false, // Optional, default: false, where errors will be converted to null. If true, any ERROR cell values (e.g. #N/A) will be converted to the zero values of the column&#39;s data type.&#xA;    usePlainNumberFormat = false,  // Optional, default: false. If true, format the cells without rounding and scientific notations&#xA;    inferSchema = false,  // Optional, default: false&#xA;    addColorColumns = true,  // Optional, default: false&#xA;    timestampFormat = &#34;MM-dd-yyyy HH:mm:ss&#34;,  // Optional, default: yyyy-mm-dd hh:mm:ss[.fffffffff]&#xA;    maxRowsInMemory = 20,  // Optional, default None. If set, uses a streaming reader which can help with big files (will fail if used with xls format files)&#xA;    excerptSize = 10,  // Optional, default: 10. If set and if schema inferred, number of rows to infer schema from&#xA;    workbookPassword = &#34;pass&#34;  // Optional, default None. Requires unlimited strength JCE for older JVMs&#xA;).schema(myCustomSchema) // Optional, default: Either inferred schema, or all columns are Strings&#xA; .load(&#34;Worktime.xlsx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the sheet name is unavailable, it is possible to pass in an index:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val df = spark.read.excel(&#xA;  header = true,&#xA;  dataAddress = &#34;0!B3:C35&#34;&#xA;).load(&#34;Worktime.xlsx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or to read in the names dynamically:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.crealytics.spark.excel.WorkbookReader&#xA;val sheetNames = WorkbookReader( Map(&#34;path&#34; -&amp;gt; &#34;Worktime.xlsx&#34;)&#xA;                               , spark.sparkContext.hadoopConfiguration&#xA;                               ).sheetNames&#xA;val df = spark.read.excel(&#xA;  header = true,&#xA;  dataAddress = sheetNames(0)&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Create a DataFrame from an Excel file using custom schema&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.apache.spark.sql._&#xA;import org.apache.spark.sql.types._&#xA;&#xA;val peopleSchema = StructType(Array(&#xA;    StructField(&#34;Name&#34;, StringType, nullable = false),&#xA;    StructField(&#34;Age&#34;, DoubleType, nullable = false),&#xA;    StructField(&#34;Occupation&#34;, StringType, nullable = false),&#xA;    StructField(&#34;Date of birth&#34;, StringType, nullable = false)))&#xA;&#xA;val spark: SparkSession = ???&#xA;val df = spark.read&#xA;    .format(&#34;com.crealytics.spark.excel&#34;) // Or .format(&#34;excel&#34;) for V2 implementation&#xA;    .option(&#34;dataAddress&#34;, &#34;&#39;Info&#39;!A1&#34;)&#xA;    .option(&#34;header&#34;, &#34;true&#34;)&#xA;    .schema(peopleSchema)&#xA;    .load(&#34;People.xlsx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Write a DataFrame to an Excel file&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.apache.spark.sql._&#xA;&#xA;val df: DataFrame = ???&#xA;df.write&#xA;  .format(&#34;com.crealytics.spark.excel&#34;) // Or .format(&#34;excel&#34;) for V2 implementation&#xA;  .option(&#34;dataAddress&#34;, &#34;&#39;My Sheet&#39;!B3:C35&#34;)&#xA;  .option(&#34;header&#34;, &#34;true&#34;)&#xA;  .option(&#34;dateFormat&#34;, &#34;yy-mmm-d&#34;) // Optional, default: yy-m-d h:mm&#xA;  .option(&#34;timestampFormat&#34;, &#34;mm-dd-yyyy hh:mm:ss&#34;) // Optional, default: yyyy-mm-dd hh:mm:ss.000&#xA;  .mode(&#34;append&#34;) // Optional, default: overwrite.&#xA;  .save(&#34;Worktime2.xlsx&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Data Addresses&lt;/h4&gt; &#xA;&lt;p&gt;As you can see in the examples above, the location of data to read or write can be specified with the &lt;code&gt;dataAddress&lt;/code&gt; option. Currently the following address styles are supported:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;B3&lt;/code&gt;: Start cell of the data. Reading will return all rows below and all columns to the right. Writing will start here and use as many columns and rows as required.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;B3:F35&lt;/code&gt;: Cell range of data. Reading will return only rows and columns in the specified range. Writing will start in the first cell (&lt;code&gt;B3&lt;/code&gt; in this example) and use only the specified columns and rows. If there are more rows or columns in the DataFrame to write, they will be truncated. Make sure this is what you want.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;&#39;My Sheet&#39;!B3:F35&lt;/code&gt;: Same as above, but with a specific sheet.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MyTable[#All]&lt;/code&gt;: Table of data. Reading will return all rows and columns in this table. Writing will only write within the current range of the table. No growing of the table will be performed. PRs to change this are welcome.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Excel API based on DataSourceV2&lt;/h3&gt; &#xA;&lt;p&gt;The V2 API offers you several improvements when it comes to file and folder handling. and works in a very similar way than data sources like csv and parquet.&lt;/p&gt; &#xA;&lt;p&gt;To use V2 implementation, just change your .format from &lt;code&gt;.format(&#34;com.crealytics.spark.excel&#34;)&lt;/code&gt; to &lt;code&gt;.format(&#34;excel&#34;)&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The big difference is the fact that you provide a path to read / write data from/to and not an individual single file only:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;dataFrame.write&#xA;        .format(&#34;excel&#34;)&#xA;        .save(&#34;some/path&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;spark.read&#xA;        .format(&#34;excel&#34;)&#xA;        // ... insert excel read specific options you need&#xA;        .load(&#34;some/path&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Because folders are supported you can read/write from/to a &#34;partitioned&#34; folder structure, just the same way as csv or parquet. Note that writing partitioned structures is only available for spark &amp;gt;=3.0.1&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;dataFrame.write&#xA;        .partitionBy(&#34;col1&#34;)&#xA;        .format(&#34;excel&#34;)&#xA;        .save(&#34;some/path&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Need some more examples? Check out the &lt;a href=&#34;https://raw.githubusercontent.com/crealytics/spark-excel/main/src/test/scala/com/crealytics/spark/v2/excel/DataFrameWriterApiComplianceSuite.scala&#34;&gt;test cases&lt;/a&gt; or have a look at our wiki&lt;/p&gt; &#xA;&lt;h2&gt;Building From Source&lt;/h2&gt; &#xA;&lt;p&gt;This library is built with &lt;a href=&#34;http://www.scala-sbt.org/0.13/docs/Command-Line-Reference.html&#34;&gt;SBT&lt;/a&gt;. To build a JAR file simply run &lt;code&gt;sbt assembly&lt;/code&gt; from the project root. To build for a specific spark version, for example spark-2.4.1, run &lt;code&gt;sbt -Dspark.testVersion=2.4.1 assembly&lt;/code&gt;, also from the project root. The build configuration includes support for Scala 2.12 and 2.11.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>sbt/sbt</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/sbt/sbt</id>
    <link href="https://github.com/sbt/sbt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;sbt, the interactive build tool&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/sbt/sbt/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/sbt/sbt/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://index.scala-lang.org/sbt/sbt&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/tag/sbt/sbt.svg?sanitize=true&#34; alt=&#34;Latest version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/sbt/sbt&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/sbt/sbt.svg?sanitize=true&#34; alt=&#34;Gitter Chat&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;sbt&lt;/h1&gt; &#xA;&lt;p&gt;sbt is a build tool for Scala, Java, and more.&lt;/p&gt; &#xA;&lt;p&gt;For general documentation, see &lt;a href=&#34;https://www.scala-sbt.org/&#34;&gt;https://www.scala-sbt.org/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;sbt 1.x&lt;/h2&gt; &#xA;&lt;p&gt;This is the 1.x series of sbt. The source code of sbt is split across several GitHub repositories, including this one.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sbt/io&#34;&gt;sbt/io&lt;/a&gt; hosts &lt;code&gt;sbt.io&lt;/code&gt; module.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sbt/librarymanagement&#34;&gt;sbt/librarymanagement&lt;/a&gt; hosts &lt;code&gt;sbt.librarymanagement&lt;/code&gt; module that wraps Ivy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sbt/zinc&#34;&gt;sbt/zinc&lt;/a&gt; hosts Zinc, an incremental compiler for Scala.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sbt/sbt&#34;&gt;sbt/sbt&lt;/a&gt;, this repository hosts modules that implements the build tool.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Other links&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.scala-sbt.org/release/docs/Getting-Started/Setup&#34;&gt;Setup&lt;/a&gt;: Describes getting started with the latest binary release.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.scala-sbt.org/release/docs/Faq.html&#34;&gt;FAQ&lt;/a&gt;: Explains how to get help and more.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sbt/sbt-zero-seven&#34;&gt;sbt/sbt-zero-seven&lt;/a&gt;: hosts sbt 0.7.7 and earlier versions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Issues and Pull Requests&lt;/h2&gt; &#xA;&lt;p&gt;Please read &lt;a href=&#34;https://raw.githubusercontent.com/sbt/sbt/develop/CONTRIBUTING.md&#34;&gt;CONTRIBUTING&lt;/a&gt; carefully before opening a GitHub Issue.&lt;/p&gt; &#xA;&lt;p&gt;The short version: try &lt;a href=&#34;https://stackoverflow.com/tags/sbt&#34;&gt;searching&lt;/a&gt; or &lt;a href=&#34;https://stackoverflow.com/questions/ask?tags=sbt&#34;&gt;asking&lt;/a&gt; on StackOverflow.&lt;/p&gt; &#xA;&lt;h2&gt;license&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/sbt/sbt/develop/LICENSE&#34;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>typelevel/cats-effect</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/typelevel/cats-effect</id>
    <link href="https://github.com/typelevel/cats-effect" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The pure asynchronous runtime for Scala&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Cats Effect&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://index.scala-lang.org/typelevel/cats-effect/cats-effect&#34;&gt;&lt;img src=&#34;https://index.scala-lang.org/typelevel/cats-effect/cats-effect/latest.svg?color=orange&#34; alt=&#34;Latest version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/QNnHKHq5Ts&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/632277896739946517.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=404244&amp;amp;labelColor=6A7EC2&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img align=&#34;right&#34; width=&#34;256px&#34; height=&#34;256px&#34; src=&#34;https://raw.githubusercontent.com/typelevel/cats-effect/series/3.x/images/cats-effect-logo.png&#34;&gt; &#xA;&lt;p&gt;Cats Effect is a high-performance, asynchronous, composable framework for building real-world applications in a purely functional style within the Typelevel ecosystem. It provides a concrete tool, known as &#34;the &lt;code&gt;IO&lt;/code&gt; monad&#34;, for capturing and controlling actions, often referred to as &#34;effects&#34;, that your program wishes to perform within a resource-safe, typed context with seamless support for concurrency and coordination. These effects may be asynchronous (callback-driven) or synchronous (directly returning values); they may return within microseconds or run infinitely.&lt;/p&gt; &#xA;&lt;p&gt;Even more importantly, Cats Effect defines a set of typeclasses which define what it means to be a purely functional runtime system. These abstractions power a thriving ecosystem consisting of streaming frameworks, JDBC database layers, HTTP servers and clients, asynchronous clients for systems like Redis and MongoDB, and so much more! Additionally, you can leverage these abstractions within your own application to unlock powerful capabilities with little-or-no code changes, for example solving problems such as dependency injection, multiple error channels, shared state across modules, tracing, and more.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Wired: &lt;strong&gt;3.3.12&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Tired: &lt;strong&gt;2.5.5&lt;/strong&gt; (end of life)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies += &#34;org.typelevel&#34; %% &#34;cats-effect&#34; % &#34;3.3.12&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above represents the core, stable dependency which brings in the entirety of Cats Effect. This is &lt;em&gt;most likely&lt;/em&gt; what you want. All current Cats Effect releases are published for Scala 2.12, 2.13, 3.0, and Scala.js 1.7.&lt;/p&gt; &#xA;&lt;p&gt;Or, if you prefer a less bare-bones starting point, you can try &lt;a href=&#34;https://github.com/typelevel/ce3.g8&#34;&gt;the Giter8 template&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sbt -Dsbt.version=1.5.5 new typelevel/ce3.g8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Depending on your use-case, you may want to consider one of the several other modules which are made available within the Cats Effect release. If you&#39;re a datatype implementer (like &lt;a href=&#34;https://monix.io&#34;&gt;Monix&lt;/a&gt;), you probably only want to depend on &lt;strong&gt;kernel&lt;/strong&gt; (the typeclasses) in your compile scope and &lt;strong&gt;laws&lt;/strong&gt; in your test scope:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies ++= Seq(&#xA;  &#34;org.typelevel&#34; %% &#34;cats-effect-kernel&#34; % &#34;3.3.12&#34;,&#xA;  &#34;org.typelevel&#34; %% &#34;cats-effect-laws&#34;   % &#34;3.3.12&#34; % Test)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you&#39;re a middleware framework (like &lt;a href=&#34;https://fs2.io/&#34;&gt;Fs2&lt;/a&gt;), you probably want to depend on &lt;strong&gt;std&lt;/strong&gt;, which gives you access to &lt;code&gt;Queue&lt;/code&gt;, &lt;code&gt;Semaphore&lt;/code&gt;, and much more without introducing a hard-dependency on &lt;code&gt;IO&lt;/code&gt; outside of your tests:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies ++= Seq(&#xA;  &#34;org.typelevel&#34; %% &#34;cats-effect-std&#34; % &#34;3.3.12&#34;,&#xA;  &#34;org.typelevel&#34; %% &#34;cats-effect&#34;     % &#34;3.3.12&#34; % Test)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may also find some utility in the &lt;strong&gt;testkit&lt;/strong&gt; and &lt;strong&gt;kernel-testkit&lt;/strong&gt; projects, which contain &lt;code&gt;TestContext&lt;/code&gt;, generators for &lt;code&gt;IO&lt;/code&gt;, and a few other things:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies += &#34;org.typelevel&#34; %% &#34;cats-effect-testkit&#34; % &#34;3.3.12&#34; % Test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Cats Effect provides backward binary compatibility within the 2.x and 3.x version lines, and both forward and backward compatibility within any major/minor line. This is analogous to the versioning scheme used by Cats itself, as well as other major projects such as Scala.js. Thus, any project depending upon Cats Effect 2.2.1 can be used with libraries compiled against Cats Effect 2.0.0 or 2.2.3, but &lt;em&gt;not&lt;/em&gt; with libraries compiled against 2.3.0 or higher.&lt;/p&gt; &#xA;&lt;h3&gt;Updating from Cats Effect 1.x / 2.x&lt;/h3&gt; &#xA;&lt;p&gt;Check out the &lt;a href=&#34;https://typelevel.org/cats-effect/docs/migration-guide&#34;&gt;migration guide&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Hello, World&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import cats.effect._&#xA;&#xA;object Main extends IOApp.Simple {&#xA;  val run = IO.println(&#34;Hello, World!&#34;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, if you need the ability to take arguments and return exit codes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import cats.effect._&#xA;&#xA;object Main extends IOApp {&#xA;  def run(args: List[String]): IO[ExitCode] =&#xA;    if (args.headOption.map(_ == &#34;--do-it&#34;).getOrElse(false))&#xA;      IO.println(&#34;I did it!&#34;).as(ExitCode.Success)&#xA;    else&#xA;      IO.println(&#34;Didn&#39;t do it&#34;).as(ExitCode(-1))&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Five Simple Rules&lt;/h2&gt; &#xA;&lt;p&gt;Any program written using Cats Effect provides incredibly strong guarantees and powerful functionality, performance, safety, and composability, provided you follow each of the following rules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Wrap &lt;em&gt;all&lt;/em&gt; side-effects&lt;/strong&gt; in &lt;code&gt;delay&lt;/code&gt;, &lt;code&gt;async&lt;/code&gt;, &lt;code&gt;blocking&lt;/code&gt;, or &lt;code&gt;interruptible&lt;/code&gt;/&lt;code&gt;interruptibleMany&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;(pro tip: try to keep the size of your &lt;code&gt;delay&lt;/code&gt; blocks small; two &lt;code&gt;delay&lt;/code&gt;s with a &lt;code&gt;flatMap&lt;/code&gt; is much better than one big &lt;code&gt;delay&lt;/code&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;bracket&lt;/code&gt; or &lt;code&gt;Resource&lt;/code&gt;&lt;/strong&gt; for anything which must be &lt;code&gt;close&lt;/code&gt;d&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Never&lt;/em&gt; hard-block a thread&lt;/strong&gt; outside of &lt;code&gt;blocking&lt;/code&gt; or &lt;code&gt;interruptible&lt;/code&gt;/&lt;code&gt;interruptibleMany&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;IOApp&lt;/code&gt;&lt;/strong&gt; instead of writing your own &lt;code&gt;def main&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Never call anything that has &lt;strong&gt;the word &lt;code&gt;unsafe&lt;/code&gt; in the name&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you follow these rules, and you use libraries and frameworks which also follow these rules, you will get a truly astonishing array of things essentially for free:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Extremely high performance, elastic, and scalable applications&lt;/li&gt; &#xA; &lt;li&gt;Proven backpressure mechanisms under extreme load in real deployments&lt;/li&gt; &#xA; &lt;li&gt;Reliable resource safety in all cases&lt;/li&gt; &#xA; &lt;li&gt;Aggressive interruption of unnecessary work (e.g. timeouts), automatically, without any extra implementation effort&lt;/li&gt; &#xA; &lt;li&gt;Composable and modular application architecture (real, &lt;em&gt;practical&lt;/em&gt; functional programming)&lt;/li&gt; &#xA; &lt;li&gt;Simple, safe, and incredibly powerful concurrency mechanisms that get &lt;em&gt;faster&lt;/em&gt; under high contention&lt;/li&gt; &#xA; &lt;li&gt;Highly tuned application runtime with optimized threading and memory management semantics&lt;/li&gt; &#xA; &lt;li&gt;Powerful and orthogonal abstractions which enable architectural decomposition that scales to any problem space&lt;/li&gt; &#xA; &lt;li&gt;Access to an entire ecosystem of uniquely powerful libraries and tooling&lt;/li&gt; &#xA; &lt;li&gt;…and so much more&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;img width=&#34;461px&#34; height=&#34;356px&#34; align=&#34;right&#34; alt=&#34;a bar chart showing &#39;Fixed Thread Pool&#39; and &#39;Cats Effect 3&#39;, with the latter being substantially taller than the former&#34; src=&#34;https://raw.githubusercontent.com/typelevel/cats-effect/series/3.x/images/contention.png&#34;&gt; &#xA;&lt;p&gt;Most functional and async frameworks will tout their performance on synthetic microbenchmarks, measuring things like how many &lt;code&gt;flatMap&lt;/code&gt;s they can evaluate per microsecond and so on. However, most programs aren&#39;t just a bunch of &lt;code&gt;flatMap&lt;/code&gt;s, and the true performance bottlenecks are usually in things like contention scaling under high load, memory and other resource management, backpressure, page faults, and such. In these areas, Cats Effect is truly unrivaled on the JVM, and in most cases, applications written in a purely functional style using Cats Effect will &lt;em&gt;exceed&lt;/em&gt; the performance and elasticity of the same applications written in an imperative style.&lt;/p&gt; &#xA;&lt;p&gt;The chart to the right shows the results of a synthetic benchmark simulating an extremely high-contention scheduling scenario. The scenario is typical of something like a microservice handling extremely high requests-per-second, with each request representing some sort of scatter/gather semantic in which many complex asynchronous actions must be taken in parallel to produce a timely response.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/typelevel/cats-effect/raw/220d0106ca0ff6106746a41504b6ab07d8fc9199/benchmarks/src/main/scala/cats/effect/benchmarks/WorkStealingBenchmark.scala&#34;&gt;The benchmark&lt;/a&gt; measures the performance of a typical &#34;disruptor pattern&#34; application written using a fixed thread pool (from &lt;code&gt;java.util.concurrent.Executors&lt;/code&gt;) compared to the same workflow implemented using Cats Effect (specifically version 3.0). The scores are not a typo: Cats Effect is &lt;em&gt;almost 55x faster&lt;/em&gt; than the typical disruptor-style, hand-tuned implementation. Similarly dramatic results are consistently observed when comparing Cats Effect with other popular asynchronous and functional frameworks.&lt;/p&gt; &#xA;&lt;p&gt;As always, benchmarks are one thing, and your application is its own special snowflake with its own performance profile. Always measure and test &lt;em&gt;your application&lt;/em&gt; before assuming that someone else&#39;s performance results apply in your use-case. When in doubt, &lt;a href=&#34;https://discord.gg/QNnHKHq5Ts&#34;&gt;come talk with us&lt;/a&gt; and we&#39;ll give you an honest opinion!&lt;/p&gt; &#xA;&lt;h2&gt;Abstraction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/typelevel/cats-effect/series/3.x/images/hierarchy.svg?sanitize=true&#34; alt=&#34;the cats effect hierarchy of typeclasses as of version 3.0&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Cats Effect isn&#39;t just designed to enable high performance applications with out-of-the-box safety and elasticity under load. It was intended first and foremost as a tool for implementing &lt;em&gt;composable&lt;/em&gt; and &lt;em&gt;reasonable&lt;/em&gt; software that is easy to write, easy to test, and easy to evolve as your team and requirements change over time. To achieve this goal, Cats Effect embraces and enables strong, typeful, purely-functional programming styles that are uniquely tailored for the Scala language.&lt;/p&gt; &#xA;&lt;p&gt;The typical Cats Effect system is often built in terms of simple, orthogonal, primitive capabilities which come together to represent all the expressive power necessary to encode a modern asynchronous runtime. Much like how the rules of addition, multiplication, and integers come together to define much of what we understand about basic arithmetic, so too do the rules of &lt;code&gt;Functor&lt;/code&gt;, &lt;code&gt;Monad&lt;/code&gt;, and &lt;code&gt;Concurrent&lt;/code&gt; come together to define the nature of a &lt;em&gt;program&lt;/em&gt; which has all the capabilities you need.&lt;/p&gt; &#xA;&lt;p&gt;By learning and leveraging these capabilities directly, it is possible to write functions and classes which clearly state their requirements and capabilities in a &lt;em&gt;statically typed&lt;/em&gt; and discoverable fashion, improving documentation, readability, and separation of concerns.&lt;/p&gt; &#xA;&lt;p&gt;And, just as with arithmetic, even when you don&#39;t directly leverage the nature of abstract mathematics in your daily life, those laws are still present shaping the world around you and enabling powerful and surprising things like computers and trains and restaurant menus. The laws and abstractions of Cats Effect support a powerful and unique ecosystem of frameworks, giving you access to rich and advanced functionality unparalleled in any language or ecosystem, battle tested in production environments ranging from some of the largest companies in the world to some of the nimblest startups.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/typelevel/cats-effect/series/3.x/CONTRIBUTING.md&#34;&gt;&lt;strong&gt;CONTRIBUTING.md&lt;/strong&gt;&lt;/a&gt; for more details. Lots to do!&lt;/p&gt; &#xA;&lt;h3&gt;Website&lt;/h3&gt; &#xA;&lt;p&gt;To build the documentation site locally, the following dependencies are needed, in addition to &lt;code&gt;sbt&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Node (14.x ideally)&lt;/li&gt; &#xA; &lt;li&gt;Yarn (any version should work)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;NOTE: &lt;a href=&#34;https://nixos.org/&#34;&gt;Nix&lt;/a&gt; users can just run &lt;code&gt;nix-shell&lt;/code&gt; at the root directory and follow along the next instructions.&lt;/p&gt; &#xA;&lt;p&gt;Next, check out the documentation branch along with its submodules.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git checkout --track origin/docs&#xA;git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, build the site.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./build.sh host&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If everything goes well, your browser will open at the end of this.&lt;/p&gt; &#xA;&lt;h2&gt;Tool Sponsorship&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img width=&#34;185px&#34; height=&#34;44px&#34; align=&#34;right&#34; src=&#34;https://www.yourkit.com/images/yklogo.png&#34;&gt;Development of Cats Effect is generously supported in part by &lt;a href=&#34;https://www.yourkit.com&#34;&gt;YourKit&lt;/a&gt; through the use of their excellent Java profiler.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;Copyright 2017-2022 Typelevel&#xA;&#xA;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);&#xA;you may not use this file except in compliance with the License.&#xA;You may obtain a copy of the License at&#xA;&#xA;   http://www.apache.org/licenses/LICENSE-2.0&#xA;&#xA;Unless required by applicable law or agreed to in writing, software&#xA;distributed under the License is distributed on an &#34;AS IS&#34; BASIS,&#xA;WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&#xA;See the License for the specific language governing permissions and&#xA;limitations under the License.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>spotify/scio</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/spotify/scio</id>
    <link href="https://github.com/spotify/scio" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Scala API for Apache Beam and Google Cloud Dataflow.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Scio&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/spotify/scio/actions?query=workflow%3Aci&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/spotify/scio/ci&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/spotify/scio?branch=master&#34;&gt;&lt;img src=&#34;https://codecov.io/github/spotify/scio/coverage.svg?branch=master&#34; alt=&#34;codecov.io&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/spotify/scio/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/spotify/scio.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maven-badges.herokuapp.com/maven-central/com.spotify/scio-core_2.12&#34;&gt;&lt;img src=&#34;https://img.shields.io/maven-central/v/com.spotify/scio-core_2.12.svg?sanitize=true&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://spotify.github.io/scio/api/com/spotify/scio/index.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/scaladoc-latest-blue.svg?sanitize=true&#34; alt=&#34;Scaladoc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://scala-steward.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Scala_Steward-helping-brightgreen.svg?style=flat&amp;amp;logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAQCAMAAAARSr4IAAAAVFBMVEUAAACHjojlOy5NWlrKzcYRKjGFjIbp293YycuLa3pYY2LSqql4f3pCUFTgSjNodYRmcXUsPD/NTTbjRS+2jomhgnzNc223cGvZS0HaSD0XLjbaSjElhIr+AAAAAXRSTlMAQObYZgAAAHlJREFUCNdNyosOwyAIhWHAQS1Vt7a77/3fcxxdmv0xwmckutAR1nkm4ggbyEcg/wWmlGLDAA3oL50xi6fk5ffZ3E2E3QfZDCcCN2YtbEWZt+Drc6u6rlqv7Uk0LdKqqr5rk2UCRXOk0vmQKGfc94nOJyQjouF9H/wCc9gECEYfONoAAAAASUVORK5CYII=&#34; alt=&#34;Scala Steward badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.github.com/spotify/scio/master/site/src/main/paradox/images/scio.png&#34; alt=&#34;Scio Logo&#34; width=&#34;250&#34;&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Ecclesiastical Latin IPA: /ˈʃi.o/, [ˈʃiː.o], [ˈʃi.i̯o] Verb: I can, know, understand, have knowledge.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Scio is a Scala API for &lt;a href=&#34;http://beam.incubator.apache.org/&#34;&gt;Apache Beam&lt;/a&gt; and &lt;a href=&#34;https://github.com/GoogleCloudPlatform/DataflowJavaSDK&#34;&gt;Google Cloud Dataflow&lt;/a&gt; inspired by &lt;a href=&#34;http://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt; and &lt;a href=&#34;https://github.com/twitter/scalding&#34;&gt;Scalding&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Scio 0.3.0 and future versions depend on Apache Beam (&lt;code&gt;org.apache.beam&lt;/code&gt;) while earlier versions depend on Google Cloud Dataflow SDK (&lt;code&gt;com.google.cloud.dataflow&lt;/code&gt;). See this &lt;a href=&#34;https://spotify.github.io/scio/Apache-Beam.html&#34;&gt;page&lt;/a&gt; for a list of breaking changes.&lt;/p&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scala API close to that of Spark and Scalding core APIs&lt;/li&gt; &#xA; &lt;li&gt;Unified batch and streaming programming model&lt;/li&gt; &#xA; &lt;li&gt;Fully managed service&lt;sup&gt;*&lt;/sup&gt;&lt;/li&gt; &#xA; &lt;li&gt;Integration with Google Cloud products: Cloud Storage, BigQuery, Pub/Sub, Datastore, Bigtable&lt;/li&gt; &#xA; &lt;li&gt;JDBC, &lt;a href=&#34;http://tensorflow.org/&#34;&gt;TensorFlow&lt;/a&gt; TFRecords, Cassandra, Elasticsearch and Parquet I/O&lt;/li&gt; &#xA; &lt;li&gt;Interactive mode with Scio REPL&lt;/li&gt; &#xA; &lt;li&gt;Type safe BigQuery&lt;/li&gt; &#xA; &lt;li&gt;Integration with &lt;a href=&#34;https://github.com/twitter/algebird&#34;&gt;Algebird&lt;/a&gt; and &lt;a href=&#34;https://github.com/scalanlp/breeze&#34;&gt;Breeze&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Pipeline orchestration with &lt;a href=&#34;http://docs.scala-lang.org/overviews/core/futures.html&#34;&gt;Scala Futures&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Distributed cache&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;sup&gt;*&lt;/sup&gt; provided by Google Cloud Dataflow&lt;/p&gt; &#xA;&lt;h1&gt;Quick Start&lt;/h1&gt; &#xA;&lt;p&gt;Download and install the &lt;a href=&#34;https://adoptopenjdk.net/index.html&#34;&gt;Java Development Kit (JDK)&lt;/a&gt; version 8.&lt;/p&gt; &#xA;&lt;p&gt;Install &lt;a href=&#34;https://www.scala-sbt.org/1.x/docs/Setup.html&#34;&gt;sbt&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Use our &lt;a href=&#34;https://github.com/spotify/scio.g8&#34;&gt;giter8 template&lt;/a&gt; to quickly create a new Scio job repository:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;sbt new spotify/scio.g8&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Switch to the new repo (default &lt;code&gt;scio-job&lt;/code&gt;) and build it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd scio-job&#xA;sbt stage&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the included word count example:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;target/universal/stage/bin/scio-job --output=wc&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;List result files and inspect content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ls -l wc&#xA;cat wc/part-00000-of-00004.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://spotify.github.io/scio/Getting-Started.html&#34;&gt;Getting Started&lt;/a&gt; is the best place to start with Scio. If you are new to Apache Beam and distributed data processing, check out the &lt;a href=&#34;https://beam.apache.org/documentation/programming-guide/&#34;&gt;Beam Programming Guide&lt;/a&gt; first for a detailed explanation of the Beam programming model and concepts. If you have experience with other Scala data processing libraries, check out this comparison between &lt;a href=&#34;https://spotify.github.io/scio/Scio,-Scalding-and-Spark.html&#34;&gt;Scio, Scalding and Spark&lt;/a&gt;. Finally check out this document about the relationship between &lt;a href=&#34;https://spotify.github.io/scio/Scio,-Beam-and-Dataflow.html&#34;&gt;Scio, Beam and Dataflow&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Example Scio pipelines and tests can be found under &lt;a href=&#34;https://github.com/spotify/scio/tree/master/scio-examples/src&#34;&gt;scio-examples&lt;/a&gt;. A lot of them are direct ports from Beam&#39;s Java &lt;a href=&#34;https://github.com/apache/beam/tree/master/examples&#34;&gt;examples&lt;/a&gt;. See this &lt;a href=&#34;http://spotify.github.io/scio/examples/&#34;&gt;page&lt;/a&gt; for some of them with side-by-side explanation. Also see &lt;a href=&#34;https://github.com/spotify/big-data-rosetta-code&#34;&gt;Big Data Rosetta Code&lt;/a&gt; for common data processing code snippets in Scio, Scalding and Spark.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://spotify.github.io/scio/&#34;&gt;Scio Docs&lt;/a&gt; - main documentation site&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://spotify.github.io/scio/api/&#34;&gt;Scio Scaladocs&lt;/a&gt; - current API documentation&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://spotify.github.io/scio/examples/&#34;&gt;Scio Examples&lt;/a&gt; - examples with side-by-side explanation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Artifacts&lt;/h1&gt; &#xA;&lt;p&gt;Scio includes the following artifacts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-core&lt;/code&gt;: core library&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-test&lt;/code&gt;: test utilities, add to your project as a &#34;test&#34; dependency&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-avro&lt;/code&gt;: add-on for Avro, can also be used standalone&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-google-cloud-platform&lt;/code&gt;: add-on for Google Cloud IO&#39;s: BigQuery, Bigtable, Pub/Sub, Datastore, Spanner&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-cassandra*&lt;/code&gt;: add-ons for Cassandra&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-elasticsearch*&lt;/code&gt;: add-ons for Elasticsearch&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-extra&lt;/code&gt;: extra utilities for working with collections, Breeze, etc., best effort support&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-jdbc&lt;/code&gt;: add-on for JDBC IO&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-parquet&lt;/code&gt;: add-on for Parquet&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-tensorflow&lt;/code&gt;: add-on for TensorFlow TFRecords IO and prediction&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-redis&lt;/code&gt;: add-on for Redis&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-smb&lt;/code&gt;: add-on for Sort Merge Bucket operations&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;scio-repl&lt;/code&gt;: extension of the Scala REPL with Scio specific operations&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;Copyright 2021 Spotify AB.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0: &lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>slick/slick</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/slick/slick</id>
    <link href="https://github.com/slick/slick" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Scala Language Integrated Connection Kit. Slick is a modern database query and access library for Scala&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Slick&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://mvnrepository.com/artifact/com.typesafe.slick/slick_2.13&#34;&gt;&lt;img src=&#34;https://img.shields.io/maven-central/v/com.typesafe.slick/slick_2.13.svg?sanitize=true&#34; alt=&#34;Maven&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/slick/slick?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/Join%20Chat.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Slick is a functional database library for Scala.&lt;/p&gt; &#xA;&lt;p&gt;It allows you to work with relational databases almost as if you were using Scala collections, while at the same time giving you full control over when a database access happens and what data is transferred. By writing your queries in Scala you can benefit from the static type checking, compile-time safety, and compositionality of Scala, while retaining the ability to drop down to raw SQL where needed for custom or advanced database features.&lt;/p&gt; &#xA;&lt;p&gt;Slick also features an advanced query compiler which can generate SQL for a variety of different database engines from the same Scala code, allowing you to focus on application logic without worrying about database-specific syntax and quirks.&lt;/p&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Full documentation, including Scaladocs and more complex examples, can be found on the &lt;a href=&#34;https://scala-slick.org&#34;&gt;Slick website&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;We have an active &lt;a href=&#34;https://gitter.im/slick/slick&#34;&gt;gitter channel&lt;/a&gt; where you can ask for help&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Think you&#39;ve found a bug? Have an idea for a new feature? Please raise it in our &lt;a href=&#34;https://github.com/slick/slick/issues&#34;&gt;issue tracker&lt;/a&gt; here on github&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Our friends at &lt;a href=&#34;https://underscore.io/&#34;&gt;&lt;code&gt;underscore.io&lt;/code&gt;&lt;/a&gt; have written &#34;Essential Slick&#34;, an excellent guide to using slick from first principles, which is now available &lt;a href=&#34;https://underscore.io/books/essential-slick/&#34;&gt;as a free download&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;As a simple example we will create a Scala object &lt;code&gt;Coffee&lt;/code&gt;, and a table to store instances of this object in the database:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// First declare our Scala object&#xA;final case class Coffee(name: String, price: Double)&#xA;&#xA;// Next define how Slick maps from a database table to Scala objects&#xA;class Coffees(tag: Tag) extends Table[Coffee](tag, &#34;COFFEES&#34;) {&#xA;  def name  = column[String](&#34;NAME&#34;)&#xA;  def price = column[Double](&#34;PRICE&#34;)&#xA;  def * = (name, price).mapTo[Coffee]&#xA;}&#xA;&#xA;// The `TableQuery` object gives us access to Slick&#39;s rich query API&#xA;val coffees = TableQuery[Coffees]&#xA;&#xA;// Inserting is done by appending to our query object&#xA;// as if it were a regular Scala collection&#xA;// SQL: insert into COFFEES (NAME, PRICE) values (&#39;Latte&#39;, 2.50)&#xA;coffees += Coffee(&#34;Latte&#34;, 2.50)&#xA;&#xA;// Fetching data is also done using the query object&#xA;// SQL: select NAME from COFFEES&#xA;coffees.map(_.name)&#xA;&#xA;// More complex queries can be chained together&#xA;// SQL: select NAME, PRICE from COFFEES where PRICE &amp;lt; 10.0 order by NAME&#xA;coffees.filter(_.price &amp;lt; 10.0).sortBy(_.name)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Database support&lt;/h2&gt; &#xA;&lt;p&gt;The following databases are directly supported by Slick, and are currently covered by a large suite of automated tests to ensure compatibility:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Database&lt;/th&gt; &#xA;   &lt;th&gt;JDBC Driver&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DB2 10.5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www-01.ibm.com/support/docview.wss?uid=swg21363866&#34;&gt;db2jcc4:4.19.20&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Derby/JavaDB&lt;/td&gt; &#xA;   &lt;td&gt;derby:10.14.2.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;H2&lt;/td&gt; &#xA;   &lt;td&gt;com.h2database.h2:1.4.199&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HSQLDB/HyperSQL&lt;/td&gt; &#xA;   &lt;td&gt;hsqldb:2.4.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MySQL&lt;/td&gt; &#xA;   &lt;td&gt;mysql-connector-java:8.0.16&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oracle 11g&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.oracle.com/technetwork/database/features/jdbc/index-091264.html&#34;&gt;ojdbc7:12.1.0.2&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PostgreSQL&lt;/td&gt; &#xA;   &lt;td&gt;postgresql:42.2.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SQLite&lt;/td&gt; &#xA;   &lt;td&gt;sqlite-jdbc:3.27.2.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SQLServer 2008, 2012, 2014, 2017&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://sourceforge.net/projects/jtds/files/jtds/&#34;&gt;jtds:1.3.1&lt;/a&gt; and &lt;a href=&#34;https://docs.microsoft.com/en-us/sql/connect/jdbc/download-microsoft-jdbc-driver-for-sql-server?view=sql-server-2017&#34;&gt;msjdbc:7.2.2&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Accessing other database systems is possible, although possibly with a reduced feature set.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Slick is community-maintained: pull requests are very welcome, and we ask that all contributors abide by the &lt;a href=&#34;https://www.lightbend.com/conduct&#34;&gt;Lightbend Community Code of Conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Lightbend staff (such as @SethTisue) may be able to assist with administrative issues.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apache/tvm-vta</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/apache/tvm-vta</id>
    <link href="https://github.com/apache/tvm-vta" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open, Modular, Deep Learning Accelerator&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VTA Hardware Design Stack&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ci.tlcpack.ai/job/tvm-vta/job/main/&#34;&gt;&lt;img src=&#34;https://ci.tlcpack.ai/job/tvm-vta/job/main/badge/icon&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;VTA (versatile tensor accelerator) is an open-source deep learning accelerator complemented with an end-to-end TVM-based compiler stack.&lt;/p&gt; &#xA;&lt;p&gt;The key features of VTA include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generic, modular, open-source hardware &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Streamlined workflow to deploy to FPGAs.&lt;/li&gt; &#xA;   &lt;li&gt;Simulator support to prototype compilation passes on regular workstations.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Driver and JIT runtime for both simulator and FPGA hardware back-end.&lt;/li&gt; &#xA; &lt;li&gt;End-to-end TVM stack integration &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Direct optimization and deployment of models from deep learning frameworks via TVM.&lt;/li&gt; &#xA;   &lt;li&gt;Customized and extensible TVM compiler back-end.&lt;/li&gt; &#xA;   &lt;li&gt;Flexible RPC support to ease deployment, and program FPGAs with the convenience of Python.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>akka/akka</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/akka/akka</id>
    <link href="https://github.com/akka/akka" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build highly concurrent, distributed, and resilient message-driven applications on the JVM&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Akka &lt;a href=&#34;https://index.scala-lang.org/akka/akka/akka-actor&#34;&gt;&lt;img src=&#34;https://index.scala-lang.org/akka/akka/akka-actor/latest.svg?sanitize=true&#34; alt=&#34;Latest version&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://travis-ci.com/github/akka/akka&#34;&gt;&lt;img src=&#34;https://api.travis-ci.com/akka/akka.svg?branch=main&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;We believe that writing correct concurrent &amp;amp; distributed, resilient and elastic applications is too hard. Most of the time it&#39;s because we are using the wrong tools and the wrong level of abstraction.&lt;/p&gt; &#xA;&lt;p&gt;Akka is here to change that.&lt;/p&gt; &#xA;&lt;p&gt;Using the Actor Model we raise the abstraction level and provide a better platform to build correct concurrent and scalable applications. This model is a perfect match for the principles laid out in the &lt;a href=&#34;https://www.reactivemanifesto.org/&#34;&gt;Reactive Manifesto&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For resilience, we adopt the &#34;Let it crash&#34; model which the telecom industry has used with great success to build applications that self-heal and systems that never stop.&lt;/p&gt; &#xA;&lt;p&gt;Actors also provide the abstraction for transparent distribution and the basis for truly scalable and fault-tolerant applications.&lt;/p&gt; &#xA;&lt;p&gt;Learn more at &lt;a href=&#34;https://akka.io/&#34;&gt;akka.io&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Reference Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The reference documentation is available at &lt;a href=&#34;https://doc.akka.io&#34;&gt;doc.akka.io&lt;/a&gt;, for &lt;a href=&#34;https://doc.akka.io/docs/akka/current/scala.html&#34;&gt;Scala&lt;/a&gt; and &lt;a href=&#34;https://doc.akka.io/docs/akka/current/java.html&#34;&gt;Java&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;You can join these groups and chats to discuss and ask Akka related questions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Forums: &lt;a href=&#34;https://discuss.akka.io&#34;&gt;discuss.akka.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Chat room about &lt;em&gt;using&lt;/em&gt; Akka: &lt;a href=&#34;https://gitter.im/akka/akka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/gitter%3A-akka%2Fakka-blue.svg?style=flat-square&#34; alt=&#34;gitter: akka/akka&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Issue tracker: &lt;a href=&#34;https://github.com/akka/akka/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/github%3A-issues-blue.svg?style=flat-square&#34; alt=&#34;github: akka/akka&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In addition to that, you may enjoy following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://akka.io/blog/news-archive.html&#34;&gt;news&lt;/a&gt; section of the page, which is updated whenever a new version is released&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://akka.io/blog/article-archive.html&#34;&gt;Akka Team Blog&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/akkateam&#34;&gt;@akkateam&lt;/a&gt; on Twitter&lt;/li&gt; &#xA; &lt;li&gt;Questions tagged &lt;a href=&#34;https://stackoverflow.com/questions/tagged/akka&#34;&gt;#akka on StackOverflow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Projects built with Akka: &lt;a href=&#34;https://index.scala-lang.org/search?q=dependencies:akka/*&#34;&gt;&lt;img src=&#34;https://index.scala-lang.org/count.svg?q=dependencies:akka/*&amp;amp;subject=scaladex:&amp;amp;color=blue&amp;amp;style=flat-square&#34; alt=&#34;akka-dependency-badge&#34; title=&#34;Built with Akka&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Contributions are &lt;em&gt;very&lt;/em&gt; welcome!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you see an issue that you&#39;d like to see fixed, or want to shape out some ideas, the best way to make it happen is to help out by submitting a pull request implementing it. We welcome contributions from all, even you are not yet familiar with this project, We are happy to get you started, and will guide you through the process once you&#39;ve submitted your PR.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://index.scala-lang.org/search?q=dependencies:akka/*&#34;&gt;&lt;img src=&#34;https://index.scala-lang.org/count.svg?q=dependencies:akka/*&amp;amp;subject=scaladex:&amp;amp;color=blue&amp;amp;style=flat-square&#34; alt=&#34;akka-dependency-badge&#34; title=&#34;Built with Akka&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Refer to the &lt;a href=&#34;https://github.com/akka/akka/raw/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; file for more details about the workflow, and general hints on how to prepare your pull request. You can also ask for clarifications or guidance in GitHub issues directly, or in the akka/dev chat if a more real time communication would be of benefit.&lt;/p&gt; &#xA;&lt;p&gt;A chat room is available for all questions related to &lt;em&gt;developing and contributing&lt;/em&gt; to Akka: &lt;a href=&#34;https://gitter.im/akka/dev&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/gitter%3A-akka%2Fdev-blue.svg?style=flat-square&#34; alt=&#34;gitter: akka/dev&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Akka is Open Source and available under the Apache 2 License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>enso-org/enso</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/enso-org/enso</id>
    <link href="https://github.com/enso-org/enso" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Hybrid visual and textual functional programming.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://enso.org&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/1623053/114557275-cbd27a80-9c69-11eb-9e4d-a60187cdb7a4.gif&#34; width=&#34;640&#34; height=&#34;640&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/enso&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/401396655599124480.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2&#34; alt=&#34;Chat&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/enso-org/enso/actions&#34;&gt; &lt;img src=&#34;https://github.com/enso-org/enso/workflows/Engine%20CI/badge.svg?sanitize=true&#34; alt=&#34;Actions Status&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/enso-org/enso/actions&#34;&gt; &lt;img src=&#34;https://github.com/enso-org/enso/workflows/GUI%20CI/badge.svg?sanitize=true&#34; alt=&#34;Actions Status&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/enso-org/enso/raw/develop/LICENSE&#34;&gt; &lt;img src=&#34;https://img.shields.io/static/v1?label=Compiler%20License&amp;amp;message=Apache%20v2&amp;amp;color=2ec352&amp;amp;labelColor=2c3239&#34; alt=&#34;License&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/enso-org/enso/raw/develop/app/gui/LICENSE&#34;&gt; &lt;img src=&#34;https://img.shields.io/static/v1?label=GUI%20License&amp;amp;message=AGPL%20v3&amp;amp;color=2ec352&amp;amp;labelColor=2c3239&#34; alt=&#34;License&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://enso.org&#34;&gt;Enso.org&lt;/a&gt;. Get insights you can rely on. In real time.&lt;/h1&gt; &#xA;&lt;p&gt;Enso is an award-winning interactive programming language with dual visual and textual representations. It is a tool that spans the entire stack, going from high-level visualisation and communication to the nitty-gritty of backend services, all in a single language. Watch the following introduction video to learn what Enso is, and how it helps companies build data workflows in minutes instead of weeks.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;a href=&#34;https://www.youtube.com/watch?v=fQvWMoOjmQk&#34; rel=&#34;nofollow&#34;&gt; &lt;img width=&#34;692&#34; alt=&#34;Screenshot 2021-04-15 at 12 16 32&#34; src=&#34;https://user-images.githubusercontent.com/1623053/114854125-c8173300-9de4-11eb-9b10-99a331eb2251.png&#34;&gt; &lt;/a&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Enso&#39;s Features&lt;/h1&gt; &#xA;&lt;p&gt;Turning your data into knowledge is slow and error-prone. You can’t trust tools that don’t embrace best practices and provide quality assurance. Enso redefines the way you can work with your data: it is interactive, provides intelligent assistance, and was designed on a strong mathematical foundation, so you can always trust the results you get.&lt;/p&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;44px&#34; src=&#34;https://raw.githubusercontent.com/enso-org/icons/master/blue/with-bg/it/web-apps-development/001-algorithm.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Intelligent suggestions of possible next steps. Build workflows in minutes instead of weeks.&lt;/b&gt;&#xA;  &lt;br&gt; Enso analyses the data, suggests possible next steps, and displays related help and examples. It lets you build dashboards, RPA workflows, and apps, with no coding required. Enso ships with a robust set of libraries, allowing you to work with local files, databases, HTTP services and other applications in a seamless fashion. &#xA;  &lt;br&gt;&#xA;  &lt;a href=&#34;https://enso.org&#34;&gt;Learn more →&lt;/a&gt;&#xA;  &lt;a&gt;&lt;/a&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;44px&#34; src=&#34;https://raw.githubusercontent.com/enso-org/icons/master/blue/with-bg/it/badges/018-military.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Reproducible, trustworthy results.&lt;/b&gt;&#xA;  &lt;br&gt; Versioning and visual data quality management allow you to trust the results that you get. &#xA;  &lt;br&gt;&#xA;  &lt;a href=&#34;https://enso.org&#34;&gt;Learn more →&lt;/a&gt;&#xA;  &lt;a&gt;&lt;/a&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;44px&#34; src=&#34;https://raw.githubusercontent.com/enso-org/icons/master/blue/with-bg/it/basic-ui/041-graph.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;A powerful, purely functional language. Both visual and textual.&lt;/b&gt;&#xA;  &lt;br&gt; Enso incorporates many recent innovations in data processing and programming language design to allow you to work interactively and trust the results that you get. It is a purely functional programming language with higher-order functions, user-defined algebraic datatypes, pattern-matching, and two equivalent representations that you can switch between on-demand. &#xA;  &lt;br&gt;&#xA;  &lt;a href=&#34;https://enso.org&#34;&gt;Learn more →&lt;/a&gt;&#xA;  &lt;a&gt;&lt;/a&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;44px&#34; src=&#34;https://raw.githubusercontent.com/enso-org/icons/master/blue/with-bg/it/business/036-puzzle.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Mix languages with close-to-zero interop overhead.&lt;/b&gt;&#xA;  &lt;br&gt; Import any library from Enso, Java, JavaScript, R, or Python, and use functions, callbacks, and data types without any wrappers. Enso uses &#xA;  &lt;a href=&#34;https://www.graalvm.org&#34;&gt;GraalVM&lt;/a&gt; to compile them to the same instruction set with a unified memory model. &#xA;  &lt;br&gt;&#xA;  &lt;a href=&#34;https://enso.org&#34;&gt;Learn more →&lt;/a&gt;&#xA;  &lt;a&gt;&lt;/a&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;44px&#34; src=&#34;https://raw.githubusercontent.com/enso-org/icons/master/blue/with-bg/it/startup-and-new-business/051-rocket.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Fast. Up to 80x faster than Python.&lt;/b&gt;&#xA;  &lt;br&gt; It can even run other languages faster than their official runtimes. &#xA;  &lt;a href=&#34;https://github.com/oracle/fastr&#34;&gt;Enso-R (using FastR on the GraalVM)&lt;/a&gt; is 36x faster than GNU-R. &#xA;  &lt;br&gt;&#xA;  &lt;a href=&#34;https://github.com/enso-org/benchmarks&#34;&gt;See benchmarks →&lt;/a&gt;&#xA;  &lt;a&gt;&lt;/a&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;44px&#34; src=&#34;https://raw.githubusercontent.com/enso-org/icons/master/blue/with-bg/it/school/063-palette.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;A cutting-edge visualization engine.&lt;/b&gt;&#xA;  &lt;br&gt; Enso is equipped with a highly-tailored WebGL visualization engine capable of displaying many millions of data points at 60 frames per second in a web browser. Currently, Enso includes a set of core data visualizations out of the box, and you can easily extend it with libraries such as D3.js, Three.js, Babylon.js, deck.gl, VTK.js, Potree, and many more. &#xA;  &lt;br&gt;&#xA;  &lt;a href=&#34;https://enso.org&#34;&gt;Learn more →&lt;/a&gt;&#xA;  &lt;a&gt;&lt;/a&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;44px&#34; src=&#34;https://raw.githubusercontent.com/enso-org/icons/master/blue/with-bg/it/shipping/004-cargo-ship.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Runs everywhere.&lt;/b&gt;&#xA;  &lt;br&gt; Enso is available on MacOS, Windows, and Linux, and the Enso IDE runs on web-native technologies. In time, you&#39;ll be able to run it in the web-browser, giving even your tablet and phone access to your data. &#xA;  &lt;br&gt;&#xA;  &lt;a href=&#34;https://enso.org&#34;&gt;Learn more →&lt;/a&gt;&#xA;  &lt;a&gt;&lt;/a&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;img align=&#34;right&#34; alt=&#34;An example Enso graph&#34; src=&#34;https://user-images.githubusercontent.com/1623053/105841783-7c1ed400-5fd5-11eb-8493-7c6a629a84b7.png&#34; width=&#34;380&#34;&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;36px&#34; src=&#34;https://github.com/google/material-design-icons/raw/master/src/action/get_app/materialiconsround/24px.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Download Enso&lt;/b&gt;&#xA;  &lt;br&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/enso-org/ide/releases&#34;&gt;Enso Interactive Environment&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/enso-org/enso/releases&#34;&gt;Enso Compiler (CLI, optional)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;36px&#34; src=&#34;https://github.com/google/material-design-icons/raw/master/src/social/school/materialiconsround/24px.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Watch Tutorials&lt;/b&gt;&#xA;  &lt;br&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/enso-org/enso/raw/develop/app/gui/docs/product/shortcuts.md&#34;&gt;Enso keyboard shortcuts&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://youtu.be/3f6FE1dgMNw?list=PLk8NuufOVK01GhaObYr1_gqeASlkj2um0&#34;&gt;Enso 101&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://youtu.be/hFxugfGbvGI?list=PLk8NuufOVK01GhaObYr1_gqeASlkj2um0&#34;&gt;Analyze trams data&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://youtu.be/gXnojGR6wOI?list=PLk8NuufOVK01GhaObYr1_gqeASlkj2um0&#34;&gt;Analyze GitHub Stargazers data&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLk8NuufOVK01GhaObYr1_gqeASlkj2um0&#34;&gt;... other tutorials&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;36px&#34; src=&#34;https://github.com/google/material-design-icons/raw/master/src/hardware/cast_for_education/materialiconsround/24px.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Watch Video Podcasts&lt;/b&gt;&#xA;  &lt;br&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=U3pb7HiZIBg&amp;amp;t=2996s&amp;amp;ab_channel=Enso&#34;&gt;Enso Textual Language Basics&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://youtu.be/bcpOEX1x06I&#34;&gt;Using Java libraries in Enso&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://youtu.be/wFkh5LgAZTs&#34;&gt;Custom data visualizations&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://youtu.be/BibjcUjdkO4&#34;&gt;Enso vision. What is in the future?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/c/Enso_org/videos?view=2&amp;amp;sort=dd&amp;amp;live_view=503&amp;amp;shelf_id=3&#34;&gt;... other video podcasts&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;36px&#34; src=&#34;https://github.com/google/material-design-icons/raw/master/src/communication/forum/materialiconsround/24px.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Join Our Community&lt;/b&gt;&#xA;  &lt;br&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://discord.gg/enso&#34;&gt;Discord chat. Get help, share your use cases, meet the team behind Enso and other Enso users!&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/enso-org/enso/discussions&#34;&gt;GitHub Discussion Forum&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;img align=&#34;left&#34; width=&#34;36px&#34; src=&#34;https://github.com/google/material-design-icons/raw/master/src/av/new_releases/materialiconsround/24px.svg?sanitize=true&#34;&gt; &#xA;&lt;ul&gt;&#xA; &lt;ul&gt; &#xA;  &lt;b&gt;Keep Up With the Latest Updates&lt;/b&gt;&#xA;  &lt;br&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://medium.com/@enso_org&#34;&gt;Enso Development Blog&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://eepurl.com/bRru9j&#34;&gt;Enso Mailing List&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA; &lt;/ul&gt;&#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Enso Source Code&lt;/h1&gt; &#xA;&lt;p&gt;If you want to start &lt;em&gt;using&lt;/em&gt; Enso, please see the download links in the &lt;a href=&#34;https://raw.githubusercontent.com/enso-org/enso/develop/#getting-started&#34;&gt;getting started&lt;/a&gt; section above. Alternatively you can get the IDE &lt;a href=&#34;https://github.com/enso-org/ide/releases&#34;&gt;here&lt;/a&gt; and the language itself &lt;a href=&#34;https://github.com/enso-org/enso-/releases&#34;&gt;here&lt;/a&gt;. This section is intended for people interested in contributing to the development of Enso.&lt;/p&gt; &#xA;&lt;p&gt;Enso is a community-driven open source project which is, and will always be, open and free to use. Join us, help us to build it, and spread the word!&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Project Components&lt;/h3&gt; &#xA;&lt;p&gt;Enso consists of several sub projects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enso Engine:&lt;/strong&gt; The Enso Engine is the set of tools that implement the Enso language and its associated services. These include the Enso interpreter, a just-in-time compiler and runtime (both powered by &lt;a href=&#34;https://www.graalvm.org&#34;&gt;GraalVM&lt;/a&gt;), and a language server that lets you inspect Enso code as it runs. These components can be used on their own as command line tools.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enso IDE:&lt;/strong&gt; The &lt;a href=&#34;https://github.com/enso-org/enso/tree/develop/gui&#34;&gt;Enso IDE&lt;/a&gt; is the desktop application that allows working with the visual form of Enso. It consists of an Electron application, a high performance WebGL UI framework, and the searcher which provides contextual search, hints, and documentation for all of Enso&#39;s functionality.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;The Enso Engine is licensed under the &lt;a href=&#34;https://opensource.org/licenses/apache-2.0&#34;&gt;Apache 2.0&lt;/a&gt;, as specified in the &lt;a href=&#34;https://github.com/enso-org/enso/raw/develop/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file. The Enso IDE is licensed under the &lt;a href=&#34;https://opensource.org/licenses/AGPL-3.0&#34;&gt;AGPL 3.0&lt;/a&gt;, as specified in the &lt;a href=&#34;https://github.com/enso-org/enso/raw/develop/app/gui/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;This license set was choosen to both provide you with a complete freedom to use Enso, create libraries, and release them under any license of your choice, while also allowing us to release commercial products on top of the platform, including Enso Cloud and Enso Enterprise server managers.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Contributing to Enso&lt;/h3&gt; &#xA;&lt;p&gt;Enso is a community-driven open source project which is and will always be open and free to use. We are committed to a fully transparent development process and highly appreciate every contribution. If you love the vision behind Enso and you want to redefine the data processing world, join us and help us track down bugs, implement new features, improve the documentation or spread the word!&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d like to help us make this vision a reality, please feel free to join our &lt;a href=&#34;https://discord.gg/enso&#34;&gt;chat&lt;/a&gt;, and take a look at our &lt;a href=&#34;https://raw.githubusercontent.com/enso-org/enso/develop/docs/CONTRIBUTING.md&#34;&gt;development and contribution guidelines&lt;/a&gt;. The latter describes all the ways in which you can help out with the project, as well as provides detailed instructions for building and hacking on Enso.&lt;/p&gt; &#xA;&lt;p&gt;If you believe that you have found a security vulnerability in Enso, or that you have a bug report that poses a security risk to Enso&#39;s users, please take a look at our &lt;a href=&#34;https://raw.githubusercontent.com/enso-org/enso/develop/docs/SECURITY.md&#34;&gt;security guidelines&lt;/a&gt; for a course of action.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Enso&#39;s Design&lt;/h3&gt; &#xA;&lt;p&gt;If you would like to gain a better understanding of the principles on which Enso is based, or just delve into the why&#39;s and what&#39;s of Enso&#39;s design, please take a look in the &lt;a href=&#34;https://raw.githubusercontent.com/enso-org/enso/develop/docs/&#34;&gt;&lt;code&gt;docs/&lt;/code&gt; folder&lt;/a&gt;. It is split up into subfolders for each component of Enso. You can view this same documentation in a rendered form at &lt;a href=&#34;https://enso.org/docs/developer&#34;&gt;the developer docs website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This folder also contains a document on Enso&#39;s &lt;a href=&#34;https://raw.githubusercontent.com/enso-org/enso/develop/docs/enso-philosophy.md&#34;&gt;design philosophy&lt;/a&gt;, that details the thought process that we use when contemplating changes or additions to the language.&lt;/p&gt; &#xA;&lt;p&gt;This documentation will evolve as Enso does, both to help newcomers to the project understand the reasoning behind the code, but also to act as a record of the decisions that have been made through Enso&#39;s evolution.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lichess-org/lila</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/lichess-org/lila</id>
    <link href="https://github.com/lichess-org/lila" rel="alternate"></link>
    <summary type="html">&lt;p&gt;♞ lichess.org: the forever free, adless and open source chess server ♞&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&#34;https://lichess.org&#34;&gt;lichess.org&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lichess-org/lila/actions?query=workflow%3A%22Build+server%22&#34;&gt;&lt;img src=&#34;https://github.com/lichess-org/lila/workflows/Build%20server/badge.svg?sanitize=true&#34; alt=&#34;Build server&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lichess-org/lila/actions?query=workflow%3A%22Build+assets%22&#34;&gt;&lt;img src=&#34;https://github.com/lichess-org/lila/workflows/Build%20assets/badge.svg?sanitize=true&#34; alt=&#34;Build assets&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://crowdin.com/project/lichess&#34;&gt;&lt;img src=&#34;https://d322cqt584bo4o.cloudfront.net/lichess/localized.svg?sanitize=true&#34; alt=&#34;Crowdin&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/lichess&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Twitter-%40lichess-blue.svg?sanitize=true&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/lichess-org/lila/master/public/images/home-bicolor.png&#34; alt=&#34;Lichess homepage&#34; title=&#34;Lichess comes with light and dark theme, this screenshot shows both.&#34;&gt; &#xA;&lt;p&gt;Lila (li[chess in sca]la) is a free online chess game server focused on &lt;a href=&#34;https://lichess.org/games&#34;&gt;realtime&lt;/a&gt; gameplay and ease of use.&lt;/p&gt; &#xA;&lt;p&gt;It features a &lt;a href=&#34;https://lichess.org/games/search&#34;&gt;search engine&lt;/a&gt;, &lt;a href=&#34;https://lichess.org/ief49lif&#34;&gt;computer analysis&lt;/a&gt; distributed with &lt;a href=&#34;https://github.com/lichess-org/fishnet&#34;&gt;fishnet&lt;/a&gt;, &lt;a href=&#34;https://lichess.org/tournament&#34;&gt;tournaments&lt;/a&gt;, &lt;a href=&#34;https://lichess.org/simul&#34;&gt;simuls&lt;/a&gt;, &lt;a href=&#34;https://lichess.org/forum&#34;&gt;forums&lt;/a&gt;, &lt;a href=&#34;https://lichess.org/team&#34;&gt;teams&lt;/a&gt;, &lt;a href=&#34;https://lichess.org/training&#34;&gt;tactic trainer&lt;/a&gt;, a &lt;a href=&#34;https://lichess.org/mobile&#34;&gt;mobile app&lt;/a&gt;, and a &lt;a href=&#34;https://lichess.org/study&#34;&gt;shared analysis board&lt;/a&gt;. The UI is available in more than &lt;a href=&#34;https://crowdin.com/project/lichess&#34;&gt;130 languages&lt;/a&gt; thanks to the community.&lt;/p&gt; &#xA;&lt;p&gt;Lichess is written in &lt;a href=&#34;https://www.scala-lang.org/&#34;&gt;Scala 2.13&lt;/a&gt;, and relies on the &lt;a href=&#34;https://www.playframework.com/&#34;&gt;Play 2.8&lt;/a&gt; framework. &lt;a href=&#34;https://com-lihaoyi.github.io/scalatags/&#34;&gt;scalatags&lt;/a&gt; is used for templating. Pure chess logic is contained in the &lt;a href=&#34;https://github.com/lichess-org/scalachess&#34;&gt;scalachess&lt;/a&gt; submodule. The server is fully asynchronous, making heavy use of Scala Futures and &lt;a href=&#34;https://akka.io&#34;&gt;Akka streams&lt;/a&gt;. WebSocket connections are handled by a &lt;a href=&#34;https://github.com/lichess-org/lila-ws&#34;&gt;separate server&lt;/a&gt; that communicates using &lt;a href=&#34;https://redis.io/&#34;&gt;redis&lt;/a&gt;. Lichess talks to &lt;a href=&#34;https://stockfishchess.org/&#34;&gt;Stockfish&lt;/a&gt; deployed in an &lt;a href=&#34;https://github.com/lichess-org/fishnet&#34;&gt;AI cluster&lt;/a&gt; of donated servers. It uses &lt;a href=&#34;https://www.mongodb.com&#34;&gt;MongoDB&lt;/a&gt; to store more than 1.7 billion games, which are indexed by &lt;a href=&#34;https://github.com/elastic/elasticsearch&#34;&gt;elasticsearch&lt;/a&gt;. HTTP requests and WebSocket connections can be proxied by &lt;a href=&#34;https://nginx.org&#34;&gt;nginx&lt;/a&gt;. The web client is written in &lt;a href=&#34;https://www.typescriptlang.org/&#34;&gt;TypeScript&lt;/a&gt; and &lt;a href=&#34;https://github.com/snabbdom/snabbdom&#34;&gt;snabbdom&lt;/a&gt;, using &lt;a href=&#34;https://sass-lang.com/&#34;&gt;Sass&lt;/a&gt; to generate CSS. The &lt;a href=&#34;https://lichess.org/blog&#34;&gt;blog&lt;/a&gt; uses a free open content plan from &lt;a href=&#34;https://prismic.io&#34;&gt;prismic.io&lt;/a&gt;. All rated games are published in a &lt;a href=&#34;https://database.lichess.org&#34;&gt;free PGN database&lt;/a&gt;. Browser testing done with &lt;a href=&#34;https://www.browserstack.com&#34;&gt;Browserstack&lt;/a&gt;. Proxy detection done with &lt;a href=&#34;https://www.ip2location.com/database/ip2proxy&#34;&gt;IP2Proxy database&lt;/a&gt;. Please help us &lt;a href=&#34;https://crowdin.com/project/lichess&#34;&gt;translate Lichess with Crowdin&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://lichess.org/source&#34;&gt;lichess.org/source&lt;/a&gt; for a list of repositories.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/lichess&#34;&gt;Join us on Discord&lt;/a&gt; for more info. Use &lt;a href=&#34;https://github.com/lichess-org/lila/issues&#34;&gt;GitHub issues&lt;/a&gt; for bug reports and feature requests.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;./lila # thin wrapper around sbt&#xA;run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The Wiki describes &lt;a href=&#34;https://github.com/lichess-org/lila/wiki/Lichess-Development-Onboarding&#34;&gt;how to setup a development environment&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;HTTP API&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to use the &lt;a href=&#34;https://lichess.org/api&#34;&gt;Lichess API&lt;/a&gt; in your applications and websites.&lt;/p&gt; &#xA;&lt;h2&gt;Supported browsers&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Version&lt;/th&gt; &#xA;   &lt;th&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chromium / Chrome&lt;/td&gt; &#xA;   &lt;td&gt;last 10&lt;/td&gt; &#xA;   &lt;td&gt;Full support&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Firefox&lt;/td&gt; &#xA;   &lt;td&gt;61+&lt;/td&gt; &#xA;   &lt;td&gt;Full support (fastest local analysis since FF 79)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Edge&lt;/td&gt; &#xA;   &lt;td&gt;91+&lt;/td&gt; &#xA;   &lt;td&gt;Full support (reasonable support for 17+)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Opera&lt;/td&gt; &#xA;   &lt;td&gt;55+&lt;/td&gt; &#xA;   &lt;td&gt;Reasonable support&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Safari&lt;/td&gt; &#xA;   &lt;td&gt;11.1+&lt;/td&gt; &#xA;   &lt;td&gt;Reasonable support&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Older browsers (including any version of Internet Explorer) will not work. For your own sake, please upgrade. Security and performance, think about it!&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Lila is licensed under the GNU Affero General Public License 3 or any later version at your choice with an exception for Highcharts. See &lt;a href=&#34;https://github.com/lichess-org/lila/raw/master/COPYING.md&#34;&gt;copying&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://lichess.org/thanks&#34;&gt;lichess.org/thanks&lt;/a&gt; and the contributors here:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lichess-org/lila/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=lichess-org/lila&#34; alt=&#34;GitHub contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Competence development program&lt;/h2&gt; &#xA;&lt;p&gt;Lichess would like to support its contributors in their competence development by covering costs of relevant training materials and activities. This is a small way to further empower contributors who have given their time to Lichess and to enable or improve additional contributions to Lichess in the future. For more information, including how to apply, check &lt;a href=&#34;https://lichess.org/page/competence-development&#34;&gt;Competence Development for Lichess contributors&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>firesim/firesim</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/firesim/firesim</id>
    <link href="https://github.com/firesim/firesim" rel="alternate"></link>
    <summary type="html">&lt;p&gt;FireSim: Easy-to-use, Scalable, FPGA-accelerated Cycle-accurate Hardware Simulation in the Cloud&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FireSim: Easy-to-use, Scalable, FPGA-accelerated Cycle-accurate Hardware Simulation&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://readthedocs.org/projects/firesim/badge/&#34; alt=&#34;FireSim Documentation Status&#34;&gt; &lt;img src=&#34;https://github.com/firesim/firesim/actions/workflows/firesim-run-tests.yml/badge.svg?sanitize=true&#34; alt=&#34;Github Actions Status&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firesim/firesim/main/#using-firesim&#34;&gt;Using FireSim&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firesim/firesim/main/#what-is-firesim&#34;&gt;What is FireSim?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firesim/firesim/main/#what-can-i-simulate-with-firesim&#34;&gt;What can I simulate with FireSim?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firesim/firesim/main/#need-help&#34;&gt;Need help?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firesim/firesim/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firesim/firesim/main/#publications&#34;&gt;Publications&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Using FireSim&lt;/h2&gt; &#xA;&lt;p&gt;To get started with using FireSim, see the tutorials on the FireSim documentation site: &lt;a href=&#34;https://docs.fires.im/&#34;&gt;https://docs.fires.im/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Another good overview (in video format) is our tutorial from the Chisel Community Conference on &lt;a href=&#34;https://www.youtube.com/watch?v=S3OriQnJXYQ&#34;&gt;YouTube&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;What is FireSim?&lt;/h2&gt; &#xA;&lt;p&gt;FireSim is an &lt;a href=&#34;https://github.com/firesim/firesim&#34;&gt;open-source&lt;/a&gt; cycle-accurate FPGA-accelerated full-system hardware simulation platform that runs on cloud FPGAs (Amazon EC2 F1). FireSim is actively developed in the &lt;a href=&#34;http://bar.eecs.berkeley.edu&#34;&gt;Berkeley Architecture Research Group&lt;/a&gt; in the &lt;a href=&#34;https://eecs.berkeley.edu&#34;&gt;Electrical Engineering and Computer Sciences Department&lt;/a&gt; at the &lt;a href=&#34;https://berkeley.edu&#34;&gt;University of California, Berkeley&lt;/a&gt;. You can learn more about FireSim in the following places:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;FireSim website&lt;/strong&gt;: &lt;a href=&#34;https://fires.im&#34;&gt;https://fires.im&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;FireSim ISCA 2018 Paper&lt;/strong&gt;: &lt;a href=&#34;https://sagark.org/assets/pubs/firesim-isca2018.pdf&#34;&gt;Paper PDF&lt;/a&gt; | &lt;a href=&#34;https://ieeexplore.ieee.org/document/8416816&#34;&gt;IEEE Xplore&lt;/a&gt; | &lt;a href=&#34;https://dl.acm.org/citation.cfm?id=3276543&#34;&gt;ACM DL&lt;/a&gt; | &lt;a href=&#34;https://sagark.org/assets/pubs/firesim-isca2018.bib.txt&#34;&gt;BibTeX&lt;/a&gt; | Selected as one of IEEE Micro’s “Top Picks from Computer Architecture Conferences, 2018”.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;FireSim documentation&lt;/strong&gt;: &lt;a href=&#34;https://docs.fires.im&#34;&gt;https://docs.fires.im&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Scala API Documentation&lt;/strong&gt;: &lt;a href=&#34;https://fires.im/firesim/latest/api/&#34;&gt;https://fires.im/firesim/latest/api/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Two-minute lightning talk from ISCA 2018&lt;/strong&gt; (FireSim simulating a datacenter): &lt;a href=&#34;https://www.youtube.com/watch?v=4XwoSe5c8lY&#34;&gt;YouTube&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chisel Community Conference Tutorial&lt;/strong&gt;: &lt;a href=&#34;https://www.youtube.com/watch?v=S3OriQnJXYQ&#34;&gt;YouTube&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Updates/News&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/firesim/firesim/main/CHANGELOG.md&#34;&gt;Changelog&lt;/a&gt; | &lt;a href=&#34;https://fires.im/blog/&#34;&gt;FireSim Blog&lt;/a&gt; | &lt;a href=&#34;https://twitter.com/firesimproject&#34;&gt;Twitter&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What can I simulate with FireSim?&lt;/h2&gt; &#xA;&lt;p&gt;FireSim can simulate arbitrary hardware designs written in &lt;a href=&#34;https://chisel.eecs.berkeley.edu&#34;&gt;Chisel&lt;/a&gt;. With FireSim, you can write your own RTL (processors, accelerators, etc.) and run it at near-FPGA-prototype speeds on cloud FPGAs, while obtaining cycle-accurate performance results (i.e. matching what you would find if you taped-out a chip). Depending on the hardware design and the simulation scale, FireSim simulations run at &lt;strong&gt;10s to 100s of MHz&lt;/strong&gt;. You can also integrate custom software models for components that you don&#39;t want/need to write as RTL.&lt;/p&gt; &#xA;&lt;p&gt;FireSim was originally developed to simulate datacenters by combining open RTL for RISC-V processors with a custom cycle-accurate network simulation. By default, FireSim provides all the RTL and models necessary to &lt;strong&gt;cycle-exactly&lt;/strong&gt; simulate from &lt;strong&gt;one to thousands of multi-core compute nodes&lt;/strong&gt;, derived directly from &lt;strong&gt;silicon-proven&lt;/strong&gt; and &lt;strong&gt;open&lt;/strong&gt; target-RTL (&lt;a href=&#34;https://riscv.org/&#34;&gt;RISC-V&lt;/a&gt; &lt;a href=&#34;https://github.com/freechipsproject/rocket-chip&#34;&gt;Rocket Chip&lt;/a&gt; and &lt;a href=&#34;https://github.com/ucb-bar/riscv-boom&#34;&gt;BOOM&lt;/a&gt;), with an optional &lt;strong&gt;cycle-accurate network simulation&lt;/strong&gt; tying them together. FireSim also provides a &lt;a href=&#34;https://github.com/firesim/firesim-software&#34;&gt;Linux distribution&lt;/a&gt; that is compatible with the RISC-V systems it simulates and &lt;a href=&#34;https://docs.fires.im/en/latest/Advanced-Usage/Workloads/Defining-Custom-Workloads.html&#34;&gt;automates&lt;/a&gt; the process of including new workloads into this Linux distribution. These simulations run fast enough to interact with Linux on the simulated system at the command line, &lt;a href=&#34;https://twitter.com/firesimproject/status/1031267637303508993&#34;&gt;like a real computer&lt;/a&gt;. Users can even &lt;a href=&#34;http://docs.fires.im/en/latest/Advanced-Usage/Miscellaneous-Tips.html#experimental-support-for-sshing-into-simulated-nodes-and-accessing-the-internet-from-within-simulations&#34;&gt;SSH into simulated systems in FireSim&lt;/a&gt; and access the Internet from within them.&lt;/p&gt; &#xA;&lt;p&gt;Head to the &lt;a href=&#34;https://fires.im&#34;&gt;FireSim Website&lt;/a&gt; to learn more.&lt;/p&gt; &#xA;&lt;h2&gt;Need help?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Join the FireSim Mailing list: &lt;a href=&#34;https://groups.google.com/forum/#!forum/firesim&#34;&gt;https://groups.google.com/forum/#!forum/firesim&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Post an issue on this repo&lt;/li&gt; &#xA; &lt;li&gt;Follow on Twitter for project updates: &lt;a href=&#34;https://twitter.com/firesimproject&#34;&gt;@firesimproject&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/firesim/firesim/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Publications&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;strong&gt;ISCA 2018&lt;/strong&gt;: FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud&lt;/h3&gt; &#xA;&lt;p&gt;You can learn more about FireSim in our ISCA 2018 paper, which covers the overall FireSim infrastructure and large distributed simulations of networked clusters. This paper was &lt;strong&gt;selected as one of IEEE Micro’s “Top Picks from Computer Architecture Conferences, 2018”.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Sagar Karandikar, Howard Mao, Donggyu Kim, David Biancolin, Alon Amid, Dayeol Lee, Nathan Pemberton, Emmanuel Amaro, Colin Schmidt, Aditya Chopra, Qijing Huang, Kyle Kovacs, Borivoje Nikolic, Randy Katz, Jonathan Bachrach, and Krste Asanović. &lt;strong&gt;FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud&lt;/strong&gt;. &lt;em&gt;In proceedings of the 45th International Symposium on Computer Architecture (ISCA’18)&lt;/em&gt;, Los Angeles, CA, June 2018.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sagark.org/assets/pubs/firesim-isca2018.pdf&#34;&gt;Paper PDF&lt;/a&gt; | &lt;a href=&#34;https://ieeexplore.ieee.org/document/8416816&#34;&gt;IEEE Xplore&lt;/a&gt; | &lt;a href=&#34;https://dl.acm.org/citation.cfm?id=3276543&#34;&gt;ACM DL&lt;/a&gt; | &lt;a href=&#34;https://sagark.org/assets/pubs/firesim-isca2018.bib.txt&#34;&gt;BibTeX&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;FPGA 2019&lt;/strong&gt;: FASED: FPGA-Accelerated Simulation and Evaluation of DRAM&lt;/h3&gt; &#xA;&lt;p&gt;Our paper from FPGA 2019 details the DRAM model used in FireSim:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;David Biancolin, Sagar Karandikar, Donggyu Kim, Jack Koenig, Andrew Waterman, Jonathan Bachrach, Krste Asanović, &lt;strong&gt;FASED: FPGA-Accelerated Simulation and Evaluation of DRAM&lt;/strong&gt;, &lt;em&gt;In proceedings of the 27th ACM/SIGDA International Symposium on Field-Programmable Gate Arrays&lt;/em&gt;, Seaside, CA, February 2018.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~biancolin/papers/fased-fpga19.pdf&#34;&gt;Paper PDF&lt;/a&gt; | &lt;a href=&#34;https://dl.acm.org/citation.cfm?id=3293894&#34;&gt;ACM DL&lt;/a&gt; | &lt;a href=&#34;https://people.eecs.berkeley.edu/~biancolin/bib/fased-fpga19.bib&#34;&gt;BibTeX&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;IEEE Micro Top Picks of 2018&lt;/strong&gt;: FireSim: FPGA-Accelerated, Cycle-Accurate Scale-Out System Simulation in the Public Cloud&lt;/h3&gt; &#xA;&lt;p&gt;This article discusses several updates since the FireSim ISCA 2018 paper:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Sagar Karandikar, Howard Mao, Donggyu Kim, David Biancolin, Alon Amid, Dayeol Lee, Nathan Pemberton, Emmanuel Amaro, Colin Schmidt, Aditya Chopra, Qijing Huang, Kyle Kovacs, Borivoje Nikolic, Randy Katz, Jonathan Bachrach, and Krste Asanović. &lt;strong&gt;FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud&lt;/strong&gt;. &lt;em&gt;IEEE Micro, vol. 39, no. 3, pp. 56-65, (Micro Top Picks 2018 Issue)&lt;/em&gt;. May-June 2019.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sagark.org/assets/pubs/firesim-micro-top-picks2018.pdf&#34;&gt;Article PDF&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;ICCAD 2019&lt;/strong&gt;: Golden Gate: Bridging The Resource-Efficiency Gap Between ASICs and FPGA Prototypes&lt;/h3&gt; &#xA;&lt;p&gt;Our paper describing FireSim&#39;s Compiler, &lt;em&gt;Golden Gate&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Albert Magyar, David T. Biancolin, Jack Koenig, Sanjit Seshia, Jonathan Bachrach, Krste Asanović, &lt;strong&gt;Golden Gate: Bridging The Resource-Efficiency Gap Between ASICs and FPGA Prototypes&lt;/strong&gt;, &lt;em&gt;In proceedings of the 39th International Conference on Computer-Aided Design (ICCAD &#39;19)&lt;/em&gt;, Westminster, CO, November 2019.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://davidbiancolin.github.io/papers/goldengate-iccad19.pdf&#34;&gt;Paper PDF&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;ASPLOS 2020&lt;/strong&gt;: FirePerf: FPGA-Accelerated Full-System Hardware/Software Performance Profiling and Co-Design&lt;/h3&gt; &#xA;&lt;p&gt;Our paper to appear in ASPLOS 2020 discusses system-level profiling features in FireSim:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Sagar Karandikar, Albert Ou, Alon Amid, Howard Mao, Randy Katz, Borivoje Nikolić, and Krste Asanović, &lt;strong&gt;FirePerf: FPGA-Accelerated Full-System Hardware/Software Performance Profiling and Co-Design&lt;/strong&gt;, &lt;em&gt;In Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2020)&lt;/em&gt;, Lausanne, Switzerland, March 2020.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sagark.org/assets/pubs/fireperf-asplos2020.pdf&#34;&gt;Paper PDF&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;IEEE MICRO 2021&lt;/strong&gt;: Accessible, FPGA Resource-Optimized Simulation of Multi-Clock Systems in FireSim&lt;/h3&gt; &#xA;&lt;p&gt;In this special issue, we describe the automated instance-multithreading optimization and support for multiple clock domains in the simulated target.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;David Biancolin, Albert Magyar, Sagar Karandikar, Alon Amid, Borivoje Nikolić, Jonathan Bachrach, Krste Asanović. &lt;strong&gt;Accessible, FPGA Resource-Optimized Simulation of Multi-Clock Systems in FireSim&lt;/strong&gt;. &lt;em&gt;In IEEE Micro Volume: 41, Issue: 4, July-Aug. 1 2021&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://davidbiancolin.github.io/papers/firesim-micro21.pdf&#34;&gt;Article PDF&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can find other publications, including publications that &lt;em&gt;use&lt;/em&gt; FireSim on the &lt;a href=&#34;https://fires.im/publications/&#34;&gt;FireSim Website&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>playframework/playframework</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/playframework/playframework</id>
    <link href="https://github.com/playframework/playframework" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Play Framework&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Play Framework - The High Velocity Web Framework&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/playframework?label=follow&amp;amp;style=flat&amp;amp;logo=twitter&amp;amp;color=brightgreen&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/g5s2vtZ4Fa&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/931647755942776882?logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/playframework/playframework/discussions&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/discussions/playframework/playframework?&amp;amp;logo=github&amp;amp;color=brightgreen&#34; alt=&#34;GitHub Discussions&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://stackoverflow.com/tags/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=stackoverflow&amp;amp;logo=stackoverflow&amp;amp;logoColor=fe7a16&amp;amp;color=brightgreen&amp;amp;message=playframework&#34; alt=&#34;StackOverflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCRp6QDm5SDjbIuisUpxV9cg&#34;&gt;&lt;img src=&#34;https://img.shields.io/youtube/channel/views/UCRp6QDm5SDjbIuisUpxV9cg?label=watch&amp;amp;logo=youtube&amp;amp;style=flat&amp;amp;color=brightgreen&amp;amp;logoColor=ff0000&#34; alt=&#34;YouTube&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.twitch.tv/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitch/status/playframework?logo=twitch&amp;amp;logoColor=white&amp;amp;color=brightgreen&amp;amp;label=live%20stream&#34; alt=&#34;Twitch Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/opencollective/all/playframework?label=financial%20contributors&amp;amp;logo=open-collective&#34; alt=&#34;OpenCollective&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/playframework/playframework/actions/workflows/build-test.yml&#34;&gt;&lt;img src=&#34;https://github.com/playframework/playframework/actions/workflows/build-test.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mvnrepository.com/artifact/com.typesafe.play/play_2.13&#34;&gt;&lt;img src=&#34;https://img.shields.io/maven-central/v/com.typesafe.play/play_2.13.svg?logo=apache-maven&#34; alt=&#34;Maven&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/playframework/playframework&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/repo-size/playframework/playframework.svg?logo=git&#34; alt=&#34;Repository size&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://scala-steward.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Scala_Steward-helping-blue.svg?style=flat&amp;amp;logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAQCAMAAAARSr4IAAAAVFBMVEUAAACHjojlOy5NWlrKzcYRKjGFjIbp293YycuLa3pYY2LSqql4f3pCUFTgSjNodYRmcXUsPD/NTTbjRS+2jomhgnzNc223cGvZS0HaSD0XLjbaSjElhIr+AAAAAXRSTlMAQObYZgAAAHlJREFUCNdNyosOwyAIhWHAQS1Vt7a77/3fcxxdmv0xwmckutAR1nkm4ggbyEcg/wWmlGLDAA3oL50xi6fk5ffZ3E2E3QfZDCcCN2YtbEWZt+Drc6u6rlqv7Uk0LdKqqr5rk2UCRXOk0vmQKGfc94nOJyQjouF9H/wCc9gECEYfONoAAAAASUVORK5CYII=&#34; alt=&#34;Scala Steward badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mergify.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://api.mergify.com/v1/badges/playframework/playframework&amp;amp;style=flat&#34; alt=&#34;Mergify Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Play Framework combines productivity and performance making it easy to build scalable web applications with Java and Scala. Play is developer friendly with a &#34;just hit refresh&#34; workflow and built-in testing support. With Play, applications scale predictably due to a stateless and non-blocking architecture. By being RESTful by default, including assets compilers, JSON &amp;amp; WebSocket support, Play is a perfect fit for modern web &amp;amp; mobile applications.&lt;/p&gt; &#xA;&lt;h2&gt;Learn More&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com&#34;&gt;www.playframework.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/download&#34;&gt;Download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/Installing&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/NewApplication&#34;&gt;Create a new application&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/ScalaHome&#34;&gt;Play for Scala developers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/JavaHome&#34;&gt;Play for Java developers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/documentation/latest/BuildingFromSource&#34;&gt;Build from source&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/playframework/playframework/issues&#34;&gt;Search or create issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/tagged/playframework&#34;&gt;Get help&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.playframework.com/contributing&#34;&gt;Contribute&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Sponsors &amp;amp; Backers&lt;/h2&gt; &#xA;&lt;p&gt;If you find Play useful for work, please consider asking your company to support this Open Source project by &lt;a href=&#34;https://www.playframework.com/sponsors&#34;&gt;becoming a sponsor&lt;/a&gt;.&lt;br&gt; You can also individually sponsor the project by &lt;a href=&#34;https://www.playframework.com/sponsors&#34;&gt;becoming a backer&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://opencollective.com/playframework&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://opencollective.com/playframework/donate/button@2x.png?color=blue&#34; width=&#34;250&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Thank you to our premium sponsors!&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://informaticon.com/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/61220b8306493af6a21b7db17de7f4b2-informaticon-logo-full-color.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://cedarlakeventures.com/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/bec2b526c9ce52c051f9089a10044867-cedar-lake-ventures.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://iterable.com/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/61ddb4c3665b621e6672181f97196748-iterable.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://pronto.net/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/c77b1d664f10a1c9cb19b97c6d8bd204-pronto-software.png&#34; width=&#34;250&#34;&gt; &lt;/a&gt;&#xA; &lt;a href=&#34;https://civiform.us/&#34;&gt;&lt;img src=&#34;https://www.playframework.com/assets/images/home/sponsors/cb047b3782866c962c4d6a35b056b809-civiform.png&#34; width=&#34;250&#34;&gt; &lt;/a&gt;&#xA;&lt;/div&gt;&#xA;&lt;a href=&#34;https://civiform.us/&#34;&gt; &lt;h3&gt;Thank you to all our backers!&lt;/h3&gt; &lt;/a&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://civiform.us/&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://opencollective.com/playframework#section-contributors&#34;&gt;&lt;img src=&#34;https://opencollective.com/playframework/organizations.svg?width=890&amp;amp;button=false&amp;amp;avatarHeight=46&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opencollective.com/playframework#section-contributors&#34;&gt;&lt;img src=&#34;https://opencollective.com/playframework/individuals.svg?width=890&amp;amp;button=false&amp;amp;avatarHeight=46&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (C) Lightbend Inc. (&lt;a href=&#34;https://www.lightbend.com&#34;&gt;https://www.lightbend.com&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this project except in compliance with the License. You may obtain a copy of the License at &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>snowplow/snowplow</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/snowplow/snowplow</id>
    <link href="https://github.com/snowplow/snowplow" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The enterprise-grade behavioral data engine (web, mobile, server-side, webhooks), running cloud-natively on AWS and GCP&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Snowplow&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/releases/tag/22.01&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Snowplow-22.01%20Western%20Ghats-6638b8&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache--2-blue.svg?style=flat&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://discourse.snowplowanalytics.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/discourse/posts?server=https%3A%2F%2Fdiscourse.snowplowanalytics.com%2F&#34; alt=&#34;Discourse posts&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://snowplowanalytics.com&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/snowplow/snowplow/master/media/snowplow_logo.png&#34; alt=&#34;Snowplow logo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Snowplow is an enterprise-strength marketing and product analytics platform. It does three things:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Identifies your users, and tracks the way they engage with your website or application&lt;/li&gt; &#xA; &lt;li&gt;Stores your users&#39; behavioral data in a scalable &#34;event data warehouse&#34; you control: Amazon Redshift, Google BigQuery, Snowflake or Elasticsearch&lt;/li&gt; &#xA; &lt;li&gt;Lets you leverage the biggest range of tools to analyze that data, including big data tools (e.g. Spark) via EMR or more traditional tools e.g. Looker, Mode, Superset, Re:dash to analyze that behavioral data&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;To find out more, please check out the &lt;a href=&#34;https://snowplowanalytics.com&#34;&gt;Snowplow website&lt;/a&gt; and the &lt;a href=&#34;https://docs.snowplowanalytics.com/open-source-docs/&#34;&gt;docs website&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Version Compatibility Matrix&lt;/h3&gt; &#xA;&lt;p&gt;For compatibility assurance, the version compatibility matrix offers clarity on our recommended stack. It is strongly recommended when setting up a Snowplow pipeline to use the versions listed in the version compatibility matrix which can be found &lt;a href=&#34;https://docs.snowplowanalytics.com/docs/pipeline-components-and-applications/version-compatibility-matrix/&#34;&gt;within our docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Public Roadmap&lt;/h3&gt; &#xA;&lt;p&gt;This repository also contains the &lt;a href=&#34;https://github.com/snowplow/snowplow/projects&#34;&gt;Snowplow Public Roadmap&lt;/a&gt;. The Public Roadmap lets you stay up to date and find out what&#39;s happening on the Snowplow Platform. Help us prioritize our cards: open the issue and leave a 👍 to vote for your favorites. Want us to build a feature or function? Tell us by heading to our &lt;a href=&#34;http://discourse.snowplowanalytics.com/&#34;&gt;Discourse forum&lt;/a&gt; 💬.&lt;/p&gt; &#xA;&lt;h3&gt;Try Snowplow&lt;/h3&gt; &#xA;&lt;p&gt;Setting up a full open-source Snowplow pipeline requires a non-trivial amount of engineering expertise and time investment. You might be interested in finding out what Snowplow can do first, by setting up &lt;a href=&#34;https://try.snowplowanalytics.com/?utm_source=github&amp;amp;utm_medium=post&amp;amp;utm_campaign=try-snowplow&#34;&gt;Try Snowplow&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Open Source Quick Start&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://docs.snowplowanalytics.com/docs/open-source-quick-start/&#34;&gt;Open Source Quick Start&lt;/a&gt; will help you get up and running with a Snowplow open source pipeline. Snowplow publishes a &lt;a href=&#34;https://registry.terraform.io/modules/snowplow-devops&#34;&gt;set of terraform modules&lt;/a&gt;, which automate the setting up &amp;amp; deployment of the required infrastructure &amp;amp; applications for an operational Snowplow open source pipeline, with just a handful of input variables required on your side.&lt;/p&gt; &#xA;&lt;h3&gt;Join the Snowplow Research Panel and help shape the future of open source&lt;/h3&gt; &#xA;&lt;p&gt;As part of our ongoing efforts to improve the Snowplow Open Source experience, we&#39;re looking for users of our open-source software and members of our community to take part in research studies. &lt;a href=&#34;https://forms.gle/pCtYx8naum7A8vvw5&#34;&gt;Join here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Our Commercial Offering&lt;/h3&gt; &#xA;&lt;p&gt;If you wish to get everything setup and managed for you, you can consider &lt;a href=&#34;https://snowplowanalytics.com/products/snowplow-bdp/&#34;&gt;Snowplow BDP&lt;/a&gt;. You can also &lt;a href=&#34;https://go.snowplowanalytics.com/l/571483/2021-05-04/3sv1pg8&#34;&gt;request a demo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Snowplow technology 101&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/snowplow/snowplow/master/ARCHITECTURE.md&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/snowplow/snowplow/master/media/snowplow_architecture.png&#34; alt=&#34;Snowplow architecture&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The repository structure follows the conceptual architecture of Snowplow, which consists of six loosely-coupled sub-systems connected by five standardized data protocols/formats.&lt;/p&gt; &#xA;&lt;p&gt;To briefly explain these six sub-systems:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/1-trackers&#34;&gt;Trackers&lt;/a&gt;&lt;/strong&gt; fire Snowplow events. Currently we have 15 trackers, covering web, mobile, desktop, server and IoT&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/2-collectors&#34;&gt;Collector&lt;/a&gt;&lt;/strong&gt; receives Snowplow events from trackers. Currently we have one official collector implementation with different sinks: Amazon Kinesis, Google PubSub, Amazon SQS, Apache Kafka and NSQ&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/3-enrich&#34;&gt;Enrich&lt;/a&gt;&lt;/strong&gt; cleans up the raw Snowplow events, enriches them and puts them into storage. Currently we have several implementations, built for different environments (GCP, AWS, Apache Kafka) and one core library&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/4-storage&#34;&gt;Storage&lt;/a&gt;&lt;/strong&gt; is where the Snowplow events live. Currently we store the Snowplow events in a flat file structure on S3, and in the Redshift, Postgres, Snowflake and BigQuery databases&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow/tree/master/5-data-modeling&#34;&gt;Data modeling&lt;/a&gt;&lt;/strong&gt; is where event-level data is joined with other data sets and aggregated into smaller data sets, and business logic is applied. This produces a clean set of tables which make it easier to perform analysis on the data. We officially support data models for Redshift, Snowflake and BigQuery.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.snowplowanalytics.com/docs/modeling-your-data/analytics-sdk/&#34;&gt;Analytics&lt;/a&gt;&lt;/strong&gt; are performed on the Snowplow events or on the aggregate tables.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;For more information on the current Snowplow architecture, please see the &lt;a href=&#34;https://raw.githubusercontent.com/snowplow/snowplow/master/ARCHITECTURE.md&#34;&gt;Technical architecture&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;About this repository&lt;/h2&gt; &#xA;&lt;p&gt;This repository is an umbrella repository for all loosely-coupled Snowplow components and is updated on each component release.&lt;/p&gt; &#xA;&lt;p&gt;Since June 2020, all components have been extracted into their dedicated repositories (more info &lt;a href=&#34;https://snowplowanalytics.com/blog/2020/07/16/changing-releasing/&#34;&gt;here&lt;/a&gt;) and this repository serves as an entry point for Snowplow users, the home of our public roadmap and as a historical artifact.&lt;/p&gt; &#xA;&lt;p&gt;Components that have been extracted to their own repository are still here as &lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Tools-Submodules&#34;&gt;git submodules&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Trackers&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Web&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Mobile&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Gaming&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;TV&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Desktop &amp;amp; Server&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-javascript-tracker&#34;&gt;JavaScript&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-android-tracker&#34;&gt;Android&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-unity-tracker&#34;&gt;Unity&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-roku-tracker&#34;&gt;Roku&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-tracking-cli&#34;&gt;Command line&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://docs.snowplowanalytics.com/docs/collecting-data/collecting-from-own-applications/google-amp-tracker/&#34;&gt;AMP&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-objc-tracker&#34;&gt;iOS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-dotnet-tracker&#34;&gt;.NET&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-react-native-tracker&#34;&gt;React Native&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-golang-tracker&#34;&gt;Go&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-flutter-tracker&#34;&gt;Flutter&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-java-tracker&#34;&gt;Java&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-javascript-tracker&#34;&gt;Node.js&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-php-tracker&#34;&gt;PHP&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-python-tracker&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-ruby-tracker&#34;&gt;Ruby&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-scala-tracker&#34;&gt;Scala&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/snowplow/stream-collector&#34;&gt;Collector&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/snowplow/enrich&#34;&gt;Enrich&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;Loaders&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-bigquery-loader&#34;&gt;BigQuery (streaming)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-rdb-loader&#34;&gt;Redshift (batch)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-snowflake-loader&#34;&gt;Snowflake (batch)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-google-cloud-storage-loader&#34;&gt;Google Cloud Storage (streaming)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-s3-loader&#34;&gt;Amazon S3 (streaming)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-postgres-loader&#34;&gt;Postgres (streaming)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-elasticsearch-loader&#34;&gt;Elasticsearch (streaming)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Iglu&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/iglu-server/&#34;&gt;Iglu Server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/igluctl/&#34;&gt;igluctl&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/iglu-central/&#34;&gt;Iglu Central&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Data modeling&lt;/h3&gt; &#xA;&lt;h4&gt;Web&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/data-models/tree/master/web/v1&#34;&gt;Web model: SQL-Runner version&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/dbt-snowplow-web&#34;&gt;Web model: dbt version&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Mobile&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/data-models/tree/master/mobile/v1&#34;&gt;Mobile model: SQL-Runner version&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Testing&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-mini&#34;&gt;Mini&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-micro&#34;&gt;Micro&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Parsing enriched event&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-scala-analytics-sdk&#34;&gt;Analytics SDK Scala&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-python-analytics-sdk&#34;&gt;Analytics SDK Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-dotnet-analytics-sdk&#34;&gt;Analytics SDK .NET&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-js-analytics-sdk/&#34;&gt;Analytics SDK Javascript&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snowplow/snowplow-golang-analytics-sdk&#34;&gt;Analytics SDK Golang&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/snowplow-incubator/snowplow-badrows&#34;&gt;Bad rows&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://registry.terraform.io/modules/snowplow-devops&#34;&gt;Terraform Modules&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;Need help?&lt;/h2&gt; &#xA;&lt;p&gt;We want to make it super-easy for Snowplow users and contributors to talk to us and connect with each other, to share ideas, solve problems and help make Snowplow awesome. Here are the main channels we&#39;re running currently, we&#39;d love to hear from you on one of them:&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://discourse.snowplowanalytics.com/&#34;&gt;Discourse&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;This is for all Snowplow users: engineers setting up Snowplow, data modelers structuring the data and data consumers building insights. You can find guides, recipes, questions and answers from Snowplow users including the Snowplow team.&lt;/p&gt; &#xA;&lt;p&gt;We welcome all questions and contributions!&lt;/p&gt; &#xA;&lt;h3&gt;Twitter&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/SnowplowData&#34;&gt;@SnowplowData&lt;/a&gt; for official news or &lt;a href=&#34;https://twitter.com/SnowplowLabs&#34;&gt;@SnowplowLabs&lt;/a&gt; for engineering-heavy conversations and release updates.&lt;/p&gt; &#xA;&lt;h3&gt;GitHub&lt;/h3&gt; &#xA;&lt;p&gt;If you spot a bug, then please raise an issue in the GitHub repository of the component in question. Likewise if you have developed a cool new feature or an improvement, please open a pull request, we&#39;ll be glad to integrate it in the codebase!&lt;/p&gt; &#xA;&lt;p&gt;If you want to brainstorm a potential new feature, then &lt;a href=&#34;http://discourse.snowplowanalytics.com/&#34;&gt;Discourse&lt;/a&gt; is the best place to start.&lt;/p&gt; &#xA;&lt;h3&gt;Email&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;mailto:community@snowplowanalytics.com&#34;&gt;community@snowplowanalytics.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to talk directly to us (e.g. about a commercially sensitive issue), email is the easiest way.&lt;/p&gt; &#xA;&lt;h2&gt;Copyright and license&lt;/h2&gt; &#xA;&lt;p&gt;Snowplow is copyright 2012-2022 Snowplow Analytics Ltd.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the &lt;strong&gt;&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License, Version 2.0&lt;/a&gt;&lt;/strong&gt; (the &#34;License&#34;); you may not use this software except in compliance with the License.&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>yahoo/CMAK</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/yahoo/CMAK</id>
    <link href="https://github.com/yahoo/CMAK" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CMAK is a tool for managing Apache Kafka clusters&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CMAK (Cluster Manager for Apache Kafka, previously known as Kafka Manager)&lt;/h1&gt; &#xA;&lt;p&gt;CMAK (previously known as Kafka Manager) is a tool for managing &lt;a href=&#34;http://kafka.apache.org&#34;&gt;Apache Kafka&lt;/a&gt; clusters. &lt;em&gt;See below for details about the name change.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;CMAK supports the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Manage multiple clusters&lt;/li&gt; &#xA; &lt;li&gt;Easy inspection of cluster state (topics, consumers, offsets, brokers, replica distribution, partition distribution)&lt;/li&gt; &#xA; &lt;li&gt;Run preferred replica election&lt;/li&gt; &#xA; &lt;li&gt;Generate partition assignments with option to select brokers to use&lt;/li&gt; &#xA; &lt;li&gt;Run reassignment of partition (based on generated assignments)&lt;/li&gt; &#xA; &lt;li&gt;Create a topic with optional topic configs (0.8.1.1 has different configs than 0.8.2+)&lt;/li&gt; &#xA; &lt;li&gt;Delete topic (only supported on 0.8.2+ and remember set delete.topic.enable=true in broker config)&lt;/li&gt; &#xA; &lt;li&gt;Topic list now indicates topics marked for deletion (only supported on 0.8.2+)&lt;/li&gt; &#xA; &lt;li&gt;Batch generate partition assignments for multiple topics with option to select brokers to use&lt;/li&gt; &#xA; &lt;li&gt;Batch run reassignment of partition for multiple topics&lt;/li&gt; &#xA; &lt;li&gt;Add partitions to existing topic&lt;/li&gt; &#xA; &lt;li&gt;Update config for existing topic&lt;/li&gt; &#xA; &lt;li&gt;Optionally enable JMX polling for broker level and topic level metrics.&lt;/li&gt; &#xA; &lt;li&gt;Optionally filter out consumers that do not have ids/ owners/ &amp;amp; offsets/ directories in zookeeper.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Cluster Management&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yahoo/CMAK/master/img/cluster.png&#34; alt=&#34;cluster&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Topic List&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yahoo/CMAK/master/img/topic-list.png&#34; alt=&#34;topic&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Topic View&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yahoo/CMAK/master/img/topic.png&#34; alt=&#34;topic&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Consumer List View&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yahoo/CMAK/master/img/consumer-list.png&#34; alt=&#34;consumer&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Consumed Topic View&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yahoo/CMAK/master/img/consumed-topic.png&#34; alt=&#34;consumer&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Broker List&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yahoo/CMAK/master/img/broker-list.png&#34; alt=&#34;broker&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Broker View&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yahoo/CMAK/master/img/broker.png&#34; alt=&#34;broker&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://kafka.apache.org/downloads.html&#34;&gt;Kafka 0.8.&lt;em&gt;.&lt;/em&gt; or 0.9.&lt;em&gt;.&lt;/em&gt; or 0.10.&lt;em&gt;.&lt;/em&gt; or 0.11.&lt;em&gt;.&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Java 11+&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;The minimum configuration is the zookeeper hosts which are to be used for CMAK (pka kafka manager) state. This can be found in the application.conf file in conf directory. The same file will be packaged in the distribution zip file; you may modify settings after unzipping the file on the desired server.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmak.zkhosts=&#34;my.zookeeper.host.com:2181&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can specify multiple zookeeper hosts by comma delimiting them, like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmak.zkhosts=&#34;my.zookeeper.host.com:2181,other.zookeeper.host.com:2181&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, use the environment variable &lt;code&gt;ZK_HOSTS&lt;/code&gt; if you don&#39;t want to hardcode any values.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ZK_HOSTS=&#34;my.zookeeper.host.com:2181&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can optionally enable/disable the following functionality by modifying the default list in application.conf :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;application.features=[&#34;KMClusterManagerFeature&#34;,&#34;KMTopicManagerFeature&#34;,&#34;KMPreferredReplicaElectionFeature&#34;,&#34;KMReassignPartitionsFeature&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;KMClusterManagerFeature - allows adding, updating, deleting cluster from CMAK (pka Kafka Manager)&lt;/li&gt; &#xA; &lt;li&gt;KMTopicManagerFeature - allows adding, updating, deleting topic from a Kafka cluster&lt;/li&gt; &#xA; &lt;li&gt;KMPreferredReplicaElectionFeature - allows running of preferred replica election for a Kafka cluster&lt;/li&gt; &#xA; &lt;li&gt;KMReassignPartitionsFeature - allows generating partition assignments and reassigning partitions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Consider setting these parameters for larger clusters with jmx enabled :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;cmak.broker-view-thread-pool-size=&amp;lt; 3 * number_of_brokers&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;cmak.broker-view-max-queue-size=&amp;lt; 3 * total # of partitions across all topics&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;cmak.broker-view-update-seconds=&amp;lt; cmak.broker-view-max-queue-size / (10 * number_of_brokers) &amp;gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Here is an example for a kafka cluster with 10 brokers, 100 topics, with each topic having 10 partitions giving 1000 total partitions with JMX enabled :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;cmak.broker-view-thread-pool-size=30&lt;/li&gt; &#xA; &lt;li&gt;cmak.broker-view-max-queue-size=3000&lt;/li&gt; &#xA; &lt;li&gt;cmak.broker-view-update-seconds=30&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The follow control consumer offset cache&#39;s thread pool and queue :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;cmak.offset-cache-thread-pool-size=&amp;lt; default is # of processors&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;cmak.offset-cache-max-queue-size=&amp;lt; default is 1000&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;cmak.kafka-admin-client-thread-pool-size=&amp;lt; default is # of processors&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;cmak.kafka-admin-client-max-queue-size=&amp;lt; default is 1000&amp;gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You should increase the above for large # of consumers with consumer polling enabled. Though it mainly affects ZK based consumer polling.&lt;/p&gt; &#xA;&lt;p&gt;Kafka managed consumer offset is now consumed by KafkaManagedOffsetCache from the &#34;__consumer_offsets&#34; topic. Note, this has not been tested with large number of offsets being tracked. There is a single thread per cluster consuming this topic so it may not be able to keep up on large # of offsets being pushed to the topic.&lt;/p&gt; &#xA;&lt;h3&gt;Authenticating a User with LDAP&lt;/h3&gt; &#xA;&lt;p&gt;Warning, you need to have SSL configured with CMAK (pka Kafka Manager) to ensure your credentials aren&#39;t passed unencrypted. Authenticating a User with LDAP is possible by passing the user credentials with the Authorization header. LDAP authentication is done on first visit, if successful, a cookie is set. On next request, the cookie value is compared with credentials from Authorization header. LDAP support is through the basic authentication filter.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Configure basic authentication&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;basicAuthentication.enabled=true&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.realm=&amp;lt; basic authentication realm&amp;gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Encryption parameters (optional, otherwise randomly generated on startup) :&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;basicAuthentication.salt=&#34;some-hex-string-representing-byte-array&#34;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.iv=&#34;some-hex-string-representing-byte-array&#34;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.secret=&#34;my-secret-string&#34;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Configure LDAP/LDAPS authentication&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.enabled=&amp;lt; Boolean flag to enable/disable ldap authentication &amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.server=&amp;lt; fqdn of LDAP server&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.port=&amp;lt; port of LDAP server&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.username=&amp;lt; LDAP search username&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.password=&amp;lt; LDAP search password&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.search-base-dn=&amp;lt; LDAP search base&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.search-filter=&amp;lt; LDAP search filter&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.connection-pool-size=&amp;lt; number of connection to LDAP server&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.ssl=&amp;lt; Boolean flag to enable/disable LDAPS&amp;gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;(Optional) Limit access to a specific LDAP Group&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.group-filter=&amp;lt; LDAP group filter&amp;gt;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.ssl-trust-all=&amp;lt; Boolean flag to allow non-expired invalid certificates&amp;gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Example (Online LDAP Test Server):&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.enabled=true&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.server=&#34;ldap.forumsys.com&#34;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.port=389&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.username=&#34;cn=read-only-admin,dc=example,dc=com&#34;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.password=&#34;password&#34;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.search-base-dn=&#34;dc=example,dc=com&#34;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.search-filter=&#34;(uid=$capturedLogin$)&#34;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.group-filter=&#34;cn=allowed-group,ou=groups,dc=example,dc=com&#34;&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.connection-pool-size=10&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.ssl=false&lt;/li&gt; &#xA; &lt;li&gt;basicAuthentication.ldap.ssl-trust-all=false&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;p&gt;The command below will create a zip file which can be used to deploy the application.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./sbt clean dist&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please refer to play framework documentation on &lt;a href=&#34;https://www.playframework.com/documentation/2.4.x/ProductionConfiguration&#34;&gt;production deployment/configuration&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If java is not in your path, or you need to build against a specific java version, please use the following (the example assumes zulu java11):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ PATH=/usr/lib/jvm/zulu-11-amd64/bin:$PATH \&#xA;  JAVA_HOME=/usr/lib/jvm/zulu-11-amd64 \&#xA;  /path/to/sbt -java-home /usr/lib/jvm/zulu-11-amd64 clean dist&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This ensures that the &#39;java&#39; and &#39;javac&#39; binaries in your path are first looked up in the correct location. Next, for all downstream tools that only listen to JAVA_HOME, it points them to the java11 location. Lastly, it tells sbt to use the java11 location as well.&lt;/p&gt; &#xA;&lt;h2&gt;Starting the service&lt;/h2&gt; &#xA;&lt;p&gt;After extracting the produced zipfile, and changing the working directory to it, you can run the service like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bin/cmak&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, it will choose port 9000. This is overridable, as is the location of the configuration file. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bin/cmak -Dconfig.file=/path/to/application.conf -Dhttp.port=8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Again, if java is not in your path, or you need to run against a different version of java, add the -java-home option as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bin/cmak -java-home /usr/lib/jvm/zulu-11-amd64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Starting the service with Security&lt;/h2&gt; &#xA;&lt;p&gt;To add JAAS configuration for SASL, add the config file location at start:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bin/cmak -Djava.security.auth.login.config=/path/to/my-jaas.conf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;NOTE: Make sure the user running CMAK (pka kafka manager) has read permissions on the jaas config file&lt;/p&gt; &#xA;&lt;h2&gt;Packaging&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;d like to create a Debian or RPM package instead, you can run one of:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sbt debian:packageBin&#xA;&#xA;sbt rpm:packageBin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;Most of the utils code has been adapted to work with &lt;a href=&#34;http://curator.apache.org&#34;&gt;Apache Curator&lt;/a&gt; from &lt;a href=&#34;http://kafka.apache.org&#34;&gt;Apache Kafka&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Name and Management&lt;/h2&gt; &#xA;&lt;p&gt;CMAK was renamed from its previous name due to &lt;a href=&#34;https://github.com/yahoo/kafka-manager/issues/713&#34;&gt;this issue&lt;/a&gt;. CMAK is designed to be used with Apache Kafka and is offered to support the needs of the Kafka community. This project is currently managed by employees at Verizon Media and the community who supports this project.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Licensed under the terms of the Apache License 2.0. See accompanying LICENSE file for terms.&lt;/p&gt; &#xA;&lt;h2&gt;Consumer/Producer Lag&lt;/h2&gt; &#xA;&lt;p&gt;Producer offset is polled. Consumer offset is read from the offset topic for Kafka based consumers. This means the reported lag may be negative since we are consuming offset from the offset topic faster then polling the producer offset. This is normal and not a problem.&lt;/p&gt; &#xA;&lt;h2&gt;Migration from Kafka Manager to CMAK&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Copy config files from old version to new version (application.conf, consumer.properties)&lt;/li&gt; &#xA; &lt;li&gt;Change start script to use bin/cmak instead of bin/kafka-manager&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>spark-examples/spark-scala-examples</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/spark-examples/spark-scala-examples</id>
    <link href="https://github.com/spark-examples/spark-scala-examples" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This project provides Apache Spark SQL, RDD, DataFrame and Dataset examples in Scala language&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Explanation of all Spark SQL, RDD, DataFrame and Dataset examples present on this project are available at &lt;a href=&#34;https://sparkbyexamples.com/&#34;&gt;https://sparkbyexamples.com/&lt;/a&gt; , All these examples are coded in Scala language and tested in our development environment.&lt;/p&gt; &#xA;&lt;h1&gt;Table of Contents (Spark Examples in Scala)&lt;/h1&gt; &#xA;&lt;h2&gt;Spark RDD Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/how-to-create-an-rdd-using-parallelize/&#34;&gt;Create a Spark RDD using Parallelize&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/spark-read-multiple-text-files-into-a-single-rdd/&#34;&gt;Spark – Read multiple text files into single RDD?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/spark-load-csv-file-into-rdd/&#34;&gt;Spark load CSV file into RDD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/different-ways-to-create-spark-rdd/&#34;&gt;Different ways to create Spark RDD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/spark-how-to-create-an-empty-rdd/&#34;&gt;Spark – How to create an empty RDD?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/spark-rdd-transformations/&#34;&gt;Spark RDD Transformations with examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/spark-rdd-actions/&#34;&gt;Spark RDD Actions with examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/spark-pair-rdd-functions/&#34;&gt;Spark Pair RDD Functions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-repartition-vs-coalesce/&#34;&gt;Spark Repartition() vs Coalesce()&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-shuffle-partitions/&#34;&gt;Spark Shuffle Partitions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-persistence-storage-levels/&#34;&gt;Spark Persistence Storage Levels&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/spark-rdd-cache-and-persist-example/&#34;&gt;Spark RDD Cache and Persist with Example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-broadcast-variables/&#34;&gt;Spark Broadcast Variables&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-accumulators/&#34;&gt;Spark Accumulators Explained&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/apache-spark-rdd/convert-spark-rdd-to-dataframe-dataset/&#34;&gt;Convert Spark RDD to DataFrame | Dataset&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Spark SQL Tutorial&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/different-ways-to-create-a-spark-dataframe/&#34;&gt;Spark Create DataFrame with Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-dataframe-withcolumn/&#34;&gt;Spark DataFrame withColumn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/rename-a-column-on-spark-dataframes/&#34;&gt;Ways to Rename column on Spark DataFrame&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-drop-column-from-dataframe-dataset/&#34;&gt;Spark – How to Drop a DataFrame/Dataset column&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-dataframe-where-filter/&#34;&gt;Working with Spark DataFrame Where Filter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-case-when-otherwise-example/&#34;&gt;Spark SQL “case when” and “when otherwise”&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-dataframe-collect/&#34;&gt;Collect() – Retrieve data from Spark RDD/DataFrame&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-remove-duplicate-rows/&#34;&gt;Spark – How to remove duplicate rows&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/how-to-pivot-table-and-unpivot-a-spark-dataframe/&#34;&gt;How to Pivot and Unpivot a Spark DataFrame&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-dataframe-data-types/&#34;&gt;Spark SQL Data Types with Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-structtype-on-dataframe/&#34;&gt;Spark SQL StructType &amp;amp; StructField with examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-schema-explained-with-examples/&#34;&gt;Spark schema – explained with examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/using-groupby-on-dataframe/&#34;&gt;Spark Groupby Example with DataFrame&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-how-to-sort-dataframe-column-explained/&#34;&gt;Spark – How to Sort DataFrame column explained&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-dataframe-join/&#34;&gt;Spark SQL Join Types with examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-dataframe-union-and-union-all/&#34;&gt;Spark DataFrame Union and UnionAll&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-map-vs-mappartitions-transformation/&#34;&gt;Spark map vs mapPartitions transformation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-foreachpartition-vs-foreach-explained/&#34;&gt;Spark foreachPartition vs foreach | what to use?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-dataframe-cache-and-persist-explained/&#34;&gt;Spark DataFrame Cache and Persist Explained&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-udf/&#34;&gt;Spark SQL UDF (User Defined Functions)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-array-arraytype-dataframe-column/&#34;&gt;Spark SQL DataFrame Array (ArrayType) Column&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-dataframe-map-maptype-column/&#34;&gt;Working with Spark DataFrame Map (MapType) column&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-flatten-nested-struct-column/&#34;&gt;Spark SQL – Flatten Nested Struct column&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-flatten-nested-array-column-to-single-column/&#34;&gt;Spark – Flatten nested array to single array column&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/explode-spark-array-and-map-dataframe-column/&#34;&gt;Spark explode array and map columns to rows&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Spark SQL Functions&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/usage-of-spark-sql-string-functions/&#34;&gt;Spark SQL String Functions Explained&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-date-and-time-functions/&#34;&gt;Spark SQL Date and Time Functions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-array-functions/&#34;&gt;Spark SQL Array functions complete list&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-map-functions/&#34;&gt;Spark SQL Map functions – complete list&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-sort-functions/&#34;&gt;Spark SQL Sort functions – complete list&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-aggregate-functions/&#34;&gt;Spark SQL Aggregate Functions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-sql-window-functions/&#34;&gt;Spark Window Functions with Examples&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Spark Data Source API&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-read-csv-file-into-dataframe/&#34;&gt;Spark Read CSV file into DataFrame&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-read-and-write-json-file/&#34;&gt;Spark Read and Write JSON file into DataFrame&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-read-write-dataframe-parquet-example/&#34;&gt;Spark Read and Write Apache Parquet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-read-write-xml/&#34;&gt;Spark Read XML file using Databricks API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/read-write-avro-file-spark-dataframe/&#34;&gt;Read &amp;amp; Write Avro files using Spark DataFrame&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/using-avro-data-files-from-spark-sql-2-3-x/&#34;&gt;Using Avro Data Files From Spark SQL 2.3.x or earlier&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-read-write-using-hbase-spark-connector/&#34;&gt;Spark Read from &amp;amp; Write to HBase table | Example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/create-spark-dataframe-from-hbase-using-hortonworks/&#34;&gt;Create Spark DataFrame from HBase using Hortonworks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-read-orc-file-into-dataframe/&#34;&gt;Spark Read ORC file into DataFrame&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-read-binary-file-into-dataframe/&#34;&gt;Spark 3.0 Read Binary File into DataFrame&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Spark Streaming &amp;amp; Kafka&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-streaming-outputmode/&#34;&gt;Spark Streaming – Different Output modes explained&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-streaming-read-json-files-from-directory/&#34;&gt;Spark Streaming files from a directory&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-streaming-from-tcp-socket/&#34;&gt;Spark Streaming – Reading data from TCP Socket&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-streaming-with-kafka/&#34;&gt;Spark Streaming with Kafka Example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-streaming-consume-and-produce-kafka-messages-in-avro-format/&#34;&gt;Spark Streaming – Kafka messages in Avro format&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sparkbyexamples.com/spark/spark-batch-processing-produce-consume-kafka-topic/&#34;&gt;Spark SQL Batch Processing – Produce and Consume Apache Kafka Topic&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ucb-bar/plsi-mdf</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/ucb-bar/plsi-mdf</id>
    <link href="https://github.com/ucb-bar/plsi-mdf" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Macro description format&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MDF&lt;/h1&gt; &#xA;&lt;h2&gt;Scala library for the MDF format&lt;/h2&gt;</summary>
  </entry>
  <entry>
    <title>chipsalliance/rocket-chip</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/chipsalliance/rocket-chip</id>
    <link href="https://github.com/chipsalliance/rocket-chip" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Rocket Chip Generator&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Rocket Chip Generator &lt;span&gt;🚀&lt;/span&gt; &lt;img src=&#34;https://github.com/chipsalliance/rocket-chip/workflows/Continuous%20Integration/badge.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the Rocket chip generator necessary to instantiate the RISC-V Rocket Core. For more information on Rocket Chip, please consult our &lt;a href=&#34;http://www.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.html&#34;&gt;technical report&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#quick&#34;&gt;Quick instructions&lt;/a&gt; for those who want to dive directly into the details without knowing exactly what&#39;s in the repository.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#what&#34;&gt;What&#39;s in the Rocket chip generator repository?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#how&#34;&gt;How should I use the Rocket chip generator?&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#emulator&#34;&gt;Using the cycle-accurate Verilator simulation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#fpga&#34;&gt;Mapping a Rocket core down to an FPGA&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#vlsi&#34;&gt;Pushing a Rocket core through the VLSI tools&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#param&#34;&gt;How can I parameterize my Rocket chip?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#debug&#34;&gt;Debugging with GDB&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#ide&#34;&gt;Building Rocket Chip with an IDE&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/#contributors&#34;&gt;Contributors&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;quick&#34;&gt;&lt;/a&gt; Quick Instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Checkout The Code&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ucb-bar/rocket-chip.git&#xA;$ cd rocket-chip&#xA;$ git submodule update --init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Setting up the RISCV environment variable&lt;/h3&gt; &#xA;&lt;p&gt;To build the rocket-chip repository, you must point the RISCV environment variable to your rocket-tools installation directory.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ export RISCV=/path/to/riscv/toolchain/installation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The rocket-tools repository known to work with rocket-chip is noted in the file riscv-tools.hash. However, any recent rocket-tools should work. You can build rocket-tools as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/freechipsproject/rocket-tools&#xA;$ cd rocket-tools&#xA;$ git submodule update --init --recursive&#xA;$ export RISCV=/path/to/install/riscv/toolchain&#xA;$ export MAKEFLAGS=&#34;$MAKEFLAGS -jN&#34; # Assuming you have N cores on your host system&#xA;$ ./build.sh&#xA;$ ./build-rv32ima.sh (if you are using RV32).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install Necessary Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;You may need to install some additional packages to use this repository. Rather than list all dependencies here, please see the appropriate section of the READMEs for each of the subprojects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/freechipsproject/rocket-tools/raw/master/README.md&#34;&gt;rocket-tools &#34;Ubuntu Packages Needed&#34;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ucb-bar/chisel3#installation&#34;&gt;chisel3 &#34;Installation&#34;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Building The Project&lt;/h3&gt; &#xA;&lt;p&gt;First, to build the C simulator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd emulator&#xA;$ make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or to build the VCS simulator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd vsim&#xA;$ make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In either case, you can run a set of assembly tests or simple benchmarks (Assuming you have N cores on your host system):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make -jN run-asm-tests&#xA;$ make -jN run-bmark-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To build a C simulator that is capable of VCD waveform generation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd emulator&#xA;$ make debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And to run the assembly tests on the C simulator and generate waveforms:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make -jN run-asm-tests-debug&#xA;$ make -jN run-bmark-tests-debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate FPGA- or VLSI-synthesizable Verilog (output will be in &lt;code&gt;vsim/generated-src&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd vsim&#xA;$ make verilog&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the Scala tests (&lt;code&gt;sbt test&lt;/code&gt;) or linter (&lt;code&gt;sbt scalafix&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd regression&#xA;&#xA;# Scala tests&#xA;$ make scalatest SUITE=foo&#xA;&#xA;# Scala linter, automatically modifying files to correct issues&#xA;$ make scalafix SUITE=foo&#xA;&#xA;# Scala linter, only printing out issues&#xA;$ make scalafix-check SUITE=foo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Keeping Your Repo Up-to-Date&lt;/h3&gt; &#xA;&lt;p&gt;If you are trying to keep your repo up to date with this GitHub repo, you also need to keep the submodules and tools up to date.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ # Get the newest versions of the files in this repo&#xA;$ git pull origin master&#xA;$ # Make sure the submodules have the correct versions&#xA;$ git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If rocket-tools version changes, you should recompile and install rocket-tools according to the directions in the &lt;a href=&#34;https://github.com/freechipsproject/rocket-tools/raw/master/README.md&#34;&gt;rocket-tools/README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd rocket-tools&#xA;$ ./build.sh&#xA;$ ./build-rv32ima.sh (if you are using RV32)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;what&#34;&gt;&lt;/a&gt; What&#39;s in the Rocket chip generator repository?&lt;/h2&gt; &#xA;&lt;p&gt;The rocket-chip repository is a meta-repository that points to several sub-repositories using &lt;a href=&#34;http://git-scm.com/book/en/Git-Tools-Submodules&#34;&gt;Git submodules&lt;/a&gt;. Those repositories contain tools needed to generate and test SoC designs. This respository also contains code that is used to generate RTL. Hardware generation is done using &lt;a href=&#34;http://chisel.eecs.berkeley.edu&#34;&gt;Chisel&lt;/a&gt;, a hardware construction language embedded in Scala. The rocket-chip generator is a Scala program that invokes the Chisel compiler in order to emit RTL describing a complete SoC. The following sections describe the components of this repository.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;what_submodules&#34;&gt;&lt;/a&gt;Git Submodules&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Tools-Submodules&#34;&gt;Git submodules&lt;/a&gt; allow you to keep a Git repository as a subdirectory of another Git repository. For projects being co-developed with the Rocket Chip Generator, we have often found it expedient to track them as submodules, allowing for rapid exploitation of new features while keeping commit histories separate. As submoduled projects adopt stable public APIs, we transition them to external dependencies. Here are the submodules that are currently being tracked in the rocket-chip repository:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;chisel3&lt;/strong&gt; (&lt;a href=&#34;https://github.com/ucb-bar/chisel3&#34;&gt;https://github.com/ucb-bar/chisel3&lt;/a&gt;): The Rocket Chip Generator uses &lt;a href=&#34;http://chisel.eecs.berkeley.edu&#34;&gt;Chisel&lt;/a&gt; to generate RTL.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;firrtl&lt;/strong&gt; (&lt;a href=&#34;https://github.com/ucb-bar/firrtl&#34;&gt;https://github.com/ucb-bar/firrtl&lt;/a&gt;): &lt;a href=&#34;http://bar.eecs.berkeley.edu/projects/2015-firrtl.html&#34;&gt;Firrtl (Flexible Internal Representation for RTL)&lt;/a&gt; is the intermediate representation of RTL constructions used by Chisel3. The Chisel3 compiler generates a Firrtl representation, from which the final product (Verilog code, C code, etc) is generated.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;hardfloat&lt;/strong&gt; (&lt;a href=&#34;https://github.com/ucb-bar/berkeley-hardfloat&#34;&gt;https://github.com/ucb-bar/berkeley-hardfloat&lt;/a&gt;): Hardfloat holds Chisel code that generates parameterized IEEE 754-2008 compliant floating-point units used for fused multiply-add operations, conversions between integer and floating-point numbers, and conversions between floating-point conversions with different precision.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;rocket-tools&lt;/strong&gt; (&lt;a href=&#34;https://github.com/freechipsproject/rocket-tools&#34;&gt;https://github.com/freechipsproject/rocket-tools&lt;/a&gt;): We tag a version of RISC-V software tools that work with the RTL committed in this repository.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;torture&lt;/strong&gt; (&lt;a href=&#34;https://github.com/ucb-bar/riscv-torture&#34;&gt;https://github.com/ucb-bar/riscv-torture&lt;/a&gt;): This module is used to generate and execute constrained random instruction streams that can be used to stress-test both the core and uncore portions of the design.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;what_packages&#34;&gt;&lt;/a&gt;Scala Packages&lt;/h3&gt; &#xA;&lt;p&gt;In addition to submodules that track independent Git repositories, the rocket-chip code base is itself factored into a number of Scala packages. These packages are all found within the src/main/scala directory. Some of these packages provide Scala utilities for generator configuration, while other contain the actual Chisel RTL generators themselves. Here is a brief description of what can be found in each package:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;amba&lt;/strong&gt; This RTL package uses diplomacy to generate bus implementations of AMBA protocols, including AXI4, AHB-lite, and APB.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;config&lt;/strong&gt; This utility package provides Scala interfaces for configuring a generator via a dynamically-scoped parameterization library.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;coreplex&lt;/strong&gt; This RTL package generates a complete coreplex by gluing together a variety of components from other packages, including: tiled Rocket cores, a system bus network, coherence agents, debug devices, interrupt handlers, externally-facing peripherals, clock-crossers and converters from TileLink to external bus protocols (e.g. AXI or AHB).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;devices&lt;/strong&gt; This RTL package contains implementations for peripheral devices, including the Debug module and various TL slaves.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;diplomacy&lt;/strong&gt; This utility package extends Chisel by allowing for two-phase hardware elaboration, in which certain parameters are dynamically negotiated between modules. For more information about diplomacy, see &lt;a href=&#34;https://carrv.github.io/2017/papers/cook-diplomacy-carrv2017.pdf&#34;&gt;this paper&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;groundtest&lt;/strong&gt; This RTL package generates synthesizable hardware testers that emit randomized memory access streams in order to stress-tests the uncore memory hierarchy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;jtag&lt;/strong&gt; This RTL package provides definitions for generating JTAG bus interfaces.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;regmapper&lt;/strong&gt; This utility package generates slave devices with a standardized interface for accessing their memory-mapped registers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;rocket&lt;/strong&gt; This RTL package generates the Rocket in-order pipelined core, as well as the L1 instruction and data caches. This library is intended to be used by a chip generator that instantiates the core within a memory system and connects it to the outside world.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;tile&lt;/strong&gt; This RTL package contains components that can be combined with cores to construct tiles, such as FPUs and accelerators.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;tilelink&lt;/strong&gt; This RTL package uses diplomacy to generate bus implementations of the TileLink protocol. It also contains a variety of adapters and protocol converters.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;system&lt;/strong&gt; This top-level utility package invokes Chisel to elaborate a particular configuration of a coreplex, along with the appropriate testing collateral.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;unittest&lt;/strong&gt; This utility package contains a framework for generateing synthesizable hardware testers of individual modules.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;util&lt;/strong&gt; This utility package provides a variety of common Scala and Chisel constructs that are re-used across multiple other packages,&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;what_else&#34;&gt;&lt;/a&gt;Other Resources&lt;/h3&gt; &#xA;&lt;p&gt;Outside of Scala, we also provide a variety of resources to create a complete SoC implementation and test the generated designs.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;bootrom&lt;/strong&gt; Sources for the first-stage bootloader included in the BootROM.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;csrc&lt;/strong&gt; C sources for use with Verilator simulation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;docs&lt;/strong&gt; Documentation, tutorials, etc for specific parts of the codebase.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;emulator&lt;/strong&gt; Directory in which Verilator simulations are compiled and run.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;project&lt;/strong&gt; Directory used by SBT for Scala compilation and build.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;regression&lt;/strong&gt; Defines continuous integration and nightly regression suites.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;scripts&lt;/strong&gt; Utilities for parsing the output of simulations or manipulating the contents of source files.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;vsim&lt;/strong&gt; Directory in which Synopsys VCS simulations are compiled and run.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;vsrc&lt;/strong&gt; Verilog sources containing interfaces, harnesses and VPI.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;what_toplevel&#34;&gt;&lt;/a&gt;Extending the Top-Level Design&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/ucb-bar/project-template&#34;&gt;this description&lt;/a&gt; of how to create you own top-level design with custom devices.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;how&#34;&gt;&lt;/a&gt; How should I use the Rocket chip generator?&lt;/h2&gt; &#xA;&lt;p&gt;Chisel can generate code for three targets: a high-performance cycle-accurate Verilator, Verilog optimized for FPGAs, and Verilog for VLSI. The rocket-chip generator can target all three backends. You will need a Java runtime installed on your machine, since Chisel is overlaid on top of &lt;a href=&#34;http://www.scala-lang.org/&#34;&gt;Scala&lt;/a&gt;. Chisel RTL (i.e. rocket-chip source code) is a Scala program executing on top of your Java runtime. To begin, ensure that the ROCKETCHIP environment variable points to the rocket-chip repository.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ucb-bar/rocket-chip.git&#xA;$ cd rocket-chip&#xA;$ export ROCKETCHIP=`pwd`&#xA;$ git submodule update --init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Before going any further, you must point the RISCV environment variable to your rocket-tools installation directory. If you do not yet have rocket-tools installed, follow the directions in the &lt;a href=&#34;https://github.com/freechipsproject/rocket-tools/raw/master/README.md&#34;&gt;rocket-tools/README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export RISCV=/path/to/install/riscv/toolchain&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Otherwise, you will see the following error message while executing any command in the rocket-chip generator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;*** Please set environment variable RISCV. Please take a look at README.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;emulator&#34;&gt;&lt;/a&gt; 1) Using the high-performance cycle-accurate Verilator&lt;/h3&gt; &#xA;&lt;p&gt;Your next step is to get the Verilator working. Assuming you have N cores on your host system, do the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/emulator&#xA;$ make -jN run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By doing so, the build system will generate C++ code for the cycle-accurate emulator, compile the emulator, compile all RISC-V assembly tests and benchmarks, and run both tests and benchmarks on the emulator. If Make finished without any errors, it means that the generated Rocket chip has passed all assembly tests and benchmarks!&lt;/p&gt; &#xA;&lt;p&gt;You can also run assembly tests and benchmarks separately:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make -jN run-asm-tests&#xA;$ make -jN run-bmark-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate vcd waveforms, you can run one of the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make -jN run-debug&#xA;$ make -jN run-asm-tests-debug&#xA;$ make -jN run-bmark-tests-debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or call out individual assembly tests or benchmarks:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ make output/rv64ui-p-add.out&#xA;$ make output/rv64ui-p-add.vcd&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now take a look in the emulator/generated-src directory. You will find Chisel generated Verilog code and its associated C++ code generated by Verilator.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ls $ROCKETCHIP/emulator/generated-src&#xA;freechips.rocketchip.system.DefaultConfig&#xA;freechips.rocketchip.system.DefaultConfig.0x0.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x0.1.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x2000000.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x40.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0xc000000.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.anno.json&#xA;freechips.rocketchip.system.DefaultConfig.behav_srams.v&#xA;freechips.rocketchip.system.DefaultConfig.conf&#xA;freechips.rocketchip.system.DefaultConfig.d&#xA;freechips.rocketchip.system.DefaultConfig.dts&#xA;freechips.rocketchip.system.DefaultConfig.fir&#xA;freechips.rocketchip.system.DefaultConfig.graphml&#xA;freechips.rocketchip.system.DefaultConfig.json&#xA;freechips.rocketchip.system.DefaultConfig.memmap.json&#xA;freechips.rocketchip.system.DefaultConfig.plusArgs&#xA;freechips.rocketchip.system.DefaultConfig.rom.conf&#xA;freechips.rocketchip.system.DefaultConfig.v&#xA;TestHarness.anno.json&#xA;$ ls $ROCKETCHIP/emulator/generated-src/freechips.rocketchip.system.DefaultConfig&#xA;VTestHarness__1.cpp&#xA;VTestHarness__2.cpp&#xA;VTestHarness__3.cpp&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Also, output of the executed assembly tests and benchmarks can be found at emulator/output/*.out. Each file has a cycle-by-cycle dump of write-back stage of the pipeline. Here&#39;s an excerpt of emulator/output/rv64ui-p-add.out:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;C0: 483 [1] pc=[00000002138] W[r 3=000000007fff7fff][1] R[r 1=000000007fffffff] R[r 2=ffffffffffff8000] inst=[002081b3] add s1, ra, s0&#xA;C0: 484 [1] pc=[0000000213c] W[r29=000000007fff8000][1] R[r31=ffffffff80007ffe] R[r31=0000000000000005] inst=[7fff8eb7] lui t3, 0x7fff8&#xA;C0: 485 [0] pc=[00000002140] W[r 0=0000000000000000][0] R[r 0=0000000000000000] R[r 0=0000000000000000] inst=[00000000] unknown&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The first [1] at cycle 483, core 0, shows that there&#39;s a valid instruction at PC 0x2138 in the writeback stage, which is 0x002081b3 (add s1, ra, s0). The second [1] tells us that the register file is writing r3 with the corresponding value 0x7fff7fff. When the add instruction was in the decode stage, the pipeline had read r1 and r2 with the corresponding values next to it. Similarly at cycle 484, there&#39;s a valid instruction (lui instruction) at PC 0x213c in the writeback stage. At cycle 485, there isn&#39;t a valid instruction in the writeback stage, perhaps, because of a instruction cache miss at PC 0x2140.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;fpga&#34;&gt;&lt;/a&gt; 2) Mapping a Rocket core to an FPGA&lt;/h3&gt; &#xA;&lt;p&gt;You can generate synthesizable Verilog with the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make verilog CONFIG=freechips.rocketchip.system.DefaultFPGAConfig&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The Verilog used for the FPGA tools will be generated in vsim/generated-src. Please proceed further with the directions shown in the &lt;a href=&#34;https://github.com/sifive/freedom/raw/master/README.md&#34;&gt;README&lt;/a&gt; of the freedom repository. You can also run Rocket Chip on Amazon EC2 F1 with &lt;a href=&#34;https://github.com/firesim/firesim&#34;&gt;FireSim&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you have access to VCS, you will be able to run assembly tests and benchmarks in simulation with the following commands (again assuming you have N cores on your host machine):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make -jN run CONFIG=freechips.rocketchip.system.DefaultFPGAConfig&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The generated output looks similar to those generated from the emulator. Look into vsim/output/*.out for the output of the executed assembly tests and benchmarks.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a name=&#34;vlsi&#34;&gt;&lt;/a&gt; 3) Pushing a Rocket core through the VLSI tools&lt;/h3&gt; &#xA;&lt;p&gt;You can generate Verilog for your VLSI flow with the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make verilog&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now take a look at vsim/generated-src, and the contents of the Top.DefaultConfig.conf file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim/generated-src&#xA;freechips.rocketchip.system.DefaultConfig&#xA;freechips.rocketchip.system.DefaultConfig.0x0.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x0.1.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x2000000.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0x40.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.0xc000000.0.regmap.json&#xA;freechips.rocketchip.system.DefaultConfig.anno.json&#xA;freechips.rocketchip.system.DefaultConfig.behav_srams.v&#xA;freechips.rocketchip.system.DefaultConfig.conf&#xA;freechips.rocketchip.system.DefaultConfig.d&#xA;freechips.rocketchip.system.DefaultConfig.dts&#xA;freechips.rocketchip.system.DefaultConfig.fir&#xA;freechips.rocketchip.system.DefaultConfig.graphml&#xA;freechips.rocketchip.system.DefaultConfig.json&#xA;freechips.rocketchip.system.DefaultConfig.memmap.json&#xA;freechips.rocketchip.system.DefaultConfig.plusArgs&#xA;freechips.rocketchip.system.DefaultConfig.rom.conf&#xA;freechips.rocketchip.system.DefaultConfig.v&#xA;TestHarness.anno.json&#xA;$ cat $ROCKETCHIP/vsim/generated-src/*.conf&#xA;name data_arrays_0_ext depth 512 width 256 ports mrw mask_gran 8&#xA;name tag_array_ext depth 64 width 88 ports mrw mask_gran 22&#xA;name tag_array_0_ext depth 64 width 84 ports mrw mask_gran 21&#xA;name data_arrays_0_1_ext depth 512 width 128 ports mrw mask_gran 32&#xA;name mem_ext depth 33554432 width 64 ports mwrite,read mask_gran 8&#xA;name mem_2_ext depth 512 width 64 ports mwrite,read mask_gran 8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The conf file contains information for all SRAMs instantiated in the flow. If you take a close look at the $ROCKETCHIP/Makefrag, you will see that during Verilog generation, the build system calls a $(mem_gen) script with the generated configuration file as an argument, which will fill in the Verilog for the SRAMs. Currently, the $(mem_gen) script points to vsim/vlsi_mem_gen, which simply instantiates behavioral SRAMs. You will see those SRAMs being appended at the end of vsim/generated-src/Top.DefaultConfig.v. To target vendor-specific SRAMs, you will need to make necessary changes to vsim/vlsi_mem_gen.&lt;/p&gt; &#xA;&lt;p&gt;Similarly, if you have access to VCS, you can run assembly tests and benchmarks with the following commands (again assuming you have N cores on your host machine):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make -jN run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The generated output looks similar to those generated from the emulator. Look into vsim/output/*.out for the output of the executed assembly tests and benchmarks.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;param&#34;&gt;&lt;/a&gt; How can I parameterize my Rocket chip?&lt;/h2&gt; &#xA;&lt;p&gt;By now, you probably figured out that all generated files have a configuration name attached, e.g. &lt;code&gt;freechips.rocketchip.system.DefaultConfig&lt;/code&gt;. Take a look at &lt;code&gt;src/main/scala/system/Configs.scala&lt;/code&gt;. Search for &lt;code&gt;NSets&lt;/code&gt; and &lt;code&gt;NWays&lt;/code&gt; defined in &lt;code&gt;BaseConfig&lt;/code&gt;. You can change those numbers to get a Rocket core with different cache parameters. For example, by changing L1I, NWays to 4, you will get a 32KB 4-way set-associative L1 instruction cache rather than a 16KB 2-way set-associative L1 instruction cache. Towards the end, you can also find that &lt;code&gt;DefaultSmallConfig&lt;/code&gt; inherits all parameters from &lt;code&gt;BaseConfig&lt;/code&gt; but overrides the same parameters of &lt;code&gt;WithNSmallCores&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Now take a look at &lt;code&gt;vsim/Makefile&lt;/code&gt;. Search for the &lt;code&gt;CONFIG&lt;/code&gt; variable. By default, it is set to &lt;code&gt;freechips.rocketchip.system.DefaultConfig&lt;/code&gt;. You can also change the CONFIG variable on the make command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim&#xA;$ make -jN CONFIG=freechips.rocketchip.system.DefaultSmallConfig run-asm-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, even by defining CONFIG as an environment variable:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ export CONFIG=freechips.rocketchip.system.DefaultSmallConfig&#xA;$ make -jN run-asm-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This parameterization is one of the many strengths of processor generators written in Chisel, and will be more detailed in a future blog post, so please stay tuned.&lt;/p&gt; &#xA;&lt;p&gt;To override specific configuration items, such as the number of external interrupts, you can create your own Configuration(s) and compose them with Config&#39;s ++ operator&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;class WithNExtInterrupts(nExt: Int) extends Config {&#xA;    (site, here, up) =&amp;gt; {&#xA;        case NExtInterrupts =&amp;gt; nExt&#xA;    }&#xA;}&#xA;class MyConfig extends Config (new WithNExtInterrupts(16) ++ new DefaultSmallConfig)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then you can build as usual with &lt;code&gt;CONFIG=&amp;lt;MyConfigPackage&amp;gt;.MyConfig&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;debug&#34;&gt;&lt;/a&gt; Debugging with GDB&lt;/h2&gt; &#xA;&lt;h3&gt;1) Generating the Remote Bit-Bang (RBB) Emulator&lt;/h3&gt; &#xA;&lt;p&gt;The objective of this section is to use GNU debugger to debug RISC-V programs running on the emulator in the same fashion as in &lt;a href=&#34;https://github.com/riscv/riscv-isa-sim#debugging-with-gdb&#34;&gt;Spike&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For that we need to add a Remote Bit-Bang client to the emulator. We can do so by extending our Config with JtagDTMSystem, which will add a DebugTransportModuleJTAG to the DUT and connect a SimJTAG module in the Test Harness. This will allow OpenOCD to interface with the emulator, and GDB can interface with OpenOCD. In the following example we add this Config alteration to &lt;code&gt;src/main/scala/system/Configs.scala&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;class DefaultConfigRBB extends Config(&#xA;new WithJtagDTMSystem ++ new WithNBigCores(1) ++ new WithCoherentBusTopology ++ new BaseConfig)&#xA;&#xA;class QuadCoreConfigRBB extends Config(&#xA;new WithJtagDTMSystem ++ new WithNBigCores(4) ++ new WithCoherentBusTopology ++ new BaseConfig)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To build the emulator with &lt;code&gt;DefaultConfigRBB&lt;/code&gt; configuration we use the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;rocket-chip$ cd emulator&#xA;emulator$ CONFIG=freechips.rocketchip.system.DefaultConfigRBB make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can also build a debug version capable of generating VCD waveforms using the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;emulator$ CONFIG=freechips.rocketchip.system.DefaultConfigRBB make debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default the emulator is generated under the name &lt;code&gt;emulator-freechips.rocketchip.system-DefaultConfigRBB&lt;/code&gt; in the first case and &lt;code&gt;emulator-freechips.rocketchip.system-DefaultConfigRBB-debug&lt;/code&gt; in the second.&lt;/p&gt; &#xA;&lt;h3&gt;2) Compiling and executing a custom program using the emulator&lt;/h3&gt; &#xA;&lt;p&gt;We suppose that &lt;code&gt;helloworld&lt;/code&gt; is our program, you can use &lt;code&gt;crt.S&lt;/code&gt;, &lt;code&gt;syscalls.c&lt;/code&gt; and the linker script &lt;code&gt;test.ld&lt;/code&gt; to construct your own program, check examples stated in &lt;a href=&#34;https://github.com/riscv/riscv-tests&#34;&gt;riscv-tests&lt;/a&gt;. Note that &lt;code&gt;test.ld&lt;/code&gt; loads the program at 0x80000000 so you will need to use &lt;code&gt;-mcmodel=medany&lt;/code&gt; otherwise you will get relocation errors. See &lt;a href=&#34;https://www.sifive.com/blog/2017/09/11/all-aboard-part-4-risc-v-code-models/&#34;&gt;All Aboard, Part 4: The RISC-V Code Models&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;In our case we will use the following example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;char text[] = &#34;Vafgehpgvba frgf jnag gb or serr!&#34;;&#xA;&#xA;// Don&#39;t use the stack, because sp isn&#39;t set up.&#xA;volatile int wait = 1;&#xA;&#xA;int main()&#xA;{&#xA;    while (wait)&#xA;        ;&#xA;&#xA;    // Doesn&#39;t actually go on the stack, because there are lots of GPRs.&#xA;    int i = 0;&#xA;    while (text[i]) {&#xA;        char lower = text[i] | 32;&#xA;        if (lower &amp;gt;= &#39;a&#39; &amp;amp;&amp;amp; lower &amp;lt;= &#39;m&#39;)&#xA;            text[i] += 13;&#xA;        else if (lower &amp;gt; &#39;m&#39; &amp;amp;&amp;amp; lower &amp;lt;= &#39;z&#39;)&#xA;            text[i] -= 13;&#xA;        i++;&#xA;    }&#xA;&#xA;    while (!wait)&#xA;        ;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;First we can test if your program executes well in the simple version of emulator before moving to debugging in step 3 :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig helloworld &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additional verbose information (clock cycle, pc, instruction being executed) can be printed using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig +verbose helloworld 2&amp;gt;&amp;amp;1 | spike-dasm &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;VCD output files can be obtained using the &lt;code&gt;-debug&lt;/code&gt; version of the emulator and are specified using &lt;code&gt;-v&lt;/code&gt; or &lt;code&gt;--vcd=FILE&lt;/code&gt; arguments. A detailed log file of all executed instructions can also be obtained from the emulator, this is an example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig-debug +verbose -v output.vcd  helloworld 2&amp;gt;&amp;amp;1 | spike-dasm &amp;gt; output.log&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please note that generated VCD waveforms and execution log files can be very voluminous depending on the size of the .elf file (i.e. code size + debugging symbols).&lt;/p&gt; &#xA;&lt;p&gt;Please note also that the time it takes the emulator to load your program depends on executable size. Stripping the .elf executable will unsurprisingly make it run faster. For this you can use &lt;code&gt;$RISCV/bin/riscv64-unknown-elf-strip&lt;/code&gt; tool to reduce the size. This is good for accelerating your simulation but not for debugging. Keep in mind that the HTIF communication interface between our system and the emulator relies on &lt;code&gt;tohost&lt;/code&gt; and &lt;code&gt;fromhost&lt;/code&gt; symbols to communicate. This is why you may get the following error when you try to run a totally stripped executable on the emulator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig totally-stripped-helloworld &#xA;This emulator compiled with JTAG Remote Bitbang client. To enable, use +jtag_rbb_enable=1.&#xA;Listening on port 46529&#xA;warning: tohost and fromhost symbols not in ELF; can&#39;t communicate with target&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To resolve this, we need to strip all the .elf executable but keep &lt;code&gt;tohost&lt;/code&gt; and &lt;code&gt;fromhost&lt;/code&gt; symbols using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$riscv64-unknown-elf-strip -s -Kfromhost -Ktohost helloworld&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More details on the GNU strip tool can be found &lt;a href=&#34;https://www.thegeekstuff.com/2012/09/strip-command-examples/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The interest of this step is to make sure your program executes well. To perform debugging you need the original unstripped version, as explained in step 3.&lt;/p&gt; &#xA;&lt;h3&gt;3) Launch the emulator&lt;/h3&gt; &#xA;&lt;p&gt;First, do not forget to compile your program with &lt;code&gt;-g -Og&lt;/code&gt; flags to provide debugging support as explained &lt;a href=&#34;https://github.com/riscv/riscv-isa-sim#debugging-with-gdb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We can then launch the Remote Bit-Bang enabled emulator with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./emulator-freechips.rocketchip.system-DefaultConfigRBB +jtag_rbb_enable=1 --rbb-port=9823 helloworld&#xA;This emulator compiled with JTAG Remote Bitbang client. To enable, use +jtag_rbb_enable=1.&#xA;Listening on port 9823&#xA;Attempting to accept client socket&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use the &lt;code&gt;emulator-freechips.rocketchip.system-DefaultConfigRBB-debug&lt;/code&gt; version instead if you would like to generate VCD waveforms.&lt;/p&gt; &#xA;&lt;p&gt;Please note that if the argument &lt;code&gt;--rbb-port&lt;/code&gt; is not passed, a default free TCP port on your computer will be chosen randomly.&lt;/p&gt; &#xA;&lt;p&gt;Please note also that when debugging with GDB, the .elf file is not actually loaded by the FESVR. In contrast with Spike, it must be loaded from GDB as explained in step 5. So the &lt;code&gt;helloworld&lt;/code&gt; argument may be replaced by any dummy name.&lt;/p&gt; &#xA;&lt;h3&gt;4) Launch OpenOCD&lt;/h3&gt; &#xA;&lt;p&gt;You will need a RISC-V Enabled OpenOCD binary. This is installed with rocket-tools in &lt;code&gt;$(RISCV)/bin/openocd&lt;/code&gt;, or can be compiled manually from riscv-openocd. OpenOCD requires a configuration file, in which we define the RBB port we will use, which is in our case &lt;code&gt;9823&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cat cemulator.cfg &#xA;interface remote_bitbang&#xA;remote_bitbang_host localhost&#xA;remote_bitbang_port 9823&#xA;&#xA;set _CHIPNAME riscv&#xA;jtag newtap $_CHIPNAME cpu -irlen 5&#xA;&#xA;set _TARGETNAME $_CHIPNAME.cpu&#xA;target create $_TARGETNAME riscv -chain-position $_TARGETNAME&#xA;&#xA;gdb_report_data_abort enable&#xA;&#xA;init&#xA;halt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then we launch OpenOCD in another terminal using the command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$(RISCV)/bin/openocd -f ./cemulator.cfg&#xA;Open On-Chip Debugger 0.10.0+dev-00112-g3c1c6e0 (2018-04-12-10:40)&#xA;Licensed under GNU GPL v2&#xA;For bug reports, read&#xA;http://openocd.org/doc/doxygen/bugs.html&#xA;Warn : Adapter driver &#39;remote_bitbang&#39; did not declare which transports it allows; assuming legacy JTAG-only&#xA;Info : only one transport option; autoselect &#39;jtag&#39;&#xA;Info : Initializing remote_bitbang driver&#xA;Info : Connecting to localhost:9823&#xA;Info : remote_bitbang driver initialized&#xA;Info : This adapter doesn&#39;t support configurable speed&#xA;Info : JTAG tap: riscv.cpu tap/device found: 0x00000001 (mfg: 0x000 (&amp;lt;invalid&amp;gt;), part: 0x0000, ver: 0x0)&#xA;Info : datacount=2 progbufsize=16&#xA;Info : Disabling abstract command reads from CSRs.&#xA;Info : Disabling abstract command writes to CSRs.&#xA;Info : [0] Found 1 triggers&#xA;Info : Examined RISC-V core; found 1 harts&#xA;Info :  hart 0: XLEN=64, 1 triggers&#xA;Info : Listening on port 3333 for gdb connections&#xA;Info : Listening on port 6666 for tcl connections&#xA;Info : Listening on port 4444 for telnet connections&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A &lt;code&gt;-d&lt;/code&gt; flag can be added to the command to show further debug information.&lt;/p&gt; &#xA;&lt;h3&gt;5) Launch GDB&lt;/h3&gt; &#xA;&lt;p&gt;In another terminal launch GDB and point to the elf file you would like to load then run it with the debugger (in this example, &lt;code&gt;helloworld&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ riscv64-unknown-elf-gdb helloworld&#xA;GNU gdb (GDB) 8.0.50.20170724-git&#xA;Copyright (C) 2017 Free Software Foundation, Inc.&#xA;License GPLv3+: GNU GPL version 3 or later &amp;lt;http://gnu.org/licenses/gpl.html&amp;gt;&#xA;This is free software: you are free to change and redistribute it.&#xA;There is NO WARRANTY, to the extent permitted by law.  Type &#34;show copying&#34;&#xA;and &#34;show warranty&#34; for details.&#xA;This GDB was configured as &#34;--host=x86_64-pc-linux-gnu --target=riscv64-unknown-elf&#34;.&#xA;Type &#34;show configuration&#34; for configuration details.&#xA;For bug reporting instructions, please see:&#xA;&amp;lt;http://www.gnu.org/software/gdb/bugs/&amp;gt;.&#xA;Find the GDB manual and other documentation resources online at:&#xA;&amp;lt;http://www.gnu.org/software/gdb/documentation/&amp;gt;.&#xA;For help, type &#34;help&#34;.&#xA;Type &#34;apropos word&#34; to search for commands related to &#34;word&#34;...&#xA;Reading symbols from ./proj1.out...done.&#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Compared to Spike, the C Emulator is very slow, so several problems may be encountered due to timeouts between issuing commands and response from the emulator. To solve this problem, we increase the timeout with the GDB &lt;code&gt;set remotetimeout&lt;/code&gt; command.&lt;/p&gt; &#xA;&lt;p&gt;After that we load our program by performing a &lt;code&gt;load&lt;/code&gt; command. This automatically sets the &lt;code&gt;$PC&lt;/code&gt; to the &lt;code&gt;_start&lt;/code&gt; symbol in our .elf file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(gdb) set remotetimeout 2000&#xA;(gdb) target remote localhost:3333&#xA;Remote debugging using localhost:3333&#xA;0x0000000000010050 in ?? ()&#xA;(gdb) load&#xA;Loading section .text.init, size 0x2cc lma 0x80000000&#xA;Loading section .tohost, size 0x48 lma 0x80001000&#xA;Loading section .text, size 0x98c lma 0x80001048&#xA;Loading section .rodata, size 0x158 lma 0x800019d4&#xA;Loading section .rodata.str1.8, size 0x20 lma 0x80001b30&#xA;Loading section .data, size 0x22 lma 0x80001b50&#xA;Loading section .sdata, size 0x4 lma 0x80001b74&#xA;Start address 0x80000000, load size 3646&#xA;Transfer rate: 40 bytes/sec, 520 bytes/write.&#xA;(gdb) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now we can proceed as with Spike, debugging works in a similar way:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(gdb) print wait&#xA;$1 = 1&#xA;(gdb) print wait=0&#xA;$2 = 0&#xA;(gdb) print text&#xA;$3 = &#34;Vafgehpgvba frgf jnag gb or serr!&#34;&#xA;(gdb) c&#xA;Continuing.&#xA;&#xA;^C&#xA;Program received signal SIGINT, Interrupt.&#xA;main (argc=0, argv=&amp;lt;optimized out&amp;gt;) at src/main.c:33&#xA;33&#x9;    while (!wait)&#xA;(gdb) print wait&#xA;$4 = 0&#xA;(gdb) print text&#xA;$5 = &#34;Instruction sets want to be free!&#34;&#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Further information about GDB debugging is available &lt;a href=&#34;https://sourceware.org/gdb/onlinedocs/gdb/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://sourceware.org/gdb/onlinedocs/gdb/Remote-Debugging.html#Remote-Debugging&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;ide&#34;&gt;&lt;/a&gt; Building Rocket Chip with an IDE&lt;/h2&gt; &#xA;&lt;p&gt;The Rocket Chip Scala build uses the standard Scala build tool SBT. IDEs like &lt;a href=&#34;https://www.jetbrains.com/idea/&#34;&gt;IntelliJ&lt;/a&gt; and &lt;a href=&#34;https://code.visualstudio.com/&#34;&gt;VSCode&lt;/a&gt; are popular in the Scala community and work with Rocket Chip. To use one of these IDEs, there is one minor peculiarity of the Rocket Chip build that must be addressed.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;contributors&#34;&gt;&lt;/a&gt; Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Contributing guidelines can be found in &lt;a href=&#34;https://raw.githubusercontent.com/chipsalliance/rocket-chip/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;A list of contributors can be found &lt;a href=&#34;https://github.com/chipsalliance/rocket-chip/graphs/contributors&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;attribution&#34;&gt;&lt;/a&gt; Attribution&lt;/h2&gt; &#xA;&lt;p&gt;If used for research, please cite Rocket Chip by the technical report:&lt;/p&gt; &#xA;&lt;p&gt;Krste Asanović, Rimas Avižienis, Jonathan Bachrach, Scott Beamer, David Biancolin, Christopher Celio, Henry Cook, Palmer Dabbelt, John Hauser, Adam Izraelevitz, Sagar Karandikar, Benjamin Keller, Donggyu Kim, John Koenig, Yunsup Lee, Eric Love, Martin Maas, Albert Magyar, Howard Mao, Miquel Moreto, Albert Ou, David Patterson, Brian Richards, Colin Schmidt, Stephen Twigg, Huy Vo, and Andrew Waterman, &lt;em&gt;&lt;a href=&#34;http://www.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.html&#34;&gt;The Rocket Chip Generator&lt;/a&gt;&lt;/em&gt;, Technical Report UCB/EECS-2016-17, EECS Department, University of California, Berkeley, April 2016&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>scalameta/metals</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/scalameta/metals</id>
    <link href="https://github.com/scalameta/metals" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Scala language server with rich IDE features 🚀&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Metals&lt;/h1&gt; &#xA;&lt;a href=&#34;https://discord.gg/FaVDrJegEh&#34;&gt; &lt;img alt=&#34;Chat with us on discord&#34; src=&#34;https://img.shields.io/discord/632642981228314653&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://twitter.com/scalameta&#34;&gt; &lt;img alt=&#34;Follow scalameta on Twitter&#34; src=&#34;https://img.shields.io/twitter/follow/scalameta.svg?logo=twitter&amp;amp;color=blue&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://index.scala-lang.org/scalameta/metals/metals&#34;&gt; &lt;img alt=&#34;Find us on scaladex&#34; src=&#34;https://index.scala-lang.org/scalameta/metals/metals/latest.svg?sanitize=true&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;See the website: &lt;a href=&#34;https://scalameta.org/metals/&#34;&gt;https://scalameta.org/metals/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;See the contributing guide: &lt;a href=&#34;https://scalameta.org/metals/docs/contributors/getting-started.html&#34;&gt;https://scalameta.org/metals/docs/contributors/getting-started.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Team&lt;/h3&gt; &#xA;&lt;p&gt;The current maintainers (people who can merge pull requests) are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Adrien Piquerez - &lt;a href=&#34;https://github.com/adpi2&#34;&gt;&lt;code&gt;@adpi2&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Arthur McGibbon - &lt;a href=&#34;https://github.com/Arthurm1&#34;&gt;&lt;code&gt;@Arthurm1&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Chris Kipp - &lt;a href=&#34;https://github.com/ckipp01&#34;&gt;&lt;code&gt;@ckipp01&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kamil Podsiadło - &lt;a href=&#34;https://github.com/kpodsiad&#34;&gt;&lt;code&gt;@kpodsiad&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Ólafur Páll Geirsson - &lt;a href=&#34;https://github.com/olafurpg&#34;&gt;&lt;code&gt;@olafurpg&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Tomasz Godzik - &lt;a href=&#34;https://github.com/tgodzik&#34;&gt;&lt;code&gt;@tgodzik&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Vadim Chelyshov - &lt;a href=&#34;https://github.com/dos65&#34;&gt;&lt;code&gt;@dos65&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Past maintainers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Alexey Alekhin - &lt;a href=&#34;https://github.com/laughedelic&#34;&gt;&lt;code&gt;@laughedelic&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Gabriele Petronella - &lt;a href=&#34;https://github.com/gabro&#34;&gt;&lt;code&gt;@gabro&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Johan Mudsam - &lt;a href=&#34;https://github.com/mudsam&#34;&gt;&lt;code&gt;@mudsam&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Krzysztof Bochenek - &lt;a href=&#34;https://github.com/kpbochenek&#34;&gt;&lt;code&gt;@kpbochenek&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Jorge Vicente Cantero - &lt;a href=&#34;https://github.com/jvican&#34;&gt;&lt;code&gt;@jvican&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Marek Żarnowski - &lt;a href=&#34;https://github.com/marek1840&#34;&gt;&lt;code&gt;@marek1840&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Shane Delmore - &lt;a href=&#34;https://github.com/ShaneDelmore&#34;&gt;&lt;code&gt;@ShaneDelmore&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;Huge thanks to &lt;a href=&#34;https://github.com/dragos&#34;&gt;&lt;code&gt;@dragos&lt;/code&gt;&lt;/a&gt; for his work on a Scala implementation of the LSP (see: &lt;a href=&#34;https://github.com/dragos/dragos-vscode-scala&#34;&gt;https://github.com/dragos/dragos-vscode-scala&lt;/a&gt;). This project helped us get quickly started with LSP. Since then, we have refactored the project&#39;s original sources to the point where only a few simple case classes remain.&lt;/p&gt; &#xA;&lt;h2&gt;Alternatives&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jetbrains.com/help/idea/discover-intellij-idea-for-scala.html&#34;&gt;IntelliJ IDEA&lt;/a&gt;: the most widely used IDE for Scala using a re-implementation of the Scala typechecker.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why Metals?&lt;/h2&gt; &#xA;&lt;p&gt;Metals = Meta (from Scalameta) + LS (from Language Server)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>dream11/zio-http</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/dream11/zio-http</id>
    <link href="https://github.com/dream11/zio-http" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A scala library to write Http apps.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ZIO Http&lt;/h1&gt; &#xA;&lt;p&gt;ZIO Http is a scala library for building http apps. It is powered by &lt;a href=&#34;https://zio.dev&#34;&gt;ZIO&lt;/a&gt; and &lt;a href=&#34;http://netty.io&#34;&gt;netty&lt;/a&gt; and aims at being the defacto solution for writing, highly scalable and &lt;a href=&#34;https://raw.githubusercontent.com/dream11/zio-http/main/#benchmarks&#34;&gt;performant&lt;/a&gt; web applications using idiomatic scala.&lt;/p&gt; &#xA;&lt;p&gt;Check out the full documentation here: &lt;a href=&#34;https://dream11.github.io/zio-http&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/dream11/zio-http/workflows/Continuous%20Integration/badge.svg?sanitize=true&#34; alt=&#34;Continuous Integration&#34;&gt; &lt;a href=&#34;https://discord.com/channels/629491597070827530/819703129267372113&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/629491597070827530.svg?logo=discord&#34; alt=&#34;Discord Chat&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://oss.sonatype.org/content/repositories/releases/io/d11/zhttp_2.13/&#34;&gt;&lt;img src=&#34;https://img.shields.io/nexus/r/io.d11/zhttp_2.13?server=https%3A%2F%2Fs01.oss.sonatype.org&#34; alt=&#34;Sonatype Nexus (Releases)&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://s01.oss.sonatype.org/content/repositories/snapshots/io/d11/zhttp_2.13/&#34;&gt;&lt;img src=&#34;https://img.shields.io/nexus/s/io.d11/zhttp_2.13?server=https%3A%2F%2Fs01.oss.sonatype.org&#34; alt=&#34;Sonatype Nexus (Snapshots)&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://isitmaintained.com/project/dream11/zio-http&#34; title=&#34;Average time to resolve an issue&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/resolution/dream11/zio-http.svg?sanitize=true&#34; alt=&#34;Average time to resolve an issue&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://open.vscode.dev/dream11/zio-http&#34;&gt;&lt;img src=&#34;https://open.vscode.dev/badges/open-in-vscode.svg?sanitize=true&#34; alt=&#34;Open in Visual Studio Code&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dream11/zio-http/main/#zio-http&#34;&gt;ZIO Http&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dream11/zio-http/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dream11/zio-http/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dream11.github.io/zio-http/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;p&gt;A simple Http server can be built using a few lines of code.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import zio._&#xA;import zhttp.http._&#xA;import zhttp.service.Server&#xA;&#xA;object HelloWorld extends App {&#xA;  val app = Http.collect[Request] {&#xA;    case Method.GET -&amp;gt; !! / &#34;text&#34; =&amp;gt; Response.text(&#34;Hello World!&#34;)&#xA;  }&#xA;&#xA;  override def run(args: List[String]): URIO[zio.ZEnv, ExitCode] =&#xA;    Server.start(8090, app).exitCode&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Examples&lt;/h4&gt; &#xA;&lt;p&gt;You can checkout more examples in the &lt;a href=&#34;https://github.com/dream11/zio-http/tree/main/example/src/main/scala/example&#34;&gt;example&lt;/a&gt; project —&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dream11/zio-http/raw/main/example/src/main/scala/example/HelloWorld.scala&#34;&gt;Simple Server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dream11/zio-http/raw/main/example/src/main/scala/example/HelloWorldAdvanced.scala&#34;&gt;Advanced Server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dream11/zio-http/raw/main/example/src/main/scala/example/WebSocketEcho.scala&#34;&gt;WebSocket Server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dream11/zio-http/raw/main/example/src/main/scala/example/StreamingResponse.scala&#34;&gt;Streaming Response&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dream11/zio-http/raw/main/example/src/main/scala/example/SimpleClient.scala&#34;&gt;Simple Client&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dream11/zio-http/raw/main/example/src/main/scala/example/FileStreaming.scala&#34;&gt;File Streaming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dream11/zio-http/raw/main/example/src/main/scala/example/Authentication.scala&#34;&gt;Authentication&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Steps to run an example&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Edit the &lt;a href=&#34;https://github.com/dream11/zio-http/raw/main/project/BuildHelper.scala#L109&#34;&gt;RunSettings&lt;/a&gt; - modify &lt;code&gt;className&lt;/code&gt; to the example you&#39;d like to run.&lt;/li&gt; &#xA; &lt;li&gt;From sbt shell, run &lt;code&gt;~example/reStart&lt;/code&gt;. You should see &lt;code&gt;Server started on port: 8090&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Send curl request for defined &lt;code&gt;http Routes&lt;/code&gt;, for eg : &lt;code&gt;curl -i &#34;http://localhost:8090/text&#34;&lt;/code&gt; for &lt;code&gt;example.HelloWorld&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;Setup via &lt;code&gt;build.sbt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies += &#34;io.d11&#34; %% &#34;zhttp&#34;      % &#34;[version]&#34;&#xA;libraryDependencies += &#34;io.d11&#34; %% &#34;zhttp-test&#34; % &#34;[version]&#34; % Test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; ZIO Http is compatible with &lt;code&gt;ZIO 1.x&lt;/code&gt; and &lt;code&gt;ZIO 2.x&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Watch Mode&lt;/h1&gt; &#xA;&lt;p&gt;You can use the &lt;a href=&#34;https://github.com/spray/sbt-revolver&#34;&gt;sbt-revolver&lt;/a&gt; plugin to start the server and run it in watch mode using &lt;code&gt;~ reStart&lt;/code&gt; command on the SBT console.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apache/spark</title>
    <updated>2022-06-01T01:53:09Z</updated>
    <id>tag:github.com,2022-06-01:/apache/spark</id>
    <link href="https://github.com/apache/spark" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache Spark - A unified analytics engine for large-scale data processing&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache Spark&lt;/h1&gt; &#xA;&lt;p&gt;Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Scala, Java, Python, and R, and an optimized engine that supports general computation graphs for data analysis. It also supports a rich set of higher-level tools including Spark SQL for SQL and DataFrames, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for stream processing.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://spark.apache.org/&#34;&gt;https://spark.apache.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/spark/actions/workflows/build_and_test.yml?query=branch%3Amaster+event%3Apush&#34;&gt;&lt;img src=&#34;https://github.com/apache/spark/actions/workflows/build_and_test.yml/badge.svg?branch=master&amp;amp;event=push&#34; alt=&#34;GitHub Action Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ci.appveyor.com/project/ApacheSoftwareFoundation/spark&#34;&gt;&lt;img src=&#34;https://img.shields.io/appveyor/ci/ApacheSoftwareFoundation/spark/master.svg?style=plastic&amp;amp;logo=appveyor&#34; alt=&#34;AppVeyor Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/apache/spark&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/apache/spark/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;PySpark Coverage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Online Documentation&lt;/h2&gt; &#xA;&lt;p&gt;You can find the latest Spark documentation, including a programming guide, on the &lt;a href=&#34;https://spark.apache.org/documentation.html&#34;&gt;project web page&lt;/a&gt;. This README file only contains basic setup instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Building Spark&lt;/h2&gt; &#xA;&lt;p&gt;Spark is built using &lt;a href=&#34;https://maven.apache.org/&#34;&gt;Apache Maven&lt;/a&gt;. To build Spark and its example programs, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./build/mvn -DskipTests clean package&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(You do not need to do this if you downloaded a pre-built package.)&lt;/p&gt; &#xA;&lt;p&gt;More detailed documentation is available from the project site, at &lt;a href=&#34;https://spark.apache.org/docs/latest/building-spark.html&#34;&gt;&#34;Building Spark&#34;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For general development tips, including info on developing Spark using an IDE, see &lt;a href=&#34;https://spark.apache.org/developer-tools.html&#34;&gt;&#34;Useful Developer Tools&#34;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Interactive Scala Shell&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to start using Spark is through the Scala shell:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/spark-shell&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Try the following command, which should return 1,000,000,000:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;scala&amp;gt; spark.range(1000 * 1000 * 1000).count()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Interactive Python Shell&lt;/h2&gt; &#xA;&lt;p&gt;Alternatively, if you prefer Python, you can use the Python shell:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/pyspark&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And run the following command, which should also return 1,000,000,000:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; spark.range(1000 * 1000 * 1000).count()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example Programs&lt;/h2&gt; &#xA;&lt;p&gt;Spark also comes with several sample programs in the &lt;code&gt;examples&lt;/code&gt; directory. To run one of them, use &lt;code&gt;./bin/run-example &amp;lt;class&amp;gt; [params]&lt;/code&gt;. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/run-example SparkPi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;will run the Pi example locally.&lt;/p&gt; &#xA;&lt;p&gt;You can set the MASTER environment variable when running examples to submit examples to a cluster. This can be a mesos:// or spark:// URL, &#34;yarn&#34; to run on YARN, and &#34;local&#34; to run locally with one thread, or &#34;local[N]&#34; to run locally with N threads. You can also use an abbreviated class name if the class is in the &lt;code&gt;examples&lt;/code&gt; package. For instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;MASTER=spark://host:7077 ./bin/run-example SparkPi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Many of the example programs print usage help if no params are given.&lt;/p&gt; &#xA;&lt;h2&gt;Running Tests&lt;/h2&gt; &#xA;&lt;p&gt;Testing first requires &lt;a href=&#34;https://raw.githubusercontent.com/apache/spark/master/#building-spark&#34;&gt;building Spark&lt;/a&gt;. Once Spark is built, tests can be run using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./dev/run-tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please see the guidance on how to &lt;a href=&#34;https://spark.apache.org/developer-tools.html#individual-tests&#34;&gt;run tests for a module, or individual tests&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There is also a Kubernetes integration test, see resource-managers/kubernetes/integration-tests/README.md&lt;/p&gt; &#xA;&lt;h2&gt;A Note About Hadoop Versions&lt;/h2&gt; &#xA;&lt;p&gt;Spark uses the Hadoop core library to talk to HDFS and other Hadoop-supported storage systems. Because the protocols have changed in different versions of Hadoop, you must build Spark against the same version that your cluster runs.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to the build documentation at &lt;a href=&#34;https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn&#34;&gt;&#34;Specifying the Hadoop Version and Enabling YARN&#34;&lt;/a&gt; for detailed guidance on building for a particular distribution of Hadoop, including building for particular Hive and Hive Thriftserver distributions.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://spark.apache.org/docs/latest/configuration.html&#34;&gt;Configuration Guide&lt;/a&gt; in the online documentation for an overview on how to configure Spark.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please review the &lt;a href=&#34;https://spark.apache.org/contributing.html&#34;&gt;Contribution to Spark guide&lt;/a&gt; for information on how to get started contributing to the project.&lt;/p&gt;</summary>
  </entry>
</feed>