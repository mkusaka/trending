<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-08T01:51:52Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>debasishg/tradeioZ2</title>
    <updated>2022-08-08T01:51:52Z</updated>
    <id>tag:github.com,2022-08-08:/debasishg/tradeioZ2</id>
    <link href="https://github.com/debasishg/tradeioZ2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A disciplined way to purely functional domain models in Scala (zio 2 version)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;tradeioZ2&lt;/h1&gt; &#xA;&lt;p&gt;A disciplined way to purely functional domain models in Scala (zio 2 version)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>VirtusLab/typed-frames</title>
    <updated>2022-08-08T01:51:52Z</updated>
    <id>tag:github.com,2022-08-08:/VirtusLab/typed-frames</id>
    <link href="https://github.com/VirtusLab/typed-frames" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TypedFrames&lt;/h1&gt; &#xA;&lt;p&gt;TypedFrames is a Scala 3 wrapper around Apache Spark API which allows writing typesafe and boilerplate-free but still efficient Spark code.&lt;/p&gt; &#xA;&lt;h2&gt;How is it possible to write Spark applications in Scala 3?&lt;/h2&gt; &#xA;&lt;p&gt;Starting from the release of 3.2.0, Spark is cross-compiled also for Scala 2.13, which opens a way to using Spark from Scala 3 code, as Scala 3 projects can depend on Scala 2.13 artifacts.&lt;/p&gt; &#xA;&lt;p&gt;However, one might run into problems when trying to call a method requiring an implicit instance of Spark&#39;s &lt;code&gt;Encoder&lt;/code&gt; type. Derivation of instances of &lt;code&gt;Encoder&lt;/code&gt; relies on presence of a &lt;code&gt;TypeTag&lt;/code&gt; for a given type. However &lt;code&gt;TypeTag&lt;/code&gt;s are not generated by Scala 3 compiler anymore (and there are no plans to support this) so instances of &lt;code&gt;Encoder&lt;/code&gt; cannot be automatically synthesized in most cases.&lt;/p&gt; &#xA;&lt;p&gt;TypedFrames tries to work around this problem by using its own encoders (unrelated to Spark&#39;s &lt;code&gt;Encoder&lt;/code&gt; type) generated using Scala 3&#39;s new metaprogramming API.&lt;/p&gt; &#xA;&lt;h2&gt;How does TypedFrames make things typesafe and efficient at the same time?&lt;/h2&gt; &#xA;&lt;p&gt;TypedFrames provides thin (but strongly typed) wrappers around &lt;code&gt;DataFrame&lt;/code&gt;s, which track types and names of columns at compile time but let Catalyst perform all of its optimizations at runtime.&lt;/p&gt; &#xA;&lt;p&gt;TypedFrames uses structural types rather than case classes as data models, which gives us a lot of flexibility (no need to explicitly define a new case class when a column is added/removed/renamed!) but we still get compilation errors when we try to refer to a column which doesn&#39;t exist or can&#39;t be used in a given context.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;span&gt;âš &lt;/span&gt; This library is in its early stage of development - the syntax and type hierarchy might still change, the coverage of Spark&#39;s API is far from being complete and more tests are needed.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Add TypedFrames as a dependency to your project, e.g.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;in a file compiled with Scala CLI:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;//&amp;gt; using lib &#34;org.virtuslab::typed-frames:0.0.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;when starting Scala CLI REPL:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;scala-cli repl --dep org.virtuslab::typed-frames:0.0.1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;in &lt;code&gt;build.sbt&lt;/code&gt; in an sbt project:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies += &#34;org.virtuslab&#34; %% &#34;typed-frames&#34; % &#34;0.0.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;TypedFrames is built with Scala 3.1.3 so it&#39;s compatible with Scala 3.1.x and newer minor releases (starting from 3.2.0-RC1 you&#39;ll get code completions for names of columns in REPL and Metals!). TypedFrames transitively depends on Spark 3.2.0.&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Import the basic definitions from the API&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.virtuslab.typedframes.api.*&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Get a Spark session, e.g.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;given spark: SparkSession =&#xA;  SparkSession&#xA;    .builder()&#xA;    .master(&#34;local&#34;)&#xA;    .appName(&#34;my-spark-app&#34;)&#xA;    .getOrCreate()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Create a typed data frame in either of the two ways:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;by using &lt;code&gt;toTypedDF&lt;/code&gt; extension method on a &lt;code&gt;Seq&lt;/code&gt; of case classes, e.g.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;Seq(Foo(1, &#34;abc&#34;), Foo(2, &#34;xyz&#34;)).toTypedDF&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;by taking a good old (untyped) data frame and calling &lt;code&gt;typed&lt;/code&gt; extension method on it with a type parameter representing a case class, e.g.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;df.typed[Foo]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In case you needed to get back to the unsafe world of untyped data frames for some reason, just call &lt;code&gt;.untyped&lt;/code&gt; on a typed data frame.&lt;/p&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Follow your intuition of a Spark developer &lt;span&gt;ðŸ˜‰&lt;/span&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This library intends to maximally resemble the original API of Spark (e.g. by using the same names of methods, etc.) where possible, although trying to make the code feel more like regular Scala without unnecessary boilerplate and adding some other syntactic improvements.&lt;/p&gt; &#xA;&lt;p&gt;Most important differences:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Refer to columns (also with prefixes specifying the alias for a dataframe in case of ambiguities) simply with &lt;code&gt;$.foo.bar&lt;/code&gt; instead of &lt;code&gt;$&#34;foo.bar&#34;&lt;/code&gt; or &lt;code&gt;col(&#34;foo.bar&#34;)&lt;/code&gt;. Use backticks when necessary, e.g. &lt;code&gt;$.`column with spaces` &lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;From inside of &lt;code&gt;.select(...)&lt;/code&gt; or &lt;code&gt;.select{...}&lt;/code&gt; you should return something that is a named column or a tuple of named columns. Because of how Scala syntax works you can write simply &lt;code&gt;.select($.x, $.y)&lt;/code&gt; instead of &lt;code&gt;select(($.x, $.y))&lt;/code&gt;. With braces you can compute intermediate values like&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;.select {&#xA;  val sum = ($.x + $.y).as(&#34;sum&#34;)&#xA;  ($.x, $.y, sum)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Syntax for joins looks slightly more like SQL, but with dots and parentheses as for usual method calls, e.g.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;foos.innerJoin(bars).on($.foos.barId === $.bars.id).select(...)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;As you might have noticed above, the aliases for &lt;code&gt;foos&lt;/code&gt; and &lt;code&gt;bars&lt;/code&gt; were automatically inferred&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;For reference look at the &lt;a href=&#34;https://raw.githubusercontent.com/VirtusLab/typed-frames/main/src/test/example/&#34;&gt;examples&lt;/a&gt; and the &lt;a href=&#34;https://virtuslab.github.io/typed-frames/&#34;&gt;API docs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Local development&lt;/h2&gt; &#xA;&lt;p&gt;This project is built using &lt;a href=&#34;https://scala-cli.virtuslab.org/&#34;&gt;scala-cli&lt;/a&gt; so just use the traditional commands with &lt;code&gt;.&lt;/code&gt; as root like &lt;code&gt;scala-cli compile .&lt;/code&gt; or &lt;code&gt;scala-cli test .&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>