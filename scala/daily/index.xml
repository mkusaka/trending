<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-19T01:55:47Z</updated>
  <subtitle>Daily Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>meta-soul/LakeSoul</title>
    <updated>2022-07-19T01:55:47Z</updated>
    <id>tag:github.com,2022-07-19:/meta-soul/LakeSoul</id>
    <link href="https://github.com/meta-soul/LakeSoul" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Table Structure Storage on Data Lakes to Unify Batch and Streaming Data Processing&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-soul/LakeSoul/main/README-CN.md&#34;&gt;CN Doc&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;LakeSoul&lt;/h1&gt; &#xA;&lt;p&gt;LakeSoul is a unified streaming and batch table storage for fast data processing built on top of the Apache Spark engine by the &lt;a href=&#34;https://www.dmetasoul.com&#34;&gt;DMetaSoul&lt;/a&gt; team, and supports scalable metadata management, ACID transactions, efficient and flexible upsert operation, schema evolution, and streaming &amp;amp; batch unification. &lt;img src=&#34;https://raw.githubusercontent.com/meta-soul/LakeSoul/main/doc/LakeSoul.png&#34; alt=&#34;LakeSoul Arch&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;LakeSoul implements incremental upserts for both row and column and allows concurrent updates on the same partition. LakeSoul uses LSM-Tree like structure to support updates on hash partitioning table with primary key, and achieve very high write throughput (30MB/s/core) on cloud object store like S3 while providing optimized merge on read performance. LakeSoul scales meta data management by using distributed NoSQL DB Cassandra.&lt;/p&gt; &#xA;&lt;p&gt;More detailed features please refer to our wiki page: &lt;a href=&#34;https://raw.githubusercontent.com/meta-soul/wiki/Home&#34;&gt;Wiki Home&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Usage Documentations&lt;/h1&gt; &#xA;&lt;p&gt;Please find usage documentations in project&#39;s wiki: &lt;a href=&#34;https://raw.githubusercontent.com/meta-soul/wiki/Usage-Doc&#34;&gt;Usage Doc&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-soul/wiki/%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3&#34;&gt;使用文档&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Follow the &lt;a href=&#34;https://raw.githubusercontent.com/meta-soul/wiki/QuickStart&#34;&gt;Quick Start&lt;/a&gt; to quickly set up a test env.&lt;/p&gt; &#xA;&lt;p&gt;Checkout the &lt;a href=&#34;https://raw.githubusercontent.com/meta-soul/LakeSoul/main/examples/cdc_ingestion_debezium&#34;&gt;CDC Ingestion with Debezium and Kafka&lt;/a&gt; example on how to sync LakeSoul table with OLTP dbs like MySQL in a realtime manner.&lt;/p&gt; &#xA;&lt;h1&gt;Feature Roadmap&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Meta Management &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multiple Level Partitioning: Multiple range partition and at most one hash partition&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Concurrent write with auto conflict resolution&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; MVCC with read isolation&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Write transaction through Postgres Transaction&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Table operations &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; LSM-Tree style upsert for hash partitioned table&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Merge on read for hash partition with upsert delta file&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Copy on write update for non hash partitioned table&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Compaction&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Spark Integration &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Table/Dataframe API&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; SQL support with catalog except upsert&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Query optimization &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Shuffle/Join elimination for operations on primary key&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Merge UDF (Merge operator)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Merge Into SQL support &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Merge Into SQL with match on Primary Key (Merge on read)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Merge Into SQL with match on non-pk&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Merge Into SQL with match condition and complex expression (Merge on read when match on PK)&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Flink Integration &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Table API&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Flink CDC&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Hive Integration &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Export to Hive partition after compaction&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Realtime Data Warehousing &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CDC ingestion&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Time Travel (Snapshot read)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Snapshot rollback&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; MPP Engine Integration &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Presto&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Apache Doris&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Cloud Native &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Object storage IO optimization&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Multi-layer storage classes support with data tiering&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Community guidelines&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-soul/LakeSoul/main/community-guideline.md&#34;&gt;Community guidelines&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Feedback and Contribution&lt;/h1&gt; &#xA;&lt;p&gt;Please feel free to open an issue or dicussion if you have any questions.&lt;/p&gt; &#xA;&lt;p&gt;Join our &lt;a href=&#34;https://join.slack.com/t/dmetasoul-user/shared_invite/zt-1681xagg3-4YouyW0Y4wfhPnvji~OwFg&#34;&gt;slack user group&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Contact Us&lt;/h1&gt; &#xA;&lt;p&gt;Email us at &lt;a href=&#34;mailto:opensource@dmetasoul.com&#34;&gt;opensource@dmetasoul.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Opensource License&lt;/h1&gt; &#xA;&lt;p&gt;LakeSoul is opensourced under Apache License v2.0.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OSCPU/NutShell</title>
    <updated>2022-07-19T01:55:47Z</updated>
    <id>tag:github.com,2022-07-19:/OSCPU/NutShell</id>
    <link href="https://github.com/OSCPU/NutShell" rel="alternate"></link>
    <summary type="html">&lt;p&gt;RISC-V SoC designed by students in UCAS&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NutShell (果壳)&lt;/h1&gt; &#xA;&lt;p&gt;NutShell is a processor developed by the OSCPU (Open Source Chip Project by University) team.&lt;/p&gt; &#xA;&lt;p&gt;Currently it supports riscv64/32.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/OSCPU/NutShell-doc&#34;&gt;here&lt;/a&gt; for the documents.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/OSCPU/NutShell/master/#history&#34;&gt;the History and Naming section&lt;/a&gt; for naming issue.&lt;/p&gt; &#xA;&lt;h2&gt;Demo: &lt;a href=&#34;https://raw.githubusercontent.com/OSCPU/NutShell/master/debian_on_fpga.gif&#34;&gt;Running Debian on FPGA&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OSCPU/NutShell/master/debian_on_fpga.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Compile chisel code&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install &lt;code&gt;mill&lt;/code&gt;. Refer to &lt;a href=&#34;https://com-lihaoyi.github.io/mill/&#34;&gt;the Manual section in this guide&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;make&lt;/code&gt; to generate verilog code. The output file is &lt;code&gt;build/TopMain.v&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Run programs by simulation&lt;/h2&gt; &#xA;&lt;p&gt;You can either use our ready-to-run image for simulation or build image yourself.&lt;/p&gt; &#xA;&lt;p&gt;To use ready-to run image (recommended) :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run &lt;code&gt;make emu&lt;/code&gt; to launch simulation. Default image is linux kernel.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;make IMAGE=yourimage.bin emu&lt;/code&gt; to specify your image file. We have provided some in ./ready-to-run.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To build image yourself:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Set a new environment variable &lt;code&gt;NEMU_HOME&lt;/code&gt; to the &lt;strong&gt;absolute path&lt;/strong&gt; of the &lt;a href=&#34;https://github.com/OpenXiangShan/NEMU&#34;&gt;NEMU project&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Set a new environment variable &lt;code&gt;NUTSHELL_HOME&lt;/code&gt; to the &lt;strong&gt;absolute path&lt;/strong&gt; of the NutShell project.&lt;/li&gt; &#xA; &lt;li&gt;Clone the &lt;a href=&#34;https://github.com/OSCPU/nexus-am.git&#34;&gt;AM project&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Set a new environment variable &lt;code&gt;AM_HOME&lt;/code&gt; to the &lt;strong&gt;absolute path&lt;/strong&gt; of the AM project.&lt;/li&gt; &#xA; &lt;li&gt;Run the application in the AM project by &lt;code&gt;make ARCH=riscv64-nutshell run&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd nexus-am/apps/microbench&#xA;make ARCH=riscv64-nutshell mainargs=test run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Run on FPGA&lt;/h2&gt; &#xA;&lt;h3&gt;Sub-directories Overview&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;fpga&#xA;├── board              # supported FPGA boards and files to build a Vivado project&#xA;├── boot               # PS boot flow of zynq and zynqmp&#xA;├── lib                # HDL sources shared by different boards&#xA;├── Makefile&#xA;├── Makefile.check&#xA;└── NutShell.tcl       # wrapper of NutShell core in the Vivado project&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Build a Vivado project&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install Vivado 2019.1, and source the setting of Vivado and SDK&lt;/li&gt; &#xA; &lt;li&gt;Run the following command to build a Vivado project&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd fpga&#xA;make PRJ=myproject BOARD=pynq STANDALONE=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Change &lt;code&gt;pynq&lt;/code&gt; to the target board you want. Supported boards are listed under &lt;code&gt;board/&lt;/code&gt;. The project will be created under &lt;code&gt;board/pynq/build/myproject-pynq&lt;/code&gt;. Please note that STANDALONE mode is only used in &lt;code&gt;pynq&lt;/code&gt; board.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Open the project with Vivado and generate bitstream.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Prepare SD card&lt;/h3&gt; &#xA;&lt;p&gt;Refer to the instructions of &lt;a href=&#34;https://raw.githubusercontent.com/OSCPU/NutShell/master/fpga/boot/README.md&#34;&gt;fpga/boot/README.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;NOTE: Remember to put the bitstream into BOOT.BIN, since the guide is going to boot everything from SD card.&lt;/p&gt; &#xA;&lt;h3&gt;Set your board to SD boot mode&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to the user guide of your board.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.zedboard.org/sites/default/files/ZedBoard_HW_UG_v1_1.pdf&#34;&gt;zedboard&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.xilinx.com/support/documentation/boards_and_kits/zcu102/ug1182-zcu102-eval-bd.pdf&#34;&gt;zcu102&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://sidewinder.fidus.com&#34;&gt;sidewinder&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ultraZ (currently not avaliable to the public)&lt;/li&gt; &#xA; &lt;li&gt;axu3cg (currently not avaliable to the public)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Boot linux in PS&lt;/h3&gt; &#xA;&lt;p&gt;Just insert the SD card into the board, open a serial terminal and powerup the board.&lt;/p&gt; &#xA;&lt;h3&gt;Boot NutShell (the RISC-V subsystem)&lt;/h3&gt; &#xA;&lt;p&gt;To boot the RISC-V subsystem&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Send &lt;code&gt;fpga/resource/ddr-loader/ddr-loader.c&lt;/code&gt; to PS. This can be achieved by either copying the file to SD card, or by sending the file with &lt;code&gt;scp&lt;/code&gt; if you have your board connected to your host by network.&lt;/li&gt; &#xA; &lt;li&gt;Compile the loader by gcc on PS.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;gcc -O2 -o ddr-loader ddr-loader.c&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Send the RISC-V program (bin file, should start at 0x80000000) to PS.&lt;/li&gt; &#xA; &lt;li&gt;Open minicom on PS to connect to the UART of NutShell. Note that you can connect to PS via &lt;code&gt;ssh&lt;/code&gt; and use &lt;code&gt;tmux&lt;/code&gt; to get multiple terminals.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;minicom -D /dev/ttyUL1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use the loader to load the program to NutShell memory and start running NutShell.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;./ddr-loader $(YOUR_BOARD) bin-file&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To shutdown the board, first run &lt;code&gt;poweroff&lt;/code&gt; in PS.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;history&#34;&gt;&lt;/a&gt; History and Naming&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Is NutShell developed from scratch?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;No. NutShell is originally based on the NOOP project, an educational RV32 SoC designed by Nanjing University (NJU). At 2019/08/27, the OSCPU team decided to start a new project based on a fork of NOOP.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Why was there only one contributor in this repo before 2019/08/27?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;NOOP was maintained by &lt;a href=&#34;https://github.com/sashimi-yzh&#34;&gt;sashimi-yzh&lt;/a&gt; on behalf of NJU before 2019/08/27.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What is the different between NutShell and NOOP?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Undergraduate students in the OSCPU team planned to enhance the educational SoC to a fully functional RV64 SoC, on behalf of University of Chinese Academy of Sciences (UCAS, 中国科学院大学). The goal was to boot Linux + Debian and tapeout the chip. Students have put a lot of effort into achieving such a goal.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Where can I find the original NOOP repo?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;NOOP is designed as a programming assignment for educational purpose. It is still unstable and may be redesigned every year. Therefore there is no official release for NOOP yet.&lt;/p&gt; &#xA;&lt;p&gt;But here are some reference implementations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Code in this NutShell repo before 2019/08/27 can be considered as NOOP designed in 2019.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nju-mips/noop-lo&#34;&gt;Here&lt;/a&gt; is an implementation of NOOP designed by students in NJU at 2018. This is the CPU design which won the 2nd prize in LoongsonCup18. It is designed with Chisel, too. But note that the ISA is mips32, since the contest is held by Loongson. Also the implementation is very different from the one above.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Why can I still find the name NOOP in the code as well as the commit logs after 2019/08/27?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;During the development, the OSCPU team has not yet thought of a good name for the SoC. Before this repo is available to the public, they finally decide to name the SoC NutShell. In Chinese, NutShell (果壳) and the nickname of UCAS (国科大) are similar in pronunciation. The name NutShell is welcomed by every student in UCAS.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;I found a name Argo in the code as well as the commit logs. What is it?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Argo is the name of a dual-issued OoO core designed by &lt;a href=&#34;https://github.com/AugustusWillisWang&#34;&gt;AugustusWillisWang&lt;/a&gt;. AugustusWillisWang is one of the students who develop NutShell. Argo is designed based on NutShell, and they share the same SoC architecture.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;I found a name COOSCA in the commit logs. What is it?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;COOSCA is an internal name of the SoC. Students in the team want a better name, so there comes NutShell. The name COOSCA should be rarely presented in the repo.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>locationtech/geotrellis</title>
    <updated>2022-07-19T01:55:47Z</updated>
    <id>tag:github.com,2022-07-19:/locationtech/geotrellis</id>
    <link href="https://github.com/locationtech/geotrellis" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GeoTrellis is a geographic data processing engine for high performance applications.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GeoTrellis&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/locationtech/geotrellis/actions&#34;&gt;&lt;img src=&#34;https://github.com/locationtech/geotrellis/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://circleci.com/gh/locationtech/geotrellis/tree/master&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/locationtech/geotrellis/tree/master.svg?style=svg&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/geotrellis/geotrellis?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/Join%20Chat.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/geotrellis/geotrellis&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://geotrellis.readthedocs.io/en/latest/&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/geotrellis/badge/?version=latest&#34; alt=&#34;ReadTheDocs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/locationtech/geotrellis/raw/master/CHANGELOG.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/changelog-v1.2.0-brightgreen.svg?sanitize=true&#34; alt=&#34;Changelog&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/locationtech/geotrellis/raw/master/docs/CONTRIBUTING.rst&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/contributing-see%20conditions-brightgreen.svg?sanitize=true&#34; alt=&#34;Contributing&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://search.maven.org/#search%7Cga%7C1%7Corg.locationtech.geotrellis&#34;&gt;&lt;img src=&#34;https://img.shields.io/maven-central/v/org.locationtech.geotrellis/geotrellis-spark_2.12&#34; alt=&#34;Maven Central&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://oss.sonatype.org/content/repositories/snapshots/org/locationtech/geotrellis/geotrellis-spark_2.12/&#34;&gt;&lt;img src=&#34;https://img.shields.io/nexus/s/https/oss.sonatype.org/org.locationtech.geotrellis/geotrellis-spark_2.12.svg?sanitize=true&#34; alt=&#34;Snapshots&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;GeoTrellis&lt;/em&gt; is a Scala library and framework that provides APIs for reading, writing and operating on geospatial raster and vector data. GeoTrellis also provides helpers for these same operations in Spark and for performing &lt;a href=&#34;https://en.wikipedia.org/wiki/Map_algebra&#34;&gt;MapAlgebra&lt;/a&gt; operations on rasters. It is released under the Apache 2 License.&lt;/p&gt; &#xA;&lt;p&gt;Please visit the &lt;strong&gt;&lt;a href=&#34;http://geotrellis.io&#34;&gt;project site&lt;/a&gt;&lt;/strong&gt; for more information as well as some interactive demos.&lt;/p&gt; &#xA;&lt;p&gt;You&#39;re also welcome to ask questions and talk to developers (let us know what you&#39;re working on!) via &lt;a href=&#34;https://gitter.im/geotrellis/geotrellis&#34;&gt;Gitter&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;GeoTrellis is currently available for Scala 2.11 and 2.12, using Spark 2.4.x.&lt;/p&gt; &#xA;&lt;p&gt;To get started with SBT, simply add the following to your build.sbt file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies += &#34;org.locationtech.geotrellis&#34; %% &#34;geotrellis-raster&#34; % &#34;&amp;lt;latest version&amp;gt;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To grab the latest &lt;code&gt;SNAPSHOT&lt;/code&gt;, &lt;code&gt;RC&lt;/code&gt; or milestone build, add these resolvers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// maven central snapshots&#xA;resolvers ++= Seq(&#xA;  &#34;sonatype-snapshot&#34; at &#34;https://oss.sonatype.org/content/repositories/snapshots/&#34;&#xA;)&#xA;&#xA;// or eclipse snapshots&#xA;resolvers ++= Seq(&#xA;  &#34;eclipse-releases&#34; at &#34;https://repo.eclipse.org/content/groups/releases&#34;,&#xA;  &#34;eclipse-snapshots&#34; at &#34;https://repo.eclipse.org/content/groups/snapshots&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are just getting started with GeoTrellis, we recommend familiarizing yourself with the &lt;code&gt;geotrellis-raster&lt;/code&gt; package, but it is just one of the many available. The complete list of published GeoTrellis packages includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-accumulo&lt;/code&gt;: Accumulo store integration for GeoTrellis&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-accumulo-spark&lt;/code&gt;: Accumulo store integration for GeoTrellis + Spark&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-cassandra&lt;/code&gt;: Cassandra store integration for GeoTrellis&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-cassandra-spark&lt;/code&gt;: Cassandra store integration for GeoTrellis + Spark&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-gdal&lt;/code&gt;: GDAL bindings for GeoTrellis&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-geotools&lt;/code&gt;: Conversions to and from GeoTools Vector and Raster data&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-hbase&lt;/code&gt;: HBase store integration for GeoTrellis&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-hbase-spark&lt;/code&gt;: HBase store integration for GeoTrellis + Spark&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-layer&lt;/code&gt;: Datatypes to describe sets of rasters&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-macros&lt;/code&gt;: Performance optimizations for GeoTrellis operations&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-proj4&lt;/code&gt;: Coordinate Reference systems and reproject (Scala wrapper around Proj4j)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-raster&lt;/code&gt;: Raster data types and operations, including MapAlgebra&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-raster-testkit&lt;/code&gt;: Testkit for testing &lt;code&gt;geotrellis-raster&lt;/code&gt; types&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-s3&lt;/code&gt;: Amazon S3 store integration for GeoTrellis&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-s3-spark&lt;/code&gt;: Amazon S3 store integration for GeoTrellis + Spark&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-shapefile&lt;/code&gt;: Read ESRI Shapefiles into GeoTrellis data types via GeoTools&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-spark&lt;/code&gt;: Geospatially enables Spark and provides primitives for external data stores&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-spark-pipeline&lt;/code&gt;: DSL for geospatial ingest jobs using GeoTrellis + Spark&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-spark-testkit&lt;/code&gt;: Testkit for testing &lt;code&gt;geotrellis-spark&lt;/code&gt; code&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-store&lt;/code&gt;: Abstract interfaces for storage services, with concrete implementations for local and Hadoop filesystems&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-util&lt;/code&gt;: Miscellaneous GeoTrellis helpers&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-vector&lt;/code&gt;: Vector data types and operations extending JTS&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-vector-testkit&lt;/code&gt;: Testkit for testing &lt;code&gt;geotrellis-vector&lt;/code&gt; types&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;geotrellis-vectortile&lt;/code&gt;: Experimental vector tile support, including reading and writing&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A more complete feature list can be found on the &lt;a href=&#34;https://geotrellis.readthedocs.io/en/latest/guide/module-hierarchy.html&#34;&gt;Module Hierarchy page&lt;/a&gt; of the GeoTrellis documentation. If you&#39;re looking for a specific feature or operation, we suggest searching there or reaching out on Gitter.&lt;/p&gt; &#xA;&lt;p&gt;For older releases, check the complete list of packages and versions available at &lt;a href=&#34;https://repo.locationtech.org/#view-repositories;geotrellis-releases~browsestorage&#34;&gt;locationtech-releases&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Hello Raster&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;scala&amp;gt; import geotrellis.raster._&#xA;import geotrellis.raster._&#xA;&#xA;scala&amp;gt; import geotrellis.raster.render.ascii._&#xA;import geotrellis.raster.render.ascii._&#xA;&#xA;scala&amp;gt; import geotrellis.raster.mapalgebra.focal._&#xA;import geotrellis.raster.mapalgebra.focal._&#xA;&#xA;scala&amp;gt; val nd = NODATA&#xA;nd: Int = -2147483648&#xA;&#xA;scala&amp;gt; val input = Array[Int](&#xA;     nd, 7, 1, 1,  3, 5, 9, 8, 2,&#xA;      9, 1, 1, 2,  2, 2, 4, 3, 5,&#xA;      3, 8, 1, 3,  3, 3, 1, 2, 2,&#xA;      2, 4, 7, 1, nd, 1, 8, 4, 3)&#xA;input: Array[Int] = Array(-2147483648, 7, 1, 1, 3, 5, 9, 8, 2, 9, 1, 1, 2,&#xA;2, 2, 4, 3, 5, 3, 8, 1, 3, 3, 3, 1, 2, 2, 2, 4, 7, 1, -2147483648, 1, 8, 4, 3)&#xA;&#xA;scala&amp;gt; val iat = IntArrayTile(input, 9, 4)  // 9 and 4 here specify columns and rows&#xA;iat: geotrellis.raster.IntArrayTile = IntArrayTile([I@278434d0,9,4)&#xA;&#xA;// The renderAscii method is mostly useful when you&#39;re working with small tiles&#xA;// which can be taken in at a glance.&#xA;scala&amp;gt; iat.renderAscii(AsciiArtEncoder.Palette.STIPLED)&#xA;res0: String =&#xA;∘█  ▚▜██▖&#xA;█  ▖▖▖▜▚▜&#xA;▚█ ▚▚▚ ▖▖&#xA;▖▜█ ∘ █▜▚&#xA;&#xA;scala&amp;gt; val focalNeighborhood = Square(1)  // a 3x3 square neighborhood&#xA;focalNeighborhood: geotrellis.raster.op.focal.Square =&#xA; O  O  O&#xA; O  O  O&#xA; O  O  O&#xA;&#xA;scala&amp;gt; val meanTile = iat.focalMean(focalNeighborhood)&#xA;meanTile: geotrellis.raster.Tile = DoubleArrayTile([D@7e31c125,9,4)&#xA;&#xA;scala&amp;gt; meanTile.getDouble(0, 0)  // Should equal (1 + 7 + 9) / 3&#xA;res1: Double = 5.666666666666667&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Documentation is available at &lt;a href=&#34;https://geotrellis.io/documentation&#34;&gt;geotrellis.io/documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Scaladocs&lt;/em&gt; for the the &lt;code&gt;master&lt;/code&gt; branch are &lt;a href=&#34;https://geotrellis.github.io/scaladocs/latest/geotrellis/index.html?search=geotrellis&#34;&gt;available here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Further examples and documentation of GeoTrellis use-cases can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/locationtech/geotrellis/master/docs&#34;&gt;docs/&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Feedback and contributions to the project, no matter what kind, are always very welcome. A CLA is required for contribution, see &lt;a href=&#34;http://geotrellis.readthedocs.io/en/latest/CONTRIBUTING.html&#34;&gt;Contributing&lt;/a&gt; for more information. Please refer to the &lt;a href=&#34;http://docs.scala-lang.org/style/&#34;&gt;Scala style guide&lt;/a&gt; for formatting patches to the codebase.&lt;/p&gt; &#xA;&lt;h3&gt;Where is our commit history and contributor list prior to Nov 2016?&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;The entire old history is available in the &lt;code&gt;_old/master&lt;/code&gt; branch.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Why?&lt;/h4&gt; &#xA;&lt;p&gt;In November 2016, GeoTrellis moved it&#39;s repository from the &lt;a href=&#34;https://github.com/geotrellis&#34;&gt;GeoTrellis GitHub Organization&lt;/a&gt; to it&#39;s current home in the LocationTech GitHub organization. In the process of moving our repository, we went through an IP review process. Because the Eclipse foundation only reviews a snapshot of the repository, and not all of history, we had to start from a clean &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; &#xA;&lt;p&gt;Unfortunately, we lost our commit and contributor count in the move. These are significant statistics for a repository, and our current counts make us look younger than we are. GeoTrellis has been an open source project since 2011. This is what our contributor and commit count looked like before the move to LocationTech:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/locationtech/geotrellis/master/docs/img/contributor-and-commit-count-pre-locationtech.png&#34; alt=&#34;Commit and contributor count before LocationTech move&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Along with counts, we want to make sure that all the awesome people who contributed to GeoTrellis before the LocationTech move can still be credited on a contributors page. For posterity, I will leave the following contributors page to what it was before the move:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lossyrob/geotrellis-before-locationtech/graphs/contributors&#34;&gt;https://github.com/lossyrob/geotrellis-before-locationtech/graphs/contributors&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Tie Local History to Old History&lt;/h4&gt; &#xA;&lt;p&gt;You can also tie your local clone&#39;s master history to the old history by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;&amp;gt; git fetch origin refs/replace/*:refs/replace/*&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;if &lt;code&gt;origin&lt;/code&gt; points to &lt;a href=&#34;https://github.com/locationtech/geotrellis&#34;&gt;https://github.com/locationtech/geotrellis&lt;/a&gt;. This will allow you to see the old history for commands like &lt;code&gt;git log&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>