<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-04T01:47:40Z</updated>
  <subtitle>Weekly Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ucb-bar/hwacha</title>
    <updated>2022-09-04T01:47:40Z</updated>
    <id>tag:github.com,2022-09-04:/ucb-bar/hwacha</id>
    <link href="https://github.com/ucb-bar/hwacha" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Microarchitecture implementation of the decoupled vector-fetch accelerator&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Hwacha Vector-Thread Co-Processor Sources&lt;/h1&gt; &#xA;&lt;p&gt;To use this co-processor, include this repo as a git submodule and add it as to your chip&#39;s &lt;code&gt;build.sbt&lt;/code&gt; as a Project, e.g.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;lazy val hwacha = Project(file(&#34;hwacha&#34;), &#34;hwacha&#34;)&#xA;  .settings(buildSettings)&#xA;  .dependsOn(rocketchip)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Hwacha depends on the Rocket Chip project. Make sure the proper JARs are installed. For more information on how to use this co-processor, refer to (&lt;a href=&#34;https://github.com/ucb-bar/chipyard&#34;&gt;https://github.com/ucb-bar/chipyard&lt;/a&gt;).&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>oap-project/gluten</title>
    <updated>2022-09-04T01:47:40Z</updated>
    <id>tag:github.com,2022-09-04:/oap-project/gluten</id>
    <link href="https://github.com/oap-project/gluten" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h5&gt;* LEGAL NOTICE: Your use of this software and any required dependent software (the &#34;Software Package&#34;) is subject to the terms and conditions of the software license agreements for the Software Package, which may also include notices, disclaimers, or license terms for third party or open source software included in or with the Software Package, and your use indicates your acceptance of all such terms. Please refer to the &#34;TPP.txt&#34; or other similarly-named text file included with the Software Package for additional details.&lt;/h5&gt; &#xA;&lt;h5&gt;* Optimized Analytics Package for Spark* Platform is under Apache 2.0 (&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;).&lt;/h5&gt; &#xA;&lt;h1&gt;Introduction&lt;/h1&gt; &#xA;&lt;p&gt;This is a derived project from Gazelle-plugin. The JVM code and native code in Gazelle-plugin is tightly coupled. Which make it very hard to utilize other native SQL libraries. The main goal of this project is to decouple Spark JVM and JNI layer from native SQL execution engine. So we can easily enable different native SQL libraries but share all the common JVM code like fallback logic.&lt;/p&gt; &#xA;&lt;h5&gt;The basic rule of the native offloading is that we would reuse spark&#39;s whole control flow and as many JVM code as possible but offload the compute intensive data processing part to native code.&lt;/h5&gt; &#xA;&lt;p&gt;The overview chart is like below. Spark physical plan is transformed to substrait plan. Substrait is to create a well defined cross-language specification for data compute operations. More details can be found from &lt;a href=&#34;https://substrait.io/&#34;&gt;https://substrait.io/&lt;/a&gt;. Then substrait plan is passed to native through JNI call. In native the operator chain should be built and start to run. We use Spark3.0&#39;s columnar API as the data interface, so the native library should return Columnar Batch to Spark. We may need to wrap the columnar batch for each native backend. Gazelle engine&#39;s c++ code use Apache Arrow data format as its basic data format, so the returned data to Spark JVM is ArrowColumnarBatch.&lt;/p&gt; &#xA;&lt;p&gt;There are several native libraries we may offload. Currently we are working on the Gazelle&#39;s C++ library and Velox as native backend. Velox is a C++ database acceleration library which provides reusable, extensible, and high-performance data processing components. More details can be found from &lt;a href=&#34;https://github.com/facebookincubator/velox/&#34;&gt;https://github.com/facebookincubator/velox/&lt;/a&gt;. We can also easily use Arrow Computer Engine or any accelerator libraries as backend.&lt;/p&gt; &#xA;&lt;h5&gt;Before we enable Gazelle&#39;s C++ code as backend, we will continue Gazelle&#39;s development.&lt;/h5&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/image/gluten.png&#34; alt=&#34;Overview&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;One big issue we noted during our Gazelle-plugin development is that we can&#39;t easily and exactly reproduce a Spark stage. Once we meet some bugs during Spark run, Gazelle-plugin doesn&#39;t dump enough info to reproduce it natively. Mainly because we use very complex extended Gandiva tree to pass the query plan. With well defined substrait and some helper functions, we can easily reproduce the whole stage, which makes debug, profile and optimize the native code much more easier. It also make the accelerators enabling much more easier even without touching Spark code.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/image/reproduce_natively.png&#34; alt=&#34;Overview&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Plan Build&lt;/h1&gt; &#xA;&lt;p&gt;To convert Spark&#39;s physical plan into Substrait plan, we defined a substrait transformer operator which is a wrapper of the tree of operators to be executed natively. The operator&#39;s doTransform function return the final substrait tree. doExecutorColumnar function execute the native node and return columnarBatch. Each operator has its own transformerExec which transforms this operator&#39;s plan node into a substrait plan node by transform function. The validate function is designed to check if native library support the operator. The whole process is very like Spark&#39;s whole stage code generation flow.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/image/operators.png&#34; alt=&#34;Overview&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The generated substrait plan can be single operator or a tree of operators depending on if the native library has the support. Once an operator isn&#39;t supported in native, we will fallback it to Vanilla Spark. In this way the data should be converted to unsafe row format by Columanr2Row operator. Later if the following operators can be support in native, we can add Row2Columnar operator to convert unsafe row format into native columnar format. The native implementation of the two operators can be much faster than Spark&#39;s stock ones. We have implemented them in Gazelle-plugin and will port to here later.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/image/overall_design.png&#34; alt=&#34;Overview&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Execution Flow&lt;/h1&gt; &#xA;&lt;p&gt;A simple example of execution flow is as below chart. The transformer operator transforms Spark&#39;s physical plan into Substrait. In native the operators are called according to the plan. The last native operator should return an batch which is passed to JVM. We reuse Spark&#39;s current shuffle logic but convert data into columnar format. The data split logic should be implemented natively and called by columnar shuffle operator. From Gazelle-plugin&#39;s experience the operation is expensive.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/image/flow.png&#34; alt=&#34;Overview&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Issues to Solve and status&lt;/h1&gt; &#xA;&lt;p&gt;The code is still not completely cleaned now. The work is still WIP.&lt;/p&gt; &#xA;&lt;p&gt;Not all the operators and functions are added. 22 queries of TPCH can pass. We are working on TPCDS queries.&lt;/p&gt; &#xA;&lt;p&gt;Operator stat info is pretty useful to understand Spark&#39;s execution status. Velox metrics are already added to Spark metric list for Velox backend. More info about Velox&#39;s stat can be found here: &lt;a href=&#34;https://facebookincubator.github.io/velox/develop/debugging/print-plan-with-stats.html&#34;&gt;https://facebookincubator.github.io/velox/develop/debugging/print-plan-with-stats.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Memory management is an essential feature in Spark. It&#39;s even more important to Spark Native runtime. Unlike JVM, not all OOM error can be captured which leads to ugly segment fault error in strange places like JNI call. We need to register each (large) memory allocation in executor&#39;s memory management service. Spark can control the memory used in each task. We have implemented the memory pool which apply for block of memory from Spark&#39;s memory management before real allocation. Memory allocation in Velox backend is already tracked.&lt;/p&gt; &#xA;&lt;p&gt;Spark&#39;s RDD cache is columnar batch based. In Gazelle-plugin, we use the arrow record batch directly without any memcpy. We can build the same functionality in Gluten.&lt;/p&gt; &#xA;&lt;p&gt;Pyspark support needs to be ported as well. If input data format is Arrow, we can send the data to pyspark directly. No memcpy&lt;/p&gt; &#xA;&lt;p&gt;UDF support. We need to create the interface which use columnar batch as input. So customer can port their current UDF to columnar batch based. If it&#39;s Arrow record batch based, user can utilize Arrow&#39;s JAVA or C++ API to implement their UDF, debug without Spark, then register to Spark.&lt;/p&gt; &#xA;&lt;p&gt;Ideally if all native library can return arrow record batch, we can share much features in Spark&#39;s JVM. Spark already have Apache arrow dependency, we can make arrow format as Spark&#39;s basic columnar format. The problem is that native library may not be 100% compitable with Arrow format, then there will be a transform between their native format and Arrow, usually it&#39;s not cheap.&lt;/p&gt; &#xA;&lt;h1&gt;How to use Gluten&lt;/h1&gt; &#xA;&lt;h3&gt;Build the Environment&lt;/h3&gt; &#xA;&lt;p&gt;There are two ways to build the env for compiling OAP: Gluten&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Build by Yourself&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;h3&gt;Build by yourself&lt;/h3&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you prefer to build from the source code on your hand, please follow the steps in &lt;a href=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/GlutenInstallation.md&#34;&gt;Installation Guide&lt;/a&gt; to set up your environment.&lt;/p&gt; &#xA;&lt;h3&gt;Compile and use Gluten&lt;/h3&gt; &#xA;&lt;p&gt;Once your env being successfully deployed, please refer to &lt;a href=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/GlutenUsage.md&#34;&gt;Gluten Usage&lt;/a&gt; to compile and use Gluten in Spark.&lt;/p&gt; &#xA;&lt;h3&gt;Build Gluten with Velox backend&lt;/h3&gt; &#xA;&lt;p&gt;After Gluten being successfully deployed in your environment, if you would like to build Gluten with &lt;strong&gt;Velox&lt;/strong&gt; computing, please follow the steps in &lt;a href=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/Velox.md&#34;&gt;Build with Velox&lt;/a&gt; to install the needed libraries, compile Velox and try out the TPC-H Q6 and Q1 test.&lt;/p&gt; &#xA;&lt;h3&gt;Build Gluten with Arrow backend&lt;/h3&gt; &#xA;&lt;p&gt;If you would like to build Gluten with &lt;strong&gt;Arrow&lt;/strong&gt; backend, please follow the steps in &lt;a href=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/ArrowBackend.md&#34;&gt;Build with Arrow Backend&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Build Gluten with ClickHouse backend&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/image/ClickHouse/logo.png&#34; alt=&#34;logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you would like to build Gluten with &lt;strong&gt;ClickHouse&lt;/strong&gt; backend, please follow the steps in &lt;a href=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/ClickHouse.md&#34;&gt;Build with ClickHouse Backend&lt;/a&gt;. ClickHouse backend is devleoped by &lt;a href=&#34;https://kyligence.io/&#34;&gt;Kyligence&lt;/a&gt;, please visit &lt;a href=&#34;https://github.com/Kyligence/ClickHouse&#34;&gt;https://github.com/Kyligence/ClickHouse&lt;/a&gt; for more infomation.&lt;/p&gt; &#xA;&lt;h1&gt;Performance&lt;/h1&gt; &#xA;&lt;p&gt;We use Decision Support Benchmark1(TPC-H Like) to evaluate the performance for Gluten project.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Decision Support Benchmark1 is a query set modified from &lt;a href=&#34;http://tpc.org/tpch/default5.asp&#34;&gt;TPC-H benchmark&lt;/a&gt;. Because some features are not fully supported, there are some changes during the testing. Firstly we change column data type like Decimal to Double and Date to String. Secondly we use &lt;a href=&#34;https://github.com/oap-project/gluten/tree/main/backends-velox/workload/tpch&#34;&gt;DWRF&lt;/a&gt; file format for Velox testing &amp;amp; MergeTree file format for Clickhouse testing compared to Parquet file format as baseline. Thirdly we modify the SQLs to use double and string data type for both Gluten and baseline. backends-velox/workload/tpch has the script to reproduce the performance number for Velox backend.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The testing environment is using single node with 1TB datasize. The result shows a up to 3.63X speedup in Decision Support Benchmark1 with Gluten and Velox backend. &lt;img src=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/image/velox_decision_support_bench1_10query_performance.png&#34; alt=&#34;Performance&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The testing environment is using a 8-nodes AWS cluster with 1TB datasize. The result shows a up to 3.48X speedup in Decision Support Benchmark1 with Gluten and Clickhouse backend. &lt;img src=&#34;https://raw.githubusercontent.com/oap-project/gluten/main/docs/image/clickhouse_decision_support_bench1_10query_performance.png&#34; alt=&#34;Performance&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Reference&lt;/h1&gt; &#xA;&lt;p&gt;Please check below link for more related information. &lt;a href=&#34;https://databricks.com/dataaisummit/session/gazelle-jni-middle-layer-offload-spark-sql-native-engines-execution&#34;&gt;Gluten Intro at Data AI Summit 2022&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Contact&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;mailto:rui.mo@intel.com&#34;&gt;rui.mo@intel.com&lt;/a&gt;; &lt;a href=&#34;mailto:binwei.yang@intel.com&#34;&gt;binwei.yang@intel.com&lt;/a&gt;; &lt;a href=&#34;mailto:weiting.chen@intel.com&#34;&gt;weiting.chen@intel.com&lt;/a&gt;; &lt;a href=&#34;mailto:chang.chen@kyligence.io&#34;&gt;chang.chen@kyligence.io&lt;/a&gt;; &lt;a href=&#34;mailto:zhichao.zhang@kyligence.io&#34;&gt;zhichao.zhang@kyligence.io&lt;/a&gt;; &lt;a href=&#34;mailto:neng.liu@kyligence.io&#34;&gt;neng.liu@kyligence.io&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ucb-bar/riscv-sodor</title>
    <updated>2022-09-04T01:47:40Z</updated>
    <id>tag:github.com,2022-09-04:/ucb-bar/riscv-sodor</id>
    <link href="https://github.com/ucb-bar/riscv-sodor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;educational microarchitectures for risc-v isa&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;About The Sodor Processor Collection&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: This repo has been updated to be used with the &lt;a href=&#34;https://github.com/ucb-bar/chipyard&#34;&gt;Chipyard&lt;/a&gt; SoC Generator.&lt;/strong&gt; &lt;strong&gt;For the old self-contained version of Sodor (which is no longer maintained), see &lt;a href=&#34;https://github.com/ucb-bar/riscv-sodor/tree/sodor-old&#34;&gt;https://github.com/ucb-bar/riscv-sodor/tree/sodor-old&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Diagrams: &lt;a href=&#34;https://github.com/ucb-bar/riscv-sodor/wiki&#34;&gt;Sodor Github wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;More documentation: &lt;a href=&#34;https://github.com/librecores/riscv-sodor/wiki&#34;&gt;Librecores Sodor wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Downstream development: &lt;a href=&#34;https://github.com/librecores/riscv-sodor&#34;&gt;Librecores Sodor&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repo has been put together to demonstrate a number of simple &lt;a href=&#34;http://riscv.org&#34;&gt;RISC-V&lt;/a&gt; integer pipelines written in &lt;a href=&#34;http://chisel.eecs.berkeley.edu&#34;&gt;Chisel&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;1-stage (essentially an ISA simulator)&lt;/li&gt; &#xA; &lt;li&gt;2-stage (demonstrates pipelining in Chisel)&lt;/li&gt; &#xA; &lt;li&gt;3-stage (uses sequential memory; supports both Harvard and Princeton versions)&lt;/li&gt; &#xA; &lt;li&gt;5-stage (can toggle between fully bypassed or fully interlocked)&lt;/li&gt; &#xA; &lt;li&gt;&#34;bus&#34;-based micro-coded implementation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All of the cores implement the RISC-V 32b integer base user-level ISA (RV32I) version 2.0. None of the cores support virtual memory, and thus only implement the Machine-level (M-mode) of the Privileged ISA v1.10 .&lt;/p&gt; &#xA;&lt;p&gt;All processors talk to a simple scratchpad memory (asynchronous, single-cycle), with no backing outer memory (the 3-stage is the exception - its scratchpad is synchronous). Programs are loaded in via JTAG or TSI, scratchpads 3-port memories (instruction, data, debug).&lt;/p&gt; &#xA;&lt;p&gt;This repository is set up to use the Verilog file generated by Chisel3 which is fed to Verilator along with a test harness in C++ to generate and run the Sodor emulators.&lt;/p&gt; &#xA;&lt;p&gt;This repo works great as an undergraduate lab (and has been used by Berkeley&#39;s CS152 class for 3 semesters and counting). See doc/ for an example, as well as for some processor diagrams. Be careful though - admittedly some of those documents may become dated as things like the Privileged ISA evolve.&lt;/p&gt; &#xA;&lt;h1&gt;Getting the repo and Building the processor emulators&lt;/h1&gt; &#xA;&lt;p&gt;This repo is &lt;strong&gt;NOT&lt;/strong&gt; a self-running repository. Please follow the instruction in &lt;a href=&#34;https://chipyard.readthedocs.io/en/latest/&#34;&gt;https://chipyard.readthedocs.io/en/latest/&lt;/a&gt; to set up Chipyard and simulate Sodor cores.&lt;/p&gt; &#xA;&lt;h1&gt;FAQ&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;What is the goal of these cores?&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;First and foremost, to provide a set of easy to understand cores that users can easily modify and play with. Sodor is useful both as a quick introduction to the &lt;a href=&#34;http://riscv.org&#34;&gt;RISC-V ISA&lt;/a&gt; and to the hardware construction language &lt;a href=&#34;http://chisel.eecs.berkeley.edu&#34;&gt;Chisel3&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Are there any diagrams of these cores?&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Diagrams of some of the processors can be found either in the &lt;a href=&#34;https://github.com/ucb-bar/riscv-sodor/wiki&#34;&gt;Sodor Github wiki&lt;/a&gt;, in doc/, or in doc/lab1.pdf. A more comprehensive write-up on the micro-code implementation can be found at the &lt;a href=&#34;http://inst.eecs.berkeley.edu/~cs152/sp12/handouts/microcode.pdf&#34;&gt;CS152 website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;How do I generate Verilog code for use on a FPGA?&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Chisel3 outputs verilog by default which can be generated by&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd emulator/rv32_1stage&#xA;make generated-src/Top.v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;I want to help! Where do I go?&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can participate in the Sodor conversation on &lt;a href=&#34;https://gitter.im/librecores/riscv-sodor&#34;&gt;gitter&lt;/a&gt;. Downstream development is also taking place at &lt;a href=&#34;https://github.com/librecores/riscv-sodor&#34;&gt;Librecores&lt;/a&gt;. Major milestones will be pulled back here. Check it out! We also accept pull requests here!&lt;/p&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;p&gt;Here is an informal list of things that would be nice to get done. Feel free to contribute!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Reduce the port count on the scratchpad memory by having the HTIF port share one of the cpu ports.&lt;/li&gt; &#xA; &lt;li&gt;Provide a Verilog test harness, and put the 3-stage on a FPGA.&lt;/li&gt; &#xA; &lt;li&gt;Add support for the ma_addr, ma_fetch ISA tests. This requires detecting misaligned address exceptions.&lt;/li&gt; &#xA; &lt;li&gt;Greatly cleanup the common/csr.scala file, to make it clearer and more understandable.&lt;/li&gt; &#xA; &lt;li&gt;Refactor the stall, kill, fencei, and exception logic of the 5-stage to be more understandable.&lt;/li&gt; &#xA; &lt;li&gt;Update the u-code to properly handle illegal instructions (rv32mi-p-illegal) and to properly handle exceptions generated by the CSR file (rv32mi-p-csr).&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>