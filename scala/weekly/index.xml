<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-20T01:56:12Z</updated>
  <subtitle>Weekly Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>jrudolph/llama2.scala</title>
    <updated>2023-08-20T01:56:12Z</updated>
    <id>tag:github.com,2023-08-20:/jrudolph/llama2.scala</id>
    <link href="https://github.com/jrudolph/llama2.scala" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Inference Llama 2 in Scala with AVX2 kernels in C (A port of llama2.c from Andrej Karpathy)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;A Scala 2 port of Andrej Karpathy&#39;s llama2.c&lt;/h1&gt; &#xA;&lt;p&gt;This is a Scala port of Andrej Karpathy&#39;s &lt;a href=&#34;https://github.com/karpathy/llama2.c&#34;&gt;llama2.c&lt;/a&gt;, a bare bones implementation to run inference of models with a &lt;a href=&#34;https://arxiv.org/pdf/2302.13971.pdf&#34;&gt;Llama&lt;/a&gt;-like transformer-based LLM architecture.&lt;/p&gt; &#xA;&lt;p&gt;The code expects &lt;a href=&#34;https://github.com/karpathy/llama2.c/raw/master/tokenizer.bin&#34;&gt;&lt;code&gt;tokenizer.bin&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin&#34;&gt;&lt;code&gt;stories15M.bin&lt;/code&gt;&lt;/a&gt; in the current directory.&lt;/p&gt; &#xA;&lt;p&gt;This started as a port of the original code in pure Scala. Later, more high-level abstractions were added and low-level C kernels with AVX2 intrinsics to speed up matrix multiplication.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://asciinema.org/a/h7dJq7SOkmlCHmgI3DLRQBp58&#34;&gt;&lt;img src=&#34;https://asciinema.org/a/h7dJq7SOkmlCHmgI3DLRQBp58.svg?sanitize=true&#34; alt=&#34;asciicast&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Two implementations of the model architecture are available: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;Llama2SimpleTransformer&lt;/code&gt; which is a direct port of the original C code&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Llama2TensorTransformer&lt;/code&gt; which uses a &lt;code&gt;Tensor&lt;/code&gt; abstraction to make the code more readable&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Different matrix multiplication kernels: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;ScalaMathImplementation&lt;/code&gt; (direct port of llama2.c in pure Scala)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AVX2MathImplementation&lt;/code&gt; (using JNI to call kernels written with C SIMD intrinsics)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Models are mapped into memory to avoid loading them into the JVM heap&lt;/li&gt; &#xA; &lt;li&gt;Quantization modes: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;use the weights as given in the model&lt;/li&gt; &#xA;   &lt;li&gt;Q8: quantize weights after loading to 8 bits (all but rmsnorm)&lt;/li&gt; &#xA;   &lt;li&gt;Q4: quantize weights after loading to 4 bits (all but rmsnorm)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Multi-threading: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;AVX2MathImplementation&lt;/code&gt; uses OpenMP&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Support for loading ggml models &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;only weights in Q4_0 and FP32 are supported&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;scala-native support (mostly broken right now)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;Current numbers run with version &lt;a href=&#34;https://github.com/jrudolph/llama2.scala/tree/08c65d04c0a3a4345510db289779e3243bcf7ff9&#34;&gt;08c65d04&lt;/a&gt; on my AMD Ryzen 7 4800H laptop with GraalVM JDK 17.&lt;/p&gt; &#xA;&lt;p&gt;Implementations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scala = &lt;code&gt;Llama2TensorTransformer&lt;/code&gt; with &lt;code&gt;ScalaMathImplementation&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;native-avx2 = &lt;code&gt;Llama2TensorTransformer&lt;/code&gt; with &lt;code&gt;AVX2MathImplementation&lt;/code&gt; (using JNI to call kernels written with C SIMD intrinsics)&lt;/li&gt; &#xA; &lt;li&gt;llama2.c = as of &lt;a href=&#34;https://github.com/karpathy/llama2.c/tree/94a3a5e0a5f63f06ffbfa7ec5452553eedafc215&#34;&gt;94a3a5e0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;llama.cpp = as of &lt;a href=&#34;https://github.com/ggerganov/llama.cpp/tree/d783f7982e0e823a2626a9956359c0d36c1a7e21&#34;&gt;d783f798&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;scala-native = Using scala-native 0.4.14 with the &lt;code&gt;Llama2SimpleTransformer&lt;/code&gt; implementation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Quantization&lt;/th&gt; &#xA;   &lt;th&gt;Implementation&lt;/th&gt; &#xA;   &lt;th&gt;Threads&lt;/th&gt; &#xA;   &lt;th&gt;tok / s&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;494&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;931&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;65&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;533&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;800&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;57&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;374&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;677&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;66&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;scala-native vanilla&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;14&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;scala-native (native mmaps)&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;50&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;223&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;497&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;24&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;229&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;407&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;22&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;137&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;243&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;24&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;llama2.c / run&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;21&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;llama2.c / runfast&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;69&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;llama2.c / runomp&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;98&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories42M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;llama2.c / runomp&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;195&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;95&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;239&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;9.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;99&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;183&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;8.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;50&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;85&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;8.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;none&lt;/td&gt; &#xA;   &lt;td&gt;llama2.c / runomp&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama2_7b.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama2_7b.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;6.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama2_7b.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q4&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;0.16&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama2_7b.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;1.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama2_7b.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;4.46&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama2_7b.bin&lt;/td&gt; &#xA;   &lt;td&gt;Q8&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;0.14&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama-2-7b.ggmlv3.q4_0.bin&lt;/td&gt; &#xA;   &lt;td&gt;as provided&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;1.66&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama-2-7b.ggmlv3.q4_0.bin&lt;/td&gt; &#xA;   &lt;td&gt;as provided&lt;/td&gt; &#xA;   &lt;td&gt;native-avx2&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;6.71&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama-2-7b.ggmlv3.q4_0.bin&lt;/td&gt; &#xA;   &lt;td&gt;as provided&lt;/td&gt; &#xA;   &lt;td&gt;Scala&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;0.13&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama-2-7b.ggmlv3.q4_0.bin&lt;/td&gt; &#xA;   &lt;td&gt;as provided&lt;/td&gt; &#xA;   &lt;td&gt;llama.cpp&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama-2-7b.ggmlv3.q4_0.bin&lt;/td&gt; &#xA;   &lt;td&gt;as provided&lt;/td&gt; &#xA;   &lt;td&gt;llama.cpp&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;8.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Notes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Approximate speedups are: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;pure Scala -&amp;gt; AVX2: &amp;gt; 10x&lt;/li&gt; &#xA;   &lt;li&gt;FP32 -&amp;gt; Q8/Q4 (in Scala): same speed&lt;/li&gt; &#xA;   &lt;li&gt;FP32 -&amp;gt; Q8 (AVX2): ~ 2x&lt;/li&gt; &#xA;   &lt;li&gt;Q8 -&amp;gt; Q4 (AVX2) on one thread: same speed&lt;/li&gt; &#xA;   &lt;li&gt;Q4 1 thread -&amp;gt; 6 threads on small models: ~ 2x&lt;/li&gt; &#xA;   &lt;li&gt;Q4 1 thread -&amp;gt; 6 threads on large models: ~ 3x&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;The pure Scala mode GraalVM JDK 17 is only competitive with a llama2.c version compiled with &lt;code&gt;-O3&lt;/code&gt;. Using &lt;code&gt;-Ofast&lt;/code&gt; on C already makes a huge difference. Would be interesting to see the exact differences between JIT compiled code and gcc output with &lt;code&gt;-Ofast&lt;/code&gt;. Not sure if something like &lt;code&gt;-Ofast&lt;/code&gt; (using less strict FP math) is possible on the JVM.&lt;/li&gt; &#xA; &lt;li&gt;Using (i.e. mostly adapting from llama.cpp) kernels in C with SIMD intrinsics and calling them with JNI from Scala makes a huge difference. It is easy to do locally, but, of course, much harder to do in a portable way.&lt;/li&gt; &#xA; &lt;li&gt;As expected, quantization gives another boost. Interesting that it is more pronounced when multi-threading is enabled.&lt;/li&gt; &#xA; &lt;li&gt;OMP-based multithreading is simple to use from C and helps a lot. Scaling is not perfect, with benefits diminishing sharply after using more than 6 (of 8) threads.&lt;/li&gt; &#xA; &lt;li&gt;Multithreading is interesting, as the task units are quite small (one matrix multiplication) and overheads can be significant.&lt;/li&gt; &#xA; &lt;li&gt;Quantization only helps with SIMD optimization. Only SIMD will give access to byte-wise (int8) operations and &lt;em&gt;decreasing&lt;/em&gt; the data type size will &lt;em&gt;increase&lt;/em&gt; the number of lanes per vector with the same factor. It is unclear why going from 32-bit to 8-bit gives only a 2x speedup while being able to run 4x more operations in parallel. One explanation could be that you need more instructions because of the added complexity of quantization.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>databricks/spark-sql-perf</title>
    <updated>2023-08-20T01:56:12Z</updated>
    <id>tag:github.com,2023-08-20:/databricks/spark-sql-perf</id>
    <link href="https://github.com/databricks/spark-sql-perf" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Spark SQL Performance Tests&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/databricks/spark-sql-perf&#34;&gt;&lt;img src=&#34;https://travis-ci.org/databricks/spark-sql-perf.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a performance testing framework for &lt;a href=&#34;https://spark.apache.org/sql/&#34;&gt;Spark SQL&lt;/a&gt; in &lt;a href=&#34;https://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt; 2.2+.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: This README is still under development. Please also check our source code for more information.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Quick Start&lt;/h1&gt; &#xA;&lt;h2&gt;Running from command line.&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bin/run --help&#xA;&#xA;spark-sql-perf 0.2.0&#xA;Usage: spark-sql-perf [options]&#xA;&#xA;  -b &amp;lt;value&amp;gt; | --benchmark &amp;lt;value&amp;gt;&#xA;        the name of the benchmark to run&#xA;  -m &amp;lt;value&amp;gt; | --master &amp;lt;value&#xA;        the master url to use&#xA;  -f &amp;lt;value&amp;gt; | --filter &amp;lt;value&amp;gt;&#xA;        a filter on the name of the queries to run&#xA;  -i &amp;lt;value&amp;gt; | --iterations &amp;lt;value&amp;gt;&#xA;        the number of iterations to run&#xA;  --help&#xA;        prints this usage text&#xA;        &#xA;$ bin/run --benchmark DatasetPerformance&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The first run of &lt;code&gt;bin/run&lt;/code&gt; will build the library.&lt;/p&gt; &#xA;&lt;h2&gt;Build&lt;/h2&gt; &#xA;&lt;p&gt;Use &lt;code&gt;sbt package&lt;/code&gt; or &lt;code&gt;sbt assembly&lt;/code&gt; to build the library jar.&lt;br&gt; Use &lt;code&gt;sbt +package&lt;/code&gt; to build for scala 2.11 and 2.12.&lt;/p&gt; &#xA;&lt;h2&gt;Local performance tests&lt;/h2&gt; &#xA;&lt;p&gt;The framework contains twelve benchmarks that can be executed in local mode. They are organized into three classes and target different components and functions of Spark:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/databricks/spark-sql-perf/raw/master/src/main/scala/com/databricks/spark/sql/perf/DatasetPerformance.scala&#34;&gt;DatasetPerformance&lt;/a&gt; compares the performance of the old RDD API with the new Dataframe and Dataset APIs. These benchmarks can be launched with the command &lt;code&gt;bin/run --benchmark DatasetPerformance&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/databricks/spark-sql-perf/raw/master/src/main/scala/com/databricks/spark/sql/perf/JoinPerformance.scala&#34;&gt;JoinPerformance&lt;/a&gt; compares the performance of joining different table sizes and shapes with different join types. These benchmarks can be launched with the command &lt;code&gt;bin/run --benchmark JoinPerformance&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/databricks/spark-sql-perf/raw/master/src/main/scala/com/databricks/spark/sql/perf/AggregationPerformance.scala&#34;&gt;AggregationPerformance&lt;/a&gt; compares the performance of aggregating different table sizes using different aggregation types. These benchmarks can be launched with the command &lt;code&gt;bin/run --benchmark AggregationPerformance&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;MLlib tests&lt;/h1&gt; &#xA;&lt;p&gt;To run MLlib tests, run &lt;code&gt;/bin/run-ml yamlfile&lt;/code&gt;, where &lt;code&gt;yamlfile&lt;/code&gt; is the path to a YAML configuration file describing tests to run and their parameters.&lt;/p&gt; &#xA;&lt;h1&gt;TPC-DS&lt;/h1&gt; &#xA;&lt;h2&gt;Setup a benchmark&lt;/h2&gt; &#xA;&lt;p&gt;Before running any query, a dataset needs to be setup by creating a &lt;code&gt;Benchmark&lt;/code&gt; object. Generating the TPCDS data requires dsdgen built and available on the machines. We have a fork of dsdgen that you will need. The fork includes changes to generate TPCDS data to stdout, so that this library can pipe them directly to Spark, without intermediate files. Therefore, this library will not work with the vanilla TPCDS kit.&lt;/p&gt; &#xA;&lt;p&gt;TPCDS kit needs to be installed on all cluster executor nodes under the same path!&lt;/p&gt; &#xA;&lt;p&gt;It can be found &lt;a href=&#34;https://github.com/databricks/tpcds-kit&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;// Generate the data&#xA;build/sbt &#34;test:runMain com.databricks.spark.sql.perf.tpcds.GenTPCDSData -d &amp;lt;dsdgenDir&amp;gt; -s &amp;lt;scaleFactor&amp;gt; -l &amp;lt;location&amp;gt; -f &amp;lt;format&amp;gt;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;// Create the specified database&#xA;sql(s&#34;create database $databaseName&#34;)&#xA;// Create metastore tables in a specified database for your data.&#xA;// Once tables are created, the current database will be switched to the specified database.&#xA;tables.createExternalTables(rootDir, &#34;parquet&#34;, databaseName, overwrite = true, discoverPartitions = true)&#xA;// Or, if you want to create temporary tables&#xA;// tables.createTemporaryTables(location, format)&#xA;&#xA;// For CBO only, gather statistics on all columns:&#xA;tables.analyzeTables(databaseName, analyzeColumns = true) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Run benchmarking queries&lt;/h2&gt; &#xA;&lt;p&gt;After setup, users can use &lt;code&gt;runExperiment&lt;/code&gt; function to run benchmarking queries and record query execution time. Taking TPC-DS as an example, you can start an experiment by using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import com.databricks.spark.sql.perf.tpcds.TPCDS&#xA;&#xA;val tpcds = new TPCDS (sqlContext = sqlContext)&#xA;// Set:&#xA;val databaseName = ... // name of database with TPCDS data.&#xA;val resultLocation = ... // place to write results&#xA;val iterations = 1 // how many iterations of queries to run.&#xA;val queries = tpcds.tpcds2_4Queries // queries to run.&#xA;val timeout = 24*60*60 // timeout, in seconds.&#xA;// Run:&#xA;sql(s&#34;use $databaseName&#34;)&#xA;val experiment = tpcds.runExperiment(&#xA;  queries, &#xA;  iterations = iterations,&#xA;  resultLocation = resultLocation,&#xA;  forkThread = true)&#xA;experiment.waitForFinish(timeout)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, experiment will be started in a background thread. For every experiment run (i.e. every call of &lt;code&gt;runExperiment&lt;/code&gt;), Spark SQL Perf will use the timestamp of the start time to identify this experiment. Performance results will be stored in the sub-dir named by the timestamp in the given &lt;code&gt;spark.sql.perf.results&lt;/code&gt; (for example &lt;code&gt;/tmp/results/timestamp=1429213883272&lt;/code&gt;). The performance results are stored in the JSON format.&lt;/p&gt; &#xA;&lt;h2&gt;Retrieve results&lt;/h2&gt; &#xA;&lt;p&gt;While the experiment is running you can use &lt;code&gt;experiment.html&lt;/code&gt; to get a summary, or &lt;code&gt;experiment.getCurrentResults&lt;/code&gt; to get complete current results. Once the experiment is complete, you can still access &lt;code&gt;experiment.getCurrentResults&lt;/code&gt;, or you can load the results from disk.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;// Get all experiments results.&#xA;val resultTable = spark.read.json(resultLocation)&#xA;resultTable.createOrReplaceTempView(&#34;sqlPerformance&#34;)&#xA;sqlContext.table(&#34;sqlPerformance&#34;)&#xA;// Get the result of a particular run by specifying the timestamp of that run.&#xA;sqlContext.table(&#34;sqlPerformance&#34;).filter(&#34;timestamp = 1429132621024&#34;)&#xA;// or&#xA;val specificResultTable = spark.read.json(experiment.resultPath)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can get a basic summary by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;experiment.getCurrentResults // or: spark.read.json(resultLocation).filter(&#34;timestamp = 1429132621024&#34;)&#xA;  .withColumn(&#34;Name&#34;, substring(col(&#34;name&#34;), 2, 100))&#xA;  .withColumn(&#34;Runtime&#34;, (col(&#34;parsingTime&#34;) + col(&#34;analysisTime&#34;) + col(&#34;optimizationTime&#34;) + col(&#34;planningTime&#34;) + col(&#34;executionTime&#34;)) / 1000.0)&#xA;  .select(&#39;Name, &#39;Runtime)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;TPC-H&lt;/h1&gt; &#xA;&lt;p&gt;TPC-H can be run similarly to TPC-DS replacing &lt;code&gt;tpcds&lt;/code&gt; for &lt;code&gt;tpch&lt;/code&gt;. Take a look at the data generator and &lt;code&gt;tpch_run&lt;/code&gt; notebook code below.&lt;/p&gt; &#xA;&lt;h2&gt;Running in Databricks workspace (or spark-shell)&lt;/h2&gt; &#xA;&lt;p&gt;There are example notebooks in &lt;code&gt;src/main/notebooks&lt;/code&gt; for running TPCDS and TPCH in the Databricks environment. &lt;em&gt;These scripts can also be run from spark-shell command line with minor modifications using &lt;code&gt;:load file_name.scala&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;TPC-multi_datagen notebook&lt;/h3&gt; &#xA;&lt;p&gt;This notebook (or scala script) can be use to generate both TPCDS and TPCH data at selected scale factors. It is a newer version from the &lt;code&gt;tpcds_datagen&lt;/code&gt; notebook below. To use it:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Edit the config variables the top of the script.&lt;/li&gt; &#xA; &lt;li&gt;Run the whole notebook.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;tpcds_datagen notebook&lt;/h3&gt; &#xA;&lt;p&gt;This notebook can be used to install dsdgen on all worker nodes, run data generation, and create the TPCDS database. Note that because of the way dsdgen is installed, it will not work on an autoscaling cluster, and &lt;code&gt;num_workers&lt;/code&gt; has to be updated to the number of worker instances on the cluster. Data generation may also break if any of the workers is killed - the restarted worker container will not have &lt;code&gt;dsdgen&lt;/code&gt; anymore.&lt;/p&gt; &#xA;&lt;h3&gt;tpcds_run notebook&lt;/h3&gt; &#xA;&lt;p&gt;This notebook can be used to run TPCDS queries.&lt;/p&gt; &#xA;&lt;p&gt;For running parallel TPCDS streams:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a Cluster and attach the spark-sql-perf library to it.&lt;/li&gt; &#xA; &lt;li&gt;Create a Job using the notebook and attaching to the created cluster as &#34;existing cluster&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Allow concurrent runs of the created job.&lt;/li&gt; &#xA; &lt;li&gt;Launch appriopriate number of Runs of the Job to run in parallel on the cluster.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;tpch_run notebook&lt;/h3&gt; &#xA;&lt;p&gt;This notebook can be used to run TPCH queries. Data needs be generated first.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>savaki/finagle-loggly</title>
    <updated>2023-08-20T01:56:12Z</updated>
    <id>tag:github.com,2023-08-20:/savaki/finagle-loggly</id>
    <link href="https://github.com/savaki/finagle-loggly" rel="alternate"></link>
    <summary type="html">&lt;p&gt;simple api for sending data to loggly&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;finagle-loggly&lt;/h1&gt; &#xA;&lt;p&gt;simple api for sending data to loggly&lt;/p&gt;</summary>
  </entry>
</feed>