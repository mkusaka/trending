<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-02T02:03:53Z</updated>
  <subtitle>Weekly Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ucb-bar/dsptools</title>
    <updated>2023-04-02T02:03:53Z</updated>
    <id>tag:github.com,2023-04-02:/ucb-bar/dsptools</id>
    <link href="https://github.com/ucb-bar/dsptools" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Library of Chisel3 Tools for Digital Signal Processing&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DSP Tools Development Environment&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ucb-bar/dsptools/actions/workflows/test.yml&#34;&gt;&lt;img src=&#34;https://github.com/ucb-bar/dsptools/actions/workflows/test.yml/badge.svg?sanitize=true&#34; alt=&#34;Test&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository serves as a good starting point for making and easily testing your various DSP generators in Chisel &lt;em&gt;(1 generator at a time)&lt;/em&gt;. See &lt;a href=&#34;https://chisel.eecs.berkeley.edu&#34;&gt;UC Berkeley Chisel&lt;/a&gt; homepage for more information about Chisel.&lt;/p&gt; &#xA;&lt;p&gt;For a list of common errors, check out the &lt;a href=&#34;https://github.com/ucb-bar/dsptools/wiki/Common-Errors&#34;&gt;wiki page&lt;/a&gt;. Feel free to add your own!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Key Enhancements&lt;/h1&gt; &#xA;&lt;p&gt;Dsptools is a library that can be used with any Chisel library. Some of the goals of dsptools are to enable:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Pipeline delay checking (Isn&#39;t it annoying when the delays of two signals into an operation don&#39;t line up because you forgot to delay a corresponding signal in your haste to close timing?)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Enhanced support for designing and testing DSP with generic types (i.e. switching between &lt;strong&gt;DSPReal&lt;/strong&gt; for verifying functional correctness with double-precision floating point and &lt;strong&gt;FixedPoint&lt;/strong&gt; for evaluating fixed-point design metrics by changing a single parameter).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;More useful and universal testing platform for numeric types!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Numbers are displayed in their correct formats instead of hex for peek, poke, and expect operations. Additionally, if your tester extends &lt;strong&gt;DSPTester&lt;/strong&gt;, you can optionally dump your test sequence to a &lt;strong&gt;Verilog testbench&lt;/strong&gt; that replays the test for functional verification on all simulation platforms (i.e. Xilinx, Altera, etc. instead of only VCS). The tolerance of comparisons with expected values can also be changed via &lt;code&gt;DSPTester.setTol(floTol = decimal_tolerance, fixedTol = number_of_bits)&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;&lt;strong&gt;Miscellaneous additional features&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Wide range of LUT modules for ease of generating lookup tables from pre-calculated constants (no intermediate representation)&lt;/li&gt; &#xA; &lt;li&gt;Memory modules that abstract out confusion associated with Chisel Mem&lt;/li&gt; &#xA; &lt;li&gt;Generates useful helper files with each Verilog output (constraints, generator parameters used, etc.).&lt;/li&gt; &#xA; &lt;li&gt;Easier to rename modules &amp;amp; signals and have renaming actually succeed.&lt;/li&gt; &#xA; &lt;li&gt;Expanding Support for non-base-2 math.&lt;/li&gt; &#xA; &lt;li&gt;Adds support for numerical processing in the Chisel Environment via &lt;a href=&#34;https://github.com/scalanlp/breeze&#34;&gt;Breeze&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;p&gt;Dsptools is published alongside Chisel, FIRRTL, and the other related projects. It can be used by adding&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies += &#34;edu.berkeley.cs&#34; %% &#34;dsptools&#34; % &#34;XXXX&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to your build.sbt, where &lt;code&gt;XXXX&lt;/code&gt; is the desired version. See Github for the latest release. Snapshots are also published on Sonatype, which are beneficial if you want to use the latest features.&lt;/p&gt; &#xA;&lt;p&gt;Projects that dsptools depends on are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/ucb-bar/firrtl&#34;&gt;FIRRTL&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/ucb-bar/firrtl-interpreter&#34;&gt;FIRRTL Interpreter&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/ucb-bar/chisel3&#34;&gt;Chisel3&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/ucb-bar/chisel-testers&#34;&gt;Chisel Testers&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Numeric Typeclasses&lt;/h1&gt; &#xA;&lt;p&gt;This library defines a number of typeclasses for numeric types. A brief explanation of how typeclasses work in scala can be found &lt;a href=&#34;http://typelevel.org/cats/typeclasses.html&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://blog.jaceklaskowski.pl/2015/05/15/ad-hoc-polymorphism-in-scala-with-type-classes.html&#34;&gt;here&lt;/a&gt;. Our DSP-specific typeclasses are built on top of &lt;a href=&#34;https://github.com/non/spire&#34;&gt;spire&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The goal of these typeclasses is to make it easy to write chisel modules that treat the number representation as a parameter. For example, using typeclasses you can write chisel that generates an FIR filter for both real and complex numbers. You can also use typeclasses to write chisel that generates a circuit implementation using floating point (via Verilog&#39;s real type). After testing that your circuit implementation works with floating point, you can use the same code to generate a fixed point version of the circuit suitable for synthesis.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For a additional, more detailed description of the Numeric classes in dsptools: see &lt;a href=&#34;https://github.com/ucb-bar/dsptools/raw/master/src/main/scala/dsptools/numbers/README.md&#34;&gt;The Numbers ReadMe&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;A generic function in scala is defined like so:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;def func[T](in: T): T&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;This means that you can call &lt;code&gt;func(obj)&lt;/code&gt; for an object of any type. If &lt;code&gt;obj&lt;/code&gt; is of type &lt;code&gt;Q&lt;/code&gt;, you can write &lt;code&gt;func[Q](obj)&lt;/code&gt; to specify that we want the &lt;code&gt;Q&lt;/code&gt; version of the generic function &lt;code&gt;func&lt;/code&gt;, but this is only necessary if the scala compiler can&#39;t figure out what &lt;code&gt;Q&lt;/code&gt; is supposed to be.&lt;/p&gt; &#xA;&lt;p&gt;You can also write&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;class SomeClass[T]&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;and use &lt;code&gt;T&lt;/code&gt; like it is a real type for any member functions of variables. To write a generic chisel Module, we might try to write&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;class Passthrough[T](gen: T) extends Module {&#xA;  val io = new IO(Bundle {&#xA;    val in = Input(gen)&#xA;    val out = Output(gen)&#xA;  })&#xA;  io.out := io.in&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here, &lt;code&gt;gen&lt;/code&gt; is a parameter specifying the type you want to use for your IO&#39;s, so you could write &lt;code&gt;Module(new Passthrough(SInt(width=10)))&lt;/code&gt; or &lt;code&gt;Module(new Passthrough(new Bundle { ... }))&lt;/code&gt;. Unfortunately, there&#39;s a problem with this. &lt;code&gt;T&lt;/code&gt; can be any type, and a lot of types don&#39;t make sense, like &lt;code&gt;String&lt;/code&gt; or &lt;code&gt;()=&amp;gt;Unit&lt;/code&gt;. This will not compile, because &lt;code&gt;Input()&lt;/code&gt;, &lt;code&gt;Output()&lt;/code&gt;, and &lt;code&gt;:=&lt;/code&gt; are functions defined on chisel types. We can fix this problem by writing&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;class Passthrough[T&amp;lt;:Data](gen: T) extends Module&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;This type constraint means that we have to choose &lt;code&gt;T&lt;/code&gt; to be a subtype of the chisel type &lt;code&gt;Data&lt;/code&gt;. Things like &lt;code&gt;UInt&lt;/code&gt;, &lt;code&gt;SInt&lt;/code&gt;, and &lt;code&gt;Bundle&lt;/code&gt; are subtypes of &lt;code&gt;Data&lt;/code&gt;. Now the example above should compile. This example isn&#39;t very interesting, though. &lt;code&gt;Data&lt;/code&gt; lets you do basic things like assignment and make registers, but doesn&#39;t define any mathematical operations, so if we write&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;class Doubler[T&amp;lt;:Data](gen: T) extends Module {&#xA;  val io = IO(new Bundle {&#xA;    val in = Input(gen)&#xA;    val out = Output(gen)&#xA;  })&#xA;  io.out := io.in + io.in&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;it won&#39;t compile. This is where typeclasses come in. This library defines a trait&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;trait Real[T] {&#xA;  ...&#xA;  def plus(x: T, y: T): T&#xA;  ...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;as well as an implicit conversion so that &lt;code&gt;a+b&lt;/code&gt; gets converted to &lt;code&gt;Real[T].plus(a,b)&lt;/code&gt;. &lt;code&gt;Real[T]&lt;/code&gt; is a typeclass. Typeclasses are a useful pattern in scala, so there is syntactic sugar to make using them easy:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import dsptools.numbers._&#xA;class Doubler[T&amp;lt;:Data:Real](gen: T) extends Module&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: If you don&#39;t include the &lt;code&gt;:Real&lt;/code&gt; at the end, the scala compiler will think &lt;code&gt;io.in + io.in&lt;/code&gt; is string concatenation and you&#39;ll get a weird error saying&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[error]  found   : T&#xA;[error]  required: String&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some useful typeclasses:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Ring&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;defines +, *, -, **, zero, one&lt;/li&gt; &#xA;   &lt;li&gt;defined in &lt;a href=&#34;https://github.com/non/spire&#34;&gt;Spire&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Read: &lt;a href=&#34;https://en.wikipedia.org/wiki/Ring_(mathematics)&#34;&gt;https://en.wikipedia.org/wiki/Ring_(mathematics)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Note: We chose to restrict ourselves to &lt;code&gt;Ring&lt;/code&gt; rather than &lt;code&gt;Field&lt;/code&gt; because division is particularly expensive and nuanced in hardware. Rather than typing &lt;code&gt;a / b&lt;/code&gt; we think it is better to require users to instantiate a module and think about what&#39;s going on.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Eq&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;defines === and =/= (returning chisel Bools!)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;PartialOrder&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;extends Eq&lt;/li&gt; &#xA;   &lt;li&gt;defines &amp;gt;, &amp;lt;, &amp;lt;=, &amp;gt;= (returning a &lt;code&gt;ValidIO[ComparisonBundle]&lt;/code&gt; that has &lt;code&gt;valid&lt;/code&gt; false if the objects are not comparable&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Order&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;extends PartialOrder&lt;/li&gt; &#xA;   &lt;li&gt;defines &amp;gt;, &amp;lt;, &amp;lt;=, &amp;gt;=, min, max&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Sign&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;defines abs, isSignZero, isSignPositive, isSignNegative, isSignNonZero, isSignNonPositive, isSignNonNegative&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Real&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;extends Ring with Order with Sign&lt;/li&gt; &#xA;   &lt;li&gt;defines ceil, round, floor, isWhole&lt;/li&gt; &#xA;   &lt;li&gt;defines a bunch of conversion methods from ConvertableTo, e.g. fromDouble, fromInt&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Integer&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;extends Real&lt;/li&gt; &#xA;   &lt;li&gt;defines mod&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Rocket-chip&lt;/h1&gt; &#xA;&lt;p&gt;Integration of dsptools with a rocket-chip based project:&lt;/p&gt; &#xA;&lt;p&gt;The github project &lt;a href=&#34;https://github.com/chick/rocket-dsp-utils&#34;&gt;Rocket Dsp Utils&lt;/a&gt; contains useful tools that can be used to integrate components from this project with a rocket-chip based one.&lt;/p&gt; &#xA;&lt;p&gt;These tools formerly were contained in this repo under the &lt;code&gt;rocket&lt;/code&gt; sub-directory.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;This code is maintained by &lt;a href=&#34;https://github.com/chick&#34;&gt;Chick&lt;/a&gt;, &lt;a href=&#34;https://github.com/shunshou&#34;&gt;Angie&lt;/a&gt; and &lt;a href=&#34;https://github.com/grebe&#34;&gt;Paul&lt;/a&gt;. Let us know if you have any questions/feedback!&lt;/p&gt; &#xA;&lt;p&gt;Copyright (c) 2015 - 2021 The Regents of the University of California. Released under the Modified (3-clause) BSD license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rockthejvm/spark-essentials</title>
    <updated>2023-04-02T02:03:53Z</updated>
    <id>tag:github.com,2023-04-02:/rockthejvm/spark-essentials</id>
    <link href="https://github.com/rockthejvm/spark-essentials" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The official repository for the Rock the JVM Spark Essentials with Scala course&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The official repository for the Rock the JVM Spark Essentials with Scala course&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the code we wrote during &lt;a href=&#34;https://rockthejvm.com/course/spark-essentials&#34;&gt;Rock the JVM&#39;s Spark Essentials with Scala&lt;/a&gt; (Udemy version &lt;a href=&#34;https://udemy.com/spark-essentials&#34;&gt;here&lt;/a&gt;) Unless explicitly mentioned, the code in this repository is exactly what was caught on camera.&lt;/p&gt; &#xA;&lt;h2&gt;How to install&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;install &lt;a href=&#34;https://docker.com&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;either clone the repo or download as zip&lt;/li&gt; &#xA; &lt;li&gt;open with IntelliJ as an SBT project&lt;/li&gt; &#xA; &lt;li&gt;in a terminal window, navigate to the folder where you downloaded this repo and run &lt;code&gt;docker-compose up&lt;/code&gt; to build and start the PostgreSQL container - we will interact with it from Spark&lt;/li&gt; &#xA; &lt;li&gt;in another terminal window, navigate to &lt;code&gt;spark-cluster/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Linux/Mac users: build the Docker-based Spark cluster with&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;chmod +x build-images.sh&#xA;./build-images.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows users: build the Docker-based Spark cluster with&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;build-images.bat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;when prompted to start the Spark cluster, go to the &lt;code&gt;spark-cluster&lt;/code&gt; directory and run &lt;code&gt;docker-compose up --scale spark-worker=3&lt;/code&gt; to spin up the Spark containers with 3 worker nodes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;A Note For Windows users: Adding Winutils&lt;/h3&gt; &#xA;&lt;p&gt;By default, Spark will be unable to write files using the local Spark executor. To write files, you will need to install the Windows Hadoop binaries, aka &lt;a href=&#34;https://github.com/cdarlint/winutils&#34;&gt;winutils&lt;/a&gt;. You can take the latest binary (Hadoop 3.2 as of June 2022), or use Hadoop 2.7 as a fallback.&lt;/p&gt; &#xA;&lt;p&gt;After you download winutils.exe, create a directory anywhere (e.g. &lt;code&gt;C:\\winutils&lt;/code&gt;), then create a &lt;code&gt;bin&lt;/code&gt; directory under that, then place the winutils executable there.&lt;/p&gt; &#xA;&lt;p&gt;You will also need to set the &lt;code&gt;HADOOP_HOME&lt;/code&gt; environment variable to your directory where you added &lt;code&gt;bin\winutils.exe&lt;/code&gt;. In the example above, that would be &lt;code&gt;C:\\winutils&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;An alternative to setting the environment variable is to add this line at the beginning of every Spark application we write:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;System.setProperty(&#34;hadoop.home.dir&#34;,&#34;C:\\hadoop&#34;) // replace C:\\hadoop with your actual directory&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;How to start&lt;/h3&gt; &#xA;&lt;p&gt;Clone this repository and checkout the &lt;code&gt;start&lt;/code&gt; tag by running the following in the repo folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git checkout start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;How to see the final code&lt;/h3&gt; &#xA;&lt;p&gt;Udemy students: checkout the &lt;code&gt;udemy&lt;/code&gt; branch of the repo:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git checkout udemy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Premium students: checkout the master branch:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git checkout master&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;How to run an intermediate state&lt;/h3&gt; &#xA;&lt;p&gt;The repository was built while recording the lectures. Prior to each lecture, I tagged each commit so you can easily go back to an earlier state of the repo!&lt;/p&gt; &#xA;&lt;p&gt;The tags are as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;start&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;1.1-scala-recap&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2.1-dataframes&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2.2-dataframes-basics-exercise&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2.4-datasources&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2.5-datasources-part-2&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2.6-columns-expressions&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2.7-columns-expressions-exercise&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2.8-aggregations&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2.9-joins&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2.10-joins-exercise&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;3.1-common-types&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;3.2-complex-types&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;3.3-managing-nulls&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;3.4-datasets&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;3.5-datasets-part-2&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;4.1-spark-sql-shell&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;4.2-spark-sql&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;4.3-spark-sql-exercises&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;5.1-rdds&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;5.2-rdds-part-2&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And for premium students, in addition:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;6.1-spark-job-anatomy&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;6.2-deploying-to-cluster&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;7.1-taxi&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;7.2-taxi-2&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;7.3-taxi-3&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;7.4-taxi-4&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When you watch a lecture, you can &lt;code&gt;git checkout&lt;/code&gt; the appropriate tag and the repo will go back to the exact code I had when I started the lecture.&lt;/p&gt; &#xA;&lt;h3&gt;For questions or suggestions&lt;/h3&gt; &#xA;&lt;p&gt;If you have changes to suggest to this repo, either&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;submit a GitHub issue&lt;/li&gt; &#xA; &lt;li&gt;tell me in the course Q/A forum&lt;/li&gt; &#xA; &lt;li&gt;submit a pull request!&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>lampepfl/async</title>
    <updated>2023-04-02T02:03:53Z</updated>
    <id>tag:github.com,2023-04-02:/lampepfl/async</id>
    <link href="https://github.com/lampepfl/async" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A strawman for a low-level async library in Scala 3&lt;/p&gt;&lt;hr&gt;&lt;p&gt;This is a proof of concept for a base library for asynchronous computing in direct style. The library needs either fibers or virtual threads as a basis. It is at present highly experimental, incomplete and provisional. It is not yet extensively tested and not optimized at all.&lt;/p&gt; &#xA;&lt;p&gt;The concepts and code here should be regarded as a strawman, in the sense of &#34;meant to be knocked down&#34;.&lt;/p&gt; &#xA;&lt;p&gt;Here is a &lt;a href=&#34;https://raw.githubusercontent.com/lampepfl/async/main/scalar-slides.pdf&#34;&gt;slidedeck&lt;/a&gt; of a talk given at Scalar 2023 covering some aspects of the library. A general rationale and introduction follows.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Towards A New Base Library for Asynchronous Computing&lt;/h1&gt; &#xA;&lt;p&gt;Martin Odersky 16 Feb 2023&lt;/p&gt; &#xA;&lt;h2&gt;Why a New Library?&lt;/h2&gt; &#xA;&lt;p&gt;We are seeing increasing adoption of continuations, coroutines, or green threads in modern runtimes. Examples are goroutines in golang, coroutines in C++, or virtual threads in project Loom. Complementary to this, we see a maturing of techniques to implement continuations by code generation. Examples range from more local solutions such as async/await in C#, Python, or Scala to more sweeping implementations such as Kotlin coroutines or dotty-cps-async, and the stack capture techniques pioneered by Krishnamurti et al. and Brachth√§user. This means that we can realistically expect support for continuations or coroutines in most runtimes in the near future.&lt;/p&gt; &#xA;&lt;p&gt;This will lead to a fundamental paradigm shift in reactive programming since we can now assume a lightweight and universal &lt;code&gt;await&lt;/code&gt; construct that can be called anywhere. Previously, most reactive code was required to be cps-transformed into (something resembling) a monad, so that suspension could be implemented in a library.&lt;/p&gt; &#xA;&lt;p&gt;As an example, here is some code using new, direct style futures:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  val sum = Future:&#xA;    val f1 = Future(c1.read)&#xA;    val f2 = Future(c2.read)&#xA;    f1.value + f2.value&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We set up two futures that each read from a connection (which might take a while). We return the sum of the read values in a new future. The &lt;code&gt;value&lt;/code&gt; method returns the result value of a future once it is available, or throws an exception if the future returns a &lt;code&gt;Failure&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;By contrast, with current, monadic style futures, we&#39;d need a composition with &lt;code&gt;flatMap&lt;/code&gt; to achieve the same effect:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  val sum =&#xA;    val f1 = Future(c1.read)&#xA;    val f2 = Future(c2.read)&#xA;    for&#xA;      x &amp;lt;- f1&#xA;      y &amp;lt;- f2&#xA;    yield x + y&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The proposed direct style futures also support structured concurrency with cancellation. If the &lt;code&gt;sum&lt;/code&gt; future in the direct style is cancelled, the two nested futures reading the connections are cancelled as well. Or, if one of the nested futures finishes with an exception, the exception is propagated and the other future is cancelled.&lt;/p&gt; &#xA;&lt;p&gt;Lightweight blocking thus gives us a fundamentally new tool to design concurrent systems. Paired with the principles of structured concurrency this allows for direct-style systems that are both very lightweight and very expressive. In the following I describe the outline of such a system. I start with the public APIs and then discuss some internal data structures and implementation details.&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;The following is an exploration of what might be possible and desirable. It is backed by a complete implementation, but the implementation is neither thoroughly tested nor optimized in any way. The current implementation only serves as a prototype to explore general feasibility of the presented concepts.&lt;/p&gt; &#xA;&lt;h2&gt;Outline&lt;/h2&gt; &#xA;&lt;p&gt;The library is built around four core abstractions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Future&lt;/strong&gt; Futures are the primary active elements of the framework. A future starts a computation that delivers a result at some point in the future. The result can be a computed value or a failure value that contains an exception. One can wait for the result of a future. Futures can suspend when waiting for other futures to complete and when reading from channels.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Channel&lt;/strong&gt; Channels are the primary passive elements of the framework. A channel provides a way to send data from producers to consumers (which can both be futures). There are several versions of channels. &lt;strong&gt;Rendevouz channels&lt;/strong&gt; block both pending receivers and senders until a communication happens. &lt;strong&gt;Buffered channels&lt;/strong&gt; allow a sender to continue immediately, buffering the sent data until it is received.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Async Source&lt;/strong&gt; Futures and Channels are both described in terms of a new fundamental abstraction of an &lt;em&gt;asynchronous source&lt;/em&gt;. Async sources can be polled or awaited by suspending a computation. They can be composed by mapping or filtering their results, or by combining several sources in a race where the first arriving result wins.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Async Context&lt;/strong&gt; An async context is a capability that allows a computation to suspend while waiting for the result of an async source. This capability is encapsulated in the &lt;code&gt;Async&lt;/code&gt; trait. Code that has access to a (usually implicit) parameter of type &lt;code&gt;Async&lt;/code&gt; is said to be in an async context. The bodies of futures are in such a context, so they can suspend.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The library supports &lt;strong&gt;structured concurrency&lt;/strong&gt; with combinators on futures such as &lt;code&gt;alt&lt;/code&gt;, which returns the first succeeding future and &lt;code&gt;zip&lt;/code&gt;, which combines all success results or otherwise returns with the first failing future. These combinators are supported by a cancellation mechanism that discards futures whose outcome is no longer relevant.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cancellation&lt;/strong&gt; is scoped and hierarchical. Futures created in the scope of some other future are registered as children of that future. If a parent is cancelled, all its children are cancelled as well.&lt;/p&gt; &#xA;&lt;h2&gt;Futures&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;Future&lt;/code&gt; trait is defined as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;trait Future[+T] extends Async.Source[Try[T]], Cancellable:&#xA;  def result(using async: Async): Try[T]&#xA;  def value(using async: Async): T = result.get&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Futures represent a computation that is completed concurrently. The computation yields a result value or a exception encapsulated in a &lt;code&gt;Try&lt;/code&gt; result. The &lt;code&gt;value&lt;/code&gt; method produces the future&#39;s value if it completed successfully or re-throws the exception contained in the &lt;code&gt;Failure&lt;/code&gt; alternative of the &lt;code&gt;Try&lt;/code&gt; otherwise.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;result&lt;/code&gt; method can be defined like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def result(using async: Async): T = async.await(this)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here, &lt;code&gt;async&lt;/code&gt; is a capability that allows to suspend in an &lt;code&gt;await&lt;/code&gt; method. The &lt;code&gt;Async&lt;/code&gt; trait is defined as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;trait Async:&#xA;  def await[T](src: Async.Source[T]): T&#xA;&#xA;  def scheduler: ExecutionContext&#xA;  def group: CancellationGroup&#xA;  def withGroup(group: CancellationGroup): Async&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The most important abstraction here is the &lt;code&gt;await&lt;/code&gt; method. Code with the &lt;code&gt;Async&lt;/code&gt; capability can &lt;em&gt;await&lt;/em&gt; an &lt;em&gt;asynchronous source&lt;/em&gt; of type &lt;code&gt;Async.Source&lt;/code&gt;. This implies that the code will suspend if the result of the async source is not yet ready. Futures are async sources of type &lt;code&gt;Try[T]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Async Sources&lt;/h2&gt; &#xA;&lt;p&gt;We have seen that futures are a particular kind of an async source. We will see other implementations related to channels later. Async sources are the primary means of communication between asynchronous computations and they can be composed in powerful ways.&lt;/p&gt; &#xA;&lt;p&gt;In particular, we have two extension methods on async sources of type &lt;code&gt;Source[T]&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def map[U](f: T =&amp;gt; U): Source[U]&#xA;  def filter(p: T =&amp;gt; Boolean): Source[T]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;map&lt;/code&gt; transforms elements of a &lt;code&gt;Source&lt;/code&gt; whereas &lt;code&gt;filter&lt;/code&gt; only passes on elements satisfying some condition.&lt;/p&gt; &#xA;&lt;p&gt;Furthermore, there is a &lt;code&gt;race&lt;/code&gt; method that passes on the first of several sources:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def race[T](sources: Source[T]*): Source[T]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;These methods are building blocks for higher-level operations. For instance, &lt;code&gt;Async&lt;/code&gt; also defines an &lt;code&gt;either&lt;/code&gt; combinator over two sources &lt;code&gt;src1: Source[T1]&lt;/code&gt; and &lt;code&gt;src2: Source[T2]&lt;/code&gt; that returns an &lt;code&gt;Either[T1, T2]&lt;/code&gt; with the result of &lt;code&gt;src1&lt;/code&gt; if it finishes first and with the result of &lt;code&gt;src2&lt;/code&gt; otherwise. It is defined as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def either[T1, T2](src1: Source[T1], src2: Source[T2]): Source[Either[T, U]] =&#xA;    race(src1.map(Left(_)), src2.map(Right(_)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We distinguish between &lt;em&gt;original&lt;/em&gt; async sources such as futures or channels and &lt;em&gt;derived&lt;/em&gt; sources such as the results of &lt;code&gt;map&lt;/code&gt;, &lt;code&gt;filter&lt;/code&gt;, or &lt;code&gt;race&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Async sources need to define three abstract methods in trait &lt;code&gt;Async.Source[T]&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  trait Source[+T]:&#xA;    def poll(k: Listener[T]): Boolean&#xA;    def onComplete(k: Listener[T]): Unit&#xA;    def dropListener(k: Listener[T]): Unit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;All three methods take a &lt;code&gt;Listener&lt;/code&gt; argument. A &lt;code&gt;Listener[T]&lt;/code&gt; is a function from &lt;code&gt;T&lt;/code&gt; to &lt;code&gt;Boolean&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  trait Listener[-T] extends (T =&amp;gt; Boolean)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;T&lt;/code&gt; argument is the value obtained from an async source. A listener returns &lt;code&gt;true&lt;/code&gt; if the argument was read by another async computation. It returns &lt;code&gt;false&lt;/code&gt; if the argument was dropped by a &lt;code&gt;filter&lt;/code&gt; or lost in a &lt;code&gt;race&lt;/code&gt;. Listeners also come with a &lt;em&gt;lineage&lt;/em&gt;, which tells us what source combinators were used to build a listener.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;poll&lt;/code&gt; method of an async source allows to poll whether data is present. If that&#39;s the case, the listener &lt;code&gt;k&lt;/code&gt; is applied to the data. The result of &lt;code&gt;poll&lt;/code&gt; is the result of the listener if it was applied and &lt;code&gt;false&lt;/code&gt; otherwise. There is also a first-order variant of &lt;code&gt;poll&lt;/code&gt; that returns data in an &lt;code&gt;Option&lt;/code&gt;. It is defined as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def poll(): Option[T] =&#xA;    var resultOpt: Option[T] = None&#xA;    poll { x =&amp;gt; resultOpt = Some(x); true }&#xA;    resultOpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;onComplete&lt;/code&gt; method of an async source calls the listener &lt;code&gt;k&lt;/code&gt; once data is present. This could either be immediately, in which case the effect is the same as &lt;code&gt;poll&lt;/code&gt;, or it could be in the future in which case the listener is installed in waiting lists in the original sources on which it depends so that it can be called when the data is ready. Note that there could be several such original sources, since the listener could have been passed to a &lt;code&gt;race&lt;/code&gt; source, which itself depends on several other sources.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;dropListener&lt;/code&gt; method drops the listener &lt;code&gt;k&lt;/code&gt; from the waiting lists of all original sources on which it depends. This an optimization that is necessary in practice to support races efficiently. Once a race is decided, all losing listeners will never pass data (i.e. they always return &lt;code&gt;false&lt;/code&gt;), so we do not want them to clutter the waiting lists of their original sources anymore.&lt;/p&gt; &#xA;&lt;p&gt;A typical way to implement &lt;code&gt;onComplete&lt;/code&gt; for original sources is to poll first and install a listener only if no data is present. This behavior is encapsulated in the &lt;code&gt;OriginalSource&lt;/code&gt; abstraction:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  abstract class OriginalSource[+T] extends Source[T]:&#xA;&#xA;    /** Add `k` to the waiting list of this source */&#xA;    protected def addListener(k: Listener[T]): Unit&#xA;&#xA;    def onComplete(k: Listener[T]): Unit = synchronized:&#xA;      if !poll(k) then addListener(k)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;So original sources are defined in terms if &lt;code&gt;poll&lt;/code&gt;, &lt;code&gt;addListener&lt;/code&gt;, and &lt;code&gt;dropListener&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Creating Futures&lt;/h2&gt; &#xA;&lt;p&gt;A simple future can be created by calling the &lt;code&gt;apply&lt;/code&gt; method of the &lt;code&gt;Future&lt;/code&gt; object. We have seen an example in the introduction:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  val sum = Future:&#xA;    val f1 = Future(c1.read)&#xA;    val f2 = Future(c2.read)&#xA;    f1.value + f2.value&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;Future.apply&lt;/code&gt; method has the following signature:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def apply[T](body: Async ?=&amp;gt; T)(using Async): Future[T]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;apply&lt;/code&gt; wraps an &lt;code&gt;Async&lt;/code&gt; capability with cancellation handling (tied to the returned &lt;code&gt;Future&lt;/code&gt;) and passes it to its &lt;code&gt;body&lt;/code&gt; argument.&lt;/p&gt; &#xA;&lt;p&gt;Futures also have a set of useful combinators that support what is usually called &lt;em&gt;structured concurrency&lt;/em&gt;. In particular, there is the &lt;code&gt;zip&lt;/code&gt; operator, which takes two futures and if they both complete successfully returns their results in a pair. If one or both of the operand futures fail, the first failure is returned as failure result of the zip. Dually, there is the &lt;code&gt;alt&lt;/code&gt; operator, which returns the result of the first succeeding future and fails only if both operand futures fail.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;zip&lt;/code&gt; and &lt;code&gt;alt&lt;/code&gt; can be implemented as extension methods on futures as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  extension [T](f1: Future[T])&#xA;&#xA;    def zip[U](f2: Future[U])(using Async): Future[(T, U)] = Future:&#xA;      Async.await(Async.either(f1, f2)) match&#xA;        case Left(Success(x1))    =&amp;gt; (x1, f2.value)&#xA;        case Right(Success(x2))   =&amp;gt; (f1.value, x2)&#xA;        case Left(Failure(ex))    =&amp;gt; throw ex&#xA;        case Right(Failure(ex))   =&amp;gt; throw ex&#xA;&#xA;    def alt(f2: Future[T])(using Async): Future[T] = Future:&#xA;      Async.await(Async.either(f1, f2)) match&#xA;        case Left(Success(x1))    =&amp;gt; x1&#xA;        case Right(Success(x2))   =&amp;gt; x2&#xA;        case Left(_: Failure[?])  =&amp;gt; f2.value&#xA;        case Right(_: Failure[?]) =&amp;gt; f1.value&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;zip&lt;/code&gt; implementation calls &lt;code&gt;await&lt;/code&gt; over a source which results from an &lt;code&gt;either&lt;/code&gt;. We have seen that &lt;code&gt;either&lt;/code&gt; is in turn implemented by a combination of &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;race&lt;/code&gt;. It distinguishes four cases reflecting which of the argument futures finished first, and whether that was with a success or a failure.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;alt&lt;/code&gt; implementation starts in the same way, calling &lt;code&gt;await&lt;/code&gt; over &lt;code&gt;either&lt;/code&gt;. If the first result was a success, it returns it. If not, it waits for the second result.&lt;/p&gt; &#xA;&lt;p&gt;In some cases an operand future is no longer needed for the result of a &lt;code&gt;zip&lt;/code&gt; or an &lt;code&gt;alt&lt;/code&gt;. For &lt;code&gt;zip&lt;/code&gt; this is the case if one of the operands fails, since then the result is always a failure, and for &lt;code&gt;alt&lt;/code&gt; this is the case if one of the operands succeeds, since then the result is that success value.&lt;/p&gt; &#xA;&lt;h2&gt;Cancellation&lt;/h2&gt; &#xA;&lt;p&gt;Futures that are no longer needed can be cancelled. &lt;code&gt;Future&lt;/code&gt; extends the &lt;code&gt;Cancellable&lt;/code&gt; trait, which is defined as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  trait Cancellable:&#xA;    def cancel(): Unit&#xA;    def link(group: CancellationGroup): this.type&#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A cancel request is transmitted via the &lt;code&gt;cancel&lt;/code&gt; method. It sets the &lt;code&gt;cancelRequest&lt;/code&gt; flag of the future to &lt;code&gt;true&lt;/code&gt;. The flag is tested before and after each &lt;code&gt;await&lt;/code&gt; and can also be tested from user code. If a test returns &lt;code&gt;true&lt;/code&gt;, a &lt;code&gt;CancellationException&lt;/code&gt; is thrown, which usually terminates the running future.&lt;/p&gt; &#xA;&lt;h2&gt;Cancellation Groups&lt;/h2&gt; &#xA;&lt;p&gt;A cancellable object such as a future belongs to a &lt;code&gt;CancellationGroup&lt;/code&gt;. Cancellation groups are themselves cancellable objects. Cancelling a cancellation group means cancelling all its members.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;class CancellationGroup extends Cancellable:&#xA;  private var members: mutable.Set[Cancellable] = mutable.Set()&#xA;&#xA;  /** Cancel all members and clear the members set */&#xA;  def cancel() =&#xA;    members.toArray.foreach(_.cancel())&#xA;    members.clear()&#xA;&#xA;  /** Add given member to the members set */&#xA;  def add(member: Cancellable): Unit = synchronized:&#xA;    members += member&#xA;&#xA;  /** Remove given member from the members set if it is an element */&#xA;  def drop(member: Cancellable): Unit = synchronized:&#xA;    members -= member&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;One can include a cancellable object in a cancellation group using the object&#39;s &lt;code&gt;link&lt;/code&gt; method. An object can belong only to one cancellation group, so linking an already linked cancellable object will unlink it from its previous cancellation group. The &lt;code&gt;link&lt;/code&gt; method is defined as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def link(group: CancellationGroup): this.type =&#xA;    this.group.drop(this)&#xA;    this.group = group&#xA;    this.group.add(this)&#xA;    this&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are also two variants of &lt;code&gt;link&lt;/code&gt; in &lt;code&gt;Cancellable&lt;/code&gt;, defined as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;trait Cancellable:&#xA;  ...&#xA;  def link()(using async: Async): this.type =&#xA;    link(async.group)&#xA;  def unlink(): this.type =&#xA;    link(CancellationGroup.Unlinked)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The second variant of &lt;code&gt;link&lt;/code&gt; links a cancellable object to the group of the current &lt;code&gt;Async&lt;/code&gt; context. The &lt;code&gt;unlink&lt;/code&gt; method drops a cancellable object from its group. This is achieved by &#34;linking&#34; the object to the special &lt;code&gt;Unlinked&lt;/code&gt; cancellation group, which ignores all cancel requests as well as all add/drop member requests.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;object CancellationGroup&#xA;  object Unlinked extends CancellationGroup:&#xA;    override def cancel() = ()&#xA;    override def add(member: Cancellable): Unit = ()&#xA;    override def drop(member: Cancellable): Unit = ()&#xA;  end Unlinked&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Structured Concurrency&lt;/h2&gt; &#xA;&lt;p&gt;As we have seen in the &lt;code&gt;sum&lt;/code&gt; example, futures can be nested.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  val sum = Future:&#xA;    val f1 = Future(c1.read)&#xA;    val f2 = Future(c2.read)&#xA;    f1.value + f2.value&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Our library follows the &lt;em&gt;structured concurrency&lt;/em&gt; principle which says that the lifetime of nested computations is contained within the lifetime of enclosing computations. In the previous example, &lt;code&gt;f1&lt;/code&gt; and &lt;code&gt;f2&lt;/code&gt; will be guaranteed to terminate when the &lt;code&gt;sum&lt;/code&gt; future terminates. This is already implied by the program logic if both futures terminate successfully. But what if &lt;code&gt;f1&lt;/code&gt; fails with an exception? In that case &lt;code&gt;f2&lt;/code&gt; will be canceled before the &lt;code&gt;sum&lt;/code&gt; future is completed.&lt;/p&gt; &#xA;&lt;p&gt;The mechanism which achieves this is as follows: When defining a future, the body of the future is run in the scope of an &lt;code&gt;Async.group&lt;/code&gt; wrapper, which is defined like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def group[T](body: Async ?=&amp;gt; T)(using async: Async): T =&#xA;    val newGroup = CancellationGroup().link()&#xA;    try body(using async.withGroup(newGroup))&#xA;    finally newGroup.cancel()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;group&lt;/code&gt; wrapper sets up a new cancellation group, runs the given &lt;code&gt;body&lt;/code&gt; in an &lt;code&gt;Async&lt;/code&gt; context with that group, and finally cancels the group once &lt;code&gt;body&lt;/code&gt; has finished.&lt;/p&gt; &#xA;&lt;h2&gt;Channels&lt;/h2&gt; &#xA;&lt;p&gt;Channels are a means for futures and related asynchronous computations to synchronize and exchange messages. There are two broad categories of channels: &lt;em&gt;asynchronous&lt;/em&gt; or &lt;em&gt;synchronous&lt;/em&gt;.Synchronous channels block the sender of a message until it is received, whereas asynchronous channels don&#39;t do this as a general rule (but they might still block a sender by some back-pressure mechanism or if a bounded buffer gets full).&lt;/p&gt; &#xA;&lt;p&gt;The general interface of a channel is as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;trait Channel[T]:&#xA;  def read()(using Async): T&#xA;  def send(x: T)(using Async): Unit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Channels provide&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;a &lt;code&gt;read&lt;/code&gt; method, which might suspend while waiting for a message to arrive,&lt;/li&gt; &#xA; &lt;li&gt;a &lt;code&gt;send&lt;/code&gt; method, which also might suspend in case this is a sync channel or there is some other mechanism that forces a sender to wait,&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Async Channels&lt;/h3&gt; &#xA;&lt;p&gt;An asynchronous channel implements both the &lt;code&gt;Async.Source&lt;/code&gt; and &lt;code&gt;Channel&lt;/code&gt; interfaces. This means inputs from an asynchronous channel can be mapped, filtered or combined with other sources in races.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;class AsyncChannel[T] extends Async.OriginalSource[T], Channel[T]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Synchronous Channels&lt;/h3&gt; &#xA;&lt;p&gt;A sync channel pairs a read request with a send request in a &lt;em&gt;rendezvous&lt;/em&gt;. Readers and/or senders are blocked until a rendezvous between them is established which causes a message to be sent and received. A sync channel provides two separate async sources for reading a message and sending one. The &lt;code&gt;canRead&lt;/code&gt; source provides messages to readers of the channel. The &lt;code&gt;canSend&lt;/code&gt; source provides message listeners to writers that send messages to the channel.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;trait SyncChannel[T] extends Channel[T]:&#xA;&#xA;  val canRead: Async.Source[T]&#xA;  val canSend: Async.Source[Listener[T]]&#xA;&#xA;  def send(x: T)(using Async): Unit = await(canSend)(x)&#xA;  def read()(using Async): T = await(canRead)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Tasks&lt;/h2&gt; &#xA;&lt;p&gt;One criticism leveled against futures is that they &#34;lack referential transparency&#34;. What this means is that a future starts running when it is defined, so passing a reference to a future is not the same as passing the referenced expression itself. Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val x = Future { println(&#34;started&#34;) }&#xA;f(x)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;is not the same as&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val x = Future { println(&#34;started&#34;) }&#xA;f(Future { println(&#34;started&#34;) })&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the first case the program prints &#34;started&#34; once whereas in the second case it prints &#34;started&#34; twice. In a sense that&#39;s exactly what&#39;s intended. After all, the whole point of futures is to get parallelism. So a future should start well before its result is requested and the simplest way to achieve that is to start the future when it is defined. &lt;em&gt;Aside&lt;/em&gt;: I believe the criticism of the existing &lt;code&gt;scala.concurrent.Future&lt;/code&gt; design in Scala 2.13 is understandable, since these futures are usually composed monad-style using for expressions, which informally suggests referential transparency. Direct-style futures like the ones presented here don&#39;t have that problem.&lt;/p&gt; &#xA;&lt;p&gt;On the other hand, the early start of futures &lt;em&gt;does&lt;/em&gt; makes it harder to assemble parallel computations as first class values in data structures and to launch them according to user-defined execution rules. Of course one can still achieve all that by working with functions producing futures instead of futures directly. A function of type &lt;code&gt;() =&amp;gt; Future[T]&lt;/code&gt; will start executing its embedded future only once it is called.&lt;/p&gt; &#xA;&lt;p&gt;Tasks make the definition of such delayed futures a bit easier. The &lt;code&gt;Task&lt;/code&gt; class is defined as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;class Task[+T](val body: Async ?=&amp;gt; T):&#xA;  def run(using Async) = Future(body)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A &lt;code&gt;Task&lt;/code&gt; takes the body of a future as an argument. Its &lt;code&gt;run&lt;/code&gt; method converts that body to a &lt;code&gt;Future&lt;/code&gt;, which means starting its execution.&lt;/p&gt; &#xA;&lt;p&gt;Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  val chan: Channel[Int]&#xA;  val allTasks = List(&#xA;      Task:&#xA;        println(&#34;task1&#34;)&#xA;        chan.read(),&#xA;      Task:&#xA;        println(&#34;task2&#34;)&#xA;        chan.read()&#xA;    )&#xA;&#xA;  def start() = Future:&#xA;    allTasks.map(_.run.value).sum&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Tasks have two advantages over simple lambdas when it comes to delaying futures:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The intent is made clear: This is a delayed computation intended to be executed concurrently in a future once it is started.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;Async&lt;/code&gt; context is implicitly provided, since &lt;code&gt;Task.apply&lt;/code&gt; takes a context function over &lt;code&gt;Async&lt;/code&gt; as argument.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Promises&lt;/h2&gt; &#xA;&lt;p&gt;Sometimes we want to define future&#39;s value externally instead of executing a specific body of code. This can be done using a promise. The design and implementation of promises is simply this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;class Promise[T]:&#xA;  private val myFuture = CoreFuture[T]()&#xA;&#xA;  val future: Future[T] = myFuture&#xA;&#xA;  def complete(result: Try[T]): Unit =&#xA;    myFuture.complete(result)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A promise provides a &lt;code&gt;future&lt;/code&gt; and a way to define the result of that future in its &lt;code&gt;complete&lt;/code&gt; method.&lt;/p&gt; &#xA;&lt;h2&gt;Going Further&lt;/h2&gt; &#xA;&lt;p&gt;The library is expressive enough so that higher-order abstractions over channels can be built with ease. In the following, I outline some of the possible extensions and explain how they could be defined and implemented.&lt;/p&gt; &#xA;&lt;h3&gt;Streams&lt;/h3&gt; &#xA;&lt;p&gt;A stream represents a sequence of values that are computed one-by-one in a separate concurrent computation. Conceptually, streams are simply nested futures, where each future produces one element:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  type Stream[+T] = Future[StreamResult[T]]&#xA;&#xA;  enum StreamResult[+T]:&#xA;    case More(elem: T, rest: Stream[T])&#xA;    case End extends StreamResult[Nothing]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;One can see a stream as a static representation of the values that are transmitted over a channel. This poses the question of termination -- when do we know that a channel receives no further values, so the stream can be terminated with an &lt;code&gt;StreamResult.End&lt;/code&gt; value? The following implementation shows one possibility: Here we map a channel of &lt;code&gt;Try&lt;/code&gt; results to a stream, mapping failures with a special &lt;code&gt;ChannelClosedException&lt;/code&gt; to &lt;code&gt;StreamResult.End&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  extension [T](c: Channel[Try[T]])&#xA;    def toStream(using Async): Stream[T] = Future:&#xA;      c.read() match&#xA;        case Success(x) =&amp;gt; StreamResult.More(x, toStream)&#xA;        case Failure(ex: ChannelClosedException) =&amp;gt; StreamResult.End&#xA;        case Failure(ex) =&amp;gt; throw ex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Coroutines or Fibers&lt;/h3&gt; &#xA;&lt;p&gt;A coroutine or fiber is simply a &lt;code&gt;Future[Unit]&lt;/code&gt;. This might seem surprising at first. Why should we return something from a coroutine or fiber? Well, we certainly do want to observe that a coroutine has terminated, and we also need to handle any exceptions that are thrown from it. A result of type &lt;code&gt;Try[Unit]&lt;/code&gt; has exactly the information we need for this. We typically want to add some supervisor framework that waits for coroutines to terminate and handles failures. A possible setup would be to send terminated coroutines to a channel that is serviced by a supervisor future.&lt;/p&gt; &#xA;&lt;h3&gt;Actors&lt;/h3&gt; &#xA;&lt;p&gt;Similarly, we can model an actor by a &lt;code&gt;Future[Unit]&lt;/code&gt; paired with a channel which serves as the actor&#39;s inbox.&lt;/p&gt; &#xA;&lt;h2&gt;Implementation Details&lt;/h2&gt; &#xA;&lt;h2&gt;Internals of Async Contexts&lt;/h2&gt; &#xA;&lt;p&gt;An async context provides three elements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;an &lt;code&gt;await&lt;/code&gt; method that allows a caller to suspend while waiting for the result of an async source to arrive,&lt;/li&gt; &#xA; &lt;li&gt;a &lt;code&gt;scheduler&lt;/code&gt; value that refers to execution context on which tasks are scheduled,&lt;/li&gt; &#xA; &lt;li&gt;a &lt;code&gt;group&lt;/code&gt; value that contains a cancellation group which determines the default linkage of all cancellable objects that are created in an async context.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Implementing Await&lt;/h2&gt; &#xA;&lt;p&gt;The most interesting part of an async context is its implementation of the &lt;code&gt;await&lt;/code&gt; method. These implementations need to be based on a lower-level mechanism of suspensions or green threads.&lt;/p&gt; &#xA;&lt;h3&gt;Using Delimited Continuations&lt;/h3&gt; &#xA;&lt;p&gt;We first describe the implementation if support for full delimited continuations is available. We assume in this case a trait&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;trait Suspension[-T, +R]:&#xA;  def resume(arg: T): R = ???&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and a method&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def suspend[T, R](body: Suspension[T, R] =&amp;gt; R)(using Label[R]): T = ???&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A call of &lt;code&gt;suspend(body)&lt;/code&gt; captures the continuation up to an enclosing boundary in a &lt;code&gt;Suspension&lt;/code&gt; object and passes it to &lt;code&gt;body&lt;/code&gt;. The continuation can be resumed by calling the suspension&#39;s &lt;code&gt;resume&lt;/code&gt; method. The enclosing boundary is the one which created the implicit &lt;code&gt;Label&lt;/code&gt; argument.&lt;/p&gt; &#xA;&lt;p&gt;Using this infrastructure, &lt;code&gt;await&lt;/code&gt; can be implemented like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def await[T](src: Async.Source[T]): T =&#xA;    checkCancellation()&#xA;    src.poll().getOrElse:&#xA;      try&#xA;        suspend[T, Unit]: k =&amp;gt;&#xA;          src.onComplete: x =&amp;gt;&#xA;            scheduler.schedule: () =&amp;gt;&#xA;              k.resume(x)&#xA;            true // signals to `src` that result `x` was consumed&#xA;      finally checkCancellation()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Notes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The main body of &lt;code&gt;await&lt;/code&gt; is enclosed by two &lt;code&gt;checkCancellation&lt;/code&gt; calls that abort the computation with a &lt;code&gt;CancellationException&lt;/code&gt; in case of a cancel request.&lt;/li&gt; &#xA; &lt;li&gt;Await first polls the async source and returns the result if one is present.&lt;/li&gt; &#xA; &lt;li&gt;If no result is present, it suspends the computation and adds a listener to the source via its &lt;code&gt;onComplete&lt;/code&gt; method. The listener is generated via a SAM conversion from the closure following &lt;code&gt;x =&amp;gt;&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If the listener is invoked with a result, it resumes the suspension with that result argument in a newly scheduled task. The listener returns &lt;code&gt;true&lt;/code&gt; to indicate that the result value was consumed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;An Async context with this version of &lt;code&gt;await&lt;/code&gt; is used in the following implementation of &lt;code&gt;async&lt;/code&gt;, the wrapper for the body of a future:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;private def async(body: Async ?=&amp;gt; Unit): Unit =&#xA;  class FutureAsync ... extends Async:&#xA;    def await[T](src: Async.Source[T]): T = ...&#xA;    ...&#xA;&#xA;  boundary [Unit]:&#xA;    body(using FutureAsync(...))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using Fibers&lt;/h3&gt; &#xA;&lt;p&gt;On a runtime that only provides fibers (&lt;em&gt;aka&lt;/em&gt; green threads), the implementation of &lt;code&gt;await&lt;/code&gt; is a bit more complicated, since we cannot suspend awaiting an argument value. We can work around this restriction by re-formulating the body of &lt;code&gt;await&lt;/code&gt; as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def await[T](src: Async.Source[T]): T =&#xA;    checkCancellation()&#xA;    src.poll().getOrElse:&#xA;      try&#xA;        var result: Option[T] = None&#xA;        src.onComplete: x =&amp;gt;&#xA;          synchronized:&#xA;            result = Some(x)&#xA;            notify()&#xA;          true&#xA;        synchronized:&#xA;          while result.isEmpty do wait()&#xA;          result.get&#xA;      finally checkCancellation()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Only the body of the &lt;code&gt;try&lt;/code&gt; is different from the previous implementation. Here we now create a variable holding an optional result value. The computation &lt;code&gt;wait&lt;/code&gt;s until the result value is defined. The variable becomes is set to a defined value when the listener is invoked, followed by a call to &lt;code&gt;notify()&lt;/code&gt; to wake up the waiting fiber.&lt;/p&gt; &#xA;&lt;p&gt;Since the whole fiber suspends, we don&#39;t need a &lt;code&gt;boundary&lt;/code&gt; anymore to delineate the limit of a continuation, so the &lt;code&gt;async&lt;/code&gt; can be defined as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;private def async(body: Async ?=&amp;gt; Unit): Unit =&#xA;  class FutureAsync(...) extends Async:&#xA;    def await[T](src: Async.Source[T]): T = ...&#xA;    ...&#xA;&#xA;  body(using FutureAsync(...))&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>