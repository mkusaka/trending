<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-09T02:01:43Z</updated>
  <subtitle>Weekly Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>twitter/the-algorithm</title>
    <updated>2023-04-09T02:01:43Z</updated>
    <id>tag:github.com,2023-04-09:/twitter/the-algorithm</id>
    <link href="https://github.com/twitter/the-algorithm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Source code for Twitter&#39;s Recommendation Algorithm&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Twitter&#39;s Recommendation Algorithm&lt;/h1&gt; &#xA;&lt;p&gt;Twitter&#39;s Recommendation Algorithm is a set of services and jobs that are responsible for constructing and serving the Home Timeline. For an introduction to how the algorithm works, please refer to our &lt;a href=&#34;https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm&#34;&gt;engineering blog&lt;/a&gt;. The diagram below illustrates how major services and jobs interconnect.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/docs/system-diagram.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;These are the main components of the Recommendation Algorithm included in this repository:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Component&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Feature&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/simclusters_v2/README.md&#34;&gt;SimClusters&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Community detection and sparse embeddings into those communities.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/twitter/the-algorithm-ml/raw/main/projects/twhin/README.md&#34;&gt;TwHIN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Dense knowledge graph embeddings for Users and Tweets.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/trust_and_safety_models/README.md&#34;&gt;trust-and-safety-models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Models for detecting NSFW or abusive content.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/interaction_graph/README.md&#34;&gt;real-graph&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Model to predict the likelihood of a Twitter User interacting with another User.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/graph/batch/job/tweepcred/README&#34;&gt;tweepcred&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Page-Rank algorithm for calculating Twitter User reputation.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/recos-injector/README.md&#34;&gt;recos-injector&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Streaming event processor for building input streams for &lt;a href=&#34;https://github.com/twitter/GraphJet&#34;&gt;GraphJet&lt;/a&gt; based services.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/graph-feature-service/README.md&#34;&gt;graph-feature-service&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Serves graph features for a directed pair of Users (e.g. how many of User A&#39;s following liked Tweets from User B).&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Candidate Source&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/java/com/twitter/search/README.md&#34;&gt;search-index&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Find and rank In-Network Tweets. ~50% of Tweets come from this candidate source.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/cr-mixer/README.md&#34;&gt;cr-mixer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Coordination layer for fetching Out-of-Network tweet candidates from underlying compute services.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/recos/user_tweet_entity_graph/README.md&#34;&gt;user-tweet-entity-graph&lt;/a&gt; (UTEG)&lt;/td&gt; &#xA;   &lt;td&gt;Maintains an in memory User to Tweet interaction graph, and finds candidates based on traversals of this graph. This is built on the &lt;a href=&#34;https://github.com/twitter/GraphJet&#34;&gt;GraphJet&lt;/a&gt; framework. Several other GraphJet based features and candidate sources are located &lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/recos&#34;&gt;here&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/follow-recommendations-service/README.md&#34;&gt;follow-recommendation-service&lt;/a&gt; (FRS)&lt;/td&gt; &#xA;   &lt;td&gt;Provides Users with recommendations for accounts to follow, and Tweets from those accounts.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ranking&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/README.md&#34;&gt;light-ranker&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Light Ranker model used by search index (Earlybird) to rank Tweets.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/twitter/the-algorithm-ml/raw/main/projects/home/recap/README.md&#34;&gt;heavy-ranker&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Neural network for ranking candidate tweets. One of the main signals used to select timeline Tweets post candidate sourcing.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Tweet mixing &amp;amp; filtering&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/home-mixer/README.md&#34;&gt;home-mixer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Main service used to construct and serve the Home Timeline. Built on &lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/product-mixer/README.md&#34;&gt;product-mixer&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/visibilitylib/README.md&#34;&gt;visibility-filters&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Responsible for filtering Twitter content to support legal compliance, improve product quality, increase user trust, protect revenue through the use of hard-filtering, visible product treatments, and coarse-grained downranking.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/timelineranker/README.md&#34;&gt;timelineranker&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Legacy service which provides relevance-scored tweets from the Earlybird Search Index and UTEG service.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Software framework&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/navi/README.md&#34;&gt;navi&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;High performance, machine learning model serving written in Rust.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/product-mixer/README.md&#34;&gt;product-mixer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Software framework for building feeds of content.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/twitter/the-algorithm/main/twml/README.md&#34;&gt;twml&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Legacy machine learning framework built on TensorFlow v1.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;We include Bazel BUILD files for most components, but not a top-level BUILD or WORKSPACE file.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We invite the community to submit GitHub issues and pull requests for suggestions on improving the recommendation algorithm. We are working on tools to manage these suggestions and sync changes to our internal repository. Any security concerns or issues should be routed to our official &lt;a href=&#34;https://hackerone.com/twitter&#34;&gt;bug bounty program&lt;/a&gt; through HackerOne. We hope to benefit from the collective intelligence and expertise of the global community in helping us identify issues and suggest improvements, ultimately leading to a better Twitter.&lt;/p&gt; &#xA;&lt;p&gt;Read our blog on the open source initiative &lt;a href=&#34;https://blog.twitter.com/en_us/topics/company/2023/a-new-era-of-transparency-for-twitter&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>delta-io/delta-sharing</title>
    <updated>2023-04-09T02:01:43Z</updated>
    <id>tag:github.com,2023-04-09:/delta-io/delta-sharing</id>
    <link href="https://github.com/delta-io/delta-sharing" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An open protocol for secure data sharing&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/1446829/144671151-b095e1b9-2d24-4d3b-b3c6-a7041e491077.png&#34; alt=&#34;Delta Sharing Logo&#34; width=&#34;200&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;Delta Sharing: An Open Protocol for Secure Data Sharing&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/delta-io/delta-sharing/actions/workflows/build-and-test.yml&#34;&gt;&lt;img src=&#34;https://github.com/delta-io/delta-sharing/actions/workflows/build-and-test.yml/badge.svg?sanitize=true&#34; alt=&#34;Build and Test&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/delta-io/delta-sharing/raw/main/LICENSE.txt&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-brightgreen.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/delta-sharing/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/delta-sharing.svg?sanitize=true&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://delta.io/sharing&#34;&gt;Delta Sharing&lt;/a&gt; is an open protocol for secure real-time exchange of large datasets, which enables organizations to share data in real time regardless of which computing platforms they use. It is a simple &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&#34;&gt;REST protocol&lt;/a&gt; that securely shares access to part of a cloud dataset and leverages modern cloud storage systems, such as S3, ADLS, or GCS, to reliably transfer data.&lt;/p&gt; &#xA;&lt;p&gt;With Delta Sharing, a user accessing shared data can directly connect to it through pandas, Tableau, Apache Spark, Rust, or other systems that support the open protocol, without having to deploy a specific compute platform first. Data providers can share a dataset once to reach a broad range of consumers, while consumers can begin using the data in minutes.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/images/delta-sharing.png&#34; width=&#34;85%&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;This repo includes the following components:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Delta Sharing &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&#34;&gt;protocol specification&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Python Connector: A Python library that implements the Delta Sharing Protocol to read shared tables as &lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;pandas&lt;/a&gt; DataFrame or &lt;a href=&#34;http://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt; DataFrames.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt; Connector: An Apache Spark connector that implements the Delta Sharing Protocol to read shared tables from a Delta Sharing Server. The tables can then be accessed in SQL, Python, Java, Scala, or R.&lt;/li&gt; &#xA; &lt;li&gt;Delta Sharing Server: A reference implementation server for the Delta Sharing Protocol for development purposes. Users can deploy this server to share existing tables in Delta Lake and Apache Parquet format on modern cloud storage systems.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Python Connector&lt;/h1&gt; &#xA;&lt;p&gt;The Delta Sharing Python Connector is a Python library that implements the &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&#34;&gt;Delta Sharing Protocol&lt;/a&gt; to read tables from a Delta Sharing Server. You can load shared tables as a &lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;pandas&lt;/a&gt; DataFrame, or as an &lt;a href=&#34;http://spark.apache.org/&#34;&gt;Apache Spark&lt;/a&gt; DataFrame if running in PySpark with the Apache Spark Connector installed.&lt;/p&gt; &#xA;&lt;h2&gt;System Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Python 3.6+&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install delta-sharing&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are using &lt;a href=&#34;https://docs.databricks.com/runtime/dbr.html&#34;&gt;Databricks Runtime&lt;/a&gt;, you can follow &lt;a href=&#34;https://docs.databricks.com/libraries/index.html&#34;&gt;Databricks Libraries doc&lt;/a&gt; to install the library on your clusters.&lt;/p&gt; &#xA;&lt;h2&gt;Accessing Shared Data&lt;/h2&gt; &#xA;&lt;p&gt;The connector accesses shared tables based on &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md#profile-file-format&#34;&gt;profile files&lt;/a&gt;, which are JSON files containing a user&#39;s credentials to access a Delta Sharing Server. We have several ways to get started:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download the profile file to access an open, example Delta Sharing Server that we&#39;re hosting &lt;a href=&#34;https://databricks-datasets-oregon.s3-us-west-2.amazonaws.com/delta-sharing/share/open-datasets.share&#34;&gt;here&lt;/a&gt;. You can try the connectors with this sample data.&lt;/li&gt; &#xA; &lt;li&gt;Start your own &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/#delta-sharing-reference-server&#34;&gt;Delta Sharing Server&lt;/a&gt; and create your own profile file following &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md#profile-file-format&#34;&gt;profile file format&lt;/a&gt; to connect to this server.&lt;/li&gt; &#xA; &lt;li&gt;Download a profile file from your data provider.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;After you save the profile file, you can use it in the connector to access shared tables.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import delta_sharing&#xA;&#xA;# Point to the profile file. It can be a file on the local file system or a file on a remote storage.&#xA;profile_file = &#34;&amp;lt;profile-file-path&amp;gt;&#34;&#xA;&#xA;# Create a SharingClient.&#xA;client = delta_sharing.SharingClient(profile_file)&#xA;&#xA;# List all shared tables.&#xA;client.list_all_tables()&#xA;&#xA;# Create a url to access a shared table.&#xA;# A table path is the profile file path following with `#` and the fully qualified name of a table &#xA;# (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).&#xA;table_url = profile_file + &#34;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&#34;&#xA;&#xA;# Fetch 10 rows from a table and convert it to a Pandas DataFrame. This can be used to read sample data &#xA;# from a table that cannot fit in the memory.&#xA;delta_sharing.load_as_pandas(table_url, limit=10)&#xA;&#xA;# Load a table as a Pandas DataFrame. This can be used to process tables that can fit in the memory.&#xA;delta_sharing.load_as_pandas(table_url)&#xA;&#xA;# If the code is running with PySpark, you can use `load_as_spark` to load the table as a Spark DataFrame.&#xA;delta_sharing.load_as_spark(table_url)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the table supports history sharing(&lt;code&gt;tableConfig.cdfEnabled=true&lt;/code&gt; in the OSS Delta Sharing Server), the connector can query table changes.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Load table changes from version 0 to version 5, as a Pandas DataFrame.&#xA;delta_sharing.load_table_changes_as_pandas(table_url, starting_version=0, ending_version=5)&#xA;&#xA;# If the code is running with PySpark, you can load table changes as Spark DataFrame.&#xA;delta_sharing.load_table_changes_as_spark(table_url, starting_version=0, ending_version=5)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can try this by running our &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/examples/README.md&#34;&gt;examples&lt;/a&gt; with the open, example Delta Sharing Server.&lt;/p&gt; &#xA;&lt;h3&gt;Details on Profile Paths&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The profile file path for &lt;code&gt;SharingClient&lt;/code&gt; and &lt;code&gt;load_as_pandas&lt;/code&gt; can be any URL supported by &lt;a href=&#34;https://filesystem-spec.readthedocs.io/en/latest/index.html&#34;&gt;FSSPEC&lt;/a&gt; (such as &lt;code&gt;s3a://my_bucket/my/profile/file&lt;/code&gt;). If you are using &lt;a href=&#34;https://docs.databricks.com/data/databricks-file-system.html&#34;&gt;Databricks File System&lt;/a&gt;, you can also &lt;a href=&#34;https://docs.databricks.com/data/databricks-file-system.html#dbfs-and-local-driver-node-paths&#34;&gt;preface the path with &lt;code&gt;/dbfs/&lt;/code&gt;&lt;/a&gt; to access the profile file as if it were a local file.&lt;/li&gt; &#xA; &lt;li&gt;The profile file path for &lt;code&gt;load_as_spark&lt;/code&gt; can be any URL supported by Hadoop FileSystem (such as &lt;code&gt;s3a://my_bucket/my/profile/file&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;A table path is the profile file path following with &lt;code&gt;#&lt;/code&gt; and the fully qualified name of a table (&lt;code&gt;&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&lt;/code&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Apache Spark Connector&lt;/h1&gt; &#xA;&lt;p&gt;The Apache Spark Connector implements the &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&#34;&gt;Delta Sharing Protocol&lt;/a&gt; to read shared tables from a Delta Sharing Server. It can be used in SQL, Python, Java, Scala and R.&lt;/p&gt; &#xA;&lt;h2&gt;System Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Java 8+&lt;/li&gt; &#xA; &lt;li&gt;Scala 2.12.x&lt;/li&gt; &#xA; &lt;li&gt;Apache Spark 3+ or &lt;a href=&#34;https://docs.databricks.com/runtime/dbr.html&#34;&gt;Databricks Runtime&lt;/a&gt; 7+&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Accessing Shared Data&lt;/h2&gt; &#xA;&lt;p&gt;The connector loads user credentials from profile files. Please see &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/#accessing-shared-data&#34;&gt;Accessing Shared Data&lt;/a&gt; to download a profile file for our example server or for your own data sharing server.&lt;/p&gt; &#xA;&lt;h2&gt;Configuring Apache Spark&lt;/h2&gt; &#xA;&lt;p&gt;You can set up Apache Spark to load the Delta Sharing connector in the following two ways:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run interactively: Start the Spark shell (Scala or Python) with the Delta Sharing connector and run the code snippets interactively in the shell.&lt;/li&gt; &#xA; &lt;li&gt;Run as a project: Set up a Maven or SBT project (Scala or Java) with the Delta Sharing connector, copy the code snippets into a source file, and run the project.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you are using &lt;a href=&#34;https://docs.databricks.com/runtime/dbr.html&#34;&gt;Databricks Runtime&lt;/a&gt;, you can skip this section and follow &lt;a href=&#34;https://docs.databricks.com/libraries/index.html&#34;&gt;Databricks Libraries doc&lt;/a&gt; to install the connector on your clusters.&lt;/p&gt; &#xA;&lt;h3&gt;Set up an interactive shell&lt;/h3&gt; &#xA;&lt;p&gt;To use Delta Sharing connector interactively within the Spark’s Scala/Python shell, you can launch the shells as follows.&lt;/p&gt; &#xA;&lt;h4&gt;PySpark shell&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;pyspark --packages io.delta:delta-sharing-spark_2.12:0.6.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Scala Shell&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;bin/spark-shell --packages io.delta:delta-sharing-spark_2.12:0.6.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Set up a standalone project&lt;/h3&gt; &#xA;&lt;p&gt;If you want to build a Java/Scala project using Delta Sharing connector from Maven Central Repository, you can use the following Maven coordinates.&lt;/p&gt; &#xA;&lt;h4&gt;Maven&lt;/h4&gt; &#xA;&lt;p&gt;You include Delta Sharing connector in your Maven project by adding it as a dependency in your POM file. Delta Sharing connector is compiled with Scala 2.12.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;&#xA;  &amp;lt;groupId&amp;gt;io.delta&amp;lt;/groupId&amp;gt;&#xA;  &amp;lt;artifactId&amp;gt;delta-sharing-spark_2.12&amp;lt;/artifactId&amp;gt;&#xA;  &amp;lt;version&amp;gt;0.6.2&amp;lt;/version&amp;gt;&#xA;&amp;lt;/dependency&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;SBT&lt;/h4&gt; &#xA;&lt;p&gt;You include Delta Sharing connector in your SBT project by adding the following line to your &lt;code&gt;build.sbt&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;libraryDependencies += &#34;io.delta&#34; %% &#34;delta-sharing-spark&#34; % &#34;0.6.2&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;After you save the profile file and launch Spark with the connector library, you can access shared tables using any language.&lt;/p&gt; &#xA;&lt;h3&gt;SQL&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- A table path is the profile file path following with `#` and the fully qualified name &#xA;-- of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).&#xA;CREATE TABLE mytable USING deltaSharing LOCATION &#39;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&#39;;&#xA;SELECT * FROM mytable;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Python&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# A table path is the profile file path following with `#` and the fully qualified name &#xA;# of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).&#xA;table_path = &#34;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&#34;&#xA;df = spark.read.format(&#34;deltaSharing&#34;).load(table_path)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Scala&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// A table path is the profile file path following with `#` and the fully qualified name &#xA;// of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).&#xA;val tablePath = &#34;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&#34;&#xA;val df = spark.read.format(&#34;deltaSharing&#34;).load(tablePath)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Java&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// A table path is the profile file path following with `#` and the fully qualified name &#xA;// of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).&#xA;String tablePath = &#34;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&#34;;&#xA;Dataset&amp;lt;Row&amp;gt; df = spark.read.format(&#34;deltaSharing&#34;).load(tablePath);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;R&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# A table path is the profile file path following with `#` and the fully qualified name &#xA;# of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).&#xA;table_path &amp;lt;- &#34;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&#34;&#xA;df &amp;lt;- read.df(table_path, &#34;deltaSharing&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can try this by running our &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/examples/README.md&#34;&gt;examples&lt;/a&gt; with the open, example Delta Sharing Server.&lt;/p&gt; &#xA;&lt;h3&gt;CDF&lt;/h3&gt; &#xA;&lt;p&gt;Starting from release 0.5.0, querying &lt;a href=&#34;https://docs.databricks.com/delta/delta-change-data-feed.html&#34;&gt;Change Data Feed&lt;/a&gt; is supported with Delta Sharing. Once the provider turns on CDF on the original delta table and shares it through Delta Sharing, the recipient can query CDF of a Delta Sharing table similar to CDF of a delta table.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val tablePath = &#34;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&#34;&#xA;val df = spark.read.format(&#34;deltaSharing&#34;)&#xA;  .option(&#34;readChangeFeed&#34;, &#34;true&#34;)&#xA;  .option(&#34;startingVersion&#34;, &#34;3&#34;)&#xA;  .load(tablePath)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Streaming&lt;/h3&gt; &#xA;&lt;p&gt;Starting from release 0.6.0, Delta Sharing table can be used as a data source for &lt;a href=&#34;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html&#34;&gt;Spark Structured Streaming&lt;/a&gt;. Once the provider shares a table with history, the recipient can perform a streaming query on the table.&lt;/p&gt; &#xA;&lt;p&gt;Note: Trigger.AvailableNow is not supported in delta sharing streaming because it&#39;s supported since spark 3.3.0, while delta sharing is still using spark 3.1.1.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val tablePath = &#34;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&#34;&#xA;val df = spark.readStream.format(&#34;deltaSharing&#34;)&#xA;  .option(&#34;startingVersion&#34;, &#34;1&#34;)&#xA;  .option(&#34;skipChangeCommits&#34;, &#34;true&#34;)&#xA;  .load(tablePath)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Table paths&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A profile file path can be any URL supported by Hadoop FileSystem (such as &lt;code&gt;s3a://my_bucket/my/profile/file&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;A table path is the profile file path following with &lt;code&gt;#&lt;/code&gt; and the fully qualified name of a table (&lt;code&gt;&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&lt;/code&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;The Community&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/87341375/212409874-a4ef350f-3b32-4031-b2cd-8c4e47cc42e2.jpeg&#34; alt=&#34;Delta Sharing OSS Connectors&#34; width=&#34;400&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Connector&lt;/th&gt; &#xA;   &lt;th&gt;Link&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;   &lt;th&gt;Supported Features&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Power BI&lt;/td&gt; &#xA;   &lt;td&gt;Databricks owned&lt;/td&gt; &#xA;   &lt;td&gt;Released&lt;/td&gt; &#xA;   &lt;td&gt;QueryTableVersion&lt;br&gt;QueryTableMetadata&lt;br&gt;QueryTableLatestSnapshot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Node.js&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/goodwillpunning/nodejs-sharing-client&#34;&gt;goodwillpunning/nodejs-sharing-client&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Released&lt;/td&gt; &#xA;   &lt;td&gt;QueryTableVersion&lt;br&gt;QueryTableMetadata&lt;br&gt;QueryTableLatestSnapshot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Java&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/databrickslabs/delta-sharing-java-connector&#34;&gt;databrickslabs/delta-sharing-java-connector&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Released&lt;/td&gt; &#xA;   &lt;td&gt;QueryTableVersion&lt;br&gt;QueryTableMetadata&lt;br&gt;QueryTableLatestSnapshot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Arcuate&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/databrickslabs/arcuate&#34;&gt;databrickslabs/arcuate&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Released&lt;/td&gt; &#xA;   &lt;td&gt;QueryTableVersion&lt;br&gt;QueryTableMetadata&lt;br&gt;QueryTableLatestSnapshot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Rust&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/r3stl355/delta-sharing-rust-client&#34;&gt;r3stl355/delta-sharing-rust-client&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Released&lt;/td&gt; &#xA;   &lt;td&gt;QueryTableVersion&lt;br&gt;QueryTableMetadata&lt;br&gt;QueryTableLatestSnapshot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Go&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/magpierre/delta-sharing/tree/golangdev/golang/delta_sharing_go&#34;&gt;magpierre/delta-sharing&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Released&lt;/td&gt; &#xA;   &lt;td&gt;QueryTableVersion&lt;br&gt;QueryTableMetadata&lt;br&gt;QueryTableLatestSnapshot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;C++&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/magpierre/delta-sharing/tree/cppdev/cpp/DeltaSharingClient&#34;&gt;magpierre/delta-sharing&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Released&lt;/td&gt; &#xA;   &lt;td&gt;QueryTableMetadata&lt;br&gt;QueryTableLatestSnapshot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;R&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/zacdav-db/delta-sharing-r&#34;&gt;zacdav-db/delta-sharing-r&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Released&lt;/td&gt; &#xA;   &lt;td&gt;QueryTableVersion&lt;br&gt;QueryTableMetadata&lt;br&gt;QueryTableLatestSnapshot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Google Spreadsheet&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/delta-incubator/delta-sharing-connectors/tree/main/google_workspace_add_on&#34;&gt;delta-incubator/delta-sharing-connectors&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Beta&lt;/td&gt; &#xA;   &lt;td&gt;QueryTableVersion&lt;br&gt;QueryTableMetadata&lt;br&gt;QueryTableLatestSnapshot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Airflow&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/apache/airflow/pull/22692&#34;&gt;apache/airflow&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Un-released&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Excel-Connector&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://www.exponam.com/solutions/&#34;&gt;https://www.exponam.com/solutions/&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;limited-release&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lakehouse Sharing&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/rajagurunath/lakehouse-sharing&#34;&gt;rajagurunath/lakehouse-sharing&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Preview&lt;/td&gt; &#xA;   &lt;td&gt; &lt;p&gt;&lt;a href=&#34;https://guruengineering.substack.com/p/lakehouse-sharing&#34;&gt;Demonstrates&lt;/a&gt; a table format agnostic data sharing&lt;br&gt; server (based on delta-sharing protocol) implemented in python for both Delta Lake and Iceberg formats.&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Delta Sharing Reference Server&lt;/h1&gt; &#xA;&lt;p&gt;The Delta Sharing Reference Server is a reference implementation server for the &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&#34;&gt;Delta Sharing Protocol&lt;/a&gt;. This can be used to set up a small service to test your own connector that implements the &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&#34;&gt;Delta Sharing Protocol&lt;/a&gt;. Please note that this is not a completed implementation of secure web server. We highly recommend you to put this behind a secure proxy if you would like to expose it to public.&lt;/p&gt; &#xA;&lt;p&gt;Some vendors offer managed services for Delta Sharing too (for example, &lt;a href=&#34;https://databricks.com/product/delta-sharing&#34;&gt;Databricks&lt;/a&gt;). Please refer to your vendor&#39;s website for how to set up sharing there. Vendors that are interested in being listed as a service provider should open an issue on GitHub to be added to this README and our project&#39;s website.&lt;/p&gt; &#xA;&lt;p&gt;Here are the steps to setup the reference server to share your own data.&lt;/p&gt; &#xA;&lt;h2&gt;Get the pre-built package&lt;/h2&gt; &#xA;&lt;p&gt;Download the pre-built package &lt;code&gt;delta-sharing-server-x.y.z.zip&lt;/code&gt; from &lt;a href=&#34;https://github.com/delta-io/delta-sharing/releases&#34;&gt;GitHub Releases&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Server configuration and adding Shared Data&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Unpack the pre-built package and copy the server config template file &lt;code&gt;conf/delta-sharing-server.yaml.template&lt;/code&gt; to create your own server yaml file, such as &lt;code&gt;conf/delta-sharing-server.yaml&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Make changes to your yaml file. You may also need to update some server configs for special requirements.&lt;/li&gt; &#xA; &lt;li&gt;To add Shared Data, add reference to Delta Lake tables you would like to share from this server in this config file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Config the server to access tables on cloud storage&lt;/h2&gt; &#xA;&lt;p&gt;We support sharing Delta Lake tables on S3, Azure Blob Storage and Azure Data Lake Storage Gen2.&lt;/p&gt; &#xA;&lt;h3&gt;S3&lt;/h3&gt; &#xA;&lt;p&gt;The server is using &lt;code&gt;hadoop-aws&lt;/code&gt; to access S3. Table paths in the server config file should use &lt;code&gt;s3a://&lt;/code&gt; paths rather than &lt;code&gt;s3://&lt;/code&gt; paths. There are multiple ways to config S3 authentication.&lt;/p&gt; &#xA;&lt;h4&gt;EC2 IAM Metadata Authentication (Recommended)&lt;/h4&gt; &#xA;&lt;p&gt;Applications running in EC2 may associate an IAM role with the VM and query the &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html&#34;&gt;EC2 Instance Metadata Service&lt;/a&gt; for credentials to access S3.&lt;/p&gt; &#xA;&lt;h4&gt;Authenticating via the AWS Environment Variables&lt;/h4&gt; &#xA;&lt;p&gt;We support configuration via &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html#cli-environment&#34;&gt;the standard AWS environment variables&lt;/a&gt;. The core environment variables are for the access key and associated secret:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=my.aws.key&#xA;export AWS_SECRET_ACCESS_KEY=my.secret.key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Other S3 authentication methods&lt;/h4&gt; &#xA;&lt;p&gt;You can find other approaches in &lt;a href=&#34;https://hadoop.apache.org/docs/r2.10.1/hadoop-aws/tools/hadoop-aws/index.html#S3A_Authentication_methods&#34;&gt;hadoop-aws doc&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Azure Blob Storage&lt;/h3&gt; &#xA;&lt;p&gt;The server is using &lt;code&gt;hadoop-azure&lt;/code&gt; to read Azure Blob Storage. Using Azure Blob Storage requires &lt;a href=&#34;https://hadoop.apache.org/docs/current/hadoop-azure/index.html#Configuring_Credentials&#34;&gt;configuration of credentials&lt;/a&gt;. You can create a Hadoop configuration file named &lt;code&gt;core-site.xml&lt;/code&gt; and add it to the server&#39;s &lt;code&gt;conf&lt;/code&gt; directory. Then add the following content to the xml file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&#34;1.0&#34;?&amp;gt;&#xA;&amp;lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&amp;gt;&#xA;&amp;lt;configuration&amp;gt;&#xA;  &amp;lt;property&amp;gt;&#xA;    &amp;lt;name&amp;gt;fs.azure.account.key.YOUR-ACCOUNT-NAME.blob.core.windows.net&amp;lt;/name&amp;gt;&#xA;    &amp;lt;value&amp;gt;YOUR-ACCOUNT-KEY&amp;lt;/value&amp;gt;&#xA;  &amp;lt;/property&amp;gt;&#xA;&amp;lt;/configuration&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;YOUR-ACCOUNT-NAME&lt;/code&gt; is your Azure storage account and &lt;code&gt;YOUR-ACCOUNT-KEY&lt;/code&gt; is your account key.&lt;/p&gt; &#xA;&lt;h3&gt;Azure Data Lake Storage Gen2&lt;/h3&gt; &#xA;&lt;p&gt;The server is using &lt;code&gt;hadoop-azure&lt;/code&gt; to read Azure Data Lake Storage Gen2. We support &lt;a href=&#34;https://hadoop.apache.org/docs/stable/hadoop-azure/abfs.html#Default:_Shared_Key&#34;&gt;the Shared Key authentication&lt;/a&gt;. You can create a Hadoop configuration file named &lt;code&gt;core-site.xml&lt;/code&gt; and add it to the server&#39;s &lt;code&gt;conf&lt;/code&gt; directory. Then add the following content to the xml file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&#34;1.0&#34;?&amp;gt;&#xA;&amp;lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&amp;gt;&#xA;&amp;lt;configuration&amp;gt;&#xA;  &amp;lt;property&amp;gt;&#xA;    &amp;lt;name&amp;gt;fs.azure.account.auth.type.YOUR-ACCOUNT-NAME.dfs.core.windows.net&amp;lt;/name&amp;gt;&#xA;    &amp;lt;value&amp;gt;SharedKey&amp;lt;/value&amp;gt;&#xA;    &amp;lt;description&amp;gt;&#xA;    &amp;lt;/description&amp;gt;&#xA;  &amp;lt;/property&amp;gt;&#xA;  &amp;lt;property&amp;gt;&#xA;    &amp;lt;name&amp;gt;fs.azure.account.key.YOUR-ACCOUNT-NAME.dfs.core.windows.net&amp;lt;/name&amp;gt;&#xA;    &amp;lt;value&amp;gt;YOUR-ACCOUNT-KEY&amp;lt;/value&amp;gt;&#xA;    &amp;lt;description&amp;gt;&#xA;    The secret password. Never share these.&#xA;    &amp;lt;/description&amp;gt;&#xA;  &amp;lt;/property&amp;gt;&#xA;&amp;lt;/configuration&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;YOUR-ACCOUNT-NAME&lt;/code&gt; is your Azure storage account and &lt;code&gt;YOUR-ACCOUNT-KEY&lt;/code&gt; is your account key.&lt;/p&gt; &#xA;&lt;h3&gt;Google Cloud Storage&lt;/h3&gt; &#xA;&lt;p&gt;We support using &lt;a href=&#34;https://cloud.google.com/iam/docs/service-accounts&#34;&gt;Service Account&lt;/a&gt; to read Google Cloud Storage. You can find more details in &lt;a href=&#34;https://cloud.google.com/docs/authentication/getting-started&#34;&gt;GCP Authentication Doc&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To set up the Service Account credentials, you can specify the environment GOOGLE_APPLICATION_CREDENTIALS before starting the Delta Sharing Server.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export GOOGLE_APPLICATION_CREDENTIALS=&#34;KEY_PATH&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Replace &lt;code&gt;KEY_PATH&lt;/code&gt; with path of the JSON file that contains your service account key.&lt;/p&gt; &#xA;&lt;h2&gt;Authorization&lt;/h2&gt; &#xA;&lt;p&gt;The server supports a basic authorization with pre-configed bearer token. You can add the following config to your server yaml file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;authorization:&#xA;  bearerToken: &amp;lt;token&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then any request should send with the above token, otherwise, the server will refuse the request.&lt;/p&gt; &#xA;&lt;p&gt;If you don&#39;t config the bearer token in the server yaml file, all requests will be accepted without authorization.&lt;/p&gt; &#xA;&lt;p&gt;To be more secure, you recommend you to put the server behind a secure proxy such as &lt;a href=&#34;https://www.nginx.com/&#34;&gt;NGINX&lt;/a&gt; to set up &lt;a href=&#34;https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-jwt-authentication/&#34;&gt;JWT Authentication&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Start the server&lt;/h2&gt; &#xA;&lt;p&gt;Run the following shell command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bin/delta-sharing-server -- --config &amp;lt;the-server-config-yaml-file&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;&amp;lt;the-server-config-yaml-file&amp;gt;&lt;/code&gt; should be the path of the yaml file you created in the previous step. You can find options to config JVM in &lt;a href=&#34;https://www.scala-sbt.org/sbt-native-packager/archetypes/java_app/index.html#start-script-options&#34;&gt;sbt-native-packager&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Use the pre-built Docker image&lt;/h2&gt; &#xA;&lt;p&gt;You can use the pre-built docker image from &lt;a href=&#34;https://hub.docker.com/r/deltaio/delta-sharing-server&#34;&gt;https://hub.docker.com/r/deltaio/delta-sharing-server&lt;/a&gt; by running the following command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -p &amp;lt;host-port&amp;gt;:&amp;lt;container-port&amp;gt; \&#xA;  --mount type=bind,source=&amp;lt;the-server-config-yaml-file&amp;gt;,target=/config/delta-sharing-server-config.yaml \&#xA;  deltaio/delta-sharing-server:0.6.2 -- --config /config/delta-sharing-server-config.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that &lt;code&gt;&amp;lt;container-port&amp;gt;&lt;/code&gt; should be the same as the port defined inside the config file.&lt;/p&gt; &#xA;&lt;h2&gt;API Compatibility&lt;/h2&gt; &#xA;&lt;p&gt;The REST APIs provided by Delta Sharing Server are stable public APIs. They are defined by &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&#34;&gt;Delta Sharing Protocol&lt;/a&gt; and we will follow the entire protocol strictly.&lt;/p&gt; &#xA;&lt;p&gt;The interfaces inside Delta Sharing Server are not public APIs. They are considered internal, and they are subject to change across minor/patch releases.&lt;/p&gt; &#xA;&lt;h1&gt;Delta Sharing Protocol&lt;/h1&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&#34;&gt;Delta Sharing Protocol specification&lt;/a&gt; details the protocol.&lt;/p&gt; &#xA;&lt;h1&gt;Building this Project&lt;/h1&gt; &#xA;&lt;h2&gt;Python Connector&lt;/h2&gt; &#xA;&lt;p&gt;To execute tests, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python/dev/pytest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install in develop mode, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd python/&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install locally, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd python/&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate a wheel file, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd python/&#xA;python setup.py sdist bdist_wheel&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will generate &lt;code&gt;python/dist/delta_sharing-x.y.z-py3-none-any.whl&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Apache Spark Connector and Delta Sharing Server&lt;/h2&gt; &#xA;&lt;p&gt;Apache Spark Connector and Delta Sharing Server are compiled using &lt;a href=&#34;https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html&#34;&gt;SBT&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To compile, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt compile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To execute tests, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate the Apache Spark Connector, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt spark/package&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will generate &lt;code&gt;spark/target/scala-2.12/delta-sharing-spark_2.12-x.y.z.jar&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To generate the pre-built Delta Sharing Server package, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt server/universal:packageBin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will generate &lt;code&gt;server/target/universal/delta-sharing-server-x.y.z.zip&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To build the Docker image for Delta Sharing Server, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;build/sbt server/docker:publishLocal&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will build a Docker image tagged &lt;code&gt;delta-sharing-server:x.y.z&lt;/code&gt;, which you can run with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -p &amp;lt;host-port&amp;gt;:&amp;lt;container-port&amp;gt; \&#xA;  --mount type=bind,source=&amp;lt;the-server-config-yaml-file&amp;gt;,target=/config/delta-sharing-server-config.yaml \&#xA;  delta-sharing-server:x.y.z -- --config /config/delta-sharing-server-config.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that &lt;code&gt;&amp;lt;container-port&amp;gt;&lt;/code&gt; should be the same as the port defined inside the config file.&lt;/p&gt; &#xA;&lt;p&gt;Refer to &lt;a href=&#34;https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html&#34;&gt;SBT docs&lt;/a&gt; for more commands.&lt;/p&gt; &#xA;&lt;h1&gt;Reporting Issues&lt;/h1&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/delta-io/delta-sharing/issues&#34;&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/#community&#34;&gt;contact&lt;/a&gt; the community for getting answers.&lt;/p&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;We welcome contributions to Delta Sharing. See our &lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;We also adhere to the &lt;a href=&#34;https://github.com/delta-io/delta/raw/master/CODE_OF_CONDUCT.md&#34;&gt;Delta Lake Code of Conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/delta-io/delta-sharing/main/LICENSE.txt&#34;&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Community&lt;/h1&gt; &#xA;&lt;p&gt;We use the same community resources as the Delta Lake project:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Public Slack Channel&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://go.delta.io/slack&#34;&gt;Register here&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://delta-users.slack.com/&#34;&gt;Login here&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Public &lt;a href=&#34;https://groups.google.com/forum/#!forum/delta-users&#34;&gt;Mailing list&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>sbt/sbt-native-packager</title>
    <updated>2023-04-09T02:01:43Z</updated>
    <id>tag:github.com,2023-04-09:/sbt/sbt-native-packager</id>
    <link href="https://github.com/sbt/sbt-native-packager" rel="alternate"></link>
    <summary type="html">&lt;p&gt;sbt Native Packager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SBT Native Packager&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/sbt/sbt-native-packager&#34;&gt;&lt;img src=&#34;https://api.travis-ci.org/sbt/sbt-native-packager.png?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ci.appveyor.com/project/muuki88/sbt-native-packager/branch/master&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/pbxd0untlcst4we7/branch/master?svg=true&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.codacy.com/app/nepomukseiler/sbt-native-packager?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=sbt/sbt-native-packager&amp;amp;utm_campaign=Badge_Grade&#34;&gt;&lt;img src=&#34;https://api.codacy.com/project/badge/Grade/0e9a7ec769c84e578f4550bf7da6bf05&#34; alt=&#34;Codacy Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://index.scala-lang.org/sbt/sbt-native-packager/sbt-native-packager&#34;&gt;&lt;img src=&#34;https://index.scala-lang.org/sbt/sbt-native-packager/sbt-native-packager/latest-by-scala-version.svg?targetType=Sbt&#34; alt=&#34;sbt-native-packager Scala version support&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/sbt/sbt-native-packager?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/Join%20Chat.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/sbt/sbt-native-packager&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://sbt-native-packager.readthedocs.org/en/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/sbt-native-packager/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sbt/sbt-native-packager/master/src/sphinx/static/np_logo_full_horizontal_transparent.png&#34; alt=&#34;Native Packager Logo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Goal&lt;/h2&gt; &#xA;&lt;p&gt;SBT native packager lets you build application packages in native formats. It offers different archetypes for common configurations, such as simple Java apps or server applications.&lt;/p&gt; &#xA;&lt;h2&gt;Issues/Discussions&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Discussion/Questions&lt;/strong&gt;: If you wish to ask questions about the native packager we&#39;re active on &lt;a href=&#34;http://stackoverflow.com/questions/tagged/sbt&#34;&gt;Stack Overflow&lt;/a&gt;. You can either use the &lt;code&gt;sbt&lt;/code&gt; tag or the &lt;code&gt;sbt-native-packager&lt;/code&gt; tag. They also have far better search support for working around issues.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href=&#34;http://sbt-native-packager.readthedocs.org/en/latest/&#34;&gt;Our docs are available online&lt;/a&gt;. If you&#39;d like to help improve the docs, they&#39;re part of this repository in the &lt;code&gt;src/sphinx&lt;/code&gt; directory. &lt;a href=&#34;http://www.scala-sbt.org/sbt-native-packager/latest/api/#package&#34;&gt;ScalaDocs&lt;/a&gt; are also available.&lt;/p&gt; &lt;p&gt;The old documentation can be found &lt;a href=&#34;http://www.scala-sbt.org/sbt-native-packager/&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Issues/Feature Requests&lt;/strong&gt;: Finally, any bugs or features you find you need, please report to our &lt;a href=&#34;https://github.com/sbt/sbt-native-packager/issues/new&#34;&gt;issue tracker&lt;/a&gt;. Please check the &lt;a href=&#34;https://github.com/sbt/sbt-native-packager/wiki/Tested-On&#34;&gt;compatibility matrix&lt;/a&gt; to see if your system is able to produce the packages you want.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Build &lt;a href=&#34;http://www.scala-sbt.org/sbt-native-packager/gettingstarted.html#packaging-formats&#34;&gt;native packages&lt;/a&gt; for different systems &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Universal &lt;code&gt;zip&lt;/code&gt;,&lt;code&gt;tar.gz&lt;/code&gt;, &lt;code&gt;xz&lt;/code&gt; archives&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;deb&lt;/code&gt; and &lt;code&gt;rpm&lt;/code&gt; packages for Debian/RHEL based systems&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;dmg&lt;/code&gt; for macOS&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;msi&lt;/code&gt; for Windows&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;docker&lt;/code&gt; images&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;graalvm&lt;/code&gt; native images&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Provide archetypes for common use cases &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://www.scala-sbt.org/sbt-native-packager/archetypes/java_app/index.html&#34;&gt;Java application&lt;/a&gt; with start scripts for Linux, macOS and Windows&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://www.scala-sbt.org/sbt-native-packager/archetypes/java_server/index.html&#34;&gt;Java server application&lt;/a&gt; adds support for service managers:s &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Systemd&lt;/li&gt; &#xA;     &lt;li&gt;Systemv&lt;/li&gt; &#xA;     &lt;li&gt;Upstart&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Java8 &lt;a href=&#34;http://www.scala-sbt.org/sbt-native-packager/formats/jdkpackager.html&#34;&gt;jdkpackager&lt;/a&gt; wrapper&lt;/li&gt; &#xA; &lt;li&gt;Java11 &lt;a href=&#34;https://docs.oracle.com/en/java/javase/11/tools/jlink.html&#34;&gt;jlink&lt;/a&gt; wrapper&lt;/li&gt; &#xA; &lt;li&gt;Optional JDeb integration for cross-platform Debian builds&lt;/li&gt; &#xA; &lt;li&gt;Optional Spotify docker client integration&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Add the following to your &lt;code&gt;project/plugins.sbt&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// for autoplugins&#xA;addSbtPlugin(&#34;com.github.sbt&#34; % &#34;sbt-native-packager&#34; % &#34;1.9.4&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In your &lt;code&gt;build.sbt&lt;/code&gt; enable the plugin you want. For example the &lt;code&gt;JavaAppPackaging&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;enablePlugins(JavaAppPackaging)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or if you need a server with autostart support&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;enablePlugins(JavaServerAppPackaging)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Build&lt;/h2&gt; &#xA;&lt;p&gt;If you have enabled one of the archetypes (app or server), you can build your application with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sbt &amp;lt;config-scope&amp;gt;:packageBin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Examples&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# universal zip&#xA;sbt universal:packageBin&#xA;&#xA;# debian package&#xA;sbt debian:packageBin&#xA;&#xA;# rpm package&#xA;sbt rpm:packageBin&#xA;&#xA;# docker image&#xA;sbt docker:publishLocal&#xA;&#xA;# graalvm image&#xA;sbt graalvm-native-image:packageBin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Read more in the specific &lt;a href=&#34;http://www.scala-sbt.org/sbt-native-packager/gettingstarted.html#packaging-formats&#34;&gt;format documentation&lt;/a&gt; on how to configure and build your package.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;There&#39;s a complete &#34;getting started&#34; guide and more detailed topics available at &lt;a href=&#34;http://www.scala-sbt.org/sbt-native-packager/&#34;&gt;the sbt-native-packager site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please feel free to &lt;a href=&#34;https://github.com/sbt/sbt-native-packager/tree/master/src/sphinx&#34;&gt;contribute documentation&lt;/a&gt;, or raise issues where you feel it may be lacking.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please read the &lt;a href=&#34;https://raw.githubusercontent.com/sbt/sbt-native-packager/master/CONTRIBUTING.md&#34;&gt;contributing.md&lt;/a&gt; on how to build and test native-packager.&lt;/p&gt; &#xA;&lt;h2&gt;Related SBT Plugins&lt;/h2&gt; &#xA;&lt;p&gt;These are a list of plugins that either use sbt-native-packager, provide additional features or provide a richer API for a single packaging format.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/arktekk/sbt-aether-deploy&#34;&gt;sbt-aether&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sbt/sbt-assembly&#34;&gt;sbt-assembly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/marcuslonnberg/sbt-docker&#34;&gt;sbt-docker&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This is in addition to the built-in &lt;a href=&#34;http://www.scala-sbt.org/sbt-native-packager/formats/docker.html&#34;&gt;Docker Plugin&lt;/a&gt; from sbt-native. Both generate docker images. &lt;code&gt;sbt-docker&lt;/code&gt; provides more customization abilities, while the &lt;code&gt;DockerPlugin&lt;/code&gt; in this project integrates more directly with predefined archetypes.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/heroku/sbt-heroku&#34;&gt;sbt-heroku&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vaslabs/sbt-kubeyml&#34;&gt;sbt-kubeyml&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gilt/sbt-newrelic&#34;&gt;sbt-newrelic&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/en-japan/sbt-packer&#34;&gt;sbt-packager&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/alkersan/sbt-package-courier&#34;&gt;sbt-package-courier&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Maintainers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Nepomuk Seiler (@muuki88)&lt;/li&gt; &#xA; &lt;li&gt;Alexey Kardapoltsev (@kardapoltsev)&lt;/li&gt; &#xA; &lt;li&gt;Derek Wickern (@dwickern)&lt;/li&gt; &#xA; &lt;li&gt;Felix Satyaputra (@fsat)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/jsuereth&#34;&gt;Josh Suereth&lt;/a&gt; for the initial developement&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.imagelab.net/&#34;&gt;Sascha Rinaldi&lt;/a&gt; for the native-packager logo&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>