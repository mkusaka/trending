<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-06T02:00:54Z</updated>
  <subtitle>Weekly Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>calinburloiu/Scala-for-the-Impatient--Exercises</title>
    <updated>2023-08-06T02:00:54Z</updated>
    <id>tag:github.com,2023-08-06:/calinburloiu/Scala-for-the-Impatient--Exercises</id>
    <link href="https://github.com/calinburloiu/Scala-for-the-Impatient--Exercises" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Solutions to exercises from the book &#34;Scala for the Impacient&#34; by Cay S. Horstmann.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Solutions to exercises from &#34;Scala for the Impatient&#34; by Cay S. Horstmann&lt;/h1&gt; &#xA;&lt;p&gt;I (Călin-Andrei Burloiu) created this project to include my solutions to exercises from the book &#34;Scala for the Impatient&#34; by Cay S. Horstmann. Feel free to fork this project in order to add unsolved exercises, better solutions or alternatives. You may issue a pull request so I can update this project if I find your solutions appropriate.&lt;/p&gt; &#xA;&lt;p&gt;DISCLAIMER: I (Călin-Andrei Burloiu) do not guarantee that the solutions are correct or are the most efficient. The project does not include solutions for all exercises, but it does include most of them.&lt;/p&gt; &#xA;&lt;h1&gt;How do I find a particular exercise?&lt;/h1&gt; &#xA;&lt;p&gt;If you have a UNIX-like environment (Linux, Mac OS X, cygwin, UNIX etc.) and you can run bash scripts, you can use &lt;code&gt;find-exercise.sh&lt;/code&gt; script to locate an exercise. Run it without arguments to prompt usage. To find an exercise pass the chapter number as the first argument and the exercise number as the second one. For example, to locate Exercise 6 of Chapter 17 run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./find-exercise.sh 17 6&#xA;Exercise 06 from Chapter 17 can be found in:&#xA;  file &#39;src/exercises/c17_type_parameters/package.scala&#39;,&#xA;  line 4.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Exercises are grouped by chapters in packages following this package name format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;package exercises.c&amp;lt;no&amp;gt;_&amp;lt;description&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;&amp;lt;no&amp;gt;&lt;/code&gt; is the chapter number and &lt;code&gt;&amp;lt;description&amp;gt;&lt;/code&gt; is a short form for the chapter name. Each package has its directory and all the code is placed in &lt;code&gt;src&lt;/code&gt;. For example package &lt;code&gt;exercises.c17_type_parameters&lt;/code&gt;, located in &lt;code&gt;src/exercises/c17_type_parameters/&lt;/code&gt;, corresponds to Chapter 17, &#34;Type Parameters&#34;.&lt;/p&gt; &#xA;&lt;p&gt;The solution to any exercise should be in a Scala file after a comment with this format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;// Exer&amp;lt;no&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;&amp;lt;no&amp;gt;&lt;/code&gt; is the number of the exercise with two digits format (eg. &lt;code&gt;// Exer02&lt;/code&gt;, &lt;code&gt;// Exer10&lt;/code&gt;).&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Zubader/addresbook</title>
    <updated>2023-08-06T02:00:54Z</updated>
    <id>tag:github.com,2023-08-06:/Zubader/addresbook</id>
    <link href="https://github.com/Zubader/addresbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>NVIDIA/spark-rapids</title>
    <updated>2023-08-06T02:00:54Z</updated>
    <id>tag:github.com,2023-08-06:/NVIDIA/spark-rapids</id>
    <link href="https://github.com/NVIDIA/spark-rapids" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Spark RAPIDS plugin - accelerate Apache Spark with GPUs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RAPIDS Accelerator For Apache Spark&lt;/h1&gt; &#xA;&lt;p&gt;NOTE: For the latest stable &lt;a href=&#34;https://github.com/nvidia/spark-rapids/raw/main/README.md&#34;&gt;README.md&lt;/a&gt; ensure you are on the main branch.&lt;/p&gt; &#xA;&lt;p&gt;The RAPIDS Accelerator for Apache Spark provides a set of plugins for &lt;a href=&#34;https://spark.apache.org&#34;&gt;Apache Spark&lt;/a&gt; that leverage GPUs to accelerate processing via the &lt;a href=&#34;https://rapids.ai&#34;&gt;RAPIDS&lt;/a&gt; libraries.&lt;/p&gt; &#xA;&lt;p&gt;Documentation on the current release can be found &lt;a href=&#34;https://nvidia.github.io/spark-rapids/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To get started and try the plugin out use the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/docs/get-started/getting-started.md&#34;&gt;getting started guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Compatibility&lt;/h2&gt; &#xA;&lt;p&gt;The SQL plugin tries to produce results that are bit for bit identical with Apache Spark. Operator compatibility is documented &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/docs/compatibility.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Tuning&lt;/h2&gt; &#xA;&lt;p&gt;To get started tuning your job and get the most performance out of it please start with the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/docs/tuning-guide.md&#34;&gt;tuning guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;The plugin has a set of Spark configs that control its behavior and are documented &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/docs/configs.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Issues &amp;amp; Questions&lt;/h2&gt; &#xA;&lt;p&gt;We use github to track bugs, feature requests, and answer questions. File an &lt;a href=&#34;https://github.com/NVIDIA/spark-rapids/issues/new/choose&#34;&gt;issue&lt;/a&gt; for a bug or feature request. Ask or answer a question on the &lt;a href=&#34;https://github.com/NVIDIA/spark-rapids/discussions&#34;&gt;discussion board&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;The jar files for the most recent release can be retrieved from the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/docs/download.md&#34;&gt;download&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;h2&gt;Building From Source&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/CONTRIBUTING.md#building-from-source&#34;&gt;build instructions in the contributing guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;p&gt;Tests are described &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/tests/README.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Integration&lt;/h2&gt; &#xA;&lt;p&gt;The RAPIDS Accelerator For Apache Spark does provide some APIs for doing zero copy data transfer into other GPU enabled applications. It is described &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/docs/additional-functionality/ml-integration.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Currently, we are working with XGBoost to try to provide this integration out of the box.&lt;/p&gt; &#xA;&lt;p&gt;You may need to disable RMM caching when exporting data to an ML library as that library will likely want to use all of the GPU&#39;s memory and if it is not aware of RMM it will not have access to any of the memory that RMM is holding.&lt;/p&gt; &#xA;&lt;h2&gt;Qualification and Profiling tools&lt;/h2&gt; &#xA;&lt;p&gt;The Qualification and Profiling tools have been moved to &lt;a href=&#34;https://github.com/NVIDIA/spark-rapids-tools&#34;&gt;nvidia/spark-rapids-tools&lt;/a&gt; repo.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/docs/spark-qualification-tool.md&#34;&gt;Qualification tool documentation&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-23.08/docs/spark-profiling-tool.md&#34;&gt;Profiling tool documentation&lt;/a&gt; for more details on how to use the tools.&lt;/p&gt; &#xA;&lt;h2&gt;Dependency for External Projects&lt;/h2&gt; &#xA;&lt;p&gt;If you need to develop some functionality on top of RAPIDS Accelerator For Apache Spark (we currently limit support to GPU-accelerated UDFs) we recommend you declare our distribution artifact as a &lt;code&gt;provided&lt;/code&gt; dependency.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;&#xA;    &amp;lt;groupId&amp;gt;com.nvidia&amp;lt;/groupId&amp;gt;&#xA;    &amp;lt;artifactId&amp;gt;rapids-4-spark_2.12&amp;lt;/artifactId&amp;gt;&#xA;    &amp;lt;version&amp;gt;23.08.0-SNAPSHOT&amp;lt;/version&amp;gt;&#xA;    &amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt;&#xA;&amp;lt;/dependency&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>