<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-10T02:01:06Z</updated>
  <subtitle>Weekly Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>apache/incubator-gluten</title>
    <updated>2024-03-10T02:01:06Z</updated>
    <id>tag:github.com,2024-03-10:/apache/incubator-gluten</id>
    <link href="https://github.com/apache/incubator-gluten" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Gluten is a middle layer responsible for offloading JVM-based SQL engines&#39; execution to native engines.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gluten: Plugin to Double SparkSQL&#39;s Performance&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bestpractices.dev/projects/8452&#34;&gt;&lt;img src=&#34;https://www.bestpractices.dev/projects/8452/badge&#34; alt=&#34;OpenSSF Best Practices&#34;&gt;&lt;/a&gt; &lt;em&gt;&lt;b&gt;This project is still under active development now, and doesn&#39;t have a stable release. Welcome to evaluate it.&lt;/b&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h1&gt;1 Introduction&lt;/h1&gt; &#xA;&lt;h2&gt;1.1 Problem Statement&lt;/h2&gt; &#xA;&lt;p&gt;Apache Spark is a stable, mature project that has been developed for many years. It is one of the best frameworks to scale out for processing petabyte-scale datasets. However, the Spark community has had to address performance challenges that require various optimizations over time. As a key optimization in Spark 2.0, Whole Stage Code Generation is introduced to replace Volcano Model, which achieves 2x speedup. Henceforth, most optimizations are at query plan level. Single operator&#39;s performance almost stops growing.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/47296334/199853029-b6d0ea19-f8e4-4f62-9562-2838f7f159a7.png&#34; width=&#34;800&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;On the other side, SQL engines have been researched for many years. There are a few libraries like Clickhouse, Arrow and Velox, etc. By using features like native implementation, columnar data format and vectorized data processing, these libraries can outperform Spark&#39;s JVM based SQL engine. However, these libraries only support single node execution.&lt;/p&gt; &#xA;&lt;h2&gt;1.2 Gluten&#39;s Solution&lt;/h2&gt; &#xA;&lt;p&gt;“Gluten” is Latin for glue. The main goal of Gluten project is to “glue&#34; native libraries with SparkSQL. Thus, we can benefit from high scalability of Spark SQL framework and high performance of native libraries.&lt;/p&gt; &#xA;&lt;p&gt;The basic rule of Gluten&#39;s design is that we would reuse spark&#39;s whole control flow and as many JVM code as possible but offload the compute-intensive data processing part to native code. Here is what Gluten does:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Transform Spark’s whole stage physical plan to Substrait plan and send to native&lt;/li&gt; &#xA; &lt;li&gt;Offload performance-critical data processing to native library&lt;/li&gt; &#xA; &lt;li&gt;Define clear JNI interfaces for native libraries&lt;/li&gt; &#xA; &lt;li&gt;Switch available native backends easily&lt;/li&gt; &#xA; &lt;li&gt;Reuse Spark’s distributed control flow&lt;/li&gt; &#xA; &lt;li&gt;Manage data sharing between JVM and native&lt;/li&gt; &#xA; &lt;li&gt;Extensible to support more native accelerators&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;1.3 Target User&lt;/h2&gt; &#xA;&lt;p&gt;Gluten&#39;s target user is anyone who wants to accelerate SparkSQL fundamentally. As a plugin to Spark, Gluten doesn&#39;t require any change for dataframe API or SQL query, but only requires user to make correct configuration. See Gluten configuration properties &lt;a href=&#34;https://github.com/oap-project/gluten/raw/main/docs/Configuration.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;1.4 References&lt;/h2&gt; &#xA;&lt;p&gt;You can click below links for more related information.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0Q6gHT_N-1U&#34;&gt;Gluten Intro Video at Data AI Summit 2022&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/intel-analytics-software/accelerate-spark-sql-queries-with-gluten-9000b65d1b4e&#34;&gt;Gluten Intro Article at Medium.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cn.kyligence.io/blog/gluten-spark/&#34;&gt;Gluten Intro Article at Kyligence.io(in Chinese)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://engineering.fb.com/2023/03/09/open-source/velox-open-source-execution-engine/&#34;&gt;Velox Intro from Meta&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;2 Architecture&lt;/h1&gt; &#xA;&lt;p&gt;The overview chart is like below. Substrait provides a well-defined cross-language specification for data compute operations (see more details &lt;a href=&#34;https://substrait.io/&#34;&gt;here&lt;/a&gt;). Spark physical plan is transformed to Substrait plan. Then Substrait plan is passed to native through JNI call. On native side, the native operator chain will be built out and offloaded to native engine. Gluten will return Columnar Batch to Spark and Spark Columnar API (since Spark-3.0) will be used at execution time. Gluten uses Apache Arrow data format as its basic data format, so the returned data to Spark JVM is ArrowColumnarBatch.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/47296334/199617207-1140698a-4d53-462d-9bc7-303d14be060b.png&#34; width=&#34;800&#34;&gt; &lt;/p&gt; Currently, Gluten only supports Clickhouse backend &amp;amp; Velox backend. Velox is a C++ database acceleration library which provides reusable, extensible and high-performance data processing components. More details can be found from https://github.com/facebookincubator/velox/. Gluten can also be extended to support more backends. &#xA;&lt;p&gt;There are several key components in Gluten:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Query Plan Conversion&lt;/strong&gt;: converts Spark&#39;s physical plan to Substrait plan.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Unified Memory Management&lt;/strong&gt;: controls native memory allocation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Columnar Shuffle&lt;/strong&gt;: shuffles Gluten columnar data. The shuffle service still reuses the one in Spark core. A kind of columnar exchange operator is implemented to support Gluten columnar data format.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fallback Mechanism&lt;/strong&gt;: supports falling back to Vanilla spark for unsupported operators. Gluten ColumnarToRow (C2R) and RowToColumnar (R2C) will convert Gluten columnar data and Spark&#39;s internal row data if needed. Both C2R and R2C are implemented in native code as well&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Metrics&lt;/strong&gt;: collected from Gluten native engine to help identify bugs, performance bottlenecks, etc. The metrics are displayed in Spark UI.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Shim Layer&lt;/strong&gt;: supports multiple Spark versions. We plan to only support Spark&#39;s latest 2 or 3 releases. Currently, Spark-3.2, Spark-3.3 &amp;amp; Spark-3.4 (experimental) are supported.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;3 How to Use&lt;/h1&gt; &#xA;&lt;p&gt;There are two ways to use Gluten.&lt;/p&gt; &#xA;&lt;h1&gt;3.1 Use Released Jar&lt;/h1&gt; &#xA;&lt;p&gt;One way is to use released jar. Here is a simple example. Currently, only centos7/8 and ubuntu20.04/22.04 are well supported.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;spark-shell \&#xA; --master yarn --deploy-mode client \&#xA; --conf spark.plugins=io.glutenproject.GlutenPlugin \&#xA; --conf spark.memory.offHeap.enabled=true \&#xA; --conf spark.memory.offHeap.size=20g \&#xA; --conf spark.shuffle.manager=org.apache.spark.shuffle.sort.ColumnarShuffleManager \&#xA; --jars https://github.com/oap-project/gluten/releases/download/v1.0.0/gluten-velox-bundle-spark3.2_2.12-ubuntu_20.04_x86_64-1.0.0.jar&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;3.2 Custom Build&lt;/h1&gt; &#xA;&lt;p&gt;Alternatively, you can build gluten from source, then do some configurations to enable Gluten plugin for Spark. Here is a simple example. Please refer to the corresponding backend part below for more details.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export gluten_jar = /PATH/TO/GLUTEN/backends-velox/target/&amp;lt;gluten-jar&amp;gt;&#xA;spark-shell &#xA;  --master yarn --deploy-mode client \&#xA;  --conf spark.plugins=io.glutenproject.GlutenPlugin \&#xA;  --conf spark.memory.offHeap.enabled=true \&#xA;  --conf spark.memory.offHeap.size=20g \&#xA;  --conf spark.driver.extraClassPath=${gluten_jar} \&#xA;  --conf spark.executor.extraClassPath=${gluten_jar} \&#xA;  --conf spark.shuffle.manager=org.apache.spark.shuffle.sort.ColumnarShuffleManager&#xA;  ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.2.1 Build and install Gluten with Velox backend&lt;/h3&gt; &#xA;&lt;p&gt;If you want to use Gluten &lt;strong&gt;Velox&lt;/strong&gt; backend, see &lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/get-started/Velox.md&#34;&gt;Build with Velox&lt;/a&gt; to build and install the necessary libraries.&lt;/p&gt; &#xA;&lt;h3&gt;3.2.2 Build and install Gluten with ClickHouse backend&lt;/h3&gt; &#xA;&lt;p&gt;If you want to use Gluten &lt;strong&gt;ClickHouse&lt;/strong&gt; backend, see &lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/get-started/ClickHouse.md&#34;&gt;Build with ClickHouse Backend&lt;/a&gt;. ClickHouse backend is developed by &lt;a href=&#34;https://kyligence.io/&#34;&gt;Kyligence&lt;/a&gt;, please visit &lt;a href=&#34;https://github.com/Kyligence/ClickHouse&#34;&gt;https://github.com/Kyligence/ClickHouse&lt;/a&gt; for more infomation.&lt;/p&gt; &#xA;&lt;h3&gt;3.2.3 Build options&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/get-started/build-guide.md&#34;&gt;Gluten build guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;4 Contribution&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to contribute to Gluten project! See &lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-gluten/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; about how to make contributions.&lt;/p&gt; &#xA;&lt;h2&gt;4.1 Community&lt;/h2&gt; &#xA;&lt;p&gt;You can join a Wechat group (Chinese) or a Spark channel in Velox Slack group (English) for community communication. Contact us if you want.&lt;/p&gt; &#xA;&lt;h2&gt;4.2 Issue Report&lt;/h2&gt; &#xA;&lt;p&gt;Please feel free to create Github issue for reporting bug or proposing enhancement. For contributing code, please submit an issue firstly and mention that issue in your PR.&lt;/p&gt; &#xA;&lt;h2&gt;4.3 Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Currently, all gluten documents are held at &lt;a href=&#34;https://github.com/oap-project/gluten/tree/main/docs&#34;&gt;docs&lt;/a&gt;. The documents may not reflect the latest designs. Please feel free to contact us for getting design details or sharing your design ideas.&lt;/p&gt; &#xA;&lt;h1&gt;5 Performance&lt;/h1&gt; &#xA;&lt;p&gt;We use Decision Support Benchmark1 (TPC-H like) to evaluate Gluten&#39;s performance. Decision Support Benchmark1 is a query set modified from &lt;a href=&#34;http://tpc.org/tpch/default5.asp&#34;&gt;TPC-H benchmark&lt;/a&gt;. We use Parquet file format for Velox testing &amp;amp; MergeTree file format for Clickhouse testing, compared to Parquet file format as baseline. See &lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-gluten/main/tools/workload/tpch&#34;&gt;Decision Support Benchmark1&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The below test environment: single node with 2TB data; Spark-3.3.2 for both baseline and Gluten. The Decision Support Benchmark1 result (tested in Jun. 2023) shows an overall speedup of 2.71x and up to 14.53x speedup in a single query with Gluten Velox backend used.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/image/velox_decision_support_bench1_22queries_performance.png&#34; alt=&#34;Performance&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The below testing environment: a 8-nodes AWS cluster with 1TB data; Spark-3.1.1 for both baseline and Gluten. The Decision Support Benchmark1 result shows an average speedup of 2.12x and up to 3.48x speedup with Gluten Clickhouse backend.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/image/clickhouse_decision_support_bench1_22queries_performance.png&#34; alt=&#34;Performance&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;6 License&lt;/h1&gt; &#xA;&lt;p&gt;Gluten is licensed under &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;7 Contact&lt;/h1&gt; &#xA;&lt;p&gt;Gluten was initiated by Intel and Kyligence in 2022. Several companies such as Intel, Kyligence, BIGO, Meituan, Alibaba Cloud, NetEase, Baidu, Microsoft and others, are actively participating in the development of Gluten. If you are interested in Gluten project, please contact below email address for further discussion.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;mailto:binwei.yang@intel.com&#34;&gt;binwei.yang@intel.com&lt;/a&gt;; &lt;a href=&#34;mailto:weiting.chen@intel.com&#34;&gt;weiting.chen@intel.com&lt;/a&gt;; &lt;a href=&#34;mailto:chang.chen@kyligence.io&#34;&gt;chang.chen@kyligence.io&lt;/a&gt;; &lt;a href=&#34;mailto:zhichao.zhang@kyligence.io&#34;&gt;zhichao.zhang@kyligence.io&lt;/a&gt;; &lt;a href=&#34;mailto:neng.liu@kyligence.io&#34;&gt;neng.liu@kyligence.io&lt;/a&gt;; &lt;a href=&#34;mailto:zuochunwei@meituan.com&#34;&gt;zuochunwei@meituan.com&lt;/a&gt;;&lt;a href=&#34;mailto:yangchuan.zy@alibaba-inc.com&#34;&gt;yangchuan.zy@alibaba-inc.com&lt;/a&gt;;&lt;a href=&#34;mailto:xiyu.zk@alibaba-inc.com&#34;&gt;xiyu.zk@alibaba-inc.com&lt;/a&gt;;&lt;a href=&#34;mailto:joey.ljy@alibaba-inc.com&#34;&gt;joey.ljy@alibaba-inc.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;* LEGAL NOTICE: Your use of this software and any required dependent software (the &#34;Software Package&#34;) is subject to the terms and conditions of the software license agreements for the Software Package, which may also include notices, disclaimers, or license terms for third party or open source software included in or with the Software Package, and your use indicates your acceptance of all such terms. Please refer to the &#34;TPP.txt&#34; or other similarly-named text file included with the Software Package for additional details.&lt;/h5&gt;</summary>
  </entry>
  <entry>
    <title>jerluc/gcj</title>
    <updated>2024-03-10T02:01:06Z</updated>
    <id>tag:github.com,2024-03-10:/jerluc/gcj</id>
    <link href="https://github.com/jerluc/gcj" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Just a repo to house all of my code for GCJ :)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Google Code Jam Codez&lt;/h1&gt; &#xA;&lt;p&gt;Just a repo to house all of my code for GCJ :)&lt;/p&gt; &#xA;&lt;p&gt;But honest, please don&#39;t use these as your own, just being published here for educational purposes only!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>scala/scala3</title>
    <updated>2024-03-10T02:01:06Z</updated>
    <id>tag:github.com,2024-03-10:/scala/scala3</id>
    <link href="https://github.com/scala/scala3" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Scala 3 compiler, also known as Dotty.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dotty&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/scala/scala3/actions?query=branch%3Amain&#34;&gt;&lt;img src=&#34;https://github.com/scala/scala3/workflows/Dotty/badge.svg?branch=master&#34; alt=&#34;Dotty CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.com/invite/scala&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/632150470000902164&#34; alt=&#34;Join the chat at https://discord.com/invite/scala&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.scala-lang.org/scala3/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Try it out&lt;/h1&gt; &#xA;&lt;p&gt;To try it in your project see also the &lt;a href=&#34;https://docs.scala-lang.org/scala3/getting-started.html&#34;&gt;Getting Started User Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Building a Local Distribution&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;sbt dist/packArchive&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Find the newly-built distributions in &lt;code&gt;dist/target/&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Code of Conduct&lt;/h1&gt; &#xA;&lt;p&gt;Dotty uses the &lt;a href=&#34;https://www.scala-lang.org/conduct.html&#34;&gt;Scala Code of Conduct&lt;/a&gt; for all communication and discussion. This includes both GitHub, Discord and other more direct lines of communication such as email.&lt;/p&gt; &#xA;&lt;h1&gt;How to Contribute&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.scala-lang.org/scala3/guides/contribution/contribution-intro.html&#34;&gt;Getting Started as Contributor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/scala/scala3/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22&#34;&gt;Issues&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;Dotty is licensed under the &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License Version 2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>