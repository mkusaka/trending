<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-03T02:51:44Z</updated>
  <subtitle>Monthly Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>yutax77/KeyValueStore-scala</title>
    <updated>2022-06-03T02:51:44Z</updated>
    <id>tag:github.com,2022-06-03:/yutax77/KeyValueStore-scala</id>
    <link href="https://github.com/yutax77/KeyValueStore-scala" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TDDBC Tokyo1.6&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;KeyValueStore&lt;/h1&gt; &#xA;&lt;p&gt;TDDBC Tokyo1.6&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>databricks/Spark-The-Definitive-Guide</title>
    <updated>2022-06-03T02:51:44Z</updated>
    <id>tag:github.com,2022-06-03:/databricks/Spark-The-Definitive-Guide</id>
    <link href="https://github.com/databricks/Spark-The-Definitive-Guide" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Spark: The Definitive Guide&#39;s Code Repository&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Spark: The Definitive Guide&lt;/h1&gt; &#xA;&lt;p&gt;This is the central repository for all materials related to &lt;a href=&#34;http://shop.oreilly.com/product/0636920034957.do&#34;&gt;Spark: The Definitive Guide&lt;/a&gt; by Bill Chambers and Matei Zaharia.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;This repository is currently a work in progress and new material will be added over time.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://images-na.ssl-images-amazon.com/images/I/51z7TzI-Y3L._SX379_BO1,204,203,200_.jpg&#34; alt=&#34;Spark: The Definitive Guide&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Code from the book&lt;/h1&gt; &#xA;&lt;p&gt;You can find the code from the book in the &lt;code&gt;code&lt;/code&gt; subfolder where it is broken down by language and chapter.&lt;/p&gt; &#xA;&lt;h1&gt;How to run the code&lt;/h1&gt; &#xA;&lt;h2&gt;Run on your local machine&lt;/h2&gt; &#xA;&lt;p&gt;To run the example on your local machine, either pull all data in the &lt;code&gt;data&lt;/code&gt; subfolder to &lt;code&gt;/data&lt;/code&gt; on your computer or specify the path to that particular dataset on your local machine.&lt;/p&gt; &#xA;&lt;h2&gt;Run on Databricks&lt;/h2&gt; &#xA;&lt;p&gt;To run these modules on Databricks, you&#39;re going to need to do two things.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Sign up for an account. You can do that &lt;a href=&#34;https://databricks.com/try-databricks&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Import individual Notebooks to run on the platform&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Databricks is a zero-management cloud platform that provides:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fully managed Spark clusters&lt;/li&gt; &#xA; &lt;li&gt;An interactive workspace for exploration and visualization&lt;/li&gt; &#xA; &lt;li&gt;A production pipeline scheduler&lt;/li&gt; &#xA; &lt;li&gt;A platform for powering your favorite Spark-based applications&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Instructions for importing&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Navigate to the notebook you would like to import&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For instance, you might go to &lt;a href=&#34;https://github.com/databricks/Spark-The-Definitive-Guide/raw/master/code/A_Gentle_Introduction_to_Spark-Chapter_3_A_Tour_of_Sparks_Toolset.py&#34;&gt;this page&lt;/a&gt;. Once you do that, you&#39;re going to need to navigate to the &lt;strong&gt;RAW&lt;/strong&gt; version of the file and save that to your Desktop. You can do that by clicking the &lt;strong&gt;Raw&lt;/strong&gt; button. &lt;em&gt;Alternatively, you could just clone the entire repository to your local desktop and navigate to the file on your computer&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Upload that to Databricks&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Read &lt;a href=&#34;https://docs.databricks.com/user-guide/notebooks/index.html#import-a-notebook&#34;&gt;the instructions&lt;/a&gt; here. Simply open the Databricks workspace and go to import in a given directory. From there, navigate to the file on your computer to upload it. &lt;em&gt;Unfortunately due to a recent security upgrade, notebooks cannot be imported from external URLs. Therefore you must upload it from your computer&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;You&#39;re almost ready to go!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Now you just need to simply run the notebooks! All the examples run on Databricks Runtime 3.1 and above so just be sure to create a cluster with a version equal to or greater than that. Once you&#39;ve created your cluster, attach the notebook.&lt;/p&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Replacing the data path in each notebook&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Rather than you having to upload all of the data yourself, you simply have to change the path in each chapter from &lt;code&gt;/data&lt;/code&gt; to &lt;code&gt;/databricks-datasets/definitive-guide/data&lt;/code&gt;. Once you&#39;ve done that, all examples should run without issue. You can use find and replace to do this very efficiently.&lt;/p&gt;</summary>
  </entry>
</feed>