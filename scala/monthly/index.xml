<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Scala Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-01T01:54:54Z</updated>
  <subtitle>Monthly Trending of Scala in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>rtyley/bfg-repo-cleaner</title>
    <updated>2022-09-01T01:54:54Z</updated>
    <id>tag:github.com,2022-09-01:/rtyley/bfg-repo-cleaner</id>
    <link href="https://github.com/rtyley/bfg-repo-cleaner" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Removes large or troublesome blobs like git-filter-branch does, but faster. And written in Scala&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BFG Repo-Cleaner &lt;a href=&#34;https://travis-ci.com/rtyley/bfg-repo-cleaner&#34;&gt;&lt;img src=&#34;https://travis-ci.com/rtyley/bfg-repo-cleaner.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Removes large or troublesome blobs like git-filter-branch does, but faster - and written in Scala&lt;/em&gt; - &lt;a href=&#34;https://j.mp/fund-bfg&#34;&gt;Fund the BFG&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bfg --strip-blobs-bigger-than 1M --replace-text banned.txt repo.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The BFG is a simpler, faster (&lt;a href=&#34;https://docs.google.com/spreadsheet/ccc?key=0AsR1d5Zpes8HdER3VGU1a3dOcmVHMmtzT2dsS2xNenc&#34;&gt;10 - 720x&lt;/a&gt; faster) alternative to &lt;code&gt;git-filter-branch&lt;/code&gt; for cleansing bad data out of your Git repository:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Removing &lt;strong&gt;Crazy Big Files&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Removing &lt;strong&gt;Passwords, Credentials&lt;/strong&gt; &amp;amp; other &lt;strong&gt;Private data&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Main documentation for The BFG is here : &lt;strong&gt;&lt;a href=&#34;https://rtyley.github.io/bfg-repo-cleaner/&#34;&gt;https://rtyley.github.io/bfg-repo-cleaner/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apache/incubator-kyuubi</title>
    <updated>2022-09-01T01:54:54Z</updated>
    <id>tag:github.com,2022-09-01:/apache/incubator-kyuubi</id>
    <link href="https://github.com/apache/incubator-kyuubi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache Kyuubi is a distributed multi-tenant JDBC server for large-scale data processing and analytics, built on top of Apache Spark&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache Kyuubi (Incubating)&lt;/h1&gt; &#xA;&lt;img src=&#34;https://svn.apache.org/repos/asf/comdev/project-logos/originals/kyuubi-1.svg?sanitize=true&#34; alt=&#34;Kyuubi logo&#34; height=&#34;120px&#34; align=&#34;right&#34;&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/incubator-kyuubi/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/apache/incubator-kyuubi?label=release&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://tokei.rs/b1/github.com/apache/incubator-kyuubi&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/apache/incubator-kyuubi/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/workflow/status/apache/incubator-kyuubi/Kyuubi/master?style=plastic&#34; alt=&#34;GitHub Workflow Status&#34;&gt; &lt;a href=&#34;https://travis-ci.com/apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://api.travis-ci.com/apache/incubator-kyuubi.svg?branch=master&#34; alt=&#34;Travis&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://kyuubi.apache.org/docs/latest/&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/kyuubi/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/languages/top/apache/incubator-kyuubi&#34; alt=&#34;GitHub top language&#34;&gt; &lt;a href=&#34;https://github.com/apache/incubator-kyuubi/graphs/commit-activity&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/m/apache/incubator-kyuubi&#34; alt=&#34;Commit activity&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://isitmaintained.com/project/apache/incubator-kyuubi&#34; title=&#34;Average time to resolve an issue&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/resolution/apache/incubator-kyuubi.svg?sanitize=true&#34; alt=&#34;Average time to resolve an issue&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://isitmaintained.com/project/apache/incubator-kyuubi&#34; title=&#34;Percentage of issues still open&#34;&gt;&lt;img src=&#34;http://isitmaintained.com/badge/open/apache/incubator-kyuubi.svg?sanitize=true&#34; alt=&#34;Percentage of issues still open&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Kyuubi?&lt;/h2&gt; &#xA;&lt;p&gt;Kyuubi is a distributed multi-tenant Thrift JDBC/ODBC server for large-scale data management, processing, and analytics, built on top of Apache Spark and designed to support more engines (i.e., Flink). It has been open-sourced by NetEase since 2018. We are aiming to make Kyuubi an &#34;out-of-the-box&#34; tool for data warehouses and data lakes.&lt;/p&gt; &#xA;&lt;p&gt;Kyuubi provides a pure SQL gateway through Thrift JDBC/ODBC interface for end-users to manipulate large-scale data with pre-programmed and extensible Spark SQL engines. This &#34;out-of-the-box&#34; model minimizes the barriers and costs for end-users to use Spark at the client side. At the server-side, Kyuubi server and engines&#39; multi-tenant architecture provides the administrators a way to achieve computing resource isolation, data security, high availability, high client concurrency, etc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/docs/imgs/kyuubi_positioning.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; A HiveServer2-like API&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multi-tenant Spark Support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Running Spark in a serverless way&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Target Users&lt;/h3&gt; &#xA;&lt;p&gt;Kyuubi&#39;s goal is to make it easy and efficient for &lt;code&gt;anyone&lt;/code&gt; to use Spark(maybe other engines soon) and facilitate users to handle big data like ordinary data. Here, &lt;code&gt;anyone&lt;/code&gt; means that users do not need to have a Spark technical background but a human language, SQL only. Sometimes, SQL skills are unnecessary when integrating Kyuubi with Apache Superset, which supports rich visualizations and dashboards.&lt;/p&gt; &#xA;&lt;p&gt;In typical big data production environments with Kyuubi, there should be system administrators and end-users.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;System administrators: A small group consists of Spark experts responsible for Kyuubi deployment, configuration, and tuning.&lt;/li&gt; &#xA; &lt;li&gt;End-users: Focus on business data of their own, not where it stores, how it computes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Additionally, the Kyuubi community will continuously optimize the whole system with various features, such as History-Based Optimizer, Auto-tuning, Materialized View, SQL Dialects, Functions, e.t.c.&lt;/p&gt; &#xA;&lt;h3&gt;Usage scenarios&lt;/h3&gt; &#xA;&lt;h4&gt;Port workloads from HiveServer2 to Spark SQL&lt;/h4&gt; &#xA;&lt;p&gt;In typical big data production environments, especially secured ones, all bundled services manage access control lists to restricting access to authorized users. For example, Hadoop YARN divides compute resources into queues. With Queue ACLs, it can identify and control which users/groups can take actions on particular queues. Similarly, HDFS ACLs control access of HDFS files by providing a way to set different permissions for specific users/groups.&lt;/p&gt; &#xA;&lt;p&gt;Apache Spark is a unified analytics engine for large-scale data processing. It provides a Distributed SQL Engine, a.k.a, the Spark Thrift Server(STS), designed to be seamlessly compatible with HiveServer2 and get even better performance.&lt;/p&gt; &#xA;&lt;p&gt;HiveServer2 can identify and authenticate a caller, and then if the caller also has permissions for the YARN queue and HDFS files, it succeeds. Otherwise, it fails. However, on the one hand, STS is a single Spark application. The user and queue to which STS belongs are uniquely determined at startup. Consequently, STS cannot leverage cluster managers such as YARN and Kubernetes for resource isolation and sharing or control the access for callers by the single user inside the whole system. On the other hand, the Thrift Server is coupled in the Spark driver&#39;s JVM process. This coupled architect puts a high risk on server stability and makes it unable to handle high client concurrency or apply high availability such as load balancing as it is stateful.&lt;/p&gt; &#xA;&lt;p&gt;Kyuubi extends the use of STS in a multi-tenant model based on a unified interface and relies on the concept of multi-tenancy to interact with cluster managers to finally gain the ability of resources sharing/isolation and data security. The loosely coupled architecture of the Kyuubi server and engine dramatically improves the client concurrency and service stability of the service itself.&lt;/p&gt; &#xA;&lt;h4&gt;DataLake/LakeHouse Support&lt;/h4&gt; &#xA;&lt;p&gt;The vision of Kyuubi is to unify the portal and become an easy-to-use data lake management platform. Different kinds of workloads, such as ETL processing and BI analytics, can be supported by one platform, using one copy of data, with one SQL interface.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Logical View support via Kyuubi DataLake Metadata APIs&lt;/li&gt; &#xA; &lt;li&gt;Multiple Catalogs support&lt;/li&gt; &#xA; &lt;li&gt;SQL Standard Authorization support for DataLake(coming)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Cloud Native Support&lt;/h4&gt; &#xA;&lt;p&gt;Kyuubi can deploy its engines on different kinds of Cluster Managers, such as, Hadoop YARN, Kubernetes, etc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/docs/imgs/kyuubi_migrating_yarn_to_k8s.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;The Kyuubi Ecosystem(present and future)&lt;/h3&gt; &#xA;&lt;p&gt;The figure below shows our vision for the Kyuubi Ecosystem. Some of them have been realized, some in development, and others would not be possible without your help.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/docs/imgs/kyuubi_ecosystem.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Online Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Since Kyuubi 1.3.0-incubating, the Kyuubi online documentation is hosted by &lt;a href=&#34;https://kyuubi.apache.org/&#34;&gt;https://kyuubi.apache.org/&lt;/a&gt;. You can find the latest Kyuubi documentation on &lt;a href=&#34;https://kyuubi.apache.org/docs/latest/&#34;&gt;this web page&lt;/a&gt;. For 1.2 and earlier versions, please check the &lt;a href=&#34;https://kyuubi.readthedocs.io/en/v1.2.0/&#34;&gt;Readthedocs&lt;/a&gt; directly.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Ready? &lt;a href=&#34;https://kyuubi.apache.org/docs/latest/quick_start/quick_start.html&#34;&gt;Getting Started&lt;/a&gt; with Kyuubi.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;Contributor over time&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://api7.ai/contributor-graph?chart=contributorOverTime&amp;amp;repo=apache/incubator-kyuubi&#34;&gt;&lt;img src=&#34;https://contributor-graph-api.apiseven.com/contributors-svg?chart=contributorOverTime&amp;amp;repo=apache/incubator-kyuubi&#34; alt=&#34;Contributor over time&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Aside&lt;/h2&gt; &#xA;&lt;p&gt;The project took its name from a character of a popular Japanese manga - &lt;code&gt;Naruto&lt;/code&gt;. The character is named &lt;code&gt;Kyuubi Kitsune/Kurama&lt;/code&gt;, which is a nine-tailed fox in mythology. &lt;code&gt;Kyuubi&lt;/code&gt; spread the power and spirit of fire, which is used here to represent the powerful &lt;a href=&#34;http://spark.apache.org&#34;&gt;Apache Spark&lt;/a&gt;. Its nine tails stand for end-to-end multi-tenancy support of this project.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache 2.0 License. See the &lt;a href=&#34;https://raw.githubusercontent.com/apache/incubator-kyuubi/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>chipsalliance/cde</title>
    <updated>2022-09-01T01:54:54Z</updated>
    <id>tag:github.com,2022-09-01:/chipsalliance/cde</id>
    <link href="https://github.com/chipsalliance/cde" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Scala library for Context-Dependent Environments&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CDE&lt;/h1&gt; &#xA;&lt;p&gt;A Scala library for Context-Dependent Environments, where a key-value environment is passed down a module hierarchy and each returned value depends on the key and the query’s origin. CDE is provably superior to existing parameterization schemes because it avoids introducing non-local source code changes when a design is modified, while also enabling features for large-scale design space exploration of compositions of generators.&lt;/p&gt; &#xA;&lt;h2&gt;User Guide&lt;/h2&gt; &#xA;&lt;p&gt;The library presents its key-value storage under an abstract class &lt;code&gt;Parameters&lt;/code&gt;. Values stored in &lt;code&gt;Parameters&lt;/code&gt; are each associated with a case object extends &lt;code&gt;Field[T]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The main interface for user to create a &lt;code&gt;Parameters&lt;/code&gt; object is using &lt;code&gt;Config&lt;/code&gt; object. Its &lt;code&gt;apply&lt;/code&gt; method takes &lt;code&gt;(View, View, View) =&amp;gt; PartialFunction[Any, Any]&lt;/code&gt; as a lookup table.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;//Field MyKey1 contains value of type Int&#xA;case object MyKey1 extends Field[Int]&#xA;//Field MyKey2 contains value of type String, with default value &#34;None&#34;&#xA;case object MyKey2 extends Field[String](&#34;None&#34;)&#xA;&#xA;// The meaning of parameter (site, here, up) will be explained later&#xA;val p: Parameters = Config((site, here, up) =&amp;gt; {&#xA;  case MyKey1 =&amp;gt; 0&#xA;  case MyKey2 =&amp;gt; &#34;MyValue&#34;&#xA;})&#xA;&#xA;// Apply Paramaters object to Field to query&#xA;assert(p(MyKey1) == 0)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Parameter Overrides&lt;/h3&gt; &#xA;&lt;p&gt;We can use one &lt;code&gt;Parameters&lt;/code&gt; to override another. Each single &lt;code&gt;Config&lt;/code&gt; is like a row in a table, while each &lt;code&gt;Field&lt;/code&gt; is a column in the table. To concat two table together, we have &lt;code&gt;alter&lt;/code&gt; and &lt;code&gt;orElse&lt;/code&gt; methods. &lt;code&gt;alter&lt;/code&gt; puts the rhs at bottom of the table and &lt;code&gt;orElse&lt;/code&gt; puts the rhs at top of the table.&lt;/p&gt; &#xA;&lt;p&gt;A query will inspect the table from bottom to up, row by row, until it finds the first row having the key defined.&lt;/p&gt; &#xA;&lt;p&gt;For example: &lt;code&gt;Config1.alter(Config2).alter(Config3)&lt;/code&gt; yields&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Key1&lt;/th&gt; &#xA;   &lt;th&gt;Key2&lt;/th&gt; &#xA;   &lt;th&gt;Key3&lt;/th&gt; &#xA;   &lt;th&gt;...&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Config1&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;V1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Config2&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;V2&lt;/td&gt; &#xA;   &lt;td&gt;V3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Config3&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;V4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;And now &lt;code&gt;p(Key1) == V2&lt;/code&gt;, &lt;code&gt;p(Key2) == V3&lt;/code&gt; and &lt;code&gt;p(Key3) == V4&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The same &lt;code&gt;Parameters&lt;/code&gt; can also be defined by &lt;code&gt;Config3.orElse(Config2).orElse(Config1)&lt;/code&gt;. There is also deprecated shorthand &lt;code&gt;++&lt;/code&gt; for &lt;code&gt;orElse&lt;/code&gt;, so &lt;code&gt;Config3 ++ Config2 ++ Config1&lt;/code&gt; is also valid.&lt;/p&gt; &#xA;&lt;h3&gt;Environment Reference&lt;/h3&gt; &#xA;&lt;p&gt;Each query contains the entire environment of where the query originates. This is pass to the lookup table of each &lt;code&gt;Config&lt;/code&gt; by &lt;code&gt;(site, here, up)&lt;/code&gt; arguments.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;here&lt;/code&gt; dynamically refers to the current row of the table&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;up&lt;/code&gt; dynamically refers to the rows appearing up than the current row&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;site&lt;/code&gt; dynamically refers to the entire table. When it gets called by &lt;code&gt;here&lt;/code&gt; or &lt;code&gt;up&lt;/code&gt; queries, it still refers to the &lt;strong&gt;entire&lt;/strong&gt; table instead of current row or upper half as indicated by &lt;code&gt;here&lt;/code&gt; or &lt;code&gt;up&lt;/code&gt; respectively.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For example, in the following &lt;code&gt;Parameters&lt;/code&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Key1&lt;/th&gt; &#xA;   &lt;th&gt;Key2&lt;/th&gt; &#xA;   &lt;th&gt;Key3&lt;/th&gt; &#xA;   &lt;th&gt;Key4&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Config1&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;site(Key1)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Config2&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;here(Key1)&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;up(Key2)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;Config3&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The value for each key is&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Key1: 3, given by &lt;code&gt;Config3&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Key2: 3, as it is value of &lt;code&gt;Key1&lt;/code&gt; in the entire table&lt;/li&gt; &#xA; &lt;li&gt;Key3: 2, as it is value of &lt;code&gt;Key1&lt;/code&gt; defined in the current row&lt;/li&gt; &#xA; &lt;li&gt;Key4: 3, as it is value of &lt;code&gt;Key2&lt;/code&gt; defined in the upper row, which is in turn value of &lt;code&gt;Key1&lt;/code&gt; defined in the table, which should be 3 as overriden by &lt;code&gt;Config3&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If one config layer does not refer environment at all, &lt;code&gt;alterMap&lt;/code&gt; and &lt;code&gt;alterPartial&lt;/code&gt; can be used to avoid create a redundant &lt;code&gt;Config&lt;/code&gt; object, as they accept &lt;code&gt;Map&lt;/code&gt; and &lt;code&gt;PartialFunction&lt;/code&gt; as their parameter.&lt;/p&gt; &#xA;&lt;h2&gt;Implementation Details&lt;/h2&gt; &#xA;&lt;p&gt;This section discusses the internal data structure used to track environment information. Normal reader can skip the section.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;alter&lt;/code&gt; and &lt;code&gt;orElse&lt;/code&gt; function wraps two operand as &lt;code&gt;ChainParameters&lt;/code&gt;, which forms a binary tree when &lt;code&gt;alter&lt;/code&gt; are called multiple times. Query on &lt;code&gt;ChainParameters&lt;/code&gt; calls &lt;code&gt;chain&lt;/code&gt; method.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;chain&lt;/code&gt; method traverses the tree by wrapping the right child in &lt;code&gt;ChainView&lt;/code&gt;, which records &lt;code&gt;up&lt;/code&gt; for later reference, and invoking &lt;code&gt;chain&lt;/code&gt; on the left child. This happens recursively until a leaf node is found. Then if the requested key is not in the node, we can turn to &lt;code&gt;chain&lt;/code&gt; of currently &lt;code&gt;up&lt;/code&gt; node.&lt;/p&gt; &#xA;&lt;p&gt;The following figure illustrates a querying process of &lt;code&gt;Parameters&lt;/code&gt; constructed by &lt;code&gt;C1.alter(C2).alter(C3).orElse(C4)&lt;/code&gt;. &lt;code&gt;chain&lt;/code&gt; is invoked on the node in blue, and &lt;code&gt;ChainView&lt;/code&gt; generated is in red.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chipsalliance/cde/master/doc/ChainParameters.svg?sanitize=true&#34; alt=&#34;Query Example&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>