<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C# Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-05T01:35:16Z</updated>
  <subtitle>Daily Trending of C# in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>AdminTest0/SharpWxDump</title>
    <updated>2022-08-05T01:35:16Z</updated>
    <id>tag:github.com,2022-08-05:/AdminTest0/SharpWxDump</id>
    <link href="https://github.com/AdminTest0/SharpWxDump" rel="alternate"></link>
    <summary type="html">&lt;p&gt;微信客户端取证，可获取用户个人信息(昵称/账号/手机/邮箱/数据库密钥(用来解密聊天记录))；支持获取多用户信息，不定期更新新版本偏移，目前支持所有新版本、正式版本&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;SharpWxDump&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;2022/07/23 更新内容&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;修复部分场景报错：登录微信后仍然提示：[-] WeChat Base Address Get Faild&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;支持功能&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;支持微信多开场景，获取多用户信息等&lt;/li&gt; &#xA; &lt;li&gt;微信需要登录状态才能获取数据库密钥&lt;/li&gt; &#xA; &lt;li&gt;没有动态获取功能，已将偏移地址写入代码内，会不定期更新，如有需要的版本请Issues&lt;/li&gt; &#xA; &lt;li&gt;请选择x86编译生成&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/33925462/179410099-c0f52c1c-b552-4a51-9822-7440b097bca4.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;版本差异&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;版本 &amp;lt; 3.7.0.30 只运行不登录能获取个人信息，登录后可以获取数据库密钥&lt;/li&gt; &#xA; &lt;li&gt;版本 &amp;gt; 3.7.0.30 只运行不登录不能获取个人信息，登录后都能获取&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;利用场景&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;钓鱼攻击(通过钓鱼控到的机器通常都是登录状态)&lt;/li&gt; &#xA; &lt;li&gt;渗透到运维机器(有些运维机器会日常登录自己的微信)&lt;/li&gt; &#xA; &lt;li&gt;某些工作需要取证(数据库需要拷贝到本地)&lt;/li&gt; &#xA; &lt;li&gt;自行备份(日常备份自己留存)&lt;/li&gt; &#xA; &lt;li&gt;等等...............&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;数据库解密&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;解密后可拖入数据库工具查找敏感信息&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/33925462/179410883-10deefb3-793d-4e15-8475-a74954fafe19.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;参考地址&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;数据库解密脚本：&lt;a href=&#34;https://mp.weixin.qq.com/s/4DbXOS5jDjJzM2PN0Mp2JA&#34;&gt;https://mp.weixin.qq.com/s/4DbXOS5jDjJzM2PN0Mp2JA&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;免责声明&lt;/h2&gt; &#xA;&lt;p&gt;本项目仅允许在授权情况下对数据库进行备份，严禁用于非法目的，否则自行承担所有相关责任。使用该工具则代表默认同意该条款;&lt;/p&gt; &#xA;&lt;p&gt;请勿利用本项目的相关技术从事非法测试，如因此产生的一切不良后果与项目作者无关。&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Kyome22/RunCat_for_windows</title>
    <updated>2022-08-05T01:35:16Z</updated>
    <id>tag:github.com,2022-08-05:/Kyome22/RunCat_for_windows</id>
    <link href="https://github.com/Kyome22/RunCat_for_windows" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A cute running cat animation on your windows taskbar.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RunCat_for_windows&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;A cute running cat animation on your windows taskbar.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Kyome22/RunCat_for_windows/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/Kyome22/RunCat_for_windows&#34; alt=&#34;Github issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Kyome22/RunCat_for_windows/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/Kyome22/RunCat_for_windows&#34; alt=&#34;Github forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Kyome22/RunCat_for_windows/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/Kyome22/RunCat_for_windows&#34; alt=&#34;Github stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Kyome22/RunCat_for_windows/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/languages/top/Kyome22/RunCat_for_windows&#34; alt=&#34;Top language&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/Kyome22/RunCat_for_windows&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Kyome22/RunCat_for_windows/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/Kyome22/RunCat_for_windows&#34; alt=&#34;Github license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Tags&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;C#&lt;/code&gt; &lt;code&gt;.NET 6.0&lt;/code&gt; &lt;code&gt;Visual Studio&lt;/code&gt; &lt;code&gt;RunCat&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Demo&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Kyome22/RunCat_for_windows/master/RunCat/resources/runcat_demo.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;You only have to run the RunCat.exe.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access to the &#34;Releases&#34; page and download the RunCat.exe.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Or install via &lt;a href=&#34;https://github.com/ScoopInstaller/Scoop&#34;&gt;Scoop&lt;/a&gt; (x64 version): &lt;code&gt;scoop install runcat&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;a href=&#34;https://github.com/Kyome22/RunCat_for_windows/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=Kyome22/RunCat_for_windows&#34;&gt; &lt;/a&gt; &#xA;&lt;!-- Please do not delete the below comment. --&gt; &#xA;&lt;!-- CREATED_BY_LEADYOU_README_GENERATOR --&gt;</summary>
  </entry>
  <entry>
    <title>confluentinc/confluent-kafka-dotnet</title>
    <updated>2022-08-05T01:35:16Z</updated>
    <id>tag:github.com,2022-08-05:/confluentinc/confluent-kafka-dotnet</id>
    <link href="https://github.com/confluentinc/confluent-kafka-dotnet" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Confluent&#39;s Apache Kafka .NET client&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Confluent&#39;s .NET Client for Apache Kafka&lt;sup&gt;TM&lt;/sup&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ci.appveyor.com/project/ConfluentClientEngineering/confluent-kafka-dotnet/branch/master&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/kux83eykufuv16cn/branch/master?svg=true&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://launchpass.com/confluentcommunity&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/chat-on%20slack-7A5979.svg?sanitize=true&#34; alt=&#34;Chat on Slack&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;confluent-kafka-dotnet&lt;/strong&gt; is Confluent&#39;s .NET client for &lt;a href=&#34;http://kafka.apache.org/&#34;&gt;Apache Kafka&lt;/a&gt; and the &lt;a href=&#34;https://www.confluent.io/product/&#34;&gt;Confluent Platform&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;High performance&lt;/strong&gt; - confluent-kafka-dotnet is a lightweight wrapper around &lt;a href=&#34;https://github.com/edenhill/librdkafka&#34;&gt;librdkafka&lt;/a&gt;, a finely tuned C client.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reliability&lt;/strong&gt; - There are a lot of details to get right when writing an Apache Kafka client. We get them right in one place (librdkafka) and leverage this work across all of our clients (also &lt;a href=&#34;https://github.com/confluentinc/confluent-kafka-python&#34;&gt;confluent-kafka-python&lt;/a&gt; and &lt;a href=&#34;https://github.com/confluentinc/confluent-kafka-go&#34;&gt;confluent-kafka-go&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supported&lt;/strong&gt; - Commercial support is offered by &lt;a href=&#34;https://confluent.io/&#34;&gt;Confluent&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Future proof&lt;/strong&gt; - Confluent, founded by the creators of Kafka, is building a &lt;a href=&#34;https://www.confluent.io/product/&#34;&gt;streaming platform&lt;/a&gt; with Apache Kafka at its core. It&#39;s high priority for us that client features keep pace with core Apache Kafka and components of the &lt;a href=&#34;https://www.confluent.io/product/&#34;&gt;Confluent Platform&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;confluent-kafka-dotnet is derived from Andreas Heider&#39;s &lt;a href=&#34;https://github.com/ah-/rdkafka-dotnet&#34;&gt;rdkafka-dotnet&lt;/a&gt;. We&#39;re fans of his work and were very happy to have been able to leverage rdkafka-dotnet as the basis of this client. Thanks Andreas!&lt;/p&gt; &#xA;&lt;h2&gt;Referencing&lt;/h2&gt; &#xA;&lt;p&gt;confluent-kafka-dotnet is distributed via NuGet. We provide five packages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nuget.org/packages/Confluent.Kafka/&#34;&gt;Confluent.Kafka&lt;/a&gt; &lt;em&gt;[net462, netstandard1.3, netstandard2.0]&lt;/em&gt; - The core client library.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nuget.org/packages/Confluent.SchemaRegistry.Serdes.Avro/&#34;&gt;Confluent.SchemaRegistry.Serdes.Avro&lt;/a&gt; &lt;em&gt;[netstandard2.0]&lt;/em&gt; - Provides a serializer and deserializer for working with Avro serialized data with Confluent Schema Registry integration.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nuget.org/packages/Confluent.SchemaRegistry.Serdes.Protobuf/&#34;&gt;Confluent.SchemaRegistry.Serdes.Protobuf&lt;/a&gt; &lt;em&gt;[netstandard2.0]&lt;/em&gt; - Provides a serializer and deserializer for working with Protobuf serialized data with Confluent Schema Registry integration.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nuget.org/packages/Confluent.SchemaRegistry.Serdes.Json/&#34;&gt;Confluent.SchemaRegistry.Serdes.Json&lt;/a&gt; &lt;em&gt;[netstandard2.0]&lt;/em&gt; - Provides a serializer and deserializer for working with Json serialized data with Confluent Schema Registry integration.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nuget.org/packages/Confluent.SchemaRegistry/&#34;&gt;Confluent.SchemaRegistry&lt;/a&gt; &lt;em&gt;[netstandard1.4, netstandard2.0]&lt;/em&gt; - Confluent Schema Registry client (a dependency of the Confluent.SchemaRegistry.Serdes packages).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To install Confluent.Kafka from within Visual Studio, search for Confluent.Kafka in the NuGet Package Manager UI, or run the following command in the Package Manager Console:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Install-Package Confluent.Kafka -Version 1.9.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To add a reference to a dotnet core project, execute the following at the command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet add package -v 1.9.2 Confluent.Kafka&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: &lt;code&gt;Confluent.Kafka&lt;/code&gt; depends on the &lt;code&gt;librdkafka.redist&lt;/code&gt; package which provides a number of different builds of &lt;code&gt;librdkafka&lt;/code&gt; that are compatible with &lt;a href=&#34;https://github.com/edenhill/librdkafka/wiki/librdkafka.redist-NuGet-package-runtime-libraries&#34;&gt;common platforms&lt;/a&gt;. If you are on one of these platforms this will all work seamlessly (and you don&#39;t need to explicitly reference &lt;code&gt;librdkafka.redist&lt;/code&gt;). If you are on a different platform, you may need to &lt;a href=&#34;https://github.com/edenhill/librdkafka#building&#34;&gt;build librdkafka&lt;/a&gt; manually (or acquire it via other means) and load it using the &lt;a href=&#34;https://docs.confluent.io/current/clients/confluent-kafka-dotnet/api/Confluent.Kafka.Library.html#Confluent_Kafka_Library_Load_System_String_&#34;&gt;Library.Load&lt;/a&gt; method.&lt;/p&gt; &#xA;&lt;h3&gt;Branch builds&lt;/h3&gt; &#xA;&lt;p&gt;Nuget packages corresponding to all commits to release branches are available from the following nuget package source (Note: this is not a web URL - you should specify it in the nuget package manager): &lt;a href=&#34;https://ci.appveyor.com/nuget/confluent-kafka-dotnet&#34;&gt;https://ci.appveyor.com/nuget/confluent-kafka-dotnet&lt;/a&gt;. The version suffix of these nuget packages matches the appveyor build number. You can see which commit a particular build number corresponds to by looking at the &lt;a href=&#34;https://ci.appveyor.com/project/ConfluentClientEngineering/confluent-kafka-dotnet/history&#34;&gt;AppVeyor build history&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;For a step-by-step guide and code samples, see &lt;a href=&#34;https://developer.confluent.io/get-started/dotnet/&#34;&gt;Getting Started with Apache Kafka and .NET&lt;/a&gt; on &lt;a href=&#34;https://developer.confluent.io/&#34;&gt;Confluent Developer&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Take a look in the &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-dotnet/master/examples&#34;&gt;examples&lt;/a&gt; directory and at the &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-dotnet/master/test/Confluent.Kafka.IntegrationTests/Tests&#34;&gt;integration tests&lt;/a&gt; for further examples.&lt;/p&gt; &#xA;&lt;p&gt;For an overview of configuration properties, refer to the &lt;a href=&#34;https://github.com/edenhill/librdkafka/raw/master/CONFIGURATION.md&#34;&gt;librdkafka documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Basic Producer Examples&lt;/h3&gt; &#xA;&lt;p&gt;You should use the &lt;code&gt;ProduceAsync&lt;/code&gt; method if you would like to wait for the result of your produce requests before proceeding. You might typically want to do this in highly concurrent scenarios, for example in the context of handling web requests. Behind the scenes, the client will manage optimizing communication with the Kafka brokers for you, batching requests as appropriate.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;using System;&#xA;using System.Threading.Tasks;&#xA;using Confluent.Kafka;&#xA;&#xA;class Program&#xA;{&#xA;    public static async Task Main(string[] args)&#xA;    {&#xA;        var config = new ProducerConfig { BootstrapServers = &#34;localhost:9092&#34; };&#xA;&#xA;        // If serializers are not specified, default serializers from&#xA;        // `Confluent.Kafka.Serializers` will be automatically used where&#xA;        // available. Note: by default strings are encoded as UTF8.&#xA;        using (var p = new ProducerBuilder&amp;lt;Null, string&amp;gt;(config).Build())&#xA;        {&#xA;            try&#xA;            {&#xA;                var dr = await p.ProduceAsync(&#34;test-topic&#34;, new Message&amp;lt;Null, string&amp;gt; { Value=&#34;test&#34; });&#xA;                Console.WriteLine($&#34;Delivered &#39;{dr.Value}&#39; to &#39;{dr.TopicPartitionOffset}&#39;&#34;);&#xA;            }&#xA;            catch (ProduceException&amp;lt;Null, string&amp;gt; e)&#xA;            {&#xA;                Console.WriteLine($&#34;Delivery failed: {e.Error.Reason}&#34;);&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that a server round-trip is slow (3ms at a minimum; actual latency depends on many factors). In highly concurrent scenarios you will achieve high overall throughput out of the producer using the above approach, but there will be a delay on each &lt;code&gt;await&lt;/code&gt; call. In stream processing applications, where you would like to process many messages in rapid succession, you would typically use the &lt;code&gt;Produce&lt;/code&gt; method instead:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;using System;&#xA;using Confluent.Kafka;&#xA;&#xA;class Program&#xA;{&#xA;    public static void Main(string[] args)&#xA;    {&#xA;        var conf = new ProducerConfig { BootstrapServers = &#34;localhost:9092&#34; };&#xA;&#xA;        Action&amp;lt;DeliveryReport&amp;lt;Null, string&amp;gt;&amp;gt; handler = r =&amp;gt; &#xA;            Console.WriteLine(!r.Error.IsError&#xA;                ? $&#34;Delivered message to {r.TopicPartitionOffset}&#34;&#xA;                : $&#34;Delivery Error: {r.Error.Reason}&#34;);&#xA;&#xA;        using (var p = new ProducerBuilder&amp;lt;Null, string&amp;gt;(conf).Build())&#xA;        {&#xA;            for (int i=0; i&amp;lt;100; ++i)&#xA;            {&#xA;                p.Produce(&#34;my-topic&#34;, new Message&amp;lt;Null, string&amp;gt; { Value = i.ToString() }, handler);&#xA;            }&#xA;&#xA;            // wait for up to 10 seconds for any inflight messages to be delivered.&#xA;            p.Flush(TimeSpan.FromSeconds(10));&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Basic Consumer Example&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;using System;&#xA;using System.Threading;&#xA;using Confluent.Kafka;&#xA;&#xA;class Program&#xA;{&#xA;    public static void Main(string[] args)&#xA;    {&#xA;        var conf = new ConsumerConfig&#xA;        { &#xA;            GroupId = &#34;test-consumer-group&#34;,&#xA;            BootstrapServers = &#34;localhost:9092&#34;,&#xA;            // Note: The AutoOffsetReset property determines the start offset in the event&#xA;            // there are not yet any committed offsets for the consumer group for the&#xA;            // topic/partitions of interest. By default, offsets are committed&#xA;            // automatically, so in this example, consumption will only start from the&#xA;            // earliest message in the topic &#39;my-topic&#39; the first time you run the program.&#xA;            AutoOffsetReset = AutoOffsetReset.Earliest&#xA;        };&#xA;&#xA;        using (var c = new ConsumerBuilder&amp;lt;Ignore, string&amp;gt;(conf).Build())&#xA;        {&#xA;            c.Subscribe(&#34;my-topic&#34;);&#xA;&#xA;            CancellationTokenSource cts = new CancellationTokenSource();&#xA;            Console.CancelKeyPress += (_, e) =&amp;gt; {&#xA;                e.Cancel = true; // prevent the process from terminating.&#xA;                cts.Cancel();&#xA;            };&#xA;&#xA;            try&#xA;            {&#xA;                while (true)&#xA;                {&#xA;                    try&#xA;                    {&#xA;                        var cr = c.Consume(cts.Token);&#xA;                        Console.WriteLine($&#34;Consumed message &#39;{cr.Value}&#39; at: &#39;{cr.TopicPartitionOffset}&#39;.&#34;);&#xA;                    }&#xA;                    catch (ConsumeException e)&#xA;                    {&#xA;                        Console.WriteLine($&#34;Error occured: {e.Error.Reason}&#34;);&#xA;                    }&#xA;                }&#xA;            }&#xA;            catch (OperationCanceledException)&#xA;            {&#xA;                // Ensure the consumer leaves the group cleanly and final offsets are committed.&#xA;                c.Close();&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;IHostedService and Web Application Integration&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/confluentinc/confluent-kafka-dotnet/tree/master/examples/Web&#34;&gt;Web&lt;/a&gt; example demonstrates how to integrate Apache Kafka with a web application, including how to implement &lt;code&gt;IHostedService&lt;/code&gt; to realize a long running consumer poll loop, how to register a producer as a singleton service, and how to bind configuration from an injected &lt;code&gt;IConfiguration&lt;/code&gt; instance.&lt;/p&gt; &#xA;&lt;h3&gt;Exactly Once Processing&lt;/h3&gt; &#xA;&lt;p&gt;The .NET Client has full support for transactions and idempotent message production, allowing you to write horizontally scalable stream processing applications with exactly once semantics. The &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-dotnet/master/examples/ExactlyOnce&#34;&gt;ExactlyOnce&lt;/a&gt; example demonstrates this capability by way of an implementation of the classic &#34;word count&#34; problem, also demonstrating how to use the &lt;a href=&#34;https://github.com/microsoft/FASTER&#34;&gt;FASTER&lt;/a&gt; Key/Value store (similar to RocksDb) to materialize working state that may be larger than available memory, and incremental rebalancing to avoid stop-the-world rebalancing operations and unnecessary reloading of state when you add or remove processing nodes.&lt;/p&gt; &#xA;&lt;h3&gt;Schema Registry Integration&lt;/h3&gt; &#xA;&lt;p&gt;The three &#34;Serdes&#34; packages provide serializers and deserializers for Avro, Protobuf and JSON with &lt;a href=&#34;https://docs.confluent.io/current/schema-registry/docs/index.html&#34;&gt;Confluent Schema Registry&lt;/a&gt; integration. The &lt;code&gt;Confluent.SchemaRegistry&lt;/code&gt; nuget package provides a client for interfacing with Schema Registry&#39;s REST API.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; All three serialization formats are supported across Confluent Platform. They each make different tradeoffs, and you should use the one that best matches to your requirements. Avro is well suited to the streaming data use-case, but the &lt;strong&gt;quality&lt;/strong&gt; and &lt;strong&gt;maturity&lt;/strong&gt; of the non-Java implementations lags that of Java - this is an important consideration. Protobuf and JSON both have great support in .NET.&lt;/p&gt; &#xA;&lt;h3&gt;Error Handling&lt;/h3&gt; &#xA;&lt;p&gt;Errors delivered to a client&#39;s error handler should be considered informational except when the &lt;code&gt;IsFatal&lt;/code&gt; flag is set to &lt;code&gt;true&lt;/code&gt;, indicating that the client is in an un-recoverable state. Currently, this can only happen on the producer, and only when &lt;code&gt;enable.idempotence&lt;/code&gt; has been set to &lt;code&gt;true&lt;/code&gt;. In all other scenarios, clients will attempt to recover from all errors automatically.&lt;/p&gt; &#xA;&lt;p&gt;Although calling most methods on the clients will result in a fatal error if the client is in an un-recoverable state, you should generally only need to explicitly check for fatal errors in your error handler, and handle this scenario there.&lt;/p&gt; &#xA;&lt;h4&gt;Producer&lt;/h4&gt; &#xA;&lt;p&gt;When using &lt;code&gt;Produce&lt;/code&gt;, to determine whether a particular message has been successfully delivered to a cluster, check the &lt;code&gt;Error&lt;/code&gt; field of the &lt;code&gt;DeliveryReport&lt;/code&gt; during the delivery handler callback.&lt;/p&gt; &#xA;&lt;p&gt;When using &lt;code&gt;ProduceAsync&lt;/code&gt;, any delivery result other than &lt;code&gt;NoError&lt;/code&gt; will cause the returned &lt;code&gt;Task&lt;/code&gt; to be in the faulted state, with the &lt;code&gt;Task.Exception&lt;/code&gt; field set to a &lt;code&gt;ProduceException&lt;/code&gt; containing information about the message and error via the &lt;code&gt;DeliveryResult&lt;/code&gt; and &lt;code&gt;Error&lt;/code&gt; fields. Note: if you &lt;code&gt;await&lt;/code&gt; the call, this means a &lt;code&gt;ProduceException&lt;/code&gt; will be thrown.&lt;/p&gt; &#xA;&lt;h4&gt;Consumer&lt;/h4&gt; &#xA;&lt;p&gt;All &lt;code&gt;Consume&lt;/code&gt; errors will result in a &lt;code&gt;ConsumeException&lt;/code&gt; with further information about the error and context available via the &lt;code&gt;Error&lt;/code&gt; and &lt;code&gt;ConsumeResult&lt;/code&gt; fields.&lt;/p&gt; &#xA;&lt;h3&gt;3rd Party&lt;/h3&gt; &#xA;&lt;p&gt;There are numerous libraries that expand on the capabilities provided by Confluent.Kafka, or use Confluent.Kafka to integrate with Kafka. For more information, refer to the &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-dotnet/master/3RD_PARTY.md&#34;&gt;3rd Party Libraries&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;h3&gt;Confluent Cloud&lt;/h3&gt; &#xA;&lt;p&gt;For a step-by-step guide on using the .NET client with Confluent Cloud see &lt;a href=&#34;https://developer.confluent.io/get-started/dotnet/&#34;&gt;Getting Started with Apache Kafka and .NET&lt;/a&gt; on &lt;a href=&#34;https://developer.confluent.io/&#34;&gt;Confluent Developer&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also refer to the &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-dotnet/master/examples/ConfluentCloud&#34;&gt;Confluent Cloud example&lt;/a&gt; which demonstrates how to configure the .NET client for use with &lt;a href=&#34;https://www.confluent.io/confluent-cloud/&#34;&gt;Confluent Cloud&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Developer Notes&lt;/h3&gt; &#xA;&lt;p&gt;Instructions on building and testing confluent-kafka-dotnet can be found &lt;a href=&#34;https://raw.githubusercontent.com/confluentinc/confluent-kafka-dotnet/master/DEVELOPER.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Copyright (c) 2016-2019 &lt;a href=&#34;https://www.confluent.io&#34;&gt;Confluent Inc.&lt;/a&gt; 2015-2016 &lt;a href=&#34;mailto:andreas@heider.io&#34;&gt;Andreas Heider&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;KAFKA is a registered trademark of The Apache Software Foundation and has been licensed for use by confluent-kafka-dotnet. confluent-kafka-dotnet has no affiliation with and is not endorsed by The Apache Software Foundation.&lt;/p&gt;</summary>
  </entry>
</feed>