<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub C# Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-01T02:15:04Z</updated>
  <subtitle>Monthly Trending of C# in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>SciSharp/LLamaSharp</title>
    <updated>2023-12-01T02:15:04Z</updated>
    <id>tag:github.com,2023-12-01:/SciSharp/LLamaSharp</id>
    <link href="https://github.com/SciSharp/LLamaSharp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Run LLaMA/GPT model easily and fast in C#!ü§ó It&#39;s also easy to integrate LLamaSharp with semantic-kernel, unity, WPF and WebApp.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/Assets/LLamaSharpLogo.png&#34; alt=&#34;logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/7wNVU65ZDY&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1106946823282761851?label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&amp;amp;k=sN9VVMwbWjs5L0ATpizKKxOcZdEPMrp8&amp;amp;authKey=RLDw41bLTrEyEgZZi%2FzT4pYk%2BwmEFgFcrhs8ZbkiVY7a4JFckzJefaYNW6Lk4yPX&amp;amp;noverify=0&amp;amp;group_code=985366726&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=QQ&amp;amp;message=%E5%8A%A0%E5%85%A5QQ%E7%BE%A4&amp;amp;color=brightgreen&#34; alt=&#34;QQ Group&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/LLamaSharp&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/v/LLamaSharp?label=LLamaSharp&#34; alt=&#34;LLamaSharp Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/LLamaSharp.Backend.Cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/v/LLamaSharp.Backend.Cpu?label=LLamaSharp.Backend.Cpu&#34; alt=&#34;LLamaSharp Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/LLamaSharp.Backend.Cuda11&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/v/LLamaSharp.Backend.Cuda11?label=LLamaSharp.Backend.Cuda11&#34; alt=&#34;LLamaSharp Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/LLamaSharp.Backend.Cuda12&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/v/LLamaSharp.Backend.Cuda12?label=LLamaSharp.Backend.Cuda12&#34; alt=&#34;LLamaSharp Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/LLamaSharp.semantic-kernel&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/v/LLamaSharp.semantic-kernel?label=LLamaSharp.semantic-kernel&#34; alt=&#34;LLamaSharp Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/LLamaSharp.kernel-memory&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/v/LLamaSharp.kernel-memory?label=LLamaSharp.kernel-memory&#34; alt=&#34;LLamaSharp Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The C#/.NET binding of &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;. It provides higher-level APIs to inference the LLaMA Models and deploy it on local device with C#/.NET. It works on both Windows, Linux and MAC without requirement for compiling llama.cpp yourself. Even without a GPU or not enough GPU memory, you can still apply LLaMA models well with this repo. ü§ó&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Furthermore, it provides integrations with other projects such as &lt;a href=&#34;https://github.com/microsoft/semantic-kernel&#34;&gt;semantic-kernel&lt;/a&gt;, &lt;a href=&#34;https://github.com/microsoft/kernel-memory&#34;&gt;kernel-memory&lt;/a&gt; and &lt;a href=&#34;https://github.com/SciSharp/BotSharp&#34;&gt;BotSharp&lt;/a&gt; to provide higher-level applications.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Discussions about the roadmap to v1.0.0: &lt;a href=&#34;https://github.com/SciSharp/LLamaSharp/issues/287&#34;&gt;#287&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Table of Contents&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/#Documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/#Examples&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/#Installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt; &lt;a href=&#34;#(Quick Start)&#34;&gt;Quick Start&lt;/a&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;#Model Inference and Chat Session&#34;&gt;Model Inference and Chat Session&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/#Quantization&#34;&gt;Quantization&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;#Web API&#34;&gt;Web API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/#Features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;#Console Demo&#34;&gt;Console Demo&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/#FAQ&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/#Contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;#Contact us&#34;&gt;Contact us&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/#Apendix&#34;&gt;Apendix&lt;/a&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;#Mapping from LLamaSharp to llama.cpp&#34;&gt;Mapping from LLamaSharp to llama.cpp&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scisharp.github.io/LLamaSharp/latest/GetStarted/&#34;&gt;Quick start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scisharp.github.io/LLamaSharp/latest/Tricks/&#34;&gt;Tricks for FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scisharp.github.io/LLamaSharp/latest/&#34;&gt;Full documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scisharp.github.io/LLamaSharp/latest/xmldocs/&#34;&gt;API reference&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/LLama.Examples/&#34;&gt;Official Console Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/eublefar/LLAMASharpUnityDemo&#34;&gt;Unity Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/saddam213/LLamaStack&#34;&gt;LLamaStack (with WPF and Web support)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Firstly, search &lt;code&gt;LLamaSharp&lt;/code&gt; in nuget package manager and install it.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PM&amp;gt; Install-Package LLamaSharp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, search and install one of the following backends. (Please don&#39;t install two or more)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;LLamaSharp.Backend.Cpu  # cpu for windows, linux and mac (mac metal is also supported)&#xA;LLamaSharp.Backend.Cuda11  # cuda11 for windows and linux&#xA;LLamaSharp.Backend.Cuda12  # cuda12 for windows and linux&#xA;LLamaSharp.Backend.MacMetal  # Removed after v0.8.0, metal support has been moved to cpu version now&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We publish these backends because they are the most popular ones. If none of them matches, please compile the &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; yourself. In this case, please &lt;strong&gt;DO NOT&lt;/strong&gt; install the backend packages, instead, add your DLL to your project and ensure it will be copied to the output directory when compiling your project. For more informations please refer to (&lt;a href=&#34;https://scisharp.github.io/LLamaSharp/0.5/ContributingGuide/&#34;&gt;this guide&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;For &lt;a href=&#34;https://github.com/microsoft/semantic-kernel&#34;&gt;microsoft semantic-kernel&lt;/a&gt; integration, please search and install the following package:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;LLamaSharp.semantic-kernel&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For &lt;a href=&#34;https://github.com/microsoft/kernel-memory&#34;&gt;microsoft kernel-memory&lt;/a&gt; integration, please search and install the following package (currently kernel-memory only supports net6.0):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;LLamaSharp.kernel-memory&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Tips for choosing a version&lt;/h3&gt; &#xA;&lt;p&gt;In general, there may be some break changes between two minor releases, for example 0.5.1 and 0.6.0. On the contrary, we don&#39;t introduce API break changes in patch release. Therefore it&#39;s recommended to keep the highest patch version of a minor release. For example, keep 0.5.6 instead of 0.5.3.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h4&gt;Model Inference and Chat Session&lt;/h4&gt; &#xA;&lt;p&gt;LLamaSharp provides two ways to run inference: &lt;code&gt;LLamaExecutor&lt;/code&gt; and &lt;code&gt;ChatSession&lt;/code&gt;. The chat session is a higher-level wrapping of the executor and the model. Here&#39;s a simple example to use chat session.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cs&#34;&gt;using LLama.Common;&#xA;using LLama;&#xA;&#xA;string modelPath = &#34;&amp;lt;Your model path&amp;gt;&#34;; // change it to your own model path&#xA;var prompt = &#34;Transcript of a dialog, where the User interacts with an Assistant named Bob. Bob is helpful, kind, honest, good at writing, and never fails to answer the User&#39;s requests immediately and with precision.\r\n\r\nUser: Hello, Bob.\r\nBob: Hello. How may I help you today?\r\nUser: Please tell me the largest city in Europe.\r\nBob: Sure. The largest city in Europe is Moscow, the capital of Russia.\r\nUser:&#34;; // use the &#34;chat-with-bob&#34; prompt here.&#xA;&#xA;// Load a model&#xA;var parameters = new ModelParams(modelPath)&#xA;{&#xA;    ContextSize = 1024,&#xA;    Seed = 1337,&#xA;    GpuLayerCount = 5&#xA;};&#xA;using var model = LLamaWeights.LoadFromFile(parameters);&#xA;&#xA;// Initialize a chat session&#xA;using var context = model.CreateContext(parameters);&#xA;var ex = new InteractiveExecutor(context);&#xA;ChatSession session = new ChatSession(ex);&#xA;&#xA;// show the prompt&#xA;Console.WriteLine();&#xA;Console.Write(prompt);&#xA;&#xA;// run the inference in a loop to chat with LLM&#xA;while (prompt != &#34;stop&#34;)&#xA;{&#xA;    foreach (var text in session.Chat(prompt, new InferenceParams() { Temperature = 0.6f, AntiPrompts = new List&amp;lt;string&amp;gt; { &#34;User:&#34; } }))&#xA;    {&#xA;        Console.Write(text);&#xA;    }&#xA;    prompt = Console.ReadLine();&#xA;}&#xA;&#xA;// save the session&#xA;session.SaveSession(&#34;SavedSessionPath&#34;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Quantization&lt;/h4&gt; &#xA;&lt;p&gt;The following example shows how to quantize the model. With LLamaSharp you needn&#39;t to compile c++ project and run scripts to quantize the model, instead, just run it in C#.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cs&#34;&gt;string srcFilename = &#34;&amp;lt;Your source path&amp;gt;&#34;;&#xA;string dstFilename = &#34;&amp;lt;Your destination path&amp;gt;&#34;;&#xA;string ftype = &#34;q4_0&#34;;&#xA;if(Quantizer.Quantize(srcFileName, dstFilename, ftype))&#xA;{&#xA;    Console.WriteLine(&#34;Quantization succeed!&#34;);&#xA;}&#xA;else&#xA;{&#xA;    Console.WriteLine(&#34;Quantization failed!&#34;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more usages, please refer to &lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/LLama.Examples&#34;&gt;Examples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Web API&lt;/h4&gt; &#xA;&lt;p&gt;We provide &lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/LLama.WebAPI&#34;&gt;the integration of ASP.NET core&lt;/a&gt; and a &lt;a href=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/LLama.Web&#34;&gt;web app demo&lt;/a&gt;. Please clone the repo to have a try.&lt;/p&gt; &#xA;&lt;p&gt;Since we are in short of hands, if you&#39;re familiar with ASP.NET core, we&#39;ll appreciate it if you would like to help upgrading the Web API integration.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;‚úÖ: completed. ‚ö†Ô∏è: outdated for latest release but will be updated. üî≥: not completed&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;‚úÖ LLaMa model inference&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ Embeddings generation, tokenization and detokenization&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ Chat session&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ Quantization&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ Grammar&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ State saving and loading&lt;/p&gt; &#xA;&lt;p&gt;‚ö†Ô∏è BotSharp Integration&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ ASP.NET core Integration&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ Semantic-kernel Integration&lt;/p&gt; &#xA;&lt;p&gt;üî≥ Fine-tune&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ Local document search (enabled by kernel-memory now)&lt;/p&gt; &#xA;&lt;p&gt;üî≥ MAUI Integration&lt;/p&gt; &#xA;&lt;h2&gt;Console Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SciSharp/LLamaSharp/master/Assets/console_demo.gif&#34; alt=&#34;demo-console&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;GPU out of memory: Please try setting &lt;code&gt;n_gpu_layers&lt;/code&gt; to a smaller number.&lt;/li&gt; &#xA; &lt;li&gt;Unsupported model: &lt;code&gt;llama.cpp&lt;/code&gt; is under quick development and often has break changes. Please check the release date of the model and find a suitable version of LLamaSharp to install, or generate &lt;code&gt;gguf&lt;/code&gt; format weights from original weights yourself.&lt;/li&gt; &#xA; &lt;li&gt;Cannot load native lirary: 1) ensure you installed one of the backend packages. 2) Run &lt;code&gt;NativeLibraryConfig.WithLogs()&lt;/code&gt; at the very beginning of your code to print more informations. 3) check if your system supports avx2, which is the default settings of official runtimes now. If not, please compile llama.cpp yourself and specify it with &lt;code&gt;NativeLibraryConfig.WithLibrary&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;How to find a model: Models in format &lt;code&gt;gguf&lt;/code&gt; are valid for LLamaSharp (and &lt;code&gt;ggml&lt;/code&gt; before v0.5.1). If you&#39;re new to LLM/LLaMA, it&#39;s a good choice to search &lt;code&gt;LLama&lt;/code&gt; and &lt;code&gt;gguf&lt;/code&gt; on &lt;a href=&#34;https://huggingface.co/&#34;&gt;huggingface&lt;/a&gt; to find a model. Another choice is generate gguf format file yourself with a pytorch weight (or any other), pleae refer to &lt;a href=&#34;https://github.com/ggerganov/llama.cpp/raw/master/convert.py&#34;&gt;convert.py&lt;/a&gt; and &lt;a href=&#34;https://github.com/ggerganov/llama.cpp/raw/master/convert-llama-ggml-to-gguf.py&#34;&gt;convert-llama-ggml-to-gguf.py&lt;/a&gt; to get gguf file through a ggml transformation.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Any contribution is welcomed! There&#39;s a TODO list in &lt;a href=&#34;https://github.com/orgs/SciSharp/projects/5&#34;&gt;LLamaSharp Dev Project&lt;/a&gt; and you could pick an interested one to start. Please read the &lt;a href=&#34;https://scisharp.github.io/LLamaSharp/latest/ContributingGuide/&#34;&gt;contributing guide&lt;/a&gt; for more informations.&lt;/p&gt; &#xA;&lt;p&gt;You can also do one of the followings to help us make LLamaSharp better:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Submit a feature request.&lt;/li&gt; &#xA; &lt;li&gt;Star and share LLamaSharp to let others know it.&lt;/li&gt; &#xA; &lt;li&gt;Write a blog or demo about LLamaSharp.&lt;/li&gt; &#xA; &lt;li&gt;Help to develop Web API and UI integration.&lt;/li&gt; &#xA; &lt;li&gt;Just open an issue about the problem you met!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contact us&lt;/h2&gt; &#xA;&lt;p&gt;Join our chat on &lt;a href=&#34;https://discord.gg/7wNVU65ZDY&#34;&gt;Discord&lt;/a&gt; (please contact Rinne to join the dev channel if you want to be a contributor).&lt;/p&gt; &#xA;&lt;p&gt;Join &lt;a href=&#34;http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&amp;amp;k=sN9VVMwbWjs5L0ATpizKKxOcZdEPMrp8&amp;amp;authKey=RLDw41bLTrEyEgZZi%2FzT4pYk%2BwmEFgFcrhs8ZbkiVY7a4JFckzJefaYNW6Lk4yPX&amp;amp;noverify=0&amp;amp;group_code=985366726&#34;&gt;QQ group&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Apendix&lt;/h2&gt; &#xA;&lt;h3&gt;Mapping from LLamaSharp to llama.cpp&lt;/h3&gt; &#xA;&lt;p&gt;Here&#39;s the mapping of them and corresponding model samples provided by &lt;code&gt;LLamaSharp&lt;/code&gt;. If you&#39;re not sure which model is available for a version, please try our sample model.&lt;/p&gt; &#xA;&lt;p&gt;The llama.cpp commit id will help if you want to compile a DLL yourself.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;LLamaSharp&lt;/th&gt; &#xA;   &lt;th&gt;Verified Model Resources&lt;/th&gt; &#xA;   &lt;th&gt;llama.cpp commit id&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.2.0&lt;/td&gt; &#xA;   &lt;td&gt;This version is not recommended to use.&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.2.1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/TheBloke/wizardLM-7B-GGML/tree/previous_llama&#34;&gt;WizardLM&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/tree/main&#34;&gt;Vicuna (filenames with &#34;old&#34;)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.2.2, v0.2.3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/TheBloke/wizardLM-7B-GGML/tree/previous_llama_ggmlv2&#34;&gt;WizardLM&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/tree/main&#34;&gt;Vicuna (filenames without &#34;old&#34;)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;63d2046&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.3.0, v0.4.0&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/AsakusaRinne/LLamaSharpSamples/tree/v0.3.0&#34;&gt;LLamaSharpSamples v0.3.0&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/TheBloke/wizardLM-7B-GGML/tree/main&#34;&gt;WizardLM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7e4ea5b&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.4.1-preview&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/SlyEcho/open_llama_3b_ggml&#34;&gt;Open llama 3b&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/OpenBuddy/openbuddy-llama-ggml&#34;&gt;Open Buddy&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;aacdbd4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.4.2-preview&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/TheBloke/llama-2-7B-Guanaco-QLoRA-GGML&#34;&gt;Llama2 7b GGML&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;3323112&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.5.1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/TheBloke/llama-2-7B-Guanaco-QLoRA-GGUF&#34;&gt;Llama2 7b GGUF&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;6b73ef1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.6.0&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/commit/cb33f43a2a9f5a5a5f8d290dd97c625d9ba97a2f&#34;&gt;cb33f43&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.7.0, v0.8.0&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/TheBloke/Thespis-13B-v0.5-GGUF/tree/main?not-for-all-audiences=true&#34;&gt;Thespis-13B&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/TheBloke/llama-2-7B-Guanaco-QLoRA-GGUF&#34;&gt;LLaMA2-7B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/commit/207b51900e15cc7f89763a3bb1c565fe11cbb45d&#34;&gt;207b519&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.8.1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/commit/e937066420b79a757bf80e9836eb12b88420a218&#34;&gt;e937066&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>shadowsocks/shadowsocks-windows</title>
    <updated>2023-12-01T02:15:04Z</updated>
    <id>tag:github.com,2023-12-01:/shadowsocks/shadowsocks-windows</id>
    <link href="https://github.com/shadowsocks/shadowsocks-windows" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A C# port of shadowsocks&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/shadowsocks/shadowsocks-windows/main/Shadowsocks.WPF/Resources/ssw128.png&#34; alt=&#34;[logo]&#34; width=&#34;48&#34;&gt; Shadowsocks for Windows&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/shadowsocks/shadowsocks-windows/actions?query=workflow%3ABuild&#34;&gt;&lt;img src=&#34;https://github.com/shadowsocks/shadowsocks-windows/workflows/Build/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/shadowsocks/shadowsocks-windows/actions?query=workflow%3ARelease&#34;&gt;&lt;img src=&#34;https://github.com/shadowsocks/shadowsocks-windows/workflows/Release/badge.svg?sanitize=true&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Connect to Shadowsocks servers.&lt;/li&gt; &#xA; &lt;li&gt;Automatically set system proxy.&lt;/li&gt; &#xA; &lt;li&gt;SIP002 URL scheme.&lt;/li&gt; &#xA; &lt;li&gt;SIP003 plugins.&lt;/li&gt; &#xA; &lt;li&gt;SIP008 online configuration delivery.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Downloads&lt;/h2&gt; &#xA;&lt;p&gt;Download from &lt;a href=&#34;https://github.com/shadowsocks/shadowsocks-windows/releases&#34;&gt;releases&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üöÄ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;PAC&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The PAC rules are generated from the geosite database in &lt;a href=&#34;https://github.com/v2fly/domain-list-community&#34;&gt;v2fly/domain-list-community&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Generation modes: whitelist mode and blacklist mode.&lt;/li&gt; &#xA; &lt;li&gt;Domain groups: &lt;code&gt;geositeDirectGroups&lt;/code&gt; and &lt;code&gt;geositeProxiedGroups&lt;/code&gt;. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;geositeDirectGroups&lt;/code&gt; is initialized with &lt;code&gt;cn&lt;/code&gt; and &lt;code&gt;geolocation-!cn@cn&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;geositeProxiedGroups&lt;/code&gt; is initialized with &lt;code&gt;geolocation-!cn&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;To switch between different modes, modify the &lt;code&gt;geositePreferDirect&lt;/code&gt; property in &lt;code&gt;gui-config.json&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;When &lt;code&gt;geositePreferDirect&lt;/code&gt; is false (default), PAC works in whitelist mode. Exception rules are generated from &lt;code&gt;geositeDirectGroups&lt;/code&gt;. Unmatched domains goes through the proxy.&lt;/li&gt; &#xA;   &lt;li&gt;When &lt;code&gt;geositePreferDirect&lt;/code&gt; is true, PAC works in blacklist mode. Blocking rules are generated from &lt;code&gt;geositeProxiedGroups&lt;/code&gt;. Exception rules are generated from &lt;code&gt;geositeDirectGroups&lt;/code&gt;. Unmatched domains are connected to directly.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Starting from 4.3.0.0, shadowsocks-windows defaults to whitelist mode with Chinese domains excluded from connecting via the proxy.&lt;/li&gt; &#xA; &lt;li&gt;The new default values make sure that: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;When in whitelist mode, Chinese domains, including non-Chinese companies&#39; Chinese CDNs, are connected to directly.&lt;/li&gt; &#xA;   &lt;li&gt;When in blacklist mode, only non-Chinese domains goes through the proxy. Chinese domains, as well as non-Chinese companies&#39; Chinese CDNs, are connected to directly.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;User-defined rules&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To define your own PAC rules, it&#39;s recommended to use the &lt;code&gt;user-rule.txt&lt;/code&gt; file.&lt;/li&gt; &#xA; &lt;li&gt;You can also modify &lt;code&gt;pac.txt&lt;/code&gt; directly. But your modifications won&#39;t persist after updating geosite from the upstream.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;IDE: Visual Studio 2019&lt;/li&gt; &#xA; &lt;li&gt;Language: C# 9.0&lt;/li&gt; &#xA; &lt;li&gt;SDK: .NET 5&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Build&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository recursively.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone --recursive https://github.com/shadowsocks/shadowsocks-windows.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Open the repository in VS2019, switch to the &lt;em&gt;Release&lt;/em&gt; configuration, and build the solution.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Contribute&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;PR welcome&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can use the &lt;a href=&#34;https://ss-windows.cube64128.xyz/&#34;&gt;Source Browser&lt;/a&gt; to review code online.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Shadowsocks-windows is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/shadowsocks/shadowsocks-windows/main/LICENSE.txt&#34;&gt;GPLv3&lt;/a&gt; license.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;BouncyCastle.NetCore (MIT)       https://github.com/chrishaly/bc-csharp&#xA;Caseless.Fody (MIT)              https://github.com/Fody/Caseless&#xA;Costura.Fody (MIT)               https://github.com/Fody/Costura&#xA;Fody (MIT)                       https://github.com/Fody/Fody&#xA;GlobalHotKey (GPLv3)             https://github.com/kirmir/GlobalHotKey&#xA;MdXaml (MIT)                     https://github.com/whistyun/MdXaml&#xA;Newtonsoft.Json (MIT)            https://www.newtonsoft.com/json&#xA;Privoxy (GPLv2)                  https://www.privoxy.org&#xA;ReactiveUI.WPF (MIT)             https://github.com/reactiveui/ReactiveUI&#xA;ReactiveUI.Events.WPF (MIT)      https://github.com/reactiveui/ReactiveUI&#xA;ReactiveUI.Fody (MIT)            https://github.com/reactiveui/ReactiveUI&#xA;ReactiveUI.Validation (MIT)      https://github.com/reactiveui/ReactiveUI.Validation&#xA;WPFLocalizationExtension (MS-PL) https://github.com/XAMLMarkupExtensions/WPFLocalizationExtension/&#xA;ZXing.Net (Apache 2.0)           https://github.com/micjahn/ZXing.Net&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/fluentui-blazor</title>
    <updated>2023-12-01T02:15:04Z</updated>
    <id>tag:github.com,2023-12-01:/microsoft/fluentui-blazor</id>
    <link href="https://github.com/microsoft/fluentui-blazor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Microsoft Fluent UI Blazor components library. For use with .NET 6.0 or higher Blazor applications&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Microsoft Fluent UI Blazor components&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.microsoft.com/en-us/dotnet/csharp/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/.NET-C%23-blue&#34; alt=&#34;.NET C#&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/nuget/v/Microsoft.FluentUI.AspNetCore.Components?label=NuGet%20Component%20Library&#34; alt=&#34;Nuget&#34;&gt; &lt;img src=&#34;https://img.shields.io/nuget/v/Microsoft.Fast.Templates.FluentUI?label=NuGet%20Templates&#34; alt=&#34;Nuget&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/fluentui-blazor/actions/workflows/codeql-analysis.yml&#34;&gt;&lt;img src=&#34;https://github.com/microsoft/fluentui-blazor/actions/workflows/codeql-analysis.yml/badge.svg?sanitize=true&#34; alt=&#34;Validate Security&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.gitter.im/#/room/#fluentui-blazor:gitter.im&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/chat%20on-gitter-7289da.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/FcSNfg4&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/chat%20on-discord-7289da.svg?sanitize=true&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; We appreciate your star, it helps!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;This package is for use in .NET 8 Blazor projects. If you are using .NET 6 or 7, please use the v3 version f the package which is named &lt;code&gt;Microsoft.Fast.Components.FluentUI&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;Microsoft.FluentUI.AspNetCore.Components&lt;/code&gt; package provides a set of &lt;a href=&#34;https://blazor.net&#34;&gt;Blazor&lt;/a&gt; components which are used to build applications that have a Fluent design (i.e. have the look and feel or modern Microsoft applications).&lt;/p&gt; &#xA;&lt;p&gt;Some of the components in the library are wrappers around Microsoft&#39;s official Fluent UI Web Components. Others are components that leverage the Fluent Design System or make it easier to work with Fluent UI. To get up and running with the library, see the &lt;strong&gt;Getting Started&lt;/strong&gt; section below.&lt;/p&gt; &#xA;&lt;p&gt;The source for the library is hosted in the &lt;a href=&#34;https://github.com/microsoft/fluentui-blazor&#34;&gt;fluentui-blazor&lt;/a&gt; repository at GitHub. Documentation on the components is available at the &lt;a href=&#34;https://www.fluentui-blazor.net&#34;&gt;demo site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Upgrading from an earlier version&lt;/h2&gt; &#xA;&lt;p&gt;If you are upgrading from an earlier version of the library, please see the &lt;a href=&#34;https://www.fluentui-blazor.net/whatsnew&#34;&gt;what&#39;s new&lt;/a&gt; for information on (breaking) changes.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Using our dotnet templates&lt;/h3&gt; &#xA;&lt;p&gt;The easiest way to get started is by using our &lt;a href=&#34;https://www.nuget.org/packages/Microsoft.FluentUI.AspNetCore.Templates&#34;&gt;Templates&lt;/a&gt;. These mimic the regular Blazor templates and come with the design and components pre-configured. You install them with this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dotnet new install Microsoft.FluentUI.AspNetCore.Templates&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Navigate to a folder where you want to create your new project and run the following command to create a new project.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dotnet new fluentblazor --name MyApplication&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to create a new standalone WebAssembly project, you can use the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dotnet new fluentblazorwasm --name MyApplication&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When using Visual Studio, you can also use the &lt;strong&gt;New Project&lt;/strong&gt; dialog to create a new project. The templates will be available under the &lt;strong&gt;Blazor&lt;/strong&gt; category.&lt;/p&gt; &#xA;&lt;h3&gt;Manual Install&lt;/h3&gt; &#xA;&lt;p&gt;To start using the &lt;strong&gt;Fluent UI Blazor components&lt;/strong&gt; from scratch, you first need to install the main &lt;a href=&#34;https://www.nuget.org/packages/Microsoft.FluentUI.AspNetCore.Components/&#34;&gt;Nuget package&lt;/a&gt; in the project you want to use the library and its components. You can use the NuGet package manager in your IDE or use the following command when using a CLI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dotnet add package Microsoft.FluentUI.AspNetCore.Components&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to extend the functionality of the library with &lt;a href=&#34;https://www.nuget.org/packages/Microsoft.FluentUI.AspNetCore.Components.Icons&#34;&gt;icons&lt;/a&gt; or &lt;a href=&#34;https://www.nuget.org/packages/Microsoft.FluentUI.AspNetCore.Components.Emoji&#34;&gt;emoji&lt;/a&gt;, you can install additional packages for that:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dotnet add package Microsoft.FluentUI.AspNetCore.Components.Icons&#xA;dotnet add package Microsoft.FluentUI.AspNetCore.Components.Emoji&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Script&lt;/h3&gt; &#xA;&lt;p&gt;As mentioned, we wrap the &lt;strong&gt;Fluent UI Web Components&lt;/strong&gt; which are implemented in a script file. This &lt;strong&gt;file is included in the library&lt;/strong&gt; itself and does not have to be downloaded or pulled from a CDN.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;By including the script in the library we can safeguard that you are always using the best matching script version.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;When using &lt;strong&gt;SSR (Static Server Rendering)&lt;/strong&gt;, you will need to include the web components script in your &lt;code&gt;App.razor&lt;/code&gt;. As there is no Blazor script being loaded/used, our script will also not get loaded.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;script src=&#34;_content/Microsoft.FluentUI.AspNetCore.Components/js/web-components-v2.5.16.min.js&#34; type=&#34;module&#34; async&amp;gt;&amp;lt;/script&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you add interactivity later, the Blazor script will kick in and try to load the web component script again but JavaScript will handle that gracefully by design.&lt;/p&gt; &#xA;&lt;h3&gt;Reboot (optional)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Reboot&lt;/strong&gt; is a collection of element-specific CSS changes in a single file to help kick-start building a site with the &lt;strong&gt;Fluent UI Blazor&lt;/strong&gt; components. It provides an elegant, consistent, and simple baseline to build upon.&lt;/p&gt; &#xA;&lt;p&gt;If you want to use &lt;strong&gt;Reboot&lt;/strong&gt;, you&#39;ll need to add to your &lt;code&gt;app.razor&lt;/code&gt;, &lt;code&gt;index.html&lt;/code&gt; or &lt;code&gt;_Layout.cshtml&lt;/code&gt; file a line that includes the stylesheet (&lt;code&gt;.css&lt;/code&gt; file). This can be done by adding the following line to the &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt; section:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;link href=&#34;_content/Microsoft.FluentUI.AspNetCore.Components/css/reboot.css&#34; rel=&#34;stylesheet&#34; /&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When using the templates to create your application, &lt;strong&gt;Reboot&lt;/strong&gt; is already set-up for you.&lt;/p&gt; &#xA;&lt;h3&gt;Register Services&lt;/h3&gt; &#xA;&lt;p&gt;Add the following in &lt;code&gt;Program.cs&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;builder.Services.AddFluentUIComponents();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you&#39;re running your application on &lt;strong&gt;Blazor Server&lt;/strong&gt;, make sure a default &lt;code&gt;HttpClient&lt;/code&gt; is registered before the &lt;code&gt;AddFluentUIComponents&lt;/code&gt; method.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;builder.Services.AddHttpClient();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Add Component Providers&lt;/h3&gt; &#xA;&lt;p&gt;Add the following components at the end of your &lt;code&gt;MainLayout.razor&lt;/code&gt; file.&lt;br&gt; These providers are used by associated services to display Toasts, Dialog boxes, Tooltips or Message Bars correctly.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;FluentToastProvider /&amp;gt;&#xA;&amp;lt;FluentDialogProvider /&amp;gt;&#xA;&amp;lt;FluentTooltipProvider /&amp;gt;&#xA;&amp;lt;FluentMessageBarProvider /&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;note:&lt;/strong&gt; You can remove providers that are not used in your application.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Working with Icons and Emoji&lt;/h2&gt; &#xA;&lt;p&gt;We have additional packages available that include the complete &lt;strong&gt;Fluent UI System icons&lt;/strong&gt; and &lt;strong&gt;Fluent UI Emoji&lt;/strong&gt; collections. Please refer to the &lt;a href=&#34;https://www.fluentui-blazor.net/IconsAndEmoji&#34;&gt;Icons and Emoji&lt;/a&gt; page for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;With the package installed, you can begin using the &lt;strong&gt;Fluent UI Blazor components&lt;/strong&gt; in the same way as any other Blazor component.&lt;/p&gt; &#xA;&lt;h3&gt;Add Imports&lt;/h3&gt; &#xA;&lt;p&gt;After the package is added, you need to add the following in your &lt;code&gt;_Imports.razor&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-razor&#34;&gt;@using Microsoft.FluentUI.AspNetCore.Components&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Quick Start&lt;/h3&gt; &#xA;&lt;p&gt;This is literally all you need in your views to use Fluent UI Blazor components.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;FluentCard&amp;gt;&#xA;  &amp;lt;h2&amp;gt;Hello World!&amp;lt;/h2&amp;gt;&#xA;  &amp;lt;FluentButton Appearance=&#34;@Appearance.Accent&#34;&amp;gt;Click Me&amp;lt;/FluentButton&amp;gt;&#xA;&amp;lt;/FluentCard&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configuring the Design System&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;strong&gt;Fluent UI Blazor&lt;/strong&gt; components are built on FAST&#39;s (Adaptive UI) technology, which enables design customization and personalization, while automatically maintaining accessibility. This is accomplished through setting various &#34;design tokens&#34;. The library exposes all design tokens, which you can use both from code as in a declarative way in your &lt;code&gt;.razor&lt;/code&gt; pages. The different ways of working with design tokens are described in the &lt;a href=&#34;https://www.fluentui-blazor.net/DesignTokens&#34;&gt;design tokens&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;h2&gt;Blazor Hybrid&lt;/h2&gt; &#xA;&lt;p&gt;You can use this library in &lt;strong&gt;Blazor Hybrid&lt;/strong&gt; (MAUI/WPF/Windows Forms) projects. Setup is almost the same as described in the &#34;Getting started&#34; section above, but to get everything to work you&#39;ll need to take one extra steps (for now) described below.&lt;/p&gt; &#xA;&lt;h3&gt;Temporary workaround for MAUI/WPF/Windows Forms issues&lt;/h3&gt; &#xA;&lt;p&gt;Currently when using the WebView to run Blazor (so all Hybrid variants) the web-components script is not imported automatically (see &lt;a href=&#34;https://github.com/microsoft/fluentui-blazor/issues/404&#34;&gt;#404&lt;/a&gt;). There is also an issue with loading the custom event handlers that are being configured by the web-components script. Until these are fixed on the WebView side, there is a workaround available, namely to intercept &lt;code&gt;&#39;_framework/blazor.modules.json&#39;&lt;/code&gt; and provide proper JS initializers file (created by build). The needed &lt;code&gt;initializersLoader.webview.js&lt;/code&gt; has been added to the library and needs to be included with a script tag &lt;strong&gt;before&lt;/strong&gt; the &lt;code&gt;_framework/blazor.webview.js&lt;/code&gt; script tag:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;script app-name=&#34;{NAME OF YOUR APP}&#34; src=&#34;./_content/Microsoft.FluentUI.AspNetCore.Components/js/initializersLoader.webview.js&#34;&amp;gt;&amp;lt;/script&amp;gt;&#xA;&amp;lt;script src=&#34;_framework/blazor.webview.js&#34;&amp;gt;&amp;lt;/script&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;app-name&lt;/code&gt; attribute needs to match your app&#39;s assembly name - initializersLoader uses &#39;app-name&#39; to resolve name of the file with initializers. initializersLoader replaces standard &lt;code&gt;fetch&lt;/code&gt; function with one which provides the correct file in place of the empty &lt;code&gt;blazor.modules.json&lt;/code&gt;. &lt;code&gt;fetch&lt;/code&gt; is restored to its original state once &lt;code&gt;_framework/blazor.modules.json&lt;/code&gt; request is intercepted.&lt;/p&gt; &#xA;&lt;p&gt;For more information regarding the bug, see issue &lt;a href=&#34;https://github.com/dotnet/maui/issues/15234&#34;&gt;15234&lt;/a&gt; in the MAUI repo.&lt;/p&gt; &#xA;&lt;h2&gt;Use the DataGrid component with EF Core&lt;/h2&gt; &#xA;&lt;p&gt;If you want to use the &lt;code&gt;&amp;lt;FluentDataGrid&amp;gt;&lt;/code&gt; with data provided through EF Core, you need to install an additional package so the grid knows how to resolve queries asynchronously for efficiency.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;Install the package by running the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet add package Microsoft.FluentUI.AspNetCore.Components.DataGrid.EntityFrameworkAdapter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;In your &lt;code&gt;Program.cs&lt;/code&gt; file, you need to add the following after the &lt;code&gt;builder.Services.AddFluentUIComponents(...);&lt;/code&gt; lines:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;builder.Services.AddDataGridEntityFrameworkAdapter();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Additional resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The Microsoft Fluent UI Blazor components &lt;a href=&#34;https://www.fluentui-blazor.net&#34;&gt;documentation and demo site&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing to the project&lt;/h2&gt; &#xA;&lt;p&gt;We offer some guidelines on how you can get started &lt;a href=&#34;https://github.com/microsoft/fluentui-blazor/raw/main/CONTRIBUTING.md&#34;&gt;contributing to the project&lt;/a&gt;. We alo have a document that explains and shows how to &lt;a href=&#34;https://github.com/microsoft/fluentui-blazor/raw/main/unit-tests.md&#34;&gt;write and develop unit tests&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Joining the Community&lt;/h2&gt; &#xA;&lt;p&gt;Looking to get answers to questions or engage with us in real-time? Our community is active on &lt;a href=&#34;https://app.gitter.im/#/room/#fluentui-blazor:gitter.im&#34;&gt;Gitter&lt;/a&gt; and &lt;a href=&#34;https://discord.gg/FcSNfg4&#34;&gt;Discord&lt;/a&gt;. Submit requests and issues on &lt;a href=&#34;https://github.com/microsoft/blazor-fluentui/issues/new/choose&#34;&gt;GitHub&lt;/a&gt;, or join us by contributing on &lt;a href=&#34;https://github.com/microsoft/fluentui-blazor/labels/community:good-first-issue&#34;&gt;some good first issues via GitHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We look forward to building an amazing open source community with you!&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Join the community and chat with us in real-time on &lt;a href=&#34;https://app.gitter.im/#/room/#fluentui-blazor:gitter.im&#34;&gt;Gitter&lt;/a&gt; or &lt;a href=&#34;https://discord.gg/FcSNfg4&#34;&gt;Discord&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Submit requests and issues on &lt;a href=&#34;https://github.com/microsoft/fluentui-blazor/issues/new/choose&#34;&gt;GitHub&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Contribute by helping out on some of our recommended first issues on &lt;a href=&#34;https://github.com/microsoft/fluentui-blazor/labels/community:good-first-issue&#34;&gt;GitHub&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>