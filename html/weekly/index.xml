<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-14T01:57:13Z</updated>
  <subtitle>Weekly Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>durgeshsamariya/awesome-github-profile-readme-templates</title>
    <updated>2024-01-14T01:57:13Z</updated>
    <id>tag:github.com,2024-01-14:/durgeshsamariya/awesome-github-profile-readme-templates</id>
    <link href="https://github.com/durgeshsamariya/awesome-github-profile-readme-templates" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository contains best profile readme&#39;s for your reference.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome GitHub Profile README Template Collection&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/durgeshsamariya/awesome-github-profile-readme-templates/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/themlphdstudent/awesome-github-profile-readme-templates.svg?sanitize=true&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/durgeshsamariya/awesome-github-profile-readme-templates/network&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/themlphdstudent/awesome-github-profile-readme-templates.svg?color=blue&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/durgeshsamariya/awesome-github-profile-readme-templates/network&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/themlphdstudent/awesome-github-profile-readme-templates.svg?color=blue&#34; alt=&#34;GitHub contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A collection of GitHub profile README&#39;s examples.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/durgeshsamariya/awesome-github-profile-readme-templates/raw/master/CONTRIBUTING.md&#34;&gt;Contributions&lt;/a&gt; are welcome. Read the &lt;a href=&#34;https://github.com/durgeshsamariya/awesome-github-profile-readme-templates/raw/master/CONTRIBUTING.md&#34;&gt;Guidelines&lt;/a&gt; on how to contribute. Feel free to add your or someone else&#39;s GitHub profile README file.&lt;/p&gt; &#xA;&lt;p&gt;Don&#39;t forget to hit the &lt;span&gt;‚≠ê&lt;/span&gt; if you like this repo.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ethen8181/machine-learning</title>
    <updated>2024-01-14T01:57:13Z</updated>
    <id>tag:github.com,2024-01-14:/ethen8181/machine-learning</id>
    <link href="https://github.com/ethen8181/machine-learning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üåé machine learning tutorials (mainly in Python3)&lt;/p&gt;&lt;hr&gt;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#machine-learning&#34;&gt;machine-learning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#documentation-listings&#34;&gt;Documentation Listings&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#deep-learning&#34;&gt;deep learning&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#model-deployment&#34;&gt;model deployment&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#operation-research&#34;&gt;operation research&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#reinforcement-learning&#34;&gt;reinforcement learning&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#ad&#34;&gt;ad&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#search&#34;&gt;search&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#time-series&#34;&gt;time series&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#projects&#34;&gt;projects&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#ab-tests&#34;&gt;ab tests&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#model-selection&#34;&gt;model selection&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#dim-reduct&#34;&gt;dim reduct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#recsys&#34;&gt;recsys&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#trees&#34;&gt;trees&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#clustering&#34;&gt;clustering&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#keras&#34;&gt;keras&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#text-classification&#34;&gt;text classification&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#regularization&#34;&gt;regularization&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#networkx&#34;&gt;networkx&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#association-rule&#34;&gt;association rule&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#big-data&#34;&gt;big data&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#data-science-is-software&#34;&gt;data science is software&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#ga&#34;&gt;ga&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#unbalanced&#34;&gt;unbalanced&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#clustering-old&#34;&gt;clustering old&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#linear-regression&#34;&gt;linear regression&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ethen8181/machine-learning/master/#python-programming&#34;&gt;Python Programming&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;machine-learning&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ethen8181/machine-learning/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/mashape/apistatus.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/python-3.10-blue.svg?sanitize=true&#34; alt=&#34;Python 3.10&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/python-3.9-blue.svg?sanitize=true&#34; alt=&#34;Python 3.9&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/python-3.8-blue.svg?sanitize=true&#34; alt=&#34;Python 3.8&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a continuously updated repository that documents personal journey on learning data science, machine learning related topics.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; Introduce machine learning contents in Jupyter Notebook format. The content aims to strike a good balance between mathematical notations, educational implementation from scratch using Python&#39;s scientific stack including numpy, numba, scipy, pandas, matplotlib, pyspark etc. and open-source library usage such as scikit-learn, fasttext, huggingface, onnx, xgboost, lightgbm, pytorch, keras, tensorflow, gensim, h2o, ortools, ray tune etc.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation Listings&lt;/h2&gt; &#xA;&lt;h3&gt;deep learning&lt;/h3&gt; &#xA;&lt;p&gt;Curated notes on deep learning.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Softmax Regression from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/softmax.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/softmax.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Softmax Regression - Tensorflow hello world. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/softmax_tensorflow.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/softmax_tensorflow.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-layers Neural Network - Tensorflow. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/nn_tensorflow.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/nn_tensorflow.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Convolutional Neural Network (CNN) - Tensorflow. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/cnn_image_tensorflow.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/cnn_image_tensorflow.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Recurrent Neural Network (RNN). &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Vanilla RNN - Tensorflow. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/rnn/1_tensorflow_rnn.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/rnn/1_tensorflow_rnn.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Long Short Term Memory (LSTM) - Tensorflow. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/rnn/2_tensorflow_lstm.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/rnn/2_tensorflow_lstm.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;RNN, LSTM - PyTorch hello world. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/rnn/1_pytorch_rnn.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/rnn/1_pytorch_rnn.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Word2vec (skipgram + negative sampling) using Gensim. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/word2vec/word2vec_detailed.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/word2vec/word2vec_detailed.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Sequence to Sequence Neural Network (Seq2Seq). &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Seq2Seq for German to English Machine Translation - PyTorch. Includes quick intro to torchtext [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/seq2seq/1_torch_seq2seq_intro.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/seq2seq/1_torch_seq2seq_intro.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Seq2Seq with Attention for German to English Machine Translation - PyTorch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/seq2seq/2_torch_seq2seq_attention.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/seq2seq/2_torch_seq2seq_attention.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Subword Tokenization. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Byte Pair Encoding (BPE) from scratch and quick walkthrough of sentencepiece. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/subword/bpe.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/subword/bpe.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Fasttext. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Multi-Label Text Classification with Fasttext and Huggingface Tokenizers. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/multi_label/fasttext.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/multi_label/fasttext.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Product Quantization for Model Compression. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/multi_label/product_quantization.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/multi_label/product_quantization.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Approximate Nearest Neighborhood Search with Navigable Small World. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/multi_label/nsw.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/multi_label/nsw.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Graph Neural Network (GNN). &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Quick Introduction to Graph Neural Network Node Classification Task (DGL, GraphSAGE). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/gnn/gnn_node_classification_intro.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/gnn/gnn_node_classification_intro.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Transformer. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Transformer, Attention is All you Need - PyTorch, Huggingface Datasets. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/seq2seq/torch_transformer.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/seq2seq/torch_transformer.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Machine Translation with Huggingface Transformers mT5. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/seq2seq/translation_mt5/translation_mt5.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/seq2seq/translation_mt5/translation_mt5.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Fine Tuning Pre-trained Encoder on Question Answer Task. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/question_answer/question_answer.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/question_answer/question_answer.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Training Bi-Encoder Models with Contrastive Learning Notes. [&lt;a href=&#34;https://nbviewer.org/github/ethen8181/machine-learning/blob/master/deep_learning/contrastive/contrastive_learning_notes.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/contrastive/contrastive_learning_notes.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Sentence Transformer: Training Bi-Encoder via Contrastive Loss. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/contrastive/sentence_transformer.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/contrastive/sentence_transformer.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Introduction to CLIP (Contrastive Language-Image Pre-training), LiT, ViT [&lt;a href=&#34;https://nbviewer.org/github/ethen8181/machine-learning/blob/master/deep_learning/contrastive/clip/clip.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/contrastive/clip/clip.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Self Supervised (SIMCLR) versus Supervised Contrastive Learning. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/contrastive/self_supervised_vs_supervised_contrastive/self_supervised_vs_supervised_contrastive.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/contrastive/self_supervised_vs_supervised_contrastive/self_supervised_vs_supervised_contrastive.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Tabular &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Deep Learning for Tabular Data - PyTorch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/tabular/deep_learning_tabular.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/tabular/deep_learning_tabular.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Deep Learning - Learning to Rank 101 (RankNet, ListNet). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/tabular/deep_learning_learning_to_rank.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/tabular/deep_learning_learning_to_rank.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;BERT CTR. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/tabular/bert_ctr/bert_ctr.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/deep_learning/tabular/bert_ctr/bert_ctr.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;model deployment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;FastAPI &amp;amp; Azure Kubernetes Cluster. End to end example of training a model and hosting it as a service. [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/raw/master/model_deployment/fastapi_kubernetes&#34;&gt;folder&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Quick Intro to Gradient Boosted Tree Inferencing. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_deployment/gbt_inference/gbt_inference.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_deployment/gbt_inference/gbt_inference.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Speeding Up Transformers Inferencing. [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/raw/master/model_deployment/transformers&#34;&gt;folder&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Working with AWS (Amazon Web Services). [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/raw/master/model_deployment/aws/&#34;&gt;folder&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;operation research&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Operation Research Quick Intro Via Ortools. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/operation_research/ortools.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/operation_research/ortools.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;reinforcement learning&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Introduction to Multi-armed Bandits. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/reinforcement_learning/multi_armed_bandits.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/reinforcement_learning/multi_armed_bandits.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ad&lt;/h3&gt; &#xA;&lt;p&gt;Notes related to advertising domain.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Quick introduction to generalized second price auction. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ad/gsp_ad_auction.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/ad/gsp_ad_auction.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;search&lt;/h3&gt; &#xA;&lt;p&gt;Information Retrieval, some examples are demonstrated using ElasticSearch.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Introduction to BM25 (Best Match). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/search/bm25_intro.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/search/bm25_intro.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;time series&lt;/h3&gt; &#xA;&lt;p&gt;Forecasting methods for timeseries-based data.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Getting started with time series analysis with Exponential Smoothing (Holt-Winters). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/time_series/1_exponential_smoothing.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/time_series/1_exponential_smoothing.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Framing time series problem as supervised-learning. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/time_series/3_supervised_time_series.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/time_series/3_supervised_time_series.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;First Foray Into Discrete/Fast Fourier Transformation. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/time_series/fft/fft.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/time_series/fft/fft.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;projects&lt;/h3&gt; &#xA;&lt;p&gt;End to end project including data preprocessing, model building.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/c/rossmann-store-sales/&#34;&gt;Kaggle: Rossman Store Sales&lt;/a&gt; Predicting daily store sales. Also introduces deep learning for tabular data. [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/raw/master/projects/kaggle_rossman_store_sales/&#34;&gt;folder&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/c/quora-insincere-questions-classification/&#34;&gt;Kaggle: Quora Insincere Questions Classification&lt;/a&gt; Predicting insincere questions. [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/raw/master/projects/kaggle_quora_insincere/&#34;&gt;folder&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ab tests&lt;/h3&gt; &#xA;&lt;p&gt;A/B testing, a.k.a experimental design. Includes: Quick review of necessary statistic concepts. Methods and workflow/thought-process for conducting the test and caveats to look out for.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Frequentist A/B testing (includes a quick review of concepts such as p-value, confidence interval). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/frequentist_ab_test.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/ab_tests/frequentist_ab_test.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Quantile Regression and its application in A/B testing. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Quick Introduction to Quantile Regression. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/quantile_regression/quantile_regression.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/ab_tests/quantile_regression/quantile_regression.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Quantile Regression&#39;s application in A/B testing. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/quantile_regression/ab_test_regression.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/ab_tests/quantile_regression/ab_test_regression.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Casual Inference &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Propensity Score Matching. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/causal_inference/matching.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/ab_tests/causal_inference/matching.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Inverse Propensity Weighting. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/causal_inference/inverse_propensity_weighting.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/ab_tests/causal_inference/inverse_propensity_weighting.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Quick introduction to difference in difference. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ab_tests/causal_inference/diff_in_diff.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/ab_tests/causal_inference/diff_in_diff.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;model selection&lt;/h3&gt; &#xA;&lt;p&gt;Methods for selecting, improving, evaluating models/algorithms.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;K-fold cross validation, grid/random search from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/model_selection.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/model_selection.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;AUC (Area under the ROC curve and precision/recall curve) from scratch (includes the process of building a custom scikit-learn transformer). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/auc/auc.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/auc/auc.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Evaluation metrics for imbalanced dataset. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/imbalanced/imbalanced_metrics.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/imbalanced/imbalanced_metrics.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Detecting collinearity amongst features (Variance Inflation Factor for numeric features and Cramer&#39;s V statistics for categorical features), also introduces Linear Regression from a Maximum Likelihood perspective and the R-squared evaluation metric. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/collinearity.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/collinearity.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Curated tips and tricks for technical and soft skills. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/tips_and_tricks/tips_and_tricks.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/tips_and_tricks/tips_and_tricks.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Partial Dependence Plot (PDP), model-agnostic approach for directional feature influence. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/partial_dependence/partial_dependence.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/partial_dependence/partial_dependence.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Kullback-Leibler (KL) Divergence. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/kl_divergence.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/kl_divergence.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Probability Calibration for classification models with Platt Scaling, Histogram Binning, Isotonic Regression. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/prob_calibration/prob_calibration.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/prob_calibration/prob_calibration.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Probability Calibration for deep learning classification models with Temperature Scaling. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/prob_calibration/deeplearning_prob_calibration.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/prob_calibration/deeplearning_prob_calibration.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;HyperParameter Tuning with Ray Tune and Hyperband. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/model_selection/ray_tune_hyperband.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/model_selection/ray_tune_hyperband.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;dim reduct&lt;/h3&gt; &#xA;&lt;p&gt;Dimensionality reduction methods.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Principal Component Analysis (PCA) from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/dim_reduct/PCA.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/dim_reduct/PCA.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Introduction to Singular Value Decomposition (SVD), also known as Latent Semantic Analysis/Indexing (LSA/LSI). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/dim_reduct/svd.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/dim_reduct/svd.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;recsys&lt;/h3&gt; &#xA;&lt;p&gt;Recommendation system with a focus on matrix factorization methods. Starters into the field should go through the first notebook to understand the basics of matrix factorization methods.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Alternating Least Squares with Weighted Regularization (ALS-WR) from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/1_ALSWR.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/recsys/1_ALSWR.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;ALS-WR for implicit feedback data from scratch &amp;amp; Mean Average Precision at k (mapk) and Normalized Cumulative Discounted Gain (ndcg) evaluation. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/2_implicit.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/recsys/2_implicit.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Bayesian Personalized Ranking (BPR) from scratch &amp;amp; AUC evaluation. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/4_bpr.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/recsys/4_bpr.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;WARP (Weighted Approximate-Rank Pairwise) Loss using lightfm. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/5_warp.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/recsys/5_warp.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Factorization Machine from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/factorization_machine/factorization_machine.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/recsys/factorization_machine/factorization_machine.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Content-Based Recommenders: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;(Text) Content-Based Recommenders. Introducing Approximate Nearest Neighborhood (ANN) - Locality Sensitive Hashing (LSH) for cosine distance from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/content_based/lsh_text.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/recsys/content_based/lsh_text.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Approximate Nearest Neighborhood (ANN): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Benchmarking ANN implementations (nmslib). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/ann_benchmarks/ann_benchmarks.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/recsys/ann_benchmarks/ann_benchmarks.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Calibrated Recommendation for reducing bias/increasing diversity in recommendation. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/calibration/calibrated_reco.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/recsys/calibration/calibrated_reco.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Maximum Inner Product for Speeding Up Generating Recommendations. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/max_inner_product/max_inner_product.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/recsys/max_inner_product/max_inner_product.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;trees&lt;/h3&gt; &#xA;&lt;p&gt;Tree-based models for both regression and classification tasks.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Decision Tree from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/decision_tree.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/trees/decision_tree.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Random Forest from scratch and Extra Trees. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/random_forest.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/trees/random_forest.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Gradient Boosting Machine (GBM) from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/gbm/gbm.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/trees/gbm/gbm.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Xgboost API walkthrough (includes hyperparameter tuning via scikit-learn like API). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/xgboost.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/trees/xgboost.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;LightGBM API walkthrough and a discussion about categorical features in tree-based models. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/lightgbm.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/trees/lightgbm.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Monotonic Constraint with Boosted Tree. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/monotonic.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/trees/monotonic.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;clustering&lt;/h3&gt; &#xA;&lt;p&gt;TF-IDF and Topic Modeling are techniques specifically used for text analytics.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;TF-IDF (text frequency - inverse document frequency) from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/clustering/tfidf/tfidf.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/clustering/tfidf/tfidf.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;K-means, K-means++ from scratch; Elbow method for choosing K. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/clustering/kmeans.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/clustering/kmeans.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Gaussian Mixture Model from scratch; AIC and BIC for choosing the number of Gaussians. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/clustering/GMM/GMM.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/clustering/GMM/GMM.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Topic Modeling with gensim&#39;s Latent Dirichlet Allocation(LDA). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/clustering/topic_model/LDA.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/clustering/topic_model/LDA.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;keras&lt;/h3&gt; &#xA;&lt;p&gt;For those interested there&#39;s also a &lt;a href=&#34;https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf&#34;&gt;keras cheatsheet&lt;/a&gt; that may come in handy.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Multi-layers Neural Network (keras basics). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/nn_keras_basics.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/keras/nn_keras_basics.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-layers Neural Network hyperparameter tuning via scikit-learn like API. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/nn_keras_hyperparameter_tuning.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/keras/nn_keras_hyperparameter_tuning.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Convolutional Neural Network (CNN) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Image classification basics. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/cnn_image_keras.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/keras/cnn_image_keras.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Introduction to Residual Networks (ResNets) and Class Activation Maps (CAM). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/resnet_cam/resnet_cam.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/keras/resnet_cam/resnet_cam.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Recurrent Neural Network (RNN) - language modeling basics. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/rnn_language_model_basic_keras.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/keras/rnn_language_model_basic_keras.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Text Classification &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Word2vec for Text Classification. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/text_classification/word2vec_text_classification.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/keras/text_classification/word2vec_text_classification.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Leveraging Pre-trained Word Embedding for Text Classification. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/text_classification/keras_pretrained_embedding.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/keras/text_classification/keras_pretrained_embedding.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Sentencepiece Subword tokenization for Text Classification. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/keras/text_classification/keras_subword_tokenization.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/keras/text_classification/keras_subword_tokenization.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;text classification&lt;/h3&gt; &#xA;&lt;p&gt;Deep learning techniques for text classification are categorized in its own section.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Building intuition with spam classification using scikit-learn (scikit-learn hello world). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/text_classification/basics/basics.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/text_classification/basics/basics.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Bernoulli and Multinomial Naive Bayes from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/text_classification/naive_bayes/naive_bayes.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/text_classification/naive_bayes/naive_bayes.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Logistic Regression (stochastic gradient descent) from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/text_classification/logistic.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/text_classification/logistic.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Chi-square feature selection from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/text_classification/chisquare.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/text_classification/chisquare.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;regularization&lt;/h3&gt; &#xA;&lt;p&gt;Building intuition on Ridge and Lasso regularization using scikit-learn.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;View [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/regularization/regularization.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/regularization/regularization.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;networkx&lt;/h3&gt; &#xA;&lt;p&gt;Graph library other than &lt;code&gt;networkx&lt;/code&gt; are also discussed.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PyCon 2016: Practical Network Analysis Made Simple. Quickstart to networkx&#39;s API. Includes some basic graph plotting and algorithms. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/networkx/networkx.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/networkx/networkx.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Short Walkthrough of PageRank. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/networkx/page_rank.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/networkx/page_rank.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Influence Maximization from scratch. Includes discussion on Independent Cascade (IC), Submodular Optimization algorithms including Greedy and Lazy Greedy, a.k.a Cost Efficient Lazy Forward (CELF) [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/networkx/max_influence/max_influence.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/networkx/max_influence/max_influence.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;association rule&lt;/h3&gt; &#xA;&lt;p&gt;Also known as market-basket analysis.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Apriori from scratch. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/association_rule/apriori.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/association_rule/apriori.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Using R&#39;s arules package (aprori) on tabular data. [&lt;a href=&#34;http://ethen8181.github.io/machine-learning/association_rule/R/apriori.html&#34;&gt;Rmarkdown&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;big data&lt;/h3&gt; &#xA;&lt;p&gt;Exploring big data tools, such as Spark and H2O.ai. For those interested there&#39;s also a &lt;a href=&#34;https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_Cheat_Sheet_Python.pdf&#34;&gt;pyspark rdd cheatsheet&lt;/a&gt; and &lt;a href=&#34;https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf&#34;&gt;pyspark dataframe cheatsheet&lt;/a&gt; that may come in handy.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Local Hadoop cluster installation on Mac. [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/tree/master/big_data/local_hadoop.md&#34;&gt;markdown&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;PySpark installation on Mac. [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/tree/master/big_data/spark_installation.md&#34;&gt;markdown&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Examples of manipulating with data (crimes data) and building a RandomForest model with PySpark MLlib. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/big_data/spark_crime.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/big_data/spark_crime.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;PCA with PySpark MLlib. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/big_data/spark_pca.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/big_data/spark_pca.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Tuning Spark Partitions. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/big_data/spark_partitions.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/big_data/spark_partitions.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;H2O API walkthrough (using GBM as an example). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/big_data/h2o/h2o_api_walkthrough.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/big_data/h2o/h2o_api_walkthrough.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Spark MLlib Binary Classification (using GBM as an example). [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/raw/master/big_data/sparkml/sparkml.json&#34;&gt;raw zeppelin notebook&lt;/a&gt;][&lt;a href=&#34;https://www.zepl.com/explore&#34;&gt;Zepl&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;data science is software&lt;/h3&gt; &#xA;&lt;p&gt;Best practices for doing data science in Python.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;View [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/data_science_is_software/notebooks/data_science_is_software.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/data_science_is_software/notebooks/data_science_is_software.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ga&lt;/h3&gt; &#xA;&lt;p&gt;Genetic Algorithm. Math-free explanation and code from scratch.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Start from a simple optimization problem and extending it to traveling salesman problem (tsp).&lt;/li&gt; &#xA; &lt;li&gt;View [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/ga/ga.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/ga/ga.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;unbalanced&lt;/h3&gt; &#xA;&lt;p&gt;Choosing the optimal cutoff value for logistic regression using cost-sensitive mistakes (meaning when the cost of misclassification might differ between the two classes) when your dataset consists of unbalanced binary classes. e.g. Majority of the data points in the dataset have a positive outcome, while few have negative, or vice versa. The notion can be extended to any other classification algorithm that can predict class‚Äôs probability, this documentation just uses logistic regression for illustration purpose.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Visualize two by two standard confusion matrix and ROC curve with costs using ggplot2.&lt;/li&gt; &#xA; &lt;li&gt;View [&lt;a href=&#34;http://ethen8181.github.io/machine-learning/unbalanced/unbalanced.html&#34;&gt;Rmarkdown&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;clustering old&lt;/h3&gt; &#xA;&lt;p&gt;A collection of scattered old clustering documents in R.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Toy sample code of the LDA algorithm (gibbs sampling) and the topicmodels library. [&lt;a href=&#34;http://ethen8181.github.io/machine-learning/clustering_old/topic_model/LDA.html&#34;&gt;Rmarkdown&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;k-shingle, Minhash and Locality Sensitive Hashing for solving the problem of finding textually similar documents. [&lt;a href=&#34;http://ethen8181.github.io/machine-learning/clustering_old/text_similarity/text_similarity.html&#34;&gt;Rmarkdown&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Introducing tf-idf (term frequency-inverse document frequency), a text mining technique. Also uses it to perform text clustering via hierarchical clustering. [&lt;a href=&#34;http://ethen8181.github.io/machine-learning/clustering_old/tf_idf/tf_idf.html&#34;&gt;Rmarkdown&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Some useful evaluations when working with hierarchical clustering and K-means clustering (K-means++ is used here). Including Calinski-Harabasz index for determine the right K (cluster number) for clustering and boostrap evaluation of the clustering result‚Äôs stability. [&lt;a href=&#34;http://ethen8181.github.io/machine-learning/clustering_old/clustering/clustering.html&#34;&gt;Rmarkdown&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;linear regression&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Training Linear Regression with gradient descent in R, briefly covers the interpretation and visualization of linear regression&#39;s summary output. [&lt;a href=&#34;http://ethen8181.github.io/machine-learning/linear_regression/linear_regession.html&#34;&gt;Rmarkdown&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Python Programming&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Extremely Quick Guide to Unicode. [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/raw/master/python/unicode.md&#34;&gt;markdown&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Quick Example of Factory Design Pattern. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/factory_pattern.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/factory_pattern.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Parallel programming with Python (threading, multiprocessing, concurrent.futures, joblib). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/parallel.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/parallel.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Understanding iterables, iterator and generators. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/iterator/iterator.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/iterator/iterator.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Cohort analysis. Visualizing user retention by cohort with seaborn&#39;s heatmap and illustrating pandas&#39;s unstack. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/cohort/cohort.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/cohort/cohort.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Logging module. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/logging.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/logging.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Data structure, algorithms from scratch. [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/tree/master/python/algorithms&#34;&gt;folder&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Cython and Numba quickstart for high performance Python. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/cython/cython.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/cython/cython.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Optimizing Pandas (e.g. reduce memory usage using category type). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/pandas/pandas.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/pandas/pandas.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Unittest. [&lt;a href=&#34;https://github.com/ethen8181/machine-learning/raw/master/python/test.py&#34;&gt;Python script&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Using built-in data structure and algorithm. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/python3_cookbook/1_data_structure.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/python3_cookbook/1_data_structure.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Tricks with strings and text. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/python3_cookbook/2_strings_and_text.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/python3_cookbook/2_strings_and_text.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Python&#39;s decorators (useful script for logging and timing function). [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/decorators/decorators.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/decorators/decorators.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Pandas&#39;s pivot table. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/pivot_table/pivot_table.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/pivot_table/pivot_table.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Quick introduction to classmethod, staticmethod and property. [&lt;a href=&#34;http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/python/class.ipynb&#34;&gt;nbviewer&lt;/a&gt;][&lt;a href=&#34;http://ethen8181.github.io/machine-learning/python/class.html&#34;&gt;html&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>google/styleguide</title>
    <updated>2024-01-14T01:57:13Z</updated>
    <id>tag:github.com,2024-01-14:/google/styleguide</id>
    <link href="https://github.com/google/styleguide" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Style guides for Google-originated open-source projects&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Google Style Guides&lt;/h1&gt; &#xA;&lt;p&gt;Every major open-source project has its own style guide: a set of conventions (sometimes arbitrary) about how to write code for that project. It is much easier to understand a large codebase when all the code in it is in a consistent style.&lt;/p&gt; &#xA;&lt;p&gt;‚ÄúStyle‚Äù covers a lot of ground, from ‚Äúuse camelCase for variable names‚Äù to ‚Äúnever use global variables‚Äù to ‚Äúnever use exceptions.‚Äù This project (&lt;a href=&#34;https://github.com/google/styleguide&#34;&gt;google/styleguide&lt;/a&gt;) links to the style guidelines we use for Google code. If you are modifying a project that originated at Google, you may be pointed to this page to see the style guides that apply to that project.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/angularjs-google-style.html&#34;&gt;AngularJS Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/lispguide.xml&#34;&gt;Common Lisp Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/cppguide.html&#34;&gt;C++ Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/csharp-style.html&#34;&gt;C# Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/styleguide/gh-pages/go/&#34;&gt;Go Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/htmlcssguide.html&#34;&gt;HTML/CSS Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/jsguide.html&#34;&gt;JavaScript Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/javaguide.html&#34;&gt;Java Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/styleguide/gh-pages/objcguide.md&#34;&gt;Objective-C Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/pyguide.html&#34;&gt;Python Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/Rguide.html&#34;&gt;R Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/shellguide.html&#34;&gt;Shell Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/swift/&#34;&gt;Swift Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/tsguide.html&#34;&gt;TypeScript Style Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/vimscriptguide.xml&#34;&gt;Vim script Style Guide&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This project also contains &lt;a href=&#34;https://github.com/google/styleguide/tree/gh-pages/cpplint&#34;&gt;cpplint&lt;/a&gt;, a tool to assist with style guide compliance, and &lt;a href=&#34;https://raw.githubusercontent.com/google/styleguide/gh-pages/google-c-style.el&#34;&gt;google-c-style.el&lt;/a&gt;, an Emacs settings file for Google style.&lt;/p&gt; &#xA;&lt;p&gt;If your project requires that you create a new XML document format, the &lt;a href=&#34;https://google.github.io/styleguide/xmlstyle.html&#34;&gt;XML Document Format Style Guide&lt;/a&gt; may be helpful. In addition to actual style rules, it also contains advice on designing your own vs. adapting an existing format, on XML instance document formatting, and on elements vs. attributes.&lt;/p&gt; &#xA;&lt;p&gt;The style guides in this project are licensed under the CC-By 3.0 License, which encourages you to share these documents. See &lt;a href=&#34;https://creativecommons.org/licenses/by/3.0/&#34;&gt;https://creativecommons.org/licenses/by/3.0/&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;The following Google style guide lives outside of this project: &lt;a href=&#34;https://www.dartlang.org/guides/language/effective-dart&#34;&gt;Effective Dart&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;With few exceptions, these style guides are copies of Google&#39;s internal style guides to assist developers working on Google owned and originated open source projects. Changes to the style guides are made to the internal style guides first and eventually copied into the versions found here. &lt;strong&gt;External contributions are not accepted.&lt;/strong&gt; Pull requests are regularly closed without comment. Issues that raise questions, justify changes on technical merits, or point out obvious mistakes may get some engagement and could in theory lead to changes, but we are primarily optimizing for Google&#39;s internal needs.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a rel=&#34;license&#34; href=&#34;https://creativecommons.org/licenses/by/3.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;https://i.creativecommons.org/l/by/3.0/88x31.png&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>