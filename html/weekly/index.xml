<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-05T01:52:49Z</updated>
  <subtitle>Weekly Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>atelier-anchor/smiley-sans</title>
    <updated>2023-03-05T01:52:49Z</updated>
    <id>tag:github.com,2023-03-05:/atelier-anchor/smiley-sans</id>
    <link href="https://github.com/atelier-anchor/smiley-sans" rel="alternate"></link>
    <summary type="html">&lt;p&gt;得意黑 Smiley Sans：一款在人文观感和几何特征中寻找平衡的中文黑体&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/atelier-anchor/smiley-sans/main/docs/images/smiley-sans.light.svg#gh-light-mode-only&#34; title=&#34;Smiley Sans&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/atelier-anchor/smiley-sans/main/docs/images/smiley-sans.dark.svg#gh-dark-mode-only&#34; title=&#34;Smiley Sans&#34;&gt; &lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/atelier-anchor/smiley-sans/actions&#34;&gt;&lt;img src=&#34;https://github.com/atelier-anchor/smiley-sans/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/atelier-anchor/smiley-sans/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/atelier-anchor/smiley-sans/all.svg?sanitize=true&#34; alt=&#34;GitHub release&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;得意黑是一款在人文观感和几何特征中寻找平衡的中文黑体。整体字身窄而斜，细节融入了取法手绘美术字的特殊造型。字体支持简体中文常用字（覆盖 &lt;a href=&#34;https://openstd.samr.gov.cn/bzgk/gb/newGbInfo?hcno=5664A728BD9D523DE3B99BC37AC7A2CC&#34;&gt;GB/T 2312-1980&lt;/a&gt; 编码字符集）、拉丁字母、西里尔字母、希腊字母、日文假名、阿拉伯数字和各类标点符号。&lt;/p&gt; &#xA;&lt;h2&gt;下载安装&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;点击 &lt;a href=&#34;https://github.com/atelier-anchor/smiley-sans/releases&#34;&gt;Releases&lt;/a&gt; 可直接下载安装文件包，其中包含 4 个字体文件： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;.otf&lt;/code&gt; 和 &lt;code&gt;.ttf&lt;/code&gt; 文件可用于桌面端安装，双击打开文件，按照系统提示安装文件即可；&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;.woff2&lt;/code&gt; 为网页字体格式，供网站开发人员使用。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;本字体的开发版本使用 &lt;a href=&#34;https://github.com/atelier-anchor/smiley-sans/actions&#34;&gt;GitHub Actions&lt;/a&gt; 构建，可在其中选择最新成功的构建结果，并下载对应的 Artifacts。&lt;/li&gt; &#xA; &lt;li&gt;字体的安装方式取决于具体的系统或软件，请按照对应的说明操作，例如： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://support.microsoft.com/zh-cn/windows/%E5%A6%82%E4%BD%95%E5%9C%A8-windows-%E4%B8%AD%E5%AE%89%E8%A3%85%E6%88%96%E5%88%A0%E9%99%A4%E5%AD%97%E4%BD%93-f12d0657-2fc8-7613-c76f-88d043b334b8&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://support.apple.com/zh-cn/HT201749&#34;&gt;macOS&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;也可使用 &lt;a href=&#34;https://brew.sh/index_zh-cn&#34;&gt;Homebrew&lt;/a&gt; 进行安装，在命令行中输入以下指令（这要求已经安装好 Homebrew）： &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew tap homebrew/cask-fonts  # 只需要在第一次安装时执行&#xA;brew install font-smiley-sans&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Linux &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Arch Linux 可以从 &lt;a href=&#34;https://aur.archlinux.org&#34;&gt;AUR&lt;/a&gt; 获取并安装： &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yay -S ttf-smiley-sans  # 从源码编译安装发行版&#xA;yay -S ttf-smiley-sans-bin  # 从二进制发行版安装&#xA;yay -S ttf-smiley-sans-git  # 从源码编译安装开发版&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://glyphsapp.com/zh/learn/testing-your-fonts-in-adobe-apps&#34;&gt;Adobe&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://support.microsoft.com/zh-cn/office/%E4%B8%8B%E8%BD%BD%E5%92%8C%E5%AE%89%E8%A3%85%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AD%97%E4%BD%93%E4%BB%A5%E4%BE%BF%E5%9C%A8-office-%E4%B8%AD%E4%BD%BF%E7%94%A8-0ee09e74-edc1-480c-81c2-5cf9537c70ce&#34;&gt;Office&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://procreate.art/cn/handbook/procreate/text/text-fonts/&#34;&gt;Procreate&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;如需预览得意黑的设计，可以&lt;a href=&#34;https://raw.githubusercontent.com/atelier-anchor/smiley-sans/main/docs/smiley-sans-specimen.pdf&#34;&gt;下载样张&lt;/a&gt;。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;字符支持&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;文字&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;支持情况&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;汉字&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;字体覆盖 &lt;a href=&#34;https://openstd.samr.gov.cn/bzgk/gb/newGbInfo?hcno=5664A728BD9D523DE3B99BC37AC7A2CC&#34;&gt;GB/T 2312-1980&lt;/a&gt; 编码字符集中的全部 6763 个汉字，并额外补充了 &lt;code&gt;啰&lt;/code&gt;、&lt;code&gt;喰&lt;/code&gt;、&lt;code&gt;瞭&lt;/code&gt;、&lt;code&gt;𬌗&lt;/code&gt; 4 个字，共计支持汉字 6767 个&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;拉丁字母&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;除基础拉丁字母外，覆盖欧洲、美洲、南亚各种语言所需的字符共 415 个，另加入必要的变体和本地化字形，可支持 100 余种语言，包括英语、法语、德语、西班牙语、芬兰语、越南语等&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;西里尔字母&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;支持基础西里尔字母共 80 个&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;希腊字母&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;支持基础希腊字母共 71 个&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;日文假名&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;支持平假名、片假名字符共 174 个&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;数字&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;支持阿拉伯数字、大小写罗马数字，以及其他 4 种样式的序数字 &lt;code&gt;㈠&lt;/code&gt;、&lt;code&gt;②&lt;/code&gt;、&lt;code&gt;⑶&lt;/code&gt; 和 &lt;code&gt;⒋&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;标点符号&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;包含标点和其他各类符号共 200 余个&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;注意事项&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;本字体部分笔画和结构采用了美术字风格的形态处理方式，并未严格遵循中国大陆规范汉字写法，敬请注意。&lt;/li&gt; &#xA; &lt;li&gt;使用场景： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;推荐：平面海报、电商文案、视频标题及字幕、书报标题、游戏嵌入等；&lt;/li&gt; &#xA;   &lt;li&gt;不推荐：正文排版、编程代码、手机界面等。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;关于&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;设计：&lt;a href=&#34;https://space.bilibili.com/38053181&#34;&gt;oooooohmygosh&lt;/a&gt;、&lt;a href=&#34;https://github.com/Na9isa&#34;&gt;陈渚&lt;/a&gt;、&lt;a href=&#34;https://github.com/janine-sui&#34;&gt;佳宁&lt;/a&gt;、&lt;a href=&#34;https://github.com/HedaShi313&#34;&gt;史贺达&lt;/a&gt;、李健&lt;/li&gt; &#xA; &lt;li&gt;中文设计顾问：&lt;a href=&#34;https://github.com/TaoDi1032805&#34;&gt;陶帝&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;字体工程：&lt;a href=&#34;https://github.com/stone-zeng&#34;&gt;曾祥东&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;鸣谢：&lt;a href=&#34;https://www.monotype.com/cn/%E5%B7%A5%E4%BD%9C%E5%AE%A4/%E5%AD%97%E4%BD%93%E8%AE%BE%E8%AE%A1%E5%B8%88/%E5%9C%9F%E4%BA%95%E8%BE%BD%E5%A4%AA&#34;&gt;土井辽太&lt;/a&gt;、&lt;a href=&#34;https://github.com/willie4624&#34;&gt;刘育黎&lt;/a&gt;、&lt;a href=&#34;https://www.instagram.com/mhytypeclub&#34;&gt;美和园字社&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;许可证&lt;/h2&gt; &#xA;&lt;p&gt;本字体的发布遵守 &lt;a href=&#34;https://raw.githubusercontent.com/atelier-anchor/smiley-sans/main/LICENSE&#34;&gt;SIL Open Font License v1.1&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Copyright © 2022–2023 &lt;a href=&#34;https://atelier-anchor.com&#34;&gt;atelierAnchor&lt;/a&gt;. All rights reserved.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>facebookresearch/fastText</title>
    <updated>2023-03-05T01:52:49Z</updated>
    <id>tag:github.com,2023-03-05:/facebookresearch/fastText</id>
    <link href="https://github.com/facebookresearch/fastText" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Library for fast text representation and classification.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;fastText&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://fasttext.cc/&#34;&gt;fastText&lt;/a&gt; is a library for efficient learning of word representations and sentence classification.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://circleci.com/gh/facebookresearch/fastText/tree/master&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/facebookresearch/fastText/tree/master.svg?style=svg&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#resources&#34;&gt;Resources&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#models&#34;&gt;Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#supplementary-data&#34;&gt;Supplementary data&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#faq&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#cheatsheet&#34;&gt;Cheatsheet&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#building-fasttext&#34;&gt;Building fastText&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#getting-the-source-code&#34;&gt;Getting the source code&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#building-fasttext-using-make-preferred&#34;&gt;Building fastText using make (preferred)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#building-fasttext-using-cmake&#34;&gt;Building fastText using cmake&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#building-fasttext-for-python&#34;&gt;Building fastText for Python&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#example-use-cases&#34;&gt;Example use cases&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#word-representation-learning&#34;&gt;Word representation learning&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#obtaining-word-vectors-for-out-of-vocabulary-words&#34;&gt;Obtaining word vectors for out-of-vocabulary words&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#text-classification&#34;&gt;Text classification&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#full-documentation&#34;&gt;Full documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#references&#34;&gt;References&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#enriching-word-vectors-with-subword-information&#34;&gt;Enriching Word Vectors with Subword Information&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#bag-of-tricks-for-efficient-text-classification&#34;&gt;Bag of Tricks for Efficient Text Classification&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#fasttextzip-compressing-text-classification-models&#34;&gt;FastText.zip: Compressing text classification models&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#join-the-fasttext-community&#34;&gt;Join the fastText community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;h3&gt;Models&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Recent state-of-the-art &lt;a href=&#34;https://fasttext.cc/docs/en/english-vectors.html&#34;&gt;English word vectors&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Word vectors for &lt;a href=&#34;https://github.com/facebookresearch/fastText/raw/master/docs/crawl-vectors.md&#34;&gt;157 languages trained on Wikipedia and Crawl&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Models for &lt;a href=&#34;https://fasttext.cc/docs/en/language-identification.html#content&#34;&gt;language identification&lt;/a&gt; and &lt;a href=&#34;https://fasttext.cc/docs/en/supervised-models.html#content&#34;&gt;various supervised tasks&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Supplementary data&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The preprocessed &lt;a href=&#34;https://fasttext.cc/docs/en/dataset.html#content&#34;&gt;YFCC100M data&lt;/a&gt; used in [2].&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;FAQ&lt;/h3&gt; &#xA;&lt;p&gt;You can find &lt;a href=&#34;https://fasttext.cc/docs/en/faqs.html#content&#34;&gt;answers to frequently asked questions&lt;/a&gt; on our &lt;a href=&#34;https://fasttext.cc/&#34;&gt;website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Cheatsheet&lt;/h3&gt; &#xA;&lt;p&gt;We also provide a &lt;a href=&#34;https://fasttext.cc/docs/en/cheatsheet.html#content&#34;&gt;cheatsheet&lt;/a&gt; full of useful one-liners.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;We are continuously building and testing our library, CLI and Python bindings under various docker images using &lt;a href=&#34;https://circleci.com/&#34;&gt;circleci&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Generally, &lt;strong&gt;fastText&lt;/strong&gt; builds on modern Mac OS and Linux distributions. Since it uses some C++11 features, it requires a compiler with good C++11 support. These include :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;(g++-4.7.2 or newer) or (clang-3.3 or newer)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Compilation is carried out using a Makefile, so you will need to have a working &lt;strong&gt;make&lt;/strong&gt;. If you want to use &lt;strong&gt;cmake&lt;/strong&gt; you need at least version 2.8.9.&lt;/p&gt; &#xA;&lt;p&gt;One of the oldest distributions we successfully built and tested the CLI under is &lt;a href=&#34;https://www.debian.org/releases/jessie/&#34;&gt;Debian jessie&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For the word-similarity evaluation script you will need:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 2.6 or newer&lt;/li&gt; &#xA; &lt;li&gt;NumPy &amp;amp; SciPy&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For the python bindings (see the subdirectory python) you will need:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python version 2.7 or &amp;gt;=3.4&lt;/li&gt; &#xA; &lt;li&gt;NumPy &amp;amp; SciPy&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pybind/pybind11&#34;&gt;pybind11&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;One of the oldest distributions we successfully built and tested the Python bindings under is &lt;a href=&#34;https://www.debian.org/releases/jessie/&#34;&gt;Debian jessie&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If these requirements make it impossible for you to use fastText, please open an issue and we will try to accommodate you.&lt;/p&gt; &#xA;&lt;h2&gt;Building fastText&lt;/h2&gt; &#xA;&lt;p&gt;We discuss building the latest stable version of fastText.&lt;/p&gt; &#xA;&lt;h3&gt;Getting the source code&lt;/h3&gt; &#xA;&lt;p&gt;You can find our &lt;a href=&#34;https://github.com/facebookresearch/fastText/releases/latest&#34;&gt;latest stable release&lt;/a&gt; in the usual place.&lt;/p&gt; &#xA;&lt;p&gt;There is also the master branch that contains all of our most recent work, but comes along with all the usual caveats of an unstable branch. You might want to use this if you are a developer or power-user.&lt;/p&gt; &#xA;&lt;h3&gt;Building fastText using make (preferred)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip&#xA;$ unzip v0.9.2.zip&#xA;$ cd fastText-0.9.2&#xA;$ make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will produce object files for all the classes as well as the main binary &lt;code&gt;fasttext&lt;/code&gt;. If you do not plan on using the default system-wide compiler, update the two macros defined at the beginning of the Makefile (CC and INCLUDES).&lt;/p&gt; &#xA;&lt;h3&gt;Building fastText using cmake&lt;/h3&gt; &#xA;&lt;p&gt;For now this is not part of a release, so you will need to clone the master branch.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/facebookresearch/fastText.git&#xA;$ cd fastText&#xA;$ mkdir build &amp;amp;&amp;amp; cd build &amp;amp;&amp;amp; cmake ..&#xA;$ make &amp;amp;&amp;amp; make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will create the fasttext binary and also all relevant libraries (shared, static, PIC).&lt;/p&gt; &#xA;&lt;h3&gt;Building fastText for Python&lt;/h3&gt; &#xA;&lt;p&gt;For now this is not part of a release, so you will need to clone the master branch.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/facebookresearch/fastText.git&#xA;$ cd fastText&#xA;$ pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For further information and introduction see python/README.md&lt;/p&gt; &#xA;&lt;h2&gt;Example use cases&lt;/h2&gt; &#xA;&lt;p&gt;This library has two main use cases: word representation learning and text classification. These were described in the two papers &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#enriching-word-vectors-with-subword-information&#34;&gt;1&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#bag-of-tricks-for-efficient-text-classification&#34;&gt;2&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Word representation learning&lt;/h3&gt; &#xA;&lt;p&gt;In order to learn word vectors, as described in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#enriching-word-vectors-with-subword-information&#34;&gt;1&lt;/a&gt;, do:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext skipgram -input data.txt -output model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;data.txt&lt;/code&gt; is a training file containing &lt;code&gt;UTF-8&lt;/code&gt; encoded text. By default the word vectors will take into account character n-grams from 3 to 6 characters. At the end of optimization the program will save two files: &lt;code&gt;model.bin&lt;/code&gt; and &lt;code&gt;model.vec&lt;/code&gt;. &lt;code&gt;model.vec&lt;/code&gt; is a text file containing the word vectors, one per line. &lt;code&gt;model.bin&lt;/code&gt; is a binary file containing the parameters of the model along with the dictionary and all hyper parameters. The binary file can be used later to compute word vectors or to restart the optimization.&lt;/p&gt; &#xA;&lt;h3&gt;Obtaining word vectors for out-of-vocabulary words&lt;/h3&gt; &#xA;&lt;p&gt;The previously trained model can be used to compute word vectors for out-of-vocabulary words. Provided you have a text file &lt;code&gt;queries.txt&lt;/code&gt; containing words for which you want to compute vectors, use the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext print-word-vectors model.bin &amp;lt; queries.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will output word vectors to the standard output, one vector per line. This can also be used with pipes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cat queries.txt | ./fasttext print-word-vectors model.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the provided scripts for an example. For instance, running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./word-vector-example.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;will compile the code, download data, compute word vectors and evaluate them on the rare words similarity dataset RW [Thang et al. 2013].&lt;/p&gt; &#xA;&lt;h3&gt;Text classification&lt;/h3&gt; &#xA;&lt;p&gt;This library can also be used to train supervised text classifiers, for instance for sentiment analysis. In order to train a text classifier using the method described in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#bag-of-tricks-for-efficient-text-classification&#34;&gt;2&lt;/a&gt;, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext supervised -input train.txt -output model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;train.txt&lt;/code&gt; is a text file containing a training sentence per line along with the labels. By default, we assume that labels are words that are prefixed by the string &lt;code&gt;__label__&lt;/code&gt;. This will output two files: &lt;code&gt;model.bin&lt;/code&gt; and &lt;code&gt;model.vec&lt;/code&gt;. Once the model was trained, you can evaluate it by computing the precision and recall at k (P@k and R@k) on a test set using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext test model.bin test.txt k&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The argument &lt;code&gt;k&lt;/code&gt; is optional, and is equal to &lt;code&gt;1&lt;/code&gt; by default.&lt;/p&gt; &#xA;&lt;p&gt;In order to obtain the k most likely labels for a piece of text, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext predict model.bin test.txt k&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or use &lt;code&gt;predict-prob&lt;/code&gt; to also get the probability for each label&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext predict-prob model.bin test.txt k&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;test.txt&lt;/code&gt; contains a piece of text to classify per line. Doing so will print to the standard output the k most likely labels for each line. The argument &lt;code&gt;k&lt;/code&gt; is optional, and equal to &lt;code&gt;1&lt;/code&gt; by default. See &lt;code&gt;classification-example.sh&lt;/code&gt; for an example use case. In order to reproduce results from the paper &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#bag-of-tricks-for-efficient-text-classification&#34;&gt;2&lt;/a&gt;, run &lt;code&gt;classification-results.sh&lt;/code&gt;, this will download all the datasets and reproduce the results from Table 1.&lt;/p&gt; &#xA;&lt;p&gt;If you want to compute vector representations of sentences or paragraphs, please use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext print-sentence-vectors model.bin &amp;lt; text.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This assumes that the &lt;code&gt;text.txt&lt;/code&gt; file contains the paragraphs that you want to get vectors for. The program will output one vector representation per line in the file.&lt;/p&gt; &#xA;&lt;p&gt;You can also quantize a supervised model to reduce its memory usage with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext quantize -output model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will create a &lt;code&gt;.ftz&lt;/code&gt; file with a smaller memory footprint. All the standard functionality, like &lt;code&gt;test&lt;/code&gt; or &lt;code&gt;predict&lt;/code&gt; work the same way on the quantized models:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext test model.ftz test.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The quantization procedure follows the steps described in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#fasttextzip-compressing-text-classification-models&#34;&gt;3&lt;/a&gt;. You can run the script &lt;code&gt;quantization-example.sh&lt;/code&gt; for an example.&lt;/p&gt; &#xA;&lt;h2&gt;Full documentation&lt;/h2&gt; &#xA;&lt;p&gt;Invoke a command without arguments to list available arguments and their default values:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./fasttext supervised&#xA;Empty input or output path.&#xA;&#xA;The following arguments are mandatory:&#xA;  -input              training file path&#xA;  -output             output file path&#xA;&#xA;The following arguments are optional:&#xA;  -verbose            verbosity level [2]&#xA;&#xA;The following arguments for the dictionary are optional:&#xA;  -minCount           minimal number of word occurrences [1]&#xA;  -minCountLabel      minimal number of label occurrences [0]&#xA;  -wordNgrams         max length of word ngram [1]&#xA;  -bucket             number of buckets [2000000]&#xA;  -minn               min length of char ngram [0]&#xA;  -maxn               max length of char ngram [0]&#xA;  -t                  sampling threshold [0.0001]&#xA;  -label              labels prefix [__label__]&#xA;&#xA;The following arguments for training are optional:&#xA;  -lr                 learning rate [0.1]&#xA;  -lrUpdateRate       change the rate of updates for the learning rate [100]&#xA;  -dim                size of word vectors [100]&#xA;  -ws                 size of the context window [5]&#xA;  -epoch              number of epochs [5]&#xA;  -neg                number of negatives sampled [5]&#xA;  -loss               loss function {ns, hs, softmax} [softmax]&#xA;  -thread             number of threads [12]&#xA;  -pretrainedVectors  pretrained word vectors for supervised learning []&#xA;  -saveOutput         whether output params should be saved [0]&#xA;&#xA;The following arguments for quantization are optional:&#xA;  -cutoff             number of words and ngrams to retain [0]&#xA;  -retrain            finetune embeddings if a cutoff is applied [0]&#xA;  -qnorm              quantizing the norm separately [0]&#xA;  -qout               quantizing the classifier [0]&#xA;  -dsub               size of each sub-vector [2]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Defaults may vary by mode. (Word-representation modes &lt;code&gt;skipgram&lt;/code&gt; and &lt;code&gt;cbow&lt;/code&gt; use a default &lt;code&gt;-minCount&lt;/code&gt; of 5.)&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;p&gt;Please cite &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#enriching-word-vectors-with-subword-information&#34;&gt;1&lt;/a&gt; if using this code for learning word representations or &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/fastText/main/#bag-of-tricks-for-efficient-text-classification&#34;&gt;2&lt;/a&gt; if using for text classification.&lt;/p&gt; &#xA;&lt;h3&gt;Enriching Word Vectors with Subword Information&lt;/h3&gt; &#xA;&lt;p&gt;[1] P. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, &lt;a href=&#34;https://arxiv.org/abs/1607.04606&#34;&gt;&lt;em&gt;Enriching Word Vectors with Subword Information&lt;/em&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{bojanowski2017enriching,&#xA;  title={Enriching Word Vectors with Subword Information},&#xA;  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},&#xA;  journal={Transactions of the Association for Computational Linguistics},&#xA;  volume={5},&#xA;  year={2017},&#xA;  issn={2307-387X},&#xA;  pages={135--146}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Bag of Tricks for Efficient Text Classification&lt;/h3&gt; &#xA;&lt;p&gt;[2] A. Joulin, E. Grave, P. Bojanowski, T. Mikolov, &lt;a href=&#34;https://arxiv.org/abs/1607.01759&#34;&gt;&lt;em&gt;Bag of Tricks for Efficient Text Classification&lt;/em&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@InProceedings{joulin2017bag,&#xA;  title={Bag of Tricks for Efficient Text Classification},&#xA;  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},&#xA;  booktitle={Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers},&#xA;  month={April},&#xA;  year={2017},&#xA;  publisher={Association for Computational Linguistics},&#xA;  pages={427--431},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;FastText.zip: Compressing text classification models&lt;/h3&gt; &#xA;&lt;p&gt;[3] A. Joulin, E. Grave, P. Bojanowski, M. Douze, H. Jégou, T. Mikolov, &lt;a href=&#34;https://arxiv.org/abs/1612.03651&#34;&gt;&lt;em&gt;FastText.zip: Compressing text classification models&lt;/em&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{joulin2016fasttext,&#xA;  title={FastText.zip: Compressing text classification models},&#xA;  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Douze, Matthijs and J{\&#39;e}gou, H{\&#39;e}rve and Mikolov, Tomas},&#xA;  journal={arXiv preprint arXiv:1612.03651},&#xA;  year={2016}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(* These authors contributed equally.)&lt;/p&gt; &#xA;&lt;h2&gt;Join the fastText community&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Facebook page: &lt;a href=&#34;https://www.facebook.com/groups/1174547215919768&#34;&gt;https://www.facebook.com/groups/1174547215919768&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Google group: &lt;a href=&#34;https://groups.google.com/forum/#!forum/fasttext-library&#34;&gt;https://groups.google.com/forum/#!forum/fasttext-library&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Contact: &lt;a href=&#34;mailto:egrave@fb.com&#34;&gt;egrave@fb.com&lt;/a&gt;, &lt;a href=&#34;mailto:bojanowski@fb.com&#34;&gt;bojanowski@fb.com&lt;/a&gt;, &lt;a href=&#34;mailto:ajoulin@fb.com&#34;&gt;ajoulin@fb.com&lt;/a&gt;, &lt;a href=&#34;mailto:tmikolov@fb.com&#34;&gt;tmikolov@fb.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the CONTRIBUTING file for information about how to help out.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;fastText is MIT-licensed.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>librespeed/speedtest</title>
    <updated>2023-03-05T01:52:49Z</updated>
    <id>tag:github.com,2023-03-05:/librespeed/speedtest</id>
    <link href="https://github.com/librespeed/speedtest" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Self-hosted Speedtest for HTML5 and more. Easy setup, examples, configurable, mobile friendly. Supports PHP, Node, Multiple servers, and more&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/librespeed/speedtest/raw/master/.logo/logo3.png?raw=true&#34; alt=&#34;LibreSpeed Logo&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;LibreSpeed&lt;/h1&gt; &#xA;&lt;p&gt;No Flash, No Java, No Websocket, No Bullshit.&lt;/p&gt; &#xA;&lt;p&gt;This is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers.&lt;/p&gt; &#xA;&lt;h2&gt;Try it&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://librespeed.org&#34;&gt;Take a Speedtest&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Compatibility&lt;/h2&gt; &#xA;&lt;p&gt;All modern browsers are supported: IE11, latest Edge, latest Chrome, latest Firefox, latest Safari.&lt;br&gt; Works with mobile versions too.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download&lt;/li&gt; &#xA; &lt;li&gt;Upload&lt;/li&gt; &#xA; &lt;li&gt;Ping&lt;/li&gt; &#xA; &lt;li&gt;Jitter&lt;/li&gt; &#xA; &lt;li&gt;IP Address, ISP, distance from server (optional)&lt;/li&gt; &#xA; &lt;li&gt;Telemetry (optional)&lt;/li&gt; &#xA; &lt;li&gt;Results sharing (optional)&lt;/li&gt; &#xA; &lt;li&gt;Multiple Points of Test (optional)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://speedtest.fdossena.com/mpot_v6.gif&#34; alt=&#34;Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Server requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A reasonably fast web server with Apache 2 (nginx, IIS also supported)&lt;/li&gt; &#xA; &lt;li&gt;PHP 5.4 (other backends also available)&lt;/li&gt; &#xA; &lt;li&gt;MySQL database to store test results (optional, PostgreSQL and SQLite also supported)&lt;/li&gt; &#xA; &lt;li&gt;A fast! internet connection&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation videos&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fdossena.com/?p=speedtest/quickstart_v5_ubuntu.frag&#34;&gt;Quick start installation guide for Ubuntu Server 19.04&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Android app&lt;/h2&gt; &#xA;&lt;p&gt;A template to build an Android client for your LibreSpeed installation is available &lt;a href=&#34;https://github.com/librespeed/speedtest-android&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Docker&lt;/h2&gt; &#xA;&lt;p&gt;A docker image is available on the &lt;a href=&#34;https://registry.hub.docker.com/r/adolfintel/speedtest&#34;&gt;Docker Hub&lt;/a&gt;, see &lt;code&gt;doc_docker.md&lt;/code&gt; for more info about it&lt;/p&gt; &#xA;&lt;h2&gt;Go backend&lt;/h2&gt; &#xA;&lt;p&gt;A Go implementation is available in the &lt;a href=&#34;https://github.com/librespeed/speedtest-go&#34;&gt;&lt;code&gt;speedtest-go&lt;/code&gt;&lt;/a&gt; repo, maintained by &lt;a href=&#34;https://github.com/maddie&#34;&gt;Maddie Zhan&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Node.js backend&lt;/h2&gt; &#xA;&lt;p&gt;A partial Node.js implementation is available in the &lt;code&gt;node&lt;/code&gt; branch, developed by &lt;a href=&#34;https://github.com/dunklesToast&#34;&gt;dunklesToast&lt;/a&gt;. It&#39;s not recommended to use at the moment.&lt;/p&gt; &#xA;&lt;h2&gt;Donate&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://liberapay.com/fdossena/donate&#34;&gt;&lt;img src=&#34;https://liberapay.com/assets/widgets/donate.svg?sanitize=true&#34; alt=&#34;Donate with Liberapay&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://www.paypal.me/sineisochronic&#34;&gt;Donate with PayPal&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (C) 2016-2022 Federico Dossena&lt;/p&gt; &#xA;&lt;p&gt;This program is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.&lt;/p&gt; &#xA;&lt;p&gt;This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.&lt;/p&gt; &#xA;&lt;p&gt;You should have received a copy of the GNU Lesser General Public License along with this program. If not, see &lt;a href=&#34;https://www.gnu.org/licenses/lgpl&#34;&gt;https://www.gnu.org/licenses/lgpl&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>