<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-16T01:56:49Z</updated>
  <subtitle>Weekly Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>SuperSimpleDev/javascript-course</title>
    <updated>2023-04-16T01:56:49Z</updated>
    <id>tag:github.com,2023-04-16:/SuperSimpleDev/javascript-course</id>
    <link href="https://github.com/SuperSimpleDev/javascript-course" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>Instruction-Tuning-with-GPT-4/GPT-4-LLM</title>
    <updated>2023-04-16T01:56:49Z</updated>
    <id>tag:github.com,2023-04-16:/Instruction-Tuning-with-GPT-4/GPT-4-LLM</id>
    <link href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Instruction Tuning with GPT-4&lt;/h1&gt; &#xA;&lt;p&gt;Baolin Peng*, Chunyuan Li*, Pengcheng He*, Michel Galley, Jianfeng Gao (*Equal Contribution)&lt;/p&gt; &#xA;&lt;p&gt;[&lt;a href=&#34;https://instruction-tuning-with-gpt-4.github.io/&#34;&gt;Project Page&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/abs/2304.03277&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://instruction-tuning-with-gpt-4.github.io/images/gpt4llama_logo.png&#34; width=&#34;50%&#34;&gt; &lt;br&gt; Pronounced as &#34;GPT-4-LLM&#34; or &#34;GPT-for-LLM&#34;, image is generated by &lt;a href=&#34;https://gligen.github.io/&#34;&gt;GLIGEN&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg?sanitize=true&#34; alt=&#34;Code License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/DATA_LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg?sanitize=true&#34; alt=&#34;Data License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is the repo for the GPT-4-LLM, which aims to share data generated by GPT-4 for building an instruction-following LLMs with supervised learning and reinforcement learning. The repo contains:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;English Instruction-Following &lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/#data-release&#34;&gt;Data&lt;/a&gt; generated by GPT-4 using Alpaca prompts for fine-tuning LLMs.&lt;/li&gt; &#xA; &lt;li&gt;Chinese Instruction-Following &lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/#data-release&#34;&gt;Data&lt;/a&gt; generated by GPT-4 using Chinese prompts translated from Alpaca by ChatGPT.&lt;/li&gt; &#xA; &lt;li&gt;Comparison &lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/#data-release&#34;&gt;Data&lt;/a&gt; ranked by GPT-4 to train reward models.&lt;/li&gt; &#xA; &lt;li&gt;Answers on Unnatural Instructions &lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/#data-release&#34;&gt;Data&lt;/a&gt; from GPT-4 to quantify the gap between GPT-4 and instruction-tuned models at scale.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage and License Notices&lt;/strong&gt;: The data is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/#data-release&#34;&gt;GPT-4 Data Release&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/#how-good-is-the-data&#34;&gt;How Good is the Data?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/#fine-tuning-with-the-data&#34;&gt;Fine-tuning with the Data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/#collect-results-and-reproduce-figure-plots&#34;&gt;Reproduce Figure Plots&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;span&gt;ðŸ”¥&lt;/span&gt; News&lt;/h2&gt; &#xA;&lt;!--&#xA;* **[2023.04.07]** Data restored.&#xA;* **[2023.04.07]** &lt;span&gt;âš &lt;/span&gt; We turn off the data downloading temporarily.&#xA;--&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.04.15]&lt;/strong&gt; Updated comparision data, including three model responses and GPT-4 evaluation scores.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.04.06]&lt;/strong&gt; Paper and data are released.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Large Language Models (LLMs) have shown impressive generalization capabilities such as in-context-learning and chain-of-thoughts reasoning. To enable LLMs to follow natural language instructions and complete real-world tasks, researchers have been exploring methods of instruction-tuning of LLMs. To advance the state of the art of instruction-tuning for LLMs, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning.&lt;/p&gt; &#xA;&lt;h2&gt;Data Release&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/alpaca_gpt4_data.json&#34;&gt;&lt;code&gt;alpaca_gpt4_data.json&lt;/code&gt;&lt;/a&gt; contains 52K instruction-following data generated by GPT-4 with prompts in Alpaca. This JSON file has the same format as Alpaca data, except the output is generated by GPT-4:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;instruction&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, describes the task the model should perform. Each of the 52K instructions is unique.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;input&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, optional context or input for the task.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;output&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, the answer to the instruction as generated by &lt;code&gt;GPT-4&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/alpaca_gpt4_data_zh.json&#34;&gt;&lt;code&gt;alpaca_gpt4_data_zh.json&lt;/code&gt;&lt;/a&gt; contains 52K instruction-following data generated by GPT-4 with Alpaca prompts translated into Chinese by ChatGPT. This JSON file has the same format.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/comparision_data.json&#34;&gt;&lt;code&gt;comparision_data.json&lt;/code&gt;&lt;/a&gt; ranked responses from three models, including GPT-4, GPT-3.5 and OPT-IML by asking GPT-4 to rate the quality.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;user_input&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, prompts used for quering LLMs.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;completion_a&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, a model completion which is ranked higher than completion_b.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;completion_b&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, a different model completion which has a lower quality score.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/unnatural_instruction_gpt4_data.json&#34;&gt;&lt;code&gt;unnatural_instruction_gpt4_data.json&lt;/code&gt;&lt;/a&gt; contains 9K instruction-following data generated by GPT-4 with prompts in Unnatural Instruction. This JSON file has the same format as Alpaca data.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How Good is the Data&lt;/h2&gt; &#xA;&lt;p&gt;Human evaluation was performed on model generation results using Amazon Mechanical Turk following Helpfulness, Honestness and Harmlessness criteria by &lt;a href=&#34;https://arxiv.org/abs/2112.00861&#34;&gt;Anthropic AI&lt;/a&gt;. The results are summarized as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Two instruction-tuned LLaMA models were compared, fine-tuned on data generated by GPT-4 and GPT-3 respectively.&lt;/li&gt; &#xA; &lt;li&gt;LLaMA-GPT-4 performs substantially better than LLaMA-GPT-3 in the &#34;Helpfulness&#34; criterion.&lt;/li&gt; &#xA; &lt;li&gt;LLaMA-GPT-4 performs similarly to the original GPT-4 in all three criteria, suggesting a promising direction for developing state-of-the-art instruction-following LLMs.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/static/pie_llama_gpt3_vs_llam_gpt4.png&#34; alt=&#34;LLaMA-GPT4 vs Alpaca (i.e., LLaMA-GPT3)&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/static/pie_llama_gpt4_vs_gpt4.png&#34; alt=&#34;LLaMA-GPT4 vs GPT-4&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Fine-tuning with the data&lt;/h2&gt; &#xA;&lt;p&gt;We follow the same reciple to fine-tune LLaMA as Alpaca using standard Hugging Face training code.&lt;/p&gt; &#xA;&lt;p&gt;To reproduce our results with LLaMA 7B, first setup Alpaca repo and run the following CMDs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## cmd we used to train LLaMA on 16*V100&#xA;torchrun --nproc_per_node=16 &#xA;--master_port=12345 train.py &#xA;--model_name_or_path PATH/TO/LLaMA&#xA;--data_path ./data/alpaca_gpt4_data.json &#xA;--output_dir PATH/TO/SAVE&#xA;--num_train_epochs 3 &#xA;--per_device_train_batch_size 1 &#xA;--per_device_eval_batch_size 1 &#xA;--gradient_accumulation_steps 4 &#xA;--evaluation_strategy &#34;no&#34; &#xA;--save_strategy &#34;steps&#34; &#xA;--save_steps 200 &#xA;--save_total_limit 1 &#xA;--learning_rate 2e-5 &#xA;--weight_decay 0. &#xA;--warmup_ratio 0.03 &#xA;--lr_scheduler_type &#34;cosine&#34; &#xA;--logging_steps 1 &#xA;--deepspeed configs/ds_config.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To evaluate the results, we highly recommend users refer to &lt;a href=&#34;https://vicuna.lmsys.org/&#34;&gt;Vicuna&lt;/a&gt; as they have provided awesome serving scripts and evaluation piplelines.&lt;/p&gt; &#xA;&lt;h2&gt;Collect results and reproduce figure plots&lt;/h2&gt; &#xA;&lt;p&gt;The results can be plotted using the included IPython notebook plots/main_plots.ipynb. Start the IPython Notebook server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd plots&#xA;$ ipython notebook&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Select the &lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/plots/main_plots.ipynb&#34;&gt;&lt;code&gt;main_plots.ipynb&lt;/code&gt;&lt;/a&gt; notebook and execute the included code. Note that without modification, we have copyed our extracted results into the notebook, and script will output figures in the paper. Some related data for plots have been provided in &lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/plots/data&#34;&gt;data&lt;/a&gt;, the generated plots are saved in &lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/plots/output&#34;&gt;plots/output&lt;/a&gt; If you&#39;ve run your own training and wish to plot results, you&#39;ll have to organize your results in the same format instead.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Shortcut: to skip all the work and just see the results, take a look at this notebook with &lt;a href=&#34;https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/plots/main_plots.ipynb&#34;&gt;cached plots&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{peng2023instruction,&#xA;  title={Instruction Tuning with GPT-4},&#xA;  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},&#xA;  journal={arXiv preprint arXiv:2304.03277},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This repo benefits from &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;LLaMA&lt;/a&gt;, &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Alpaca&lt;/a&gt;, and &lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;Vicuna&lt;/a&gt;. Thanks for their wonderful works.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cotes2020/jekyll-theme-chirpy</title>
    <updated>2023-04-16T01:56:49Z</updated>
    <id>tag:github.com,2023-04-16:/cotes2020/jekyll-theme-chirpy</id>
    <link href="https://github.com/cotes2020/jekyll-theme-chirpy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A minimal, responsive and feature-rich Jekyll theme for technical writing.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;Chirpy Jekyll Theme&lt;/h1&gt; &#xA; &lt;p&gt;A minimal, responsive and feature-rich Jekyll theme for technical writing.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://rubygems.org/gems/jekyll-theme-chirpy&#34;&gt;&lt;img src=&#34;https://img.shields.io/gem/v/jekyll-theme-chirpy?color=brightgreen&#34; alt=&#34;Gem Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/cotes2020/jekyll-theme-chirpy/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/cotes2020/jekyll-theme-chirpy/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.codacy.com/gh/cotes2020/jekyll-theme-chirpy/dashboard?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=cotes2020/jekyll-theme-chirpy&amp;amp;utm_campaign=Badge_Grade&#34;&gt;&lt;img src=&#34;https://app.codacy.com/project/badge/Grade/4e556876a3c54d5e8f2d2857c4f43894&#34; alt=&#34;Codacy Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/cotes2020/jekyll-theme-chirpy/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/cotes2020/jekyll-theme-chirpy.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://996.icu&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/link-996.icu-%23FF4D5B.svg?sanitize=true&#34; alt=&#34;996.icu&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://cotes2020.github.io/chirpy-demo/&#34;&gt;&lt;strong&gt;Live Demo â†’&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://cotes2020.github.io/chirpy-demo/&#34;&gt;&lt;img src=&#34;https://chirpy-img.netlify.app/commons/devices-mockup.png&#34; alt=&#34;Devices Mockup&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;i&gt;Click to view features&lt;/i&gt; &lt;/summary&gt; &#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Dark / Light Theme Mode&lt;/li&gt; &#xA;  &lt;li&gt;Localized UI language&lt;/li&gt; &#xA;  &lt;li&gt;Pinned Posts&lt;/li&gt; &#xA;  &lt;li&gt;Hierarchical Categories&lt;/li&gt; &#xA;  &lt;li&gt;Trending Tags&lt;/li&gt; &#xA;  &lt;li&gt;Table of Contents&lt;/li&gt; &#xA;  &lt;li&gt;Last Modified Date of Posts&lt;/li&gt; &#xA;  &lt;li&gt;Syntax Highlighting&lt;/li&gt; &#xA;  &lt;li&gt;Mathematical Expressions&lt;/li&gt; &#xA;  &lt;li&gt;Mermaid Diagram &amp;amp; Flowchart&lt;/li&gt; &#xA;  &lt;li&gt;Dark / Light Mode Images&lt;/li&gt; &#xA;  &lt;li&gt;Embed Videos&lt;/li&gt; &#xA;  &lt;li&gt;Disqus / Utterances / Giscus Comments&lt;/li&gt; &#xA;  &lt;li&gt;Search&lt;/li&gt; &#xA;  &lt;li&gt;Atom Feeds&lt;/li&gt; &#xA;  &lt;li&gt;Google Analytics&lt;/li&gt; &#xA;  &lt;li&gt;Page Views Reporting&lt;/li&gt; &#xA;  &lt;li&gt;SEO &amp;amp; Performance Optimization&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;To explore usage, development, and upgrade guide of the project, please refer to the &lt;a href=&#34;https://github.com/cotes2020/jekyll-theme-chirpy/wiki&#34;&gt;Wiki&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Welcome to report bugs, help improve the code or submit new features. For more information, please see the &lt;a href=&#34;https://github.com/cotes2020/jekyll-theme-chirpy/raw/master/.github/CONTRIBUTING.md&#34;&gt;&#34;Contributing Guidelines&#34;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;This theme is mainly built with &lt;a href=&#34;https://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt; ecosystem, &lt;a href=&#34;https://getbootstrap.com/&#34;&gt;Bootstrap&lt;/a&gt;, &lt;a href=&#34;https://fontawesome.com/&#34;&gt;Font Awesome&lt;/a&gt; and some other &lt;a href=&#34;https://github.com/cotes2020/chirpy-static-assets&#34;&gt;wonderful tools&lt;/a&gt;. The avatar and favicon design come from &lt;a href=&#34;https://www.clipartmax.com/middle/m2i8b1m2K9Z5m2K9_ant-clipart-childrens-ant-cute/&#34;&gt;Clipart Max&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Thanks to all the &lt;a href=&#34;https://github.com/cotes2020/jekyll-theme-chirpy/graphs/contributors&#34;&gt;contributors&lt;/a&gt;. Also, folks who submitted issues or unmerged PRs should not be forgotten. Because they reported bugs, shared ideas, or inspired me to write more readable documentation.&lt;/p&gt; &#xA;&lt;p&gt;Last but not least, thanks to &lt;a href=&#34;https://www.jetbrains.com/?from=jekyll-theme-chirpy&#34;&gt;JetBrains&lt;/a&gt; for providing the &lt;em&gt;Open Source Development&lt;/em&gt; license.&lt;/p&gt; &#xA;&lt;h2&gt;Sponsoring&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;d like to sponsor this project, the following options are available.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ko-fi.com/coteschung&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Buy%20Me%20a%20Coffee-ff5f5f?logo=ko-fi&amp;amp;logoColor=white&#34; alt=&#34;Ko-fi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sponsor.cotes.page/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Tip%20Me%20on%20WeChat-brightgreen?logo=wechat&amp;amp;logoColor=white&#34; alt=&#34;Wechat Pay&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sponsor.cotes.page/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Tip%20Me%20on%20Alipay-blue?logo=alipay&amp;amp;logoColor=white&#34; alt=&#34;Alipay&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This work is published under &lt;a href=&#34;https://github.com/cotes2020/jekyll-theme-chirpy/raw/master/LICENSE&#34;&gt;MIT&lt;/a&gt; License.&lt;/p&gt;</summary>
  </entry>
</feed>