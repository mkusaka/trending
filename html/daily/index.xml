<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-11-02T01:31:03Z</updated>
  <subtitle>Daily Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>QuivrHQ/MegaParse</title>
    <updated>2024-11-02T01:31:03Z</updated>
    <id>tag:github.com,2024-11-02:/QuivrHQ/MegaParse</id>
    <link href="https://github.com/QuivrHQ/MegaParse" rel="alternate"></link>
    <summary type="html">&lt;p&gt;File Parser optimised for LLM Ingestion with no loss üß† Parse PDFs, Docx, PPTx in a format that is ideal for LLMs.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MegaParse - Your Mega Parser for every type of documents&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/QuivrHQ/MegaParse/main/logo.png&#34; alt=&#34;Quivr-logo&#34; width=&#34;30%&#34; style=&#34;border-radius: 50%; padding-bottom: 20px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;MegaParse is a powerful and versatile parser that can handle various types of documents with ease. Whether you&#39;re dealing with text, PDFs, Powerpoint presentations, Word documents MegaParse has got you covered. Focus on having no information loss during parsing.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features üéØ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Versatile Parser&lt;/strong&gt;: MegaParse is a powerful and versatile parser that can handle various types of documents with ease.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;No Information Loss&lt;/strong&gt;: Focus on having no information loss during parsing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fast and Efficient&lt;/strong&gt;: Designed with speed and efficiency at its core.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Wide File Compatibility&lt;/strong&gt;: Supports Text, PDF, Powerpoint presentations, Excel, CSV, Word documents.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Open Source&lt;/strong&gt;: Freedom is beautiful, and so is MegaParse. Open source and free to use.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Files: ‚úÖ PDF ‚úÖ Powerpoint ‚úÖ Word&lt;/li&gt; &#xA; &lt;li&gt;Content: ‚úÖ Tables ‚úÖ TOC ‚úÖ Headers ‚úÖ Footers ‚úÖ Images&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Example&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/QuivrHQ/MegaParse/assets/19614572/1b4cdb73-8dc2-44ef-b8b4-a7509bc8d4f3&#34;&gt;https://github.com/QuivrHQ/MegaParse/assets/19614572/1b4cdb73-8dc2-44ef-b8b4-a7509bc8d4f3&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install megaparse &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Add your OpenAI or Anthropic API key to the .env file&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install poppler on your computer (images and PDFs)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install tesseract on your computer (images and PDFs)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you have a mac, you also need to install libmagic &lt;code&gt;brew install libmagic&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from megaparse.core.megaparse import MegaParse&#xA;from langchain_openai import ChatOpenAI&#xA;from megaparse.core.parser.unstructured_parser import UnstructuredParser&#xA;&#xA;model = ChatOpenAI(model=&#34;gpt-4o&#34;, api_key=os.getenv(&#34;OPENAI_API_KEY&#34;))  # or any langchain compatible Chat Models&#xA;parser = UnstructuredParser(model=model)&#xA;megaparse = MegaParse(parser)&#xA;response = megaparse.load(&#34;./test.pdf&#34;)&#xA;print(response)&#xA;megaparse.save(&#34;./test.md&#34;) #saves the last processed doc in md format&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Use MegaParse Vision&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Change the parser to MegaParseVision&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from megaparse.core.megaparse import MegaParse&#xA;from langchain_openai import ChatOpenAI&#xA;from megaparse.core.parser.megaparse_vision import MegaParseVision&#xA;&#xA;model = ChatOpenAI(model=&#34;gpt-4o&#34;, api_key=os.getenv(&#34;OPENAI_API_KEY&#34;))  # type: ignore&#xA;parser = MegaParseVision(model=model)&#xA;megaparse = MegaParse(parser)&#xA;response = megaparse.load(&#34;./test.pdf&#34;)&#xA;print(response)&#xA;megaparse.save(&#34;./test.md&#34;)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The model supported by MegaParse Vision are the multimodal ones such as claude 3.5, claude 4, gpt-4o and gpt-4.&lt;/p&gt; &#xA;&lt;h3&gt;(Optional) Use LlamaParse for Improved Results&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Create an account on &lt;a href=&#34;https://cloud.llamaindex.ai/&#34;&gt;Llama Cloud&lt;/a&gt; and get your API key.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Change the parser to LlamaParser&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from megaparse.core.megaparse import MegaParse&#xA;from langchain_openai import ChatOpenAI&#xA;from megaparse.core.parser.llama import LlamaParser&#xA;&#xA;parser = LlamaParser(api_key = os.getenv(&#34;LLAMA_CLOUD_API_KEY&#34;))&#xA;megaparse = MegaParse(parser)&#xA;response = megaparse.load(&#34;./test.pdf&#34;)&#xA;print(response)&#xA;megaparse.save(&#34;./test.md&#34;) #saves the last processed doc in md format&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Use as an API&lt;/h2&gt; &#xA;&lt;p&gt;There is a MakeFile for you, simply use : &lt;code&gt;make dev&lt;/code&gt; at the root of the project and you are good to go.&lt;/p&gt; &#xA;&lt;p&gt;See localhost:8000/docs for more info on the different endpoints !&lt;/p&gt; &#xA;&lt;h2&gt;BenchMark&lt;/h2&gt; &#xA;&lt;!--BENCHMARK--&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Parser&lt;/th&gt; &#xA;   &lt;th&gt;similarity_ratio&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;megaparse_vision&lt;/td&gt; &#xA;   &lt;td&gt;0.87&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;unstructured_with_check_table&lt;/td&gt; &#xA;   &lt;td&gt;0.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;unstructured&lt;/td&gt; &#xA;   &lt;td&gt;0.59&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama_parser&lt;/td&gt; &#xA;   &lt;td&gt;0.33&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!--END_BENCHMARK--&gt; &#xA;&lt;p&gt;&lt;em&gt;Higher the better&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note: Want to evaluate and compare your Megaparse module with ours ? Please add your config in &lt;code&gt;evaluations/script.py&lt;/code&gt; and then run &lt;code&gt;python evaluations/script.py&lt;/code&gt;. If it is better, do a PR, I mean, let&#39;s go higher together üöÄ.&lt;/p&gt; &#xA;&lt;h2&gt;In Construction üöß&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Improve table checker&lt;/li&gt; &#xA; &lt;li&gt;Create Checkers to add &lt;strong&gt;modular postprocessing&lt;/strong&gt; ‚öôÔ∏è&lt;/li&gt; &#xA; &lt;li&gt;Add Structured output, &lt;strong&gt;let&#39;s get computer talking&lt;/strong&gt; ü§ñ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#QuivrHQ/MegaParse&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=QuivrHQ/MegaParse&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>