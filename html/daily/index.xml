<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-23T01:36:06Z</updated>
  <subtitle>Daily Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ekoerp1/eaglercraft-1.15-Final-Release</title>
    <updated>2023-03-23T01:36:06Z</updated>
    <id>tag:github.com,2023-03-23:/ekoerp1/eaglercraft-1.15-Final-Release</id>
    <link href="https://github.com/ekoerp1/eaglercraft-1.15-Final-Release" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Last release of eaglecraft before it was deleted use the new url&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;This repository will be deleted imminently&lt;/h1&gt; &#xA;&lt;h3&gt;Create a fresh fork ASAP to preserve it, you MUST fork a 100% fresh copy in order for the repository to be considered genuine&lt;/h3&gt; &#xA;&lt;h3&gt;Please read &lt;code&gt;LAX1DUDE_SIGNATURE.txt&lt;/code&gt; for instructions to verify this is an original copy, if the file is not present then do not use this copy of the project&lt;/h3&gt; &#xA;&lt;h3&gt;LAX1DUDE&#39;s PGP key is here: &lt;a href=&#34;https://deev.is/certs/LAX1DUDE_eagler_public.asc&#34;&gt;https://deev.is/certs/LAX1DUDE_eagler_public.asc&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;Do not edit this README, modifying any file will invalidate the repository&#39;s checksum&lt;/h3&gt; &#xA;&lt;h3&gt;Download your worlds off of &lt;a href=&#34;https://g.deev.is/eaglercraft/&#34;&gt;https://g.deev.is/eaglercraft/&lt;/a&gt; and alts in case of a URL change for the demo client&lt;/h3&gt; &#xA;&lt;h3&gt;MY LAN WORLD RELAYS (relay.deev.is, relay.lax1dude.net) WILL REMAIN ONLINE FOR CONVENIENCE&lt;/h3&gt; &#xA;&lt;h1&gt;Eaglercraft&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://g.deev.is/eaglercraft/cover.png&#34; alt=&#34;eaglercraft&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Eaglercraft is real Minecraft 1.5.2 that you can play in any regular web browser. That includes school chromebooks, it works on all chromebooks. It supports both singleplayer and multiplayer.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Currently maintained by &lt;a href=&#34;https://github.com/ayunami2000&#34;&gt;ayunami2000&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For any questions you can join the discord server and hit us up there &lt;a href=&#34;https://discord.gg/Ekzcgs3DKZ&#34;&gt;https://discord.gg/Ekzcgs3DKZ&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Quick Start&lt;/h1&gt; &#xA;&lt;h3&gt;Client: &lt;a href=&#34;https://g.deev.is/eaglercraft/&#34;&gt;https://g.deev.is/eaglercraft/&lt;/a&gt; [^1]&lt;/h3&gt; &#xA;&lt;h3&gt;Unofficial Back Up Client: &lt;a href=&#34;https://ekoerp1.github.io/eaglercraft-1.15-Final-Release/javascript/&#34;&gt;https://ekoerp1.github.io/eaglercraft-1.15-Final-Release/javascript/&lt;/a&gt; [^1]&lt;/h3&gt; &#xA;&lt;h3&gt;Offline Client Download: &lt;a href=&#34;https://github.com/lax1dude/eaglercraft/raw/main/stable-download/Offline_Download_Version.html&#34;&gt;Offline_Download_Version.html&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;(right click the link and press &#39;Save link as...&#39; to download the file)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Play Minecraft Beta Singleplayer: &lt;a href=&#34;https://g.deev.is/eaglercraft/beta/&#34;&gt;https://g.deev.is/eaglercraft/beta/&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;[^1]: A list of public servers are already added into the official client&lt;/p&gt; &#xA;&lt;h1&gt;Table Of Contents:&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Singleplayer&#34;&gt;Singleplayer&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Multiplayer&#34;&gt;Multiplayer&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Others&#34;&gt;Others&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Importing-and-Exporting-Worlds&#34;&gt;Importing and Exporting Worlds&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Public-clients-and-servers&#34;&gt;Public clients and servers&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Plugin-Development&#34;&gt;Plugin Development&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#LAN-Worlds&#34;&gt;LAN Worlds&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-server---Bukkit&#34;&gt;Creating a Server - Bukkit&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Compiling&#34;&gt;Compiling&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Public-LAN-Relays&#34;&gt;Public LAN Relays&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-server---EaglercraftBungee&#34;&gt;Creating a Server - EaglercraftBungee&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-resource-pack&#34;&gt;Creating a resource pack&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-LAN-Relay&#34;&gt;Creating a LAN Relay&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-Client&#34;&gt;Creating a Client&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#EaglercraftBungee-Configuration&#34;&gt;EaglercraftBungee Configuration&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-Reverse-Proxy---NGINX&#34;&gt;Creating a Reverse Proxy - NGINX&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#NGINX-Configuration&#34;&gt;NGINX Configuration&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Singleplayer&lt;/h1&gt; &#xA;&lt;p&gt;Simply press the &#39;Singleplayer&#39; button on the main menu and you can create a regular vanilla minecraft and play it any time.&lt;/p&gt; &#xA;&lt;h2&gt;Importing and Exporting Worlds&lt;/h2&gt; &#xA;&lt;p&gt;The worlds are stored in your browser&#39;s local storage, &lt;strong&gt;you can export them as EPK files and import them again on all other Eaglercraft sites that also support singleplayer.&lt;/strong&gt; You can even copy an exported world to an entirely different computer, or send it to a friend, and import it and continue playing with all your progress saved.&lt;/p&gt; &#xA;&lt;h2&gt;LAN Worlds&lt;/h2&gt; &#xA;&lt;h3&gt;Eaglercraft fully supports LAN worlds, you can share your world with any player and they can connect directly to it as if you are running a server in your browser.&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;LAN worlds will work between any two devices connected to the internet, you are not limited to only players connected to your Wi-Fi network&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;To open your world to LAN, go to the pause menu and click &#39;Open to LAN&#39;. You can configure the gamemode and cheats and if you would like to hide your LAN world. &lt;strong&gt;When you do not hide your LAN world, it will appear on the Multiplayer screen from the main menu to anybody else also on your Wi-Fi network.&lt;/strong&gt; Set the world hidden if you are at school or something and don&#39;t want everyone else in your class to join as well and start griefing.&lt;/p&gt; &#xA;&lt;p&gt;When you open the world to LAN it will give you a &#39;join code&#39;. Simply share the code with your friends and they can visit the Multiplayer screen from the main menu and click &#39;Direct Connect&#39; and enter the code and they will be able to join your world.&lt;/p&gt; &#xA;&lt;p&gt;Make sure they add the relay server your game opens the LAN world on to their &#34;Network Settings&#34; menu accessable from the Multiplayer screen. You simply must send them the URL indicated in the pause menu once the world is opened and they can use the &#34;Add Relay&#34; option to add the URL to their list.&lt;/p&gt; &#xA;&lt;h3&gt;THIS IS A REQUIRED STEP FOR A PERSON TO JOIN YOUR WORLD, IF THEY DO NOT HAVE THE RELAY YOUR WORLD IS HOSTED ON ADDED TO THEIR &#34;Network Settings&#34; THE GAME WILL BE UNABLE TO LOCATE THE WORLD&lt;/h3&gt; &#xA;&lt;h2&gt;Public LAN Relays&lt;/h2&gt; &#xA;&lt;h3&gt;Here are some public relay servers you can use:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;wss://relay.deev.is/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;wss://relay.lax1dude.net/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;wss://relay.shhnowisnottheti.me/&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Creating a LAN Relay&lt;/h2&gt; &#xA;&lt;h3&gt;Simply download &lt;a href=&#34;https://github.com/lax1dude/eaglercraft/raw/main/stable-download/sp-relay.jar&#34;&gt;stable-download/sp-relay.jar&lt;/a&gt; and run &lt;code&gt;java -jar sp-relay.jar&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Run &lt;code&gt;java -jar sp-relay.jar --debug&lt;/code&gt; to view debug info like all the IPs of incoming connections, as it is not shown by default because logging all that info will reduce performance when the relay is being pinged many times a second depending on it&#39;s popularity.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Edit the &lt;code&gt;relayConfig.ini&lt;/code&gt; file generated on first launch to change the port and configure ratelimiting and such, and &lt;code&gt;relays.txt&lt;/code&gt; to change the list of STUN and TURN relays reported to clients connecting to the relay, which are required to correctly establish a P2P LAN world connection in browsers&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The &lt;code&gt;origin-whitelist&lt;/code&gt; config variable is a semicolon (&lt;code&gt;;&lt;/code&gt;) seperated list of domains used to restrict what sites are to be allowed to use your relay. When left blank it allows all sites. Add &lt;code&gt;offline&lt;/code&gt; to allow offline download clients to use your relay as well, and &lt;code&gt;null&lt;/code&gt; to allow connections that do not specify an &lt;code&gt;Origin:&lt;/code&gt; header. Use &lt;code&gt;*&lt;/code&gt; as a wildcard, for example: &lt;code&gt;*.deev.is&lt;/code&gt; allows all domains ending with &#34;deev.is&#34; to use the relay.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Multiplayer&lt;/h1&gt; &#xA;&lt;p&gt;Multiplayer functions like vanilla Minecraft, allowing you to join normal Minecraft servers like a normal client.&lt;/p&gt; &#xA;&lt;h2&gt;Public clients and servers&lt;/h2&gt; &#xA;&lt;h3&gt;There are multiple official clients hosted by lax1dude, here is a small list:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Main: &lt;a href=&#34;https://g.deev.is/&#34; title=&#34;https://g.deev.is/&#34;&gt;https://g.deev.is/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://eaglercraft.net/&#34; title=&#34;https://eaglercraft.net/&#34;&gt;https://eaglercraft.net/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://eaglercraft.org/&#34; title=&#34;https://eaglercraft.org/&#34;&gt;https://eaglercraft.org/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://eaglercraft.me/&#34; title=&#34;https://eaglercraft.me/&#34;&gt;https://eaglercraft.me/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://g.lax1dude.net/eaglercraft/&#34; title=&#34;https://g.lax1dude.net/eaglercraft/&#34;&gt;https://g.lax1dude.net/eaglercraft/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;There are also multiple community hosted servers, the best way to discover those is to use the &lt;a href=&#34;https://g.deev.is/eaglercraft/&#34;&gt;official clients&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h4&gt;Alternatively, there is a server list[^2] to find servers.&lt;/h4&gt; &#xA;&lt;p&gt;[^2]: Server list is currently being rebuilt, use official client for now&lt;/p&gt; &#xA;&lt;h1&gt;Creating your own server&lt;/h1&gt; &#xA;&lt;p&gt;There are &lt;em&gt;&lt;strong&gt;multiple parts&lt;/strong&gt;&lt;/em&gt; &lt;strong&gt;to a server&lt;/strong&gt;, mainly consisting of a &lt;strong&gt;regular 1.5.2 Bukkit server&lt;/strong&gt;, and a &lt;strong&gt;modified version of Bungeecord&lt;/strong&gt; called &lt;strong&gt;EaglercraftBungee&lt;/strong&gt;, which on top of the regular Bungeecord functionality, it translates WebSocket connections to raw TCP connections which Bukkit can understand.&lt;/p&gt; &#xA;&lt;p&gt;You may also want to set up your own &lt;strong&gt;client&lt;/strong&gt;, allowing you to &lt;em&gt;control default server listings, resource packs, and an overall faster connection due to less load.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to use a domain for your server, &lt;strong&gt;a reverse proxy&lt;/strong&gt; can be set up to enable extra functionality within EaglercraftBungee. &lt;strong&gt;NGINX&lt;/strong&gt; is recommended, and a tutorial is included &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-Reverse-Proxy---NGINX&#34;&gt;here&lt;/a&gt;&lt;/strong&gt;. &lt;strong&gt;This is optional, and can be skipped by just connecting with the IP.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;If replit is acceptable, you can use &lt;a href=&#34;https://replit.com/@ayunami2000/eaglercraft-server&#34;&gt;this&lt;/a&gt; to automatically set up everything for a server, otherwise, look below for instructions&lt;/h3&gt; &#xA;&lt;h2&gt;Creating a server - Bukkit&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Check if Java is installed.&lt;/strong&gt; You can download it from &lt;a href=&#34;https://www.java.com/en/download/&#34;&gt;https://www.java.com/en/download/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Download the &lt;a href=&#34;https://github.com/lax1dude/eaglercraft/raw/main/stable-download/stable-download.zip&#34;&gt;stable-download/stable-download.zip&lt;/a&gt; file from this repository&lt;/li&gt; &#xA; &lt;li&gt;Extract the ZIP file you downloaded to a new folder&lt;/li&gt; &#xA; &lt;li&gt;Open the new folder, go into the &lt;code&gt;java/bukkit_command&lt;/code&gt; folder&lt;/li&gt; &#xA; &lt;li&gt;In Windows, double-click &lt;code&gt;run.bat&lt;/code&gt;. It should open a new terminal window&lt;br&gt; &lt;img src=&#34;https://i.gyazo.com/2b0f6b3e5b2e5a5a102c62ea5b6fba3f.png&#34; alt=&#34;run.bat&#34;&gt;&lt;br&gt; &lt;strong&gt;Some computers may just say &#39;run&#39; instead of &#39;run.bat&#39;, both are correct&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;On macOS or Linux, google how to open the terminal and use the &lt;code&gt;cd&lt;/code&gt; command to navigate to &lt;code&gt;java/bukkit_command&lt;/code&gt;&lt;br&gt; Then, in that folder, run &lt;code&gt;chmod +x run_unix.sh&lt;/code&gt; and then run &lt;code&gt;./run_unix.sh&lt;/code&gt;. It should start the same server&lt;/li&gt; &#xA; &lt;li&gt;To add some bukkit plugins, download the plugin&#39;s JAR file for CraftBukkit 1.5.2 and place it in &lt;code&gt;java/bukkit_command/plugins&lt;/code&gt; (See &lt;a href=&#34;https://github.com/lax1dude/eaglercraft-plugins/&#34;&gt;https://github.com/lax1dude/eaglercraft-plugins/&lt;/a&gt; to download some supported plugins)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Creating a server - EaglercraftBungee&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;In the same new folder, go into the &lt;code&gt;java/bungee_command&lt;/code&gt; folder&lt;/li&gt; &#xA; &lt;li&gt;In Windows, double-click &lt;code&gt;run.bat&lt;/code&gt;. It should open a second terminal window&lt;br&gt; Keep both the first and second terminal window you opened, just minimize them, don&#39;t close&lt;/li&gt; &#xA; &lt;li&gt;On macOS or Linux, repeat step 7 in &lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-server---Bukkit&#34;&gt;Creating a Server - Bukkit&lt;/a&gt;, but navigate to &lt;code&gt;java/bungee_command&lt;/code&gt; this time&lt;/li&gt; &#xA; &lt;li&gt;To add some bungee plugins, download the plugin&#39;s JAR file and place it in &lt;code&gt;java/bungee_command/plugins&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;There are alot more configurations in bungeecord, but this should set you up&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Your server is now ready.&lt;/strong&gt; Visit any client, and go to &#39;Multiplayer&#39; from the main menu. Select &#39;Direct Connect&#39;, type &lt;code&gt;127.0.0.1:25565&lt;/code&gt; and press &#39;Join Server&#39; &lt;strong&gt;It should allow you to connect, if not, check the two terminal windows for errors&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Creating a client&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;To install, upload the contents of &lt;code&gt;stable-download/web&lt;/code&gt; to a web server.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;There are &lt;em&gt;multiple ways of setting up a web server&lt;/em&gt;. &lt;strong&gt;&lt;a href=&#34;https://nginx.org&#34;&gt;NGINX&lt;/a&gt; is a powerful web server, but alternatives like &lt;a href=&#34;https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb?hl=en&#34;&gt;Web Server for Chrome&lt;/a&gt; may be easier to set up.&lt;/strong&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;A quick crash course on setting up NGINX is provided &lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-Reverse-Proxy---NGINX&#34;&gt;here&lt;/a&gt;, &lt;strong&gt;FOLLOW STEPS 1 AND 2 ONLY&lt;/strong&gt;, then navigate to &lt;code&gt;/var/www/html&lt;/code&gt; and upload the contents of &lt;code&gt;stable-download/web&lt;/code&gt; there.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;If you had installed NGINX earlier as a reverse proxy, you can also use it to host the client, &lt;strong&gt;follow the steps above ^^^&lt;/strong&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Make sure that the URL to connect to the client and the server are separate, preferably with a path, like &lt;code&gt;https://eaglercraft.example.com/server&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;The &#39;web&#39; folder will not work if you open it in your browser locally! If you see &#39;file:///&#39; in the URL you are doing it wrong. You need to upload the folder to an HTTP or HTTPS server and access it over the internet via http:// or https://. The game will not load otherwise, this is not a bug&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To modify the list of default servers, modify the &lt;code&gt;window.eaglercraftOpts&lt;/code&gt; variable in &lt;code&gt;index.html&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;A full guide on how to configure &lt;code&gt;eaglercraftOpts&lt;/code&gt; is coming soon, but it should be fairly intuitive to figure out how to set it up based on what the default values already are when you look in stable-download&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;To create a link to your site that automatically joins the server,&lt;/strong&gt; add a &lt;code&gt;?server=&lt;/code&gt; variable to the URL, like (for example): &lt;a href=&#34;https://g.deev.is/eaglercraft/?server=127.0.0.1:25565&#34;&gt;https://g.deev.is/eaglercraft/?server=127.0.0.1:25565&lt;/a&gt; will automatically join &lt;code&gt;ws://127.0.0.1:25565/&lt;/code&gt; as soon as the player finishes setting their username and skin&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;EaglercraftBungee Configuration&lt;/h1&gt; &#xA;&lt;h2&gt;MOTD&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To change your server&#39;s MOTD and icon, edit the &lt;code&gt;motd1:&lt;/code&gt; tag of the listener config in &lt;code&gt;java/bungee_command/config.yml&lt;/code&gt;, and replace &lt;code&gt;server-icon.png&lt;/code&gt; in the folder where the config file is. Use &lt;code&gt;&amp;amp;&lt;/code&gt; to add color/formatting codes. The server list will downscale your icon to 64x64 pixels&lt;/li&gt; &#xA; &lt;li&gt;You can give your MOTD multiple lines, add a &lt;code&gt;motd2:&lt;/code&gt; to define a second line&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;For an animated MOTD and icon, install EaglerMOTD: &lt;a href=&#34;https://github.com/lax1dude/eaglercraft-motd/&#34;&gt;https://github.com/lax1dude/eaglercraft-motd/&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Authentication&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;To enable the /login and /register commands in EaglercraftBungee, you can edit this portion of config.yml&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;authservice:&#xA;  authfile: auths.db&#xA;  register_enabled: true&#xA;  ip_limit: 0&#xA;  join_messages:&#xA;  - &#39;&amp;amp;3Welcome to my &amp;amp;aEaglercraftBungee &amp;amp;3server!&#39;&#xA;  login_timeout: 30&#xA;  enabled: false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;authfile&lt;/code&gt; Sets the authentication database file, which is &lt;strong&gt;compatible with AuthMe&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;register_enabled&lt;/code&gt; Turns register command on and off&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;ip_limit&lt;/code&gt; Sets the max number of registrations per IP, 0 = unlimited&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;join_messages&lt;/code&gt; List of messages to show the player when they join&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;login_timeout&lt;/code&gt; Sets how many seconds players have to log in before they are kicked&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;enable&lt;/code&gt; Turns login commands on and off&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Moderation&lt;/h2&gt; &#xA;&lt;h3&gt;Miscellaneous&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;If you use /op on your server, keep in mind that if you &#34;/op LAX1DUDE&#34;, a player joining as &#39;laX1DUDE&#39; or &#39;LaX1dUdE&#39; or &#39;lax1dude&#39; will all have /op too. To solve this problem, force all operators to only be able to join with all lowercase (&#39;lax1dude&#39;) letters in their usernames by moving &#39;BitchFilterPlugin.jar&#34; into &#34;java/bukkit_command/plugins&#34; and then register every op username lowercase&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;To disable voice chat, set &lt;code&gt;voice_enabled: false&lt;/code&gt; in the bungeecord config.yml&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Username Bans&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;To ban a username on Eaglercraftbungee, use:&lt;/strong&gt; &lt;code&gt;eag-ban &amp;lt;username&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;You can edit bans.txt in your EaglercraftBungee folder, the server automatically reloads the file when it is saved&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;To ban users by regular expression, use: &lt;code&gt;eag-ban-regex &amp;lt;regex&amp;gt;&lt;/code&gt; with a regular expression to match the username in &lt;strong&gt;lowercase&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;IP Bans&lt;/h3&gt; &#xA;&lt;p&gt;In order for IP Bans to work, a &lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-Reverse-Proxy---NGINX&#34;&gt;&lt;strong&gt;a reverse proxy&lt;/strong&gt;&lt;/a&gt; is required, and &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#NGINX-Configuration&#34;&gt;&lt;code&gt;forward_ip&lt;/code&gt;&lt;/a&gt; needs to be configured,&lt;/strong&gt; &lt;em&gt;&lt;strong&gt;otherwise it cannot ban the user&#39;s IP&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;To ban an IP on Eaglercraftbungee, use:&lt;/strong&gt; &lt;code&gt;eag-ban-ip &amp;lt;ip&amp;gt;&lt;/code&gt;, or &lt;code&gt;eag-ban-ip &amp;lt;name&amp;gt;&lt;/code&gt; to ban the IP of a player automatically&lt;/li&gt; &#xA; &lt;li&gt;To ban a range of IP addresses, use slash notation to define a subnet. Example: &lt;code&gt;eag-ban-ip 192.168.0.0/8&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;To ban users by wildcard (*) use: &lt;code&gt;eag-ban-wildcard &amp;lt;text&amp;gt;*&lt;/code&gt; or &lt;code&gt;eag-ban-wildcard *&amp;lt;text&amp;gt;&lt;/code&gt; or &lt;code&gt;eag-ban-wildcard *&amp;lt;text&amp;gt;*&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Client Bans&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;EaglercraftBungee has a built in domain blacklist that updates automatically, you can disable it by setting this in config.yml:&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;enable_web_origin_blacklist: false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;To block all clients on replit from joining, set this to true in config.yml:&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;origin_blacklist_block_replit_clients: true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;To block all offline-download clients, set this to true in config.yml:&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;origin_blacklist_block_offline_download: true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;To block the debug runtime (or other desktop clients), set this to true in config.yml:&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;origin_blacklist_block_missing_origin_header: true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;To add your own blacklisted domains&lt;/strong&gt;, create a file called &lt;code&gt;origin_blacklist.txt&lt;/code&gt; in your bungeecord directory and put the regular expressions inside, one on each line. There &#39;s also a &lt;code&gt;domain&lt;/code&gt; command in the console to view a player&#39;s domain, and a &lt;code&gt;block-domain&lt;/code&gt; and &lt;code&gt;block-domain-name&lt;/code&gt; and &lt;code&gt;unblock-domain&lt;/code&gt; command to manage the local &lt;code&gt;origin_blacklist.txt&lt;/code&gt; from the bungee console (if you don&#39;t know how to edit a file on your own). The list reloads automatically when changes to the file are detected.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;h3&gt;To configure bungee to block connections from all clients except your own, set this option:&lt;/h3&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;origin_blacklist_use_simple_whitelist: true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, add your domain to &lt;code&gt;origin_blacklist_simple_whitelist&lt;/code&gt; like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;origin_blacklist_simple_whitelist:&#xA;- type the name of your client&#39;s domain here&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, unless still you want it as an option for your players, disable the offline download so hackers don&#39;t use it to bypass the whitelist, as it is not blocked in whitelist mode by default:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;origin_blacklist_block_offline_download: true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Others&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The server has built in DoS protection, reset it via typing &#39;eag-ratelimit reset&#39; in the bungee console**&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Rate limiting is possible, but &lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#Creating-a-Reverse-Proxy---NGINX&#34;&gt;&lt;strong&gt;a reverse proxy&lt;/strong&gt;&lt;/a&gt; is required, and &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ekoerp1/eaglercraft-1.15-Final-Release/main/#NGINX-Configuration&#34;&gt;&lt;code&gt;forward_ip&lt;/code&gt;&lt;/a&gt; needs to be configured to use rate limiting,&lt;/strong&gt; &lt;em&gt;&lt;strong&gt;otherwise it will be disabled by default&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;ratelimit:&#xA;  ip:&#xA;    enable: true&#xA;    period: 90&#xA;    limit: 60&#xA;    limit_lockout: 80&#xA;    lockout_duration: 1200&#xA;    exceptions: []&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;enable&lt;/code&gt; enable rate limiting&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;period&lt;/code&gt; and &lt;code&gt;limit&lt;/code&gt; set the number of requests (&lt;code&gt;limit&lt;/code&gt;) can be made in (&lt;code&gt;period&lt;/code&gt;) number of seconds&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;limit_lockout&lt;/code&gt; and &lt;code&gt;lockout_duration&lt;/code&gt; set the number of requests (&lt;code&gt;limit_lockout&lt;/code&gt;) that can be made in (&lt;code&gt;period&lt;/code&gt;) seconds before the IP is blocked for &lt;code&gt;lockout_duration&lt;/code&gt; number of seconds&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;exceptions&lt;/code&gt; a list of IP addresses that should never get rate limited. &lt;strong&gt;Local IPs like 127.0.0.1 and 192.168.*.* and such are set as exceptions by default&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;h3&gt;Redirecting the client to a new WebSocket&lt;/h3&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you would like to signal the client to disconnect from your bungeecord and reconnect to a different bungeecord, configure an entry in the &lt;code&gt;servers&lt;/code&gt; part of config.yml like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;test:&#xA;  redirect: wss://ServerHere/&#xA;  restricted: false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In this example, sending a player to the server &lt;code&gt;test&lt;/code&gt;, such as when they enter a portal or type &lt;code&gt;/server test&lt;/code&gt;, will trigger their client to disconnect from your bungeecord and then automatically reconnect to &lt;code&gt;wss://ServerHere/&lt;/code&gt; as if it was entered via &#34;Direct Connect&#34;&lt;/p&gt; &#xA;&lt;h2&gt;Creating a Reverse Proxy - NGINX&lt;/h2&gt; &#xA;&lt;p&gt;Here is a quick crash course of setting up NGINX on Linux, specifically on Debian distributions.&lt;/p&gt; &#xA;&lt;p&gt;Here are some google searches for other distributions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.google.com/search?q=set+up+nginx+on+windows&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.google.com/search?q=set+up+nginx+on+mac&#34;&gt;Mac&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.google.com/search?q=set+up+nginx+on+arch&#34;&gt;Linux - Arch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.google.com/search?q=set+up+nginx+on+fedora&#34;&gt;Linux - Fedora&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Open up your terminal, and run&lt;br&gt; &lt;code&gt;sudo apt update&lt;/code&gt; and &lt;code&gt;sudo apt install nginx&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open any web browser, and search for &lt;code&gt;localhost&lt;/code&gt; in your search bar. You should see something like this:&lt;img src=&#34;https://ubuntucommunity.s3.dualstack.us-east-2.amazonaws.com/optimized/2X/7/7504d83a9fe8c09d861b2f7c49e144ac773f0c0d_2_690x288.png&#34; alt=&#34;Welcome to nginx&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to NGINX&#39;s configuration with &lt;code&gt;cd /etc/nginx/sites-enabled&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a new configuration file with your domain name, for example &lt;code&gt;nano eaglercraft.example.com&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Paste in the following code into the file. Replace &lt;code&gt;example.com&lt;/code&gt; with your own domain, and &lt;code&gt;app_server_address&lt;/code&gt; as the &lt;code&gt;ip:port&lt;/code&gt; of your EaglercraftBungee server you want the URL to connect to.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;server {&#xA;    listen 80;&#xA;    listen [::]:80;&#xA;&#xA;    server_name example.com eaglercraft.example.com;&#xA;        &#xA;    location / {&#xA;        proxy_pass app_server_address;&#xA;        include proxy_params;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Now, restart NGINX with &lt;code&gt;sudo service nginx restart&lt;/code&gt; and you should be good to go!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;NGINX Configuration&lt;/h2&gt; &#xA;&lt;h3&gt;To implement the following configuration, add the lines below the &lt;code&gt;proxy_pass&lt;/code&gt; line.&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;To stop people from using bookmarklets to load a client from a different URL onto your official URL via XXS, add these headers to NGINX:&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;add_header X-Frame-Options &#34;SAMEORIGIN&#34;;&#xA;add_header Referrer-Policy &#34;strict-origin&#34;;&#xA;add_header X-XSS-Protection &#34;1; mode=block&#34;;&#xA;add_header Content-Security-Policy &#34;default-src &#39;self&#39; &#39;unsafe-inline&#39;; img-src &#39;self&#39; &#39;unsafe-inline&#39; data: blob:; connect-src &#39;self&#39; ws: wss:; upgrade-insecure-requests&#34;;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h6&gt;(not fully tested, excuse the scroll bar)&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;To use IP bans and rate limiting, add &lt;code&gt;proxy_set_header X-Real-IP $remote_addr&lt;/code&gt; to your proxy configuration&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Others&lt;/h1&gt; &#xA;&lt;h2&gt;Plugin Development&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;To develop a plugin, download &lt;a href=&#34;https://github.com/lax1dude/eaglercraft/raw/main/stable-download/java/bungee_command/bungee-dist.jar&#34;&gt;stable-download/java/bungee_command/bungee_dist.jar&lt;/a&gt; and add it to the Build Path of your Java IDE. Develop the plugin just like a regular BungeeCord plugin, see &lt;a href=&#34;https://github.com/lax1dude/eaglercraft-motd/&#34;&gt;EaglerMOTD&lt;/a&gt; for an example.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Test your plugin by exporting it as a jar and putting it in the &#39;/plugins&#39; directory of EaglercraftBungee and then clicking &#39;run.bat&#39;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;New Events:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/lax1dude/eaglercraft/raw/main/eaglercraftbungee/src/main/java/net/md_5/bungee/api/event/WebsocketMOTDEvent.java&#34;&gt;net.md_5.bungee.api.event.WebsocketMOTDEvent&lt;/a&gt;&lt;/strong&gt;: Triggered when a client or website requests the MOTD&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/lax1dude/eaglercraft/raw/main/eaglercraftbungee/src/main/java/net/md_5/bungee/api/event/WebsocketQueryEvent.java&#34;&gt;net.md_5.bungee.api.event.WebsocketQueryEvent&lt;/a&gt;&lt;/strong&gt;: Triggered when a client or website requests a query. This happens when a site opens a text WebSocket to a listener and sends a single string &lt;code&gt;Accept: &amp;lt;query&amp;gt;&lt;/code&gt; packet. Can be used to provide additional custom statistics to server list sites supporting integrated WebSocket queries&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Register event handlers using the standard BungeeCord&lt;/strong&gt; &lt;code&gt;@EventHandler&lt;/code&gt; &lt;strong&gt;annotation in your&lt;/strong&gt; &lt;code&gt;Listener&lt;/code&gt; &lt;strong&gt;class&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Compiling&lt;/h2&gt; &#xA;&lt;p&gt;To compile for the web, run the gradle &#39;teavm&#39; compile target to generate the classes.js file.&lt;/p&gt; &#xA;&lt;p&gt;The LWJGL runtime is no longer supported it is only included for reference&lt;/p&gt; &#xA;&lt;h2&gt;Creating a resource pack&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To make a custom resource pack for your site, clone this repository and edit the files in &lt;a href=&#34;https://github.com/lax1dude/eaglercraft/tree/main/lwjgl-rundir/resources&#34;&gt;lwjgl-rundir/resources&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;When you are done, navigate to &lt;a href=&#34;https://github.com/lax1dude/eaglercraft/tree/main/epkcompiler&#34;&gt;epkcompiler/&lt;/a&gt; and double-click &lt;code&gt;run.bat&lt;/code&gt;. Wait for the window to say &lt;code&gt;Press any key to continue...&lt;/code&gt; and close it. Then, go to &lt;code&gt;../javascript&lt;/code&gt; in the repository and copy &lt;code&gt;javascript/assets.epk&lt;/code&gt; to the &lt;code&gt;assets.epk&lt;/code&gt; on your website&lt;/li&gt; &#xA; &lt;li&gt;If you&#39;re on mac or linux, navigate to the epkcompiler folder via &lt;code&gt;cd&lt;/code&gt; and run &lt;code&gt;chmod +x run_unix.sh&lt;/code&gt; and then &lt;code&gt;./run_unix.sh&lt;/code&gt; to do this, then copy the same &lt;code&gt;javascript/assets.epk&lt;/code&gt; to the &lt;code&gt;assets.epk&lt;/code&gt; on your website&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;All I really have to say is, tabs not spaces, and format the code to be like the eclipse auto format tool on factory settings, but also run-on lines of code long enough to go off the screen and single line if statements and other format violations in that category are welcome if it helps enhance the contrast between the less important code and the more important code in a file. Don&#39;t commit changes to &lt;code&gt;javascript/classes.js&lt;/code&gt; or &lt;code&gt;javascript/classes_server.js&lt;/code&gt; or &lt;code&gt;javascript/assets.epk&lt;/code&gt; or anything in &lt;code&gt;stable-download/&lt;/code&gt;. I&#39;ll recompile those myself when I merge the pull request.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jiep/offensive-ai-compilation</title>
    <updated>2023-03-23T01:36:06Z</updated>
    <id>tag:github.com,2023-03-23:/jiep/offensive-ai-compilation</id>
    <link href="https://github.com/jiep/offensive-ai-compilation" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A curated list of useful resources that cover Offensive AI.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Offensive AI Compilation&lt;/h1&gt; &#xA;&lt;p&gt;A curated list of useful resources that cover Offensive AI.&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“ Contents ğŸ“&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-abuse-&#34;&gt;ğŸš« Abuse ğŸš«&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-adversarial-machine-learning-&#34;&gt;ğŸ§  Adversarial Machine Learning ğŸ§ &lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-attacks-&#34;&gt;âš¡ Attacks âš¡&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-extraction-&#34;&gt;ğŸ”’ Extraction ğŸ”’&lt;/a&gt; &#xA;        &lt;ul&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-limitations-%EF%B8%8F&#34;&gt;âš ï¸ Limitations âš ï¸&lt;/a&gt;&lt;/li&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-defensive-actions-%EF%B8%8F&#34;&gt;ğŸ›¡ï¸ Defensive actions ğŸ›¡ï¸&lt;/a&gt;&lt;/li&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-useful-links-&#34;&gt;ğŸ”— Useful links ğŸ”—&lt;/a&gt;&lt;/li&gt; &#xA;        &lt;/ul&gt; &lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-inversion-or-inference-%EF%B8%8F&#34;&gt;â¬…ï¸ Inversion (or inference) â¬…ï¸&lt;/a&gt; &#xA;        &lt;ul&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-defensive-actions-%EF%B8%8F-1&#34;&gt;ğŸ›¡ï¸ Defensive actions ğŸ›¡ï¸&lt;/a&gt;&lt;/li&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-useful-links--1&#34;&gt;ğŸ”— Useful links ğŸ”—&lt;/a&gt;&lt;/li&gt; &#xA;        &lt;/ul&gt; &lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-poisoning-&#34;&gt;ğŸ’‰ Poisoning ğŸ’‰&lt;/a&gt; &#xA;        &lt;ul&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-backdoors-&#34;&gt;ğŸ”“ Backdoors ğŸ”“&lt;/a&gt;&lt;/li&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-defensive-actions-%EF%B8%8F-2&#34;&gt;ğŸ›¡ï¸ Defensive actions ğŸ›¡ï¸&lt;/a&gt;&lt;/li&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-useful-links--2&#34;&gt;ğŸ”— Useful links ğŸ”—&lt;/a&gt;&lt;/li&gt; &#xA;        &lt;/ul&gt; &lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-evasion-%EF%B8%8F&#34;&gt;ğŸƒâ€â™‚ï¸ Evasion ğŸƒâ€â™‚ï¸&lt;/a&gt; &#xA;        &lt;ul&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-defensive-actions-%EF%B8%8F-3&#34;&gt;ğŸ›¡ï¸ Defensive actions ğŸ›¡ï¸&lt;/a&gt;&lt;/li&gt; &#xA;         &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-useful-links--3&#34;&gt;ğŸ”— Useful links ğŸ”—&lt;/a&gt;&lt;/li&gt; &#xA;        &lt;/ul&gt; &lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-tools-%EF%B8%8F&#34;&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#art&#34;&gt;ART&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#cleverhans&#34;&gt;Cleverhans&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-use-&#34;&gt;ğŸ”§ Use ğŸ”§&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F%EF%B8%8F-pentesting-%EF%B8%8F%EF%B8%8F&#34;&gt;ğŸ•µï¸â€â™‚ï¸ Pentesting ğŸ•µï¸â€â™‚ï¸&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-malware-&#34;&gt;ğŸ¦  Malware ğŸ¦ &lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8Fosint-%EF%B8%8F&#34;&gt;ğŸ—ºï¸&amp;nbsp;OSINT ğŸ—ºï¸&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#phishing-&#34;&gt;ğŸ“§&amp;nbsp;Phishing ğŸ“§&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-generative-ai-&#34;&gt;ğŸ‘¨â€ğŸ¤ Generative AI ğŸ‘¨â€ğŸ¤&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-audio-&#34;&gt;ğŸ”Š Audio ğŸ”Š&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-tools-%EF%B8%8F-1&#34;&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-applications-&#34;&gt;ğŸ’¡ Applications ğŸ’¡&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-detection-&#34;&gt;ğŸ” Detection ğŸ”&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-image-&#34;&gt;ğŸ“· Image ğŸ“·&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-tools-%EF%B8%8F-2&#34;&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-applications--1&#34;&gt;ğŸ’¡ Applications ğŸ’¡&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-detection--1&#34;&gt;ğŸ” Detection ğŸ”&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-video-&#34;&gt;ğŸ¥ Video ğŸ¥&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-tools-%EF%B8%8F-3&#34;&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-applications--2&#34;&gt;ğŸ’¡ Applications ğŸ’¡&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-detection--2&#34;&gt;ğŸ” Detection ğŸ”&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-text-&#34;&gt;ğŸ“„ Text ğŸ“„&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-tools-%EF%B8%8F-4&#34;&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-detection--3&#34;&gt;ğŸ” Detection ğŸ”&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-applications--3&#34;&gt;ğŸ’¡ Applications ğŸ’¡&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-misc-&#34;&gt;ğŸ“š Misc ğŸ“š&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-surveys-&#34;&gt;ğŸ“Š Surveys ğŸ“Š&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#-contributors-&#34;&gt;ğŸ—£ Contributors ğŸ—£&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/#%EF%B8%8F-license-%EF%B8%8F&#34;&gt;Â©ï¸ License Â©ï¸&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸš« Abuse ğŸš«&lt;/h2&gt; &#xA;&lt;p&gt;Exploiting the vulnerabilities of AI models.&lt;/p&gt; &#xA;&lt;h3&gt;ğŸ§  Adversarial Machine Learning ğŸ§ &lt;/h3&gt; &#xA;&lt;p&gt;Adversarial Machine Learning is responsible for assessing their weaknesses and providing countermeasures.&lt;/p&gt; &#xA;&lt;h4&gt;âš¡ Attacks âš¡&lt;/h4&gt; &#xA;&lt;p&gt;It is organized in four types of attacks: extraction, inversion, poisoning and evasion.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/attacks.png&#34; alt=&#34;Adversarial Machine Learning attacks&#34;&gt;&lt;/p&gt; &#xA;&lt;h5&gt;ğŸ”’ Extraction ğŸ”’&lt;/h5&gt; &#xA;&lt;p&gt;It tries to steal the parameters and hyperparameters of a model by making requests that maximize the extraction of information.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/extraction.png&#34; alt=&#34;Extraction attack&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Depending on the knowledge of the adversary&#39;s model, white-box and black-box attacks can be performed.&lt;/p&gt; &#xA;&lt;p&gt;In the simplest white-box case (when the adversary has full knowledge of the model, e.g., a sigmoid function), one can create a system of linear equations that can be easily solved.&lt;/p&gt; &#xA;&lt;p&gt;In the generic case, where there is insufficient knowledge of the model, the substitute model is used. This model is trained with the requests made to the original model in order to imitate the same functionality as the original one.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/extraction-white-black-box.png&#34; alt=&#34;White-box and black-box extraction attacks&#34;&gt;&lt;/p&gt; &#xA;&lt;h6&gt;âš ï¸ Limitations âš ï¸&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Training a substitute model is equivalent (in many cases) to training a model from scratch.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Very computationally intensive.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The adversary has limitations on the number of requests before being detected.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;ğŸ›¡ï¸ Defensive actions ğŸ›¡ï¸&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Rounding of output values.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Use of &lt;a href=&#34;https://en.wikipedia.org/wiki/Differential_privacy&#34;&gt;differential privacy&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Use of &lt;a href=&#34;https://en.wikipedia.org/wiki/Ensemble_learning&#34;&gt;ensembles&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Use of specific defenses&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.07221&#34;&gt;Specific architectures&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1805.02628&#34;&gt;PRADA&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1911.07100&#34;&gt;Adaptive Misinformation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;...&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;ğŸ”— Useful links ğŸ”—&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1609.02943&#34;&gt;Stealing Machine Learning Models via Prediction APIs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1802.05351&#34;&gt;Stealing Hyperparameters in Machine Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1812.02766&#34;&gt;Knockoff Nets: Stealing Functionality of Black-Box Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.07221&#34;&gt;Model Extraction Warning in MLaaS Paradigm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1806.05476&#34;&gt;Copycat CNN: Stealing Knowledge by Persuading Confession with Random Non-Labeled Data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1906.10908&#34;&gt;Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1812.11720&#34;&gt;Stealing Neural Networks via Timing Side Channels&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.08331&#34;&gt;Model Stealing Attacks Against Inductive Graph Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1909.01838&#34;&gt;High Accuracy and High Fidelity Extraction of Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.10149&#34;&gt;Poisoning Web-Scale Training Datasets is Practical&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;â¬…ï¸ Inversion (or inference) â¬…ï¸&lt;/h5&gt; &#xA;&lt;p&gt;They are intended to reverse the information flow of a machine learning model.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/inversion.png&#34; alt=&#34;Inference attack&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;They enable an adversary to have knowledge of the model that was not explicitly intended to be shared.&lt;/p&gt; &#xA;&lt;p&gt;They allow to know the training data or information as statistical properties of the model.&lt;/p&gt; &#xA;&lt;p&gt;Three types are possible:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Membership Inference Attack (MIA)&lt;/strong&gt;: An adversary attempts to determine whether a sample was employed as part of the training.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Property Inference Attack (PIA)&lt;/strong&gt;: An adversary aims to extract statistical properties that were not explicitly encoded as features during the training phase.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reconstruction&lt;/strong&gt;: An adversary tries to reconstruct one or more samples from the training set and/or their corresponding labels. Also called inversion.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;ğŸ›¡ï¸ Defensive actions ğŸ›¡ï¸&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Use of advanced cryptography. Countermeasures include &lt;a href=&#34;https://en.wikipedia.org/wiki/Differential_privacy&#34;&gt;differential privacy&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Homomorphic_encryption&#34;&gt;homomorphic cryptography&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Secure_multi-party_computation&#34;&gt;secure multiparty computation&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Use of regularization techniques such as &lt;a href=&#34;https://en.wikipedia.org/wiki/Dilution_(neural_networks)&#34;&gt;Dropout&lt;/a&gt; due to the relationship between overtraining and privacy.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://medium.com/gsi-technology/an-overview-of-model-compression-techniques-for-deep-learning-in-space-3fd8d4ce84e5&#34;&gt;Model compression&lt;/a&gt; has been proposed as a defense against reconstruction attacks.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;ğŸ”— Useful links ğŸ”—&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1610.05820&#34;&gt;Membership Inference Attacks Against Machine Learning Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/2810103.2813677&#34;&gt;Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.07886&#34;&gt;Machine Learning Models that Remember Too Much&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1806.01246&#34;&gt;ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1702.07464&#34;&gt;Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://petsymposium.org/popets/2019/popets-2019-0008.php&#34;&gt;LOGAN: Membership Inference Attacks Against Generative Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://content.iospress.com/articles/journal-of-computer-security/jcs191362&#34;&gt;Overfitting, robustness, and malicious algorithms: A study of potential causes of privacy risk in machine learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1812.00910&#34;&gt;Comprehensive Privacy Analysis of Deep Learning: Stand-alone and Federated Learning under Passive and Active White-box Inference Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1805.04049&#34;&gt;Inference Attacks Against Collaborative Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1802.08232&#34;&gt;The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.03814&#34;&gt;Towards the Science of Security and Privacy in Machine Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1909.10594&#34;&gt;MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.07805&#34;&gt;Extracting Training Data from Large Language Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/3243734.3243834&#34;&gt;Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.13188&#34;&gt;Extracting Training Data from Diffusion Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2022.11.18.517004v1&#34;&gt;High-resolution image reconstruction with latent diffusion models from human brain activity&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸ’‰ Poisoning ğŸ’‰&lt;/h5&gt; &#xA;&lt;p&gt;They aim to corrupt the training set by causing a machine learning model to reduce its accuracy.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/poisoning.png&#34; alt=&#34;Poisoning attack&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This attack is difficult to detect when performed on the training data, since the attack can propagate among different models using the same training data.&lt;/p&gt; &#xA;&lt;p&gt;The adversary seeks to destroy the availability of the model by modifying the decision boundary and, as a result, producing incorrect predictions or, create a backdoor in a model. In the latter, the model behaves correctly (returning the desired predictions) in most cases, except for certain inputs specially created by the adversary that produce undesired results. The adversary can manipulate the results of the predictions and launch future attacks.&lt;/p&gt; &#xA;&lt;h6&gt;ğŸ”“ Backdoors ğŸ”“&lt;/h6&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1708.06733&#34;&gt;BadNets&lt;/a&gt; are the simplest type of backdoor in a machine learning model. Moreover, BadNets are able to be preserved in a model, even if they are retrained again for a different task than the original model (transfer learning).&lt;/p&gt; &#xA;&lt;p&gt;It is important to note that &lt;strong&gt;public pre-trained models may contain backdoors&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h6&gt;ğŸ›¡ï¸ Defensive actions ğŸ›¡ï¸&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Detection of poisoned data, along with the use of data sanitization.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Robust training methods.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Specific defenses.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8835365&#34;&gt;Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1902.06531&#34;&gt;STRIP: A Defence Against Trojan Attacks on Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.03728&#34;&gt;Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/3319535.3363216&#34;&gt;ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.ijcai.org/proceedings/2019/647&#34;&gt;DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1910.04749&#34;&gt;Defending Neural Backdoors via Generative Distribution Modeling&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;ğŸ”— Useful links ğŸ”—&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1206.6389&#34;&gt;Poisoning Attacks against Support Vector Machines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1712.05526&#34;&gt;Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.semanticscholar.org/paper/Trojaning-Attack-on-Neural-Networks-Liu-Ma/08f7ac64b420210aa46fcbbdb0f206215f2e0644&#34;&gt;Trojaning Attack on Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1805.12185&#34;&gt;Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1804.00792&#34;&gt;Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.00636&#34;&gt;Spectral Signatures in Backdoor Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/3319535.3354209&#34;&gt;Latent Backdoor Attacks on Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1905.10447&#34;&gt;Regula Sub-rosa: Latent Backdoor Attacks on Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1910.00033&#34;&gt;Hidden Trigger Backdoor Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1905.05897&#34;&gt;Transferable Clean-Label Poisoning Attacks on Deep Neural Nets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1908.01763&#34;&gt;TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1708.08689&#34;&gt;Towards Poisoning of Deep Learning Algorithms with Back-gradient Optimization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1803.06975&#34;&gt;When Does Machine Learning FAIL? Generalized Transferability for Evasion and Poisoning Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1706.03691&#34;&gt;Certified Defenses for Data Poisoning Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.08138&#34;&gt;Input-Aware Dynamic Backdoor Attack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1807.00459&#34;&gt;How To Backdoor Federated Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.06974&#34;&gt;Planting Undetectable Backdoors in Machine Learning Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fooltheai.mybluemix.net/&#34;&gt;Fool the AI!&lt;/a&gt;: Hackers can use backdoors to poison training data and cause an AI model to misclassify images. Learn how IBM researchers can tell when data has been poisoned, then guess what backdoors have been hidden in these datasets. Can you guess the backdoor?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸƒâ€â™‚ï¸ Evasion ğŸƒâ€â™‚ï¸&lt;/h5&gt; &#xA;&lt;p&gt;An adversary adds a small perturbation (in the form of noise) to the input of a machine learning model to make it classify incorrectly (example adversary).&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/evasion.png&#34; alt=&#34;Evasion attack&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;They are similar to poisoning attacks, but their main difference is that evasion attacks try to exploit weaknesses of the model in the inference phase.&lt;/p&gt; &#xA;&lt;p&gt;The goal of the adversary is for adversarial examples to be imperceptible to a human.&lt;/p&gt; &#xA;&lt;p&gt;Two types of attack can be performed depending on the output desired by the opponent:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Targeted&lt;/strong&gt;: the adversary aims to obtain a prediction of his choice.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/targeted.png&#34; alt=&#34;Targeted attack&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Untargeted&lt;/strong&gt;: the adversary intends to achieve a misclassification.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/untargeted.png&#34; alt=&#34;Untargeted attack&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The most common attacks are &lt;strong&gt;white-box attacks&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1312.6199&#34;&gt;L-BFGS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1412.6572&#34;&gt;FGSM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1607.02533&#34;&gt;BIM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1511.07528&#34;&gt;JSMA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1608.04644&#34;&gt;Carlini &amp;amp; Wagner (C&amp;amp;W)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://andrewxiwu.github.io/public/papers/2017/JWJ17-objective-metrics-and-gradient-descent-based-algorithms-for-adversarial-examples-in-machine-learning.pdf&#34;&gt;NewtonFool&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.04114&#34;&gt;EAD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1610.08401&#34;&gt;UAP&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;ğŸ›¡ï¸ Defensive actions ğŸ›¡ï¸&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Adversarial training, which consists of crafting adversarial examples during training so as to allow the model to learn features of the adversarial examples, making the model more robust to this type of attack.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Transformations on inputs.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Gradient masking/regularization. &lt;a href=&#34;https://arxiv.org/abs/1802.00420&#34;&gt;Not very effective&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Weak defenses.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;ğŸ”— Useful links ğŸ”—&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1602.02697&#34;&gt;Practical Black-Box Attacks against Machine Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1511.07528&#34;&gt;The Limitations of Deep Learning in Adversarial Settings&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1608.04644&#34;&gt;Towards Evaluating the Robustness of Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1511.04508&#34;&gt;Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1607.02533&#34;&gt;Adversarial examples in the physical world&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1705.07204&#34;&gt;Ensemble Adversarial Training: Attacks and Defenses&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1706.06083&#34;&gt;Towards Deep Learning Models Resistant to Adversarial Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1312.6199&#34;&gt;Intriguing properties of neural networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1412.6572&#34;&gt;Explaining and Harnessing Adversarial Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.02770&#34;&gt;Delving into Transferable Adversarial Examples and Black-box Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.01236&#34;&gt;Adversarial machine learning at scale&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1804.08598&#34;&gt;Black-box Adversarial Attacks with Limited Queries and Information&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1704.01155&#34;&gt;Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1712.04248&#34;&gt;Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_cvpr_2018/papers/Dong_Boosting_Adversarial_Attacks_CVPR_2018_paper.pdf&#34;&gt;Boosting Adversarial Attacks with Momentum&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1704.03453&#34;&gt;The Space of Transferable Adversarial Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.00117&#34;&gt;Countering Adversarial Images using Input Transformations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1805.06605&#34;&gt;Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1707.07397&#34;&gt;Synthesizing Robust Adversarial Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.01991&#34;&gt;Mitigating adversarial effects through randomization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1702.04267&#34;&gt;On Detecting Adversarial Perturbations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1712.09665&#34;&gt;Adversarial Patch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.10766&#34;&gt;PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.08864&#34;&gt;One Pixel Attack for Fooling Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1707.06728&#34;&gt;Efficient Defenses Against Adversarial Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8578273&#34;&gt;Robust Physical-World Attacks on Deep Learning Visual Classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1606.04435&#34;&gt;Adversarial Perturbations Against Deep Neural Networks for Malware Classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.12146&#34;&gt;3D Adversarial Attacks Beyond Point Cloud&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.10596&#34;&gt;Adversarial Perturbations Fool Deepfake Detectors&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2002.12749&#34;&gt;Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to Adversarial Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1803.09156&#34;&gt;An Overview of Vulnerabilities of Voice Controlled Systems&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2002.00760&#34;&gt;FastWordBug: A Fast Method To Generate Adversarial Text Against NLP Applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.nassiben.com/phantoms&#34;&gt;Phantom of the ADAS: Securing Advanced Driver Assistance Systems from Split-Second Phantom Attacks&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Type&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Supported algorithms&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Supported attack types&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Attack/Defence&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Supported frameworks&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Popularity&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/cleverhans-lab/cleverhans&#34;&gt;Cleverhans&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Image&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Deep_learning&#34;&gt;Deep Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Evasion&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Attack&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.tensorflow.org&#34;&gt;Tensorflow&lt;/a&gt;, &lt;a href=&#34;https://keras.io&#34;&gt;Keras&lt;/a&gt;, &lt;a href=&#34;https://github.com/google/jax&#34;&gt;JAX&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/cleverhans-lab/cleverhans&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/cleverhans-lab/cleverhans&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/bethgelab/foolbox&#34;&gt;Foolbox&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Image&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Deep Learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Evasion&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Attack&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Tensorflow, &lt;a href=&#34;https://pytorch.org&#34;&gt;PyTorch&lt;/a&gt;, JAX&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bethgelab/foolbox&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/bethgelab/foolbox&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Trusted-AI/adversarial-robustness-toolbox&#34;&gt;ART&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Any type (image, tabular data, audio,...)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Deep Learning, &lt;a href=&#34;https://en.wikipedia.org/wiki/Support_vector_machine&#34;&gt;SVM&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_regression&#34;&gt;LR&lt;/a&gt;, etc.&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Any (extraction, inference, poisoning, evasion)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Both&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Tensorflow, Keras, Pytorch, &lt;a href=&#34;https://scikit-learn.org&#34;&gt;Scikit Learn&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Trusted-AI/adversarial-robustness-toolbox&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Trusted-AI/adversarial-robustness-toolbox&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/QData/TextAttack&#34;&gt;TextAttack&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Text&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Deep Learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Evasion&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Attack&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Keras, &lt;a href=&#34;https://huggingface.co/&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/QData/TextAttack&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/QData/TextAttack&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/BorealisAI/advertorch&#34;&gt;Advertorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Image&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Deep Learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Evasion&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Both&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;---&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/BorealisAI/advertorch&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/BorealisAI/advertorch&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/advboxes/AdvBox&#34;&gt;AdvBox&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Image&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Deep Learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Evasion&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Both&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;PyTorch, Tensorflow, &lt;a href=&#34;https://mxnet.apache.org&#34;&gt;MxNet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/advboxes/AdvBox&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/advboxes/AdvBox&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/DSE-MSU/DeepRobust&#34;&gt;DeepRobust&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Image, graph&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Deep Learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Evasion&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Both&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;PyTorch&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/DSE-MSU/DeepRobust&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/DSE-MSU/DeepRobust&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Azure/counterfit&#34;&gt;Counterfit&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Any&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Any&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Evasion&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Attack&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;---&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Azure/counterfit&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Azure/counterfit&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/carlini/audio_adversarial_examples&#34;&gt;Adversarial Audio Examples&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Audio&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/mozilla/DeepSpeech&#34;&gt;DeepSpeech&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Evasion&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Attack&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;---&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/carlini/audio_adversarial_examples&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/carlini/audio_adversarial_examples&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h6&gt;ART&lt;/h6&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Trusted-AI/adversarial-robustness-toolbox&#34;&gt;Adversarial Robustness Toolbox&lt;/a&gt;, abbreviated as ART, is an open-source Adversarial Machine Learning library for testing the robustness of machine learning models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/art.png&#34; alt=&#34;ART logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;It is developed in Python and implements extraction, inversion, poisoning and evasion attacks and defenses.&lt;/p&gt; &#xA;&lt;p&gt;ART supports the most popular frameworks: Tensorflow, Keras, PyTorch, MxNet, ScikitLearn, among many others.&lt;/p&gt; &#xA;&lt;p&gt;It is not limited to the use of models that use images as input, but also supports other types of data, such as audio, video, tabular data, etc.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/jiep/adversarial-machine-learning&#34;&gt;Workshop to learn Adversarial Machine Learning with ART ğŸ‡ªğŸ‡¸&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h6&gt;Cleverhans&lt;/h6&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/cleverhans-lab/cleverhans&#34;&gt;Cleverhans&lt;/a&gt; is a library for performing evasion attacks and testing the robustness of a deep learning model on image models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/assets/images/cleverhans.png&#34; alt=&#34;Cleverhans logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;It is developed in Python and integrates with the Tensorflow, Torch and JAX frameworks.&lt;/p&gt; &#xA;&lt;p&gt;It implements numerous attacks such as L-BFGS, FGSM, JSMA, C&amp;amp;W, among others.&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ”§ Use ğŸ”§&lt;/h2&gt; &#xA;&lt;p&gt;The use of AI to accomplish a malicious task and boost classic attacks.&lt;/p&gt; &#xA;&lt;h3&gt;ğŸ•µï¸â€â™‚ï¸ Pentesting ğŸ•µï¸â€â™‚ï¸&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gyoisamurai/GyoiThon&#34;&gt;GyoiThon&lt;/a&gt;: Next generation penetration test tool, intelligence gathering tool for web server. &lt;a href=&#34;https://github.com/gyoisamurai/GyoiThon&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/gyoisamurai/GyoiThon&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/DeepExploit&#34;&gt;Deep Exploit&lt;/a&gt;: Fully automatic penetration test tool using Deep Reinforcement Learning. &lt;a href=&#34;https://github.com/13o-bbr-bbq/machine_learning_security&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/13o-bbr-bbq/machine_learning_security&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crond-jaist/AutoPentest-DRL&#34;&gt;AutoPentest-DRL&lt;/a&gt;: Automated penetration testing using deep reinforcement learning. &lt;a href=&#34;https://github.com/crond-jaist/AutoPentest-DRL&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/crond-jaist/AutoPentest-DRL&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Generator&#34;&gt;DeepGenerator&lt;/a&gt;: Fully automatically generate injection codes for web application assessment using Genetic Algorithm and Generative Adversarial Networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BishopFox/eyeballer&#34;&gt;Eyeballer&lt;/a&gt;: Eyeballer is meant for large-scope network penetration tests where you need to find &#34;interesting&#34; targets from a huge set of web-based hosts. &lt;a href=&#34;https://github.com/BishopFox/eyeballer&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/BishopFox/eyeballer&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ğŸ¦  Malware ğŸ¦ &lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://i.blackhat.com/us-18/Thu-August-9/us-18-Kirat-DeepLocker-Concealing-Targeted-Attacks-with-AI-Locksmithing.pdf&#34;&gt;DeepLocker&lt;/a&gt;: Concealing targeted attacks with AI locksmithing, by IBM Labs on BH.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-031-17030-0_4&#34;&gt;An Overview of Artificial Intelligence Used in Malware&lt;/a&gt;: A curated list of AI Malware resources.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1909.01837&#34;&gt;DeepObfusCode&lt;/a&gt;: Source code obfuscation through sequence-to-sequence networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2208.08025&#34;&gt;AutoCAT&lt;/a&gt;: Reinforcement learning for automated exploration of cache-timing attacks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.02223&#34;&gt;AI-BASED BOTNET&lt;/a&gt;: A game-theoretic approach for AI-based botnet attack defence.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pralab/secml_malware&#34;&gt;SECML_Malware&lt;/a&gt;: Python library for creating adversarial attacks against Windows Malware detectors. &lt;a href=&#34;https://github.com/pralab/secml_malware&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/pralab/secml_malware&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ğŸ—ºï¸&amp;nbsp;OSINT ğŸ—ºï¸&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zerofox-oss/SNAP_R&#34;&gt;SNAP_R&lt;/a&gt;: Generate automatically spear-phishing posts on social media. &lt;a href=&#34;https://github.com/zerofox-oss/SNAP_R&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/zerofox-oss/SNAP_R&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/RuthGnz/SpyScrap&#34;&gt;SpyScrap&lt;/a&gt;: SpyScrap combines facial recognition methods to filter the results and uses natural language processing for obtaining important entities from the website the user appears. &lt;a href=&#34;https://github.com/RuthGnz/SpyScrap&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/RuthGnz/SpyScrap&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ğŸ“§&amp;nbsp;Phishing ğŸ“§&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/roreagan/DeepDGA&#34;&gt;DeepDGA&lt;/a&gt;: Implementation of DeepDGA: Adversarially-Tuned Domain Generation and Detection. &lt;a href=&#34;https://github.com/roreagan/DeepDGA&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/roreagan/DeepDGA&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ğŸ‘¨â€ğŸ¤ Generative AI ğŸ‘¨â€ğŸ¤&lt;/h3&gt; &#xA;&lt;h4&gt;ğŸ”Š Audio ğŸ”Š&lt;/h4&gt; &#xA;&lt;h5&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/andabi/deep-voice-conversion&#34;&gt;deep-voice-conversion&lt;/a&gt;: Deep neural networks for voice conversion (voice style transfer) in Tensorflow. &lt;a href=&#34;https://github.com/andabi/deep-voice-conversion&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/andabi/deep-voice-conversion&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34;&gt;tacotron&lt;/a&gt;: A TensorFlow implementation of Google&#39;s Tacotron speech synthesis with pre-trained model (unofficial). &lt;a href=&#34;https://github.com/keithito/tacotron&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/keithito/tacotron&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CorentinJ/Real-Time-Voice-Cloning&#34;&gt;Real-Time-Voice-Cloning&lt;/a&gt;: Clone a voice in 5 seconds to generate arbitrary speech in real-time. &lt;a href=&#34;https://github.com/CorentinJ/Real-Time-Voice-Cloning&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/CorentinJ/Real-Time-Voice-Cloning&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MycroftAI/mimic2&#34;&gt;mimic2&lt;/a&gt;: Text to Speech engine based on the Tacotron architecture, initially implemented by Keith Ito. &lt;a href=&#34;https://github.com/MycroftAI/mimic2&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/MycroftAI/mimic2&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Sharad24/Neural-Voice-Cloning-with-Few-Samples&#34;&gt;Neural-Voice-Cloning-with-Few-Samples&lt;/a&gt;: Implementation of Neural Voice Cloning with Few Samples Research Paper by Baidu. &lt;a href=&#34;https://github.com/Sharad24/Neural-Voice-Cloning-with-Few-Samples&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Sharad24/Neural-Voice-Cloning-with-Few-Samples&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/enhuiz/vall-e&#34;&gt;Vall-E&lt;/a&gt;: An unofficial PyTorch implementation of the audio LM VALL-E. &lt;a href=&#34;https://github.com/enhuiz/vall-e&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/enhuiz/vall-e&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸ’¡ Applications ğŸ’¡&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Rudrabha/Lip2Wav&#34;&gt;Lip2Wav&lt;/a&gt;: Generate high quality speech from only lip movements. &lt;a href=&#34;https://github.com/Rudrabha/Lip2Wav&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Rudrabha/Lip2Wav&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/haoheliu/audioldm-text-to-audio-generation&#34;&gt;AudioLDM: Text-to-Audio Generation with Latent Diffusion Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34;&gt;deepvoice3_pytorch&lt;/a&gt;: PyTorch implementation of convolutional neural networks-based text-to-speech synthesis models. &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/r9y9/deepvoice3_pytorch&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/riffusion/riffusion&#34;&gt;ğŸ¸ Riffusion&lt;/a&gt;: Stable diffusion for real-time music generation. &lt;a href=&#34;https://github.com/riffusion/riffusion&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/riffusion/riffusion&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggerganov/whisper.cpp&#34;&gt;whisper.cpp&lt;/a&gt;: Port of OpenAI&#39;s Whisper model in C/C++. &lt;a href=&#34;https://github.com/ggerganov/whisper.cpp&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/ggerganov/whisper.cpp&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/coqui-ai/TTS&#34;&gt;TTS&lt;/a&gt;: ğŸ¸ğŸ’¬ - a deep learning toolkit for Text-to-Speech, battle-tested in research and production. &lt;a href=&#34;https://github.com/coqui-ai/TTS&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/coqui-ai/TTS&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Edresson/YourTTS&#34;&gt;YourTTS&lt;/a&gt;: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone. &lt;a href=&#34;https://github.com/Edresson/YourTTS&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Edresson/YourTTS&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/neonbjb/tortoise-tts&#34;&gt;TorToiSe&lt;/a&gt;: A multi-voice TTS system trained with an emphasis on quality. &lt;a href=&#34;https://github.com/neonbjb/tortoise-tts&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/neonbjb/tortoise-tts&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MoonInTheRiver/DiffSinger&#34;&gt;DiffSinger&lt;/a&gt;: Singing Voice Synthesis via Shallow Diffusion Mechanism (SVS &amp;amp; TTS). &lt;a href=&#34;https://github.com/MoonInTheRiver/DiffSinger&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/MoonInTheRiver/DiffSinger&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/wavenet_vocoder&#34;&gt;WaveNet vocoder&lt;/a&gt;: Implementation of the WaveNet vocoder, which can generate high quality raw speech samples conditioned on linguistic or acoustic features. &lt;a href=&#34;https://github.com/r9y9/wavenet_vocoder&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/r9y9/wavenet_vocoder&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34;&gt;Deepvoice3_pytorch&lt;/a&gt;: PyTorch implementation of convolutional neural networks-based text-to-speech synthesis models. &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/r9y9/deepvoice3_pytorch&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/espeak-ng/espeak-ng&#34;&gt;eSpeak NG Text-to-Speech&lt;/a&gt;: eSpeak NG is an open source speech synthesizer that supports more than hundred languages and accents. &lt;a href=&#34;https://github.com/espeak-ng/espeak-ng&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/espeak-ng/espeak-ng&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://proceedings.neurips.cc/paper/2018/hash/4559912e7a94a9c32b09d894f2bc3c82-Abstract.html&#34;&gt;Neural Voice Cloning with a Few Samples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9246264&#34;&gt;NAUTILUS: A Versatile Voice Cloning System&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1907.04448&#34;&gt;Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/2810103.2813668&#34;&gt;When Good Becomes Evil: Keystroke Inference with Smartwatch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8737591&#34;&gt;KeyListener: Inferring Keystrokes on QWERTY Keyboard of Touch Screen through Acoustic Signals&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://this-voice-does-not-exist.com&#34;&gt;This Voice Does Not Exist: On Voice Synthesis, Audio Deepfakes and Their Detection&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸ” Detection ğŸ”&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dessa-oss/fake-voice-detection&#34;&gt;fake-voice-detection&lt;/a&gt;: Using temporal convolution to detect Audio Deepfakes. &lt;a href=&#34;https://github.com/dessa-oss/fake-voice-detection&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/dessa-oss/fake-voice-detection&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S1319157822000684&#34;&gt;A robust voice spoofing detection system using novel CLS-LBP features and LSTM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0957417422002330&#34;&gt;Voice spoofing detector: A unified anti-spoofing framework&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/8695320&#34;&gt;Securing Voice-Driven Interfaces Against Fake (Cloned) Audio Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3394171.3413716&#34;&gt;DeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake Voices&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.aes.org/e-lib/online/browse.cfm?elib=20479&#34;&gt;Fighting AI with AI: Fake Speech Detection Using Deep Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mdpi.com/1999-4893/15/5/155&#34;&gt;A Review of Modern Audio Deepfake Detection Methods: Challenges and Future Directions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;ğŸ“· Image ğŸ“·&lt;/h4&gt; &#xA;&lt;h5&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/stylegan&#34;&gt;StyleGAN&lt;/a&gt;: StyleGAN - Official TensorFlow Implementation. &lt;a href=&#34;https://github.com/NVlabs/stylegan&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/NVlabs/stylegan&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/stylegan2&#34;&gt;StyleGAN2&lt;/a&gt;: StyleGAN2 - Official TensorFlow Implementation. &lt;a href=&#34;https://github.com/NVlabs/stylegan2&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/NVlabs/stylegan2&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/stylegan2-ada-pytorch&#34;&gt;stylegan2-ada-pytorch&lt;/a&gt;: StyleGAN2-ADA - Official PyTorch implementation. &lt;a href=&#34;https://github.com/NVlabs/stylegan2-ada-pytorch&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/NVlabs/stylegan2-ada-pytorch&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rinongal/StyleGAN-nada&#34;&gt;StyleGAN-nada&lt;/a&gt;: CLIP-Guided Domain Adaptation of Image Generators. &lt;a href=&#34;https://github.com/rinongal/StyleGAN-nada&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/rinongal/StyleGAN-nada&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/stylegan3&#34;&gt;StyleGAN3&lt;/a&gt;: Official PyTorch implementation of StyleGAN3. &lt;a href=&#34;https://github.com/NVlabs/stylegan3&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/NVlabs/stylegan3&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/imaginaire&#34;&gt;Imaginaire&lt;/a&gt;: Imaginaire is a pytorch library that contains optimized implementation of several image and video synthesis methods developed at NVIDIA. &lt;a href=&#34;https://github.com/NVlabs/imaginaire&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/NVlabs/imaginaire&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/ffhq-dataset&#34;&gt;ffhq-dataset&lt;/a&gt;: Flickr-Faces-HQ Dataset (FFHQ). &lt;a href=&#34;https://github.com/NVlabs/ffhq-dataset&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/NVlabs/ffhq-dataset&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lucidrains/DALLE2-pytorch&#34;&gt;DALLE2-pytorch&lt;/a&gt;: Implementation of DALL-E 2, OpenAI&#39;s updated text-to-image synthesis neural network, in Pytorch. &lt;a href=&#34;https://github.com/lucidrains/DALLE2-pytorch&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/lucidrains/DALLE2-pytorch&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/brycedrennan/imaginAIry&#34;&gt;ImaginAIry&lt;/a&gt;: AI imagined images. Pythonic generation of stable diffusion images. &lt;a href=&#34;https://github.com/brycedrennan/imaginAIry&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/brycedrennan/imaginAIry&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Sanster/lama-cleaner&#34;&gt;Lama Cleaner&lt;/a&gt;: Image inpainting tool powered by SOTA AI Model. Remove any unwanted object, defect, people from your pictures or erase and replace(powered by stable diffusion) any thing on your pictures. &lt;a href=&#34;https://github.com/Sanster/lama-cleaner&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Sanster/lama-cleaner&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pkuxmq/Invertible-Image-Rescaling&#34;&gt;Invertible-Image-Rescaling&lt;/a&gt;: This is the PyTorch implementation of paper: Invertible Image Rescaling. &lt;a href=&#34;https://github.com/pkuxmq/Invertible-Image-Rescaling&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/pkuxmq/Invertible-Image-Rescaling&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zsyOAOA/DifFace&#34;&gt;DifFace&lt;/a&gt;: Blind Face Restoration with Diffused Error Contraction (PyTorch). &lt;a href=&#34;https://github.com/zsyOAOA/DifFace&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/zsyOAOA/DifFace&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sczhou/CodeFormer&#34;&gt;CodeFormer&lt;/a&gt;: Towards Robust Blind Face Restoration with Codebook Lookup Transformer. &lt;a href=&#34;https://github.com/sczhou/CodeFormer&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/sczhou/CodeFormer&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/adobe-research/custom-diffusion&#34;&gt;Custom Diffusion&lt;/a&gt;: Multi-Concept Customization of Text-to-Image Diffusion. &lt;a href=&#34;https://github.com/adobe-research/custom-diffusion&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/adobe-research/custom-diffusion&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;Diffusers&lt;/a&gt;: ğŸ¤— Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch. &lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/huggingface/diffusers&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Stability-AI/stablediffusion&#34;&gt;Stable Diffusion&lt;/a&gt;: High-Resolution Image Synthesis with Latent Diffusion Models. &lt;a href=&#34;https://github.com/Stability-AI/stablediffusion&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Stability-AI/stablediffusion&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/invoke-ai/InvokeAI&#34;&gt;InvokeAI&lt;/a&gt;: InvokeAI is a leading creative engine for Stable Diffusion models, empowering professionals, artists, and enthusiasts to generate and create visual media using the latest AI-driven technologies. The solution offers an industry leading WebUI, supports terminal use through a CLI, and serves as the foundation for multiple commercial products. &lt;a href=&#34;https://github.com/invoke-ai/InvokeAI&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/invoke-ai/InvokeAI&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;Stable Diffusion web UI&lt;/a&gt;: Stable Diffusion web UI. &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/AUTOMATIC1111/stable-diffusion-webui&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lkwq007/stablediffusion-infinity&#34;&gt;Stable Diffusion Infinity&lt;/a&gt;: Outpainting with Stable Diffusion on an infinite canvas. &lt;a href=&#34;https://github.com/lkwq007/stablediffusion-infinity&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/lkwq007/stablediffusion-infinity&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/TheLastBen/fast-stable-diffusion&#34;&gt;Fast Stable Diffusion&lt;/a&gt;: fast-stable-diffusion + DreamBooth. &lt;a href=&#34;https://github.com/TheLastBen/fast-stable-diffusion&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/TheLastBen/fast-stable-diffusion&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nv-tlabs/GET3D&#34;&gt;GET3D&lt;/a&gt;: A Generative Model of High Quality 3D Textured Shapes Learned from Images. &lt;a href=&#34;https://github.com/nv-tlabs/GET3D&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/nv-tlabs/GET3D&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/altryne/awesome-ai-art-image-synthesis&#34;&gt;Awesome AI Art Image Synthesis&lt;/a&gt;: A list of awesome tools, ideas, prompt engineering tools, colabs, models, and helpers for the prompt designer playing with aiArt and image synthesis. Covers Dalle2, MidJourney, StableDiffusion, and open source tools. &lt;a href=&#34;https://github.com/altryne/awesome-ai-art-image-synthesis&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/altryne/awesome-ai-art-image-synthesis&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;: A latent text-to-image diffusion model. &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/CompVis/stable-diffusion&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/IGITUGraz/WeatherDiffusion&#34;&gt;Weather Diffusion&lt;/a&gt;: Code for &#34;Restoring Vision in Adverse Weather Conditions with Patch-Based Denoising Diffusion Models&#34;. &lt;a href=&#34;https://github.com/IGITUGraz/WeatherDiffusion&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/IGITUGraz/WeatherDiffusion&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tobran/DF-GAN&#34;&gt;DF-GAN&lt;/a&gt;: A Simple and Effective Baseline for Text-to-Image Synthesis. &lt;a href=&#34;https://github.com/tobran/DF-GAN&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/tobran/DF-GAN&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/saharmor/dalle-playground&#34;&gt;Dall-E Playground&lt;/a&gt;: A playground to generate images from any text prompt using Stable Diffusion (past: using DALL-E Mini). &lt;a href=&#34;https://github.com/saharmor/dalle-playground&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/saharmor/dalle-playground&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/IIGROUP/MM-CelebA-HQ-Dataset&#34;&gt;MM-CelebA-HQ-Dataset&lt;/a&gt;: A large-scale face image dataset that allows text-to-image generation, text-guided image manipulation, sketch-to-image generation, GANs for face generation and editing, image caption, and VQA. &lt;a href=&#34;https://github.com/IIGROUP/MM-CelebA-HQ-Dataset&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/IIGROUP/MM-CelebA-HQ-Dataset&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lucidrains/deep-daze&#34;&gt;Deep Daze&lt;/a&gt;: Simple command line tool for text to image generation using OpenAI&#39;s CLIP and Siren (Implicit neural representation network). &lt;a href=&#34;https://github.com/lucidrains/deep-daze&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/lucidrains/deep-daze&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naver-ai/StyleMapGAN&#34;&gt;StyleMapGAN&lt;/a&gt;: Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing. &lt;a href=&#34;https://github.com/naver-ai/StyleMapGAN&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/naver-ai/StyleMapGAN&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸ’¡ Applications ğŸ’¡&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vijishmadhavan/ArtLine&#34;&gt;ArtLine&lt;/a&gt;: A Deep Learning based project for creating line art portraits. &lt;a href=&#34;https://github.com/vijishmadhavan/ArtLine&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/vijishmadhavan/ArtLine&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/beurtschipper/Depix&#34;&gt;Depix&lt;/a&gt;: Recovers passwords from pixelized screenshots. &lt;a href=&#34;https://github.com/beurtschipper/Depix&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/beurtschipper/Depix&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life&#34;&gt;Bringing Old Photos Back to Life&lt;/a&gt;: Old Photo Restoration (Official PyTorch Implementation). &lt;a href=&#34;https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/microsoft/Bringing-Old-Photos-Back-to-Life&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/davidbau/rewriting&#34;&gt;Rewriting&lt;/a&gt;: Interactive tool to directly edit the rules of a GAN to synthesize scenes with objects added, removed, or altered. Change StyleGANv2 to make extravagant eyebrows, or horses wearing hats. &lt;a href=&#34;https://github.com/davidbau/rewriting&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/davidbau/rewriting&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Shawn-Shan/fawkes&#34;&gt;Fawkes&lt;/a&gt;: Privacy preserving tool against facial recognition systems. &lt;a href=&#34;https://github.com/Shawn-Shan/fawkes&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Shawn-Shan/fawkes&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/adamian98/pulse&#34;&gt;Pulse&lt;/a&gt;: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models. &lt;a href=&#34;https://github.com/adamian98/pulse&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/adamian98/pulse&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/saic-mdal/HiDT&#34;&gt;HiDT&lt;/a&gt;: Official repository for the paper &#34;High-Resolution Daytime Translation Without Domain Labels&#34;. &lt;a href=&#34;https://github.com/saic-mdal/HiDT&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/saic-mdal/HiDT&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vt-vl-lab/3d-photo-inpainting&#34;&gt;3D Photo Inpainting&lt;/a&gt;: 3D Photography using Context-aware Layered Depth Inpainting. &lt;a href=&#34;https://github.com/vt-vl-lab/3d-photo-inpainting&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/vt-vl-lab/3d-photo-inpainting&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DAI-Lab/SteganoGAN&#34;&gt;SteganoGAN&lt;/a&gt;: SteganoGAN is a tool for creating steganographic images using adversarial training. &lt;a href=&#34;https://github.com/DAI-Lab/SteganoGAN&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/DAI-Lab/SteganoGAN&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/autonomousvision/stylegan-t&#34;&gt;Stylegan-T&lt;/a&gt;: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis. &lt;a href=&#34;https://github.com/autonomousvision/stylegan-t&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/autonomousvision/stylegan-t&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/SamsungLabs/MegaPortraits&#34;&gt;MegaPortraits&lt;/a&gt;: One-shot Megapixel Neural Head Avatars. &lt;a href=&#34;https://github.com/SamsungLabs/MegaPortraits&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/SamsungLabs/MegaPortraits&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/eg3d&#34;&gt;eg3d&lt;/a&gt;: Efficient Geometry-aware 3D Generative Adversarial Networks. &lt;a href=&#34;https://github.com/NVlabs/eg3d&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/NVlabs/eg3d&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/IIGROUP/TediGAN&#34;&gt;TediGAN&lt;/a&gt;: Pytorch implementation for TediGAN: Text-Guided Diverse Face Image Generation and Manipulation. &lt;a href=&#34;https://github.com/IIGROUP/TediGAN&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/IIGROUP/TediGAN&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lucidrains/DALLE-pytorch&#34;&gt;DALLE-pytorch&lt;/a&gt;: Implementation / replication of DALL-E, OpenAI&#39;s Text to Image Transformer, in Pytorch. &lt;a href=&#34;https://github.com/lucidrains/DALLE-pytorch&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/lucidrains/DALLE-pytorch&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/StyleNeRF&#34;&gt;StyleNeRF&lt;/a&gt;: This is the open source implementation of the ICLR2022 paper &#34;StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis&#34;. &lt;a href=&#34;https://github.com/facebookresearch/StyleNeRF&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/facebookresearch/StyleNeRF&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/alexandre01/deepsvg&#34;&gt;DeepSVG&lt;/a&gt;: Official code for the paper &#34;DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation&#34;. Includes a PyTorch library for deep learning with SVG data. &lt;a href=&#34;https://github.com/alexandre01/deepsvg&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/alexandre01/deepsvg&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/NUWA&#34;&gt;NUWA&lt;/a&gt;: A unified 3D Transformer Pipeline for visual synthesis. &lt;a href=&#34;https://github.com/microsoft/NUWA&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/microsoft/NUWA&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement&#34;&gt;Image-Super-Resolution-via-Iterative-Refinement&lt;/a&gt;: Unofficial implementation of Image Super-Resolution via Iterative Refinement by Pytorch. &lt;a href=&#34;https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Janspiry/Image-Super-Resolution-via-Iterative-Refinement&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/saic-mdal/lama&#34;&gt;Lama&lt;/a&gt;: ğŸ¦™ LaMa Image Inpainting, Resolution-robust Large Mask Inpainting with Fourier Convolutions. &lt;a href=&#34;https://github.com/saic-mdal/lama&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/saic-mdal/lama&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/layumi/Person_reID_baseline_pytorch&#34;&gt;Person_reID_baseline_pytorch&lt;/a&gt;: Pytorch ReID: A tiny, friendly, strong pytorch implement of object re-identification baseline. &lt;a href=&#34;https://github.com/layumi/Person_reID_baseline_pytorch&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/layumi/Person_reID_baseline_pytorch&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/timothybrooks/instruct-pix2pix&#34;&gt;instruct-pix2pix&lt;/a&gt;: PyTorch implementation of InstructPix2Pix, an instruction-based image editing model. &lt;a href=&#34;https://github.com/timothybrooks/instruct-pix2pix&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/timothybrooks/instruct-pix2pix&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/TencentARC/GFPGAN&#34;&gt;GFPGAN&lt;/a&gt;: GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration. &lt;a href=&#34;https://github.com/TencentARC/GFPGAN&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/TencentARC/GFPGAN&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yizhiwang96/deepvecfont&#34;&gt;DeepVecFont&lt;/a&gt;: Synthesizing High-quality Vector Fonts via Dual-modality Learning. &lt;a href=&#34;https://github.com/yizhiwang96/deepvecfont&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/yizhiwang96/deepvecfont&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/clovaai/stargan-v2-tensorflow&#34;&gt;Stargan v2 Tensorflow&lt;/a&gt;: Official Tensorflow Implementation. &lt;a href=&#34;https://github.com/clovaai/stargan-v2-tensorflow&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/clovaai/stargan-v2-tensorflow&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/EvgenyKashin/stylegan2-distillation&#34;&gt;StyleGAN2 Distillation&lt;/a&gt;: Paired image-to-image translation, trained on synthetic data generated by StyleGAN2 outperforms existing approaches in image manipulation. &lt;a href=&#34;https://github.com/EvgenyKashin/stylegan2-distillation&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/EvgenyKashin/stylegan2-distillation&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.13188&#34;&gt;Extracting Training Data from Diffusion Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencognitives.com/mann-e&#34;&gt;Mann-E - Mann-E (Persian: Ù…Ø§Ù†ÛŒ) is an art generator model based on the weights of Stable Diffusion 1.5 and data gathered from artistic material available on Pinterest&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.07201&#34;&gt;End-to-end Trained CNN Encode-Decoder Networks for Image Steganography&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸ” Detection ğŸ”&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/stylegan3-detector&#34;&gt;stylegan3-detector&lt;/a&gt;: StyleGAN3 Synthetic Image Detection. &lt;a href=&#34;https://github.com/NVlabs/stylegan3-detector&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/NVlabs/stylegan3-detector&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/woctezuma/stylegan2-projecting-images&#34;&gt;stylegan2-projecting-images&lt;/a&gt;: Projecting images to latent space with StyleGAN2. &lt;a href=&#34;https://github.com/woctezuma/stylegan2-projecting-images&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/woctezuma/stylegan2-projecting-images&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PeterWang512/FALdetector&#34;&gt;FALdetector&lt;/a&gt;: Detecting Photoshopped Faces by Scripting Photoshop. &lt;a href=&#34;https://github.com/PeterWang512/FALdetector&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/PeterWang512/FALdetector&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;ğŸ¥ Video ğŸ¥&lt;/h4&gt; &#xA;&lt;h5&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/iperov/DeepFaceLab&#34;&gt;DeepFaceLab&lt;/a&gt;: DeepFaceLab is the leading software for creating deepfakes. &lt;a href=&#34;https://github.com/iperov/DeepFaceLab&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/iperov/DeepFaceLab&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepfakes/faceswap&#34;&gt;faceswap&lt;/a&gt;: Deepfakes Software For All. &lt;a href=&#34;https://github.com/deepfakes/faceswap&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/deepfakes/faceswap&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sensity-ai/dot&#34;&gt;dot&lt;/a&gt;: The Deepfake Offensive Toolkit. &lt;a href=&#34;https://github.com/sensity-ai/dot&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/sensity-ai/dot&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/neuralchen/SimSwap&#34;&gt;SimSwap&lt;/a&gt;: An arbitrary face-swapping framework on images and videos with one single trained model! &lt;a href=&#34;https://github.com/neuralchen/SimSwap&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/neuralchen/SimSwap&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/shaoanlu/faceswap-GAN&#34;&gt;faceswap-GAN&lt;/a&gt;: A denoising autoencoder + adversarial losses and attention mechanisms for face swapping. &lt;a href=&#34;https://github.com/shaoanlu/faceswap-GAN&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/shaoanlu/faceswap-GAN&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yuezunli/celeb-deepfakeforensics&#34;&gt;Celeb DeepFakeForensics&lt;/a&gt;: A Large-scale Challenging Dataset for DeepFake Forensics. &lt;a href=&#34;https://github.com/yuezunli/celeb-deepfakeforensics&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/yuezunli/celeb-deepfakeforensics&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸ’¡ Applications ğŸ’¡&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/datitran/face2face-demo&#34;&gt;face2face-demo&lt;/a&gt;: pix2pix demo that learns from facial landmarks and translates this into a face. &lt;a href=&#34;https://github.com/datitran/face2face-demo&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/datitran/face2face-demo&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Oldpan/Faceswap-Deepfake-Pytorch&#34;&gt;Faceswap-Deepfake-Pytorch&lt;/a&gt;: Faceswap with Pytorch or DeepFake with Pytorch. &lt;a href=&#34;https://github.com/Oldpan/Faceswap-Deepfake-Pytorch&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Oldpan/Faceswap-Deepfake-Pytorch&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/point-e&#34;&gt;Point-E&lt;/a&gt;: Point cloud diffusion for 3D model synthesis. &lt;a href=&#34;https://github.com/openai/point-e&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/openai/point-e&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Thmen/EGVSR&#34;&gt;EGVSR&lt;/a&gt;: Efficient &amp;amp; Generic Video Super-Resolution. &lt;a href=&#34;https://github.com/Thmen/EGVSR&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Thmen/EGVSR&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rotemtzaban/STIT&#34;&gt;STIT&lt;/a&gt;: Stitch it in Time: GAN-Based Facial Editing of Real Videos. &lt;a href=&#34;https://github.com/rotemtzaban/STIT&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/rotemtzaban/STIT&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PeterL1n/BackgroundMattingV2&#34;&gt;BackgroundMattingV2&lt;/a&gt;: Real-Time High-Resolution Background Matting. &lt;a href=&#34;https://github.com/PeterL1n/BackgroundMattingV2&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/PeterL1n/BackgroundMattingV2&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ZHKKKe/MODNet&#34;&gt;MODNet&lt;/a&gt;: A Trimap-Free Portrait Matting Solution in Real Time. &lt;a href=&#34;https://github.com/ZHKKKe/MODNet&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/ZHKKKe/MODNet&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/senguptaumd/Background-Matting&#34;&gt;Background-Matting&lt;/a&gt;: Background Matting: The World is Your Green Screen. &lt;a href=&#34;https://github.com/senguptaumd/Background-Matting&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/senguptaumd/Background-Matting&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AliaksandrSiarohin/first-order-model&#34;&gt;First Order Model&lt;/a&gt;: This repository contains the source code for the paper First Order Motion Model for Image Animation. &lt;a href=&#34;https://github.com/AliaksandrSiarohin/first-order-model&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/AliaksandrSiarohin/first-order-model&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/snap-research/articulated-animation&#34;&gt;Articulated Animation&lt;/a&gt;: This repository contains the source code for the CVPR&#39;2021 paper Motion Representations for Articulated Animation. &lt;a href=&#34;https://github.com/snap-research/articulated-animation&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/snap-research/articulated-animation&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasonmayes/Real-Time-Person-Removal&#34;&gt;Real Time Person Removal&lt;/a&gt;: Removing people from complex backgrounds in real time using TensorFlow.js in the web browser. &lt;a href=&#34;https://github.com/jasonmayes/Real-Time-Person-Removal&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/jasonmayes/Real-Time-Person-Removal&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xunhuang1995/AdaIN-style&#34;&gt;AdaIN-style&lt;/a&gt;: Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization. &lt;a href=&#34;https://github.com/xunhuang1995/AdaIN-style&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/xunhuang1995/AdaIN-style&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/google-research/frame-interpolation&#34;&gt;Frame Interpolation&lt;/a&gt;: Frame Interpolation for Large Motion. &lt;a href=&#34;https://github.com/google-research/frame-interpolation&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/google-research/frame-interpolation&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MarkMoHR/Awesome-Image-Colorization&#34;&gt;Awesome-Image-Colorization&lt;/a&gt;: ğŸ“š A collection of Deep Learning based Image Colorization and Video Colorization papers. &lt;a href=&#34;https://github.com/MarkMoHR/Awesome-Image-Colorization&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/MarkMoHR/Awesome-Image-Colorization&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸ” Detection ğŸ”&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ondyari/FaceForensics&#34;&gt;FaceForensics++&lt;/a&gt;: FaceForensics dataset. &lt;a href=&#34;https://github.com/ondyari/FaceForensics&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/ondyari/FaceForensics&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dessa-oss/DeepFake-Detection&#34;&gt;DeepFake-Detection&lt;/a&gt;: Towards deepfake detection that actually works. &lt;a href=&#34;https://github.com/dessa-oss/DeepFake-Detection&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/dessa-oss/DeepFake-Detection&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bbvanexttechnologies/fakeVideoForensics&#34;&gt;fakeVideoForensics&lt;/a&gt;: Detect deep fakes videos. &lt;a href=&#34;https://github.com/bbvanexttechnologies/fakeVideoForensics&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/bbvanexttechnologies/fakeVideoForensics&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/HongguLiu/Deepfake-Detection&#34;&gt;Deepfake-Detection&lt;/a&gt;: The Pytorch implemention of Deepfake Detection based on Faceforensics++. &lt;a href=&#34;https://github.com/HongguLiu/Deepfake-Detection&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/HongguLiu/Deepfake-Detection&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rshaojimmy/SeqDeepFake&#34;&gt;SeqDeepFake&lt;/a&gt;: PyTorch code for SeqDeepFake: Detecting and Recovering Sequential DeepFake Manipulation. &lt;a href=&#34;https://github.com/rshaojimmy/SeqDeepFake&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/rshaojimmy/SeqDeepFake&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jtchen0528/PCL-I2G&#34;&gt;PCL-I2G&lt;/a&gt;: Unofficial Implementation: Learning Self-Consistency for Deepfake Detection. &lt;a href=&#34;https://github.com/jtchen0528/PCL-I2G&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/jtchen0528/PCL-I2G&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepware/deepfake-scanner&#34;&gt;Deepfake Scanner&lt;/a&gt;: Deepfake Scanner by Deepware. &lt;a href=&#34;https://github.com/deepware/deepfake-scanner&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/deepware/deepfake-scanner&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/selimsef/dfdc_deepfake_challenge&#34;&gt;DFDC DeepFake Challenge&lt;/a&gt;: A prize winning solution for DFDC challenge. &lt;a href=&#34;https://github.com/selimsef/dfdc_deepfake_challenge&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/selimsef/dfdc_deepfake_challenge&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;ğŸ“„ Text ğŸ“„&lt;/h4&gt; &#xA;&lt;h5&gt;ğŸ› ï¸ Tools ğŸ› ï¸&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/THUDM/GLM-130B&#34;&gt;GLM-130B&lt;/a&gt;: An Open Bilingual Pre-Trained Model. &lt;a href=&#34;https://github.com/THUDM/GLM-130B&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/THUDM/GLM-130B&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/daveshap/LongtermChatExternalSources&#34;&gt;LongtermChatExternalSources&lt;/a&gt;: GPT-3 chatbot with long-term memory and external sources. &lt;a href=&#34;https://github.com/daveshap/LongtermChatExternalSources&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/daveshap/LongtermChatExternalSources&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/approximatelabs/sketch&#34;&gt;sketch&lt;/a&gt;: AI code-writing assistant that understands data content. &lt;a href=&#34;https://github.com/approximatelabs/sketch&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/approximatelabs/sketch&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;: âš¡ Building applications with LLMs through composability âš¡. &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/hwchase17/langchain&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mmabrouk/chatgpt-wrapper&#34;&gt;ChatGPT Wrapper&lt;/a&gt;: API for interacting with ChatGPT using Python and from Shell. &lt;a href=&#34;https://github.com/mmabrouk/chatgpt-wrapper&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/mmabrouk/chatgpt-wrapper&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/openai-python&#34;&gt;openai-python&lt;/a&gt;: The OpenAI Python library provides convenient access to the OpenAI API from applications written in the Python language. &lt;a href=&#34;https://github.com/openai/openai-python&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/openai/openai-python&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dccuchile/beto&#34;&gt;Beto&lt;/a&gt;: Spanish version of the BERT model. &lt;a href=&#34;https://github.com/dccuchile/beto&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/dccuchile/beto&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CodedotAl/gpt-code-clippy&#34;&gt;GPT-Code-Clippy&lt;/a&gt;: GPT-Code-Clippy (GPT-CC) is an open source version of GitHub Copilot, a language model -- based on GPT-3, called GPT-Codex. &lt;a href=&#34;https://github.com/CodedotAl/gpt-code-clippy&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/CodedotAl/gpt-code-clippy&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/EleutherAI/gpt-neo&#34;&gt;GPT Neo&lt;/a&gt;: An implementation of model parallel GPT-2 and GPT-3-style models using the mesh-tensorflow library. &lt;a href=&#34;https://github.com/EleutherAI/gpt-neo&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/EleutherAI/gpt-neo&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/salesforce/ctrl&#34;&gt;ctrl&lt;/a&gt;: Conditional Transformer Language Model for Controllable Generation. &lt;a href=&#34;https://github.com/salesforce/ctrl&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/salesforce/ctrl&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;Llama&lt;/a&gt;: Inference code for LLaMA models. &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/facebookresearch/llama&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.googleblog.com/2022/10/ul2-20b-open-source-unified-language.html&#34;&gt;UL2 20B&lt;/a&gt;: An Open Source Unified Language Learner&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸ” Detection ğŸ”&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/HendrikStrobelt/detecting-fake-text&#34;&gt;Detecting Fake Text&lt;/a&gt;: Giant Language Model Test Room. &lt;a href=&#34;https://github.com/HendrikStrobelt/detecting-fake-text&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/HendrikStrobelt/detecting-fake-text&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rowanz/grover&#34;&gt;Grover&lt;/a&gt;: Code for Defending Against Neural Fake News. &lt;a href=&#34;https://github.com/rowanz/grover&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/rowanz/grover&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text/&#34;&gt;New AI classifier for indicating AI-written text&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/@itamargolan/uncover-the-four-enchanted-ways-to-identify-ai-generated-text-including-chatgpts-4764847fd609&#34;&gt;Discover the 4 Magical Methods to Detect AI-Generated Text (including ChatGPT)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gptzero.me&#34;&gt;GPTZero&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.10226&#34;&gt;A Watermark for Large Language Models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;ğŸ’¡ Applications ğŸ’¡&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/builtree/handwrite&#34;&gt;handwrite&lt;/a&gt;: Handwrite generates a custom font based on your handwriting sample. &lt;a href=&#34;https://github.com/builtree/handwrite&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/builtree/handwrite&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/shreyashankar/gpt3-sandbox&#34;&gt;GPT Sandbox&lt;/a&gt;: The goal of this project is to enable users to create cool web demos using the newly released OpenAI GPT-3 API with just a few lines of Python. &lt;a href=&#34;https://github.com/shreyashankar/gpt3-sandbox&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/shreyashankar/gpt3-sandbox&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/brannondorsey/PassGAN&#34;&gt;PassGAN&lt;/a&gt;: A Deep Learning Approach for Password Guessing. &lt;a href=&#34;https://github.com/brannondorsey/PassGAN&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/brannondorsey/PassGAN&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jerryjliu/gpt_index&#34;&gt;GPT Index&lt;/a&gt;: GPT Index is a project consisting of a set of data structures designed to make it easier to use large external knowledge bases with LLMs. &lt;a href=&#34;https://github.com/jerryjliu/gpt_index&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/jerryjliu/gpt_index&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/karpathy/nanoGPT&#34;&gt;nanoGPT&lt;/a&gt;: The simplest, fastest repository for training/finetuning medium-sized GPTs. &lt;a href=&#34;https://github.com/karpathy/nanoGPT&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/karpathy/nanoGPT&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/danielgross/whatsapp-gpt&#34;&gt;whatsapp-gpt&lt;/a&gt; &lt;a href=&#34;https://github.com/danielgross/whatsapp-gpt&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/danielgross/whatsapp-gpt&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gragland/chatgpt-chrome-extension&#34;&gt;ChatGPT Chrome Extension&lt;/a&gt;: A ChatGPT Chrome extension. Integrates ChatGPT into every text box on the internet.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/unilm&#34;&gt;Unilm&lt;/a&gt;: Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities. &lt;a href=&#34;https://github.com/microsoft/unilm&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/microsoft/unilm&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/karpathy/minGPT&#34;&gt;minGPT&lt;/a&gt;: A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training. &lt;a href=&#34;https://github.com/karpathy/minGPT&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/karpathy/minGPT&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/THUDM/CodeGeeX&#34;&gt;CodeGeeX&lt;/a&gt;: An Open Multilingual Code Generation Model. &lt;a href=&#34;https://github.com/THUDM/CodeGeeX&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/THUDM/CodeGeeX&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook&#34;&gt;OpenAI Cookbook&lt;/a&gt;: Examples and guides for using the OpenAI API. &lt;a href=&#34;https://github.com/openai/openai-cookbook&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/openai/openai-cookbook&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/f/awesome-chatgpt-prompts&#34;&gt;ğŸ§  Awesome ChatGPT Prompts&lt;/a&gt;: This repo includes ChatGPT prompt curation to use ChatGPT better. &lt;a href=&#34;https://github.com/f/awesome-chatgpt-prompts&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/f/awesome-chatgpt-prompts&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/greshake/Alice&#34;&gt;Alice&lt;/a&gt;: Giving ChatGPT access to a real terminal. &lt;a href=&#34;https://github.com/greshake/Alice&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/greshake/Alice&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://research.nccgroup.com/2023/02/09/security-code-review-with-chatgpt&#34;&gt;Security Code Review With ChatGPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.03622&#34;&gt;Do Users Write More Insecure Code with AI Assistants?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://neelc.org/posts/chatgpt-gmail-spam&#34;&gt;Bypassing Gmail&#39;s spam filters with ChatGPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mdpi.com/1999-4893/15/5/155&#34;&gt;Recurrent GANs Password Cracker For IoT Password Security Enhancement&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ğŸ“š Misc ğŸ“š&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Limmen/awesome-rl-for-cybersecurity&#34;&gt;ğŸš€ Awesome Reinforcement Learning for Cyber Security&lt;/a&gt;: A curated list of resources dedicated to reinforcement learning applied to cyber security. &lt;a href=&#34;https://github.com/Limmen/awesome-rl-for-cybersecurity&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/Limmen/awesome-rl-for-cybersecurity&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jivoi/awesome-ml-for-cybersecurity&#34;&gt;Awesome Machine Learning for Cyber Security&lt;/a&gt;: A curated list of amazingly awesome tools and resources related to the use of machine learning for cyber security. &lt;a href=&#34;https://github.com/jivoi/awesome-ml-for-cybersecurity&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/jivoi/awesome-ml-for-cybersecurity&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/diffusion-models-class&#34;&gt;Hugging Face Diffusion Models Course&lt;/a&gt;: Materials for the Hugging Face Diffusion Models Course. &lt;a href=&#34;https://github.com/huggingface/diffusion-models-class&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/huggingface/diffusion-models-class&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DeepSpaceHarbor/Awesome-AI-Security&#34;&gt;Awesome-AI-Security&lt;/a&gt;: A curated list of AI security resources. &lt;a href=&#34;https://github.com/DeepSpaceHarbor/Awesome-AI-Security&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/DeepSpaceHarbor/Awesome-AI-Security&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/johnmyleswhite/ML_for_Hackers&#34;&gt;ML for Hackers&lt;/a&gt;: Code accompanying the book &#34;Machine Learning for Hackers&#34;. &lt;a href=&#34;https://github.com/johnmyleswhite/ML_for_Hackers&#34;&gt;&lt;img src=&#34;https://badgen.net/github/stars/johnmyleswhite/ML_for_Hackers&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pages.nist.gov/AIRMF&#34;&gt;NIST AI Risk Management Framework Playbook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2208.10605&#34;&gt;SoK: Explainable Machine Learning for Computer Security Applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.06008&#34;&gt;Who Evaluates the Evaluators? On Automatic Metrics for Assessing AI-based Offensive Code Generators&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.11182&#34;&gt;Vulnerability Prioritization: An Offensive Security Approach&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atlas.mitre.org&#34;&gt;MITRE ATLASâ„¢&lt;/a&gt; (Adversarial Threat Landscape for Artificial-Intelligence Systems)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.06123&#34;&gt;A Survey on Reinforcement Learning Security with Application to Autonomous Driving&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.02497&#34;&gt;How to avoid machine learning pitfalls: a guide for academic researchers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ZhengyuZhao/AI-Security-and-Privacy-Events&#34;&gt;A curated list of AI Security &amp;amp; Privacy events&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.ipd.pdf&#34;&gt;NIST AI 100-2e2023 ipd&lt;/a&gt;: Adversarial Machine Learning. A Taxonomy and Terminology of Attacks and Mitigations.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ“Š Surveys ğŸ“Š&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.15764&#34;&gt;The Threat of Offensive AI to Organizations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mdpi.com/2073-8994/12/3/410&#34;&gt;Artificial Intelligence in the Cyber Domain: Offense and Defense&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12028&#34;&gt;A survey on adversarial attacks and defences&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/9895425&#34;&gt;Adversarial Deep Learning: A Survey on Adversarial Attacks and Defense Mechanisms on Image Classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.07646&#34;&gt;A Survey of Privacy Attacks in Machine Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1911.12562&#34;&gt;Towards Security Threats of Deep Learning Systems: A Survey&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8290925&#34;&gt;A Survey on Security Threats and Defensive Techniques of Machine Learning: A Data Driven View&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/8406613&#34;&gt;SoK: Security and Privacy in Machine Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4155496&#34;&gt;Adversarial Machine Learning: The Rise in AI-Enabled Crime and its Role in Spam Filter Evasion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.07474&#34;&gt;Threats, Vulnerabilities, and Controls of Machine Learning Based Systems: A Survey and Taxonomy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1810.00069.pdf&#34;&gt;Adversarial Attacks and Defences: A Survey&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1810.07339&#34;&gt;Security Matters: A Survey on Adversarial Machine Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2111.08223.pdf&#34;&gt;A Survey on Adversarial Attacks for Malware Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2009.03728.pdf&#34;&gt;Adversarial Machine Learning in Image Classification: A Survey Towards the Defenderâ€™s Perspective&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.14046&#34;&gt;A Survey of Robust Adversarial Training in Pattern Recognition: Fundamental, Theory, and Methodologies&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ—£ Contributors ğŸ—£&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Miguel000&#34;&gt;&lt;img src=&#34;https://avatars2.githubusercontent.com/u/13256426?s=460&amp;amp;v=4&#34; width=&#34;150;&#34; alt=&#34;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Miguel HernÃ¡ndez&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/jiep&#34;&gt;&lt;img src=&#34;https://avatars2.githubusercontent.com/u/414463?s=460&amp;amp;v=4&#34; width=&#34;150px;&#34; alt=&#34;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;JosÃ© Ignacio Escribano&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Â©ï¸ License Â©ï¸&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-CC%20BY--SA%204.0-lightgrey.svg?sanitize=true&#34; alt=&#34;License: CC BY-SA 4.0&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jiep/offensive-ai-compilation/main/LICENSE.txt&#34;&gt;Creative Commons Attribution Share Alike 4.0 International&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Slope-Game/Slope-Game.github.io</title>
    <updated>2023-03-23T01:36:06Z</updated>
    <id>tag:github.com,2023-03-23:/Slope-Game/Slope-Game.github.io</id>
    <link href="https://github.com/Slope-Game/Slope-Game.github.io" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Slope Game Unblocked&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
</feed>