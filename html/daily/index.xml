<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-16T01:34:58Z</updated>
  <subtitle>Daily Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>thunlp/WebCPM</title>
    <updated>2023-05-16T01:34:58Z</updated>
    <id>tag:github.com,2023-05-16:/thunlp/WebCPM</id>
    <link href="https://github.com/thunlp/WebCPM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official codes for ACL 2023 paper &#34;WebCPM: Interactive Web Search for Chinese Long-form Question Answering&#34;&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;WebCPM&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;✨ This is the implementation of ACL 2023 paper &lt;a href=&#34;https://arxiv.org/abs/2305.06849&#34;&gt;Interactive Web Search for Chinese Long-form Question Answering&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/assets/paper.png&#34; alt=&#34;paper&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Read this in &lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/README_zh.md&#34;&gt;中文&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Quick links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#quick-links&#34;&gt;Quick links&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#preparation&#34;&gt;Preparation&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#prepare-the-data&#34;&gt;Prepare the Data&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#prepare-the-model&#34;&gt;Prepare the model&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#train-webcpm&#34;&gt;Train WebCPM&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#a-brief-introduction-of-pipeline-based-web-search&#34;&gt;A brief Introduction of Pipeline-based Web Search&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#data-preprocessing&#34;&gt;Data Preprocessing&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#training-data-generation-of-interactive-web-search&#34;&gt;Training Data Generation of Interactive Web Search&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#training-data-generation-of-pipeline-based-web-search&#34;&gt;Training Data Generation of Pipeline-based Web Search&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#training&#34;&gt;Training&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#single-task-evaluation&#34;&gt;Single-task Evaluation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#run-webcpm-for-new-questions&#34;&gt;Run WebCPM for New Questions&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#interactive-web-search&#34;&gt;Interactive Web Search&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#pipeline-based-web-search&#34;&gt;Pipeline-based Web Search&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#platform-building-for-data-annotation&#34;&gt;Platform Building for Data Annotation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#bugs-or-questions&#34;&gt;Bugs or questions?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#resources-of-tool-learning&#34;&gt;Resources of Tool Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/#citation&#34;&gt;Citation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/assets/platform.png&#34; alt=&#34;platform&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;In this work we present WebCPM, a project for interactive Web search using Chinese Pre-trained Models. We develop a web search interface which both humans and collect human web search behaviors. Then we fine-tune PLMs with up to 10B parameters to imitate human behaviors of web search and to generate answers based on the collected facts. We open source the web search interface, dataset, implementation, and model parameters.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;To run our code, please install all the dependency packages by using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Different versions of packages (e.g., &lt;code&gt;pytorch&lt;/code&gt;) may lead to different results from the paper. However, the trend should still hold no matter what versions of packages you use.&lt;/p&gt; &#xA;&lt;h2&gt;Preparation&lt;/h2&gt; &#xA;&lt;h3&gt;Prepare the Data&lt;/h3&gt; &#xA;&lt;p&gt;First download the data from &lt;a href=&#34;https://drive.google.com/drive/folders/1IQBOCwhcMUnkxevv9wVFVLIFT3o8f7HX?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;, and put the files &lt;code&gt;interactive_data&lt;/code&gt; and &lt;code&gt;pipeline_data&lt;/code&gt; to &lt;code&gt;./data&lt;/code&gt;, or run the following commands:&lt;/p&gt; &#xA;&lt;p&gt;The downloaded files contain the following:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;interactive_data/data.json&lt;/code&gt; is the dataset used in the experiments of the paper (&lt;strong&gt;5500&lt;/strong&gt; instances in total). &lt;code&gt;interactive_data/data_zhihu.json&lt;/code&gt; is additional dataset collected alongside this paper (~&lt;strong&gt;900&lt;/strong&gt; instances), with the question sourcing from &lt;a href=&#34;https://www.zhihu.com/people/71-26-1-50&#34;&gt;Zhihu&lt;/a&gt;, you can use this for data augmentation.&lt;/p&gt; &#xA;&lt;p&gt;Please use the following codes to split the above data into train, dev, and test set (setting --add_zhihu will add data_zhihu.json).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd data/interactive_data&#xA;python split.py --add_zhihu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In addition to the interactive web search data, we also provide the dataset needed for training the pipeline-based web search: &lt;code&gt;pipeline_data&lt;/code&gt; (&lt;strong&gt;110k&lt;/strong&gt; instances in total). All the data is created by prompting text-davinci-003 and then manually filtered by human annotators. (&lt;strong&gt;Note&lt;/strong&gt; This part is not included in the paper, and you don&#39;t need to split it into train / dev / test.)&lt;/p&gt; &#xA;&lt;h3&gt;Prepare the model&lt;/h3&gt; &#xA;&lt;p&gt;WebCPM is based on &lt;a href=&#34;https://github.com/OpenBMB/CPM-Live&#34;&gt;CPM-bee&lt;/a&gt; with up to &lt;strong&gt;10 billion&lt;/strong&gt; parameters, which is one of the largest Chinese pre-trained language model in the community. We use an early version of CPM-bee, which is denoted as cpm_10b_webcpm_exp.pt. The latest version of CPM-bee will be open-source soon. &lt;strong&gt;Note the model checkpoint has not been fine-tuned towards any downstream task&lt;/strong&gt;. To access cpm_10b_webcpm_exp.pt, you can download the model parameters at &lt;a href=&#34;https://cloud.tsinghua.edu.cn/d/a02ae00b11434c9c8560/&#34;&gt;Tsinghua Cloud&lt;/a&gt;, or run the following script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd models&#xA;bash download_model.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above codes will download the 10B model at &lt;code&gt;models&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Train WebCPM&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/assets/framework.png&#34; alt=&#34;platform&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;We provide two versions of WebCPM: (1) interactive web search (the method proposed in the ACL paper) and (2) pipeline-based web search, which is easier to deploy (this method is not reported in the paper). Both versions use different scripts for training data generation and the same codes for model training.&lt;/p&gt; &#xA;&lt;h3&gt;A brief Introduction of Pipeline-based Web Search&lt;/h3&gt; &#xA;&lt;p&gt;The workflow follows four stages: (1) first, generate possible search queries based on the original question; (2) then for each search query, call Bing search and visit top-K web pages; (3) for each web page, extract the important information; (4) based on all the recorded information, generate a coherent and nuanced answer. All these things are trained in a multi-task way, please refer to &lt;code&gt;run_web_browsing/run_pipeline.py&lt;/code&gt;. For details of the interactive web search, please refer to our original paper.&lt;/p&gt; &#xA;&lt;h3&gt;Data Preprocessing&lt;/h3&gt; &#xA;&lt;p&gt;Before you start, run the following codes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PYTHONPATH=/**your-base-path**/webcpm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The training data generation is as follows (we differentiate between interactive web search and pipeline-based method). The following codes will generate &lt;code&gt;train_data&lt;/code&gt;, &lt;code&gt;dev_data&lt;/code&gt;, and &lt;code&gt;test_data&lt;/code&gt; in the corresponding folder, which will be loaded during training.&lt;/p&gt; &#xA;&lt;h4&gt;Training Data Generation of Interactive Web Search&lt;/h4&gt; &#xA;&lt;p&gt;First, construct the data for the synthesis model using the following codes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd dataset_interactive&#xA;python make_data_synthesis_model.py --data_path ../../data/interactive_data  --augment_qa_data --augment_data_path ../../data/pipeline_data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We explain some of the arguments as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;data_path&lt;/code&gt;: The source data path.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;augment_qa_data&lt;/code&gt;: Whether to augment the training data with qa data automatically generated by text-davinci. (To replicate the results in our paper, do not add this argument)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;augment_data_path&lt;/code&gt;: The data path to the augmented training data.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The training data generation of the search model is as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python make_data_search_model.py --add_query --add_action --add_abstract --abstract_all_tokens&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We explain some of the arguments as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;data_path&lt;/code&gt;: The source data path.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;add_query&lt;/code&gt;: If True, will add the query generation data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;add_abstract&lt;/code&gt;: If True, will add the generate supporting fact extraction data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;abstract_all_tokens&lt;/code&gt;: If True, supporting fact extraction module will generate all the tokens, instead of only the first / last few tokens.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;add_action&lt;/code&gt;: If True, will add the action prediction data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;add_synthesis&lt;/code&gt;: If True, will load local data for the synthesis model. &lt;strong&gt;Note You must first run python make_data_synthesis_model.py to obtain the synthesis data then add this argument here&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you want to train all sub-tasks in a multi-task way, just add all the above arguments; otherwise only add one argument (e.g., &lt;code&gt;--add_query&lt;/code&gt;) for single-task testing.&lt;/p&gt; &#xA;&lt;h4&gt;Training Data Generation of Pipeline-based Web Search&lt;/h4&gt; &#xA;&lt;p&gt;Please run the following codes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd dataset_pipeline&#xA;python make_data.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Training&lt;/h3&gt; &#xA;&lt;p&gt;To train WebCPM, run the following codes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd training&#xA;export PYTHONPATH=/**your-base-path**/webcpm&#xA;export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7&#xA;GPUS_PER_NODE=$(echo $CUDA_VISIBLE_DEVICES | tr &#39;,&#39; &#39;\n&#39; | wc -l | xargs)&#xA;echo &#34;Number of visible devices: $GPUS_PER_NODE, should be the same as visible devices&#34;&#xA;&#xA;set -ex&#xA;&#xA;MASTER_ADDR=localhost&#xA;MASTER_PORT=3239&#xA;NNODES=1&#xA;NODE_RANK=0&#xA;&#xA;OPTS=&#34;&#34;&#xA;OPTS+=&#34; --model-config config/cpm-bee-10b.json&#34;&#xA;OPTS+=&#34; --dataset ../data/dataset_interactive/train_data&#34;&#xA;OPTS+=&#34; --dataseteval ../data/dataset_interactive/dev_data&#34;&#xA;OPTS+=&#34; --epoch 5&#34;&#xA;OPTS+=&#34; --batch-size 8&#34;&#xA;OPTS+=&#34; --train-iters 100&#34;&#xA;OPTS+=&#34; --save-name webcpm_finetuned&#34;&#xA;OPTS+=&#34; --max-length 2560&#34;&#xA;OPTS+=&#34; --save ../models/&#34;&#xA;OPTS+=&#34; --lr 0.0001&#34;&#xA;OPTS+=&#34; --inspect-iters 100&#34;&#xA;OPTS+=&#34; --warmup-iters 1&#34;&#xA;OPTS+=&#34; --save-epochs 1&#34;&#xA;OPTS+=&#34; --lr-decay-style noam&#34;&#xA;OPTS+=&#34; --weight-decay 0.01&#34;&#xA;OPTS+=&#34; --clip-grad 1.0&#34;&#xA;OPTS+=&#34; --loss-scale 32768&#34;&#xA;OPTS+=&#34; --start-step 0&#34;&#xA;OPTS+=&#34; --load ../models/cpm_10b_webcpm_exp.pt&#34;&#xA;&#xA;CMD=&#34;torchrun --nnodes=${NNODES} --nproc_per_node=${GPUS_PER_NODE} --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=${MASTER_ADDR}:${MASTER_PORT} finetune_cpm_bee.py ${OPTS}&#34;&#xA;&#xA;echo ${CMD}&#xA;$CMD&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We explain some of the arguments as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;dataset&lt;/code&gt; and &lt;code&gt;dataseteval&lt;/code&gt;: The path to the processed file. For interactive web search, it is dataset_interactive, while for pipeline-based method, it is dataset_pipeline.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;batch-size&lt;/code&gt;: The batch size of a single GPU, the real batch size will be #GPUs x batch-size per GPU.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;max-length&lt;/code&gt;: The maximum sequence length of the data (not the model), those longer training instances will be dropped.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;save-name&lt;/code&gt; and &lt;code&gt;save&lt;/code&gt;: The path to save the fine-tuned model and the name of the saved model checkpoint.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;epoch&lt;/code&gt;: The number of training epochs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;load&lt;/code&gt;: The path to the pre-trained model checkpoint (cpmb in this case).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note no matter which module you are training (or the multi-task setting), you can use the above codes. We are training on 8x80G A100, you can change the batch size according to your GPU devices, the performance is not sensitive to the hyper-parameters.&lt;/p&gt; &#xA;&lt;h2&gt;Single-task Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;To evaluate different sub-tasks, you can first run the following codes to get the prediction of your fine-tuned model on the test data:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd inference&#xA;python inference.py --test_file ../training/dataset_interactive/test.txt --output_file output/test_predictions.json --ckpt_path **your_finetuned_checkpoint.pt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We explain some of the arguments as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;test_file&lt;/code&gt;: The path to the test file, it should have been generated during data preprocessing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;output_file&lt;/code&gt;: The path you want to write your predictions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;ckpt_path&lt;/code&gt;: The path to your fine-tuned model.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;After obtaining the predictions on the test file, you can run the following codes for single-task evaluation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python evaluate.py --input_file output/test_predictions.txt --evaluate_action&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We explain some of the arguments as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;input_file&lt;/code&gt;: The path you write your predictions of the test file.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;evaluate_action&lt;/code&gt;: Whether you want to evaluate the action prediction task (F1).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;evaluate_query&lt;/code&gt;: Whether you want to evaluate the search query generation task (Rougel-L).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;evaluate_abstract&lt;/code&gt;: Whether you want to evaluate the supporting fact extraction task (Rougel-L).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;abstract_all_tokens&lt;/code&gt;: Which mode do you train your model for supporting fact extraction, if you generate all the tokens, add this argument (Rougel-L).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;evaluate_answer&lt;/code&gt;: Whether you want to evaluate the answer synthesis task (Rougel-L).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;beam_size&lt;/code&gt;: Setting beam size to 1 would significantly accelerate inference, but hurt the performance a little bit.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Run WebCPM for New Questions&lt;/h2&gt; &#xA;&lt;p&gt;This is the implementation for the whole pipeline evaluation. You can use the following codes to generate answers for new questions. Note this requires you to first get a Bing search API key from &lt;a href=&#34;https://www.microsoft.com/en-us/bing/apis/bing-web-search-api&#34;&gt;here&lt;/a&gt; and run the following codes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd run_web_browsing&#xA;export PYTHONPATH=/**base-path**/webcpm&#xA;export BING_SEARCH_KEY=&#34;**Your Bing Search API Key**&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Interactive Web Search&lt;/h3&gt; &#xA;&lt;p&gt;Coming soon.&lt;/p&gt; &#xA;&lt;h3&gt;Pipeline-based Web Search&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python run_pipeline.py --data_path predictions/test.json --ckpt_path **your-checkpoint**&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We explain some of the arguments as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;data_path&lt;/code&gt;: The path you write your predictions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;ckpt_path&lt;/code&gt;: The path to the checkpoint where you have trained using the pipeline-based method.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Platform Building for Data Annotation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/assets/annotation.png&#34; alt=&#34;platform&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;We open source our web search interface, you can use it for data annotation. Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/thunlp/WebCPM/main/annotation_platform/README.md&#34;&gt;Annotation&lt;/a&gt;. The codes are a bit messy currently, we will soon upload a cleaner version.&lt;/p&gt; &#xA;&lt;h2&gt;Bugs or questions?&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions related to the codes or the paper, please contact Yujia (&lt;code&gt;qyj20@mails.tsinghua.edu.cn&lt;/code&gt;) or open an issue.&lt;/p&gt; &#xA;&lt;h2&gt;Resources of Tool Learning&lt;/h2&gt; &#xA;&lt;p&gt;With the powerful capabilities of foundation models, we are eager to see their applications in manipulating various tools. WebCPM is one typical research attempts. For more resources, please refer to the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;BMTools&lt;/strong&gt;. [&lt;a href=&#34;https://github.com/OpenBMB/BMTools&#34;&gt;Project&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tool Learning&lt;/strong&gt;. [&lt;a href=&#34;https://arxiv.org/abs/2304.08354&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tool Learning Paper List&lt;/strong&gt;. [&lt;a href=&#34;https://github.com/thunlp/ToolLearningPapers&#34;&gt;Project&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our WebCPM useful, please use the following citation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{qin2023webcpm,&#xA;    title = &#34;Interactive Web Search for Chinese Long-form Question Answering&#34;,&#xA;    author={Yujia Qin and Zihan Cai and Dian Jin and Lan Yan and Shihao Liang and Kunlun Zhu and Yankai Lin and Xu Han and Ning Ding and Huadong Wang and Ruobing Xie and Fanchao Qi and Zhiyuan Liu and Maosong Sun and Jie Zhou},&#xA;    booktitle = &#34;Proceedings of ACL 2023&#34;,&#xA;    year = &#34;2023&#34;,&#xA;    publisher = &#34;Association for Computational Linguistics&#34;,&#xA;    url = &#34;https://arxiv.org/abs/2305.06849&#34;,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>Frooodle/Stirling-PDF</title>
    <updated>2023-05-16T01:34:58Z</updated>
    <id>tag:github.com,2023-05-16:/Frooodle/Stirling-PDF</id>
    <link href="https://github.com/Frooodle/Stirling-PDF" rel="alternate"></link>
    <summary type="html">&lt;p&gt;locally hosted web application that allows you to perform various operations on PDF files&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Frooodle/Stirling-PDF/main/docs/stirling.png&#34; width=&#34;80&#34;&gt;&lt;br&gt;&lt;/p&gt;&#xA;&lt;h1 align=&#34;center&#34;&gt;Stirling-PDF&lt;/h1&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/frooodle/s-pdf&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/frooodle/s-pdf&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/Cn8pWhQRxZ&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1068636748814483718?label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Frooodle/Stirling-PDF/&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/v/frooodle/s-pdf/latest&#34; alt=&#34;Docker Image Version (tag latest semver)&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Frooodle/stirling-pdf&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/frooodle/stirling-pdf?style=social&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.paypal.com/paypalme/froodleplex&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Paypal%20Donate-yellow?style=flat&amp;amp;logo=paypal&#34; alt=&#34;Paypal Donate&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sponsors/Frooodle&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Github%20Sponsor-yellow?style=flat&amp;amp;logo=github&#34; alt=&#34;Github Sponser&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a powerful locally hosted web based PDF manipulation tool using docker that allows you to perform various operations on PDF files, such as splitting merging, converting, reorganizing, adding images, rotating, compressing, and more. This locally hosted web application started as a 100% ChatGPT-made application and has evolved to include a wide range of features to handle all your PDF needs.&lt;/p&gt; &#xA;&lt;p&gt;Feel free to request any features or bug fixes either in github issues or our &lt;a href=&#34;https://discord.gg/Cn8pWhQRxZ&#34;&gt;Discord&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Frooodle/Stirling-PDF/main/images/stirling-home.png&#34; alt=&#34;stirling-home&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Full intractable GUI for merging/splitting/rotating/moving PDFs and their pages.&lt;/li&gt; &#xA; &lt;li&gt;Split PDFs into multiple files at specified page numbers or extract all pages as individual files.&lt;/li&gt; &#xA; &lt;li&gt;Merge multiple PDFs together into a single resultant file&lt;/li&gt; &#xA; &lt;li&gt;Convert PDFs to and from images&lt;/li&gt; &#xA; &lt;li&gt;Reorganize PDF pages into different orders.&lt;/li&gt; &#xA; &lt;li&gt;Add/Generate signatures&lt;/li&gt; &#xA; &lt;li&gt;Flatten PDFs&lt;/li&gt; &#xA; &lt;li&gt;Repair PDFs&lt;/li&gt; &#xA; &lt;li&gt;Detect and remove blank pages&lt;/li&gt; &#xA; &lt;li&gt;Compare 2 PDFs and show differences in text&lt;/li&gt; &#xA; &lt;li&gt;Add images to PDFs&lt;/li&gt; &#xA; &lt;li&gt;Rotating PDFs in 90 degree increments.&lt;/li&gt; &#xA; &lt;li&gt;Compressing PDFs to decrease their filesize. (Using OCRMyPDF)&lt;/li&gt; &#xA; &lt;li&gt;Add and remove passwords&lt;/li&gt; &#xA; &lt;li&gt;Set PDF Permissions&lt;/li&gt; &#xA; &lt;li&gt;Add watermark(s)&lt;/li&gt; &#xA; &lt;li&gt;Convert Any common file to PDF (using LibreOffice)&lt;/li&gt; &#xA; &lt;li&gt;Convert PDF to Word/Powerpoint/Others (using LibreOffice)&lt;/li&gt; &#xA; &lt;li&gt;Extract images from PDF&lt;/li&gt; &#xA; &lt;li&gt;OCR on PDF (Using OCRMyPDF)&lt;/li&gt; &#xA; &lt;li&gt;Edit metadata&lt;/li&gt; &#xA; &lt;li&gt;Dark mode support.&lt;/li&gt; &#xA; &lt;li&gt;Custom download options (see &lt;a href=&#34;https://github.com/Frooodle/Stirling-PDF/raw/main/images/settings.png&#34;&gt;here&lt;/a&gt; for example)&lt;/li&gt; &#xA; &lt;li&gt;Parallel file processing and downloads&lt;/li&gt; &#xA; &lt;li&gt;API for integration with external scripts&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Hosted instance/demo of the app can be seen &lt;a href=&#34;https://pdf.adminforge.de/&#34;&gt;here&lt;/a&gt; hosted by the team at adminforge.de&lt;/p&gt; &#xA;&lt;h2&gt;Technologies used&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Spring Boot + Thymeleaf&lt;/li&gt; &#xA; &lt;li&gt;PDFBox&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.libreoffice.org/discover/libreoffice/&#34;&gt;LibreOffice&lt;/a&gt; for advanced conversions&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ocrmypdf/OCRmyPDF&#34;&gt;OcrMyPdf&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;HTML, CSS, JavaScript&lt;/li&gt; &#xA; &lt;li&gt;Docker&lt;/li&gt; &#xA; &lt;li&gt;PDF.js&lt;/li&gt; &#xA; &lt;li&gt;PDF-LIB.js&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;h3&gt;Locally&lt;/h3&gt; &#xA;&lt;p&gt;Please view &lt;a href=&#34;https://github.com/Frooodle/Stirling-PDF/raw/main/LocalRunGuide.md&#34;&gt;https://github.com/Frooodle/Stirling-PDF/blob/main/LocalRunGuide.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/frooodle/s-pdf&#34;&gt;https://hub.docker.com/r/frooodle/s-pdf&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Docker Run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -d \&#xA;  -p 8080:8080 \&#xA;  -v /location/of/trainingData:/usr/share/tesseract-ocr/4.00/tessdata \&#xA;  --name stirling-pdf \&#xA;  frooodle/s-pdf&#xA;  &#xA;  &#xA;  Can also add these for customisation but are not required&#xA;  -e APP_HOME_NAME=&#34;Stirling PDF&#34; \&#xA;  -e APP_HOME_DESCRIPTION=&#34;Your locally hosted one-stop-shop for all your PDF needs.&#34; \&#xA;  -e APP_NAVBAR_NAME=&#34;Stirling PDF&#34; \&#xA;  -e ALLOW_GOOGLE_VISABILITY=&#34;true&#34; \&#xA;  -e APP_ROOT_PATH=&#34;/&#34; \&#xA;  -e APP_LOCALE=&#34;en_GB&#34; \&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Docker Compose&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;version: &#39;3.3&#39;&#xA;services:&#xA;  stirling-pdf:&#xA;    image: frooodle/s-pdf&#xA;    ports:&#xA;      - &#39;8080:8080&#39;&#xA;    volumes:&#xA;      - /location/of/trainingData:/usr/share/tesseract-ocr/4.00/tessdata #Required for extra OCR languages&#xA;#      - /location/of/extraConfigs:/configs&#xA;#    environment:&#xA;#      APP_LOCALE: en_GB&#xA;#      APP_HOME_NAME: Stirling PDF&#xA;#      APP_HOME_DESCRIPTION: Your locally hosted one-stop-shop for all your PDF needs.&#xA;#      APP_NAVBAR_NAME: Stirling PDF&#xA;#      APP_ROOT_PATH: /&#xA;#      ALLOW_GOOGLE_VISABILITY: true&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Enable OCR/Compression feature&lt;/h2&gt; &#xA;&lt;p&gt;Please view &lt;a href=&#34;https://github.com/Frooodle/Stirling-PDF/raw/main/HowToUseOCR.md&#34;&gt;https://github.com/Frooodle/Stirling-PDF/blob/main/HowToUseOCR.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Want to add your own language?&lt;/h2&gt; &#xA;&lt;p&gt;Stirling PDF currently supports&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;English&lt;/li&gt; &#xA; &lt;li&gt;Arabic (العربية)&lt;/li&gt; &#xA; &lt;li&gt;German (Deutsch)&lt;/li&gt; &#xA; &lt;li&gt;French (Français)&lt;/li&gt; &#xA; &lt;li&gt;Spanish (Español)&lt;/li&gt; &#xA; &lt;li&gt;Chinese (简体中文)&lt;/li&gt; &#xA; &lt;li&gt;Catalan (Català)&lt;/li&gt; &#xA; &lt;li&gt;Italian (Italiano)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you want to add your own language to Stirling-PDF please refer &lt;a href=&#34;https://github.com/Frooodle/Stirling-PDF/raw/main/HowToAddNewLanguage.md&#34;&gt;https://github.com/Frooodle/Stirling-PDF/blob/main/HowToAddNewLanguage.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;And please create a PR to merge it back in so others can use it!&lt;/p&gt; &#xA;&lt;p&gt;Also please note as i add new features i will google translate existing languages so that they dont lose support. This could mean that new features need grammer corrections as added.&lt;/p&gt; &#xA;&lt;h2&gt;How to View&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open a web browser and navigate to &lt;code&gt;http://localhost:8080/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Use the application by following the instructions on the website.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Customize App&lt;/h2&gt; &#xA;&lt;p&gt;Stirling PDF allows easy customization of the visible application name. Simply use environment variables APP_HOME_NAME, APP_HOME_DESCRIPTION and APP_NAVBAR_NAME with Docker or Java. If running Java directly, you can also pass these as properties using -D arguments.&lt;/p&gt; &#xA;&lt;p&gt;Using the same method you can also change&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The default language by providing APP_LOCALE with values like de-DE fr-FR or ar-AR to select your default language (Will always default to English on invalid locale)&lt;/li&gt; &#xA; &lt;li&gt;Enable/Disable search engine visablility with ALLOW_GOOGLE_VISABILITY with true / false values. Default disable visability.&lt;/li&gt; &#xA; &lt;li&gt;Change root URI for Stirling-PDF ie change server.com/ to server.com/pdf-app by running APP_ROOT_PATH as pdf-app&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;API&lt;/h2&gt; &#xA;&lt;p&gt;For those wanting to use Stirling-PDFs backend API to link with their own custom scripting to edit PDFs you can view all existing API documentation &lt;a href=&#34;https://app.swaggerhub.com/apis-docs/Frooodle/Stirling-PDF/&#34;&gt;here&lt;/a&gt; or navigate to /swagger-ui/index.html of your stirling-pdf instance for your versions documentation&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>N3evin/AmiiboAPI</title>
    <updated>2023-05-16T01:34:58Z</updated>
    <id>tag:github.com,2023-05-16:/N3evin/AmiiboAPI</id>
    <link href="https://github.com/N3evin/AmiiboAPI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A RESTful API for amiibo.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Amiibo RESTful API&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://amiiboapi.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=Offical&amp;amp;message=Site&amp;amp;color=3399CC&#34; alt=&#34;Offical Site&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hits.seeyoufarm.com&#34;&gt;&lt;img src=&#34;https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FN3evin%2FAmiiboAPI&amp;amp;count_bg=%2379C83D&amp;amp;title_bg=%23555555&amp;amp;icon=&amp;amp;icon_color=%23E7E7E7&amp;amp;title=hits&amp;amp;edge_flat=false&#34; alt=&#34;Hits&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/myxnvvc&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Join-Discord-orange.svg?colorB=7289DA&amp;amp;logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAAPUAAADwCAMAAADvotLkAAAAM1BMVEUAAAD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2B3leKCAAAAEHRSTlMAQIAQv%2B%2Bfz2Aw3yBwUK%2BPD%2FW3OwAABYNJREFUeAHt3deWqzAPhuHPljtN93%2Bzf8kasktWHLPHgBj0nk956NVA0zRN0zRN0zRN0zRN07Q%2BkTFWSKMxOKIpFJZVXDJ2jcbCEosJ%2BzUVllo02CeaWXIL9ihHlp2jHdCepRe7s4cVfSc2Rb5CM7q28DUa0THDF8kP6FfkqxTQrYmv04BeOb5OCzo18IUq6NTIVyqjTzNfKYs%2BFb5SM%2FrElyqiS5mvFbpkVK1qVata1apWtapVrWpVq1rVqlY1VK1qVata1apWtapVrWpVR2et9VytWLu4%2BEPUJaQMAMhz0%2B32PIZycXUcBzyagucP%2BTABqzxeVl1Wcl48N%2BVDxlfDUq6odgaPKMUXnPstz38UE%2BGr5K6mDsM6y35TOWetMXjJGLv80vsw4CvjrqR2%2BcscVomz04B6w2RXZDB1t0R1MX%2Ba5zGjNbPEP6YbkPwl1JYAABTWDfPGhnH%2BfR0BLfLVMePR6OvkajRGZm9p%2FQ%2BKcPVCz5dEXCL8ezn456oCmkWrHR7ZdUP8nSiVdSICRbLaAMAQiyX0KLmS8SgJVjsAMDGhW8YlPCpy1QZATuhaMgCAJFYdsWNFqjphx6xQdcGekZeptti1IFNN2LUsUh2wc06i2mDnkkB1we55eeoRuxfkqQfsXhannnFARZo64YBGaWrCAQ3C1DMOKcpSJxzSKEtNOKRBlHrGQUVJ6oSDWiSpBxxUFqSOOCwvR21xWEGO2uCwkhi1x4eGZK01hGrGWpsGfIjEqGdUM8%2Fb0u9NZH3jYHxRinpEJQr8zL8jGd88OtsiRZ3bxwhLDStrrLInKeqmbW6FnbfsCEmI2m2ZM57wUtm0Jywy1HbTvxgadkae8L4gQz1tWgl9y8wb8b5RhprwttAwkfLGlcaIUPuNO1fbcrSFSiLUDu9rOaaxW0%2FiogS13ah2LWqD980S1GkPdcb7rAS12Xg2vLQgUMlIUG8dBi81%2FP6CSlmAuqDS2LKh8ltHmhSgdhsPml3LTj2jVjlfHTaeF5qGi9wO1dz5aotaVBomkt04WvByvjptGm09UsOB64R69ny1wQa2I%2BAT239CI8lXg54kbxs%2BL%2BEGfMqcr8bnhtE57%2BZEqJSC89HZDFxfvUt0SzVOV7tbq1VtB%2FRrMnipSFTnMqJTg5vxmpOoRuIyoUNkOdJl1EjMznzf7Fe0ePXKbnZXzCtakLp%2Bm2LyzFwSfeOFxbeH7YM%2FW81z9XtePhhsjlKsnsRGPl3Ny4cTwrJkbGkdeKKY%2Bg2Vc9Wc8KbseIUbNEUrmb0l2Xf3ODWcQPp5%2FCQ31vFaGPCmkYWoK2xMjn%2FlltEQXiMzhsjP%2FDJc4ckrDnjt7cgn0c32fyWT7P8KLvIfzal6hUKQmh3hfVQ6fTsvRxalrl7tCp2%2BwzN6eW%2BxzUOfbz5NlT2CJPWapR4jj%2FgMvDYEse%2Faezt0%2BBJnpIpZlnptnr7%2FJU6HP6Lk5I%2BN40MiPAvf%2FHjekObLjHlVgjW5enOm4bAnGzuXC45lVxz%2FY67oGJWqVrWqVa1qVata1apWdbdUrWpVq1rVqla1qlWtalWrWtWqzrdUg0%2FOxzPUhU%2FOxBPUM5%2FcSPF4deKTc0A4XE18drSFjZ%2ByiE8AwtFqwycXAGA8WA3H51b2Hyte4oFK3sBGtyyf24hHkz9UjXj6vutR9oeq6WQ2tbPRsVz4zKb2%2FwP4MXM7tP8f6BotfF4FzWx0zhQ%2BrdzMRvdS5JMam995wQ5l6%2FiMYvObJNipwZwQWtn4wdlbqpFuqUa6pRrJ31GN7O%2BoRo53VIPiHdWgcEc1EG6pxnhLNdIt1cj%2Bjmrkckc1KN5RDZrvqAbCLdUYb6lGuqUa2d9RjVzuqAbFO6pBM%2BOOLdA0TdM0TdM0TdM0TdO0b%2FZfegfWFMciUSwAAAAASUVORK5CYII%3D&#34; alt=&#34;discod&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/N3evin/AmiiboAPI/actions/workflows/checkdatabase.yml&#34;&gt;&lt;img src=&#34;https://github.com/N3evin/AmiiboAPI/actions/workflows/checkdatabase.yml/badge.svg?sanitize=true&#34; alt=&#34;Check Database&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/N3evin/AmiiboAPI/actions/workflows/generate_gameinfo.yaml&#34;&gt;&lt;img src=&#34;https://github.com/N3evin/AmiiboAPI/actions/workflows/generate_gameinfo.yaml/badge.svg?sanitize=true&#34; alt=&#34;Generate game info&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/N3evin/AmiiboAPI/actions/workflows/updatejson.yml&#34;&gt;&lt;img src=&#34;https://github.com/N3evin/AmiiboAPI/actions/workflows/updatejson.yml/badge.svg?sanitize=true&#34; alt=&#34;Update json&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A RESTful API that was created for retriving amiibo information.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://heroku.com/deploy&#34;&gt;&lt;img src=&#34;https://www.herokucdn.com/deploy/button.svg?sanitize=true&#34; alt=&#34;Deploy&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://deploy.zeet.co/?url=https://github.com/n3evin/amiiboapi&#34;&gt;&lt;img src=&#34;https://imgur.com/WTCkMSx.png&#34; alt=&#34;Deploy&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;always updated&lt;/li&gt; &#xA; &lt;li&gt;RESTful API&lt;/li&gt; &#xA; &lt;li&gt;could be used with any platform&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Full amiibo: &lt;a href=&#34;https://amiiboapi.com/api/amiibo&#34;&gt;https://amiiboapi.com/api/amiibo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Specific Amiibo (Mario): &lt;a href=&#34;https://amiiboapi.com/api/amiibo?name=mario&#34;&gt;https://amiiboapi.com/api/amiibo?name=mario&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;When searching for amiibo, you can use the key or amiibo name. Key must be in hexdecimal example &lt;code&gt;0x1D0&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;More APIs can be found here: &lt;a href=&#34;https://www.amiiboapi.com/docs/&#34;&gt;https://www.amiiboapi.com/docs/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Requirements (if you want to host)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 2.X or 3.X&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://flask.pocoo.org/&#34;&gt;Flask&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://flask-cors.readthedocs.io/en/latest/&#34;&gt;Flask-Cors&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;More in &lt;a href=&#34;https://github.com/N3evin/AmiiboAPI/raw/master/requirements.txt&#34;&gt;requirements.txt&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Manually Setup (if you want to host)&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install python&lt;/li&gt; &#xA; &lt;li&gt;Install the requirements using &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;app.py&lt;/code&gt; to start.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Heroku Setup (if you want to host)&lt;/h3&gt; &#xA;&lt;p&gt;Click on the &lt;code&gt;Deploy to Heroku&lt;/code&gt; button and you are good to go!&lt;/p&gt; &#xA;&lt;h3&gt;Credit&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://script.google.com/d/143u0RLuppsmYJ0B3wzo6i0jZYSfIFV2NLJMHPM-Sqczpr9bLwdffc-Wx/edit?usp=sharing&#34;&gt;JSON script source&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/19E7pMhKN6x583uB6bWVBeaTMyBPtEAC-Bk59Y6cfgxA&#34;&gt;Amiibo Database&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://amiibo.life&#34;&gt;Amiibo images and games&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MrKev312/AmiiboGameListGenerator&#34;&gt;Amiibo Game List Generator&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>