<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-01T01:35:37Z</updated>
  <subtitle>Daily Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>heejkoo/Awesome-Diffusion-Models</title>
    <updated>2023-04-01T01:35:37Z</updated>
    <id>tag:github.com,2023-04-01:/heejkoo/Awesome-Diffusion-Models</id>
    <link href="https://github.com/heejkoo/Awesome-Diffusion-Models" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A collection of resources and papers on Diffusion Models&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/hee9joon/Awesome-Diffusion-Models&#34;&gt;&lt;img src=&#34;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true&#34; alt=&#34;Awesome&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-green.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/chetanraj/awesome-github-badges&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Made%20With-Love-red.svg?sanitize=true&#34; alt=&#34;Made With Love&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository contains a collection of resources and papers on &lt;em&gt;&lt;strong&gt;Diffusion Models&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#resources&#34;&gt;Resources&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#introductory-posts&#34;&gt;Introductory Posts&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#introductory-papers&#34;&gt;Introductory Papers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#introductory-videos&#34;&gt;Introductory Videos&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#introductory-lectures&#34;&gt;Introductory Lectures&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#tutorial-and-jupyter-notebook&#34;&gt;Tutorial and Jupyter Notebook&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#papers&#34;&gt;Papers&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#survey&#34;&gt;Survey&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#vision&#34;&gt;Vision&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#generation&#34;&gt;Generation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#segmentation&#34;&gt;Segmentation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#inverse-problem&#34;&gt;Inverse Problem&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#image-translation&#34;&gt;Image Translation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#text-driven-image-generation-and-editing&#34;&gt;Text driven Image Generation and Editing&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#medical-imaging&#34;&gt;Medical Imaging&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#3d-vision&#34;&gt;3D Vision&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#adversarial-attack&#34;&gt;Adversarial Attack&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#miscellaneous&#34;&gt;Miscellaneous&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#audio&#34;&gt;Audio&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#generation-1&#34;&gt;Generation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#conversion&#34;&gt;Conversion&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#enhancement&#34;&gt;Enhancement&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#separation&#34;&gt;Separation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#text-to-speech&#34;&gt;Text-to-Speech&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#miscellaneous-1&#34;&gt;Miscellaneous&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#natural-language&#34;&gt;Natural Language&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#generation-2&#34;&gt;Generation&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#tabular-and-time-series&#34;&gt;Tabular and Time Series&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#generation-3&#34;&gt;Generation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#forecasting&#34;&gt;Forecasting&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#imputation&#34;&gt;Imputation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#miscellaneous-2&#34;&gt;Miscellaneous&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#graph&#34;&gt;Graph&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#generation-4&#34;&gt;Generation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#molecular-and-material-generation&#34;&gt;Molecular and Material Generation&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#reinforcement-learning&#34;&gt;Reinforcement Learning&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#theory&#34;&gt;Theory&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/heejkoo/Awesome-Diffusion-Models/main/#applications&#34;&gt;Applications&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Resources&lt;/h1&gt; &#xA;&lt;h2&gt;Introductory Posts&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;span&gt;⏩&lt;/span&gt; DiffusionFastForward: 01-Diffusion-Theory&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mikolaj Czerkawski (@mikonvergence)&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://github.com/mikonvergence/DiffusionFastForward/raw/master/notes/01-Diffusion-Theory.md&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 4 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How diffusion models work: the math from scratch&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sergios Karagiannakos,Nikolas Adaloglou&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://theaisummer.com/diffusion-models/?fbclid=IwAR1BIeNHqa3NtC8SL0sKXHATHklJYphNH-8IGNoO3xZhSKM_GYcvrrQgB0o&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 24 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Path to the Variational Diffusion Loss&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alex Alemi&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://blog.alexalemi.com/diffusion.html&#34;&gt;Website&lt;/a&gt;] [&lt;a href=&#34;https://colab.research.google.com/github/google-research/vdm/blob/main/colab/SimpleDiffusionColab.ipynb&#34;&gt;Colab&lt;/a&gt;] &lt;br&gt; 15 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Annotated Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Niels Rogge, Kashif Rasul&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://huggingface.co/blog/annotated-diffusion&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 06 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The recent rise of diffusion-based models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Maciej Domagała&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://maciejdomagala.github.io/generative_models/2022/06/06/The-recent-rise-of-diffusion-based-models.html&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 06 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Introduction to Diffusion Models for Machine Learning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ryan O&#39;Connor&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 12 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improving Diffusion Models as an Alternative To GANs&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Arash Vahdat and Karsten Kreis&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-1/&#34;&gt;Website-Part 1&lt;/a&gt;] [&lt;a href=&#34;https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-2/&#34;&gt;Website-Part 2&lt;/a&gt;] &lt;br&gt; 26 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;An introduction to Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ayan Das&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://ayandas.me/blog-tut/2021/12/04/diffusion-prob-models.html&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 04 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Introduction to deep generative modeling: Diffusion-based Deep Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jakub Tomczak&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://jmtomczak.github.io/blog/10/10_ddgms_lvm_p2.html&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 30 Aug 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What are Diffusion Models?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lilian Weng&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://lilianweng.github.io/lil-log/2021/07/11/diffusion-models.html&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 11 Jul 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models as a kind of VAE&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Angus Turner&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://angusturner.github.io/generative_models/2021/06/29/diffusion-probabilistic-models-I.html&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 29 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative Modeling by Estimating Gradients of the Data Distribution&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yang Song&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://yang-song.github.io/blog/2021/score/&#34;&gt;Website&lt;/a&gt;] &lt;br&gt; 5 May 2021&lt;/p&gt; &#xA;&lt;h2&gt;Introductory Papers&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Understanding Diffusion Models: A Unified Perspective&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Calvin Luo&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.11970&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How to Train Your Energy-Based Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yang Song, Diederik P. Kingma&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2101.03288&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Jan 2021&lt;/p&gt; &#xA;&lt;h2&gt;Introductory Videos&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;span&gt;⏩&lt;/span&gt; DiffusionFastForward&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mikolaj Czerkawski (@mikonvergence)&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://www.youtube.com/playlist?list=PL5RHjmn-MVHDMcqx-SI53mB7sFOqPK6gN&#34;&gt;Video&lt;/a&gt;] &lt;br&gt; 4 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion models from scratch in PyTorch&lt;/strong&gt; &lt;br&gt; &lt;em&gt;DeepFindr&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://www.youtube.com/watch?v=a4Yfz2FxXiY&#34;&gt;Video&lt;/a&gt;] &lt;br&gt; 18 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models | Paper Explanation | Math Explained&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Outlier&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://www.youtube.com/watch?v=HoKDTa5jHvg&#34;&gt;Video&lt;/a&gt;] &lt;br&gt; 6 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What are Diffusion Models?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ari Seff&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://www.youtube.com/watch?v=fbLgFrlTnGU&amp;amp;list=LL&amp;amp;index=2&#34;&gt;Video&lt;/a&gt;] &lt;br&gt; 20 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion models explained&lt;/strong&gt; &lt;br&gt; &lt;em&gt;AI Coffee Break with Letitia&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://www.youtube.com/watch?v=344w5h24-h8&amp;amp;ab_channel=AICoffeeBreakwithLetitia&#34;&gt;Video&lt;/a&gt;] &lt;br&gt; 23 Mar 2022&lt;/p&gt; &#xA;&lt;h2&gt;Introductory Lectures&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion-based Generative Modeling: Foundations and Applications&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Karsten Kreis, Ruiqi Gao, Arash Vahdat&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://cvpr2022-tutorial-diffusion-models.github.io/&#34;&gt;Page&lt;/a&gt;] &lt;br&gt; 19 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jascha Sohl-Dickstein, MIT 6.S192 - Lecture 22&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://www.youtube.com/watch?v=XCUlnHP1TNM&#34;&gt;Video&lt;/a&gt;] &lt;br&gt; 19 Apr 2022&lt;/p&gt; &#xA;&lt;h2&gt;Tutorial and Jupyter Notebook&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;span&gt;⏩&lt;/span&gt; DiffusionFastForward: train from scratch in colab&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mikolaj Czerkawski (@mikonvergence)&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://github.com/mikonvergence/DiffusionFastForward&#34;&gt;Github&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mikonvergence/DiffusionFastForward#computer-code&#34;&gt;notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;diffusion-for-beginners&lt;/strong&gt; &lt;br&gt; &lt;em&gt;ozanciga&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://github.com/ozanciga/diffusion-for-beginners&#34;&gt;Github&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Beyond Diffusion: What is Personalized Image Generation and How Can You Customize Image Synthesis?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;J. Rafid Siddiqui&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://github.com/azad-academy/personalized-diffusion&#34;&gt;Github&lt;/a&gt;] [&lt;a href=&#34;https://medium.com/mlearning-ai/beyond-diffusion-what-is-personalized-image-generation-and-how-can-you-customize-image-synthesis-26a89d5b335&#34;&gt;Medium&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion_models_tutorial&lt;/strong&gt; &lt;br&gt; &lt;em&gt;FilippoMB&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://github.com/FilippoMB/Diffusion_models_tutorial&#34;&gt;Github&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ScoreDiffusionModel&lt;/strong&gt; &lt;br&gt; &lt;em&gt;JeongJiHeon&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://github.com/JeongJiHeon/ScoreDiffusionModel&#34;&gt;Github&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Minimal implementation of diffusion models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;VSehwag&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://github.com/VSehwag/minimal-diffusion&#34;&gt;Github&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;diffusion_tutorial&lt;/strong&gt; &lt;br&gt; &lt;em&gt;sunlin-ai&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://github.com/sunlin-ai/diffusion_tutorial&#34;&gt;Github&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising diffusion probabilistic models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;acids-ircam&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://github.com/acids-ircam/diffusion_models&#34;&gt;Github&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Centipede Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zalring&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://colab.research.google.com/github/Zalring/Centipede_Diffusion/blob/main/Centipede_Diffusion.ipynb&#34;&gt;Notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deforum Stable Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;deforum&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://colab.research.google.com/github/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb&#34;&gt;Notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stable Diffusion Interpolation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;None&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://colab.research.google.com/drive/1EHZtFjQoRr-bns1It5mTcOVyZzZD9bBc?usp=sharing&#34;&gt;Notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Keras Stable Diffusion: GPU starter example&lt;/strong&gt; &lt;br&gt; &lt;em&gt;None&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://colab.research.google.com/drive/1zVTa4mLeM_w44WaFwl7utTaa6JcaH1zK&#34;&gt;Notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Huemin Jax Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;huemin-art&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://colab.research.google.com/github/huemin-art/jax-guided-diffusion/blob/v2.7/Huemin_Jax_Diffusion_2_7.ipynb&#34;&gt;Notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Disco Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;alembics&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://colab.research.google.com/github/alembics/disco-diffusion/blob/main/Disco_Diffusion.ipynb&#34;&gt;Notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Simplified Disco Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;entmike&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://colab.research.google.com/github/entmike/disco-diffusion-1/blob/main/Simplified_Disco_Diffusion.ipynb&#34;&gt;Notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;WAS&#39;s Disco Diffusion - Portrait Generator Playground&lt;/strong&gt; &lt;br&gt; &lt;em&gt;WASasquatch&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://colab.research.google.com/github/WASasquatch/disco-diffusion-portrait-playground/blob/main/WAS&#39;s_Disco_Diffusion_v5_6_9_%5BPortrait_Generator_Playground%5D.ipynb&#34;&gt;Notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusers - Hugging Face&lt;/strong&gt; &lt;br&gt; &lt;em&gt;huggingface&lt;/em&gt; &lt;br&gt; [&lt;a href=&#34;https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb&#34;&gt;Notebook&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;h1&gt;Papers&lt;/h1&gt; &#xA;&lt;h2&gt;Survey&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Audio Diffusion Model for Speech Synthesis: A Survey on Text To Speech and Speech Enhancement in Generative AI&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chenshuang Zhang, Chaoning Zhang, Sheng Zheng, Mengchun Zhang, Maryam Qamar, Sung-Ho Bae, In So Kweon&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13336&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models in NLP: A Survey&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuansong Zhu, Yu Zhao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.07576&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-to-image Diffusion Model in Generative AI: A Survey&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chenshuang Zhang, Chaoning Zhang, Mengchun Zhang, In So Kweon&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.07909&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Non-autoregressive Text Generation: A Survey&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yifan Li, Kun Zhou, Wayne Xin Zhao, Ji-Rong Wen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06574&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models in Bioinformatics: A New Wave of Deep Learning Revolution in Action&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhiye Guo, Jian Liu, Yanli Wang, Mengrui Chen, Duolin Wang, Dong Xu, Jianlin Cheng&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10907&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative Diffusion Models on Graphs: Methods and Applications&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenqi Fan, Chengyi Liu, Yunqing Liu, Jiatong Li, Hang Li, Hui Liu, Jiliang Tang, Qing Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02591&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Medical Image Analysis: A Comprehensive Survey&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Amirhossein Kazerouni, Ehsan Khodapanah Aghdam, Moein Heidari, Reza Azad, Mohsen Fayyaz, Ilker Hacihaliloglu, Dorit Merhof&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.07804&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 14 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Efficient Diffusion Models for Vision: A Survey&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Anwaar Ulhaq, Naveed Akhtar, Ganna Pogrebna&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.09292&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models in Vision: A Survey&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Mubarak Shah&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.04747&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Survey on Generative Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hanqun Cao, Cheng Tan, Zhangyang Gao, Guangyong Chen, Pheng-Ann Heng, Stan Z. Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.02646&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models: A Comprehensive Survey of Methods and Applications&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ling Yang&lt;sup&gt;1&lt;/sup&gt;, Zhilong Zhang&lt;sup&gt;1&lt;/sup&gt;, Shenda Hong, Wentao Zhang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.00796&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Sep 2022&lt;/p&gt; &#xA;&lt;h2&gt;Vision&lt;/h2&gt; &#xA;&lt;h3&gt;Generation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Object-Centric Slot Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jindong Jiang, Fei Deng, Gautam Singh, Sungjin Ahn&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10834&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LDMVFI: Video Frame Interpolation with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Duolikun Danier, Fan Zhang, David Bull&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09508&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Efficient Diffusion Training via Min-SNR Weighting Strategy&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tiankai Hang, Shuyang Gu, Chen Li, Jianmin Bao, Dong Chen, Han Hu, Xin Geng, Baining Guo&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09556&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation&lt;/strong&gt; &lt;br&gt; CVPR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08320&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Interpretable ODE-style Generative Diffusion Model via Force Field Construction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weiyang Jin, Yongpei Zhu, Yuxi Peng&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08063&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Regularized Vector Quantization for Tokenized Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiahui Zhang, Fangneng Zhan, Christian Theobalt, Shijian Lu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06424&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PARASOL: Parametric Style Control for Diffusion Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gemma Canet Tarrés, Dan Ruta, Tu Bui, John Collomosse&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06464&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Brain-Diffuser: Natural scene reconstruction from fMRI signals using generative latent diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Furkan Ozcelik, Rufin VanRullen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05334&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models for Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Paul Hagemann, Lars Ruthotto, Gabriele Steidl, Nicole Tianjiao Yang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.04772&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TRACT: Denoising Diffusion Models with Transitive Closure Time-Distillation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;David Berthelot, Arnaud Autef, Jierui Lin, Dian Ang Yap, Shuangfei Zhai, Siyuan Hu, Daniel Zheng, Walter Talbott, Eric Gu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.04248&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative Diffusions in Augmented Spaces: A Complete Recipe&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kushagra Pandey, Stephan Mandt&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.01748&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Consistency Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yang Song, Prafulla Dhariwal, Mark Chen, Ilya Sutskever&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.01469&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Probabilistic Fields&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Peiye Zhuang, Samira Abnar, Jiatao Gu, Alex Schwing, Joshua M. Susskind, Miguel Ángel Bautista&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.00165&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unsupervised Discovery of Semantic Latent Directions in Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yong-Hyun Park&lt;sup&gt;1&lt;/sup&gt;, Mingi Kwon&lt;sup&gt;1&lt;/sup&gt;, Junghyo Jo, Youngjung Uh&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.12469&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yilun Du, Conor Durkan, Robin Strudel, Joshua B. Tenenbaum, Sander Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, Will Grathwohl&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.11552&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://energy-based-model.github.io/reduce-reuse-recycle/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 22 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning 3D Photography Videos via Self-supervised Diffusion on Single Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiaodong Wang&lt;sup&gt;1&lt;/sup&gt;, Chenfei Wu&lt;sup&gt;1&lt;/sup&gt;, Shengming Yin, Minheng Ni, Jianfeng Wang, Linjie Li, Zhengyuan Yang, Fan Yang, Lijuan Wang, Zicheng Liu, Yuejian Fang, Nan Duan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10781&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On Calibrating Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tianyu Pang, Cheng Lu, Chao Du, Min Lin, Shuicheng Yan, Zhijie Deng&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10688&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/thudzj/Calibrated-DPMs&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 21 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zebin You, Yong Zhong, Fan Bao, Jiacheng Sun, Chongxuan Li, Jun Zhu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10586&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cross-domain Compositing with Pretrained Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Roy Hachnochi, Mingrui Zhao, Nadav Orzech, Rinon Gal, Ali Mahdavi-Amiri, Daniel Cohen-Or, Amit Haim Bermano&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10167&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/cross-domain-compositing/cross-domain-compositing&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Restoration based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jaemoo Choi&lt;sup&gt;1&lt;/sup&gt;, Yesom Park&lt;sup&gt;1&lt;/sup&gt;, Myungjoo Kang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05456&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Consistent Diffusion Models: Mitigating Sampling Drift by Learning to be Consistent&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giannis Daras&lt;sup&gt;1&lt;/sup&gt;, Yuval Dagan&lt;sup&gt;1&lt;/sup&gt;, Alexandros G. Dimakis, Constantinos Daskalakis&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.09057&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/giannisdaras/cdm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 17 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LayoutDiffuse: Adapting Foundational Diffusion Models for Layout-to-Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiaxin Cheng&lt;sup&gt;1&lt;/sup&gt;, Xiao Liang&lt;sup&gt;1&lt;/sup&gt;, Xingjian Shi, Tong He, Tianjun Xiao, Mu Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.08908&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Video Probabilistic Diffusion Models in Projected Latent Space&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sihyun Yu, Kihyuk Sohn, Subin Kim, Jinwoo Shin&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07685&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sihyun.me/PVDM/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffFaceSketch: High-Fidelity Face Image Synthesis with Sketch-Guided Latent Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yichen Peng, Chunqi Zhao, Haoran Xie, Tsukasa Fukusato, Kazunori Miyata&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.06908&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Where to Diffuse, How to Diffuse, and How to Get Back: Automated Learning for Multivariate Diffusions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Raghav Singhal&lt;sup&gt;1&lt;/sup&gt;, Mark Goldstein&lt;sup&gt;1&lt;/sup&gt;, Rajesh Ranganath&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07261&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Preconditioned Score-based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Li Zhang, Hengyuan Ma, Xiatian Zhu, Jianfeng Feng&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.06504&#34;&gt;Paper&lt;/a&gt;] &lt;a href=&#34;https://github.com/fudan-zvg/PDS&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Star-Shaped Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andrey Okhotin, Dmitry Molchanov, Vladimir Arkhipkin, Grigory Bartosh, Aibek Alanov, Dmitry Vetrov&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.05259&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;UniPC: A Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenliang Zhao, Lujia Bai, Yongming Rao, Jie Zhou, Jiwen Lu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04867&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://unipc.ivg-research.xyz&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wl-zhao/UniPC&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 9 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Geometry of Score Based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sandesh Ghimire, Jinyang Liu, Armand Comas, Davin Hill, Aria Masoomi, Octavia Camps, Jennifer Dy&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04411&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q-Diffusion: Quantizing Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiuyu Li, Long Lian, Yijiang Liu, Huanrui Yang, Zhen Dong, Daniel Kang, Shanghang Zhang, Kurt Keutzer&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04304&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PFGM++: Unlocking the Potential of Physics-Inspired Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yilun Xu, Ziming Liu, Yonglong Tian, Shangyuan Tong, Max Tegmark, Tommi Jaakkola&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04265&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Newbeeer/pfgmpp&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Long Horizon Temperature Scaling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andy Shih, Dorsa Sadigh, Stefano Ermon&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03686&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Spatial Functa: Scaling Functa to ImageNet Classification and Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Matthias Bauer&lt;sup&gt;1&lt;/sup&gt;, Emilien Dupont, Andy Brock, Dan Rosenbaum, Jonathan Schwarz, Hyunjik Kim&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03130&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ShiftDDPMs: Exploring Conditional Diffusion Models by Shifting Diffusion Trajectories&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zijian Zhang, Zhou Zhao, Jun Yu, Qi Tian&lt;/em&gt; &lt;br&gt; AAAI 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02373&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Divide and Compose with Score Based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sandesh Ghimire, Armand Comas, Davin Hill, Aria Masoomi, Octavia Camps, Jennifer Dy&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02272&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sandeshgh/Score-based-disentanglement&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 5 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stable Target Field for Reduced Variance Score Estimation in Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yilun Xu&lt;sup&gt;1&lt;/sup&gt;, Shangyuan Tong&lt;sup&gt;1&lt;/sup&gt;, Tommi Jaakkola&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.00670&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Newbeeer/stf&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tao Yang, Yuwang Wang, Yan Lv, Nanning Zheng&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13721&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Optimizing DDPM Sampling with Shortcut Fine-Tuning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ying Fan, Kangwook Lee&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13362&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning Data Representations with Joint Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kamil Deja, Tomasz Trzcinski, Jakub M. Tomczak&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13622&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shengmeng Li, Luping Liu, Zenghao Chai, Runnan Li, Xu Tan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12935&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Don&#39;t Play Favorites: Minority Guidance for Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Soobin Um, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12334&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sangyun884/fast-ode&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerating Guided Diffusion Sampling with Splitting Numerical Methods&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Suttisak Wizadwongsa, Supasorn Suwajanakorn&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11558&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Input Perturbation Reduces Exposure Bias in Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mang Ning, Enver Sangineto, Angelo Porrello, Simone Calderara, Rita Cucchiara&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11706&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/forever208/DDPM-IP&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Minimizing Trajectory Curvature of ODE-based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sangyun Lee, Beomsu Kim, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12003&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;simple diffusion: End-to-end diffusion for high resolution images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Emiel Hoogeboom&lt;sup&gt;1&lt;/sup&gt;, Jonathan Heek&lt;sup&gt;1&lt;/sup&gt;, Tim Salimans&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11093&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast Inference in Denoising Diffusion Models via MMD Finetuning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Emanuele Aiello, Diego Valsesia, Enrico Magli&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.07969&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/diegovalsesia/MMD-DDM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Exploring Transformer Backbones for Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Princy Chahal&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.14678&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unsupervised Representation Learning from Pre-trained Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zijian Zhang, Zhou Zhao, Zhijie Lin&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.12990&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Scalable Adaptive Computation for Iterative Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Allan Jabri, David Fleet, Ting Chen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.11972&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Hierarchically branched diffusion models for efficient and interpretable multi-class conditional generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alex M. Tseng, Tommaso Biancalani, Max Shen, Gabriele Scalia&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.10777&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ludan Ruan, Yiyang Ma, Huan Yang, Huiguo He, Bei Liu, Jianlong Fu, Nicholas Jing Yuan, Qin Jin, Baining Guo&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.09478&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/researchmm/MM-Diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Scalable Diffusion Models with Transformers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;William Peebles, Saining Xie&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.09748&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://www.wpeebles.com/DiT&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/facebookresearch/DiT&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DAG: Depth-Aware Guidance with Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gyeongnyeon Kim&lt;sup&gt;1&lt;/sup&gt;, Wooseok Jang&lt;sup&gt;1&lt;/sup&gt;, Gyuseong Lee&lt;sup&gt;1&lt;/sup&gt;, Susung Hong, Junyoung Seo, Seungryong Kim&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.08861&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ku-cvlab.github.io/DAG/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 17 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Towards Practical Plug-and-Play Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyojun Go&lt;sup&gt;1&lt;/sup&gt;, Yunsung Lee&lt;sup&gt;1&lt;/sup&gt;, Jin-Young Kim&lt;sup&gt;1&lt;/sup&gt;, Seunghyun Lee, Myeongho Jeong, Hyun Seung Lee, Seungtaek Choi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.05973&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Semantic Brain Decoding: from fMRI to conceptually similar image reconstruction of visual stimuli&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Matteo Ferrante, Tommaso Boccato, Nicola Toschi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.06726&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MAGVIT: Masked Generative Video Transformer&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lijun Yu, Yong Cheng, Kihyuk Sohn, José Lezama, Han Zhang, Huiwen Chang, Alexander G. Hauptmann, Ming-Hsuan Yang, Yuan Hao, Irfan Essa, Lu Jiang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.05199&#34;&gt;Paper&lt;/a&gt;] &lt;a href=&#34;https://magvit.cs.cmu.edu/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 10 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gyeongman Kim, Hajin Shim, Hyunsu Kim, Yunjey Choi, Junho Kim, Eunho Yang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02802&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Naoki Matsunaga, Masato Ishii, Akio Hayakawa, Kenji Suzuki, Takuya Narihira&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02024&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;VIDM: Video Implicit Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kangfu Mei, Vishal M. Patel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00235&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://kfmei.page/vidm/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MKFMIKU/VIDM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Why Are Conditional Generative Models Better Than Unconditional Ones?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Fan Bao, Chongxuan Li, Jiacheng Sun, Jun Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00362&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;High-Fidelity Guided Image Synthesis with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jaskirat Singh, Stephen Gould, Liang Zheng&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.17084&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://1jsingh.github.io/gradop&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 30 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-based Continuous-time Discrete Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haoran Sun, Lijun Yu, Bo Dai, Dale Schuurmans, Hanjun Dai&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16750&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Wavelet Diffusion Models are fast and scalable Image Generators&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hao Phung, Quan Dao, Anh Tran&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16152&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dimensionality-Varying Diffusion Process&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Han Zhang, Ruili Feng, Zhantao Yang, Lianghua Huang, Yu Liu, Yifei Zhang, Yujun Shen, Deli Zhao, Jingren Zhou, Fan Cheng&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16032&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dongjun Kim&lt;sup&gt;1&lt;/sup&gt;, Yeongmin Kim&lt;sup&gt;1&lt;/sup&gt;, Wanmo Kang, Il-Chul Moon&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.17091&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Probabilistic Model Made Slim&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xingyi Yang, Daquan Zhou, Jiashi Feng, Xinchao Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.17106&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast Sampling of Diffusion Models via Operator Learning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hongkai Zheng, Weili Nie, Arash Vahdat, Kamyar Azizzadenesheli, Anima Anandkumar&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13449&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Latent Video Diffusion Models for High-Fidelity Video Generation with Arbitrary Lengths&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, Qifeng Chen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13221&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Paint by Example: Exemplar-based Image Editing with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun, Dong Chen, Fang Wen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13227&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SinDiffusion: Learning a Diffusion Model from a Single Natural Image&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weilun Wang, Jianmin Bao, Wengang Zhou, Dongdong Chen, Dong Chen, Lu Yuan, Houqiang Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12445&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/WeilunWang/SinDiffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerating Diffusion Sampling with Classifier-based Feature Distillation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wujie Sun, Defang Chen, Can Wang, Deshi Ye, Yan Feng, Chun Chen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12039&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SceneComposer: Any-Level Semantic Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yu Zeng, Zhe Lin, Jianming Zhang, Qing Liu, John Collomosse, Jason Kuen, Vishal M. Patel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.11742&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://zengyu.me/scenec/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-Based Scene Graph to Image Generation with Masked Contrastive Pre-Training&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ling Yang&lt;sup&gt;1&lt;/sup&gt;, Zhilin Huang&lt;sup&gt;1&lt;/sup&gt;, Yang Song, Shenda Hong, Guohao Li, Wentao Zhang, Bin Cui, Bernard Ghanem, Ming-Hsuan Yang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.11138&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SinFusion: Training Diffusion Models on a Single Image or Video&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yaniv Nikankin, Niv Haim, Michal Irani&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.11743&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MagicVideo: Efficient Video Generation With Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Daquan Zhou&lt;sup&gt;1&lt;/sup&gt;, Weimin Wang&lt;sup&gt;1&lt;/sup&gt;, Hanshu Yan, Weiwei Lv, Yizhe Zhu, Jiashi Feng&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.11018&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://magicvideo.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 20 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked Modeling for Vision Decoding&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zijiao Chen, Jiaxin Qing, Tiange Xiang, Wan Lin Yue, Juan Helen Zhou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.06956&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://mind-vis.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zjc062/mind-vis&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Few-shot Image Generation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jingyuan Zhu, Huimin Ma, Jiansheng Chen, Jian Yuan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.03264&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;From Denoising Diffusions to Denoising Markov Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Joe Benton, Yuyang Shi, Valentin De Bortoli, George Deligiannidis, Arnaud Doucet&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.03595&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yuyang-shi/generalized-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 7 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Muyang Li, Ji Lin, Chenlin Meng, Stefano Ermon, Song Han, Jun-Yan Zhu&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.02048&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/lmxyy/sige&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 4 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;An optimal control perspective on diffusion-based generative modeling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julius Berner, Lorenz Richter, Karen Ullrich&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.01364&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Entropic Neural Optimal Transport via Diffusion Processes&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nikita Gushchin, Alexander Kolesov, Alexander Korotin, Dmitry Vetrov, Evgeny Burnaev&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.01156&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, Jun Zhu&lt;/em&gt; &lt;br&gt; NeurIPS 2022 (Oral). [&lt;a href=&#34;https://arxiv.org/abs/2211.01095&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LuChengTHU/dpm-solver&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-based Denoising Diffusion with Non-Isotropic Gaussian Noise Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vikram Voleti, Christopher Pal, Adam Oberman&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.12254&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deep Equilibrium Approaches to Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ashwini Pokle, Zhengyang Geng, Zico Kolter&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.12867&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/locuslab/deq-ddim&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 23 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Representation Learning with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jeremias Traub&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.11058&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jeremiastraub/diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Self-Guided Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vincent Tao Hu&lt;sup&gt;1&lt;/sup&gt;, David W Zhang&lt;sup&gt;1&lt;/sup&gt;, Yuki M. Asano, Gertjan J. Burghouts, Cees G. M. Snoek&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.06462&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GENIE: Higher-Order Denoising Diffusion Solvers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tim Dockhorn, Arash Vahdat, Karsten Kreis&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.05475&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nv-tlabs.github.io/GENIE/&#34;&gt;Project&lt;/a&gt; [&lt;a href=&#34;https://github.com/nv-tlabs/GENIE&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 11 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;f-DM: A Multi-stage Diffusion Model via Progressive Signal Transformation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiatao Gu, Shuangfei Zhai, Yizhe Zhang, Miguel Angel Bautista, Josh Susskind&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.04955&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;http://jiataogu.me/fdm/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 10 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On Distillation of Guided Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chenlin Meng, Ruiqi Gao, Diederik P. Kingma, Stefano Ermon, Jonathan Ho, Tim Salimans&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.03142&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improving Sample Quality of Diffusion Model Using Self-Attention Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Susung Hong, Gyuseong Lee, Wooseok Jang, Seungryong Kim&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.00939&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ku-cvlab.github.io/Self-Attention-Guidance/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 3 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;OCD: Learning to Overfit with Conditional Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shahar Shlomo Lutati, Lior Wolf&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.00471&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ShaharLutatiPersonal/OCD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generated Faces in the Wild: Quantitative Comparison of Stable Diffusion, Midjourney and DALL-E 2&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ali Borji&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.00586&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/aliborji/GFW&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising MCMC for Accelerating Diffusion-Based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Beomsu Kim, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14593&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/1202kbs/DMCMC&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;All are Worth Words: a ViT Backbone for Score-based Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Fan Bao, Chongxuan Li, Yue Cao, Jun Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.12152&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Neural Wavelet-domain Diffusion for 3D Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ka-Hei Hui, Ruihui Li, Jingyu Hu, Chi-Wing Fu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.08725&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Can segmentation models be trained with fully synthetically generated data?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Virginia Fernandez, Walter Hugo Lopez Pinaya, Pedro Borges, Petru-Daniel Tudosiu, Mark S Graham, Tom Vercauteren, M Jorge Cardoso&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.08256&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Blurring Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Emiel Hoogeboom, Tim Salimans&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.05557&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Soft Diffusion: Score Matching for General Corruptions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alexandros G. Dimakis, Peyman Milanfar&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.05442&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improved Masked Image Generation with Token-Critic&lt;/strong&gt; &lt;br&gt; &lt;em&gt;José Lezama, Huiwen Chang, Lu Jiang, Irfan Essa&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.04439&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Let us Build Bridges: Understanding and Extending Diffusion Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xingchao Liu, Lemeng Wu, Mao Ye, Qiang Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.14699&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wan-Cyuan Fan, Yen-Chun Chen, DongDong Chen, Yu Cheng, Lu Yuan, Yu-Chiang Frank Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.13753&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adaptively-Realistic Image Generation from Stroke and Sketch with Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shin-I Cheng&lt;sup&gt;1&lt;/sup&gt;, Yu-Jie Chen&lt;sup&gt;1&lt;/sup&gt;, Wei-Chen Chiu, Hsin-Ying Lee, Hung-Yu Tseng&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.12675&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://cyj407.github.io/DiSS/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 26 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie S. Li, Hamid Kazemi, Furong Huang, Micah Goldblum, Jonas Geiping, Tom Goldstein&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.09392&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/arpitbansal297/Cold-Diffusion-Models&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bahjat Kawar, Roy Ganz, Michael Elad&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.08664&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 18 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Your ViT is Secretly a Hybrid Discriminative-Generative Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiulong Yang&lt;sup&gt;1&lt;/sup&gt;, Sheng-Min Shih&lt;sup&gt;1&lt;/sup&gt;, Yinlin Fu, Xiaoting Zhao, Shihao Ji&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.07791&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sndnyang/Diffusion_ViT&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Applying Regularized Schrödinger-Bridge-Based Stochastic Process in Generative Modeling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ki-Ung Song&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.07131&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/KiUngSong/RSB&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ting Chen, Ruixiang Zhang, Geoffrey Hinton&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.04202&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pyramidal Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dohoon Ryu, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.01864&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Progressive Deblurring of Diffusion Models for Coarse-to-Fine Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sangyun Lee, Hyungjin Chung, Jaehyeon Kim, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arxiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.11192&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sangyun884/blur-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improving Diffusion Model Efficiency Through Patching&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Troy Luhman, Eric Luhman&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.04316&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ericl122333/PatchDiffusion-Pytorch&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 9 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerating Score-based Generative Models with Preconditioned Diffusion Sampling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hengyuan Ma, Li Zhang, Xiatian Zhu, Jianfeng Feng&lt;/em&gt; &lt;br&gt; ECCV 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.02196&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SPI-GAN: Distilling Score-based Generative Models with Straight-Path Interpolations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jinsung Jeon, Noseong Park&lt;/em&gt; &lt;br&gt; arxiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.14464&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Entropy-driven Sampling and Training Scheme for Conditional Diffusion Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shengming Li, Guangcong Zheng, Hui Wang, Taiping Yao, Yang Chen, Shoudong Ding, Xi Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.11474&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative Modelling With Inverse Heat Dissipation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Severi Rissanen, Markus Heinonen, Arno Solin&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.13397&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://aaltoml.github.io/generative-inverse-heat-dissipation/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion models as plug-and-play priors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alexandros Graikos, Nikolay Malkin, Nebojsa Jojic, Dimitris Samaras&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.09012&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/alexgraikos/diffusion_priors&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 17 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Flexible Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weitao Du, Tao Yang, He Zhang, Yuanqi Du&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.10365&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Lossy Compression with Gaussian Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lucas Theis, Tim Salimans, Matthew D. Hoffman, Fabian Mentzer&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.08889&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Maximum Likelihood Training for Score-Based Diffusion ODEs by High-Order Denoising Score Matching&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cheng Lu, Kaiwen Zheng, Fan Bao, Jianfei Chen, Chongxuan Li, Jun Zhu&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.08265&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LuChengTHU/mle_score_ode&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Estimating the Optimal Covariance with Imperfect Mean in Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Fan Bao, Chongxuan Li, Jiacheng Sun, Jun Zhu, Bo Zhang&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.07309&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/baofff/Extended-Analytic-DPM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Video Prediction and Infilling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tobias Höppe, Arash Mehrjou, Stefan Bauer, Didrik Nielsen, Andrea Dittadi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.07696&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Discrete Contrastive Diffusion for Cross-Modal and Conditional Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ye Zhu, Yu Wu, Kyle Olszewski, Jian Ren, Sergey Tulyakov, Yan Yan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.07771&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/L-YeZhu/CDCD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;gDDIM: Generalized denoising diffusion implicit models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qinsheng Zhang, Molei Tao, Yongxin Chen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.05564&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/qsh-zh/gDDIM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 11 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How Much is Enough? A Study on Diffusion Times in Score-based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giulio Franzese, Simone Rossi, Lixuan Yang, Alessandro Finamore, Dario Rossi, Maurizio Filippone, Pietro Michiardi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.05173&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Image Generation with Multimodal Priors using Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nithin Gopalakrishnan Nair, Wele Gedara Chaminda Bandara, Vishal M Patel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.05039&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerating Score-based Generative Models for High-Resolution Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hengyuan Ma, Li Zhang, Xiatian Zhu, Jingfeng Zhang, Jianfeng Feng&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.04029&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-GAN: Training GANs with Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhendong Wang, Huangjie Zheng, Pengcheng He, Weizhu Chen, Mingyuan Zhou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.02262&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, Jun Zhu&lt;/em&gt; &lt;br&gt; NeurrIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.00927&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LuChengTHU/dpm-solver&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Elucidating the Design Space of Diffusion-Based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tero Karras, Miika Aittala, Timo Aila, Samuli Laine&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.00364&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On Analyzing Generative and Denoising Capabilities of Diffusion-based Deep Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kamil Deja, Anna Kuzina, Tomasz Trzciński, Jakub M. Tomczak&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.00070&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Few-Shot Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giorgio Giannone, Didrik Nielsen, Ole Winther&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.15463&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Continuous Time Framework for Discrete Denoising Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andrew Campbell, Joe Benton, Valentin De Bortoli, Tom Rainforth, George Deligiannidis, Arnaud Doucet&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.14987&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Maximum Likelihood Training of Implicit Nonlinear Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dongjun Kim, Byeonghu Na, Se Jung Kwon, Dongsoo Lee, Wanmo Kang, Il-Chul Moon&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.13699&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerating Diffusion Models via Early Stop of the Diffusion Process&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhaoyang Lyu, Xudong XU, Ceyuan Yang, Dahua Lin, Bo Dai&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.12524&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Flexible Diffusion Modeling of Long Videos&lt;/strong&gt; &lt;br&gt; &lt;em&gt;William Harvey, Saeid Naderiparizi, Vaden Masrani, Christian Weilbach, Frank Wood&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.11495&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/plai-group/flexible-video-diffusion-modeling&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 23 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vikram Voleti&lt;sup&gt;1&lt;/sup&gt;, Alexia Jolicoeur-Martineau&lt;sup&gt;1&lt;/sup&gt;, Christopher Pal&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.09853&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/voletiv/mcvd-pytorch&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On Conditioning the Input Noise for Controlled Image Generation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vedant Singh&lt;sup&gt;1&lt;/sup&gt;, Surgan Jandial&lt;sup&gt;1&lt;/sup&gt;, Ayush Chopra, Siddharth Ramesh, Balaji Krishnamurthy, Vineeth N. Balasubramanian&lt;/em&gt; &lt;br&gt; CVPR Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.03859&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Subspace Diffusion Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bowen Jing, Gabriele Corso, Renato Berlinghieri, Tommi Jaakkola&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.01490&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/bjing2016/subspace-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 3 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast Sampling of Diffusion Models with Exponential Integrator&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qinsheng Zhang, Yongxin Chen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.13902&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Retrieval-Augmented Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andreas Blattmann&lt;sup&gt;1&lt;/sup&gt;, Robin Rombach&lt;sup&gt;1&lt;/sup&gt;, Kaan Oktay, Björn Ommer&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.11824&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Video Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jonathan Ho&lt;sup&gt;1&lt;/sup&gt;, Tim Salimans&lt;sup&gt;1&lt;/sup&gt;, Alexey Gritsenko, William Chan, Mohammad Norouzi, David J. Fleet&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.03458&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Perception Prioritized Training of Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jooyoung Choi, Jungbeom Lee, Chaehun Shin, Sungwon Kim, Hyunwoo Kim, Sungroh Yoon&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.00227&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jychoi118/P2-weighting&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generating High Fidelity Data from Low-density Regions using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vikash Sehwag, Caner Hazirbas, Albert Gordo, Firat Ozgenel, Cristian Canton Ferrer&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.17260&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Counterfactual Explanations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Guillaume Jeanneret, Loïc Simon, Frédéric Jurie&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.15636&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Likelihood Score Matching for Conditional Score-based Data Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chen-Hao Chao, Wei-Fang Sun, Bo-Wun Cheng, Yi-Chen Lo, Chia-Che Chang, Yu-Lun Liu, Yu-Lin Chang, Chia-Ping Chen, Chun-Yi Lee&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.14206&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Probabilistic Modeling for Video Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ruihan Yang, Prakhar Srivastava, Stephan Mandt&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.09481&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/buggyyang/rvd&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dynamic Dual-Output Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yaniv Benny, Lior Wolf&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.04304&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conditional Simulation Using Diffusion Schrödinger Bridges&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuyang Shi, Valentin De Bortoli, George Deligiannidis, Arnaud Doucet&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.13460&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Causal Models for Counterfactual Estimation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pedro Sanchez, Sotirios A. Tsaftaris&lt;/em&gt; &lt;br&gt; PMLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.10166&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pseudo Numerical Methods for Diffusion Models on Manifolds&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Luping Liu, Yi Ren, Zhijie Lin, Zhou Zhao&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.09778&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/luping-liu/PNDM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Truncated Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Huangjie Zheng, Pengcheng He, Weizhu Chen, Mingyuan Zhou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.09671&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Understanding DDPM Latent Codes Through Optimal Transport&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Valentin Khrulkov, Ivan Oseledets&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.07477&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Daniel Watson, William Chan, Jonathan Ho, Mohammad Norouzi&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.05830&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion bridges vector quantized Variational AutoEncoders&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Max Cohen, Guillaume Quispe, Sylvain Le Corff, Charles Ollion, Eric Moulines&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.04895&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Progressive Distillation for Fast Sampling of Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tim Salimans, Jonathan Ho&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.00512&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Fan Bao, Chongxuan Li, Jun Zhu, Bo Zhang&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2201.06503&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kushagra Pandey, Avideep Mukherjee, Piyush Rai, Abhishek Kumar&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2201.00308&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/kpandey008/DiffuseVAE&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Itô-Taylor Sampling Scheme for Denoising Diffusion Probabilistic Models using Ideal Derivatives&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hideyuki Tachibana, Mocho Go, Muneyoshi Inahara, Yotaro Katayama, Yotaro Watanabe&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.13339&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alex Nichol&lt;sup&gt;1&lt;/sup&gt;, Prafulla Dhariwal&lt;sup&gt;1&lt;/sup&gt;, Aditya Ramesh&lt;sup&gt;1&lt;/sup&gt;, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, Mark Chen&lt;/em&gt; &lt;br&gt; ICML 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.10741&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/openai/glide-text2im&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Robin Rombach&lt;sup&gt;1&lt;/sup&gt;, Andreas Blattmann&lt;sup&gt;1&lt;/sup&gt;, Dominik Lorenz, Patrick Esser, Björn Ommer&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.10752&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Heavy-tailed denoising score matching&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jacob Deasy, Nikola Simidjievski, Pietro Liò&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.09788&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;High Fidelity Visualization of What Your Self-Supervised Representation Knows About&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Florian Bordes, Randall Balestriero, Pascal Vincent&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.09164&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Tackling the Generative Learning Trilemma with Denoising Diffusion GANs&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhisheng Xiao, Karsten Kreis, Arash Vahdat&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.07804&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nvlabs.github.io/denoising-diffusion-gan&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 15 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-Based Generative Modeling with Critically-Damped Langevin Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tim Dockhorn, Arash Vahdat, Karsten Kreis&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2112.07068&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nv-tlabs.github.io/CLD-SGM/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 14 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;More Control for Free! Image Synthesis with Semantic Diffusion Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xihui Liu, Dong Huk Park, Samaneh Azadi, Gong Zhang, Arman Chopikyan, Yuxiao Hu, Humphrey Shi, Anna Rohrbach, Trevor Darrell&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.05744&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Minghui Hu, Yujie Wang, Tat-Jen Cham, Jianfei Yang, P.N.Suganthan&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.01799&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Autoencoders: Toward a Meaningful and Decodable Representation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Konpat Preechakul, Nattanat Chatthee, Suttisak Wizadwongsa, Supasorn Suwajanakorn&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2111.15640&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://diff-ae.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/phizaz/diffae&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 30 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conditional Image Generation with Score-Based Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Schönlieb, Christian Etmann&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.13606&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sam Bond-Taylor&lt;sup&gt;1&lt;/sup&gt;, Peter Hessey&lt;sup&gt;1&lt;/sup&gt;, Hiroshi Sasaki, Toby P. Breckon, Chris G. Willcocks&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.12701&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/samb-t/unleashing-transformers&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 24 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Normalizing Flow&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qinsheng Zhang, Yongxin Chen&lt;/em&gt; &lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2110.07579&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/qsh-zh/DiffFlow&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 14 Oct 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Gamma Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Eliya Nachmani&lt;sup&gt;1&lt;/sup&gt;, Robin San Roman&lt;sup&gt;1&lt;/sup&gt;, Lior Wolf&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2110.05948&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Oct 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-based Generative Neural Networks for Large-Scale Optimal Transport&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Max Daniels, Tyler Maunu, Paul Hand&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2110.03237&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Oct 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-Based Generative Classifiers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Roland S. Zimmermann, Lukas Schott, Yang Song, Benjamin A. Dunn, David A. Klindt&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2110.00473&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Oct 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Classifier-Free Diffusion Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jonathan Ho, Tim Salimans&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2021. [&lt;a href=&#34;https://arxiv.org/abs/2207.12598&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Sep 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bilateral Denoising Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Max W. Y. Lam, Jun Wang, Rongjie Huang, Dan Su, Dong Yu&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2108.11514&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://bilateral-denoising-diffusion-model.github.io&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 26 Aug 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ImageBART: Bidirectional Context with Multinomial Diffusion for Autoregressive Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Patrick Esser&lt;sup&gt;1&lt;/sup&gt;, Robin Rombach&lt;sup&gt;1&lt;/sup&gt;, Andreas Blattmann&lt;sup&gt;1&lt;/sup&gt;, Björn Ommer&lt;/em&gt; &lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2108.08827&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://compvis.github.io/imagebart/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 19 Aug 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, Sungroh Yoon&lt;/em&gt; &lt;br&gt; ICCV 2021 (Oral). [&lt;a href=&#34;https://arxiv.org/abs/2108.02938&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jychoi118/ilvr_adm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Aug 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SDEdit: Image Synthesis and Editing with Stochastic Differential Equations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chenlin Meng, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, Stefano Ermon&lt;/em&gt; &lt;br&gt; ICLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2108.01073&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sde-image-editing.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ermongroup/SDEdit&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Aug 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Structured Denoising Diffusion Models in Discrete State-Spaces&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jacob Austin&lt;sup&gt;1&lt;/sup&gt;, Daniel D. Johnson&lt;sup&gt;1&lt;/sup&gt;, Jonathan Ho, Daniel Tarlow, Rianne van den Berg&lt;/em&gt; &lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2107.03006&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jul 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Variational Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Diederik P. Kingma&lt;sup&gt;1&lt;/sup&gt;, Tim Salimans&lt;sup&gt;1&lt;/sup&gt;, Ben Poole, Jonathan Ho&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2107.00630&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/google-research/vdm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Jul 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Priors In Variational Autoencoders&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Antoine Wehenkel&lt;sup&gt;1&lt;/sup&gt;, Gilles Louppe&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; ICML Workshop 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.15671&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deep Generative Learning via Schrödinger Bridge&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gefei Wang, Yuling Jiao, Qian Xu, Yang Wang, Can Yang&lt;/em&gt; &lt;br&gt; ICML 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.10410&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Non Gaussian Denoising Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Eliya Nachmani&lt;sup&gt;1&lt;/sup&gt;, Robin San Roman&lt;sup&gt;1&lt;/sup&gt;, Lior Wolf&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.07582&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://enk100.github.io/Non-Gaussian-Denoising-Diffusion-Models/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 14 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;D2C: Diffusion-Denoising Models for Few-shot Conditional Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Abhishek Sinha&lt;sup&gt;1&lt;/sup&gt;, Jiaming Song&lt;sup&gt;1&lt;/sup&gt;, Chenlin Meng, Stefano Ermon&lt;/em&gt; &lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.06819&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://d2c-model.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/d2c-model/d2c-model.github.io&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 12 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-based Generative Modeling in Latent Space&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Arash Vahdat&lt;sup&gt;1&lt;/sup&gt;, Karsten Kreis&lt;sup&gt;1&lt;/sup&gt;, Jan Kautz&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.05931&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning to Efficiently Sample from Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Daniel Watson, Jonathan Ho, Mohammad Norouzi, William Chan&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.03802&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Variational Perspective on Diffusion-Based Generative Models and Score Matching&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chin-Wei Huang, Jae Hyun Lim, Aaron Courville&lt;/em&gt; &lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.02808&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/CW-Huang/sdeflow-light&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 5 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Soft Truncation: A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, Il-Chul Moon&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2106.05527&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Schrödinger Bridge with Applications to Score-Based Generative Modeling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Valentin De Bortoli, James Thornton, Jeremy Heng, Arnaud Doucet&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.01357&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://jtt94.github.io/papers/schrodinger_bridge&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/JTT94/diffusion_schrodinger_bridge&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On Fast Sampling of Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhifeng Kong, Wei Ping&lt;/em&gt; &lt;br&gt; ICML Workshop 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.00132&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/FengNiMa/FastDPM_pytorch&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 31 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cascaded Diffusion Models for High Fidelity Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jonathan Ho&lt;sup&gt;1&lt;/sup&gt;, Chitwan Saharia&lt;sup&gt;1&lt;/sup&gt;, William Chan, David J. Fleet, Mohammad Norouzi, Tim Salimans&lt;/em&gt; &lt;br&gt; JMLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.15282&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://cascaded-diffusion.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 30 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Gotta Go Fast When Generating Data with Score-Based Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alexia Jolicoeur-Martineau, Ke Li, Rémi Piché-Taillefer, Tal Kachman, Ioannis Mitliagkas&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2105.14080&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/AlexiaJM/score_sde_fast_sampling&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 28 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models Beat GANs on Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Prafulla Dhariwal&lt;sup&gt;1&lt;/sup&gt;, Alex Nichol&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2105.05233&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 11 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Image Super-Resolution via Iterative Refinement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J. Fleet, Mohammad Norouzi&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2104.07636&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://iterative-refinement.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Apr 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Noise Estimation for Generative Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Robin San-Roman&lt;sup&gt;1&lt;/sup&gt;, Eliya Nachmani&lt;sup&gt;1&lt;/sup&gt;, Lior Wolf&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2104.02600&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Apr 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improved Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alex Nichol&lt;sup&gt;1&lt;/sup&gt;, Prafulla Dhariwal&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; ICLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2102.09672&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/openai/improved-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 18 Feb 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Maximum Likelihood Training of Score-Based Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yang Song&lt;sup&gt;1&lt;/sup&gt;, Conor Durkan&lt;sup&gt;1&lt;/sup&gt;, Iain Murray, Stefano Ermon&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2101.09258&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Jan 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Knowledge Distillation in Iterative Generative Models for Improved Sampling Speed&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Eric Luhman&lt;sup&gt;1&lt;/sup&gt;, Troy Luhman&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2101.02388&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/tcl9876/Denoising_Student&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 7 Jan 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning Energy-Based Models by Diffusion Recovery Likelihood&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ruiqi Gao, Yang Song, Ben Poole, Ying Nian Wu, Diederik P. Kingma&lt;/em&gt; &lt;br&gt; ICLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2012.08125&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ruiqigao/recovery_likelihood&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Dec 2020&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-Based Generative Modeling through Stochastic Differential Equations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole&lt;/em&gt; &lt;br&gt; ICLR 2021 (Oral). [&lt;a href=&#34;https://arxiv.org/abs/2011.13456&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yang-song/score_sde&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 26 Nov 2020&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Variational (Gradient) Estimate of the Score Function in Energy-based Latent Variable Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Fan Bao, Kun Xu, Chongxuan Li, Lanqing Hong, Jun Zhu, Bo Zhang&lt;/em&gt; &lt;br&gt; ICML 2021. [&lt;a href=&#34;https://arxiv.org/abs/2010.08258&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Oct 2020&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Implicit Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiaming Song, Chenlin Meng, Stefano Ermon&lt;/em&gt; &lt;br&gt; ICLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2010.02502&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ermongroup/ddim&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Oct 2020&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adversarial score matching and improved sampling for image generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alexia Jolicoeur-Martineau&lt;sup&gt;1&lt;/sup&gt;, Rémi Piché-Taillefer&lt;sup&gt;1&lt;/sup&gt;, Rémi Tachet des Combes, Ioannis Mitliagkas&lt;/em&gt; &lt;br&gt; ICLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2009.05475&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/AlexiaJM/AdversarialConsistentScoreMatching&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 11 Sep 2020&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jonathan Ho, Ajay Jain, Pieter Abbeel&lt;/em&gt; &lt;br&gt; NeurIPS 2020. [&lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/hojonathanho/diffusion&#34;&gt;Github&lt;/a&gt;] [&lt;a href=&#34;https://github.com/pesser/pytorch_diffusion&#34;&gt;Github2&lt;/a&gt;] &lt;br&gt; 19 Jun 2020&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improved Techniques for Training Score-Based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yang Song, Stefano Ermon&lt;/em&gt; &lt;br&gt; NeurIPS 2020. [&lt;a href=&#34;https://arxiv.org/abs/2006.09011&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ermongroup/ncsnv2&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Jun 2020&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative Modeling by Estimating Gradients of the Data Distribution&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yang Song, Stefano Ermon&lt;/em&gt; &lt;br&gt; NeurIPS 2019. [&lt;a href=&#34;https://arxiv.org/abs/1907.05600&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://yang-song.github.io/blog/2021/score/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ermongroup/ncsn&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 12 Jul 2019&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Neural Stochastic Differential Equations: Deep Latent Gaussian Models in the Diffusion Limit&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Belinda Tzen, Maxim Raginsky&lt;/em&gt; &lt;br&gt; arXiv 2019. [&lt;a href=&#34;https://arxiv.org/abs/1905.09883&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 May 2019&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deep Unsupervised Learning using Nonequilibrium Thermodynamics&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, Surya Ganguli&lt;/em&gt; &lt;br&gt; ICML 2015. [&lt;a href=&#34;https://arxiv.org/abs/1503.03585&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Sohl-Dickstein/Diffusion-Probabilistic-Models&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Mar 2015&lt;/p&gt; &#xA;&lt;h3&gt;Segmentation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Distribution Aligned Diffusion and Prototype-guided network for Unsupervised Domain Adaptive Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haipeng Zhou, Lei Zhu, Yuyin Zhou&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12313&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Semantic Latent Space Regression of Diffusion Autoencoders for Vertebral Fracture Grading&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Matthias Keicher, Matan Atad, David Schinz, Alexandra S. Gersing, Sarah C. Foreman, Sophia S. Goller, Juergen Weissinger, Jon Rischewski, Anna-Sophia Dietrich, Benedikt Wiestler, Jan S. Kirschke, Nassir Navab&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12031&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LD-ZNet: A Latent Diffusion Approach for Text-Based Image Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Koutilya Pnvr, Bharat Singh, Pallabi Ghosh, Behjat Siddiquie, David Jacobs&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12343&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffuMask: Synthesizing Images with Pixel-level Annotations for Semantic Segmentation Using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weijia Wu, Yuzhong Zhao, Mike Zheng Shou, Hong Zhou, Chunhua Shen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11681&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://weijiawu.github.io/DiffusionMask/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Object-Centric Slot Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jindong Jiang, Fei Deng, Gautam Singh, Sungjin Ahn&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10834&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diff-UNet: A Diffusion Embedded Network for Volumetric Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhaohu Xing, Liang Wan, Huazhu Fu, Guang Yang, Lei Zhu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10326&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ge-xing/Diff-UNet&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 18 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionSeg: Adapting Diffusion Towards Unsupervised Object Discovery&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chaofan Ma&lt;sup&gt;1&lt;/sup&gt;, Yuhuan Yang&lt;sup&gt;1&lt;/sup&gt;, Chen Ju, Fei Zhang, Jinxiang Liu, Yu Wang, Ya Zhang, Yanfeng Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09813&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stochastic Segmentation with Conditional Categorical Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lukas Zbinden&lt;sup&gt;1&lt;/sup&gt;, Lars Doorenbos&lt;sup&gt;1&lt;/sup&gt;, Theodoros Pissas, Raphael Sznitman, Pablo Márquez-Neila&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08888&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LarsDoorenbos/ccdm-stochastic-segmentation&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffBEV: Conditional Diffusion Model for Bird&#39;s Eye View Perception&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiayu Zou, Zheng Zhu, Yun Ye, Xingang Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08333&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Importance of Aligning Training Strategy with Evaluation for Diffusion Models in 3D Multiclass Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yunguan Fu, Yiwen Li, Shaheer U. Saeed, Matthew J. Clarkson, Yipeng Hu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06040&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mathpluscode/ImgX-DiffSeg&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MaskDiff: Modeling Mask Distribution with Diffusion Probabilistic Model for Few-Shot Instance Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Minh-Quan Le, Tam V. Nguyen, Trung-Nghia Le, Thanh-Toan Do, Minh N. Do, Minh-Triet Tran&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05105&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiarui Xu, Sifei Liu, Arash Vahdat, Wonmin Byeon, Xiaolong Wang, Shalini De Mello&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.04803&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://jerryxu.net/ODISE/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Semantic Diffusion Network for Semantic Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haoru Tan&lt;sup&gt;1&lt;/sup&gt;, Sitong Wu&lt;sup&gt;1&lt;/sup&gt;, Jimin Pi&lt;/em&gt; &lt;br&gt; NeurIPS 2022. &lt;a href=&#34;https://arxiv.org/abs/2302.02057&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junde Wu, Rao Fu, Huihui Fang, Yu Zhang, Yanwu Xu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11798&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionInst: Diffusion Model for Instance Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhangxuan Gu, Haoxing Chen, Zhuoer Xu, Jun Lan, Changhua Meng, Weiqiang Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02773&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/chenhaoxing/DiffusionInst&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 DEc 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multi-Class Segmentation from Aerial Views using Recursive Noise Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Benedikt Kolbeinsson, Krystian Mikolajczyk&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00787&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ryan Burgert, Kanchana Ranasinghe, Xiang Li, Michael S. Ryoo&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13224&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improved HER2 Tumor Segmentation with Subtype Balancing using Deep Generative Networks&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mathias Öttl, Jana Mönius, Matthias Rübner, Carol I. Geppert, Jingna Qiu, Frauke Wilm, Arndt Hartmann, Matthias W. Beckmann, Peter A. Fasching, Andreas Maier, Ramona Erber, Katharina Breininger&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.06150&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junde Wu, Huihui Fang, Yu Zhang, Yehui Yang, Yanwu Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.00611&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerating Diffusion Models via Pre-segmentation Diffusion Sampling for Medical Image Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xutao Guo, Yanwu Yang, Chenfei Ye, Shang Lu, Yang Xiang, Ting Ma&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.17408&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Anatomically constrained CT image translation for heterogeneous blood vessel segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giammarco La Barbera, Haithem Boussaid, Francesco Maso, Sabine Sarnacki, Laurence Rouet, Pietro Gori, Isabelle Bloch&lt;/em&gt; &lt;br&gt; BMVC 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.01713&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Boah Kim&lt;sup&gt;1&lt;/sup&gt;, Yujin Oh&lt;sup&gt;1&lt;/sup&gt;, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14566&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Can segmentation models be trained with fully synthetically generated data?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Virginia Fernandez, Walter Hugo Lopez Pinaya, Pedro Borges, Petru-Daniel Tudosiu, Mark S Graham, Tom Vercauteren, M Jorge Cardoso&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.08256&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Let us Build Bridges: Understanding and Extending Diffusion Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xingchao Liu, Lemeng Wu, Mao Ye, Qiang Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.14699&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Semantic Image Synthesis via Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weilun Wang, Jianmin Bao, Wengang Zhou, Dongdong Chen, Dong Chen, Lu Yuan, Houqiang Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.00050&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Remote Sensing Change Detection (Segmentation) using Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wele Gedara Chaminda Bandara, Nithin Gopalakrishnan Nair, Vishal M. Patel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.11892&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wgcban/ddpm-cd&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 23 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion models as plug-and-play priors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alexandros Graikos, Nikolay Malkin, Nebojsa Jojic, Dimitris Samaras&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.09012&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast Unsupervised Brain Anomaly Detection and Segmentation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Walter H. L. Pinaya, Mark S. Graham, Robert Gray, Pedro F Da Costa, Petru-Daniel Tudosiu, Paul Wright, Yee H. Mah, Andrew D. MacKinnon, James T. Teo, Rolf Jager, David Werring, Geraint Rees, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardos&lt;/em&gt; &lt;br&gt; MICCAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.03461&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Decoder Denoising Pretraining for Semantic Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Emmanuel Brempong Asiedu, Simon Kornblith, Ting Chen, Niki Parmar, Matthias Minderer, Mohammad Norouzi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.11423&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Implicit Image Segmentation Ensembles&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julia Wolleb&lt;sup&gt;1&lt;/sup&gt;, Robin Sandkühler&lt;sup&gt;1&lt;/sup&gt;, Florentin Bieder, Philippe Valmaggia, Philippe C. Cattin&lt;/em&gt; &lt;br&gt; MIDL 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.03145&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Label-Efficient Semantic Segmentation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dmitry Baranchuk, Ivan Rubachev, Andrey Voynov, Valentin Khrulkov, Artem Babenko&lt;/em&gt; &lt;br&gt; ICLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.03126&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yandex-research/ddpm-segmentation&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SegDiff: Image Segmentation with Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tomer Amit, Eliya Nachmani, Tal Shaharbany, Lior Wolf&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.00390&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Dec 2021&lt;/p&gt; &#xA;&lt;h3&gt;Inverse Problem&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiracDiffusion: Denoising and Incremental Reconstruction with Assured Data-Consistency&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zalan Fabian, Berk Tinaz, Mahdi Soltanolkotabi&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14353&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MindDiffuser: Controlled Image Reconstruction from Human Brain Activity with Semantic and Structural Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yizhuo Lu, Changde Du, Dianpeng Wang, Huiguang He&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14139&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DisC-Diff: Disentangled Conditional Diffusion Model for Multi-Contrast MRI Super-Resolution&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ye Mao&lt;sup&gt;1&lt;/sup&gt;, Lan Jiang&lt;sup&gt;1&lt;/sup&gt;, Xi Chen, Chao Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13933&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Sub-volume-based Denoising Diffusion Probabilistic Model for Cone-beam CT Reconstruction from Incomplete Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenjun Xia, Chuang Niu, Wenxiang Cong, Ge Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12861&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Perceptual Quality Assessment Exploration for AIGC Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zicheng Zhang, Chunyi Li, Wei Sun, Xiaohong Liu, Xiongkuo Min, Guangtao Zhai&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12618&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mauricio Delbracio, Peyman Milanfar&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11435&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Efficient Neural Generation of 4K Masks for Homogeneous Diffusion Inpainting&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Karl Schrader, Pascal Peter, Niklas Kämper, Joachim Weickert&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10096&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Post-Processing for Low-Light Image Enhancement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Savvas Panagiotou, Anna S. Bosman&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09627&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SUD2: Supervision by Denoising Diffusion Models for Image Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Matthew A. Chan, Sean I. Young, Christopher A. Metzler&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09642&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffIR: Efficient Diffusion Model for Image Restoration&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bin Xia, Yulun Zhang, Shiyin Wang, Yitong Wang, Xinglong Wu, Yapeng Tian, Wenming Yang, Luc Van Gool&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09472&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ResDiff: Combining CNN and Diffusion Model for Image Super-Resolution&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shuyao Shang, Zhengyang Shan, Guangxing Liu, Jinglin Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08714&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Class-Guided Image-to-Image Diffusion: Cell Painting from Brightfield Images with Class Labels&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jan Oscar Cross-Zamirski, Praveen Anand, Guy Williams, Elizabeth Mouchet, Yinhai Wang, Carola-Bibiane Schönlieb&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08863&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/crosszamirski/guided-I2I&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Contrast Harmonization of Magnetic Resonance Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alicia Durrer, Julia Wolleb, Florentin Bieder, Tim Sinnecker, Matthias Weigel, Robin Sandkühler, Cristina Granziera, Özgür Yaldizli, Philippe C. Cattin&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08189&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Synthesizing Realistic Image Restoration Training Pairs: A Diffusion Approach&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tao Yang, Peiran Ren, Xuansong xie, Lei Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06994&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DR2: Diffusion-based Robust Degradation Remover for Blind Face Restoration&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhixin Wang, Xiaoyun Zhang, Ziying Zhang, Huangjie Zheng, Mingyuan Zhou, Ya Zhang, Yanfeng Wang&lt;/em&gt; &lt;br&gt; CVPR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06885&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for Hyperspectral Image Restoration&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuchun Miao, Lefei Zhang, Liangpei Zhang, Dacheng Tao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06682&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast Diffusion Sampler for Inverse Problems by Geometric Decomposition&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung, Suhyeon Lee, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05754&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generalized Diffusion MRI Denoising and Super-Resolution using Swin Transformers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Amir Sadikov, Jamie Wren-Jarvis, Xinlei Pan, Lanya T. Cai, Pratik Mukherjee&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05686&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionDepth: Diffusion Denoising Approach for Monocular Depth Estimation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yiqun Duan, Zheng Zhu, Xianda Guo&lt;/em&gt; &lt;br&gt; arxiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05021&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/duanyiqun/DiffusionDepth&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 9 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning Enhancement From Degradation: A Diffusion Model For Fundus Image Enhancement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Puijin Cheng, Li Lin, Yijin Huang, Huaqing He, Wenhan Luo, Xiaoying Tang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.04603&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/QtacierP/LED&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unlimited-Size Diffusion Restoration&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yinhuai Wang, Jiwen Yu, Runyi Yu, Jian Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.00354&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unsupervised Out-of-Distribution Detection with Diffusion Inpainting&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhenzhen Liu&lt;sup&gt;1&lt;/sup&gt;, Jin Peng Zhou&lt;sup&gt;1&lt;/sup&gt;, Yufan Wang, Kilian Q. Weinberger&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10326&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Restoration based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jaemoo Choi&lt;sup&gt;1&lt;/sup&gt;, Yesom Park&lt;sup&gt;1&lt;/sup&gt;, Myungjoo Kang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05456&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Explicit Diffusion of Gaussian Mixture Model Based Image Priors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Martin Zach, Thomas Pock, Erich Kobler, Antonin Chambolle&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.08411&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Probabilistic Models for Robust Image Super-Resolution in the Wild&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hshmat Sahak, Daniel Watson, Chitwan Saharia, David Fleet&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07864&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CDPMSR: Conditional Diffusion Probabilistic Models for Single Image Super-Resolution&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Axi Niu, Kang Zhang, Trung X. Pham, Jinqiu Sun, Yu Zhu, In So Kweon, Yanning Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.12831&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How to Trust Your Diffusion Model: A Convex Optimization Approach to Conformal Risk Control&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jacopo Teneggi, Matt Tivnan, J Webster Stayman, Jeremias Sulam&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03791&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DDM2: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tiange Xiang, Mahmut Yurt, Ali B Syed, Kawin Setsompop, Akshay Chaudhari&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03018&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/StanfordMIMI/DDM2&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Model for Generative Image Denoising&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yutong Xie, Minne Yuan, Bin Dong, Quanzheng Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02398&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Theoretical Justification for Image Inpainting using Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Litu Rout, Advait Parulekar, Constantine Caramanis, Sanjay Shakkottai&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.01217&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Naoki Murata, Koichi Saito, Chieh-Hsin Lai, Yuhta Takida, Toshimitsu Uesaka, Yuki Mitsufuji, Stefano Ermon&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12686&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerating Guided Diffusion Sampling with Splitting Numerical Methods&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Suttisak Wizadwongsa, Supasorn Suwajanakorn&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11558&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Denoising for Low-Dose-CT Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Runyi Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11482&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dual Diffusion Architecture for Fisheye Image Rectification: Synthetic-to-Real Generalization&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shangrong Yang, Chunyu Lin, Kang Liao, Yao Zhao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11785&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;RainDiffusion:When Unsupervised Learning Meets Diffusion Models for Real-world Image Deraining&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mingqiang Wei, Yiyang Shen, Yongzhen Wang, Haoran Xie, Fu Lee Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.09430&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image Fusion with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mingqiang Wei, Yiyang Shen, Yongzhen Wang, Haoran Xie, Fu Lee Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.09430&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Removing Structured Noise with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tristan S.W. Stevens&lt;sup&gt;1&lt;/sup&gt;, Jean-Luc Robert&lt;sup&gt;1&lt;/sup&gt;, Faik C. Meral Jason Yu, Jun Seob Shin, Ruud J.G. van Sloun&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.05290&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Image Restoration with Mean-Reverting Stochastic Differential Equations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ziwei Luo, Fredrik K. Gustafsson, Zheng Zhao, Jens Sjölund, Thomas B. Schön&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11699&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Algolzw/image-restoration-sde&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionCT: Latent Diffusion Model for CT Image Standardization&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Md Selim, Jie Zhang, Michael A. Brooks, Ge Wang, Jin Chen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.08815&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Targeted Image Reconstruction by Sampling Pre-trained Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiageng Zheng&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.07557&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 18 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Annealed Score-Based Diffusion Model for MR Motion Artifact Reduction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gyutaek Oh, Jeong Eun Lee, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.03027&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Exploring Vision Transformers as Diffusion Learners&lt;/strong&gt; &lt;br&gt; &lt;em&gt;He Cao, Jianan Wang, Tianhe Ren, Xianbiao Qi, Yihao Chen, Yuan Yao, Lei Zhang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.13771&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Towards Blind Watermarking: Combining Invertible and Non-invertible Mechanisms&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rui Ma, Mengxi Guo, Yi Hou, Fan Yang, Yuan Li, Huizhu Jia, Xiaodong Xie&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.12678&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/rmpku/CIN&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 24 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bi-Noising Diffusion: Towards Conditional Diffusion Models with Generative Restoration Priors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kangfu Mei, Nithin Gopalakrishnan Nair, Vishal M. Patel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.07352&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://kfmei.page/bi-noising/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 14 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SPIRiT-Diffusion: SPIRiT-driven Score-Based Generative Modeling for Vessel Wall imaging&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chentao Cao, Zhuo-Xu Cui, Jing Cheng, Sen Jia, Hairong Zheng, Dong Liang, Yanjie Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.11274&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Universal Generative Modeling in Dual-domain for Dynamic MR Imaging&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chuanming Yu, Yu Guan, Ziwen Ke, Dong Liang, Qiegen Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.07599&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DifFace: Blind Face Restoration with Diffused Error Contraction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zongsheng Yue, Chen Change Loy&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.06512&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zsyOAOA/DifFace&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ShadowDiffusion: When Degradation Prior Meets Diffusion Model for Shadow Removal&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lanqing Guo, Chong Wang, Wenhan Yang, Siyu Huang, Yufei Wang, Hanspeter Pfister, Bihan Wen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04711&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;One Sample Diffusion Model in Projection Domain for Low-Dose CT Imaging&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bin Huang, Liu Zhang, Shiyu Lu, Boyu Lin, Weiwen Wu, Qiegen Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03630&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SDM: Spatial Diffusion Model for Large Hole Image Inpainting&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenbo Li, Xin Yu, Kun Zhou, Yibing Song, Zhe Lin, Jiaya Jia&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02963&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ADIR: Adaptive Diffusion for Image Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shady Abu-Hussein, Tom Tirer, Raja Giryes&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03221&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://shadyabh.github.io/ADIR/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Image Deblurring with Domain Generalizable Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mengwei Ren, Mauricio Delbracio, Hossein Talebi, Guido Gerig, Peyman Milanfar&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.01789&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yinhuai Wang&lt;sup&gt;1&lt;/sup&gt;, Jiwen Yu&lt;sup&gt;1&lt;/sup&gt;, Jian Zhang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00490&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wyhuai/DDNM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;FREDSR: Fourier Residual Efficient Diffusive GAN for Single Image Super Resolution&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kyoungwan Woo&lt;sup&gt;1&lt;/sup&gt;, Achyuta Rajaram&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16678&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CHIMLE: Conditional Hierarchical IMLE for Multimodal Conditional Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shichong Peng, Alireza Moazeni, Ke Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.14286&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DOLCE: A Model-Based Probabilistic Diffusion Framework for Limited-Angle CT Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiaming Liu, Rushil Anirudh, Jayaraman J. Thiagarajan, Stewart He, K. Aditya Mohan, Ulugbek S. Kamilov, Hyojin Kim&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12340&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Model Based Posterior Sampling for Noisy Linear Inverse Problems&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiangming Meng, Yoshiyuki Kabashima&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12343&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mengxiangming/dmps&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Parallel Diffusion Models of Operator and Image for Blind Inverse Problems&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung&lt;sup&gt;1&lt;/sup&gt;, Jeongsol Kim&lt;sup&gt;1&lt;/sup&gt;, Sehui Kim, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10656&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solving 3D Inverse Problems using Pre-trained 2D Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung&lt;sup&gt;1&lt;/sup&gt;, Dohoon Ryu&lt;sup&gt;1&lt;/sup&gt;, Michael T. McCann, Marc L. Klasky, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10655&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Patch-Based Denoising Diffusion Probabilistic Model for Sparse-View CT Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenjun Xia, Wenxiang Cong, Ge Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10388&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 18 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Structure-Guided Diffusion Model for Large-Hole Diverse Image Completion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Daichi Horita, Jiaolong Yang, Dong Chen, Yuki Koyama, Kiyoharu Aizawa&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10437&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 18 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conffusion: Confidence Intervals for Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Eliahu Horwitz, Yedid Hoshen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09795&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Superresolution Reconstruction of Single Image for Latent features&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xin Wang, Jing-Ke Yan, Jing-Ye Cai, Jian-Hua Deng, Qin Qin, Qin Wang, Heng Xiao, Yao Cheng, Peng-Fei Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12845&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DriftRec: Adapting diffusion models to blind image restoration tasks&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Simon Welker, Henry N. Chapman, Timo Gerkmann&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.06757&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;From Denoising Diffusions to Denoising Markov Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Joe Benton, Yuyang Shi, Valentin De Bortoli, George Deligiannidis, Arnaud Doucet&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.03595&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yuyang-shi/generalized-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 7 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Intelligent Painter: Picture Composition With Resampling Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wing-Fung Ku, Wan-Chi Siu, Xi Cheng, H. Anthony Chan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.17106&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multitask Brain Tumor Inpainting with Diffusion Models: A Methodological Report&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pouria Rouzrokh&lt;sup&gt;1&lt;/sup&gt;, Bardia Khosravi&lt;sup&gt;1&lt;/sup&gt;, Shahriar Faghani, Mana Moassefi, Sanaz Vahdati, Bradley J. Erickson&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.12113&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Mayo-Radiology-Informatics-Lab/MBTI&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 21 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffGAR: Model-Agnostic Restoration from Generative Artifacts Using Image-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yueqin Yin, Lianghua Huang, Yu Liu, Kaiqi Huang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.08573&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Low-Dose CT Using Denoising Diffusion Probabilistic Model for 20× Speedup&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenjun Xia, Qing Lyu, Ge Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.15136&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Posterior Sampling for General Noisy Inverse Problems&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung&lt;sup&gt;1&lt;/sup&gt;, Jeongsol Kim&lt;sup&gt;1&lt;/sup&gt;, Michael T. Mccann, Marc L. Klasky, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14687&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/DPS2022/diffusion-posterior-sampling&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Face Super-Resolution Using Stochastic Differential Equations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Marcelo dos Santos&lt;sup&gt;1&lt;/sup&gt;, Rayson Laroca&lt;sup&gt;1&lt;/sup&gt;, Rafael O. Ribeiro, João Neves, Hugo Proença, David Menotti&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.12064&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/marcelowds/sr-sde&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 24 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;JPEG Artifact Correction using Denoising Diffusion Restoration Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bahjat Kawar&lt;sup&gt;1&lt;/sup&gt;, Jiaming Song&lt;sup&gt;1&lt;/sup&gt;, Stefano Ermon, Michael Elad&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.11888&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;T2V-DDPM: Thermal to Visible Face Translation using Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nithin Gopalakrishnan Nair, Vishal M. Patel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.08814&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Delving Globally into Texture and Structure for Image Inpainting&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haipeng Liu, Yang Wang, Meng Wang, Yong Rui&lt;/em&gt; &lt;br&gt; ACM 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.08217&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/htyjers/DGTS-Inpainting&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 17 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PET image denoising based on denoising diffusion probabilistic models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kuang Gong, Keith A. Johnson, Georges El Fakhri, Quanzheng Li, Tinsu Pan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.06167&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Self-Score: Self-Supervised Learning on Score-Based Models for MRI Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhuo-Xu Cui, Chentao Cao, Shaonan Liu, Qingyong Zhu, Jing Cheng, Haifeng Wang, Yanjie Zhu, Dong Liang&lt;/em&gt; &lt;br&gt; IEEE TMI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.00835&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AT-DDPM: Restoring Faces degraded by Atmospheric Turbulence using Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nithin Gopalakrishnan Nair, Kangfu Mei, Vishal M Patel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.11284&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie S. Li, Hamid Kazemi, Furong Huang, Micah Goldblum, Jonas Geiping, Tom Goldstein&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.09392&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/arpitbansal297/Cold-Diffusion-Models&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;High-Frequency Space Diffusion Models for Accelerated MRI&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chentao Cao, Zhuo-Xu Cui, Shaonan Liu, Dong Liang, Yanjie Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.05481&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Restoring Vision in Adverse Weather Conditions with Patch-Based Denoising Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ozan Özdenizci, Robert Legenstein&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.14626&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/IGITUGraz/WeatherDiffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Non-Uniform Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Schönlieb, Christian Etmann&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.09786&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unsupervised Medical Image Translation with Adversarial Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Muzaffer Özbey, Salman UH Dar, Hasan A Bedel, Onat Dalmaz, Şaban Özturk, Alper Güngör, Tolga Çukur&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.08208&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adaptive Diffusion Priors for Accelerated MRI Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Salman UH Dar, Şaban Öztürk, Yilmaz Korkmaz, Gokberk Elmas, Muzaffer Özbey, Alper Güngör, Tolga Çukur&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.05876&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Novel Unified Conditional Score-based Generative Framework for Multi-modal Medical Image Completion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiangxi Meng, Yuning Gu, Yongsheng Pan, Nizhuan Wang, Peng Xue, Mengkang Lu, Xuming He, Yiqiang Zhan, Dinggang Shen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.03430&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SAR Despeckling using a Denoising Diffusion Probabilistic Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Malsha V. Perera, Nithin Gopalakrishnan Nair, Wele Gedara Chaminda Bandara, Vishal M. Patel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.04514&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improving Diffusion Models for Inverse Problems using Manifold Constraints&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung&lt;sup&gt;1&lt;/sup&gt;, Byeongsu Sim&lt;sup&gt;1&lt;/sup&gt;, Dohoon Ryu, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.00941&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Swiss Army Knife for Image-to-Image Translation: Multi-Task Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julia Wolleb&lt;sup&gt;1&lt;/sup&gt;, Robin Sandkühler&lt;sup&gt;1&lt;/sup&gt;, Florentin Bieder, Philippe C. Cattin&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.02641&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MR Image Denoising and Super-Resolution Using Regularized Reverse Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung, Eun Sun Lee, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.12621&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Towards performant and reliable undersampled MR reconstruction via diffusion model sampling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cheng Peng, Pengfei Guo, S. Kevin Zhou, Vishal Patel, Rama Chellappa&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.04292&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/cpeng93/diffuserecon&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Measurement-conditioned Denoising Diffusion Probabilistic Model for Under-sampled Medical Image Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yutong Xie, Quanzheng Li&lt;/em&gt; &lt;br&gt; MICCAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.03623&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Theodore-PKU/MC-DDPM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 5 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MRI Reconstruction via Data Driven Markov Chain with Joint Uncertainty Estimation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Guanxiong Luo, Martin Heide, Martin Uecker&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.01479&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mrirecon/spreco&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 3 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unsupervised Denoising of Retinal OCT with Diffusion Probabilistic Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dewei Hu, Yuankai K. Tao, Ipek Oguz&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2201.11760&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/DeweiHu/OCT_DDPM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Restoration Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song&lt;/em&gt; &lt;br&gt; ICLR 2022 Workshop (Oral). [&lt;a href=&#34;https://arxiv.org/abs/2201.11793&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;RePaint: Inpainting using Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, Luc Van Gool&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2201.09865&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/andreas128/RePaint&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 24 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kushagra Pandey, Avideep Mukherjee, Piyush Rai, Abhishek Kumar&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2201.00308&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/kpandey008/DiffuseVAE&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Robin Rombach&lt;sup&gt;1&lt;/sup&gt;, Andreas Blattmann&lt;sup&gt;1&lt;/sup&gt;, Dominik Lorenz, Patrick Esser, Björn Ommer&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2112.10752&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Come-Closer-Diffuse-Faster: Accelerating Conditional Diffusion Models for Inverse Problems through Stochastic Contraction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung, Byeongsu Sim, Jong Chul Ye&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2112.05146&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deblurring via Stochastic Refinement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jay Whang, Mauricio Delbracio, Hossein Talebi, Chitwan Saharia, Alexandros G. Dimakis, Peyman Milanfar&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2112.02475&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conditional Image Generation with Score-Based Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Schönlieb, Christian Etmann&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.13606&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solving Inverse Problems in Medical Imaging with Score-Based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yang Song&lt;sup&gt;1&lt;/sup&gt;, Liyue Shen&lt;sup&gt;1&lt;/sup&gt;, Lei Xing, Stefano Ermon&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.08005&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yang-song/score_inverse_problems&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;S3RP: Self-Supervised Super-Resolution and Prediction for Advection-Diffusion Process&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chulin Wang, Kyongmin Yeo, Xiao Jin, Andres Codas, Levente J. Klein, Bruce Elmegreen&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2111.04639&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-based diffusion models for accelerated MRI&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung, Jong chul Ye&lt;/em&gt; &lt;br&gt; MIA 2021. [&lt;a href=&#34;https://arxiv.org/abs/2110.05243&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/HJ-harry/score-MRI&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Oct 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Autoregressive Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Emiel Hoogeboom, Alexey A. Gritsenko, Jasmijn Bastings, Ben Poole, Rianne van den Berg, Tim Salimans&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2110.02037&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Oct 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, Sungroh Yoon&lt;/em&gt; &lt;br&gt; ICCV 2021 (Oral). [&lt;a href=&#34;https://arxiv.org/abs/2108.02938&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jychoi118/ilvr_adm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Aug 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cascaded Diffusion Models for High Fidelity Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jonathan Ho&lt;sup&gt;1&lt;/sup&gt;, Chitwan Saharia&lt;sup&gt;1&lt;/sup&gt;, William Chan, David J. Fleet, Mohammad Norouzi, Tim Salimans&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.15282&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://cascaded-diffusion.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 30 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SRDiff: Single Image Super-Resolution with Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haoying Li, Yifan Yang, Meng Chang, Huajun Feng, Zhihai Xu, Qi Li, Yueting Chen&lt;/em&gt; &lt;br&gt; ACM 2022. [&lt;a href=&#34;https://arxiv.org/abs/2104.14951&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Apr 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Image Super-Resolution via Iterative Refinement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J. Fleet, Mohammad Norouzi&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2104.07636&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://iterative-refinement.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Apr 2021&lt;/p&gt; &#xA;&lt;h3&gt;Image Translation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Target Sampler for Unsupervised Domain Adaptation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yulong Zhang, Shuhao Chen, Yu Zhang, Jiangang Lu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12724&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;StyO: Stylize Your Face in Only One-Shot&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bonan Li, Zicheng Zhang, Xuecheng Nie, Congying Han, Yinhan Hu, Tiande Guo&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.03231&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffFashion: Reference-based Fashion Design with Structure-aware Transfer by Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shidong Cao&lt;sup&gt;1&lt;/sup&gt;, Wenhao Chai&lt;sup&gt;1&lt;/sup&gt;, Shengyu Hao, Yanting Zhang, Hangyue Chen, Gaoang Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.06826&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;I2SB: Image-to-Image Schrödinger Bridge&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Guan-Horng Liu, Arash Vahdat, De-An Huang, Evangelos A. Theodorou, Weili Nie, Anima Anandkumar&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.05872&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://i2sb.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 12 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zihao Wang, Yingyu Yang, Maxime Sermesant, Hervé Delingette, Ona Wu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13743&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffFace: Diffusion-based Face Swapping with Facial Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kihong Kim, Yunho Kim, Seokju Cho, Junyoung Seo, Jisu Nam, Kychul Lee, Seungryong Kim, KwangHee Lee&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.13344&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://hxngiee.github.io/DiffFace/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 27 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;HS-Diffusion: Learning a Semantic-Guided Diffusion Model for Head Swapping&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qinghe Wang, Lijie Liu, Miao Hua, Qian He, Pengfei Zhu, Bing Cao, Qinghua Hu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.06458&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unifying Diffusion Models&#39; Latent Space, with Applications to CycleDiffusion and Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chen Henry Wu, Fernando De la Torre&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.05559&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ChenWu98/cycle-diffusion&#34;&gt;Github-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ChenWu98/unified-generative-zoo&#34;&gt;Github-2&lt;/a&gt;] &lt;br&gt; 11 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Anatomically constrained CT image translation for heterogeneous blood vessel segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giammarco La Barbera, Haithem Boussaid, Francesco Maso, Sabine Sarnacki, Laurence Rouet, Pietro Gori, Isabelle Bloch&lt;/em&gt; &lt;br&gt; BMVC 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.01713&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Image Translation using Disentangled Style and Content Representation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gihyun Kwon, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.15264&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image Translation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junyoung Seo&lt;sup&gt;1&lt;/sup&gt;, Gyuseong Lee&lt;sup&gt;1&lt;/sup&gt;, Seokju Cho, Jiyoung Lee, Seungryong Kim&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.11047&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ku-cvlab.github.io/MIDMs/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 22 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Restoring Vision in Adverse Weather Conditions with Patch-Based Denoising Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ozan Özdenizci, Robert Legenstein&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.14626&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Non-Uniform Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Schönlieb, Christian Etmann&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.09786&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unsupervised Medical Image Translation with Adversarial Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Muzaffer Özbey, Salman UH Dar, Hasan A Bedel, Onat Dalmaz, Şaban Özturk, Alper Güngör, Tolga Çukur&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.08208&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Min Zhao, Fan Bao, Chongxuan Li, Jun Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.06635&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Discrete Contrastive Diffusion for Cross-Modal and Conditional Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ye Zhu, Yu Wu, Kyle Olszewski, Jian Ren, Sergey Tulyakov, Yan Yan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.07771&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/L-YeZhu/CDCD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pretraining is All You Need for Image-to-Image Translation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tengfei Wang, Ting Zhang, Bo Zhang, Hao Ouyang, Dong Chen, Qifeng Chen, Fang Wen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.12952&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://tengfei-wang.github.io/PITI/index.html&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/PITI-Synthesis/PITI&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 25 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;VQBB: Image-to-image Translation with Vector Quantized Brownian Bridge&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bo Li, Kaitao Xue, Bin Liu, Yu-Kun Lai&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.07680&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Swiss Army Knife for Image-to-Image Translation: Multi-Task Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julia Wolleb&lt;sup&gt;1&lt;/sup&gt;, Robin Sandkühler&lt;sup&gt;1&lt;/sup&gt;, Florentin Bieder, Philippe C. Cattin&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.02641&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dual Diffusion Implicit Bridges for Image-to-Image Translation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xuan Su, Jiaming Song, Chenlin Meng, Stefano Ermon&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.08382&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Restoration Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2201.11793&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffuseMorph: Unsupervised Deformable Image Registration Along Continuous Trajectory Using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Boah Kim, Inhwa Han, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.05149&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Autoencoders: Toward a Meaningful and Decodable Representation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Konpat Preechakul, Nattanat Chatthee, Suttisak Wizadwongsa, Supasorn Suwajanakorn&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.15640&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://diff-ae.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 30 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conditional Image Generation with Score-Based Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Schönlieb, Christian Etmann&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.13606&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, Sungroh Yoon&lt;/em&gt; &lt;br&gt; ICCV 2021 (Oral). [&lt;a href=&#34;https://arxiv.org/abs/2108.02938&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jychoi118/ilvr_adm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Aug 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hiroshi Sasaki, Chris G. Willcocks, Toby P. Breckon&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2104.05358&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Apr 2021&lt;/p&gt; &#xA;&lt;h3&gt;Text driven Image Generation and Editing&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hiromichi Kamata, Yuiko Sakuma, Akio Hayakawa, Masato Ishii, Takuya Narihira&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15780&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sony.github.io/Instruct3Dto3D-doc/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 28 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;StyleDiffusion: Prompt-Embedding Inversion for Text-Based Editing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Senmao Li, Joost van de Weijer, Taihang Hu, Fahad Shahbaz Khan, Qibin Hou, Yaxing Wang, Jian Yang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15649&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Seer: Language Instructed Video Prediction with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xianfan Gu, Chuan Wen, Jiaming Song, Yang Gao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14897&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Susung Hong&lt;sup&gt;1&lt;/sup&gt;, Donghoon Ahn&lt;sup&gt;1&lt;/sup&gt;, Seungryong Kim&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15413&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Anti-DreamBooth: Protecting users from personalized text-to-image synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Thanh Van Le, Hao Phung, Thuan Hoang Nguyen, Quan Dao, Ngoc Tran, Anh Tran&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15433&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/VinAIResearch/Anti-DreamBooth&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GestureDiffuCLIP: Gesture Diffusion Model with CLIP Latents&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tenglong Ao, Zeyi Zhang, Libin Liu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14613&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Better Aligning Text-to-Image Models with Human Preference&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiaoshi Wu, Keqiang Sun, Feng Zhu, Rui Zhao, Hongsheng Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14420&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://tgxs002.github.io/align_sd_web/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 25 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ISS++: Image as Stepping Stone for Text-Guided 3D Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhengzhe Liu, Peng Dai, Ruihui Li, Xiaojuan Qi, Chi-Wing Fu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15181&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yiqi Lin&lt;sup&gt;1&lt;/sup&gt;, Haotian Bai&lt;sup&gt;1&lt;/sup&gt;, Sijia Li, Haonan Lu, Xiaodong Lin, Hui Xiong, Lin Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13843&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://fantasia3d.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rui Chen, Yongwei Chen, Ningxin Jiao, Kui Jia&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13873&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ayaan Haque, Matthew Tancik, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12789&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://instruct-nerf2nerf.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Juil Koo&lt;sup&gt;1&lt;/sup&gt;, Seungwoo Yoo&lt;sup&gt;1&lt;/sup&gt;, Minh Hieu Nguyen&lt;sup&gt;1&lt;/sup&gt;, Minhyuk Sung&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12236&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://salad3d.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Vox-E: Text-guided Voxel Editing of 3D Objects&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Etai Sella, Gal Fiebelman, Peter Hedman, Hadar Averbuch-Elor&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12048&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://tau-vailab.github.io/Vox-E/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3D-CLFusion: Fast Text-to-3D Rendering with Contrastive Latent Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yu-Jhe Li, Kris Kitani&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11938&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text2Tex: Text-driven Texture Synthesis via Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dave Zhenyu Chen, Yawar Siddiqui, Hsin-Ying Lee, Sergey Tulyakov, Matthias Nießner&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11396&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://daveredrum.github.io/Text2Tex/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Localizing Object-level Shape Variations with Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Or Patashnik, Daniel Garibi, Idan Azuri, Hadar Averbuch-Elor, Daniel Cohen-Or&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11306&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://orpatashnik.github.io/local-prompt-mixing/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SVDiff: Compact Parameter Space for Diffusion Fine-Tuning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ligong Han, Yinxiao Li, Han Zhang, Peyman Milanfar, Dimitris Metaxas, Feng Yang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11305&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Discovering Interpretable Directions in the Semantic Latent Space of Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;René Haas, Inbar Huberman-Spiegelglas, Rotem Mulayoff, Tomer Michaeli&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11073&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SKED: Sketch-guided Text-based 3D Editing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Aryan Mikaeili, Or Perel, Daniel Cohen-Or, Ali Mahdavi-Amiri&lt;/em&gt; &lt;br&gt; arxiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10735&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DialogPaint: A Dialog-based Image Editing Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jingxuan Wei&lt;sup&gt;1&lt;/sup&gt;, Shiyu Wu&lt;sup&gt;1&lt;/sup&gt;, Xin Jiang, Yequan Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10073&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GlueGen: Plug and Play Multi-modal Encoders for X-to-image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Can Qin, Ning Yu, Chen Xing, Shu Zhang, Zeyuan Chen, Stefano Ermon, Yun Fu, Caiming Xiong, Ran Xu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10056&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionRet: Generative Text-Video Retrieval with Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Peng Jin&lt;sup&gt;1&lt;/sup&gt;, Hao Li&lt;sup&gt;1&lt;/sup&gt;, Zesen Cheng, Kehan Li, Xiangyang Ji, Chang Liu, Li Yuan, Jie Chen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09867&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiwen Yu, Yinhuai Wang, Chen Zhao, Bernard Ghanem, Jian Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09833&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/vvictoryuki/FreeDoM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unified Multi-Modal Latent Diffusion for Joint Subject and Text Conditional Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yiyang Ma, Huan Yang, Wenjing Wang, Jianlong Fu, Jiaying Liu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09319&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;FateZero: Fusing Attentions for Zero-shot Text-based Video Editing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chenyang Qi, Xiaodong Cun, Yong Zhang, Chenyang Lei, Xintao Wang, Ying Shan, Qifeng Chen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09535&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://fate-zero-edit.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ChenyangQiQi/FateZero&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;HIVE: Harnessing Human Feedback for Instructional Visual Editing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shu Zhang&lt;sup&gt;1&lt;/sup&gt;, Xinyi Yang&lt;sup&gt;1&lt;/sup&gt;, Yihao Feng&lt;sup&gt;1&lt;/sup&gt;, Can Qin, Chia-Chih Chen, Ning Yu, Zeyuan Chen, Huan Wang, Silvio Savarese, Stefano Ermon, Caiming Xiong, Ran Xu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09618&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;P+: Extended Textual Conditioning in Text-to-Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andrey Voynov, Qinghao Chu, Daniel Cohen-Or, Kfir Aberman&lt;/em&gt; &lt;br&gt; arXiv 2023. [[Paper(https://arxiv.org/abs/2303.09522)] [&lt;a href=&#34;https://prompt-plus.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Highly Personalized Text Embedding for Image Manipulation by Stable Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Inhwa Han&lt;sup&gt;1&lt;/sup&gt;, Serin Yang&lt;sup&gt;1&lt;/sup&gt;, Taesung Kwon, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08767&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Aerial Diffusion: Text Guided Ground-to-Aerial View Translation from a Single Image using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Divya Kothandaraman, Tianyi Zhou, Ming Lin, Dinesh Manocha&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11444&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/divyakraman/AerialDiffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Serin Yang, Hyunmin Hwang, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08622&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Edit-A-Video: Single Video Editing with Object-Aware Consistency&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chaehun Shin&lt;sup&gt;1&lt;/sup&gt;, Heeseung Kim&lt;sup&gt;1&lt;/sup&gt;, Che Hyun Lee, Sang-gil Lee, Sungroh Yoon&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.07945&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://edit-a-video.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Editing Implicit Assumptions in Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hadas Orgad&lt;sup&gt;1&lt;/sup&gt;, Bahjat Kawar&lt;sup&gt;1&lt;/sup&gt;, Yonatan Belinkov&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08084&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://time-diffusion.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/bahjat-kawar/time-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junyoung Seo&lt;sup&gt;1&lt;/sup&gt;, Wooseok Jang&lt;sup&gt;1&lt;/sup&gt;, Min-Seop Kwak&lt;sup&gt;1&lt;/sup&gt;, Jaehoon Ko, Hyeonsu Kim, Junho Kim, Jin-Hwa Kim, Jiyoung Lee, Seungryong Kim&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.07937&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, Nan Duan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.04671&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/microsoft/visual-chatgpt&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Video-P2P: Video Editing with Cross-attention Control&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shaoteng Liu, Yuechen Zhang, Wenbo Li, Zhe Lin, Jiaya Jia&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.04761&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://video-p2p.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Erasing Concepts from Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rohit Gandikota&lt;sup&gt;1&lt;/sup&gt;, Joanna Materzynska&lt;sup&gt;1&lt;/sup&gt;, Jaden Fiotto-Kaufman, David Bau&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.07345&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://erasing.baulab.info/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/rohitgandikota/erasing&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Fan Bao, Shen Nie, Kaiwen Xue, Chongxuan Li, Shi Pu, Yaole Wang, Gang Yue, Yue Cao, Hang Su, Jun Zhu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06555&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/thu-ml/unidiffuser&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 12 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cones: Concept Neurons in Diffusion Models for Customized Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhiheng Liu&lt;sup&gt;1&lt;/sup&gt;, Ruili Feng&lt;sup&gt;1&lt;/sup&gt;, Kai Zhu, Yifei Zhang, Kecheng Zheng, Yu Liu, Deli Zhao, Jingren Zhou, Yang Cao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05125&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Prompt Log Analysis of Text-to-Image Generation Systems&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yutong Xie, Zhaoying Pan, Jinge Ma, Jie Luo, Qiaozhu Mei&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.04587&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zeroth-Order Optimization Meets Human Feedback: Provable Learning via Ranking Oracles&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhiwei Tang, Dmitry Rybin, Tsung-Hui Chang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.03751&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/TZW1998/Taming-Stable-Diffusion-with-Human-Ranking-Feedback&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 7 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unleashing Text-to-Image Diffusion Models for Visual Perception&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenliang Zhao&lt;sup&gt;1&lt;/sup&gt;, Yongming Rao&lt;sup&gt;1&lt;/sup&gt;, Zuyan Liu&lt;sup&gt;1&lt;/sup&gt;, Benlin Liu, Jie Zhou, Jiwen Lu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.02153&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wl-zhao/VPD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 3 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Collage Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vishnu Sarukkai, Linden Li, Arden Ma, Christopher Ré, Kayvon Fatahalian&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.00262&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Towards Enhanced Controllability of Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wonwoong Cho, Hareesh Ravi, Midhun Harikumar, Vinh Khuc, Krishna Kumar Singh, Jingwan Lu, David I. Inouye, Ajinkya Kale&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.14368&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Directed Diffusion: Direct Control of Object Placement through Attention Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wan-Duo Kurt Ma, J.P. Lewis, W. Bastiaan Kleijn, Thomas Leung&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.13153&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Modulating Pretrained Diffusion Models for Multimodal Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cusuh Ham, James Hays, Jingwan Lu, Krishna Kumar Singh, Zhifei Zhang, Tobias Hinz&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.12764&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Region-Aware Diffusion for Zero-shot Text-driven Image Editing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nisha Huang, Fan Tang, Weiming Dong, Tong-Yee Lee, Changsheng Xu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.11797&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/haha-lisa/RDM-Region-Aware-Diffusion-Model&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 23 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Controlled and Conditional Text to Image Generation with Diffusion Prior&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pranav Aggarwal, Hareesh Ravi, Naveen Marri, Sachin Kelkar, Fengbin Chen, Vinh Khuc, Midhun Harikumar, Ritiz Tambi, Sudharshan Reddy Kakumanu, Purvak Lapsiya, Alvin Ghouas, Sarah Saber, Malavika Ramprasad, Baldo Faieta, Ajinkya Kale&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.11710&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yilun Du, Conor Durkan, Robin Strudel, Joshua B. Tenenbaum, Sander Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, Will Grathwohl&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.11552&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://energy-based-model.github.io/reduce-reuse-recycle/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 22 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning 3D Photography Videos via Self-supervised Diffusion on Single Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiaodong Wang&lt;sup&gt;1&lt;/sup&gt;, Chenfei Wu&lt;sup&gt;1&lt;/sup&gt;, Shengming Yin, Minheng Ni, Jianfeng Wang, Linjie Li, Zhengyuan Yang, Fan Yang, Lijuan Wang, Zicheng Liu, Yuejian Fang, Nan Duan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10781&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Exploring the Representation Manifolds of Stable Diffusion Through the Lens of Intrinsic Dimension&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Henry Kvinge, Davis Brown, Charles Godfrey&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.09301&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-driven Visual Synthesis with Latent Diffusion Prior&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ting-Hsuan Liao, Songwei Ge, Yiran Xu, Yao-Chih Lee, Badour AlBahar, Jia-Bin Huang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.08510&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://latent-diffusion-prior.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 16 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chong Mou, Xintao Wang, Liangbin Xie, Jian Zhang, Zhongang Qi, Ying Shan, Xiaohu Qie&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.08453&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/TencentARC/T2I-Adapter&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Omer Bar-Tal&lt;sup&gt;1&lt;/sup&gt;, Lior Yariv&lt;sup&gt;1&lt;/sup&gt;, Yaron Lipman, Tali Dekel&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.08113&#34;&gt;Paper&lt;/a&gt;] &lt;a href=&#34;https://multidiffusion.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/omerbt/MultiDiffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Boundary Guided Mixing Trajectory for Semantic Control with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ye Zhu, Yu Wu, Zhiwei Deng, Olga Russakovsky, Yan Yan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.08357&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Joshua Vendrow&lt;sup&gt;1&lt;/sup&gt;, Saachi Jain&lt;sup&gt;1&lt;/sup&gt;, Logan Engstrom, Aleksander Madry&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07865&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MadryLab/dataset-interfaces&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PRedItOR: Text Guided Image Editing with Diffusion Prior&lt;/strong&gt;&lt;br&gt; &lt;em&gt;Hareesh Ravi, Sachin Kelkar, Midhun Harikumar, Ajinkya Kale&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07979&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-Guided Scene Sketch-to-Photo Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;AprilPyone MaungMaung, Makoto Shing, Kentaro Mitsui, Kei Sawada, Fumio Okura&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.06883&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Universal Guidance for Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Arpit Bansal&lt;sup&gt;1&lt;/sup&gt;, Hong-Min Chu&lt;sup&gt;1&lt;/sup&gt;, Avi Schwarzschild, Soumyadip Sengupta, Micah Goldblum, Jonas Geiping, Tom Goldstein&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07121&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/arpitbansal297/Universal-Guided-Diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 14 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adding Conditional Control to Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lvmin Zhang, Maneesh Agrawala&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.05543&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Analyzing Multimodal Objectives Through the Lens of Generative Diffusion Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chaerin Kong, Nojun Kwak&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10305&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Is This Loss Informative? Speeding Up Textual Inversion with Deterministic Objective Evaluation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Anton Voronov&lt;sup&gt;1&lt;/sup&gt;, Mikhail Khoroshikh&lt;sup&gt;1&lt;/sup&gt;, Artem Babenko, Max Ryabinin&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04841&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q-Diffusion: Quantizing Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiuyu Li, Long Lian, Yijiang Liu, Huanrui Yang, Zhen Dong, Daniel Kang, Shanghang Zhang, Kurt Keutzer&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04304&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GLAZE: Protecting Artists from Style Mimicry by Text-to-Image Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng, Rana Hanocka, Ben Y. Zhao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04222&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero-shot Generation of Coherent Storybook from Plain Text Story using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyeonho Jeong, Gihyun Kwon, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03900&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fair Diffusion: Instructing Text-to-Image Generation Models on Fairness&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Felix Friedrich, Patrick Schramowski, Manuel Brack, Lukas Struppek, Dominik Hintersdorf, Sasha Luccioni, Kristian Kersting&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10893&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuxin Wen&lt;sup&gt;1&lt;/sup&gt;, Neel Jain&lt;sup&gt;1&lt;/sup&gt;, John Kirchenbauer, Micah Goldblum, Jonas Geiping, Tom Goldstein&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03668&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/YuxinWenRick/hard-prompts-made-easy&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero-shot Image-to-Image Translation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gaurav Parmar, Krishna Kumar Singh, Richard Zhang, Yijun Li, Jingwan Lu, Jun-Yan Zhu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03027&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Structure and Content-Guided Video Synthesis with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Patrick Esser, Johnathan Chiu, Parmida Atighehchian, Jonathan Granskog, Anastasis Germanidis&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03011&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://research.runwayml.com/gen1&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 6 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Mixture of Diffusers for scene composition and high resolution image generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Álvaro Barbero Jiménez&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02412&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ReDi: Efficient Learning-Free Diffusion Inference via Trajectory Retrieval&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kexun Zhang, Xianjun Yang, William Yang Wang, Lei Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02285&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Eliminating Prior Bias for Semantic Image Editing via Dual-Cycle Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zuopeng Yang, Tianshu Chu, Xin Lin, Erdun Gao, Daqing Liu, Jie Yang, Chaoyue Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02394&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Semantic-Guided Image Augmentation with Pre-trained Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bohan Li, Xinghao Wang, Xiao Xu, Yutai Hou, Yunlong Feng, Feng Wang, Wanxiang Che&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02070&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TEXTure: Text-Guided Texturing of 3D Shapes&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Elad Richardson&lt;sup&gt;1&lt;/sup&gt;, Gal Metzer&lt;sup&gt;1&lt;/sup&gt;, Yuval Alaluf, Raja Giryes, Daniel Cohen-Or&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.01721&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://texturepaper.github.io/TEXTurePaper/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/TEXTurePaper/TEXTurePaper&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 3 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dreamix: Video Diffusion Models are General Video Editors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Eyal Molad&lt;sup&gt;1&lt;/sup&gt;, Eliahu Horwitz&lt;sup&gt;1&lt;/sup&gt;, Dani Valevski&lt;sup&gt;1&lt;/sup&gt;, Alex Rav Acha, Yossi Matias, Yael Pritch, Yaniv Leviathan, Yedid Hoshen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.01329&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://dreamix-video-editing.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 2 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Trash to Treasure: Using text-to-image models to inform the design of physical artefacts&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Amy Smith&lt;sup&gt;1&lt;/sup&gt;, Hope Schroeder&lt;sup&gt;1&lt;/sup&gt;, Ziv Epstein, Michael Cook, Simon Colton, Andrew Lippman&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.00561&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hila Chefer&lt;sup&gt;1&lt;/sup&gt;, Yuval Alaluf&lt;sup&gt;1&lt;/sup&gt;, Yael Vinker, Lior Wolf, Daniel Cohen-Or&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13826&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://attendandexcite.github.io/Attend-and-Excite/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/AttendAndExcite/Attend-and-Excite&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero3D: Semantic-Driven Multi-Category 3D Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bo Han, Yitong Liu, Yixuan Shen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13591&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Shape-aware Text-driven Layered Video Editing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yao-Chih Lee, Ji-Ze Genevieve Jang, Yi-Ting Chen, Elizabeth Qiu, Jia-Bin Huang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13173&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://text-video-edit.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 30 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PromptMix: Text-to-image diffusion models enhance the performance of lightweight networks&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Arian Bakhtiarnia, Qi Zhang, Alexandros Iosifidis&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12914&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://gitlab.au.dk/maleci/promptmix&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 30 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ming Tao, Bing-Kun Bao, Hao Tang, Changsheng Xu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12959&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/tobran/GALIP&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 30 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SEGA: Instructing Diffusion using Semantic Dimensions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Manuel Brack, Felix Friedrich, Dominik Hintersdorf, Lukas Struppek, Patrick Schramowski, Kristian Kersting&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12247&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhixuan Liu, Youeun Shin, Beverley-Claire Okogwu, Youngsik Yun, Lia Coleman, Peter Schaldenbrand, Jihie Kim, Jean Oh&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12073&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-To-4D Dynamic Scene Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Uriel Singer&lt;sup&gt;1&lt;/sup&gt;, Shelly Sheynin&lt;sup&gt;1&lt;/sup&gt;, Adam Polyak&lt;sup&gt;1&lt;/sup&gt;, Oron Ashual, Iurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea Vedaldi, Devi Parikh, Justin Johnson, Yaniv Taigman&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11280&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Guiding Text-to-Image Diffusion Model Towards Grounded Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ziyi Li, Qinye Zhou, Xiaoyun Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.05221&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://lipurple.github.io/Grounded_Diffusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 12 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Visual Story Generation Based on Emotion and Keywords&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuetian Chen, Ruohua Li, Bowen Shi, Peiru Liu, Mei Si&lt;/em&gt; &lt;br&gt; AAAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2301.02777&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Muse: Text-To-Image Generation via Masked Generative Transformers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Huiwen Chang&lt;sup&gt;1&lt;/sup&gt;, Han Zhang&lt;sup&gt;1&lt;/sup&gt;, Jarred Barber, AJ Maschinot, Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy, William T. Freeman, Michael Rubinstein, Yuanzhen Li, Dilip Krishnan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.00704&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://muse-model.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 2 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiale Xu, Xintao Wang, Weihao Cheng, Yan-Pei Cao, Ying Shan, Xiaohu Qie, Shenghua Gao&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.14704&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://bluestyle97.github.io/dream3d/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 28 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Exploring Vision Transformers as Diffusion Learners&lt;/strong&gt; &lt;br&gt; &lt;em&gt;He Cao, Jianan Wang, Tianhe Ren, Xianbiao Qi, Yihao Chen, Yuan Yao, Lei Zhang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.13771&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jay Zhangjie Wu, Yixiao Ge, Xintao Wang, Weixian Lei, Yuchao Gu, Wynne Hsu, Ying Shan, Xiaohu Qie, Mike Zheng Shou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.11565&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://tuneavideo.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 22 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Optimizing Prompts for Text-to-Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yaru Hao&lt;sup&gt;1&lt;/sup&gt;, Zewen Chi&lt;sup&gt;1&lt;/sup&gt;, Li Dong, Furu Wei&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.09611&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/spaces/microsoft/Promptist&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/microsoft/LMOps/tree/main/promptist&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qiucheng Wu, Yujian Liu, Handong Zhao, Ajinkya Kale, Trung Bui, Tong Yu, Zhe Lin, Yang Zhang, Shiyu Chang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.08698&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/UCSB-NLP-Chang/DiffusionDisentanglement&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TeTIm-Eval: a novel curated evaluation data set for comparing text-to-image models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Federico A. Galatolo, Mario G. C. A. Cimino, Edoardo Cogotti&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.07839&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Imagen Editor and EditBench: Advancing and Evaluating Text-Guided Image Inpainting&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Su Wang&lt;sup&gt;1&lt;/sup&gt;, Chitwan Saharia&lt;sup&gt;1&lt;/sup&gt;, Ceslee Montgomery&lt;sup&gt;1&lt;/sup&gt;, Jordi Pont-Tuset, Shai Noy, Stefano Pellegrini, Yasumasa Onoe, Sarah Laszlo, David J. Fleet, Radu Soricut, Jason Baldridge, Mohammad Norouzi, Peter Anderson, William Chan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.06909&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Stable Artist: Steering Semantics in Diffusion Latent Space&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Manuel Brack, Patrick Schramowski, Felix Friedrich, Dominik Hintersdorf, Kristian Kersting&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.06013&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shaoan Xie, Zhifei Zhang, Zhe Lin, Tobias Hinz, Kun Zhang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.05034&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weixi Feng, Xuehai He, Tsu-Jui Fu, Varun Jampani, Arjun Akula, Pradyumna Narayana, Sugato Basu, Xin Eric Wang, William Yang Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.05032&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/weixi-feng/Structured-Diffusion-Guidance&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 9 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MoFusion: A Framework for Denoising-Diffusion-based Motion Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rishabh Dabral, Muhammad Hamza Mughal, Vladislav Golyanik, Christian Theobalt&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04495&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://vcai.mpi-inf.mpg.de/projects/MoFusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yen-Chi Cheng, Hsin-Ying Lee, Sergey Tulyakov, Alexander Schwing, Liangyan Gui&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04493&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://yccyenchicheng.github.io/SDFusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SINE: SINgle Image Editing with Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhixing Zhang, Ligong Han, Arnab Ghosh, Dimitris Metaxas, Jian Ren&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04489&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://zhang-zx.github.io/SINE/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zhang-zx/SINE&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multi-Concept Customization of Text-to-Image Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli Shechtman, Jun-Yan Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04488&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://www.cs.cmu.edu/~custom-diffusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Guided Domain Adaptation of Image Generators&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kunpeng Song, Ligong Han, Bingchen Liu, Dimitris Metaxas, Ahmed Elgammal&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04473&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://styleganfusion.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Executing your Commands via Motion Diffusion in Latent Space&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xin Chen, Biao Jiang, Wen Liu, Zilong Huang, Bin Fu, Tao Chen, Jingyi Yu, Gang Yu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04048&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://chenxin.tech/mld/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Magic: Multi Art Genre Intelligent Choreography Dataset and Network for 3D Dance Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ronghui Li, Junfan Zhao, Yachao Zhang, Mingyang Su, Zeping Ren, Han Zhang, Xiu Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03741&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Judge, Localize, and Edit: Ensuring Visual Commonsense Morality for Text-to-Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Seongbeom Park, Suhong Moon, Jinkyu Kim&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03507&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Congyue Deng, Chiyu &#34;Max&#39;&#39; Jiang, Charles R. Qi, Xinchen Yan, Yin Zhou, Leonidas Guibas, Dragomir Anguelov&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03267&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-SDF: Text-to-Shape via Voxelized Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Muheng Li, Yueqi Duan, Jie Zhou, Jiwen Lu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03293&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ADIR: Adaptive Diffusion for Image Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shady Abu-Hussein, Tom Tirer, Raja Giryes&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03221&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://shadyabh.github.io/ADIR/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;M-VADER: A Model for Diffusion with Multimodal Context&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Samuel Weinbach&lt;sup&gt;1&lt;/sup&gt;, Marco Bellagente&lt;sup&gt;1&lt;/sup&gt;, Constantin Eichenberg, Andrew Dai, Robert Baldock, Souradeep Nanda, Björn Deiseroth, Koen Oostermeijer, Hannah Teufel, Andres Felipe Cruz-Salinas&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02936&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gyeongman Kim, Hajin Shim, Hyunsu Kim, Yunjey Choi, Junho Kim, Eunho Yang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02802&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unite and Conquer: Cross Dataset Multimodal Synthesis using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nithin Gopalakrishnan Nair, Wele Gedara Chaminda Bandara, Vishal M. Patel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00793&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nithin-gk.github.io/projectpages/Multidiff/index.html&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Shape-Guided Diffusion with Inside-Outside Attention&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dong Huk Park&lt;sup&gt;1&lt;/sup&gt;, Grace Luo&lt;sup&gt;1&lt;/sup&gt;, Clayton Toste, Samaneh Azadi, Xihui Liu, Maka Karalashvili, Anna Rohrbach, Trevor Darrell&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00210&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://shape-guided-diffusion.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SinDDM: A Single Image Denoising Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vladimir Kulikov, Shahar Yadin, Matan Kleiner, Tomer Michaeli&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16582&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://matankleiner.github.io/sinddm/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 29 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gwanghyun Kim, Se Young Chun&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16374&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://datid-3d.github.io/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unified Discrete Diffusion for Simultaneous Vision-Language Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Minghui Hu, Chuanxia Zheng, Heliang Zheng, Tat-Jen Cham, Chaoyue Wang, Zuopeng Yang, Dacheng Tao, Ponnuthurai N. Suganthan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.14842&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3DDesigner: Towards Photorealistic 3D Object Generation and Editing with Text-guided Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gang Li, Heliang Zheng, Chaoyue Wang, Chang Li, Changwen Zheng, Dacheng Tao&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.14108&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SpaText: Spatio-Textual Representation for Controllable Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Omri Avrahami, Thomas Hayes, Oran Gafni, Sonal Gupta, Yaniv Taigman, Devi Parikh, Dani Lischinski, Ohad Fried, Xi Yin&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.14305&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://omriavrahami.com/spatext/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 25 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Sketch-Guided Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andrey Voynov, Kfir Aberman, Daniel Cohen-Or&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13752&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sketch-guided-diffusion.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 24 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Shifted Diffusion for Text-to-image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yufan Zhou, Bingchen Liu, Yizhe Zhu, Xiao Yang, Changyou Chen, Jinhui Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.15388&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;EDICT: Exact Diffusion Inversion via Coupled Transformations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bram Wallace, Akash Gokul, Nikhil Naik&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12446&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Narek Tumanyan&lt;sup&gt;1&lt;/sup&gt;, Michal Geyer&lt;sup&gt;1&lt;/sup&gt;, Shai Bagon, Tali Dekel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12572&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Human Evaluation of Text-to-Image Models on a Multi-Task Benchmark&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vitali Petsiuk, Alexander E. Siemenn, Saisamrit Surbehera, Zad Chin, Keith Tyser, Gregory Hunter, Arvind Raghavan, Yann Hicke, Bryan A. Plummer, Ori Kerret, Tonio Buonassisi, Kate Saenko, Armando Solar-Lezama, Iddo Drori&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12112&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SinDiffusion: Learning a Diffusion Model from a Single Natural Image&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weilun Wang, Jianmin Bao, Wengang Zhou, Dongdong Chen, Dong Chen, Lu Yuan, Houqiang Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12445&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/WeilunWang/SinDiffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SinFusion: Training Diffusion Models on a Single Image or Video&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yaniv Nikankin, Niv Haim, Michal Irani&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.11743&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Investigating Prompt Engineering in Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sam Witteveen, Martin Andrews&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.15462&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ajay Jain&lt;sup&gt;1&lt;/sup&gt;, Amber Xie&lt;sup&gt;1&lt;/sup&gt;, Pieter Abbeel&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.11319&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ajayj.com/vectorfusion&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffStyler: Controllable Dual Diffusion for Text-Driven Image Stylization&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nisha Huang, Yuxin Zhang, Fan Tang, Chongyang Ma, Haibin Huang, Yong Zhang, Weiming Dong, Changsheng Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10682&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Magic3D: High-Resolution Text-to-3D Content Creation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chen-Hsuan Lin&lt;sup&gt;1&lt;/sup&gt;, Jun Gao&lt;sup&gt;1&lt;/sup&gt;, Luming Tang&lt;sup&gt;1&lt;/sup&gt;, Towaki Takikawa&lt;sup&gt;1&lt;/sup&gt;, Xiaohui Zeng&lt;sup&gt;1&lt;/sup&gt;, Xun Huang, Karsten Kreis, Sanja Fidler, Ming-Yu Liu, Tsung-Yi Lin&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10440&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://deepimagination.cc/Magic3D/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 18 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Invariant Learning via Diffusion Dreamed Distribution Shifts&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Priyatham Kattakinda, Alexander Levine, Soheil Feizi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10370&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 18 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Null-text Inversion for Editing Real Images using Guided Diffusion Models&lt;/strong&gt;&lt;br&gt; &lt;em&gt;Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, Daniel Cohen-Or&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09794&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;InstructPix2Pix: Learning to Follow Image Editing Instructions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tim Brooks, Aleksander Holynski, Alexei A. Efros&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09800&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Versatile Diffusion: Text, Images and Variations All in One Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xingqian Xu, Zhangyang Wang, Eric Zhang, Kai Wang, Humphrey Shi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.08332&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/SHI-Labs/Versatile-Diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Direct Inversion: Optimization-Free Text-Driven Real Image Editing with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Adham Elarabawy, Harish Kamath, Samuel Denton&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.07825&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Arbitrary Style Guidance for Enhanced Diffusion-Based Text-to-Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhihong Pan, Xin Zhou, Hao Tian&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.07751&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Patrick Schramowski, Manuel Brack, Björn Deiseroth, Kristian Kersting&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.05105&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ml-research/safe-latent-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 9 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rickrolling the Artist: Injecting Invisible Backdoors into Text-Guided Image Generation Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lukas Struppek, Dominik Hintersdorf, Kristian Kersting&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.02408&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LukasStruppek/Rickrolling-the-Artist&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 4 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;eDiffi: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Karsten Kreis, Miika Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, Ming-Yu Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.01324&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://deepimagination.cc/eDiffi/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MagicMix: Semantic Mixing with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jun Hao Liew, Hanshu Yan, Daquan Zhou, Jiashi Feng&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.16056&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://magicmix.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 28 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wei Li, Xue Xu, Xinyan Xiao, Jiachen Liu, Hu Yang, Guohao Li, Zhanpeng Wang, Zhifan Feng, Qiaoqiao She, Yajuan Lyu, Hua Wu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.16031&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How well can Text-to-Image Generative Models understand Ethical Natural Language Interventions?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hritik Bansal&lt;sup&gt;1&lt;/sup&gt;, Da Yin&lt;sup&gt;1&lt;/sup&gt;, Masoud Monajatipoor, Kai-Wei Chang&lt;/em&gt; &lt;br&gt; EMNLP 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.15230&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Hritikbansal/entigen_emnlp&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhida Feng&lt;sup&gt;1&lt;/sup&gt;, Zhenyu Zhang&lt;sup&gt;1&lt;/sup&gt;, Xintong Yu&lt;sup&gt;1&lt;/sup&gt;, Yewei Fang, Lanxin Li, Xuyi Chen, Yuxiang Lu, Jiaxiang Liu, Weichong Yin, Shikun Feng, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.15257&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, Duen Horng Chau&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.14896&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://poloclub.github.io/diffusiondb/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 26 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Lafite2: Few-shot Text-to-Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yufan Zhou, Chunyuan Li, Changyou Chen, Jianfeng Gao, Jinhui Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.14124&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;High-Resolution Image Editing via Multi-Stage Blended Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Johannes Ackermann, Minjun Li&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.12965&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/pfnet-research/multi-stage-blended-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 24 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conditional Diffusion with Less Explicit Guidance via Model Predictive Control&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Max W. Shen, Ehsan Hajiramezanali, Gabriele Scalia, Alex Tseng, Nathaniel Diamant, Tommaso Biancalani, Andreas Loukas&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.12192&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Visual Tour Of Current Challenges In Multimodal Language Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shashank Sonkar, Naiming Liu, Richard G. Baraniuk&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.12565&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffEdit: Diffusion-based semantic image editing with mask guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Guillaume Couairon, Jakob Verbeek, Holger Schwenk, Matthieu Cord&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.11427&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models already have a Semantic Latent Space&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mingi Kwon, Jaeseok Jeong, Youngjung Uh&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.10960&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://kwonminki.github.io/Asyrp/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 20 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation Model on a Single Image&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dani Valevski, Matan Kalman, Yossi Matias, Yaniv Leviathan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.09477&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 18 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Swinv2-Imagen: Hierarchical Vision Transformer Diffusion Models for Text-to-Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ruijun Li, Weihua Li, Yi Yang, Hanyu Wei, Jianhua Jiang, Quan Bai&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.09549&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 18 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Imagic: Text-Based Real Image Editing with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bahjat Kawar&lt;sup&gt;1&lt;/sup&gt;, Shiran Zada&lt;sup&gt;1&lt;/sup&gt;, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar Mosseri, Michal Irani&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.09276&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chaerin Kong, DongHyeon Jeon, Ohjoon Kwon, Nojun Kwak&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.05872&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unifying Diffusion Models&#39; Latent Space, with Applications to CycleDiffusion and Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chen Henry Wu, Fernando De la Torre&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.05559&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ChenWu98/cycle-diffusion&#34;&gt;Github-1&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ChenWu98/unified-generative-zoo&#34;&gt;Github-2&lt;/a&gt;] &lt;br&gt; 11 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Imagen Video: High Definition Video Generation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jonathan Ho&lt;sup&gt;1&lt;/sup&gt;, William Chan&lt;sup&gt;1&lt;/sup&gt;, Chitwan Saharia&lt;sup&gt;1&lt;/sup&gt;, Jay Whang&lt;sup&gt;1&lt;/sup&gt;, Ruiqi Gao, Alexey Gritsenko, Diederik P. Kingma, Ben Poole, Mohammad Norouzi, David J. Fleet, Tim Salimans&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.02303&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DALL-E-Bot: Introducing Web-Scale Diffusion Models to Robotics&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ivan Kapelyukh, Vitalis Vosylius, Edward Johns&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.02438&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LDEdit: Towards Generalized Text Guided Image Manipulation via Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Paramanand Chandramouli, Kanchana Vaishnavi Gandikota&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.02249&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;clip2latent: Text driven sampling of a pre-trained StyleGAN using denoising diffusion and CLIP&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Justin N. M. Pinkney, Chuan Li&lt;/em&gt; &lt;br&gt; BMVC 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.02347&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/justinpinkney/clip2latent&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 5 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Membership Inference Attacks Against Text-to-image Generation Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yixin Wu, Ning Yu, Zheng Li, Michael Backes, Yang Zhang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.00968&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Make-A-Video: Text-to-Video Generation without Text-Video Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, Yaniv Taigman&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14792&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DreamFusion: Text-to-3D using 2D Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ben Poole, Ajay Jain, Jonathan T. Barron, Ben Mildenhall&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14988&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://dreamfusion3d.github.io/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Re-Imagen: Retrieval-Augmented Text-to-Image Generator&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenhu Chen, Hexiang Hu, Chitwan Saharia, William W. Cohen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14491&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Creative Painting with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xianchao Wu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14697&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Draw Your Art Dream: Diverse Digital Art Synthesis with Multimodal Guided Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nisha Huang, Fan Tang, Weiming Dong, Changsheng Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.13360&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/haha-lisa/MGAD-multimodal-guided-artwork-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Personalizing Text-to-Image Generation via Aesthetic Gradients&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Victor Gallego&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.12330&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/vicgalle/stable-diffusion-aesthetic-gradients&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 25 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Best Prompts for Text-to-Image Models and How to Find Them&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nikita Pavlichenko, Dmitry Ustalov&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.11711&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Biased Artist: Exploiting Cultural Biases via Homoglyphs in Text-Guided Image Generation Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lukas Struppek, Dominik Hintersdorf, Kristian Kersting&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.08891&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LukasStruppek/The-Biased-Artist&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chen Henry Wu, Saman Motamed, Shaunak Srivastava, Fernando De la Torre&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.06970&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ChenWu98/Generative-Visual-Prompt&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 14 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhengzhe Liu, Peng Dai, Ruihui Li, Xiaojuan Qi, Chi-Wing Fu&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2209.04145&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/liuzhengzhe/ISS-Image-as-Stepping-Stone-for-Text-Guided-3D-Shape-Generation&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 9 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, Kfir Aberman&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.12242&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://dreambooth.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Victarry/stable-dreambooth&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 25 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Robin Rombach&lt;sup&gt;1&lt;/sup&gt;, Andreas Blattmann&lt;sup&gt;1&lt;/sup&gt;, Björn Ommer&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.13038&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 26 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Discrete Contrastive Diffusion for Cross-Modal and Conditional Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ye Zhu, Yu Wu, Kyle Olszewski, Jian Ren, Sergey Tulyakov, Yan Yan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.07771&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/L-YeZhu/CDCD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Blended Latent Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Omri Avrahami, Ohad Fried, Dani Lischinski&lt;/em&gt; &lt;br&gt; ACM 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.02779&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://omriavrahami.com/blended-latent-diffusion-page/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/omriav/blended-latent-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Compositional Visual Generation with Composable Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nan Liu&lt;sup&gt;1&lt;/sup&gt;, Shuang Li&lt;sup&gt;1&lt;/sup&gt;, Yilun Du&lt;sup&gt;1&lt;/sup&gt;, Antonio Torralba, Joshua B. Tenenbaum&lt;/em&gt; &lt;br&gt; ECCV 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.01714&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 3 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiVAE: Photorealistic Images Synthesis with Denoising Diffusion Decoder&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jie Shi&lt;sup&gt;1&lt;/sup&gt;, Chenfei Wu&lt;sup&gt;1&lt;/sup&gt;, Jian Liang, Xiang Liu, Nan Duan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.00386&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improved Vector Quantized Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhicong Tang, Shuyang Gu, Jianmin Bao, Dong Chen, Fang Wen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.16007&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/microsoft/VQ-Diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 31 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text2Human: Text-Driven Controllable Human Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuming Jiang, Shuai Yang, Haonan Qiu, Wayne Wu, Chen Change Loy, Ziwei Liu&lt;/em&gt; &lt;br&gt; ACM 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.15996&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yumingj/Text2Human&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 31 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chitwan Saharia&lt;sup&gt;1&lt;/sup&gt;, William Chan&lt;sup&gt;1&lt;/sup&gt;, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, Mohammad Norouzi&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.11487&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/lucidrains/imagen-pytorch&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 23 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Retrieval-Augmented Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andreas Blattmann&lt;sup&gt;1&lt;/sup&gt;, Robin Rombach&lt;sup&gt;1&lt;/sup&gt;, Kaan Oktay, Björn Ommer&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.11824&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/lucidrains/retrieval-augmented-ddpm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 25 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Hierarchical Text-Conditional Image Generation with CLIP Latents&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.06125&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/lucidrains/DALLE2-pytorch&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;KNN-Diffusion: Image Generation via Large-Scale Retrieval&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Oron Ashual, Shelly Sheynin, Adam Polyak, Uriel Singer, Oran Gafni, Eliya Nachmani, Yaniv Taigman&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.02849&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Robin Rombach&lt;sup&gt;1&lt;/sup&gt;, Andreas Blattmann&lt;sup&gt;1&lt;/sup&gt;, Dominik Lorenz, Patrick Esser, Björn Ommer&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2112.10752&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;More Control for Free! Image Synthesis with Semantic Diffusion Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xihui Liu, Dong Huk Park, Samaneh Azadi, Gong Zhang, Arman Chopikyan, Yuxiao Hu, Humphrey Shi, Anna Rohrbach, Trevor Darrell&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.05744&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://xh-liu.github.io/sdg/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 10 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Vector Quantized Diffusion Model for Text-to-Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan, Baining Guo&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2111.14822&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/microsoft/VQ-Diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Blended Diffusion for Text-driven Editing of Natural Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Omri Avrahami, Dani Lischinski, Ohad Fried&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2111.14818&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://omriavrahami.com/blended-diffusion-page/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/omriav/blended-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Tackling the Generative Learning Trilemma with Denoising Diffusion GANs&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhisheng Xiao, Karsten Kreis, Arash Vahdat&lt;/em&gt; &lt;br&gt; ICLR 2022 (Spotlight). [&lt;a href=&#34;https://arxiv.org/abs/2112.07804&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nvlabs.github.io/denoising-diffusion-gan&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 15 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gwanghyun Kim, Jong Chul Ye&lt;/em&gt; &lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2110.02711&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Oct 2021&lt;/p&gt; &#xA;&lt;h3&gt;Medical Imaging&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;DDMM-Synth: A Denoising Diffusion Model for Cross-modal Medical Image Synthesis with Sparse-view Measurement Embedding&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiaoyue Li, Kai Shang, Gaoang Wang, Mark D. Butala&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15770&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Memory-efficient Processing of 3D Medical Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Florentin Bieder, Julia Wolleb, Alicia Durrer, Robin Sandkühler, Philippe C. Cattin&lt;/em&gt; &lt;br&gt; MIDL 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15288&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiaofei Wang, Stephen Price, Chao Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14845&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CoLa-Diff: Conditional Latent Diffusion Model for Multi-Modal MRI Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lan Jiang, Ye Mao, Xi Chen, Xiangfeng Wang, Chao Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14081&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DisC-Diff: Disentangled Conditional Diffusion Model for Multi-Contrast MRI Super-Resolution&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ye Mao&lt;sup&gt;1&lt;/sup&gt;, Lan Jiang&lt;sup&gt;1&lt;/sup&gt;, Xi Chen, Chao Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13933&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Medical diffusion on a budget: textual inversion for medical image generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bram de Wilde, Anindo Saha, Richard P.G. ten Broek, Henkjan Huisman&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13430&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Sub-volume-based Denoising Diffusion Probabilistic Model for Cone-beam CT Reconstruction from Incomplete Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenjun Xia, Chuang Niu, Wenxiang Cong, Ge Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12861&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Feature-Conditioned Cascaded Video Diffusion Models for Precise Echocardiogram Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hadrien Reynaud, Mengyun Qiao, Mischa Dombrowski, Thomas Day, Reza Razavi, Alberto Gomez, Paul Leeson, Bernhard Kainz&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12644&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Distribution Aligned Diffusion and Prototype-guided network for Unsupervised Domain Adaptive Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haipeng Zhou, Lei Zhu, Yuyin Zhou&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12313&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Semantic Latent Space Regression of Diffusion Autoencoders for Vertebral Fracture Grading&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Matthias Keicher, Matan Atad, David Schinz, Alexandra S. Gersing, Sarah C. Foreman, Sophia S. Goller, Juergen Weissinger, Jon Rischewski, Anna-Sophia Dietrich, Benedikt Wiestler, Jan S. Kirschke, Nassir Navab&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12031&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Aman Shrivastava, P. Thomas Fletcher&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11477&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cascaded Latent Diffusion Models for High-Resolution Chest X-ray Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tobias Weber, Michael Ingrisch, Bernd Bischl, David Rügamer&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11224&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffMIC: Dual-Guidance Diffusion Network for Medical Image Classification&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yijun Yang, Huazhu Fu, Angelica Aviles-Rivero, Carola-Bibiane Schönlieb, Lei Zhu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10610&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diff-UNet: A Diffusion Embedded Network for Volumetric Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhaohu Xing, Liang Wan, Huazhu Fu, Guang Yang, Lei Zhu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10326&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ge-xing/Diff-UNet&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 18 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cosmin I Bercea, Benedikt Wiestler, Daniel Rueckert, Julia A Schnabel&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08452&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improving 3D Imaging with Pre-Trained Perpendicular 2D Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Suhyeon Lee&lt;sup&gt;1&lt;/sup&gt;, Hyungjin Chung&lt;sup&gt;1&lt;/sup&gt;, Minyoung Park, Jonghyuk Park, Wi-Sun Ryu, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08440&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Class-Guided Image-to-Image Diffusion: Cell Painting from Brightfield Images with Class Labels&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jan Oscar Cross-Zamirski, Praveen Anand, Guy Williams, Elizabeth Mouchet, Yinhai Wang, Carola-Bibiane Schönlieb&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08863&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/crosszamirski/guided-I2I&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stochastic Segmentation with Conditional Categorical Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lukas Zbinden&lt;sup&gt;1&lt;/sup&gt;, Lars Doorenbos&lt;sup&gt;1&lt;/sup&gt;, Theodoros Pissas, Raphael Sznitman, Pablo Márquez-Neila&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08888&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LarsDoorenbos/ccdm-stochastic-segmentation&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Contrast Harmonization of Magnetic Resonance Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alicia Durrer, Julia Wolleb, Florentin Bieder, Tim Sinnecker, Matthias Weigel, Robin Sandkühler, Cristina Granziera, Özgür Yaldizli, Philippe C. Cattin&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08189&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Efficiently Training Vision Transformers on Structural MRI Scans for Alzheimer&#39;s Disease Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nikhil J. Dhinagar, Sophia I. Thomopoulos, Emily Laltoo, Paul M. Thompson&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08216&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-Based Hierarchical Multi-Label Object Detection to Analyze Panoramic Dental X-rays&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ibrahim Ethem Hamamci, Sezgin Er, Enis Simsar, Anjany Sekuboyina, Mustafa Gundogar, Bernd Stadlinger, Albert Mehl, Bjoern Menze&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06500&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AugDiff: Diffusion based Feature Augmentation for Multiple Instance Learning in Whole Slide Image&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhuchen Shao, Liuxi Dai, Yifeng Wang, Haoqian Wang, Yongbing Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06371&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Brain Diffuser: An End-to-End Brain Image to Brain Network Pipeline&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xuhang Chen, Baiying Lei, Chi-Man Pun, Shuqiang Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06410&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast Diffusion Sampler for Inverse Problems by Geometric Decomposition&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung, Suhyeon Lee, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05754&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generalized Diffusion MRI Denoising and Super-Resolution using Swin Transformers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Amir Sadikov, Jamie Wren-Jarvis, Xinlei Pan, Lanya T. Cai, Pratik Mukherjee&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05686&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Importance of Aligning Training Strategy with Evaluation for Diffusion Models in 3D Multiclass Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yunguan Fu, Yiwen Li, Shaheer U. Saeed, Matthew J. Clarkson, Yipeng Hu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06040&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mathpluscode/ImgX-DiffSeg&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Patched Diffusion Models for Unsupervised Anomaly Detection in Brain MRI&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Finn Behrendt, Debayan Bhattacharya, Julia Krüger, Roland Opfer, Alexander Schlaefer&lt;/em&gt; &lt;br&gt; MIDL 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.03758&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bi-parametric prostate MR image synthesis using pathology and sequence-conditioned stable diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shaheer U. Saeed, Tom Syer, Wen Yan, Qianye Yang, Mark Emberton, Shonit Punwani, Matthew J. Clarkson, Dean C. Barratt, Yipeng Hu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.02094&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dissolving Is Amplifying: Towards Fine-Grained Anomaly Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jian Shi, Pengyi Zhang, Ni Zhang, Hakim Ghazzai, Yehia Massoud&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.14696&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DDM2: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tiange Xiang, Mahmut Yurt, Ali B Syed, Kawin Setsompop, Akshay Chaudhari&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03018&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/StanfordMIMI/DDM2&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zihao Wang, Yingyu Yang, Maxime Sermesant, Hervé Delingette, Ona Wu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13743&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Denoising for Low-Dose-CT Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Runyi Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11482&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionCT: Latent Diffusion Model for CT Image Standardization&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Md Selim, Jie Zhang, Michael A. Brooks, Ge Wang, Jin Chen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.08815&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MedSegDiff-V2: Diffusion based Medical Image Segmentation with Transformer&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junde Wu, Rao Fu, Huihui Fang, Yu Zhang, Yanwu Xu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11798&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The role of noise in denoising models for anomaly detection in medical images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Antanas Kascenas, Pedro Sanchez, Patrick Schrempf, Chaoyang Wang, William Clackett, Shadia S. Mikhael, Jeremy P. Voisey, Keith Goatman, Alexander Weir, Nicolas Pugeault, Sotirios A. Tsaftaris, Alison Q. O&#39;Neil&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.08330&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/AntanasKascenas/DenoisingAE&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Annealed Score-Based Diffusion Model for MR Motion Artifact Reduction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gyutaek Oh, Jeong Eun Lee, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.03027&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Probabilistic Models for Generation of Realistic Fully-Annotated Microscopy Image Data Sets&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dennis Eschweiler, Johannes Stegmaier&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.10227&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Model based Semi-supervised Learning on Brain Hemorrhage Images for Efficient Midline Shift Quantification&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shizhan Gong, Cheng Chen, Yuqi Gong, Nga Yan Chan, Wenao Ma, Calvin Hoi-Kwan Mak, Jill Abrigo, Qi Dou&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.00409&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SADM: Sequence-Aware Diffusion Model for Longitudinal Medical Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jee Seok Yoon, Chenghao Zhang, Heung-Il Suk, Jia Guo, Xiaoxiao Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.08228&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Universal Generative Modeling in Dual-domain for Dynamic MR Imaging&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chuanming Yu, Yu Guan, Ziwen Ke, Dong Liang, Qiegen Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.07599&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SPIRiT-Diffusion: SPIRiT-driven Score-Based Generative Modeling for Vessel Wall imaging&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chentao Cao, Zhuo-Xu Cui, Jing Cheng, Sen Jia, Hairong Zheng, Dong Liang, Yanjie Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.11274&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Probabilistic Models beat GANs on Medical Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gustav Müller-Franzes, Jan Moritz Niehues, Firas Khader, Soroosh Tayebi Arasteh, Christoph Haarburger, Christiane Kuhl, Tianci Wang, Tianyu Han, Sven Nebelung, Jakob Nikolas Kather, Daniel Truhn&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.07501&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;One Sample Diffusion Model in Projection Domain for Low-Dose CT Imaging&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bin Huang, Liu Zhang, Shiyu Lu, Boyu Lin, Weiwen Wu, Qiegen Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03630&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improving dermatology classifiers across populations using images generated by large diffusion models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Luke W. Sagers&lt;sup&gt;1&lt;/sup&gt;, James A. Diao&lt;sup&gt;1&lt;/sup&gt;, Matthew Groh, Pranav Rajpurkar, Adewole S. Adamson, Arjun K. Manrai&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13352&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;RoentGen: Vision-Language Foundation Model for Chest X-ray Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pierre Chambon&lt;sup&gt;1&lt;/sup&gt;, Christian Bluethgen&lt;sup&gt;1&lt;/sup&gt;, Jean-Benoit Delbrouck, Rogier Van der Sluijs, Małgorzata Połacin, Juan Manuel Zambrano Chaves, Tanishq Mathew Abraham, Shivanshu Purohit, Curtis P. Langlotz, Akshay Chaudhari&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12737&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DOLCE: A Model-Based Probabilistic Diffusion Framework for Limited-Angle CT Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiaming Liu, Rushil Anirudh, Jayaraman J. Thiagarajan, Stewart He, K. Aditya Mohan, Ulugbek S. Kamilov, Hyojin Kim&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12340&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solving 3D Inverse Problems using Pre-trained 2D Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung&lt;sup&gt;1&lt;/sup&gt;, Dohoon Ryu&lt;sup&gt;1&lt;/sup&gt;, Michael T. McCann, Marc L. Klasky, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10655&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Patch-Based Denoising Diffusion Probabilistic Model for Sparse-View CT Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenjun Xia, Wenxiang Cong, Ge Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10388&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 18 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Brain PET Synthesis from MRI Using Joint Probability Distribution of Diffusion Model at Ultrahigh Fields&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xie Taofeng&lt;sup&gt;1&lt;/sup&gt;, Cao Chentao&lt;sup&gt;1&lt;/sup&gt;, Cui Zhuoxu, Li Fanshi, Wei Zidong, Zhu Yanjie, Li Ye, Liang Dong, Jin Qiyu, Chen Guoqing, Wang Haifeng&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.08901&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improved HER2 Tumor Segmentation with Subtype Balancing using Deep Generative Networks&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mathias Öttl, Jana Mönius, Matthias Rübner, Carol I. Geppert, Jingna Qiu, Frauke Wilm, Arndt Hartmann, Matthias W. Beckmann, Peter A. Fasching, Andreas Maier, Ramona Erber, Katharina Breininger&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.06150&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;An unobtrusive quality supervision approach for medical image annotation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sonja Kunzmann, Mathias Öttl, Prathmesh Madhu, Felix Denzinger, Andreas Maier&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.06146&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Medical Diffusion -- Denoising Diffusion Probabilistic Models for 3D Medical Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Firas Khader, Gustav Mueller-Franzes, Soroosh Tayebi Arasteh, Tianyu Han, Christoph Haarburger, Maximilian Schulze-Hagen, Philipp Schad, Sandy Engelhardt, Bettina Baessler, Sebastian Foersch, Johannes Stegmaier, Christiane Kuhl, Sven Nebelung, Jakob Nikolas Kather, Daniel Truhn&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.03364&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generation of Anonymous Chest Radiographs Using Latent Diffusion Models for Training Thoracic Abnormality Classification Systems&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kai Packhäuser, Lukas Folle, Florian Thamm, Andreas Maier&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.01323&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Spot the fake lungs: Generating Synthetic Medical Images using Neural Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hazrat Ali, Shafaq Murad, Zubair Shah&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.00902&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://www.kaggle.com/datasets/hazrat/awesomelungs&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 2 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junde Wu, Huihui Fang, Yu Zhang, Yehui Yang, Yanwu Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.00611&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerating Diffusion Models via Pre-segmentation Diffusion Sampling for Medical Image Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xutao Guo, Yanwu Yang, Chenfei Ye, Shang Lu, Yang Xiang, Ting Ma&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.17408&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multitask Brain Tumor Inpainting with Diffusion Models: A Methodological Report&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pouria Rouzrokh&lt;sup&gt;1&lt;/sup&gt;, Bardia Khosravi&lt;sup&gt;1&lt;/sup&gt;, Shahriar Faghani, Mana Moassefi, Sanaz Vahdati, Bradley J. Erickson&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.12113&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Mayo-Radiology-Informatics-Lab/MBTI&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 21 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adapting Pretrained Vision-Language Foundational Models to Medical Imaging Domains&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pierre Chambon&lt;sup&gt;1&lt;/sup&gt;, Christian Bluethgen&lt;sup&gt;1&lt;/sup&gt;, Curtis P. Langlotz, Akshay Chaudhari&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.04133&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Anatomically constrained CT image translation for heterogeneous blood vessel segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giammarco La Barbera, Haithem Boussaid, Francesco Maso, Sabine Sarnacki, Laurence Rouet, Pietro Gori, Isabelle Bloch&lt;/em&gt; &lt;br&gt; BMVC 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.01713&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Low-Dose CT Using Denoising Diffusion Probabilistic Model for 20× Speedup&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenjun Xia, Qing Lyu, Ge Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.15136&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Boah Kim&lt;sup&gt;1&lt;/sup&gt;, Yujin Oh&lt;sup&gt;1&lt;/sup&gt;, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14566&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conversion Between CT and MRI Images Using Diffusion and Score-Matching Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qing Lyu, Ge Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.12104&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Brain Imaging Generation with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Walter H. L. Pinaya&lt;sup&gt;1&lt;/sup&gt;, Petru-Daniel Tudosiu&lt;sup&gt;1&lt;/sup&gt;, Jessica Dafflon, Pedro F da Costa, Virginia Fernandez, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardoso&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.07162&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PET image denoising based on denoising diffusion probabilistic models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kuang Gong, Keith A. Johnson, Georges El Fakhri, Quanzheng Li, Tinsu Pan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.06167&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Self-Score: Self-Supervised Learning on Score-Based Models for MRI Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhuo-Xu Cui, Chentao Cao, Shaonan Liu, Qingyong Zhu, Jing Cheng, Haifeng Wang, Yanjie Zhu, Dong Liang&lt;/em&gt; &lt;br&gt; IEEE TMI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.00835&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;High-Frequency Space Diffusion Models for Accelerated MRI&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chentao Cao, Zhuo-Xu Cui, Shaonan Liu, Dong Liang, Yanjie Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.05481&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What is Healthy? Generative Counterfactual Diffusion for Lesion Localization&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pedro Sanchez, Antanas Kascenas, Xiao Liu, Alison Q. O&#39;Neil, Sotirios A. Tsaftaris&lt;/em&gt; &lt;br&gt; MICCAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.12268&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/vios-s/Diff-SCM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 25 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unsupervised Medical Image Translation with Adversarial Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Muzaffer Özbey, Salman UH Dar, Hasan A Bedel, Onat Dalmaz, Şaban Özturk, Alper Güngör, Tolga Çukur&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.08208&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adaptive Diffusion Priors for Accelerated MRI Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Salman UH Dar, Şaban Öztürk, Yilmaz Korkmaz, Gokberk Elmas, Muzaffer Özbey, Alper Güngör, Tolga Çukur&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.05876&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Novel Unified Conditional Score-based Generative Framework for Multi-modal Medical Image Completion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiangxi Meng, Yuning Gu, Yongsheng Pan, Nizhuan Wang, Peng Xue, Mengkang Lu, Xuming He, Yiqiang Zhan, Dinggang Shen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.03430&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cross-Modal Transformer GAN: A Brain Structure-Function Deep Fusing Framework for Alzheimer&#39;s Disease&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junren Pan, Shuqiang Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.13393&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Deformable Model for 4D Temporal Medical Image Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Boah Kim, Jong Chul Ye&lt;/em&gt; &lt;br&gt; MICCAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.13295&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/torchddm/ddm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast Unsupervised Brain Anomaly Detection and Segmentation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Walter H. L. Pinaya, Mark S. Graham, Robert Gray, Pedro F Da Costa, Petru-Daniel Tudosiu, Paul Wright, Yee H. Mah, Andrew D. MacKinnon, James T. Teo, Rolf Jager, David Werring, Geraint Rees, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardos&lt;/em&gt; &lt;br&gt; MICCAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.03461&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improving Diffusion Models for Inverse Problems using Manifold Constraints&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung&lt;sup&gt;1&lt;/sup&gt;, Byeongsu Sim&lt;sup&gt;1&lt;/sup&gt;, Dohoon Ryu, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.00941&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AnoDDPM: Anomaly Detection with Denoising Diffusion Probabilistic Models using Simplex Noise&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julian Wyatt, Adam Leach, Sebastian M. Schmon, Chris G. Willcocks&lt;/em&gt; &lt;br&gt; CVPR Workshop 2022. [&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Wyatt_AnoDDPM_Anomaly_Detection_With_Denoising_Diffusion_Probabilistic_Models_Using_Simplex_CVPRW_2022_paper.pdf&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Julian-Wyatt/AnoDDPM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Swiss Army Knife for Image-to-Image Translation: Multi-Task Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julia Wolleb&lt;sup&gt;1&lt;/sup&gt;, Robin Sandkühler&lt;sup&gt;1&lt;/sup&gt;, Florentin Bieder, Philippe C. Cattin&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.02641&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MR Image Denoising and Super-Resolution Using Regularized Reverse Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung, Eun Sun Lee, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.12621&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Medical Anomaly Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julia Wolleb, Florentin Bieder, Robin Sandkühler, Philippe C. Cattin&lt;/em&gt; &lt;br&gt; MICCAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.04306&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/JuliaWolleb/diffusion-anomaly&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Towards performant and reliable undersampled MR reconstruction via diffusion model sampling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cheng Peng, Pengfei Guo, S. Kevin Zhou, Vishal Patel, Rama Chellappa&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.04292&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/cpeng93/diffuserecon&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Measurement-conditioned Denoising Diffusion Probabilistic Model for Under-sampled Medical Image Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yutong Xie, Quanzheng Li&lt;/em&gt; &lt;br&gt; MICCAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.03623&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Theodore-PKU/MC-DDPM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 5 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MRI Reconstruction via Data Driven Markov Chain with Joint Uncertainty Estimation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Guanxiong Luo, Martin Heide, Martin Uecker&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.01479&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mrirecon/spreco&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 3 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unsupervised Denoising of Retinal OCT with Diffusion Probabilistic Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dewei Hu, Yuankai K. Tao, Ipek Oguz&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2201.11760&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/DeweiHu/OCT_DDPM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Come-Closer-Diffuse-Faster: Accelerating Conditional Diffusion Models for Inverse Problems through Stochastic Contraction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung, Byeongsu Sim, Jong Chul Ye&lt;/em&gt; &lt;br&gt; CVPR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.05146&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solving Inverse Problems in Medical Imaging with Score-Based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yang Song&lt;sup&gt;1&lt;/sup&gt;, Liyue Shen&lt;sup&gt;1&lt;/sup&gt;, Lei Xing, Stefano Ermon&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.08005&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yang-song/score_inverse_problems&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 15 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-based diffusion models for accelerated MRI&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyungjin Chung, Jong chul Ye&lt;/em&gt; &lt;br&gt; MIA 2021. [&lt;a href=&#34;https://arxiv.org/abs/2110.05243&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/HJ-harry/score-MRI&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Oct 2021&lt;/p&gt; &#xA;&lt;h3&gt;3D Vision&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hiromichi Kamata, Yuiko Sakuma, Akio Hayakawa, Masato Ishii, Takuya Narihira&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15780&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sony.github.io/Instruct3Dto3D-doc/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 28 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Novel View Synthesis of Humans using Differentiable Rendering&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Guillaume Rochette, Chris Russell, Richard Bowden&lt;/em&gt; &lt;br&gt; IEEE T-BIOM 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15880&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/GuillaumeRochette/HumanViewSynthesis&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 28 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Susung Hong&lt;sup&gt;1&lt;/sup&gt;, Donghoon Ahn&lt;sup&gt;1&lt;/sup&gt;, Seungryong Kim&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15413&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junshu Tang, Tengfei Wang, Bo Zhang, Ting Zhang, Ran Yi, Lizhuang Ma, Dong Chen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14184&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://make-it-3d.github.io/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ISS++: Image as Stepping Stone for Text-Guided 3D Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhengzhe Liu, Peng Dai, Ruihui Li, Xiaojuan Qi, Chi-Wing Fu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15181&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yiqi Lin&lt;sup&gt;1&lt;/sup&gt;, Haotian Bai&lt;sup&gt;1&lt;/sup&gt;, Sijia Li, Haonan Lu, Xiaodong Lin, Hui Xiong, Lin Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13843&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://fantasia3d.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rui Chen, Yongwei Chen, Ningxin Jiao, Kui Jia&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13873&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DDT: A Diffusion-Driven Transformer-based Framework for Human Mesh Recovery from a Video&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ce Zheng, Guo-Jun Qi, Chen Chen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13397&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ayaan Haque, Matthew Tancik, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12789&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://instruct-nerf2nerf.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;FeatureNeRF: Learning Generalizable NeRFs by Distilling Foundation Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jianglong Ye, Naiyan Wang, Xiaolong Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12786&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://jianglongye.com/featurenerf/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Vox-E: Text-guided Voxel Editing of 3D Objects&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Etai Sella, Gal Fiebelman, Peter Hedman, Hadar Averbuch-Elor&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12048&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://tau-vailab.github.io/Vox-E/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Compositional 3D Scene Generation using Locally Conditioned Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ryan Po, Gordon Wetzstein&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12218&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ryanpo.com/comp3d/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis Aggregation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenkang Shan, Zhenhua Liu, Xinfeng Zhang, Zhao Wang, Kai Han, Shanshe Wang, Siwei Ma, Wen Gao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11579&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/paTRICK-swk/D3DP&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3D-CLFusion: Fast Text-to-3D Rendering with Contrastive Latent Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yu-Jhe Li, Kris Kitani&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11938&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Juil Koo&lt;sup&gt;1&lt;/sup&gt;, Seungwoo Yoo&lt;sup&gt;1&lt;/sup&gt;, Minh Hieu Nguyen&lt;sup&gt;1&lt;/sup&gt;, Minhyuk Sung&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12236&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://salad3d.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning a 3D Morphable Face Reflectance Model from Low-cost Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuxuan Han, Zhibo Wang, Feng Xu&lt;/em&gt; &lt;br&gt; CVPR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11686&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://yxuhan.github.io/ReflectanceMM/index.html&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text2Tex: Text-driven Texture Synthesis via Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dave Zhenyu Chen, Yawar Siddiqui, Hsin-Ying Lee, Sergey Tulyakov, Matthias Nießner&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11396&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://daveredrum.github.io/Text2Tex/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero-1-to-3: Zero-shot One Image to 3D Object&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ruoshi Liu, Rundi Wu, Basile Van Hoorick, Pavel Tokmakov, Sergey Zakharov, Carl Vondrick&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11328&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://zero123.cs.columbia.edu/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/cvlab-columbia/zero123&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SKED: Sketch-guided Text-based 3D Editing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Aryan Mikaeili, Or Perel, Daniel Cohen-Or, Ali Mahdavi-Amiri&lt;/em&gt; &lt;br&gt; arxiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10735&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3DQD: Generalized Deep 3D Shape Prior via Part-Discretized Diffusion Process&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuhan Li, Yishun Dou, Xuanhong Chen, Bingbing Ni, Yilin Sun, Yutian Liu, Fuzhen Wang&lt;/em&gt; &lt;br&gt; CVPR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10406&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/colorful-liyu/3DQD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 18 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Taming Diffusion Models for Audio-Driven Co-Speech Gesture Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lingting Zhu&lt;sup&gt;1&lt;/sup&gt;, Xian Liu&lt;sup&gt;1&lt;/sup&gt;, Xuanyu Liu, Rui Qian, Ziwei Liu, Lequan Yu&lt;/em&gt; &lt;br&gt; CVPR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09119&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Advocate99/DiffGesture&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-HPC: Generating Synthetic Images with Realistic Humans&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhenzhen Weng, Laura Bravo-Sánchez, Serena Yeung&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09541&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ZZWENG/Diffusion_HPC&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human Avatars&lt;/strong&gt; &lt;br&gt; &lt;em&gt;David Svitov, Dmitrii Gudkov, Renat Bashirov, Victor Lempitsky&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09375&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improving 3D Imaging with Pre-Trained Perpendicular 2D Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Suhyeon Lee&lt;sup&gt;1&lt;/sup&gt;, Hyungjin Chung&lt;sup&gt;1&lt;/sup&gt;, Minyoung Park, Jonghyuk Park, Wi-Sun Ryu, Jong Chul Ye&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08440&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Controllable Mesh Generation Through Sparse Latent Point Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhaoyang Lyu, Jinyi Wang, Yuwei An, Ya Zhang, Dahua Lin, Bo Dai&lt;/em&gt; &lt;br&gt; CVPR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.07938&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://slide-3d.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MeshDiffusion: Score-based Generative 3D Mesh Modeling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhen Liu, Yao Feng, Michael J. Black, Derek Nowrouzezahrai, Liam Paull, Weiyang Liu&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08133&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://meshdiffusion.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/lzzcd001/MeshDiffusion/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Point Cloud Diffusion Models for Automatic Implant Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Paul Friedrich, Julia Wolleb, Florentin Bieder, Florian M. Thieringer, Philippe C. Cattin&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08061&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junyoung Seo&lt;sup&gt;1&lt;/sup&gt;, Wooseok Jang&lt;sup&gt;1&lt;/sup&gt;, Min-Seop Kwak&lt;sup&gt;1&lt;/sup&gt;, Jaehoon Ko, Hyeonsu Kim, Junho Kim, Jin-Hwa Kim, Jiyoung Lee, Seungryong Kim&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.07937&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GECCO: Geometrically-Conditioned Point Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Michał J. Tyszkiewicz, Pascal Fua, Eduard Trulls&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05916&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3DGen: Triplane Latent Diffusion for Textured Mesh Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Anchit Gupta, Wenhan Xiong, Yixin Nie, Ian Jones, Barlas Oğuz&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05371&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Human Motion Diffusion as a Generative Prior&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yonatan Shafir&lt;sup&gt;1&lt;/sup&gt;, Guy Tevet&lt;sup&gt;1&lt;/sup&gt;, Roy Kapon, Amit H. Bermano&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.01418&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Can We Use Diffusion Probabilistic Models for 3D Motion Prediction?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyemin Ahn, Esteve Valls Mascaro, Dongheui Lee&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.14503&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sites.google.com/view/diffusion-motion-prediction&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/cotton-ahn/diffusion-motion-prediction&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 28 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusioNeRF: Regularizing Neural Radiance Fields with Denoising Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jamie Wynn, Daniyar Turmukhambetov&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.12231&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/nianticlabs/diffusionerf&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 23 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PC2: Projection-Conditioned Point Cloud Diffusion for Single-Image 3D Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Luke Melas-Kyriazi, Christian Rupprecht, Andrea Vedaldi&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10668&#34;&gt;Paper&lt;/a&gt;] &lt;a href=&#34;https://lukemelas.github.io/projection-conditioned-point-cloud-diffusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 23 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NerfDiff: Single-image View Synthesis with NeRF-guided Distillation from 3D-aware Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiatao Gu, Alex Trevithick, Kai-En Lin, Josh Susskind, Christian Theobalt, Lingjie Liu, Ravi Ramamoorthi&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10109&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://jiataogu.me/nerfdiff/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SinMDM: Single Motion Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sigal Raab&lt;sup&gt;1&lt;/sup&gt;, Inbal Leibovitch&lt;sup&gt;1&lt;/sup&gt;, Guy Tevet, Moab Arar, Amit H. Bermano, Daniel Cohen-Or&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.05905&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sinmdm.github.io/SinMDM-page/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 12 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3D Colored Shape Reconstruction from a Single RGB Image through Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bo Li, Xiaolin Wei, Fengwei Chen, Bin Liu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.05573&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;HumanMAC: Masked Motion Completion for Human Motion Prediction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ling-Hao Chen, Jiawei Zhang, Yewen Li, Yiren Pang, Xiaobo Xia, Tongliang Liu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03665&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://lhchen.top/Human-MAC/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LinghaoChan/HumanMAC&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TEXTure: Text-Guided Texturing of 3D Shapes&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Elad Richardson&lt;sup&gt;1&lt;/sup&gt;, Gal Metzer&lt;sup&gt;1&lt;/sup&gt;, Yuval Alaluf, Raja Giryes, Daniel Cohen-Or&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.01721&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://texturepaper.github.io/TEXTurePaper/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/TEXTurePaper/TEXTurePaper&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 3 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero3D: Semantic-Driven Multi-Category 3D Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bo Han, Yitong Liu, Yixuan Shen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13591&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Neural Wavelet-domain Diffusion for 3D Shape Generation, Inversion, and Manipulation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jingyu Hu&lt;sup&gt;1&lt;/sup&gt;, Ka-Hei Hui&lt;sup&gt;1&lt;/sup&gt;, Zhengzhe Liu, Ruihui Li, Chi-Wing Fu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.00190&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3DShape2VecSet: A 3D Shape Representation for Neural Fields and Generative Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Biao Zhang, Jiapeng Tang, Matthias Niessner, Peter Wonka&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11445&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Fan Zhang, Naye Ji, Fuxing Gao, Yongping Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.10047&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bipartite Graph Diffusion Model for Human Interaction Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Baptiste Chopin, Hao Tang, Mohamed Daoudi&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.10134&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Generation, Optimization, and Planning in 3D Scenes&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Siyuan Huang&lt;sup&gt;1&lt;/sup&gt;, Zan Wang&lt;sup&gt;1&lt;/sup&gt;, Puhao Li, Baoxiong Jia, Tengyu Liu, Yixin Zhu, Wei Liang, Song-Chun Zhu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.06015&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://scenediffuser.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 15 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Modiff: Action-Conditioned 3D Motion Generation with Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mengyi Zhao, Mengyuan Liu, Bin Ren, Shuling Dai, Nicu Sebe&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.03949&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jumin Lee, Woobin Im, Sebin Lee, Sung-Eui Yoon&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.00527&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zoomin-lee/scene-scale-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiale Xu, Xintao Wang, Weihao Cheng, Yan-Pei Cao, Ying Shan, Xiaohu Qie, Shenghua Gao&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.14704&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://bluestyle97.github.io/dream3d/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 28 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Point-E: A System for Generating 3D Point Clouds from Complex Prompts&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alex Nichol&lt;sup&gt;1&lt;/sup&gt;, Heewoo Jun&lt;sup&gt;1&lt;/sup&gt;, Prafulla Dhariwal, Pamela Mishkin, Mark Chen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.08751&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/openai/point-e&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Real-Time Rendering of Arbitrary Surface Geometries using Learnt Transfer&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sirikonda Dhawal, Aakash KT, P.J. Narayanan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.09315&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unifying Human Motion Synthesis and Style Transfer with Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ziyi Chang, Edmund J. C. Findlay, Haozheng Zhang, Hubert P. H. Shum&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.08526&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rodin: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tengfei Wang&lt;sup&gt;1&lt;/sup&gt;, Bo Zhang&lt;sup&gt;1&lt;/sup&gt;, Ting Zhang, Shuyang Gu, Jianmin Bao, Tadas Baltrusaitis, Jingjing Shen, Dong Chen, Fang Wen, Qifeng Chen, Baining Guo&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.06135&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://3d-avatar-diffusion.microsoft.com/#/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 12 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative Scene Synthesis via Incremental View Inpainting using RGBD Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiabao Lei, Jiapeng Tang, Kui Jia&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.05993&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://jblei.site/project-pages/rgbd-diffusion.html&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 12 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Ego-Body Pose Estimation via Ego-Head Pose Estimation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiaman Li, C. Karen Liu, Jiajun Wu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04636&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MoFusion: A Framework for Denoising-Diffusion-based Motion Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rishabh Dabral, Muhammad Hamza Mughal, Vladislav Golyanik, Christian Theobalt&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04495&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://vcai.mpi-inf.mpg.de/projects/MoFusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yen-Chi Cheng, Hsin-Ying Lee, Sergey Tulyakov, Alexander Schwing, Liangyan Gui&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04493&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://yccyenchicheng.github.io/SDFusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Executing your Commands via Motion Diffusion in Latent Space&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xin Chen, Biao Jiang, Wen Liu, Zilong Huang, Bin Fu, Tao Chen, Jingyi Yu, Gang Yu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04048&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://chenxin.tech/mld/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Magic: Multi Art Genre Intelligent Choreography Dataset and Network for 3D Dance Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ronghui Li, Junfan Zhao, Yachao Zhang, Mingyang Su, Zeping Ren, Han Zhang, Xiu Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03741&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Congyue Deng, Chiyu &#34;Max&#39;&#39; Jiang, Charles R. Qi, Xinchen Yan, Yin Zhou, Leonidas Guibas, Dragomir Anguelov&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03267&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-SDF: Text-to-Shape via Voxelized Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Muheng Li, Yueqi Duan, Jie Zhou, Jiwen Lu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03293&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pretrained Diffusion Models for Unified Human Motion Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jianxin Ma, Shuai Bai, Chang Zhou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02837&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ofa-sys.github.io/MoFusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffuPose: Monocular 3D Human Pose Estimation via Denoising Diffusion Probabilistic Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jeongjun Choi, Dongseok Shim, H. Jin Kim&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02796&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PhysDiff: Physics-Guided Human Motion Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ye Yuan, Jiaming Song, Umar Iqbal, Arash Vahdat, Jan Kautz&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02500&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nvlabs.github.io/PhysDiff/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 5 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast Point Cloud Generation with Straight Flows&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lemeng Wu, Dilin Wang, Chengyue Gong, Xingchao Liu, Yunyang Xiong, Rakesh Ranjan, Raghuraman Krishnamoorthi, Vikas Chandra, Qiang Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.01747&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffRF: Rendering-Guided 3D Radiance Field Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Norman Müller, Yawar Siddiqui, Lorenzo Porzi, Samuel Rota Bulò, Peter Kontschieder, Matthias Nießner&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.01206&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sirwyver.github.io/DiffRF/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 2 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3D-LDM: Neural Implicit 3D Shape Generation with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gimin Nam, Mariem Khlifi, Andrew Rodriguez, Alberto Tono, Linqi Zhou, Paul Guerrero&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00842&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haochen Wang&lt;sup&gt;1&lt;/sup&gt;, Xiaodan Du&lt;sup&gt;1&lt;/sup&gt;, Jiahao Li&lt;sup&gt;1&lt;/sup&gt;, Raymond A. Yeh, Greg Shakhnarovich&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00774&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhizhuo Zhou, Shubham Tulsiani&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00792&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sparsefusion.github.io/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3D Neural Field Generation using Triplane Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;J. Ryan Shue, Eric Ryan Chan, Ryan Po, Zachary Ankner, Jiajun Wu, Gordon Wetzstein&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16677&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://jryanshue.com/nfd/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 30 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffPose: Toward More Reliable 3D Pose Estimation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jia Gong&lt;sup&gt;1&lt;/sup&gt;, Lin Geng Foo&lt;sup&gt;1&lt;/sup&gt;, Zhipeng Fan, Qiuhong Ke, Hossein Rahmani, Jun Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16940&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffPose: Multi-hypothesis Human Pose Estimation using Diffusion models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Karl Holmquist, Bastian Wandt&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16487&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gwanghyun Kim, Se Young Chun&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16374&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://datid-3d.github.io/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with 360° Views&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dejia Xu, Yifan Jiang, Peihao Wang, Zhiwen Fan, Yi Wang, Zhangyang Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16431&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://vita-group.github.io/NeuralLift-360/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 29 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Ada3Diff: Defending against 3D Adversarial Point Clouds via Adaptive Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kui Zhang, Hang Zhou, Jie Zhang, Qidong Huang, Weiming Zhang, Nenghai Yu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16247&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;UDE: A Unified Driving Engine for Human Motion Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zixiang Zhou, Baoyuan Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.16016&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://zixiangzhou916.github.io/UDE/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zixiangzhou916/UDE/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3DDesigner: Towards Photorealistic 3D Object Generation and Editing with Text-guided Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gang Li, Heliang Zheng, Chaoyue Wang, Chang Li, Changwen Zheng, Dacheng Tao&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.14108&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionSDF: Conditional Generative Modeling of Signed Distance Functions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gene Chou, Yuval Bahat, Felix Heide&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13757&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Tetrahedral Diffusion Models for 3D Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nikolai Kalischek, Torben Peters, Jan D. Wegner, Konrad Schindler&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13220&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;IC3D: Image-Conditioned 3D Diffusion for Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cristian Sbrolli, Paolo Cudrano, Matteo Frosi, Matteo Matteucci&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10865&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Listen, denoise, action! Audio-driven motion synthesis with diffusion models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Simon Alexanderson, Rajmund Nagy, Jonas Beskow, Gustav Eje Henter&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09707&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Titas Anciukevičius, Zexiang Xu, Matthew Fisher, Paul Henderson, Hakan Bilen, Niloy J. Mitra, Paul Guerrero&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09869&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Anciukevicius/RenderDiffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 17 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gal Metzer&lt;sup&gt;1&lt;/sup&gt;, Elad Richardson&lt;sup&gt;1&lt;/sup&gt;, Or Patashnik, Raja Giryes, Daniel Cohen-Or&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.07600&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/eladrich/latent-nerf&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 14 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ReFu: Refine and Fuse the Unobserved View for Detail-Preserving Single-Image 3D Human Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gyumin Shim&lt;sup&gt;1&lt;/sup&gt;, Minsoo Lee&lt;sup&gt;1&lt;/sup&gt;, Jaegul Choo&lt;/em&gt; &lt;br&gt; ACM 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.04753&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;StructDiffusion: Object-Centric Diffusion for Semantic Rearrangement of Novel Objects&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weiyu Liu, Tucker Hermans, Sonia Chernova, Chris Paxton&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.04604&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Motion: Generate Text-Guided 3D Human Motion by Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhiyuan Ren, Zhihong Pan, Xin Zhou, Le Kang&lt;/em&gt; &lt;br&gt; ICASSP 2023. [&lt;a href=&#34;https://arxiv.org/abs/2210.12315&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LION: Latent Point Diffusion Models for 3D Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiaohui Zeng, Arash Vahdat, Francis Williams, Zan Gojcic, Or Litany, Sanja Fidler, Karsten Kreis&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/pdf/2210.06978.pdf&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nv-tlabs.github.io/LION/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 12 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Human Joint Kinematics Diffusion-Refinement for Stochastic Motion Prediction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dong Wei, Huaijiang Sun, Bin Li, Jianfeng Lu, Weiqing Li, Xiaoning Sun, Shengxiang Hu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.05976&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A generic diffusion-based approach for 3D human pose prediction in the wild&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Saeed Saadatnejad, Ali Rasekh, Mohammadreza Mofayezi, Yasamin Medghalchi, Sara Rajabzadeh, Taylor Mordan, Alexandre Alahi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.05669&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Novel View Synthesis with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Daniel Watson, William Chan, Ricardo Martin-Brualla, Jonathan Ho, Andrea Tagliasacchi, Mohammad Norouzi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.04628&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Neural Volumetric Mesh Generator&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yan Zheng, Lemeng Wu, Xingchao Liu, Zhen Chen, Qiang Liu, Qixing Huang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.03158&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Probabilistic Models for Styled Walking Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Edmund J. C. Findlay, Haozheng Zhang, Ziyi Chang, Hubert P. H. Shum&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14828&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Human Motion Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Amit H. Bermano, Daniel Cohen-Or&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14916&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://guytevet.github.io/mdm-page/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhengzhe Liu, Peng Dai, Ruihui Li, Xiaojuan Qi, Chi-Wing Fu&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2209.04145&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/liuzhengzhe/ISS-Image-as-Stepping-Stone-for-Text-Guided-3D-Shape-Generation&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 9 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SE(3)-DiffusionFields: Learning cost functions for joint grasp and motion optimization through diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julen Urain, Niklas Funk, Georgia Chalvatzaki, Jan Peters&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.03855&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/TheCamusean/grasp_diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;First Hitting Diffusion Models for Generating Manifold, Graph and Categorical Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mao Ye, Lemeng Wu, Qiang Liu&lt;/em&gt; &lt;br&gt; NeruIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.01170&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;FLAME: Free-form Language-based Motion Synthesis &amp;amp; Editing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jihoon Kim, Jiseob Kim, Sungjoon Choi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.00349&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Let us Build Bridges: Understanding and Extending Diffusion Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xingchao Liu, Lemeng Wu, Mao Ye, Qiang Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.14699&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MotionDiffuse: Text-Driven Human Motion Generation with Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mingyuan Zhang, Zhongang Cai, Liang Pan, Fangzhou Hong, Xinying Guo, Lei Yang, Ziwei Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.15001&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://mingyuan-zhang.github.io/projects/MotionDiffuse.html&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 31 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dominik J. E. Waibel, Ernst Röell, Bastian Rieck, Raja Giryes, Carsten Marr&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.14125&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PointDP: Diffusion-driven Purification against Adversarial Attacks on 3D Point Cloud Recognition&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiachen Sun, Weili Nie, Zhiding Yu, Z. Morley Mao, Chaowei Xiao&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.09801&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhaoyang Lyu, Zhifeng Kong, Xudong Xu, Liang Pan, Dahua Lin&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2112.03530&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zhaoyanglyu/point_diffusion_refinement&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 7 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-Based Point Cloud Denoising&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shitong Luo, Wei Hu&lt;/em&gt;&lt;br&gt; ICCV 2021. [&lt;a href=&#34;https://arxiv.org/abs/2107.10981&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/luost26/score-denoise&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 23 Jul 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffuStereo: High Quality Human Reconstruction via Diffusion-based Stereo Using Sparse Cameras&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ruizhi Shao, Zerong Zheng, Hongwen Zhang, Jingxiang Sun, Yebin Liu&lt;/em&gt; &lt;br&gt; ECCV 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.08000&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;http://liuyebin.com/diffustereo/diffustereo.html&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/DSaurus/DiffuStereo&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3D Shape Generation and Completion through Point-Voxel Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Linqi Zhou, Yilun Du, Jiajun Wu&lt;/em&gt; &lt;br&gt; ICCV 2021. [&lt;a href=&#34;https://arxiv.org/abs/2104.03670&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://alexzhou907.github.io/pvd&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Apr 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Probabilistic Models for 3D Point Cloud Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shitong Luo, Wei Hu&lt;/em&gt; &lt;br&gt; CVPR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2103.01458&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/luost26/diffusion-point-cloud&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Mar 2021&lt;/p&gt; &#xA;&lt;h3&gt;Adversarial Attack&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Black-box Backdoor Defense via Zero-shot Image Purification&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yucheng Shi, Mengnan Du, Xuansheng Wu, Zihan Guan, Ninghao Liu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12175&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adversarial Counterfactual Visual Explanations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Guillaume Jeanneret, Loïc Simon, Frédéric Jurie&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09962&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Robust Evaluation of Diffusion-Based Adversarial Purification&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Minjong Lee, Dongwoo Kim&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09051&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Devil&#39;s Advocate: Shattering the Illusion of Unexploitable Data using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08500&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TrojDiff: Trojan Attacks on Diffusion Models with Diverse Targets&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weixin Chen, Dawn Song, Bo Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05762&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/chenweixin107/TrojDiff&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative Model-Based Attack on Learnable Image Encryption for Privacy-Preserving Deep Learning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;AprilPyone MaungMaung, Hitoshi Kiya&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05036&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Differentially Private Diffusion Models Generate Useful Synthetic Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sahra Ghalebikesabi, Leonard Berrada, Sven Gowal, Ira Ktena, Robert Stanforth, Jamie Hayes, Soham De, Samuel L. Smith, Olivia Wiles, Borja Balle&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.13861&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Data Forensics in Diffusion Models: A Systematic Analysis of Membership Privacy&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Derui Zhu&lt;sup&gt;1&lt;/sup&gt;, Dingfan Chen&lt;sup&gt;1&lt;/sup&gt;, Jens Grossklags, Mario Fritz&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07801&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Raising the Cost of Malicious AI-Powered Image Editing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hadi Salman, Alaa Khaddaj, Guillaume Leclerc, Andrew Ilyas, Aleksander Madry&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.06588&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chumeng Liang&lt;sup&gt;1&lt;/sup&gt;, Xiaoyu Wu&lt;sup&gt;1&lt;/sup&gt;, Yang Hua, Jiaru Zhang, Yiming Xue, Tao Song, Zhengui Xue, Ruhui Ma, Haibing Guan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04578&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Better Diffusion Models Further Improve Adversarial Training&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zekai Wang&lt;sup&gt;1&lt;/sup&gt;, Tianyu Pang&lt;sup&gt;1&lt;/sup&gt;, Chao Du, Min Lin, Weiwei Liu, Shuicheng Yan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04638&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/wzekai99/DM-Improves-AT&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 9 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Membership Inference Attacks against Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tomoya Matsumoto, Takayuki Miura, Naoto Yanai&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03262&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MorDIFF: Recognition Vulnerability and Attack Detectability of Face Morphing Attacks Created by Diffusion Autoencoders&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Naser Damer, Meiling Fang, Patrick Siebke, Jan Niklas Kolf, Marco Huber, Fadi Boutros&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.01843&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Extracting Training Data from Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nicholas Carlini&lt;sup&gt;1&lt;/sup&gt;, Jamie Hayes&lt;sup&gt;1&lt;/sup&gt;, Milad Nasr&lt;sup&gt;1&lt;/sup&gt;, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.00860&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Are Diffusion Models Vulnerable to Membership Inference Attacks?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jinhao Duan, Fei Kong, Shiqi Wang, Xiaoshuang Shi, Kaidi Xu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.01316&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Salient Conditional Diffusion for Defending Against Backdoor Attacks&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Brandon B. May&lt;sup&gt;1&lt;/sup&gt;, N. Joseph Tatro&lt;sup&gt;1&lt;/sup&gt;, Piyush Kumar, Nathan Shnidman&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13721&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Extracting Training Data from Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nicholas Carlini&lt;sup&gt;1&lt;/sup&gt;, Jamie Hayes&lt;sup&gt;1&lt;/sup&gt;, Milad Nasr&lt;sup&gt;1&lt;/sup&gt;, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13188&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Membership Inference of Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hailong Hu, Jun Pang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.09956&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Probabilistic Models as a Defense against Adversarial Attacks&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lars Lien Ankile, Anna Midgley, Sebastian Weisshaar&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.06871&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ankile/Adversarial-Diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 17 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fight Fire With Fire: Reversing Skin Adversarial Examples by Multiscale Diffusive and Denoising Aggregation Mechanism&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yongwei Wang&lt;sup&gt;1&lt;/sup&gt;, Yuan Li&lt;sup&gt;1&lt;/sup&gt;, Zhiqi Shen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.10373&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DensePure: Understanding Diffusion Models towards Adversarial Robustness&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chaowei Xiao&lt;sup&gt;1&lt;/sup&gt;, Zhongzhu Chen&lt;sup&gt;1&lt;/sup&gt;, Kun Jin&lt;sup&gt;1&lt;/sup&gt;, Jiongxiao Wang&lt;sup&gt;1&lt;/sup&gt;, Weili Nie, Mingyan Liu, Anima Anandkumar, Bo Li, Dawn Song&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.00322&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improving Adversarial Robustness by Contrastive Guided Diffusion Process&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yidong Ouyang, Liyan Xie, Guang Cheng&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.09643&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 18 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Differentially Private Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tim Dockhorn, Tianshi Cao, Arash Vahdat, Karsten Kreis&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.09929&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nv-tlabs.github.io/DPDM/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 18 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PointDP: Diffusion-driven Purification against Adversarial Attacks on 3D Point Cloud Recognition&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiachen Sun, Weili Nie, Zhiding Yu, Z. Morley Mao, Chaowei Xiao&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.09801&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Threat Model-Agnostic Adversarial Defense using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tsachi Blau, Roy Ganz, Bahjat Kawar, Alex Bronstein, Michael Elad&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.08089&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Back to the Source: Diffusion-Driven Test-Time Adaptation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jin Gao&lt;sup&gt;1&lt;/sup&gt;, Jialing Zhang&lt;sup&gt;1&lt;/sup&gt;, Xihui Liu, Trevor Darrell, Evan Shelhamer, Dequan Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.03442&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Guided Diffusion Model for Adversarial Purification from Random Noise&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Quanlin Wu, Hang Ye, Yuntian Gu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.10875&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;(Certified!!) Adversarial Robustness for Free!&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nicholas Carlini, Florian Tramer, Krishnamurthy (Dj)Dvijotham, J. Zico Kolter&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.10550&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Guided Diffusion Model for Adversarial Purification&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jinyi Wang&lt;sup&gt;1&lt;/sup&gt;, Zhaoyang Lyu&lt;sup&gt;1&lt;/sup&gt;, Dahua Lin, Bo Dai, Hongfei Fu&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.14969&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jinyiw/guideddiffusionpur&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 30 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Adversarial Purification&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat, Anima Anandkumar&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.07460&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://diffpure.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/NVlabs/DiffPure&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TFDPM: Attack detection for cyber-physical systems with diffusion probabilistic models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tijin Yan, Tong Zhou, Yufeng Zhan, Yuanqing Xia&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.10774&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adversarial purification with Score-based generative models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jongmin Yoon, Sung Ju Hwang, Juho Lee&lt;/em&gt; &lt;br&gt; ICML 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.06041&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jmyoon1/adp&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 11 Jun 2021&lt;/p&gt; &#xA;&lt;h3&gt;Miscellaneous&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Visual Chain-of-Thought Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;William Harvey, Frank Wood&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.16187&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Your Diffusion Model is Secretly a Zero-Shot Classifier&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alexander C. Li, Mihir Prabhudesai, Shivam Duggal, Ellis Brown, Deepak Pathak&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.16203&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://diffusion-classifier.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 28 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nicola Franco, Daniel Korth, Jeanette Miriam Lorenz, Karsten Roscher, Stephan Guennemann&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14961&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-to-Image Diffusion Models are Zero-Shot Classifiers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kevin Clark, Priyank Jaini&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15233&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sauradip Nag, Xiatian Zhu, Jiankang Deng, Yi-Zhe Song, Tao Xiang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14863&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Stable Signature: Rooting Watermarks in Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pierre Fernandez, Guillaume Couairon, Hervé Jégou, Matthijs Douze, Teddy Furon&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15435&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://pierrefdz.github.io/publications/stablesignature/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Exploring Continual Learning of Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Michał Zając, Kamil Deja, Anna Kuzina, Jakub M. Tomczak, Tomasz Trzciński, Florian Shkurti, Piotr Miłoś&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15342&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Freestyle Layout-to-Image Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Han Xue, Zhiwu Huang, Qianru Sun, Li Song, Wenjun Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14412&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jordan J. Bird, Ahmad Lotfi&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.14126&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Controllable Inversion of Black-Box Face-Recognition Models via Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Manuel Kansy, Anton Raël, Graziana Mignone, Jacek Naruniec, Christopher Schroers, Markus Gross, Romann M. Weber&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13006&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffPattern: Layout Pattern Generation via Discrete Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zixiao Wang, Yunheng Shen, Wenqian Zhao, Yang Bai, Guojin Chen, Farzan Farnia, Bei Yu&lt;/em&gt; &lt;br&gt; DAC 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13060&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffuse-Denoise-Count: Accurate Crowd-Counting with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yasiru Ranasinghe, Nithin Gopalakrishnan Nair, Wele Gedara Chaminda Bandara, Vishal M. Patel&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12790&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junyi Zhang&lt;sup&gt;1&lt;/sup&gt;, Jiaqi Guo&lt;sup&gt;1&lt;/sup&gt;, Shizhao Sun, Jian-Guang Lou, Dongmei Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11589&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Positional Diffusion: Ordering Unordered Sets with Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Francesco Giuliari, Gianluca Scarpellini, Stuart James, Yiming Wang, Alessio Del Bue&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11120&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://iit-pavis.github.io/Positional_Diffusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Leapfrog Diffusion Model for Stochastic Trajectory Prediction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weibo Mao, Chenxin Xu, Qi Zhu, Siheng Chen, Yanfeng Wang&lt;/em&gt; &lt;br&gt; arxiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10895&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MediaBrain-SJTU/LED&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pluralistic Aging Diffusion Autoencoder&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Peipei Li, Rui Wang, Huaibo Huang, Ran He, Zhaofeng He&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11086&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AnimeDiffusion: Anime Face Line Drawing Colorization via Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yu Cao, Xiangqiao Meng, P.Y. Mok, Xueting Liu, Tong-Yee Lee, Ping Li&lt;/em&gt; &lt;br&gt; arxiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11137&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Document Layout Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Liu He, Yijuan Lu, John Corring, Dinei Florencio, Cha Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10787&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On the De-duplication of LAION-2B&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ryan Webster, Julien Rabin, Loic Simon, Frederic Jurie&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12733&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Recipe for Watermarking Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Ngai-Man Cheung, Min Lin&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.10137&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Autoencoders are Unified Self-supervised Learners&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Weilai Xiang, Hongyu Yang, Di Huang, Yunhong Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09769&#34;&gt;Paper&lt;/a&gt;] )] &lt;br&gt; 17 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DIRE for Diffusion-Generated Image Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhendong Wang, Jianmin Bao, Wengang Zhou, Weilun Wang, Hezhen Hu, Hong Chen, Houqiang Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09295&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ZhendongWang6/DIRE&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Maham Tanveer, Yizhi Wang, Ali Mahdavi-Amiri, Hao Zhang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.09604&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ds-fusion.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 16 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionAD: Denoising Diffusion for Anomaly Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hui Zhang, Zheng Wang, Zuxuan Wu, Yu-Gang Jiang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08730&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LayoutDM: Discrete Diffusion Model for Controllable Layout Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Naoto Inoue, Kotaro Kikuchi, Edgar Simo-Serra, Mayu Otani, Kota Yamaguchi&lt;/em&gt; &lt;br&gt; CVPR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08137&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://cyberagentailab.github.io/layout-dm/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/CyberAgentAILab/layout-dm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Parallel Vertex Diffusion for Unified Visual Grounding&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zesen Cheng, Kehan Li, Peng Jin, Xiangyang Ji, Li Yuan, Chang Liu, Jie Chen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.07216&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zixiang Zhao, Haowen Bai, Yuanzhi Zhu, Jiangshe Zhang, Shuang Xu, Yulun Zhang, Kai Zhang, Deyu Meng, Radu Timofte, Luc Van Gool&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06840&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Detecting Images Generated by Diffusers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Davide Alessandro Coccomini, Andrea Esuli, Fabrizio Falchi, Claudio Gennaro, Giuseppe Amato&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05275&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unifying Layout Generation with a Decoupled Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mude Hui, Zhizheng Zhang, Xiaoyi Zhang, Wenxuan Xie, Yuwang Wang, Yan Lu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05049&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DLT: Conditioned layout generation with Joint Discrete-Continuous Diffusion Layout Transformer&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Elad Levi, Eli Brosh, Mykola Mykhailych, Meir Perez&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.03755&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion in the Dark: A Diffusion Model for Low-Light Text Recognition&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cindy M. Nguyen, Eric R. Chan, Alexander W. Bergman, Gordon Wetzstein&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.04291&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ccnguyen.github.io/diffusion-in-the-dark/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 7 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Word-As-Image for Semantic Typography&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shir Iluz&lt;sup&gt;1&lt;/sup&gt;, Yael Vinker&lt;sup&gt;1&lt;/sup&gt;, Amir Hertz, Daniel Berio, Daniel Cohen-Or, Ariel Shamir&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.01818&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Makeup Extraction of 3D Representation via Illumination-Aware Image Decomposition&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xingchao Yang, Takafumi Taketomi, Yoshihiro Kanamori&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.13279&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Monocular Depth Estimation using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Saurabh Saxena, Abhishek Kar, Mohammad Norouzi, David J. Fleet&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.14816&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Spatial-temporal Transformer-guided Diffusion based Data Augmentation for Efficient Skeleton-based Action Recognition&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yifan Jiang, Han Chen, Hanseok Ko&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.13434&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://depth-gen.github.io/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 26 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LDFA: Latent Diffusion Face Anonymization for Self-driving Applications&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Marvin Klemp, Kevin Rösch, Royden Wagner, Jannik Quehl, Martin Lauer&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.08931&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Road Redesign Technique Achieving Enhanced Road Safety by Inpainting with a Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sumit Mishra, Medhavi Mishra, Taeyoung Kim, Dongsoo Har&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07440&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Effective Data Augmentation With Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Brandon Trabucco, Kyle Doherty, Max Gurinas, Ruslan Salakhutdinov&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07944&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://btrabuc.co/da-fusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Boosting Zero-shot Classification with Synthetic Data Diversity via Stable Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jordan Shipard, Arnold Wiliem, Kien Nguyen Thanh, Wei Xiang, Clinton Fookes&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03298&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning End-to-End Channel Coding with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Muah Kim, Rick Fritschek, Rafael F. Schaefer&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.01714&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Extracting Training Data from Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nicholas Carlini&lt;sup&gt;1&lt;/sup&gt;, Jamie Hayes&lt;sup&gt;1&lt;/sup&gt;, Milad Nasr&lt;sup&gt;1&lt;/sup&gt;, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.00860&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for High-Resolution Solar Forecasts&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yusuke Hatanaka, Yannik Glaser, Geoff Galgon, Giuseppe Torri, Peter Sadowski&lt;/em&gt; &lt;br&gt; arxiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.00170&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Denoising Diffusion Model for Fluid Field Prediction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gefan Yang&lt;sup&gt;1&lt;/sup&gt;, Stefan Sommer&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11661&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models as Artists: Are we Closing the Gap between Humans and Machines?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Victor Boutin, Thomas Fel, Lakshya Singhal, Rishav Mukherji, Akash Nagaraj, Julien Colin, Thomas Serre&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11722&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PLay: Parametrically Conditioned Layout Generation using Latent Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chin-Yi Cheng, Forrest Huang, Gang Li, Yang Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11529&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Screen Space Indirect Lighting with Visibility Bitmask&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Olivier Therrien, Yannick Levesque, Guillaume Gilet&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11376&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On the Importance of Noise Scheduling for Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ting Chen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.10972&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LEGO-Net: Learning Regular Rearrangements of Objects in Rooms&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qiuhong Anna Wei, Sijie Ding, Jeong Joon Park, Rahul Sajnani, Adrien Poulenard, Srinath Sridhar, Leonidas Guibas&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.09629&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ivl.cs.brown.edu/#/projects/lego-net&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 23 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image Fusion with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jun Yue, Leyuan Fang, Shaobo Xia, Yue Deng, Jiayi Ma&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.08072&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Neural Image Compression with a Diffusion-Based Decoder&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Noor Fathima Goose&lt;sup&gt;1&lt;/sup&gt;, Jens Petersen&lt;sup&gt;1&lt;/sup&gt;, Auke Wiggers&lt;sup&gt;1&lt;/sup&gt;, Tianlin Xu, Guillaume Sautière&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.05489&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Data Augmentation for Skin Disease Classification: Impact Across Original Medical Datasets to Fully Synthetic Images&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mohamed Akrout&lt;sup&gt;1&lt;/sup&gt;, Bálint Gyepesi&lt;sup&gt;1&lt;/sup&gt;, Péter Holló, Adrienn Poór, Blága Kincső, Stephen Solis, Katrina Cirone, Jeremy Kawahara, Dekker Slade, Latif Abid, Máté Kovács, István Fazekas&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.04802&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speech Driven Video Editing via an Audio-Conditioned Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dan Bigioi, Shubhajit Basak, Hugh Jordan, Rachel McDonnell, Peter Corcoran&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.04474&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://danbigioi.github.io/DiffusionVideoEditing/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/DanBigioi/DiffusionVideoEditing&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models For Stronger Face Morphing Attacks&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zander Blasingame, Chen Liu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.04218&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffTalk: Crafting Diffusion Models for Generalized Talking Head Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shuai Shen, Wenliang Zhao, Zibin Meng, Wanhua Li, Zheng Zhu, Jie Zhou, Jiwen Lu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.03786&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speech Driven Video Editing via an Audio-Conditioned Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dan Bigioi, Shubhajit Basak, Hugh Jordan, Rachel McDonnell, Peter Corcoran&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.04474&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Michał Stypułkowski, Konstantinos Vougioukas, Sen He, Maciej Zięba, Stavros Petridis, Maja Pantic&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.03396&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://mstypulkowski.github.io/diffusedheads/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 6 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Contrastive Language-Vision AI Models Pretrained on Web-Scraped Multimodal Data Exhibit Sexual Objectification Bias&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Robert Wolfe, Yiwei Yang, Bill Howe, Aylin Caliskan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.11261&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AI Art in Architecture&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Joern Ploennigs, Markus Berger&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.09399&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusing Surrogate Dreams of Video Scenes to Predict Video Memorability&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lorin Sweeney, Graham Healy, Alan F. Smeaton&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.09308&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fake it till you make it: Learning(s) from a synthetic ImageNet clone&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mert Bulent Sariyildiz, Karteek Alahari, Diane Larlus, Yannis Kalantidis&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.08420&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The Infinite Index: Information Retrieval on Generative Text-To-Image Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Niklas Deckers, Maik Fröbe, Johannes Kiesel, Gianluca Pandolfo, Christopher Schröder, Benno Stein, Martin Potthast&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.07476&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LidarCLIP or: How I Learned to Talk to Point Clouds&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Georg Hess, Adam Tonderski, Christoffer Petersson, Lennart Svensson, Kalle Åström&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.06858&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/atonderski/lidarclip&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diff-Font: Diffusion Model for Robust One-Shot Font Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haibin He, Xinyuan Chen, Chaoyue Wang, Juhua Liu, Bo Du, Dacheng Tao, Yu Qiao&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.05895&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffAlign : Few-shot learning using diffusion based synthesis and alignment&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Aniket Roy, Anshul Shah, Ketul Shah, Anirban Roy, Rama Chellappa&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.05404&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How to Backdoor Diffusion Models?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.05400&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Talking Head Generation with Probabilistic Audio-to-Visual Diffusion Priors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhentao Yu, Zixin Yin, Deyu Zhou, Duomin Wang, Finn Wong, Baoyuan Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.04248&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://zxyin.github.io/TH-PAD/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 7 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, Tom Goldstein&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03860&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Neural Cell Video Synthesis via Optical-Flow Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Manuel Serna-Aguilera, Khoa Luu, Nathaniel Harris, Min Zou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03250&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Semantic-Conditional Diffusion Networks for Image Captioning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jianjie Luo, Yehao Li, Yingwei Pan, Ting Yao, Jianlin Feng, Hongyang Chao, Tao Mei&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.03099&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/YehLi/xmodaler/tree/master/configs/image_caption/scdnet&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ObjectStitch: Generative Object Compositing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yizhi Song, Zhifei Zhang, Zhe Lin, Scott Cohen, Brian Price, Jianming Zhang, Soo Ye Kim, Daniel Aliaga&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00932&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Post-training Quantization on Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuzhang Shang&lt;sup&gt;1&lt;/sup&gt;, Zhihang Yuan&lt;sup&gt;1&lt;/sup&gt;, Bin Xie&lt;sup&gt;1&lt;/sup&gt;, Bingzhe Wu, Yan Yan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.15736&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Refined Semantic Enhancement towards Frequency Diffusion for Video Captioning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xian Zhong, Zipeng Li, Shuqin Chen, Kui Jiang, Chen Chen, Mang Ye&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.15076&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/lzp870/RSFD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 28 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Probabilistic Model Made Slim&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xingyi Yang, Daquan Zhou, Jiashi Feng, Xinchao Wang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.17106&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;German Barquero, Sergio Escalera, Cristina Palmero&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.14304&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;JigsawPlan: Room Layout Jigsaw Puzzle Extreme Structure from Motion using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sepidehsadat Hosseini, Mohammad Amin Shabani, Saghar Irandoust, Yasutaka Furukawa&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13785&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sepidsh.github.io/JigsawPlan/index.html&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 24 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;HouseDiffusion: Vector Floorplan Generation via a Diffusion Model with Discrete and Continuous Denoising&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mohammad Amin Shabani, Sepidehsadat Hosseini, Yasutaka Furukawa&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13287&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://aminshabani.github.io/housediffusion/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Make-A-Story: Visual Memory Conditioned Consistent Story Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tanzila Rahman, Hsin-Ying Lee, Jian Ren, Sergey Tulyakov, Shweta Mahajan, Leonid Sigal&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13319&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Inversion-Based Creativity Transfer with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuxin Zhang, Nisha Huang, Fan Tang, Haibin Huang, Chongyang Ma, Weiming Dong, Changsheng Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13203&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Schrödinger&#39;s Bat: Diffusion Models Sometimes Generate Polysemous Words in Superposition&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jennifer C. White, Ryan Cotterell&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13095&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Can denoising diffusion probabilistic models generate realistic astrophysical fields?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nayantara Mudur, Douglas P. Finkbeiner&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12444&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffDreamer: Consistent Single-view Perpetual View Generation with Conditional Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shengqu Cai, Eric Ryan Chan, Songyou Peng, Mohamad Shahbazi, Anton Obukhov, Luc Van Gool, Gordon Wetzstein&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12131&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://primecai.github.io/diffdreamer&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Person Image Synthesis via Denoising Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ankan Kumar Bhunia, Salman Khan, Hisham Cholakkal, Rao Muhammad Anwer, Jorma Laaksonen, Mubarak Shah, Fahad Shahbaz Khan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.12500&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Denoising Process for Perceptron Bias in Out-of-distribution Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Luping Liu, Yi Ren, Xize Cheng, Zhou Zhao&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.11255&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/luping-liu/DiffOOD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 21 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Exploring Discrete Diffusion Models for Image Captioning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zixin Zhu, Yixuan Wei, Jianfeng Wang, Zhe Gan, Zheng Zhang, Le Wang, Gang Hua, Lijuan Wang, Zicheng Liu, Han Hu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.11694&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/buxiangzhiren/DDCap&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 21 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xichen Pan, Pengda Qin, Yuhong Li, Hui Xue, Wenhu Chen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10950&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionDet: Diffusion Model for Object Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shoufa Chen, Peize Sun, Yibing Song, Ping Luo&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09788&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ShoufaChen/DiffusionDet&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 17 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Learning to Kindle the Starlight&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yu Yuan, Jiaqi Wu, Lindong Wang, Zhongliang Jing, Henry Leung, Shuyuan Zhu, Han Pan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09206&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CaDM: Codec-aware Diffusion Modeling for Neural-enhanced Video Streaming&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qihua Zhou, Ruibin Li, Song Guo, Yi Liu, Jingcai Guo, Zhenda Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.08428&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ShadowDiffusion: Diffusion-based Shadow Removal using Classifier-driven Attention and Structure Preservation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yeying Jin, Wenhan Yang, Wei Ye, Yuan Yuan, Robby T. Tan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.08089&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Extreme Generative Image Compression by Learning Text Embedding from Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhihong Pan, Xin Zhou, Hao Tian&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.07793&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Models for Out-of-Distribution Detection&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mark S. Graham, Walter H.L. Pinaya, Petru-Daniel Tudosiu, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardoso&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.07740&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Evaluating a Synthetic Image Dataset Generated with Stable Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andreas Stöckl&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.01777&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Quantized Compressed Sensing with Score-Based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiangming Meng, Yoshiyuki Kabashima&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.13006&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mengxiangming/QCS-SGM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On the detection of synthetic images generated by diffusion models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Riccardo Corvi, Davide Cozzolino, Giada Zingarini, Giovanni Poggi, Koki Nagano, Luisa Verdoliva&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.00680&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DOLPH: Diffusion Models for Phase Retrieval&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shirin Shoushtari&lt;sup&gt;1&lt;/sup&gt;, Jiaming Liu&lt;sup&gt;1&lt;/sup&gt;, Ulugbek S. Kamilov&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.00529&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A simple, efficient and scalable contrastive masked autoencoder for learning visual representations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shlok Mishra, Joshua Robinson, Huiwen Chang, David Jacobs, Aaron Sarna, Aaron Maschinot, Dilip Krishnan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.16870&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Towards the Detection of Diffusion Model Deepfakes&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jonas Ricker, Simon Damm, Thorsten Holz, Asja Fischer&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.14571&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;From Points to Functions: Infinite-dimensional Representations in Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sarthak Mittal, Guillaume Lajoie, Stefan Bauer, Arash Mehrjou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.13774&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sarthmit/traj_drl&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 25 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Boomerang: Local sampling on image manifolds using diffusion models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lorenzo Luzi, Ali Siahkoohi, Paul M Mayer, Josue Casco-Rodriguez, Richard Baraniuk&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.12100&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://colab.research.google.com/drive/1PV5Z6b14HYZNx1lHCaEVhId-Y4baKXwt&#34;&gt;Colab&lt;/a&gt;] &lt;br&gt; 21 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deep Data Augmentation for Weed Recognition Enhancement: A Diffusion Probabilistic Model and Transfer Learning Based Approach&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dong Chen, Xinda Qi, Yu Zheng, Yuzhen Lu, Zhaojian Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.09509&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/DongChen06/DMWeeds&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 18 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Meta-Learning via Classifier(-free) Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Elvis Nava&lt;sup&gt;1&lt;/sup&gt;, Seijin Kobayashi&lt;sup&gt;1&lt;/sup&gt;, Yifei Yin, Robert K. Katzschmann, Benjamin F. Grewe&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.08942&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zeyang Sha, Zheng Li, Ning Yu, Yang Zhang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.06998&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Markup-to-Image Diffusion Models with Scheduled Sampling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuntian Deng, Noriyuki Kojima, Alexander M. Rush&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.05147&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What the DAAM: Interpreting Stable Diffusion Using Cross Attention&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Raphael Tang, Akshat Pandey, Zhiying Jiang, Gefei Yang, Karun Kumar, Jimmy Lin, Ferhan Ture&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.04885&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/castorini/daam&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CLIP-Diffusion-LM: Apply Diffusion Model on Image Captioning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shitong Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.04559&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/xu-shitong/diffusion-image-captioning&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TopoDiff: A Performance and Constraint-Guided Diffusion Model for Topology Optimization&lt;/strong&gt; &lt;br&gt; &lt;em&gt;François Mazé, Faez Ahmed&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.09591&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models Beat GANs on Topology Optimization&lt;/strong&gt; &lt;br&gt; &lt;em&gt;François Mazé, Faez Ahmed&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.09591&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://decode.mit.edu/projects/topodiff/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/francoismaze/topodiff&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Vector Quantized Diffusion Model with CodeUnet for Text-to-Sign Pose Sequences Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pan Xie, Qipeng Zhang, Zexian Li, Hao Tang, Yao Du, Xiaohui Hu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.09141&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deep Diffusion Models for Seismic Processing&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ricard Durall, Ammar Ghanim, Mario Fernandez, Norman Ettrich, Janis Keuper&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.10451&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tianpei Gu&lt;sup&gt;1&lt;/sup&gt;, Guangyi Chen&lt;sup&gt;1&lt;/sup&gt;, Junlong Li, Chunze Lin, Yongming Rao, Jie Zhou, Jiwen Lu&lt;/em&gt;&lt;br&gt; CVPR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.13777&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gutianpei/MID&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 25 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forré, Max Welling&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2102.05379&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Feb 2021&lt;/p&gt; &#xA;&lt;h2&gt;Audio&lt;/h2&gt; &#xA;&lt;h3&gt;Generation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generating symbolic music using diffusion models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lilac Atassi&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08385&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffuseRoll: Multi-track multi-category music generation based on diffusion model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hongfei Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.07794&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multi-Source Diffusion Models for Simultaneous Music Generation and Separation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giorgio Mariani&lt;sup&gt;1&lt;/sup&gt;, Irene Tallini&lt;sup&gt;1&lt;/sup&gt;, Emilian Postolache&lt;sup&gt;1&lt;/sup&gt;, Michele Mancusi&lt;sup&gt;1&lt;/sup&gt;, Luca Cosmo, Emanuele Rodolà&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02257&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://gladia-research-group.github.io/multi-source-diffusion-models/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 4 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ludan Ruan, Yiyang Ma, Huan Yang, Huiguo He, Bei Liu, Jianlong Fu, Nicholas Jing Yuan, Qin Jin, Baining Guo&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.09478&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/researchmm/MM-Diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SDMuse: Stochastic Differential Music Editing and Generation via Hybrid Representation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chen Zhang, Yi Ren, Kejun Zhang, Shuicheng Yan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.00222&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://sdmuse.github.io/posts/sdmuse/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 1 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Full-band General Audio Synthesis with Score-based Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Santiago Pascual, Gautam Bhattacharya, Chunghsin Yeh, Jordi Pons, Joan Serrà&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.14661&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Hierarchical Diffusion Models for Singing Voice Neural Vocoder&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Naoya Takahashi, Mayank Kumar, Singh, Yuki Mitsufuji&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.07508&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Mandarin Singing Voice Synthesis with Denoising Diffusion Probabilistic Wasserstein GAN&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yin-Ping Cho, Yu Tsao, Hsin-Min Wang, Yi-Wen Liu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.10446&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://yinping-cho.github.io/diffwgansvs.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 21 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DDSP-based Singing Vocoders: A New Subtractive-based Synthesizer and A Comprehensive Evaluation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Da-Yi Wu&lt;sup&gt;1&lt;/sup&gt;, Wen-Yi Hsiao&lt;sup&gt;1&lt;/sup&gt;, Fu-Rong Yang, Oscar Friedman, Warren Jackson, Scott Bruzenak, Yi-Wen Liu, Yi-Hsuan Yang&lt;/em&gt; &lt;br&gt; ISMIR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.04756&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/YatingMusic/ddsp-singing-vocoders/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 9 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ProDiff: Progressive Fast Diffusion Model For High-Quality Text-to-Speech&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rongjie Huang&lt;sup&gt;1&lt;/sup&gt;, Zhou Zhao, Huadai Liu&lt;sup&gt;1&lt;/sup&gt;, Jinglin Liu, Chenye Cui, Yi Ren&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.06389&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://prodiff.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 13 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CARD: Classification and Regression Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xizewen Han&lt;sup&gt;1&lt;/sup&gt;, Huangjie Zheng&lt;sup&gt;1&lt;/sup&gt;, Mingyuan Zhou&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.07275&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Adversarial Audio Synthesis with Complex-valued Polynomial Networks&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yongtao Wu, Grigorios G Chrysos, Volkan Cevher&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.06811&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multi-instrument Music Synthesis with Spectrogram Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Curtis Hawthorne, Ian Simon, Adam Roberts, Neil Zeghidour, Josh Gardner, Ethan Manilow, Jesse Engel&lt;/em&gt; &lt;br&gt; ISMIR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.05408&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yichong Leng, Zehua Chen, Junliang Guo, Haohe Liu, Jiawei Chen, Xu Tan, Danilo Mandic, Lei He, Xiang-Yang Li, Tao Qin, Sheng Zhao, Tie-Yan Liu&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.14807&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://speechresearch.github.io/binauralgrad/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 30 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rongjie Huang&lt;sup&gt;1&lt;/sup&gt;, Max W. Y. Lam&lt;sup&gt;1&lt;/sup&gt;, Jun Wang, Dan Su, Dong Yu, Yi Ren, Zhou Zhao&lt;/em&gt; &lt;br&gt; IJCAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.09934&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://fastdiff.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Rongjiehuang/FastDiff&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 21 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuma Koizumi, Heiga Zen, Kohei Yatabe, Nanxin Chen, Michiel Bacchiani&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.16749&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Max W. Y. Lam, Jun Wang, Dan Su, Dong Yu&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.13508&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/tencent-ailab/bddm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 25 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ItôWave: Itô Stochastic Differential Equation Is All You Need For Wave Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shoule Wu&lt;sup&gt;1&lt;/sup&gt;, Ziqiang Shi&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; CoRR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2201.12519&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://wushoule.github.io/ItoAudio/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 29 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Itô-Taylor Sampling Scheme for Denoising Diffusion Probabilistic Models using Ideal Derivatives&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hideyuki Tachibana, Mocho Go, Muneyoshi Inahara, Yotaro Katayama, Yotaro Watanabe&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2112.13339&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Gamma Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Eliya Nachmani&lt;sup&gt;1&lt;/sup&gt;, Robin San Roman&lt;sup&gt;1&lt;/sup&gt;, Lior Wolf&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2110.05948&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Oct 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Variational Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Diederik P. Kingma, Tim Salimans, Ben Poole, Jonathan Ho&lt;/em&gt; &lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2107.00630&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/revsic/jax-variational-diffwave&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Jul 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CRASH: Raw Audio Score-based Generative Modeling for Controllable High-resolution Drum Sound Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Simon Rouard&lt;sup&gt;1&lt;/sup&gt;, Gaëtan Hadjeres&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; ISMIR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.07431&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://crash-diffusion.github.io/crash/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 14 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Driven Adaptive Prior&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sang-gil Lee, Heeseung Kim, Chaehun Shin, Xu Tan, Chang Liu, Qi Meng, Tao Qin, Wei Chen, Sungroh Yoon, Tie-Yan Liu&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2106.06406&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://speechresearch.github.io/priorgrad/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 11 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ItôTTS and ItôWave: Linear Stochastic Differential Equation Is All You Need For Audio Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shoule Wu&lt;sup&gt;1&lt;/sup&gt;, Ziqiang Shi&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2105.07583&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://wushoule.github.io/ItoAudio/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 17 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jinglin Liu&lt;sup&gt;1&lt;/sup&gt;, Chengxi Li&lt;sup&gt;1&lt;/sup&gt;, Yi Ren&lt;sup&gt;1&lt;/sup&gt;, Feiyang Chen, Peng Liu, Zhou Zhao&lt;/em&gt; &lt;br&gt; AAAI 2022. [&lt;a href=&#34;https://arxiv.org/abs/2105.02446&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://diffsinger.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/keonlee9420/DiffSinger&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Symbolic Music Generation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gautam Mittal, Jesse Engel, Curtis Hawthorne, Ian Simon&lt;/em&gt; &lt;br&gt; ISMIR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2103.16091&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/magenta/symbolic-music-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 30 Mar 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffWave: A Versatile Diffusion Model for Audio Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, Bryan Catanzaro&lt;/em&gt; &lt;br&gt; ICLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2009.09761&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://diffwave-demo.github.io/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 21 Sep 2020&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;WaveGrad: Estimating Gradients for Waveform Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nanxin Chen, Yu Zhang, Heiga Zen, Ron J. Weiss, Mohammad Norouzi, William Chan&lt;/em&gt;&lt;br&gt; ICLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2009.00713&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://wavegrad.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ivanvovk/WaveGrad&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Sep 2020&lt;/p&gt; &#xA;&lt;h3&gt;Conversion&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Songxiang Liu&lt;sup&gt;1&lt;/sup&gt;, Yuewen Cao&lt;sup&gt;1&lt;/sup&gt;, Dan Su, Helen Meng&lt;/em&gt; &lt;br&gt; IEEE 2021. [&lt;a href=&#34;https://arxiv.org/abs/2105.13871&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/liusongxiang/diffsvc&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 28 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, Mikhail Kudinov, Jiansheng Wei&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2109.13821&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://diffvc-fast-ml-solver.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 28 Sep 2021&lt;/p&gt; &#xA;&lt;h3&gt;Enhancement&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speech Signal Improvement Using Causal Generative Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julius Richter, Simon Welker, Jean-Marie Lemercier, Bunlong Lay, Tal Peer, Timo Gerkmann&lt;/em&gt; &lt;br&gt; ICASSP 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.08674&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Reducing the Prior Mismatch of Stochastic Differential Equations for Diffusion-based Speech Enhancement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bunlong Lay, Simon Welker, Julius Richter, Timo Gerkmann&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.14748&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Metric-oriented Speech Enhancement using Diffusion Probabilistic Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chen Chen, Yuchen Hu, Weiwei Weng, Eng Siong Chng&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.11989&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;StoRM: A Diffusion-based Stochastic Regeneration Model for Speech Enhancement and Dereverberation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jean-Marie Lemercier, Julius Richter, Simon Welker, Timo Gerkmann&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.11851&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unsupervised vocal dereverberation with diffusion-based generative models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Koichi Saito, Naoki Murata, Toshimitsu Uesaka, Chieh-Hsin Lai, Yuhta Takida, Takao Fukui, Yuki Mitsufuji&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.04124&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffPhase: Generative Diffusion-based STFT Phase Retrieval&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tal Peer, Simon Welker, Timo Gerkmann&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.04332&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cold Diffusion for Speech Enhancement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hao Yen, François G. Germain, Gordon Wichern, Jonathan Le Roux&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.02527&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Analysing Diffusion-based Generative Approaches versus Discriminative Approaches for Speech Restoration&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jean-Marie Lemercier, Julius Richter, Simon Welker, Timo Gerkmann&lt;/em&gt; &lt;br&gt; ICASSP. [&lt;a href=&#34;https://arxiv.org/abs/2211.02397&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://www.inf.uni-hamburg.de/en/inst/ab/sp/publications/sgmse-multitask.html&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sp-uhh/sgmse&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 4 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SRTNet: Time Domain Speech Enhancement Via Stochastic Refinement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhibin Qiu, Mengfan Fu, Yinfeng Yu, LiLi Yin, Fuchun Sun, Hao Huang&lt;/em&gt; &lt;br&gt; ICASSP 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.16805&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zhibinQiu/SRTNet&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 30 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Versatile Diffusion-based Generative Refiner for Speech Enhancement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ryosuke Sawata, Naoki Murata, Yuhta Takida, Toshimitsu Uesaka, Takashi Shibuya, Shusuke Takahashi, Yuki Mitsufuji&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.17287&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conditioning and Sampling in Variational Diffusion Models for Speech Super-resolution&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chin-Yun Yu, Sung-Lin Yeh, György Fazekas, Hao Tang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.15793&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://yoyololicon.github.io/diffwave-sr/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yoyololicon/diffwave-sr&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Solving Audio Inverse Problems with a Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Eloi Moliner, Jaakko Lehtinen, Vesa Välimäki&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.15228&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speech Enhancement and Dereverberation with Diffusion-based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Julius Richter, Simon Welker, Jean-Marie Lemercier, Bunlong Lay, Timo Gerkmann&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.05830&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://www.inf.uni-hamburg.de/en/inst/ab/sp/publications/sgmse&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sp-uhh/sgmse&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 11 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Seungu Han, Junhyeok Lee&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.08545&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://mindslab-ai.github.io/nuwave2/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 17 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Universal Speech Enhancement with Score-based Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Joan Serrà, Santiago Pascual, Jordi Pons, R. Oguz Araz, Davide Scaini&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.03065&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speech Enhancement with Score-Based Generative Models in the Complex STFT Domain&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Simon Welker, Julius Richter, Timo Gerkmann&lt;/em&gt; &lt;br&gt; InterSpeech 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.17004&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sp-uhh/sgmse&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 31 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conditional Diffusion Probabilistic Model for Speech Enhancement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yen-Ju Lu, Zhong-Qiu Wang, Shinji Watanabe, Alexander Richard, Cheng Yu, Yu Tsao&lt;/em&gt; &lt;br&gt; IEEE 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.05256&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/neillu23/cdiffuse&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Study on Speech Enhancement Based on Diffusion Probabilistic Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yen-Ju Lu&lt;sup&gt;1&lt;/sup&gt;, Yu Tsao&lt;sup&gt;1&lt;/sup&gt;, Shinji Watanabe&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2107.11876&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Jul 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Restoring degraded speech via a modified diffusion model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jianwei Zhang, Suren Jayasuriya, Visar Berisha&lt;/em&gt; &lt;br&gt; Interspeech 2021. [&lt;a href=&#34;https://arxiv.org/abs/2104.11347&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Apr 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Junhyeok Lee, Seungu Han&lt;/em&gt; &lt;br&gt; Interspeech 2021. [&lt;a href=&#34;https://arxiv.org/abs/2104.02321&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://mindslab-ai.github.io/nuwave/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mindslab-ai/nuwave&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Apr 2021&lt;/p&gt; &#xA;&lt;h3&gt;Separation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multi-Source Diffusion Models for Simultaneous Music Generation and Separation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giorgio Mariani&lt;sup&gt;1&lt;/sup&gt;, Irene Tallini&lt;sup&gt;1&lt;/sup&gt;, Emilian Postolache&lt;sup&gt;1&lt;/sup&gt;, Michele Mancusi&lt;sup&gt;1&lt;/sup&gt;, Luca Cosmo, Emanuele Rodolà&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02257&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://gladia-research-group.github.io/multi-source-diffusion-models/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 4 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Separate And Diffuse: Using a Pretrained Diffusion Model for Improving Source Separation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shahar Lutati, Eliya Nachmani, Lior Wolf&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.10752&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;StoRM: A Diffusion-based Stochastic Regeneration Model for Speech Enhancement and Dereverberation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jean-Marie Lemercier, Julius Richter, Simon Welker, Timo Gerkmann&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.11851&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Generative Speech Source Separation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Robin Scheibler, Youna Ji, Soo-Whan Chung, Jaeuk Byun, Soyeon Choe, Min-Seok Choi&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.17327&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Instrument Separation of Symbolic Music by Explicitly Guided Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sangjun Han, Hyeongrae Ihm, DaeHan Ahn, Woohyung Lim&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.02696&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Sep 2022&lt;/p&gt; &#xA;&lt;h3&gt;Text-to-Speech&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;An investigation into the adaptability of a diffusion-based TTS model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haolin Chen, Philip N. Garner&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.01849&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Imaginary Voice: Face-styled Diffusion Model for Text-to-Speech&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiyoung Lee, Joon Son Chung, Soo-Whan Chung&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.13700&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ERNIE-Music: Text-to-Waveform Music Generation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pengfei Zhu, Chao Pang, Shuohuan Wang, Yekun Chai, Yu Sun, Hao Tian, Hua Wu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04456&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Noise2Music: Text-conditioned Music Generation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qingqing Huang&lt;sup&gt;1&lt;/sup&gt;, Daniel S. Park&lt;sup&gt;1&lt;/sup&gt;, Tao Wang, Timo I. Denk, Andy Ly, Nanxin Chen, Zhengdong Zhang, Zhishuai Zhang, Jiahui Yu, Christian Frank, Jesse Engel, Quoc V. Le, William Chan, Wei Han&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03917&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://google-research.github.io/noise2music/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 8 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Moûsai: Text-to-Music Generation with Long-Context Latent Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Flavio Schneider, Zhijing Jin, Bernhard Schölkopf&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11757&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://anonymous0.notion.site/anonymous0/Mo-sai-Text-to-Audio-with-Long-Context-Latent-Diffusion-b43dbc71caf94b5898f9e8de714ab5dc&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/archinetai/audio-diffusion-pytorch&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dongchao Yang&lt;sup&gt;1&lt;/sup&gt;, Songxiang Liu&lt;sup&gt;1&lt;/sup&gt;, Rongjie Huang, Guangzhi Lei, Chao Weng, Helen Meng, Dong Yu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13662&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;http://dongchaoyang.top/InstructTTS/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rongjie Huang&lt;sup&gt;1&lt;/sup&gt;, Jiawei Huang&lt;sup&gt;1&lt;/sup&gt;, Dongchao Yang&lt;sup&gt;1&lt;/sup&gt;, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, Zhou Zhao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12661&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://text-to-audio.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 30 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AudioLDM: Text-to-Audio Generation with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haohe Liu&lt;sup&gt;1&lt;/sup&gt;, Zehua Chen&lt;sup&gt;1&lt;/sup&gt;, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, Mark D. Plumbley&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12503&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://audioldm.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/haoheliu/AudioLDM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 29 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to Speech&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zehua Chen, Yihan Wu, Yichong Leng, Jiawei Chen, Haohe Liu, Xu Tan, Yang Cui, Ke Wang, Lei He, Sheng Zhao, Jiang Bian, Danilo Mandic&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.14518&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://resgrad1.github.io/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 30 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-to-speech synthesis based on latent variable conversion using diffusion probabilistic model and variational autoencoder&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yusuke Yasuda, Tomoki Toda&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.08329&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Any-speaker Adaptive Text-To-Speech Synthesis with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Minki Kang, Dongchan Min, Sung Ju Hwang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09383&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nardien.github.io/grad-stylespeech-demo/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 17 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;EmoDiff: Intensity Controllable Emotional Text-to-Speech with Soft-Label Guidance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yiwei Guo, Chenpeng Du, Xie Chen, Kai Yu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09496&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://cantabile-kwok.github.io/EmoDiff-intensity-ctrl/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 17 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NoreSpeech: Knowledge Distillation based Conditional Diffusion Model for Noise-robust Expressive TTS&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dongchao Yang, Songxiang Liu, Jianwei Yu, Helin Wang, Chao Weng, Yuexian Zou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.02448&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;WaveFit: An Iterative and Non-autoregressive Neural Vocoder based on Fixed-Point Iteration&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yuma Koizumi, Kohei Yatabe, Heiga Zen, Michiel Bacchiani&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.01029&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://google.github.io/df-conformer/wavefit/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 3 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffsound: Discrete Diffusion Model for Text-to-sound Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dongchao Yang, Jianwei Yu, Helin Wang, Wen Wang, Chao Weng, Yuexian Zou, Dong Yu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2207.09983&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;http://dongchaoyang.top/text-to-sound-synthesis-demo/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 20 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alon Levkovitch, Eliya Nachmani, Lior Wolf&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.02246&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://alonlevko.github.io/ilvr-tts-diff&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 5 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Guided-TTS 2: A Diffusion Model for High-quality Adaptive Text-to-Speech with Untranscribed Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sungwon Kim&lt;sup&gt;1&lt;/sup&gt;, Heeseung Kim&lt;sup&gt;1&lt;/sup&gt;, Sungroh Yoon&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.15370&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://ksw0306.github.io/guided-tts2-demo/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 30 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;InferGrad: Improving Diffusion Models for Vocoder by Considering Inference in Training&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zehua Chen, Xu Tan, Ke Wang, Shifeng Pan, Danilo Mandic, Lei He, Sheng Zhao&lt;/em&gt; &lt;br&gt; ICASSP 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.03751&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffGAN-TTS: High-Fidelity and Efficient Text-to-Speech with Denoising Diffusion GANs&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Songxiang Liu, Dan Su, Dong Yu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2201.11972&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/keonlee9420/DiffGAN-TTS&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 28 Jan 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Guided-TTS:Text-to-Speech with Untranscribed Speech&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Heeseung Kim, Sungwon Kim, Sungroh Yoon&lt;/em&gt; &lt;br&gt; ICML 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.11755&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;EdiTTS: Score-based Editing for Controllable Text-to-Speech&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jaesung Tae&lt;sup&gt;1&lt;/sup&gt;, Hyeongju Kim&lt;sup&gt;1&lt;/sup&gt;, Taesu Kim&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2110.02584&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://editts.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/neosapience/EdiTTS&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Oct 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nanxin Chen, Yu Zhang, Heiga Zen, Ron J. Weiss, Mohammad Norouzi, Najim Dehak, William Chan&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.09660&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://mindslab-ai.github.io/wavegrad2/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/keonlee9420/WaveGrad2&#34;&gt;Github&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mindslab-ai/wavegrad2&#34;&gt;Github2&lt;/a&gt;] &lt;br&gt; 17 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vadim Popov&lt;sup&gt;1&lt;/sup&gt;, Ivan Vovk&lt;sup&gt;1&lt;/sup&gt;, Vladimir Gogoryan, Tasnima Sadekova, Mikhail Kudinov&lt;/em&gt; &lt;br&gt; ICML 2021. [&lt;a href=&#34;https://arxiv.org/abs/2105.06337&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://grad-tts.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/huawei-noah/Speech-Backbones/tree/main/Grad-TTS&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jinglin Liu&lt;sup&gt;1&lt;/sup&gt;, Chengxi Li&lt;sup&gt;1&lt;/sup&gt;, Yi Ren&lt;sup&gt;1&lt;/sup&gt;, Feiyang Chen, Peng Liu, Zhou Zhao&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2105.02446&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://diffsinger.github.io/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/keonlee9420/DiffSinger&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 May 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diff-TTS: A Denoising Diffusion Model for Text-to-Speech&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Myeonghun Jeong, Hyeongju Kim, Sung Jun Cheon, Byoung Jin Choi, Nam Soo Kim&lt;/em&gt; &lt;br&gt; Interspeech 2021. [&lt;a href=&#34;https://arxiv.org/abs/2104.01409&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Apr 2021&lt;/p&gt; &#xA;&lt;h3&gt;Miscellaneous&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Data Augmentation for Environmental Sound Classification Using Diffusion Probabilistic Model with Top-k Selection Discriminator&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yunhao Chen, Yunjie Zhu, Zihui Yan, Jianlu Shen, Zhen Ren, Yifan Huang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.15161&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Enhancing Unsupervised Speech Recognition with Diffusion GANs&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xianchao Wu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13559&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Defending against Adversarial Audio via Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shutong Wu, Jiongxiao Wang, Wei Ping, Weili Nie, Chaowei Xiao&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.01507&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/cychomatica/AudioPure&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TransFusion: Transcribing Speech with Multinomial Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Matthew Baas, Kevin Eloff, Herman Kamper&lt;/em&gt; &lt;br&gt; SACAIR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.07677&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/RF5/transfusion-asr&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 14 Oct 2022&lt;/p&gt; &#xA;&lt;h2&gt;Natural Language&lt;/h2&gt; &#xA;&lt;h3&gt;Generation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;DINOISER: Diffused Conditional Sequence Learning by Manipulating Noises&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Mingxuan Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10025&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Reparameterized Discrete Diffusion Model for Text Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lin Zheng, Jianbo Yuan, Lei Yu, Lingpeng Kong&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.05737&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Long Horizon Temperature Scaling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Andy Shih, Dorsa Sadigh, Stefano Ermon&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03686&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusER: Diffusion via Edit-based Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Machel Reid, Vincent Josua Hellendoorn, Graham Neubig&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://openreview.net/forum?id=nG9RF9z1yy3&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GENIE: Large Scale Pre-training for Text Generation with Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhenghao Lin, Yeyun Gong, Yelong Shen, Tong Wu, Zhihao Fan, Chen Lin, Weizhu Chen, Nan Duan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.11685&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diff-Glat: Diffusion Glancing Transformer for Parallel Sequence to Sequence Learning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lihua Qian, Mingxuan Wang, Yang Liu, Hao Zhou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.10240&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Fei Huang, Songfang Huang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.10325&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Latent Diffusion for Language Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Justin Lovelace, Varsha Kishore, Chao Wan, Eliot Shekhtman, Kilian Weinberger&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.09462&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Difformer: Empowering Diffusion Model on Embedding Space for Text Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhujin Gao&lt;sup&gt;1&lt;/sup&gt;, Junliang Guo&lt;sup&gt;1&lt;/sup&gt;, Xu Tan, Yongxin Zhu, Fang Zhang, Jiang Bian, Linli Xu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.09412&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhengfu He&lt;sup&gt;1&lt;/sup&gt;, Tianxiang Sun&lt;sup&gt;1&lt;/sup&gt;, Kuanning Wang, Xuanjing Huang, Xipeng Qiu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.15029&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Hzfinfdu/Diffusion-BERT&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 28 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Continuous diffusion for categorical data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sander Dieleman, Laurent Sartran, Arman Roshannai, Nikolay Savinov, Yaroslav Ganin, Pierre H. Richemond, Arnaud Doucet, Robin Strudel, Chris Dyer, Conor Durkan, Curtis Hawthorne, Rémi Leblond, Will Grathwohl, Jonas Adler&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.15089&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Self-conditioned Embedding Diffusion for Text Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Robin Strudel, Corentin Tallec, Florent Altché, Yilun Du, Yaroslav Ganin, Arthur Mensch, Will Grathwohl, Nikolay Savinov, Sander Dieleman, Laurent Sifre, Rémi Leblond&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.04236&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusER: Discrete Diffusion via Edit-based Reconstruction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Machel Reid, Vincent J. Hellendoorn, Graham Neubig&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.16886&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.17432&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shansan Gong&lt;sup&gt;1&lt;/sup&gt;, Mukai Li&lt;sup&gt;1&lt;/sup&gt;, Jiangtao Feng, Zhiyong Wu, LingPeng Kong&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.08933&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Composable Text Controls in Latent Space with ODEs&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Guangyi Liu, Zeyu Feng, Yuan Gao, Zichao Yang, Xiaodan Liang, Junwei Bao, Xiaodong He, Shuguang Cui, Zhen Li, Zhiting Hu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.00638&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/guangyliu/LatentOps&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Structured Denoising Diffusion Models in Discrete State-Spaces&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jacob Austin&lt;sup&gt;1&lt;/sup&gt;, Daniel D. Johnson&lt;sup&gt;1&lt;/sup&gt;, Jonathan Ho, Daniel Tarlow, Rianne van den Berg&lt;/em&gt; &lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2107.03006&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jul 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Latent Diffusion Energy-Based Model for Interpretable Text Modeling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Peiyu Yu, Sirui Xie, Xiaojian Ma, Baoxiong Jia, Bo Pang, Ruigi Gao, Yixin Zhu, Song-Chun Zhu, Ying Nian Wu&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.05895&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yuPeiyu98/LDEBM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-LM Improves Controllable Text Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, Tatsunori B. Hashimoto&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.14217&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/XiangLi1999/Diffusion-LM&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 27 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step-unrolled Denoising Autoencoders for Text Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nikolay Savinov, Junyoung Chung, Mikolaj Binkowski, Erich Elsen, Aaron van den Oord&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2112.06749&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/vvvm23/sundae&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Dec 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Zero-Shot Translation using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Eliya Nachmani&lt;sup&gt;1&lt;/sup&gt;, Shaked Dovrat&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.01471&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Nov 2021&lt;/p&gt; &#xA;&lt;h2&gt;Tabular and Time Series&lt;/h2&gt; &#xA;&lt;h3&gt;Generation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Synthetic Health-related Longitudinal Data with Mixed-type Variables Generated using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nicholas I-Hsien Kuo, Louisa Jorm, Sebastiano Barbieri&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12281&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusing Gaussian Mixtures for Generating Categorical Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Florence Regol, Mark Coates&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.04635&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;EHRDiff: Exploring Realistic EHR Synthesis with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hongyi Yuan&lt;sup&gt;1&lt;/sup&gt;, Songchi Zhou&lt;sup&gt;1&lt;/sup&gt;, Sheng Yu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05656&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/sczzz3/ehrdiff&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Synthesizing Mixed-type Electronic Health Records using Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Taha Ceritli, Ghadeer O. Ghosheh, Vinod Kumar Chauhan, Tingting Zhu, Andrew P. Creagh, David A. Clifton&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.14679&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MedDiff: Generating Electronic Health Records using Accelerated Denoising Diffusion Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Huan He, Shifan Zhao, Yuanzhe Xi, Joyce C Ho&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04355&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Conditional ECG Generation with Structured State Space Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Juan Miguel Lopez Alcaraz, Nils Strodthoff&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.08227&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TabDDPM: Modelling Tabular Data with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, Artem Babenko&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.15421&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/rotot0/tab-ddpm&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 30 Sep 2022&lt;/p&gt; &#xA;&lt;h3&gt;Forecasting&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;TDSTF: Transformer-based Diffusion probabilistic model for Sparse Time series Forecasting&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ping Chang, Huayu Li, Stuart F. Quan, Janet Roveda, Ao Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.06625&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/PingChang818/TDSTF&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative Time Series Forecasting with Diffusion, Denoise, and Disentanglement&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yan Li, Xinjiang Lu, Yaqing Wang, Dejing Dou&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2301.03028&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpatial/tree/main/research/D3VAE&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising diffusion probabilistic models for probabilistic energy forecasting&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Esteban Hernandez, Jonathan Dumas&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.02977&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Modeling Temporal Data as Continuous Functions with Process Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Marin Biloš, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, Stephan Günnemann&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.02590&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Time Series Imputation and Forecasting with Structured State Space Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Juan Miguel Lopez Alcaraz, Nils Strodthoff&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.09399&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/AI4HealthUOL/SSSD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CARD: Classification and Regression Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xizewen Han&lt;sup&gt;1&lt;/sup&gt;, Huangjie Zheng&lt;sup&gt;1&lt;/sup&gt;, Mingyuan Zhou&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.07275&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ScoreGrad: Multivariate Probabilistic Time Series Forecasting with Continuous Energy-based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tijin Yan, Hongwei Zhang, Tong Zhou, Yufeng Zhan, Yuanqing Xia&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2106.10121&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/yantijin/ScoreGradPred&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 18 Jun 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Autoregressive Denoising Diffusion Models for Multivariate Probabilistic Time Series Forecasting&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kashif Rasul, Calvin Seward, Ingmar Schuster, Roland Vollgraf&lt;/em&gt; &lt;br&gt; ICLR 2021. [&lt;a href=&#34;https://arxiv.org/abs/2101.12072&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zalandoresearch/pytorch-ts&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Feb 2021&lt;/p&gt; &#xA;&lt;h3&gt;Imputation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;PriSTI: A Conditional Diffusion Framework for Spatiotemporal Imputation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Mingzhe Liu, Han Huang, Hao Feng, Leilei Sun, Bowen Du, Yanjie Fu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.09746&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LMZZML/PriSTI&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Modeling Temporal Data as Continuous Functions with Process Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Marin Biloš, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, Stephan Günnemann&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.02590&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion models for missing value imputation in tabular data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shuhan Zheng, Nontawat Charoenphakdee&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.17128&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Neural Markov Controlled SDE: Stochastic Optimization for Continuous-Time Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sung Woo Park, Kyungjae Lee, Junseok Kwon&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://openreview.net/forum?id=7DI6op61AY&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Time Series Imputation and Forecasting with Structured State Space Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Juan Miguel Lopez Alcaraz, Nils Strodthoff&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.09399&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/AI4HealthUOL/SSSD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 19 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;CSDI: Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yusuke Tashiro, Jiaming Song, Yang Song, Stefano Ermon&lt;/em&gt; &lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2107.03502&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ermongroup/csdi&#34;&gt;Github&lt;/a&gt;]&lt;br&gt; 7 Jul 2021&lt;/p&gt; &#xA;&lt;h3&gt;Miscellaneous&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;EEG Synthetic Data Generation Using Probabilistic Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giulio Tosato, Cesare M. Dalbagno, Francesco Fumagalli&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.06068&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DeScoD-ECG: Deep Score-Based Diffusion Model for ECG Baseline Wander and Noise Removal&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Huayu Li, Gregory Ditzler, Janet Roveda, Ao Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.00542&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jul 2022&lt;/p&gt; &#xA;&lt;h2&gt;Graph&lt;/h2&gt; &#xA;&lt;h3&gt;Generation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Probabilistic Models for Graph-Structured Prediction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hyosoon Jang, Sangwoo Mo, Sungsoo Ahn&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10506&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GraphGUIDE: interpretable and controllable conditional graph generation with discrete Bernoulli diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alex M. Tseng, Nathaniel Diamant, Tommaso Biancalani, Gabriele Scalia&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03790&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Graph Generation with Destination-Driven Diffusion Mixture&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jaehyeong Jo&lt;sup&gt;1&lt;/sup&gt;, Dongki Kim&lt;sup&gt;1&lt;/sup&gt;, Sung Ju Hwang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03596&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffSTG: Probabilistic Spatio-Temporal Graph Forecasting with Denoising Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haomin Wen, Youfang Lin, Yutong Xia, Huaiyu Wan, Roger Zimmermann, Yuxuan Liang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13629&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Qitian Wu, Chenxiao Yang, Wentao Zhao, Yixuan He, David Wipf, Junchi Yan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.09474&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GraphGDP: Generative Diffusion Processes for Permutation Invariant Graph Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Han Huang, Leilei Sun, Bowen Du, Yanjie Fu, Weifeng Lv&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.01842&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NVDiff: Graph Generation through the Diffusion of Node Vectors&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Cristian Sbrolli, Paolo Cudrano, Matteo Frosi, Matteo Matteucci&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.10794&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fast Graph Generative Model via Spectral Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tianze Luo, Zhanfeng Mo, Sinno Jialin Pan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.08892&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Graphs Benefit From Discrete State Spaces&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kilian Konstantin Haefeli, Karolis Martinkus, Nathanaël Perraudin, Roger Wattenhofer&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.01549&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 4 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiGress: Discrete Denoising diffusion for graph generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Clement Vignac&lt;sup&gt;1&lt;/sup&gt;, Igor Krawczuk&lt;sup&gt;1&lt;/sup&gt;, Antoine Siraudin, Bohan Wang, Volkan Cevher, Pascal Frossard&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14734&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Permutation Invariant Graph Generation via Score-Based Generative Modeling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chenhao Niu, Yang Song, Jiaming Song, Shengjia Zhao, Aditya Grover, Stefano Ermon&lt;/em&gt; &lt;br&gt; AISTATS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2003.00638&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ermongroup/GraphScoreMatching&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 2 Mar 2020&lt;/p&gt; &#xA;&lt;h3&gt;Molecular and Material Generation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;3D Equivariant Diffusion for Target-Aware Molecule Generation and Affinity Prediction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jiaqi Guan, Wesley Wei Qian, Xingang Peng, Yufeng Su, Jian Peng, Jianzhu Ma&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.03543&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising diffusion algorithm for inverse design of microstructures with fine-tuned nonlinear material properties&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Nikolaos N. Vlassis, WaiChing Sun&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.12881&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Aligned Diffusion Schrödinger Bridges&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vignesh Ram Somnath&lt;sup&gt;1&lt;/sup&gt;, Matteo Pariset&lt;sup&gt;1&lt;/sup&gt;, Ya-Ping Hsieh, Maria Rodriguez Martinez, Andreas Krause, Charlotte Bunne&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.11419&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MiDi: Mixed Graph and 3D Denoising Diffusion for Molecule Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Clement Vignac, Nagham Osman, Laura Toni, Pascal Frossard&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.09048&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Geometry-Complete Diffusion for 3D Molecule Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alex Morehead, Jianlin Cheng&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.04313&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/BioinfoMachineLearning/bio-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 8 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SE(3) diffusion model with application to protein backbone generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jason Yim&lt;sup&gt;1&lt;/sup&gt;, Brian L. Trippe&lt;sup&gt;1&lt;/sup&gt;, Valentin De Bortoli&lt;sup&gt;1&lt;/sup&gt;, Emile Mathieu&lt;sup&gt;1&lt;/sup&gt;, Arnaud Doucet, Regina Barzilay, Tommi Jaakkola&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.02277&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Data-Efficient Protein 3D Geometric Pretraining via Refinement of Diffused Protein Structure Decoy&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yufei Huang, Lirong Wu, Haitao Lin, Jiangbin Zheng, Ge Wang, Stan Z. Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10888&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 5 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Two for One: Diffusion Models and Force Fields for Coarse-Grained Molecular Dynamics&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Marloes Arts, Victor Garcia Satorras, Chin-Wei Huang, Daniel Zuegner, Marco Federici, Cecilia Clementi, Frank Noé, Robert Pinsler, Rianne van den Berg&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.00600&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generating Novel, Designable, and Diverse Protein Structures by Equivariantly Diffusing Oriented Residue Clouds&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yeqing Lin, Mohammed AlQuraishi&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12485&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Physics-Inspired Protein Encoder Pre-Training via Siamese Sequence-Structure Diffusion Trajectory Prediction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zuobai Zhang&lt;sup&gt;1&lt;/sup&gt;, Minghao Xu&lt;sup&gt;1&lt;/sup&gt;, Aurélie Lozano, Vijil Chenthamarakshan, Payel Das, Jian Tang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.12068&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffSDS: A language diffusion model for protein backbone inpainting under geometric conditions and constraints&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhangyang Gao, Cheng Tan, Stan Z. Li&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.09642&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffBP: Generative Diffusion of 3D Molecules for Target Protein Binding&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Haitao Lin&lt;sup&gt;1&lt;/sup&gt;, Yufei Huang&lt;sup&gt;1&lt;/sup&gt;, Meng Liu, Xuanjing Li, Shuiwang Ji, Stan Z. Li&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.11214&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ParticleGrid: Enabling Deep Learning using 3D Representation of Materials&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shehtab Zaman, Ethan Ferguson, Cecile Pereira, Denis Akhiyarov, Mauricio Araya-Polo, Kenneth Chiu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.08506&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 15 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Structure-based Drug Design with Equivariant Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Arne Schneuing&lt;sup&gt;1&lt;/sup&gt;, Yuanqi Du&lt;sup&gt;1&lt;/sup&gt;, Charles Harris, Arian Jamasb, Ilia Igashov, Weitao Du, Tom Blundell, Pietro Lió, Carla Gomes, Max Welling, Michael Bronstein, Bruno Correia&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.13695&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Protein Sequence and Structure Co-Design with Equivariant Translation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chence Shi, Chuanrui Wang, Jiarui Lu, Bozitao Zhong, Jian Tang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.08761&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Equivariant 3D-Conditional Diffusion Models for Molecular Linker Design&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ilia Igashov, Hannes Stärk, Clément Vignac, Victor Garcia Satorras, Pascal Frossard, Max Welling, Michael Bronstein, Bruno Correia&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.05274&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dynamic-Backbone Protein-Ligand Structure Prediction with Multiscale Generative Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhuoran Qiao, Weili Nie, Arash Vahdat, Thomas F. Miller III, Anima Anandkumar&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.15171&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Equivariant Energy-Guided SDE for Inverse Molecular Design&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Fan Bao&lt;sup&gt;1&lt;/sup&gt;, Min Zhao&lt;sup&gt;1&lt;/sup&gt;, Zhongkai Hao, Peiyao Li, Chongxuan Li, Jun Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.15408&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Protein structure generation via folding diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kevin E. Wu, Kevin K. Yang, Rianne van den Berg, James Y. Zou, Alex X. Lu, Ava P. Amini&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.15611&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;MDM: Molecular Diffusion Model for 3D Molecule Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lei Huang, Hengtong Zhang, Tingyang Xu, Ka-Chun Wong&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.05710&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 13 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion-based Molecule Generation with Informative Prior Bridges&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lemeng Wu&lt;sup&gt;1&lt;/sup&gt;, Chengyue Gong&lt;sup&gt;1&lt;/sup&gt;, Xingchao Liu, Mao Ye, Qiang Liu&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.00865&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Antigen-Specific Antibody Design and Optimization with Diffusion-Based Generative Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shitong Luo&lt;sup&gt;1&lt;/sup&gt;, Yufeng Su&lt;sup&gt;1&lt;/sup&gt;, Xingang Peng, Sheng Wang, Jian Peng, Jianzhu Ma&lt;/em&gt; &lt;br&gt; BioRXiv 2022. [&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2022.07.10.499510v1&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 11 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Data-driven discovery of novel 2D materials by deep generative models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Peder Lyngby, Kristian Sommer Thygesen&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.12159&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-based Generative Models for Calorimeter Shower Simulation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vinicius Mikuni, Benjamin Nachman&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.11898&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion probabilistic modeling of protein backbones in 3D for the motif-scaffolding problem&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Brian L. Trippe&lt;sup&gt;1&lt;/sup&gt;, Jason Yim&lt;sup&gt;1&lt;/sup&gt;, Doug Tischer, Tamara Broderick, David Baker, Regina Barzilay, Tommi Jaakkola&lt;/em&gt; &lt;br&gt; CoRR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.04119&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Torsional Diffusion for Molecular Conformer Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bowen Jing, Gabriele Corso, Regina Barzilay, Tommi S. Jaakkola&lt;/em&gt; &lt;br&gt; ICLR Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.01729&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gcorso/torsional-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Protein Structure and Sequence Generation with Equivariant Denoising Diffusion Probabilistic Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Namrata Anand, Tudor Achim&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.15019&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://nanand2.github.io/proteins/&#34;&gt;Project&lt;/a&gt;] [&lt;a href=&#34;https://github.com/lucidrains/ddpm-ipa-protein-generation&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 26 May 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Score-based Geometric Model for Molecular Dynamics Simulations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Fang Wu&lt;sup&gt;1&lt;/sup&gt;, Qiang Zhang&lt;sup&gt;1&lt;/sup&gt;, Xurui Jin, Yinghui Jiang, Stan Z. Li&lt;/em&gt; &lt;br&gt; CoRR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2204.08672&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Apr 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Equivariant Diffusion for Molecule Generation in 3D&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Emiel Hoogeboom&lt;sup&gt;1&lt;/sup&gt;, Victor Garcia Satorras&lt;sup&gt;1&lt;/sup&gt;, Clément Vignac, Max Welling&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.17003&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/ehoogeboom/e3_diffusion_for_molecules&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 31 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GeoDiff: a Geometric Diffusion Model for Molecular Conformation Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon, Jian Tang&lt;/em&gt; &lt;br&gt; ICLR 2022. [&lt;a href=&#34;https://arxiv.org/abs/2203.02923&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/MinkaiXu/GeoDiff&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 6 Mar 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Crystal Diffusion Variational Autoencoder for Periodic Material Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tian Xie&lt;sup&gt;1&lt;/sup&gt;, Xiang Fu&lt;sup&gt;1&lt;/sup&gt;, Octavian-Eugen Ganea&lt;sup&gt;1&lt;/sup&gt;, Regina Barzilay, Tommi Jaakkola&lt;/em&gt;&lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://arxiv.org/abs/2110.06197&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/txie-93/cdvae&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 12 Oct 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Predicting Molecular Conformation via Dynamic Graph Score Matching&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Shitong Luo, Chence Shi, Minkai Xu, Jian Tang&lt;/em&gt; &lt;br&gt; NeurIPS 2021. [&lt;a href=&#34;https://proceedings.neurips.cc/paper/2021/hash/a45a1d12ee0fb7f1f872ab91da18f899-Abstract.html&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 May 2021&lt;/p&gt; &#xA;&lt;h2&gt;Reinforcement Learning&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;EDGI: Equivariant Diffusion for Planning with Embodied Agents&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Johann Brehmer, Joey Bose, Pim de Haan, Taco Cohen&lt;/em&gt; &lt;br&gt; ICLR Workshop 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12410&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Multi-Agent Adversarial Training Using Diffusion Learning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ying Cao, Elsa Rizk, Stefan Vlaski, Ali H. Sayed&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.01936&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Model-Augmented Behavioral Cloning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hsiang-Chun Wang, Shang-Fu Chen, Shao-Hua Sun&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.13335&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;To the Noise and Back: Diffusion for Shared Autonomy&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Takuma Yoneda, Luzhe Sun, Bradly Stadie, Ge Yang, Matthew Walter&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.12244&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://diffusion-for-shared-autonomy.github.io/&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 23 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AdaptDiffuser: Diffusion Models as Adaptive Self-evolving Planners&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhixuan Liang, Yao Mu, Mingyu Ding, Fei Ni, Masayoshi Tomizuka, Ping Luo&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.01877&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Imitating Human Behaviour with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tim Pearce, Tabish Rashid, Anssi Kanervisto, Dave Bignell, Mingfei Sun, Raluca Georgescu, Sergio Valcarcel Macua, Shan Zheng Tan, Ida Momennejad, Katja Hofmann, Sam Devlin&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.10677&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Is Conditional Generative Modeling all you need for Decision-Making?&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Anurag Ajay&lt;sup&gt;1&lt;/sup&gt;, Yilun Du&lt;sup&gt;1&lt;/sup&gt;, Abhi Gupta&lt;sup&gt;1&lt;/sup&gt;, Joshua Tenenbaum, Tommi Jaakkola, Pulkit Agrawal&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.15657&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 28 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;LAD: Language Augmented Diffusion for Reinforcement Learning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Edwin Zhang, Yujie Lu, William Wang, Amy Zhang&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.15629&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Zhendong Wang, Jonathan J Hunt, Mingyuan Zhou&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.06193&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/zhendong-wang/diffusion-policies-for-offline-rl&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 12 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Offline Reinforcement Learning via High-Fidelity Generative Behavior Modeling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Huayu Chen, Cheng Lu, Chengyang Ying, Hang Su, Jun Zhu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14548&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Planning with Diffusion for Flexible Behavior Synthesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Michael Janner, Yilun Du, Joshua B. Tenenbaum, Sergey Levine&lt;/em&gt; &lt;br&gt; ICML 2022. [&lt;a href=&#34;https://arxiv.org/abs/2205.09991&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jannerm/diffuser&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 May 2022&lt;/p&gt; &#xA;&lt;h2&gt;Theory&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Restoration-Degradation Beyond Linear Diffusions: A Non-Asymptotic Analysis For DDIM-Type Samplers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sitan Chen, Giannis Daras, Alexandros G. Dimakis&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.03384&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models are Minimax Optimal Distribution Estimators&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Kazusato Oko, Shunta Akiyama, Taiji Suzuki&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.01861&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Understanding the Diffusion Objective as a Weighted Integral of ELBOs&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Diederik P. Kingma, Ruiqi Gao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.00848&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Continuous-Time Functional Diffusion Processes&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Giulio Franzese, Simone Rossi, Dario Rossi, Markus Heinonen, Maurizio Filippone, Pietro Michiardi&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.00800&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Samplers&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Francisco Vargas, Will Grathwohl, Arnaud Doucet&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.13834&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 27 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Infinite-Dimensional Diffusion Models for Function Spaces&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jakiw Pidstrigach, Youssef Marzouk, Sebastian Reich, Sven Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.10130&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-based Diffusion Models in Function Space&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Jae Hyun Lim&lt;sup&gt;1&lt;/sup&gt;, Nikola B. Kovachki&lt;sup&gt;1&lt;/sup&gt;, Ricardo Baptista&lt;sup&gt;1&lt;/sup&gt;, Christopher Beckham, Kamyar Azizzadenesheli, Jean Kossaifi, Vikram Voleti, Jiaming Song, Karsten Kreis, Jan Kautz, Christopher Pal, Arash Vahdat, Anima Anandkumar&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07400&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score Approximation, Estimation and Distribution Recovery of Diffusion Models on Low-Dimensional Data&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Minshuo Chen&lt;sup&gt;1&lt;/sup&gt;, Kaixuan Huang&lt;sup&gt;1&lt;/sup&gt;, Tuo Zhao, Mengdi Wang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07194&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stochastic Modified Flows, Mean-Field Limits and Dynamics of Stochastic Gradient Descent&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Benjamin Gess&lt;sup&gt;1&lt;/sup&gt;, Sebastian Kassing&lt;sup&gt;1&lt;/sup&gt;, Vitalii Konarovskyi&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.07125&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 14 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Monte Carlo Neural Operator for Learning PDEs via Probabilistic Representation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Rui Zhang, Qi Meng, Rongchan Zhu, Yue Wang, Wenlei Shi, Shihua Zhang, Zhi-Ming Ma, Tie-Yan Liu&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.05104&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example-Based Sampling with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bastien Doignies, Nicolas Bonneel, David Coeurjolly, Julie Digne, Loïs Paulin, Jean-Claude Iehl, Victor Ostromoukhov&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.05116&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Information-Theoretic Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Xianghao Kong, Rob Brekelmans, Greg Ver Steeg&lt;/em&gt; &lt;br&gt; ICLR 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.03792&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gregversteeg/InfoDiffusionSimple&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 7 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Conditional Flow Matching: Simulation-Free Dynamic Optimal Transport&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alexander Tong, Nikolay Malkin, Guillaume Huguet, Yanlei Zhang, Jarrid Rector-Brooks, Kilian Fatras, Guy Wolf, Yoshua Bengio&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.00482&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/atong01/conditional-flow-matching&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Transport with Support: Data-Conditional Diffusion Bridges&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Ella Tamir, Martin Trapp, Arno Solin&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.13636&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 31 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Understanding and contextualising diffusion models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Stefano Scotta, Alberto Messina&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.01394&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On the Mathematics of Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;David McAllester&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.11108&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 25 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Understanding the diffusion models by conditional expectations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yubin Lu, Zhongjian Wang, Guillaume Bal&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.07882&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Thompson Sampling with Diffusion Generative Prior&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yu-Guan Hsieh, Shiva Prasad Kasiviswanathan, Branislav Kveton, Patrick Blöbaum&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2301.05182&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 12 Jan 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Your diffusion model secretly knows the dimension of the data manifold&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Georgios Batzolis&lt;sup&gt;1&lt;/sup&gt;, Jan Stanczuk&lt;sup&gt;1&lt;/sup&gt;, Carola-Bibiane Schönlieb&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.12611&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 23 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Score-based Generative Modeling Secretly Minimizes the Wasserstein Distance&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Dohyun Kwon, Ying Fan, Kangwook Lee&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.06359&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/UW-Madison-Lee-Lab/score-wasserstein&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Nonlinear controllability and function representation by neural stochastic differential equations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Tanya Veeravalli, Maxim Raginsky&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00896&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Generative Models in Infinite Dimensions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Gavin Kerrigan, Justin Ley, Padhraic Smyth&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00886&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Dec 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Neural Langevin Dynamics: towards interpretable Neural Stochastic Differential Equations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Simon M. Koop, Mark A. Peletier, Jacobus W. Portegies, Vlado Menkovski&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.09537&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 17 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Improved Analysis of Score-based Generative Modeling: User-Friendly Bounds under Minimal Smoothness Assumptions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hongrui Chen, Holden Lee, Jianfeng Lu&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.01916&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 3 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Categorical SDEs with Simplex Diffusion&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pierre H. Richemond, Sander Dieleman, Arnaud Doucet&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.14784&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion Models for Causal Discovery via Topological Ordering&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pedro Sanchez, Xiao Liu, Alison Q O&#39;Neil, Sotirios A. Tsaftaris&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.06201&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/vios-s/DiffAN&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 12 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Regularizing Score-based Models with Score Fokker-Planck Equations&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chieh-Hsin Lai, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji, Stefano Ermon&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.04296&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Sequential Neural Score Estimation: Likelihood-Free Inference with Conditional Score Based Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Louis Sharrock, Jack Simons, Song Liu, Mark Beaumont&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.04872&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Analyzing Diffusion as Serial Reproduction&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Raja Marjieh, Ilia Sucholutsky, Thomas A. Langlois, Nori Jacoby, Thomas L. Griffiths&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.14821&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 29 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Convergence of score-based generative modeling for general data distributions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Holden Lee, Jianfeng Lu, Yixin Tan&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.12381&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 26 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, Anru R. Zhang&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.11215&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 22 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Riemannian Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Chin-Wei Huang, Milad Aghajohari, Avishek Joey Bose, Prakash Panangaden, Aaron Courville&lt;/em&gt; &lt;br&gt; NeurIPS 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.07949&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Convergence of denoising diffusion models under the manifold hypothesis&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Valentin De Bortoli&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2208.05314&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 10 Aug 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Neural Diffusion Processes&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Vincent Dutordoir, Alan Saul, Zoubin Ghahramani, Fergus Simpson&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.03992&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 8 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Theory and Algorithms for Diffusion Processes on Riemannian Manifolds&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Bowen Jing, Gabriele Corso, Jeffrey Chang, Regina Barzilay, Tommi Jaakkola&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2206.01729&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gcorso/torsional-diffusion&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 1 Jun 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Riemannian Score-Based Generative Modeling&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Valentin De Bortoli&lt;sup&gt;1&lt;/sup&gt;, Emile Mathieu&lt;sup&gt;1&lt;/sup&gt;, Michael Hutchinson, James Thornton, Yee Whye Teh, Arnaud Doucet&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2202.02763&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 6 Feb 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Interpreting diffusion score matching using normalizing flow&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Wenbo Gong&lt;sup&gt;1&lt;/sup&gt;, Yingzhen Li&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; ICML Workshop 2021. [&lt;a href=&#34;https://arxiv.org/abs/2107.10072&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 21 Jul 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Connection Between Score Matching and Denoising Autoencoders&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Pascal Vincent&lt;/em&gt; &lt;br&gt; Neural Computation 2011. [&lt;a href=&#34;http://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 7 Jul 2011&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bayesian Learning via Stochastic Gradient Langevin Dynamics&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Max Welling, Yee Whye Teh&lt;/em&gt; &lt;br&gt; ICML 2011. [&lt;a href=&#34;https://www.stats.ox.ac.uk/~teh/research/compstats/WelTeh2011a.pdf&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/JavierAntoran/Bayesian-Neural-Networks#stochastic-gradient-langevin-dynamics-sgld&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 20 Apr 2011&lt;/p&gt; &#xA;&lt;h2&gt;Applications&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;AI-Generated 6G Internet Design: A Diffusion Model-based Learning Approach&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yudong Huang, Minrui Xu, Xinyuan Zhang, Dusit Niyato, Zehui Xiong, Shuo Wang, Tao Huang&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13869&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 24 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generative AI-aided Optimization for AI-Generated Content (AIGC) Services in Edge Networks&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hongyang Du, Zonghang Li, Dusit Niyato, Jiawen Kang, Zehui Xiong, Huawei Huang, Shiwen Mao&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.13052&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Lizonghang/AGOD&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 23 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stable Bias: Analyzing Societal Representations in Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alexandra Sasha Luccioni, Christopher Akiki, Margaret Mitchell, Yacine Jernite&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.11408&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PC-JeDi: Diffusion for Particle Cloud Generation in High Energy Physics&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Matthew Leigh, Debajyoti Sengupta, Guillaume Quétant, John Andrew Raine, Knut Zoch, Tobias Golling&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.05376&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 9 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generating Initial Conditions for Ensemble Data Assimilation of Large-Eddy Simulations with Latent Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Alex Rybchuk, Malik Hassanaly, Nicholas Hamilton, Paula Doubrawa, Mitchell J. Fulton, Luis A. Martínez-Tossas&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.00836&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 1 Mar 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ReorientDiff: Diffusion Model based Reorientation for Object Manipulation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Utkarsh A. Mishra, Yongxin Chen&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2303.12700&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;http://umishra.me/ReorientDiff/&#34;&gt;Project&lt;/a&gt;] &lt;br&gt; 28 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Interventional and Counterfactual Inference with Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Patrick Chao, Patrick Blöbaum, Shiva Prasad Kasiviswanathan&lt;/em&gt; &lt;br&gt; arXiv 2023. [&lt;a href=&#34;https://arxiv.org/abs/2302.00860&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 2 Feb 2023&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion for Sampling SAT Solutions&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Karlis Freivalds, Sergejs Kozlovics&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2212.00121&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 30 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generating astronomical spectra from photometry with conditional diffusion models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Lars Doorenbos, Stefano Cavuoti, Giuseppe Longo, Massimo Brescia, Raphael Sznitman, Pablo Márquez-Neila&lt;/em&gt; &lt;br&gt; NeurIPS Workshop 2022. [&lt;a href=&#34;https://arxiv.org/abs/2211.05556&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LarsDoorenbos/generate-spectra&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 10 Nov 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Graphically Structured Diffusion Models&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Christian Weilbach, William Harvey, Frank Wood&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2210.11633&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 20 Oct 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Denoising Diffusion Error Correction Codes&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Yoni Choukroun, Lior Wolf&lt;/em&gt; &lt;br&gt; arXiv 2022. [&lt;a href=&#34;https://arxiv.org/abs/2209.13533&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 16 Sep 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Recommendation via Collaborative Diffusion Generative Model&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Joojo Walker, Ting Zhong, Fengli Zhang, Qiang Gao, Fan Zhou&lt;/em&gt; &lt;br&gt; KSEM 2022. [&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-031-10989-8_47&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt; 19 Jul 2022&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Deep Diffusion Models for Robust Channel Estimation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Marius Arvinte, Jonathan I Tamir&lt;/em&gt; &lt;br&gt; arXiv 2021. [&lt;a href=&#34;https://arxiv.org/abs/2111.08177&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/utcsilab/diffusion-channels&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 16 Nov 2021&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Diffusion models for Handwriting Generation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Troy Luhman&lt;sup&gt;1&lt;/sup&gt;, Eric Luhman&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;br&gt; arXiv 2020. [&lt;a href=&#34;https://arxiv.org/abs/2011.06704&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/tcl9876/Diffusion-Handwriting-Generation&#34;&gt;Github&lt;/a&gt;] &lt;br&gt; 13 Nov 2020&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>shadowgmes/shadowgmes.github.io</title>
    <updated>2023-04-01T01:35:37Z</updated>
    <id>tag:github.com,2023-04-01:/shadowgmes/shadowgmes.github.io</id>
    <link href="https://github.com/shadowgmes/shadowgmes.github.io" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The best place to procrastinate. This is the game site that strives to be better than best. We don&#39;t focus on the little things, we go BIG.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Shadow&#39;s Games&lt;/h1&gt; &#xA;&lt;p&gt;This project has a license so don&#39;t even try to copy it. You can fork it and give credit, but no claiming it&#39;s yours. Self hosting and hosting providers are fine &lt;em&gt;&lt;strong&gt;WITH CREDIT AND LICENSE&lt;/strong&gt;&lt;/em&gt;. Also all games here are not mine so you can have them.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/ZdHBCFXdT3&#34;&gt;&lt;img src=&#34;https://invidget.switchblade.xyz/ZdHBCFXdT3?theme=dark&#34; alt=&#34;Join the Discord!&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Donate to the dev, SipSup3314, using the button below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/sipsup3314&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png&#34; alt=&#34;Buy Me A Coffee&#34; style=&#34;height: 40px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Stats&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/repo-size/shadowgmes/shadowgmes.github.io?label=Total%20size&#34; alt=&#34;GitHub repo size&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://repobeats.axiom.co/api/embed/50c98819138ee524ce9eb6666cc3c5fea8a694e8.svg?sanitize=true&#34; alt=&#34;Alt&#34; title=&#34;Repobeats analytics image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=shadowgmes/shadowgmes.github.io&amp;amp;type=Date&#34; alt=&#34;Alt&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;This site has a few features to make your life easier:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Tab Hider (Opens tab in about:blank. Not visible to most extensions such as GoGuardian)&lt;/li&gt; &#xA; &lt;li&gt;Homepage is disguised as Google&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Feel free to make a pull request&lt;/h2&gt; &#xA;&lt;p&gt;Pull requests are highly encouraged as they take work off our hands and they allow people to contribute to this site.&lt;/p&gt; &#xA;&lt;h2&gt;Reviewing and requesting&lt;/h2&gt; &#xA;&lt;p&gt;To make a game request or review the site, please &lt;a href=&#34;https://github.com/shadowgmes/shadowgmes.github.io/issues/new/choose&#34;&gt;make an issue on GitHub&lt;/a&gt; or &lt;a href=&#34;https://discord.gg/ZdHBCFXdT3&#34;&gt;make a ticket in the Discord Server&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;To-do list&lt;/h2&gt; &#xA;&lt;p&gt;Things we have to get done:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make all games disguised as Google&lt;/li&gt; &#xA; &lt;li&gt;Add more games (always here. not going away. we will have all the games)&lt;/li&gt; &#xA; &lt;li&gt;We can now start focusing on adding apps&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;As stated before, please feel free to make a pull request accomplishing these features.&lt;/p&gt;</summary>
  </entry>
</feed>