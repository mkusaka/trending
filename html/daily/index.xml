<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-18T01:33:37Z</updated>
  <subtitle>Daily Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>webtutorialsw/css_sliding_cards</title>
    <updated>2023-12-18T01:33:37Z</updated>
    <id>tag:github.com,2023-12-18:/webtutorialsw/css_sliding_cards</id>
    <link href="https://github.com/webtutorialsw/css_sliding_cards" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stunning HTML &amp;amp; CSS Card Animation&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/webtutorialsw/css_sliding_cards/master/thumbnail.png&#34; alt=&#34;Thumbnail&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Full tutorial here: &lt;a href=&#34;https://www.youtube.com/watch?v=45mnmy2JUl0&#34;&gt;https://www.youtube.com/watch?v=45mnmy2JUl0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Sliding images (not in repo): &lt;a href=&#34;https://wirestock.io/james591&#34;&gt;https://wirestock.io/james591&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kh-kim/arxiv-translator</title>
    <updated>2023-12-18T01:33:37Z</updated>
    <id>tag:github.com,2023-12-18:/kh-kim/arxiv-translator</id>
    <link href="https://github.com/kh-kim/arxiv-translator" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Arxiv Translation Project&lt;/h1&gt; &#xA;&lt;p&gt;이 레포는 쏟아지는 페이퍼들에 대응하기 위하여, 빠르게 Arxiv 페이퍼를 살펴볼 수 있도록 한글화된 웹페이지를 제공하는 것을 목표로 합니다. 각기 다른 형태의 PDF 파일을 번역하기 위해서, 텍스트를 추출할 때 nougat OCR 라이브러리를 활용합니다. 따라서 추출이 원활하지 않을 수 있습니다. 처음에는 Ar5iv를 번역할까 생각했지만, Ar5iv도 한달이 지나서야 페이퍼가 업데이트 되며, 최초 버전만 HTML화 하고 최종 버전은 반영되어 있지 않기 때문에, 자체적으로 내용을 추출하기로 결정하였습니다. 정확한 내용을 파악하기 위해서는 원본 페이퍼를 읽는 것을 추천합니다.&lt;/p&gt; &#xA;&lt;h2&gt;Paper List&lt;/h2&gt; &#xA;&lt;p&gt;새 창 열기가 지원되지 않습니다. 직접 새 창으로 열기를 통해 열기를 권장합니다.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ArXiv ID&lt;/th&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ArXiv / Ar5iv&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;English / Korean&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2312.09256&lt;/td&gt; &#xA;   &lt;td&gt;LIME Localized Image Editing via Attention Regularization in Diffusion Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.09256&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2312.09256&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.09256/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.09256/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2312.09256&lt;/td&gt; &#xA;   &lt;td&gt;LIME Localized Image Editing via Attention Regularization in Diffusion Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.09256&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2312.09256&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.09256/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.09256/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2312.08629&lt;/td&gt; &#xA;   &lt;td&gt;ChatSOS LLM-based knowledge QA system for safety engineering&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.08629&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2312.08629&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.08629/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.08629/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2312.07910&lt;/td&gt; &#xA;   &lt;td&gt;PromptBench A Unified Library for Evaluation of Large Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.07910&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2312.07910&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.07910/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.07910/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2312.07398&lt;/td&gt; &#xA;   &lt;td&gt;LLMEval A Preliminary Study on How to Evaluate Large Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.07398&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2312.07398&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.07398/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.07398/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2312.06585&lt;/td&gt; &#xA;   &lt;td&gt;Beyond Human Data Scaling Self-Training for Problem-Solving with Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.06585&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2312.06585&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.06585/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.06585/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2312.02783&lt;/td&gt; &#xA;   &lt;td&gt;Large Language Models on Graphs A Comprehensive Survey&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.02783&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2312.02783&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.02783/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.02783/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2312.01454&lt;/td&gt; &#xA;   &lt;td&gt;D-Bot Database Diagnosis System using Large Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.01454&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2312.01454&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.01454/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2312.01454/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2311.16867&lt;/td&gt; &#xA;   &lt;td&gt;The Falcon Series of Open Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2311.16867&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2311.16867&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.16867/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.16867/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2311.13165&lt;/td&gt; &#xA;   &lt;td&gt;Multimodal Large Language Models A Survey&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2311.13165&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2311.13165&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.13165/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.13165/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2311.11045&lt;/td&gt; &#xA;   &lt;td&gt;Orca 2 Teaching Small Language Models How to Reason&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2311.11045&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2311.11045&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.11045/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.11045/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2311.10770&lt;/td&gt; &#xA;   &lt;td&gt;Exponentially Faster Language Modelling&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2311.10770&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2311.10770&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.10770/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.10770/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2311.08355&lt;/td&gt; &#xA;   &lt;td&gt;Mustango Toward Controllable Text-to-Music Generation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2311.08355&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2311.08355&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.08355/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.08355/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2311.08355&lt;/td&gt; &#xA;   &lt;td&gt;Mustango Toward Controllable Text-to-Music Generation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2311.08355&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2311.08355&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.08355/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.08355/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2311.04590&lt;/td&gt; &#xA;   &lt;td&gt;Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2311.04590&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2311.04590&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.04590/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2311.04590/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2310.08659&lt;/td&gt; &#xA;   &lt;td&gt;LoftQ LoRA-Fine-Tuning-Aware Quantization for Large Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.08659&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2310.08659&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2310.08659/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2310.08659/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2310.04678&lt;/td&gt; &#xA;   &lt;td&gt;DORIS-MAE Scientific Document Retrieval using Multi-level Aspect-based Queries&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.04678&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2310.04678&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2310.04678/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2310.04678/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2310.04406&lt;/td&gt; &#xA;   &lt;td&gt;Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.04406&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2310.04406&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2310.04406/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2310.04406/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2310.03813&lt;/td&gt; &#xA;   &lt;td&gt;Accurate Cold-start Bundle Recommendation via Popularity-based Coalescence and Curriculum Heating&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.03813&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2310.03813&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2310.03813/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2310.03813/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2309.16039&lt;/td&gt; &#xA;   &lt;td&gt;Effective Long-Context Scaling of Foundation Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.16039&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2309.16039&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.16039/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.16039/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2309.15402&lt;/td&gt; &#xA;   &lt;td&gt;A Survey of Chain of Thought Reasoning Advances Frontiers and Future&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.15402&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2309.15402&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.15402/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.15402/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2309.05463&lt;/td&gt; &#xA;   &lt;td&gt;Textbooks Are All You Need II phi-15 technical report&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.05463&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2309.05463&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.05463/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.05463/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2309.04902&lt;/td&gt; &#xA;   &lt;td&gt;Transformers in Small Object Detection A Benchmark and Survey of State-of-the-Art&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.04902&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2309.04902&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.04902/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.04902/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2309.00267&lt;/td&gt; &#xA;   &lt;td&gt;RLAIF Scaling Reinforcement Learning from Human Feedback with AI Feedback&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.00267&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2309.00267&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.00267/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2309.00267/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2308.11432&lt;/td&gt; &#xA;   &lt;td&gt;A Survey on Large Language Model based Autonomous Agents&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2308.11432&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2308.11432&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2308.11432/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2308.11432/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2308.10848&lt;/td&gt; &#xA;   &lt;td&gt;AgentVerse Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2308.10848&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2308.10848&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2308.10848/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2308.10848/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2308.04014&lt;/td&gt; &#xA;   &lt;td&gt;Continual Pre-Training of Large Language Models How to rewarm your model?&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2308.04014&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2308.04014&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2308.04014/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2308.04014/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2307.14334&lt;/td&gt; &#xA;   &lt;td&gt;Towards Generalist Biomedical AI&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.14334&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2307.14334&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2307.14334/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2307.14334/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2306.14462&lt;/td&gt; &#xA;   &lt;td&gt;Multi-task Item-attribute Graph Pre-training for Strict Cold-start Item Recommendation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.14462&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2306.14462&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.14462/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.14462/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2306.13549&lt;/td&gt; &#xA;   &lt;td&gt;A Survey on Multimodal Large Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.13549&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2306.13549&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.13549/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.13549/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2306.12509&lt;/td&gt; &#xA;   &lt;td&gt;Joint Prompt Optimization of Stacked LLMs using Variational Inference&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.12509&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2306.12509&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.12509/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.12509/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2306.11167&lt;/td&gt; &#xA;   &lt;td&gt;Large Language Models are Fixated by Red Herrings Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.11167&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2306.11167&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.11167/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.11167/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2306.03361&lt;/td&gt; &#xA;   &lt;td&gt;WHAT WHEN and HOW to Ground Designing User Persona-Aware Conversational Agents for Engaging Dialogue&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.03361&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2306.03361&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.03361/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2306.03361/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2305.18395&lt;/td&gt; &#xA;   &lt;td&gt;Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.18395&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2305.18395&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.18395/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.18395/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2305.18290&lt;/td&gt; &#xA;   &lt;td&gt;Direct Preference Optimization Your Language Model is Secretly a Reward Model&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.18290&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2305.18290&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.18290/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.18290/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2305.14992&lt;/td&gt; &#xA;   &lt;td&gt;Reasoning with Language Model is Planning with World Model&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.14992&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2305.14992&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.14992/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.14992/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2305.14314&lt;/td&gt; &#xA;   &lt;td&gt;QLoRA Efficient Finetuning of Quantized LLMs&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.14314&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2305.14314&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.14314/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.14314/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2305.10601&lt;/td&gt; &#xA;   &lt;td&gt;Tree of Thoughts Deliberate Problem Solving with Large Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.10601&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2305.10601&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.10601/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2305.10601/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2304.12244&lt;/td&gt; &#xA;   &lt;td&gt;WizardLM Empowering Large Language Models to Follow Complex Instructions&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.12244&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2304.12244&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2304.12244/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2304.12244/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2303.18223&lt;/td&gt; &#xA;   &lt;td&gt;A Survey of Large Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.18223&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2303.18223&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2303.18223/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2303.18223/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2303.16755&lt;/td&gt; &#xA;   &lt;td&gt;Training Language Models with Language Feedback at Scale&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.16755&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2303.16755&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2303.16755/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2303.16755/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2212.09147&lt;/td&gt; &#xA;   &lt;td&gt;Achiral dielectric metasurfaces for spectral and polarization control of valley specific light emission from monolayer MoS2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.09147&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2212.09147&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2212.09147/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2212.09147/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2210.03629&lt;/td&gt; &#xA;   &lt;td&gt;ReAct Synergizing Reasoning and Acting in Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.03629&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2210.03629&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2210.03629/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2210.03629/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2207.14255&lt;/td&gt; &#xA;   &lt;td&gt;Efficient Training of Language Models to Fill in the Middle&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.14255&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2207.14255&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2207.14255/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2207.14255/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2205.14193&lt;/td&gt; &#xA;   &lt;td&gt;2 Active metasurfaces lighting the path to commercial success&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.14193&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2205.14193&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2205.14193/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2205.14193/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2204.10365&lt;/td&gt; &#xA;   &lt;td&gt;Towards an Enhanced Understanding of Bias in Pre-trained Neural Language Models A Survey with Special Emphasis on Affective Bias&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.10365&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2204.10365&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2204.10365/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2204.10365/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2203.14473&lt;/td&gt; &#xA;   &lt;td&gt;Towards Dynamic and Safe Configuration Tuning for Cloud Databases&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.14473&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2203.14473&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2203.14473/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2203.14473/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2203.11171&lt;/td&gt; &#xA;   &lt;td&gt;Self-Consistency Improves Chain of Thought Reasoning in Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.11171&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2203.11171&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2203.11171/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2203.11171/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2202.06991&lt;/td&gt; &#xA;   &lt;td&gt;Transformer Memory as a Differentiable Search Index&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.06991&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2202.06991&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2202.06991/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2202.06991/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2201.11903&lt;/td&gt; &#xA;   &lt;td&gt;Chain-of-Thought Prompting Elicits Reasoning in Large Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2201.11903&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2201.11903&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2201.11903/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2201.11903/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2112.02300&lt;/td&gt; &#xA;   &lt;td&gt;Unsupervised Domain Generalization by Learning a Bridge Across Domains&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.02300&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2112.02300&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2112.02300/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2112.02300/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2108.13475&lt;/td&gt; &#xA;   &lt;td&gt;An Analysis Of Entire Space Multi-Task Models For Post-Click Conversion Prediction&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.13475&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2108.13475&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2108.13475/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2108.13475/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2106.09685&lt;/td&gt; &#xA;   &lt;td&gt;LoRA Low-Rank Adaptation of Large Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2106.09685&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2106.09685/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2106.09685/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2101.03961&lt;/td&gt; &#xA;   &lt;td&gt;Switch Transformers Scaling to Trillion Parameter Models with Simple and Efficient Sparsity&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2101.03961&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2101.03961&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2101.03961/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2101.03961/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2007.01282&lt;/td&gt; &#xA;   &lt;td&gt;Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.01282&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2007.01282&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2007.01282/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2007.01282/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2005.11401&lt;/td&gt; &#xA;   &lt;td&gt;Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.11401&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2005.11401&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2005.11401/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2005.11401/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2004.04906&lt;/td&gt; &#xA;   &lt;td&gt;Dense Passage Retrieval for Open-Domain Question Answering&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2004.04906&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2004.04906&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2004.04906/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2004.04906/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2002.08909&lt;/td&gt; &#xA;   &lt;td&gt;REALM Retrieval-Augmented Language Model Pre-Training&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2002.08909&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2002.08909&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2002.08909/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2002.08909/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2002.06563&lt;/td&gt; &#xA;   &lt;td&gt;Epidemic analysis of COVID-19 in China by dynamical modeling&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2002.06563&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/2002.06563&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2002.06563/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2002.06563/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1910.10683&lt;/td&gt; &#xA;   &lt;td&gt;Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/1910.10683&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/1910.10683&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/1910.10683/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/1910.10683/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1910.07099&lt;/td&gt; &#xA;   &lt;td&gt;Entire Space Multi-Task Modeling via Post-Click Behavior Decomposition for Conversion Rate Prediction&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/1910.07099&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/1910.07099&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/1910.07099/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/1910.07099/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1706.03762&lt;/td&gt; &#xA;   &lt;td&gt;Attention Is All You Need&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/1706.03762&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/1706.03762/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/1706.03762/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1702.08734&lt;/td&gt; &#xA;   &lt;td&gt;Billion-scale similarity search with GPUs&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/1702.08734&#34;&gt;arXiv&lt;/a&gt; / &lt;a href=&#34;https://ar5iv.org/abs/1702.08734&#34;&gt;ar5iv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/1702.08734/paper.en.html&#34;&gt;en&lt;/a&gt; / &lt;a href=&#34;https://raw.githack.com/kh-kim/arxiv-translator/master/papers/1702.08734/paper.ko.html&#34;&gt;ko&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Procedure&lt;/h2&gt; &#xA;&lt;p&gt;Arxiv 페이퍼를 번역하기 위해서 총 4단계를 거칩니다.&lt;/p&gt; &#xA;&lt;h4&gt;ArXiv Paper Download&lt;/h4&gt; &#xA;&lt;p&gt;Arxiv는 wget 등의 명령어를 통해서 pdf 파일을 다운로드 받을 수 없게 하였습니다. 아마도 무분별한 scrapping에 대응하기 위한 것으로 생각됩니다. 따라서 pdf 파일을 다운로드 받기 위해서 &lt;a href=&#34;https://pypi.org/project/arxiv-dl/&#34;&gt;arxiv-dl&lt;/a&gt; 패키지를 활용합니다.&lt;/p&gt; &#xA;&lt;h4&gt;PDF to Markdown&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/facebookresearch/nougat&#34;&gt;Nougat OCR&lt;/a&gt;을 활용하여 Mathpix Markdown 파일로 변환합니다.&lt;/p&gt; &#xA;&lt;h4&gt;Translation&lt;/h4&gt; &#xA;&lt;p&gt;자체 번역 모델을 활용하여 번역을 수행합니다. 다음과 같이 페이퍼의 번역을 위해 사용된 번역기의 성능(초록색)은 DeepL과 Google, Naver의 중간쯤에 위치합니다.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kh-kim/arxiv-translator/main/assets/nmt_eval.png&#34; alt=&#34;NMT Evaluation Results&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Markdown to HTML&lt;/h4&gt; &#xA;&lt;p&gt;Mathpix Markdown을 HTML로 변환합니다. 변환 방법은 &lt;a href=&#34;https://github.com/Mathpix/mathpix-markdown-it/tree/master?tab=readme-ov-file#using-mathpix-markdown-it-in-web-browsers&#34;&gt;여기&lt;/a&gt;에 설명되어 있습니다. 그리고 저장된 github에 push되어 저장된 HTML 파일을 githack.com을 통해 렌더링하도록 합니다.&lt;/p&gt; &#xA;&lt;h2&gt;Future Work&lt;/h2&gt; &#xA;&lt;p&gt;페이퍼 중간의 이미지들은 Nougat OCR에서 추출해주지 않기 때문에 빠져 있습니다. 따라서 이미지도 함께 포함하여 결과물을 만들어내도록 하고자 합니다.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;Kim Ki Hyun &lt;a href=&#34;mailto:pointzz.ki@gmail.com&#34;&gt;pointzz.ki@gmail.com&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>