<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-12T01:32:52Z</updated>
  <subtitle>Daily Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>liguodongiot/llm-action</title>
    <updated>2024-05-12T01:32:52Z</updated>
    <id>tag:github.com,2024-05-12:/liguodongiot/llm-action</id>
    <link href="https://github.com/liguodongiot/llm-action" rel="alternate"></link>
    <summary type="html">&lt;p&gt;本项目旨在分享大模型相关技术原理以及实战经验。&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/liguodongiot/llm-action/raw/main/pic/llm-action-v3.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://github.com/liguodongiot/llm-action/stargazers&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/liguodongiot/llm-action?style=social&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/pic/wx.jpg&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/吃果冻不吐果冻皮-1AAD19.svg?style=plastic&amp;amp;logo=wechat&amp;amp;logoColor=white&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.zhihu.com/people/liguodong-iot&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/吃果冻不吐果冻皮-0079FF.svg?style=plastic&amp;amp;logo=zhihu&amp;amp;logoColor=white&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://juejin.cn/user/3642056016410728&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/掘金-吃果冻不吐果冻皮-000099.svg?style=plastic&amp;amp;logo=juejin&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://liguodong.blog.csdn.net/&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/CSDN-吃果冻不吐果冻皮-6B238E.svg&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;目录&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🔥 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E8%AE%AD%E7%BB%83&#34;&gt;LLM训练&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;🐫 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E8%AE%AD%E7%BB%83%E5%AE%9E%E6%88%98&#34;&gt;LLM训练实战&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;🐼 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86&#34;&gt;LLM参数高效微调技术原理&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;🐰 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98&#34;&gt;LLM参数高效微调技术实战&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;🐘 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E5%B9%B6%E8%A1%8C%E6%8A%80%E6%9C%AF&#34;&gt;LLM分布式训练并行技术&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;🌋 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E5%88%86%E5%B8%83%E5%BC%8Fai%E6%A1%86%E6%9E%B6&#34;&gt;分布式AI框架&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;📡 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1&#34;&gt;分布式训练网络通信&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;span&gt;🌿&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF&#34;&gt;LLM训练优化技术&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;span&gt;⌛&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%AF%B9%E9%BD%90%E6%8A%80%E6%9C%AF&#34;&gt;LLM对齐技术&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;🐎 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E6%8E%A8%E7%90%86&#34;&gt;LLM推理&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;🚀 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6&#34;&gt;LLM推理框架&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;✈️ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF&#34;&gt;LLM推理优化技术&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;♻️ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%8E%8B%E7%BC%A9&#34;&gt;LLM压缩&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;📐 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E9%87%8F%E5%8C%96&#34;&gt;LLM量化&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;🔰 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%89%AA%E6%9E%9D&#34;&gt;LLM剪枝&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;💹 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F&#34;&gt;LLM知识蒸馏&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;♑️ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3&#34;&gt;低秩分解&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;🌴&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B&#34;&gt;LLM数据工程&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;span&gt;🐬&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%BE%AE%E8%B0%83%E9%AB%98%E6%95%88%E6%95%B0%E6%8D%AE%E7%AD%9B%E9%80%89%E6%8A%80%E6%9C%AF&#34;&gt;LLM微调高效数据筛选技术&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;🌀&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B&#34;&gt;提示工程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;♍️ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E7%AE%97%E6%B3%95%E6%9E%B6%E6%9E%84&#34;&gt;LLM算法架构&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;🧩&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91&#34;&gt;LLM应用开发&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🀄️ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%9B%BD%E4%BA%A7%E5%8C%96%E9%80%82%E9%85%8D&#34;&gt;LLM国产化适配&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🔯 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#ai%E7%BC%96%E8%AF%91%E5%99%A8&#34;&gt;AI编译器&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🔘 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD&#34;&gt;AI基础设施&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;span&gt;🍁&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#ai%E5%8A%A0%E9%80%9F%E5%8D%A1&#34;&gt;AI加速卡&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;img alt=&#34;octocat&#34; src=&#34;https://github.githubassets.com/images/icons/emoji/octocat.png?v8&#34;&gt;) &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#ai%E9%9B%86%E7%BE%A4%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1&#34;&gt;AI集群网络通信&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;💟 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llmops&#34;&gt;LLMOps&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🍄 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E7%94%9F%E6%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF&#34;&gt;LLM生态相关技术&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🔨 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7&#34;&gt;服务器基础环境安装及常用工具&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;💬 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%AD%A6%E4%B9%A0%E4%BA%A4%E6%B5%81%E7%BE%A4&#34;&gt;LLM学习交流群&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;👥 &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7&#34;&gt;微信公众号&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;⭐️ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#star-history&#34;&gt;Star History&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;🔗&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#ai%E5%B7%A5%E7%A8%8B%E5%8C%96%E8%AF%BE%E7%A8%8B%E6%8E%A8%E8%8D%90&#34;&gt;AI工程化课程推荐&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLM训练&lt;/h2&gt; &#xA;&lt;h3&gt;LLM训练实战&lt;/h3&gt; &#xA;&lt;p&gt;下面汇总了我在大模型实践中训练相关的所有教程。从6B到65B，从全量微调到高效微调（LoRA，QLoRA，P-Tuning v2），再到RLHF（基于人工反馈的强化学习）。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;LLM&lt;/th&gt; &#xA;   &lt;th&gt;预训练/SFT/RLHF...&lt;/th&gt; &#xA;   &lt;th&gt;参数&lt;/th&gt; &#xA;   &lt;th&gt;教程&lt;/th&gt; &#xA;   &lt;th&gt;代码&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/618321077&#34;&gt;从0到1复现斯坦福羊驼（Stanford Alpaca 7B）&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/alpaca&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Alpaca(LLaMA)&lt;/td&gt; &#xA;   &lt;td&gt;LoRA&lt;/td&gt; &#xA;   &lt;td&gt;7B~65B&lt;/td&gt; &#xA;   &lt;td&gt;1.&lt;a href=&#34;https://zhuanlan.zhihu.com/p/619426866&#34;&gt;足够惊艳，使用Alpaca-Lora基于LLaMA(7B)二十分钟完成微调，效果比肩斯坦福羊驼&lt;/a&gt;&lt;br&gt;2. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/632492604&#34;&gt;使用 LoRA 技术对 LLaMA 65B 大模型进行微调及推理&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/alpaca-lora&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BELLE(LLaMA/Bloom)&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;1.&lt;a href=&#34;https://zhuanlan.zhihu.com/p/618876472&#34;&gt;基于LLaMA-7B/Bloomz-7B1-mt复现开源中文对话大模型BELLE及GPTQ量化&lt;/a&gt; &lt;br&gt; 2. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/621128368&#34;&gt;BELLE(LLaMA-7B/Bloomz-7B1-mt)大模型使用GPTQ量化后推理性能测试&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM&lt;/td&gt; &#xA;   &lt;td&gt;LoRA&lt;/td&gt; &#xA;   &lt;td&gt;6B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/621793987&#34;&gt;从0到1基于ChatGLM-6B使用LoRA进行参数高效微调&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/chatglm-lora&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning/P-Tuning v2&lt;/td&gt; &#xA;   &lt;td&gt;6B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/622351059&#34;&gt;使用DeepSpeed/P-Tuning v2对ChatGLM-6B进行微调&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/chatglm&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna(LLaMA)&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/624012908&#34;&gt;大模型也内卷，Vicuna训练及推理指南，效果碾压斯坦福羊驼&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OPT&lt;/td&gt; &#xA;   &lt;td&gt;RLHF&lt;/td&gt; &#xA;   &lt;td&gt;0.1B~66B&lt;/td&gt; &#xA;   &lt;td&gt;1.&lt;a href=&#34;https://zhuanlan.zhihu.com/p/626159553&#34;&gt;一键式 RLHF 训练 DeepSpeed Chat（一）：理论篇&lt;/a&gt;&amp;nbsp;&lt;br&gt; 2. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/626214655&#34;&gt;一键式 RLHF 训练 DeepSpeed Chat（二）：实践篇&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/deepspeedchat&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniGPT-4(LLaMA)&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/627671257&#34;&gt;大杀器，多模态大模型MiniGPT-4入坑指南&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-LLaMA-Alpaca(LLaMA)&lt;/td&gt; &#xA;   &lt;td&gt;LoRA（预训练+微调）&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/631360711&#34;&gt;中文LLaMA&amp;amp;Alpaca大语言模型词表扩充+预训练+指令精调&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/chinese-llama-alpaca&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA&lt;/td&gt; &#xA;   &lt;td&gt;QLoRA&lt;/td&gt; &#xA;   &lt;td&gt;7B/65B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/636644164&#34;&gt;高效微调技术QLoRA实战，基于LLaMA-65B微调仅需48G显存，真香&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/qlora&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA&lt;/td&gt; &#xA;   &lt;td&gt;GaLore&lt;/td&gt; &#xA;   &lt;td&gt;60M/7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/686686751&#34;&gt;突破内存瓶颈，使用 GaLore 一张4090消费级显卡也能预训练LLaMA-7B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/galore/torchrun_main.py&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;⬆ 一键返回目录&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;LLM微调技术原理&lt;/h3&gt; &#xA;&lt;p&gt;对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。&lt;/p&gt; &#xA;&lt;p&gt;因此，该技术值得我们进行深入分析其背后的机理，本系列大体分七篇文章进行讲解。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/pic/llm/train/sft/peft%E6%96%B9%E6%B3%95.jpg&#34; alt=&#34;peft方法&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/635152813&#34;&gt;大模型参数高效微调技术原理综述（一）-背景、参数高效微调简介&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/635686756&#34;&gt;大模型参数高效微调技术原理综述（二）-BitFit、Prefix Tuning、Prompt Tuning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/635848732&#34;&gt;大模型参数高效微调技术原理综述（三）-P-Tuning、P-Tuning v2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/636038478&#34;&gt;大模型参数高效微调技术原理综述（四）-Adapter Tuning及其变体&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/636215898&#34;&gt;大模型参数高效微调技术原理综述（五）-LoRA、AdaLoRA、QLoRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/636362246&#34;&gt;大模型参数高效微调技术原理综述（六）-MAM Adapter、UniPELT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/649755252&#34;&gt;大模型参数高效微调技术原理综述（七）-最佳实践、总结&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLM微调实战&lt;/h3&gt; &#xA;&lt;p&gt;下面给大家分享&lt;strong&gt;大模型参数高效微调技术实战&lt;/strong&gt;，该系列主要针对 HuggingFace PEFT 框架支持的一些高效微调技术进行讲解。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;教程&lt;/th&gt; &#xA;   &lt;th&gt;代码&lt;/th&gt; &#xA;   &lt;th&gt;框架&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/651744834&#34;&gt;大模型参数高效微调技术实战（一）-PEFT概述及环境搭建&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/646748939&#34;&gt;大模型参数高效微调技术实战（二）-Prompt Tuning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_prompt_tuning_clm.ipynb&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/646876256&#34;&gt;大模型参数高效微调技术实战（三）-P-Tuning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_p_tuning_clm.ipynb&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/648156780&#34;&gt;大模型参数高效微调技术实战（四）-Prefix Tuning / P-Tuning v2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_p_tuning_v2_clm.ipynb&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/649315197&#34;&gt;大模型参数高效微调技术实战（五）-LoRA&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_lora_clm.ipynb&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/649707359&#34;&gt;大模型参数高效微调技术实战（六）-IA3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_ia3_clm.ipynb&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/670048482&#34;&gt;大模型微调实战（七）-基于LoRA微调多模态大模型&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/multimodal/blip2_lora_int8_fine_tune.py&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/670116171&#34;&gt;大模型微调实战（八）-使用INT8/FP4/NF4微调大模型&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/multimodal/finetune_bloom_bnb_peft.ipynb&#34;&gt;配套代码&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PEFT、bitsandbytes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;⬆ 一键返回目录&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/docs/llm-base/distribution-parallelism&#34;&gt;LLM分布式训练并行技术&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡模式已经无法满足超大模型进行训练的要求。因此，我们需要基于单机多卡、甚至是多机多卡进行分布式大模型的训练。&lt;/p&gt; &#xA;&lt;p&gt;而利用AI集群，使深度学习算法更好地从大量数据中高效地训练出性能优良的大模型是分布式机器学习的首要目标。为了实现该目标，一般需要根据硬件资源与数据/模型规模的匹配情况，考虑对计算任务、训练数据和模型进行划分，从而进行分布式训练。因此，分布式训练相关技术值得我们进行深入分析其背后的机理。&lt;/p&gt; &#xA;&lt;p&gt;下面主要对大模型进行分布式训练的并行技术进行讲解，本系列大体分九篇文章进行讲解。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/598714869&#34;&gt;大模型分布式训练并行技术（一）-概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/650002268&#34;&gt;大模型分布式训练并行技术（二）-数据并行&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/653860567&#34;&gt;大模型分布式训练并行技术（三）-流水线并行&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/657921100&#34;&gt;大模型分布式训练并行技术（四）-张量并行&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/659792351&#34;&gt;大模型分布式训练并行技术（五）-序列并行&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/661279318&#34;&gt;大模型分布式训练并行技术（六）-多维混合并行&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/662517647&#34;&gt;大模型分布式训练并行技术（七）-自动并行&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/662518387&#34;&gt;大模型分布式训练并行技术（八）-MOE并行&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/667051845&#34;&gt;大模型分布式训练并行技术（九）-总结&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;⬆ 一键返回目录&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;分布式AI框架&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/pytorch/&#34;&gt;PyTorch&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;PyTorch 单机多卡训练&lt;/li&gt; &#xA;   &lt;li&gt;PyTorch 多机多卡训练&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/megatron&#34;&gt;Megatron-LM&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Megatron-LM 单机多卡训练&lt;/li&gt; &#xA;   &lt;li&gt;Megatron-LM 多机多卡训练&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7259682893648724029&#34;&gt;基于Megatron-LM从0到1完成GPT2模型预训练、模型评估及推理&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/deepspeed&#34;&gt;DeepSpeed&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;DeepSpeed 单机多卡训练&lt;/li&gt; &#xA;   &lt;li&gt;DeepSpeed 多机多卡训练&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/megatron-deepspeed&#34;&gt;Megatron-DeepSpeed&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;基于 Megatron-DeepSpeed 从 0 到1 完成 LLaMA 预训练&lt;/li&gt; &#xA;   &lt;li&gt;基于 Megatron-DeepSpeed 从 0 到1 完成 Bloom 预训练&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;分布式训练网络通信&lt;/h3&gt; &#xA;&lt;p&gt;待更新...&lt;/p&gt; &#xA;&lt;h3&gt;LLM训练优化技术&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;FlashAttention V1、V2&lt;/li&gt; &#xA; &lt;li&gt;混合精度训练&lt;/li&gt; &#xA; &lt;li&gt;重计算&lt;/li&gt; &#xA; &lt;li&gt;MQA / GQA&lt;/li&gt; &#xA; &lt;li&gt;梯度累积&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLM对齐技术&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PPO（近端策略优化）&lt;/li&gt; &#xA; &lt;li&gt;DPO&lt;/li&gt; &#xA; &lt;li&gt;ORPO&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;⬆ 一键返回目录&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/inference&#34;&gt;LLM推理&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;LLM推理框架&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/625415776/answer/3243562246&#34;&gt;大模型推理框架概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/626008090&#34;&gt;大模型的好伙伴，浅析推理加速引擎FasterTransformer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/629336492&#34;&gt;模型推理服务化框架Triton保姆式教程（一）：快速入门&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/634143650&#34;&gt;模型推理服务化框架Triton保姆式教程（二）：架构解析&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/634444666&#34;&gt;模型推理服务化框架Triton保姆式教程（三）：开发实践&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/666849728&#34;&gt;TensorRT-LLM保姆级教程（一）-快速入门&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/667572720&#34;&gt;TensorRT-LLM保姆级教程（二）-开发实践&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TensorRT-LLM保姆级教程（三）-基于Triton完成模型服务化&lt;/li&gt; &#xA; &lt;li&gt;TensorRT-LLM保姆级教程（四）-新模型适配&lt;/li&gt; &#xA; &lt;li&gt;TensorRT&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLM推理优化技术&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;LLM推理优化技术概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;FlashAttention&lt;/li&gt; &#xA; &lt;li&gt;PagedAttention&lt;/li&gt; &#xA; &lt;li&gt;Continuous Batching&lt;/li&gt; &#xA; &lt;li&gt;KV Cache&lt;/li&gt; &#xA; &lt;li&gt;Flash Decoding&lt;/li&gt; &#xA; &lt;li&gt;FlashDecoding++&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLM压缩&lt;/h2&gt; &#xA;&lt;p&gt;近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，从而导致模型变得越来越大，因此，我们需要一些大模型压缩技术来降低模型部署的成本，并提升模型的推理性能。 模型压缩主要分为如下几类：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;剪枝（Pruning）&lt;/li&gt; &#xA; &lt;li&gt;知识蒸馏（Knowledge Distillation）&lt;/li&gt; &#xA; &lt;li&gt;量化&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/model-compression/quantization&#34;&gt;LLM量化&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;本系列将针对一些常见大模型量化方案（GPTQ、LLM.int8()、SmoothQuant、AWQ等）进行讲述。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/627484732/answer/3261671478&#34;&gt;大模型量化概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;量化感知训练： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/647589650&#34;&gt;大模型量化感知训练技术原理：LLM-QAT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;&#34;&gt;大模型量化感知微调技术原理：QLoRA&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;PEQA&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;训练后量化： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/680212402&#34;&gt;大模型量化技术原理：GPTQ、LLM.int8()&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/576376372/answer/3388402085&#34;&gt;大模型量化技术原理：SmoothQuant&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/681578090&#34;&gt;大模型量化技术原理：AWQ、AutoAWQ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/682871823&#34;&gt;大模型量化技术原理：SpQR&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/683813769&#34;&gt;大模型量化技术原理：ZeroQuant系列&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;大模型量化技术原理：总结&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLM剪枝&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/652126515/answer/3457652467&#34;&gt;大模型剪枝概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/692858636?&#34;&gt;万字长文谈深度神经网络剪枝综述&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;结构化剪枝&lt;/strong&gt;：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LLM-Pruner(LLM-Pruner: On the Structural Pruning of Large Language Models)&lt;/li&gt; &#xA; &lt;li&gt;LLM-Shearing(Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;非结构化剪枝&lt;/strong&gt;：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;SparseGPT(SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot)&lt;/li&gt; &#xA; &lt;li&gt;LoRAPrune(LoRAPrune: Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning)&lt;/li&gt; &#xA; &lt;li&gt;Wanda(A Simple and Effective Pruning Approach for Large Language Models)&lt;/li&gt; &#xA; &lt;li&gt;Flash-LLM(Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLM知识蒸馏&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/625415893/answer/3243565375&#34;&gt;大模型知识蒸馏概述&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Standard KD&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;p&gt;使学生模型学习教师模型(LLM)所拥有的常见知识，如输出分布和特征信息，这种方法类似于传统的KD。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MINILLM&lt;/li&gt; &#xA; &lt;li&gt;GKD&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;EA-based KD&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;p&gt;不仅仅是将LLM的常见知识转移到学生模型中，还涵盖了蒸馏它们独特的涌现能力。具体来说，EA-based KD又分为了上下文学习（ICL）、思维链（CoT）和指令跟随（IF）。&lt;/p&gt; &#xA;&lt;p&gt;In-Context Learning：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;In-Context Learning distillation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Chain-of-Thought：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MT-COT&lt;/li&gt; &#xA; &lt;li&gt;Fine-tune-CoT&lt;/li&gt; &#xA; &lt;li&gt;DISCO&lt;/li&gt; &#xA; &lt;li&gt;SCOTT&lt;/li&gt; &#xA; &lt;li&gt;SOCRATIC CoT&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Instruction Following：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lion&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;低秩分解&lt;/h3&gt; &#xA;&lt;p&gt;低秩分解旨在通过将给定的权重矩阵分解成两个或多个较小维度的矩阵，从而对其进行近似。低秩分解背后的核心思想是找到一个大的权重矩阵W的分解，得到两个矩阵U和V，使得W≈U V，其中U是一个m×k矩阵，V是一个k×n矩阵，其中k远小于m和n。U和V的乘积近似于原始的权重矩阵，从而大幅减少了参数数量和计算开销。&lt;/p&gt; &#xA;&lt;p&gt;在LLM研究的模型压缩领域，研究人员通常将多种技术与低秩分解相结合，包括修剪、量化等。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ZeroQuant-FP（低秩分解+量化）&lt;/li&gt; &#xA; &lt;li&gt;LoRAPrune（低秩分解+剪枝）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLM数据工程&lt;/h2&gt; &#xA;&lt;p&gt;LLM Data Engineering&lt;/p&gt; &#xA;&lt;h3&gt;预训练语料处理技术&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/pic/llm/train/pretrain/llm-pretrain-pipeline-v2.png&#34; alt=&#34;llm-pretrain-pipeline&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;数据收集&lt;/li&gt; &#xA; &lt;li&gt;数据处理 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;去重&lt;/li&gt; &#xA;   &lt;li&gt;过滤&lt;/li&gt; &#xA;   &lt;li&gt;选择&lt;/li&gt; &#xA;   &lt;li&gt;组合&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLM微调高效数据筛选技术&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;LLM微调高效数据筛选技术原理-DEITA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;LLM微调高效数据筛选技术原理-MoDS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;LLM微调高效数据筛选技术原理-IFD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;LLM微调高效数据筛选技术原理-CaR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/686007325&#34;&gt;LESS：仅选择5%有影响力的数据优于全量数据集进行目标指令微调&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/686687923&#34;&gt;LESS 实践：用少量的数据进行目标指令微调&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;提示工程&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Zero-Shot Prompting&lt;/li&gt; &#xA; &lt;li&gt;Few-Shot Prompting&lt;/li&gt; &#xA; &lt;li&gt;Chain-of-Thought (CoT) Prompting&lt;/li&gt; &#xA; &lt;li&gt;Automatic Chain-of-Thought (Auto-CoT) Prompting&lt;/li&gt; &#xA; &lt;li&gt;Tree-of-Thoughts (ToT) Prompting&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/docs/llm-base/ai-algo&#34;&gt;LLM算法架构&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/pic/llm/model/llm-famliy.jpg&#34; alt=&#34;llm-famliy&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/600016134&#34;&gt;大模型算法演进&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/pic/llm/model/llm-timeline-v2.png&#34; alt=&#34;llm-famliy&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ChatGLM / ChatGLM2 / ChatGLM3 大模型解析&lt;/li&gt; &#xA; &lt;li&gt;Bloom 大模型解析&lt;/li&gt; &#xA; &lt;li&gt;LLaMA / LLaMA2 大模型解析&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/606757218/answer/3075464500&#34;&gt;百川智能开源大模型baichuan-7B技术剖析&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/611507751/answer/3114988669&#34;&gt;百川智能开源大模型baichuan-13B技术剖析&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/653374932/answer/3470909634&#34;&gt;LLaMA3 技术剖析&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;QWen 大模型剖析&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLM应用开发&lt;/h2&gt; &#xA;&lt;p&gt;大模型是基座，要想让其变成一款产品，我们还需要一些其他相关的技术，比如：向量数据库（Pinecone、Milvus、Vespa、Weaviate），LangChain等。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/476025527&#34;&gt;云原生向量数据库Milvus（一）-简述、系统架构及应用场景&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/477231485&#34;&gt;云原生向量数据库Milvus（二）-数据与索引的处理流程、索引类型及Schema&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/651921120&#34;&gt;关于大模型驱动的AI智能体Agent的一些思考&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/docs/llm_localization&#34;&gt;LLM国产化适配&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;随着 ChatGPT 的现象级走红，引领了AI大模型时代的变革，从而导致 AI 算力日益紧缺。与此同时，中美贸易战以及美国对华进行AI芯片相关的制裁导致 AI 算力的国产化适配势在必行。本系列将对一些国产化 AI 加速卡进行讲解。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/637918406&#34;&gt;大模型国产化适配1-华为昇腾AI全栈软硬件平台总结&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/650730807&#34;&gt;大模型国产化适配2-基于昇腾910使用ChatGLM-6B进行模型推理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/651324599&#34;&gt;大模型国产化适配3-基于昇腾910使用ChatGLM-6B进行模型训练&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/655902796&#34;&gt;大模型国产化适配4-基于昇腾910使用LLaMA-13B进行多机多卡训练&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/665807431&#34;&gt;大模型国产化适配5-百度飞浆PaddleNLP大语言模型工具链总结&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/677799157&#34;&gt;大模型国产化适配6-基于昇腾910B快速验证ChatGLM3-6B/BaiChuan2-7B模型推理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/692377206&#34;&gt;大模型国产化适配7-华为昇腾LLM落地可选解决方案（MindFormers、ModelLink、MindIE）&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;⬆ 一键返回目录&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/ai-compiler&#34;&gt;AI编译器&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;AI编译器是指将机器学习算法从开发阶段，通过变换和优化算法，使其变成部署状态。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/669347560&#34;&gt;AI编译器技术剖析（一）-概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/671477784&#34;&gt;AI编译器技术剖析（二）-传统编译器&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/676723324&#34;&gt;AI编译器技术剖析（三）-树模型编译工具 Treelite 详解&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;AI编译器技术剖析（四）-编译器前端&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;AI编译器技术剖析（五）-编译器后端&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;AI编译器技术剖析（六）-主流编译框架&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;AI编译器技术剖析（七）-深度学习模型编译优化&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/672584013&#34;&gt;lleaves：使用 LLVM 编译梯度提升决策树将预测速度提升10+倍&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;框架：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MLIR&lt;/li&gt; &#xA; &lt;li&gt;XLA&lt;/li&gt; &#xA; &lt;li&gt;TVM&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;AI基础设施&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/672098336&#34;&gt;AI 集群基础设施 NVMe SSD 详解&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/673903240&#34;&gt;AI 集群基础设施 InfiniBand 详解&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;大模型训练基础设施：算力篇&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;AI加速卡&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/667686665&#34;&gt;AI芯片技术原理剖析（一）：国内外AI芯片概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;AI芯片技术原理剖析（二）：英伟达GPU&lt;/li&gt; &#xA; &lt;li&gt;AI芯片技术原理剖析（三）：谷歌TPU&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;AI集群&lt;/h3&gt; &#xA;&lt;p&gt;待更新...&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/docs/llm-base/network-communication&#34;&gt;AI集群网络通信&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;待更新...&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;分布式训练网络通讯原语&lt;/li&gt; &#xA; &lt;li&gt;AI 集群通信软硬件&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLMOps&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/676389726&#34;&gt;在 Kubernetes 上部署机器学习模型的指南&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7320513026188099619&#34;&gt;使用 Kubernetes 部署机器学习模型的优势&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLM生态相关技术&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/630696264&#34;&gt;大模型词表扩充必备工具SentencePiece&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/601594836/answer/3032763174&#34;&gt;大模型实践总结&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/604393963/answer/3061358152&#34;&gt;ChatGLM 和 ChatGPT 的技术区别在哪里？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/602504880/answer/3041965998&#34;&gt;现在为什么那么多人以清华大学的ChatGLM-6B为基座进行试验？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/616600181/answer/3195333332&#34;&gt;为什么很多新发布的大模型默认使用BF16而不是FP16？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/652836990/answer/3468210626&#34;&gt;大模型训练时ZeRO-2、ZeRO-3能否和Pipeline并行相结合？&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;⬆ 一键返回目录&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;服务器基础环境安装及常用工具&lt;/h2&gt; &#xA;&lt;p&gt;基础环境安装：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/docs/llm-base/a800-env-install.md&#34;&gt;英伟达A800加速卡常见软件包安装命令&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/docs/llm-base/h800-env-install.md&#34;&gt;英伟达H800加速卡常见软件包安装命令&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/docs/llm_localization/ascend910-env-install.md&#34;&gt;昇腾910加速卡常见软件包安装命令&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;常用工具：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/6992742028605915150&#34;&gt;Linux 常见命令大全&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7089093437223338015&#34;&gt;Conda 常用命令大全&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/6999405667261874183&#34;&gt;Poetry 常用命令大全&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7016238524286861325&#34;&gt;Docker 常用命令大全&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7016595442062327844&#34;&gt;Docker Dockerfile 指令大全&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7031201391553019911&#34;&gt;Kubernetes 常用命令大全&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/docs/llm-base/dcgmi.md&#34;&gt;集群环境 GPU 管理和监控工具 DCGM 常用命令大全&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLM学习交流群&lt;/h2&gt; &#xA;&lt;p&gt;我创建了大模型相关的学习交流群，供大家一起学习交流大模型相关的最新技术，目前已有5个群，每个群都有上百人的规模，&lt;strong&gt;可加我微信进群&lt;/strong&gt;（加微信请备注来意，如：进大模型学习交流群+GitHub，进大模型推理加速交流群+GitHub、进大模型应用开发交流群+GitHub等）。&lt;strong&gt;一定要备注哟，否则不予通过&lt;/strong&gt;。&lt;/p&gt; &#xA;&lt;p&gt;PS：&lt;strong&gt;成都有个本地大模型交流群，想进可以另外单独备注下。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/liguodongiot/llm-action/raw/main/pic/wx.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;微信公众号&lt;/h2&gt; &#xA;&lt;p&gt;微信公众号：&lt;strong&gt;吃果冻不吐果冻皮&lt;/strong&gt;，该公众号主要分享AI工程化（大模型、MLOps等）相关实践经验，免费电子书籍、论文等。&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/liguodongiot/llm-action/raw/main/pic/wx-gzh.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;⬆ 一键返回目录&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#liguodongiot/llm-action&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=liguodongiot/llm-action&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;AI工程化课程推荐&lt;/h2&gt; &#xA;&lt;p&gt;如今人工智能的发展可谓是如火如荼，ChatGPT、Sora、文心一言等AI大模型如雨后春笋般纷纷涌现。AI大模型优势在于它能处理复杂性问题；因此，越来越多的企业需要具备&lt;strong&gt;AI算法设计、AI应用开发、模型推理加速及模型压缩&lt;/strong&gt;等AI工程化落地的能力。这就导致行业内的工程师，需要快速提升自身的技术栈，以便于在行业内站稳脚跟。我在&lt;a href=&#34;https://github.com/liguodongiot/llm-resource&#34;&gt;llm-resource&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/liguodongiot/ai-system&#34;&gt;ai-system&lt;/a&gt;梳理了一些大模型和AI工程化相关资料，同时，推荐一些AI工程化相关的课程，&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzU3Mzg5ODgxMg==&amp;amp;mid=2247488019&amp;amp;idx=1&amp;amp;sn=90ca4657a643431f21df44fa199e695f&amp;amp;chksm=fd3bfb40ca4c72565fdb91717c8a27739bcb71d10fae89c7994f141d375d21059be19e702164&amp;amp;token=701439972&amp;amp;lang=zh_CN#rd&#34;&gt;点击&lt;/a&gt;查看详情。&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>khushi-joshi-05/Food-ordering-website</title>
    <updated>2024-05-12T01:32:52Z</updated>
    <id>tag:github.com,2024-05-12:/khushi-joshi-05/Food-ordering-website</id>
    <link href="https://github.com/khushi-joshi-05/Food-ordering-website" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Foodie is a food ordering website that aims to provide users with a seamless experience for ordering food online, taking orders for pickup, and booking tables for dining in. The website showcases the quality and specialties of the food offered, along with a variety of services to cater to different user preferences.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/khushi-joshi-05/Food-ordering-website/main/Images/gssoc.png&#34; alt=&#34;gssoc&#34;&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;Food Ordering Website&lt;/h1&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://badges.frapsoft.com/os/v2/open-source.svg?v=103&#34; alt=&#34;Open Source Love&#34;&gt; &amp;nbsp; &lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-green.svg?sanitize=true&#34; alt=&#34;PRs Welcome&#34;&gt; &amp;nbsp; &lt;a href=&#34;https://github.com/khushi-joshi-05/Food-ordering-website&#34;&gt;&lt;img src=&#34;https://sloc.xyz/github/khushi-joshi-05/Food-ordering-website&#34; alt=&#34;Lines of Code&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://github.com/khushi-joshi-05/Food-ordering-website/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/khushi-joshi-05/Food-ordering-website&#34; alt=&#34;Stars Badge&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://github.com/khushi-joshi-05/Food-ordering-website/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/khushi-joshi-05/Food-ordering-website&#34; alt=&#34;Forks Badge&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;img src=&#34;https://img.shields.io/github/contributors/khushi-joshi-05/Food-ordering-website?color=blue&#34; alt=&#34;GitHub contributors&#34;&gt; &amp;nbsp; &lt;img src=&#34;https://img.shields.io/github/last-commit/khushi-joshi-05/Food-ordering-website?color=red&amp;amp;style=plastic&#34; alt=&#34;GitHub last commit&#34;&gt; &amp;nbsp; &lt;img src=&#34;https://img.shields.io/github/repo-size/khushi-joshi-05/Food-ordering-website?color=white&#34; alt=&#34;Repo. Size&#34;&gt; &amp;nbsp;&lt;br&gt; &lt;a href=&#34;https://github.com/khushi-joshi-05/Food-ordering-website/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue.svg?v=103&#34;&gt;&lt;/a&gt;&amp;nbsp; &lt;a href=&#34;https://github.com/khushi-joshi-05/Food-ordering-website/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/khushi-joshi-05/Food-ordering-website?color=0059b3&#34;&gt;&lt;/a&gt;&amp;nbsp; &lt;a href=&#34;https://github.com/khushi-joshi-05/Food-ordering-website/issues?q=is%3Aissue+is%3Aclosed&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-closed-raw/khushi-joshi-05/Food-ordering-website?color=yellow&#34;&gt;&lt;/a&gt;&amp;nbsp; &lt;a href=&#34;https://github.com/khushi-joshi-05/Food-ordering-website/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/khushi-joshi-05/Food-ordering-website?color=brightgreen&#34;&gt;&lt;/a&gt;&amp;nbsp; &lt;a href=&#34;https://github.com/khushi-joshi-05/Food-ordering-website/pulls?q=is%3Apr+is%3Aclosed&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr-closed-raw/khushi-joshi-05/Food-ordering-website?color=0059b3&#34;&gt;&lt;/a&gt; &amp;nbsp;&lt;/p&gt; &#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Foodie is a food ordering website that aims to provide users with a seamless experience for ordering food online, taking orders for pickup, and booking tables for dining in. The website showcases the quality and specialities of the food offered, along with a variety of services to cater to different user preferences.&lt;/p&gt; &#xA;&lt;p&gt;This repository is aimed to help people to contribute in open source and learn Git and GitHub.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Order Online&lt;/strong&gt;: Users can easily browse through the menu and place orders for delivery.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Take Order&lt;/strong&gt;: Customers can also choose to place orders for pickup.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Book Table&lt;/strong&gt;: For those who prefer dining in, the website offers the option to book a table in advance.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Menu&lt;/strong&gt;: The menu section provides a comprehensive list of food items available for order, along with descriptions and prices.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;App Details&lt;/strong&gt;: Information about any associated mobile applications for easy access to the service.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Contact Page&lt;/strong&gt;: A dedicated contact page for users to reach out for inquiries, feedback, or support.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Technologies Used&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;HTML&lt;/strong&gt;: Markup language for structuring web pages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CSS&lt;/strong&gt;: Styling language for designing the visual layout of web pages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: Programming language for adding interactivity and functionality to web pages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;: Hosting service for publishing the frontend code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development Steps&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Planning and Design&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Defined UI requirements based on user needs and business goals.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTML Structure&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Developed web page structure using HTML elements.&lt;/li&gt; &#xA;   &lt;li&gt;Organized content into logical sections like header, navigation, main content, and footer.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;CSS Styling&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Styled HTML elements to create visually appealing design.&lt;/li&gt; &#xA;   &lt;li&gt;Implemented responsive design for compatibility across various devices.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;JavaScript Interactivity&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Enhanced user interaction with dynamic features like menu filtering and form validation.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Tech Stack&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: HTML, CSS, JavaScript (for user interface and interactivity)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: MongoDB (for storing user data, orders, etc.)~~~~ need to be implemented&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Responsive Design&lt;/strong&gt;: Ensuring compatibility across various devices and screen sizes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to Run Locally&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the project repository:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/khushi-joshi-05/FoodOrderingWebsite.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;2.Navigate to the project directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd FoodOrderingWebsite&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;3.Open the index.html file in your preferred web browser to view the website locally.&lt;/p&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;p&gt;These are some snapshots of the project.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/khushi-joshi-05/Food-ordering-website/main/Images/homepg.png&#34; alt=&#34;Landing Page&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/khushi-joshi-05/Food-ordering-website/main/Images/service.png&#34; alt=&#34;Service&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://choosealicense.com/licenses/mit/&#34;&gt;MIT&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>unclecode/crawl4ai</title>
    <updated>2024-05-12T01:32:52Z</updated>
    <id>tag:github.com,2024-05-12:/unclecode/crawl4ai</id>
    <link href="https://github.com/unclecode/crawl4ai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🔥🕷️ Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scrapper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Crawl4AI 🕷️🤖&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/unclecode/crawl4ai/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/unclecode/crawl4ai?style=social&#34; alt=&#34;GitHub Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/unclecode/crawl4ai?style=social&#34; alt=&#34;GitHub Forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/unclecode/crawl4ai&#34; alt=&#34;GitHub Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/unclecode/crawl4ai&#34; alt=&#34;GitHub Pull Requests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/unclecode/crawl4ai&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Crawl4AI is a powerful, free web crawling service designed to extract useful information from web pages and make it accessible for large language models (LLMs) and AI applications. 🆓🌐&lt;/p&gt; &#xA;&lt;h2&gt;Features ✨&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🕷️ Efficient web crawling to extract valuable data from websites&lt;/li&gt; &#xA; &lt;li&gt;🤖 LLM-friendly output formats (JSON, cleaned HTML, markdown)&lt;/li&gt; &#xA; &lt;li&gt;🌍 Supports crawling multiple URLs simultaneously&lt;/li&gt; &#xA; &lt;li&gt;🌃 Replace media tags with ALT.&lt;/li&gt; &#xA; &lt;li&gt;🆓 Completely free to use and open-source&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started 🚀&lt;/h2&gt; &#xA;&lt;p&gt;To get started with Crawl4AI, simply visit our web application at &lt;a href=&#34;https://crawl4ai.uccode.io&#34;&gt;https://crawl4ai.uccode.io&lt;/a&gt; (Available now!) and enter the URL(s) you want to crawl. The application will process the URLs and provide you with the extracted data in various formats.&lt;/p&gt; &#xA;&lt;h2&gt;Installation 💻&lt;/h2&gt; &#xA;&lt;p&gt;There are two ways to use Crawl4AI: as a library in your Python projects or as a standalone local server.&lt;/p&gt; &#xA;&lt;h3&gt;Using Crawl4AI as a Library 📚&lt;/h3&gt; &#xA;&lt;p&gt;To install Crawl4AI as a library, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install the package from GitHub:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install git+https://github.com/unclecode/crawl4ai.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can clone the repository and install the package locally:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;virtualenv venv&#xA;source venv/bin/activate&#xA;git clone https://github.com/unclecode/crawl4ai.git&#xA;cd crawl4ai&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Import the necessary modules in your Python script:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from crawl4ai.web_crawler import WebCrawler&#xA;from crawl4ai.models import UrlModel&#xA;import os&#xA;&#xA;crawler = WebCrawler(db_path=&#39;crawler_data.db&#39;)&#xA;&#xA;# Single page crawl&#xA;single_url = UrlModel(url=&#39;https://kidocode.com&#39;, forced=False)&#xA;result = crawl4ai.fetch_page(&#xA;    single_url, &#xA;    provider= &#34;openai/gpt-3.5-turbo&#34;, &#xA;    api_token = os.getenv(&#39;OPENAI_API_KEY&#39;),&#xA;    # Set `extract_blocks_flag` to True to enable the LLM to generate semantically clustered chunks&#xA;    # and return them as JSON. Depending on the model and data size, this may take up to 1 minute.&#xA;    # Without this setting, it will take between 5 to 20 seconds.&#xA;    extract_blocks_flag=False &#xA;    word_count_threshold=5 # Minimum word count for a HTML tag to be considered as a worthy block&#xA;)&#xA;print(result.model_dump())&#xA;&#xA;# Multiple page crawl&#xA;urls = [&#xA;    UrlModel(url=&#39;http://example.com&#39;, forced=False),&#xA;    UrlModel(url=&#39;http://example.org&#39;, forced=False)&#xA;]&#xA;results = crawl4ai.fetch_pages(&#xA;    urls, &#xA;    provider= &#34;openai/gpt-3.5-turbo&#34;, &#xA;    api_token = os.getenv(&#39;OPENAI_API_KEY&#39;), &#xA;    extract_blocks_flag=True, &#xA;    word_count_threshold=5&#xA;)&#xA;&#xA;for res in results:&#xA;    print(res.model_dump())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Running for the first time will download the chrome driver for selenium. Also creates a SQLite database file &lt;code&gt;crawler_data.db&lt;/code&gt; in the current directory. This file will store the crawled data for future reference.&lt;/p&gt; &#xA;&lt;p&gt;The response model is a &lt;code&gt;CrawlResponse&lt;/code&gt; object that contains the following attributes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class CrawlResult(BaseModel):&#xA;    url: str&#xA;    html: str&#xA;    success: bool&#xA;    cleaned_html: str = None&#xA;    markdown: str = None&#xA;    parsed_json: str = None&#xA;    error_message: str = None&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running Crawl4AI as a Local Server 🚀&lt;/h3&gt; &#xA;&lt;p&gt;To run Crawl4AI as a standalone local server, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/unclecode/crawl4ai.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Navigate to the project directory:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd crawl4ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Open &lt;code&gt;crawler/config.py&lt;/code&gt; and set your favorite LLM provider and API token.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build the Docker image:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker build -t crawl4ai .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For Mac users, use the following command instead:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker build --platform linux/amd64 -t crawl4ai .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Run the Docker container:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run -d -p 8000:80 crawl4ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Access the application at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CURL Example: Set the api_token to your OpenAI API key or any other provider you are using.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -X POST -H &#34;Content-Type: application/json&#34; -d &#39;{&#34;urls&#34;:[&#34;https://techcrunch.com/&#34;],&#34;provider_model&#34;:&#34;openai/gpt-3.5-turbo&#34;,&#34;api_token&#34;:&#34;your_api_token&#34;,&#34;include_raw_html&#34;:true,&#34;forced&#34;:false,&#34;extract_blocks_flag&#34;:false,&#34;word_count_threshold&#34;:10}&#39; http://localhost:8000/crawl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Set &lt;code&gt;extract_blocks_flag&lt;/code&gt; to True to enable the LLM to generate semantically clustered chunks and return them as JSON. Depending on the model and data size, this may take up to 1 minute. Without this setting, it will take between 5 to 20 seconds.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python Example:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import requests&#xA;import os&#xA;&#xA;url = &#34;http://localhost:8000/crawl&#34;  # Replace with the appropriate server URL&#xA;data = {&#xA;  &#34;urls&#34;: [&#xA;    &#34;https://example.com&#34;&#xA;  ],&#xA;  &#34;provider_model&#34;: &#34;groq/llama3-70b-8192&#34;,&#xA;  &#34;api_token&#34;: &#34;your_api_token&#34;,&#xA;  &#34;include_raw_html&#34;: true,&#xA;  &#34;forced&#34;: false,&#xA;    # Set `extract_blocks_flag` to True to enable the LLM to generate semantically clustered chunks&#xA;    # and return them as JSON. Depending on the model and data size, this may take up to 1 minute.&#xA;    # Without this setting, it will take between 5 to 20 seconds.&#xA;  &#34;extract_blocks_flag&#34;: False,&#xA;  &#34;word_count_threshold&#34;: 5&#xA;}&#xA;&#xA;response = requests.post(url, json=data)&#xA;&#xA;if response.status_code == 200:&#xA;    result = response.json()[&#34;results&#34;][0]&#xA;    print(&#34;Parsed JSON:&#34;)&#xA;    print(result[&#34;parsed_json&#34;])&#xA;    print(&#34;\nCleaned HTML:&#34;)&#xA;    print(result[&#34;cleaned_html&#34;])&#xA;    print(&#34;\nMarkdown:&#34;)&#xA;    print(result[&#34;markdown&#34;])&#xA;else:&#xA;    print(&#34;Error:&#34;, response.status_code, response.text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This code sends a POST request to the Crawl4AI server running on localhost, specifying the target URL (&lt;code&gt;https://example.com&lt;/code&gt;) and the desired options (&lt;code&gt;grq_api_token&lt;/code&gt;, &lt;code&gt;include_raw_html&lt;/code&gt;, and &lt;code&gt;forced&lt;/code&gt;). The server processes the request and returns the crawled data in JSON format.&lt;/p&gt; &#xA;&lt;p&gt;The response from the server includes the parsed JSON, cleaned HTML, and markdown representations of the crawled webpage. You can access and use this data in your Python application as needed.&lt;/p&gt; &#xA;&lt;p&gt;Make sure to replace &lt;code&gt;&#34;http://localhost:8000/crawl&#34;&lt;/code&gt; with the appropriate server URL if your Crawl4AI server is running on a different host or port.&lt;/p&gt; &#xA;&lt;p&gt;Choose the approach that best suits your needs. If you want to integrate Crawl4AI into your existing Python projects, installing it as a library is the way to go. If you prefer to run Crawl4AI as a standalone service and interact with it via API endpoints, running it as a local server using Docker is the recommended approach.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Make sure to check the config.py tp set required environment variables.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;That&#39;s it! You can now integrate Crawl4AI into your Python projects and leverage its web crawling capabilities. 🎉&lt;/p&gt; &#xA;&lt;h2&gt;📖 Parameters&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Parameter&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Required&lt;/th&gt; &#xA;   &lt;th&gt;Default Value&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;urls&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A list of URLs to crawl and extract data from.&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;provider_model&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The provider and model to use for extracting relevant information (e.g., &#34;groq/llama3-70b-8192&#34;).&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;api_token&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Your API token for the specified provider.&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;include_raw_html&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Whether to include the raw HTML content in the response.&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;forced&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Whether to force a fresh crawl even if the URL has been previously crawled.&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;extract_blocks_flag&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Whether to extract semantical blocks of text from the HTML.&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;word_count_threshold&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The minimum number of words a block must contain to be considered meaningful (minimum value is 5).&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;5&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;🛠️ Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Crawl4AI allows you to configure various parameters and settings in the &lt;code&gt;crawler/config.py&lt;/code&gt; file. Here&#39;s an example of how you can adjust the parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;from dotenv import load_dotenv&#xA;&#xA;load_dotenv()  # Load environment variables from .env file&#xA;&#xA;# Default provider&#xA;DEFAULT_PROVIDER = &#34;openai/gpt-4-turbo&#34;&#xA;&#xA;# Provider-model dictionary&#xA;PROVIDER_MODELS = {&#xA;    &#34;groq/llama3-70b-8192&#34;: os.getenv(&#34;GROQ_API_KEY&#34;),&#xA;    &#34;groq/llama3-8b-8192&#34;: os.getenv(&#34;GROQ_API_KEY&#34;),&#xA;    &#34;openai/gpt-3.5-turbo&#34;: os.getenv(&#34;OPENAI_API_KEY&#34;),&#xA;    &#34;openai/gpt-4-turbo&#34;: os.getenv(&#34;OPENAI_API_KEY&#34;),&#xA;    &#34;anthropic/claude-3-haiku-20240307&#34;: os.getenv(&#34;ANTHROPIC_API_KEY&#34;),&#xA;    &#34;anthropic/claude-3-opus-20240229&#34;: os.getenv(&#34;ANTHROPIC_API_KEY&#34;),&#xA;    &#34;anthropic/claude-3-sonnet-20240229&#34;: os.getenv(&#34;ANTHROPIC_API_KEY&#34;),&#xA;}&#xA;&#xA;# Chunk token threshold&#xA;CHUNK_TOKEN_THRESHOLD = 1000&#xA;&#xA;# Threshold for the minimum number of words in an HTML tag to be considered &#xA;MIN_WORD_THRESHOLD = 5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the &lt;code&gt;crawler/config.py&lt;/code&gt; file, you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Set the default provider using the &lt;code&gt;DEFAULT_PROVIDER&lt;/code&gt; variable.&lt;/li&gt; &#xA; &lt;li&gt;Add or modify the provider-model dictionary (&lt;code&gt;PROVIDER_MODELS&lt;/code&gt;) to include your desired providers and their corresponding API keys. Crawl4AI supports various providers such as Groq, OpenAI, Anthropic, and more. You can add any provider supported by LiteLLM, as well as Ollama.&lt;/li&gt; &#xA; &lt;li&gt;Adjust the &lt;code&gt;CHUNK_TOKEN_THRESHOLD&lt;/code&gt; value to control the splitting of web content into chunks for parallel processing. A higher value means fewer chunks and faster processing, but it may cause issues with weaker LLMs during extraction.&lt;/li&gt; &#xA; &lt;li&gt;Modify the &lt;code&gt;MIN_WORD_THRESHOLD&lt;/code&gt; value to set the minimum number of words an HTML tag must contain to be considered a meaningful block.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Make sure to set the appropriate API keys for each provider in the &lt;code&gt;PROVIDER_MODELS&lt;/code&gt; dictionary. You can either directly provide the API key or use environment variables to store them securely.&lt;/p&gt; &#xA;&lt;p&gt;Remember to update the &lt;code&gt;crawler/config.py&lt;/code&gt; file based on your specific requirements and the providers you want to use with Crawl4AI.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing 🤝&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the open-source community to help improve Crawl4AI and make it even more valuable for AI enthusiasts and developers. To contribute, please follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork the repository.&lt;/li&gt; &#xA; &lt;li&gt;Create a new branch for your feature or bug fix.&lt;/li&gt; &#xA; &lt;li&gt;Make your changes and commit them with descriptive messages.&lt;/li&gt; &#xA; &lt;li&gt;Push your changes to your forked repository.&lt;/li&gt; &#xA; &lt;li&gt;Submit a pull request to the main repository.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For more information on contributing, please see our &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/CONTRIBUTING.md&#34;&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License 📄&lt;/h2&gt; &#xA;&lt;p&gt;Crawl4AI is released under the &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/LICENSE&#34;&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact 📧&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, suggestions, or feedback, please feel free to reach out to us:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GitHub: &lt;a href=&#34;https://github.com/unclecode&#34;&gt;unclecode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Twitter: &lt;a href=&#34;https://twitter.com/unclecode&#34;&gt;@unclecode&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Let&#39;s work together to make the web more accessible and useful for AI applications! 💪🌐🤖&lt;/p&gt;</summary>
  </entry>
</feed>