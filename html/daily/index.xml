<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-07T01:34:56Z</updated>
  <subtitle>Daily Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>posgnu/rci-agent</title>
    <updated>2023-04-07T01:34:56Z</updated>
    <id>tag:github.com,2023-04-07:/posgnu/rci-agent</id>
    <link href="https://github.com/posgnu/rci-agent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A codebase for &#34;Language Models can Solve Computer Tasks&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RCI Agent for MiniWoB++&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to the codebase for our paper, &#34;Language Models can Solve Computer Tasks&#34;. In this codebase, you will find the implementation of our RCI agent, which uses a pre-trained language model to execute computer tasks in &lt;a href=&#34;http://miniwob.farama.org/&#34;&gt;MiniWoB++ benchmark&lt;/a&gt; guided by natural language. The agent employs a simple RCI prompting scheme that allows it to improve its outputs.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posgnu/rci-agent/main/artifacts/overview.gif&#34; alt=&#34;overview&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://posgnu.github.io/rci-web/&#34;&gt;[Website]&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2303.17491v1&#34;&gt;[Arxiv Paper]&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/pdf/2303.17491v1.pdf&#34;&gt;[PDF]&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;The RCI agent is implemented in Python 3.9 and requires the following dependencies:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;gym&lt;/li&gt; &#xA; &lt;li&gt;openai&lt;/li&gt; &#xA; &lt;li&gt;selenium&lt;/li&gt; &#xA; &lt;li&gt;Pillow&lt;/li&gt; &#xA; &lt;li&gt;regex&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;p&gt;To run the code, you must first install MiniWoB++ and configure your OpenAI API key. MiniWoB++ is integrated with the OpenAI Gym environment. Navigate to the &lt;code&gt;computergym&lt;/code&gt; directory and execute the following command to install it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd computergym&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once that&#39;s done, you need to write your OpenAI API key in the &lt;code&gt;example_config.json&lt;/code&gt; file, then rename the file to &lt;code&gt;config.json&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Run&lt;/h3&gt; &#xA;&lt;p&gt;To run the code, simply execute the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python main.py --env [TASK NAME] --llm [LLM NAME] --num-episodes [NUM EPISODES] --erci [NUM Explicit RCI] --irci [NUM Implicit RCI] --sgrounding&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here are the arguments you need to specify:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--env&lt;/code&gt;: MiniWoB++ task name&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--llm&lt;/code&gt;: the name of language model. model name and the corresponding API name is specified below.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;chatgpt&lt;/code&gt;: &#34;gpt-3.5-turbo&#34;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;davinci&lt;/code&gt;: &#34;text-davinci-003&#34;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;ada&lt;/code&gt;: &#34;ada&#34;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;babbage&lt;/code&gt;: &#34;babbage&#34;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;curie&lt;/code&gt;: &#34;curie&#34;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;davinci1&lt;/code&gt;: &#34;davinci&#34;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;davinci2&lt;/code&gt;: &#34;text-davinci-002&#34;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--env&lt;/code&gt;: Name of the MiniWoB++ task you want to run. You can see the list of available tasks in &lt;code&gt;available_tasks.txt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--llm&lt;/code&gt;: Name of the language model you want to use. The model name and corresponding API name are specified below:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;chatgpt: &#34;gpt-3.5-turbo&#34;&lt;/li&gt; &#xA;   &lt;li&gt;davinci: &#34;text-davinci-003&#34;&lt;/li&gt; &#xA;   &lt;li&gt;ada: &#34;ada&#34;&lt;/li&gt; &#xA;   &lt;li&gt;babbage: &#34;babbage&#34;&lt;/li&gt; &#xA;   &lt;li&gt;curie: &#34;curie&#34;&lt;/li&gt; &#xA;   &lt;li&gt;davinci1: &#34;davinci&#34;&lt;/li&gt; &#xA;   &lt;li&gt;davinci2: &#34;text-davinci-002&#34;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--num-episodes&lt;/code&gt;: Number of episodes to run the task&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--erci&lt;/code&gt;: The number of explicit RCI loop for an action plan. &lt;code&gt;-1&lt;/code&gt; will remove the action plan sampling.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--irci&lt;/code&gt;: The number of implicit RCI loop for the agent grounding.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--sgrounding&lt;/code&gt;: If this is True, then the state grounding update is enabled.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--headless&lt;/code&gt;: If this is True, then the MiniWoB++ environment will run in headless mode.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Consider running the following command to verify if everything is functioning correctly:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python main.py --env choose-list --llm chatgpt --num-episodes 1 --irci 1 --sgrounding&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;Our project&#39;s approach has yielded impressive results, with our agent achieving the second-highest score out of all tested models. We have observed that our agent outperforms the baselines, with the exception of CC-Net (SL + RL), which uses dictionary-based typing actions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posgnu/rci-agent/main/artifacts/baseline-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;What sets our RCI agent apart is that it accomplished this feat using 120 times fewer samples than WebN-T5-3B and 11,000 times fewer samples than CC-Net. Obtaining expert demonstrations and defining reward functions for computer tasks can be a daunting challenge, but our research highlights the potential of using LLMs to overcome these obstacles and achieve success in general computer tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/posgnu/rci-agent/main/artifacts/demos-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Check out our paper!&lt;/h2&gt; &#xA;&lt;p&gt;Our paper is available on &lt;a href=&#34;https://arxiv.org/abs/2303.17491v1&#34;&gt;Arxiv&lt;/a&gt;. If you use this code in your research, we kindly ask that you cite our paper.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{kim2023language,&#xA;      title={Language Models can Solve Computer Tasks}, &#xA;      author={Geunwoo Kim and Pierre Baldi and Stephen McAleer},&#xA;      journal={arXiv preprint arXiv:2303.17491},&#xA;      year={2023},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>codingstella/vCard-personal-portfolio</title>
    <updated>2023-04-07T01:34:56Z</updated>
    <id>tag:github.com,2023-04-07:/codingstella/vCard-personal-portfolio</id>
    <link href="https://github.com/codingstella/vCard-personal-portfolio" rel="alternate"></link>
    <summary type="html">&lt;p&gt;vCard is a fully responsive personal portfolio website, responsive for all devices.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;vCard - Personal portfolio&lt;/h1&gt; &#xA; &lt;p&gt;vCard is a fully responsive personal portfolio website, responsive for all devices, built using HTML, CSS, and JavaScript.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://codingstella.github.io/Gaming-website/&#34;&gt;&lt;strong&gt;âž¥ Live Demo&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/codingstella/vCard-personal-portfolio/main/website-demo-image/desktop.png&#34; alt=&#34;vCard Desktop Demo&#34; title=&#34;Desktop Demo&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/codingstella/vCard-personal-portfolio/main/website-demo-image/mobile.png&#34; alt=&#34;vCard Mobile Demo&#34; title=&#34;Mobile Demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is &lt;strong&gt;free to use&lt;/strong&gt; and does not contains any license.&lt;/p&gt;</summary>
  </entry>
</feed>