<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub HTML Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-21T01:31:49Z</updated>
  <subtitle>Daily Trending of HTML in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>JuergenFleiss/aTrain</title>
    <updated>2025-05-21T01:31:49Z</updated>
    <id>tag:github.com,2025-05-21:/JuergenFleiss/aTrain</id>
    <link href="https://github.com/JuergenFleiss/aTrain" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A GUI tool for offline transcription of speech recordings, including speaker diarization, utilizing state-of-the-art machine learning models.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://github.com/BANDAS-Center/aTrain/raw/main/docs/images/logo.svg?sanitize=true&#34; width=&#34;300&#34; alt=&#34;Logo&#34;&gt; &#xA;&lt;h2&gt;Accessible Transcription of Interviews&lt;/h2&gt; &#xA;&lt;p&gt;aTrain is a tool for automatically transcribing speech recordings utilizing state-of-the-art machine learning models without uploading any data. It was developed by researchers at the Business Analytics and Data Science-Center at the University of Graz and tested by researchers from the Know-Center Graz.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Windows (10 and 11)&lt;/strong&gt; users can install aTrain via the Microsoft app store (&lt;a href=&#34;https://apps.microsoft.com/store/detail/atrain/9N15Q44SZNS2&#34;&gt;Link&lt;/a&gt;) or by downloading the installer from the BANDAS-Center Website (&lt;a href=&#34;https://business-analytics.uni-graz.at/de/forschen/atrain/download/&#34;&gt;Link&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Beta Versions available for &lt;strong&gt;MacOS (Apple Silicon)&lt;/strong&gt; and &lt;strong&gt;Debian&lt;/strong&gt; &lt;a href=&#34;https://business-analytics.uni-graz.at/en/research/atrain/download/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Cite the published paper if you used aTrain for your research: &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S2214635024000066&#34;&gt;Take the aTrain. Introducing an Interface for the Accessible Transcription of Interviews.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Becoming a developer&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://github.com/JuergenFleiss/aTrain/wiki/Development:-Branching,-contributing-and-releases&#34;&gt;Developer wiki page&lt;/a&gt; for the details on how to contribute to the project and other useful information for developers.&lt;/p&gt; &#xA;&lt;h2&gt;About aTrain&lt;/h2&gt; &#xA;&lt;p&gt;aTrain offers the following benefits: &lt;br&gt; &lt;br&gt; &lt;strong&gt;Fast and accurate üöÄ&lt;/strong&gt; &lt;br&gt; aTrain provides a user friendly access to the &lt;a href=&#34;https://github.com/guillaumekln/faster-whisper&#34;&gt;faster-whisper&lt;/a&gt; implementation of OpenAI‚Äôs &lt;a href=&#34;https://github.com/openai/whisper&#34;&gt;Whisper model&lt;/a&gt;, ensuring best in class transcription quality (see &lt;a href=&#34;https://www.static.tu.berlin/fileadmin/www/10005401/Publikationen_sos/Wollin-Giering_et_al_2023_Automatic_transcription.pdf&#34;&gt;Wollin-Geiring et al. 2023&lt;/a&gt;) paired with higher speeds on your local computer. Transcription when selecting the highest-quality model takes only around three times the audio length on current mobile CPUs typically found in middle-class business notebooks (e.g., Core i5 12th Gen, Ryzen Series 6000). &lt;br&gt; &lt;br&gt; &lt;strong&gt;Speaker detection üó£Ô∏è&lt;/strong&gt; &lt;br&gt; aTrain has a speaker detection mode based on &lt;a href=&#34;https://github.com/pyannote/pyannote-audio&#34;&gt;pyannote.audio&lt;/a&gt; and can analyze each text segment to determine which speaker it belongs to. &lt;br&gt; &lt;br&gt; &lt;strong&gt;Privacy Preservation and GDPR compliance üîí&lt;/strong&gt; &lt;br&gt; aTrain processes the provided speech recordings completely offline on your own device and does not send recordings or transcriptions to the internet. This helps researchers to maintain data privacy requirements arising from ethical guidelines or to comply with legal requirements such as the GDPR. &lt;br&gt; &lt;br&gt; &lt;strong&gt;Multi-language support üåç&lt;/strong&gt; &lt;br&gt; aTrain-core can process speech recordings a total of 99 languages, including Afrikaans, Arabic, Armenian, Azerbaijani, Belarusian, Bosnian, Bulgarian, Catalan, Chinese, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, Galician, German, Greek, Hebrew, Hindi, Hungarian, Icelandic, Indonesian, Italian, Japanese, Kannada, Kazakh, Korean, Latvian, Lithuanian, Macedonian, Malay, Marathi, Maori, Nepali, Norwegian, Persian, Polish, Portuguese, Romanian, Russian, Serbian, Slovak, Slovenian, Spanish, Swahili, Swedish, Tagalog, Tamil, Thai, Turkish, Ukrainian, Urdu, Vietnamese, and Welsh. A full list can be found &lt;a href=&#34;https://github.com/openai/whisper/raw/main/whisper/tokenizer.py&#34;&gt;here&lt;/a&gt;. Note that transcription quality varies with language; word error rates for the different languages can be found &lt;a href=&#34;https://github.com/openai/whisper?tab=readme-ov-file#available-models-and-languages&#34;&gt;here&lt;/a&gt;. &lt;br&gt; &lt;br&gt; &lt;strong&gt;MAXQDA, ATLAS.ti and nVivo compatible output üìÑ&lt;/strong&gt; &lt;br&gt; aTrain-core provides transcription files that are seamlessly importable into the most popular tools for qualitative analysis, ATLAS.ti, MAXQDA and nVivo. This allows you to directly play audio for the corresponding text segment by clicking on its timestamp. Go to the &lt;a href=&#34;https://github.com/BANDAS-Center/aTrain/wiki/Tutorials&#34;&gt;tutorial&lt;/a&gt; for MAXQDA. &lt;br&gt; &lt;br&gt; &lt;strong&gt;Nvidia GPU support üñ•Ô∏è&lt;/strong&gt; &lt;br&gt; aTrain can either run on the CPU or an NVIDIA GPU (CUDA toolkit installation required). A &lt;a href=&#34;https://developer.nvidia.com/cuda-gpus&#34;&gt;CUDA-enabled NVIDIA GPU&lt;/a&gt; significantly improves the speed of transcriptions and speaker detection, reducing transcription time to 20% of audio length on current entry-level gaming notebooks.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Screenshot 1&lt;/th&gt; &#xA;   &lt;th&gt;Screenshot 2&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JuergenFleiss/aTrain/main/docs/images/screenshot_1.webp&#34; alt=&#34;Screenshot1&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JuergenFleiss/aTrain/main/docs/images/screenshot_2.webp&#34; alt=&#34;Screenshot2&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;For testing the processing time of aTrain-core we transcribe a &lt;a href=&#34;https://www.youtube.com/watch?v=kd7e3OXkajY&#34;&gt;conversation between Christine Lagarde and Andrea Enria at the Fifth ECB Forum on Banking Supervision 2023&lt;/a&gt; published on YouTube by the European Central Bank under a Creative Commons license , downloaded as 320p MP4 video file. The file has a duration of exactly 22 minutes and was transcribed on different computing devices with speaker detection enabled. The figure below shows the processing time of each transcription.&lt;/p&gt; &#xA;&lt;p&gt;Transcription Time (incl. speaker detection) for 00:22:00 File:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Computing Device&lt;/th&gt; &#xA;   &lt;th&gt;large-v3&lt;/th&gt; &#xA;   &lt;th&gt;Distil large-v3&lt;/th&gt; &#xA;   &lt;th&gt;large-v3-turbo&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPU: Ryzen 6850U&lt;/td&gt; &#xA;   &lt;td&gt;00:26:12&lt;/td&gt; &#xA;   &lt;td&gt;00:13:30&lt;/td&gt; &#xA;   &lt;td&gt;00:18:30&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPU: Apple M1&lt;/td&gt; &#xA;   &lt;td&gt;00:33:15&lt;/td&gt; &#xA;   &lt;td&gt;00:21:40&lt;/td&gt; &#xA;   &lt;td&gt;00:??:??&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPU: Intel i9-10940X&lt;/td&gt; &#xA;   &lt;td&gt;00:10:25&lt;/td&gt; &#xA;   &lt;td&gt;00:04:36&lt;/td&gt; &#xA;   &lt;td&gt;00:??:??&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPU: Intel i7-8750H&lt;/td&gt; &#xA;   &lt;td&gt;00:??:??&lt;/td&gt; &#xA;   &lt;td&gt;00:??:??&lt;/td&gt; &#xA;   &lt;td&gt;00:19:16&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPU: RTX 2080 Ti&lt;/td&gt; &#xA;   &lt;td&gt;00:01:44&lt;/td&gt; &#xA;   &lt;td&gt;00:01:06&lt;/td&gt; &#xA;   &lt;td&gt;00:??:??&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPU: RTX 2070 Max-Q&lt;/td&gt; &#xA;   &lt;td&gt;00:05:59&lt;/td&gt; &#xA;   &lt;td&gt;00:??:??&lt;/td&gt; &#xA;   &lt;td&gt;00:04:37&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Roadmap and Upcoming Features&lt;/h2&gt; &#xA;&lt;p&gt;Planned in the near future.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Batch Processing, allowing to have files queued for transcription&lt;/li&gt; &#xA; &lt;li&gt;Add options for more verbatim output&lt;/li&gt; &#xA; &lt;li&gt;Make adding custom models more easy&lt;/li&gt; &#xA; &lt;li&gt;Stable Debian and MacOS installers&lt;/li&gt; &#xA; &lt;li&gt;Somehow getting that snap package to work&lt;/li&gt; &#xA; &lt;li&gt;Customization of output naming&lt;/li&gt; &#xA; &lt;li&gt;Allowing users to setting the output directory&lt;/li&gt; &#xA; &lt;li&gt;Allow for saving settings and defaults (currently resets after each transcription)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Attribution&lt;/h2&gt; &#xA;&lt;p&gt;The GIFs and Icons in aTrain are from &lt;a href=&#34;https://tenor.com/&#34;&gt;tenor&lt;/a&gt; and &lt;a href=&#34;https://www.flaticon.com/&#34;&gt;flaticon&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>