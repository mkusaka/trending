<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Shell Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-27T01:44:06Z</updated>
  <subtitle>Daily Trending of Shell in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>PR3SIDENT/enshrouded-server</title>
    <updated>2024-01-27T01:44:06Z</updated>
    <id>tag:github.com,2024-01-27:/PR3SIDENT/enshrouded-server</id>
    <link href="https://github.com/PR3SIDENT/enshrouded-server" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A repository of guides, files and settings for self-hosting the game Enshrouded.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Enshrouded Community Hosting Resources&lt;/h1&gt; &#xA;&lt;p&gt;This repository serves as a guide for anyone looking to host their own Enshrouded server. It may link to other projects, repos, guides, etc.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d like to rent a server from a provider, &lt;a href=&#34;https://github.com/PR3SIDENT/enshrouded-server/raw/main/Hosting%20Providers/hosting-providers.md&#34;&gt;we are also maintaining a list of those here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Official Server Guide (By Keen Games)&lt;/h1&gt; &#xA;&lt;p&gt;This contains server specs, FAQ, installation instructions, and beyond...&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://enshrouded.zendesk.com/hc/en-us/sections/16050842957085-Multiplayer-and-Server-Hosting&#34;&gt;https://enshrouded.zendesk.com/hc/en-us/sections/16050842957085-Multiplayer-and-Server-Hosting&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;SteamCMD&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/XG8Hyk1PC70?si=0W_6NXf7M7HALxsn&#34;&gt;TroubleChute&#39;s SteamCMD Install Guide&lt;/a&gt; (Video)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.tcno.co/games/enshrouded/dedicated_server/&#34;&gt;TrobleChute&#39;s SteamCMD Install Guide&lt;/a&gt; (Written/Text)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Docker&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Docker is a set of platform as a service products that use OS-level virtualization to deliver software in packages called containers. The service has both free and premium tiers. The software that hosts the containers is called Docker Engine&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PR3SIDENT/enshrouded-server/raw/main/DockerResources&#34;&gt;DrSh4d0w&#39;s Container&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jsknnr/enshrouded-server&#34;&gt;Sknnr&#39;s Container&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.docker.com/r/mornedhels/enshrouded-server&#34;&gt;Mornedhels Container&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Pterodactyl&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;PterodactylÂ® is a free, open-source game server management panel built with PHP, React, and Go. Designed with security in mind, Pterodactyl runs all game servers in isolated Docker containers while exposing a beautiful and intuitive UI to end users.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gOOvER/own-pterodactyl-eggs/tree/main/steamcmd/enshrouded&#34;&gt;gOOvER&#39;s Eggs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/parkervcp/eggs/tree/master/game_eggs/steamcmd_servers/enshrouded&#34;&gt;Parker&#39;s Eggs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;WindowsGSM&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;WindowsGSM is a powerful tool to manage game servers. Equipped with a GUI for server admins to install, import, start, stop, restart, update, and automate multiple servers with a push of a button.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ohmcodes/WindowsGSM.Enshrouded&#34;&gt;WindowsGSM.Enshrouded&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;GameServerApp.com&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;GSA is a hosted (SaaS) auto-pilot for game servers that has automation, monetization, collaboration and admin tools baked in. Supports Enshrouded natively on Windows Docker containers, for optimal performance &amp;amp; security.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gameserverapp.com/connect/dediconnect&#34;&gt;How to connect &amp;gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;AMP&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;AMP (Application Management Panel) is a simple to use, self-hosted web control panel for game servers that runs on both Windows and Linux systems with a focus on ease of use through its intuitive user interface and simple setup process.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The plugin has been merged into the main repo... Users just have to Fetch Latest under Instance Deployment, and Enshrouded will appear in the dropdown when they go to create an instance.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Windows Applications&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ISpaikI/Enshrouded-Server-Manager&#34;&gt;Spaik&#39;s Server Manager&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TBD (In-Development)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Linux - InstallServer.sh&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The script present here is an automated script to install the server,components and create a service so it can be managed more easier. Make it executable with &lt;code&gt;chmod +x InstallServer.sh&lt;/code&gt; and run it.&lt;br&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; Script tested on Ubuntu 22.04 (not sure that will work on older versions and alternatives distros)</summary>
  </entry>
  <entry>
    <title>jsknnr/enshrouded-server</title>
    <updated>2024-01-27T01:44:06Z</updated>
    <id>tag:github.com,2024-01-27:/jsknnr/enshrouded-server</id>
    <link href="https://github.com/jsknnr/enshrouded-server" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Run Enshrouded dedicated server in a container&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;enshrouded-server&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/sknnr/enshrouded-dedicated-server&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DockerHub-blue&#34; alt=&#34;Static Badge&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/sknnr/enshrouded-dedicated-server&#34; alt=&#34;Docker Pulls&#34;&gt; &lt;a href=&#34;https://github.com/jsknnr/enshrouded-server&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-green&#34; alt=&#34;Static Badge&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/stars/jsknnr/enshrouded-server&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Run Enshrouded dedicated server in a container. Optionally includes helm chart for running in Kubernetes.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; This is not an official image. No support, implied or otherwise is offered to any end user by the author or anyone else. Feel free to do what you please with the contents of this repo.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;The processes within the container do &lt;strong&gt;NOT&lt;/strong&gt; run as root. Everything runs as the user steam (gid:10000/uid:10000 by default). If you exec into the container, you will drop into &lt;code&gt;/home/steam&lt;/code&gt; as the steam user. Enshrouded will be installed to &lt;code&gt;/home/steam/enshrouded&lt;/code&gt;. Any persistent volumes should be mounted to &lt;code&gt;/home/steam/enshrouded/savegame&lt;/code&gt; and be owned by 10000:10000.&lt;/p&gt; &#xA;&lt;p&gt;In all of the examples below the image tag is set to &lt;code&gt;v2.0.4&lt;/code&gt; which is the current latest release. I will update the examples each time I cut a new release. This is to avoid forcing potentially breaking changes if your tag is set to &lt;code&gt;latest&lt;/code&gt; and you always pull. Please review my release notes for each version between your current and your target before upgrading.&lt;/p&gt; &#xA;&lt;h3&gt;Ports&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Port&lt;/th&gt; &#xA;   &lt;th&gt;Protocol&lt;/th&gt; &#xA;   &lt;th&gt;Default&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Game Port&lt;/td&gt; &#xA;   &lt;td&gt;UDP&lt;/td&gt; &#xA;   &lt;td&gt;15636&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Query Port&lt;/td&gt; &#xA;   &lt;td&gt;UDP&lt;/td&gt; &#xA;   &lt;td&gt;15637&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Environment Variables&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Default&lt;/th&gt; &#xA;   &lt;th&gt;Required&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SERVER_NAME&lt;/td&gt; &#xA;   &lt;td&gt;Name for the Server&lt;/td&gt; &#xA;   &lt;td&gt;Enshrouded Containerized&lt;/td&gt; &#xA;   &lt;td&gt;False&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SERVER_PASSWORD&lt;/td&gt; &#xA;   &lt;td&gt;Password for the server&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;   &lt;td&gt;True&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GAME_PORT&lt;/td&gt; &#xA;   &lt;td&gt;Port for server connections&lt;/td&gt; &#xA;   &lt;td&gt;15636&lt;/td&gt; &#xA;   &lt;td&gt;False&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QUERY_PORT&lt;/td&gt; &#xA;   &lt;td&gt;Port for steam query of server&lt;/td&gt; &#xA;   &lt;td&gt;15637&lt;/td&gt; &#xA;   &lt;td&gt;False&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SERVER_SLOTS&lt;/td&gt; &#xA;   &lt;td&gt;Number of slots for connections (Max 16)&lt;/td&gt; &#xA;   &lt;td&gt;16&lt;/td&gt; &#xA;   &lt;td&gt;False&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SERVER_IP&lt;/td&gt; &#xA;   &lt;td&gt;IP address for server to listen on&lt;/td&gt; &#xA;   &lt;td&gt;0.0.0.0&lt;/td&gt; &#xA;   &lt;td&gt;False&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; SERVER_IP is ignored if using Helm because that isn&#39;t how Kubernetes works.&lt;/p&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;To run the container in Docker, run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker volume create enshrouded-persistent-data&#xA;docker run \&#xA;  --detach \&#xA;  --name enshrouded-server \&#xA;  --mount type=volume,source=enshrouded-persistent-data,target=/home/steam/enshrouded/savegame \&#xA;  --publish 15636:15636/udp \&#xA;  --publish 15637:15637/udp \&#xA;  --env=SERVER_NAME=&#39;Enshrouded Containerized Server&#39; \&#xA;  --env=SERVER_SLOTS=16 \&#xA;  --env=SERVER_PASSWORD=&#39;ChangeThisPlease&#39; \&#xA;  --env=GAME_PORT=15636 \&#xA;  --env=QUERY_PORT=15637 \&#xA;  sknnr/enshrouded-dedicated-server:v2.0.4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker Compose&lt;/h3&gt; &#xA;&lt;p&gt;To use Docker Compose, either clone this repo or copy the &lt;code&gt;compose.yaml&lt;/code&gt; and the &lt;code&gt;default.env&lt;/code&gt; file out of the &lt;code&gt;container&lt;/code&gt; directory to your local machine. Edit the &lt;code&gt;default.env&lt;/code&gt; file to change the environment variables to the values you desire and then save the changes. You should only need to edit the &lt;code&gt;compose.yaml&lt;/code&gt; if you intend to change the game and query port. Once you have made your changes, from the same directory that contains the compose and the env files, simply run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To bring the container down:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose down&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;compose.yaml file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;services:&#xA;  enshrouded:&#xA;    image: sknnr/enshrouded-dedicated-server:v2.0.4&#xA;    ports:&#xA;      - &#34;15636:15636/udp&#34;&#xA;      - &#34;15637:15637/udp&#34;&#xA;    env_file:&#xA;      - default.env&#xA;    volumes:&#xA;      - enshrouded-persistent-data:/home/steam/enshrouded/savegame&#xA;&#xA;volumes:&#xA;  enshrouded-persistent-data:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;default.env file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SERVER_NAME=Enshrouded Containerized&#xA;SERVER_PASSWORD=PleaseChangeMe&#xA;GAME_PORT=15636&#xA;QUERY_PORT=15637&#xA;SERVER_SLOTS=16&#xA;SERVER_IP=0.0.0.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Podman&lt;/h3&gt; &#xA;&lt;p&gt;To run the container in Podman, run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;podman volume create enshrouded-persistent-data&#xA;podman run \&#xA;  --detach \&#xA;  --name enshrouded-server \&#xA;  --mount type=volume,source=enshrouded-persistent-data,target=/home/steam/enshrouded/savegame \&#xA;  --publish 15636:15636/udp \&#xA;  --publish 15637:15637/udp \&#xA;  --env=SERVER_NAME=&#39;Enshrouded Containerized Server&#39; \&#xA;  --env=SERVER_SLOTS=16 \&#xA;  --env=SERVER_PASSWORD=&#39;ChangeThisPlease&#39; \&#xA;  --env=GAME_PORT=15636 \&#xA;  --env=QUERY_PORT=15637 \&#xA;  docker.io/sknnr/enshrouded-dedicated-server:v2.0.4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Kubernetes&lt;/h3&gt; &#xA;&lt;p&gt;I&#39;ve built a Helm chart and have included it in the &lt;code&gt;helm&lt;/code&gt; directory within this repo. Modify the &lt;code&gt;values.yaml&lt;/code&gt; file to your liking and install the chart into your cluster. Be sure to create and specify a namespace as I did not include a template for provisioning a namespace.&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;h3&gt;Connectivity&lt;/h3&gt; &#xA;&lt;p&gt;If you are having issues connecting to the server once the container is deployed, I promise the issue is not with this image. You need to make sure that the ports 15636 and 15637 (or whichever ones you decide to use) are open on your router as well as the container host where this container image is running. You will also have to port-forward the game-port and query-port from your router to the private IP address of the container host where this image is running. After this has been done correctly and you are still experiencing issues, your internet service provider (ISP) may be blocking the ports and you should contact them to troubleshoot.&lt;/p&gt; &#xA;&lt;p&gt;For additional help, refer to this closed issue where some folks were able to debug their issues. It may be of help. &lt;br&gt; &lt;a href=&#34;https://github.com/jsknnr/enshrouded-server/issues/16&#34;&gt;https://github.com/jsknnr/enshrouded-server/issues/16&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Storage&lt;/h3&gt; &#xA;&lt;p&gt;I recommend having Docker or Podman manage the volume that gets mounted into the container. However, if you absolutely must bind mount a directory into the container you need to make sure that on your container host the directory you are bind mounting is owned by 10000:10000 by default (&lt;code&gt;chown -R 10000:10000 /path/to/directory&lt;/code&gt;). If the ownership of the directory is not correct the container will not start as the server will be unable to persist the savegame.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jkool702/forkrun</title>
    <updated>2024-01-27T01:44:06Z</updated>
    <id>tag:github.com,2024-01-27:/jkool702/forkrun</id>
    <link href="https://github.com/jkool702/forkrun" rel="alternate"></link>
    <summary type="html">&lt;p&gt;runs multiple inputs through a script/function in parallel using bash coprocs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FORKRUN&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;forkrun&lt;/code&gt; is a pure-bash function for parallelizing loops in much the same way that &lt;code&gt;xargs&lt;/code&gt; or &lt;code&gt;parallel&lt;/code&gt; does, only faster than either (especially parallel) (see the &lt;code&gt;hyperfine_benchmark&lt;/code&gt; subdirectory for benchmarks showing this). In my testing, &lt;code&gt;forkrun&lt;/code&gt; was, on average (for problems where the efficiency of the parallelization framework actually makes a difference) ~20% faster to twice as fast versus &lt;code&gt;xargs -P $(nproc)&lt;/code&gt;; and ~2x to ~8x as fast versus &lt;code&gt;parallel -m&lt;/code&gt;. To be clear: these are the &#34;fast&#34; invocations of xargs and parallel. If you were to compare the &#34;1 line at a time&#34; version of all 3 (&lt;code&gt;forkrun -l1&lt;/code&gt;, &lt;code&gt;xargs -P $(nproc) -L 1&lt;/code&gt;, &lt;code&gt;parallel -j $(nprooc)&lt;/code&gt;), &lt;code&gt;forkrun&lt;/code&gt; is 7-10x as fast as &lt;code&gt;xargs&lt;/code&gt; and 20-30x as fast as &lt;code&gt;parallel&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;USAGE&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;forkrun&lt;/code&gt; in invoked in much the same way as &lt;code&gt;xargs&lt;/code&gt;: on the command-line, pass forkrun options, then the function/script/binary that you are parallelizing, then any initial constant arguments (in that order). The arguments to parallelize running are passed to forkrun on stdin. A typical &lt;code&gt;forkrun&lt;/code&gt; invocation looks something like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;printf &#39;%s\n&#39; &#34;${inArgs[@]}&#34; | forkrun [flags] [--] parFunc [&#34;${initialArgs[@]}&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;forkrun&lt;/code&gt; strives to automatically choose reasonable and near-optimal values for flags, so in most usage scenarios no flags will need to be set to attain maximum performance and speed.&lt;/p&gt; &#xA;&lt;p&gt;NOTE: you&#39;ll need to &lt;code&gt;source&lt;/code&gt; forkrun before using it&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;source /path/to/forkrun.bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternately, if you dont have &lt;code&gt;forkrun.bash&lt;/code&gt; saved locally but have internet access (or want to ensure you are using the latest version), you can run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;source &amp;lt;(curl https://raw.githubusercontent.com/jkool702/forkrun/main/forkrun.bash)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, for those (understandably) concerned with directly sourcing unseen code from the internet, you can use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;source &amp;lt;(echo &#39;shopt -s extglob&#39;; ( cd /proc/self/fd; decfun=&#39;forkrun forkrun_displayHelp &#39;; type -p cat &amp;amp;&amp;gt;/dev/null || decfun+=&#39;cat &#39;; type -p mktemp &amp;amp;&amp;gt;/dev/null || decfun+=&#39;mktemp &#39;; shopt -s extglob; curl=&#34;$(type -p curl)&#34;; bash=&#34;$(type -p bash)&#34;; PATH=&#39;&#39;; { $curl https://raw.githubusercontent.com/jkool702/forkrun/main/forkrun.bash; echo &#39;declare -f &#39;&#34;$decfun&#34;; } | $bash -r ) )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;HELP&lt;/strong&gt;: the &lt;code&gt;forkrun.bash&lt;/code&gt; script, when sourced, will source a helper function (&lt;code&gt;forkrun_displayHelp&lt;/code&gt;) to display help. This is activated by calling one of the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;--usage              :  display brief usage info&#xA;-? | -h | --help     :  dispay standard help (includes brief descriptions + short names for flags)&#xA;--help=s[hort]       :  more detailed varient of &#39;--usage&#39;&#xA;--help=f[lags]       :  display detailed info about flags (longer descriptions, short + long names)&#xA;--help=a[ll]         :  display all help (includes detailed descriptions for flags)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;NOTE: text inside of the brackets &lt;code&gt;[...]&lt;/code&gt; is optional. NOTE: &lt;code&gt;forkrun -?&lt;/code&gt; may not work unless you escape the &lt;code&gt;?&lt;/code&gt;. i.e., &lt;code&gt;forkrun -\?&lt;/code&gt; or &lt;code&gt;forkrun &#39;-?&#39;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;HOW IT WORKS&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;BASH COPROCS&lt;/strong&gt;: &lt;code&gt;forkrun&lt;/code&gt; parallelizes loops by running multiple inputs through a script/function in parallel using bash coprocs. &lt;code&gt;forkrun&lt;/code&gt; is fundamentally different than most existing loop parallelization codes in the sense that individual function evaluations are not forked. Rather, initially, a number of persistent bash coprocs are forked, and then inputs (passed on stdin) are distributed to these coprocs without any additional forking (or reopening pipes/fd&#39;s, or...). In other words, you &lt;strong&gt;FORK&lt;/strong&gt; [coprocs], then you &lt;strong&gt;RUN&lt;/strong&gt;. This, combined with the (almost) exclusive use of bash builtins as well as being &lt;em&gt;heavily&lt;/em&gt; optimized, is what makes &lt;code&gt;forkrun&lt;/code&gt; so fast.&lt;/p&gt; &#xA;&lt;p&gt;Coproc workers read data (via &lt;code&gt;mapfile&lt;/code&gt;) using a shared file descriptor, keeping them all &#34;in sync&#34; and allowing workers to read data &#34;on demand&#34; without any buffers. This necessitates only allowing 1 worker to read data at a time, but has the benefit of avoiding the CPU overhead of, the potential bottleneck (especially on high-core count systems) from, and the need to buffer inputs due to having a separate process explicitly distribute stdin to the worker coprocs. Typically a &#34;helper&#34; coproc saves stdin to a tmpfs temp file (under &lt;code&gt;/dev/shm&lt;/code&gt;) and workers read from the tmpfile (avoiding the &#34;read 1 byte at a time from pipes&#34; issue); but, depending on the flags passed to &lt;code&gt;forkrun&lt;/code&gt;, the &#34;workers&#34; can also read data directly from the stdin pipe.&lt;/p&gt; &#xA;&lt;p&gt;Compared to the traditional approach, &lt;code&gt;forkrun&lt;/code&gt;&#39;s approach allows for much better use of multiple CPU cores in parallel, since nearly every task can be run in parallel. The traditional &#34;forking every function call&#34; method, on the other hand, can be implemented such that is takes slightly fewer total CPU cycles, but that comes at the cost of having most of the CPU cores waiting while the main thread is setting up for / cleaning up after the forked function call. To be clear here, I am referring to forking in a lower-level language like C...forking in bash is horribly slow and inefficient, and any pure-bash loop parallelizer that forks every function call will take orders of magnitude more time and CPU cycle to run.&lt;/p&gt; &#xA;&lt;p&gt;To give a real-life data point: on my test rig that has a 14C/28T i9-7940x CPU, &lt;code&gt;perf&lt;/code&gt; consistently tells me that for sufficiently large problems, &lt;code&gt;forkrun&lt;/code&gt; is (averaged over its entire runtime) fully utilizing between 19-20 cores. Considering that the machine only has 14 &#34;real&#34; cores and that28 threads running on 14 hyperthreaded cores will never be as capable as 28 threads running on 28 &#34;real&#34; non-hyperthreaded cores, doing (on average) nearly 20 cores worth of work is about as good as it gets.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;AUTOMATIC BATCH SIZE ADJUSTMENT&lt;/strong&gt;: by default, &lt;code&gt;forkrun&lt;/code&gt; will automatically dynamically adjust how many lines are passed to the function each time it is called (batch size). The batch size starts at 1, and is dynamically adjusted upwards (but never downwards) up to a maximum of 512 lines per batch (which is typically near-optimal in my personal trial-and-error testing). The logic used here involves:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Calculating the average bytes/line by looking number of lines read and the number of bytes read (from &lt;code&gt;/proc/self/fdinfo/$fd&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Estimating the number of remaining lines left to read by getting the difference in the number of bytes read/written and dividing by the average bytes/line&lt;/li&gt; &#xA; &lt;li&gt;dividing the estimated number of remaining lines by the number of worker coprocs&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;NOTE: this is a &#34;maximum lines per batch&#34; (implemented via &lt;code&gt;mapfile -n ${nLines}&lt;/code&gt;)...if stdin is arriving slowly then fewer than this many lines will be used. What this serves to accomplish is to prevent a couple of coproc workers from claiming all the lines of input while the rest sit idle if the total number of lines is less than &lt;code&gt;512 * (# worker coprocs)&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;To overrule this logic and set a static batch size use the &#39;-l&#39; flag. Alternately, use the &lt;code&gt;-L&lt;/code&gt; flag to keep the automatic batch size logic enabled but to change the initial and maximum number of lines per batch.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;IPC&lt;/strong&gt;: Forkrun distributes stdin to the worker coprocs by first saving them to a tmpfile (by default on a tmpfs -- in a directory under &lt;code&gt;/dev/shm&lt;/code&gt;; customizable with the &lt;code&gt;-t&lt;/code&gt; flag) using a forked coproc. The worker coprocs then read data from this file into an array (using &lt;code&gt;mapfile&lt;/code&gt;) using a shared read-only file descriptor and an exclusive read lock.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;NO FUNCTION MODE&lt;/strong&gt;: forkrun supports an additional mode of operation where &lt;code&gt;parFunc&lt;/code&gt; and &lt;code&gt;initialArgs&lt;/code&gt; are not given as function inputs, but instead are integrated into each line of &lt;code&gt;args&lt;/code&gt;. In this mode, each line passed on stin will be run as-is (by saving groups of 512 lines to tmp files and then sourcing them). This allows you to easily run multiple different functions/scripts/binaries in paralel and still utalize forkrun&#39;s very quick and efficient parallelization method. To activate this mode, use flag &lt;code&gt;-N&lt;/code&gt; and do not provide &lt;code&gt;parFunc&lt;/code&gt; or &lt;code&gt;initialArgs&lt;/code&gt;. This is implemented via &lt;code&gt;source &amp;lt;(printf &#39;%s\n&#39; &#34;${args[@]}&#34;)&lt;/code&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;DEPENDENCIES&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;forkrun&lt;/code&gt; strives to rely on as few external dependencies as possible. It is &lt;em&gt;almost&lt;/em&gt; pure-bash, though does have a handful of [optional] external dependencies:&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;REQUIRED DEPENDENCIES&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Bash 4+ : This is when coprocs were added. NOTE: &lt;code&gt;forkrun&lt;/code&gt; will be much faster on bash 5.1+, since it healivy relies of arrays and the &lt;code&gt;mapfile&lt;/code&gt; command which got a major overhaul in bash 5.1. The vast majority of testing has been done on bash 5.2 so while bash 4-5.0 &lt;em&gt;should&lt;/em&gt; work it is not well tested.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;rm&lt;/code&gt; and &lt;code&gt;mkdir&lt;/code&gt;: For some basic filesystem operations. I couldnt figure out how to re-implement these in pure bash. Either the GNU or the busybox versions of these will both work.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;OPTIONAL DEPENDENCIES&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Bash 5.1+: For improved speed due to overhauled handling of arrays.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;mktemp&lt;/code&gt; and &lt;code&gt;cat&lt;/code&gt;: The code will provide pure-bash replacements for these if they arent available, but if external binaries for these are present they will be used&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;inotifywait&lt;/code&gt;: If available, this is used to monitor the tmpfile where stdin is saved before being read by the coprocs. This enables the coprocs to efficiently wait for input if stdin is arriving slowly (e.g., &lt;code&gt;ping 1.1.1.1 | forkrun &amp;lt;...&amp;gt;&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;fallocate&lt;/code&gt;: If available, this is used to deallocate already-processed data from the beginning of the tmpfile holding stdin. This enables &lt;code&gt;forkrun&lt;/code&gt; to be used in long-running processes that consistently output data for days/weeks/months/... Without &lt;code&gt;fallocate&lt;/code&gt;, this tmpfile will continually grow and will not be removed until forkrun exits&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;WHY USE FORKRUN&lt;/h1&gt; &#xA;&lt;p&gt;There are 2 other common programs for parallelizing loops in the (bash) shell: &lt;code&gt;xargs&lt;/code&gt; and &lt;code&gt;parallel&lt;/code&gt;. I believe &lt;code&gt;forkrun&lt;/code&gt; offers more than either of these programs can offer:&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;COMPARED TO PARALLEL&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;forkrun&lt;/code&gt; is considerably faster. In terms of &#34;wall clock time&#34; in my tests where I computed 11 different checksums of ~500,000 small files totaling ~19 gb saved on a ramdisk (see the &lt;code&gt;hyperfine_speedtest&lt;/code&gt; sub-directory for details): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;forkrun was on average 8x faster than &lt;code&gt;parallel -m&lt;/code&gt; for very large file counts. For all batch sizes tested forkrun was at leasst twice as fast as parallel&lt;/li&gt; &#xA;   &lt;li&gt;In the particuarly lightweight checksums (&lt;code&gt;sum -s&lt;/code&gt;, &lt;code&gt;cksum&lt;/code&gt;) &lt;code&gt;forkrun&lt;/code&gt; was ~18x faster than &lt;code&gt;parallel -m&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;If comparing in &#34;1 line at a time mode&#34;, forkrun is more like 20-30x faster.&lt;/li&gt; &#xA;   &lt;li&gt;In terms of &#34;CPU&#34; time forkrun also tended to use less CPU cycles than parallel, though the difference here is smaller (forkrun is very good at fully utilizing all CPU cores, but doesnt magically make running whatever is being parallelized take fewer CPU cycles than running it sequential;ly would have taken).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;forkrun&lt;/code&gt; has fewer dependencies. As long as your system has a recent-ish version of bash (which is preinstalled on basically every non-embedded linux system) it can run &lt;code&gt;forkrun&lt;/code&gt;. &lt;code&gt;parallel&lt;/code&gt;, on the other hand, is not typically installed by default.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;COMPARED TO XARGS&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Better set of available options. All of the &lt;code&gt;xargs&lt;/code&gt; options (excluding those intended for running code interactively) have been implemented in &lt;code&gt;forkrun&lt;/code&gt;. Additionally, a handful of additional (and rather useful) options have also been implemented. This includes:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ordering the output the same as the input (making it much easier to use forkrun as a filter)&lt;/li&gt; &#xA;   &lt;li&gt;passing stdin to the workers via the worker&#39;s stdin (&lt;code&gt;func &amp;lt;&amp;lt;&amp;lt;&#34;${args[@]}&#34;&lt;/code&gt; instead of &lt;code&gt;func &#34;${args[@]}&#34;&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;a &#34;no function mode&#34; that allows you to embed the code to run into &lt;code&gt;&#34;${args[@]}&#34;&lt;/code&gt; and run arbitrary code that differs from oline to line in parallel&lt;/li&gt; &#xA;   &lt;li&gt;The ability to unescape (via the &lt;code&gt;-u&lt;/code&gt; flag) the input and have the commands run by &lt;code&gt;forkrun&lt;/code&gt; interpret things like redirects and forks. (this &lt;em&gt;might&lt;/em&gt; be possible in &lt;code&gt;xargs&lt;/code&gt; by wrapping everything in a &lt;code&gt;bash -c&lt;/code&gt; call, but that is unnecessary here).&lt;/li&gt; &#xA;   &lt;li&gt;Better/easier (IMO) usage of the &lt;code&gt;-i&lt;/code&gt; flag to replace &lt;code&gt;{}&lt;/code&gt; with the lines from stdin. No need to wrap everything in a &lt;code&gt;bash -c &#39;...&#39; _&lt;/code&gt; call, and the &lt;code&gt;{}&lt;/code&gt; can bne used multiple times.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Because &lt;code&gt;forkrun&lt;/code&gt; runs directly in the shell, other shell functions can be used as the &lt;code&gt;parFunc&lt;/code&gt; being parallelized (this &lt;em&gt;might&lt;/em&gt; be possible in &lt;code&gt;xargs&lt;/code&gt; by exporting thje function first, but this is not needed with &lt;code&gt;forkrun&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Because &lt;code&gt;forkrun&lt;/code&gt; is faster in problems where parallelization speed matters (in problems where total run time is more than 50 ms or so). Forkrun is twice as fast in medium-size problems (10,000 - 100,000 inputs) and slightly faster (10-20%) in large-size problems (&amp;gt;500,000 inputs).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;SUPPORTED OPTIONS / FLAGS&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;forkrun&lt;/code&gt; supports many of the same flags as &lt;code&gt;xargs&lt;/code&gt; (excluding options intended for interactive use), plus several additional options that are present in &lt;code&gt;parallel&lt;/code&gt; but not &lt;code&gt;xargs&lt;/code&gt;. A quick summary will be provided here - for more info refer to the comment block at the top of the forkrun function, or source forkrun and then run &lt;code&gt;forkrun --help[={flags,all}]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;GENERAL NOTES: 1. Flags must be given separately (e.g., use &lt;code&gt;-k -v&lt;/code&gt; and not &lt;code&gt;-kv&lt;/code&gt;) 2. Flags must be given before the name of the function being parallelized (&lt;code&gt;parFunc&lt;/code&gt;) -- any flags given after the function name will be assumed to be initial arguments for the function, not forkrun options. 3. There are also &#34;long&#34; versions of the flags (e.g., &lt;code&gt;--insert&lt;/code&gt; is the same as &lt;code&gt;-i&lt;/code&gt;). Run &lt;code&gt;forkrun --help=all&lt;/code&gt; for a full list of long options/flags.&lt;/p&gt; &#xA;&lt;p&gt;The following flags are supported:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;FLAGS WITH ARGUMENTS&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;   (-j|-p) &amp;lt;#&amp;gt;  : num worker coprocs. set number of worker coprocs. Default is $(nproc).&#xA;    -l &amp;lt;#&amp;gt;      : num lines per function call (batch size). set static number of lines to pass to the function on each function call. Disables automatic dynamic batch size adjustment. if -l=1 then the &#34;read from a pipe&#34; mode (-p) flag is automatically activated (unless flag `+p` is also given). Default is to use the automatic batch size adjustment.&#xA;    -L &amp;lt;#[,#]&amp;gt;  : set initial (&amp;lt;#&amp;gt;) or initial+maximum (&amp;lt;#,#&amp;gt;) lines per batch while keeping the automatic batch size adjustment enabled. Default is &#39;1,512&#39;&#xA;    -t &amp;lt;path&amp;gt;   : set tmp directory. set the directory where the temp files containing lines from stdin will be kept. These files will be saved inside a new mktemp-generated directory created under the directory specified here. Default is &#39;/dev/shm&#39;, or (if unavailable) &#39;/tmp&#39;&#xA; -d &amp;lt;delimiter&amp;gt; : set the delimiter to something other than a newline (default) or NULL ((-z|-0) flag). must be a single character.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;FLAGS WITHOUT ARGUMENTS&lt;/strong&gt;: for each of these passing &lt;code&gt;-&amp;lt;FLAG&amp;gt;&lt;/code&gt; enables the feasture, and passing &lt;code&gt;+&amp;lt;FLAG&amp;gt;&lt;/code&gt; disables the feature. Unless otherwise noted, all features are, by default, disabled. If a given flag is passed multiple times both enabling &lt;code&gt;-&amp;lt;FLAG&amp;gt;&lt;/code&gt; and disabling &lt;code&gt;+&amp;lt;FLAG&amp;gt;&lt;/code&gt; some option, the last one passed is used.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SYNTAX NOTE: for each of these passing `-&amp;lt;FLAG&amp;gt;` enables the feasture, and passing `+&amp;lt;FLAG&amp;gt;` disables the feature. Unless otherwise noted, all features are, by default, disabled. If a given flag is passed multiple times both enabling `-&amp;lt;FLAG&amp;gt;` and disabling `+&amp;lt;FLAG&amp;gt;` some option, the last one passed is used.&#xA;&#xA;    -i          : insert {}. replace `{}` with the inputs passed on stdin (instead of placing them at the end)&#xA;    -I          : insert {id}. replace `{id}` with an index (0, 1, ...) describing which coproc the process ran on. &#xA;    -k          : ordered output. retain input order in output. The 1st output will correspond to the 1st input, 2nd output to 2nd input, etc. &#xA;    -n          : add ordering info to output. pre-pend each output group with an index describing its input order, demoted via `$&#39;\n&#39;\n$&#39;\034&#39;$INDEX$&#39;\035&#39;$&#39;\n&#39;`. This requires and will automatically enable the `-k` output ordering flag.&#xA;    (-0|-z)     : NULL-seperated stdin. stdin is NULL-separated, not newline separated. WARNING: this flag (by necessity) disables a check that prevents lines from occasionally being split into two separate lines, which can happen if `parFunc` evaluates very quickly. In general a delimiter other than NULL is recommended, especially when `parFunc` evaluates very fast and/or there are many items (passed on stdin) to evaluate.&#xA;    -s          : run in subshell. run each evaluation of `parFunc` in a subshell. This adds some overhead but ensures that running `parFunc` does not alter the coproc&#39;s environment and affect future evaluations of `parFunc`.&#xA;    -S          : pass via function&#39;s stdin. pass stdin to the function being parallelized via stdin ( $parFunc &amp;lt; /tmpdir/fileWithLinesFromStdin ) instead of via function inputs  ( $parFunc $(&amp;lt;/tmpdir/fileWithLinesFromStdin) )&#xA;    -p          : pipe read. dont use a tmpfile and have coprocs read (via shared file descriptor) directly from stdin. Enabled by default only when `-l 1` is passed.&#xA;    -D          : delete tmpdir. Remove the tmp dir used by `forkrun` when `forkrun` exits. NOTE: the `-D` flag is enabled by default...disable with flag `+D`.&#xA;    -N          : enable no func mode. Only has an effect when `parFunc` and `initialArgs` are not given. If `-N` is not passed and `parFunc` and `initialArgs` are missing, `forkrun` will silently set `parFunc` to `printf &#39;%s\n&#39;`, which will basically just copy stdin to stdout.&#xA;    -u          : unescape redirects/pipes/forks/logical operators. Typically `parFunc` and `initialArgs` are run through `printf &#39;%q&#39;` making things like `&amp;lt;` , `&amp;lt;&amp;lt;` , `&amp;lt;&amp;lt;&amp;lt;` , `&amp;gt;` , `&amp;gt;&amp;gt;` , `|` , `&amp;amp;&amp;amp;` , and `||` appear as literal characters. This flag skips the `printf &#39;%q&#39;` call, meaning that these operators can be used to allow for piping, redirection, forking, logical comparison, etc. to occur *inside the coproc*. &#xA;    --          : end of forkrun options indicator. indicate that all remaining arguments are for the function being parallelized and are not forkrun inputs. This allows using a `parFunc` that begins with a `-`. NOTE: there is no `+&amp;lt;FLAG&amp;gt;` equivalent for `--`.&#xA;    -v          : increase verbosity level by 1. This can be passed up to 4 times for progressively more verbose output. +v decreases the verbosity level by 1.&#xA;    (-h|-?)     : display help text. use `--help=f[lags]` or `--help=a[ll]` for more details about flags that `forkrun` supports. NOTE: you must escape the `?` otherwise the shell can interpret it before passing it to forkrun.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>