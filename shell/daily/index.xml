<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Shell Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-02T01:37:27Z</updated>
  <subtitle>Daily Trending of Shell in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>atmoz/sftp</title>
    <updated>2022-11-02T01:37:27Z</updated>
    <id>tag:github.com,2022-11-02:/atmoz/sftp</id>
    <link href="https://github.com/atmoz/sftp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Securely share your files&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SFTP&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/atmoz/sftp/build?logo=github&#34; alt=&#34;GitHub Workflow Status&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/atmoz/sftp?logo=github&#34; alt=&#34;GitHub stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/stars/atmoz/sftp?label=stars&amp;amp;logo=docker&#34; alt=&#34;Docker Stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/atmoz/sftp?label=pulls&amp;amp;logo=docker&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/atmoz/sftp/master/openssh.png&#34; alt=&#34;OpenSSH logo&#34; title=&#34;Powered by OpenSSH&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Supported tags and respective &lt;code&gt;Dockerfile&lt;/code&gt; links&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/atmoz/sftp/raw/master/Dockerfile&#34;&gt;&lt;code&gt;debian&lt;/code&gt;, &lt;code&gt;latest&lt;/code&gt; (&lt;em&gt;Dockerfile&lt;/em&gt;)&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/docker/image-size/atmoz/sftp/debian?label=debian&amp;amp;logo=debian&amp;amp;style=plastic&#34; alt=&#34;Docker Image Size (debian)&#34;&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/atmoz/sftp/raw/master/Dockerfile-alpine&#34;&gt;&lt;code&gt;alpine&lt;/code&gt; (&lt;em&gt;Dockerfile&lt;/em&gt;)&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/docker/image-size/atmoz/sftp/alpine?label=alpine&amp;amp;logo=Alpine%20Linux&amp;amp;style=plastic&#34; alt=&#34;Docker Image Size (alpine)&#34;&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Securely share your files&lt;/h1&gt; &#xA;&lt;p&gt;Easy to use SFTP (&lt;a href=&#34;https://en.wikipedia.org/wiki/SSH_File_Transfer_Protocol&#34;&gt;SSH File Transfer Protocol&lt;/a&gt;) server with &lt;a href=&#34;https://en.wikipedia.org/wiki/OpenSSH&#34;&gt;OpenSSH&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Define users in (1) command arguments, (2) &lt;code&gt;SFTP_USERS&lt;/code&gt; environment variable or (3) in file mounted as &lt;code&gt;/etc/sftp/users.conf&lt;/code&gt; (syntax: &lt;code&gt;user:pass[:e][:uid[:gid[:dir1[,dir2]...]]] ...&lt;/code&gt;, see below for examples) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Set UID/GID manually for your users if you want them to make changes to your mounted volumes with permissions matching your host filesystem.&lt;/li&gt; &#xA;   &lt;li&gt;Directory names at the end will be created under user&#39;s home directory with write permission, if they aren&#39;t already present.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Mount volumes &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The users are chrooted to their home directory, so you can mount the volumes in separate directories inside the user&#39;s home directory (/home/user/&lt;strong&gt;mounted-directory&lt;/strong&gt;) or just mount the whole &lt;strong&gt;/home&lt;/strong&gt; directory. Just remember that the users can&#39;t create new files directly under their own home directory, so make sure there are at least one subdirectory if you want them to upload files.&lt;/li&gt; &#xA;   &lt;li&gt;For consistent server fingerprint, mount your own host keys (i.e. &lt;code&gt;/etc/ssh/ssh_host_*&lt;/code&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Examples&lt;/h1&gt; &#xA;&lt;h2&gt;Simplest docker run example&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -p 22:22 -d atmoz/sftp foo:pass:::upload&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;User &#34;foo&#34; with password &#34;pass&#34; can login with sftp and upload files to a folder called &#34;upload&#34;. No mounted directories or custom UID/GID. Later you can inspect the files and use &lt;code&gt;--volumes-from&lt;/code&gt; to mount them somewhere else (or see next example).&lt;/p&gt; &#xA;&lt;h2&gt;Sharing a directory from your computer&lt;/h2&gt; &#xA;&lt;p&gt;Let&#39;s mount a directory and set UID:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run \&#xA;    -v &amp;lt;host-dir&amp;gt;/upload:/home/foo/upload \&#xA;    -p 2222:22 -d atmoz/sftp \&#xA;    foo:pass:1001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using Docker Compose:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;sftp:&#xA;    image: atmoz/sftp&#xA;    volumes:&#xA;        - &amp;lt;host-dir&amp;gt;/upload:/home/foo/upload&#xA;    ports:&#xA;        - &#34;2222:22&#34;&#xA;    command: foo:pass:1001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Logging in&lt;/h3&gt; &#xA;&lt;p&gt;The OpenSSH server runs by default on port 22, and in this example, we are forwarding the container&#39;s port 22 to the host&#39;s port 2222. To log in with the OpenSSH client, run: &lt;code&gt;sftp -P 2222 foo@&amp;lt;host-ip&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Store users in config&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run \&#xA;    -v &amp;lt;host-dir&amp;gt;/users.conf:/etc/sftp/users.conf:ro \&#xA;    -v mySftpVolume:/home \&#xA;    -p 2222:22 -d atmoz/sftp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&#xA; &lt;host-dir&gt;&#xA;  /users.conf:&#xA; &lt;/host-dir&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;foo:123:1001:100&#xA;bar&lt;span&gt;ðŸ”¤&lt;/span&gt;1002:100&#xA;baz:xyz:1003:100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Encrypted password&lt;/h2&gt; &#xA;&lt;p&gt;Add &lt;code&gt;:e&lt;/code&gt; behind password to mark it as encrypted. Use single quotes if using terminal.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run \&#xA;    -v &amp;lt;host-dir&amp;gt;/share:/home/foo/share \&#xA;    -p 2222:22 -d atmoz/sftp \&#xA;    &#39;foo:$1$0G2g0GSt$ewU0t6GXG15.0hWoOX8X9.:e:1001&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Tip: you can use this Python code to generate encrypted passwords:&lt;br&gt; &lt;code&gt;docker run --rm python:alpine python -c &#34;import crypt; print(crypt.crypt(&#39;YOUR_PASSWORD&#39;))&#34;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Logging in with SSH keys&lt;/h2&gt; &#xA;&lt;p&gt;Mount public keys in the user&#39;s &lt;code&gt;.ssh/keys/&lt;/code&gt; directory. All keys are automatically appended to &lt;code&gt;.ssh/authorized_keys&lt;/code&gt; (you can&#39;t mount this file directly, because OpenSSH requires limited file permissions). In this example, we do not provide any password, so the user &lt;code&gt;foo&lt;/code&gt; can only login with his SSH key.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run \&#xA;    -v &amp;lt;host-dir&amp;gt;/id_rsa.pub:/home/foo/.ssh/keys/id_rsa.pub:ro \&#xA;    -v &amp;lt;host-dir&amp;gt;/id_other.pub:/home/foo/.ssh/keys/id_other.pub:ro \&#xA;    -v &amp;lt;host-dir&amp;gt;/share:/home/foo/share \&#xA;    -p 2222:22 -d atmoz/sftp \&#xA;    foo::1001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Providing your own SSH host key (recommended)&lt;/h2&gt; &#xA;&lt;p&gt;This container will generate new SSH host keys at first run. To avoid that your users get a MITM warning when you recreate your container (and the host keys changes), you can mount your own host keys.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run \&#xA;    -v &amp;lt;host-dir&amp;gt;/ssh_host_ed25519_key:/etc/ssh/ssh_host_ed25519_key \&#xA;    -v &amp;lt;host-dir&amp;gt;/ssh_host_rsa_key:/etc/ssh/ssh_host_rsa_key \&#xA;    -v &amp;lt;host-dir&amp;gt;/share:/home/foo/share \&#xA;    -p 2222:22 -d atmoz/sftp \&#xA;    foo::1001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Tip: you can generate your keys with these commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ssh-keygen -t ed25519 -f ssh_host_ed25519_key &amp;lt; /dev/null&#xA;ssh-keygen -t rsa -b 4096 -f ssh_host_rsa_key &amp;lt; /dev/null&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Execute custom scripts or applications&lt;/h2&gt; &#xA;&lt;p&gt;Put your programs in &lt;code&gt;/etc/sftp.d/&lt;/code&gt; and it will automatically run when the container starts. See next section for an example.&lt;/p&gt; &#xA;&lt;h2&gt;Bindmount dirs from another location&lt;/h2&gt; &#xA;&lt;p&gt;If you are using &lt;code&gt;--volumes-from&lt;/code&gt; or just want to make a custom directory available in user&#39;s home directory, you can add a script to &lt;code&gt;/etc/sftp.d/&lt;/code&gt; that bindmounts after container starts.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#!/bin/bash&#xA;# File mounted as: /etc/sftp.d/bindmount.sh&#xA;# Just an example (make your own)&#xA;&#xA;function bindmount() {&#xA;    if [ -d &#34;$1&#34; ]; then&#xA;        mkdir -p &#34;$2&#34;&#xA;    fi&#xA;    mount --bind $3 &#34;$1&#34; &#34;$2&#34;&#xA;}&#xA;&#xA;# Remember permissions, you may have to fix them:&#xA;# chown -R :users /data/common&#xA;&#xA;bindmount /data/admin-tools /home/admin/tools&#xA;bindmount /data/common /home/dave/common&#xA;bindmount /data/common /home/peter/common&#xA;bindmount /data/docs /home/peter/docs --read-only&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Using &lt;code&gt;mount&lt;/code&gt; requires that your container runs with the &lt;code&gt;CAP_SYS_ADMIN&lt;/code&gt; capability turned on. &lt;a href=&#34;https://github.com/atmoz/sftp/issues/60#issuecomment-332909232&#34;&gt;See this answer for more information&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;What&#39;s the difference between Debian and Alpine?&lt;/h1&gt; &#xA;&lt;p&gt;The biggest differences are in size and OpenSSH version. &lt;a href=&#34;https://hub.docker.com/_/alpine/&#34;&gt;Alpine&lt;/a&gt; is 10 times smaller than &lt;a href=&#34;https://hub.docker.com/_/debian/&#34;&gt;Debian&lt;/a&gt;. OpenSSH version can also differ, as it&#39;s two different teams maintaining the packages. Debian is generally considered more stable and only bugfixes and security fixes are added after each Debian release (about 2 years). Alpine has a faster release cycle (about 6 months) and therefore newer versions of OpenSSH. As I&#39;m writing this, Debian has version 7.4 while Alpine has version 7.5. Recommended reading: &lt;a href=&#34;https://www.turnkeylinux.org/blog/alpine-vs-debian&#34;&gt;Comparing Debian vs Alpine for container &amp;amp; Docker apps&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;What version of OpenSSH do I get?&lt;/h1&gt; &#xA;&lt;p&gt;It depends on which linux distro and version you choose (see available images at the top). You can see what version you get by checking the distro&#39;s packages online. I have provided direct links below for easy access.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pkgs.alpinelinux.org/packages?name=openssh&amp;amp;branch=&amp;amp;repo=main&amp;amp;arch=x86_64&#34;&gt;List of &lt;code&gt;openssh&lt;/code&gt; packages on Alpine releases&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://packages.debian.org/search?keywords=openssh-server&amp;amp;searchon=names&amp;amp;exact=1&amp;amp;suite=all&amp;amp;section=main&#34;&gt;List of &lt;code&gt;openssh-server&lt;/code&gt; packages on Debian releases&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Daily builds&lt;/h1&gt; &#xA;&lt;p&gt;Images are automatically built daily to get the newest version of OpenSSH provided by the package managers.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rwxrob/book-terminal-velocity</title>
    <updated>2022-11-02T01:37:27Z</updated>
    <id>tag:github.com,2022-11-02:/rwxrob/book-terminal-velocity</id>
    <link href="https://github.com/rwxrob/book-terminal-velocity" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ðŸ“• Terminal Velocity: Mastering the Fastest Human-Computer Interface&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ðŸ“• Terminal Velocity: Mastering the Fastest Human-Computer Interface&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Terminal Velocity&lt;/em&gt; is first and foremost an online knowledge base of tips and tricks for becoming your best self when faced with a UNIX (or Linux) terminal. This also just so happens to be a book.&lt;/p&gt; &#xA;&lt;h2&gt;Summary&lt;/h2&gt; &#xA;&lt;p&gt;Learn to use the UNIX terminal interface with the least amount of installation and setup possible --- specifically, vim, bash, screen/tmux, lynx/w3m, and docker/podman. We&#39;ll follow the UNIX philosophy when editing files, creating tools, and doing research. Eventually, you will become much faster than those who depend on cumbersome graphic user interfaces for most of the same tasks.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rwxrob/book-terminal-velocity/main/content-organization-and-style&#34;&gt;Content Organization and Style&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rwxrob/book-terminal-velocity/main/fastest-human-computer-interface&#34;&gt;Fastest Human-Computer Interface&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rwxrob/book-terminal-velocity/main/get-bash&#34;&gt;Get Bash&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rwxrob/book-terminal-velocity/main/edit-without-installing&#34;&gt;Edit Without Installing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rwxrob/book-terminal-velocity/main/its-all-code&#34;&gt;It&#39;s All Code&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rwxrob/book-terminal-velocity/main/multiplex-flex&#34;&gt;Multiplex Flex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rwxrob/book-terminal-velocity/main/research-from-command-line&#34;&gt;Research from Command-Line&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rwxrob/book-terminal-velocity/main/contain-yourself&#34;&gt;Contain Yourself&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rwxrob/book-terminal-velocity/main/faq&#34;&gt;Frequently Answered Questions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>conduktor/kafka-stack-docker-compose</title>
    <updated>2022-11-02T01:37:27Z</updated>
    <id>tag:github.com,2022-11-02:/conduktor/kafka-stack-docker-compose</id>
    <link href="https://github.com/conduktor/kafka-stack-docker-compose" rel="alternate"></link>
    <summary type="html">&lt;p&gt;docker compose files to create a fully working kafka stack&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/conduktor/kafka-stack-docker-compose/actions&#34;&gt;&lt;img src=&#34;https://github.com/conduktor/kafka-stack-docker-compose/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;Actions Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;An open-source project by &lt;a href=&#34;https://conduktor.io/&#34;&gt;&lt;img src=&#34;https://www.conduktor.io/uploads/conduktor.svg?sanitize=true&#34; alt=&#34;Conduktor.io&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;This project is sponsored by &lt;a href=&#34;https://www.conduktor.io/&#34;&gt;Conduktor.io&lt;/a&gt;, a graphical desktop user interface for Apache Kafka.&lt;/p&gt; &#xA;&lt;p&gt;Once you have started your cluster, you can use Conduktor to easily manage it. Just connect against &lt;code&gt;localhost:9092&lt;/code&gt;. If you are on Mac or Windows and want to connect from another container, use &lt;code&gt;host.docker.internal:29092&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h1&gt;kafka-stack-docker-compose&lt;/h1&gt; &#xA;&lt;p&gt;This replicates as well as possible real deployment configurations, where you have your zookeeper servers and kafka servers actually all distinct from each other. This solves all the networking hurdles that comes with Docker and docker-compose, and is compatible cross platform.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;: No /etc/hosts file changes are necessary anymore. Explanations at: &lt;a href=&#34;https://rmoff.net/2018/08/02/kafka-listeners-explained/&#34;&gt;https://rmoff.net/2018/08/02/kafka-listeners-explained/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Stack version&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Conduktor Platform: 1.0.2&lt;/li&gt; &#xA; &lt;li&gt;Zookeeper version: 3.6.3 (Confluent 7.2.1)&lt;/li&gt; &#xA; &lt;li&gt;Kafka version: 3.2.0 (Confluent 7.2.1)&lt;/li&gt; &#xA; &lt;li&gt;Kafka Schema Registry: Confluent 7.2.1&lt;/li&gt; &#xA; &lt;li&gt;Kafka Rest Proxy: Confluent 7.2.1&lt;/li&gt; &#xA; &lt;li&gt;Kafka Connect: Confluent 7.2.1&lt;/li&gt; &#xA; &lt;li&gt;ksqlDB Server: Confluent 7.2.1&lt;/li&gt; &#xA; &lt;li&gt;Zoonavigator: 1.1.1&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For a UI tool to access your local Kafka cluster, use the free version of &lt;a href=&#34;https://www.conduktor.io/download&#34;&gt;Conduktor&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Requirements&lt;/h1&gt; &#xA;&lt;p&gt;Kafka will be exposed on &lt;code&gt;127.0.0.1&lt;/code&gt; or &lt;code&gt;DOCKER_HOST_IP&lt;/code&gt; if set in the environment. (You probably don&#39;t need to set it if you&#39;re not using Docker-Toolbox)&lt;/p&gt; &#xA;&lt;h2&gt;Docker-Toolbox&lt;/h2&gt; &#xA;&lt;p&gt;Docker toolbox is &lt;a href=&#34;https://github.com/docker-archive/toolbox&#34;&gt;deprecated&lt;/a&gt; and not maintained anymore for several years. We can&#39;t guarantee this stack will work with Docker Toolbox, but if you want to try anyway, please export your environment before starting the stack:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export DOCKER_HOST_IP=192.168.99.100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(your docker machine IP is usually &lt;code&gt;192.168.99.100&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Apple M1 support&lt;/h2&gt; &#xA;&lt;p&gt;Confluent platform supports Apple M1 (ARM64) since version &lt;code&gt;7.2.0&lt;/code&gt;! Basically, this stack will work out of the box.&lt;/p&gt; &#xA;&lt;p&gt;If you want to downgrade confluent platform version, there are two ways:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Add &lt;code&gt;platform: linux/amd64&lt;/code&gt;. It will work as docker is able to emulate AMD64 instructions.&lt;/li&gt; &#xA; &lt;li&gt;Previous versions have been &lt;a href=&#34;https://github.com/arm64-compat/confluent-platform&#34;&gt;built&lt;/a&gt; for ARM64 by the community. If you want to use it, just change the image in the corresponding yml. Since it is a not an official image, use it at your own risks.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Full stack&lt;/h2&gt; &#xA;&lt;p&gt;To ease you journey with kafka just connect to &lt;a href=&#34;http://localhost:8080/&#34;&gt;localhost:8080&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;login: &lt;code&gt;login@admin.io&lt;/code&gt; password: &lt;code&gt;admin&lt;/code&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Conduktor-platform: &lt;code&gt;$DOCKER_HOST_IP:8080&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Single Zookeeper: &lt;code&gt;$DOCKER_HOST_IP:2181&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Single Kafka: &lt;code&gt;$DOCKER_HOST_IP:9092&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kafka Schema Registry: &lt;code&gt;$DOCKER_HOST_IP:8081&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kafka Rest Proxy: &lt;code&gt;$DOCKER_HOST_IP:8082&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kafka Connect: &lt;code&gt;$DOCKER_HOST_IP:8083&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;KSQL Server: &lt;code&gt;$DOCKER_HOST_IP:8088&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;(experimental) JMX port at &lt;code&gt;$DOCKER_HOST_IP:9001&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Run with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose -f full-stack.yml up&#xA;docker-compose -f full-stack.yml down&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Single Zookeeper / Single Kafka&lt;/h2&gt; &#xA;&lt;p&gt;This configuration fits most development requirements.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Zookeeper will be available at &lt;code&gt;$DOCKER_HOST_IP:2181&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kafka will be available at &lt;code&gt;$DOCKER_HOST_IP:9092&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;(experimental) JMX port at &lt;code&gt;$DOCKER_HOST_IP:9999&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Run with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose -f zk-single-kafka-single.yml up&#xA;docker-compose -f zk-single-kafka-single.yml down&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Single Zookeeper / Multiple Kafka&lt;/h2&gt; &#xA;&lt;p&gt;If you want to have three brokers and experiment with kafka replication / fault-tolerance.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Zookeeper will be available at &lt;code&gt;$DOCKER_HOST_IP:2181&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kafka will be available at &lt;code&gt;$DOCKER_HOST_IP:9092,$DOCKER_HOST_IP:9093,$DOCKER_HOST_IP:9094&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Run with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose -f zk-single-kafka-multiple.yml up&#xA;docker-compose -f zk-single-kafka-multiple.yml down&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Multiple Zookeeper / Single Kafka&lt;/h2&gt; &#xA;&lt;p&gt;If you want to have three zookeeper nodes and experiment with zookeeper fault-tolerance.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Zookeeper will be available at &lt;code&gt;$DOCKER_HOST_IP:2181,$DOCKER_HOST_IP:2182,$DOCKER_HOST_IP:2183&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kafka will be available at &lt;code&gt;$DOCKER_HOST_IP:9092&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;(experimental) JMX port at &lt;code&gt;$DOCKER_HOST_IP:9999&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Run with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose -f zk-multiple-kafka-single.yml up&#xA;docker-compose -f zk-multiple-kafka-single.yml down&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Multiple Zookeeper / Multiple Kafka&lt;/h2&gt; &#xA;&lt;p&gt;If you want to have three zookeeper nodes and three kafka brokers to experiment with production setup.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Zookeeper will be available at &lt;code&gt;$DOCKER_HOST_IP:2181,$DOCKER_HOST_IP:2182,$DOCKER_HOST_IP:2183&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kafka will be available at &lt;code&gt;$DOCKER_HOST_IP:9092,$DOCKER_HOST_IP:9093,$DOCKER_HOST_IP:9094&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Run with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose -f zk-multiple-kafka-multiple.yml up&#xA;docker-compose -f zk-multiple-kafka-multiple.yml down&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;FAQ&lt;/h1&gt; &#xA;&lt;h2&gt;Kafka&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q: Kafka&#39;s log is too verbose, how can I reduce it?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;A: Add the following line to your docker-compose environment variables: &lt;code&gt;KAFKA_LOG4J_LOGGERS: &#34;kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO&#34;&lt;/code&gt;. Full logging control can be accessed here: &lt;a href=&#34;https://github.com/confluentinc/cp-docker-images/raw/master/debian/kafka/include/etc/confluent/docker/log4j.properties.template&#34;&gt;https://github.com/confluentinc/cp-docker-images/blob/master/debian/kafka/include/etc/confluent/docker/log4j.properties.template&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q: How do I delete data to start fresh?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;A: Your data is persisted from within the docker compose folder, so if you want for example to reset the data in the full-stack docker compose, do a &lt;code&gt;docker-compose -f full-stack.yml down&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q: Can I change the zookeeper ports?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;A: yes. Say you want to change &lt;code&gt;zoo1&lt;/code&gt; port to &lt;code&gt;12181&lt;/code&gt; (only relevant lines are shown):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  zoo1:&#xA;    ports:&#xA;      - &#34;12181:12181&#34;&#xA;    environment:&#xA;        ZOO_PORT: 12181&#xA;        &#xA;  kafka1:&#xA;    environment:&#xA;      KAFKA_ZOOKEEPER_CONNECT: &#34;zoo1:12181&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q: Can I change the Kafka ports?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;A: yes. Say you want to change &lt;code&gt;kafka1&lt;/code&gt; port to &lt;code&gt;12345&lt;/code&gt; (only relevant lines are shown). Note only &lt;code&gt;LISTENER_DOCKER_EXTERNAL&lt;/code&gt; changes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  kafka1:&#xA;    image: confluentinc/cp-kafka:7.2.1&#xA;    hostname: kafka1&#xA;    ports:&#xA;      - &#34;12345:12345&#34;&#xA;    environment:&#xA;      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:12345,DOCKER://host.docker.internal:29092&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q: Kafka is using a lot of disk space for testing. Can I reduce it?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;A: yes. This is for testing only!!! Reduce the KAFKA_LOG_SEGMENT_BYTES to 16MB and the KAFKA_LOG_RETENTION_BYTES to 128MB&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  kafka1:&#xA;    image: confluentinc/cp-kafka:7.2.1&#xA;    ...&#xA;    environment:&#xA;      ...&#xA;      # For testing small segments 16MB and retention of 128MB&#xA;      KAFKA_LOG_SEGMENT_BYTES: 16777216&#xA;      KAFKA_LOG_RETENTION_BYTES: 134217728&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q: How do I expose kafka?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;A: If you want to expose kafka outside of your local machine, you must set &lt;code&gt;KAFKA_ADVERTISED_LISTENERS&lt;/code&gt; to the IP of the machine so that kafka is externally accessible. To achieve this you can set &lt;code&gt;LISTENER_DOCKER_EXTERNAL&lt;/code&gt; to the IP of the machine. For example, if the IP of your machine is &lt;code&gt;50.10.2.3&lt;/code&gt;, follow the sample mapping below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  kafka1:&#xA;    image: confluentinc/cp-kafka:7.2.1&#xA;    ...&#xA;    environment:&#xA;      ...&#xA;      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:19093,EXTERNAL://50.10.2.3:9093,DOCKER://host.docker.internal:29093&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q: How do I add connectors to kafka connect?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Create a &lt;code&gt;connectors&lt;/code&gt; directory and place your connectors there (usually in a subdirectory) &lt;code&gt;connectors/example/my.jar&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The directory is automatically mounted by the &lt;code&gt;kafka-connect&lt;/code&gt; Docker container&lt;/p&gt; &#xA;&lt;p&gt;OR edit the bash command which pulls connectors at runtime&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;confluent-hub install --no-prompt debezium/debezium-connector-mysql:latest&#xA;        confluent-hub install &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q: How to disable Confluent metrics?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Add this environment variable&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE=false&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>