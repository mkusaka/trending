<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Shell Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-21T01:40:52Z</updated>
  <subtitle>Daily Trending of Shell in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ai-dock/comfyui</title>
    <updated>2024-02-21T01:40:52Z</updated>
    <id>tag:github.com,2024-02-21:/ai-dock/comfyui</id>
    <link href="https://github.com/ai-dock/comfyui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ComfyUI docker images&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/ai-dock/comfyui/actions/workflows/docker-build.yml&#34;&gt;&lt;img src=&#34;https://github.com/ai-dock/comfyui/actions/workflows/docker-build.yml/badge.svg?sanitize=true&#34; alt=&#34;Docker Build&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;ComfyUI Docker Image&lt;/h1&gt; &#xA;&lt;p&gt;Run &lt;a href=&#34;https://github.com/comfyanonymous/ComfyUI&#34;&gt;ComfyUI&lt;/a&gt; in a docker container locally or in the cloud.&lt;/p&gt; &#xA;&lt;p&gt;These container images are tested extensively at &lt;a href=&#34;https://link.ai-dock.org/template-vast-comfyui-jupyter&#34;&gt;Vast.ai&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://link.ai-dock.org/template-runpod-comfyui-jupyter&#34;&gt;Runpod.io&lt;/a&gt; but compatibility with other GPU cloud services is expected.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] These images do not bundle models or third-party configurations. You should use a &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#provisioning-script&#34;&gt;provisioning script&lt;/a&gt; to automatically configure your container. You can find examples in &lt;code&gt;config/provisioning&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Simply declare your &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#environment-variables&#34;&gt;environment variables&lt;/a&gt; and launch a container with &lt;code&gt;docker compose&lt;/code&gt; or choose a pre-configured &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#pre-configured-templates&#34;&gt;cloud template&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;About ComfyUI&lt;/h2&gt; &#xA;&lt;p&gt;ComfyUI is a powerful and modular stable diffusion GUI and backend with a user-friendly interface that empowers users to effortlessly design and execute intricate Stable Diffusion pipelines. This innovative system employs a visual approach with nodes, flowcharts, and graphs, eliminating the need for manual coding.&lt;/p&gt; &#xA;&lt;p&gt;Some features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Graphical Workflow Design&lt;/strong&gt;: Create complex Stable Diffusion workflows through a user-friendly node-based interface, without requiring coding skills.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Wide Compatibility&lt;/strong&gt;: Fully supports SD1.x, SD2.x, and SDXL for comprehensive applicability.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Efficient Queue System&lt;/strong&gt;: Incorporates an asynchronous queue system for streamlined workflow execution.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Selective Optimization&lt;/strong&gt;: Optimizes execution by re-running only the parts of the workflow that have changed.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;CPU Support&lt;/strong&gt;: Capable of functioning on CPUs with the --cpu option, although at a slower pace.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model Integration&lt;/strong&gt;: Load ckpt, safetensors, diffusers models/checkpoints, standalone VAEs, CLIP models, and more.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Diverse Capabilities&lt;/strong&gt;: Handle embeddings, textual inversion, Loras (regular, locon, loha), hypernetworks, inpainting, control networks, upscale models, unCLIP models, GLIGEN, model merging, and latent previews with TAESD.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Workflow Flexibility&lt;/strong&gt;: Save and load workflows conveniently in JSON format, facilitating easy modification and reuse.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced Workflows&lt;/strong&gt;: The node interface empowers the creation of intricate workflows, from high-resolution fixes to more advanced applications.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Area Composition&lt;/strong&gt;: Supports area composition techniques for enhanced creative control.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Offline Functionality&lt;/strong&gt;: Operates completely offline, ensuring data privacy and eliminating any need for downloads.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configuration Control&lt;/strong&gt;: Utilize a configuration file to set specific search paths for models.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Pre-built Images&lt;/h2&gt; &#xA;&lt;p&gt;Docker images are built automatically through a GitHub Actions workflow and hosted at the GitHub Container Registry.&lt;/p&gt; &#xA;&lt;p&gt;An incremental build process is used to avoid needing a huge cache - The following images are used to provide functionality:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVIDIA/nvidia-docker&#34;&gt;nvidia/cuda&lt;/a&gt; / &lt;a href=&#34;https://github.com/docker-library/docs/tree/master/ubuntu&#34;&gt;ubuntu&lt;/a&gt; ↴&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ai-dock/base-image&#34;&gt;ai-dock/base-image&lt;/a&gt; ↴&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ai-dock/python&#34;&gt;ai-dock/python&lt;/a&gt; ↴&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ai-dock/pytorch&#34;&gt;ai-dock/pytorch&lt;/a&gt; / &lt;a href=&#34;https://github.com/ai-dock/jupyter-pytorch&#34;&gt;ai-dock/jupyter-pytorch&lt;/a&gt; ↴&lt;/li&gt; &#xA; &lt;li&gt;ai-dock/comfyui&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Version Tags&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;:latest&lt;/code&gt; tag points to &lt;code&gt;:latest-cuda&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Tags follow these patterns:&lt;/p&gt; &#xA;&lt;h5&gt;&lt;em&gt;CUDA&lt;/em&gt;&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;:pytorch-[pytorch-version]-py[python-version]-cuda-[x.x.x]-base-[ubuntu-version]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;:latest-cuda&lt;/code&gt; → &lt;code&gt;:pytorch-2.2.0-py3.10-cuda-11.8.0-base-22.04&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;:latest-cuda-jupyter&lt;/code&gt; → &lt;code&gt;:jupyter-pytorch-2.2.0-py3.10-cuda-11.8.0-base-22.04&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;&lt;em&gt;ROCm&lt;/em&gt;&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;:pytorch-[pytorch-version]-py[python-version]-rocm-[x.x.x]-runtime-[ubuntu-version]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;:latest-rocm&lt;/code&gt; → &lt;code&gt;:pytorch-2.2.0-py3.10-rocm-5.7-runtime-22.04&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;:latest-rocm-jupyter&lt;/code&gt; → &lt;code&gt;:jupyter-pytorch-2.2.0-py3.10-rocm-5.7-runtime-22.04&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;&lt;em&gt;CPU&lt;/em&gt;&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;:pytorch-[pytorch-version]-py[python-version]-ubuntu-[ubuntu-version]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;:latest-cpu&lt;/code&gt; → &lt;code&gt;:pytorch-2.2.0-py3.10-cpu-22.04&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;:latest-cpu-jupyter&lt;/code&gt; → &lt;code&gt;:jupyter-pytorch-2.2.0-py3.10-cpu-22.04&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Browse &lt;a href=&#34;https://github.com/ai-dock/comfyui/pkgs/container/comfyui&#34;&gt;here&lt;/a&gt; for an image suitable for your target environment.&lt;/p&gt; &#xA;&lt;p&gt;You can also &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#building-images&#34;&gt;build from source&lt;/a&gt; by editing &lt;code&gt;.env&lt;/code&gt; and running &lt;code&gt;docker compose build&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Supported Python versions: &lt;code&gt;3.11&lt;/code&gt;, &lt;code&gt;3.10&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Supported Pytorch versions: &lt;code&gt;2.2.0&lt;/code&gt;, &lt;code&gt;2.1.2&lt;/code&gt;, &lt;code&gt;2.1.1&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Supported Platforms: &lt;code&gt;NVIDIA CUDA&lt;/code&gt;, &lt;code&gt;AMD ROCm&lt;/code&gt;, &lt;code&gt;CPU&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Building Images&lt;/h2&gt; &#xA;&lt;p&gt;You can self-build from source by editing &lt;code&gt;docker-compose.yaml&lt;/code&gt; or &lt;code&gt;.env&lt;/code&gt; and running &lt;code&gt;docker compose build&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It is a good idea to leave the main source tree alone and copy any extra files you would like in the container into &lt;code&gt;build/COPY_ROOT_EXTRA/...&lt;/code&gt;. The structure within this directory will be overlayed on &lt;code&gt;/&lt;/code&gt; near the end of the build process.&lt;/p&gt; &#xA;&lt;p&gt;After copying has been completed, the script &lt;code&gt;build/COPY_ROOT_EXTRA/opt/ai-dock/bin/build/layer1/init.sh&lt;/code&gt; will be executed. A template for this file capable of downloading models and nodes is provided for convenience.&lt;/p&gt; &#xA;&lt;p&gt;Any directories and files that you add into &lt;code&gt;opt/storage&lt;/code&gt; will be made available in the running container at &lt;code&gt;$WORKSPACE/storage&lt;/code&gt; through symbolic links.&lt;/p&gt; &#xA;&lt;p&gt;This directory is monitored by &lt;code&gt;inotifywait&lt;/code&gt;. Any items appearing here will be automatically symlinked to the application directories as defined in &lt;code&gt;/opt/ai-dock/storage_monitor/etc/mappings.sh&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Recommended workflow&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fork this repository and clone&lt;/li&gt; &#xA; &lt;li&gt;Create and switch to a new branch&lt;/li&gt; &#xA; &lt;li&gt;Create &lt;code&gt;.env&lt;/code&gt; to override the &lt;code&gt;IMAGE_TAG&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Copy non-public models to &lt;code&gt;build/COPY_ROOT_EXTRA/opt/storage/stable_diffusion/ckpt/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Edit &lt;code&gt;build/COPY_ROOT_EXTRA/opt/ai-dock/bin/build/layer1/init.sh&lt;/code&gt; to download public models and nodes&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;docker compose build&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;docker compose push&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Run Locally&lt;/h2&gt; &#xA;&lt;p&gt;A &#39;feature-complete&#39; &lt;code&gt;docker-compose.yaml&lt;/code&gt; file is included for your convenience. All features of the image are included - Simply edit the environment variables in &lt;code&gt;.env&lt;/code&gt;, save and then type &lt;code&gt;docker compose up&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you prefer to use the standard &lt;code&gt;docker run&lt;/code&gt; syntax, the command to pass is &lt;code&gt;init.sh&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Run in the Cloud&lt;/h2&gt; &#xA;&lt;p&gt;This image should be compatible with any GPU cloud platform. You simply need to pass environment variables at runtime.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;br&gt; Please raise an issue on this repository if your provider cannot run the image.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;Container Cloud&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Container providers don&#39;t give you access to the docker host but are quick and easy to set up. They are often inexpensive when compared to a full VM or bare metal solution.&lt;/p&gt; &#xA;&lt;p&gt;All images built for ai-dock are tested for compatibility with both &lt;a href=&#34;https://link.ai-dock.org/template-vast-comfyui&#34;&gt;vast.ai&lt;/a&gt; and &lt;a href=&#34;https://link.ai-dock.org/template-runpod-comfyui&#34;&gt;runpod.io&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Images that include Jupyter are also tested to ensure compatibility with &lt;a href=&#34;https://link.ai-dock.org/console.paperspace.com&#34;&gt;Paperspace Gradient&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See a list of pre-configured templates &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#pre-configured-templates&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING]&lt;br&gt; Container cloud providers may offer both &#39;community&#39; and &#39;secure&#39; versions of their cloud. If your usecase involves storing sensitive information (eg. API keys, auth tokens) then you should always choose the secure option.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;VM Cloud&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Running docker images on a virtual machine/bare metal server is much like running locally.&lt;/p&gt; &#xA;&lt;p&gt;You&#39;ll need to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Configure your server&lt;/li&gt; &#xA; &lt;li&gt;Set up docker&lt;/li&gt; &#xA; &lt;li&gt;Clone this repository&lt;/li&gt; &#xA; &lt;li&gt;Edit &lt;code&gt;.env&lt;/code&gt;and &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;docker compose up&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Find a list of compatible VM providers &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#compatible-vm-providers&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Connecting to Your Instance&lt;/h3&gt; &#xA;&lt;p&gt;All services listen for connections at &lt;a href=&#34;https://en.m.wikipedia.org/wiki/0.0.0.0&#34;&gt;&lt;code&gt;0.0.0.0&lt;/code&gt;&lt;/a&gt;. This gives you some flexibility in how you interact with your instance:&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Expose the Ports&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is fine if you are working locally but can be &lt;strong&gt;dangerous for remote connections&lt;/strong&gt; where data is passed in plaintext between your machine and the container over http.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;SSH Tunnel&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;You will only need to expose port &lt;code&gt;22&lt;/code&gt; (SSH) which can then be used with port forwarding to allow &lt;strong&gt;secure&lt;/strong&gt; connections to your services.&lt;/p&gt; &#xA;&lt;p&gt;If you are unfamiliar with port forwarding then you should read the guides &lt;a href=&#34;https://link.ai-dock.org/guide-ssh-tunnel-do-a&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://link.ai-dock.org/guide-ssh-tunnel-do-b&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cloudflare Tunnel&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can use the included &lt;code&gt;cloudflared&lt;/code&gt; service to make secure connections without having to expose any ports to the public internet. See more below.&lt;/p&gt; &#xA;&lt;h2&gt;Environment Variables&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Variable&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;CF_TUNNEL_TOKEN&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Cloudflare zero trust tunnel token - See &lt;a href=&#34;https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/&#34;&gt;documentation&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;CF_QUICK_TUNNELS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Create ephemeral Cloudflare tunnels for web services (default &lt;code&gt;true&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;COMFYUI_BRANCH&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ComfyUI branch/commit hash. Defaults to &lt;code&gt;master&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;COMFYUI_FLAGS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Startup flags. eg. &lt;code&gt;--gpu-only --highvram&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;COMFYUI_PORT&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ComfyUI interface port (default &lt;code&gt;8188&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;DIRECT_ADDRESS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;IP/hostname for service portal direct links (default &lt;code&gt;localhost&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;DIRECT_ADDRESS_GET_WAN&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Use the internet facing interface for direct links (default &lt;code&gt;false&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;GPU_COUNT&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Limit the number of available GPUs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;PROVISIONING_SCRIPT&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;URL of a remote script to execute on init. See &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#provisioning-script&#34;&gt;note&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;RCLONE_*&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Rclone configuration - See &lt;a href=&#34;https://rclone.org/docs/#config-file&#34;&gt;rclone documentation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;SKIP_ACL&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Set &lt;code&gt;true&lt;/code&gt; to skip modifying workspace ACL&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;SSH_PORT_LOCAL&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Set a non-standard port for SSH (default &lt;code&gt;22&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;USER_NAME&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;System account username (default &lt;code&gt;user&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;USER_PASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;System account username (default &lt;code&gt;password&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;WEB_ENABLE_AUTH&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Enable password protection for web services (default &lt;code&gt;true&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;WEB_USER&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Username for web services (default &lt;code&gt;user&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;WEB_PASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Password for web services (default &lt;code&gt;auto generated&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;WORKSPACE&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A volume path. Defaults to &lt;code&gt;/workspace/&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;WORKSPACE_SYNC&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Move mamba environments and services to workspace if mounted (default &lt;code&gt;false&lt;/code&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Environment variables can be specified by using any of the standard methods (&lt;code&gt;docker-compose.yaml&lt;/code&gt;, &lt;code&gt;docker run -e...&lt;/code&gt;). Additionally, environment variables can also be passed as parameters of &lt;code&gt;init.sh&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Passing environment variables to init.sh is usually unnecessary, but is useful for some cloud environments where the full &lt;code&gt;docker run&lt;/code&gt; command cannot be specified.&lt;/p&gt; &#xA;&lt;p&gt;Example usage: &lt;code&gt;docker run -e STANDARD_VAR1=&#34;this value&#34; -e STANDARD_VAR2=&#34;that value&#34; init.sh EXTRA_VAR=&#34;other value&#34;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;All ai-dock containers are interactive and will not drop root privileges. You should ensure that your docker daemon runs as an unprivileged user.&lt;/p&gt; &#xA;&lt;h3&gt;System&lt;/h3&gt; &#xA;&lt;p&gt;A system user will be created at startup. The UID will be either 1000 or will match the UID of the &lt;code&gt;$WORKSPACE&lt;/code&gt; bind mount.&lt;/p&gt; &#xA;&lt;p&gt;The user will share the root user&#39;s ssh public key.&lt;/p&gt; &#xA;&lt;p&gt;Some processes may start in the user context for convenience only.&lt;/p&gt; &#xA;&lt;h3&gt;Web Services&lt;/h3&gt; &#xA;&lt;p&gt;By default, all exposed web services are protected by a single login form at &lt;code&gt;:1111/login&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The default username is &lt;code&gt;user&lt;/code&gt; and the password is auto generated unless you have passed a value in the environment variable &lt;code&gt;WEB_PASSWORD&lt;/code&gt;. To find the auto-generated password and related tokens you should type &lt;code&gt;env | grep WEB_&lt;/code&gt; from inside the container.&lt;/p&gt; &#xA;&lt;p&gt;You can set your credentials by passing environment variables as shown above.&lt;/p&gt; &#xA;&lt;p&gt;If you are running the image locally on a trusted network, you may disable authentication by setting the environment variable &lt;code&gt;WEB_ENABLE_AUTH=false&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you need to connect programmatically to the web services you can authenticate using either &lt;code&gt;Bearer $WEB_TOKEN&lt;/code&gt; or &lt;code&gt;Basic $WEB_PASSWORD_B64&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The security measures included aim to be as secure as basic authentication, i.e. not secure without HTTPS. Please use the provided cloudflare connections wherever possible.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;br&gt; You can use &lt;code&gt;set-web-credentials.sh &amp;lt;username&amp;gt; &amp;lt;password&amp;gt;&lt;/code&gt; to change the username and password in a running container.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Provisioning script&lt;/h2&gt; &#xA;&lt;p&gt;It can be useful to perform certain actions when starting a container, such as creating directories and downloading files.&lt;/p&gt; &#xA;&lt;p&gt;You can use the environment variable &lt;code&gt;PROVISIONING_SCRIPT&lt;/code&gt; to specify the URL of a script you&#39;d like to run.&lt;/p&gt; &#xA;&lt;p&gt;The URL must point to a plain text file - GitHub Gists/Pastebin (raw) are suitable options.&lt;/p&gt; &#xA;&lt;p&gt;If you are running locally you may instead opt to mount a script at &lt;code&gt;/opt/ai-dock/bin/provisioning.sh&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;br&gt; If configured, &lt;code&gt;sshd&lt;/code&gt;, &lt;code&gt;caddy&lt;/code&gt;, &lt;code&gt;cloudflared&lt;/code&gt;, &lt;code&gt;serviceportal&lt;/code&gt;, &lt;code&gt;storagemonitor&lt;/code&gt; &amp;amp; &lt;code&gt;logtail&lt;/code&gt; will be launched before provisioning; Any other processes will launch after.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING]&lt;br&gt; Only use scripts that you trust and which cannot be changed without your consent.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Software Management&lt;/h2&gt; &#xA;&lt;p&gt;A small software collection is installed by apt-get to provide basic utility.&lt;/p&gt; &#xA;&lt;p&gt;All other software is installed into its own environment by &lt;code&gt;micromamba&lt;/code&gt;, which is a drop-in replacement for conda/mamba. Read more about it &lt;a href=&#34;https://mamba.readthedocs.io/en/latest/user_guide/micromamba.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Micromamba environments are particularly useful where several software packages are required but their dependencies conflict.&lt;/p&gt; &#xA;&lt;h3&gt;Installed Micromamba Environments&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Environment&lt;/th&gt; &#xA;   &lt;th&gt;Packages&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;micromamba&#39;s base environment&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;comfyui&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ComfyUI and dependencies&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;python_[ver]&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;python&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;If you are extending this image or running an interactive session where additional software is required, you should almost certainly create a new environment first. See below for guidance.&lt;/p&gt; &#xA;&lt;h3&gt;Useful Micromamba Commands&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Command&lt;/th&gt; &#xA;   &lt;th&gt;Function&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;micromamba env list&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;List available environments&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;micromamba activate [name]&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Activate the named environment&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;micromamba deactivate&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Close the active environment&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;micromamba run -n [name] [command]&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Run a command in the named environment without activating&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;All ai-dock images create micromamba environments using the &lt;code&gt;--always-softlink&lt;/code&gt; flag which can save disk space where multiple environments are available.&lt;/p&gt; &#xA;&lt;p&gt;To create an additional micromamba environment, eg for python, you can use the following:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;micromamba --always-softlink create -y -c conda-forge -c defaults -n [name] python=3.10&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Volumes&lt;/h2&gt; &#xA;&lt;p&gt;Data inside docker containers is ephemeral - You&#39;ll lose all of it when the container is destroyed.&lt;/p&gt; &#xA;&lt;p&gt;You may opt to mount a data volume at &lt;code&gt;/workspace&lt;/code&gt; - This is a directory that ai-dock images will look for to make downloaded data available outside of the container for persistence.&lt;/p&gt; &#xA;&lt;p&gt;When the runtime scripts detect a mounted workspace, the &lt;code&gt;ComfyUI&lt;/code&gt; directory will be moved there from its original location in &lt;code&gt;/opt&lt;/code&gt;. If the workspace is not mounted then a symlink will be created for convenience.&lt;/p&gt; &#xA;&lt;p&gt;You can define an alternative path for the workspace directory by passing the environment variable &lt;code&gt;WORKSPACE=/my/alternative/path/&lt;/code&gt; and mounting your volume there. This feature will generally assist where cloud providers enforce their own mountpoint location for persistent storage.&lt;/p&gt; &#xA;&lt;p&gt;The provided docker-compose.yaml will mount the local directory &lt;code&gt;./workspace&lt;/code&gt; at &lt;code&gt;/workspace&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;As docker containers generally run as the root user, new files created in /workspace will be owned by uid 0(root).&lt;/p&gt; &#xA;&lt;p&gt;To ensure that the files remain accessible to the local user that owns the directory, the docker entrypoint will set a default ACL on the directory by executing the commamd &lt;code&gt;setfacl -d -m u:${WORKSPACE_UID}:rwx /workspace&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Running Services&lt;/h2&gt; &#xA;&lt;p&gt;This image will spawn multiple processes upon starting a container because some of our remote environments do not support more than one container per instance.&lt;/p&gt; &#xA;&lt;p&gt;All processes are managed by &lt;a href=&#34;https://supervisord.readthedocs.io/en/latest/&#34;&gt;supervisord&lt;/a&gt; and will restart upon failure until you either manually stop them or terminate the container.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;br&gt; &lt;em&gt;Some of the included services would not normally be found &lt;strong&gt;inside&lt;/strong&gt; of a container. They are, however, necessary here as some cloud providers give no access to the host; Containers are deployed as if they were a virtual machine.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;ComfyUI&lt;/h3&gt; &#xA;&lt;p&gt;The service will launch on port &lt;code&gt;8188&lt;/code&gt; unless you have specified an override with &lt;code&gt;COMFYUI_PORT&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;ComfyUI will be updated to the latest version on container start. You can pin the version to a branch or commit hash by setting the &lt;code&gt;COMFYUI_BRANCH&lt;/code&gt; variable.&lt;/p&gt; &#xA;&lt;p&gt;You can set startup flags by using variable &lt;code&gt;COMFYUI_FLAGS&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To manage this service you can use &lt;code&gt;supervisorctl [start|stop|restart] comfyui&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;ComfyUI RP API&lt;/h3&gt; &#xA;&lt;p&gt;This service is available on port &lt;code&gt;8188&lt;/code&gt; and is used to test the &lt;a href=&#34;https://link.ai-dock.org/runpod-serverless&#34;&gt;RunPod serverless&lt;/a&gt; API.&lt;/p&gt; &#xA;&lt;p&gt;You can access the api directly at &lt;code&gt;/rp-api/runsync&lt;/code&gt; or you can use the Swager/openAPI playground at &lt;code&gt;/rp-api&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There are several &lt;a href=&#34;https://github.com/ai-dock/comfyui/tree/main/build/COPY_ROOT/opt/serverless/docs/example_payloads&#34;&gt;example payloads&lt;/a&gt; included in this repository.&lt;/p&gt; &#xA;&lt;p&gt;This API is available on all platforms - But the container can ony run in serverless mode on RunPod infrastructure.&lt;/p&gt; &#xA;&lt;p&gt;To learn more about the serverless API see the &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#runpod-serverless&#34;&gt;serverless section&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;API Playground&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/.github/images/api1.png&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Jupyter (with tag &lt;code&gt;jupyter&lt;/code&gt; only)&lt;/h3&gt; &#xA;&lt;p&gt;The jupyter server will launch a &lt;code&gt;lab&lt;/code&gt; instance unless you specify &lt;code&gt;JUPYTER_MODE=notebook&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Jupyter server will listen on port &lt;code&gt;8888&lt;/code&gt; unless you have specified an alternative with the &lt;code&gt;JUPYTER_PORT&lt;/code&gt; environment variable.&lt;/p&gt; &#xA;&lt;p&gt;A python kernel will be installed coresponding with the python version of the image.&lt;/p&gt; &#xA;&lt;p&gt;Jupyter&#39;s official documentation is available at &lt;a href=&#34;https://jupyter.org/&#34;&gt;https://jupyter.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Caddy&lt;/h3&gt; &#xA;&lt;p&gt;This is a simple webserver acting as a reverse proxy.&lt;/p&gt; &#xA;&lt;p&gt;Caddy is used to enable basic authentication for all sensitive web services.&lt;/p&gt; &#xA;&lt;h3&gt;Service Portal&lt;/h3&gt; &#xA;&lt;p&gt;This is a simple list of links to the web services available inside the container.&lt;/p&gt; &#xA;&lt;p&gt;The service will bind to port &lt;code&gt;1111&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For each service, you will find a direct link and, if you have set &lt;code&gt;CF_QUICK_TUNNELS=true&lt;/code&gt;, a link to the service via a fast and secure Cloudflare tunnel.&lt;/p&gt; &#xA;&lt;p&gt;A simple web-based log viewer and process manager are included for convenience.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Service Portal links&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/.github/images/serviceportal-links.png&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Service Portal logs&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/.github/images/serviceportal-logs.png&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Service Portal process manager&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/.github/images/serviceportal-processes.png&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Cloudflared&lt;/h3&gt; &#xA;&lt;p&gt;The Cloudflare tunnel daemon will start if you have provided a token with the &lt;code&gt;CF_TUNNEL_TOKEN&lt;/code&gt; environment variable.&lt;/p&gt; &#xA;&lt;p&gt;This service allows you to connect to your local services via https without exposing any ports.&lt;/p&gt; &#xA;&lt;p&gt;You can also create a private network to enable remote connecions to the container at its local address (&lt;code&gt;172.x.x.x&lt;/code&gt;) if your local machine is running a Cloudflare WARP client.&lt;/p&gt; &#xA;&lt;p&gt;If you do not wish to provide a tunnel token, you could enable &lt;code&gt;CF_QUICK_TUNNELS&lt;/code&gt; which will create a throwaway tunnel for your web services.&lt;/p&gt; &#xA;&lt;p&gt;Secure links can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#service-portal&#34;&gt;service portal&lt;/a&gt; and in the log files at &lt;code&gt;/var/log/supervisor/quicktunnel-*.log&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Full documentation for Cloudflare tunnels is &lt;a href=&#34;https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;br&gt; &lt;em&gt;Cloudflared is included so that secure networking is available in all cloud environments.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING]&lt;br&gt; You should only provide tunnel tokens in secure cloud environments.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;SSHD&lt;/h3&gt; &#xA;&lt;p&gt;A SSH server will be started if at least one valid public key is found inside the running container in the file &lt;code&gt;/root/.ssh/authorized_keys&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The server will bind to port &lt;code&gt;22&lt;/code&gt; unless you specify variable &lt;code&gt;SSH_PORT&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There are several ways to get your keys to the container.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;If using docker compose, you can paste your key in the local file &lt;code&gt;config/authorized_keys&lt;/code&gt; before starting the container.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You can pass the environment variable &lt;code&gt;SSH_PUBKEY&lt;/code&gt; with your public key as the value.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Cloud providers often have a built-in method to transfer your key into the container&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you choose not to provide a public key then the SSH server will not be started.&lt;/p&gt; &#xA;&lt;p&gt;To make use of this service you should map port &lt;code&gt;22&lt;/code&gt; to a port of your choice on the host operating system.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://link.ai-dock.org/guide-sshd-do&#34;&gt;this guide&lt;/a&gt; by DigitalOcean for an excellent introduction to working with SSH servers.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;br&gt; &lt;em&gt;SSHD is included because the end-user should be able to know the version prior to deloyment. Using a providers add-on, if available, does not guarantee this.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Logtail&lt;/h3&gt; &#xA;&lt;p&gt;This script follows and prints the log files for each of the above services to stdout. This allows you to follow the progress of all running services through docker&#39;s own logging system.&lt;/p&gt; &#xA;&lt;p&gt;If you are logged into the container you can follow the logs by running &lt;code&gt;logtail.sh&lt;/code&gt; in your shell.&lt;/p&gt; &#xA;&lt;h3&gt;Storage Monitor&lt;/h3&gt; &#xA;&lt;p&gt;This service detects changes to files in &lt;code&gt;$WORKSPACE/storage&lt;/code&gt; and creates symbolic links to the application directories defined in &lt;code&gt;/opt/ai-dock/storage_monitor/etc/mappings.sh&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Open Ports&lt;/h2&gt; &#xA;&lt;p&gt;Some ports need to be exposed for the services to run or for certain features of the provided software to function&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Open Port&lt;/th&gt; &#xA;   &lt;th&gt;Service / Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;22&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;SSH server&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;1111&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Service Portal web UI&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;8188&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ComfyUI Interface&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;8888&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Jupyter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;53682&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Rclone interactive config&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Pre-Configured Templates&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Vast.​ai&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://link.ai-dock.org/template-vast-comfyui&#34;&gt;comfyui:latest&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://link.ai-dock.org/template-vast-comfyui-jupyter&#34;&gt;comfyui:latest-jupyter&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;Runpod.​io&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://link.ai-dock.org/template-runpod-comfyui&#34;&gt;comfyui:latest&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://link.ai-dock.org/template-runpod-comfyui-jupyter&#34;&gt;comfyui:latest-jupyter&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;Paperspace&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a &lt;a href=&#34;https://link.ai-dock.org/console.paperspace.com&#34;&gt;new notebook&lt;/a&gt; with the &lt;code&gt;Start from Scratch&lt;/code&gt; template.&lt;/li&gt; &#xA; &lt;li&gt;Select &lt;code&gt;Advanced options&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;In Container Name enter &lt;code&gt;ghcr.io/ai-dock/comfyui:latest-jupyter&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;In Command enter &lt;code&gt;init.sh WORKSPACE=/notebooks PROVISIONING_SCRIPT=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/config/provisioning/get-models-sd-official.sh&#34; CF_QUICK_TUNNELS=true&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can use the web UI to do further configuration, or you can supply further environment variables as detailed above.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;br&gt; The use of &lt;code&gt;CF_QUICK_TUNNELS&lt;/code&gt; enables us to reach the web UI with a link supplied by Cloudflare. You can find the link in &lt;code&gt;/var/log/supervisor/quicktunnel-comfyui.log&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING]&lt;br&gt; Do not attempt to use tunnels to circumvent Paperspace restrictions (eg. SSH &amp;amp; private networking) - You will lose your account.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;br&gt; These templates are configured to use the &lt;code&gt;:latest&lt;/code&gt; tag but you are free to change to any of the available Pytorch CUDA tags listed &lt;a href=&#34;https://github.com/ai-dock/comfyui/pkgs/container/comfyui&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Compatible VM Providers&lt;/h2&gt; &#xA;&lt;p&gt;Images that do not require a GPU will run anywhere - Use an image tagged &lt;code&gt;:*-cpu-xx.xx&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Where a GPU is required you will need either &lt;code&gt;:*cuda*&lt;/code&gt; or &lt;code&gt;:*rocm*&lt;/code&gt; depending on the underlying hardware.&lt;/p&gt; &#xA;&lt;p&gt;A curated list of VM providers currently offering GPU instances:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://link.ai-dock.org/linode.com&#34;&gt;Akami/Linode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://link.ai-dock.org/aws.amazon.com&#34;&gt;Amazon Web Services&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://link.ai-dock.org/cloud.google.com&#34;&gt;Google Compute Engine&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://link.ai-dock.org/vultr.com&#34;&gt;Vultr&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;RunPod Serverless&lt;/h2&gt; &#xA;&lt;p&gt;The container can be used as a &lt;a href=&#34;https://link.ai-dock.org/runpod-serverless&#34;&gt;RunPod serverless&lt;/a&gt; worker. To enable serverless mode you must run the container with environment variables &lt;code&gt;SERVERLESS=true&lt;/code&gt; and &lt;code&gt;WORKSPACE=runpod-volume&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The handlers will accept a job, process it and upload your images to s3 compatible storage.&lt;/p&gt; &#xA;&lt;p&gt;You may either set your s3 credentials as environment variables or you can pass them to the worker in the payload.&lt;/p&gt; &#xA;&lt;p&gt;You should set &lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;, &lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;, &lt;code&gt;AWS_ENDPOINT_URL&lt;/code&gt; and &lt;code&gt;AWS_BUCKET_NAME&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Serverless template example&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/.github/images/runpod-template.png&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;If passed in the payload these variables should be in lowercase.&lt;/p&gt; &#xA;&lt;p&gt;Incorrect or unset s3 credentials will not resut in job failure. You can still retrieve your images from the network volume.&lt;/p&gt; &#xA;&lt;p&gt;When used in serverless mode, the container will skip provisioning and will not update ComfyUI or the nodes on start so you must either ensure everyting you need is built into the image (see &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#building-images&#34;&gt;Building Images&lt;/a&gt;) or first run the container with a network volume in GPU Cloud to get everything set up before launching your workers.&lt;/p&gt; &#xA;&lt;p&gt;After launching a serverless worker, any instances of the container launched on the network volume in GPU cloud will also skip auto-updating. All updates must be done manually.&lt;/p&gt; &#xA;&lt;p&gt;The API is documented in openapi format. You can test it in a running container on the ComfyUI port at &lt;code&gt;/rp-api/docs&lt;/code&gt; - See &lt;a href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/#comfyui-rp-api&#34;&gt;ComfyUI RP API&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;The API can use multiple handlers which you may define in the payload. Three handlers have been included for your convenience&lt;/p&gt; &#xA;&lt;h3&gt;Handler: RawWorkflow&lt;/h3&gt; &#xA;&lt;p&gt;This handler should be passed a full ComfyUI workflow in the payload. It will detect any URL&#39;s and download the files into the input directory before replacing the URL value with the local path of the resource. This is very useful when working with image to image and controlnets.&lt;/p&gt; &#xA;&lt;p&gt;This is the most flexible of all handlers.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;RawWorkflow schema&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/.github/images/api-schema-rawworkflow.png&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;a target=&#34;_blank&#34; href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/build/COPY_ROOT/opt/serverless/docs/example_payloads/raw_controlnet_t2i_adapters.json&#34;&gt;Example payload&lt;/a&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Handler: Text2Image&lt;/h3&gt; &#xA;&lt;p&gt;This is a basic handler that is bound to a static workflow file (&lt;code&gt;/opt/serverless/workflows/text2image.json&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;You can define several overrides to modify the workflow before processing.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Text2Image schema&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/.github/images/api-schema-text2image.png&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;a target=&#34;_blank&#34; href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/build/COPY_ROOT/opt/serverless/docs/example_payloads/bound_text2image.json&#34;&gt;Example payload&lt;/a&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Handler: Image2Image&lt;/h3&gt; &#xA;&lt;p&gt;This is a basic handler that is bound to a static workflow file (&lt;code&gt;/opt/serverless/workflows/image2image.json&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;You can define several overrides to modify the workflow before processing.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Image2Image schema&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/.github/images/api-schema-text2image.png&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;a target=&#34;_blank&#34; href=&#34;https://raw.githubusercontent.com/ai-dock/comfyui/main/build/COPY_ROOT/opt/serverless/docs/example_payloads/bound_image2image.json&#34;&gt;Example payload&lt;/a&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;These handlers demonstrate how you can create a very simple endpoint which will require very little frontend work to implement.&lt;/p&gt; &#xA;&lt;p&gt;You can find example payloads for these handlers &lt;a href=&#34;https://github.com/ai-dock/comfyui/tree/main/build/COPY_ROOT/opt/serverless/docs/example_payloads&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;em&gt;The author (&lt;a href=&#34;https://github.com/robballantyne&#34;&gt;@robballantyne&lt;/a&gt;) may be compensated if you sign up to services linked in this document. Testing multiple variants of GPU images in many different environments is both costly and time-consuming; This helps to offset costs&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
</feed>