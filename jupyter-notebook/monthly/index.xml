<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-01T02:02:52Z</updated>
  <subtitle>Monthly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Baiyuetribe/paper2gui</title>
    <updated>2022-12-01T02:02:52Z</updated>
    <id>tag:github.com,2022-12-01:/Baiyuetribe/paper2gui</id>
    <link href="https://github.com/Baiyuetribe/paper2gui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Convert AI papers to GUI，Make it easy and convenient for everyone to use artificial intelligence technology。让每个人都简单方便的使用前沿人工智能技术&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;&lt;p align=&#34;center&#34;&gt; Paper2GUI 🚀🚀🌟: 让每个人都简单方便的使用前沿人工智能技术 &lt;/p&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Paper2GUI: 一款面向普通人的AI桌面APP工具箱，免安装即开即用，已支持20+AI模型，内容涵盖语音合成、视频补帧、视频超分、目标检测、图片风格化、OCR识别等领域。支持Windows、Mac、Linux系统。&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/README_en.md&#34;&gt;English&lt;/a&gt; | 中文 | &lt;a href=&#34;https://t.me/baiyueblog&#34;&gt;Telegram&lt;/a&gt; | &lt;a href=&#34;https://www.bilibili.com/video/BV1jY411u7yU&#34;&gt;B站(媒体)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;经过两个月的开发，我们将现有的优秀AI模型进行了统一融合，Paper2GUI 现在有了一个中文名“小白兔AI”。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/docs/images/xiaobaituai.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;下载地址：&lt;a href=&#34;https://ffsup.oduuu.com/uploads%2F1759%2F2022%2F11%2FLFYBw9HN_%E5%B0%8F%E7%99%BD%E5%85%94AI_v2.3.0.zip&#34;&gt;Download&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;已发布内容【单独APP完全免费】&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Text2Speech/readme.md&#34;&gt;语音合成&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;文字转语音工具，适用于配音、讲解、说书、广告等场景。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Text2Speech/microsoft_tts.md&#34;&gt;微软语音合成🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;5Mb&lt;/td&gt; &#xA;   &lt;td&gt;FastSpeech&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Text2Speech/huoshan_tts.md&#34;&gt;抖音火山语音🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;13Mb&lt;/td&gt; &#xA;   &lt;td&gt;Unknown&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Text2Speech/aliyun_tts.md&#34;&gt;阿里云语音合成&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;13Mb&lt;/td&gt; &#xA;   &lt;td&gt;Unknown&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/StableDiffusion/readme.md&#34;&gt;艺术绘画&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;文本转图片，想象力与AI的完美结合&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/StableDiffusion/readme.md&#34;&gt;StableDiffusion🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;10Mb&lt;/td&gt; &#xA;   &lt;td&gt;Naifu&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Video%20Super%20Resolution/readme.md&#34;&gt;视频超分辨放大&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;视频超分工具，适用于720p或360p视频转1080p或4k视频,画质升级且不模糊，目前主要用于动漫视频超分。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Video%20Super%20Resolution/RealESRGAN-GUI-RAM.md&#34;&gt;RealESRGAN-GUI(RAM)🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;41.8Mb&lt;/td&gt; &#xA;   &lt;td&gt;RealESRGANv3&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Video%20Super%20Resolution/waifu2x-gui.md&#34;&gt;waifu2x-GUI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;38.9Mb&lt;/td&gt; &#xA;   &lt;td&gt;waifu2x&lt;/td&gt; &#xA;   &lt;td&gt;⏳&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Video%20Super%20Resolution/RealESRGAN-GUI.md&#34;&gt;RealESRGAN-GUI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;28.8Mb&lt;/td&gt; &#xA;   &lt;td&gt;RealESRGANv2&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Video%20Super%20Resolution/RealCugan-GUI.md&#34;&gt;RealCugan-GUI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;56.4Mb&lt;/td&gt; &#xA;   &lt;td&gt;RealCugan&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Video%20Super%20Resolution/RealSR-GUI.md&#34;&gt;RealSR-GUI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;94.5Mb&lt;/td&gt; &#xA;   &lt;td&gt;RealSR&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Video%20Frame%20Interpolation/readme.md&#34;&gt;视频补帧&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;运动类视频流畅度升级工具，可以将低帧率30fps升级到60fps或360fps。适用于丝滑质感需求。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Video%20Frame%20Interpolation/rife-gui.md&#34;&gt;RIFE-GUI(RAM)🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;51.2Mb&lt;/td&gt; &#xA;   &lt;td&gt;Rife&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Video%20Frame%20Interpolation/dain-gui.md&#34;&gt;DAIN-GUI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;72.6Mb&lt;/td&gt; &#xA;   &lt;td&gt;Dain&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Style%20Transfer/readme.md&#34;&gt;图像风格化(照片转动漫)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;图像风格化，可以将照片转换为动漫风格、梵高风格、毕加索风格等等。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Style%20Transfer/animegan_gui.md&#34;&gt;AnimeGAN-GUI🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;8.9Mb&lt;/td&gt; &#xA;   &lt;td&gt;AnimeGANv2&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/ImageMatting/readme.md&#34;&gt;人像抠图&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;AI一键抠图，可生成透明图、绿幕、红幕、蓝幕等背景图片，头发丝处理良好，适合任意人物抠图需求。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/ImageMatting/rvm_gui.md&#34;&gt;RVM-GUI🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;12.9Mb&lt;/td&gt; &#xA;   &lt;td&gt;rvm&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/FaceRestoration/readme.md&#34;&gt;人像修复&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;人像修复，可以将人像修复为清晰的图片，提升清晰度。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/FaceRestoration/readme.md&#34;&gt;GFPGAN-GUI🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;242Mb&lt;/td&gt; &#xA;   &lt;td&gt;GFPGAN&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/VideoMatting/readme.md&#34;&gt;视频抠图&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;视频抠图，利用RVM等算法，可实现无绿幕视频抠图，适合各种自媒体视频制作，节约大量时间。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/VideoMatting/modnet_gui.md&#34;&gt;MODNet-GUI🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;77.5Mb&lt;/td&gt; &#xA;   &lt;td&gt;modnet&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/VideoMatting/modnet_gui.md&#34;&gt;MobileNetV2-GUI🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;34.6Mb&lt;/td&gt; &#xA;   &lt;td&gt;MobileNetV2&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Object%20Detection/readme.md&#34;&gt;目标检测&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;适用范围太广，比如物体检测、口罩检测、车牌检测、车辆检测、苹果质量等级检测等等。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Object%20Detection/yolov6_gui.md&#34;&gt;YOLOv6-GUI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;46Mb&lt;/td&gt; &#xA;   &lt;td&gt;yolov6n&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Object%20Detection/yolov5_gui.md&#34;&gt;YOLOv5-GUI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;60.2Mb&lt;/td&gt; &#xA;   &lt;td&gt;yolov5s&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Object%20Detection/yolox_gui.md&#34;&gt;YOLOX-GUI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;50Mb&lt;/td&gt; &#xA;   &lt;td&gt;yolox_nano&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Auxiliary_tools/readme.md&#34;&gt;辅助工具&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;辅助工具，提供了一些常用的辅助工具，比如视频比对工具等。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;大小&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;多语言&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Mac&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/Auxiliary_tools/readme.md&#34;&gt;Video_compare🔥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;56.1Mb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;🔲&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/paper2gui/releases/tag/Published&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xiaobaituai.com&#34;&gt;小白兔AI - 聚合版【更专业的选择】&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;小白兔AI 是一款功能非常强大的人工智能软件,实现了语音合成、视频抠图、动漫超分辨、视频补帧、录音降噪、视频上色、人脸动漫化、图片OCR批量识别等十余种功能，致力于打造一款实用、好玩又有趣的AI生产力聚合工具箱。面向专业用户，可免费试用7天。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;已内置功能&lt;/th&gt; &#xA;   &lt;th&gt;适用场景&lt;/th&gt; &#xA;   &lt;th&gt;功能简介&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RealCugan-Pro动漫超分辨&lt;/td&gt; &#xA;   &lt;td&gt;动漫图片或视频超分辨放大&lt;/td&gt; &#xA;   &lt;td&gt;自研AI引擎驱动，可获得最高质量的动漫超分辨效果，可能是目前唯一可轻松使用RealCugan-Pro模型的软件&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RealESRGAN动漫超分辨&lt;/td&gt; &#xA;   &lt;td&gt;动漫图片或视频&lt;/td&gt; &#xA;   &lt;td&gt;推理速度快，质量比waifu2x好太多，常规超分辨首选&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;智能抠图&lt;/td&gt; &#xA;   &lt;td&gt;任意图片或视频&lt;/td&gt; &#xA;   &lt;td&gt;推理速度快，一键获得透明图片或绿幕视，进行二次创作&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;人像动漫化&lt;/td&gt; &#xA;   &lt;td&gt;仅适合头像处理&lt;/td&gt; &#xA;   &lt;td&gt;转换效果出众，有趣又好玩&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;语音合成&lt;/td&gt; &#xA;   &lt;td&gt;自媒体视频配音、有声读书等&lt;/td&gt; &#xA;   &lt;td&gt;效果逼近真人，发音自然、带呼吸声、支持txt大文件极速合成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;录音降噪&lt;/td&gt; &#xA;   &lt;td&gt;真人配音后处理&lt;/td&gt; &#xA;   &lt;td&gt;一键去除环境和背景噪音，提升录音清晰度，效果明显&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;视频补帧&lt;/td&gt; &#xA;   &lt;td&gt;运动类视频流畅度升级工具&lt;/td&gt; &#xA;   &lt;td&gt;可获得丝滑观感，已支持RIFE和IFRNET两种AI模型&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;一键超补&lt;/td&gt; &#xA;   &lt;td&gt;同时完成超分和补帧&lt;/td&gt; &#xA;   &lt;td&gt;融合超分和补帧模型，一键获得超补结果&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AI一键跑分&lt;/td&gt; &#xA;   &lt;td&gt;一键查看设备AI性能数据&lt;/td&gt; &#xA;   &lt;td&gt;模拟真实推理任务，统一量化推理任务，耗时越小越好&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;图片OCR识别&lt;/td&gt; &#xA;   &lt;td&gt;图片转文字&lt;/td&gt; &#xA;   &lt;td&gt;基于Paddle-OCR-v3模型，迄今最优秀的OCR识别模型、效果出众&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;视频字幕OCR提取&lt;/td&gt; &#xA;   &lt;td&gt;硬字幕提取&lt;/td&gt; &#xA;   &lt;td&gt;使用PP-OCR自动识别字幕位置及文字，输出字幕文件&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;视频上色&lt;/td&gt; &#xA;   &lt;td&gt;老旧黑白照片或视频上色&lt;/td&gt; &#xA;   &lt;td&gt;适合风景类黑白视频上色，推理速度快&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;人脸修复&lt;/td&gt; &#xA;   &lt;td&gt;人脸照片修复&lt;/td&gt; &#xA;   &lt;td&gt;可增强老旧照片、修复人脸，提高清晰度&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;目标检测&lt;/td&gt; &#xA;   &lt;td&gt;图像检测和分割&lt;/td&gt; &#xA;   &lt;td&gt;展示AI技术在通用场景下的检测、分割、追踪等效果&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;聚合版面向专业需求用户，付费只是为了做的更好更专业。功能持续添加中，已开源的20个单独APP完全免费，各取所需，请勿喷我，如果项目帮到了你，不妨点个Star。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;部分截图&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Baiyuetribe/paper2gui@main/docs/images/huoshan_tts.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://cdn.jsdelivr.net/gh/Baiyuetribe/paper2gui@main/docs/images/microsoft_tts.gif&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/docs/images/gfpgan_gui.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/docs/images/rvm_gui.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/docs/images/video_compare.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Baiyuetribe/paper2gui@main/docs/images/rife-gui.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Baiyuetribe/paper2gui@main/docs/images/modnet_gui.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/docs/images/realESRGAN_RAM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Baiyuetribe/paper2gui@main/docs/images/realcugan-gui.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Baiyuetribe/paper2gui@main/docs/images/animegan-gui.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/docs/images/yolov6_gui.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/docs/images/yolox_gui.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/docs/images/yolov5_gui.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;适配说明&lt;/h3&gt; &#xA;&lt;p&gt;本人开发环境为&lt;code&gt;Windows&lt;/code&gt;系统，默认会发布&lt;code&gt;Windows&lt;/code&gt;和&lt;code&gt;Linux&lt;/code&gt;版本，得益于微软&lt;code&gt;Sandbox&lt;/code&gt;和&lt;code&gt;WSL2&lt;/code&gt;，可随时测试这些环境。Mac版需要主动参与反馈。为了拓展和持续产出优质又实用的AI生产力工具，现已上架“小白兔AI”，欢迎大家助力开发者，推动人工智能的普及化。&lt;/p&gt; &#xA;&lt;h3&gt;社群交流&lt;/h3&gt; &#xA;&lt;p&gt;QQ群：497556961（限时领福利）&lt;/p&gt; &#xA;&lt;h3&gt;变更日志&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Baiyuetribe/paper2gui/main/docs/CHANGELOG.md&#34;&gt;查看&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;参考&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/webview/webview&#34;&gt;webview/webview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn&#34;&gt;Tencent/ncnn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FFmpeg/FFmpeg&#34;&gt;FFmpeg/FFmpeg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wailsapp/wails&#34;&gt;wailsapp/wails&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;xinntao/Real-ESRGAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nihui/waifu2x-ncnn-vulkan&#34;&gt;nihui/waifu2x-ncnn-vulkan&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nihui/realcugan-ncnn-vulkan&#34;&gt;nihui/realcugan-ncnn-vulkan&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nihui/rife-ncnn-vulkan&#34;&gt;nihui/rife-ncnn-vulkan&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN/&#34;&gt;RealESRGAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/TuSimple/naive-ui&#34;&gt;TuSimple/naive-ui&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vitejs/vite&#34;&gt;vitejs/vite&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Baiyuetribe/ncnn-models&#34;&gt;Baiyuetribe/ncnn-models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Star History&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#Baiyuetribe/paper2gui&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=Baiyuetribe/paper2gui&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>WongKinYiu/yolov7</title>
    <updated>2022-12-01T02:02:52Z</updated>
    <id>tag:github.com,2022-12-01:/WongKinYiu/yolov7</id>
    <link href="https://github.com/WongKinYiu/yolov7" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implementation of paper - YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Official YOLOv7&lt;/h1&gt; &#xA;&lt;p&gt;Implementation of paper - &lt;a href=&#34;https://arxiv.org/abs/2207.02696&#34;&gt;YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/real-time-object-detection-on-coco?p=yolov7-trainable-bag-of-freebies-sets-new&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/yolov7-trainable-bag-of-freebies-sets-new/real-time-object-detection-on-coco&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/akhaliq/yolov7&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/gist/AlexeyAB/b769f5795e65fdab80086f6cb7940dae/yolov7detection.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2207.02696&#34;&gt;&lt;img src=&#34;http://img.shields.io/badge/cs.CV-arXiv%3A2207.02696-B31B1B.svg?sanitize=true&#34; alt=&#34;arxiv.org&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/figure/performance.png&#34; width=&#34;79%&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Web Demo&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Integrated into &lt;a href=&#34;https://huggingface.co/spaces/akhaliq/yolov7&#34;&gt;Huggingface Spaces 🤗&lt;/a&gt; using Gradio. Try out the Web Demo &lt;a href=&#34;https://huggingface.co/spaces/akhaliq/yolov7&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;MS COCO&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Test Size&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;AP&lt;sup&gt;test&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;AP&lt;sub&gt;50&lt;/sub&gt;&lt;sup&gt;test&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;AP&lt;sub&gt;75&lt;/sub&gt;&lt;sup&gt;test&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;batch 1 fps&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;batch 32 average time&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt&#34;&gt;&lt;strong&gt;YOLOv7&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;51.4%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;69.7%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;55.9%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;161 &lt;em&gt;fps&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.8 &lt;em&gt;ms&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7x.pt&#34;&gt;&lt;strong&gt;YOLOv7-X&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;640&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;53.1%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;71.2%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;57.8%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;114 &lt;em&gt;fps&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.3 &lt;em&gt;ms&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6.pt&#34;&gt;&lt;strong&gt;YOLOv7-W6&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;54.9%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;72.6%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;60.1%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;84 &lt;em&gt;fps&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.6 &lt;em&gt;ms&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6.pt&#34;&gt;&lt;strong&gt;YOLOv7-E6&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;56.0%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;73.5%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56 &lt;em&gt;fps&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12.3 &lt;em&gt;ms&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-d6.pt&#34;&gt;&lt;strong&gt;YOLOv7-D6&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;56.6%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;74.0%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;61.8%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44 &lt;em&gt;fps&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.0 &lt;em&gt;ms&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6e.pt&#34;&gt;&lt;strong&gt;YOLOv7-E6E&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1280&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;56.8%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;74.4%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;62.1%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36 &lt;em&gt;fps&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18.7 &lt;em&gt;ms&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Docker environment (recommended)&lt;/p&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; &lt;b&gt;Expand&lt;/b&gt; &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# create the docker container, you can change the share memory size if you have more.&#xA;nvidia-docker run --name yolov7 -it -v your_coco_path/:/coco/ -v your_code_path/:/yolov7 --shm-size=64g nvcr.io/nvidia/pytorch:21.08-py3&#xA;&#xA;# apt install required packages&#xA;apt update&#xA;apt install -y zip htop screen libgl1-mesa-glx&#xA;&#xA;# pip install required packages&#xA;pip install seaborn thop&#xA;&#xA;# go to code folder&#xA;cd /yolov7&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt&#34;&gt;&lt;code&gt;yolov7.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7x.pt&#34;&gt;&lt;code&gt;yolov7x.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6.pt&#34;&gt;&lt;code&gt;yolov7-w6.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6.pt&#34;&gt;&lt;code&gt;yolov7-e6.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-d6.pt&#34;&gt;&lt;code&gt;yolov7-d6.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6e.pt&#34;&gt;&lt;code&gt;yolov7-e6e.pt&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python test.py --data data/coco.yaml --img 640 --batch 32 --conf 0.001 --iou 0.65 --device 0 --weights yolov7.pt --name yolov7_640_val&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You will get the results:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.51206&#xA; Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.69730&#xA; Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.55521&#xA; Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.35247&#xA; Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.55937&#xA; Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.66693&#xA; Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.38453&#xA; Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.63765&#xA; Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.68772&#xA; Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.53766&#xA; Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.73549&#xA; Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.83868&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To measure accuracy, download &lt;a href=&#34;http://images.cocodataset.org/annotations/annotations_trainval2017.zip&#34;&gt;COCO-annotations for Pycocotools&lt;/a&gt; to the &lt;code&gt;./coco/annotations/instances_val2017.json&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;Data preparation&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bash scripts/get_coco.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download MS COCO dataset images (&lt;a href=&#34;http://images.cocodataset.org/zips/train2017.zip&#34;&gt;train&lt;/a&gt;, &lt;a href=&#34;http://images.cocodataset.org/zips/val2017.zip&#34;&gt;val&lt;/a&gt;, &lt;a href=&#34;http://images.cocodataset.org/zips/test2017.zip&#34;&gt;test&lt;/a&gt;) and &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/coco2017labels-segments.zip&#34;&gt;labels&lt;/a&gt;. If you have previously used a different version of YOLO, we strongly recommend that you delete &lt;code&gt;train2017.cache&lt;/code&gt; and &lt;code&gt;val2017.cache&lt;/code&gt; files, and redownload &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/coco2017labels-segments.zip&#34;&gt;labels&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Single GPU training&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# train p5 models&#xA;python train.py --workers 8 --device 0 --batch-size 32 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights &#39;&#39; --name yolov7 --hyp data/hyp.scratch.p5.yaml&#xA;&#xA;# train p6 models&#xA;python train_aux.py --workers 8 --device 0 --batch-size 16 --data data/coco.yaml --img 1280 1280 --cfg cfg/training/yolov7-w6.yaml --weights &#39;&#39; --name yolov7-w6 --hyp data/hyp.scratch.p6.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Multiple GPU training&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# train p5 models&#xA;python -m torch.distributed.launch --nproc_per_node 4 --master_port 9527 train.py --workers 8 --device 0,1,2,3 --sync-bn --batch-size 128 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights &#39;&#39; --name yolov7 --hyp data/hyp.scratch.p5.yaml&#xA;&#xA;# train p6 models&#xA;python -m torch.distributed.launch --nproc_per_node 8 --master_port 9527 train_aux.py --workers 8 --device 0,1,2,3,4,5,6,7 --sync-bn --batch-size 128 --data data/coco.yaml --img 1280 1280 --cfg cfg/training/yolov7-w6.yaml --weights &#39;&#39; --name yolov7-w6 --hyp data/hyp.scratch.p6.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Transfer learning&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt&#34;&gt;&lt;code&gt;yolov7_training.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7x_training.pt&#34;&gt;&lt;code&gt;yolov7x_training.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6_training.pt&#34;&gt;&lt;code&gt;yolov7-w6_training.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6_training.pt&#34;&gt;&lt;code&gt;yolov7-e6_training.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-d6_training.pt&#34;&gt;&lt;code&gt;yolov7-d6_training.pt&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6e_training.pt&#34;&gt;&lt;code&gt;yolov7-e6e_training.pt&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Single GPU finetuning for custom dataset&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# finetune p5 models&#xA;python train.py --workers 8 --device 0 --batch-size 32 --data data/custom.yaml --img 640 640 --cfg cfg/training/yolov7-custom.yaml --weights &#39;yolov7_training.pt&#39; --name yolov7-custom --hyp data/hyp.scratch.custom.yaml&#xA;&#xA;# finetune p6 models&#xA;python train_aux.py --workers 8 --device 0 --batch-size 16 --data data/custom.yaml --img 1280 1280 --cfg cfg/training/yolov7-w6-custom.yaml --weights &#39;yolov7-w6_training.pt&#39; --name yolov7-w6-custom --hyp data/hyp.scratch.custom.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Re-parameterization&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/tools/reparameterization.ipynb&#34;&gt;reparameterization.ipynb&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;On video:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source yourvideo.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source inference/images/horses.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/figure/horses_prediction.jpg&#34; width=&#34;59%&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Export&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pytorch to CoreML (and inference on MacOS/iOS)&lt;/strong&gt; &lt;a href=&#34;https://colab.research.google.com/github/WongKinYiu/yolov7/blob/main/tools/YOLOv7CoreML.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pytorch to ONNX with NMS (and inference)&lt;/strong&gt; &lt;a href=&#34;https://colab.research.google.com/github/WongKinYiu/yolov7/blob/main/tools/YOLOv7onnx.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python export.py --weights yolov7-tiny.pt --grid --end2end --simplify \&#xA;        --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 640 640 --max-wh 640&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pytorch to TensorRT with NMS (and inference)&lt;/strong&gt; &lt;a href=&#34;https://colab.research.google.com/github/WongKinYiu/yolov7/blob/main/tools/YOLOv7trt.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt&#xA;python export.py --weights ./yolov7-tiny.pt --grid --end2end --simplify --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 640 640&#xA;git clone https://github.com/Linaom1214/tensorrt-python.git&#xA;python ./tensorrt-python/export.py -o yolov7-tiny.onnx -e yolov7-tiny-nms.trt -p fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pytorch to TensorRT another way&lt;/strong&gt; &lt;a href=&#34;https://colab.research.google.com/gist/AlexeyAB/fcb47ae544cf284eb24d8ad8e880d45c/yolov7trtlinaom.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;/p&gt;&#xA;&lt;details&gt;&#xA; &lt;summary&gt; &lt;b&gt;Expand&lt;/b&gt; &lt;/summary&gt;&#xA; &lt;p&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt&#xA;python export.py --weights yolov7-tiny.pt --grid --include-nms&#xA;git clone https://github.com/Linaom1214/tensorrt-python.git&#xA;python ./tensorrt-python/export.py -o yolov7-tiny.onnx -e yolov7-tiny-nms.trt -p fp16&#xA;&#xA;# Or use trtexec to convert ONNX to TensorRT engine&#xA;/usr/src/tensorrt/bin/trtexec --onnx=yolov7-tiny.onnx --saveEngine=yolov7-tiny-nms.trt --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Tested with: Python 3.7.13, Pytorch 1.12.0+cu113&lt;/p&gt; &#xA;&lt;h2&gt;Pose estimation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/tree/pose&#34;&gt;&lt;code&gt;code&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt&#34;&gt;&lt;code&gt;yolov7-w6-pose.pt&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/raw/main/tools/keypoint.ipynb&#34;&gt;keypoint.ipynb&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/figure/pose.png&#34; width=&#34;39%&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Instance segmentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolov7/tree/mask&#34;&gt;&lt;code&gt;code&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-mask.pt&#34;&gt;&lt;code&gt;yolov7-mask.pt&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/WongKinYiu/yolov7/raw/main/tools/instance.ipynb&#34;&gt;instance.ipynb&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/figure/mask.png&#34; width=&#34;59%&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{wang2022yolov7,&#xA;  title={{YOLOv7}: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},&#xA;  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},&#xA;  journal={arXiv preprint arXiv:2207.02696},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Teaser&lt;/h2&gt; &#xA;&lt;p&gt;Yolov7-semantic &amp;amp; YOLOv7-panoptic &amp;amp; YOLOv7-caption&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/figure/tennis.jpg&#34; width=&#34;24%&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/figure/tennis_semantic.jpg&#34; width=&#34;24%&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/figure/tennis_panoptic.png&#34; width=&#34;24%&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/WongKinYiu/yolov7/main/figure/tennis_caption.png&#34; width=&#34;24%&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; &lt;b&gt;Expand&lt;/b&gt; &lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/AlexeyAB/darknet&#34;&gt;https://github.com/AlexeyAB/darknet&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/WongKinYiu/yolor&#34;&gt;https://github.com/WongKinYiu/yolor&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/WongKinYiu/PyTorch_YOLOv4&#34;&gt;https://github.com/WongKinYiu/PyTorch_YOLOv4&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/WongKinYiu/ScaledYOLOv4&#34;&gt;https://github.com/WongKinYiu/ScaledYOLOv4&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/Megvii-BaseDetection/YOLOX&#34;&gt;https://github.com/Megvii-BaseDetection/YOLOX&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/ultralytics/yolov3&#34;&gt;https://github.com/ultralytics/yolov3&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/ultralytics/yolov5&#34;&gt;https://github.com/ultralytics/yolov5&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/DingXiaoH/RepVGG&#34;&gt;https://github.com/DingXiaoH/RepVGG&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/JUGGHM/OREPA_CVPR2022&#34;&gt;https://github.com/JUGGHM/OREPA_CVPR2022&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/TexasInstruments/edgeai-yolov5/tree/yolo-pose&#34;&gt;https://github.com/TexasInstruments/edgeai-yolov5/tree/yolo-pose&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt;</summary>
  </entry>
  <entry>
    <title>huggingface/deep-rl-class</title>
    <updated>2022-12-01T02:02:52Z</updated>
    <id>tag:github.com,2022-12-01:/huggingface/deep-rl-class</id>
    <link href="https://github.com/huggingface/deep-rl-class" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repo contain the syllabus of the Hugging Face Deep Reinforcement Learning Class.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Hugging Face Deep Reinforcement Learning Class 🤗&lt;/h1&gt; &#xA;&lt;p&gt;In this free course, you will:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;📖 Study Deep Reinforcement Learning in &lt;strong&gt;theory and practice&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;🧑‍💻 Learn to &lt;strong&gt;use famous Deep RL libraries&lt;/strong&gt; such as Stable Baselines3, RL Baselines3 Zoo, and RLlib.&lt;/li&gt; &#xA; &lt;li&gt;🤖 Train agents in &lt;strong&gt;unique environments&lt;/strong&gt; such as SnowballFight, Huggy the Doggo 🐶, and classical ones such as Space Invaders and PyBullet.&lt;/li&gt; &#xA; &lt;li&gt;💾 &lt;strong&gt;Publish your trained agents in one line of code to the Hugging Face Hub&lt;/strong&gt;. But also &lt;strong&gt;download powerful agents from the community&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;🏆 &lt;strong&gt;Participate in challenges&lt;/strong&gt; where you will evaluate your agents against other teams.&lt;/li&gt; &#xA; &lt;li&gt;🖌️🎨 &lt;strong&gt;Learn to share your own environments made with Unity and Godot&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;➡️➡️➡️ Don&#39;t forget to sign up here: &lt;a href=&#34;http://eepurl.com/h1pElX&#34;&gt;http://eepurl.com/h1pElX&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The best way to keep in touch is to &lt;strong&gt;join our discord server to exchange with the community and with us&lt;/strong&gt; 👉🏻 &lt;a href=&#34;https://discord.gg/aYka4Yhff9&#34;&gt;https://discord.gg/aYka4Yhff9&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Are you new to Discord? Check our &lt;strong&gt;discord 101 to get the best practices&lt;/strong&gt; 👉 &lt;a href=&#34;https://github.com/huggingface/deep-rl-class/raw/main/DISCORD.Md&#34;&gt;https://github.com/huggingface/deep-rl-class/blob/main/DISCORD.Md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;And don&#39;t forget to share with your friends who want to learn 🤗!&lt;/p&gt; &#xA;&lt;h2&gt;The Syllabus 🏗️&lt;/h2&gt; &#xA;&lt;p&gt;This course is &lt;strong&gt;self-paced&lt;/strong&gt; you can start when you want 🥳.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;📆 Publishing date&lt;/th&gt; &#xA;   &lt;th&gt;📘 Unit&lt;/th&gt; &#xA;   &lt;th&gt;👩‍💻 Hands-on&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit1#unit-1-introduction-to-deep-reinforcement-learning&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit1&#34;&gt;An Introduction to Deep Reinforcement Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/raw/main/unit1/unit1.ipynb&#34;&gt;Train a Deep Reinforcement Learning lander agent to land correctly on the Moon 🌕 using Stable-Baselines3&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit1/unit1-bonus&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit1/unit1-bonus&#34;&gt;Bonus&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/raw/main/unit2/README.md&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/raw/main/unit2/README.md&#34;&gt;Q-Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/raw/main/unit2/unit2.ipynb&#34;&gt;Train an agent to cross a Frozen lake ⛄ and train an autonomous taxi 🚖&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit3#unit-3-deep-q-learning-with-atari-games-&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit3#unit-3-deep-q-learning-with-atari-games-&#34;&gt;Deep Q-Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Train a Deep Q-Learning agent to play Space Invaders using &lt;a href=&#34;https://github.com/DLR-RM/rl-baselines3-zoo&#34;&gt;RL-Baselines3-Zoo&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/raw/main/unit3/bonus.md&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/raw/main/unit3/bonus.md&#34;&gt;Bonus: Automatic Hyperparameter Tuning using Optuna&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit4#unit-4-an-introduction-to-unity-mlagents-with-hugging-face-&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit4#unit-4-an-introduction-to-unity-mlagents-with-hugging-face-&#34;&gt;🎁 Learn to train your first Unity MLAgent&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit4/unit4.ipynb&#34;&gt;Train a curious agent to destroy Pyramids 💥&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit5#unit-5-policy-gradient-with-pytorch&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/blog/deep-rl-pg&#34;&gt;Policy Gradient with PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit5/unit5.ipynb&#34;&gt;Code a Reinforce agent from scratch using PyTorch and train it to play Pong 🎾, CartPole and Pixelcopter 🚁&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit6#towards-better-explorations-methods-with-curiosity&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit6#towards-better-explorations-methods-with-curiosity&#34;&gt;Towards better explorations methods with Curiosity&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit7#unit-7-advantage-actor-critic-a2c-using-robotics-simulations-with-pybullet-&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit7#unit-7-advantage-actor-critic-a2c-using-robotics-simulations-with-pybullet-&#34;&gt;Advantage Actor Critic (A2C)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit7#unit-7-advantage-actor-critic-a2c-using-robotics-simulations-with-pybullet-&#34;&gt;Train a bipedal walker and a spider to learn to walk using A2C&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit8#unit-8-proximal-policy-optimization-ppo-with-pytorch&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit8#unit-8-proximal-policy-optimization-ppo-with-pytorch&#34;&gt;Proximal Policy Optimization (PPO)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit8/unit8.ipynb&#34;&gt;Code a PPO agent from scratch using PyTorch and bulletproof it with Classical Control Environments&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit9#unit-9-decision-transformers-and-offline-reinforcement-learning-&#34;&gt;Published 🥳&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/deep-rl-class/tree/main/unit9#unit-9-decision-transformers-and-offline-reinforcement-learning-&#34;&gt;Decision Transformers and offline Reinforcement Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/blog/raw/main/notebooks/101_train-decision-transformers.ipynb&#34;&gt;Train your first Offline Decision Transformer model from scratch to make a half-cheetah run &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;The library you&#39;ll learn during this course&lt;/h2&gt; &#xA;&lt;p&gt;Version 1.0 (current):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DLR-RM/stable-baselines3&#34;&gt;Stable-Baselines3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DLR-RM/rl-baselines3-zoo&#34;&gt;RL Baselines3 Zoo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vwxyzjn/cleanrl&#34;&gt;CleanRL&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Version 2.0 (in addition to SB3, RL-Baselines3-Zoo and CleanRL):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.ray.io/en/latest/rllib/index.html&#34;&gt;RLlib&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/alex-petrenko/sample-factory&#34;&gt;Sample Factory&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/blog/decision-transformers&#34;&gt;Hugging Face Decision Transformers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;More to come 🏗️&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;The Environments you&#39;ll use&lt;/h2&gt; &#xA;&lt;h3&gt;Custom environments made by the Hugging Face Team using Unity and Godot&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Environment&lt;/th&gt; &#xA;   &lt;th&gt;Screenshot&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Huggy the Doggo 🐶 (Based on &lt;a href=&#34;https://blog.unity.com/technology/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit&#34;&gt;Unity&#39;s Puppo the Corgi work&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/huggy.jpg&#34; alt=&#34;lunarlander.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SnowballFight ☃️ 👉 Play it here: &lt;a href=&#34;https://huggingface.co/spaces/ThomasSimonini/SnowballFight&#34;&gt;https://huggingface.co/spaces/ThomasSimonini/SnowballFight&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/snowballfight.gif&#34; alt=&#34;snowballfight.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Gym classic and controls environments 🕹️&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Environment&lt;/th&gt; &#xA;   &lt;th&gt;Screenshot&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lunar Lander 🚀🌙&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/lunarlander.gif&#34; alt=&#34;lunarlander.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Frozen Lake ⛄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/frozenlake.gif&#34; alt=&#34;frozenlake.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Taxi 🚖&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/taxi.gif&#34; alt=&#34;taxi.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Cartpole&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/cartpole.jpg&#34; alt=&#34;cartpole.jpg&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Pong 🎾&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/pong.jpg&#34; alt=&#34;pong.jpg&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Pixelcopter 🚁&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/pixelcopter.jpg&#34; alt=&#34;pong.jpg&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Gym Atari environments 👾&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Environment&lt;/th&gt; &#xA;   &lt;th&gt;Screenshot&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Space Invaders 👾&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/spaceinvaders.gif&#34; alt=&#34;spaceinvaders.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Breakout&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/breakout.gif&#34; alt=&#34;breakout.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qbert&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/qbert.gif&#34; alt=&#34;qbert.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Seaquest&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/seaquest.gif&#34; alt=&#34;seaquest.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;PyBullet 🤖&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Environment&lt;/th&gt; &#xA;   &lt;th&gt;Screenshot&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ant Bullet&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/antbullet.gif&#34; alt=&#34;antbullet.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Walker 2D Bullet&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/deep-rl-class/main/assets/img/walker2d.gif&#34; alt=&#34;walker2d.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;MLAgents environments 🖌️&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;More to come 🚧&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;More to come 🚧&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Good skills in Python 🐍&lt;/li&gt; &#xA; &lt;li&gt;Basics in Deep Learning and Pytorch&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If it&#39;s not the case yet, you can check these free resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python: &lt;a href=&#34;https://www.udacity.com/course/introduction-to-python--ud1110&#34;&gt;https://www.udacity.com/course/introduction-to-python--ud1110&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Intro to Deep Learning with PyTorch: &lt;a href=&#34;https://www.udacity.com/course/deep-learning-pytorch--ud188&#34;&gt;https://www.udacity.com/course/deep-learning-pytorch--ud188&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;PyTorch in 60min: &lt;a href=&#34;https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html&#34;&gt;https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Is this class free?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Yes, totally free 🥳.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Do I need to have a Hugging Face account to follow the course?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Yes, to push your trained agents during the hands-on, you need an account (it&#39;s free) 🤗.&lt;/p&gt; &#xA;&lt;p&gt;You can create one here 👉 &lt;a href=&#34;https://huggingface.co/join&#34;&gt;https://huggingface.co/join&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What’s the format of the class?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The course consists of&amp;nbsp;&lt;strong&gt;8 Units.&lt;/strong&gt;&amp;nbsp;In each of the Units, we&#39;ll have:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;A theory explained part&lt;/strong&gt;: an article and a video (based on Deep Reinforcement Learning Course)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;A hands-on Google Colab&lt;/strong&gt; where you&#39;ll learn to use famous Deep RL libraries such as Stable Baselines3, RL Baselines3 Zoo, and RLlib to train your agents in unique environments such as SnowballFight, Huggy the Doggo 🐶, and classical ones such as Space Invaders and PyBullet.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Some optional challenges&lt;/strong&gt;: train an agent in another environment, and try to beat the results.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;It&#39;s not a live course video, so you can watch and read each unit when you want 🤗 You can check the syllabus here 👉 &lt;a href=&#34;https://github.com/huggingface/deep-rl-class&#34;&gt;https://github.com/huggingface/deep-rl-class&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;What I will do during this course?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;In this free course, you will:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;📖 Study Deep Reinforcement Learning in theory and practice.&lt;/li&gt; &#xA; &lt;li&gt;🧑‍💻 Learn to use famous Deep RL libraries such as Stable Baselines3, RL Baselines3 Zoo, and RLlib.&lt;/li&gt; &#xA; &lt;li&gt;🤖 Train agents in unique environments such as SnowballFight, Huggy the Doggo 🐶, and classical ones such as Space Invaders and PyBullet.&lt;/li&gt; &#xA; &lt;li&gt;💾 Publish your trained agents in one line of code to the Hub. But also download powerful agents from the community.&lt;/li&gt; &#xA; &lt;li&gt;🏆 Participate in challenges where you will evaluate your agents against other teams.&lt;/li&gt; &#xA; &lt;li&gt;🖌️🎨 Learn to share your own environments made with Unity and Godot.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Where do I sign up?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here 👉 &lt;a href=&#34;http://eepurl.com/h1pElX&#34;&gt;http://eepurl.com/h1pElX&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Where can I find the course?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;On this repository&lt;/strong&gt;, we&#39;ll publish every week the links (chapters, hands-ons, videos).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Where can I exchange with my classmates and with you?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;We have a discord server where you &lt;strong&gt;can exchange with the community and with us&lt;/strong&gt; 👉🏻 &lt;a href=&#34;https://discord.gg/aYka4Yhff9&#34;&gt;https://discord.gg/aYka4Yhff9&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Don’t forget to &lt;strong&gt;introduce yourself when you sign up 🤗&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;I have some feedback&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;We want to improve and update the course iteratively with your feedback. If you have some, please fill this form 👉 &lt;a href=&#34;https://forms.gle/3HgA7bEHwAmmLfwh9&#34;&gt;https://forms.gle/3HgA7bEHwAmmLfwh9&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How much background knowledge is needed?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Some prerequisites:&lt;/p&gt; &#xA;&lt;p&gt;Good skills in &lt;strong&gt;Python&lt;/strong&gt; 🐍 Basics in &lt;strong&gt;Deep Learning and Pytorch&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If it&#39;s not the case yet, you can check these free resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python: &lt;a href=&#34;https://www.udacity.com/course/introduction-to-python--ud1110&#34;&gt;https://www.udacity.com/course/introduction-to-python--ud1110&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Intro to Deep Learning with PyTorch: &lt;a href=&#34;https://www.udacity.com/course/deep-learning-pytorch--ud188&#34;&gt;https://www.udacity.com/course/deep-learning-pytorch--ud188&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;PyTorch in 60min: &lt;a href=&#34;https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html&#34;&gt;https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Is there a certificate?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Yes 🎉. You&#39;ll &lt;strong&gt;need to upload the eight models with the eight hands-on.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citing the project&lt;/h2&gt; &#xA;&lt;p&gt;To cite this repository in publications:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{deep-rl-class,&#xA;  author = {Simonini, Thomas and Sanseviero, Omar},&#xA;  title = {The Hugging Face Deep Reinforcement Learning Class},&#xA;  year = {2022},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/huggingface/deep-rl-class}},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>