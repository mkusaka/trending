<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-01T01:53:31Z</updated>
  <subtitle>Monthly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>jaakkopasanen/AutoEq</title>
    <updated>2023-01-01T01:53:31Z</updated>
    <id>tag:github.com,2023-01-01:/jaakkopasanen/AutoEq</id>
    <link href="https://github.com/jaakkopasanen/AutoEq" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Automatic headphone equalization from frequency responses&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AutoEq&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; If you are here just looking to make your headphones sound better, find your headphone model in &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/results&#34;&gt;results&lt;/a&gt; folder&#39;s recommended headphones list and follow instructions in &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#usage&#34;&gt;Usage&lt;/a&gt; section.&lt;/p&gt; &#xA;&lt;h2&gt;About This Project&lt;/h2&gt; &#xA;&lt;p&gt;AutoEq is a project for equalizing headphone frequency responses automatically, and it achieves this by parsing frequency response measurements and producing equalization settings which correct the headphone to a neutral sound. This project currently has over 4000 headphones covered in the &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/results&#34;&gt;results&lt;/a&gt; folder. See &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#usage&#34;&gt;Usage&lt;/a&gt; for instructions how to use the results with different equalizer softwares and &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#results&#34;&gt;Results&lt;/a&gt; section for details about parameters and how the results were obtained.&lt;/p&gt; &#xA;&lt;p&gt;AutoEq is not just a collection of automatically produced headphone equalization settings but also a tool for equalizing headphones for yourself. AutoEq provides methods for reading data, equalizing it to a given target response and saving the results for usage with equalizers. It&#39;s possible to use different compensation (target) curves, apply tilt for making the headphones brighter/darker and adding a bass boost. It&#39;s even possible to make one headphone sound (roughly) like another headphone. For more info about equalizing see &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#equalizing&#34;&gt;Equalizing&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Third major contribution of this project is the measurement data and compensation curves all in a numerical format except for Crinacle&#39;s raw data. Everything is stored as CSV files so they are easy to process with any programming language or even Excel.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/results/oratory1990/harman_over-ear_2018/Sennheiser%20HD%20800/Sennheiser%20HD%20800.png&#34; alt=&#34;Sennheiser HD 800&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Sennheiser HD 800 equalization results plotted&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Updates&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;2022-10-30&lt;/strong&gt; Restructured the project and published in PyPi. Source code moved under &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/autoeq&#34;&gt;autoeq&lt;/a&gt; directory and command line usage changed from &lt;code&gt;python autoeq.py&lt;/code&gt; to &lt;code&gt;python -m autoeq&lt;/code&gt; with underscores &lt;code&gt;_&lt;/code&gt; replaced with hyphens &lt;code&gt;-&lt;/code&gt; in the parameter names.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;2022-09-18&lt;/strong&gt; Parametric eq optimizer reworked. The new optimizer supports shelf filters, has a powerful configuration system, run 10x faster, has limits for Fc, Q and gain value ranges and treats +10 kHz range as average value instead of trying to fix it precisely.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;AutoEq produces settings for basically all types of equalizer apps.&lt;/p&gt; &#xA;&lt;h3&gt;Parametric Equalizers&lt;/h3&gt; &#xA;&lt;p&gt;Parametric equalizers have filters (bands) with user adjustable gain, center frequency and quality Q. Keep in mind that parametric eq accuracy depends on the number of filters available. Usually 10 filters produce very good results but as little as 5 can be good enough. Keep in mind that different parametric equalizers will produce different outcomes with the same parameter values. Parameters produced by AutoEq are equal with EqualizerAPO using 44.1 kHz sampling rate. When using other equalizers or sampling rates, it&#39;s always highly recommended to check that the frequency response of the equalizer matches the parametric eq curve in the graphs.&lt;/p&gt; &#xA;&lt;p&gt;All parametric equalizer except Peace require you to configure the filter parameters manually with the software user interface. Some parametric equalizer use filter width (band width) instead of Q. Filter width can be calculated as: &lt;code&gt;bw = Fc / Q&lt;/code&gt; where &lt;code&gt;bw&lt;/code&gt; is the band width in Herts, &lt;code&gt;Fc&lt;/code&gt; is center frequency and &lt;code&gt;Q&lt;/code&gt; is quality. Filter width in octaves can be calculated as: &lt;code&gt;N = ln(1 + 1/(2*Q^2) + sqrt(((2*Q^2 + 1) / Q^2 )^2 / 4 - 1)) / ln(2)&lt;/code&gt; where &lt;code&gt;ln&lt;/code&gt; is the natural logarithm. See &lt;a href=&#34;http://www.sengpielaudio.com/calculator-bandwidth.htm&#34;&gt;http://www.sengpielaudio.com/calculator-bandwidth.htm&lt;/a&gt; for an online calculator.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s very important to set preamp according to the value given in the result README.md document. Parametric eq filters will produce positive gains and to avoid clipping a preamp with negative gain is required.&lt;/p&gt; &#xA;&lt;p&gt;Parametric eq settings can be used with Peace or any other parametric eq which has at least 5 bands available. Even fewer bands is possible but pre-computed results require you to use at least the five first of the filters. Parametric equalizer filter parameters look like this:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Type&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Fc&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Q&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Gain&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;LowShelf&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;105 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.70&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;6.3 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;162 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.91&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-2.3 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;2237 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.94&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-4.6 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;6093 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;2.26&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-4.7 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;8251 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.71&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-2.9 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Fixed Band Equalizers&lt;/h3&gt; &#xA;&lt;p&gt;Fixed band eq is more commonly known as graphic equalizer but in order not to confuse with EqualizerAPO GraphicEQ it is called like that in this project. Fixed band equalizer is like parametric equalizer with several peaking filters but don&#39;t have adjustable frequency information, only gain. All other types are preferred over fixed band equalizers but on some devices these are the only available ones.&lt;/p&gt; &#xA;&lt;p&gt;Fixed band equalizers have trouble compensating for narrow notches and peaks that fall between two bands. Good example is &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/results/oratory1990/harman_over-ear_2018/Sennheiser%20HD%20800&#34;&gt;Sennheiser HD 800&lt;/a&gt; with it&#39;s 6 kHz peak that is right in between 4 kHz and 8 kHz bands of standard 10-band equalizer. When using 10-band equalizer check if the fixed band equalization curve is very different than the desired equalization curve at some frequency and adjust the nearby filters by ear for best results.&lt;/p&gt; &#xA;&lt;p&gt;Fixed band equalizer settings look like this:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Type&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Fc&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Q&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Gain&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;31 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;6.1 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;62 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.0 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;125 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-1.1 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;250 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-2.2 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;500 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-0.9 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1000 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.1 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;2000 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.6 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;4000 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-1.0 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;8000 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-4.1 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;16000 Hz&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-7.5 dB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Convolution Equalizers&lt;/h3&gt; &#xA;&lt;p&gt;Convolution equalizer is the most powerful type of equalizer software. These equalizers allow extremely precise control over the frequency response and the results are the same on all devices and platforms when using the same FIR filter.&lt;/p&gt; &#xA;&lt;p&gt;AutoEq supports convolution equalizers with FIR filters as WAV files and with EqualizerAPO&#39;s GraphicEQ filter type. The default results contain FIR filters for both 44.1 kHz and 48 kHz sampling rates. Other sampling rates are supported but not given in the default results. EqualizerAPO&#39;s GraphicEQ works with any sampling rate.&lt;/p&gt; &#xA;&lt;p&gt;To use the FIR filters, download the appropriate WAV file and import it to the EQ software of your choice. Please keep in mind that not all EQ softwares support convolution. Some equalizers can load multiple FIR filters at the same time. Download both WAV files, create a Zip file containing both and load the Zip file to for example Roon.&lt;/p&gt; &#xA;&lt;p&gt;Convolution equalizers might produce clipping with AutoEq generated files despite the fact that AutoEq normalizes the impulse responses. You can add a few dB of negative preamp with &lt;code&gt;--preamp&lt;/code&gt; parameter if you experience clipping.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#EqualizerAPO&#34;&gt;EqualizerApo&lt;/a&gt; for instructions on how to use the GraphicEQ.&lt;/p&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;p&gt;has &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#equalizerapo&#34;&gt;EqualizerAPO&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#peace&#34;&gt;Peace&lt;/a&gt; and many media players with parametric equalizers such as &lt;a href=&#34;https://www.microsoft.com/en-us/p/neutron-music-player/9nblggh4vp2h?activetab=pivot:overviewtab&#34;&gt;Neutron&lt;/a&gt;, &lt;a href=&#34;https://roonlabs.com/&#34;&gt;Roon&lt;/a&gt; and &lt;a href=&#34;https://www.foobar2000.org/&#34;&gt;Foobar2000&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;EqualizerAPO&lt;/h4&gt; &#xA;&lt;p&gt;It&#39;s possible to use plain &lt;a href=&#34;https://sourceforge.net/projects/equalizerapo/&#34;&gt;EqualizerAPO&lt;/a&gt; and edit configuration file in &lt;code&gt;C:\Program Files\EqualizerAPO\config\config.txt&lt;/code&gt;. Replace contents of the file with the GraphicEQ.txt file found in results. Preamp is not needed because it is incorporated into the GraphicEQ line. Using &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/results/oratory1990/harman_over-ear_2018/Sennheiser%20HD%20650&#34;&gt;Sennheiser HD 650&lt;/a&gt; would make config file look like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;GraphicEQ: 20 -0.5; 21 -0.5; 22 -0.5; 23 -0.5; 24 -0.5; 26 -0.5; 27 -0.5; 29 -0.5; 30 -0.5; 32 -0.9; 34 -1.2; 36 -1.5; 38 -1.8; 40 -2.1; 43 -2.4; 45 -2.4; 48 -2.5; 50 -2.6; 53 -3.0; 56 -3.2; 59 -3.3; 63 -3.6; 66 -4.0; 70 -4.5; 74 -5.0; 78 -5.5; 83 -5.9; 87 -6.3; 92 -6.7; 97 -7.0; 103 -7.3; 109 -7.6; 115 -7.8; 121 -8.0; 128 -8.1; 136 -8.4; 143 -8.6; 151 -8.7; 160 -8.8; 169 -8.8; 178 -8.9; 188 -8.9; 199 -9.0; 210 -9.0; 222 -9.0; 235 -8.9; 248 -8.8; 262 -8.6; 277 -8.5; 292 -8.4; 309 -8.3; 326 -8.2; 345 -8.1; 364 -7.9; 385 -7.8; 406 -7.7; 429 -7.6; 453 -7.6; 479 -7.5; 506 -7.4; 534 -7.2; 565 -7.1; 596 -7.0; 630 -7.0; 665 -7.0; 703 -7.0; 743 -7.0; 784 -7.1; 829 -7.1; 875 -7.1; 924 -7.0; 977 -7.1; 1032 -7.2; 1090 -7.3; 1151 -7.2; 1216 -7.0; 1284 -6.9; 1357 -6.7; 1433 -6.4; 1514 -6.2; 1599 -6.1; 1689 -5.9; 1784 -5.6; 1885 -5.4; 1991 -5.2; 2103 -5.1; 2221 -5.2; 2347 -5.5; 2479 -5.8; 2618 -6.2; 2766 -6.6; 2921 -6.9; 3086 -7.0; 3260 -6.8; 3443 -6.2; 3637 -5.6; 3842 -5.1; 4058 -4.6; 4287 -4.2; 4528 -4.2; 4783 -4.8; 5052 -5.2; 5337 -4.8; 5637 -4.3; 5955 -4.7; 6290 -4.9; 6644 -4.7; 7018 -4.8; 7414 -5.7; 7831 -6.3; 8272 -6.5; 8738 -6.5; 9230 -6.5; 9749 -6.5; 10298 -6.5; 10878 -6.5; 11490 -6.5; 12137 -6.5; 12821 -7.8; 13543 -9.9; 14305 -9.7; 15110 -9.0; 15961 -11.0; 16860 -13.5; 17809 -14.5; 18812 -15.2; 19871 -15.7&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;EqualizerAPO has a graphical user interface for adjusting configurations. Launch the editor from &lt;code&gt;C:\Program Files\EqualizerAPO\Editor.exe&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/lHhRBuA.png&#34; alt=&#34;equalizerapo-editor&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;EqualizerAPO Editor GUI&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Peace&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sourceforge.net/projects/peace-equalizer-apo-extension/&#34;&gt;Peace&lt;/a&gt; is a GUI for manipulating parametric eq filters with EqualizerAPO. Peace also has visualization for the end result equalization frequency response, profile manager for multiple different eq settings and a switch for disabling everything among other features. Load eq settings into Peace by clicking &lt;em&gt;Import&lt;/em&gt; button and select the &lt;em&gt;&#xA;  &lt;model&gt;&#xA;    ParametricEQ.txt&#xA;  &lt;/model&gt;&lt;/em&gt; file. Set the preamp to value mentioned in the results.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/e0POEbF.png&#34; alt=&#34;peace&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Peace with full GUI for EqualizerAPO&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Android&lt;/h3&gt; &#xA;&lt;p&gt;Android has several different equalizer options but not too many powerful apps which work with all apps. Wavelet is the best option for newer Androids (version 9 and up) but older devices have a built-in fixed band equalizer which works system wide but the center frequencies and Q values vary so might need to &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#equalizing&#34;&gt;produce your own results&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Wavelet&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://play.google.com/store/apps/details?id=com.pittvandewitt.wavelet&#34;&gt;Wavelet&lt;/a&gt; is an Android app which comes with all the AutoEq eq profiles built in. The app works with all music apps so is closest to system-wide equalizer one can have on Android without rooting. The equalizer built into this app is very powerful and can represent the AutoEq profiles very accurately. There is also an option to tune the sound with graphic equalizer. Wavelet has the best Bluetooth device compatibility of all the tested eq apps on Android.&lt;/p&gt; &#xA;&lt;p&gt;The main functionalities of Wavelet are free (including AutoEq profiles and graphic eq) but some extra features can be unlocked with an in-app purchase.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/UGiBwFX.png&#34; alt=&#34;Wavelet&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Neutron&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://play.google.com/store/apps/details?id=com.neutroncode.mp&#34;&gt;Neutron&lt;/a&gt; is a music player with parametric equalizer and comes with all the AutoEq profiles built into a Frequency Response Correction DSP (FRC). It is also available on Apple iOS and Windows platforms and not free. On Android it has a &lt;a href=&#34;https://play.google.com/store/apps/details?id=com.neutroncode.mpeval&#34;&gt;trial version&lt;/a&gt; where FRC with AutoEq is fully functional and can be freely evaluated.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://neutroncode.com/images/neutronmp/feature/feature_frc_autoeq_combined.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h4&gt;USB Audio Player PRO&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://play.google.com/store/apps/details?id=com.extreamsd.usbaudioplayerpro&#34;&gt;USB Audio Player PRO&lt;/a&gt; is an Android app with improved USB audio drivers for usage with USB DACs. USB Audio Player PRO is not system-wide but works with local files and many streaming services though not with Spotify. USB Audio Player has Toneboosters Morphit plugin which has parametric equalizer. This app and the plugin are not free.&lt;/p&gt; &#xA;&lt;h4&gt;Music EQ Equalizer&lt;/h4&gt; &#xA;&lt;p&gt;The best app for system wide equalization on older Android phones (without rooting) is &lt;a href=&#34;https://play.google.com/store/apps/details?id=mediam.music.equalizer&#34;&gt;Music Equalizer EQ&lt;/a&gt; which is a 10-band standard equalizer. Gains for each band can be adjusted with only 1 dB resolution but this isn&#39;t a problem because the average error is then only 0.25 dB, hardly noticeable. Bigger problem is the potential narrow peaks and notches between the bands&#39; center frequencies since there isn&#39;t really anything that can be done for those. See notes about &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#fixed-band-equalizers&#34;&gt;fixed band equalizers&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The app starts in the presets view so you need to click the left arrow in the top left corner to get to the manual view. Here you can adjust the bands. Set each band level to the closest value to what the equalization settings ask. Pre-computed results only support standard 10-band equalizers which have band center frequencies at 31, 63, 125, 250, 500, 1000, 2000, 4000, 8000 and 16000 Hz. Q values are not adjustable so you don&#39;t have to worry about those even though they are given in the result settings.&lt;/p&gt; &#xA;&lt;h4&gt;Viper4Android&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://forum.xda-developers.com/showthread.php?t=2191223&#34;&gt;Viper4Android&lt;/a&gt; is a system-wide convolution based equalizer (and much more) on Android but it requires rooting of the device. Viper4Android is supported with impulse response (WAV) files. For rooted users this is the best option.&lt;/p&gt; &#xA;&lt;h4&gt;JamesDSP&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://forum.xda-developers.com/android/apps-games/app-reformed-dsp-manager-t3607970&#34;&gt;JamesDSP&lt;/a&gt; is an alternative to Viper4Android. It provides a system wide solution, has a convolution engine but requires rooting.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ThePBone/RootlessJamesDSP&#34;&gt;RootlessJamesDSP&lt;/a&gt; works on non-rooted devices but does not work on some apps like Spotify.&lt;/p&gt; &#xA;&lt;h3&gt;Linux&lt;/h3&gt; &#xA;&lt;h4&gt;PulseEffects / EasyEffects&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/wwmm/easyeffects&#34;&gt;PulseEffects / EasyEffects&lt;/a&gt; is a Linux module with wide variety of signal processing tools including convolution and parametric equalizers.&lt;/p&gt; &#xA;&lt;p&gt;From version 4.7.2 onwards PulseEffects added support for convolution FIR filters. This is the recommended way to apply AutoEq presets. Navigate to the plugins tab and add the convolver plugin, then click the waveform button above the stereo width controls (or just the &#39;Impulses&#39; button as of 6.1.x), click &#34;Import impulse&#34; and select the AutoEq generated WAV file. You may also need to manually click &#39;load&#39; in the Impulses menu for the filter to be fully loaded. PulseEffects&#39; convolver requires you to set the input gain to prevent clipping. The gain required by parametric eq should be sufficient, maybe 0.5 dB of negative gain more. Depending on the version, you may need to rename the &lt;code&gt;.wav&lt;/code&gt; file as &lt;code&gt;.irs&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To use parametric eq, from version 6.0.0 onwards, first select the &lt;code&gt;plugins&lt;/code&gt; tab at the bottom of the screen, add the equalizer plugin, and load APO settings by clicking &#34;Load APO Preset&#34; and selecting the ParametricEQ.txt file. For EasyEffects &amp;lt;= 6.1.3, Pre-amp can be adjusted with the input slider. Later versions support reading this from ParametricEQ.txt.&lt;/p&gt; &#xA;&lt;p&gt;From version 5.0.0 onwards, PulseEffects was renamed to EasyEffects and uses PipeWire instead of PulseAudio as backend. Load eq settings by clicking the top center cog &amp;amp; clicking &lt;em&gt;Import ACO Presets&lt;/em&gt; button and select the ParametricEQ.txt file. Pre-amp can be adjusted with the input slider.&lt;/p&gt; &#xA;&lt;p&gt;For versions prior to v4.8.0, adjust filter parameters by clicking the cog button on each filter and set type to &#34;Bell&#34;, mode to &#34;APO&#34; and adjust the gain with the slider. Number of filters can be changed by clicking the screwdriver and wrench button.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/32952512/112381638-6cd3b280-8d08-11eb-844a-b83600c6c02a.png&#34; alt=&#34;pulseeffects&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;OSX / MacOS&lt;/h3&gt; &#xA;&lt;p&gt;System wide parametric EQ solutions on OSX typically rely on separate plugin hosting software and the actual plugin which does the actual equalization.&lt;/p&gt; &#xA;&lt;p&gt;Pardon the lack of documentation for these. I have not tested any of the methods myself but they have been suggested by helpful AutoEq users.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://rogueamoeba.com/soundsource/&#34;&gt;SoundSource&lt;/a&gt; is the easiest way to use AutoEq on Mac since it comes with all of the profiles built in. The software is however not free.&lt;/p&gt; &#xA;&lt;p&gt;Audio plugin hosts include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Apple&#39;s own &lt;a href=&#34;https://www.apple.com/apple-music/apple-digital-masters/&#34;&gt;AU Lab&lt;/a&gt; hosts AU plugins and can be used as a system-wide audio output via &lt;a href=&#34;https://github.com/ExistentialAudio/BlackHole&#34;&gt;BlackHole&lt;/a&gt; or &lt;a href=&#34;https://github.com/mattingalls/Soundflower&#34;&gt;Soundflower&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.menubus.audio/versions&#34;&gt;MenuBus&lt;/a&gt; has a free version but is no longer actively developed.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://ju-x.com/hostingau.html&#34;&gt;Hosting AU&lt;/a&gt; with &lt;a href=&#34;https://github.com/ExistentialAudio/BlackHole&#34;&gt;BlackHole&lt;/a&gt; or &lt;a href=&#34;https://github.com/mattingalls/Soundflower&#34;&gt;Soundflower&lt;/a&gt; can be used as a system wide AU plugin host.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;EQ plugins include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.voxengo.com/product/primeeq/&#34;&gt;Voxengo PrimeEQ&lt;/a&gt; is a parametric EQ plugin but is not free.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.fabfilter.com/products/pro-q-3-equalizer-plug-in&#34;&gt;Fabfilter Pro Q3&lt;/a&gt; is another parametric EQ plugin, more expensive than Voxengo but might be easier to install and use. Note: Pro Q3 uses a different system and all Q values need to be multiplied by 1.41!&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://audio.lernvall.com/&#34;&gt;LAConvolver plugin&lt;/a&gt; is a free convolver EQ which works with impulse response WAV files.&lt;/li&gt; &#xA; &lt;li&gt;AUNBandEq comes built in with Mac OSX. Works at least with HostingAU + BlackHole&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/38220377/71527191-9706ac80-28da-11ea-8f70-88caf57c4821.png&#34; alt=&#34;hostingau+blackhole&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Tutorials:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.superbestaudiofriends.org/index.php?threads/systemwide-eq-on-mac.7435/&#34;&gt;Apple AU Lab + Soundflower + AUNBandEQ Tutorial&lt;/a&gt; &lt;a href=&#34;https://discussions.apple.com/thread/8552731&#34;&gt;AU Lab Permission Issue&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;eqMac&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://eqmac.app&#34;&gt;eqMac&lt;/a&gt; is a Free &amp;amp; &lt;a href=&#34;https://github.com/bitgapp/eqmac&#34;&gt;Open Source&lt;/a&gt; System Wide equalizer for macOS. eqMac has a Free 10 Band EQ and an Unlimited Band EQ (paid) with built-in AutoEq Integration! (Expert EQ)&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;512&#34; src=&#34;https://raw.githubusercontent.com/bitgapp/eqMac/master/assets/screenshots/autoeq-promo.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;iOS&lt;/h3&gt; &#xA;&lt;p&gt;iOS unfortunately doesn&#39;t allow system-wide equalizers, so the only options are either music players with built-in equalizer or &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#Hardware&#34;&gt;hardware solutions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Neutron&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://apps.apple.com/app/neutron-music-player/id766858884&#34;&gt;Neutron&lt;/a&gt; is a music player with parametric equalizer and comes with all the AutoEq profiles built into a Frequency Response Correction DSP (FRC). It is also available on Android and Windows platforms and not free.&lt;/p&gt; &#xA;&lt;h4&gt;EQE&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/rweichler/EQE&#34;&gt;EQE&lt;/a&gt; is a system wide parametric equalizer on iOS but requires jailbreaking. Here are instructions on how to set it up: &lt;a href=&#34;https://www.reddit.com/r/headphones/comments/dqbt81/psa_if_you_have_a_jailbroken_iphone_you_can/&#34;&gt;https://www.reddit.com/r/headphones/comments/dqbt81/psa_if_you_have_a_jailbroken_iphone_you_can/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Hardware&lt;/h3&gt; &#xA;&lt;p&gt;Some devices have built-in equalizers and since they do the processing in the device, they work with any source which can connect to the device.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.qudelix.com/products/qudelix-5k-dac-amp&#34;&gt;Qudelix 5K&lt;/a&gt; is a portable DAC and amplifier with wired and Bluetooth connectivity and 10 band parametric equalizer.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.minidsp.com/products/plate-amplifiers/il-dsp-headphone-amp&#34;&gt;MiniDSP IL-DSP&lt;/a&gt; is a smaller form factor mobile headphone dac/amp with 10 band parametric equalizer. The equalizer in the device doesn&#39;t have adjustable preamp but AutoEq can build that in with &lt;code&gt;--preamp&lt;/code&gt; parameter.&lt;/p&gt; &#xA;&lt;h2&gt;Equalizing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;autoeq.py&lt;/code&gt; is the tool used to produce the equalization results from measurement data. There is no fancy graphical user interface but instead it is used from command line.&lt;/p&gt; &#xA;&lt;h3&gt;Installing&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download and install Git: &lt;a href=&#34;https://git-scm.com/downloads&#34;&gt;https://git-scm.com/downloads&lt;/a&gt;. When installing Git on Windows, use Windows SSL verification instead of Open SSL or you might run into problems when installing project dependencies.&lt;/li&gt; &#xA; &lt;li&gt;Download and install 64-bit &lt;strong&gt;&lt;a href=&#34;https://www.python.org/getit/&#34;&gt;Python 3&lt;/a&gt;&lt;/strong&gt;. Make sure to check &lt;em&gt;Add Python 3.X to PATH&lt;/em&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You may need to install &lt;a href=&#34;http://www.mega-nerd.com/libsndfile/&#34;&gt;libsndfile&lt;/a&gt; if you&#39;re having problems with &lt;code&gt;soundfile&lt;/code&gt; when installing and/or running AutoEq.&lt;/li&gt; &#xA; &lt;li&gt;On Linux you may need to install Python dev packages&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt install python3-dev python3-pip python3-venv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;On Linux you may need to install &lt;a href=&#34;https://pip.pypa.io/en/stable/installing/&#34;&gt;pip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;On Windows you may need to install &lt;a href=&#34;https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads&#34;&gt;Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Open a terminal / command prompt. On Windows, search &lt;code&gt;cmd&lt;/code&gt; in the start menu.&lt;/li&gt; &#xA; &lt;li&gt;Clone AutoEq&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/jaakkopasanen/AutoEq.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go to AutoEq location&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd AutoEq&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a python virtual environment&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m venv venv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Activate virtualenv&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# On Windows&#xA;venv\Scripts\activate.bat&#xA;# On Linux and Mac&#xA;. venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Update pip&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m pip install -U pip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install required packages&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m pip install -U -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Verify installation. If everything went well, you&#39;ll see the list of command line parameters AutoEq accepts.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m autoeq --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When coming back at a later time you&#39;ll only need to activate virtual environment again&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# On Windows&#xA;cd AutoEq&#xA;venv\Scripts\activate.bat&#xA;# On Linux and Mac&#xA;cd AutoEq&#xA;. venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To learn more about virtual environments, read &lt;a href=&#34;https://docs.python.org/3.8/library/venv.html&#34;&gt;Python&#39; venv documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Updating&lt;/h4&gt; &#xA;&lt;p&gt;AutoEq is in active development and gets new measurements, results and features all the time. You can get the latest version from git&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git pull&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Dependencies may change from time to time, you can update to the latest with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m pip install -U -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Command Line Usage&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;usage: __main__.py [-h] --input-dir INPUT_DIR --output-dir OUTPUT_DIR [--standardize-input] [--new-only] [--compensation COMPENSATION] [--equalize] [--parametric-eq]&#xA;                   [--fixed-band-eq] [--rockbox] [--ten-band-eq] [--parametric-eq-config PARAMETRIC_EQ_CONFIG] [--fixed-band-eq-config FIXED_BAND_EQ_CONFIG]&#xA;                   [--convolution-eq] [--fs FS] [--bit-depth BIT_DEPTH] [--phase PHASE] [--f-res F_RES] [--bass-boost BASS_BOOST] [--treble-boost TREBLE_BOOST]&#xA;                   [--tilt TILT] [--sound-signature SOUND_SIGNATURE] [--max-gain MAX_GAIN] [--window-size WINDOW_SIZE] [--treble-window-size TREBLE_WINDOW_SIZE]&#xA;                   [--treble-f-lower TREBLE_F_LOWER] [--treble-f-upper TREBLE_F_UPPER] [--treble-gain-k TREBLE_GAIN_K] [--thread-count THREAD_COUNT]&#xA;&#xA;optional arguments:&#xA;  -h, --help            show this help message and exit&#xA;  --input-dir INPUT_DIR&#xA;                        Path to input data directory. Will look for CSV files in the data directory and recursively in sub-directories.&#xA;  --output-dir OUTPUT_DIR&#xA;                        Path to results directory. Will keep the same relative paths for files found in input-dir.&#xA;  --standardize-input   Overwrite input data in standardized sampling and bias?&#xA;  --new-only            Only process input files which don&#39;t have results in output directory.&#xA;  --compensation COMPENSATION&#xA;                        File path to CSV containing compensation (target) curve. Compensation is necessary when equalizing because all input data is raw microphone data.&#xA;                        See &#34;compensation&#34;, &#34;innerfidelity/resources&#34; and &#34;headphonecom/resources&#34;.&#xA;  --equalize            Will run equalization if this parameter exists, no value needed.&#xA;  --parametric-eq       Will produce parametric eq settings if this parameter exists, no value needed.&#xA;  --fixed-band-eq       Will produce fixed band eq settings if this parameter exists, no value needed.&#xA;  --rockbox             Will produce a Rockbox .cfg file with 10 band eq settings if this parameter exists,no value needed.&#xA;  --ten-band-eq         Shortcut parameter for activating standard ten band eq optimization.&#xA;  --parametric-eq-config PARAMETRIC_EQ_CONFIG&#xA;                        Name of parametric equalizer configuration or a path to a configuration file. Available named configurations are &#34;10_PEAKING&#34; for 10 peaking&#xA;                        filters, &#34;8_PEAKING_WITH_SHELVES&#34; for 8 peaking filters and a low shelf at 105 Hz for bass adjustment and a high shelf at 10 kHz for treble&#xA;                        adjustment, &#34;4_PEAKING_WITH_LOW_SHELF&#34; for 4 peaking filters and a low shelf at 105 Hz for bass adjustment, &#34;4_PEAKING_WITH_HIGH_SHELF&#34; for 4&#xA;                        peaking filters and a high shelf at 10 kHz for treble adjustments. You can give multiple named configurations by separating the names with commas&#xA;                        and filter sets will be built on top of each other. When the value is a file path, the file will be read and used as a configuration. The file&#xA;                        needs to be a YAML file with &#34;filters&#34; field as a list of filter configurations, each of which can define &#34;fc&#34;, &#34;min_fc&#34;, &#34;max_fc&#34;, &#34;q&#34;, &#34;min_q&#34;,&#xA;                        &#34;max_q&#34;, &#34;gain&#34;, &#34;min_gain&#34;, &#34;max_gain&#34; and &#34;type&#34; fields. When the fc, q or gain value is given, the parameter won&#39;t be optimized for the filter.&#xA;                        &#34;type&#34; needs to be either &#34;LOW_SHELF&#34;, &#34;PEAKING&#34; or &#34;HIGH_SHELF&#34;. Also &#34;filter_defaults&#34; field is supported on the top level and it can have the&#xA;                        same fields as the filters do. All fields missing from the filters will be read from &#34;filter_defaults&#34;. Defaults to&#xA;                        &#34;4_PEAKING_WITH_LOW_SHELF,4_PEAKING_WITH_HIGH_SHELF&#34;. Optimizer behavior can be adjusted by defining &#34;optimizer&#34; field which has fields &#34;min_f&#34;&#xA;                        and &#34;max_f&#34; for lower and upper bounds of the optimization range, &#34;max_time&#34; for maximum optimization duration in seconds, &#34;target_loss&#34; for RMSE&#xA;                        target level upon reaching which the optimization is ended, &#34;min_change_rate&#34; for minimum rate of improvement in db/s and &#34;min_std&#34; for minimum&#xA;                        standard deviation of the last few loss values. &#34;min_change_rate&#34; and &#34;min_std&#34; end the optimization when further time spent optimizing can&#39;t be&#xA;                        expected to improve the results dramatically. See peq.yaml for an example.&#xA;  --fixed-band-eq-config FIXED_BAND_EQ_CONFIG&#xA;                        Path to fixed band equalizer configuration. The file format is the same YAML as for parametric equalizer.&#xA;  --convolution-eq      Will produce impulse response for convolution equalizers if this parameter exists, no value needed.&#xA;  --fs FS               Sampling frequency in Hertz for impulse response and parametric eq filters. Single value or multiple values separated by commas eg 44100,48000.&#xA;                        When multiple values are given only the first one will be used for parametric eq. Defaults to 44100.&#xA;  --bit-depth BIT_DEPTH&#xA;                        Number of bits for every sample in impulse response. Defaults to 16.&#xA;  --phase PHASE         Impulse response phase characteristic. &#34;minimum&#34;, &#34;linear&#34; or &#34;both&#34;. Defaults to &#34;minimum&#34;&#xA;  --f-res F_RES         Frequency resolution for impulse responses. If this is 20 then impulse response frequency domain will be sampled every 20 Hz. Filter length for&#xA;                        impulse responses will be fs/f_res. Defaults to 10.0.&#xA;  --bass-boost BASS_BOOST&#xA;                        Bass boost shelf. Sub-bass frequencies will be boosted by this amount. Can be either a single value for a gain in dB or a comma separated list of&#xA;                        three values for parameters of a low shelf filter, where the first is gain in dB, second is center frequency (Fc) in Hz and the last is quality&#xA;                        (Q). When only a single value (gain) is given, default values for Fc and Q are used which are 105.0 Hz and 0.7, respectively. For example &#34;--bass-&#xA;                        boost=6&#34; or &#34;--bass-boost=9.5,150,0.69&#34;.&#xA;  --treble-boost TREBLE_BOOST&#xA;                        Treble boost shelf. &amp;gt; 10 kHz frequencies will be boosted by this amount. Can be either a single value for a gain in dB or a comma separated list&#xA;                        of three values for parameters of a high shelf filter, where the first is gain in dB, second is center frequency (Fc) in Hz and the last is&#xA;                        quality (Q). When only a single value (gain) is given, default values for Fc and Q are used which are 10000.0 Hz and 0.7, respectively. For&#xA;                        example &#34;--treble-boost=3&#34; or &#34;--treble-boost=-4,12000,0.69&#34;.&#xA;  --tilt TILT           Target tilt in dB/octave. Positive value (upwards slope) will result in brighter frequency response and negative value (downwards slope) will&#xA;                        result in darker frequency response. 1 dB/octave will produce nearly 10 dB difference in desired value between 20 Hz and 20 kHz. Tilt is applied&#xA;                        with bass boost and both will affect the bass gain.&#xA;  --sound-signature SOUND_SIGNATURE&#xA;                        File path to a sound signature CSV file. Sound signature is added to the compensation curve. Error data will be used as the sound signature target&#xA;                        if the CSV file contains an error column and otherwise the raw column will be used. This means there are two different options for using sound&#xA;                        signature: 1st is pointing it to a result CSV file of a previous run and the 2nd is to create a CSV file with just frequency and raw columns by&#xA;                        hand (or other means). The Sound signature graph will be interpolated so any number of point at any frequencies will do, making it easy to create&#xA;                        simple signatures with as little as two or three points.&#xA;  --max-gain MAX_GAIN   Maximum positive gain in equalization. Higher max gain allows to equalize deeper dips in frequency response but will limit output volume if no&#xA;                        analog gain is available because positive gain requires negative digital preamp equal to maximum positive gain. Defaults to 6.0.&#xA;  --window-size WINDOW_SIZE&#xA;                        Smoothing window size in octaves.&#xA;  --treble-window-size TREBLE_WINDOW_SIZE&#xA;                        Smoothing window size in octaves in the treble region.&#xA;  --treble-f-lower TREBLE_F_LOWER&#xA;                        Lower bound for transition region between normal and treble frequencies. Treble frequencies can have different max gain and gain K. Defaults to&#xA;                        6000.0.&#xA;  --treble-f-upper TREBLE_F_UPPER&#xA;                        Upper bound for transition region between normal and treble frequencies. Treble frequencies can have different max gain and gain K. Defaults to&#xA;                        8000.0.&#xA;  --treble-gain-k TREBLE_GAIN_K&#xA;                        Coefficient for treble gain, affects both positive and negative gain. Useful for disabling or reducing equalization power in treble region.&#xA;                        Defaults to 1.0.&#xA;  --thread-count THREAD_COUNT&#xA;                        Amount of threads to use for processing results. If set to &#34;max&#34; all the threads available will be used. Using more threads result in higher&#xA;                        memory usage. Defaults to 1.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Examples&lt;/h3&gt; &#xA;&lt;h4&gt;Reproducing Results&lt;/h4&gt; &#xA;&lt;p&gt;Reproducing pre-computed results for oratory1990 measured on-ear headphones:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m autoeq --input-dir=&#34;measurements/oratory1990/data/onear&#34; --output-dir=&#34;my_results/oratory1990/harman_over-ear_2018&#34; --compensation=&#34;compensation/harman_over-ear_2018_wo_bass.csv&#34; --parametric-eq --parametric-eq-config=4_PEAKING_WITH_LOW_SHELF,4_PEAKING_WITH_HIGH_SHELF --ten-band-eq --bass-boost=4.0 --convolution-eq --fs=44100,48000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Reproducing pre-computed results for Rtings measured IEMs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m autoeq --input-dir=&#34;measurements/rtings/data/inear&#34; --output-dir=&#34;my_results/rtings/avg&#34; --compensation=&#34;measurements/rtings/resources/rtings_compensation_avg.csv&#34; --parametric-eq --parametric-eq-config=4_PEAKING_WITH_LOW_SHELF,4_PEAKING_WITH_HIGH_SHELF --ten-band-eq --bass-boost=6.0 --convolution-eq --fs=44100,48000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;All parameters used for pre-computed results can be found in the &lt;code&gt;results/update.py&lt;/code&gt; script.&lt;/p&gt; &#xA;&lt;h4&gt;Equalizing Individual Headphones&lt;/h4&gt; &#xA;&lt;p&gt;Equalizing Sennheiser HD 650 and saving results to &lt;code&gt;my_results/HD650&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m autoeq --input-dir=&#34;measurements/innerfidelity/data/onear/Sennheiser HD 650&#34; --output-dir=&#34;my_results/HD650&#34; --compensation=&#34;measurements/innerfidelity/resources/innerfidelity_harman_over-ear_2018_wo_bass.csv&#34; --bass-boost=4 --convolution-eq --parametric-eq --ten-band-eq --fs=44100,48000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Fixed Band Equalizers&lt;/h4&gt; &#xA;&lt;p&gt;Fixed band equalizer settings can be produced the same way as parametric eq. Create &lt;code&gt;fbeq.yaml&lt;/code&gt; with contents&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;filter_defaults:&#xA;  type: PEAKING&#xA;  q: 1.05&#xA;filters:&#xA;  - fc: 400&#xA;  - fc: 1000&#xA;  - fc: 2500&#xA;  - fc: 6300&#xA;  - fc: 16000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to optimize for Sony WH-1000XM3 app.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m autoeq --input-dir=&#34;measurements/oratory1990/data/onear/Sony WH-1000XM3&#34; --output-dir=&#34;my_results/Sony WH-1000XM3 (app)&#34; --compensation=&#34;compensation/harman_over-ear_2018_wo_bass.csv&#34; --bass-boost=4.0 --fixed-band-eq --fixed-band-eq-config=fbeq.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Using Sound Signatures&lt;/h4&gt; &#xA;&lt;p&gt;AutoEq provides a way to play around with different sound signatures easily. The use-cases include making headphones deviate from the neutral target or making one headphone sound like another.&lt;/p&gt; &#xA;&lt;p&gt;Equalizing Sennheiser HD 800 to sound like Sennheiser HD 650 using pre-computed results. Both have been measured by oratory1990 so we&#39;ll use those measurements. Pre-computed results include 4dB of bass boost for over-ear headphones and therefore we need to apply a bass boost of 4dB here as well.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m autoeq --input-dir=&#34;measurements/oratory1990/data/onear/Sennheiser HD 800&#34; --output-dir=&#34;my_results/Sennheiser HD 800 (HD 650)&#34; --compensation=&#34;compensation/harman_over-ear_2018_wo_bass.csv&#34; --sound-signature=&#34;results/oratory1990/harman_over-ear_2018/Sennheiser HD 650/Sennheiser HD 650.csv&#34; --parametric-eq --parametric-eq-config=8_PEAKING_WITH_SHELVES --ten-band-eq --bass-boost=4 --convolution-eq --fs=44100,48000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Equalizing Massdrop x Sennheiser HD 800 to sound like AKG K701. There is no K701 measurement made by oratory1990 so we&#39;ll use Innerfidelity&#39;s measurement for the sound signature. The list of recommended results always points to best measurement so you can check there which one to use (measurement system can be found in the URL).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m autoeq --input-dir=&#34;measurements/oratory1990/data/onear/Sennheiser HD 800&#34; --output-dir=&#34;my_results/Sennheiser HD 800 (K701)&#34; --compensation=&#34;compensation/harman_over-ear_2018_wo_bass.csv&#34; --sound-signature=&#34;results/innerfidelity/innerfidelity_harman_over-ear_2018/AKG K701/AKG K701.csv&#34; --parametric-eq --parametric-eq-config=8_PEAKING_WITH_SHELVES --ten-band-eq --bass-boost=4 --convolution-eq --fs=44100,48000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Equalizing HiFiMAN HE400S to sound like Massdrop x Meze 99 Noir. HE400S is measured only by Innerfidelity so we&#39;ll point compensation file pointing to Innerfidelity&#39;s calibrated Harman target. Meze 99 Noir has massive natural bass boost and to capture that we need to relax max gain to +12dB.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m autoeq --input-dir=&#34;measurements/innerfidelity/data/onear/HiFiMAN HE400S&#34; --output-dir=&#34;my_results/HE400S (99 Noir)&#34; --compensation=&#34;measurements/innerfidelity/resources/innerfidelity_harman_over-ear_2018_wo_bass.csv&#34; --sound-signature=&#34;results/oratory1990/harman_over-ear_2018/Meze 99 Noir/Meze 99 Noir.csv&#34; --parametric-eq --parametric-eq-config=8_PEAKING_WITH_SHELVES --ten-band-eq --bass-boost=4 --max_gain=8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Applying V-shaped sound signature to Audeze Mobius. First step is to create the sound signature file. Save this to &lt;code&gt;my_data/v.csv&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-csv&#34;&gt;frequency,raw&#xA;20,4.0&#xA;1000,-4.0&#xA;10000,4.0&#xA;20000,0.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then use it by providing the path to &lt;code&gt;--sound-signature&lt;/code&gt; parameter. We&#39;ll set bass boost to 0dB because the sound signature already has a significant bass boost. Of course it&#39;s possible to add bass boost on top of the sound signature file if you want even more bass.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m autoeq --input-dir=&#34;measurements/rtings/data/onear/Audeze Mobius&#34; --output-dir=&#34;my_results/Audeze Mobius (V-signature)&#34; --compensation=&#34;measurements/rtings/resources/rtings_compensation_avg.csv&#34; --sound-signature=&#34;my_data/v.csv&#34; --parametric-eq --parametric-eq-config=8_PEAKING_WITH_SHELVES --ten-band-eq --bass-boost=4.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Building&lt;/h3&gt; &#xA;&lt;p&gt;Build PyPi package&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;copy /y README.md README.md.bak &amp;amp;&amp;amp; copy /y autoeq\README.md README.md &amp;amp;&amp;amp; python -m build &amp;amp;&amp;amp; copy /y README.md.bak README.md &amp;amp;&amp;amp; del README.md.bak&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;publish&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m twine upload dist/autoeq-&amp;lt;VERSION&amp;gt;*&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;p&gt;The main principle used by AutoEq for producing the equalization function is to invert the error curve. Error is the difference between raw microphone data and the compensation (target) curve. If headphone&#39;s frequency response is 4 dB below the target at 20 Hz equalization function will have +4 dB boost at 20 Hz. In reality simply inverting the error is not sufficient since measurements and equalization have several problems that need to be addressed, see &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/#technical-challenges&#34;&gt;Technical Challenges&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;Results provided in this project currently have all the headphone measurements from&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://crinacle.com/&#34;&gt;Crinacle&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://graphs.headphone.com/&#34;&gt;Headphone.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.innerfidelity.com/headphone-measurements&#34;&gt;Innerfidelity&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/oratory1990&#34;&gt;oratory1990&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://reference-audio-analyzer.pro/en/catalog-reports.php?sp_1=1&amp;amp;tp=1&#34;&gt;Reference Audio Analyzer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.rtings.com/headphones&#34;&gt;Rtings&lt;/a&gt; with the exception of Reference Audio Analyzer measurements done on the SF1 system.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Results are organized by &lt;code&gt;source/target/headphone&lt;/code&gt; so a Sennheiser HD 650 measured by Innerfidelity and tuned to a calibrated Harman target would be found in &lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/results/innerfidelity/innerfidelity_harman_over-ear_2018/Sennheiser%20HD%20650&#34;&gt;innerfidelity/innerfidelity_harman_over-ear_2018/Sennheiser HD 650&lt;/a&gt;. Multiple measurements of the same headphone by the same measurement entity are averaged. All different measurements for averaging have been renamed with snXXX (serial number) or sample X in the end of the name to distinguish from the averaged data which has no suffixes in the name.&lt;/p&gt; &#xA;&lt;p&gt;oratory1990 measurements have been done on Gras 43AG and 43AC couplers, the same which were used to develop Harman target responses by Olive et al. and therefore use Harman target responses for the equalization targets. These results are recommended over all other measurements because of this reason. Harman target data is in the &lt;code&gt;compensation&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;p&gt;Crinacle&#39;s in-ear measurements have been performed with IEC 60318-4 coupler and are therefore compatible with Harman in-ear targets. This fact also earns Crinacle&#39;s measurements second highest ranking recommendation after oratory1990. Crinacle&#39;s over-ear measurements use the same ear simulator attached to a MiniDSP ears pinna. The measurements done on this system are not as accurate as oratory1990&#39;s but because of the high quality ear simulator, these are a bit better than rest.&lt;/p&gt; &#xA;&lt;p&gt;Innerfidelity, Rtings and Headphone.com measurements have been performed on Head Acoustics HMSII.3 measurement system. This system is not an industry standard anymore because of the rigid pinnae. The Headphone.com measurements are the old ones which are no longer available. These are not to be consfused with the new measurements Resolve is producing using GRAS system.&lt;/p&gt; &#xA;&lt;p&gt;Reference Audio Analyzer have &lt;a href=&#34;https://reference-audio-analyzer.pro/en/stands.php&#34;&gt;three different measurement systems&lt;/a&gt; none of which seem to represent human hearing particularly well. The most recent HDM-X system is close to the Head Acoustics HMSII.3 systems but seems to suffer a bit more in the bass range. HDM1 is clearly worse than other systems and the measurements done on the SF1 system are not included at all because that is a flat plate coupler. IEM measurements are done with what looks like a tubing coupler and these don&#39;t look very accurate. Reference Audio Analyzer measurements and results are a last resort.&lt;/p&gt; &#xA;&lt;p&gt;All of the results use frequency response targets that were specifically developed for this project except oratory1990 and Crinacle&#39;s IEM measurements which use standard Harman targets. The target curves were developed by calibrating measurements against reference measurements by oratory1990 and Crinacle (IEMs) and modifying the Harman 2018 over-ear and 2019 in-ear targets with the calibration data.&lt;/p&gt; &#xA;&lt;p&gt;None of these targets have bass boost seen in Harman target responses and therefore a +4dB boost was applied for all over-ear headphones, +6dB for in-ear headphones and no boost for earbuds. Harman targets actually ask for about +6dB for over-ears and +9dB for in-ears but since some headphones cannot achieve this with positive gain limited to +6dB, a smaller boost was selected. Above 6 to 12 kHz data is filtered more heavily to avoid equalizing the narrow dips and notches that depend heavily on the listener&#39;s own ears.&lt;/p&gt; &#xA;&lt;h3&gt;oratory1990 IEM Target&lt;/h3&gt; &#xA;&lt;p&gt;In-ear results with oratory1990 target (formerly &#34;Usound&#34; target) are not longer given because the new 2019 Harman in-ear fixes the +10 kHz problems of the 2017 target. Also it is easy to transform results created for Harman 2019 to oratory1990 target without running the processing yourself if you are using parametric equalizer and have two filters (bands) available by adding these two to your eq software:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Type&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Fc&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Q&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Gain&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;113&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.75&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Peaking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3766&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.63&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-2.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The results will be remarkably similar to results produced with the actual oratory1990 target:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/kGYBOev.png&#34; alt=&#34;oratory1990 vs Harman in-ear 2019&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Of course it&#39;s still possible to produce native results with oratory1990 target by pointing compensation to the oratory1990 target file: &lt;code&gt;--compensation=&#34;compensation/oratory1990.csv&lt;/code&gt; or &lt;code&gt;--compensation=&#34;compensation/oratory1990_wo_bass.csv&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Innerfidelity Target by Super Best Audio Friends Forum User &#34;Serious&#34;&lt;/h3&gt; &#xA;&lt;p&gt;Innerfidelity and Headphone.com measured headphones previously used &lt;a href=&#34;https://www.superbestaudiofriends.org/index.php?threads/innerfidelity-fr-target.5560/&#34;&gt;SBAF-Serious target&lt;/a&gt; only. The SBAF-Serious curve is no longer used for these measurements since a new targets were developed by calibrating Harman targets. This is a modified version of Innerfidelity target curve produced by a user called Serious on Super Best Audio Friends forum. This curve doesn&#39;t have any glaring problems and is quite well balanced overall. Curve was turned into a compensation for raw microphone data and tilted 0.2 dB / octave brighter. Innerfidelity measurements are recommended over Headphone.com measurements because SBAF-Serious target was developed for Innerfidelity. SBAF-Serious curve was modified to be suitable for Headphone.com measurements. CSV data files for Innerfidelity and Headphone.com are at &lt;code&gt;innerfidelity/resources/innerfidelity_compensation_sbaf-serious.csv&lt;/code&gt; and &lt;code&gt;headphonecom/resources/headphonecom_compensation_sbaf-serious.csv&lt;/code&gt;, respectively.&lt;/p&gt; &#xA;&lt;h3&gt;Rtings Targets&lt;/h3&gt; &#xA;&lt;p&gt;Rtings measured headphones have a frequency response target made for this project. This treble average target is using an average of frequency responses of all Rtings measured headphones in the treble range with small manual reduction of the 9kHz peak and the Rtings native response below 2500 Hz without bass boost. Three different targets were compared in listening tests and the treble average target was found to sound the best. Other two were the Rtings native target curve and calibrated and uncalibrated versions of SBAF Serious target curve. Rtings uses the same measurement system as Innerfidelity uses so in theory the uncalibrated SBAF Serious target should work similarly with Rtings but listening tests found the treble average target to be slightly better. Rtings have &lt;a href=&#34;https://www.youtube.com/watch?v=HNEI3qLZEKo&#34;&gt;a very informative video&lt;/a&gt; about how they are doing the measurements and how they came up with the target they use.&lt;/p&gt; &#xA;&lt;p&gt;All of these Rtings targets retired when new calibrated Harman targets were developed for Rtings measurements.&lt;/p&gt; &#xA;&lt;h2&gt;Technical Challenges&lt;/h2&gt; &#xA;&lt;p&gt;Simply inverting headphone frequency response deviation from target response does not usually produce sufficient results. Some problems are caused by imperfections in measurements, some are reliability issues and some are practical end-user problems. Rtings has a good &lt;a href=&#34;https://www.youtube.com/watch?v=HNEI3qLZEKo&#34;&gt;video on Youtube&lt;/a&gt; about measurement system challenges and solutions which is definitely worth checking out. Innerfidelity also has a very educational &lt;a href=&#34;https://www.youtube.com/watch?v=SDRHFNfFCFU&#34;&gt;video on Youtube&lt;/a&gt; about measurements and what constitutes as a neutral sound. Main takeoffs are that bass and treble measurements are very inconsistent, neutral sound is not very well defined yet and on-ear headphones have big reliability problems in 8 to 9kHz range due to resonances which move when headphone placement is changed. Harman international has done some solid research into preferred headphone frequency response but since that research was done on a different measurement system the target does not apply directly to Innerfidelity (Summer 2018) and Headphone.com measurements.&lt;/p&gt; &#xA;&lt;p&gt;There is very little that can be done for fighting bass inconsistencies because the same problems will be there whether equalization is used or not. Headphones simply have different bass responses on different listeners (heads). Therefore bass is taken as is in AutoEq and equalized as if there was nothing wrong with it. Your mileage may vary. Luckily bass has smaller impact on music and having too much bass (especially sub-bass) doesn&#39;t create problems of the same magnitude as having too much treble.&lt;/p&gt; &#xA;&lt;p&gt;Moving resonances around 8 to 9kHz may cause big problems if not taken into account. Spikes and dips in this range are of great amplitude and very narrow. If one equalizes these spikes and dips according to frequency response measurement in worst case scenario a spike will move in a place of dip when headphone is moved, and therefore the spike is amplified significantly, leading to a very sharp and piercing sound signature. To counter these problems by default AutoEq uses heavy smoothing and limited positive gain above 6 to 8kHz. This way the equalization will follow a broader trend of the region and will not care so much about narrow spikes and dips. Also positive gain is limited to 0dB as an extra safety measure against amplifying spikes due to moving the headphone. Suppressing a narrow dip even further is not an optimal thing to do but in practice has little negative effect on the sound. Both of these measures will also alleviate upper treble measurement inconsistencies above 11 to 12 kHz.&lt;/p&gt; &#xA;&lt;p&gt;A practical end-user problem is if too high positive gain is allowed which asks for equal amount of negative digital pre-amp to prevent clipping. This negative preamp will limit maximum volume produced by the system if there is no analog gain available. If a dedicated headphone amplifier is available or if the motherboard/soundcard can drive the headphones loud enough even when using high negative preamp larger &lt;code&gt;--max_gain&lt;/code&gt; values can be used. By default &lt;code&gt;--max_gain&lt;/code&gt; is set to +6dB so as not to cripple the user&#39;s volume too much. Max gain will clip the equalization curve which produces sharp kinks in it. Sharp changes in equalization may produce unwanted equalization artifacts. To counter this AutoEq rounds the corners whenever max gain clips the curve.&lt;/p&gt; &#xA;&lt;h2&gt;Parametric Equalizer Optimization&lt;/h2&gt; &#xA;&lt;p&gt;AutoEq has an optimizer to fit several filters to the desired equalization curve. Optimization is an iterative process where the filter parameters which provide the best results are searched until optimization finishes or any of the early stopping conditions are met.&lt;/p&gt; &#xA;&lt;p&gt;The optimizer can be configured quite flexibly. The filter type (peaking, low shelf or high shelf) and minimum and maximum values for center frequency (fc), quality (q) and gain can be set as well as disable optimization for any of these in favor of fixed value. The optimizer itself can be configured to stop the process early when the changes being made are too small, a target error level has been reached or maximum amount of time has been used.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jaakkopasanen/AutoEq/master/peq.yaml&#34;&gt;peq.yaml&lt;/a&gt; has an example configuration. Feel free to adjust the file to your needs.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s an animation of what happens during the optimization.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/3breF6l.gif&#34; alt=&#34;optimization-animation&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Optimization of parametric eq filters (click to play again)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Technically speaking the optimization is an error minimization process. The error is the root mean squared difference between the equalization target and the frequency response from the current set of filter parameters. The optimizer adjusts the filter parameters multiple times on each iteration to figure out in which direction each should be adjusted to decrease the error. In addition to the RMSE between target and current equalizer frequency response, the undesired combination of filter parameters is penalized. Currently that means adding more error if the filter has positive gain and too steep slope (as this can cause audible ringing). The additional error (regularization) ensures the optimizer doesn&#39;t produce these kinds of filter parameter combinations.&lt;/p&gt; &#xA;&lt;p&gt;The &amp;gt; 10 kHz frequency range is treated as a single average level because research indicates that the perceived sound quality is not sensitive to accurately following a curve above 10 kHz but rather a total energy in the range.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jaakkopasanen/AutoEq/issues&#34;&gt;Issues&lt;/a&gt; are the way to go if you are experiencing problems or have ideas or feature requests. Issues are not the correct channel for headphone requests because this project sources the measurements from other databases and a headphone missing from AutoEq means it has not been measured by any of the supported sources.&lt;/p&gt; &#xA;&lt;p&gt;You can find me in &lt;a href=&#34;https://www.reddit.com/user/jaakkopasanen&#34;&gt;Reddit&lt;/a&gt;, &lt;a href=&#34;https://www.audiosciencereview.com/forum/index.php?members/jaakkopasanen.17838/&#34;&gt;Audio Science Review&lt;/a&gt; and &lt;a href=&#34;https://www.head-fi.org/members/jaakkopasanen.491235/&#34;&gt;Head-fi&lt;/a&gt; if you just want to say hello.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>DataTalksClub/data-engineering-zoomcamp</title>
    <updated>2023-01-01T01:53:31Z</updated>
    <id>tag:github.com,2023-01-01:/DataTalksClub/data-engineering-zoomcamp</id>
    <link href="https://github.com/DataTalksClub/data-engineering-zoomcamp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Free Data Engineering course!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Data Engineering Zoomcamp&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://airtable.com/shr6oVXeQvSI5HuWD&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/875246/185755203-17945fd1-6b64-46f2-8377-1011dcb1a444.png&#34; height=&#34;50&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Register in &lt;a href=&#34;https://datatalks.club/slack.html&#34;&gt;DataTalks.Club&#39;s Slack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Join the &lt;a href=&#34;https://app.slack.com/client/T01ATQK62F8/C01FABYF2RG&#34;&gt;&lt;code&gt;#course-data-engineering&lt;/code&gt;&lt;/a&gt; channel&lt;/li&gt; &#xA; &lt;li&gt;Join the &lt;a href=&#34;https://t.me/dezoomcamp&#34;&gt;course Telegram channel with announcements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The videos are published on &lt;a href=&#34;https://www.youtube.com/c/DataTalksClub&#34;&gt;DataTalks.Club&#39;s YouTube channel&lt;/a&gt; in &lt;a href=&#34;https://www.youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&#34;&gt;the course playlist&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/19bnYs80DwuUimHM65UV3sylsCn2j1vziPOwzBwQrebw/edit?usp=sharing&#34;&gt;Frequently asked technical questions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Syllabus&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/#week-1-introduction--prerequisites&#34;&gt;Week 1: Introduction &amp;amp; Prerequisites&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/#week-2-data-ingestion&#34;&gt;Week 2: Data ingestion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/#week-3-data-warehouse&#34;&gt;Week 3: Data Warehouse&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/#week-4-analytics-engineering&#34;&gt;Week 4: Analytics Engineering&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/#week-5-batch-processing&#34;&gt;Week 5: Batch processing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/#week-6-streaming&#34;&gt;Week 6: Streaming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/#week-7-8--9-project&#34;&gt;Week 7, 8 &amp;amp; 9: Project&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Taking the course&lt;/h2&gt; &#xA;&lt;h3&gt;2023 Cohort&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Start&lt;/strong&gt;: 16 January 2023 (Monday)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Registration link&lt;/strong&gt;: &lt;a href=&#34;https://airtable.com/shr6oVXeQvSI5HuWD&#34;&gt;https://airtable.com/shr6oVXeQvSI5HuWD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Subscribe to our &lt;a href=&#34;https://calendar.google.com/calendar/?cid=ZXIxcjA1M3ZlYjJpcXU0dTFmaG02MzVxMG9AZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&#34;&gt;public Google Calendar&lt;/a&gt; (it works from Desktop only)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Self-paced mode&lt;/h3&gt; &#xA;&lt;p&gt;All the materials of the course are freely available, so that you can take the course at your own pace&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Follow the suggested syllabus (see below) week by week&lt;/li&gt; &#xA; &lt;li&gt;You don&#39;t need to fill in the registration form. Just start watching the videos and join Slack&lt;/li&gt; &#xA; &lt;li&gt;Check &lt;a href=&#34;https://docs.google.com/document/d/19bnYs80DwuUimHM65UV3sylsCn2j1vziPOwzBwQrebw/edit?usp=sharing&#34;&gt;FAQ&lt;/a&gt; if you have problems&lt;/li&gt; &#xA; &lt;li&gt;If you can&#39;t find a solution to your problem in FAQ, ask for help in Slack&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2022 Cohort&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Start&lt;/strong&gt;: 17 January 2022&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Registration link&lt;/strong&gt;: &lt;a href=&#34;https://airtable.com/shr6oVXeQvSI5HuWD&#34;&gt;https://airtable.com/shr6oVXeQvSI5HuWD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/e/2PACX-1vR9oQiYnAVvzL4dagnhvp0sngqagF0AceD0FGjhS-dnzMTBzNQIal3-hOgkTibVQvfuqbQ69b0fvRnf/pubhtml&#34;&gt;Leaderboard&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Subscribe to our &lt;a href=&#34;https://calendar.google.com/calendar/?cid=ZXIxcjA1M3ZlYjJpcXU0dTFmaG02MzVxMG9AZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&#34;&gt;public Google Calendar&lt;/a&gt; (it works from Desktop only)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Asking for help in Slack&lt;/h3&gt; &#xA;&lt;p&gt;The best way to get support is to use &lt;a href=&#34;https://datatalks.club/slack.html&#34;&gt;DataTalks.Club&#39;s Slack&lt;/a&gt;. Join the &lt;a href=&#34;https://app.slack.com/client/T01ATQK62F8/C01FABYF2RG&#34;&gt;&lt;code&gt;#course-data-engineering&lt;/code&gt;&lt;/a&gt; channel.&lt;/p&gt; &#xA;&lt;p&gt;To make discussions in Slack more organized:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Follow &lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/asking-questions.md&#34;&gt;these recommendations&lt;/a&gt; when asking for help&lt;/li&gt; &#xA; &lt;li&gt;Read the &lt;a href=&#34;https://datatalks.club/slack/guidelines.html&#34;&gt;DataTalks.Club community guidelines&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Syllabus&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; NYC TLC changed the format of the data we use to parquet. But you can still access the csv files &lt;a href=&#34;https://github.com/DataTalksClub/nyc-tlc-data&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_1_basics_n_setup&#34;&gt;Week 1: Introduction &amp;amp; Prerequisites&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Course overview&lt;/li&gt; &#xA; &lt;li&gt;Introduction to GCP&lt;/li&gt; &#xA; &lt;li&gt;Docker and docker-compose&lt;/li&gt; &#xA; &lt;li&gt;Running Postgres locally with Docker&lt;/li&gt; &#xA; &lt;li&gt;Setting up infrastructure on GCP with Terraform&lt;/li&gt; &#xA; &lt;li&gt;Preparing the environment for the course&lt;/li&gt; &#xA; &lt;li&gt;Homework&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_1_basics_n_setup&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_2_data_ingestion&#34;&gt;Week 2: Data ingestion&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Data Lake&lt;/li&gt; &#xA; &lt;li&gt;Workflow orchestration&lt;/li&gt; &#xA; &lt;li&gt;Setting up Airflow locally&lt;/li&gt; &#xA; &lt;li&gt;Ingesting data to GCP with Airflow&lt;/li&gt; &#xA; &lt;li&gt;Ingesting data to local Postgres with Airflow&lt;/li&gt; &#xA; &lt;li&gt;Moving data from AWS to GCP (Transfer service)&lt;/li&gt; &#xA; &lt;li&gt;Homework&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_2_data_ingestion&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_3_data_warehouse&#34;&gt;Week 3: Data Warehouse&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Data Warehouse&lt;/li&gt; &#xA; &lt;li&gt;BigQuery&lt;/li&gt; &#xA; &lt;li&gt;Partitioning and clustering&lt;/li&gt; &#xA; &lt;li&gt;BigQuery best practices&lt;/li&gt; &#xA; &lt;li&gt;Internals of BigQuery&lt;/li&gt; &#xA; &lt;li&gt;Integrating BigQuery with Airflow&lt;/li&gt; &#xA; &lt;li&gt;BigQuery Machine Learning&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_3_data_warehouse&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_4_analytics_engineering/&#34;&gt;Week 4: Analytics engineering&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Basics of analytics engineering&lt;/li&gt; &#xA; &lt;li&gt;dbt (data build tool)&lt;/li&gt; &#xA; &lt;li&gt;BigQuery and dbt&lt;/li&gt; &#xA; &lt;li&gt;Postgres and dbt&lt;/li&gt; &#xA; &lt;li&gt;dbt models&lt;/li&gt; &#xA; &lt;li&gt;Testing and documenting&lt;/li&gt; &#xA; &lt;li&gt;Deployment to the cloud and locally&lt;/li&gt; &#xA; &lt;li&gt;Visualizing the data with google data studio and metabase&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_4_analytics_engineering&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_5_batch_processing&#34;&gt;Week 5: Batch processing&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Batch processing&lt;/li&gt; &#xA; &lt;li&gt;What is Spark&lt;/li&gt; &#xA; &lt;li&gt;Spark Dataframes&lt;/li&gt; &#xA; &lt;li&gt;Spark SQL&lt;/li&gt; &#xA; &lt;li&gt;Internals: GroupBy and joins&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_5_batch_processing&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_6_stream_processing&#34;&gt;Week 6: Streaming&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Introduction to Kafka&lt;/li&gt; &#xA; &lt;li&gt;Schemas (avro)&lt;/li&gt; &#xA; &lt;li&gt;Kafka Streams&lt;/li&gt; &#xA; &lt;li&gt;Kafka Connect and KSQL&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_6_stream_processing&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_7_project&#34;&gt;Week 7, 8 &amp;amp; 9: Project&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Putting everything we learned to practice&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Week 7 and 8: working on your project&lt;/li&gt; &#xA; &lt;li&gt;Week 9: reviewing your peers&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_7_project&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;h3&gt;Architecture diagram&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/images/architecture/arch_1.jpg&#34;&gt; &#xA;&lt;h3&gt;Technologies&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Google Cloud Platform (GCP)&lt;/em&gt;: Cloud-based auto-scaling platform by Google &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;em&gt;Google Cloud Storage (GCS)&lt;/em&gt;: Data Lake&lt;/li&gt; &#xA;   &lt;li&gt;&lt;em&gt;BigQuery&lt;/em&gt;: Data Warehouse&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Terraform&lt;/em&gt;: Infrastructure-as-Code (IaC)&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Docker&lt;/em&gt;: Containerization&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;SQL&lt;/em&gt;: Data Analysis &amp;amp; Exploration&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Airflow&lt;/em&gt;: Pipeline Orchestration&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;dbt&lt;/em&gt;: Data Transformation&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Spark&lt;/em&gt;: Distributed Processing&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Kafka&lt;/em&gt;: Streaming&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;To get the most out of this course, you should feel comfortable with coding and command line and know the basics of SQL. Prior experience with Python will be helpful, but you can pick Python relatively fast if you have experience with other programming languages.&lt;/p&gt; &#xA;&lt;p&gt;Prior experience with data engineering is not required.&lt;/p&gt; &#xA;&lt;h2&gt;Instructors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ankush Khanna (&lt;a href=&#34;https://linkedin.com/in/ankushkhanna2&#34;&gt;https://linkedin.com/in/ankushkhanna2&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Sejal Vaidya (&lt;a href=&#34;https://linkedin.com/in/vaidyasejal&#34;&gt;https://linkedin.com/in/vaidyasejal&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Victoria Perez Mola (&lt;a href=&#34;https://www.linkedin.com/in/victoriaperezmola/&#34;&gt;https://www.linkedin.com/in/victoriaperezmola/&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Alexey Grigorev (&lt;a href=&#34;https://linkedin.com/in/agrigorev&#34;&gt;https://linkedin.com/in/agrigorev&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Tools&lt;/h2&gt; &#xA;&lt;p&gt;For this course, you&#39;ll need to have the following software installed on your computer:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Docker and Docker-Compose&lt;/li&gt; &#xA; &lt;li&gt;Python 3 (e.g. via &lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;Anaconda&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Google Cloud SDK&lt;/li&gt; &#xA; &lt;li&gt;Terraform&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/week_1_basics_n_setup&#34;&gt;Week 1&lt;/a&gt; for more details about installing these tools&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Q&lt;/strong&gt;: I registered, but haven&#39;t received a confirmation email. Is it normal? &lt;strong&gt;A&lt;/strong&gt;: Yes, it&#39;s normal. It&#39;s not automated. But you will receive an email eventually&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Q&lt;/strong&gt;: At what time of the day will it happen? &lt;strong&gt;A&lt;/strong&gt;: Office hours will happen on Mondays at 17:00 CET. But everything will be recorded, so you can watch it whenever it&#39;s convenient for you&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Q&lt;/strong&gt;: Will there be a certificate? &lt;strong&gt;A&lt;/strong&gt;: Yes, if you complete the project&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Q&lt;/strong&gt;: I&#39;m 100% not sure I&#39;ll be able to attend. Can I still sign up? &lt;strong&gt;A&lt;/strong&gt;: Yes, please do! You&#39;ll receive all the updates and then you can watch the course at your own pace.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Q&lt;/strong&gt;: Do you plan to run a ML engineering course as well? &lt;strong&gt;A&lt;/strong&gt;: Glad you asked. &lt;a href=&#34;https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp&#34;&gt;We do&lt;/a&gt; :)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Q&lt;/strong&gt;: I&#39;m stuck! I&#39;ve got a technical question! &lt;strong&gt;A&lt;/strong&gt;: Ask on Slack! And check out the &lt;a href=&#34;https://docs.google.com/document/d/19bnYs80DwuUimHM65UV3sylsCn2j1vziPOwzBwQrebw/edit?usp=sharing&#34;&gt;student FAQ&lt;/a&gt;; many common issues have been answered already. If your issue is solved, please add how you solved it to the document. Thanks!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Supporters and partners&lt;/h2&gt; &#xA;&lt;p&gt;Do you want to support our course and our community? Please reach out to &lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/alexey@datatalks.club&#34;&gt;alexey@datatalks.club&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Big thanks to other communities for helping us spread the word about the course:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dphi.tech/&#34;&gt;DPhi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mlops.community/&#34;&gt;MLOps.community&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/ML-For-Beginners</title>
    <updated>2023-01-01T01:53:31Z</updated>
    <id>tag:github.com,2023-01-01:/microsoft/ML-For-Beginners</id>
    <link href="https://github.com/microsoft/ML-For-Beginners" rel="alternate"></link>
    <summary type="html">&lt;p&gt;12 weeks, 26 lessons, 52 quizzes, classic Machine Learning for all&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/ML-For-Beginners/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/microsoft/ML-For-Beginners.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/ML-For-Beginners/graphs/contributors/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/microsoft/ML-For-Beginners.svg?sanitize=true&#34; alt=&#34;GitHub contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/ML-For-Beginners/issues/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/microsoft/ML-For-Beginners.svg?sanitize=true&#34; alt=&#34;GitHub issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/ML-For-Beginners/pulls/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/microsoft/ML-For-Beginners.svg?sanitize=true&#34; alt=&#34;GitHub pull-requests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://makeapullrequest.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://GitHub.com/microsoft/ML-For-Beginners/watchers/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/watchers/microsoft/ML-For-Beginners.svg?style=social&amp;amp;label=Watch&#34; alt=&#34;GitHub watchers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/ML-For-Beginners/network/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/microsoft/ML-For-Beginners.svg?style=social&amp;amp;label=Fork&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/ML-For-Beginners/stargazers/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/microsoft/ML-For-Beginners.svg?style=social&amp;amp;label=Star&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Machine Learning for Beginners - A Curriculum&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt; Travel around the world as we explore Machine Learning by means of world cultures &lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Azure Cloud Advocates at Microsoft are pleased to offer a 12-week, 26-lesson curriculum all about &lt;strong&gt;Machine Learning&lt;/strong&gt;. In this curriculum, you will learn about what is sometimes called &lt;strong&gt;classic machine learning&lt;/strong&gt;, using primarily Scikit-learn as a library and avoiding deep learning, which is covered in our forthcoming &#39;AI for Beginners&#39; curriculum. Pair these lessons with our &lt;a href=&#34;https://aka.ms/datascience-beginners&#34;&gt;&#39;Data Science for Beginners&#39; curriculum&lt;/a&gt;, as well!&lt;/p&gt; &#xA;&lt;p&gt;Travel with us around the world as we apply these classic techniques to data from many areas of the world. Each lesson includes pre- and post-lesson quizzes, written instructions to complete the lesson, a solution, an assignment, and more. Our project-based pedagogy allows you to learn while building, a proven way for new skills to &#39;stick&#39;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt; Hearty thanks to our authors&lt;/strong&gt; Jen Looper, Stephen Howell, Francesca Lazzeri, Tomomi Imura, Cassie Breviu, Dmitry Soshnikov, Chris Noring, Anirban Mukherjee, Ornella Altunyan, and Amy Boyd&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt; Thanks as well to our illustrators&lt;/strong&gt; Tomomi Imura, Dasani Madipalli, and Jen Looper&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt; Special thanks  to our Microsoft Student Ambassador authors, reviewers, and content contributors&lt;/strong&gt;, notably Rishit Dagli, Muhammad Sakib Khan Inan, Rohan Raj, Alexandru Petrescu, Abhishek Jaiswal, Nawrin Tabassum, Ioan Samuila, and Snigdha Agarwal&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt; Extra gratitude to Microsoft Student Ambassador Eric Wanjau for our R lessons!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://aka.ms/student-page&#34;&gt;Students&lt;/a&gt;&lt;/strong&gt;, to use this curriculum, fork the entire repo to your own GitHub account and complete the exercises on your own or with a group:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Start with a pre-lecture quiz.&lt;/li&gt; &#xA; &lt;li&gt;Read the lecture and complete the activities, pausing and reflecting at each knowledge check.&lt;/li&gt; &#xA; &lt;li&gt;Try to create the projects by comprehending the lessons rather than running the solution code; however that code is available in the &lt;code&gt;/solution&lt;/code&gt; folders in each project-oriented lesson.&lt;/li&gt; &#xA; &lt;li&gt;Take the post-lecture quiz.&lt;/li&gt; &#xA; &lt;li&gt;Complete the challenge.&lt;/li&gt; &#xA; &lt;li&gt;Complete the assignment.&lt;/li&gt; &#xA; &lt;li&gt;After completing a lesson group, visit the &lt;a href=&#34;https://github.com/microsoft/ML-For-Beginners/discussions&#34;&gt;Discussion Board&lt;/a&gt; and &#34;learn out loud&#34; by filling out the appropriate PAT rubric. A &#39;PAT&#39; is a Progress Assessment Tool that is a rubric you fill out to further your learning. You can also react to other PATs so we can learn together.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;For further study, we recommend following these &lt;a href=&#34;https://docs.microsoft.com/en-us/users/jenlooper-2911/collections/k7o7tg1gp306q4?WT.mc_id=academic-77952-leestott&#34;&gt;Microsoft Learn&lt;/a&gt; modules and learning paths.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;Teachers&lt;/strong&gt;, we have &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/for-teachers.md&#34;&gt;included some suggestions&lt;/a&gt; on how to use this curriculum.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Meet the Team&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/Tj1XWrDSYJU&#34; title=&#34;Promo video&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/ml.gif&#34; alt=&#34;Promo video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Gif by&lt;/strong&gt; &lt;a href=&#34;https://linkedin.com/in/mohitjaisal&#34;&gt;Mohit Jaisal&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt; Click the image above for a video about the project and the folks who created it!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Pedagogy&lt;/h2&gt; &#xA;&lt;p&gt;We have chosen two pedagogical tenets while building this curriculum: ensuring that it is hands-on &lt;strong&gt;project-based&lt;/strong&gt; and that it includes &lt;strong&gt;frequent quizzes&lt;/strong&gt;. In addition, this curriculum has a common &lt;strong&gt;theme&lt;/strong&gt; to give it cohesion.&lt;/p&gt; &#xA;&lt;p&gt;By ensuring that the content aligns with projects, the process is made more engaging for students and retention of concepts will be augmented. In addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 12-week cycle. This curriculum also includes a postscript on real-world applications of ML, which can be used as extra credit or as a basis for discussion.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Find our &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/CODE_OF_CONDUCT.md&#34;&gt;Code of Conduct&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/TRANSLATIONS.md&#34;&gt;Translation&lt;/a&gt; guidelines. We welcome your constructive feedback!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Each lesson includes:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;optional sketchnote&lt;/li&gt; &#xA; &lt;li&gt;optional supplemental video&lt;/li&gt; &#xA; &lt;li&gt;pre-lecture warmup quiz&lt;/li&gt; &#xA; &lt;li&gt;written lesson&lt;/li&gt; &#xA; &lt;li&gt;for project-based lessons, step-by-step guides on how to build the project&lt;/li&gt; &#xA; &lt;li&gt;knowledge checks&lt;/li&gt; &#xA; &lt;li&gt;a challenge&lt;/li&gt; &#xA; &lt;li&gt;supplemental reading&lt;/li&gt; &#xA; &lt;li&gt;assignment&lt;/li&gt; &#xA; &lt;li&gt;post-lecture quiz&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;A note about languages&lt;/strong&gt;: These lessons are primarily written in Python, but many are also available in R. To complete an R lesson, go to the &lt;code&gt;/solution&lt;/code&gt; folder and look for R lessons. They include an .rmd extension that represents an &lt;strong&gt;R Markdown&lt;/strong&gt; file which can be simply defined as an embedding of &lt;code&gt;code chunks&lt;/code&gt; (of R or other languages) and a &lt;code&gt;YAML header&lt;/code&gt; (that guides how to format outputs such as PDF) in a &lt;code&gt;Markdown document&lt;/code&gt;. As such, it serves as an exemplary authoring framework for data science since it allows you to combine your code, its output, and your thoughts by allowing you to write them down in Markdown. Moreover, R Markdown documents can be rendered to output formats such as PDF, HTML, or Word.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;A note about quizzes&lt;/strong&gt;: All quizzes are contained &lt;a href=&#34;https://gray-sand-07a10f403.1.azurestaticapps.net/&#34;&gt;in this app&lt;/a&gt;, for 52 total quizzes of three questions each. They are linked from within the lessons but the quiz app can be run locally; follow the instruction in the &lt;code&gt;quiz-app&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Lesson Number&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Topic&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Lesson Grouping&lt;/th&gt; &#xA;   &lt;th&gt;Learning Objectives&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Linked Lesson&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Author&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;01&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Introduction to machine learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/README.md&#34;&gt;Introduction&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn the basic concepts behind machine learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/1-intro-to-ML/README.md&#34;&gt;Lesson&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Muhammad&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;The History of machine learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/README.md&#34;&gt;Introduction&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn the history underlying this field&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/2-history-of-ML/README.md&#34;&gt;Lesson&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Jen and Amy&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;03&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Fairness and machine learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/README.md&#34;&gt;Introduction&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;What are the important philosophical issues around fairness that students should consider when building and applying ML models?&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/3-fairness/README.md&#34;&gt;Lesson&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Tomomi&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;04&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Techniques for machine learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/README.md&#34;&gt;Introduction&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;What techniques do ML researchers use to build ML models?&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/4-techniques-of-ML/README.md&#34;&gt;Lesson&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Chris and Jen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;05&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Introduction to regression&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/README.md&#34;&gt;Regression&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Get started with Python and Scikit-learn for regression models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/1-Tools/README.md&#34;&gt;Python&lt;/a&gt;&lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/1-Tools/solution/R/lesson_1-R.ipynb&#34;&gt;R&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;Jen&lt;/li&gt;&#xA;     &lt;li&gt;Eric Wanjau&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;06&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;North American pumpkin prices &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/README.md&#34;&gt;Regression&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Visualize and clean data in preparation for ML&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/2-Data/README.md&#34;&gt;Python&lt;/a&gt;&lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/2-Data/solution/R/lesson_2-R.ipynb&#34;&gt;R&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;Jen&lt;/li&gt;&#xA;     &lt;li&gt;Eric Wanjau&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;07&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;North American pumpkin prices &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/README.md&#34;&gt;Regression&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Build linear and polynomial regression models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/3-Linear/README.md&#34;&gt;Python&lt;/a&gt;&lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/3-Linear/solution/R/lesson_3-R.ipynb&#34;&gt;R&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;Jen and Dmitry&lt;/li&gt;&#xA;     &lt;li&gt;Eric Wanjau&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;08&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;North American pumpkin prices &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/README.md&#34;&gt;Regression&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Build a logistic regression model&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/README.md&#34;&gt;Python&lt;/a&gt; &lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/solution/R/lesson_4-R.ipynb&#34;&gt;R&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;Jen&lt;/li&gt;&#xA;     &lt;li&gt;Eric Wanjau&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;09&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;A Web App &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/3-Web-App/README.md&#34;&gt;Web App&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Build a web app to use your trained model&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/3-Web-App/1-Web-App/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Jen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Introduction to classification&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/README.md&#34;&gt;Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Clean, prep, and visualize your data; introduction to classification&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/1-Introduction/README.md&#34;&gt;Python&lt;/a&gt; &lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/1-Introduction/solution/R/lesson_10-R.ipynb&#34;&gt;R&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;Jen and Cassie&lt;/li&gt;&#xA;     &lt;li&gt;Eric Wanjau&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Delicious Asian and Indian cuisines &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/README.md&#34;&gt;Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Introduction to classifiers&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/2-Classifiers-1/README.md&#34;&gt;Python&lt;/a&gt;&lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/2-Classifiers-1/solution/R/lesson_11-R.ipynb&#34;&gt;R&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;Jen and Cassie&lt;/li&gt;&#xA;     &lt;li&gt;Eric Wanjau&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Delicious Asian and Indian cuisines &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/README.md&#34;&gt;Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;More classifiers&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/3-Classifiers-2/README.md&#34;&gt;Python&lt;/a&gt;&lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb&#34;&gt;R&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;Jen and Cassie&lt;/li&gt;&#xA;     &lt;li&gt;Eric Wanjau&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Delicious Asian and Indian cuisines &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/README.md&#34;&gt;Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Build a recommender web app using your model&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/4-Applied/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Jen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Introduction to clustering&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/README.md&#34;&gt;Clustering&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Clean, prep, and visualize your data; Introduction to clustering&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/1-Visualize/README.md&#34;&gt;Python&lt;/a&gt;&lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/1-Visualize/solution/R/lesson_14-R.ipynb&#34;&gt;R&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;Jen&lt;/li&gt;&#xA;     &lt;li&gt;Eric Wanjau&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Exploring Nigerian Musical Tastes &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/README.md&#34;&gt;Clustering&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Explore the K-Means clustering method&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/2-K-Means/README.md&#34;&gt;Python&lt;/a&gt;&lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/2-K-Means/solution/R/lesson_15-R.ipynb&#34;&gt;R&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;Jen&lt;/li&gt;&#xA;     &lt;li&gt;Eric Wanjau&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Introduction to natural language processing &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/README.md&#34;&gt;Natural language processing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn the basics about NLP by building a simple bot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/1-Introduction-to-NLP/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Stephen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Common NLP Tasks &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/README.md&#34;&gt;Natural language processing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Deepen your NLP knowledge by understanding common tasks required when dealing with language structures&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/2-Tasks/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Stephen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Translation and sentiment analysis &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/README.md&#34;&gt;Natural language processing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Translation and sentiment analysis with Jane Austen&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/3-Translation-Sentiment/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Stephen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Romantic hotels of Europe &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/README.md&#34;&gt;Natural language processing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Sentiment analysis with hotel reviews 1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/4-Hotel-Reviews-1/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Stephen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Romantic hotels of Europe &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/README.md&#34;&gt;Natural language processing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Sentiment analysis with hotel reviews 2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/5-Hotel-Reviews-2/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Stephen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Introduction to time series forecasting&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/7-TimeSeries/README.md&#34;&gt;Time series&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Introduction to time series forecasting&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/7-TimeSeries/1-Introduction/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Francesca&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; World Power Usage  - time series forecasting with ARIMA&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/7-TimeSeries/README.md&#34;&gt;Time series&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Time series forecasting with ARIMA&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/7-TimeSeries/2-ARIMA/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Francesca&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;23&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; World Power Usage  - time series forecasting with SVR&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/7-TimeSeries/README.md&#34;&gt;Time series&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Time series forecasting with Support Vector Regressor&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/7-TimeSeries/3-SVR/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Anirban&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Introduction to reinforcement learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/8-Reinforcement/README.md&#34;&gt;Reinforcement learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Introduction to reinforcement learning with Q-Learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/8-Reinforcement/1-QLearning/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Dmitry&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Help Peter avoid the wolf! &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/8-Reinforcement/README.md&#34;&gt;Reinforcement learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Reinforcement learning Gym&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/8-Reinforcement/2-Gym/README.md&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Dmitry&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Postscript&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Real-World ML scenarios and applications&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/9-Real-World/README.md&#34;&gt;ML in the Wild&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Interesting and revealing real-world applications of classical ML&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/9-Real-World/1-Applications/README.md&#34;&gt;Lesson&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Team&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Offline access&lt;/h2&gt; &#xA;&lt;p&gt;You can run this documentation offline by using &lt;a href=&#34;https://docsify.js.org/#/&#34;&gt;Docsify&lt;/a&gt;. Fork this repo, &lt;a href=&#34;https://docsify.js.org/#/quickstart&#34;&gt;install Docsify&lt;/a&gt; on your local machine, and then in the root folder of this repo, type &lt;code&gt;docsify serve&lt;/code&gt;. The website will be served on port 3000 on your localhost: &lt;code&gt;localhost:3000&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;PDFs&lt;/h2&gt; &#xA;&lt;p&gt;Find a pdf of the curriculum with links &lt;a href=&#34;https://microsoft.github.io/ML-For-Beginners/pdf/readme.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Help Wanted!&lt;/h2&gt; &#xA;&lt;p&gt;Would you like to contribute a translation? Please read our &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/TRANSLATIONS.md&#34;&gt;translation guidelines&lt;/a&gt; and add a templated issue to manage the workload &lt;a href=&#34;https://github.com/microsoft/ML-For-Beginners/issues&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Other Curricula&lt;/h2&gt; &#xA;&lt;p&gt;Our team produces other curricula! Check out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/webdev-beginners&#34;&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/iot-beginners&#34;&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/datascience-beginners&#34;&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/ai-beginners&#34;&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>