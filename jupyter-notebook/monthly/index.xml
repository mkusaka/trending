<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-08-01T01:54:49Z</updated>
  <subtitle>Monthly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>langchain-ai/agents-from-scratch</title>
    <updated>2025-08-01T01:54:49Z</updated>
    <id>tag:github.com,2025-08-01:/langchain-ai/agents-from-scratch</id>
    <link href="https://github.com/langchain-ai/agents-from-scratch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build an email assistant with human-in-the-loop and memory&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agents From Scratch&lt;/h1&gt; &#xA;&lt;p&gt;The repo is a guide to building agents from scratch. It builds up to an &lt;a href=&#34;https://blog.langchain.dev/introducing-ambient-agents/&#34;&gt;&#34;ambient&#34;&lt;/a&gt; agent that can manage your email with connection to the Gmail API. It&#39;s grouped into 4 sections, each with a notebook and accompanying code in the &lt;code&gt;src/email_assistant&lt;/code&gt; directory. These section build from the basics of agents, to agent evaluation, to human-in-the-loop, and finally to memory. These all come together in an agent that you can deploy, and the principles can be applied to other agents across a wide range of tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview.png&#34; alt=&#34;overview&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Environment Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Python Version&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ensure you&#39;re using Python 3.11 or later.&lt;/li&gt; &#xA; &lt;li&gt;This version is required for optimal compatibility with LangGraph.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python3 --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;API Keys&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you don&#39;t have an OpenAI API key, you can sign up &lt;a href=&#34;https://openai.com/index/openai-api/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Sign up for LangSmith &lt;a href=&#34;https://smith.langchain.com/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Generate a LangSmith API key.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Set Environment Variables&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Copy the .env.example file to .env&#xA;cp .env.example .env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Edit the &lt;code&gt;.env&lt;/code&gt; file with the following:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LANGSMITH_API_KEY=your_langsmith_api_key&#xA;LANGSMITH_TRACING=true&#xA;LANGSMITH_PROJECT=&#34;interrupt-workshop&#34;&#xA;OPENAI_API_KEY=your_openai_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You can also set the environment variables in your terminal:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export LANGSMITH_API_KEY=your_langsmith_api_key&#xA;export LANGSMITH_TRACING=true&#xA;export OPENAI_API_KEY=your_openai_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Package Installation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Recommended: Using uv (faster and more reliable)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Install uv if you haven&#39;t already&#xA;pip install uv&#xA;&#xA;# Install the package with development dependencies&#xA;uv sync --extra dev&#xA;&#xA;# Activate the virtual environment&#xA;source .venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Alternative: Using pip&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ python3 -m venv .venv&#xA;$ source .venv/bin/activate&#xA;# Ensure you have a recent version of pip (required for editable installs with pyproject.toml)&#xA;$ python3 -m pip install --upgrade pip&#xA;# Install the package in editable mode&#xA;$ pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;⚠️ IMPORTANT&lt;/strong&gt;: Do not skip the package installation step! This editable install is &lt;strong&gt;required&lt;/strong&gt; for the notebooks to work correctly. The package is installed as &lt;code&gt;interrupt_workshop&lt;/code&gt; with import name &lt;code&gt;email_assistant&lt;/code&gt;, allowing you to import from anywhere with &lt;code&gt;from email_assistant import ...&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Structure&lt;/h2&gt; &#xA;&lt;p&gt;The repo is organized into the 4 sections, with a notebook for each and accompanying code in the &lt;code&gt;src/email_assistant&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;Preface: LangGraph 101&lt;/h3&gt; &#xA;&lt;p&gt;For a brief introduction to LangGraph and some of the concepts used in this repo, see the &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/langgraph_101.ipynb&#34;&gt;LangGraph 101 notebook&lt;/a&gt;. This notebook explains the basics of chat models, tool calling, agents vs workflows, LangGraph nodes / edges / memory, and LangGraph Studio.&lt;/p&gt; &#xA;&lt;h3&gt;Building an agent&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Notebook: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/agent.ipynb&#34;&gt;notebooks/agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Code: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant.py&#34;&gt;src/email_assistant/email_assistant.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview_agent.png&#34; alt=&#34;overview-agent&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook shows how to build the email assistant, combining an &lt;a href=&#34;https://langchain-ai.github.io/langgraph/tutorials/workflows/&#34;&gt;email triage step&lt;/a&gt; with an agent that handles the email response. You can see the linked code for the full implementation in &lt;code&gt;src/email_assistant/email_assistant.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/studio.png&#34; alt=&#34;Screenshot 2025-04-04 at 4 06 18 PM&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Notebook: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/evaluation.ipynb&#34;&gt;notebooks/evaluation.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview_eval.png&#34; alt=&#34;overview-eval&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook introduces evaluation with an email dataset in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/eval/email_dataset.py&#34;&gt;eval/email_dataset.py&lt;/a&gt;. It shows how to run evaluations using Pytest and the LangSmith &lt;code&gt;evaluate&lt;/code&gt; API. It runs evaluation for emails responses using LLM-as-a-judge as well as evaluations for tools calls and triage decisions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/eval.png&#34; alt=&#34;Screenshot 2025-04-08 at 8 07 48 PM&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Human-in-the-loop&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Notebook: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/hitl.ipynb&#34;&gt;notebooks/hitl.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Code: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl.py&#34;&gt;src/email_assistant/email_assistant_hitl.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview_hitl.png&#34; alt=&#34;overview-hitl&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebooks shows how to add human-in-the-loop (HITL), allowing the user to review specific tool calls (e.g., send email, schedule meeting). For this, we use &lt;a href=&#34;https://github.com/langchain-ai/agent-inbox&#34;&gt;Agent Inbox&lt;/a&gt; as an interface for human in the loop. You can see the linked code for the full implementation in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl.py&#34;&gt;src/email_assistant/email_assistant_hitl.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/agent-inbox.png&#34; alt=&#34;Agent Inbox showing email threads&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Memory&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Notebook: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/memory.ipynb&#34;&gt;notebooks/memory.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Code: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl_memory.py&#34;&gt;src/email_assistant/email_assistant_hitl_memory.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview_memory.png&#34; alt=&#34;overview-memory&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook shows how to add memory to the email assistant, allowing it to learn from user feedback and adapt to preferences over time. The memory-enabled assistant (&lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl_memory.py&#34;&gt;email_assistant_hitl_memory.py&lt;/a&gt;) uses the &lt;a href=&#34;https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory&#34;&gt;LangGraph Store&lt;/a&gt; to persist memories. You can see the linked code for the full implementation in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl_memory.py&#34;&gt;src/email_assistant/email_assistant_hitl_memory.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Connecting to APIs&lt;/h2&gt; &#xA;&lt;p&gt;The above notebooks using mock email and calendar tools.&lt;/p&gt; &#xA;&lt;h3&gt;Gmail Integration and Deployment&lt;/h3&gt; &#xA;&lt;p&gt;Set up Google API credentials following the instructions in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/tools/gmail/README.md&#34;&gt;Gmail Tools README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The README also explains how to deploy the graph to LangGraph Platform.&lt;/p&gt; &#xA;&lt;p&gt;The full implementation of the Gmail integration is in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl_memory_gmail.py&#34;&gt;src/email_assistant/email_assistant_hitl_memory_gmail.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Running Tests&lt;/h2&gt; &#xA;&lt;p&gt;The repository includes an automated test suite to evaluate the email assistant.&lt;/p&gt; &#xA;&lt;p&gt;Tests verify correct tool usage and response quality using LangSmith for tracking.&lt;/p&gt; &#xA;&lt;h3&gt;Running Tests with &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/tests/run_all_tests.py&#34;&gt;run_all_tests.py&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python tests/run_all_tests.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Test Results&lt;/h3&gt; &#xA;&lt;p&gt;Test results are logged to LangSmith under the project name specified in your &lt;code&gt;.env&lt;/code&gt; file (&lt;code&gt;LANGSMITH_PROJECT&lt;/code&gt;). This provides:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Visual inspection of agent traces&lt;/li&gt; &#xA; &lt;li&gt;Detailed evaluation metrics&lt;/li&gt; &#xA; &lt;li&gt;Comparison of different agent implementations&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Available Test Implementations&lt;/h3&gt; &#xA;&lt;p&gt;The available implementations for testing are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;email_assistant&lt;/code&gt; - Basic email assistant&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Testing Notebooks&lt;/h3&gt; &#xA;&lt;p&gt;You can also run tests to verify all notebooks execute without errors:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Run all notebook tests&#xA;python tests/test_notebooks.py&#xA;&#xA;# Or run via pytest&#xA;pytest tests/test_notebooks.py -v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Future Extensions&lt;/h2&gt; &#xA;&lt;p&gt;Add &lt;a href=&#34;https://langchain-ai.github.io/langmem/&#34;&gt;LangMem&lt;/a&gt; to manage memories:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Manage a collection of background memories.&lt;/li&gt; &#xA; &lt;li&gt;Add memory tools that can look up facts in the background memories.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>GoogleCloudPlatform/vertex-ai-creative-studio</title>
    <updated>2025-08-01T01:54:49Z</updated>
    <id>tag:github.com,2025-08-01:/GoogleCloudPlatform/vertex-ai-creative-studio</id>
    <link href="https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GenMedia Creative Studio is a Vertex AI generative media example user experience to highlight the use of Imagen, Veo and other generative media APIs on Google Cloud.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GenMedia Creative Studio | Vertex AI&lt;/h1&gt; &#xA;&lt;p&gt;GenMedia Creative Studio is an app that highlights the capabilities of Google Cloud Vertex AI generative AI creative APIs, including Imagen, the text-to-image model.&lt;/p&gt; &#xA;&lt;p&gt;Features Gemini for prompt rewriting as well as for a critic to provide a multimodal evaluation of the generated images.&lt;/p&gt; &#xA;&lt;p&gt;This app is built with &lt;a href=&#34;https://mesop-dev.github.io/mesop/&#34;&gt;Mesop&lt;/a&gt;, a Python-based UI framework that enables you to rapidly build web apps like this demo and internal apps.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;New!&lt;/strong&gt; Experiments&lt;/h3&gt; &#xA;&lt;p&gt;We&#39;re releasing stand-alone applications in advance of integration into the main GenMedia Creative Studio. Please see the &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-creative-studio/main/experiments/&#34;&gt;experiments&lt;/a&gt; folder for new, upcoming capbilities.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Creative GenMedia Workflow&lt;/strong&gt; - combining product image, brand guidelines and brief to create prompts for generation of creative video content using Veo.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Veo&lt;/strong&gt; - a stand-alone Veo app&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;MCP tools for Genmedia&lt;/strong&gt; - Model Context Protocol servers for genmedia services&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Babel&lt;/strong&gt; - Chirp 3: HD Voices&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Arena&lt;/strong&gt; - rate Model Garden image models&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Creative Podcast Assistant&lt;/strong&gt; - create a podcast using Chirp 3, using audio and other sources&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;GenMedia | Creative Studio&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-creative-studio/main/screenshots/creative_studio_02.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Run locally&lt;/h2&gt; &#xA;&lt;p&gt;Two environment variables are required to run this application:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;PROJECT_ID&lt;/code&gt;&lt;br&gt; Provide an environment variable for your Google Cloud Project ID&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export PROJECT_ID=$(gcloud config get project)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;IMAGE_CREATION_BUCKET&lt;/code&gt;&lt;br&gt; You&#39;ll need Google Cloud Storage bucket for the generative media. Note that this has to exist prior to running the application.&lt;/p&gt; &#xA;&lt;p&gt;If an existing Google Cloud Storage bucket is available, please provide its name without the &lt;code&gt;&#34;gs://&#34;&lt;/code&gt; prefix.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export IMAGE_CREATION_BUCKET=$PROJECT_ID-genmedia&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Otherwise, follow the next steps to create a storage bucket.&lt;/p&gt; &#xA;&lt;h3&gt;Create Storage Bucket (Optional)&lt;/h3&gt; &#xA;&lt;p&gt;Please run the following command to obtain new credentials.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gcloud auth login  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have already logged in with a different account, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gcloud config set account $PROJECT_ID  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create the storage bucket.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gcloud storage buckets create gs://$IMAGE_CREATION_BUCKET --location=US --default-storage-class=STANDARD&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; We have provided a &lt;code&gt;env_template&lt;/code&gt; that you can use to in your development environment. Simply duplicate it, rename it to &lt;code&gt;.env&lt;/code&gt; and replace &lt;code&gt;&amp;lt;YOUR_GCP_PROJECT_ID&amp;gt;&lt;/code&gt; with your project ID.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Then run &lt;code&gt;source .env&lt;/code&gt; to add those variables into your environment.&lt;/p&gt; &#xA;&lt;h3&gt;Create Virtual Environment&lt;/h3&gt; &#xA;&lt;p&gt;Create and activate a virtual environment for your solution.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 -m venv venv &#xA;source venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install requirements&lt;/h3&gt; &#xA;&lt;p&gt;Install the required Python libraries.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run with mesop&lt;/h3&gt; &#xA;&lt;p&gt;To run locally, use the &lt;code&gt;mesop&lt;/code&gt; command and open the browser to the URL provided:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mesop main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The mesop application may request you to allow it to accept incoming network connections. Please accept to avoid limiting the application&#39;s behavior.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Deploy to Cloud Run&lt;/h2&gt; &#xA;&lt;p&gt;Deploy this application to a Cloud Run service.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s recommended that you create a separate service account to deploy a Cloud Run Service.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export SA_NAME=sa-genmedia-creative-studio&#xA;export PROJECT_ID=$(gcloud config get project)&#xA;&#xA;gcloud iam service-accounts create $SA_NAME --description=&#34;genmedia creative studio&#34; --display-name=&#34;$SA_NAME&#34;&#xA;&#xA;gcloud projects add-iam-policy-binding $PROJECT_ID --member=&#34;serviceAccount:$SA_NAME@$PROJECT_ID.iam.gserviceaccount.com&#34;  --role=&#34;roles/aiplatform.user&#34;&#xA;&#xA;gcloud projects add-iam-policy-binding $PROJECT_ID --member=&#34;serviceAccount:$SA_NAME@$PROJECT_ID.iam.gserviceaccount.com&#34; --role=&#34;roles/storage.objectUser&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Deploy with the service account and environment variables created above; &lt;code&gt;PROJECT_ID&lt;/code&gt; and &lt;code&gt;IMAGE_CREATION_BUCKET&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gcloud run deploy creative-studio --source . \&#xA;  --allow-unauthenticated --region us-central1 \&#xA;  --service-account $SA_NAME@$PROJECT_ID.iam.gserviceaccount.com \&#xA;  --update-env-vars=IMAGE_CREATION_BUCKET=$IMAGE_CREATION_BUCKET,PROJECT_ID=$PROJECT_ID&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Disclaimer&lt;/h1&gt; &#xA;&lt;p&gt;This is not an officially supported Google product.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>NirDiamant/RAG_Techniques</title>
    <updated>2025-08-01T01:54:49Z</updated>
    <id>tag:github.com,2025-08-01:/NirDiamant/RAG_Techniques</id>
    <link href="https://github.com/NirDiamant/RAG_Techniques" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;http://makeapullrequest.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/in/nir-diamant-759323134/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/LinkedIn-Connect-blue&#34; alt=&#34;LinkedIn&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/NirDiamantAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/NirDiamantAI?label=Follow%20@NirDiamantAI&amp;amp;style=social&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.reddit.com/r/EducationalAI/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Reddit-Join%20our%20subreddit-FF4500?style=flat-square&amp;amp;logo=reddit&amp;amp;logoColor=white&#34; alt=&#34;Reddit&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/cA6Aa4uyDX&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-Join%20our%20community-7289da?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sponsors/NirDiamant&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=Sponsor&amp;amp;message=%E2%9D%A4&amp;amp;logo=GitHub&amp;amp;color=ff69b4&#34; alt=&#34;Sponsor&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;🌟 &lt;strong&gt;Support This Project:&lt;/strong&gt; Your sponsorship fuels innovation in RAG technologies. &lt;strong&gt;&lt;a href=&#34;https://github.com/sponsors/NirDiamant&#34;&gt;Become a sponsor&lt;/a&gt;&lt;/strong&gt; to help maintain and expand this valuable resource!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Sponsors ❤️&lt;/h2&gt; &#xA;&lt;p&gt;We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Company Sponsors&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zilliz.com&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/images/ziliz_logo.png&#34; style=&#34;border-radius: 12px; margin-right: 24px; vertical-align: middle;&#34; height=&#34;96&#34; alt=&#34;Zilliz: Key Collaborator&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Individual Sponsors&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/sponsors/Eisenh&#34;&gt;&lt;img src=&#34;https://github.com/Eisenh.png&#34; style=&#34;border-radius: 50%;&#34; width=&#34;64&#34; height=&#34;64&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Advanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems 🚀&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.&lt;/p&gt; &#xA;&lt;h2&gt;📫 Stay Updated!&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;🚀&lt;br&gt;&lt;b&gt;Cutting-edge&lt;br&gt;Updates&lt;/b&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;💡&lt;br&gt;&lt;b&gt;Expert&lt;br&gt;Insights&lt;/b&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;🎯&lt;br&gt;&lt;b&gt;Top 0.1%&lt;br&gt;Content&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/images/subscribe-button.svg?sanitize=true&#34; alt=&#34;Subscribe to DiamantAI Newsletter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;em&gt;Join over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!&lt;/em&gt; &lt;em&gt;&lt;strong&gt;Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/images/substack_image.png&#34; alt=&#34;DiamantAI&#39;s newsletter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Retrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.&lt;/p&gt; &#xA;&lt;p&gt;Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what&#39;s possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.&lt;/p&gt; &#xA;&lt;h2&gt;Related Projects&lt;/h2&gt; &#xA;&lt;p&gt;🚀 Level up with my &lt;strong&gt;&lt;a href=&#34;https://github.com/NirDiamant/agents-towards-production&#34;&gt;Agents Towards Production&lt;/a&gt;&lt;/strong&gt; repository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you&#39;re serious about shipping agents to production.&lt;/p&gt; &#xA;&lt;p&gt;🤖 Explore my &lt;strong&gt;&lt;a href=&#34;https://github.com/NirDiamant/GenAI_Agents&#34;&gt;GenAI Agents Repository&lt;/a&gt;&lt;/strong&gt; to discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.&lt;/p&gt; &#xA;&lt;p&gt;🖋️ Check out my &lt;strong&gt;&lt;a href=&#34;https://github.com/NirDiamant/Prompt_Engineering&#34;&gt;Prompt Engineering Techniques guide&lt;/a&gt;&lt;/strong&gt; for a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.&lt;/p&gt; &#xA;&lt;h2&gt;A Community-Driven Knowledge Hub&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;This repository grows stronger with your contributions!&lt;/strong&gt; Join our vibrant communities - the central hubs for shaping and advancing this project together 🤝&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.reddit.com/r/EducationalAI/&#34;&gt;Educational AI Subreddit&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://discord.gg/cA6Aa4uyDX&#34;&gt;RAG Techniques Discord Community&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Whether you&#39;re an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to our &lt;strong&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_Techniques/raw/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/strong&gt; file. Let&#39;s advance RAG technology together!&lt;/p&gt; &#xA;&lt;p&gt;🔗 For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free to &lt;strong&gt;&lt;a href=&#34;https://www.linkedin.com/in/nir-diamant-759323134/&#34;&gt;connect on LinkedIn&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🧠 State-of-the-art RAG enhancements&lt;/li&gt; &#xA; &lt;li&gt;📚 Comprehensive documentation for each technique&lt;/li&gt; &#xA; &lt;li&gt;🛠️ Practical implementation guidelines&lt;/li&gt; &#xA; &lt;li&gt;🌟 Regular updates with the latest advancements&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Advanced Techniques&lt;/h2&gt; &#xA;&lt;p&gt;Explore our extensive list of cutting-edge RAG techniques:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;#&lt;/th&gt; &#xA;   &lt;th&gt;Category&lt;/th&gt; &#xA;   &lt;th&gt;Technique&lt;/th&gt; &#xA;   &lt;th&gt;View&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;⭐ Key Collaboration&lt;/td&gt; &#xA;   &lt;td&gt;Graph RAG with Milvus Vector DB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/graphrag_with_milvus_vectordb.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graphrag_with_milvus_vectordb.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;   &lt;td&gt;Foundational 🌱&lt;/td&gt; &#xA;   &lt;td&gt;Basic RAG&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/simple_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;Foundational 🌱&lt;/td&gt; &#xA;   &lt;td&gt;RAG with CSV Files&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/simple_csv_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;Foundational 🌱&lt;/td&gt; &#xA;   &lt;td&gt;Reliable RAG&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/reliable_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5&lt;/td&gt; &#xA;   &lt;td&gt;Foundational 🌱&lt;/td&gt; &#xA;   &lt;td&gt;Optimizing Chunk Sizes&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/choose_chunk_size.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/choose_chunk_size.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;Foundational 🌱&lt;/td&gt; &#xA;   &lt;td&gt;Proposition Chunking&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/proposition_chunking.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/proposition_chunking.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;Query Enhancement 🔍&lt;/td&gt; &#xA;   &lt;td&gt;Query Transformations&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/query_transformations.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/query_transformations.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;Query Enhancement 🔍&lt;/td&gt; &#xA;   &lt;td&gt;HyDE (Hypothetical Document Embedding)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9&lt;/td&gt; &#xA;   &lt;td&gt;Query Enhancement 🔍&lt;/td&gt; &#xA;   &lt;td&gt;HyPE (Hypothetical Prompt Embedding)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embeddings.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embeddings.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10&lt;/td&gt; &#xA;   &lt;td&gt;Context Enrichment 📚&lt;/td&gt; &#xA;   &lt;td&gt;Contextual Chunk Headers&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/contextual_chunk_headers.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;11&lt;/td&gt; &#xA;   &lt;td&gt;Context Enrichment 📚&lt;/td&gt; &#xA;   &lt;td&gt;Relevant Segment Extraction&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/relevant_segment_extraction.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;Context Enrichment 📚&lt;/td&gt; &#xA;   &lt;td&gt;Context Window Enhancement&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;13&lt;/td&gt; &#xA;   &lt;td&gt;Context Enrichment 📚&lt;/td&gt; &#xA;   &lt;td&gt;Semantic Chunking&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/semantic_chunking.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/semantic_chunking.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;14&lt;/td&gt; &#xA;   &lt;td&gt;Context Enrichment 📚&lt;/td&gt; &#xA;   &lt;td&gt;Contextual Compression&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/contextual_compression.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_compression.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;15&lt;/td&gt; &#xA;   &lt;td&gt;Context Enrichment 📚&lt;/td&gt; &#xA;   &lt;td&gt;Document Augmentation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/document_augmentation.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/document_augmentation.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;16&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Retrieval 🚀&lt;/td&gt; &#xA;   &lt;td&gt;Fusion Retrieval&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/fusion_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;17&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Retrieval 🚀&lt;/td&gt; &#xA;   &lt;td&gt;Reranking&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/reranking.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;18&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Retrieval 🚀&lt;/td&gt; &#xA;   &lt;td&gt;Multi-faceted Filtering&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/multi_faceted_filtering.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_faceted_filtering.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;19&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Retrieval 🚀&lt;/td&gt; &#xA;   &lt;td&gt;Hierarchical Indices&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/hierarchical_indices.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/hierarchical_indices.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;20&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Retrieval 🚀&lt;/td&gt; &#xA;   &lt;td&gt;Ensemble Retrieval&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/ensemble_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/ensemble_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;21&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Retrieval 🚀&lt;/td&gt; &#xA;   &lt;td&gt;Dartboard Retrieval&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/dartboard.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/dartboard.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;22&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Retrieval 🚀&lt;/td&gt; &#xA;   &lt;td&gt;Multi-modal RAG with Captioning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;23&lt;/td&gt; &#xA;   &lt;td&gt;Iterative Techniques 🔁&lt;/td&gt; &#xA;   &lt;td&gt;Retrieval with Feedback Loop&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;24&lt;/td&gt; &#xA;   &lt;td&gt;Iterative Techniques 🔁&lt;/td&gt; &#xA;   &lt;td&gt;Adaptive Retrieval&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/adaptive_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/adaptive_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;25&lt;/td&gt; &#xA;   &lt;td&gt;Iterative Retrieval 🔄&lt;/td&gt; &#xA;   &lt;td&gt;Iterative Retrieval&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/iterative_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/iterative_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;26&lt;/td&gt; &#xA;   &lt;td&gt;Evaluation 📊&lt;/td&gt; &#xA;   &lt;td&gt;DeepEval&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/evaluation/evaluation_deep_eval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_deep_eval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;27&lt;/td&gt; &#xA;   &lt;td&gt;Evaluation 📊&lt;/td&gt; &#xA;   &lt;td&gt;GroUSE&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/evaluation/evaluation_grouse.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_grouse.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;28&lt;/td&gt; &#xA;   &lt;td&gt;Explainability 🔬&lt;/td&gt; &#xA;   &lt;td&gt;Explainable Retrieval&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/explainable_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;29&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Architecture 🏗️&lt;/td&gt; &#xA;   &lt;td&gt;Graph RAG with LangChain&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/graph_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;30&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Architecture 🏗️&lt;/td&gt; &#xA;   &lt;td&gt;Microsoft GraphRAG&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/Microsoft_GraphRag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;31&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Architecture 🏗️&lt;/td&gt; &#xA;   &lt;td&gt;RAPTOR&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/raptor.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/raptor.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;32&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Architecture 🏗️&lt;/td&gt; &#xA;   &lt;td&gt;Self-RAG&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/self_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/self_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;33&lt;/td&gt; &#xA;   &lt;td&gt;Advanced Architecture 🏗️&lt;/td&gt; &#xA;   &lt;td&gt;Corrective RAG (CRAG)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/crag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;34&lt;/td&gt; &#xA;   &lt;td&gt;Special Technique 🌟&lt;/td&gt; &#xA;   &lt;td&gt;Sophisticated Controllable Agent&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NirDiamant/Controllable-RAG-Agent&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;🌱 Foundational RAG Techniques&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Simple RAG 🌱&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_Techniques/raw/main/all_rag_techniques_runnable_scripts/simple_rag.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Introducing basic RAG techniques ideal for newcomers.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Start with basic retrieval queries and integrate incremental learning mechanisms.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Simple RAG using a CSV file 🧩&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Introducing basic RAG using CSV files.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reliable RAG 🏷️&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Check for retrieved document relevancy and highlight the segment of docs used for answering.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Choose Chunk Size 📏&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/choose_chunk_size.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/choose_chunk_size.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/choose_chunk_size.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Proposition Chunking ⛓️‍💥&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/proposition_chunking.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/proposition_chunking.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;💪 &lt;strong&gt;Proposition Generation:&lt;/strong&gt; The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.&lt;/li&gt; &#xA;   &lt;li&gt;✅ &lt;strong&gt;Quality Checking:&lt;/strong&gt; The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Additional Resources 📚&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://open.substack.com/pub/diamantai/p/the-propositions-method-enhancing?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&#34;&gt;The Propositions Method: Enhancing Information Retrieval for AI Systems&lt;/a&gt;&lt;/strong&gt; - A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;🔍 Query Enhancement&lt;/h3&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Query Transformations 🔄&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/query_transformations.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/query_transformations.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/query_transformations.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Modifying and expanding queries to improve retrieval effectiveness.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;✍️ &lt;strong&gt;Query Rewriting:&lt;/strong&gt; Reformulate queries to improve retrieval.&lt;/li&gt; &#xA;   &lt;li&gt;🔙 &lt;strong&gt;Step-back Prompting:&lt;/strong&gt; Generate broader queries for better context retrieval.&lt;/li&gt; &#xA;   &lt;li&gt;🧩 &lt;strong&gt;Sub-query Decomposition:&lt;/strong&gt; Break complex queries into simpler sub-queries.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Hypothetical Questions (HyDE Approach) ❓&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/HyDe_Hypothetical_Document_Embedding.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Generating hypothetical questions to improve alignment between queries and data.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://open.substack.com/pub/diamantai/p/hyde-exploring-hypothetical-document?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&#34;&gt;HyDE: Exploring Hypothetical Document Embeddings for AI Retrieval&lt;/a&gt;&lt;/strong&gt; - A short blog post explaining this method clearly.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;📚 Context and Content Enrichment&lt;/h3&gt; &#xA;&lt;ol start=&#34;8&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Hypothetical Prompt Embeddings (HyPE) ❓🚀&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embedding.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embedding.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/HyPE_Hypothetical_Prompt_Embeddings.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval that &lt;strong&gt;precomputes hypothetical prompts at the indexing stage&lt;/strong&gt;, but inseting the chunk in their place. This transforms retrieval into a &lt;strong&gt;question-question matching task&lt;/strong&gt;. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead while &lt;strong&gt;improving retrieval alignment&lt;/strong&gt;.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;📖 &lt;strong&gt;Precomputed Questions:&lt;/strong&gt; Instead of embedding document chunks, HyPE &lt;strong&gt;generates multiple hypothetical queries per chunk&lt;/strong&gt; at indexing time.&lt;/li&gt; &#xA;   &lt;li&gt;🔍 &lt;strong&gt;Question-Question Matching:&lt;/strong&gt; User queries are matched against stored hypothetical questions, leading to &lt;strong&gt;better retrieval alignment&lt;/strong&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;⚡ &lt;strong&gt;No Runtime Overhead:&lt;/strong&gt; Unlike HyDE, HyPE does &lt;strong&gt;not require LLM calls at query time&lt;/strong&gt;, making retrieval &lt;strong&gt;faster and cheaper&lt;/strong&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;📈 &lt;strong&gt;Higher Precision &amp;amp; Recall:&lt;/strong&gt; Improves retrieval &lt;strong&gt;context precision by up to 42 percentage points&lt;/strong&gt; and &lt;strong&gt;claim recall by up to 45 percentage points&lt;/strong&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5139335&#34;&gt;Preprint: Hypothetical Prompt Embeddings (HyPE)&lt;/a&gt;&lt;/strong&gt; - Research paper detailing the method, evaluation, and benchmarks.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Contextual Chunk Headers &lt;span&gt;🏷&lt;/span&gt;&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/D-Star-AI/dsRAG&#34;&gt;dsRAG&lt;/a&gt;&lt;/strong&gt;: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Relevant Segment Extraction 🧩&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Context Enrichment Techniques 📝&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/context_enrichment_window_around_chunk.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Overview 🔎&lt;/h4&gt; &#xA;&lt;p&gt;Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.&lt;/p&gt; &#xA;&lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;&lt;p&gt;Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.&lt;/p&gt; &#xA;&lt;ol start=&#34;12&#34;&gt; &#xA; &lt;li&gt;Semantic Chunking 🧠&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/semantic_chunking.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/semantic_chunking.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_Techniques/raw/main/all_rag_techniques_runnable_scripts/semantic_chunking.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Overview 🔎&lt;/h4&gt; &#xA;&lt;p&gt;Dividing documents based on semantic coherence rather than fixed sizes.&lt;/p&gt; &#xA;&lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;&lt;p&gt;Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.&lt;/p&gt; &#xA;&lt;h4&gt;Additional Resources 📚&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://open.substack.com/pub/diamantai/p/semantic-chunking-improving-ai-information?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&#34;&gt;Semantic Chunking: Improving AI Information Retrieval&lt;/a&gt;&lt;/strong&gt; - A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;13&#34;&gt; &#xA; &lt;li&gt;Contextual Compression 🗜️&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_compression.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_compression.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/contextual_compression.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Overview 🔎&lt;/h4&gt; &#xA;&lt;p&gt;Compressing retrieved information while preserving query-relevant content.&lt;/p&gt; &#xA;&lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;&lt;p&gt;Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.&lt;/p&gt; &#xA;&lt;ol start=&#34;14&#34;&gt; &#xA; &lt;li&gt;Document Augmentation through Question Generation for Enhanced Retrieval&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/document_augmentation.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/document_augmentation.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/document_augmentation.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Overview 🔎&lt;/h4&gt; &#xA;&lt;p&gt;This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.&lt;/p&gt; &#xA;&lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;&lt;p&gt;Use an LLM to augment text dataset with all possible questions that can be asked to each document.&lt;/p&gt; &#xA;&lt;h3&gt;🚀 Advanced Retrieval Methods&lt;/h3&gt; &#xA;&lt;ol start=&#34;15&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Fusion Retrieval 🔗&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/fusion_retrieval.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Optimizing search results by combining different retrieval methods.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Intelligent Reranking 📈&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking_with_llamaindex.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/reranking.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;🧠 &lt;strong&gt;LLM-based Scoring:&lt;/strong&gt; Use a language model to score the relevance of each retrieved chunk.&lt;/li&gt; &#xA;   &lt;li&gt;🔀 &lt;strong&gt;Cross-Encoder Models:&lt;/strong&gt; Re-encode both the query and retrieved documents jointly for similarity scoring.&lt;/li&gt; &#xA;   &lt;li&gt;🏆 &lt;strong&gt;Metadata-enhanced Ranking:&lt;/strong&gt; Incorporate metadata into the scoring process for more nuanced ranking.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://open.substack.com/pub/diamantai/p/relevance-revolution-how-re-ranking?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&#34;&gt;Relevance Revolution: How Re-ranking Transforms RAG Systems&lt;/a&gt;&lt;/strong&gt; - A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Multi-faceted Filtering 🔍&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Applying various filtering techniques to refine and improve the quality of retrieved results.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;🏷️ &lt;strong&gt;Metadata Filtering:&lt;/strong&gt; Apply filters based on attributes like date, source, author, or document type.&lt;/li&gt; &#xA;   &lt;li&gt;📊 &lt;strong&gt;Similarity Thresholds:&lt;/strong&gt; Set thresholds for relevance scores to keep only the most pertinent results.&lt;/li&gt; &#xA;   &lt;li&gt;📄 &lt;strong&gt;Content Filtering:&lt;/strong&gt; Remove results that don&#39;t match specific content criteria or essential keywords.&lt;/li&gt; &#xA;   &lt;li&gt;🌈 &lt;strong&gt;Diversity Filtering:&lt;/strong&gt; Ensure result diversity by filtering out near-duplicate entries.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Hierarchical Indices 🗂️&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/hierarchical_indices.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/hierarchical_indices.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/hierarchical_indices.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Creating a multi-tiered system for efficient information navigation and retrieval.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://open.substack.com/pub/diamantai/p/hierarchical-indices-enhancing-rag?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&#34;&gt;Hierarchical Indices: Enhancing RAG Systems&lt;/a&gt;&lt;/strong&gt; - A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ensemble Retrieval 🎭&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Combining multiple retrieval models or techniques for more robust and accurate results.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Dartboard Retrieval 🎯&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/dartboard.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/dartboard.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Optimizing over Relevant Information Gain in Retrieval&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Combine both relevance and diversity into a single scoring function and directly optimize for it.&lt;/li&gt; &#xA;   &lt;li&gt;POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Multi-modal Retrieval 📽️&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Extending RAG capabilities to handle diverse data types for richer responses.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Multi-model RAG with Multimedia Captioning&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt; - Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Multi-model RAG with Colpali&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_colpali.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_colpali.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt; - Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;🔁 Iterative and Adaptive Techniques&lt;/h3&gt; &#xA;&lt;ol start=&#34;22&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Retrieval with Feedback Loops 🔁&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/retrieval_with_feedback_loop.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Implementing mechanisms to learn from user interactions and improve future retrievals.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Adaptive Retrieval 🎯&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/adaptive_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/adaptive_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/adaptive_retrieval.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Dynamically adjusting retrieval strategies based on query types and user contexts.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Iterative Retrieval 🔄&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Performing multiple rounds of retrieval to refine and enhance result quality.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;📊 Evaluation&lt;/h3&gt; &#xA;&lt;ol start=&#34;25&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;DeepEval Evaluation&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_deep_eval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_deep_eval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt; | Comprehensive RAG system evaluation |&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Use the &lt;code&gt;deepeval&lt;/code&gt; library to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;GroUSE Evaluation&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_grouse.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_grouse.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt; | Contextually-grounded LLM evaluation |&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Use the &lt;code&gt;grouse&lt;/code&gt; package to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;🔬 Explainability and Transparency&lt;/h3&gt; &#xA;&lt;ol start=&#34;27&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Explainable Retrieval 🔍&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/explainable_retrieval.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Providing transparency in the retrieval process to enhance user trust and system refinement.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Explain why certain pieces of information were retrieved and how they relate to the query.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;🏗️ Advanced Architectures&lt;/h3&gt; &#xA;&lt;ol start=&#34;28&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Graph RAG with Milvus Vector Database 🔍&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Graph RAG with Milvus&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graphrag_with_milvus_vectordb.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graphrag_with_milvus_vectordb.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collections&lt;/li&gt; &#xA;   &lt;li&gt;Perform multi-way retrieval by querying both collections&lt;/li&gt; &#xA;   &lt;li&gt;Use an LLM to rerank retrieved relationships based on their relevance to the query&lt;/li&gt; &#xA;   &lt;li&gt;Retrieve the final passages based on the most relevant relationships&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Knowledge Graph Integration (Graph RAG) 🕸️&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/graph_rag.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Incorporating structured data from knowledge graphs to enrich context and improve retrieval.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;GraphRag (Microsoft) 🎯&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;GraphRag&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMs&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;• Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval 🌳&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/raptor.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/raptor.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/raptor.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Implementing a recursive approach to process and organize retrieved information in a tree structure.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Self RAG 🔁&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/self_rag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/self_rag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/self_rag.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;• Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Corrective RAG 🔧&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&#34;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-View-blue&#34; height=&#34;20&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/crag.py&#34;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;• Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;🌟 Special Advanced Technique 🌟&lt;/h2&gt; &#xA;&lt;ol start=&#34;34&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/NirDiamant/Controllable-RAG-Agent&#34;&gt;Sophisticated Controllable Agent for Complex RAG Tasks 🤖&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the &#34;brain&#34; 🧠 of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;• Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To begin implementing these advanced RAG techniques in your projects:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository: &lt;pre&gt;&lt;code&gt;git clone https://github.com/NirDiamant/RAG_Techniques.git&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Navigate to the technique you&#39;re interested in: &lt;pre&gt;&lt;code&gt;cd all_rag_techniques/technique-name&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Follow the detailed implementation guide in each technique&#39;s directory.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the community! If you have a new technique or improvement to suggest:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork the repository&lt;/li&gt; &#xA; &lt;li&gt;Create your feature branch: &lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Commit your changes: &lt;code&gt;git commit -m &#39;Add some AmazingFeature&#39;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Push to the branch: &lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Open a pull request&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/NirDiamant/RAG_Techniques/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=NirDiamant/RAG_Techniques&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under a custom non-commercial license - see the &lt;a href=&#34;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;⭐️ If you find this repository helpful, please consider giving it a star!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=main-readme&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search&lt;/p&gt;</summary>
  </entry>
</feed>