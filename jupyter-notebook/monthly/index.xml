<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-01T02:03:53Z</updated>
  <subtitle>Monthly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>AccumulateMore/CV</title>
    <updated>2023-11-01T02:03:53Z</updated>
    <id>tag:github.com,2023-11-01:/AccumulateMore/CV</id>
    <link href="https://github.com/AccumulateMore/CV" rel="alternate"></link>
    <summary type="html">&lt;p&gt;âœ”ï¼ˆå·²å®Œç»“ï¼‰æœ€å…¨é¢çš„ æ·±åº¦å­¦ä¹  ç¬”è®°ã€åœŸå † Pytorchã€‘ã€ææ² åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‘ã€å´æ©è¾¾ æ·±åº¦å­¦ä¹ ã€‘&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;æœ€å…¨é¢çš„ æ·±åº¦å­¦ä¹  ç¬”è®°&lt;/h1&gt; &#xA;&lt;p&gt;Pytorch è§†é¢‘è®²è§£ã€ä¸»è®²äººï¼šåœŸå †ã€‘ã€å¯¹åº”ç¬”è®°ï¼š100-122ã€‘&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1hE411t7RN?spm_id_from=333.337.search-card.all.click&#34;&gt;https://www.bilibili.com/video/BV1hE411t7RN?spm_id_from=333.337.search-card.all.click&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;æ·±åº¦å­¦ä¹  è§†é¢‘è®²è§£ã€ä¸»è®²äººï¼šææ²ã€‘ã€å¯¹åº”ç¬”è®°ï¼š200-268ã€‘&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497&#34;&gt;https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;æ·±åº¦å­¦ä¹  è§†é¢‘è®²è§£ã€ä¸»è®²äººï¼šå´æ©è¾¾ã€‘ã€å¯¹åº”ç¬”è®°ï¼š300-354ã€‘&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=c9745e4447536b28b2b0735071d30bd6&#34;&gt;https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=c9745e4447536b28b2b0735071d30bd6&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;åœŸå †&amp;amp;ææ²&amp;amp;å´æ©è¾¾ æ•°æ®é›†ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;é“¾æ¥ï¼š&lt;a href=&#34;https://pan.baidu.com/s/1Fjw3o1Jr_-yOabpXyLXLNA&#34;&gt;https://pan.baidu.com/s/1Fjw3o1Jr_-yOabpXyLXLNA&lt;/a&gt; æå–ç ï¼šeal7&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;å¤‡æ³¨ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;åœ¨çº¿è§‚çœ‹ç¬”è®°æ—¶ï¼Œæœ‰æ—¶ä¼šå‡ºç°å›¾ç‰‡ï¼ˆæˆ–å…¬å¼ï¼‰æ˜¾ç¤ºä¸å®Œæ•´ï¼Œè¿™æ˜¯Githubç½‘ç«™æ²¡æœ‰è§£æå¥½ï¼Œç¬”è®°ä¸‹è½½åˆ°æœ¬åœ°è§‚çœ‹å°±æ­£å¸¸äº†ã€‚ä¸ä¼šä¸‹è½½ç¬”è®°çš„ï¼Œç™¾åº¦æŸ¥ä¸€ä¸‹&#34;Githubå¦‚ä½•ä¸‹è½½æ–‡ä»¶&#34;ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ç¬”è®°æ˜¯ç”¨ Anaconda çš„ Jupyter Notebook æ‰“å¼€çš„ï¼Œä¸ä¼šæ‰“å¼€çš„ï¼Œç™¾åº¦æŸ¥ä¸€ä¸‹&#34;Anacondaå¦‚ä½•æ‰“å¼€jupyter notebookæ–‡ä»¶&#34;ï¼Œæˆ–è€…æˆ‘çš„ä¸»é¡µPythonä»“åº“é‡Œé¢&#34;00_Pythonç¼–è¾‘å™¨&#34;é‡Œé¢æœ‰å†™ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å®‰è£… Jupyter Notebook çš„ç›®å½•æ’ä»¶ï¼Œå¯ä»¥å¿«é€Ÿé€šè¿‡ç›®å½•ï¼Œè·³è½¬åˆ°ç›¸åº”çš„ç« èŠ‚ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ä¸ä¼šå®‰è£…ç›®å½•çš„ï¼Œç™¾åº¦æŸ¥ä¸€ä¸‹&#34;jupyter notebookå¦‚ä½•å®‰è£…ç›®å½•&#34;ï¼Œæˆ–è€…æˆ‘çš„ä¸»é¡µPythonä»“åº“é‡Œé¢&#34;00_Pythonç¼–è¾‘å™¨&#34;é‡Œé¢æœ‰ç›¸å…³é“¾æ¥ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/AccumulateMore/CV/assets/60348867/20b6a8e9-ad05-4940-93b9-ab63dc75bb7b&#34; alt=&#34;ae3cce2d56a4953972ed4201c085722&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;è¡¥å……ï¼š&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘çš„Githubä¸»é¡µï¼Œè¿˜æœ‰å…¶ä»–ä¼˜ç§€è§†é¢‘çš„ç¬”è®°ï¼Œå¸Œæœ›èƒ½å¸®åŠ©åˆ°ä½ ~&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AccumulateMore&#34;&gt;https://github.com/AccumulateMore&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;æˆ‘çš„çŸ¥ä¹ä¸»é¡µï¼Œè¿˜æœ‰å…¶ä»–é¢†åŸŸçš„ç¬”è®°ï¼Œå¸Œæœ›èƒ½å¸®åŠ©åˆ°ä½ ~&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/people/bao-bei-ru-huai&#34;&gt;https://www.zhihu.com/people/bao-bei-ru-huai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;æˆ‘çš„å“”å“©å“”å“© ï¼ˆæœªæ¥æ›´æ–°é¡¹ç›®~ï¼‰&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://space.bilibili.com/402601153?spm_id_from=333.788.0.0&#34;&gt;https://space.bilibili.com/402601153?spm_id_from=333.788.0.0&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&#34;â™¥æˆ‘çš„ç¬”è®°ï¼Œå¸Œæœ›å¯¹ä½ æœ‰å¸®åŠ©â™¥&#34;&lt;/p&gt; &#xA;&lt;p&gt;â™¥å°å£°å“”å“”ï¼šä½ çš„starï¼Œæ˜¯æˆ‘æ›´æ–°çš„åŠ¨åŠ›~â™¥&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;æ­å»ºäº¤æµç¾¤ï¼Œå¸®åŠ©å­¤å•çš„è‡ªå­¦è€…äº¤æµ&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ã€æ·±åº¦å­¦ä¹  å­¦ä¹ äº¤æµâ‘ ç¾¤ã€‘&lt;/th&gt; &#xA;   &lt;th&gt;ã€æ·±åº¦å­¦ä¹  å­¦ä¹ äº¤æµâ‘¡ç¾¤ã€‘&lt;/th&gt; &#xA;   &lt;th&gt;å¾®ä¿¡&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/AccumulateMore/CV/assets/60348867/c99750a2-89c0-45ed-bf42-e8f63a222d60&#34; alt=&#34;312f346ad393a2f617f21da7ffec9d8&#34;&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/AccumulateMore/CV/assets/60348867/d6c44e7b-8349-4de3-b91b-ed62ee7c1544&#34; alt=&#34;2f44c2648aaf04f393162501e9e4e0a&#34;&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/AccumulateMore/CV/assets/60348867/0d3f05f6-ba72-4a1d-9c5b-6d5f0c8eb8f8&#34; alt=&#34;ad9bc1ef4eccf11a0e521dec10968d3&#34;&gt;&lt;br&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;çœ‹äººä¹‹çŸ­ï¼Œå¤©ä¸‹æ— ä¸€å¯äº¤ä¹‹äººã€‚çœ‹äººä¹‹é•¿ï¼Œä¸–é—´ä¸€åˆ‡çš†æ˜¯å¾å¸ˆã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¡¥å……è¯´æ˜ï¼šæœ¬äººä»…æ­å»ºå¹¶ç®¡ç†ç¾¤ã€å‘å¹¿å‘Šè¸¢ã€‘ï¼Œä¸åœ¨ç¾¤å†…ç­”ç–‘ï¼Œç¾¤å‹äº’ç›¸äº¤æµç­”ç–‘ã€‚&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;å¸®ä½ ä»¬å°±ä¸šï¼Œæœ‰æ„å‘çš„å¯ä»¥æŠ•ç®€å†&lt;/p&gt; &#xA;&lt;p&gt;è”å½±åŒ»ç–— åœ°ç‚¹ï¼ˆè‡ªé€‰ï¼‰ï¼šä¸Šæµ·ã€åŒ—äº¬ã€æ·±åœ³ã€æ­¦æ±‰ã€å¹¿å·ã€æˆéƒ½ã€è¥¿å®‰ã€æ²ˆé˜³ã€ä¸‰äºšç­‰&lt;/p&gt; &#xA;&lt;p&gt;å†…æ¨äººï¼šè”å½±è€å‘˜å·¥&lt;/p&gt; &#xA;&lt;p&gt;å†…æ¨å…¥å£ï¼ˆæ ¡æ‹›ã€ç¤¾æ‹›ï¼‰ï¼š&lt;a href=&#34;https://neitui.italent.cn/united-imaging/sharejobs?shareId=9d052226-87e4-4fb9-942b-f6f83abfb1cd&#34;&gt;https://neitui.italent.cn/united-imaging/sharejobs?shareId=9d052226-87e4-4fb9-942b-f6f83abfb1cd&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;å²—ä½èŒè´£ã€å›¾åƒæ–¹å‘ã€‘ï¼š&lt;/p&gt; &#xA;&lt;p&gt;å‚ä¸è”å½±é›†å›¢äº§å“çš„AIç®—æ³•å¼€å‘å·¥ä½œæˆ–å›¾å½¢ç®—æ³•å¼€å‘å·¥ä½œï¼Œè´Ÿè´£ä¸‹åˆ—è‡³å°‘ä¸€é¡¹å·¥ä½œï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;è´Ÿè´£æä¾›äº§å“çº§é«˜ç«¯ç®—æ³•è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼šè”å½±é€šç”¨è½¯ä»¶å¹³å°ã€è”å½±é«˜çº§åº”ç”¨åå¤„ç†å·¥ä½œç«™ã€è”å½±æ™ºèƒ½uAlå¹³å°ã€è”å½±æœºå™¨äººæ‰‹æœ¯è§„åˆ’ä¸å¯¼èˆªã€MR/CT/RT/MI/USäº‹ä¸šéƒ¨çš„ç®—æ³•éœ€æ±‚ã€ç§‘ç ”é™¢æ‰€å’ŒåŒ»é™¢çš„å‰ç»æ€§ç ”ç©¶é¡¹ç›®ç­‰ï¼›å‚ä¸åˆ›æ–°æŠ€æœ¯çš„äº§å“åŒ–å·¥ä½œã€‚&lt;/li&gt; &#xA; &lt;li&gt;åŒ»å­¦å›¾åƒ3Dæ¸²æŸ“ç®—æ³•å’Œåº”ç”¨ç»´æŠ¤ä¸å¼€å‘ï¼Œåˆ©ç”¨å›¾åƒå¤„ç†å’Œäººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œä»äº‹åŒ»å­¦å›¾åƒå¤„ç†é¢†åŸŸç›¸å…³ç®—æ³•çš„è®¾è®¡å’Œç ”å‘ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;ä»»èŒè¦æ±‚ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ç†Ÿæ‚‰æœºå™¨è§†è§‰åŸç†ï¼Œç†Ÿæ‚‰ä»¥ä¸‹é¢†åŸŸä¹‹ä¸€ï¼š3Dé‡å»ºã€ç«‹ä½“è§†è§‰ã€SLAMã€é€šç”¨å›¾åƒè§†é¢‘åˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€äººä½“å§¿æ€ä¼°è®¡ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ç†Ÿæ‚‰ä»¥ä¸‹åŒ»å­¦å›¾åƒåå¤„ç†ç®—æ³•ä¹‹ä¸€ï¼šå›¾å½¢ç®—æ³•ã€é‡å»ºç®—æ³•ã€åˆ†å‰²ç®—æ³•ã€æ£€æµ‹ç®—æ³•ã€åˆ†ç±»ç®—æ³•ã€é…å‡†ç®—æ³•ã€æ·±åº¦å­¦ä¹ ç®—æ³•ã€æµä½“åŠ›å­¦ç®—æ³•ã€çŒæ³¨ç®—æ³•ã€çº¹ç†åˆ†æç®—æ³•ç­‰ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;å²—ä½èŒè´£ã€è¯­éŸ³æ–¹å‘ã€‘ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;è´Ÿè´£éŸ³é¢‘ä¿¡å·å¤„ç†å’Œè¯†åˆ«ç›¸å…³ç®—æ³•çš„ç ”ç©¶å’Œå®ç°ï¼ŒåŒ…å«ä½†ä¸é™äºå›å£°æ¶ˆé™¤ã€éº¦å…‹é£é˜µåˆ—ã€ç›²æºåˆ†ç¦»ç­‰æŠ€æœ¯ã€‚&lt;/li&gt; &#xA; &lt;li&gt;è´Ÿè´£æ·±åº¦å­¦ä¹ ã€ç¥ç»ç½‘ç»œç­‰AIéŸ³é¢‘ç®—æ³•çš„ç ”ç©¶å’Œå®ç°ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;ä»»èŒè¦æ±‚ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;æ‰å®çš„æ•°å­¦ç†è®ºåŠæ•°å­—ä¿¡å·å¤„ç†åŸºç¡€ï¼ŒæŒæ¡MatlabåŠC/C++è¯­è¨€ç¼–ç¨‹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æœ‰è¯­éŸ³ã€éŸ³é¢‘ä¿¡å·å¤„ç†(é™å™ªï¼Œå›å£°æ¶ˆé™¤ã€éº¦é˜µã€éŸ³æ•ˆç­‰)ç›¸å…³ç»éªŒã€‚&lt;/li&gt; &#xA; &lt;li&gt;æœ‰æ·±åº¦å­¦ä¹ ã€ç¥ç»ç½‘ç»œã€æ™ºèƒ½è¯­éŸ³è¯†åˆ«ç›¸å…³ç ”ç©¶ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;å²—ä½èŒè´£ã€å¤§æ¨¡å‹æ–¹å‘ã€‘ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;è´Ÿè´£å¤§è¯­è¨€æ¨¡å‹æ–¹é¢çš„ç®—æ³•å¼€å‘ã€ä¼˜åŒ–ã€åº”ç”¨è½åœ°ã€‚&lt;/li&gt; &#xA; &lt;li&gt;è´Ÿè´£ç›¸åº”AIè§£å†³æ–¹æ¡ˆè®¾è®¡ï¼Œå‚ä¸å…³é”®æŠ€æœ¯ç ”å‘ï¼Œæ”»å…³æŠ€æœ¯éš¾ç‚¹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;è´Ÿè´£è®¾è®¡å’Œå®ç°å¤§è¯­è¨€æ¨¡å‹ç›¸å…³çš„ç®—æ³•å’Œæ¨¡å‹å®ç°ï¼Œç ”ç©¶å¹¶è®¾è®¡æ–°æ˜¯ç®—æ³•å’Œæ¨¡å‹ï¼Œè§£å†³å¤§è¯­è¨€æ¨¡å‹åº”ç”¨é—®é¢˜ã€‚&lt;/li&gt; &#xA; &lt;li&gt;è´Ÿè´£å¼€å‘å’Œä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œè®¾è®¡å¹¶å®ç°å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒç®—æ³•å’Œç­–ç•¥ï¼Œé…ç½®å’Œä¼˜åŒ–è®­ç»ƒçš„è¶…å‚æ•°å’Œè®¡ç®—èµ„æºï¼Œä¿è¯æ¨¡å‹çš„è®­ç»ƒæ•ˆæœå’Œæ•ˆç‡ã€‚&lt;/li&gt; &#xA; &lt;li&gt;è´Ÿè´£æ„å»ºå’Œç®¡ç†å¤§è§„æ¨¡åŒ»ç–—æ–‡æœ¬æ•°æ®é›†ï¼Œç”¨äºæ¨¡å‹é¢„è®­ç»ƒå’Œå¾®è°ƒï¼Œå®Œæˆä¸ç”¨åœºæ™¯ä¸‹çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚&lt;/li&gt; &#xA; &lt;li&gt;è´Ÿè´£è¿›è¡Œå¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°å’ŒéªŒè¯ï¼Œè®¾è®¡è¯„ä¼°æŒ‡æ ‡å’Œå®éªŒ;è®¾è®¡å’Œå®æ–½è¯„ä¼°æŒ‡æ ‡å’Œå®éªŒï¼Œå¯¹è®­ç»ƒå¥½çš„å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€§èƒ½è¯„ä¼°å’Œåˆ†æã€‚è¯†åˆ«æ¨¡å‹çš„å¼±ç‚¹å’Œæ”¹è¿›ç©ºé—´ï¼Œæå‡ºç›¸åº”çš„æ”¹è¿›ç­–ç•¥å’Œæ–¹æ³•ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å‚ä¸é«˜æ ¡ã€ç§‘ç ”ã€åŒ»ç–—æœºæ„ç§‘ç ”åˆä½œï¼ŒååŠ©ç§‘ç ”æˆæœè½åœ°è½¬åŒ–ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;ä»»èŒè¦æ±‚ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;å…·æœ‰æœºå™¨å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€åŒ»å­¦å½±åƒåˆ†æï¼Œæˆ–ç›¸å…³é¢†åŸŸçš„å­¦ä¹ å’Œç ”ç©¶ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æœ‰é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹æˆ–GPTæ¨¡å‹ç­‰ç›¸å…³ç ”ç©¶å¼€å‘ç»éªŒã€‚&lt;/li&gt; &#xA; &lt;li&gt;åœ¨æœºå™¨å­¦ä¹ (ICMLï¼ŒNeurlPSã€ICLRç­‰)ã€è®¡ç®—æœºè§†è§‰(CVPRã€ICCVã€ECCVç­‰)ã€è‡ªç„¶è¯­è¨€å¤„ç†(ACLï¼ŒEMN LPç­‰)å’ŒåŒ»ç–—å½±åƒåˆ†æ(MICCAIã€IPMI)ç­‰é¡¶çº§ä¼šè®®ï¼Œæˆ–è€…é¡¶çº§æœŸåˆŠ(IEEE T-PAMIï¼ŒIEEE TMIã€Medical lmage An alysis)å‘è¡¨è¿‡ç›¸å…³è®ºæ–‡ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å…·æœ‰äººå·¥æ™ºèƒ½ç›¸å…³ä¸“ä¸š(è®¡ç®—æœºè§†è§‰ã€æœºå™¨å­¦ä¹ ã€åŒ»ç–—å›¾åƒåˆ†æç­‰)ç¡•å£«åŠä»¥ä¸Šå­¦ä½ã€‚&lt;/li&gt; &#xA; &lt;li&gt;èƒ½ç†Ÿç»ƒä½¿ç”¨è‹±è¯­ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;åˆä¼—æ±½è½¦ï¼ˆè‡ªåŠ¨é©¾é©¶éƒ¨é—¨ï¼‰ åœ°ç‚¹ï¼šä¸Šæµ·&lt;/p&gt; &#xA;&lt;p&gt;å†…æ¨äººï¼šé¡¹ç›®ç»„æŸleader&lt;/p&gt; &#xA;&lt;p&gt;å²—ä½èŒè´£ã€å›¾åƒæ–¹å‘ã€‘ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;è´Ÿè´£æ™ºèƒ½é©¾é©¶æ£€æµ‹è·Ÿè¸ªåŠç›¸å…³æ–¹å‘çš„ç®—æ³•ç ”å‘å·¥ä½œã€‚&lt;/li&gt; &#xA; &lt;li&gt;å·¥ä½œå†…å®¹åŒ…æ‹¬ä½†ä¸é™äºï¼šåŸºäºå›¾åƒçš„ç‰©ä½“æ£€æµ‹è·Ÿè¸ªï¼Œäº¤é€šæ ‡å¿—/æ ‡çº¿æ£€æµ‹ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;ä»»èŒè¦æ±‚ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ç†Ÿæ‚‰å¸¸ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæœ‰å®é™…çš„æ·±åº¦å­¦ä¹ æ¨¡å‹è®¾è®¡è®­ç»ƒç»éªŒã€‚&lt;/li&gt; &#xA; &lt;li&gt;å…·å¤‡æ‰å®çš„ç¼–ç¨‹èƒ½åŠ›ï¼Œç†Ÿç»ƒæŒæ¡C++ç¼–ç¨‹è¯­è¨€ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;å¤‡æ³¨ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;åˆå­¦è€…ä¹Ÿå¯ä»¥æ ¹æ®å¸‚åœºä¸Šå°±ä¸šéœ€æ±‚ï¼Œå»å­¦ä¹ è‡ªå·±ã€‚&lt;/li&gt; &#xA; &lt;li&gt;èƒ½å†…æ¨ç®€å†çš„ï¼Œä¹Ÿå¯ä»¥è”ç³»æˆ‘ï¼ŒæŠŠå²—ä½èŒè´£ã€ä»»èŒè¦æ±‚å‘ç»™æˆ‘ã€ä½ æ”¶å…¬å¸å†…æ¨å¥–é‡‘ã€taä»¬å°±ä¸šï¼ŒåŒèµ¢ã€‘ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;æä¾›æ¯•è®¾ã€è®ºæ–‡æŒ‡å¯¼æœåŠ¡ï¼Œæœ‰å®Œæ•´çš„è®ºæ–‡æ–‡æ¡£ï¼Œæ•°æ®é›†ã€å’Œä»£ç å¯å¤ç°ï¼Œç¨åŠ ä¿®æ”¹å¯å‘è®ºæ–‡&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;ã€ŠåŸºäºæ·±åº¦å­¦ä¹ çš„ç–²åŠ³é©¾é©¶æ£€æµ‹ç³»ç»Ÿã€‹&lt;/p&gt; &lt;p&gt;å…³é”®å­—ï¼šç–²åŠ³é©¾é©¶æ£€æµ‹ã€äººè„¸å…³é”®ç‚¹æ£€æµ‹ã€é•¿å®½æ¯”ä¼˜åŒ–ç®—æ³•ã€ç›¸æœºæ ‡å®šã€å¤´éƒ¨å§¿æ€ä¼°è®¡&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;æä¾›å•†ä¸šçº§é¡¹ç›®ï¼Œæœ‰æ•°æ®é›†å’Œä»£ç å¯å¤ç°ï¼Œå¯å†™ç®€å†ä¸Š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;è¡Œäººæ£€æµ‹&lt;/li&gt; &#xA; &lt;li&gt;è½¦è¾†æ£€æµ‹&lt;/li&gt; &#xA; &lt;li&gt;é«˜é€Ÿå…¬è·¯ è½¦äººæ‘©æ‰˜è½¦æ£€æµ‹ è·Ÿè¸ª&lt;/li&gt; &#xA; &lt;li&gt;äººè„¸å…³é”®ç‚¹æ£€æµ‹ 106ç‚¹&lt;/li&gt; &#xA; &lt;li&gt;æŠ½çƒŸæ‰“ç”µè¯æ£€æµ‹&lt;/li&gt; &#xA; &lt;li&gt;å® ç‰©è¯†åˆ«&lt;/li&gt; &#xA; &lt;li&gt;æƒ…ç»ª7ç±»åˆ«è¯†åˆ«&lt;/li&gt; &#xA; &lt;li&gt;æ‰‹åŠ¿è¯†åˆ« 18ç§æ‰‹åŠ¿&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;æ›´å¤šé¡¹ç›®ï¼Œæ•¬è¯·æœŸå¾…..........&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;æä¾›ç®€å†æŒ‡å¯¼æœåŠ¡ï¼ŒæŒ‡å¯¼å†™é¡¹ç›®ç»å†ï¼ˆæˆ–è€…è¯´ï¼šå¦‚ä½•å»å­¦ä¹ é¡¹ç›®ï¼‰&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/AccumulateMore/CV/assets/60348867/5b13bb46-b426-4144-a5fd-340f75f668f3&#34; alt=&#34;UVCkSLQLig&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä»¥å‰æˆ‘æ¯•ä¸šæ—¶ï¼ŒæŠ€èƒ½ä¹¦å†™ï¼Œå¯ä»¥å€Ÿé‰´&lt;/p&gt; &#xA;&lt;p&gt;ç”¨äº†å‡ ä¸ªæŠ€å·§ï¼Œåˆ†äº«ç»™å¤§å®¶ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;æŠ€èƒ½åªå†™æŒæ¡äº†XXï¼Œæ²¡æŒæ¡ä¸è¦å†™ï¼ŒæŒæ¡ä¸”æ›´ç†Ÿç»ƒçš„æ”¾å‰é¢ï¼ŒæŒæ¡ä½†ä¸ç†Ÿç»ƒçš„æ”¾åé¢ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å†™æŒæ¡æŸé¡¹æŠ€èƒ½æ—¶ï¼Œåé¢è¦è®ºè¯è‡ªå·±çœŸçš„æŒæ¡äº†ï¼Œæä¾›ç›¸å…³ç»å†ï¼Œæ–¹ä¾¿é¢è¯•å®˜åˆ‡å…¥è¯¢é—®ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å›´ç»•ç®—æ³•å²—å±•å¼€æŠ€èƒ½é˜è¿°ï¼Œä»ç¼–ç¨‹è¯­è¨€ã€åˆ°æ·±åº¦å­¦ä¹ æ¡†æ¶ã€åˆ°å›¾åƒå¤„ç†ç®—æ³•ã€æœåŠ¡å™¨æ•°æ®åº“å­˜å‚¨å›¾åƒç­‰ã€‚&lt;/li&gt; &#xA; &lt;li&gt;åªå†™å²—ä½éœ€è¦çš„æŠ€èƒ½ï¼Œä¸ç®—æ³•å²—ä¸éœ€è¦çš„ç¡¬ä»¶çŸ¥è¯†ã€ç»„ç»‡èƒ½åŠ›ç­‰ä¸è¦å†™ï¼Œè®©ç®€å†æ›´é«˜åŒ¹é…ç®—æ³•å²—ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æŒæ¡ä¸€ç§ç±»åˆ«æŠ€èƒ½ï¼Œåªå ä¸€è¡Œï¼Œä¸è¦æœ‰çš„ä¸¤è¡Œã€æœ‰çš„ä¸€è¡Œï¼Œçœ‹ç€ä¸æ•´é½ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;é¢è¯•å®˜åŠHRä¼šçœ‹ç€æ„Ÿè§‰æ•´é½ã€å¯ä¿¡ã€å²—ä½åŒ¹é…åº¦é«˜ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&#34;â™¥å›å­è—å™¨äºèº«ï¼Œå¾…æ—¶è€ŒåŠ¨â€¦â€¦â™¥&#34;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&#34;â™¥æˆ‘ä»¬è¯»ä¹¦æ˜¯ä¸ºäº†æˆä¸ºæç¯äººå»ç…§äº®é»‘æš—ï¼Œè€Œä¸æ˜¯ä¸ºäº†è‡ªå·±æœ‰ç¯è€Œæ²¾æ²¾è‡ªå–œè¿˜è¦å»å¹ç­åˆ«äººçš„èœ¡çƒ›â™¥&#34;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/autogen</title>
    <updated>2023-11-01T02:03:53Z</updated>
    <id>tag:github.com,2023-11-01:/microsoft/autogen</id>
    <link href="https://github.com/microsoft/autogen" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Enable Next-Gen Large Language Model Applications. Join our Discord: https://discord.gg/pAbnFJrkgZ&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://badge.fury.io/py/pyautogen&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/pyautogen.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/microsoft/autogen/actions/workflows/python-package.yml&#34;&gt;&lt;img src=&#34;https://github.com/microsoft/autogen/actions/workflows/python-package.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/3.8%20%7C%203.9%20%7C%203.10%20%7C%203.11-blue&#34; alt=&#34;Python Version&#34;&gt; &lt;a href=&#34;https://pepy.tech/project/pyautogen&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/pyautogen/week&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/pAbnFJrkgZ&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1153072414184452236?logo=discord&amp;amp;style=flat&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This project is a spinoff from &lt;a href=&#34;https://github.com/microsoft/FLAML&#34;&gt;FLAML&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;AutoGen&lt;/h1&gt; &#xA;&lt;!-- &lt;p align=&#34;center&#34;&gt;&#xA;    &lt;img src=&#34;https://github.com/microsoft/autogen/blob/main/website/static/img/flaml.svg&#34;  width=200&gt;&#xA;    &lt;br&gt;&#xA;&lt;/p&gt; --&gt; &#xA;&lt;p&gt;&lt;span&gt;ğŸ”¥&lt;/span&gt; Heads-up: pyautogen v0.2 will switch to using openai v1.&lt;/p&gt; &#xA;&lt;!--&#xA;&lt;span&gt;ğŸ”¥&lt;/span&gt; FLAML is highlighted in OpenAI&#39;s [cookbook](https://github.com/openai/openai-cookbook#related-resources-from-around-the-web).&#xA;&#xA;&lt;span&gt;ğŸ”¥&lt;/span&gt; [autogen](https://microsoft.github.io/autogen/) is released with support for ChatGPT and GPT-4, based on [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673).&#xA;&#xA;&lt;span&gt;ğŸ”¥&lt;/span&gt; FLAML supports Code-First AutoML &amp; Tuning â€“ Private Preview in [Microsoft Fabric Data Science](https://learn.microsoft.com/en-us/fabric/data-science/). --&gt; &#xA;&lt;h2&gt;What is AutoGen&lt;/h2&gt; &#xA;&lt;p&gt;AutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/microsoft/autogen/raw/main/website/static/img/autogen_agentchat.png&#34; alt=&#34;AutoGen Overview&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;AutoGen enables building next-gen LLM applications based on &lt;strong&gt;multi-agent conversations&lt;/strong&gt; with minimal effort. It simplifies the orchestration, automation, and optimization of a complex LLM workflow. It maximizes the performance of LLM models and overcomes their weaknesses.&lt;/li&gt; &#xA; &lt;li&gt;It supports &lt;strong&gt;diverse conversation patterns&lt;/strong&gt; for complex workflows. With customizable and conversable agents, developers can use AutoGen to build a wide range of conversation patterns concerning conversation autonomy, the number of agents, and agent conversation topology.&lt;/li&gt; &#xA; &lt;li&gt;It provides a collection of working systems with different complexities. These systems span a &lt;strong&gt;wide range of applications&lt;/strong&gt; from various domains and complexities. This demonstrates how AutoGen can easily support diverse conversation patterns.&lt;/li&gt; &#xA; &lt;li&gt;AutoGen provides &lt;strong&gt;enhanced LLM inference&lt;/strong&gt;. It offers easy performance tuning, plus utilities like API unification and caching, and advanced usage patterns, such as error handling, multi-config inference, context programming, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;AutoGen is powered by collaborative &lt;a href=&#34;https://microsoft.github.io/autogen/docs/Research&#34;&gt;research studies&lt;/a&gt; from Microsoft, Penn State University, and the University of Washington.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to start playing is&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Click below to use the Github Codespace&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://codespaces.new/microsoft/autogen?quickstart=1&#34;&gt;&lt;img src=&#34;https://github.com/codespaces/badge.svg?sanitize=true&#34; alt=&#34;Open in GitHub Codespaces&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Copy OAI_CONFIG_LIST_sample to /notebook folder, name to OAI_CONFIG_LIST, and set the correct config.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start playing with the notebooks!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;AutoGen requires &lt;strong&gt;Python version &amp;gt;= 3.8&lt;/strong&gt;. It can be installed from pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install pyautogen&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Minimal dependencies are installed without extra options. You can install extra options based on the feature you need.&lt;/p&gt; &#xA;&lt;!-- For example, use the following to install the dependencies needed by the [`blendsearch`](https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function#blendsearch-economical-hyperparameter-optimization-with-blended-search-strategy) option.&#xA;```bash&#xA;pip install &#34;pyautogen[blendsearch]&#34;&#xA;``` --&gt; &#xA;&lt;p&gt;Find more options in &lt;a href=&#34;https://microsoft.github.io/autogen/docs/Installation&#34;&gt;Installation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!-- Each of the [`notebook examples`](https://github.com/microsoft/autogen/tree/main/notebook) may require a specific option to be installed. --&gt; &#xA;&lt;p&gt;For &lt;a href=&#34;https://microsoft.github.io/autogen/docs/FAQ/#code-execution&#34;&gt;code execution&lt;/a&gt;, we strongly recommend installing the python docker package, and using docker.&lt;/p&gt; &#xA;&lt;p&gt;For LLM inference configurations, check the &lt;a href=&#34;https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints&#34;&gt;FAQs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Multi-Agent Conversation Framework&lt;/h2&gt; &#xA;&lt;p&gt;Autogen enables the next-gen LLM applications with a generic multi-agent conversation framework. It offers customizable and conversable agents that integrate LLMs, tools, and humans. By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code.&lt;/p&gt; &#xA;&lt;p&gt;Features of this use case include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-agent conversations&lt;/strong&gt;: AutoGen agents can communicate with each other to solve tasks. This allows for more complex and sophisticated applications than would be possible with a single LLM.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Customization&lt;/strong&gt;: AutoGen agents can be customized to meet the specific needs of an application. This includes the ability to choose the LLMs to use, the types of human input to allow, and the tools to employ.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Human participation&lt;/strong&gt;: AutoGen seamlessly allows human participation. This means that humans can provide input and feedback to the agents as needed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For &lt;a href=&#34;https://github.com/microsoft/autogen/raw/main/test/twoagent.py&#34;&gt;example&lt;/a&gt;,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from autogen import AssistantAgent, UserProxyAgent, config_list_from_json&#xA;# Load LLM inference endpoints from an env variable or a file&#xA;# See https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints&#xA;# and OAI_CONFIG_LIST_sample&#xA;config_list = config_list_from_json(env_or_file=&#34;OAI_CONFIG_LIST&#34;)&#xA;# You can also set config_list directly as a list, for example, config_list = [{&#39;model&#39;: &#39;gpt-4&#39;, &#39;api_key&#39;: &#39;&amp;lt;your OpenAI API key here&amp;gt;&#39;},]&#xA;assistant = AssistantAgent(&#34;assistant&#34;, llm_config={&#34;config_list&#34;: config_list})&#xA;user_proxy = UserProxyAgent(&#34;user_proxy&#34;, code_execution_config={&#34;work_dir&#34;: &#34;coding&#34;})&#xA;user_proxy.initiate_chat(assistant, message=&#34;Plot a chart of NVDA and TESLA stock price change YTD.&#34;)&#xA;# This initiates an automated chat between the two agents to solve the task&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This example can be run with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python test/twoagent.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After the repo is cloned. The figure below shows an example conversation flow with AutoGen. &lt;img src=&#34;https://github.com/microsoft/autogen/raw/main/website/static/img/chat_example.png&#34; alt=&#34;Agent Chat Example&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please find more &lt;a href=&#34;https://microsoft.github.io/autogen/docs/Examples/AutoGen-AgentChat&#34;&gt;code examples&lt;/a&gt; for this feature.&lt;/p&gt; &#xA;&lt;h2&gt;Enhanced LLM Inferences&lt;/h2&gt; &#xA;&lt;p&gt;Autogen also helps maximize the utility out of the expensive LLMs such as ChatGPT and GPT-4. It offers enhanced LLM inference with powerful functionalities like tuning, caching, error handling, and templating. For example, you can optimize generations by LLM with your own tuning data, success metrics, and budgets.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# perform tuning&#xA;config, analysis = autogen.Completion.tune(&#xA;    data=tune_data,&#xA;    metric=&#34;success&#34;,&#xA;    mode=&#34;max&#34;,&#xA;    eval_func=eval_func,&#xA;    inference_budget=0.05,&#xA;    optimization_budget=3,&#xA;    num_samples=-1,&#xA;)&#xA;# perform inference for a test instance&#xA;response = autogen.Completion.create(context=test_instance, **config)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please find more &lt;a href=&#34;https://microsoft.github.io/autogen/docs/Examples/AutoGen-Inference&#34;&gt;code examples&lt;/a&gt; for this feature.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;You can find detailed documentation about AutoGen &lt;a href=&#34;https://microsoft.github.io/autogen/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In addition, you can find:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://microsoft.github.io/autogen/docs/Research&#34;&gt;Research&lt;/a&gt;, &lt;a href=&#34;https://microsoft.github.io/autogen/blog&#34;&gt;blogposts&lt;/a&gt; around AutoGen, and &lt;a href=&#34;https://github.com/microsoft/autogen/raw/main/TRANSPARENCY_FAQS.md&#34;&gt;Transparency FAQs&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://discord.gg/pAbnFJrkgZ&#34;&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://microsoft.github.io/autogen/docs/Contribute&#34;&gt;Contributing guide&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/orgs/microsoft/projects/989/views/3&#34;&gt;Roadmap&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2308.08155&#34;&gt;AutoGen&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{wu2023autogen,&#xA;      title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework},&#xA;      author={Qingyun Wu and Gagan Bansal and Jieyu Zhang and Yiran Wu and Shaokun Zhang and Erkang Zhu and Beibin Li and Li Jiang and Xiaoyun Zhang and Chi Wang},&#xA;      year={2023},&#xA;      eprint={2308.08155},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.AI}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.04673&#34;&gt;EcoOptiGen&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{wang2023EcoOptiGen,&#xA;    title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},&#xA;    author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},&#xA;    year={2023},&#xA;    booktitle={AutoML&#39;23},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.01337&#34;&gt;MathChat&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{wu2023empirical,&#xA;    title={An Empirical Study on Challenging Math Problem Solving with GPT-4},&#xA;    author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},&#xA;    year={2023},&#xA;    booktitle={ArXiv preprint arXiv:2306.01337},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you are new to GitHub &lt;a href=&#34;https://help.github.com/categories/collaborating-with-issues-and-pull-requests/&#34;&gt;here&lt;/a&gt; is a detailed help source on getting involved with development on GitHub.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information, see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Contributors Wall&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/microsoft/autogen/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=microsoft/autogen&#34;&gt; &lt;/a&gt; &#xA;&lt;h1&gt;Legal Notices&lt;/h1&gt; &#xA;&lt;p&gt;Microsoft and any contributors grant you a license to the Microsoft documentation and other content in this repository under the &lt;a href=&#34;https://creativecommons.org/licenses/by/4.0/legalcode&#34;&gt;Creative Commons Attribution 4.0 International Public License&lt;/a&gt;, see the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/autogen/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file, and grant you a license to any code in the repository under the &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;MIT License&lt;/a&gt;, see the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/autogen/main/LICENSE-CODE&#34;&gt;LICENSE-CODE&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;Microsoft, Windows, Microsoft Azure, and/or other Microsoft products and services referenced in the documentation may be either trademarks or registered trademarks of Microsoft in the United States and/or other countries. The licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks. Microsoft&#39;s general trademark guidelines can be found at &lt;a href=&#34;http://go.microsoft.com/fwlink/?LinkID=254653&#34;&gt;http://go.microsoft.com/fwlink/?LinkID=254653&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Privacy information can be found at &lt;a href=&#34;https://privacy.microsoft.com/en-us/&#34;&gt;https://privacy.microsoft.com/en-us/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Microsoft and any contributors reserve all other rights, whether under their respective copyrights, patents, or trademarks, whether by implication, estoppel, or otherwise.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>iusztinpaul/hands-on-llms</title>
    <updated>2023-11-01T02:03:53Z</updated>
    <id>tag:github.com,2023-11-01:/iusztinpaul/hands-on-llms</id>
    <link href="https://github.com/iusztinpaul/hands-on-llms" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Learn how to engineer your end-to-end LLM ecosystem: training, streaming, and inference pipelines | deploy &amp; automate | work in progress...&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;Hands-on LLMOps&lt;/h2&gt; &#xA; &lt;h1&gt;Train and Deploy a Real-Time Financial Advisor&lt;/h1&gt; &#xA; &lt;i&gt;by &lt;a href=&#34;https://github.com/iusztinpaul&#34;&gt;Paul Iusztin&lt;/a&gt; and &lt;a href=&#34;https://github.com/Paulescu&#34;&gt;Pau Labarta Bajo&lt;/a&gt;&lt;/i&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/#1-building-blocks&#34;&gt;1. Building Blocks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/#2-setup-external-services&#34;&gt;2. Setup External Services&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/#3-install--usage&#34;&gt;3. Install &amp;amp; Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/#4-video-lectures&#34;&gt;4. Video lectures&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;1. Building Blocks&lt;/h2&gt; &#xA;&lt;h3&gt;Training pipeline&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Fine-tune Falcon 7B using our own &lt;a href=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/modules/q_and_a_dataset_generator/&#34;&gt;Q&amp;amp;A generated dataset&lt;/a&gt; containing investing questions and answers based on Alpaca News. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;It seems that 1 GPU is enough if we use &lt;a href=&#34;https://lightning.ai/pages/blog/falcon-a-guide-to-finetune-and-inference/&#34;&gt;Lit-Parrot&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Real-time data pipeline&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Build real-time feature pipeline, that ingests data form Alpaca, computes embeddings, and stores them into a serverless Vector DB.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Inference pipeline&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; REST API for inference, that &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;receives a question (e.g. &#34;Is it a good time to invest in renewable energy?&#34;),&lt;/li&gt; &#xA;   &lt;li&gt;finds the most relevant documents in the VectorDB (aka context)&lt;/li&gt; &#xA;   &lt;li&gt;sends a prompt with question and context to our fine-tuned Falcon and return response.&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/media/architecture.png&#34; alt=&#34;architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;2. Setup External Services&lt;/h2&gt; &#xA;&lt;p&gt;Before diving into the modules, you have to set up a couple of additional tools for the course.&lt;/p&gt; &#xA;&lt;h3&gt;2.1. Alpaca&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;financial news data source&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Follow this &lt;a href=&#34;https://alpaca.markets/docs/market-data/getting-started/&#34;&gt;document&lt;/a&gt;, showing you how to create a FREE account, generate the API Keys, and put them somewhere safe.&lt;/p&gt; &#xA;&lt;h3&gt;2.2. Qdrant&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;vector DB&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Go to &lt;a href=&#34;https://qdrant.tech/?utm_source=thepauls&amp;amp;utm_medium=partner&amp;amp;utm_content=github&#34;&gt;Qdrant&lt;/a&gt;, create a FREE account, and follow &lt;a href=&#34;https://qdrant.tech/documentation/cloud/authentication/?utm_source=thepauls&amp;amp;utm_medium=partner&amp;amp;utm_content=github&#34;&gt;this document&lt;/a&gt; on how to generate the API Keys.&lt;/p&gt; &#xA;&lt;h3&gt;2.3. Comet ML&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;ML platform&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Go to &lt;a href=&#34;https://www.comet.com/signup?utm_source=thepauls&amp;amp;utm_medium=partner&amp;amp;utm_content=github&#34;&gt;Comet ML&lt;/a&gt;, create a FREE account, a project, and an API KEY. We will show you in every module how to add these credentials.&lt;/p&gt; &#xA;&lt;h3&gt;2.4. Beam&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;cloud compute&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Go to &lt;a href=&#34;https://www.beam.cloud?utm_source=thepauls&amp;amp;utm_medium=partner&amp;amp;utm_content=github&#34;&gt;Beam&lt;/a&gt; and follow their quick setup/get started tutorial. You must install their CLI and configure your credentials on your local machine.&lt;/p&gt; &#xA;&lt;p&gt;When using Poetry, we had issues locating the Beam CLI when using the Poetry virtual environment. To fix this, create a symlink using the following command - replace &lt;code&gt;&amp;lt;your-poetry-env-name&amp;gt;&lt;/code&gt; with your Poetry env name:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export POETRY_ENV_NAME=&amp;lt;your-poetry-env-name&amp;gt;&#xA; ln -s /usr/local/bin/beam ~/.cache/pypoetry/virtualenvs/${POETRY_ENV_NAME}/bin/beam&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2.5. AWS&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;cloud compute&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Go to &lt;a href=&#34;https://aws.amazon.com/console/&#34;&gt;AWS&lt;/a&gt;, create an account, and generate a pair of credentials.&lt;/p&gt; &#xA;&lt;p&gt;After, download and install their &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html&#34;&gt;AWS CLI&lt;/a&gt; and &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html&#34;&gt;configure it&lt;/a&gt; with your credentials.&lt;/p&gt; &#xA;&lt;h2&gt;3. Install &amp;amp; Usage&lt;/h2&gt; &#xA;&lt;p&gt;Every module has its dependencies and scripts. In a production setup, every module would have its repository, but in this use case, for learning purposes, we put everything in one place:&lt;/p&gt; &#xA;&lt;p&gt;Thus, check out the README for every module individually to see how to install &amp;amp; use it:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/modules/q_and_a_dataset_generator/&#34;&gt;q_and_a_dataset_generator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/modules/training_pipeline/&#34;&gt;training_pipeline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/modules/streaming_pipeline/&#34;&gt;streaming_pipeline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/modules/financial_bot/&#34;&gt;inference_pipeline&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;3.1 Run Notebooks Server&lt;/h3&gt; &#xA;&lt;p&gt;If you want to run a notebook server inside a virtual environment, follow the next steps.&lt;/p&gt; &#xA;&lt;p&gt;First, expose the virtual environment as a notebook kernel:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m ipykernel install --user --name hands-on-llms --display-name &#34;hands-on-llms&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now run the notebook server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;jupyter notebook notebooks/ --ip 0.0.0.0 --port 8888&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;4. Video lectures&lt;/h2&gt; &#xA;&lt;h3&gt;4.0 Intro to the course&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.youtube.com/watch?v=l4HTEf0_s70&#34;&gt; &lt;p&gt;Click here to watch the video ğŸ¬&lt;/p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/media/youtube_thumbnails/00_intro.png&#34; alt=&#34;Intro to the course&#34; style=&#34;width:75%;&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;4.1 Fine-tuning our open-source LLM (overview)&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.youtube.com/watch?v=HcxwOYMmj40&#34;&gt; &lt;p&gt;Click here to watch the video ğŸ¬&lt;/p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/media/youtube_thumbnails/01_fine_tuning_pipeline_overview.png&#34; alt=&#34;Intro to the course&#34; style=&#34;width:75%;&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;4.2 Fine-tuning our open-source LLM (Hands-on!)&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.youtube.com/watch?v=RS96R0dH0uE&#34;&gt; &lt;p&gt;Click here to watch the video ğŸ¬&lt;/p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iusztinpaul/hands-on-llms/main/media/youtube_thumbnails/02_fine_tuning_pipeline_hands_on.png&#34; alt=&#34;Hands-on Fine Tuning an LLM&#34; style=&#34;width:75%;&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
</feed>