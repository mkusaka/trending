<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-10-06T01:44:33Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>SharifiZarchi/Introduction_to_Machine_Learning</title>
    <updated>2024-10-06T01:44:33Z</updated>
    <id>tag:github.com,2024-10-06:/SharifiZarchi/Introduction_to_Machine_Learning</id>
    <link href="https://github.com/SharifiZarchi/Introduction_to_Machine_Learning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Machine Learning Course, Sharif University of Technology&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Machine Learning Course&lt;/h1&gt; &#xA;&lt;h2&gt;Computer Engineering Department, Sharif University of Technology&lt;/h2&gt; &#xA;&lt;p&gt;You can access the slides, Jupyter notebooks, and exercises for the &#34;Introduction to Machine Learning&#34; course for the Fall 2024 (1403) semester. Please note that the content is still under construction and will be updated throughout the semester.&lt;/p&gt; &#xA;&lt;p&gt;Course materials from previous semesters are available in the &#34;Previous Semesters&#34; section.&lt;/p&gt; &#xA;&lt;p&gt;Class videos and other information are available at: &lt;a href=&#34;http://www.SharifML.ir&#34;&gt;www.SharifML.ir&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>tatsath/fin-ml</title>
    <updated>2024-10-06T01:44:33Z</updated>
    <id>tag:github.com,2024-10-06:/tatsath/fin-ml</id>
    <link href="https://github.com/tatsath/fin-ml" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This github repository of &#34;Machine Learning and Data Science Blueprints for Finance&#34;. Please star.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Machine Learning and Data Science Blueprints for Finance - Jupyter Notebooks&lt;/h1&gt; &#xA;&lt;p&gt;This github repository contains the code to the case studies in the O&#39;Reilly book &lt;em&gt;Machine Learning and Data Science Blueprints for Finance&lt;/em&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://images-na.ssl-images-amazon.com/images/I/51EhsIZvh7L._SX379_BO1,204,203,200_.jpg&#34; title=&#34;book&#34; width=&#34;150&#34;&gt; &#xA;&lt;p&gt;Simply open the &lt;a href=&#34;http://jupyter.org/&#34;&gt;Jupyter&lt;/a&gt; notebooks you are interested in by cloning this repository and running Jupyter locally. This option lets you play around with the code. In this case, follow the installation instructions below.&lt;/p&gt; &#xA;&lt;h3&gt;Want to play with these notebooks online without having to install anything?&lt;/h3&gt; &#xA;&lt;p&gt;Use any of the following services.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: Please be aware that these services provide temporary environmets: anything you do will be deleted after a while, so make sure you download any data you care about.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Recommended&lt;/strong&gt;: Open it in &lt;a href=&#34;https://mybinder.org/v2/gh/tatsath/fin-ml/master&#34;&gt;Binder&lt;/a&gt;: &lt;a href=&#34;https://mybinder.org/v2/gh/tatsath/fin-ml/master&#34;&gt;&lt;img src=&#34;https://matthiasbussonnier.com/posts/img/binder_logo_128x128.png&#34; width=&#34;90&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;em&gt;Note&lt;/em&gt;: Binder is a hosting service and the directories of the book will open exactly like they open on your local machine with no installation required. The connection between different files within the folder will work seamlessly. Most of the time, Binder starts up quickly and works great, but when the github repository of this book is updated, Binder creates a new environment from scratch, and this can take quite some time. Also, some of the case study, specially that require more cache data might be slow.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open this repository in &lt;a href=&#34;https://colab.research.google.com/github/tatsath/fin-ml/blob/master&#34;&gt;Colaboratory&lt;/a&gt;: &lt;a href=&#34;https://colab.research.google.com/github/tatsath/fin-ml/blob/master&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/img/colab_favicon.ico&#34; width=&#34;90&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;em&gt;Note&lt;/em&gt;: Google colab supports GPU and can be quite fast. However, the linkages to data file located in the folders of the git directory may not work. Upload the data files seperately while running the jupyter notebooks on google colab. For loading the data files on google colab, you can replace the local directory path with the github path. For example, for the data of case study 1 of chapter 7 &lt;em&gt;dataset = read_csv(&#39;Dow_adjcloses.csv&#39;)&lt;/em&gt; in the code can be replace with &lt;em&gt;dataset = read_csv(&#39;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%207%20-%20Unsup.%20Learning%20-%20Dimensionality%20Reduction/CaseStudy1%20-%20Portfolio%20Management%20-%20Eigen%20Portfolio/Dow_adjcloses.csv&#34;&gt;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%207%20-%20Unsup.%20Learning%20-%20Dimensionality%20Reduction/CaseStudy1%20-%20Portfolio%20Management%20-%20Eigen%20Portfolio/Dow_adjcloses.csv&lt;/a&gt;&#39;)&lt;/em&gt; for it to work on google colab.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Just want to quickly look at some notebooks, without executing any code?&lt;/h3&gt; &#xA;&lt;p&gt;Browse this repository using &lt;a href=&#34;https://nbviewer.jupyter.org/github/tatsath/fin-ml/blob/master/index.ipynb&#34;&gt;jupyter.org&#39;s notebook viewer&lt;/a&gt;: &lt;a href=&#34;https://nbviewer.jupyter.org/github/tatsath/fin-ml/blob/master/index.ipynb&#34;&gt;&lt;img src=&#34;https://jupyter.org/assets/nav_logo.svg?sanitize=true&#34; width=&#34;150&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Want to install this project on your own machine?&lt;/h3&gt; &#xA;&lt;p&gt;Start by installing &lt;a href=&#34;https://www.anaconda.com/distribution/&#34;&gt;Anaconda&lt;/a&gt; (or &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;Miniconda&lt;/a&gt;), &lt;a href=&#34;https://git-scm.com/downloads&#34;&gt;git&lt;/a&gt;, and if you have a TensorFlow-compatible GPU, install the &lt;a href=&#34;https://www.nvidia.com/Download/index.aspx&#34;&gt;GPU driver&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Next, clone this project by opening a terminal and typing the following commands (do not type the first &lt;code&gt;$&lt;/code&gt; signs on each line, they just indicate that these are terminal commands):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd $HOME  # or any other development directory you prefer&#xA;$ git clone https://github.com/tatsath/fin-ml.git&#xA;$ cd fin-ml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you do not want to install git, you can instead download &lt;a href=&#34;https://github.com/tatsath/fin-ml/archive/master.zip&#34;&gt;master.zip&lt;/a&gt;, unzip it, rename the resulting directory to &lt;code&gt;fin-ml&lt;/code&gt; and move it to your development directory.&lt;/p&gt; &#xA;&lt;p&gt;If you are familiar with Python and you know how to install Python libraries, go ahead and install the libraries listed in &lt;code&gt;requirements.txt&lt;/code&gt; and jump to the &lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/#starting-jupyter&#34;&gt;Starting Jupyter&lt;/a&gt; section. If you need detailed instructions, please read on. We would encourage you to stick to the version of the packages in the &#39;requirement.txt&#39; file.&lt;/p&gt; &#xA;&lt;h2&gt;Python &amp;amp; Required Libraries&lt;/h2&gt; &#xA;&lt;p&gt;Of course, you obviously need Python. Python 3 is already preinstalled on many systems nowadays. You can check which version you have by typing the following command (you may need to replace &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 --version  # for Python 3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Any Python 3 version should be fine, preferably 3.5 or above. If you don&#39;t have Python 3, we recommend installing it. To do so, you have several options: on Windows or MacOSX, you can just download it from &lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;python.org&lt;/a&gt;. On MacOSX, you can alternatively use &lt;a href=&#34;https://www.macports.org/&#34;&gt;MacPorts&lt;/a&gt; or &lt;a href=&#34;https://brew.sh/&#34;&gt;Homebrew&lt;/a&gt;. If you are using Python 3.6 on MacOSX, you need to run the following command to install the &lt;code&gt;certifi&lt;/code&gt; package of certificates because Python 3.6 on MacOSX has no certificates to validate SSL connections (see this &lt;a href=&#34;https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error&#34;&gt;StackOverflow question&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ /Applications/Python\ 3.6/Install\ Certificates.command&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On Linux, unless you know what you are doing, you should use your system&#39;s packaging system. For example, on Debian or Ubuntu, type:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get update&#xA;$ sudo apt-get install python3 python3-pip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Installing Anaconda&lt;/h2&gt; &#xA;&lt;p&gt;After installing Python, we recommend installing &lt;a href=&#34;https://docs.anaconda.com/anaconda/install/&#34;&gt;Anaconda&lt;/a&gt;. This is a package that includes both Python and many scientific libraries. You should prefer the Python 3 version.&lt;/p&gt; &#xA;&lt;h2&gt;Using pip&lt;/h2&gt; &#xA;&lt;p&gt;Installing Anaconda, should install most of the commonly used libraries in the case studies. Given that there might be changes to the Anaconda package and some libraries might be out of date, it is a good idea to learn how to install packages in python using pip.&lt;/p&gt; &#xA;&lt;h3&gt;Installing pip&lt;/h3&gt; &#xA;&lt;p&gt;These are the commands you need to type in a terminal if you want to use pip to install. Note: in all the following commands, if you chose to use Python 2 rather than Python 3, you must replace &lt;code&gt;pip3&lt;/code&gt; with &lt;code&gt;pip&lt;/code&gt;, and &lt;code&gt;python3&lt;/code&gt; with &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;First you need to make sure you have the latest version of pip installed. If you are on the latest version of Python, pip should already be installed. You can check using the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip -V&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you do not have pip install, you can run the following command on Linux&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install python3-pip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or download &lt;a href=&#34;https://bootstrap.pypa.io/get-pip.py&#34;&gt;get-pip.py&lt;/a&gt; and install it on Windows using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 get-pip.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have &lt;code&gt;pip&lt;/code&gt; already installed, it might be a good idea to upgrade it.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade pip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;--user&lt;/code&gt; option will install the latest version of pip only for the current user. If you prefer to install it system wide (i.e. for all users), you must have administrator rights (e.g. use &lt;code&gt;sudo python3&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt; on Linux), and you should remove the &lt;code&gt;--user&lt;/code&gt; option. The same is true of the command below that uses the &lt;code&gt;--user&lt;/code&gt; option.&lt;/p&gt; &#xA;&lt;h3&gt;Creating an environment (optional)&lt;/h3&gt; &#xA;&lt;p&gt;Next, you can optionally create an isolated environment. This is recommended as it makes it possible to have a different environment for each project (e.g. one for this project), with potentially very different libraries, and different versions:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user --upgrade virtualenv&#xA;$ python3 -m virtualenv -p `which python3` env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This creates a new directory called &lt;code&gt;env&lt;/code&gt; in the current directory, containing an isolated Python environment based on Python 3. If you installed multiple versions of Python 3 on your system, you can replace &lt;code&gt;`which python3`&lt;/code&gt; with the path to the Python executable you prefer to use.&lt;/p&gt; &#xA;&lt;p&gt;Now you must activate this environment. You will need to run this command every time you want to use this environment.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ source ./env/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On Windows, the command is slightly different:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ .\env\Scripts\activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Installing Python packages&lt;/h3&gt; &#xA;&lt;p&gt;Next, use pip to install the required python packages. If you are not using virtualenv, you should add the &lt;code&gt;--user&lt;/code&gt; option (alternatively you could install the libraries system-wide, but this will probably require administrator rights, e.g. using &lt;code&gt;sudo pip3&lt;/code&gt; instead of &lt;code&gt;pip3&lt;/code&gt; on Linux).&lt;/p&gt; &#xA;&lt;p&gt;The following command is used to install python package with a particular version.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip3 install &amp;lt;PACKAGE&amp;gt;==&amp;lt;VERSION&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to try to install a list of packages from a file. You can use the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --upgrade -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Great! You&#39;re all set, you just need to start Jupyter now.&lt;/p&gt; &#xA;&lt;h2&gt;Installing Package models&lt;/h2&gt; &#xA;&lt;p&gt;For the chapter on Natural Language Processing. We will be using the &lt;code&gt;spaCy&lt;/code&gt; python package. Installing &lt;code&gt;spaCy&lt;/code&gt; does not install the language models used. In order to do that, we need to open up python and install it ourselves using the following commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python -m spacy download en_core_web_lg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Starting Jupyter&lt;/h2&gt; &#xA;&lt;p&gt;Okay! You can now start Jupyter, simply type:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ jupyter notebook&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This should open up your browser, and you should see Jupyter&#39;s tree view, with the contents of the current directory. If your browser does not open automatically, visit &lt;a href=&#34;http://127.0.0.1:8888/tree&#34;&gt;127.0.0.1:8888&lt;/a&gt;. Click on &lt;code&gt;index.ipynb&lt;/code&gt; to get started!&lt;/p&gt; &#xA;&lt;h2&gt;Installing Libraries in Jupyter using pip&lt;/h2&gt; &#xA;&lt;p&gt;If you install a library and are not able to import it on the jupyter notebook. You might be installing them on the system python environment. We can use Jupyter notebooks to install packages using the ! symbol at the start. THe following libraries are the ones that are required outside the latest Anaconda package as of now.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ !pip install spacy&#xA;$ !pip install pandas-datareader&#xA;$ !pip install keras&#xA;$ !pip install dash&#xA;$ !pip install dash&#xA;$ !pip install dash_daq&#xA;$ !pip install quandl&#xA;$ !pip install cvxopt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Want to look at the individual case studies or jupyter notebooks?&lt;/h2&gt; &#xA;&lt;h3&gt;Notebooks by Application in Finance&lt;/h3&gt; &#xA;&lt;h4&gt;1. Trading Strategies and Algorithmic Trading&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%206%20-%20Sup.%20Learning%20-%20Classification%20models/CaseStudy3%20-%20Bitcoin%20Trading%20Strategy/BitcoinTradingStrategy.ipynb&#34;&gt;Bitcoin Trading Strategy using classification&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%207%20-%20Unsup.%20Learning%20-%20Dimensionality%20Reduction/CaseStudy3%20-Bitcoin%20Trading%20-%20Enhancing%20Speed%20and%20accuracy/BitcoinTradingEnhancingSpeedAccuracy.ipynb&#34;&gt;Bitcoin Trading - Enhancing Speed and Accuracy using dimensionality reduction &lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%208%20-%20Unsup.%20Learning%20-%20Clustering/Case%20Study1%20-%20Clustering%20for%20Pairs%20Trading/ClusteringForPairsTrading.ipynb&#34;&gt;Clustering for Pairs Trading Strategy&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%209%20-%20Reinforcement%20Learning/Case%20Study%201%20-%20Reinforcement%20Learning%20based%20Trading%20Strategy/ReinforcementLearningBasedTradingStrategy.ipynb&#34;&gt;Reinforcement Learning based Trading Strategy&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%2010%20-%20Natural%20Language%20Processing/Case%20Study%201%20-%20NLP%20and%20Sentiments%20Analysis%20based%20Trading%20Strategy/NLPandSentimentAnalysisBasedTradingStrategy.ipynb&#34;&gt;NLP and Sentiments Analysis based Trading Strategy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;2. Portfolio Management and robo-advisors&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Case%20Study%203%20-%20Investor%20Risk%20Tolerance%20and%20Robo-advisors/InvestorRiskToleranceAndRoboAdvisor.ipynb&#34;&gt;Investor Risk Tolerance and Robo-advisors - using supervised regression&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Case%20Study%203%20-%20Investor%20Risk%20Tolerance%20and%20Robo-advisors/Sample-Robo%20Advisor.ipynb&#34;&gt;Robo-Advisor Dashboard-powdered by ML&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%207%20-%20Unsup.%20Learning%20-%20Dimensionality%20Reduction/CaseStudy1%20-%20Portfolio%20Management%20-%20Eigen%20Portfolio/PortfolioManagementEigen%20Portfolio.ipynb&#34;&gt;Portfolio Management - Eigen Portfolio - using dimensionality reduction&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%208%20-%20Unsup.%20Learning%20-%20Clustering/Case%20Study2%20-%20Portfolio%20Management%20-%20%20Clustering%20Investors/PortfolioManagementClusteringInvestors.ipynb&#34;&gt;Portfolio Management - Clustering Investors&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%208%20-%20Unsup.%20Learning%20-%20Clustering/Case%20Study3%20-%20Hierarchial%20Risk%20Parity/HierarchicalRiskParity.ipynb&#34;&gt;Hierarchial Risk Parity - using clustering&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%209%20-%20Reinforcement%20Learning/Case%20Study%203%20-%20Portfolio%20Allocation/PortfolioAllocation.ipynb&#34;&gt;Portfolio Allocation - using reinforcement learning&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;3. Derivatives Pricing and Hedging&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Case%20Study%202%20-%20Derivatives%20Pricing/DerivativesPricing.ipynb&#34;&gt;Derivative Pricing - using supervised regression&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%209%20-%20Reinforcement%20Learning/Case%20Study%202%20-%20Derivatives%20Hedging/DerivativesHedging.ipynb&#34;&gt;Derivatives Hedging - using reinforcement learning&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;4. Asset Price Prediction&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Case%20Study%201%20-%20Stock%20Price%20Prediction/StockPricePrediction.ipynb&#34;&gt;Stock Price Prediction - using regression and time series&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Case%20Study%204%20-%20Yield%20Curve%20Prediction/%20YieldCurvePrediction.ipynb&#34;&gt;Yield Curve Prediction - using regression and time series&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%207%20-%20Unsup.%20Learning%20-%20Dimensionality%20Reduction/CaseStudy2%20-%20Yield%20Curve%20Construction%20and%20Interest%20Rate%20Modeling/YieldCurveConstruction.ipynb&#34;&gt;Yield Curve Construction and Interest Rate Modeling - using dimensionality reduction&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;5. Fraud Detection&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%206%20-%20Sup.%20Learning%20-%20Classification%20models/CaseStudy1%20-%20Fraud%20Detection/FraudDetection.ipynb&#34;&gt;Fraud Detection - using classification&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;6. Loan Default probability prediction&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%206%20-%20Sup.%20Learning%20-%20Classification%20models/CaseStudy2%20-%20Loan%20Default%20Probability/LoanDefaultProbability.ipynb&#34;&gt;Loan Default Probability - using classification&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;7. Chatbot and automation&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%2010%20-%20Natural%20Language%20Processing/Case%20Study%202%20-%20Digital%20Assistant-chat-bots/DigitalAssistant-chat-bot.ipynb&#34;&gt;Digital Assistant-chat-bots - using NLP&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%2010%20-%20Natural%20Language%20Processing/Case%20Study%202%20-%20Digital%20Assistant-chat-bots/Case%20Study%203%20-%20Documents%20Summarization/DocumentSummarization.ipynb&#34;&gt;Documents Summarization - using NLP&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Notebooks by Machine Learning Types&lt;/h3&gt; &#xA;&lt;h4&gt;1. Supervised Learning- Regression and Time series Models&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Case%20Study%201%20-%20Stock%20Price%20Prediction/StockPricePrediction.ipynb&#34;&gt;Stock Price Prediction &lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Case%20Study%202%20-%20Derivatives%20Pricing/DerivativesPricing.ipynb&#34;&gt;Derivative Pricing&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Case%20Study%203%20-%20Investor%20Risk%20Tolerance%20and%20Robo-advisors/InvestorRiskToleranceAndRoboAdvisor.ipynb&#34;&gt;Investor Risk Tolerance and Robo-advisors&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Case%20Study%204%20-%20Yield%20Curve%20Prediction/%20YieldCurvePrediction.ipynb&#34;&gt;Yield Curve Prediction&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;2. Supervised Learning- Classification Models&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%206%20-%20Sup.%20Learning%20-%20Classification%20models/CaseStudy1%20-%20Fraud%20Detection/FraudDetection.ipynb&#34;&gt;Fraud Detection&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%206%20-%20Sup.%20Learning%20-%20Classification%20models/CaseStudy2%20-%20Loan%20Default%20Probability/LoanDefaultProbability.ipynb&#34;&gt;Loan Default Probability&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%206%20-%20Sup.%20Learning%20-%20Classification%20models/CaseStudy3%20-%20Bitcoin%20Trading%20Strategy/BitcoinTradingStrategy.ipynb&#34;&gt;Bitcoin Trading Strategy&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h4&gt;3. Unsupervised Learning- Dimensionality Reduction Models&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%207%20-%20Unsup.%20Learning%20-%20Dimensionality%20Reduction/CaseStudy1%20-%20Portfolio%20Management%20-%20Eigen%20Portfolio/PortfolioManagementEigen%20Portfolio.ipynb&#34;&gt;Portfolio Management - Eigen Portfolio&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%207%20-%20Unsup.%20Learning%20-%20Dimensionality%20Reduction/CaseStudy2%20-%20Yield%20Curve%20Construction%20and%20Interest%20Rate%20Modeling/YieldCurveConstruction.ipynb&#34;&gt;Yield Curve Construction and Interest Rate Modeling&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%207%20-%20Unsup.%20Learning%20-%20Dimensionality%20Reduction/CaseStudy3%20-Bitcoin%20Trading%20-%20Enhancing%20Speed%20and%20accuracy/BitcoinTradingEnhancingSpeedAccuracy.ipynb&#34;&gt;Bitcoin Trading - Enhancing Speed and accuracy&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h4&gt;4. Unsupervised Learning- Clustering&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%208%20-%20Unsup.%20Learning%20-%20Clustering/Case%20Study1%20-%20Clustering%20for%20Pairs%20Trading/ClusteringForPairsTrading.ipynb&#34;&gt;Clustering for Pairs Trading&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%208%20-%20Unsup.%20Learning%20-%20Clustering/Case%20Study2%20-%20Portfolio%20Management%20-%20%20Clustering%20Investors/PortfolioManagementClusteringInvestors.ipynb&#34;&gt;Portfolio Management - Clustering Investors&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%208%20-%20Unsup.%20Learning%20-%20Clustering/Case%20Study3%20-%20Hierarchial%20Risk%20Parity/HierarchicalRiskParity.ipynb&#34;&gt;Hierarchial Risk Parity&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h4&gt;5. Reinforcement Learning&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%209%20-%20Reinforcement%20Learning/Case%20Study%201%20-%20Reinforcement%20Learning%20based%20Trading%20Strategy/ReinforcementLearningBasedTradingStrategy.ipynb&#34;&gt;Reinforcement Learning based Trading Strategy&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%209%20-%20Reinforcement%20Learning/Case%20Study%202%20-%20Derivatives%20Hedging/DerivativesHedging.ipynb&#34;&gt;Derivatives Hedging&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%209%20-%20Reinforcement%20Learning/Case%20Study%203%20-%20Portfolio%20Allocation/PortfolioAllocation.ipynb&#34;&gt;Portfolio Allocation&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h4&gt;6. Natural Language Processing&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%2010%20-%20Natural%20Language%20Processing/Case%20Study%201%20-%20NLP%20and%20Sentiments%20Analysis%20based%20Trading%20Strategy/NLPandSentimentAnalysisBasedTradingStrategy.ipynb&#34;&gt;NLP and Sentiments Analysis based Trading Strategy&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%2010%20-%20Natural%20Language%20Processing/Case%20Study%202%20-%20Digital%20Assistant-chat-bots/DigitalAssistant-chat-bot.ipynb&#34;&gt;Digital Assistant-chat-bots&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%2010%20-%20Natural%20Language%20Processing/Case%20Study%202%20-%20Digital%20Assistant-chat-bots/Case%20Study%203%20-%20Documents%20Summarization/DocumentSummarization.ipynbb&#34;&gt;Documents Summarization&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Master Template for different machine learning type&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%205%20-%20Sup.%20Learning%20-%20Regression%20and%20Time%20Series%20models/Regression-MasterTemplate.ipynb&#34;&gt;Supervised learning - Regression and Time series&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%206%20-%20Sup.%20Learning%20-%20Classification%20models/Classification-MasterTemplate.ipynb&#34;&gt;Supervised learning - Classification&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%207%20-%20Unsup.%20Learning%20-%20Dimensionality%20Reduction/DimensionalityReduction-MasterTemplate.ipynb&#34;&gt;Unsupervised learning - Dimensionality Reduction &lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%208%20-%20Unsup.%20Learning%20-%20Clustering/Clustering-MasterTemplate.ipynb&#34;&gt;Unsupervised learning - Clustering&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%2010%20-%20Natural%20Language%20Processing/NLP-MasterTemplate.ipynb&#34;&gt;Natural Language Processing&lt;/a&gt;&lt;br&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>meta-llama/llama-recipes</title>
    <updated>2024-10-06T01:44:33Z</updated>
    <id>tag:github.com,2024-10-06:/meta-llama/llama-recipes</id>
    <link href="https://github.com/meta-llama/llama-recipes" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Scripts for fine-tuning Meta Llama with composable FSDP &amp; PEFT methods to cover single/multi-node GPUs. Supports default &amp; custom datasets for applications such as summarization and Q&amp;A. Supporting a number of candid inference solutions such as HF TGI, VLLM for local or cloud deployment. Demo apps to showcase Meta Llama for WhatsApp &amp; Messenger.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Llama Recipes: Examples to get started using the Llama models from Meta&lt;/h1&gt; &#xA;&lt;!-- markdown-link-check-disable --&gt; &#xA;&lt;p&gt;The &#39;llama-recipes&#39; repository is a companion to the &lt;a href=&#34;https://github.com/meta-llama/llama-models&#34;&gt;Meta Llama&lt;/a&gt; models. We support the latest version, &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_2/MODEL_CARD_VISION.md&#34;&gt;Llama 3.2 Vision&lt;/a&gt; and &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_2/MODEL_CARD.md&#34;&gt;Llama 3.2 Text&lt;/a&gt;, in this repository. This repository contains example scripts and notebooks to get started with the models in a variety of use-cases, including fine-tuning for domain adaptation and building LLM-based applications with Llama and other tools in the LLM ecosystem. The examples here use Llama locally, in the cloud, and on-prem.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Get started with Llama 3.2 with these new recipes:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-recipes/raw/main/recipes/quickstart/finetuning/finetune_vision_model.md&#34;&gt;Finetune Llama 3.2 Vision&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-recipes/raw/main/recipes/quickstart/inference/local_inference/README.md#multimodal-inference&#34;&gt;Multimodal Inference with Llama 3.2 Vision&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-recipes/raw/main/recipes/responsible_ai/llama_guard/llama_guard_text_and_vision_inference.ipynb&#34;&gt;Inference on Llama Guard 1B + Multimodal inference on Llama Guard 11B-Vision&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!-- markdown-link-check-enable --&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Llama 3.2 follows the same prompt template as Llama 3.1, with a new special token &lt;code&gt;&amp;lt;|image|&amp;gt;&lt;/code&gt; representing the input image for the multimodal models.&lt;/p&gt; &#xA; &lt;p&gt;More details on the prompt templates for image reasoning, tool-calling and code interpreter can be found &lt;a href=&#34;https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_2&#34;&gt;on the documentation website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#llama-recipes-examples-to-get-started-using-the-llama-models-from-meta&#34;&gt;Llama Recipes: Examples to get started using the Llama models from Meta&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#prerequisites&#34;&gt;Prerequisites&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#pytorch-nightlies&#34;&gt;PyTorch Nightlies&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#installing&#34;&gt;Installing&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#install-with-pip&#34;&gt;Install with pip&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#install-with-optional-dependencies&#34;&gt;Install with optional dependencies&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#install-from-source&#34;&gt;Install from source&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#getting-the-llama-models&#34;&gt;Getting the Llama models&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#model-conversion-to-hugging-face&#34;&gt;Model conversion to Hugging Face&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#repository-organization&#34;&gt;Repository Organization&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#recipes&#34;&gt;&lt;code&gt;recipes/&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#src&#34;&gt;&lt;code&gt;src/&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#supported-features&#34;&gt;Supported Features&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.&lt;/p&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;h4&gt;PyTorch Nightlies&lt;/h4&gt; &#xA;&lt;p&gt;If you want to use PyTorch nightlies instead of the stable release, go to &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;this guide&lt;/a&gt; to retrieve the right &lt;code&gt;--extra-index-url URL&lt;/code&gt; parameter for the &lt;code&gt;pip install&lt;/code&gt; commands on your platform.&lt;/p&gt; &#xA;&lt;h3&gt;Installing&lt;/h3&gt; &#xA;&lt;p&gt;Llama-recipes provides a pip distribution for easy install and usage in other projects. Alternatively, it can be installed from source.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Ensure you use the correct CUDA version (from &lt;code&gt;nvidia-smi&lt;/code&gt;) when installing the PyTorch wheels. Here we are using 11.8 as &lt;code&gt;cu118&lt;/code&gt;. H100 GPUs work better with CUDA &amp;gt;12.0&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Install with pip&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install llama-recipes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Install with optional dependencies&lt;/h4&gt; &#xA;&lt;p&gt;Llama-recipes offers the installation of optional packages. There are three optional dependency groups. To run the unit tests we can install the required dependencies with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install llama-recipes[tests]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For the vLLM example we need additional requirements that can be installed with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install llama-recipes[vllm]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use the sensitive topics safety checker install with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install llama-recipes[auditnlg]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some recipes require the presence of langchain. To install the packages follow the recipe description or install with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install llama-recipes[langchain]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Optional dependencies can also be combines with [option1,option2].&lt;/p&gt; &#xA;&lt;h4&gt;Install from source&lt;/h4&gt; &#xA;&lt;p&gt;To install from source e.g. for development use these commands. We&#39;re using hatchling as our build backend which requires an up-to-date pip as well as setuptools package.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:meta-llama/llama-recipes.git&#xA;cd llama-recipes&#xA;pip install -U pip setuptools&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For development and contributing to llama-recipes please install all optional dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:meta-llama/llama-recipes.git&#xA;cd llama-recipes&#xA;pip install -U pip setuptools&#xA;pip install -e .[tests,auditnlg,vllm]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Getting the Llama models&lt;/h3&gt; &#xA;&lt;p&gt;You can find Llama models on Hugging Face hub &lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;here&lt;/a&gt;, &lt;strong&gt;where models with &lt;code&gt;hf&lt;/code&gt; in the name are already converted to Hugging Face checkpoints so no further conversion is needed&lt;/strong&gt;. The conversion step below is only for original model weights from Meta that are hosted on Hugging Face model hub as well.&lt;/p&gt; &#xA;&lt;h4&gt;Model conversion to Hugging Face&lt;/h4&gt; &#xA;&lt;p&gt;If you have the model checkpoints downloaded from the Meta website, you can convert it to the Hugging Face format with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## Install Hugging Face Transformers from source&#xA;pip freeze | grep transformers ## verify it is version 4.45.0 or higher&#xA;&#xA;git clone git@github.com:huggingface/transformers.git&#xA;cd transformers&#xA;pip install protobuf&#xA;python src/transformers/models/llama/convert_llama_weights_to_hf.py \&#xA;   --input_dir /path/to/downloaded/llama/weights --model_size 3B --output_dir /output/path&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Repository Organization&lt;/h2&gt; &#xA;&lt;p&gt;Most of the code dealing with Llama usage is organized across 2 main folders: &lt;code&gt;recipes/&lt;/code&gt; and &lt;code&gt;src/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;recipes/&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Contains examples are organized in folders by topic:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Subfolder&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/quickstart&#34;&gt;quickstart&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The &#34;Hello World&#34; of using Llama, start here if you are new to using Llama.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/use_cases&#34;&gt;use_cases&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts showing common applications of Meta Llama3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/3p_integrations&#34;&gt;3p_integrations&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Partner owned folder showing common applications of Meta Llama3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/responsible_ai&#34;&gt;responsible_ai&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts to use PurpleLlama for safeguarding model outputs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/experimental&#34;&gt;experimental&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Meta Llama implementations of experimental LLM techniques&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;code&gt;src/&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Contains modules which support the example recipes:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Subfolder&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/configs/&#34;&gt;configs&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Contains the configuration files for PEFT methods, FSDP, Datasets, Weights &amp;amp; Biases experiment tracking.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/datasets/&#34;&gt;datasets&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Contains individual scripts for each dataset to download and process. Note&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/inference/&#34;&gt;inference&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Includes modules for inference for the fine-tuned models.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/model_checkpointing/&#34;&gt;model_checkpointing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Contains FSDP checkpoint handlers.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/policies/&#34;&gt;policies&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Contains FSDP scripts to provide different policies, such as mixed precision, transformer wrapping policy and activation checkpointing along with any precision optimizer (used for running FSDP with pure bf16 mode).&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/utils/&#34;&gt;utils&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Utility files for:&lt;br&gt; - &lt;code&gt;train_utils.py&lt;/code&gt; provides training/eval loop and more train utils.&lt;br&gt; - &lt;code&gt;dataset_utils.py&lt;/code&gt; to get preprocessed datasets.&lt;br&gt; - &lt;code&gt;config_utils.py&lt;/code&gt; to override the configs received from CLI.&lt;br&gt; - &lt;code&gt;fsdp_utils.py&lt;/code&gt; provides FSDP wrapping policy for PEFT methods.&lt;br&gt; - &lt;code&gt;memory_utils.py&lt;/code&gt; context manager to track different memory stats in train loop.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Supported Features&lt;/h2&gt; &#xA;&lt;p&gt;The recipes and modules in this repository support the following features:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HF support for inference&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HF support for finetuning&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PEFT&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Deferred initialization ( meta init)&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Low CPU mode for multi GPU&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mixed precision&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Single node quantization&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Flash attention&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Activation checkpointing FSDP&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Hybrid Sharded Data Parallel (HSDP)&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dataset packing &amp;amp; padding&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BF16 Optimizer (Pure BF16)&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Profiling &amp;amp; MFU tracking&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gradient accumulation&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPU offloading&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FSDP checkpoint conversion to HF for inference&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;W&amp;amp;B experiment tracker&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please read &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for details on our code of conduct, and the process for submitting pull requests to us.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;!-- markdown-link-check-disable --&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 3.2 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_2/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_2/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 3.1 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_1/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_1/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 3 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 2 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama2/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama2/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- markdown-link-check-enable --&gt;</summary>
  </entry>
</feed>