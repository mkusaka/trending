<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-11-17T01:39:53Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>google-deepmind/deepmind-research</title>
    <updated>2024-11-17T01:39:53Z</updated>
    <id>tag:github.com,2024-11-17:/google-deepmind/deepmind-research</id>
    <link href="https://github.com/google-deepmind/deepmind-research" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository contains implementations and illustrative code to accompany DeepMind publications&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DeepMind Research&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains implementations and illustrative code to accompany DeepMind publications. Along with publishing papers to accompany research conducted at DeepMind, we release open-source &lt;a href=&#34;https://deepmind.com/research/open-source/open-source-environments/&#34;&gt;environments&lt;/a&gt;, &lt;a href=&#34;https://deepmind.com/research/open-source/open-source-datasets/&#34;&gt;data sets&lt;/a&gt;, and &lt;a href=&#34;https://deepmind.com/research/open-source/open-source-code/&#34;&gt;code&lt;/a&gt; to enable the broader research community to engage with our work and build upon it, with the ultimate goal of accelerating scientific progress to benefit society. For example, you can build on our implementations of the &lt;a href=&#34;https://github.com/deepmind/dqn&#34;&gt;Deep Q-Network&lt;/a&gt; or &lt;a href=&#34;https://github.com/deepmind/dnc&#34;&gt;Differential Neural Computer&lt;/a&gt;, or experiment in the same environments we use for our research, such as &lt;a href=&#34;https://github.com/deepmind/lab&#34;&gt;DeepMind Lab&lt;/a&gt; or &lt;a href=&#34;https://github.com/deepmind/pysc2&#34;&gt;StarCraft II&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you enjoy building tools, environments, software libraries, and other infrastructure of the kind listed below, you can view open positions to work in related areas on our &lt;a href=&#34;https://deepmind.com/careers/&#34;&gt;careers page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For a full list of our publications, please see &lt;a href=&#34;https://deepmind.com/research/publications/&#34;&gt;https://deepmind.com/research/publications/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Projects&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/fusion_tcv&#34;&gt;Magnetic control of tokamak plasmas through deep reinforcement learning&lt;/a&gt;, Nature 2022&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/density_functional_approximation_dm21&#34;&gt;Pushing the Frontiers of Density Functionals by Solving the Fractional Electron Problem&lt;/a&gt;, Science 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/pitfalls_static_language_models&#34;&gt;Mind the Gap: Assessing Temporal Generalization in Neural Language Models&lt;/a&gt;, NeurIPS 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/tandem_dqn&#34;&gt;The Difficulty of Passive Learning in Deep Reinforcement Learning&lt;/a&gt;, NeurIPS 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/nowcasting&#34;&gt;Skilful precipitation nowcasting using deep generative models of radar&lt;/a&gt;, Nature 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/cadl&#34;&gt;Compute-Aided Design as Language&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/continual_learning&#34;&gt;Encoders and ensembles for continual learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/hierarchical_transformer_memory&#34;&gt;Towards mental time travel: a hierarchical memory for reinforcement learning agents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/perceiver&#34;&gt;Perceiver IO: A General Architecture for Structured Inputs &amp;amp; Outputs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/neural_mip_solving&#34;&gt;Solving Mixed Integer Programs Using Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/noisy_label&#34;&gt;A Realistic Simulation Framework for Learning with Label Noise&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/rapid_task_solving&#34;&gt;Rapid Task-Solving in Novel Environments&lt;/a&gt;, ICLR 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/wikigraphs&#34;&gt;WikiGraphs: A Wikipedia - Knowledge Graph Paired Dataset&lt;/a&gt;, TextGraphs 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/box_arrangement&#34;&gt;Behavior Priors for Efficient Reinforcement Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/meshgraphnets&#34;&gt;Learning Mesh-Based Simulation with Graph Networks&lt;/a&gt;, ICLR 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/ogb_lsc&#34;&gt;Open Graph Benchmark - Large-Scale Challenge (OGB-LSC)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/synthetic_returns&#34;&gt;Synthetic Returns for Long-Term Credit Assignment&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/galaxy_mergers&#34;&gt;A Deep Learning Approach for Characterizing Major Galaxy Mergers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/kfac_ferminet_alpha&#34;&gt;Better, Faster Fermionic Neural Networks&lt;/a&gt; (KFAC implementation)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/object_attention_for_reasoning&#34;&gt;Object-based attention for spatio-temporal reasoning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/enformer&#34;&gt;Effective gene expression prediction from sequence by integrating long-range interactions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/satore&#34;&gt;Satore: First-order logic saturation with atom rewriting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/nfnets&#34;&gt;Characterizing signal propagation to close the performance gap in unnormalized ResNets&lt;/a&gt;, ICLR 2021&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/adversarial_robustness&#34;&gt;Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/cmtouch&#34;&gt;Learning rich touch representations through cross-modal self-supervision&lt;/a&gt;, CoRL 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/functional_regularisation_for_continual_learning&#34;&gt;Functional Regularisation for Continual Learning&lt;/a&gt;, ICLR 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/avae&#34;&gt;The Autoencoding Variational Autoencoder&lt;/a&gt;, NeurIPS 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/mmv&#34;&gt;Self-Supervised MultiModal Versatile Networks&lt;/a&gt;, NeurIPS 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/ode_gan&#34;&gt;ODE-GAN: Training GANs by Solving Ordinary Differential Equations&lt;/a&gt;, NeurIPS 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/causal_reasoning&#34;&gt;Algorithms for Causal Reasoning in Probability Trees&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/gated_linear_networks&#34;&gt;Gated Linear Networks&lt;/a&gt;, NeurIPS 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/himo&#34;&gt;Value-driven Hindsight Modelling&lt;/a&gt;, NeurIPS 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/learned_free_energy_estimation&#34;&gt;Targeted free energy estimation via learned mappings&lt;/a&gt;, Journal of Chemical Physics 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/learning_to_simulate&#34;&gt;Learning to Simulate Complex Physics with Graph Networks&lt;/a&gt;, ICML 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/physics_planning_games&#34;&gt;Physically Embedded Planning Problems&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/polygen&#34;&gt;PolyGen: PolyGen: An Autoregressive Generative Model of 3D Meshes&lt;/a&gt;, ICML 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/byol&#34;&gt;Bootstrap Your Own Latent&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/catch_carry&#34;&gt;Catch &amp;amp; Carry: Reusable Neural Controllers for Vision-Guided Whole-Body Tasks&lt;/a&gt;, SIGGRAPH 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/memo&#34;&gt;MEMO: A Deep Network For Flexible Combination Of Episodic Memories&lt;/a&gt;, ICLR 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/rl_unplugged&#34;&gt;RL Unplugged: Benchmarks for Offline Reinforcement Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/geomancer&#34;&gt;Disentangling by Subspace Diffusion (GEOMANCER)&lt;/a&gt;, NeurIPS 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/affordances_theory&#34;&gt;What can I do here? A theory of affordances in reinforcement learning&lt;/a&gt;, ICML 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/sketchy&#34;&gt;Scaling data-driven robotics with reward sketching and batch reinforcement learning&lt;/a&gt;, RSS 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/counterfactual_fairness&#34;&gt;Path-Specific Counterfactual Fairness&lt;/a&gt;, AAAI 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/option_keyboard&#34;&gt;The Option Keyboard: Combining Skills in Reinforcement Learning&lt;/a&gt;, NeurIPS 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/visr&#34;&gt;VISR - Fast Task Inference with Variational Intrinsic Successor Features&lt;/a&gt;, ICLR 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/glassy_dynamics&#34;&gt;Unveiling the predictive power of static structure in glassy systems&lt;/a&gt;, Nature Physics 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/iodine&#34;&gt;Multi-Object Representation Learning with Iterative Variational Inference (IODINE)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/alphafold_casp13&#34;&gt;AlphaFold CASP13&lt;/a&gt;, Nature 2020&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/unrestricted_advx&#34;&gt;Unrestricted Adversarial Challenge&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/hierarchical_probabilistic_unet&#34;&gt;Hierarchical Probabilistic U-Net (HPU-Net)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/scratchgan&#34;&gt;Training Language GANs from Scratch&lt;/a&gt;, NeurIPS 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/tvt&#34;&gt;Temporal Value Transport&lt;/a&gt;, Nature Communications 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/curl&#34;&gt;Continual Unsupervised Representation Learning (CURL)&lt;/a&gt;, NeurIPS 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/transporter&#34;&gt;Unsupervised Learning of Object Keypoints (Transporter)&lt;/a&gt;, NeurIPS 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/bigbigan&#34;&gt;BigBiGAN&lt;/a&gt;, NeurIPS 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/cs_gan&#34;&gt;Deep Compressed Sensing&lt;/a&gt;, ICML 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/side_effects_penalties&#34;&gt;Side Effects Penalties&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/PrediNet&#34;&gt;PrediNet Architecture and Relations Game Datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/unsupervised_adversarial_training&#34;&gt;Unsupervised Adversarial Training&lt;/a&gt;, NeurIPS 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/graph_matching_networks&#34;&gt;Graph Matching Networks for Learning the Similarity of Graph Structured Objects&lt;/a&gt;, ICML 2019&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/regal&#34;&gt;REGAL: Transfer Learning for Fast Optimization of Computation Graphs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/ensemble_loss_landscape&#34;&gt;Deep Ensembles: A Loss Landscape Perspective&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/powerpropagation&#34;&gt;Powerpropagation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/deepmind-research/master/physics_inspired_models&#34;&gt;Physics Inspired Models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;This is not an official Google product.&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>huggingface/notebooks</title>
    <updated>2024-11-17T01:39:53Z</updated>
    <id>tag:github.com,2024-11-17:/huggingface/notebooks</id>
    <link href="https://github.com/huggingface/notebooks" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Notebooks using the Hugging Face libraries 🤗&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;notebooks&lt;/h1&gt; &#xA;&lt;p&gt;Notebooks using the Hugging Face libraries 🤗&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>langchain-ai/langchain-academy</title>
    <updated>2024-11-17T01:39:53Z</updated>
    <id>tag:github.com,2024-11-17:/langchain-ai/langchain-academy</id>
    <link href="https://github.com/langchain-ai/langchain-academy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LangChain Academy&lt;/h1&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Welcome to LangChain Academy! This is a growing set of modules focused on foundational concepts within the LangChain ecosystem. Module 0 is basic setup and Modules 1 - 4 focus on LangGraph, progressively adding more advanced themes. In each module folder, you&#39;ll see a set of notebooks. A LangChain Academy accompanies each notebook to guide you through the topic. Each module also has a &lt;code&gt;studio&lt;/code&gt; subdirectory, with a set of relevant graphs that we will explore using the LangGraph API and Studio.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Python version&lt;/h3&gt; &#xA;&lt;p&gt;To get the most out of this course, please ensure you&#39;re using Python 3.11 or later. This version is required for optimal compatibility with LangGraph. If you&#39;re on an older version, upgrading will ensure everything runs smoothly.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Clone repo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/langchain-ai/langchain-academy.git&#xA;$ cd langchain-academy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Create an environment and install dependencies&lt;/h3&gt; &#xA;&lt;h4&gt;Mac/Linux/WSL&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 -m venv lc-academy-env&#xA;$ source lc-academy-env/bin/activate&#xA;$ pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Windows Powershell&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;PS&amp;gt; python3 -m venv lc-academy-env&#xA;PS&amp;gt; Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process&#xA;PS&amp;gt; lc-academy-env\scripts\activate&#xA;PS&amp;gt; pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running notebooks&lt;/h3&gt; &#xA;&lt;p&gt;If you don&#39;t have Jupyter set up, follow installation instructions &lt;a href=&#34;https://jupyter.org/install&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ jupyter notebook&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Setting up env variables&lt;/h3&gt; &#xA;&lt;p&gt;Briefly going over how to set up environment variables. You can also use a &lt;code&gt;.env&lt;/code&gt; file with &lt;code&gt;python-dotenv&lt;/code&gt; library.&lt;/p&gt; &#xA;&lt;h4&gt;Mac/Linux/WSL&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ export API_ENV_VAR=&#34;your-api-key-here&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Windows Powershell&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;PS&amp;gt; $env:API_ENV_VAR = &#34;your-api-key-here&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Set OpenAI API key&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you don&#39;t have an OpenAI API key, you can sign up &lt;a href=&#34;https://openai.com/index/openai-api/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Set &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in your environment&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Sign up and Set LangSmith API&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sign up for LangSmith &lt;a href=&#34;https://smith.langchain.com/&#34;&gt;here&lt;/a&gt;, find out more about LangSmith&lt;/li&gt; &#xA; &lt;li&gt;and how to use it within your workflow &lt;a href=&#34;https://www.langchain.com/langsmith&#34;&gt;here&lt;/a&gt;, and relevant library &lt;a href=&#34;https://docs.smith.langchain.com/&#34;&gt;docs&lt;/a&gt;!&lt;/li&gt; &#xA; &lt;li&gt;Set &lt;code&gt;LANGCHAIN_API_KEY&lt;/code&gt;, &lt;code&gt;LANGCHAIN_TRACING_V2=true&lt;/code&gt; in your environment&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Set up Tavily API for web search&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Tavily Search API is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You can sign up for an API key &lt;a href=&#34;https://tavily.com/&#34;&gt;here&lt;/a&gt;. It&#39;s easy to sign up and offers a very generous free tier. Some lessons (in Module 4) will use Tavily.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set &lt;code&gt;TAVILY_API_KEY&lt;/code&gt; in your environment.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Set up LangGraph Studio&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Currently, Studio only has macOS support and needs Docker Desktop running.&lt;/li&gt; &#xA; &lt;li&gt;Download the latest &lt;code&gt;.dmg&lt;/code&gt; file &lt;a href=&#34;https://github.com/langchain-ai/langgraph-studio?tab=readme-ov-file#download&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install Docker desktop for Mac &lt;a href=&#34;https://docs.docker.com/engine/install/&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Running Studio&lt;/h3&gt; &#xA;&lt;p&gt;Graphs for LangGraph Studio are in the &lt;code&gt;module-x/studio/&lt;/code&gt; folders.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To use Studio, you will need to create a .env file with the relevant API keys&lt;/li&gt; &#xA; &lt;li&gt;Run this from the command line to create these files for module 1 to 4, as an example:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ for i in {1..4}; do&#xA;  cp module-$i/studio/.env.example module-$i/studio/.env&#xA;  echo &#34;OPENAI_API_KEY=\&#34;$OPENAI_API_KEY\&#34;&#34; &amp;gt; module-$i/studio/.env&#xA;done&#xA;$ echo &#34;TAVILY_API_KEY=\&#34;$TAVILY_API_KEY\&#34;&#34; &amp;gt;&amp;gt; module-4/studio/.env&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>