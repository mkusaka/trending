<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-07-13T01:40:30Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>langchain-ai/agents-from-scratch</title>
    <updated>2025-07-13T01:40:30Z</updated>
    <id>tag:github.com,2025-07-13:/langchain-ai/agents-from-scratch</id>
    <link href="https://github.com/langchain-ai/agents-from-scratch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build an email assistant with human-in-the-loop and memory&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agents From Scratch&lt;/h1&gt; &#xA;&lt;p&gt;The repo is a guide to building agents from scratch. It builds up to an &lt;a href=&#34;https://blog.langchain.dev/introducing-ambient-agents/&#34;&gt;&#34;ambient&#34;&lt;/a&gt; agent that can manage your email with connection to the Gmail API. It&#39;s grouped into 4 sections, each with a notebook and accompanying code in the &lt;code&gt;src/email_assistant&lt;/code&gt; directory. These section build from the basics of agents, to agent evaluation, to human-in-the-loop, and finally to memory. These all come together in an agent that you can deploy, and the principles can be applied to other agents across a wide range of tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview.png&#34; alt=&#34;overview&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Environment Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Python Version&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ensure you&#39;re using Python 3.11 or later.&lt;/li&gt; &#xA; &lt;li&gt;This version is required for optimal compatibility with LangGraph.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python3 --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;API Keys&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you don&#39;t have an OpenAI API key, you can sign up &lt;a href=&#34;https://openai.com/index/openai-api/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Sign up for LangSmith &lt;a href=&#34;https://smith.langchain.com/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Generate a LangSmith API key.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Set Environment Variables&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Copy the .env.example file to .env&#xA;cp .env.example .env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Edit the &lt;code&gt;.env&lt;/code&gt; file with the following:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;LANGSMITH_API_KEY=your_langsmith_api_key&#xA;LANGSMITH_TRACING=true&#xA;LANGSMITH_PROJECT=&#34;interrupt-workshop&#34;&#xA;OPENAI_API_KEY=your_openai_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You can also set the environment variables in your terminal:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export LANGSMITH_API_KEY=your_langsmith_api_key&#xA;export LANGSMITH_TRACING=true&#xA;export OPENAI_API_KEY=your_openai_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Package Installation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Recommended: Using uv (faster and more reliable)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Install uv if you haven&#39;t already&#xA;pip install uv&#xA;&#xA;# Install the package with development dependencies&#xA;uv sync --extra dev&#xA;&#xA;# Activate the virtual environment&#xA;source .venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Alternative: Using pip&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ python3 -m venv .venv&#xA;$ source .venv/bin/activate&#xA;# Ensure you have a recent version of pip (required for editable installs with pyproject.toml)&#xA;$ python3 -m pip install --upgrade pip&#xA;# Install the package in editable mode&#xA;$ pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;⚠️ IMPORTANT&lt;/strong&gt;: Do not skip the package installation step! This editable install is &lt;strong&gt;required&lt;/strong&gt; for the notebooks to work correctly. The package is installed as &lt;code&gt;interrupt_workshop&lt;/code&gt; with import name &lt;code&gt;email_assistant&lt;/code&gt;, allowing you to import from anywhere with &lt;code&gt;from email_assistant import ...&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Structure&lt;/h2&gt; &#xA;&lt;p&gt;The repo is organized into the 4 sections, with a notebook for each and accompanying code in the &lt;code&gt;src/email_assistant&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;Preface: LangGraph 101&lt;/h3&gt; &#xA;&lt;p&gt;For a brief introduction to LangGraph and some of the concepts used in this repo, see the &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/langgraph_101.ipynb&#34;&gt;LangGraph 101 notebook&lt;/a&gt;. This notebook explains the basics of chat models, tool calling, agents vs workflows, LangGraph nodes / edges / memory, and LangGraph Studio.&lt;/p&gt; &#xA;&lt;h3&gt;Building an agent&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Notebook: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/agent.ipynb&#34;&gt;notebooks/agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Code: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant.py&#34;&gt;src/email_assistant/email_assistant.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview_agent.png&#34; alt=&#34;overview-agent&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook shows how to build the email assistant, combining an &lt;a href=&#34;https://langchain-ai.github.io/langgraph/tutorials/workflows/&#34;&gt;email triage step&lt;/a&gt; with an agent that handles the email response. You can see the linked code for the full implementation in &lt;code&gt;src/email_assistant/email_assistant.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/studio.png&#34; alt=&#34;Screenshot 2025-04-04 at 4 06 18 PM&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Notebook: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/evaluation.ipynb&#34;&gt;notebooks/evaluation.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview_eval.png&#34; alt=&#34;overview-eval&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook introduces evaluation with an email dataset in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/eval/email_dataset.py&#34;&gt;eval/email_dataset.py&lt;/a&gt;. It shows how to run evaluations using Pytest and the LangSmith &lt;code&gt;evaluate&lt;/code&gt; API. It runs evaluation for emails responses using LLM-as-a-judge as well as evaluations for tools calls and triage decisions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/eval.png&#34; alt=&#34;Screenshot 2025-04-08 at 8 07 48 PM&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Human-in-the-loop&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Notebook: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/hitl.ipynb&#34;&gt;notebooks/hitl.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Code: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl.py&#34;&gt;src/email_assistant/email_assistant_hitl.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview_hitl.png&#34; alt=&#34;overview-hitl&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebooks shows how to add human-in-the-loop (HITL), allowing the user to review specific tool calls (e.g., send email, schedule meeting). For this, we use &lt;a href=&#34;https://github.com/langchain-ai/agent-inbox&#34;&gt;Agent Inbox&lt;/a&gt; as an interface for human in the loop. You can see the linked code for the full implementation in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl.py&#34;&gt;src/email_assistant/email_assistant_hitl.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/agent-inbox.png&#34; alt=&#34;Agent Inbox showing email threads&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Memory&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Notebook: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/memory.ipynb&#34;&gt;notebooks/memory.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Code: &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl_memory.py&#34;&gt;src/email_assistant/email_assistant_hitl_memory.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/notebooks/img/overview_memory.png&#34; alt=&#34;overview-memory&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook shows how to add memory to the email assistant, allowing it to learn from user feedback and adapt to preferences over time. The memory-enabled assistant (&lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl_memory.py&#34;&gt;email_assistant_hitl_memory.py&lt;/a&gt;) uses the &lt;a href=&#34;https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory&#34;&gt;LangGraph Store&lt;/a&gt; to persist memories. You can see the linked code for the full implementation in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl_memory.py&#34;&gt;src/email_assistant/email_assistant_hitl_memory.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Connecting to APIs&lt;/h2&gt; &#xA;&lt;p&gt;The above notebooks using mock email and calendar tools.&lt;/p&gt; &#xA;&lt;h3&gt;Gmail Integration and Deployment&lt;/h3&gt; &#xA;&lt;p&gt;Set up Google API credentials following the instructions in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/tools/gmail/README.md&#34;&gt;Gmail Tools README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The README also explains how to deploy the graph to LangGraph Platform.&lt;/p&gt; &#xA;&lt;p&gt;The full implementation of the Gmail integration is in &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/src/email_assistant/email_assistant_hitl_memory_gmail.py&#34;&gt;src/email_assistant/email_assistant_hitl_memory_gmail.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Running Tests&lt;/h2&gt; &#xA;&lt;p&gt;The repository includes an automated test suite to evaluate the email assistant.&lt;/p&gt; &#xA;&lt;p&gt;Tests verify correct tool usage and response quality using LangSmith for tracking.&lt;/p&gt; &#xA;&lt;h3&gt;Running Tests with &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/agents-from-scratch/main/tests/run_all_tests.py&#34;&gt;run_all_tests.py&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python tests/run_all_tests.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Test Results&lt;/h3&gt; &#xA;&lt;p&gt;Test results are logged to LangSmith under the project name specified in your &lt;code&gt;.env&lt;/code&gt; file (&lt;code&gt;LANGSMITH_PROJECT&lt;/code&gt;). This provides:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Visual inspection of agent traces&lt;/li&gt; &#xA; &lt;li&gt;Detailed evaluation metrics&lt;/li&gt; &#xA; &lt;li&gt;Comparison of different agent implementations&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Available Test Implementations&lt;/h3&gt; &#xA;&lt;p&gt;The available implementations for testing are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;email_assistant&lt;/code&gt; - Basic email assistant&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Testing Notebooks&lt;/h3&gt; &#xA;&lt;p&gt;You can also run tests to verify all notebooks execute without errors:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Run all notebook tests&#xA;python tests/test_notebooks.py&#xA;&#xA;# Or run via pytest&#xA;pytest tests/test_notebooks.py -v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Future Extensions&lt;/h2&gt; &#xA;&lt;p&gt;Add &lt;a href=&#34;https://langchain-ai.github.io/langmem/&#34;&gt;LangMem&lt;/a&gt; to manage memories:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Manage a collection of background memories.&lt;/li&gt; &#xA; &lt;li&gt;Add memory tools that can look up facts in the background memories.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>datawhalechina/happy-llm</title>
    <updated>2025-07-13T01:40:30Z</updated>
    <id>tag:github.com,2025-07-13:/datawhalechina/happy-llm</id>
    <link href="https://github.com/datawhalechina/happy-llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;📚 从零开始的大语言模型原理与实践教程&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/images/head.jpg&#34; alt=&#34;alt text&#34; width=&#34;100%&#34;&gt; &#xA; &lt;h1&gt;Happy-LLM&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://img.shields.io/github/stars/datawhalechina/happy-llm?style=flat&amp;amp;logo=github&#34; alt=&#34;GitHub stars&#34;&gt; &#xA; &lt;img src=&#34;https://img.shields.io/github/forks/datawhalechina/happy-llm?style=flat&amp;amp;logo=github&#34; alt=&#34;GitHub forks&#34;&gt; &#xA; &lt;img src=&#34;https://img.shields.io/badge/language-Chinese-brightgreen?style=flat&#34; alt=&#34;Language&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/datawhalechina/happy-llm&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;amp;logo=github&#34; alt=&#34;GitHub Project&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://swanlab.cn/@kmno4/Happy-LLM/overview&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SwanHubX/assets/main/badge1.svg?sanitize=true&#34; alt=&#34;SwanLab&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://trendshift.io/repositories/14175&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/14175&#34; alt=&#34;datawhalechina%2Fhappy-llm | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/README.md&#34;&gt;中文&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/README_en.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://datawhalechina.github.io/happy-llm/&#34;&gt;📚 在线阅读地址&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;📚 从零开始的大语言模型原理与实践教程&lt;/h3&gt; &#xA; &lt;p&gt;&lt;em&gt;深入理解 LLM 核心原理，动手实现你的第一个大模型&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;🎯 项目介绍&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;  &lt;em&gt;很多小伙伴在看完 Datawhale开源项目： &lt;a href=&#34;https://github.com/datawhalechina/self-llm&#34;&gt;self-llm 开源大模型食用指南&lt;/a&gt; 后，感觉意犹未尽，想要深入了解大语言模型的原理和训练过程。于是我们（Datawhale）决定推出《Happy-LLM》项目，旨在帮助大家深入理解大语言模型的原理和训练过程。&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;  本项目是一个&lt;strong&gt;系统性的 LLM 学习教程&lt;/strong&gt;，将从 NLP 的基本研究方法出发，根据 LLM 的思路及原理逐层深入，依次为读者剖析 LLM 的架构基础和训练过程。同时，我们会结合目前 LLM 领域最主流的代码框架，演练如何亲手搭建、训练一个 LLM，期以实现授之以鱼，更授之以渔。希望大家能从这本书开始走入 LLM 的浩瀚世界，探索 LLM 的无尽可能。&lt;/p&gt; &#xA;&lt;h3&gt;✨ 你将收获什么？&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;📚 &lt;strong&gt;Datawhale 开源免费&lt;/strong&gt; 完全免费的学习本项目所有内容&lt;/li&gt; &#xA; &lt;li&gt;🔍 &lt;strong&gt;深入理解&lt;/strong&gt; Transformer 架构和注意力机制&lt;/li&gt; &#xA; &lt;li&gt;📚 &lt;strong&gt;掌握&lt;/strong&gt; 预训练语言模型的基本原理&lt;/li&gt; &#xA; &lt;li&gt;🧠 &lt;strong&gt;了解&lt;/strong&gt; 现有大模型的基本结构&lt;/li&gt; &#xA; &lt;li&gt;🏗️ &lt;strong&gt;动手实现&lt;/strong&gt; 一个完整的 LLaMA2 模型&lt;/li&gt; &#xA; &lt;li&gt;⚙️ &lt;strong&gt;掌握训练&lt;/strong&gt; 从预训练到微调的全流程&lt;/li&gt; &#xA; &lt;li&gt;🚀 &lt;strong&gt;实战应用&lt;/strong&gt; RAG、Agent 等前沿技术&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;📖 内容导航&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;章节&lt;/th&gt; &#xA;   &lt;th&gt;关键内容&lt;/th&gt; &#xA;   &lt;th&gt;状态&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/%E5%89%8D%E8%A8%80.md&#34;&gt;前言&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;本项目的缘起、背景及读者建议&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20NLP%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.md&#34;&gt;第一章 NLP 基础概念&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;什么是 NLP、发展历程、任务分类、文本表示演进&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/chapter2/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20Transformer%E6%9E%B6%E6%9E%84.md&#34;&gt;第二章 Transformer 架构&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;注意力机制、Encoder-Decoder、手把手搭建 Transformer&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/chapter3/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B.md&#34;&gt;第三章 预训练语言模型&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Encoder-only、Encoder-Decoder、Decoder-Only 模型对比&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B.md&#34;&gt;第四章 大语言模型&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;LLM 定义、训练策略、涌现能力分析&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/chapter5/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%8A%A8%E6%89%8B%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B.md&#34;&gt;第五章 动手搭建大模型&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;实现 LLaMA2、训练 Tokenizer、预训练小型 LLM&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E5%AE%9E%E8%B7%B5.md&#34;&gt;第六章 大模型训练实践&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;预训练、有监督微调、LoRA/QLoRA 高效微调&lt;/td&gt; &#xA;   &lt;td&gt;🚧&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/chapter7/%E7%AC%AC%E4%B8%83%E7%AB%A0%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8.md&#34;&gt;第七章 大模型应用&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;模型评测、RAG 检索增强、Agent 智能体&lt;/td&gt; &#xA;   &lt;td&gt;✅&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/Extra-Chapter/&#34;&gt;Extra Chapter LLM Blog&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;优秀的大模型 学习笔记/Blog ，欢迎大家来 PR ！&lt;/td&gt; &#xA;   &lt;td&gt;🚧&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Extar Chapter LLM Blog&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/Extra-Chapter/why-fine-tune-small-large-language-models/readme.md&#34;&gt;大模型都这么厉害了，微调0.6B的小模型有什么意义？&lt;/a&gt; @&lt;a href=&#34;https://github.com/KMnO4-zx&#34;&gt;不要葱姜蒜&lt;/a&gt; 2025-7-11&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;  &lt;em&gt;&lt;strong&gt;如果大家在学习 Happy-LLM 项目或 LLM 相关知识中有自己独到的见解、认知、实践，欢迎大家 PR 在 &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/Extra-Chapter/&#34;&gt;Extra Chapter LLM Blog&lt;/a&gt; 中。请遵守 Extra Chapter LLM Blog 的 &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/Extra-Chapter/Readme.md&#34;&gt;PR 规范&lt;/a&gt;，我们会视 PR 内容的质量和价值来决定是否合并或补充到 Happy-LLM 正文中来。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;模型下载&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型名称&lt;/th&gt; &#xA;   &lt;th&gt;下载地址&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Happy-LLM-Chapter5-Base-215M&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.modelscope.cn/models/kmno4zx/happy-llm-215M-base&#34;&gt;🤖 ModelScope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Happy-LLM-Chapter5-SFT-215M&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.modelscope.cn/models/kmno4zx/happy-llm-215M-sft&#34;&gt;🤖 ModelScope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;em&gt;ModelScope 创空间体验地址：&lt;a href=&#34;https://www.modelscope.cn/studios/kmno4zx/happy_llm_215M_sft&#34;&gt;🤖 创空间&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;PDF 版本下载&lt;/h3&gt; &#xA;&lt;p&gt;  &lt;em&gt;&lt;strong&gt;本 Happy-LLM PDF 教程完全开源免费。为防止各类营销号加水印后贩卖给大模型初学者，我们特地在 PDF 文件中预先添加了不影响阅读的 Datawhale 开源标志水印，敬请谅解～&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;em&gt;Happy-LLM PDF : &lt;a href=&#34;https://github.com/datawhalechina/happy-llm/releases/tag/PDF&#34;&gt;https://github.com/datawhalechina/happy-llm/releases/tag/PDF&lt;/a&gt;&lt;/em&gt;&lt;br&gt; &lt;em&gt;Happy-LLM PDF 国内下载地址 : &lt;a href=&#34;https://www.datawhale.cn/learn/summary/179&#34;&gt;https://www.datawhale.cn/learn/summary/179&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;💡 如何学习&lt;/h2&gt; &#xA;&lt;p&gt;  本项目适合大学生、研究人员、LLM 爱好者。在学习本项目之前，建议具备一定的编程经验，尤其是要对 Python 编程语言有一定的了解。最好具备深度学习的相关知识，并了解 NLP 领域的相关概念和术语，以便更轻松地学习本项目。&lt;/p&gt; &#xA;&lt;p&gt;  本项目分为两部分——基础知识与实战应用。第1章～第4章是基础知识部分，从浅入深介绍 LLM 的基本原理。其中，第1章简单介绍 NLP 的基本任务和发展，为非 NLP 领域研究者提供参考；第2章介绍 LLM 的基本架构——Transformer，包括原理介绍及代码实现，作为 LLM 最重要的理论基础；第3章整体介绍经典的 PLM，包括 Encoder-Only、Encoder-Decoder 和 Decoder-Only 三种架构，也同时介绍了当前一些主流 LLM 的架构和思想；第4章则正式进入 LLM 部分，详细介绍 LLM 的特点、能力和整体训练过程。第5章～第7章是实战应用部分，将逐步带领大家深入 LLM 的底层细节。其中，第5章将带领大家者基于 PyTorch 层亲手搭建一个 LLM，并实现预训练、有监督微调的全流程；第6章将引入目前业界主流的 LLM 训练框架 Transformers，带领学习者基于该框架快速、高效地实现 LLM 训练过程；第7章则将介绍 基于 LLM 的各种应用，补全学习者对 LLM 体系的认知，包括 LLM 的评测、检索增强生成（Retrieval-Augmented Generation，RAG）、智能体（Agent）的思想和简单实现。你可以根据个人兴趣和需求，选择性地阅读相关章节。&lt;/p&gt; &#xA;&lt;p&gt;  在阅读本书的过程中，建议你将理论和实际相结合。LLM 是一个快速发展、注重实践的领域，我们建议你多投入实战，复现本书提供的各种代码，同时积极参加 LLM 相关的项目与比赛，真正投入到 LLM 开发的浪潮中。我们鼓励你关注 Datawhale 及其他 LLM 相关开源社区，当遇到问题时，你可以随时在本项目的 issue 区提问。&lt;/p&gt; &#xA;&lt;p&gt;  最后，欢迎每一位读者在学习完本项目后加入到 LLM 开发者的行列。作为国内 AI 开源社区，我们希望充分聚集共创者，一起丰富这个开源 LLM 的世界，打造更多、更全面特色 LLM 的教程。星火点点，汇聚成海。我们希望成为 LLM 与普罗大众的阶梯，以自由、平等的开源精神，拥抱更恢弘而辽阔的 LLM 世界。&lt;/p&gt; &#xA;&lt;h2&gt;🤝 如何贡献&lt;/h2&gt; &#xA;&lt;p&gt;我们欢迎任何形式的贡献！&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🐛 &lt;strong&gt;报告 Bug&lt;/strong&gt; - 发现问题请提交 Issue&lt;/li&gt; &#xA; &lt;li&gt;💡 &lt;strong&gt;功能建议&lt;/strong&gt; - 有好想法就告诉我们&lt;/li&gt; &#xA; &lt;li&gt;📝 &lt;strong&gt;内容完善&lt;/strong&gt; - 帮助改进教程内容&lt;/li&gt; &#xA; &lt;li&gt;🔧 &lt;strong&gt;代码优化&lt;/strong&gt; - 提交 Pull Request&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🙏 致谢&lt;/h2&gt; &#xA;&lt;h3&gt;核心贡献者&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/KMnO4-zx&#34;&gt;宋志学-项目负责人&lt;/a&gt; (Datawhale成员-中国矿业大学(北京))&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/logan-zou&#34;&gt;邹雨衡-项目负责人&lt;/a&gt; (Datawhale成员-对外经济贸易大学)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xinzhongzhu.github.io/&#34;&gt;朱信忠-指导专家&lt;/a&gt;（Datawhale首席科学家-浙江师范大学杭州人工智能研究院教授）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;特别感谢&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;感谢 &lt;a href=&#34;https://github.com/Sm1les&#34;&gt;@Sm1les&lt;/a&gt; 对本项目的帮助与支持&lt;/li&gt; &#xA; &lt;li&gt;感谢所有为本项目做出贡献的开发者们 ❤️&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34; style=&#34;margin-top: 30px;&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/datawhalechina/happy-llm/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=datawhalechina/happy-llm&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/images/star-history-2025710.png&#34; alt=&#34;Datawhale&#34; width=&#34;90%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;⭐ 如果这个项目对你有帮助，请给我们一个 Star！&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;关于 Datawhale&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/datawhalechina/happy-llm/main/images/datawhale.png&#34; alt=&#34;Datawhale&#34; width=&#34;30%&#34;&gt; &#xA; &lt;p&gt;扫描二维码关注 Datawhale 公众号，获取更多优质开源内容&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;📜 开源协议&lt;/h2&gt; &#xA;&lt;p&gt;本作品采用&lt;a href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议&lt;/a&gt;进行许可。&lt;/p&gt;</summary>
  </entry>
</feed>