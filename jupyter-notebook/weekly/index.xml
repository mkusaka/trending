<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-26T01:57:24Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dair-ai/Prompt-Engineering-Guide</title>
    <updated>2023-02-26T01:57:24Z</updated>
    <id>tag:github.com,2023-02-26:/dair-ai/Prompt-Engineering-Guide</id>
    <link href="https://github.com/dair-ai/Prompt-Engineering-Guide" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üêô Guides, papers, lecture, and resources for prompt engineering&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Prompt Engineering Guide&lt;/h1&gt; &#xA;&lt;p&gt;Prompt engineering is a relatively new discipline for developing and optimizing prompts to efficiently use language models (LMs) for a wide variety of applications and research topics. Prompt engineering skills help to better understand the capabilities and limitations of large language models (LLMs). Researchers use prompt engineering to improve the capacity of LLMs on a wide range of common and complex tasks such as question answering and arithmetic reasoning. Developers use prompt engineering to design robust and effective prompting techniques that interface with LLMs and other tools.&lt;/p&gt; &#xA;&lt;p&gt;Motivated by the high interest in developing with LLMs, we have created this new prompt engineering guide that contains all the latest papers, learning guides, lectures, references, and tools related to prompt engineering.&lt;/p&gt; &#xA;&lt;p&gt;Happy Prompting!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Announcements / Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üî• We reached #1 on Hacker News on 21 Feb 2023&lt;/li&gt; &#xA; &lt;li&gt;üéâ The Prompt Engineering Lecture went live &lt;a href=&#34;https://youtu.be/dOxUroR57xs&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üéì We&#39;re creating a set of comprehensive guides &lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#guides&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üìñ New set of deep tutorials coming soon!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/SKgkVT8BGJ&#34;&gt;Join our Discord&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/dair_ai&#34;&gt;Follow us on Twitter&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#lecture&#34;&gt;Lecture&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#guides&#34;&gt;Guides&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#papers&#34;&gt;Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#tools--libraries&#34;&gt;Tools &amp;amp; Libraries&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#datasets&#34;&gt;Datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#blog-guides-tutorials-and-other-readings&#34;&gt;Blog, Guides, Tutorials and Other Readings&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Lecture&lt;/h2&gt; &#xA;&lt;p&gt;We have published a 1 hour lecture that provides a comprehensive overview of prompting techniques, applications, and tools.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/dOxUroR57xs&#34;&gt;Video Lecture&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/Prompt-Engineering-Guide/raw/main/notebooks/pe-lecture.ipynb&#34;&gt;Notebook with code&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/Prompt-Engineering-Guide/raw/main/lecture/Prompt-Engineering-Lecture-Elvis.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Guides&lt;/h2&gt; &#xA;&lt;p&gt;The following are a set of guides on prompt engineering developed by us. Guides are work in progress.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompts-intro.md&#34;&gt;Prompt Engineering - Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompts-basic-usage.md&#34;&gt;Prompt Engineering - Basic Prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompts-advanced-usage.md&#34;&gt;Prompt Engineering - Advanced Prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompt-adversarial.md&#34;&gt;Prompt Engineering - Adversarial Prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompt-miscellaneous.md&#34;&gt;Prompt Engineering - Miscellaneous Topics&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Papers&lt;/h2&gt; &#xA;&lt;p&gt;The following are the latest papers (sorted by release date) on prompt engineering. We update this on a daily basis and new papers come in. We incorporate summaries of these papers to the guides above every week.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Surveys / Overviews:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07842&#34;&gt;Augmented Language Models: a Survey&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.00234&#34;&gt;A Survey for In-context Learning&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.10403&#34;&gt;Towards Reasoning in Large Language Models: A Survey&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.07682&#34;&gt;Emergent Abilities of Large Language Models&lt;/a&gt; (Jun 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.13988&#34;&gt;A Taxonomy of Prompt Modifiers for Text-To-Image Generation&lt;/a&gt; (Apr 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2107.13586&#34;&gt;Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing&lt;/a&gt; (Jul 2021)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Approaches/Techniques:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.12246&#34;&gt;Active Prompting with Chain-of-Thought for Large Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.12173&#34;&gt;More than you&#39;ve asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.11520&#34;&gt;Guiding Large Language Models via Directional Stimulus Prompting&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.11521&#34;&gt;How Does In-Context Learning Help Prompt Tuning?&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.09236&#34;&gt;Scalable Prompt Generation for Semi-supervised Learning with Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.09185&#34;&gt;Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07994&#34;&gt;√Ä-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.08043&#34;&gt;GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07459&#34;&gt;The Capacity for Moral Self-Correction in Large Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.06868&#34;&gt;SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.05619&#34;&gt;Evaluating the Robustness of Discrete Prompts&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.05698&#34;&gt;Compositional Exemplars for In-context Learning&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03668&#34;&gt;Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.00923&#34;&gt;Multimodal Chain-of-Thought Reasoning in Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.00093&#34;&gt;Large Language Models Can Be Easily Distracted by Irrelevant Context&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.00618&#34;&gt;Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.12314&#34;&gt;Progressive Prompts: Continual Learning for Language Models&lt;/a&gt; (Jan 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.08721&#34;&gt;Batch Prompting: Efficient Inference with LLM APIs&lt;/a&gt; (Jan 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.14024&#34;&gt;Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.08061&#34;&gt;On Second Thought, Let&#39;s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.08073&#34;&gt;Constitutional AI: Harmlessness from AI Feedback&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.04092&#34;&gt;Successive Prompting for Decomposing Complex Questions&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.09251&#34;&gt;Discovering Language Model Behaviors with Model-Written Evaluations&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.06713&#34;&gt;Structured Prompting: Scaling In-Context Learning to 1,000 Examples&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.10435&#34;&gt;PAL: Program-aided Language Models&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.01910&#34;&gt;Large Language Models Are Human-Level Prompt Engineers&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.09527&#34;&gt;Ignore Previous Prompt: Attack Techniques For Language Models&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.07321&#34;&gt;Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.09066&#34;&gt;Teaching Algorithmic Reasoning via In-context Learning&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.11875&#34;&gt;Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for&#34;&gt;Ask Me Anything: A simple strategy for prompting language models&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.03629&#34;&gt;ReAct: Synergizing Reasoning and Acting in Language Models&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.09150&#34;&gt;Prompting GPT-3 To Be Reliable&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.02406&#34;&gt;Decomposed Prompting: A Modular Approach for Solving Complex Tasks&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.01240v3&#34;&gt;Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.02128&#34;&gt;Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples&lt;/a&gt; (Sep 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.14610&#34;&gt;Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning&lt;/a&gt; (Sep 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.11755&#34;&gt;Promptagator: Few-shot Dense Retrieval From 8 Examples&lt;/a&gt; (Sep 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.05987&#34;&gt;DocPrompting: Generating Code by Retrieving the Docs&lt;/a&gt; (July 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.02336&#34;&gt;On the Advance of Making Language Models Better Reasoners&lt;/a&gt; (June 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.11916&#34;&gt;Large Language Models are Zero-Shot Reasoners&lt;/a&gt; (May 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.00445&#34;&gt;MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning&lt;/a&gt; (May 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.12390&#34;&gt;Toxicity Detection with Generative Prompt-based Inference&lt;/a&gt; (May 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.01543&#34;&gt;Learning to Transfer Prompts for Text Generation&lt;/a&gt; (May 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.03401&#34;&gt;The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning&lt;/a&gt; (May 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.13988&#34;&gt;A Taxonomy of Prompt Modifiers for Text-To-Image Generation&lt;/a&gt; (Apr 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.06566&#34;&gt;PromptChainer: Chaining Large Language Model Prompts through Visual Programming&lt;/a&gt; (Mar 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.11171&#34;&gt;Self-Consistency Improves Chain of Thought Reasoning in Language Models&lt;/a&gt; (March 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.02155&#34;&gt;Training language models to follow instructions with human feedback&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.12837&#34;&gt;Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?&lt;/a&gt; (Feb 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2201.11903&#34;&gt;Chain of Thought Prompting Elicits Reasoning in Large Language Models&lt;/a&gt; (Jan 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.00114&#34;&gt;Show Your Work: Scratchpads for Intermediate Computation with Language Models&lt;/a&gt; (Nov 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2110.08387&#34;&gt;Generated Knowledge Prompting for Commonsense Reasoning&lt;/a&gt; (Oct 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2110.08207&#34;&gt;Multitask Prompted Training Enables Zero-Shot Task Generalization&lt;/a&gt; (Oct 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2109.07830&#34;&gt;Reframing Instructional Prompts to GPTk&#39;s Language&lt;/a&gt; (Sep 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2109.06977&#34;&gt;Design Guidelines for Prompt Engineering Text-to-Image Generative Models&lt;/a&gt; (Sep 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2021.acl-long.295&#34;&gt;Making Pre-trained Language Models Better Few-shot Learners&lt;/a&gt; (Aug 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.08786&#34;&gt;Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity&lt;/a&gt; (April 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2021.eacl-main.316&#34;&gt;BERTese: Learning to Speak to BERT&lt;/a&gt; (April 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.08691&#34;&gt;The Power of Scale for Parameter-Efficient Prompt Tuning&lt;/a&gt; (April 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2102.07350&#34;&gt;Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm&lt;/a&gt; (Feb 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2102.09690&#34;&gt;Calibrate Before Use: Improving Few-Shot Performance of Language Models&lt;/a&gt; (Feb 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2101.00190&#34;&gt;Prefix-Tuning: Optimizing Continuous Prompts for Generation&lt;/a&gt; (Jan 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.15980&#34;&gt;AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts&lt;/a&gt; (Oct 2020)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.14165&#34;&gt;Language Models are Few-Shot Learners&lt;/a&gt; (May 2020)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00324/96460/How-Can-We-Know-What-Language-Models-Know&#34;&gt;How Can We Know What Language Models Know?&lt;/a&gt; (July 2020)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Applications:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.10916&#34;&gt;How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.08961&#34;&gt;Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.08068&#34;&gt;LabelPrompt: Effective Prompt-based Learning for Relation Classification&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.09236&#34;&gt;Language Model Crossover: Variation through Few-Shot Prompting&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.08102&#34;&gt;Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07459&#34;&gt;The Capacity for Moral Self-Correction in Large Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.04156&#34;&gt;Prompting for Multimodal Hateful Meme Classification&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03269&#34;&gt;PLACES: Prompting Language Models for Social Conversation Synthesis&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.01441&#34;&gt;Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.12810&#34;&gt;Crawling the Internal Knowledge-Base of Language Models&lt;/a&gt; (Jan 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.02199&#34;&gt;Legal Prompt Engineering for Multilingual Legal Judgement Prediction&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.15462&#34;&gt;Investigating Prompt Engineering in Diffusion Models&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.09513v2&#34;&gt;Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering&lt;/a&gt; (Sep 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.15157&#34;&gt;Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.14699&#34;&gt;Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2022.inlg-main.5&#34;&gt;Plot Writing From Scratch Pre-Trained Language Models&lt;/a&gt; (July 2022)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Collections:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Timothyxxx/Chain-of-ThoughtsPapers&#34;&gt;Chain-of-ThoughtsPapers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://paperswithcode.com/task/prompt-engineering&#34;&gt;Papers with Code&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/thunlp/PromptPapers#papers&#34;&gt;Prompt Papers&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Tools &amp;amp; Libraries&lt;/h2&gt; &#xA;&lt;h4&gt;(Sorted by Name)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aitestkitchen.withgoogle.com&#34;&gt;AI Test Kitchen&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/krrishdholakia/betterprompt&#34;&gt;betterprompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://beta.dreamstudio.ai&#34;&gt;DreamStudio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dust.tt&#34;&gt;DUST&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://trydyno.com&#34;&gt;Dyno&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.everyprompt.com&#34;&gt;EveryPrompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jerryjliu/gpt_index&#34;&gt;GPT Index&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpttools.com/comparisontool&#34;&gt;GPTTools&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hwchase17/adversarial-prompts&#34;&gt;hwchase17/adversarial-prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/oughtinc/ice&#34;&gt;Interactive Composition Explorer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.learngpt.com&#34;&gt;LearnGPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lexica.art&#34;&gt;Lexica&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/socketteer/loom&#34;&gt;loom&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://metaprompt.vercel.app/?task=gpt&#34;&gt;Metaprompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://beta.openai.com/playground&#34;&gt;OpenAI Playground&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/thunlp/OpenPrompt&#34;&gt;OpenPrompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://playgroundai.com&#34;&gt;Playground&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://app.prodia.com/#/&#34;&gt;Prodia&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://promptbase.com&#34;&gt;Prompt Base&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/prompt-engine&#34;&gt;Prompt Engine&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://dalle2-prompt-generator.s3-website-us-west-2.amazonaws.com&#34;&gt;Prompt Generator for OpenAI&#39;s DALL-E 2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://promptable.ai&#34;&gt;Promptable&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/agencyenterprise/PromptInject&#34;&gt;PromptInject&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sevazhidkov/prompts-ai&#34;&gt;Prompts.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://trypromptly.com/&#34;&gt;Promptly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bigscience-workshop/promptsource&#34;&gt;PromptSource&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://promptist.herokuapp.com/&#34;&gt;Promptist&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scale.com/spellbook&#34;&gt;Scale SpellBook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sharegpt.com&#34;&gt;sharegpt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/OpenBioLink/ThoughtSource&#34;&gt;ThoughtSource&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tools.saxifrage.xyz/prompt&#34;&gt;Visual Prompt Builder&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;h4&gt;(Sorted by Name)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/anthropics/hh-rlhf/tree/master/red-team-attempts&#34;&gt;Anthropic&#39;s Red Team dataset&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2209.07858&#34;&gt;(paper)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/fka/awesome-chatgpt-prompts&#34;&gt;Awesome ChatGPT Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/poloclub/diffusiondb&#34;&gt;DiffusionDB&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/succinctly/midjourney-prompts&#34;&gt;Midjourney Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/bigscience/P3&#34;&gt;P3 - Public Pool of Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://parti.research.google&#34;&gt;PartiPrompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://allenai.org/data/real-toxicity-prompts&#34;&gt;Real Toxicity Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/Gustavosta/Stable-Diffusion-Prompts&#34;&gt;Stable Diffusion Dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/WritingPrompts&#34;&gt;WritingPrompts&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Blog, Guides, Tutorials and Other Readings&lt;/h2&gt; &#xA;&lt;h4&gt;(Sorted by Name)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/3-principles-prompt-engineering-gpt-3-ben-whately&#34;&gt;3 Principles for prompt engineering with GPT-3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aitestkitchen.withgoogle.com/how-lamda-works&#34;&gt;A beginner-friendly guide to generative language models - LaMBDA guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mihaileric.com/posts/a-complete-introduction-to-prompt-engineering&#34;&gt;A Complete Introduction to Prompt Engineering for Large Language Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/@thorbjoern.heise/a-generic-framework-for-chatgpt-prompt-engineering-7097f6513a0b&#34;&gt;A Generic Framework for ChatGPT Prompt Engineering&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jonstokes.com/p/ai-content-generation-part-1-machine&#34;&gt;AI Content Generation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.axios.com/2023/02/22/chatgpt-prompt-engineers-ai-job&#34;&gt;AI&#39;s rise generates new job title: Prompt engineer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/f/awesome-chatgpt-prompts&#34;&gt;Awesome ChatGPT Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mpost.io/best-100-stable-diffusion-prompts-the-most-beautiful-ai-text-to-image-prompts&#34;&gt;Best 100+ Stable Diffusion Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api&#34;&gt;Best practices for prompt engineering with OpenAI API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/data-science-at-microsoft/building-gpt-3-applications-beyond-the-prompt-504140835560&#34;&gt;Building GPT-3 applications ‚Äî beyond the prompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpt3demo.com&#34;&gt;ChatGPT, AI and GPT-3 Apps and use cases&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=5ef83Wljm-M&amp;amp;feature=shares&#34;&gt;CMU Advanced NLP 2022: Prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gist.github.com/Curtis-64&#34;&gt;Curtis64&#39;s set of prompt gists&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/11WlzjBT0xRpQhP9tFMtxzd0q6ANIdHPUBkMV-YB043U/edit#&#34;&gt;DALL¬∑E 2 Prompt Engineering Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/dalle-2-preview/raw/main/system-card.md&#34;&gt;DALL¬∑E 2 Preview - Risks and Limitations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dallery.gallery/the-dalle-2-prompt-book&#34;&gt;DALLE Prompt Book&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.newyorker.com/magazine/2022/07/11/dall-e-make-me-another-picasso-please?&#34;&gt;DALL-E, Make Me Another Picasso, Please&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scale.com/guides/diffusion-models-guide&#34;&gt;Diffusion Models: A Practical Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/goodside/status/1569128808308957185&#34;&gt;Exploiting GPT-3 Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks&#34;&gt;Exploring Prompt Injection Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://ai.stanford.edu/blog/in-context-learning&#34;&gt;Extrapolating to Unnatural Language Processing with GPT-3&#39;s In-context Learning: The Good, the Bad, and the Mysterious&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://txt.cohere.ai/generative-ai-part-1&#34;&gt;Generative AI with Cohere: Part 1 - Model Prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html&#34;&gt;Giving GPT-3 a Turing Test&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=-lnHHWRCDGk&#34;&gt;GPT-3 &amp;amp; Beyond&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://buildspace.so/notes/intro-to-gpt3-prompts&#34;&gt;GPT3 and Prompts: A quick primer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://andys.page/posts/how-to-draw&#34;&gt;How to Draw Anything&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/StableDiffusion/comments/x41n87/how_to_get_images_that_dont_suck_a&#34;&gt;How to get images that don&#39;t suck&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://evanjconrad.com/posts/world-models&#34;&gt;How to make LLMs say true things&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://andymatuschak.org/prompts&#34;&gt;How to write good prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.surgehq.ai/blog/introduction-to-reinforcement-learning-with-human-feedback-rlhf-series-part-1&#34;&gt;Introduction to Reinforcement Learning with Human Feedback&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2023/Feb/21/in-defense-of-prompt-engineering/&#34;&gt;In defense of prompt engineering&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=OsbUfL8w-mo&amp;amp;feature=shares&#34;&gt;Language Models and Prompt Engineering: Systematic Survey of Prompting Methods in NLP&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learnprompting.org&#34;&gt;Learn Prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://generative.ink/posts/methods-of-prompt-programming&#34;&gt;Methods of prompt programming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/t9svvNPNmFf5Qa3TA/mysteries-of-mode-collapse&#34;&gt;Mysteries of mode collapse&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://heartbeat.comet.ml/nlp-for-text-to-image-generators-prompt-analysis-part-1-5076a44d8365&#34;&gt;NLP for Text-to-Image Generators: Prompt Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture11-prompting-rlhf.pdf&#34;&gt;NLP with Deep Learning CS224N/Ling284 - Lecture 11: Promting, Instruction Tuning, and RLHF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sw-yx/ai-notes&#34;&gt;Notes for Prompt Engineering by sw-yx&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook&#34;&gt;OpenAI Cookbook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/examples&#34;&gt;OpenAI Prompt Examples for several applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://pretrain.nlpedia.ai&#34;&gt;Pretrain, Prompt, Predict - A New Paradigm for NLP&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/prompt-engineering-101-introduction-resources-amatriain&#34;&gt;Prompt Engineering 101 - Introduction and resources&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=v2gD8BHOaX4&amp;amp;feature=shares&#34;&gt;Prompt Engineering 101: Autocomplete, Zero-shot, One-shot, and Few-shot prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://humanloop.com/blog/prompt-engineering-101&#34;&gt;Prompt Engineering 101&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=w102J3_9Bcs&amp;amp;ab_channel=PatrickDebois&#34;&gt;Prompt Engineering - A new profession ?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.cohere.ai/docs/prompt-engineering&#34;&gt;Prompt Engineering by co:here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoft.github.io/prompt-engineering&#34;&gt;Prompt Engineering by Microsoft&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shubhamsaboo111.medium.com/prompt-engineering-the-career-of-future-2fb93f90f117&#34;&gt;Prompt Engineering: The Career of Future&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.patterns.app/blog/2022/12/21/finetune-llm-tech-support&#34;&gt;Prompt engineering davinci-003 on our own docs for automated support (Part I)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://richardbatt.co.uk/prompt-engineering-guide-how-to-engineer-the-perfect-prompts&#34;&gt;Prompt Engineering Guide: How to Engineer the Perfect Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2022/05/prompt-engineering-in-gpt-3&#34;&gt;Prompt Engineering in GPT-3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/1-snKDn38-KypoYCk9XLPg799bHcNFSBAVu2HVvFEAkA/edit#gid=0&#34;&gt;Prompt Engineering Template&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/topics/prompt-engineering&#34;&gt;Prompt Engineering Topic by GitHub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.saxifrage.xyz/post/prompt-engineering&#34;&gt;Prompt Engineering: From Words to Art&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=BP9fi_0XTlw&amp;amp;feature=shares&#34;&gt;Prompt Engineering with OpenAI&#39;s GPT-3 and other LLMs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2022/Sep/12/prompt-injection&#34;&gt;Prompt injection attacks against GPT-3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/ludwig_stumpp/status/1619701277419794435?s=20&amp;amp;t=GtoMlmYCSt-UmvjqJVbBSA&#34;&gt;Prompt injection to read out the secret OpenAI API key&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://savasy-22028.medium.com/prompting-in-nlp-prompt-based-zero-shot-learning-3f34bfdb2b72&#34;&gt;Prompting in NLP: Prompt-based zero-shot learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://snorkel.ai/prompting-methods-with-language-models-nlp&#34;&gt;Prompting Methods with Language Models and Their Applications to Weak Supervision&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gwern.net/GPT-3#prompts-as-programming&#34;&gt;Prompts as Programming by Gwern&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lspace.swyx.io/p/reverse-prompt-eng&#34;&gt;Reverse Prompt Engineering for Fun and (no) Profit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://venturebeat.com/ai/so-you-want-to-be-a-prompt-engineer-critical-careers-of-the-future/&#34;&gt;So you want to be a prompt engineer: Critical careers of the future&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators&#34;&gt;Simulators&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://beta.openai.com/docs/quickstart/start-with-an-instruction&#34;&gt;Start with an Instruction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://artifact-research.com/artificial-intelligence/talking-to-machines-prompt-engineering-injection&#34;&gt;Talking to machines: prompt engineering &amp;amp; injection&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fedhoneypot.notion.site/25fdbdb69e9e44c6877d79e18336fe05?v=1d2bf4143680451986fd2836a04afbf4&#34;&gt;The Book - Fed Honeypot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/17b_ocq-GL5lhV_bYSShzUgxL02mtWDoiw9xEroJ5m3Q/edit#slide=id.gc6f83aa91_0_79&#34;&gt;The ChatGPT Prompt Book&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://deepfates.com/the-mirror-of-language&#34;&gt;The Mirror of Language&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=jqTkMpziGBU&amp;amp;feature=shares&#34;&gt;Unleash Your Creativity with Generative AI: Learn How to Build Innovative Products!&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.alignmentforum.org/posts/pNcFYZnPdXyL2RfgA/using-gpt-eliezer-against-chatgpt-jailbreaking&#34;&gt;Using GPT-Eliezer against ChatGPT Jailbreaking&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/&#34;&gt;What Is ChatGPT Doing ‚Ä¶ and Why Does It Work?&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;If you are using the guide for your work, please cite us as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{Saravia_Prompt_Engineering_Guide_2022,&#xA;author = {Saravia, Elvis},&#xA;journal = {https://github.com/dair-ai/Prompt-Engineering-Guide},&#xA;month = {12},&#xA;title = {{Prompt Engineering Guide}},&#xA;year = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Feel free to open a PR if you think something is missing here. Always welcome feedback and suggestions. Just open an issue!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>arpitbansal297/Universal-Guided-Diffusion</title>
    <updated>2023-02-26T01:57:24Z</updated>
    <id>tag:github.com,2023-02-26:/arpitbansal297/Universal-Guided-Diffusion</id>
    <link href="https://github.com/arpitbansal297/Universal-Guided-Diffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Universal Guidance for Diffusion Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/stable-diffusion-guided/data/images/all_cover_figure.png&#34; width=&#34;1000px&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The official PyTorch implementation of &lt;a href=&#34;https://arxiv.org/abs/2302.07121&#34;&gt;Universal Guidance for Diffusion Models&lt;/a&gt;. This repository has python implementation of universal guidance algorithm that enables controlling diffusion models by arbitrary guidance modalities without the need to retrain any use-specific components. Different guidance modalities we demonstrate are Human Identity, Segmentation Maps, Object Location, Image Style and Clip. Our implementation is based on the text-to-img model from &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt; and Imagenet Diffusion Model from &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;OpenAI&#39;s guided diffusion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Stable Diffusion&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd stable-diffusion-guided&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The code for stable diffusion is in &lt;code&gt;stable-diffusion-guided&lt;/code&gt;, and we use the &lt;code&gt;sd-v1-4.ckpt&lt;/code&gt; checkpoint. Download this model and use its location in the scripts.&lt;/p&gt; &#xA;&lt;h3&gt;Installations&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create -f environment.yaml&#xA;conda activate ldm&#xA;conda install pytorch torchvision cudatoolkit=11.3 -c pytorch&#xA;pip install GPUtil&#xA;pip install blobfile&#xA;pip install facenet-pytorch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For each of the guidance below, we can control the image generation by changing the following arguments. &lt;br&gt; &lt;code&gt;--optim_original_conditioning&lt;/code&gt; enables the original text conditioning &lt;br&gt; &lt;code&gt;--optim_forward_guidance&lt;/code&gt; enables the forward universal guidance &lt;br&gt; &lt;code&gt;--optim_backward_guidance&lt;/code&gt; enables the backward universal guidance &lt;br&gt; &lt;code&gt;--ddim_steps&lt;/code&gt; sets the number of diffusion steps involved &lt;br&gt; &lt;code&gt;--optim_num_steps&lt;/code&gt; sets the number of recurrent steps &lt;br&gt; &lt;code&gt;--optim_forward_guidance_wt&lt;/code&gt; sets the constant in s(t)&lt;/p&gt; &#xA;&lt;p&gt;We now provide the arguments that produces our results for each of the guidance. For each guidance we show only for one of the guiding images but can easily be changed to others by changing the argument &lt;code&gt;--indexes&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Face Recognition&lt;/h3&gt; &#xA;&lt;p&gt;In this we generate images conditioned on the text and guided by the face identity.&lt;br&gt; The following script will take the human face from &lt;code&gt;./data/face_data/celeb/&lt;/code&gt; and use it to guide the image generation conditioned on the given text prompt, set by &lt;code&gt;--text&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir test_face&#xA;python scripts/face_detection.py --indexes 0 --text &#34;Headshot of a person with blonde hair with space background&#34; --optim_forward_guidance --fr_crop --optim_num_steps 2 --optim_forward_guidance_wt 20000 --optim_original_conditioning --ddim_steps 500 --optim_folder ./test_face/text_type_4/ --ckpt &amp;lt;Path to stable diffusion model&amp;gt;&#xA;python scripts/face_detection.py --indexes 0 --text &#34;A headshot of a woman looking like a lara croft&#34; --optim_forward_guidance --fr_crop --optim_num_steps 2 --optim_forward_guidance_wt 20000 --optim_original_conditioning --ddim_steps 500 --optim_folder ./test_face/text_type_11/ --ckpt &amp;lt;Path to stable diffusion model&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above script will produce 20 images from which one can get the top k images based on face recognition models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/face_top_k.py --folder ./test_face/text_type_4/ --img_index 0 --img_saved 20 --top_k 5&#xA;python scripts/face_top_k.py --folder ./test_face/text_type_11/ --img_index 0 --img_saved 20 --top_k 5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some of the results produced for both the texts are as follows - the first image is the guiding image and rest are the generated images.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/stable-diffusion-guided/data/images/App/Face/row_1_1.png&#34; width=&#34;1000px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/stable-diffusion-guided/data/images/App/Face/row_1_2.png&#34; width=&#34;1000px&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Segmentation&lt;/h3&gt; &#xA;&lt;p&gt;In this we generate images conditioned on the text and guided by the segmentation map.&lt;br&gt; The following script will take the images of dogs from &lt;code&gt;./data/segmentation_data/Walker/&lt;/code&gt; to create the segmentation map. This segmentation map is then used to guide the image generation conditioned on the given text prompt, set by &lt;code&gt;--text&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir test_segmentation&#xA;python scripts/segmentation.py --indexes 1 --text &#34;Walker hound, Walker foxhound on snow&#34; --scale 1.5 --optim_forward_guidance --optim_num_steps 10 --optim_forward_guidance_wt 400 --optim_original_conditioning --ddim_steps 500 --optim_folder ./test_segmentation/text_type_4/ --ckpt &amp;lt;Path to stable diffusion model&amp;gt;&#xA;python scripts/segmentation.py --indexes 1 --text &#34;Walker hound, Walker foxhound as an oil painting&#34; --scale 2.0 --optim_forward_guidance --optim_num_steps 10 --optim_forward_guidance_wt 400 --optim_original_conditioning --ddim_steps 500 --optim_folder ./test_segmentation/text_type_3/ --ckpt &amp;lt;Path to stable diffusion model&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some of the results produced for both the texts are as follows - the first image is the guiding image and rest are the generated images.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/stable-diffusion-guided/data/images/App/Seg/row_1.png&#34; width=&#34;1000px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/stable-diffusion-guided/data/images/App/Seg/row_3.png&#34; width=&#34;1000px&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Object Detection&lt;/h3&gt; &#xA;&lt;p&gt;In this we generate images conditioned on the text and guided by the bounding boxes of different objects. The following script will take the first sample bounding boxe in &lt;code&gt;scripts/object_detection.py&lt;/code&gt;. The bounding boxes are then used to guide the image generation conditioned on the given text prompt, set by &lt;code&gt;--text&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir test_od&#xA;python scripts/segmentation.py --indexes 0 --text &#34;a headshot of a woman with a dog&#34; --scale 1.5 --optim_forward_guidance --optim_num_steps 5 --optim_forward_guidance_wt 100 --optim_original_conditioning --ddim_steps 250 --optim_folder ./test_od/ --ckpt &amp;lt;Path to stable diffusion model&amp;gt;&#xA;python scripts/segmentation.py --indexes 0 --text &#34;a headshot of a woman with a dog on beach&#34; --scale 1.5 --optim_forward_guidance --optim_num_steps 5 --optim_forward_guidance_wt 100 --optim_original_conditioning --ddim_steps 250 --optim_folder ./test_od/ --ckpt &amp;lt;Path to stable diffusion model&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some of the results produced for both the texts are as follows - the first image shows the given boxes and rest are the generated images.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/stable-diffusion-guided/data/images/App/OD/row_2_1.png&#34; width=&#34;1000px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/stable-diffusion-guided/data/images/App/OD/row_2_2.png&#34; width=&#34;1000px&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Style Transfer&lt;/h3&gt; &#xA;&lt;p&gt;In this we generate images conditioned on the text and guided by the target image style.&lt;br&gt; The following script will take the styling images from &lt;code&gt;./data/style_folder/styles/&lt;/code&gt; and use it to guide the image generation conditioned on the given text prompt, set by &lt;code&gt;--text&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir test_segmentation&#xA;python scripts/style_transfer.py --indexes 0 --text &#34;A colorful photo of a eiffel tower&#34; --scale 3.0 --optim_forward_guidance --optim_num_steps 6 --optim_forward_guidance_wt 6 --optim_original_conditioning --ddim_steps 500 --optim_folder ./test_style/text_type_1/ --ckpt &amp;lt;Path to stable diffusion model&amp;gt;&#xA;python scripts/style_transfer.py --indexes 0 --text &#34;A fantasy photo of volcanoes&#34; --scale 3.0 --optim_forward_guidance --optim_num_steps 6 --optim_forward_guidance_wt 6 --optim_original_conditioning --ddim_steps 500 --optim_folder ./test_style/text_type_2/ --ckpt &amp;lt;Path to stable diffusion model&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Some of the results produced for both the texts are as follows - the first image is the guiding image and rest are the generated images.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/stable-diffusion-guided/data/images/App/Style_Transfer/appendix_text_type_8_img_style_0.png&#34; width=&#34;1000px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/stable-diffusion-guided/data/images/App/Style_Transfer/appendix_text_type_16_img_style_0.png&#34; width=&#34;1000px&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Imagenet Diffusion&lt;/h2&gt; &#xA;&lt;p&gt;In this we show scripts that can be used to run the experiments for image generation trained on imagenet.&lt;/p&gt; &#xA;&lt;h3&gt;Clip guided&lt;/h3&gt; &#xA;&lt;p&gt;In this one can use the text encoding from clip to guide image generation. This leads to diffusion model generating images which are either out-of-distribution as well. Make sure to download the diffusion model from &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;OpenAI&#39;s guided diffusion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python Guided/Clip_guided.py --trials 5 --samples_per_diffusion 2 --text &#34;English foxhound by Edward Hopper&#34; --optim_forward_guidance --optim_forward_guidance_wt 2.0 --optim_num_steps 10 --optim_folder ./Clip_btd_cake/ --batch_size 8 --attention_resolutions 32,16,8 --class_cond False --diffusion_steps 1000 --image_size 256 --learn_sigma True --noise_schedule linear --num_channels 256 --num_head_channels 64 --num_res_blocks 2 --resblock_updown True --use_fp16 False --use_scale_shift_norm True --model_path &amp;lt;Path to the unconditional diffusion model&amp;gt;&#xA;python Guided/Clip_guided.py --trials 5 --samples_per_diffusion 2 --text &#34;Van Gogh Style&#34; --optim_forward_guidance --optim_forward_guidance_wt 5.0 --optim_num_steps 5 --optim_folder ./Clip_btd_cake/ --batch_size 8 --attention_resolutions 32,16,8 --class_cond False --diffusion_steps 1000 --image_size 256 --learn_sigma True --noise_schedule linear --num_channels 256 --num_head_channels 64 --num_res_blocks 2 --resblock_updown True --use_fp16 False --use_scale_shift_norm True --model_path &amp;lt;Path to the unconditional diffusion model&amp;gt;&#xA;python Guided/Clip_guided.py --trials 5 --samples_per_diffusion 2 --text &#34;Birthday Cake&#34; --optim_forward_guidance --optim_forward_guidance_wt 2.0 --optim_num_steps 10 --optim_folder ./Clip_btd_cake/ --batch_size 8 --attention_resolutions 32,16,8 --class_cond False --diffusion_steps 1000 --image_size 256 --learn_sigma True --noise_schedule linear --num_channels 256 --num_head_channels 64 --num_res_blocks 2 --resblock_updown True --use_fp16 False --use_scale_shift_norm True --model_path &amp;lt;Path to the unconditional diffusion model&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arpitbansal297/Universal-Guided-Diffusion/main/Guided_Diffusion_Imagenet/images_readme/imgnet_ood.png&#34; width=&#34;1000px&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>fastai/numerical-linear-algebra</title>
    <updated>2023-02-26T01:57:24Z</updated>
    <id>tag:github.com,2023-02-26:/fastai/numerical-linear-algebra</id>
    <link href="https://github.com/fastai/numerical-linear-algebra" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Free online textbook of Jupyter notebooks for fast.ai Computational Linear Algebra course&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Computational Linear Algebra for Coders&lt;/h2&gt; &#xA;&lt;p&gt;This course is focused on the question: &lt;strong&gt;How do we do matrix computations with acceptable speed and acceptable accuracy?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;This course was taught in the &lt;a href=&#34;https://www.usfca.edu/arts-sciences/graduate-programs/analytics&#34;&gt;University of San Francisco&#39;s Masters of Science in Analytics&lt;/a&gt; program, summer 2017 (for graduate students studying to become data scientists). The course is taught in Python with Jupyter Notebooks, using libraries such as Scikit-Learn and Numpy for most lessons, as well as Numba (a library that compiles Python to C for faster performance) and PyTorch (an alternative to Numpy for the GPU) in a few lessons.&lt;/p&gt; &#xA;&lt;p&gt;Accompanying the notebooks is a &lt;a href=&#34;https://www.youtube.com/playlist?list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;playlist of lecture videos, available on YouTube&lt;/a&gt;. If you are ever confused by a lecture or it goes too quickly, check out the beginning of the next video, where I review concepts from the previous lecture, often explaining things from a new perspective or with different illustrations, and answer questions.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Help&lt;/h2&gt; &#xA;&lt;p&gt;You can ask questions or share your thoughts and resources using the &lt;a href=&#34;http://forums.fast.ai/c/lin-alg&#34;&gt;&lt;strong&gt;Computational Linear Algebra&lt;/strong&gt; category on our fast.ai discussion forums&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;p&gt;The following listing links to the notebooks in this repository, rendered through the &lt;a href=&#34;http://nbviewer.jupyter.org&#34;&gt;nbviewer&lt;/a&gt; service. Topics Covered:&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/0.%20Course%20Logistics.ipynb&#34;&gt;0. Course Logistics&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=8iGzBMboA0I&amp;amp;index=1&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;Video 1&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/0.%20Course%20Logistics.ipynb#Intro&#34;&gt;My background&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/0.%20Course%20Logistics.ipynb#Teaching&#34;&gt;Teaching Approach&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/0.%20Course%20Logistics.ipynb#Writing-Assignment&#34;&gt;Importance of Technical Writing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/0.%20Course%20Logistics.ipynb#Excellent-Technical-Blogs&#34;&gt;List of Excellent Technical Blogs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/0.%20Course%20Logistics.ipynb#Linear-Algebra&#34;&gt;Linear Algebra Review Resources&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb&#34;&gt;1. Why are we here?&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=8iGzBMboA0I&amp;amp;index=1&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;Video 1&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;We start with a high level overview of some foundational concepts in numerical linear algebra.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb#Matrix-and-Tensor-Products&#34;&gt;Matrix and Tensor Products&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb#Matrix-Decompositions&#34;&gt;Matrix Decompositions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb#Accuracy&#34;&gt;Accuracy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb#Memory-Use&#34;&gt;Memory use&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb#Speed&#34;&gt;Speed&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb#Scalability-/-parallelization&#34;&gt;Parallelization &amp;amp; Vectorization&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/2.%20Topic%20Modeling%20with%20NMF%20and%20SVD.ipynb&#34;&gt;2. Topic Modeling with NMF and SVD&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=kgd40iDT8yY&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&amp;amp;index=2&#34;&gt;Video 2&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=C8KEtrWjjyo&amp;amp;index=3&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;Video 3&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;We will use the newsgroups dataset to try to identify the topics of different posts. We use a term-document matrix that represents the frequency of the vocabulary in the documents. We factor it using NMF, and then with SVD.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/2.%20Topic%20Modeling%20with%20NMF%20and%20SVD.ipynb#TF-IDF&#34;&gt;Topic Frequency-Inverse Document Frequency (TF-IDF)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/2.%20Topic%20Modeling%20with%20NMF%20and%20SVD.ipynb#Singular-Value-Decomposition-(SVD)&#34;&gt;Singular Value Decomposition (SVD)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/2.%20Topic%20Modeling%20with%20NMF%20and%20SVD.ipynb#Non-negative-Matrix-Factorization-(NMF)&#34;&gt;Non-negative Matrix Factorization (NMF)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/2.%20Topic%20Modeling%20with%20NMF%20and%20SVD.ipynb#Gradient-Descent&#34;&gt;Stochastic Gradient Descent (SGD)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/2.%20Topic%20Modeling%20with%20NMF%20and%20SVD.ipynb#PyTorch&#34;&gt;Intro to PyTorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/2.%20Topic%20Modeling%20with%20NMF%20and%20SVD.ipynb#Truncated-SVD&#34;&gt;Truncated SVD&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb&#34;&gt;3. Background Removal with Robust PCA&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=C8KEtrWjjyo&amp;amp;index=3&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;Video 3&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=Ys8R2nUTOAk&amp;amp;index=4&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;Video 4&lt;/a&gt;, and &lt;a href=&#34;https://www.youtube.com/watch?v=O2x5KPJr5ag&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&amp;amp;index=5&#34;&gt;Video 5&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;Another application of SVD is to identify the people and remove the background of a surveillance video. We will cover robust PCA, which uses randomized SVD. And Randomized SVD uses the LU factorization.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb#Load-and-view-the-data&#34;&gt;Load and View Video Data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb#SVD&#34;&gt;SVD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/fastai/numerical-linear-algebra/raw/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb&#34;&gt;Principal Component Analysis (PCA)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb#L1-norm-induces-sparsity&#34;&gt;L1 Norm Induces Sparsity&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb#Robust-PCA-(via-Primary-Component-Pursuit)&#34;&gt;Robust PCA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb#LU-Factorization&#34;&gt;LU factorization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb#Stability&#34;&gt;Stability of LU&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb#LU-factorization-with-Partial-Pivoting&#34;&gt;LU factorization with Pivoting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb#History-of-Gaussian-Elimination&#34;&gt;History of Gaussian Elimination&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/3.%20Background%20Removal%20with%20Robust%20PCA.ipynb#Block-Matrices&#34;&gt;Block Matrix Multiplication&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/4.%20Compressed%20Sensing%20of%20CT%20Scans%20with%20Robust%20Regression.ipynb#4.-Compressed-Sensing-of-CT-Scans-with-Robust-Regression&#34;&gt;4. Compressed Sensing with Robust Regression&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=YY9_EYNj5TY&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&amp;amp;index=6&#34;&gt;Video 6&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=ZUGkvIM6ehM&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&amp;amp;index=7&#34;&gt;Video 7&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;Compressed sensing is critical to allowing CT scans with lower radiation-- the image can be reconstructed with less data. Here we will learn the technique and apply it to CT images.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/4.%20Compressed%20Sensing%20of%20CT%20Scans%20with%20Robust%20Regression.ipynb#Broadcasting&#34;&gt;Broadcasting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/4.%20Compressed%20Sensing%20of%20CT%20Scans%20with%20Robust%20Regression.ipynb#Sparse-Matrices-(in-Scipy)&#34;&gt;Sparse matrices&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/4.%20Compressed%20Sensing%20of%20CT%20Scans%20with%20Robust%20Regression.ipynb#Sparse-Matrices-(in-Scipy)&#34;&gt;CT Scans and Compressed Sensing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/4.%20Compressed%20Sensing%20of%20CT%20Scans%20with%20Robust%20Regression.ipynb#Regresssion&#34;&gt;L1 and L2 regression&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/5.%20Health%20Outcomes%20with%20Linear%20Regression.ipynb&#34;&gt;5. Predicting Health Outcomes with Linear Regressions&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=SjX55V8zDXI&amp;amp;index=8&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;Video 8&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/5.%20Health%20Outcomes%20with%20Linear%20Regression.ipynb#Linear-regression-in-Scikit-Learn&#34;&gt;Linear regression in sklearn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/5.%20Health%20Outcomes%20with%20Linear%20Regression.ipynb#Polynomial-Features&#34;&gt;Polynomial Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/5.%20Health%20Outcomes%20with%20Linear%20Regression.ipynb#Speeding-up-feature-generation&#34;&gt;Speeding up with Numba&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/5.%20Health%20Outcomes%20with%20Linear%20Regression.ipynb#Regularization-and-noise&#34;&gt;Regularization and Noise&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb&#34;&gt;6. How to Implement Linear Regression&lt;/a&gt;(&lt;a href=&#34;https://www.youtube.com/watch?v=SjX55V8zDXI&amp;amp;index=8&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;Video 8&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#How-did-sklearn-do-it?&#34;&gt;How did Scikit Learn do it?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#Naive-Solution&#34;&gt;Naive solution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#Normal-Equations-(Cholesky)&#34;&gt;Normal equations and Cholesky factorization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#QR-Factorization&#34;&gt;QR factorization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#SVD&#34;&gt;SVD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#Timing-Comparison&#34;&gt;Timing Comparison&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#Conditioning-&amp;amp;-stability&#34;&gt;Conditioning &amp;amp; Stability&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#Full-vs-Reduced-Factorizations&#34;&gt;Full vs Reduced Factorizations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#Matrix-Inversion-is-Unstable&#34;&gt;Matrix Inversion is Unstable&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/7.%20PageRank%20with%20Eigen%20Decompositions.ipynb&#34;&gt;7. PageRank with Eigen Decompositions&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=AbB-w77yxD0&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&amp;amp;index=9&#34;&gt;Video 9&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=1kw8bpA9QmQ&amp;amp;index=10&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;Video 10&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;We have applied SVD to topic modeling, background removal, and linear regression. SVD is intimately connected to the eigen decomposition, so we will now learn how to calculate eigenvalues for a large matrix. We will use DBpedia data, a large dataset of Wikipedia links, because here the principal eigenvector gives the relative importance of different Wikipedia pages (this is the basic idea of Google&#39;s PageRank algorithm). We will look at 3 different methods for calculating eigenvectors, of increasing complexity (and increasing usefulness!).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/7.%20PageRank%20with%20Eigen%20Decompositions.ipynb#Motivation&#34;&gt;SVD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/7.%20PageRank%20with%20Eigen%20Decompositions.ipynb#DBpedia&#34;&gt;DBpedia Dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/7.%20PageRank%20with%20Eigen%20Decompositions.ipynb#Power-method&#34;&gt;Power Method&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/7.%20PageRank%20with%20Eigen%20Decompositions.ipynb#QR-Algorithm&#34;&gt;QR Algorithm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/7.%20PageRank%20with%20Eigen%20Decompositions.ipynb#A-Two-Phase-Approach&#34;&gt;Two-phase approach to finding eigenvalues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/7.%20PageRank%20with%20Eigen%20Decompositions.ipynb#Arnoldi-Iteration&#34;&gt;Arnoldi Iteration&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/8.%20Implementing%20QR%20Factorization.ipynb&#34;&gt;8. Implementing QR Factorization&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=1kw8bpA9QmQ&amp;amp;index=10&amp;amp;list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY&#34;&gt;Video 10&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/8.%20Implementing%20QR%20Factorization.ipynb#Gram-Schmidt&#34;&gt;Gram-Schmidt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/8.%20Implementing%20QR%20Factorization.ipynb#Householder&#34;&gt;Householder&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/8.%20Implementing%20QR%20Factorization.ipynb#Ex-9.2:-Classical-vs-Modified-Gram-Schmidt&#34;&gt;Stability Examples&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Why is this course taught in such a weird order?&lt;/h2&gt; &#xA;&lt;p&gt;This course is structured with a &lt;em&gt;top-down&lt;/em&gt; teaching method, which is different from how most math courses operate. Typically, in a &lt;em&gt;bottom-up&lt;/em&gt; approach, you first learn all the separate components you will be using, and then you gradually build them up into more complex structures. The problems with this are that students often lose motivation, don&#39;t have a sense of the &#34;big picture&#34;, and don&#39;t know what they&#39;ll need.&lt;/p&gt; &#xA;&lt;p&gt;Harvard Professor David Perkins has a book, &lt;a href=&#34;https://www.amazon.com/Making-Learning-Whole-Principles-Transform/dp/0470633719&#34;&gt;Making Learning Whole&lt;/a&gt; in which he uses baseball as an analogy. We don&#39;t require kids to memorize all the rules of baseball and understand all the technical details before we let them play the game. Rather, they start playing with a just general sense of it, and then gradually learn more rules/details as time goes on.&lt;/p&gt; &#xA;&lt;p&gt;If you took the fast.ai deep learning course, that is what we used. You can hear more about my teaching philosophy &lt;a href=&#34;http://www.fast.ai/2016/10/08/teaching-philosophy/&#34;&gt;in this blog post&lt;/a&gt; or &lt;a href=&#34;https://vimeo.com/214233053&#34;&gt;this talk I gave at the San Francisco Machine Learning meetup&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;All that to say, don&#39;t worry if you don&#39;t understand everything at first! You&#39;re not supposed to. We will start using some &#34;black boxes&#34; or matrix decompositions that haven&#39;t yet been explained, and then we&#39;ll dig into the lower level details later.&lt;/p&gt; &#xA;&lt;p&gt;To start, focus on what things DO, not what they ARE.&lt;/p&gt;</summary>
  </entry>
</feed>