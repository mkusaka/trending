<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-07T02:12:07Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>pesser/stable-diffusion</title>
    <updated>2022-08-07T02:12:07Z</updated>
    <id>tag:github.com,2022-08-07:/pesser/stable-diffusion</id>
    <link href="https://github.com/pesser/stable-diffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Latent Diffusion Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.10752&#34;&gt;arXiv&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/#bibtex&#34;&gt;BibTeX&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/assets/results.gif&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.10752&#34;&gt;&lt;strong&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/strong&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/rromb&#34;&gt;Robin Rombach&lt;/a&gt;*, &lt;a href=&#34;https://github.com/ablattmann&#34;&gt;Andreas Blattmann&lt;/a&gt;*, &lt;a href=&#34;https://github.com/qp-qp&#34;&gt;Dominik Lorenz&lt;/a&gt;, &lt;a href=&#34;https://github.com/pesser&#34;&gt;Patrick Esser&lt;/a&gt;, &lt;a href=&#34;https://hci.iwr.uni-heidelberg.de/Staff/bommer&#34;&gt;Bj√∂rn Ommer&lt;/a&gt;&lt;br&gt; * equal contribution&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/assets/modelfigure.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;h3&gt;April 2022&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Thanks to &lt;a href=&#34;https://github.com/crowsonkb&#34;&gt;Katherine Crowson&lt;/a&gt;, classifier-free guidance received a ~2x speedup and the &lt;a href=&#34;https://arxiv.org/abs/2202.09778&#34;&gt;PLMS sampler&lt;/a&gt; is available. See also &lt;a href=&#34;https://github.com/CompVis/latent-diffusion/pull/51&#34;&gt;this PR&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Our 1.45B &lt;a href=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/#text-to-image&#34;&gt;latent diffusion LAION model&lt;/a&gt; was integrated into &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;Huggingface Spaces ü§ó&lt;/a&gt; using &lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;Gradio&lt;/a&gt;. Try out the Web Demo: &lt;a href=&#34;https://huggingface.co/spaces/multimodalart/latentdiffusion&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;More pre-trained LDMs are available:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A 1.45B &lt;a href=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/#text-to-image&#34;&gt;model&lt;/a&gt; trained on the &lt;a href=&#34;https://arxiv.org/abs/2111.02114&#34;&gt;LAION-400M&lt;/a&gt; database.&lt;/li&gt; &#xA;   &lt;li&gt;A class-conditional model on ImageNet, achieving a FID of 3.6 when using &lt;a href=&#34;https://openreview.net/pdf?id=qw8AKxfYbI&#34;&gt;classifier-free guidance&lt;/a&gt; Available via a &lt;a href=&#34;https://colab.research.google.com/github/CompVis/latent-diffusion/blob/main/scripts/latent_imagenet_diffusion.ipynb&#34;&gt;colab notebook&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/CompVis/latent-diffusion/blob/main/scripts/latent_imagenet_diffusion.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;A suitable &lt;a href=&#34;https://conda.io/&#34;&gt;conda&lt;/a&gt; environment named &lt;code&gt;ldm&lt;/code&gt; can be created and activated with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create -f environment.yaml&#xA;conda activate ldm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Pretrained Models&lt;/h1&gt; &#xA;&lt;p&gt;A general list of all available checkpoints is available in via our &lt;a href=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/#model-zoo&#34;&gt;model zoo&lt;/a&gt;. If you use any of these models in your work, we are always happy to receive a &lt;a href=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/#bibtex&#34;&gt;citation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Text-to-Image&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/assets/txt2img-preview.png&#34; alt=&#34;text2img-figure&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Download the pre-trained weights (5.7GB)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir -p models/ldm/text2img-large/&#xA;wget -O models/ldm/text2img-large/model.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and sample with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/txt2img.py --prompt &#34;a virus monster is playing guitar, oil on canvas&#34; --ddim_eta 0.0 --n_samples 4 --n_iter 4 --scale 5.0  --ddim_steps 50&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will save each sample individually as well as a grid of size &lt;code&gt;n_iter&lt;/code&gt; x &lt;code&gt;n_samples&lt;/code&gt; at the specified output location (default: &lt;code&gt;outputs/txt2img-samples&lt;/code&gt;). Quality, sampling speed and diversity are best controlled via the &lt;code&gt;scale&lt;/code&gt;, &lt;code&gt;ddim_steps&lt;/code&gt; and &lt;code&gt;ddim_eta&lt;/code&gt; arguments. As a rule of thumb, higher values of &lt;code&gt;scale&lt;/code&gt; produce better samples at the cost of a reduced output diversity.&lt;br&gt; Furthermore, increasing &lt;code&gt;ddim_steps&lt;/code&gt; generally also gives higher quality samples, but returns are diminishing for values &amp;gt; 250. Fast sampling (i.e. low values of &lt;code&gt;ddim_steps&lt;/code&gt;) while retaining good quality can be achieved by using &lt;code&gt;--ddim_eta 0.0&lt;/code&gt;.&lt;br&gt; Faster sampling (i.e. even lower values of &lt;code&gt;ddim_steps&lt;/code&gt;) while retaining good quality can be achieved by using &lt;code&gt;--ddim_eta 0.0&lt;/code&gt; and &lt;code&gt;--plms&lt;/code&gt; (see &lt;a href=&#34;https://arxiv.org/abs/2202.09778&#34;&gt;Pseudo Numerical Methods for Diffusion Models on Manifolds&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h4&gt;Beyond 256¬≤&lt;/h4&gt; &#xA;&lt;p&gt;For certain inputs, simply running the model in a convolutional fashion on larger features than it was trained on can sometimes result in interesting results. To try it out, tune the &lt;code&gt;H&lt;/code&gt; and &lt;code&gt;W&lt;/code&gt; arguments (which will be integer-divided by 8 in order to calculate the corresponding latent size), e.g. run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/txt2img.py --prompt &#34;a sunset behind a mountain range, vector image&#34; --ddim_eta 1.0 --n_samples 1 --n_iter 1 --H 384 --W 1024 --scale 5.0  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to create a sample of size 384x1024. Note, however, that controllability is reduced compared to the 256x256 setting.&lt;/p&gt; &#xA;&lt;p&gt;The example below was generated using the above command. &lt;img src=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/assets/txt2img-convsample.png&#34; alt=&#34;text2img-figure-conv&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Inpainting&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/assets/inpainting.png&#34; alt=&#34;inpainting&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Download the pre-trained weights&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;wget -O models/ldm/inpainting_big/last.ckpt https://heibox.uni-heidelberg.de/f/4d9ac7ea40c64582b7c9/?dl=1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and sample with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/inpaint.py --indir data/inpainting_examples/ --outdir outputs/inpainting_results&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;indir&lt;/code&gt; should contain images &lt;code&gt;*.png&lt;/code&gt; and masks &lt;code&gt;&amp;lt;image_fname&amp;gt;_mask.png&lt;/code&gt; like the examples provided in &lt;code&gt;data/inpainting_examples&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Class-Conditional ImageNet&lt;/h2&gt; &#xA;&lt;p&gt;Available via a &lt;a href=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/scripts/latent_imagenet_diffusion.ipynb&#34;&gt;notebook&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/CompVis/latent-diffusion/blob/main/scripts/latent_imagenet_diffusion.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt;. &lt;img src=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/assets/birdhouse.png&#34; alt=&#34;class-conditional&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Unconditional Models&lt;/h2&gt; &#xA;&lt;p&gt;We also provide a script for sampling from unconditional LDMs (e.g. LSUN, FFHQ, ...). Start it via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;CUDA_VISIBLE_DEVICES=&amp;lt;GPU_ID&amp;gt; python scripts/sample_diffusion.py -r models/ldm/&amp;lt;model_spec&amp;gt;/model.ckpt -l &amp;lt;logdir&amp;gt; -n &amp;lt;\#samples&amp;gt; --batch_size &amp;lt;batch_size&amp;gt; -c &amp;lt;\#ddim steps&amp;gt; -e &amp;lt;\#eta&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Train your own LDMs&lt;/h1&gt; &#xA;&lt;h2&gt;Data preparation&lt;/h2&gt; &#xA;&lt;h3&gt;Faces&lt;/h3&gt; &#xA;&lt;p&gt;For downloading the CelebA-HQ and FFHQ datasets, proceed as described in the &lt;a href=&#34;https://github.com/CompVis/taming-transformers#celeba-hq&#34;&gt;taming-transformers&lt;/a&gt; repository.&lt;/p&gt; &#xA;&lt;h3&gt;LSUN&lt;/h3&gt; &#xA;&lt;p&gt;The LSUN datasets can be conveniently downloaded via the script available &lt;a href=&#34;https://github.com/fyu/lsun&#34;&gt;here&lt;/a&gt;. We performed a custom split into training and validation images, and provide the corresponding filenames at &lt;a href=&#34;https://ommer-lab.com/files/lsun.zip&#34;&gt;https://ommer-lab.com/files/lsun.zip&lt;/a&gt;. After downloading, extract them to &lt;code&gt;./data/lsun&lt;/code&gt;. The beds/cats/churches subsets should also be placed/symlinked at &lt;code&gt;./data/lsun/bedrooms&lt;/code&gt;/&lt;code&gt;./data/lsun/cats&lt;/code&gt;/&lt;code&gt;./data/lsun/churches&lt;/code&gt;, respectively.&lt;/p&gt; &#xA;&lt;h3&gt;ImageNet&lt;/h3&gt; &#xA;&lt;p&gt;The code will try to download (through &lt;a href=&#34;http://academictorrents.com/&#34;&gt;Academic Torrents&lt;/a&gt;) and prepare ImageNet the first time it is used. However, since ImageNet is quite large, this requires a lot of disk space and time. If you already have ImageNet on your disk, you can speed things up by putting the data into &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/&lt;/code&gt; (which defaults to &lt;code&gt;~/.cache/autoencoders/data/ILSVRC2012_{split}/data/&lt;/code&gt;), where &lt;code&gt;{split}&lt;/code&gt; is one of &lt;code&gt;train&lt;/code&gt;/&lt;code&gt;validation&lt;/code&gt;. It should have the following structure:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/&#xA;‚îú‚îÄ‚îÄ n01440764&#xA;‚îÇ   ‚îú‚îÄ‚îÄ n01440764_10026.JPEG&#xA;‚îÇ   ‚îú‚îÄ‚îÄ n01440764_10027.JPEG&#xA;‚îÇ   ‚îú‚îÄ‚îÄ ...&#xA;‚îú‚îÄ‚îÄ n01443537&#xA;‚îÇ   ‚îú‚îÄ‚îÄ n01443537_10007.JPEG&#xA;‚îÇ   ‚îú‚îÄ‚îÄ n01443537_10014.JPEG&#xA;‚îÇ   ‚îú‚îÄ‚îÄ ...&#xA;‚îú‚îÄ‚îÄ ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you haven&#39;t extracted the data, you can also place &lt;code&gt;ILSVRC2012_img_train.tar&lt;/code&gt;/&lt;code&gt;ILSVRC2012_img_val.tar&lt;/code&gt; (or symlinks to them) into &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_train/&lt;/code&gt; / &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_validation/&lt;/code&gt;, which will then be extracted into above structure without downloading it again. Note that this will only happen if neither a folder &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/&lt;/code&gt; nor a file &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/.ready&lt;/code&gt; exist. Remove them if you want to force running the dataset preparation again.&lt;/p&gt; &#xA;&lt;h2&gt;Model Training&lt;/h2&gt; &#xA;&lt;p&gt;Logs and checkpoints for trained models are saved to &lt;code&gt;logs/&amp;lt;START_DATE_AND_TIME&amp;gt;_&amp;lt;config_spec&amp;gt;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Training autoencoder models&lt;/h3&gt; &#xA;&lt;p&gt;Configs for training a KL-regularized autoencoder on ImageNet are provided at &lt;code&gt;configs/autoencoder&lt;/code&gt;. Training can be started by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=&amp;lt;GPU_ID&amp;gt; python main.py --base configs/autoencoder/&amp;lt;config_spec&amp;gt;.yaml -t --gpus 0,    &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;config_spec&lt;/code&gt; is one of {&lt;code&gt;autoencoder_kl_8x8x64&lt;/code&gt;(f=32, d=64), &lt;code&gt;autoencoder_kl_16x16x16&lt;/code&gt;(f=16, d=16), &lt;code&gt;autoencoder_kl_32x32x4&lt;/code&gt;(f=8, d=4), &lt;code&gt;autoencoder_kl_64x64x3&lt;/code&gt;(f=4, d=3)}.&lt;/p&gt; &#xA;&lt;p&gt;For training VQ-regularized models, see the &lt;a href=&#34;https://github.com/CompVis/taming-transformers&#34;&gt;taming-transformers&lt;/a&gt; repository.&lt;/p&gt; &#xA;&lt;h3&gt;Training LDMs&lt;/h3&gt; &#xA;&lt;p&gt;In &lt;code&gt;configs/latent-diffusion/&lt;/code&gt; we provide configs for training LDMs on the LSUN-, CelebA-HQ, FFHQ and ImageNet datasets. Training can be started by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;CUDA_VISIBLE_DEVICES=&amp;lt;GPU_ID&amp;gt; python main.py --base configs/latent-diffusion/&amp;lt;config_spec&amp;gt;.yaml -t --gpus 0,&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;&amp;lt;config_spec&amp;gt;&lt;/code&gt; is one of {&lt;code&gt;celebahq-ldm-vq-4&lt;/code&gt;(f=4, VQ-reg. autoencoder, spatial size 64x64x3),&lt;code&gt;ffhq-ldm-vq-4&lt;/code&gt;(f=4, VQ-reg. autoencoder, spatial size 64x64x3), &lt;code&gt;lsun_bedrooms-ldm-vq-4&lt;/code&gt;(f=4, VQ-reg. autoencoder, spatial size 64x64x3), &lt;code&gt;lsun_churches-ldm-vq-4&lt;/code&gt;(f=8, KL-reg. autoencoder, spatial size 32x32x4),&lt;code&gt;cin-ldm-vq-8&lt;/code&gt;(f=8, VQ-reg. autoencoder, spatial size 32x32x4)}.&lt;/p&gt; &#xA;&lt;h1&gt;Model Zoo&lt;/h1&gt; &#xA;&lt;h2&gt;Pretrained Autoencoding Models&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pesser/stable-diffusion/main/assets/reconstruction2.png&#34; alt=&#34;rec2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;All models were trained until convergence (no further substantial improvement in rFID).&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;rFID vs val&lt;/th&gt; &#xA;   &lt;th&gt;train steps&lt;/th&gt; &#xA;   &lt;th&gt;PSNR&lt;/th&gt; &#xA;   &lt;th&gt;PSIM&lt;/th&gt; &#xA;   &lt;th&gt;Link&lt;/th&gt; &#xA;   &lt;th&gt;Comments&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;f=4, VQ (Z=8192, d=3)&lt;/td&gt; &#xA;   &lt;td&gt;0.58&lt;/td&gt; &#xA;   &lt;td&gt;533066&lt;/td&gt; &#xA;   &lt;td&gt;27.43 +/- 4.26&lt;/td&gt; &#xA;   &lt;td&gt;0.53 +/- 0.21&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/vq-f4.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/vq-f4.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;f=4, VQ (Z=8192, d=3)&lt;/td&gt; &#xA;   &lt;td&gt;1.06&lt;/td&gt; &#xA;   &lt;td&gt;658131&lt;/td&gt; &#xA;   &lt;td&gt;25.21 +/- 4.17&lt;/td&gt; &#xA;   &lt;td&gt;0.72 +/- 0.26&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://heibox.uni-heidelberg.de/f/9c6681f64bb94338a069/?dl=1&#34;&gt;https://heibox.uni-heidelberg.de/f/9c6681f64bb94338a069/?dl=1&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;no attention&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;f=8, VQ (Z=16384, d=4)&lt;/td&gt; &#xA;   &lt;td&gt;1.14&lt;/td&gt; &#xA;   &lt;td&gt;971043&lt;/td&gt; &#xA;   &lt;td&gt;23.07 +/- 3.99&lt;/td&gt; &#xA;   &lt;td&gt;1.17 +/- 0.36&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/vq-f8.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/vq-f8.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;f=8, VQ (Z=256, d=4)&lt;/td&gt; &#xA;   &lt;td&gt;1.49&lt;/td&gt; &#xA;   &lt;td&gt;1608649&lt;/td&gt; &#xA;   &lt;td&gt;22.35 +/- 3.81&lt;/td&gt; &#xA;   &lt;td&gt;1.26 +/- 0.37&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/vq-f8-n256.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/vq-f8-n256.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;f=16, VQ (Z=16384, d=8)&lt;/td&gt; &#xA;   &lt;td&gt;5.15&lt;/td&gt; &#xA;   &lt;td&gt;1101166&lt;/td&gt; &#xA;   &lt;td&gt;20.83 +/- 3.61&lt;/td&gt; &#xA;   &lt;td&gt;1.73 +/- 0.43&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://heibox.uni-heidelberg.de/f/0e42b04e2e904890a9b6/?dl=1&#34;&gt;https://heibox.uni-heidelberg.de/f/0e42b04e2e904890a9b6/?dl=1&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;f=4, KL&lt;/td&gt; &#xA;   &lt;td&gt;0.27&lt;/td&gt; &#xA;   &lt;td&gt;176991&lt;/td&gt; &#xA;   &lt;td&gt;27.53 +/- 4.54&lt;/td&gt; &#xA;   &lt;td&gt;0.55 +/- 0.24&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/kl-f4.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/kl-f4.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;f=8, KL&lt;/td&gt; &#xA;   &lt;td&gt;0.90&lt;/td&gt; &#xA;   &lt;td&gt;246803&lt;/td&gt; &#xA;   &lt;td&gt;24.19 +/- 4.19&lt;/td&gt; &#xA;   &lt;td&gt;1.02 +/- 0.35&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/kl-f8.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/kl-f8.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;f=16, KL (d=16)&lt;/td&gt; &#xA;   &lt;td&gt;0.87&lt;/td&gt; &#xA;   &lt;td&gt;442998&lt;/td&gt; &#xA;   &lt;td&gt;24.08 +/- 4.22&lt;/td&gt; &#xA;   &lt;td&gt;1.07 +/- 0.36&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/kl-f16.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/kl-f16.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;f=32, KL (d=64)&lt;/td&gt; &#xA;   &lt;td&gt;2.04&lt;/td&gt; &#xA;   &lt;td&gt;406763&lt;/td&gt; &#xA;   &lt;td&gt;22.27 +/- 3.93&lt;/td&gt; &#xA;   &lt;td&gt;1.41 +/- 0.40&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/kl-f32.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/kl-f32.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Get the models&lt;/h3&gt; &#xA;&lt;p&gt;Running the following script downloads und extracts all available pretrained autoencoding models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bash scripts/download_first_stages.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The first stage models can then be found in &lt;code&gt;models/first_stage_models/&amp;lt;model_spec&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Pretrained LDMs&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Datset&lt;/th&gt; &#xA;   &lt;th&gt;Task&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;FID&lt;/th&gt; &#xA;   &lt;th&gt;IS&lt;/th&gt; &#xA;   &lt;th&gt;Prec&lt;/th&gt; &#xA;   &lt;th&gt;Recall&lt;/th&gt; &#xA;   &lt;th&gt;Link&lt;/th&gt; &#xA;   &lt;th&gt;Comments&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CelebA-HQ&lt;/td&gt; &#xA;   &lt;td&gt;Unconditional Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;LDM-VQ-4 (200 DDIM steps, eta=0)&lt;/td&gt; &#xA;   &lt;td&gt;5.11 (5.11)&lt;/td&gt; &#xA;   &lt;td&gt;3.29&lt;/td&gt; &#xA;   &lt;td&gt;0.72&lt;/td&gt; &#xA;   &lt;td&gt;0.49&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/celeba.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/celeba.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FFHQ&lt;/td&gt; &#xA;   &lt;td&gt;Unconditional Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;LDM-VQ-4 (200 DDIM steps, eta=1)&lt;/td&gt; &#xA;   &lt;td&gt;4.98 (4.98)&lt;/td&gt; &#xA;   &lt;td&gt;4.50 (4.50)&lt;/td&gt; &#xA;   &lt;td&gt;0.73&lt;/td&gt; &#xA;   &lt;td&gt;0.50&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/ffhq.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/ffhq.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LSUN-Churches&lt;/td&gt; &#xA;   &lt;td&gt;Unconditional Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;LDM-KL-8 (400 DDIM steps, eta=0)&lt;/td&gt; &#xA;   &lt;td&gt;4.02 (4.02)&lt;/td&gt; &#xA;   &lt;td&gt;2.72&lt;/td&gt; &#xA;   &lt;td&gt;0.64&lt;/td&gt; &#xA;   &lt;td&gt;0.52&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/lsun_churches.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/lsun_churches.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LSUN-Bedrooms&lt;/td&gt; &#xA;   &lt;td&gt;Unconditional Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;LDM-VQ-4 (200 DDIM steps, eta=1)&lt;/td&gt; &#xA;   &lt;td&gt;2.95 (3.0)&lt;/td&gt; &#xA;   &lt;td&gt;2.22 (2.23)&lt;/td&gt; &#xA;   &lt;td&gt;0.66&lt;/td&gt; &#xA;   &lt;td&gt;0.48&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/lsun_bedrooms.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/lsun_bedrooms.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ImageNet&lt;/td&gt; &#xA;   &lt;td&gt;Class-conditional Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;LDM-VQ-8 (200 DDIM steps, eta=1)&lt;/td&gt; &#xA;   &lt;td&gt;7.77(7.76)* /15.82**&lt;/td&gt; &#xA;   &lt;td&gt;201.56(209.52)* /78.82**&lt;/td&gt; &#xA;   &lt;td&gt;0.84* / 0.65**&lt;/td&gt; &#xA;   &lt;td&gt;0.35* / 0.63**&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/cin.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/cin.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;*: w/ guiding, classifier_scale 10 **: w/o guiding, scores in bracket calculated with script provided by &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;ADM&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Conceptual Captions&lt;/td&gt; &#xA;   &lt;td&gt;Text-conditional Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;LDM-VQ-f4 (100 DDIM steps, eta=0)&lt;/td&gt; &#xA;   &lt;td&gt;16.79&lt;/td&gt; &#xA;   &lt;td&gt;13.89&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/text2img.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/text2img.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;finetuned from LAION&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenImages&lt;/td&gt; &#xA;   &lt;td&gt;Super-resolution&lt;/td&gt; &#xA;   &lt;td&gt;LDM-VQ-4&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/sr_bsr.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/sr_bsr.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;BSR image degradation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenImages&lt;/td&gt; &#xA;   &lt;td&gt;Layout-to-Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;LDM-VQ-4 (200 DDIM steps, eta=0)&lt;/td&gt; &#xA;   &lt;td&gt;32.02&lt;/td&gt; &#xA;   &lt;td&gt;15.92&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/layout2img_model.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/layout2img_model.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Landscapes&lt;/td&gt; &#xA;   &lt;td&gt;Semantic Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;LDM-VQ-4&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/semantic_synthesis256.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/semantic_synthesis256.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Landscapes&lt;/td&gt; &#xA;   &lt;td&gt;Semantic Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;LDM-VQ-4&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ommer-lab.com/files/latent-diffusion/semantic_synthesis.zip&#34;&gt;https://ommer-lab.com/files/latent-diffusion/semantic_synthesis.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;finetuned on resolution 512x512&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Get the models&lt;/h3&gt; &#xA;&lt;p&gt;The LDMs listed above can jointly be downloaded and extracted via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bash scripts/download_models.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The models can then be found in &lt;code&gt;models/ldm/&amp;lt;model_spec&amp;gt;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Coming Soon...&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;More inference scripts for conditional LDMs.&lt;/li&gt; &#xA; &lt;li&gt;In the meantime, you can play with our colab notebook &lt;a href=&#34;https://colab.research.google.com/drive/1xqzUi2iXQXDqXBHQGP9Mqt2YrYW6cx-J?usp=sharing&#34;&gt;https://colab.research.google.com/drive/1xqzUi2iXQXDqXBHQGP9Mqt2YrYW6cx-J?usp=sharing&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Comments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Our codebase for the diffusion models builds heavily on &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;OpenAI&#39;s ADM codebase&lt;/a&gt; and &lt;a href=&#34;https://github.com/lucidrains/denoising-diffusion-pytorch&#34;&gt;https://github.com/lucidrains/denoising-diffusion-pytorch&lt;/a&gt;. Thanks for open-sourcing!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The implementation of the transformer encoder is from &lt;a href=&#34;https://github.com/lucidrains/x-transformers&#34;&gt;x-transformers&lt;/a&gt; by &lt;a href=&#34;https://github.com/lucidrains?tab=repositories&#34;&gt;lucidrains&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{rombach2021highresolution,&#xA;      title={High-Resolution Image Synthesis with Latent Diffusion Models}, &#xA;      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj√∂rn Ommer},&#xA;      year={2021},&#xA;      eprint={2112.10752},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>mrdbourke/pytorch-deep-learning</title>
    <updated>2022-08-07T02:12:07Z</updated>
    <id>tag:github.com,2022-08-07:/mrdbourke/pytorch-deep-learning</id>
    <link href="https://github.com/mrdbourke/pytorch-deep-learning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Materials for the Learn PyTorch for Deep Learning: Zero to Mastery course.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Learn PyTorch for Deep Learning (work in progress)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update July 25 2022:&lt;/strong&gt; The &lt;a href=&#34;https://dbourke.link/ZTMPyTorch&#34;&gt;course is out on the Zero to Mastery Academy&lt;/a&gt; with videos for sections 00-07, 08 &amp;amp; 09 will come soon.&lt;/p&gt; &#xA;&lt;p&gt;Welcome to the &lt;a href=&#34;https://dbourke.link/ZTMPyTorch&#34;&gt;Zero to Mastery Learn PyTorch for Deep Learning course&lt;/a&gt;, the second best place to learn PyTorch on the internet (the first being the &lt;a href=&#34;https://pytorch.org/docs/stable/index.html&#34;&gt;PyTorch documentation&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://learnpytorch.io&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/misc-pytorch-course-launch-cover-white-text-black-background.jpg&#34; width=&#34;750&#34; alt=&#34;pytorch deep learning by zero to mastery cover photo with different sections of the course&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Contents of this page&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning#course-materialsoutline&#34;&gt;Course materials/outline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning#about-this-course&#34;&gt;About this course&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning#status&#34;&gt;Status&lt;/a&gt; (the progress of the course creation)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning#log&#34;&gt;Log&lt;/a&gt; (a log of the course material creation process)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Course materials/outline&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìñ &lt;strong&gt;Online book version:&lt;/strong&gt; All of course materials are available in a readable online book at &lt;a href=&#34;https://learnpytorch.io&#34;&gt;learnpytorch.io&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üé• &lt;strong&gt;First five sections on YouTube:&lt;/strong&gt; Learn Pytorch in a day by watching the &lt;a href=&#34;https://youtu.be/Z_ikDlimN6A&#34;&gt;first 25-hours of material&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üî¨ &lt;strong&gt;Course focus:&lt;/strong&gt; code, code, code, experiment, experiment, experiment.&lt;/li&gt; &#xA; &lt;li&gt;üèÉ‚Äç‚ôÇÔ∏è &lt;strong&gt;Teaching style:&lt;/strong&gt; &lt;a href=&#34;https://sive.rs/kimo&#34;&gt;https://sive.rs/kimo&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Section&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;What does it cover?&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Exercises &amp;amp; Extra-curriculum&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Slides&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/00_pytorch_fundamentals/&#34;&gt;00 - PyTorch Fundamentals&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Many fundamental PyTorch operations used for deep learning and neural networks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises&#34;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/00_pytorch_and_deep_learning_fundamentals.pdf&#34;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/01_pytorch_workflow/&#34;&gt;01 - PyTorch Workflow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Provides an outline for approaching deep learning problems and building neural networks with PyTorch.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/01_pytorch_workflow/#exercises&#34;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/01_pytorch_workflow.pdf&#34;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/02_pytorch_classification/&#34;&gt;02 - PyTorch Neural Network Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Uses the PyTorch workflow from 01 to go through a neural network classification problem.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/02_pytorch_classification/#exercises&#34;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/02_pytorch_classification.pdf&#34;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/03_pytorch_computer_vision/&#34;&gt;03 - PyTorch Computer Vision&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Let&#39;s see how PyTorch can be used for computer vision problems using the same workflow from 01 &amp;amp; 02.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/03_pytorch_computer_vision/#exercises&#34;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/03_pytorch_computer_vision.pdf&#34;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/04_pytorch_custom_datasets/&#34;&gt;04 - PyTorch Custom Datasets&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;How do you load a custom dataset into PyTorch? Also we&#39;ll be laying the foundations in this notebook for our modular code (covered in 05).&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/04_pytorch_custom_datasets/#exercises&#34;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/04_pytorch_custom_datasets.pdf&#34;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/05_pytorch_going_modular/&#34;&gt;05 - PyTorch Going Modular&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PyTorch is designed to be modular, let&#39;s turn what we&#39;ve created into a series of Python scripts (this is how you&#39;ll often find PyTorch code in the wild).&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/05_pytorch_going_modular/#exercises&#34;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/05_pytorch_going_modular.pdf&#34;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/06_pytorch_transfer_learning/&#34;&gt;06 - PyTorch Transfer Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Let&#39;s take a well performing pre-trained model and adjust it to one of our own problems.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/06_pytorch_transfer_learning/#exercises&#34;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/06_pytorch_transfer_learning.pdf&#34;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/07_pytorch_experiment_tracking/&#34;&gt;07 - Milestone Project 1: PyTorch Experiment Tracking&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;We&#39;ve built a bunch of models... wouldn&#39;t it be good to track how they&#39;re all going?&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/07_pytorch_experiment_tracking/#exercises&#34;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/07_pytorch_experiment_tracking.pdf&#34;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/08_pytorch_paper_replicating/&#34;&gt;08 - Milestone Project 2: PyTorch Paper Replicating&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PyTorch is the most popular deep learning framework for machine learning research, let&#39;s see why by replicating a machine learning paper.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnpytorch.io/08_pytorch_paper_replicating/#exercises&#34;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/08_pytorch_paper_replicating.pdf&#34;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Coming soon: 09 - Milestone Project 3: Model deployment&lt;/td&gt; &#xA;   &lt;td&gt;So we&#39;ve built a working PyTorch model... how do we get it in the hands of others? Hint: deploy it to the internet.&lt;/td&gt; &#xA;   &lt;td&gt;Go to exercises &amp;amp; extra-curriculum&lt;/td&gt; &#xA;   &lt;td&gt;Go to slides&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Status&lt;/h2&gt; &#xA;&lt;p&gt;See the project page for work-in-progress board - &lt;a href=&#34;https://github.com/users/mrdbourke/projects/1&#34;&gt;https://github.com/users/mrdbourke/projects/1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Working on:&lt;/strong&gt; creating materials for 09. PyTorch Model Deployment&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Total video count:&lt;/strong&gt; 263&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Done skeleton code for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Done annotations (text) for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Done images for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Done keynotes for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Done exercises and solutions for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning#log&#34;&gt;log&lt;/a&gt; for almost daily updates.&lt;/p&gt; &#xA;&lt;h2&gt;About this course&lt;/h2&gt; &#xA;&lt;h3&gt;Who is this course for?&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;You:&lt;/strong&gt; Are a beginner in the field of machine learning or deep learning and would like to learn PyTorch.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;This course:&lt;/strong&gt; Teaches you PyTorch and many machine learning concepts in a hands-on, code-first way.&lt;/p&gt; &#xA;&lt;p&gt;If you already have 1-year+ experience in machine learning, this course may help but it is specifically designed to be beginner-friendly.&lt;/p&gt; &#xA;&lt;h3&gt;What are the prerequisites?&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;3-6 months coding Python.&lt;/li&gt; &#xA; &lt;li&gt;At least one beginner machine learning course (however this might be able to be skipped, resources are linked for many different topics).&lt;/li&gt; &#xA; &lt;li&gt;Experience using Jupyter Notebooks or Google Colab (though you can pick this up as we go along).&lt;/li&gt; &#xA; &lt;li&gt;A willingness to learn (most important).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For 1 &amp;amp; 2, I&#39;d recommend the &lt;a href=&#34;https://dbourke.link/ZTMMLcourse&#34;&gt;Zero to Mastery Data Science and Machine Learning Bootcamp&lt;/a&gt;, it&#39;ll teach you the fundamentals of machine learning and Python (I&#39;m biased though, I also teach that course).&lt;/p&gt; &#xA;&lt;h3&gt;How is the course taught?&lt;/h3&gt; &#xA;&lt;p&gt;All of the course materials are available for free in an online book at &lt;a href=&#34;https://learnpytorch.io&#34;&gt;learnpytorch.io&lt;/a&gt;. If you like to read, I&#39;d recommend going through the resources there.&lt;/p&gt; &#xA;&lt;p&gt;If you prefer to learn via video, the course is also taught in apprenticeship-style format, meaning I write PyTorch code, you write PyTorch code.&lt;/p&gt; &#xA;&lt;p&gt;There&#39;s a reason the course motto&#39;s include &lt;em&gt;if in doubt, run the code&lt;/em&gt; and &lt;em&gt;experiment, experiment, experiment!&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;My whole goal is to help you to do one thing: learn machine learning by writing PyTorch code.&lt;/p&gt; &#xA;&lt;p&gt;The code is all written via &lt;a href=&#34;https://colab.research.google.com&#34;&gt;Google Colab Notebooks&lt;/a&gt; (you could also use Jupyter Notebooks), an incredible free resource to experiment with machine learning.&lt;/p&gt; &#xA;&lt;h3&gt;What will I get if I finish the course?&lt;/h3&gt; &#xA;&lt;p&gt;There&#39;s certificates and all that jazz if you go through the videos.&lt;/p&gt; &#xA;&lt;p&gt;But certificates are meh.&lt;/p&gt; &#xA;&lt;p&gt;You can consider this course a machine learning momentum builder.&lt;/p&gt; &#xA;&lt;p&gt;By the end, you&#39;ll have written hundreds of lines of PyTorch code.&lt;/p&gt; &#xA;&lt;p&gt;And will have been exposed to many of the most important concepts in machine learning.&lt;/p&gt; &#xA;&lt;p&gt;So when you go to build your own machine learning projects or inspect a public machine learning project made with PyTorch, it&#39;ll feel familiar and if it doesn&#39;t, at least you&#39;ll know where to look.&lt;/p&gt; &#xA;&lt;h3&gt;What will I build in the course?&lt;/h3&gt; &#xA;&lt;p&gt;We start with the barebone fundamentals of PyTorch and machine learning, so even if you&#39;re new to machine learning you&#39;ll be caught up to speed.&lt;/p&gt; &#xA;&lt;p&gt;Then we‚Äôll explore more advanced areas including PyTorch neural network classification, PyTorch workflows, computer vision, custom datasets, experiment tracking, model deployment, and my personal favourite: transfer learning, a powerful technique for taking what one machine learning model has learned on another problem and applying it to your own!&lt;/p&gt; &#xA;&lt;p&gt;Along the way, you‚Äôll build three milestone projects surrounding an overarching project called FoodVision, a neural network computer vision model to classify images of food.&lt;/p&gt; &#xA;&lt;p&gt;These milestone projects will help you practice using PyTorch to cover important machine learning concepts and create a portfolio you can show employers and say &#34;here&#39;s what I&#39;ve done&#34;.&lt;/p&gt; &#xA;&lt;h3&gt;How do I get started?&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Click on one of the notebook or section links above like &#34;&lt;a href=&#34;https://www.learnpytorch.io/00_pytorch_fundamentals/&#34;&gt;00. PyTorch Fundamentals&lt;/a&gt;&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Click the &#34;Open in Colab&#34; button up the top.&lt;/li&gt; &#xA; &lt;li&gt;Press SHIFT+Enter a few times and see what happens.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;My question isn&#39;t answered&lt;/h3&gt; &#xA;&lt;p&gt;Please leave a &lt;a href=&#34;https://github.com/mrdbourke/pytorch-deep-learning/discussions&#34;&gt;discussion&lt;/a&gt; or send me an email directly: daniel (at) mrdbourke (dot) com.&lt;/p&gt; &#xA;&lt;h2&gt;Log&lt;/h2&gt; &#xA;&lt;p&gt;Almost daily updates of what&#39;s happening.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;05 Aug 2022 - recorded 11 videos for 08, total videos: 263, section 08 videos finished!... the biggest section so far&lt;/li&gt; &#xA; &lt;li&gt;04 Aug 2022 - recorded 13 videos for 08, total videos: 252&lt;/li&gt; &#xA; &lt;li&gt;03 Aug 2022 - recorded 3 videos for 08, total videos: 239&lt;/li&gt; &#xA; &lt;li&gt;02 Aug 2022 - recorded 12 videos for 08, total videos: 236&lt;/li&gt; &#xA; &lt;li&gt;30 July 2022 - recorded 11 videos for 08, total videos: 224&lt;/li&gt; &#xA; &lt;li&gt;29 July 2022 - add exercises + solutions for 08, see live walkthrough on YouTube: &lt;a href=&#34;https://youtu.be/tjpW_BY8y3g&#34;&gt;https://youtu.be/tjpW_BY8y3g&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;28 July 2022 - add slides for 08&lt;/li&gt; &#xA; &lt;li&gt;27 July 2022 - cleanup much of 08, start on slides for 08, exercises and extra-curriculum next&lt;/li&gt; &#xA; &lt;li&gt;26 July 2022 - add annotations and images for 08&lt;/li&gt; &#xA; &lt;li&gt;25 July 2022 - add annotations for 08&lt;/li&gt; &#xA; &lt;li&gt;24 July 2022 - launched first half of course (notebooks 00-04) in a single video (25+ hours!!!) on YouTube: &lt;a href=&#34;https://youtu.be/Z_ikDlimN6A&#34;&gt;https://youtu.be/Z_ikDlimN6A&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;21 July 2022 - add annotations and images for 08&lt;/li&gt; &#xA; &lt;li&gt;20 July 2022 - add annotations and images for 08, getting so close! this is an epic section&lt;/li&gt; &#xA; &lt;li&gt;19 July 2022 - add annotations and images for 08&lt;/li&gt; &#xA; &lt;li&gt;15 July 2022 - add annotations and images for 08&lt;/li&gt; &#xA; &lt;li&gt;14 July 2022 - add annotations for 08&lt;/li&gt; &#xA; &lt;li&gt;12 July 2022 - add annotations for 08, woo woo this is bigggg section!&lt;/li&gt; &#xA; &lt;li&gt;11 July 2022 - add annotations for 08&lt;/li&gt; &#xA; &lt;li&gt;9 July 2022 - add annotations for 08&lt;/li&gt; &#xA; &lt;li&gt;8 July 2022 - add a bunch of annotations to 08&lt;/li&gt; &#xA; &lt;li&gt;6 July 2022 - course launched on ZTM Academy with videos for sections 00-07! üöÄ - &lt;a href=&#34;https://dbourke.link/ZTMPyTorch&#34;&gt;https://dbourke.link/ZTMPyTorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;1 July 2022 - add annotations and images for 08&lt;/li&gt; &#xA; &lt;li&gt;30 June 2022 - add annotations for 08&lt;/li&gt; &#xA; &lt;li&gt;28 June 2022 - recorded 11 videos for section 07, total video count 213, all videos for section 07 complete!&lt;/li&gt; &#xA; &lt;li&gt;27 June 2022 - recorded 11 videos for section 07, total video count 202&lt;/li&gt; &#xA; &lt;li&gt;25 June 2022 - recreated 7 videos for section 06 to include updated APIs, total video count 191&lt;/li&gt; &#xA; &lt;li&gt;24 June 2022 - recreated 12 videos for section 06 to include updated APIs&lt;/li&gt; &#xA; &lt;li&gt;23 June 2022 - finish annotations for 07, add exercise template and solutions for 07 + video walkthrough on YouTube: &lt;a href=&#34;https://youtu.be/cO_r2FYcAjU&#34;&gt;https://youtu.be/cO_r2FYcAjU&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;21 June 2022 - make 08 runnable end-to-end, add images and annotations for 07&lt;/li&gt; &#xA; &lt;li&gt;17 June 2022 - fix up 06, 07 v2 for upcoming torchvision version upgrade, add plenty of annotations to 08&lt;/li&gt; &#xA; &lt;li&gt;13 June 2022 - add notebook 08 first version, starting to replicate the Vision Transformer paper&lt;/li&gt; &#xA; &lt;li&gt;10 June 2022 - add annotations for 07 v2&lt;/li&gt; &#xA; &lt;li&gt;09 June 2022 - create 07 v2 for &lt;code&gt;torchvision&lt;/code&gt; v0.13 (this will replace 07 v1 when &lt;code&gt;torchvision=0.13&lt;/code&gt; is released)&lt;/li&gt; &#xA; &lt;li&gt;08 June 2022 - adapt 06 v2 for &lt;code&gt;torchvision&lt;/code&gt; v0.13 (this will replace 06 v1 when &lt;code&gt;torchvision=0.13&lt;/code&gt; is released)&lt;/li&gt; &#xA; &lt;li&gt;07 June 2022 - create notebook 06 v2 for upcoming &lt;code&gt;torchvision&lt;/code&gt; v0.13 update (new transfer learning methods)&lt;/li&gt; &#xA; &lt;li&gt;04 June 2022 - add annotations for 07&lt;/li&gt; &#xA; &lt;li&gt;03 June 2022 - huuuuuuge amount of annotations added to 07&lt;/li&gt; &#xA; &lt;li&gt;31 May 2022 - add a bunch of annotations for 07, make code runnable end-to-end&lt;/li&gt; &#xA; &lt;li&gt;30 May 2022 - record 4 videos for 06, finished section 06, onto section 07, total videos 186&lt;/li&gt; &#xA; &lt;li&gt;28 May 2022 - record 10 videos for 06, total videos 182&lt;/li&gt; &#xA; &lt;li&gt;24 May 2022 - add solutions and exercises for 06&lt;/li&gt; &#xA; &lt;li&gt;23 May 2022 - finished annotations and images for 06, time to do exercises and solutions&lt;/li&gt; &#xA; &lt;li&gt;22 May 2202 - add plenty of images to 06&lt;/li&gt; &#xA; &lt;li&gt;18 May 2022 - add plenty of annotations to 06&lt;/li&gt; &#xA; &lt;li&gt;17 May 2022 - added a bunch of annotations for section 06&lt;/li&gt; &#xA; &lt;li&gt;16 May 2022 - recorded 10 videos for section 05, finish videos for section 05 ‚úÖ&lt;/li&gt; &#xA; &lt;li&gt;12 May 2022 - added exercises and solutions for 05&lt;/li&gt; &#xA; &lt;li&gt;11 May 2022 - clean up part 1 and part 2 notebooks for 05, make slides for 05, start on exercises and solutions for 05&lt;/li&gt; &#xA; &lt;li&gt;10 May 2022 - huuuuge updates to the 05 section, see the website, it looks pretty: &lt;a href=&#34;https://www.learnpytorch.io/05_pytorch_going_modular/&#34;&gt;https://www.learnpytorch.io/05_pytorch_going_modular/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;09 May 2022 - add a bunch of materials for 05, cleanup docs&lt;/li&gt; &#xA; &lt;li&gt;08 May 2022 - add a bunch of materials for 05&lt;/li&gt; &#xA; &lt;li&gt;06 May 2022 - continue making materials for 05&lt;/li&gt; &#xA; &lt;li&gt;05 May 2022 - update section 05 with headings/outline&lt;/li&gt; &#xA; &lt;li&gt;28 Apr 2022 - recorded 13 videos for 04, finished videos for 04, now to make materials for 05&lt;/li&gt; &#xA; &lt;li&gt;27 Apr 2022 - recorded 3 videos for 04&lt;/li&gt; &#xA; &lt;li&gt;26 Apr 2022 - recorded 10 videos for 04&lt;/li&gt; &#xA; &lt;li&gt;25 Apr 2022 - recorded 11 videos for 04&lt;/li&gt; &#xA; &lt;li&gt;24 Apr 2022 - prepared slides for 04&lt;/li&gt; &#xA; &lt;li&gt;23 Apr 2022 - recorded 6 videos for 03, finished videos for 03, now to 04&lt;/li&gt; &#xA; &lt;li&gt;22 Apr 2022 - recorded 5 videos for 03&lt;/li&gt; &#xA; &lt;li&gt;21 Apr 2022 - recorded 9 videos for 03&lt;/li&gt; &#xA; &lt;li&gt;20 Apr 2022 - recorded 3 videos for 03&lt;/li&gt; &#xA; &lt;li&gt;19 Apr 2022 - recorded 11 videos for 03&lt;/li&gt; &#xA; &lt;li&gt;18 Apr 2022 - finish exercises/solutions for 04, added live-coding walkthrough of 04 exercises/solutions on YouTube: &lt;a href=&#34;https://youtu.be/vsFMF9wqWx0&#34;&gt;https://youtu.be/vsFMF9wqWx0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;16 Apr 2022 - finish exercises/solutions for 03, added live-coding walkthrough of 03 exercises/solutions on YouTube: &lt;a href=&#34;https://youtu.be/_PibmqpEyhA&#34;&gt;https://youtu.be/_PibmqpEyhA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;14 Apr 2022 - add final images/annotations for 04, begin on exercises/solutions for 03 &amp;amp; 04&lt;/li&gt; &#xA; &lt;li&gt;13 Apr 2022 - add more images/annotations for 04&lt;/li&gt; &#xA; &lt;li&gt;3 Apr 2022 - add more annotations for 04&lt;/li&gt; &#xA; &lt;li&gt;2 Apr 2022 - add more annotations for 04&lt;/li&gt; &#xA; &lt;li&gt;1 Apr 2022 - add more annotations for 04&lt;/li&gt; &#xA; &lt;li&gt;31 Mar 2022 - add more annotations for 04&lt;/li&gt; &#xA; &lt;li&gt;29 Mar 2022 - add more annotations for 04&lt;/li&gt; &#xA; &lt;li&gt;27 Mar 2022 - starting to add annotations for 04&lt;/li&gt; &#xA; &lt;li&gt;26 Mar 2022 - making dataset for 04&lt;/li&gt; &#xA; &lt;li&gt;25 Mar 2022 - make slides for 03&lt;/li&gt; &#xA; &lt;li&gt;24 Mar 2022 - fix error for 03 not working in docs (finally)&lt;/li&gt; &#xA; &lt;li&gt;23 Mar 2022 - add more images for 03&lt;/li&gt; &#xA; &lt;li&gt;22 Mar 2022 - add images for 03&lt;/li&gt; &#xA; &lt;li&gt;20 Mar 2022 - add more annotations for 03&lt;/li&gt; &#xA; &lt;li&gt;18 Mar 2022 - add more annotations for 03&lt;/li&gt; &#xA; &lt;li&gt;17 Mar 2022 - add more annotations for 03&lt;/li&gt; &#xA; &lt;li&gt;16 Mar 2022 - add more annotations for 03&lt;/li&gt; &#xA; &lt;li&gt;15 Mar 2022 - add more annotations for 03&lt;/li&gt; &#xA; &lt;li&gt;14 Mar 2022 - start adding annotations for notebook 03, see the work in progress here: &lt;a href=&#34;https://www.learnpytorch.io/03_pytorch_computer_vision/&#34;&gt;https://www.learnpytorch.io/03_pytorch_computer_vision/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;12 Mar 2022 - recorded 12 videos for 02, finished section 02, now onto making materials for 03, 04, 05&lt;/li&gt; &#xA; &lt;li&gt;11 Mar 2022 - recorded 9 videos for 02&lt;/li&gt; &#xA; &lt;li&gt;10 Mar 2022 - recorded 10 videos for 02&lt;/li&gt; &#xA; &lt;li&gt;9 Mar 2022 - cleaning up slides/code for 02, getting ready for recording&lt;/li&gt; &#xA; &lt;li&gt;8 Mar 2022 - recorded 9 videos for section 01, finished section 01, now onto 02&lt;/li&gt; &#xA; &lt;li&gt;7 Mar 2022 - recorded 4 videos for section 01&lt;/li&gt; &#xA; &lt;li&gt;6 Mar 2022 - recorded 4 videos for section 01&lt;/li&gt; &#xA; &lt;li&gt;4 Mar 2022 - recorded 10 videos for section 01&lt;/li&gt; &#xA; &lt;li&gt;20 Feb 2022 - recorded 8 videos for section 00, finished section, now onto 01&lt;/li&gt; &#xA; &lt;li&gt;18 Feb 2022 - recorded 13 videos for section 00&lt;/li&gt; &#xA; &lt;li&gt;17 Feb 2022 - recorded 11 videos for section 00&lt;/li&gt; &#xA; &lt;li&gt;16 Feb 2022 - added setup guide&lt;/li&gt; &#xA; &lt;li&gt;12 Feb 2022 - tidy up README with table of course materials, finish images and slides for 01&lt;/li&gt; &#xA; &lt;li&gt;10 Feb 2022 - finished slides and images for 00, notebook is ready for publishing: &lt;a href=&#34;https://www.learnpytorch.io/00_pytorch_fundamentals/&#34;&gt;https://www.learnpytorch.io/00_pytorch_fundamentals/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;01-07 Feb 2022 - add annotations for 02, finished, still need images, going to work on exercises/solutions today&lt;/li&gt; &#xA; &lt;li&gt;31 Jan 2022 - start adding annotations for 02&lt;/li&gt; &#xA; &lt;li&gt;28 Jan 2022 - add exercies and solutions for 01&lt;/li&gt; &#xA; &lt;li&gt;26 Jan 2022 - lots more annotations to 01, should be finished tomorrow, will do exercises + solutions then too&lt;/li&gt; &#xA; &lt;li&gt;24 Jan 2022 - add a bunch of annotations to 01&lt;/li&gt; &#xA; &lt;li&gt;21 Jan 2022 - start adding annotations for 01&lt;/li&gt; &#xA; &lt;li&gt;20 Jan 2022 - finish annotations for 00 (still need to add images), add exercises and solutions for 00&lt;/li&gt; &#xA; &lt;li&gt;19 Jan 2022 - add more annotations for 00&lt;/li&gt; &#xA; &lt;li&gt;18 Jan 2022 - add more annotations for 00&lt;/li&gt; &#xA; &lt;li&gt;17 Jan 2022 - back from holidays, adding more annotations to 00&lt;/li&gt; &#xA; &lt;li&gt;10 Dec 2021 - start adding annoations for 00&lt;/li&gt; &#xA; &lt;li&gt;9 Dec 2021 - Created a website for the course (&lt;a href=&#34;https://learnpytorch.io&#34;&gt;learnpytorch.io&lt;/a&gt;) you&#39;ll see updates posted there as development continues&lt;/li&gt; &#xA; &lt;li&gt;8 Dec 2021 - Clean up notebook 07, starting to go back through code and add annotations&lt;/li&gt; &#xA; &lt;li&gt;26 Nov 2021 - Finish skeleton code for 07, added four different experiments, need to clean up and make more straightforward&lt;/li&gt; &#xA; &lt;li&gt;25 Nov 2021 - clean code for 06, add skeleton code for 07 (experiment tracking)&lt;/li&gt; &#xA; &lt;li&gt;24 Nov 2021 - Update 04, 05, 06 notebooks for easier digestion and learning, each section should cover a max of 3 big ideas, 05 is now dedicated to turning notebook code into modular code&lt;/li&gt; &#xA; &lt;li&gt;22 Nov 2021 - Update 04 train and test functions to make more straightforward&lt;/li&gt; &#xA; &lt;li&gt;19 Nov 2021 - Added 05 (transfer learning) notebook, update custom data loading code in 04&lt;/li&gt; &#xA; &lt;li&gt;18 Nov 2021 - Updated vision code for 03 and added custom dataset loading code in 04&lt;/li&gt; &#xA; &lt;li&gt;12 Nov 2021 - Added a bunch of skeleton code to notebook 04 for custom dataset loading, next is modelling with custom data&lt;/li&gt; &#xA; &lt;li&gt;10 Nov 2021 - researching best practice for custom datasets for 04&lt;/li&gt; &#xA; &lt;li&gt;9 Nov 2021 - Update 03 skeleton code to finish off building CNN model, onto 04 for loading custom datasets&lt;/li&gt; &#xA; &lt;li&gt;4 Nov 2021 - Add GPU code to 03 + train/test loops + &lt;code&gt;helper_functions.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;3 Nov 2021 - Add basic start for 03, going to finish by end of week&lt;/li&gt; &#xA; &lt;li&gt;29 Oct 2021 - Tidied up skeleton code for 02, still a few more things to clean/tidy, created 03&lt;/li&gt; &#xA; &lt;li&gt;28 Oct 2021 - Finished skeleton code for 02, going to clean/tidy tomorrow, 03 next week&lt;/li&gt; &#xA; &lt;li&gt;27 Oct 2021 - add a bunch of code for 02, going to finish tomorrow/by end of week&lt;/li&gt; &#xA; &lt;li&gt;26 Oct 2021 - update 00, 01, 02 with outline/code, skeleton code for 00 &amp;amp; 01 done, 02 next&lt;/li&gt; &#xA; &lt;li&gt;23, 24 Oct 2021 - update 00 and 01 notebooks with more outline/code&lt;/li&gt; &#xA; &lt;li&gt;20 Oct 2021 - add v0 outlines for 01 and 02, add rough outline of course to README, this course will focus on less but better&lt;/li&gt; &#xA; &lt;li&gt;19 Oct 2021 - Start repo üî•, add fundamentals notebook draft v0&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>spmallick/learnopencv</title>
    <updated>2022-08-07T02:12:07Z</updated>
    <id>tag:github.com,2022-08-07:/spmallick/learnopencv</id>
    <link href="https://github.com/spmallick/learnopencv" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Learn OpenCV : C++ and Python Examples&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LearnOpenCV&lt;/h1&gt; &#xA;&lt;p&gt;This repo contains code for Computer Vision, Deep learning, and AI articles shared on our blog &lt;a href=&#34;https://www.LearnOpenCV.com&#34;&gt;LearnOpenCV.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Want to become an expert in AI? &lt;a href=&#34;https://opencv.org/courses/&#34;&gt;AI Courses by OpenCV&lt;/a&gt; is a great place to start.&lt;/p&gt; &#xA;&lt;a href=&#34;https://opencv.org/courses/&#34;&gt; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://www.learnopencv.com/wp-content/uploads/2020/04/AI-Courses-By-OpenCV-Github.png&#34;&gt; &lt;/p&gt; &lt;/a&gt; &#xA;&lt;h2&gt;List of Blog Posts&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Blog Post&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/yolov7-object-detection-paper-explanation-and-inference/&#34;&gt;YOLOv7 Object Detection Paper Explanation and Inference&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/YOLOv7-Object-Detection-Paper-Explanation-and-Inference&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/pothole-detection-using-yolov4-and-darknet/&#34;&gt;Pothole Detection using YOLOv4 and Darknet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Pothole-Detection-using-YOLOv4-and-Darknet&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/automatic-document-scanner-using-opencv/&#34;&gt;Automatic Document Scanner using OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Automatic-Document-Scanner&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/demystifying-gpu-architectures-for-deep-learning-part-2/&#34;&gt;Demystifying GPU architectures for deep learning: Part 2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/gpu_arch_and_CUDA&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/demystifying-gpu-architectures-for-deep-learning/&#34;&gt;Demystifying GPU Architectures For Deep Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/gpu_arch_and_CUDA&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/intersection-over-unioniou-in-object-detection-and-segmentation/&#34;&gt;Intersection-over-Union(IoU)-in-Object-Detection-and-Segmentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Intersection-over-Union-IoU-in-Object-Detection-and-Segmentation&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/understanding-multiple-object-tracking-using-deepsort/&#34;&gt;Understanding Multiple Object Tracking using DeepSORT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Understanding-Multiple-Object-Tracking-using-DeepSORT&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/optical-character-recognition-using-paddleocr/&#34;&gt;Optical Character Recognition using PaddleOCR&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Optical-Character-Recognition-using-PaddleOCR&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/gesture-control-in-zoom-call-using-mediapipe/&#34;&gt;Gesture Control in Zoom Call using Mediapipe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/zoom-gestures&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/deep-dive-into-tensorflow-model-optimization-toolkit/&#34;&gt;A Deep Dive into Tensorflow Model Optimization&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/A-Deep-Dive-into-Tensorflow-Model-Optimization&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/anti-spoofing-face-recognition-system-using-oak-d-and-depthai/&#34;&gt;Anti-Spoofing Face Recognition System using OAK-D and DepthAI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Anti-Spoofing-Face-Recognition-with-OAK-D&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/depthai-pipeline-overview-creating-a-complex-pipeline/&#34;&gt;DepthAI Pipeline Overview: Creating a Complex Pipeline&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OAK-DepthAi-Pipeline-Overview&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/tensorflow-lite-model-maker-create-models-for-on-device-machine-learning/&#34;&gt;TensorFlow Lite Model Maker: Create Models for On-Device Machine Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Tensorflow-Lite-Model-Maker-Create-Models-for-On-Device-ML&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/tensorflow-lite-model-optimization-for-on-device-machine-learning&#34;&gt;TensorFlow Lite: Model Optimization for On Device Machine Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Lite-Model-Optimization-for-On-Device-MachineLearning&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/object-detection-with-depth-measurement-with-oak-d/&#34;&gt;Object detection with depth measurement using pre-trained models with OAK-D&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OAK-Object-Detection-with-Depth&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/custom-object-detection-training-using-yolov5/&#34;&gt;Custom Object Detection Training using YOLOv5&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Custom-Object-Detection-Training-using-YOLOv5&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/object-detection-using-yolov5-and-opencv-dnn-in-c-and-python/&#34;&gt;Object Detection using Yolov5 and OpenCV DNN (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/create-snapchat-instagram-filters-using-mediapipe/&#34;&gt;Create Snapchat/Instagram filters using Mediapipe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Create-AR-filters-using-Mediapipe&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/autosar-c-compliant-deep-learning-inference-with-tensorrt/&#34;&gt;AUTOSAR C++ compliant deep learning inference with TensorRT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/industrial_cv_TensorRT_cpp&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/nvidia-gtc-2022-day-4-highlights-meet-the-new-jetson-orin/&#34;&gt;NVIDIA GTC 2022 Day 4 Highlights: Meet the new Jetson Orin&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/nvidia-gtc-2022-day-3-highlights-deep-dive-into-hopper-architecture/&#34;&gt;NVIDIA GTC 2022 Day 3 Highlights: Deep Dive into Hopper architecture&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/nvidia-gtc-2022-day-2-highlights/&#34;&gt;NVIDIA GTC 2022 Day 2 Highlights: Jensen‚Äôs Keynote&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/gtc-day-1-highlights/&#34;&gt;NVIDIA GTC 2022 Day 1 Highlights: Brilliant Start&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/automatic-license-plate-recognition-using-deep-learning/&#34;&gt;Automatic License Plate Recognition using Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ALPR&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/building-a-body-posture-analysis-system-using-mediapipe/&#34;&gt;Building a Poor Body Posture Detection and Alert System using MediaPipe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Posture-analysis-system-using-MediaPipe-Pose&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/introduction-to-mediapipe/&#34;&gt;Introduction to MediaPipe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Introduction-to-MediaPipe&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/disparity-estimation-using-deep-learning/&#34;&gt;Disparity Estimation using Deep Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Disparity-Estimation-Using-Deep-Learning&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/how-to-build-chrome-dino-game-bot-using-opencv-feature-matching/&#34;&gt;How to build Chrome Dino game bot using OpenCV Feature Matching&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Chrome-Dino-Bot-using-OpenCV-feature-matching&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/top-10-sources-to-find-computer-vision-and-ai-models/&#34;&gt;Top 10 Sources to Find Computer Vision and AI Models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/multi-attribute-and-graph-based-object-detection/&#34;&gt;Multi-Attribute and Graph-based Object Detection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/plastic-waste-detection-with-deep-learning/&#34;&gt;Plastic Waste Detection with Deep Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Plastic-Waste-Detection-with-Deep-Learning&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/ensemble-deep-learning-based-defect-classification-and-detection-in-sem-images/&#34;&gt;Ensemble Deep Learning-based Defect Classification and Detection in SEM Images&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/building-industrial-embedded-deep-learning-inference-pipelines-with-tensorrt/&#34;&gt;Building Industrial embedded deep learning inference pipelines with TensorRT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/industrial_cv_TensorRT_python&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/transfer-learning-for-medical-images/&#34;&gt;Transfer Learning for Medical Images&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/stereo-vision-and-depth-estimation-using-opencv-ai-kit/&#34;&gt;Stereo Vision and Depth Estimation using OpenCV AI Kit&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/oak-getting-started&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/introduction-to-opencv-ai-kit-and-depthai/&#34;&gt;Introduction to OpenCV AI Kit and DepthAI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/oak-getting-started&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/wechat-qr-code-scanner-in-opencv&#34;&gt;WeChat QR Code Scanner in OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/WeChat-QRCode-Scanner-OpenCV&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/ai-behind-the-diwali-2021-not-just-a-cadbury-ad/&#34;&gt;AI behind the Diwali 2021 ‚ÄòNot just a Cadbury ad‚Äô&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/model-selection-and-benchmarking-with-modelplace-ai/&#34;&gt;Model Selection and Benchmarking with Modelplace.AI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://modelplace.ai/&#34;&gt;Model Zoo&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/real-time-style-transfer-in-a-zoom-meeting/&#34;&gt;Real-time style transfer in a zoom meeting&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/style-transfer-zoom&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/introduction-to-openvino-deep-learning-workbench/&#34;&gt;Introduction to OpenVino Deep Learning Workbench&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Introduction-to-OpenVino-Deep-Learning-Workbench&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/running-openvino-models-on-intel-integrated-gpu/&#34;&gt;Running OpenVino Models on Intel Integrated GPU&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Running-OpenVino-Models-on-Intel-Integrated-GPU&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/post-training-quantization-with-openvino-toolkit/&#34;&gt;Post Training Quantization with OpenVino Toolkit&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Post-Training-Quantization-with-OpenVino-Toolkit&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/introduction-to-intel-openvino-toolkit/&#34;&gt;Introduction to Intel OpenVINO Toolkit&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/human-action-recognition-using-detectron2-and-lstm/&#34;&gt;Human Action Recognition using Detectron2 and LSTM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Human-Action-Recognition-Using-Detectron2-And-Lstm&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/paired-image-to-image-translation-pix2pix/&#34;&gt;Pix2Pix:Image-to-Image Translation in PyTorch &amp;amp; TensorFlow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Image-to-Image-Translation-with-GAN&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/conditional-gan-cgan-in-pytorch-and-tensorflow/&#34;&gt;Conditional GAN (cGAN) in PyTorch and TensorFlow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Conditional-GAN-PyTorch-TensorFlow&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/deep-convolutional-gan-in-pytorch-and-tensorflow/&#34;&gt;Deep Convolutional GAN in PyTorch and TensorFlow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Deep-Convolutional-GAN&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/introduction-to-generative-adversarial-networks/&#34;&gt;Introduction to Generative Adversarial Networks (GANs)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Intro-to-Generative-Adversarial-Network&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/human-pose-estimation-using-keypoint-rcnn-in-pytorch/&#34;&gt;Human Pose Estimation using Keypoint RCNN in PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-Keypoint-RCNN&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch&#34;&gt;Non Maximum Suppression: Theory and Implementation in PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Non-Maximum-Suppression&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/mrnet-multitask-approach/&#34;&gt;MRNet ‚Äì The Multi-Task Approach&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/MRnet-MultiTask-Approach&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/generative-and-discriminative-models/&#34;&gt;Generative and Discriminative Models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/playing-chromes-t-rex-game-with-facial-gestures/&#34;&gt;Playing Chrome&#39;s T-Rex Game with Facial Gestures&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Playing-Chrome-TRex-Game-with-Facial-Gestures&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/variational-autoencoder-in-tensorflow/&#34;&gt;Variational Autoencoder in TensorFlow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Variational-Autoencoder-TensorFlow&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/autoencoder-in-tensorflow-2-beginners-guide/&#34;&gt;Autoencoder in TensorFlow 2: Beginner‚Äôs Guide&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Autoencoder-in-TensorFlow&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/&#34;&gt;Deep Learning with OpenCV DNN Module: A Definitive Guide&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Deep-Learning-with-OpenCV-DNN-Module&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/depth-perception-using-stereo-camera-python-c/&#34;&gt;Depth perception using stereo camera (Python/C++)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Depth-Perception-Using-Stereo-Camera&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/contour-detection-using-opencv-python-c/&#34;&gt;Contour Detection using OpenCV (Python/C++)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Contour-Detection-using-OpenCV&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/super-resolution-in-opencv/&#34;&gt;Super Resolution in OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/Super-Resolution-in-OpenCV&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/improving-illumination-in-night-time-images/&#34;&gt;Improving Illumination in Night Time Images&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Improving-Illumination-in-Night-Time-Images&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/introduction-to-video-classification-and-human-activity-recognition/&#34;&gt;Video Classification and Human Activity Recognition&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/video-classification-and-human-activity-recognition&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/how-to-use-opencv-dnn-module-with-nvidia-gpu-on-windows&#34;&gt;How to use OpenCV DNN Module with Nvidia GPU on Windows&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OpenCV-dnn-gpu-support-Windows&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/opencv-dnn-with-gpu-support/&#34;&gt;How to use OpenCV DNN Module with NVIDIA GPUs&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OpenCV-dnn-gpu-support-Linux&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/code-opencv-in-visual-studio/&#34;&gt;Code OpenCV in Visual Studio&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/install-opencv-on-windows/&#34;&gt;Install OpenCV on Windows ‚Äì C++ / Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Install-OpenCV-Windows-exe&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/face-recognition-with-arcface/&#34;&gt;Face Recognition with ArcFace&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Face-Recognition-with-ArcFace&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/background-subtraction-with-opencv-and-bgs-libraries/&#34;&gt;Background Subtraction with OpenCV and BGS Libraries&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Background-Subtraction&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/optical-flow-using-deep-learning-raft/&#34;&gt;RAFT: Optical Flow estimation using Deep Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Optical-Flow-Estimation-using-Deep-Learning-RAFT&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/making-a-low-cost-stereo-camera-using-opencv/&#34;&gt;Making A Low-Cost Stereo Camera Using OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/stereo-camera&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/optical-flow-in-opencv&#34;&gt;Optical Flow in OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Optical-Flow-in-OpenCV&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/&#34;&gt;Introduction to Epipolar Geometry and Stereo Vision&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/EpipolarGeometryAndStereoVision&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/classification-with-localization/&#34;&gt;Classification With Localization: Convert any keras Classifier to a Detector&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Classification-with-localization-convert-any-keras-classifier-into-a-detector/README.md&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/photoshop-filters-in-opencv/&#34;&gt;Photoshop Filters in OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Photoshop-Filters-in-OpenCV&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/tetris-with-opencv-python&#34;&gt;Tetris Game using OpenCV Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Tetris&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-classification-with-opencv-for-android/&#34;&gt;Image Classification with OpenCV for Android&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/DNN-OpenCV-Classification-Android&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-classification-with-opencv-java&#34;&gt;Image Classification with OpenCV Java&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/DNN-OpenCV-Classification-with-Java&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/pytorch-to-tensorflow-model-conversion/&#34;&gt;PyTorch to Tensorflow Model Conversion&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-to-TensorFlow-Model-Conversion&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/snake-game-with-opencv-python/&#34;&gt;Snake Game with OpenCV Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/SnakeGame&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/stanford-mrnet-challenge-classifying-knee-mris/&#34;&gt;Stanford MRNet Challenge: Classifying Knee MRIs&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/MRNet-Single-Model&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/experiment-logging-with-tensorboard-and-wandb&#34;&gt;Experiment Logging with TensorBoard and wandb&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-Vision-Experiment-Logging&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/understanding-lens-distortion/&#34;&gt;Understanding Lens Distortion&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/UnderstandingLensDistortion&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-matting-with-state-of-the-art-method-f-b-alpha-matting/&#34;&gt;Image Matting with state-of-the-art Method ‚ÄúF, B, Alpha Matting‚Äù&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/FBAMatting&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/bag-of-tricks-for-image-classification-lets-check-if-it-is-working-or-not/&#34;&gt;Bag Of Tricks For Image Classification - Let&#39;s check if it is working or not&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Bag-Of-Tricks-For-Image-Classification&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/getting-started-opencv-cuda-module/&#34;&gt;Getting Started with OpenCV CUDA Module&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Getting-Started-OpenCV-CUDA-Module&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/training-a-custom-object-detector-with-dlib-making-gesture-controlled-applications/&#34;&gt;Training a Custom Object Detector with DLIB &amp;amp; Making Gesture Controlled Applications&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Training_a_custom_hand_detector_with_dlib&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/how-to-run-inference-using-tensorrt-c-api/&#34;&gt;How To Run Inference Using TensorRT C++ API&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-ONNX-TensorRT-CPP&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/using-facial-landmarks-for-overlaying-faces-with-masks/&#34;&gt;Using Facial Landmarks for Overlaying Faces with Medical Masks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/FaceMaskOverlay&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/tensorboard-with-pytorch-lightning&#34;&gt;Tensorboard with PyTorch Lightning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/TensorBoard-With-Pytorch-Lightning&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/otsu-thresholding-with-opencv/&#34;&gt;Otsu&#39;s Thresholding with OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/otsu-method&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/pytorch-to-coreml-model-conversion/&#34;&gt;PyTorch-to-CoreML-model-conversion&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-to-CoreML-model-conversion&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/playing-rock-paper-scissors-with-ai/&#34;&gt;Playing Rock, Paper, Scissors with AI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Playing-rock-paper-scissors-with-AI&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/cnn-receptive-field-computation-using-backprop-with-tensorflow/&#34;&gt;CNN Receptive Field Computation Using Backprop with TensorFlow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Receptive-Field-With-Backprop&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/cnn-fully-convolutional-image-classification-with-tensorflow&#34;&gt;CNN Fully Convolutional Image Classification with TensorFlow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Fully-Convolutional-Image-Classification&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/how-to-convert-a-model-from-pytorch-to-tensorrt-and-speed-up-inference/&#34;&gt;How to convert a model from PyTorch to TensorRT and speed up inference&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-ONNX-TensorRT&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/efficient-image-loading/&#34;&gt;Efficient image loading&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Efficient-image-loading&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/graph-convolutional-networks-model-relations-in-data/&#34;&gt;Graph Convolutional Networks: Model Relations In Data&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Graph-Convolutional-Networks-Model-Relations-In-Data&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/federated-learning-using-pytorch-and-pysyft/&#34;&gt;Getting Started with Federated Learning with PyTorch and PySyft&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Federated-Learning-Intro&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/creating-a-virtual-pen-and-eraser-with-opencv/&#34;&gt;Creating a Virtual Pen &amp;amp; Eraser&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Creating-a-Virtual-Pen-and-Eraser&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/getting-started-with-pytorch-lightning/&#34;&gt;Getting Started with PyTorch Lightning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Pytorch-Lightning&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/&#34;&gt;Multi-Label Image Classification with PyTorch: Image Tagging&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-Multi-Label-Image-Classification-Image-Tagging&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/Funny-Mirrors-Using-OpenCV/&#34;&gt;Funny Mirrors Using OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/FunnyMirrors&#34;&gt;code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/t-sne-for-resnet-feature-visualization/&#34;&gt;t-SNE for ResNet feature visualization&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/TSNE&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/multi-label-image-classification-with-pytorch/&#34;&gt;Multi-Label Image Classification with Pytorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-Multi-Label-Image-Classification&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/cnn-receptive-field-computation-using-backprop/&#34;&gt;CNN Receptive Field Computation Using Backprop&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-Receptive-Field-With-Backprop&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/cnn-receptive-field-computation-using-backprop-with-tensorflow/&#34;&gt;CNN Receptive Field Computation Using Backprop with TensorFlow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Receptive-Field-With-Backprop&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/augmented-reality-using-aruco-markers-in-opencv-(c++-python)/&#34;&gt;Augmented Reality using AruCo Markers in OpenCV(C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/AugmentedRealityWithArucoMarkers&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/fully-convolutional-image-classification-on-arbitrary-sized-image/&#34;&gt;Fully Convolutional Image Classification on Arbitrary Sized Image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-Fully-Convolutional-Image-Classification&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/camera-calibration-using-opencv/&#34;&gt;Camera Calibration using OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/CameraCalibration&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/geometry-of-image-formation/&#34;&gt;Geometry of Image Formation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/ensuring-training-reproducibility-in-pytorch&#34;&gt;Ensuring Training Reproducibility in Pytorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/gaze-tracking/&#34;&gt;Gaze Tracking&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/simple-background-estimation-in-videos-using-opencv-c-python/&#34;&gt;Simple Background Estimation in Videos Using OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/VideoBackgroundEstimation&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/applications-of-foreground-background-separation-with-semantic-segmentation/&#34;&gt;Applications of Foreground-Background separation with Semantic Segmentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/app-seperation-semseg&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/efficientnet-theory-code&#34;&gt;EfficientNet: Theory + Code&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/EfficientNet&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/mask-r-cnn-instance-segmentation-with-pytorch/&#34;&gt;PyTorch for Beginners: Mask R-CNN Instance Segmentation with PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/spmallick/learnopencv/master/PyTorch-Mask-RCNN&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/faster-r-cnn-object-detection-with-pytorch&#34;&gt;PyTorch for Beginners: Faster R-CNN Object Detection with PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-faster-RCNN&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/pytorch-for-beginners-semantic-segmentation-using-torchvision/&#34;&gt;PyTorch for Beginners: Semantic Segmentation using torchvision&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-Segmentation-torchvision&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-classification-using-pre-trained-models-using-pytorch/&#34;&gt;PyTorch for Beginners: Comparison of pre-trained models for Image Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Image-classification-pre-trained-models/Image_Classification_using_pre_trained_models.ipynb&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/pytorch-for-beginners-basics/&#34;&gt;PyTorch for Beginners: Basics&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/PyTorch-for-Beginners/PyTorch_for_Beginners.ipynb&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/pytorch-model-inference-using-onnx-and-caffe2/&#34;&gt;PyTorch Model Inference using ONNX and Caffe2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Inference-for-PyTorch-Models/ONNX-Caffe2&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-classification-using-transfer-learning-in-pytorch/&#34;&gt;Image Classification Using Transfer Learning in PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Image-Classification-in-PyTorch&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/hangman-creating-games-in-opencv/&#34;&gt;Hangman: Creating games in OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Hangman&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-inpainting-with-opencv-c-python/&#34;&gt;Image Inpainting with OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Image-Inpainting&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/hough-transform-with-opencv-c-python/&#34;&gt;Hough Transform with OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Hough-Transform&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/xeus-cling-run-c-code-in-jupyter-notebook/&#34;&gt;Xeus-Cling: Run C++ code in Jupyter Notebook&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/XeusCling&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/&#34;&gt;Gender &amp;amp; Age Classification using OpenCV Deep Learning ( C++/Python )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/AgeGender&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/invisibility-cloak-using-color-detection-and-segmentation-with-opencv/&#34;&gt;Invisibility Cloak using Color Detection and Segmentation with OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/InvisibilityCloak&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/fast-image-downloader-for-open-images-v4/&#34;&gt;Fast Image Downloader for Open Images V4 (Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/downloadOpenImages&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/deep-learning-based-text-detection-using-opencv-c-python/&#34;&gt;Deep Learning based Text Detection Using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/TextDetectionEAST&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/video-stabilization-using-point-feature-matching-in-opencv/&#34;&gt;Video Stabilization Using Point Feature Matching in OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/VideoStabilization&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/training-yolov3-deep-learning-based-custom-object-detector/&#34;&gt;Training YOLOv3 : Deep Learning based Custom Object Detector&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/YOLOv3-Training-Snowman-Detector&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/using-openvino-with-opencv/&#34;&gt;Using OpenVINO with OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OpenVINO-OpenCV&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/duplicate-search-on-quora-dataset/&#34;&gt;Duplicate Search on Quora Dataset&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Quora-Dataset-Duplicate-Search&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/shape-matching-using-hu-moments-c-python/&#34;&gt;Shape Matching using Hu Moments (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/HuMoments&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-4-on-centos-7/&#34;&gt;Install OpenCV 4 on CentOS (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-3-on-centos.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-3-4-4-on-centos-7/&#34;&gt;Install OpenCV 3.4.4 on CentOS (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-3-on-centos.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-3-4-4-on-red-hat/&#34;&gt;Install OpenCV 3.4.4 on Red Hat (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-3-on-red-hat.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-4-on-red-hat/&#34;&gt;Install OpenCV 4 on Red Hat (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-4-on-red-hat.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-4-on-macos/&#34;&gt;Install OpenCV 4 on macOS (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/InstallScripts/installOpenCV-4-macos.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-3-4-4-on-raspberry-pi/&#34;&gt;Install OpenCV 3.4.4 on Raspberry Pi&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-3-raspberry-pi.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-3-4-4-on-macos/&#34;&gt;Install OpenCV 3.4.4 on macOS (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-3-macos.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/opencv-qr-code-scanner-c-and-python/&#34;&gt;OpenCV QR Code Scanner (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/QRCode-OpenCV&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-3-4-4-on-windows/&#34;&gt;Install OpenCV 3.4.4 on Windows (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/InstallScripts/Windows-3&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-3-4-4-on-ubuntu-16-04/&#34;&gt;Install OpenCV 3.4.4 on Ubuntu 16.04 (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-3-on-Ubuntu-16-04.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-3-4-4-on-ubuntu-18-04/&#34;&gt;Install OpenCV 3.4.4 on Ubuntu 18.04 (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-3-on-Ubuntu-18-04.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/universal-sentence-encoder&#34;&gt;Universal Sentence Encoder&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/Universal-Sentence-Encoder&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-4-on-raspberry-pi/&#34;&gt;Install OpenCV 4 on Raspberry Pi&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-4-raspberry-pi.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-4-on-windows/&#34;&gt;Install OpenCV 4 on Windows (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/InstallScripts/Windows-4&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/hand-keypoint-detection-using-deep-learning-and-opencv/&#34;&gt;Hand Keypoint Detection using Deep Learning and OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/HandPose&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/deep-learning-based-object-detection-and-instance-segmentation-using-mask-r-cnn-in-opencv-python-c/&#34;&gt;Deep learning based Object Detection and Instance Segmentation using Mask R-CNN in OpenCV (Python / C++)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Mask-RCNN&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-4-on-ubuntu-18-04/&#34;&gt;Install OpenCV 4 on Ubuntu 18.04 (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-4-on-Ubuntu-18-04.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-4-on-ubuntu-16-04/&#34;&gt;Install OpenCV 4 on Ubuntu 16.04 (C++ and Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/raw/master/InstallScripts/installOpenCV-4-on-Ubuntu-16-04.sh&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/&#34;&gt;Multi-Person Pose Estimation in OpenCV using OpenPose&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OpenPose-Multi-Person&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/heatmap-for-logo-detection-using-opencv-python/&#34;&gt;Heatmap for Logo Detection using OpenCV (Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/heatmap&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/deep-learning-based-object-detection-using-yolov3-with-opencv-python-c/&#34;&gt;Deep Learning based Object Detection using YOLOv3 with OpenCV ( Python / C++ )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ObjectDetection-YOLO&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/convex-hull-using-opencv-in-python-and-c/&#34;&gt;Convex Hull using OpenCV in Python and C++&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ConvexHull&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/multitracker-multiple-object-tracking-using-opencv-c-python/&#34;&gt;MultiTracker : Multiple Object Tracking using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/MultiObjectTracker&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/convolutional-neural-network-based-image-colorization-using-opencv/&#34;&gt;Convolutional Neural Network based Image Colorization using OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Colorization&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/svm-using-scikit-learn-in-python/&#34;&gt;SVM using scikit-learn&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/SVM-using-Python&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/goturn-deep-learning-based-object-tracking/&#34;&gt;GOTURN: Deep Learning based Object Tracking&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/GOTURN&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/find-center-of-blob-centroid-using-opencv-cpp-python/&#34;&gt;Find the Center of a Blob (Centroid) using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/CenterofBlob&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/support-vector-machines-svm/&#34;&gt;Support Vector Machines (SVM)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/SVM-using-Python&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/batch-normalization-in-deep-networks/&#34;&gt;Batch Normalization in Deep Networks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/BatchNormalization&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/deep-learning-character-classification-using-synthetic-dataset/&#34;&gt;Deep Learning based Character Classification using Synthetic Dataset&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/CharClassification&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-quality-assessment-brisque/&#34;&gt;Image Quality Assessment : BRISQUE&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ImageMetrics&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/understanding-alexnet/&#34;&gt;Understanding AlexNet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/deep-learning-based-text-recognition-ocr-using-tesseract-and-opencv/&#34;&gt;Deep Learning based Text Recognition (OCR) using Tesseract and OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OCR&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/&#34;&gt;Deep Learning based Human Pose Estimation using OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OpenPose&#34;&gt; Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/&#34;&gt;Number of Parameters and Tensor Sizes in a Convolutional Neural Network (CNN)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/how-to-convert-your-opencv-c-code-into-a-python-module/&#34;&gt;How to convert your OpenCV C++ code into a Python module&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/pymodule&#34;&gt; Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/cv4faces-best-project-award-2018/&#34;&gt;CV4Faces : Best Project Award 2018&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/facemark-facial-landmark-detection-using-opencv/&#34;&gt;Facemark : Facial Landmark Detection using OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/FacialLandmarkDetection&#34;&gt; Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-alignment-feature-based-using-opencv-c-python/&#34;&gt;Image Alignment (Feature Based) using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ImageAlignment-FeatureBased&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/barcode-and-qr-code-scanner-using-zbar-and-opencv/&#34;&gt;Barcode and QR code Scanner using ZBar and OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/barcode-QRcodeScanner&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/&#34;&gt;Keras Tutorial : Fine-tuning using pre-trained models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Keras-Fine-Tuning&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/opencv-transparent-api/&#34;&gt;OpenCV Transparent API&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/face-reconstruction-using-eigenfaces-cpp-python/&#34;&gt;Face Reconstruction using EigenFaces (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ReconstructFaceUsingEigenFaces&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/eigenface-using-opencv-c-python/&#34;&gt;Eigenface using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/EigenFace&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/principal-component-analysis/&#34;&gt;Principal Component Analysis&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/keras-tutorial-transfer-learning-using-pre-trained-models/&#34;&gt;Keras Tutorial : Transfer Learning using pre-trained models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Keras-Transfer-Learning&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/keras-tutorial-using-pre-trained-imagenet-models/&#34;&gt;Keras Tutorial : Using pre-trained Imagenet models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Keras-ImageNet-Models&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/technical-aspects-of-a-digital-slr/&#34;&gt;Technical Aspects of a Digital SLR&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/using-harry-potter-interactive-wand-with-opencv-to-create-magic/&#34;&gt;Using Harry Potter interactive wand with OpenCV to create magic&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/install-opencv-3-and-dlib-on-windows-python-only/&#34;&gt;Install OpenCV 3 and Dlib on Windows ( Python only )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras&#34;&gt;Image Classification using Convolutional Neural Networks in Keras&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/KerasCNN-CIFAR&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/understanding-autoencoders-using-tensorflow-python/&#34;&gt;Understanding Autoencoders using Tensorflow (Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/DenoisingAutoencoder&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/best-project-award-computer-vision-for-faces/&#34;&gt;Best Project Award : Computer Vision for Faces&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/understanding-activation-functions-in-deep-learning/&#34;&gt;Understanding Activation Functions in Deep Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/image-classification-using-feedforward-neural-network-in-keras/&#34;&gt;Image Classification using Feedforward Neural Network in Keras&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/KerasMLP-MNIST&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/exposure-fusion-using-opencv-cpp-python/&#34;&gt;Exposure Fusion using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ExposureFusion&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.learnopencv.com/understanding-feedforward-neural-networks/&#34;&gt;Understanding Feedforward Neural Networks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/high-dynamic-range-hdr-imaging-using-opencv-cpp-python&#34;&gt;High Dynamic Range (HDR) Imaging using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/hdr&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/deep-learning-using-keras-the-basics&#34;&gt;Deep learning using Keras ‚Äì The Basics&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/keras-linear-regression&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/selective-search-for-object-detection-cpp-python/&#34;&gt;Selective Search for Object Detection (C++ / Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/SelectiveSearch&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/installing-deep-learning-frameworks-on-ubuntu-with-cuda-support/&#34;&gt;Installing Deep Learning Frameworks on Ubuntu with CUDA support&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/parallel-pixel-access-in-opencv-using-foreach/&#34;&gt;Parallel Pixel Access in OpenCV using forEach&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/forEach&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/cvui-gui-lib-built-on-top-of-opencv-drawing-primitives/&#34;&gt;cvui: A GUI lib built on top of OpenCV drawing primitives&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/UI-cvui&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/install-dlib-on-windows/&#34;&gt;Install Dlib on Windows&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/install-dlib-on-ubuntu/&#34;&gt;Install Dlib on Ubuntu&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/install-opencv3-on-ubuntu/&#34;&gt;Install OpenCV3 on Ubuntu&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/&#34;&gt;Read, Write and Display a video using OpenCV ( C++/ Python )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/VideoReadWriteDisplay&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/install-dlib-on-macos/&#34;&gt;Install Dlib on MacOS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/install-opencv3-on-macos/&#34;&gt;Install OpenCV 3 on MacOS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/install-opencv3-on-windows/&#34;&gt;Install OpenCV 3 on Windows&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/get-opencv-build-information-getbuildinformation/&#34;&gt;Get OpenCV Build Information ( getBuildInformation )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/color-spaces-in-opencv-cpp-python/&#34;&gt;Color spaces in OpenCV (C++ / Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ColorSpaces&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/neural-networks-a-30000-feet-view-for-beginners/&#34;&gt;Neural Networks : A 30,000 Feet View for Beginners&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/alpha-blending-using-opencv-cpp-python/&#34;&gt;Alpha Blending using OpenCV (C++ / Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/AlphaBlending&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/user-stories-how-readers-of-this-blog-are-applying-their-knowledge-to-build-applications/&#34;&gt;User stories : How readers of this blog are applying their knowledge to build applications&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/how-to-select-a-bounding-box-roi-in-opencv-cpp-python/&#34;&gt;How to select a bounding box ( ROI ) in OpenCV (C++/Python) ?&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/automatic-red-eye-remover-using-opencv-cpp-python/&#34;&gt;Automatic Red Eye Remover using OpenCV (C++ / Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/RedEyeRemover&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/bias-variance-tradeoff-in-machine-learning/&#34;&gt;Bias-Variance Tradeoff in Machine Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/embedded-computer-vision-which-device-should-you-choose/&#34;&gt;Embedded Computer Vision: Which device should you choose?&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/object-tracking-using-opencv-cpp-python/&#34;&gt;Object Tracking using OpenCV (C++/Python)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/tracking&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/handwritten-digits-classification-an-opencv-c-python-tutorial/&#34;&gt;Handwritten Digits Classification : An OpenCV ( C++ / Python ) Tutorial&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/digits-classification&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/training-better-haar-lbp-cascade-eye-detector-opencv/&#34;&gt;Training a better Haar and LBP cascade based Eye Detector using OpenCV&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/deep-learning-book-gift-recipients/&#34;&gt;Deep Learning Book Gift Recipients&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/minified-opencv-haar-and-lbp-cascades/&#34;&gt;Minified OpenCV Haar and LBP Cascades&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ninjaEyeDetector&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/deep-learning-book-gift/&#34;&gt;Deep Learning Book Gift&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/histogram-of-oriented-gradients/&#34;&gt;Histogram of Oriented Gradients&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/image-recognition-and-object-detection-part1/&#34;&gt;Image Recognition and Object Detection : Part 1&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/&#34;&gt;Head Pose Estimation using OpenCV and Dlib&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/HeadPose&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/live-cv/&#34;&gt;Live CV : A Computer Vision Coding Application&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/approximate-focal-length-for-webcams-and-cell-phone-cameras/&#34;&gt;Approximate Focal Length for Webcams and Cell Phone Cameras&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/configuring-qt-for-opencv-on-osx/&#34;&gt;Configuring Qt for OpenCV on OSX&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/qt-test&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/rotation-matrix-to-euler-angles/&#34;&gt;Rotation Matrix To Euler Angles&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/RotationMatrixToEulerAngles&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/speeding-up-dlib-facial-landmark-detector/&#34;&gt;Speeding up Dlib‚Äôs Facial Landmark Detector&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/warp-one-triangle-to-another-using-opencv-c-python/&#34;&gt;Warp one triangle to another using OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/WarpTriangle&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/average-face-opencv-c-python-tutorial/&#34;&gt;Average Face : OpenCV ( C++ / Python ) Tutorial&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/FaceAverage&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/face-swap-using-opencv-c-python/&#34;&gt;Face Swap using OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/FaceSwap&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/face-morph-using-opencv-cpp-python/&#34;&gt;Face Morph Using OpenCV ‚Äî C++ / Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/FaceMorph&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/deep-learning-example-using-nvidia-digits-3-on-ec2/&#34;&gt;Deep Learning Example using NVIDIA DIGITS 3 on EC2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/nvidia-digits-3-on-ec2/&#34;&gt;NVIDIA DIGITS 3 on EC2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/homography-examples-using-opencv-python-c/&#34;&gt;Homography Examples using OpenCV ( Python / C ++ )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Homography&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/filling-holes-in-an-image-using-opencv-python-c/&#34;&gt;Filling holes in an image using OpenCV ( Python / C++ )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Holes&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/how-to-find-frame-rate-or-frames-per-second-fps-in-opencv-python-cpp/&#34;&gt;How to find frame rate or frames per second (fps) in OpenCV ( Python / C++ ) ?&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/FPS&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/&#34;&gt;Delaunay Triangulation and Voronoi Diagram using OpenCV ( C++ / Python) &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Delaunay&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/opencv-c-vs-python-vs-matlab-for-computer-vision/&#34;&gt;OpenCV (C++ vs Python) vs MATLAB for Computer Vision&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/facial-landmark-detection/&#34;&gt;Facial Landmark Detection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/why-does-opencv-use-bgr-color-format/&#34;&gt;Why does OpenCV use BGR color format ?&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/computer-vision-for-predicting-facial-attractiveness/&#34;&gt;Computer Vision for Predicting Facial Attractiveness&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/FacialAttractiveness&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/applycolormap-for-pseudocoloring-in-opencv-c-python/&#34;&gt;applyColorMap for pseudocoloring in OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Colormap&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/image-alignment-ecc-in-opencv-c-python/&#34;&gt;Image Alignment (ECC) in OpenCV ( C++ / Python )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/ImageAlignment&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/how-to-find-opencv-version-python-cpp/&#34;&gt;How to find OpenCV version in Python and C++ ?&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/baidu-banned-from-ilsvrc-2015/&#34;&gt;Baidu banned from ILSVRC 2015&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/opencv-transparent-api/&#34;&gt;OpenCV Transparent API&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/how-computer-vision-solved-the-greatest-soccer-mystery-of-all-times/&#34;&gt;How Computer Vision Solved the Greatest Soccer Mystery of All Time&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/embedded-vision-summit-2015/&#34;&gt;Embedded Vision Summit 2015&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/read-an-image-in-opencv-python-cpp/&#34;&gt;Read an Image in OpenCV ( Python, C++ )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/imread&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/non-photorealistic-rendering-using-opencv-python-c/&#34;&gt;Non-Photorealistic Rendering using OpenCV ( Python, C++ )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/NonPhotorealisticRendering&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/seamless-cloning-using-opencv-python-cpp/&#34;&gt;Seamless Cloning using OpenCV ( Python , C++ )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/SeamlessCloning&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/opencv-threshold-python-cpp/&#34;&gt;OpenCV Threshold ( Python , C++ )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Threshold&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/blob-detection-using-opencv-python-c/&#34;&gt;Blob Detection Using OpenCV ( Python, C++ )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/BlobDetector&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/turn-your-opencv-Code-into-a-web-api-in-under-10-minutes-part-1/&#34;&gt;Turn your OpenCV Code into a Web API in under 10 minutes ‚Äî Part 1&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/how-to-compile-opencv-sample-Code/&#34;&gt;How to compile OpenCV sample Code ?&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.learnopencv.com/install-opencv-3-on-yosemite-osx-10-10-x/&#34;&gt;Install OpenCV 3 on Yosemite ( OSX 10.10.x )&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/create-snapchat-instagram-filters-using-mediapipe/&#34;&gt;Create Snapchat/Instagram Filters Using Medipipe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Create-AR-filters-using-Mediapipe&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/object-detection-with-depth-measurement-with-oak-d/&#34;&gt;Object detection with depth measurement using pre-trained models with OAK-D&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OAK-Object-Detection-with-Depth&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/depthai-pipeline-overview-creating-a-complex-pipeline/&#34;&gt;DepthAi Pipeline Overview&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/OAK-DepthAi-Pipeline-Overview&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/anti-spoofing-face-recognition-system-using-oak-d-and-depthai/&#34;&gt;Anti-Spoofing Face Recognition with OAK-D&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Anti-Spoofing-Face-Recognition-with-OAK-D&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/understanding-multiple-object-tracking-using-deepsort/&#34;&gt;Understanding Multiple Object Tracking using DeepSORT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Understanding-Multiple-Object-Tracking-using-DeepSORT&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/automatic-document-scanner-using-opencv/&#34;&gt;Automatic Document Scanner&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Automatic-Document-Scanner&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://learnopencv.com/pothole-detection-using-yolov4-and-darknet/&#34;&gt;Pothole Detection using YOLOv4 and Darknet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv/tree/master/Pothole-Detection-using-YOLOv4-and-Darknet&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>