<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-03T01:46:41Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>datawhalechina/self-llm</title>
    <updated>2024-03-03T01:46:41Z</updated>
    <id>tag:github.com,2024-03-03:/datawhalechina/self-llm</id>
    <link href="https://github.com/datawhalechina/self-llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;《开源大模型食用指南》基于AutoDL快速部署开源大模型，更适合中国宝宝的部署教程&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;开源大模型食用指南&lt;/h1&gt; &#xA;&lt;h2&gt;项目简介&lt;/h2&gt; &#xA;&lt;p&gt;  本项目是一个围绕开源大模型、针对国内初学者、基于 AutoDL 平台的中国宝宝专属大模型教程，针对各类开源大模型提供包括环境配置、本地部署、高效微调等技能在内的全流程指导，简化开源大模型的部署、使用和应用流程，让更多的普通学生、研究者更好地使用开源大模型，帮助开源、自由的大模型更快融入到普通学习者的生活中。&lt;/p&gt; &#xA;&lt;p&gt;  本项目的主要内容包括：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;基于 AutoDL 平台（可扩展，例如阿里云）的开源 LLM 环境配置指南，针对不同模型要求提供不同的详细环境配置步骤；&lt;/li&gt; &#xA; &lt;li&gt;针对国内外主流开源 LLM 的部署使用教程，包括 LLaMA、ChatGLM、InternLM 等；&lt;/li&gt; &#xA; &lt;li&gt;开源 LLM 的部署应用指导，包括命令行调用、在线 Demo 部署、LangChain 框架集成等；&lt;/li&gt; &#xA; &lt;li&gt;开源 LLM 的全量微调、高效微调方法，包括分布式全量微调、LoRA、ptuning 等。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;  &lt;strong&gt;项目的主要内容就是教程，让更多的学生和未来的从业者了解和熟悉开源大模型的食用方法！任何人都可以提出issue或是提交PR，共同构建维护这个项目。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;  想要深度参与的同学可以联系我们，我们会将你加入到项目的维护者中。&lt;/p&gt; &#xA;&lt;h2&gt;项目意义&lt;/h2&gt; &#xA;&lt;p&gt;  什么是大模型？&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;大模型（LLM）狭义上指基于深度学习算法进行训练的自然语言处理（NLP）模型，主要应用于自然语言理解和生成等领域，广义上还包括机器视觉（CV）大模型、多模态大模型和科学计算大模型等。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;  百模大战正值火热，开源 LLM 层出不穷。如今国内外已经涌现了众多优秀开源 LLM，国外如 LLaMA、Alpaca，国内如 ChatGLM、BaiChuan、InternLM（书生·蒲语）等。开源 LLM 支持用户本地部署、私域微调，每一个人都可以在开源 LLM 的基础上打造专属于自己的独特大模型。&lt;/p&gt; &#xA;&lt;p&gt;  然而，当前普通学生和用户想要使用这些大模型，需要具备一定的技术能力，才能完成模型的部署和使用。对于层出不穷又各有特色的开源 LLM，想要快速掌握一个开源 LLM 的应用方法，是一项比较有挑战的任务。&lt;/p&gt; &#xA;&lt;p&gt;  本项目旨在首先基于核心贡献者的经验，实现国内外主流开源 LLM 的部署、使用与微调教程；在实现主流 LLM 的相关部分之后，我们希望充分聚集共创者，一起丰富这个开源 LLM 的世界，打造更多、更全面特色 LLM 的教程。星火点点，汇聚成海。&lt;/p&gt; &#xA;&lt;p&gt;  &lt;em&gt;&lt;strong&gt;我们希望成为 LLM 与普罗大众的阶梯，以自由、平等的开源精神，拥抱更恢弘而辽阔的 LLM 世界。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;项目受众&lt;/h2&gt; &#xA;&lt;p&gt;  本项目适合以下学习者：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;想要使用或体验 LLM，但无条件获得或使用相关 API；&lt;/li&gt; &#xA; &lt;li&gt;希望长期、低成本、大量应用 LLM；&lt;/li&gt; &#xA; &lt;li&gt;对开源 LLM 感兴趣，想要亲自上手开源 LLM；&lt;/li&gt; &#xA; &lt;li&gt;NLP 在学，希望进一步学习 LLM；&lt;/li&gt; &#xA; &lt;li&gt;希望结合开源 LLM，打造领域特色的私域 LLM；&lt;/li&gt; &#xA; &lt;li&gt;以及最广大、最普通的学生群体。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;项目规划及进展&lt;/h2&gt; &#xA;&lt;p&gt;   本项目拟围绕开源 LLM 应用全流程组织，包括环境配置及使用、部署应用、微调等，每个部分覆盖主流及特点开源 LLM：&lt;/p&gt; &#xA;&lt;h3&gt;已支持模型&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/google/gemma-7b-it&#34;&gt;谷歌-Gemma&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; gemma-7b-it FastApi 部署调用 @东东 ddl=3月底&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; gemma-7b-it langchain 接入 @东东 ddl=3月底&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; gemma-7b-it WebDemo 部署 @东东 ddl=3月底&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; gemma-7b-it Peft Lora 微调 @东东 ddl=3月底&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/QwenLM/Qwen1.5.git&#34;&gt;Qwen 1.5&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen1.5/01-Qwen1.5-7B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;Qwen1.5-7B-chat FastApi 部署调用&lt;/a&gt; @颜鑫&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen1.5/02-Qwen1.5-7B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&#34;&gt;Qwen1.5-7B-chat langchain 接入&lt;/a&gt; @颜鑫&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen1.5/03-Qwen1.5-7B-Chat%20WebDemo.md&#34;&gt;Qwen1.5-7B-chat WebDemo 部署&lt;/a&gt; @颜鑫&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen1.5/04-Qwen1.5-7B-chat%20Lora%20%E5%BE%AE%E8%B0%83.md&#34;&gt;Qwen1.5-7B-chat Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/OpenBMB/MiniCPM.git&#34;&gt;MiniCPM&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/MiniCPM/MiniCPM-2B-chat%20transformers%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;MiniCPM-2B-chat transformers 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/MiniCPM/MiniCPM-2B-chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;MiniCPM-2B-chat FastApi 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/MiniCPM/MiniCPM-2B-chat%20langchain%E6%8E%A5%E5%85%A5.md&#34;&gt;MiniCPM-2B-chat langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/MiniCPM/MiniCPM-2B-chat%20WebDemo%E9%83%A8%E7%BD%B2.md&#34;&gt;MiniCPM-2B-chat webdemo 部署&lt;/a&gt; @Kailigithub&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/MiniCPM/MiniCPM-2B-chat%20Lora%20&amp;amp;&amp;amp;%20Full%20%E5%BE%AE%E8%B0%83.md&#34;&gt;MiniCPM-2B-chat Lora &amp;amp;&amp;amp; Full 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/THUDM/ChatGLM3.git&#34;&gt;ChatGLM3&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/ChatGLM/01-ChatGLM3-6B%20Transformer%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;ChatGLM3-6B Transformers 部署调用&lt;/a&gt; @丁悦 ddl=12.2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/ChatGLM/02-ChatGLM3-6B%20FastApi%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;ChatGLM3-6B FastApi 部署调用&lt;/a&gt; @丁悦 ddl=12.2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/ChatGLM/03-ChatGLM3-6B-chat.md&#34;&gt;ChatGLM3-6B chat WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/ChatGLM/04-ChatGLM3-6B-Code-Interpreter.md&#34;&gt;ChatGLM3-6B Code Interpreter WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/ChatGLM/05-ChatGLM3-6B%E6%8E%A5%E5%85%A5LangChain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&#34;&gt;ChatGLM3-6B 接入 LangChain 框架&lt;/a&gt; @ Logan Zou&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/ChatGLM/06-ChatGLM3-6B-Lora%E5%BE%AE%E8%B0%83.md&#34;&gt;ChatGLM3-6B Lora 微调&lt;/a&gt; @ Hongru0306&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-LLM&#34;&gt;DeepSeek 深度求索&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/DeepSeek/01-DeepSeek-7B-chat%20FastApi.md&#34;&gt;DeepSeek-7B-chat FastApi 部署调用&lt;/a&gt; @ 不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/DeepSeek/02-DeepSeek-7B-chat%20langchain.md&#34;&gt;DeepSeek-7B-chat langchain 接入&lt;/a&gt; @ 不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/DeepSeek/03-DeepSeek-7B-chat%20WebDemo.md&#34;&gt;DeepSeek-7B-chat WebDemo&lt;/a&gt; @ 不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/DeepSeek/04-DeepSeek-7B-chat%20Lora%20%E5%BE%AE%E8%B0%83.md&#34;&gt;DeepSeek-7B-chat Lora 微调&lt;/a&gt; @ 不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/DeepSeek/05-DeepSeek-7B-chat%204bits%E9%87%8F%E5%8C%96%20Qlora%20%E5%BE%AE%E8%B0%83.md&#34;&gt;DeepSeek-7B-chat 4bits量化 Qlora 微调&lt;/a&gt; @ 不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/DeepSeek/06-DeepSeek-MoE-16b-chat%20Transformer%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;DeepSeek-MoE-16b-chat Transformers 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/DeepSeek/06-DeepSeek-MoE-16b-chat%20FastApi.md&#34;&gt;DeepSeek-MoE-16b-chat FastApi 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/QwenLM/Qwen-Audio.git&#34;&gt;Qwen-Audio&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen-Audio/01-Qwen-Audio-chat%20FastApi.md&#34;&gt;Qwen-Audio FastApi 部署调用&lt;/a&gt; @ jjyaoao&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen-Audio/02-Qwen-Audio-chat%20WebDemo.md&#34;&gt;Qwen-Audio WebDemo&lt;/a&gt; @ jjyaoao&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/QwenLM/Qwen.git&#34;&gt;Qwen&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen/01-Qwen-7B-Chat%20Transformers%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;Qwen-7B-chat Transformers 部署调用&lt;/a&gt; @娇娇 ddl=12.2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen/02-Qwen-7B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;Qwen-7B-chat FastApi 部署调用&lt;/a&gt; @娇娇 ddl=12.2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen/03-Qwen-7B-Chat%20WebDemo.md&#34;&gt;Qwen-7B-chat WebDemo&lt;/a&gt; @娇娇 ddl=12.2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen/04-Qwen-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md&#34;&gt;Qwen-7B-chat Lora 微调&lt;/a&gt; @ 不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen/05-Qwen-7B-Chat%20Ptuning%20%E5%BE%AE%E8%B0%83.md&#34;&gt;Qwen-7B-chat ptuning 微调&lt;/a&gt; @ Hongru0306&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen/06-Qwen-7B-chat%20%E5%85%A8%E9%87%8F%E5%BE%AE%E8%B0%83.md&#34;&gt;Qwen-7B-chat 全量微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen/07-Qwen-7B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&#34;&gt;Qwen-7B-Chat 接入langchain搭建知识库助手&lt;/a&gt; @娇娇&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen/08-Qwen-7B-Chat%20Lora%20%E4%BD%8E%E7%B2%BE%E5%BA%A6%E5%BE%AE%E8%B0%83.md&#34;&gt;Qwen-7B-chat 低精度训练&lt;/a&gt; @ Hongru0306 ddl=12.11&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Qwen/09-Qwen-1_8B-chat%20CPU%20%E9%83%A8%E7%BD%B2%20.md&#34;&gt;Qwen-1_8B-chat CPU 部署&lt;/a&gt; @ 散步&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/01-ai/Yi.git&#34;&gt;Yi 零一万物&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Yi/01-Yi-6B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;Yi-6B-chat FastApi 部署调用&lt;/a&gt; @ Joe ddl=12.15&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Yi/02-Yi-6B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&#34;&gt;Yi-6B-chat langchain接入&lt;/a&gt; @ Joe ddl=12.15&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Yi/03-Yi-6B-chat%20WebDemo.md&#34;&gt;Yi-6B-chat WebDemo&lt;/a&gt; @ Hongru0306 ddl=12.15&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Yi/04-Yi-6B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md&#34;&gt;Yi-6B-chat Lora 微调&lt;/a&gt; @ 娇娇 ddl=12.15&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.baichuan-ai.com/home&#34;&gt;Baichuan 百川智能&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/BaiChuan/01-Baichuan2-7B-chat%2BFastApi%2B%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;Baichuan2-7B-chat FastApi 部署调用&lt;/a&gt; @ 三山时春い ddl=12.15&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/BaiChuan/02-Baichuan-7B-chat%2BWebDemo.md&#34;&gt;Baichuan2-7B-chat WebDemo&lt;/a&gt; @ 三山时春いddl=12.15&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/BaiChuan/03-Baichuan2-7B-chat%E6%8E%A5%E5%85%A5LangChain%E6%A1%86%E6%9E%B6.md&#34;&gt;Baichuan2-7B-chat 接入 LangChain 框架&lt;/a&gt; @ 三山时春いddl=12.15&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/BaiChuan/04-Baichuan2-7B-chat%2Blora%2B%E5%BE%AE%E8%B0%83.md&#34;&gt;Baichuan2-7B-chat Lora 微调&lt;/a&gt; @ 三山时春いddl=12.15&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/InternLM/InternLM.git&#34;&gt;InternLM&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/InternLM/01-InternLM-Chat-7B%20Transformers%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&#34;&gt;InternLM-Chat-7B Transformers 部署调用&lt;/a&gt; @小罗 ddl=11.26&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/InternLM/02-internLM-Chat-7B%20FastApi.md&#34;&gt;InternLM-Chat-7B FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/InternLM/03-InternLM-Chat-7B.md&#34;&gt;InternLM-Chat-7B WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/InternLM/04-Lagent+InternLM-Chat-7B-V1.1.md&#34;&gt;Lagent+InternLM-Chat-7B-V1.1 WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/InternLM/05-%E6%B5%A6%E8%AF%AD%E7%81%B5%E7%AC%94%E5%9B%BE%E6%96%87%E7%90%86%E8%A7%A3&amp;amp;%E5%88%9B%E4%BD%9C.md&#34;&gt;浦语灵笔图文理解&amp;amp;创作 WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/InternLM/06-InternLM%E6%8E%A5%E5%85%A5LangChain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&#34;&gt;InternLM-Chat-7B 接入 LangChain 框架&lt;/a&gt; @ Logan Zou&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://hf-mirror.com/FlagAlpha/Atom-7B-Chat&#34;&gt;Atom (llama2)&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Atom/01-Atom-7B-chat-WebDemo.md&#34;&gt;Atom-7B-chat WebDemo&lt;/a&gt; @凯立 ddl=11.24&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Atom/02-Atom-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md&#34;&gt;Atom-7B-chat Lora&lt;/a&gt; 微调 @ Logan Zou&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Atom/03-Atom-7B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&#34;&gt;Atom-7B-Chat 接入langchain搭建知识库助手&lt;/a&gt; @ jjyaoao&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/Atom/04-Atom-7B-chat%20%E5%85%A8%E9%87%8F%E5%BE%AE%E8%B0%83.md&#34;&gt;Atom-7B-chat 全量微调&lt;/a&gt; @ Logan Zou&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;通用环境配置&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/01-pip%E3%80%81conda%E6%8D%A2%E6%BA%90.md&#34;&gt;pip、conda 换源&lt;/a&gt; @不要葱姜蒜&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/02-AutoDL%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3.md&#34;&gt;AutoDL 开放端口&lt;/a&gt; @不要葱姜蒜&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;模型下载&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&#34;&gt;hugging face&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&#34;&gt;hugging face&lt;/a&gt; 镜像下载 @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&#34;&gt;modelscope&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&#34;&gt;git-lfs&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&#34;&gt;Openxlab&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Issue &amp;amp;&amp;amp; PR&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/04-Issue&amp;amp;PR&amp;amp;update.md&#34;&gt;Issue 提交&lt;/a&gt; @ Hongru0306&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/04-Issue&amp;amp;PR&amp;amp;update.md&#34;&gt;PR 提交&lt;/a&gt; @ Hongru0306&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/04-Issue&amp;amp;PR&amp;amp;update.md&#34;&gt;fork更新&lt;/a&gt; @ Hongru0306&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;致谢&lt;/h2&gt; &#xA;&lt;h3&gt;核心贡献者&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/KMnO4-zx&#34;&gt;宋志学(不要葱姜蒜)-项目负责人&lt;/a&gt; （Datawhale成员-河南理工大学）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/logan-zou&#34;&gt;邹雨衡-项目负责人&lt;/a&gt; （Datawhale成员-对外经济贸易大学）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Hongru0306&#34;&gt;肖鸿儒&lt;/a&gt; （Datawhale意向成员-同济大学）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Aphasia0515&#34;&gt;李娇娇&lt;/a&gt; （Datawhale意向成员-鲸英助教）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lyj11111111&#34;&gt;小罗&lt;/a&gt; （Datawhale-鲸英助教）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dingyue772&#34;&gt;丁悦&lt;/a&gt; （Datawhale-鲸英助教）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Kailigithub&#34;&gt;Kailigithub&lt;/a&gt; （Datawhale-鲸英助教）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jjyaoao&#34;&gt;陈思州&lt;/a&gt; （Datawhale成员）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;李柯辰&lt;/a&gt; （Datawhale成员）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;散步&lt;/a&gt; （Datawhale成员）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;惠佳豪&lt;/a&gt; （Datawhale-宣传大使）&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/thomas-yanxin&#34;&gt;颜鑫&lt;/a&gt; （Datawhale成员）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;其他&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;特别感谢&lt;a href=&#34;https://github.com/Sm1les&#34;&gt;@Sm1les&lt;/a&gt;对本项目的帮助与支持&lt;/li&gt; &#xA; &lt;li&gt;部分lora代码和讲解参考仓库：&lt;a href=&#34;https://github.com/zyds/transformers-code.git&#34;&gt;https://github.com/zyds/transformers-code.git&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;如果有任何想法可以联系我们 DataWhale 也欢迎大家多多提出 issue&lt;/li&gt; &#xA; &lt;li&gt;特别感谢以下为教程做出贡献的同学！&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34; style=&#34;margin-top: 30px;&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/datawhalechina/self-llm/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=datawhalechina/self-llm&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Star History&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34; style=&#34;margin-top: 30px;&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/datawhalechina/self-llm/master/images/star-history-2024229.png&#34;&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>hustvl/4DGaussians</title>
    <updated>2024-03-03T01:46:41Z</updated>
    <id>tag:github.com,2024-03-03:/hustvl/4DGaussians</id>
    <link href="https://github.com/hustvl/4DGaussians" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[CVPR 2024]4D Gaussian Splatting for Real-Time Dynamic Scene Rendering&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;4D Gaussian Splatting for Real-Time Dynamic Scene Rendering&lt;/h1&gt; &#xA;&lt;h2&gt;CVPR 2024&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://guanjunwu.github.io/4dgs/index.html&#34;&gt;Project Page&lt;/a&gt;| &lt;a href=&#34;https://arxiv.org/abs/2310.08528&#34;&gt;arXiv Paper&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://guanjunwu.github.io/&#34;&gt;Guanjun Wu&lt;/a&gt; &lt;sup&gt;1*&lt;/sup&gt;, &lt;a href=&#34;https://github.com/taoranyi&#34;&gt;Taoran Yi&lt;/a&gt; &lt;sup&gt;2*&lt;/sup&gt;, &lt;a href=&#34;https://jaminfong.cn/&#34;&gt;Jiemin Fang&lt;/a&gt; &lt;sup&gt;3‡&lt;/sup&gt;, &lt;a href=&#34;http://lingxixie.com/&#34;&gt;Lingxi Xie&lt;/a&gt; &lt;sup&gt;3 &lt;/sup&gt;, &lt;br&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=Ud6aBAcAAAAJ&amp;amp;hl=zh-CN&#34;&gt;Xiaopeng Zhang&lt;/a&gt; &lt;sup&gt;3 &lt;/sup&gt;, &lt;a href=&#34;https://www.eric-weiwei.com/&#34;&gt;Wei Wei&lt;/a&gt; &lt;sup&gt;1 &lt;/sup&gt;,&lt;a href=&#34;http://eic.hust.edu.cn/professor/liuwenyu/&#34;&gt;Wenyu Liu&lt;/a&gt; &lt;sup&gt;2 &lt;/sup&gt;, &lt;a href=&#34;https://www.qitian1987.com/&#34;&gt;Qi Tian&lt;/a&gt; &lt;sup&gt;3 &lt;/sup&gt; , &lt;a href=&#34;https://xwcv.github.io&#34;&gt;Xinggang Wang&lt;/a&gt; &lt;sup&gt;2‡✉&lt;/sup&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;sup&gt;1 &lt;/sup&gt;School of CS, HUST   &lt;sup&gt;2 &lt;/sup&gt;School of EIC, HUST   &lt;sup&gt;3 &lt;/sup&gt;Huawei Inc.  &lt;/p&gt; &#xA;&lt;p&gt;&lt;sup&gt;*&lt;/sup&gt; Equal Contributions. &lt;sup&gt;$\ddagger$&lt;/sup&gt; Project Lead. &lt;sup&gt;✉&lt;/sup&gt; Corresponding Author.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hustvl/4DGaussians/master/assets/teaserfig.jpg&#34; alt=&#34;block&#34;&gt; Our method converges very quickly and achieves real-time rendering speed.&lt;/p&gt; &#xA;&lt;p&gt;New Colab demo:&lt;a href=&#34;https://colab.research.google.com/drive/1wz0D5Y9egAlcxXy8YO9UmpQ9oH51R7OW?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; (Thanks &lt;a href=&#34;https://github.com/Tasmay-Tibrewal&#34;&gt;Tasmay-Tibrewal &lt;/a&gt;)&lt;/p&gt; &#xA;&lt;p&gt;Old Colab demo:&lt;a href=&#34;https://colab.research.google.com/github/hustvl/4DGaussians/blob/master/4DGaussians.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; (Thanks &lt;a href=&#34;https://github.com/camenduru/4DGaussians-colab&#34;&gt;camenduru&lt;/a&gt;.)&lt;/p&gt; &#xA;&lt;p&gt;Light Gaussian implementation: &lt;a href=&#34;https://github.com/pablodawson/4DGaussians&#34;&gt;This link&lt;/a&gt; (Thanks &lt;a href=&#34;https://github.com/pablodawson&#34;&gt;pablodawson&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;p&gt;2024.02.28: Update SIBR viewer guidance. 2024.02.27: Accepted by CVPR 2024. We delete some logging settings for debugging, the corrected training time is only &lt;strong&gt;8 mins&lt;/strong&gt; (20 mins before) in D-NeRF datasets and &lt;strong&gt;30 mins&lt;/strong&gt; (1 hour before) in HyperNeRF datasets. The rendering quality is not affected.&lt;/p&gt; &#xA;&lt;h2&gt;Environmental Setups&lt;/h2&gt; &#xA;&lt;p&gt;Please follow the &lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;3D-GS&lt;/a&gt; to install the relative packages.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/hustvl/4DGaussians&#xA;cd 4DGaussians&#xA;git submodule update --init --recursive&#xA;conda create -n Gaussians4D python=3.7 &#xA;conda activate Gaussians4D&#xA;&#xA;pip install -r requirements.txt&#xA;pip install -e submodules/depth-diff-gaussian-rasterization&#xA;pip install -e submodules/simple-knn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In our environment, we use pytorch=1.13.1+cu116.&lt;/p&gt; &#xA;&lt;h2&gt;Data Preparation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;For synthetic scenes:&lt;/strong&gt; The dataset provided in &lt;a href=&#34;https://github.com/albertpumarola/D-NeRF&#34;&gt;D-NeRF&lt;/a&gt; is used. You can download the dataset from &lt;a href=&#34;https://www.dropbox.com/s/0bf6fl0ye2vz3vr/data.zip?dl=0&#34;&gt;dropbox&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For real dynamic scenes:&lt;/strong&gt; The dataset provided in &lt;a href=&#34;https://github.com/google/hypernerf&#34;&gt;HyperNeRF&lt;/a&gt; is used. You can download scenes from &lt;a href=&#34;https://github.com/google/hypernerf/releases/tag/v0.1&#34;&gt;Hypernerf Dataset&lt;/a&gt; and organize them as &lt;a href=&#34;https://github.com/google/nerfies#datasets&#34;&gt;Nerfies&lt;/a&gt;. Meanwhile, &lt;a href=&#34;https://github.com/facebookresearch/Neural_3D_Video&#34;&gt;Plenoptic Dataset&lt;/a&gt; could be downloaded from their official websites. To save the memory, you should extract the frames of each video and then organize your dataset as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;├── data&#xA;│   | dnerf &#xA;│     ├── mutant&#xA;│     ├── standup &#xA;│     ├── ...&#xA;│   | hypernerf&#xA;│     ├── interp&#xA;│     ├── misc&#xA;│     ├── virg&#xA;│   | dynerf&#xA;│     ├── cook_spinach&#xA;│       ├── cam00&#xA;│           ├── images&#xA;│               ├── 0000.png&#xA;│               ├── 0001.png&#xA;│               ├── 0002.png&#xA;│               ├── ...&#xA;│       ├── cam01&#xA;│           ├── images&#xA;│               ├── 0000.png&#xA;│               ├── 0001.png&#xA;│               ├── ...&#xA;│     ├── cut_roasted_beef&#xA;|     ├── ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;For training synthetic scenes such as &lt;code&gt;bouncingballs&lt;/code&gt;, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python train.py -s data/dnerf/bouncingballs --port 6017 --expname &#34;dnerf/bouncingballs&#34; --configs arguments/dnerf/bouncingballs.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can customize your training config through the config files.&lt;/p&gt; &#xA;&lt;p&gt;Checkpoint&lt;/p&gt; &#xA;&lt;p&gt;Also, you can training your model with checkpoint.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python train.py -s data/dnerf/bouncingballs --port 6017 --expname &#34;dnerf/bouncingballs&#34; --configs arguments/dnerf/bouncingballs.py --checkpoint_iterations 200 # change it.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then load checkpoint with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python train.py -s data/dnerf/bouncingballs --port 6017 --expname &#34;dnerf/bouncingballs&#34; --configs arguments/dnerf/bouncingballs.py --start_checkpoint &#34;output/dnerf/bouncingballs/chkpnt_coarse_200.pth&#34;&#xA;# finestage: --start_checkpoint &#34;output/dnerf/bouncingballs/chkpnt_fine_200.pth&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Rendering&lt;/h2&gt; &#xA;&lt;p&gt;Run the following script to render the images.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python render.py --model_path &#34;output/dnerf/bouncingballs/&#34;  --skip_train --configs arguments/dnerf/bouncingballs.py  &amp;amp;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;You can just run the following script to evaluate the model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python metrics.py --model_path &#34;output/dnerf/bouncingballs/&#34; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Custom Datasets&lt;/h2&gt; &#xA;&lt;p&gt;Install nerfstudio and follow their colmap pipeline.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install nerfstudio&#xA;ns-process-data images --data data/your-data --output-dir data/your-ns-data&#xA;cp -r data/your-ns-data/images data/your-ns-data/colmap/images&#xA;python train.py -s data/your-ns-data/colmap --port 6017 --expname &#34;custom&#34; --configs arguments/hypernerf/default.py &#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Viewer&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hustvl/4DGaussians/master/docs/viewer_usage.md&#34;&gt;Watch me&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Scripts&lt;/h2&gt; &#xA;&lt;p&gt;There are some helpful scripts in , please feel free to use them.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;vis_point.py&lt;/code&gt;: get all points clouds at each timestamps.&lt;/p&gt; &#xA;&lt;p&gt;usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;export exp_name=&#34;hypernerf&#34;&#xA;python vis_point.py --model_path output/$exp_name/interp/aleks-teapot --configs arguments/$exp_name/default.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;weight_visualization.ipynb&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;visualize the weight of Multi-resolution HexPlane module.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;merge_many_4dgs.py&lt;/code&gt;: merge your trained 4dgs. usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;export exp_name=&#34;dynerf&#34;&#xA;python merge_many_4dgs.py --model_path output/$exp_name/sear_steak&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;colmap.sh&lt;/code&gt;: generate point clouds from input data&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bash colmap.sh data/hypernerf/virg/vrig-chicken hypernerf &#xA;bash colmap.sh data/dynerf/sear_steak llff&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Blender&lt;/strong&gt; format seems doesn&#39;t work. Welcome to raise a pull request to fix it.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;downsample_point.py&lt;/code&gt; :downsample generated point clouds by sfm.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python scripts/downsample_point.py data/dynerf/sear_steak/colmap/dense/workspace/fused.ply data/dynerf/sear_steak/points3D_downsample2.ply&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In my paper, I always use &lt;code&gt;colmap.sh&lt;/code&gt; to generate dense point clouds and downsample it to less than 40000 points.&lt;/p&gt; &#xA;&lt;p&gt;Here are some codes maybe useful but never adopted in my paper, you can also try it.&lt;/p&gt; &#xA;&lt;h2&gt;Further works&lt;/h2&gt; &#xA;&lt;p&gt;We sincerely thank the authors and their fantastic works for other applications based on our code.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://md-splatting.github.io/&#34;&gt;MD-Splatting: Learning Metric Deformation from 4D Gaussians in Highly Deformable Scenes&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://vita-group.github.io/4DGen/&#34;&gt;4DGen: Grounded 4D Content Generation with Spatial-temporal Consistency&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jiawei-ren/dreamgaussian4d&#34;&gt;DreamGaussian4D: Generative 4D Gaussian Splatting&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/yifliu3/EndoGaussian&#34;&gt;EndoGaussian: Real-time Gaussian Splatting for Dynamic Endoscopic Scene Reconstruction&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/HKU-MedAI/EndoGS&#34;&gt;EndoGS: Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2401.16416&#34;&gt;Endo-4DGS: Endoscopic Monocular Scene Reconstruction with 4D Gaussian Splatting&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;This project is still under development. Please feel free to raise issues or submit pull requests to contribute to our codebase.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Some source code of ours is borrowed from &lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;3DGS&lt;/a&gt;, &lt;a href=&#34;https://github.com/Giodiro/kplanes_nerfstudio&#34;&gt;k-planes&lt;/a&gt;,&lt;a href=&#34;https://github.com/Caoang327/HexPlane&#34;&gt;HexPlane&lt;/a&gt;, &lt;a href=&#34;https://github.com/hustvl/TiNeuVox&#34;&gt;TiNeuVox&lt;/a&gt;. We sincerely appreciate the excellent works of these authors.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;We would like to express our sincere gratitude to &lt;a href=&#34;https://github.com/zhouzhenghong-gt/&#34;&gt;@zhouzhenghong-gt&lt;/a&gt; for his revisions to our code and discussions on the content of our paper.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Some insights about neural voxel grids and dynamic scenes reconstruction originate from &lt;a href=&#34;https://github.com/hustvl/TiNeuVox&#34;&gt;TiNeuVox&lt;/a&gt;. If you find this repository/work helpful in your research, welcome to cite these papers and give a ⭐.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{wu20234dgaussians,&#xA;  title={4D Gaussian Splatting for Real-Time Dynamic Scene Rendering},&#xA;  author={Wu, Guanjun and Yi, Taoran and Fang, Jiemin and Xie, Lingxi and Zhang, Xiaopeng and Wei Wei and Liu, Wenyu and Tian, Qi and Wang Xinggang},&#xA;  journal={arXiv preprint arXiv:2310.08528},&#xA;  year={2023}&#xA;}&#xA;&#xA;@inproceedings{TiNeuVox,&#xA;  author = {Fang, Jiemin and Yi, Taoran and Wang, Xinggang and Xie, Lingxi and Zhang, Xiaopeng and Liu, Wenyu and Nie\ss{}ner, Matthias and Tian, Qi},&#xA;  title = {Fast Dynamic Radiance Fields with Time-Aware Neural Voxels},&#xA;  year = {2022},&#xA;  booktitle = {SIGGRAPH Asia 2022 Conference Papers}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>GoogleCloudPlatform/ai-on-gke</title>
    <updated>2024-03-03T01:46:41Z</updated>
    <id>tag:github.com,2024-03-03:/GoogleCloudPlatform/ai-on-gke</id>
    <link href="https://github.com/GoogleCloudPlatform/ai-on-gke" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI on GKE Assets&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains assets related to AI/ML workloads on &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/integrations/ai-infra&#34;&gt;Google Kubernetes Engine (GKE)&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Run optimized AI/ML workloads with Google Kubernetes Engine (GKE) platform orchestration capabilities. A robust AI/ML platform considers the following layers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Infrastructure orchestration that support GPUs and TPUs for training and serving workloads at scale&lt;/li&gt; &#xA; &lt;li&gt;Flexible integration with distributed computing and data processing frameworks&lt;/li&gt; &#xA; &lt;li&gt;Support for multiple teams on the same infrastructure to maximize utilization of resources&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Infrastructure&lt;/h2&gt; &#xA;&lt;p&gt;The AI-on-GKE application modules assumes you already have a functional GKE cluster. If not, follow the instructions under &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/ai-on-gke/main/infrastructure/README.md&#34;&gt;infrastructure/README.md&lt;/a&gt; to install a Standard or Autopilot GKE cluster.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.&#xA;├── LICENSE&#xA;├── README.md&#xA;├── infrastructure&#xA;│   ├── README.md&#xA;│   ├── backend.tf&#xA;│   ├── main.tf&#xA;│   ├── outputs.tf&#xA;│   ├── platform.tfvars&#xA;│   ├── variables.tf&#xA;│   └── versions.tf&#xA;├── modules&#xA;│   ├── gke-autopilot-private-cluster&#xA;│   ├── gke-autopilot-public-cluster&#xA;│   ├── gke-standard-private-cluster&#xA;│   ├── gke-standard-public-cluster&#xA;│   ├── jupyter&#xA;│   ├── jupyter_iap&#xA;│   ├── jupyter_service_accounts&#xA;│   ├── kuberay-cluster&#xA;│   ├── kuberay-logging&#xA;│   ├── kuberay-monitoring&#xA;│   ├── kuberay-operator&#xA;│   └── kuberay-serviceaccounts&#xA;└── tutorial.md&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To deploy new GKE cluster update the &lt;code&gt;platform.tfvars&lt;/code&gt; file with the appropriate values and then execute below terraform commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;terraform init&#xA;terraform apply -var-file platform.tfvars&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Applications&lt;/h2&gt; &#xA;&lt;p&gt;The repo structure looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.&#xA;├── LICENSE&#xA;├── Makefile&#xA;├── README.md&#xA;├── applications&#xA;│   ├── jupyter&#xA;│   └── ray&#xA;├── contributing.md&#xA;├── dcgm-on-gke&#xA;│   ├── grafana&#xA;│   └── quickstart&#xA;├── gke-a100-jax&#xA;│   ├── Dockerfile&#xA;│   ├── README.md&#xA;│   ├── build_push_container.sh&#xA;│   ├── kubernetes&#xA;│   └── train.py&#xA;├── gke-batch-refarch&#xA;│   ├── 01_gke&#xA;│   ├── 02_platform&#xA;│   ├── 03_low_priority&#xA;│   ├── 04_high_priority&#xA;│   ├── 05_compact_placement&#xA;│   ├── 06_jobset&#xA;│   ├── Dockerfile&#xA;│   ├── README.md&#xA;│   ├── cloudbuild-create.yaml&#xA;│   ├── cloudbuild-destroy.yaml&#xA;│   ├── create-platform.sh&#xA;│   ├── destroy-platform.sh&#xA;│   └── images&#xA;├── gke-disk-image-builder&#xA;│   ├── README.md&#xA;│   ├── cli&#xA;│   ├── go.mod&#xA;│   ├── go.sum&#xA;│   ├── imager.go&#xA;│   └── script&#xA;├── gke-dws-examples&#xA;│   ├── README.md&#xA;│   ├── dws-queues.yaml&#xA;│   ├── job.yaml&#xA;│   └── kueue-manifests.yaml&#xA;├── gke-online-serving-single-gpu&#xA;│   ├── README.md&#xA;│   └── src&#xA;├── gke-tpu-examples&#xA;│   ├── single-host-inference&#xA;│   └── training&#xA;├── indexed-job&#xA;│   ├── Dockerfile&#xA;│   ├── README.md&#xA;│   └── mnist.py&#xA;├── jobset&#xA;│   └── pytorch&#xA;├── modules&#xA;│   ├── gke-autopilot-private-cluster&#xA;│   ├── gke-autopilot-public-cluster&#xA;│   ├── gke-standard-private-cluster&#xA;│   ├── gke-standard-public-cluster&#xA;│   ├── jupyter&#xA;│   ├── jupyter_iap&#xA;│   ├── jupyter_service_accounts&#xA;│   ├── kuberay-cluster&#xA;│   ├── kuberay-logging&#xA;│   ├── kuberay-monitoring&#xA;│   ├── kuberay-operator&#xA;│   └── kuberay-serviceaccounts&#xA;├── saxml-on-gke&#xA;│   ├── httpserver&#xA;│   └── single-host-inference&#xA;├── training-single-gpu&#xA;│   ├── README.md&#xA;│   ├── data&#xA;│   └── src&#xA;├── tutorial.md&#xA;└── tutorials&#xA;    ├── e2e-genai-langchain-app&#xA;    ├── finetuning-llama-7b-on-l4&#xA;    └── serving-llama2-70b-on-l4-gpus&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Jupyter Hub&lt;/h3&gt; &#xA;&lt;p&gt;This repository contains a Terraform template for running JupyterHub on Google Kubernetes Engine. We&#39;ve also included some example notebooks ( under &lt;code&gt;applications/ray/example_notebooks&lt;/code&gt;), including one that serves a GPT-J-6B model with Ray AIR (see here for the original notebook). To run these, follow the instructions at &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/ai-on-gke/main/applications/ray/README.md&#34;&gt;applications/ray/README.md&lt;/a&gt; to install a Ray cluster.&lt;/p&gt; &#xA;&lt;p&gt;This jupyter module deploys the following resources, once per user:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;JupyterHub deployment&lt;/li&gt; &#xA; &lt;li&gt;User namespace&lt;/li&gt; &#xA; &lt;li&gt;Kubernetes service accounts&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Learn more &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/ai-on-gke/main/applications/jupyter/README.md&#34;&gt;about JupyterHub on GKE here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Ray&lt;/h3&gt; &#xA;&lt;p&gt;This repository contains a Terraform template for running Ray on Google Kubernetes Engine.&lt;/p&gt; &#xA;&lt;p&gt;This module deploys the following, once per user:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;User namespace&lt;/li&gt; &#xA; &lt;li&gt;Kubernetes service accounts&lt;/li&gt; &#xA; &lt;li&gt;Kuberay cluster&lt;/li&gt; &#xA; &lt;li&gt;Prometheus monitoring&lt;/li&gt; &#xA; &lt;li&gt;Logging container&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Learn more &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/ai-on-gke/main/applications/ray/README.md&#34;&gt;about Ray on GKE here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Important Considerations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make sure to configure terraform backend to use GCS bucket, in order to persist terraform state across different environments.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Licensing&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The use of the assets contained in this repository is subject to compliance with &lt;a href=&#34;https://ai.google/responsibility/principles/&#34;&gt;Google&#39;s AI Principles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/ai-on-gke/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>