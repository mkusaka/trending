<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-12T01:54:13Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>wibus-wee/stable_diffusion_chilloutmix_ipynb</title>
    <updated>2023-03-12T01:54:13Z</updated>
    <id>tag:github.com,2023-03-12:/wibus-wee/stable_diffusion_chilloutmix_ipynb</id>
    <link href="https://github.com/wibus-wee/stable_diffusion_chilloutmix_ipynb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AUTOMATIC1111 Stable Diffusion WebUI 1.5 + ChilloutMix + Kohya&#39;s Scripts&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AUTOMATIC1111 Stable Diffusion WebUI 1.5 + ChilloutMix + Kohya&#39;s Scripts&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/wibus-wee/stable_diffusion_chilloutmix_ipynb/blob/main/stable_diffusion_1_5_webui.ipynb&#34;&gt;[Web UI] Go To Colab&lt;/a&gt; | &lt;a href=&#34;https://colab.research.google.com/github/wibus-wee/stable_diffusion_chilloutmix_ipynb/blob/main/lora_train.ipynb&#34;&gt;[LoRA Train] Go To Colab&lt;/a&gt; | &lt;a href=&#34;https://colab.research.google.com/github/wibus-wee/stable_diffusion_chilloutmix_ipynb/blob/main/xformers_build.ipynb&#34;&gt;[Xformers Build] Go To Colab&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/wibus-wee/stable_diffusion_chilloutmix_ipynb/main/prompts.md&#34;&gt;Prompts Collection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now the download script of &lt;a href=&#34;https://raw.githubusercontent.com/wibus-wee/stable_diffusion_chilloutmix_ipynb/main/#recommended-loras&#34;&gt;&#34;Recommended Loras&#34;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/wibus-wee/stable_diffusion_chilloutmix_ipynb/main/#recommended-checkpoints&#34;&gt;&#34;Recommended Checkpoints&#34;&lt;/a&gt; has been built into the script (before startup), if you don&#39;t want to download it, you can disable them before startup.&lt;/p&gt; &#xA;&lt;p&gt;Most of the models are the latest versions from &lt;a href=&#34;https://civitai.com&#34;&gt;CivitAI&lt;/a&gt;, but some LoRA models are marked with special versions, which are versions that I personally think are better. If you don&#39;t want to use this version, you may need to download other versions yourself (see below).&lt;/p&gt; &#xA;&lt;p&gt;If you want to download other models, you can go to the CivitAI tab in WebUI to download it yourself (if you have checked the install Civitai Browser extension option). In addition, remember to check the Save to Additional Network option.&lt;/p&gt; &#xA;&lt;p&gt;The script has already soft-linked the LoRA in Additional Network to the &lt;code&gt;models/Lora&lt;/code&gt; folder, but when using WebUI to download LoRA, you need to manually soft-link it to the &lt;code&gt;models/Stable-diffusion&lt;/code&gt; folder, or restart the program to refresh the soft link.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: Please note that there may be legal risks before painting. Please note whether your painting may cause controversy and negative impact on the development of the AI community. Please use it with caution.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Paperspace Support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support for training LoRA Jupyter Notebook&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Optimize model download speed with aria2&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Internationalization&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Provide xformer support for Paperspace M4000 GPU&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Soft link LoRA in Additional Network to &lt;code&gt;models/Stable-diffusion&lt;/code&gt; folder&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Jupyter Notebook&#39;s Language is still Chinese, I want to find a way to make it internationalized, but maintaining two versions is a bit troublesome, so I will do it later.&lt;/p&gt; &#xA;&lt;h2&gt;About Training LoRA&lt;/h2&gt; &#xA;&lt;p&gt;Basic training script based on &lt;a href=&#34;https://github.com/Akegarasu/lora-scripts&#34;&gt;Akegarasu/lora-scripts&lt;/a&gt; which is based on &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts&#34;&gt;kohya-ss/sd-scripts&lt;/a&gt;, but you can also use &lt;a href=&#34;https://github.com/ddPn08/kohya-sd-scripts-webui&#34;&gt;ddPn08/kohya-sd-scripts-webui&lt;/a&gt; which provides a GUI, it is more convenient, I also provide the corresponding SD WebUI extension installation method in &lt;code&gt;stable_diffusion_1_5_webui.ipynb&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Some models are not compatible with the training script, and the training script will not be able to train them. If you want to train them, you need to use the training script provided by the model author.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;In &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts/raw/main/train_network_README-ja.md&#34;&gt;kohya-ss/sd-scripts train_network documentaion&lt;/a&gt;, it notes that the cloneofsimo&#39;s repository and the d8ahazard&#39;s Dreambooth Extension for Stable-Diffusion-WebUI are not compatible at the current time. This is because they have extended some features.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Recommended Loras&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;It seems that the LoRA related to &lt;strong&gt;@kbr&lt;/strong&gt; has disappeared, and I don&#39;t know the reason. Currently, you can find it at &lt;a href=&#34;https://github.com/wibus-wee/stable_diffusion_chilloutmix_ipynb/releases/tag/koreanDollLikeness&#34;&gt;https://github.com/wibus-wee/stable_diffusion_chilloutmix_ipynb/releases/tag/koreanDollLikeness&lt;/a&gt;, I have uploaded it to the release.&lt;/p&gt; &#xA; &lt;p&gt;In addition, I have updated the startup script so that if you check install &lt;code&gt;koreanDollLikeness&lt;/code&gt;, it will be installed automatically.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;(x1)&lt;/code&gt; üåü St. Louis (Luxurious Wheels) (Azur Lane): &lt;a href=&#34;https://civitai.com/models/6669/st-louis-luxurious-wheels-azur-lane&#34;&gt;https://civitai.com/models/6669/st-louis-luxurious-wheels-azur-lane&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x1)&lt;/code&gt; üëç Girls&#39; Frontline-OTs-14&#34;lightning&#34;: &lt;a href=&#34;https://civitai.com/models/6525/girls-frontline-ots-14lightning&#34;&gt;https://civitai.com/models/6525/girls-frontline-ots-14lightning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x0.5)&lt;/code&gt; üåü @kbr/Korean Doll Likeness (v10): &lt;del&gt;&lt;a href=&#34;https://civitai.com/models/7448/korean-doll-likeness&#34;&gt;https://civitai.com/models/7448/korean-doll-likeness&lt;/a&gt;&lt;/del&gt; ( Has been re-uploaded to the release by me.)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x0.5)&lt;/code&gt; üëç @kbr/Korean Doll Likeness (v15)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x0.5)&lt;/code&gt; üÜí &lt;del&gt;@kbr/Japanese Doll Likeness: &lt;a href=&#34;https://civitai.com/models/10135&#34;&gt;https://civitai.com/models/10135&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x0.5)&lt;/code&gt; üÜí &lt;del&gt;@kbr/Taiwan Doll Likeness : &lt;a href=&#34;https://civitai.com/models/7716/taiwan-doll-likeness&#34;&gt;https://civitai.com/models/7716/taiwan-doll-likeness&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x0.5)&lt;/code&gt; üÜí Yae Miko | Realistic Genshin (Mixed): &lt;a href=&#34;https://civitai.com/models/8484/yae-miko-or-realistic-genshin&#34;&gt;https://civitai.com/models/8484/yae-miko-or-realistic-genshin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x0.5)&lt;/code&gt; üëç Gakki | Aragaki Yui | Êñ∞Âû£ÁµêË°£: &lt;a href=&#34;https://civitai.com/models/8416/gakki-or-aragaki-yui-or&#34;&gt;https://civitai.com/models/8416/gakki-or-aragaki-yui-or&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x0.5 - x1)&lt;/code&gt; &lt;del&gt;üÜí ChilloutMixss: &lt;a href=&#34;https://civitai.com/models/10850/chilloutmixss&#34;&gt;https://civitai.com/models/10850/chilloutmixss&lt;/a&gt;&lt;/del&gt; (This model is disappeared.)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x0.5)&lt;/code&gt; üÜí Cute_girl_mix4: &lt;a href=&#34;https://civitai.com/models/14171/cutegirlmix4&#34;&gt;https://civitai.com/models/14171/cutegirlmix4&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;(x0.5)&lt;/code&gt; üÜí Fashion Girl (v4.5): &lt;a href=&#34;https://civitai.com/models/8217/fashion-girl&#34;&gt;https://civitai.com/models/8217/fashion-girl&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;üåü - Very good, very recommended.&lt;/p&gt; &#xA; &lt;p&gt;üëç - Good, recommended.&lt;/p&gt; &#xA; &lt;p&gt;üÜí - Good.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Recommended Checkpoints&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2.5D] ChilloutMix: &lt;a href=&#34;https://civitai.com/models/6424/chilloutmix&#34;&gt;https://civitai.com/models/6424/chilloutmix&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2.5D] SunshineMix: &lt;a href=&#34;https://civitai.com/models/9291/sunshinemix&#34;&gt;https://civitai.com/models/9291/sunshinemix&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2D] Grapefruit (hentai model): &lt;a href=&#34;https://civitai.com/models/2583/grapefruit-hentai-model&#34;&gt;https://civitai.com/models/2583/grapefruit-hentai-model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2.5D] Chilled_re_generic_v2: &lt;a href=&#34;https://drive.google.com/file/d/1KNU_giorZYOflT3gdwAPtIPh6sNE2oNR/view?usp=sharing&#34;&gt;https://drive.google.com/file/d/1KNU_giorZYOflT3gdwAPtIPh6sNE2oNR/view?usp=sharing&lt;/a&gt; (merged by &lt;a href=&#34;https://github.com/wibus-wee&#34;&gt;wibus-wee&lt;/a&gt;, recipe by &lt;a href=&#34;https://twitter.com/sazyou_roukaku&#34;&gt;@sazyou_roukaku&lt;/a&gt;, recipe &lt;a href=&#34;https://raw.githubusercontent.com/wibus-wee/stable_diffusion_chilloutmix_ipynb/main/chilled_re-generic.md&#34;&gt;See here&lt;/a&gt; )&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Recommended Textual Inversion&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ulzzang-6500 (Korean doll aesthetic): &lt;a href=&#34;https://civitai.com/models/8109/ulzzang-6500-korean-doll-aesthetic&#34;&gt;https://civitai.com/models/8109/ulzzang-6500-korean-doll-aesthetic&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Pure Eros Face: &lt;a href=&#34;https://civitai.com/models/4514/pure-eros-face&#34;&gt;https://civitai.com/models/4514/pure-eros-face&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Experimental LoRA&lt;/h2&gt; &#xA;&lt;p&gt;Experimental LoRA refers to models that are not yet fully tested by me, and have not yet been determined to be compatible. If you want to use these models, please judge the compatibility with other LoRA by yourself.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;liuyifei: &lt;a href=&#34;https://civitai.com/models/8453/liuyifei&#34;&gt;https://civitai.com/models/8453/liuyifei&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Lisa Blackpink: &lt;a href=&#34;https://civitai.com/models/8605/lisa-blackpink&#34;&gt;https://civitai.com/models/8605/lisa-blackpink&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Jisoo Blackpink: &lt;a href=&#34;https://civitai.com/models/8311/jisoo-blackpink&#34;&gt;https://civitai.com/models/8311/jisoo-blackpink&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Ros√® Blackpink: &lt;a href=&#34;https://civitai.com/models/8600/rose-blackpink&#34;&gt;https://civitai.com/models/8600/rose-blackpink&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;MoXin: &lt;a href=&#34;https://civitai.com/models/12597/moxin&#34;&gt;https://civitai.com/models/12597/moxin&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Experimental Checkpoints&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GuoFeng3: &lt;a href=&#34;https://civitai.com/models/10415/guofeng3&#34;&gt;https://civitai.com/models/10415/guofeng3&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;NoteBook Built-in Extension&lt;/h2&gt; &#xA;&lt;p&gt;WebUI Jupyter Notebook built-in Extension, you can install it directly from the notebook.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deforum-art/deforum-for-automatic1111-webui&#34;&gt;deforum-art/deforum-for-automatic1111-webui&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Akegarasu/stable-diffusion-webui-images-browser&#34;&gt;AlUlkesh/stable-diffusion-webui-images-browser&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/camenduru/stable-diffusion-webui-huggingface&#34;&gt;camenduru/stable-diffusion-webui-huggingface&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/camenduru/sd-civitai-browser&#34;&gt;camenduru/sd-civitai-browser&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/camenduru/openpose-editor&#34;&gt;camenduru/openpose-editor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikubill/sd-webui-controlnet&#34;&gt;Mikubill/sd-webui-controlnet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kohya-ss/sd-webui-additional-networks&#34;&gt;kohya-ss/sd-webui-additional-networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ddpn08/kohya-sd-scripts-webui&#34;&gt;ddpn08/kohya-sd-scripts-webui&lt;/a&gt; &lt;em&gt;(This extension has better install before WebUI Starting, otherwise you need to restart Application instead of just reload the UI.)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/d8ahazard/sd_dreambooth_extension&#34;&gt;d8ahazard/sd_dreambooth_extension&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Build xformers from source&lt;/h2&gt; &#xA;&lt;p&gt;If you are using Google Colab, there are many precompiled wheels for you to choose from. If you are using something else or want to build from source, you can use this notebook to build the library.&lt;/p&gt; &#xA;&lt;p&gt;I have written a &lt;a href=&#34;https://raw.githubusercontent.com/wibus-wee/stable_diffusion_chilloutmix_ipynb/main/xformers_build.ipynb&#34;&gt;notebook&lt;/a&gt; to build xformers from source. You can use it to build xformers for your own GPU.&lt;/p&gt; &#xA;&lt;h2&gt;CHANGELOG&lt;/h2&gt; &#xA;&lt;h3&gt;2023.3.8&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;README&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Modify Chilled_re_generic_v2 link to Google Drive Share Link&lt;/li&gt; &#xA;   &lt;li&gt;Set &lt;code&gt;Chilloutmixss&lt;/code&gt; model to deprecated (This model is disappeared.)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Remove &lt;code&gt;Chilloutmixss&lt;/code&gt; model option&lt;/li&gt; &#xA;   &lt;li&gt;Use &lt;code&gt;try-except&lt;/code&gt; to catch &lt;code&gt;KeyError&lt;/code&gt; when downloading models.&lt;/li&gt; &#xA;   &lt;li&gt;Support download &lt;code&gt;styles.csv&lt;/code&gt; with url.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.3.4&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;README&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add Chilled_re_generic_v2 download link&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Support custom checkpoint name ( From custom url )&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.3.5&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Custom checkpoint version&lt;/li&gt; &#xA;   &lt;li&gt;Missing return value&lt;/li&gt; &#xA;   &lt;li&gt;API argument support&lt;/li&gt; &#xA;   &lt;li&gt;Fixed xformer not starting on M4000 GPU platforms with xformer installed&lt;/li&gt; &#xA;   &lt;li&gt;Support download multiple checkpoints at the same time&lt;/li&gt; &#xA;   &lt;li&gt;Support download checkpoints from other URLs&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.3.4&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Download &lt;code&gt;koreanDollLikeness&lt;/code&gt; model with GitHub Release API&lt;/li&gt; &#xA;   &lt;li&gt;Soft link LoRA models so that they can be used in prompts and additional networks. (Only operate before startup, the LoRA installed after startup may not be used in prompts. You need to restart the application to re-link the models installed in other networks.)&lt;/li&gt; &#xA;   &lt;li&gt;Provides the option to install LoRA before startup&lt;/li&gt; &#xA;   &lt;li&gt;Get the latest checkpoint download address from the CivitAI API&lt;/li&gt; &#xA;   &lt;li&gt;Support for entering custom checkpoint id&lt;/li&gt; &#xA;   &lt;li&gt;Define download functions to optimize readability&lt;/li&gt; &#xA;   &lt;li&gt;Support LoRA specific version selection in download function&lt;/li&gt; &#xA;   &lt;li&gt;Auto detect download tool&lt;/li&gt; &#xA;   &lt;li&gt;Textual Inversion download function&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;README.md&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Update &#34;Experimental Checkpoints&#34; and &#34;Experimental LoRA&#34; section&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;prompts.md&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add a new prompt &lt;code&gt;Basic Tiara&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.2.25&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;README.md&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Update Experimental Lora List - Add &lt;code&gt;ChilloutMixss&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Optimize CHANGELOG format&lt;/li&gt; &#xA;   &lt;li&gt;Internationalize README&lt;/li&gt; &#xA;   &lt;li&gt;New &#34;Textual Inversion&#34; section&lt;/li&gt; &#xA;   &lt;li&gt;Add &#34;NoteBook Built-in Extension&#34; section&lt;/li&gt; &#xA;   &lt;li&gt;Add &#34;Build xformers from source&#34; section&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;lora_train.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fix serious errors in LoRA training script&lt;/li&gt; &#xA;   &lt;li&gt;Remove unnecessary platform and GPU checks&lt;/li&gt; &#xA;   &lt;li&gt;Add &lt;code&gt;export_model_dir&lt;/code&gt; option to specify the directory where the model is exported&lt;/li&gt; &#xA;   &lt;li&gt;Add an extra build installation xformers option for the M4000 GPU&lt;/li&gt; &#xA;   &lt;li&gt;Use &lt;code&gt;ninja&lt;/code&gt; to build xformers much faster ( Followed by Official README)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add an extra build installation xFormer option for the M4000 GPU&lt;/li&gt; &#xA;   &lt;li&gt;Use &lt;code&gt;ninja&lt;/code&gt; to build xformers much faster ( Followed by Official README)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;prompts.md&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Internationalize&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;xformers_build.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;New xformers build script&lt;/li&gt; &#xA;   &lt;li&gt;Switch xformers source version to 0.0.16&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;workflows&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add &lt;code&gt;xformers_build.ipynb&lt;/code&gt; to Preview CI&lt;/li&gt; &#xA;   &lt;li&gt;Remove &lt;code&gt;pull_request_target&lt;/code&gt; value to prevent the workflow from running twice&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Release&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Publish xformers precompiled wheels for M4000 GPU&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.2.24&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;workflows&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Automatically comment on Preview link when Pull Request ( &lt;a href=&#34;https://github.com/wibus-wee/stable_diffusion_chilloutmix_ipynb/pull/2&#34;&gt;https://github.com/wibus-wee/stable_diffusion_chilloutmix_ipynb/pull/2&lt;/a&gt; )&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Install controlnet, openpose-editor, Kohya sd-scripts extension with Stable-Diffusion-WebUI&lt;/li&gt; &#xA;   &lt;li&gt;Remove the old training model installation scheme and merge it into the installation steps ( created in 2023.2.19 )&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;lora_train.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;New Lora Train Script ( Alpha )&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.2.21&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Better option selection mechanism&lt;/li&gt; &#xA;   &lt;li&gt;Fine distinction between Paperspace and Colab platforms rather than relying on a single Free GPU model&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.2.19&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fix the problem of incorrectly identifying the Quadro M4000 GPU&lt;/li&gt; &#xA;   &lt;li&gt;Add &lt;strong&gt;Training Model&lt;/strong&gt; Installation Scheme ( Power by &lt;a href=&#34;https://github.com/d8ahazard/sd_dreambooth_extension&#34;&gt;d8ahazard/sd_dreambooth_extension&lt;/a&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Optimize checkpoint selection&lt;/li&gt; &#xA;   &lt;li&gt;Fix the problem of not being able to read variables&lt;/li&gt; &#xA;   &lt;li&gt;Automatically check whether webUI and training extensions are installed&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.2.18&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Update the latest version of the upstream ChilloutMix&lt;/li&gt; &#xA;   &lt;li&gt;Update Prompts Collection&lt;/li&gt; &#xA;   &lt;li&gt;Compatible with Paperspace platform (Free GPU)&lt;/li&gt; &#xA;   &lt;li&gt;Export all generated images&lt;/li&gt; &#xA;   &lt;li&gt;Use &lt;code&gt;nvidia-smi&lt;/code&gt; to view GPU information&lt;/li&gt; &#xA;   &lt;li&gt;Check if GPU supports Xformers&lt;/li&gt; &#xA;   &lt;li&gt;Optimize variable passing&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.2.17&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add SunshineMix Checkpoint as a second choice for 2.5D painting&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2023.2.16&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;stable_diffusion_1_5_webui.ipynb&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Because there may be a sudden exit in the middle, there is another way to restart&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Created by &lt;a href=&#34;https://github.com/wibus-wee&#34;&gt;@wibus-wee&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;Reference: &lt;a href=&#34;https://github.com/camenduru/stable-diffusion-webui-colab&#34;&gt;camenduru/stable-diffusion-webui-colab&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
  <entry>
    <title>PeiranLi0930/DL-Algorithms</title>
    <updated>2023-03-12T01:54:13Z</updated>
    <id>tag:github.com,2023-03-12:/PeiranLi0930/DL-Algorithms</id>
    <link href="https://github.com/PeiranLi0930/DL-Algorithms" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;NOTE: This repo is currently being fixed and finished!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;I am now re-implementing all of the codes in Pytorch (Don&#39;t worry if you are only familiar with PyTorch now!)&lt;/li&gt; &#xA; &lt;li&gt;In the future, this document will be transformed into an interactive e-book for easy searching and studying&lt;/li&gt; &#xA; &lt;li&gt;Now that I am working on my own, if you are interested in ML/DL/CV, please email me and welcome to my workspace! (You can find my email on my Github Homepage)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Deep Learning &amp;amp; Machine Learning Algorithms and Applications&lt;/h1&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;To better express these concepts and bring the general public into the domains of Machine Learning and Deep Learning, I am creating and organizing this repository to display comprehensive facts and expertise in an approachable manner. To be honest, developing complete specialities is difficult and time intensive. As a result, if there is an error or something incorrect, I would appreciate all corrections and recommendations.&lt;/p&gt; &#xA;&lt;p&gt;I&#39;d want to thank all of my teachers and professors for their help and guidance during my education.&lt;/p&gt; &#xA;&lt;p&gt;This program includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Machine Learning Specialization&lt;/li&gt; &#xA; &lt;li&gt;Matrix Methods in Data Mining and Pattern Recognition (A new viewpoint of ML problems)&lt;/li&gt; &#xA; &lt;li&gt;Deep Learning Specialization&lt;/li&gt; &#xA; &lt;li&gt;Deep Learning in Computer Vision&lt;/li&gt; &#xA; &lt;li&gt;The Collection of Relavant Papers&lt;/li&gt; &#xA; &lt;li&gt;The Proofs of All Applied Axioms&lt;/li&gt; &#xA; &lt;li&gt;All Codes Implemented by Tensorflow 2.x Currently&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Declarations:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Feel free to share but DO NOT replicate, sell, or any commercial behaviors&lt;/li&gt; &#xA; &lt;li&gt;Appreciate all instructors and professors who contribute to these contents&lt;/li&gt; &#xA; &lt;li&gt;All the contents have the permissions to share and propagate&lt;/li&gt; &#xA; &lt;li&gt;Keep to the Open-source Protocol&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;¬© 2022 - Peiran in USA - All rights reserved&lt;/p&gt; &#xA;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>glouppe/info8010-deep-learning</title>
    <updated>2023-03-12T01:54:13Z</updated>
    <id>tag:github.com,2023-03-12:/glouppe/info8010-deep-learning</id>
    <link href="https://github.com/glouppe/info8010-deep-learning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lectures for INFO8010 - Deep Learning, ULi√®ge&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;INFO8010 - Deep Learning&lt;/h1&gt; &#xA;&lt;p&gt;Lectures for INFO8010 - Deep Learning, ULi√®ge, Spring 2023.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Instructor: Gilles Louppe&lt;/li&gt; &#xA; &lt;li&gt;Teaching assistants: Arnaud Delaunoy, Fran√ßois Rozet, Yann Claes, Victor Dachet&lt;/li&gt; &#xA; &lt;li&gt;When: Spring 2023, Friday 8:30 AM&lt;/li&gt; &#xA; &lt;li&gt;Classroom: R3 / B28&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Agenda&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Date&lt;/th&gt; &#xA;   &lt;th&gt;Topic&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;February 10&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=course-syllabus.md&#34;&gt;Course syllabus&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/course-syllabus.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://www.youtube.com/watch?v=51UOdB199Nk&#34;&gt;video&lt;/a&gt;]&lt;br&gt;Lecture 0: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture0.md&#34;&gt;Introduction&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec0.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://www.youtube.com/watch?v=-Ee-Z311a3k&#34;&gt;video&lt;/a&gt;]&lt;br&gt;Lecture 1: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture1.md&#34;&gt;Fundamentals of machine learning&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec1.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://www.youtube.com/watch?v=GwpG0sHPklE&#34;&gt;video&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;February 17&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 2: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture2.md&#34;&gt;Multi-layer perceptron&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec2.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://www.youtube.com/watch?v=OF6AkE9Fnjc&#34;&gt;video&lt;/a&gt;] [&lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/raw/master/code/lec2-space-stretching.ipynb&#34;&gt;code 1&lt;/a&gt;, &lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/raw/master/code/lec2-spiral-classification.ipynb&#34;&gt;code 2&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;February 24&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 3: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture3.md&#34;&gt;Automatic differentiation&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec3.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/fD047xXpSfI&#34;&gt;video&lt;/a&gt;] [&lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/raw/master/code/lec3-autodiff.ipynb&#34;&gt;code&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;March 3&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 4: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture4.md&#34;&gt;Training neural networks&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec4.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/G7qw620V_3g&#34;&gt;video&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;March 6&lt;/td&gt; &#xA;   &lt;td&gt;Deadline for Homework 1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;March 10&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 5: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture5.md&#34;&gt;Convolutional neural networks&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec5.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/54WShJMWYo0&#34;&gt;video&lt;/a&gt;] [&lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/raw/master/code/lec5-convnet.ipynb&#34;&gt;code&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;March 17&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 6: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture6.md&#34;&gt;Computer vision&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec6.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/cfZGfJaLRxA&#34;&gt;video&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;March 20&lt;/td&gt; &#xA;   &lt;td&gt;Deadline for Homework 2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;March 20&lt;/td&gt; &#xA;   &lt;td&gt;Deadline for the project proposal&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;March 24&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 7: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture7.md&#34;&gt;Attention and transformers&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec7.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/cwFE1pLld-g&#34;&gt;video&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;March 31&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 8: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture8.md&#34;&gt;GPT&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec8.pdf&#34;&gt;PDF&lt;/a&gt;] [notebook]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;April 21&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 9: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture9.md&#34;&gt;Graph neural networks&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec9.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;April 28&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 10: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture10.md&#34;&gt;Uncertainty&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec10.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/AxJBY9eRTL4&#34;&gt;video&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;May 5&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 11: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture11.md&#34;&gt;Auto-encoders and variational auto-encoders&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec11.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/6gWeyUZtHWs&#34;&gt;video&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;May 12&lt;/td&gt; &#xA;   &lt;td&gt;Lecture 12: &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=lecture12.md&#34;&gt;Score-based diffusion models&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/lec12.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/cM6m1eHY5FI&#34;&gt;video&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;May 12&lt;/td&gt; &#xA;   &lt;td&gt;Deadline for the reading assignment&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;May 12&lt;/td&gt; &#xA;   &lt;td&gt;Deadline for the project&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Homeworks&lt;/h2&gt; &#xA;&lt;p&gt;The goal of these two assignments is to get you familiar with the PyTorch library. You can find the installation instructions in the &lt;a href=&#34;https://raw.githubusercontent.com/glouppe/info8010-deep-learning/master/homeworks&#34;&gt;Homeworks&lt;/a&gt; folder. Each homework should be done in groups of 2 or 3 (the same as for the project) and must be submitted &lt;strong&gt;before 23:59 on the due date&lt;/strong&gt;. Homeworks should be submitted on Gradescope.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/raw/master/homeworks/homework1.ipynb&#34;&gt;Homework 1&lt;/a&gt;: Tensor operations, &lt;code&gt;autograd&lt;/code&gt; and &lt;code&gt;nn&lt;/code&gt;. Due by &lt;strong&gt;March 6, 2023&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/raw/master/homeworks/homework2.ipynb&#34;&gt;Homework 2&lt;/a&gt;: Dataset, Dataloader, running on GPU, training a convolutional neural network. Due by &lt;strong&gt;March 20, 2023&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Homeworks are optional. If submitted, each homework will account for 5% of the final grade.&lt;/p&gt; &#xA;&lt;h2&gt;Project&lt;/h2&gt; &#xA;&lt;p&gt;See instructions in &lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/raw/master/project.md&#34;&gt;&lt;code&gt;project.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Reading assignment&lt;/h2&gt; &#xA;&lt;p&gt;Your task is to read and summarize a major scientific paper in the field of deep learning. You are free to select one among the following three papers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Rombach et al, &#34;High-Resolution Image Synthesis with Latent Diffusion Models&#34;, 2022. [&lt;a href=&#34;https://arxiv.org/abs/2112.10752&#34;&gt;Paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Chen et al, &#34;Evaluating Large Language Models Trained on Code&#34;, 2021 [&lt;a href=&#34;https://arxiv.org/abs/2107.03374&#34;&gt;Paper&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Jumper et al, &#34;Highly accurate protein structure prediction with AlphaFold&#34;, 2021. [&lt;a href=&#34;https://www.nature.com/articles/s41586-021-03819-2&#34;&gt;Paper&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You should produce a report that summarizes the problem that is tackled by the paper and explains why it is challenging or important, from the perspective of the wider research context. The report should outline the main contributions and results with respect to the problem that is addressed. It should also include a critical discussion of the advantages and shortcomings of the contributions of the paper. Further guidelines for writing a good summary can be found &lt;a href=&#34;https://web.stanford.edu/class/cs224n/project/project-proposal-instructions.pdf&#34;&gt;here&lt;/a&gt; (Section 2, &#34;The summary&#34;).&lt;/p&gt; &#xA;&lt;p&gt;Constraints:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You can work in groups of maximum 3 students (the same as for the project).&lt;/li&gt; &#xA; &lt;li&gt;You report must be written in English.&lt;/li&gt; &#xA; &lt;li&gt;2 pages (excluding references, if any).&lt;/li&gt; &#xA; &lt;li&gt;Formatted using the LaTeX template &lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/template-report.tex&#34;&gt;&lt;code&gt;template-report.tex&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Your report should be submitted by &lt;strong&gt;May 12&lt;/strong&gt; on Gradescope. This is a &lt;strong&gt;hard&lt;/strong&gt; deadline.&lt;/p&gt; &#xA;&lt;h2&gt;Archives&lt;/h2&gt; &#xA;&lt;h3&gt;Previous editions&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/tree/v5-info8010-2022&#34;&gt;2021-2022&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/tree/v4-info8010-2021&#34;&gt;2020-2021&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/tree/v3-info8010-2020&#34;&gt;2019-2020&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glouppe/info8010-deep-learning/tree/v2-info8010-2019&#34;&gt;2018-2019&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Archived lectures&lt;/h3&gt; &#xA;&lt;p&gt;Due to progress in the field, some of the lectures have become less relevant. However, they are still available for those who are interested.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=archives-lecture-rnn.md&#34;&gt;Recurrent neural networks&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/archives-lec-rnn.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/qnux5dg5wZ4&#34;&gt;video&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/?p=archives-lecture-gan.md&#34;&gt;Generative adversarial networks&lt;/a&gt; [&lt;a href=&#34;https://glouppe.github.io/info8010-deep-learning/pdf/archives-lec-gan.pdf&#34;&gt;PDF&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/cM6m1eHY5FI&#34;&gt;video&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>