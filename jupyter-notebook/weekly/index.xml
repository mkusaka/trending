<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-09T01:44:03Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>epfml/ML_course</title>
    <updated>2022-10-09T01:44:03Z</updated>
    <id>tag:github.com,2022-10-09:/epfml/ML_course</id>
    <link href="https://github.com/epfml/ML_course" rel="alternate"></link>
    <summary type="html">&lt;p&gt;EPFL Machine Learning Course, Fall 2021&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;EPFL Machine Learning Course CS-433&lt;/h1&gt; &#xA;&lt;p&gt;Machine Learning Course, Fall 2022&lt;/p&gt; &#xA;&lt;p&gt;Repository for all lecture notes, labs and projects - resources, code templates and solutions. Videos available &lt;a href=&#34;https://tube.switch.ch/switchcast/epfl.ch/series/60d0234f-e9b0-42c9-b727-35e518fe8833&#34;&gt;here for 2022 lectures&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/playlist?list=PL4O4bXkI-fAcBxnceaGFoVutetFyhSx6r&#34;&gt;and for 2022 exercises&lt;/a&gt;, and &lt;a href=&#34;https://www.youtube.com/playlist?list=PL4O4bXkI-fAd4nB7YYR5F8WitmPxjPeAa&#34;&gt;here for 2021&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The course website and syllabus is available here: &lt;a href=&#34;https://www.epfl.ch/labs/mlo/machine-learning-cs-433/&#34;&gt;https://www.epfl.ch/labs/mlo/machine-learning-cs-433/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Contact us if you have any questions, via the &lt;a href=&#34;https://www.oknoname.com/EPFL/CS433-Fall2022/&#34;&gt;discussion forum&lt;/a&gt; (password on moodle for EPFL students), or email to the assistants or teachers. Please create issues and pull requests here using the menu above.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>JoePenna/Dreambooth-Stable-Diffusion</title>
    <updated>2022-10-09T01:44:03Z</updated>
    <id>tag:github.com,2022-10-09:/JoePenna/Dreambooth-Stable-Diffusion</id>
    <link href="https://github.com/JoePenna/Dreambooth-Stable-Diffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) by way of Textual Inversion (https://arxiv.org/abs/2208.01618) for Stable Diffusion. Tweaks focused on training faces, objects, and styles.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Index&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#notes-by-joe-penna&#34;&gt;Notes by Joe Penna&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#setup&#34;&gt;Setup&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#easy-runpod-instructions&#34;&gt;Easy RunPod Instructions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#vast-ai-setup&#34;&gt;Vast.AI Setup&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#text-vs-dreamb&#34;&gt;Textual Inversion vs. Dreambooth&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#using-the-generated-model&#34;&gt;Using the Generated Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#debugging-your-results&#34;&gt;Debugging Your Results&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#they-dont-look-like-you&#34;&gt;They don&#39;t look like you at all!&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#they-sorta-look-like-you-but-exactly-like-your-training-images&#34;&gt;They sorta look like you, but exactly like your training images&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#they-look-like-you-but-not-when-you-try-different-styles&#34;&gt;They look like you, but not when you try different styles&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#hugging-face-diffusers&#34;&gt;Hugging Face Diffusers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;The Repo Formerly Known As &#34;Dreambooth&#34;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/100188076/192390551-cb89364f-af57-4aed-8f3d-f9eb9b61cf95.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;notes-by-joe-penna&#34;&gt;&lt;/a&gt; Notes by Joe Penna&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;strong&gt;INTRODUCTIONS!&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Hi! My name is Joe Penna.&lt;/p&gt; &#xA;&lt;p&gt;You might have seen a few YouTube videos of mine under &lt;em&gt;MysteryGuitarMan&lt;/em&gt;. I&#39;m now a feature film director. You might have seen &lt;a href=&#34;https://www.youtube.com/watch?v=N5aD9ppoQIo&amp;amp;t=6s&#34;&gt;ARCTIC&lt;/a&gt; or &lt;a href=&#34;https://www.youtube.com/watch?v=A_apvQkWsVY&#34;&gt;STOWAWAY&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For my movies, I need to be able to train specific actors, props, locations, etc. So, I did a bunch of changes to @XavierXiao&#39;s repo in order to train people&#39;s faces.&lt;/p&gt; &#xA;&lt;p&gt;I can&#39;t release all the tests for the movie I&#39;m working on, but when I test with my own face, I release those on my Twitter page - &lt;a href=&#34;https://twitter.com/MysteryGuitarM&#34;&gt;@MysteryGuitarM&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Lots of these tests were done with a buddy of mine -- Niko from CorridorDigital. It might be how you found this repo!&lt;/p&gt; &#xA;&lt;p&gt;I&#39;m not really a coder. I&#39;m just stubborn, and I&#39;m not afraid of googling. So, eventually, some really smart folks joined in and have been contributing. In this repo, specifically: &lt;a href=&#34;https://github.com/djbielejeski&#34;&gt;@djbielejeski&lt;/a&gt; @gammagec @MrSaad –– but so many others in our Discord!&lt;/p&gt; &#xA;&lt;p&gt;This is no longer my repo. This is the people-who-wanna-see-Dreambooth-on-SD-working-well&#39;s repo!&lt;/p&gt; &#xA;&lt;p&gt;Now, if you wanna try to do this... please read the warnings below first:&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;WARNING!&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;This is bleeding edge stuff&lt;/strong&gt;... there is currently no easy way to run this. This repo is based on a repo based on another repo.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;At the moment, it takes a LOT of effort to create something that&#39;s basically duct tape and bubble gum -- but eventually works SUPER well.&lt;/li&gt; &#xA;   &lt;li&gt;Step in, please! Don&#39;t let that scare ya -- but please know that you&#39;re wading through the jungle at night, with no torch...&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Unfreezing the model takes a lot of juice.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;del&gt;You&#39;re gonna need an A6000 / A40 / A100 (or similar top-of-the-line thousands-of-dollars GPU).&lt;/del&gt;&lt;/li&gt; &#xA;   &lt;li&gt;You can now run this on a GPU with 24GB of VRAM (e.g. 3090). Training will be slower, and you&#39;ll need to be sure this is the &lt;em&gt;only&lt;/em&gt; program running.&lt;/li&gt; &#xA;   &lt;li&gt;If, like myself, you don&#39;t happen to own one of those, I&#39;m including a Jupyter notebook here to help you run it on a rented cloud computing platform.&lt;/li&gt; &#xA;   &lt;li&gt;It&#39;s currently tailored to &lt;a href=&#34;https://runpod.io?ref=n8yfwyum&#34;&gt;runpod.io&lt;/a&gt;, but can work on &lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#vast-ai-setup&#34;&gt;vast.ai&lt;/a&gt; / etc.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;This implementation does not fully implement Google&#39;s ideas on how to preserve the latent space.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Most images that are similar to what you&#39;re training will be shifted towards that.&lt;/li&gt; &#xA;   &lt;li&gt;e.g. If you&#39;re training a person, all people will look like you. If you&#39;re training an object, anything in that class will look like your object.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;There doesn&#39;t seem to be an easy way to train two subjects consecutively. You will end up with an &lt;code&gt;11-12GB&lt;/code&gt; file before pruning.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The provided notebook has a pruner that crunches it down to &lt;code&gt;~2gb&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Best practice is to change the &lt;strong&gt;token&lt;/strong&gt; to a celebrity name (&lt;em&gt;note: token, not class&lt;/em&gt; -- so your prompt would be something like: &lt;code&gt;Chris Evans person&lt;/code&gt;). Here&#39;s &lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#using-the-generated-model&#34;&gt;my wife trained with the exact same settings, except for the token&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;&lt;a name=&#34;setup&#34;&gt;&lt;/a&gt; Setup&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;easy-runpod-instructions&#34;&gt;&lt;/a&gt; Easy RunPod Instructions&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sign up for RunPod. Feel free to use my &lt;a href=&#34;https://runpod.io?ref=n8yfwyum&#34;&gt;referral link here&lt;/a&gt;, so that I don&#39;t have to pay for it (but you do).&lt;/li&gt; &#xA; &lt;li&gt;Click &lt;strong&gt;Deploy&lt;/strong&gt; on either &lt;code&gt;SECURE CLOUD&lt;/code&gt; or &lt;code&gt;COMMUNITY CLOUD&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Follow these video instructions here:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=7m__xadX0z0#t=5m33.1s&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/7m__xadX0z0/0.jpg&#34; alt=&#34;VIDEO INSTRUCTIONS&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;vast-ai-setup&#34;&gt;&lt;/a&gt; Vast.AI Instructions&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sign up for &lt;a href=&#34;https://vast.ai/&#34;&gt;Vast.AI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Add some funds (I typically add them in $10 increments)&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the &lt;a href=&#34;https://vast.ai/console/create/&#34;&gt;Client - Create page&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Select pytorch/pytorch as your docker image, and the buttons &#34;Use Jupyter Lab Interface&#34; and &#34;Jupyter direct HTTPS&#34;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/readme-images/vast-ai-step1-select-docker-image.png&#34; alt=&#34;img.png&#34;&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;You will want to increase your disk space, and filter on GPU RAM (12gb checkpoint files + 4gb model file + regularization images + other stuff adds up fast) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;I typically allocate 150GB&lt;/li&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/readme-images/vast-ai-step2-instance-filters.png&#34; alt=&#34;img.png&#34;&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Also good to check the Upload/Download speed for enough bandwidth so you don&#39;t spend all your money waiting for things to download.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Select the instance you want, and click &lt;code&gt;Rent&lt;/code&gt;, then head over to your &lt;a href=&#34;https://vast.ai/console/instances/&#34;&gt;Instances&lt;/a&gt; page and click &lt;code&gt;Open&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/readme-images/vast-ai-step3-instances.png&#34; alt=&#34;img.png&#34;&gt;&lt;/li&gt; &#xA;   &lt;li&gt;You will get an unsafe certificate warning. Click past the warning or install the &lt;a href=&#34;https://vast.ai/static/jvastai_root.cer&#34;&gt;Vast cert&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Click &lt;code&gt;Notebook -&amp;gt; Python 3&lt;/code&gt; (You can do this next step a number of ways, but I typically do this) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/readme-images/vast-ai-step4-get-repo.png&#34; alt=&#34;img.png&#34;&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Clone Joe&#39;s repo with this command &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;!git clone https://github.com/JoePenna/Dreambooth-Stable-Diffusion.git&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Click &lt;code&gt;run&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/readme-images/vast-ai-step5-clone-repo.png&#34; alt=&#34;img.png&#34;&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Navigate into the new &lt;code&gt;Dreambooth-Stable-Diffusion&lt;/code&gt; directory on the left and open the &lt;code&gt;dreambooth_runpod_joepenna.ipynb&lt;/code&gt; file &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/readme-images/vast-ai-step6-open-notebook.png&#34; alt=&#34;img.png&#34;&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Follow the instructions in the workbook and start training&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;&lt;a name=&#34;text-vs-dreamb&#34;&gt;&lt;/a&gt; Textual Inversion vs. Dreambooth&lt;/h1&gt; &#xA;&lt;p&gt;The majority of the code in this repo was written by Rinon Gal et. al, the authors of the Textual Inversion research paper. Though a few ideas about regularization images and prior loss preservation (ideas from &#34;Dreambooth&#34;) were added in, out of respect to both the MIT team and the Google researchers, I&#39;m renaming this fork to: &lt;em&gt;&#34;The Repo Formerly Known As &#34;Dreambooth&#34;&#34;&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For an alternate implementation , please see &lt;a href=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/#hugging-face-diffusers&#34;&gt;&#34;Alternate Option&#34;&lt;/a&gt; below.&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a name=&#34;using-the-generated-model&#34;&gt;&lt;/a&gt; Using the generated model&lt;/h1&gt; &#xA;&lt;p&gt;The &lt;code&gt;ground truth&lt;/code&gt; (real picture, caution: very beautiful woman) &lt;br&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/100188076/192403948-8d1d0e50-3e9f-495f-b8ba-1bcb6b536fc8.png&#34; width=&#34;200&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Same prompt for all of these images below:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;code&gt;sks person&lt;/code&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;woman person&lt;/code&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;Natalie Portman person&lt;/code&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;Kate Mara person&lt;/code&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/100188076/192403506-ab96c652-f7d0-47b0-98fa-267defa1e511.png&#34; width=&#34;200&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/100188076/192403491-cb258777-5091-4492-a6cc-82305fa729f4.png&#34; width=&#34;200&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/100188076/192403437-f9a93720-d41c-4334-8901-fa2d2a10fe36.png&#34; width=&#34;200&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/100188076/192403461-1f6972d9-64d0-46b0-b2ed-737e47aae31e.png&#34; width=&#34;200&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;&lt;a name=&#34;debugging-your-results&#34;&gt;&lt;/a&gt; Debugging your results&lt;/h1&gt; &#xA;&lt;h3&gt;❗❗ THE NUMBER ONE MISTAKE PEOPLE MAKE ❗❗&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Prompting with just your token. ie &#34;joepenna&#34; instead of &#34;joepenna person&#34;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you trained with &lt;code&gt;joepenna&lt;/code&gt; under the class &lt;code&gt;person&lt;/code&gt;, the model should only know your face as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;joepenna person&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example Prompts:&lt;/p&gt; &#xA;&lt;p&gt;🚫 Incorrect (missing &lt;code&gt;person&lt;/code&gt; following &lt;code&gt;joepenna&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;portrait photograph of joepenna 35mm film vintage glass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;✅ This is right (&lt;code&gt;person&lt;/code&gt; is included after &lt;code&gt;joepenna&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;portrait photograph of joepenna person 35mm film vintage glass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You might sometimes get someone who kinda looks like you with joepenna (especially if you trained for too many steps), but that&#39;s only because this current iteration of Dreambooth overtrains that token so much that it bleeds into that token.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;☢ Be careful with the types of images you train&lt;/h4&gt; &#xA;&lt;p&gt;While training, Stable doesn&#39;t know that you&#39;re a person. It&#39;s just going to mimic what it sees.&lt;/p&gt; &#xA;&lt;p&gt;So, if these are your training images look like this:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/readme-images/caution-training.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;You&#39;re only going to get generations of you outside next to a spiky tree, wearing a white-and-gray shirt, in the style of... well, selfie photograph.&lt;/p&gt; &#xA;&lt;p&gt;Instead, this training set is much better:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoePenna/Dreambooth-Stable-Diffusion/main/readme-images/better-training-images.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The only thing that is consistent between images is the subject. So, Stable will look through the images and learn only your face, which will make &#34;editing&#34; it into other styles possible.&lt;/p&gt; &#xA;&lt;h2&gt;Oh no! You&#39;re not getting good generations!&lt;/h2&gt; &#xA;&lt;h4&gt;&lt;a name=&#34;they-dont-look-like-you&#34;&gt;&lt;/a&gt; OPTION 1: They&#39;re not looking like you at all! (Train longer, or get better training images)&lt;/h4&gt; &#xA;&lt;p&gt;Are you sure you&#39;re prompting it right?&lt;/p&gt; &#xA;&lt;p&gt;It should be &lt;code&gt;&amp;lt;token&amp;gt; &amp;lt;class&amp;gt;&lt;/code&gt;, not just &lt;code&gt;&amp;lt;token&amp;gt;&lt;/code&gt;. For example:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;JoePenna person, portrait photograph, 85mm medium format photo&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;If it still doesn&#39;t look like you, you didn&#39;t train long enough.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;&lt;a name=&#34;they-sorta-look-like-you-but-exactly-like-your-training-images&#34;&gt;&lt;/a&gt; OPTION 2: They&#39;re looking like you, but are all looking like your training images. (Train for less steps, get better training images, fix with prompting)&lt;/h4&gt; &#xA;&lt;p&gt;Okay, a few reasons why: you might have trained too long... or your images were too similar... or you didn&#39;t train with enough images.&lt;/p&gt; &#xA;&lt;p&gt;No problem. We can fix that with the prompt. Stable Diffusion puts a LOT of merit to whatever you type first. So save it for later:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;an exquisite portrait photograph, 85mm medium format photo of JoePenna person with a classic haircut&lt;/code&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;&lt;a name=&#34;they-look-like-you-but-not-when-you-try-different-styles&#34;&gt;&lt;/a&gt; OPTION 3: They&#39;re looking like you, but not when you try different styles. (Train longer, get better training images)&lt;/h4&gt; &#xA;&lt;p&gt;You didn&#39;t train long enough...&lt;/p&gt; &#xA;&lt;p&gt;No problem. We can fix that with the prompt:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;JoePenna person in a portrait photograph, JoePenna person in a 85mm medium format photo of JoePenna person&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;More tips and help here: &lt;a href=&#34;https://discord.com/invite/qbMuXBXyHA&#34;&gt;Stable Diffusion Dreambooth Discord&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h1&gt;&lt;a name=&#34;hugging-face-diffusers&#34;&gt;&lt;/a&gt; Hugging Face Diffusers - Alternate Option&lt;/h1&gt; &#xA;&lt;p&gt;Dreambooth is now supported in HuggingFace Diffusers for training with Stable Diffusion.&lt;/p&gt; &#xA;&lt;p&gt;Try it out here:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Azure/Azure-Sentinel</title>
    <updated>2022-10-09T01:44:03Z</updated>
    <id>tag:github.com,2022-10-09:/Azure/Azure-Sentinel</id>
    <link href="https://github.com/Azure/Azure-Sentinel" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cloud-native SIEM for intelligent security analytics for your entire enterprise.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Microsoft Sentinel and Microsoft 365 Defender&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to the unified Microsoft Sentinel and Microsoft 365 Defender repository! This repository contains out of the box detections, exploration queries, hunting queries, workbooks, playbooks and much more to help you get ramped up with Microsoft Sentinel and provide you security content to secure your environment and hunt for threats. The hunting queries also include Microsoft 365 Defender hunting queries for advanced hunting scenarios in both Microsoft 365 Defender and Microsoft Sentinel. You can also submit to &lt;a href=&#34;https://github.com/Azure/Azure-Sentinel/issues&#34;&gt;issues&lt;/a&gt; for any samples or resources you would like to see here as you onboard to Microsoft Sentinel. This repository welcomes contributions and refer to this repository&#39;s &lt;a href=&#34;https://aka.ms/threathunters&#34;&gt;wiki&lt;/a&gt; to get started. For questions and feedback, please contact &lt;a href=&#34;https://raw.githubusercontent.com/Azure/Azure-Sentinel/master/AzureSentinel@microsoft.com&#34;&gt;AzureSentinel@microsoft.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Resources&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://go.microsoft.com/fwlink/?linkid=2073774&amp;amp;clcid=0x409&#34;&gt;Microsoft Sentinel documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/microsoft-365/security/defender/microsoft-365-defender?view=o365-worldwide&#34;&gt;Microsoft 365 Defender documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/securitywebinars&#34;&gt;Security Community Webinars&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://help.github.com/en#dotcom&#34;&gt;Getting started with GitHub&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We value your feedback. Here are some channels to help surface your questions or feedback:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;General product specific Q&amp;amp;A for SIEM and SOAR - Join in the &lt;a href=&#34;https://techcommunity.microsoft.com/t5/microsoft-sentinel/bd-p/MicrosoftSentinel&#34;&gt;Microsoft Sentinel Tech Community conversations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;General product specific Q&amp;amp;A for XDR - Join in the &lt;a href=&#34;https://techcommunity.microsoft.com/t5/microsoft-365-defender/bd-p/MicrosoftThreatProtection&#34;&gt;Microsoft 365 Defender Tech Community conversations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Product specific feature requests - Upvote or post new on &lt;a href=&#34;https://feedback.azure.com/d365community/forum/37638d17-0625-ec11-b6e6-000d3a4f07b8&#34;&gt;Microsoft Sentinel feedback forums&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Report product or contribution bugs - File a GitHub Issue using &lt;a href=&#34;https://github.com/Azure/Azure-Sentinel/issues/new?assignees=&amp;amp;labels=&amp;amp;template=bug_report.md&amp;amp;title=&#34;&gt;Bug template&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;General feedback on community and contribution process - File a GitHub Issue using &lt;a href=&#34;https://github.com/Azure/Azure-Sentinel/issues/new?assignees=&amp;amp;labels=&amp;amp;template=feature_request.md&amp;amp;title=&#34;&gt;Feature Request template&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.microsoft.com&#34;&gt;https://cla.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Add in your new or updated contributions to GitHub&lt;/h2&gt; &#xA;&lt;p&gt;Note: If you are a first time contributor to this repository, &lt;a href=&#34;https://docs.github.com/github/getting-started-with-github/fork-a-repo&#34;&gt;General GitHub Fork the repo guidance&lt;/a&gt; before cloning or &lt;a href=&#34;https://github.com/Azure/Azure-Sentinel/raw/master/GettingStarted.md&#34;&gt;Specific steps for the Sentinel repo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;General Steps&lt;/h2&gt; &#xA;&lt;p&gt;Brand new or update to a contribution via these methods:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Submit for review directly on GitHub website &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Browse to the folder you want to upload your file to&lt;/li&gt; &#xA;   &lt;li&gt;Choose Upload Files and browse to your file.&lt;/li&gt; &#xA;   &lt;li&gt;You will be required to create your own branch and then submit the Pull Request for review.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Use &lt;a href=&#34;https://help.github.com/en/desktop/getting-started-with-github-desktop&#34;&gt;GitHub Desktop&lt;/a&gt; or &lt;a href=&#34;https://visualstudio.microsoft.com/vs/&#34;&gt;Visual Studio&lt;/a&gt; or &lt;a href=&#34;https://code.visualstudio.com/?wt.mc_id=DX_841432&#34;&gt;VSCode&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.github.com/github/getting-started-with-github/fork-a-repo&#34;&gt;Fork the repo&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository&#34;&gt;Clone the repo&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://help.github.com/en/desktop/contributing-to-projects/creating-a-branch-for-your-work&#34;&gt;Create your own branch&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Do your additions/updates in GitHub Desktop&lt;/li&gt; &#xA;   &lt;li&gt;Be sure to merge master back to your branch before you push.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://help.github.com/en/github/using-git/pushing-commits-to-a-remote-repository&#34;&gt;Push your changes to GitHub&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Pull Request&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;After you push your changes, you will need to submit the &lt;a href=&#34;https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests&#34;&gt;Pull Request (PR)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Details about the Proposed Changes are required, be sure to include a minimal level of detail so a review can clearly understand the reason for the change and what he change is related to in the code.&lt;/li&gt; &#xA; &lt;li&gt;After submission, check the &lt;a href=&#34;https://github.com/Azure/Azure-Sentinel/pulls&#34;&gt;Pull Request&lt;/a&gt; for comments&lt;/li&gt; &#xA; &lt;li&gt;Make changes as suggested and update your branch or explain why no change is needed. Resolve the comment when done.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Pull Request Detection Template Structure Validation Check&lt;/h3&gt; &#xA;&lt;p&gt;As part of the PR checks we run a structure validation to make sure all required parts of the YAML structure are included. For Detections, there is a new section that must be included. See the &lt;a href=&#34;https://github.com/Azure/Azure-Sentinel/wiki/Contribute-to-Sentinel-GitHub-Community-of-Queries#now-onto-the-how&#34;&gt;contribution guidelines&lt;/a&gt; for more information. If this section or any other required section is not included, then a validation error will occur similar to the below. The example is specifically if the YAML is missing the entityMappings section:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;A total of 1 test files matched the specified pattern.&#xA;[xUnit.net 00:00:00.95]     Kqlvalidations.Tests.DetectionTemplateStructureValidationTests.Validate_DetectionTemplates_HaveValidTemplateStructure(detectionsYamlFileName: &#34;ExcessiveBlockedTrafficGeneratedbyUser.yaml&#34;) [FAIL]&#xA;  X Kqlvalidations.Tests.DetectionTemplateStructureValidationTests.Validate_DetectionTemplates_HaveValidTemplateStructure(detectionsYamlFileName: &#34;ExcessiveBlockedTrafficGeneratedbyUser.yaml&#34;) [104ms]&#xA;  Error Message:&#xA;   Expected object to be &amp;lt;null&amp;gt;, but found System.ComponentModel.DataAnnotations.ValidationException with message &#34;An old mapping for entity &#39;AccountCustomEntity&#39; does not have a matching new mapping entry.&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pull Request Kql Validation Check&lt;/h3&gt; &#xA;&lt;p&gt;As part of the PR checks we run a syntax validation of the kql queries defined in the template. If this check fails go to Azure Pipeline (by pressing on the errors link on the checks tab in your PR) &lt;img src=&#34;https://raw.githubusercontent.com/Azure/Azure-Sentinel/master/.github/Media/Azurepipeline.png&#34; alt=&#34;Azurepipeline&#34;&gt; In the pipeline you can see which test failed and what is the cause: &lt;img src=&#34;https://raw.githubusercontent.com/Azure/Azure-Sentinel/master/.github/Media/PipelineTestsTab.png&#34; alt=&#34;Pipeline Tests Tab&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Example error message:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;A total of 1 test files matched the specified pattern.&#xA;[xUnit.net 00:00:01.81]     Kqlvalidations.Tests.KqlValidationTests.Validate_DetectionQueries_HaveValidKql(detectionsYamlFileName: &#34;ExcessiveBlockedTrafficGeneratedbyUser.yaml&#34;) [FAIL]&#xA;  X Kqlvalidations.Tests.KqlValidationTests.Validate_DetectionQueries_HaveValidKql(detectionsYamlFileName: &#34;ExcessiveBlockedTrafficGeneratedbyUser.yaml&#34;) [21ms]&#xA;  Error Message:&#xA;   Template Id:fa0ab69c-7124-4f62-acdd-61017cf6ce89 is not valid Errors:The name &#39;SymantecEndpointProtection&#39; does not refer to any known table, tabular variable or function., Code: &#39;KS204&#39;, Severity: &#39;Error&#39;, Location: &#39;67..93&#39;,The name &#39;SymantecEndpointProtection&#39; does not refer to any known table, tabular variable or function., Code: &#39;KS204&#39;, Severity: &#39;Error&#39;, Location: &#39;289..315&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are using custom logs table (a table which is not defined on all workspaces by default) you should verify your table schema is defined in json file in the folder &lt;em&gt;Azure-Sentinel\.script\tests\KqlvalidationsTests\CustomTables&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example for table tablexyz.json&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;Name&#34;: &#34;tablexyz&#34;,&#xA;  &#34;Properties&#34;: [&#xA;    {&#xA;      &#34;Name&#34;: &#34;SomeDateTimeColumn&#34;,&#xA;      &#34;Type&#34;: &#34;DateTime&#34;&#xA;    },&#xA;    {&#xA;      &#34;Name&#34;: &#34;SomeStringColumn&#34;,&#xA;      &#34;Type&#34;: &#34;String&#34;&#xA;    },&#xA;    {&#xA;      &#34;Name&#34;: &#34;SomeDynamicColumn&#34;,&#xA;      &#34;Type&#34;: &#34;Dynamic&#34;&#xA;    }&#xA;  ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run Kql Validation Locally&lt;/h3&gt; &#xA;&lt;p&gt;In order to run the kql validation before submitting Pull Request in you local machine:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You need to have &lt;strong&gt;.Net Core 3.1 SDK&lt;/strong&gt; installed &lt;a href=&#34;https://dotnet.microsoft.com/download&#34;&gt;How to download .Net&lt;/a&gt; (Supports all platforms)&lt;/li&gt; &#xA; &lt;li&gt;Open Shell and navigate to &lt;code&gt;Azure-Sentinel\\.script\tests\KqlvalidationsTests\&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Execute &lt;code&gt;dotnet test&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example of output (in Ubuntu):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Welcome to .NET Core 3.1!&#xA;---------------------&#xA;SDK Version: 3.1.403&#xA;&#xA;Telemetry&#xA;---------&#xA;The .NET Core tools collect usage data in order to help us improve your experience. The data is anonymous. It is collected by Microsoft and shared with the community. You can opt-out of telemetry by setting the DOTNET_CLI_TELEMETRY_OPTOUT environment variable to &#39;1&#39; or &#39;true&#39; using your favorite shell.&#xA;&#xA;Read more about .NET Core CLI Tools telemetry: https://aka.ms/dotnet-cli-telemetry&#xA;&#xA;----------------&#xA;Explore documentation: https://aka.ms/dotnet-docs&#xA;Report issues and find source on GitHub: https://github.com/dotnet/core&#xA;Find out what&#39;s new: https://aka.ms/dotnet-whats-new&#xA;Learn about the installed HTTPS developer cert: https://aka.ms/aspnet-core-https&#xA;Use &#39;dotnet --help&#39; to see available commands or visit: https://aka.ms/dotnet-cli-docs&#xA;Write your first app: https://aka.ms/first-net-core-app&#xA;--------------------------------------------------------------------------------------&#xA;Test run for /mnt/c/git/Azure-Sentinel/.script/tests/KqlvalidationsTests/bin/Debug/netcoreapp3.1/Kqlvalidations.Tests.dll(.NETCoreApp,Version=v3.1)&#xA;Microsoft (R) Test Execution Command Line Tool Version 16.7.0&#xA;Copyright (c) Microsoft Corporation.  All rights reserved.&#xA;&#xA;Starting test execution, please wait...&#xA;&#xA;A total of 1 test files matched the specified pattern.&#xA;&#xA;Test Run Successful.&#xA;Total tests: 171&#xA;     Passed: 171&#xA; Total time: 25.7973 Seconds&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Detection schema validation tests&lt;/h3&gt; &#xA;&lt;p&gt;Similarly to KQL Validation, there is an automatic validation of the schema of a detection. The schema validation includes the detection&#39;s frequency and period, the detection&#39;s trigger type and threshold, validity of connectors Ids (&lt;a href=&#34;https://github.com/Azure/Azure-Sentinel/raw/master/.script/tests/detectionTemplateSchemaValidation/ValidConnectorIds.json&#34;&gt;valid connectors Ids list&lt;/a&gt;), etc. A wrong format or missing attributes will result with an informative check failure, which should guide you through the resolution of the issue, but make sure to look into the format of already approved detection.&lt;/p&gt; &#xA;&lt;h3&gt;Run Detection Schema Validation Locally&lt;/h3&gt; &#xA;&lt;p&gt;In order to run the kql validation before submitting Pull Request in you local machine:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You need to have &lt;strong&gt;.Net Core 3.1 SDK&lt;/strong&gt; installed &lt;a href=&#34;https://dotnet.microsoft.com/download&#34;&gt;How to download .Net&lt;/a&gt; (Supports all platforms)&lt;/li&gt; &#xA; &lt;li&gt;Open Shell and navigate to &lt;code&gt;Azure-Sentinel\\.script\tests\DetectionTemplateSchemaValidation\&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Execute &lt;code&gt;dotnet test&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;p&gt;For information on what you can contribute and further details, refer to the &lt;a href=&#34;https://github.com/Azure/Azure-Sentinel/wiki#get-started&#34;&gt;&#34;get started&#34;&lt;/a&gt; section on the project&#39;s &lt;a href=&#34;https://aka.ms/threathunters&#34;&gt;wiki&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>