<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-21T03:30:15Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>bnsreenu/python_for_microscopists</title>
    <updated>2024-04-21T03:30:15Z</updated>
    <id>tag:github.com,2024-04-21:/bnsreenu/python_for_microscopists</id>
    <link href="https://github.com/bnsreenu/python_for_microscopists" rel="alternate"></link>
    <summary type="html">&lt;p&gt;https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w?sub_confirmation=1&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;b&gt; Author: Dr. Sreenivas Bhattiprolu &lt;/b&gt;&lt;br&gt; &lt;b&gt;Twitter: @digitalsreeni &lt;/b&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Supporting code for the tutorials on DigitalSreeni YouTube channel&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w?sub_confirmation=1&#34;&gt;https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w?sub_confirmation=1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The YouTube channel associated with this code walks you through the entire process of learning to code in Python; all the way from basics to advanced machine learning and deep learning. The primary emphasis will be on image processing and other relevant functionality.&lt;/p&gt; &#xA;&lt;h1&gt;How to cite my work?&lt;/h1&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;&lt;b&gt; 1. YouTube video: &lt;/b&gt; The general format for citing a YouTube video in APA (American Psychological Association) style is: Author’s Last Name, First Initial. (Year, Month Day Published). Title of video [Video]. YouTube. URL&lt;/p&gt; &#xA;&lt;p&gt;So, here is an example: &lt;/p&gt;&#xA;&lt;p&gt; &lt;em&gt;Bhattiprolu, S. (2023, August 23). 330 - Fine tuning Detectron2 for instance segmentation using custom data [Video]. YouTube. &lt;a href=&#34;https://youtu.be/cEgF0YknpZw&#34;&gt;https://youtu.be/cEgF0YknpZw&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;&lt;b&gt; 2. GitHub code: &lt;b&gt; There isn&#39;t a universally agreed-upon format for citing GitHub repositories, but here&#39;s a commonly used one: Author’s Last Name, First Initial. (Year). Title of Repository. GitHub. URL&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;&#xA;&lt;b&gt;&lt;b&gt; &lt;p&gt;Example: &lt;/p&gt;&lt;p&gt; &lt;em&gt;Bhattiprolu, S. (2023). python_for_microscopists. GitHub. &lt;a href=&#34;https://github.com/bnsreenu/python_for_microscopists/raw/master/330_Detectron2_Instance_3D_EM_Platelet.ipynb&#34;&gt;https://github.com/bnsreenu/python_for_microscopists/blob/master/330_Detectron2_Instance_3D_EM_Platelet.ipynb&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;/p&gt; &lt;/b&gt;&lt;/b&gt;</summary>
  </entry>
  <entry>
    <title>OpenBMB/MiniCPM</title>
    <updated>2024-04-21T03:30:15Z</updated>
    <id>tag:github.com,2024-04-21:/OpenBMB/MiniCPM</id>
    <link href="https://github.com/OpenBMB/MiniCPM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;MiniCPM-2B: An end-side LLM outperforms Llama2-13B.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; MiniCPM: 揭示端侧大语言模型的无限潜力 &lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;p&gt; &lt;b&gt;中文&lt;/b&gt; | &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/README-en.md&#34;&gt;English&lt;/a&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://openbmb.vercel.app/?category=Chinese+Blog&#34; target=&#34;_blank&#34;&gt;MiniCPM 技术博客&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2404.06395&#34; target=&#34;_blank&#34;&gt;MiniCPM 论文&lt;/a&gt; | &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM-V/&#34; target=&#34;_blank&#34;&gt;MiniCPM-V 仓库&lt;/a&gt; | 加入我们的 &lt;a href=&#34;https://discord.gg/3cGQn9b3YM&#34; target=&#34;_blank&#34;&gt;discord&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/assets/wechat.jpg&#34; target=&#34;_blank&#34;&gt;微信群&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;MiniCPM 是面壁智能与清华大学自然语言处理实验室共同开源的系列端侧大模型，主体语言模型 MiniCPM-2B 仅有 24亿（2.4B）的非词嵌入参数量, 总计2.7B参数量。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;经过 SFT 后，MiniCPM-2B 在公开综合性评测集上与 Mistral-7B 表现相近（中文、数学、代码能力更优），整体性能超越 Llama2-13B、MPT-30B、Falcon-40B 等模型。&lt;/li&gt; &#xA; &lt;li&gt;经过 DPO 后，MiniCPM-2B 在当前最接近用户体感的评测集 MTBench 上也超越了 Llama2-70B-Chat、Vicuna-33B、Mistral-7B-Instruct-v0.1、Zephyr-7B-alpha 等众多代表性开源大模型。&lt;/li&gt; &#xA; &lt;li&gt;以 MiniCPM-2B 为基础构建端侧多模态大模型 MiniCPM-V 2.0，在多个测试基准中实现了 7B 以下模型的最佳性能，在 OpenCompass 榜单上超过了 Qwen-VL-Chat 9.6B、CogVLM-Chat 17.4B 和 Yi-VL 34B 等更大参数规模的模型。MiniCPM-V 2.0 还展现出领先的 OCR 能力，在场景文字识别能力上接近 Gemini Pro。&lt;/li&gt; &#xA; &lt;li&gt;经过 Int4 量化后，MiniCPM 可在手机上进行部署推理，流式输出速度略高于人类说话速度。MiniCPM-V 也直接跑通了多模态大模型在手机上的部署。&lt;/li&gt; &#xA; &lt;li&gt;一张1080/2080可高效参数微调，一张3090/4090可全参数微调，一台机器可持续训练 MiniCPM，二次开发成本较低。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;我们完全开源MiniCPM系列的模型参数供学术研究和有限商用。 具体而言，我们目前已公开以下模型，地址详见 &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#1&#34;&gt;模型下载&lt;/a&gt; 部分&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;基于MiniCPM-2B的指令微调与人类偏好对齐版本&lt;strong&gt;MiniCPM-2B-SFT/DPO&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;基于MiniCPM-2B的多模态模型&lt;strong&gt;MiniCPM-V 2.0&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM-2B-SFT/DPO的Int4量化版&lt;strong&gt;MiniCPM-2B-SFT/DPO-Int4&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM-2B的128k长文本版本&lt;strong&gt;MiniCPM-2B-128k&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM-2B的MoE版本&lt;strong&gt;MiniCPM-MoE-8x2B&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;更轻量级的MiniCPM-1B指令微调版本&lt;strong&gt;MiniCPM-1B-SFT&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;基于MLC-LLM、LLMFarm开发的MiniCPM手机端程序，&lt;strong&gt;文本及多模态模型均可在手机端进行推理&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM-2B训练过程中的&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-history&#34;&gt;30个Checkpoints&lt;/a&gt;供模型机理研究。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;局限性：&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;受限于模型规模，模型可能出现&lt;strong&gt;幻觉性问题&lt;/strong&gt;。其中由于DPO模型生成的回复内容更长，更容易出现幻觉。我们也将持续进行MiniCPM模型的迭代改进。&lt;/li&gt; &#xA; &lt;li&gt;为了保证在学术研究用途上模型的通用性，我们&lt;strong&gt;未对模型进行任何身份认同训练&lt;/strong&gt;。同时由于我们用ShareGPT开源语料作为部分训练数据，模型可能会输出类似GPT系列模型的身份认同信息。&lt;/li&gt; &#xA; &lt;li&gt;受限于模型规模，模型的&lt;strong&gt;输出受到提示词（prompt）的影响较大&lt;/strong&gt;，可能多次尝试产生不一致的结果。&lt;/li&gt; &#xA; &lt;li&gt;受限于模型容量，模型的&lt;strong&gt;知识记忆较不准确&lt;/strong&gt;，后续我们将结合RAG方法来增强模型的知识记忆能力。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;目录&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#0&#34;&gt;更新日志&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#1&#34;&gt;模型下载&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#2&#34;&gt;快速上手&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#community&#34;&gt;开源社区&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#3&#34;&gt;评测结果&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#4&#34;&gt;手机部署&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#5&#34;&gt;Demo &amp;amp; API 部署&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#6&#34;&gt;二次开发&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#7&#34;&gt;开源协议&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#8&#34;&gt;工作引用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#9&#34;&gt;典型示例&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;0&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;更新日志&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;2024/04/11 开源&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-V-2.0&#34;&gt;MiniCPM-V-2.0&lt;/a&gt;、&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-128k&#34;&gt;MiniCPM-2B-128k&lt;/a&gt;、&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-MoE-8x2B&#34;&gt;MiniCPM-MoE-8x2B&lt;/a&gt;和&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16&#34;&gt;MiniCPM-1B&lt;/a&gt;！点击&lt;a href=&#34;https://openbmb.vercel.app/?category=Chinese+Blog&#34;&gt;这里&lt;/a&gt;查看技术博客。&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;2024/03/16 MiniCPM-2B 的30余个中间检查点开放了！&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-history&#34;&gt;HuggingFace链接&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;2024/02/13 支持了llama.cpp&lt;/li&gt; &#xA; &lt;li&gt;2024/02/09 我们在README里加入了一个&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#community&#34;&gt;开源社区&lt;/a&gt;章节，用来收集开源社区对MiniCPM的支持案例。&lt;/li&gt; &#xA; &lt;li&gt;2024/02/08 我们更新了&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#llamaformat&#34;&gt;llama-format的模型权重&lt;/a&gt;，方便大家更加快捷地使用我们的模型。&lt;/li&gt; &#xA; &lt;li&gt;2024/02/01 初始发布。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;1&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;模型下载&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;语言模型&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th&gt;HuggingFace&lt;/th&gt; &#xA;     &lt;th&gt;ModelScope&lt;/th&gt; &#xA;     &lt;th&gt;WiseModel&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16&#34;&gt;MiniCPM-2B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/miniCPM-bf16&#34;&gt;MiniCPM-2B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://wisemodel.cn/models/OpenBMB/miniCPM-bf16&#34;&gt;MiniCPM-2B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-dpo-bf16&#34;&gt;MiniCPM-2B-dpo-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-2B-dpo-bf16/summary&#34;&gt;MiniCPM-2B-dpo-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://wisemodel.cn/models/OpenBMB/MiniCPM-2B-dpo-bf16&#34;&gt;MiniCPM-2B-dpo-bf16&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-128k&#34;&gt;MiniCPM-2B-128k&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/openbmb/MiniCPM-2B-128k/summary&#34;&gt;MiniCPM-2B-128k&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-MoE-8x2B&#34;&gt;MiniCPM-MoE-8x2B&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-MoE-8x2B&#34;&gt;MiniCPM-MoE-8x2B&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16&#34;&gt;MiniCPM-1B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-1B-sft-bf16&#34;&gt;MiniCPM-1B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;p&gt;注: 更多模型版本见&lt;a href=&#34;https://huggingface.co/collections/openbmb/minicpm-2b-65d48bf958302b9fd25b698f&#34;&gt;这里&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;多模态模型&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th&gt;HuggingFace&lt;/th&gt; &#xA;     &lt;th&gt;ModelScope&lt;/th&gt; &#xA;     &lt;th&gt;WiseModel&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-V-2&#34;&gt;MiniCPM-V 2.0&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-V-2&#34;&gt;MiniCPM-V 2.0&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-V&#34;&gt;MiniCPM-V&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-V/&#34;&gt;MiniCPM-V&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://wisemodel.cn/models/OpenBMB/MiniCPM-V&#34;&gt;MiniCPM-V&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/OmniLMM-12B&#34;&gt;OmniLMM-12B&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/OmniLMM-12B&#34;&gt;OmniLMM-12B&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://wisemodel.cn/models/OpenBMB/OmniLMM-12B&#34;&gt;OmniLMM-12B&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;2&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;快速上手&lt;/h2&gt; &#xA;&lt;h4&gt;在线体验&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1tJcfPyWGWA5HezO7GKLeyeIso0HyOc0l?usp=sharing&#34;&gt;Colab&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Huggingface 模型&lt;/h4&gt; &#xA;&lt;h5&gt;MiniCPM-2B&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装&lt;code&gt;transformers&amp;gt;=4.36.0&lt;/code&gt;以及&lt;code&gt;accelerate&lt;/code&gt;后，运行以下代码&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;import torch&#xA;torch.manual_seed(0)&#xA;&#xA;path = &#39;openbmb/MiniCPM-2B-dpo-bf16&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(path)&#xA;model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map=&#39;cuda&#39;, trust_remote_code=True)&#xA;&#xA;responds, history = model.chat(tokenizer, &#34;山东省最高的山是哪座山, 它比黄山高还是矮？差距多少？&#34;, temperature=0.5, top_p=0.8, repetition_penalty=1.02)&#xA;print(responds)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;期望输出&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;山东省最高的山是泰山，海拔1545米。&#xA;&#xA;相对于黄山（海拔1864米），泰山海拔较低，相差约319米。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p id=&#34;llamaformat&#34;&gt;&lt;/p&gt; &#xA;&lt;h5&gt;MiniCPM-2B （Llama Format）&lt;/h5&gt; &#xA;&lt;p&gt;我们将MiniCPM的模型权重转化成了Llama代码可以直接调用的&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16-llama-format&#34;&gt;格式&lt;/a&gt;，以便大家尝试:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import LlamaTokenizerFast, LlamaForCausalLM&#xA;model_path = &#34;openbmb/MiniCPM-2B-dpo-bf16-llama-format&#34;&#xA;tokenizer = LlamaTokenizerFast.from_pretrained(model_path)&#xA;model = LlamaForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, device_map=&#39;cuda&#39;, trust_remote_code=True)&#xA;&#xA;prompt=&#34;Now you act like a terminal situated within a beginner&#39;s C++ practice repository folder, please provide the output for the command: `ls -l`&#34;&#xA;input_ids = tokenizer.encode(&#34;&amp;lt;用户&amp;gt;{}&amp;lt;AI&amp;gt;&#34;.format(prompt), return_tensors=&#39;pt&#39;, add_special_tokens=True).cuda()&#xA;responds = model.generate(input_ids, temperature=0.3, top_p=0.8, repetition_penalty=1.02, max_length=1024)&#xA;responds = tokenizer.decode(responds[0], skip_special_tokens=True)&#xA;print(responds)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;MiniCPM-V&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from PIL import Image&#xA;from transformers import AutoModel, AutoTokenizer&#xA;&#xA;model = AutoModel.from_pretrained(&#39;openbmb/MiniCPM-V&#39;, trust_remote_code=True)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;openbmb/MiniCPM-V&#39;, trust_remote_code=True)&#xA;model.eval().cuda()&#xA;&#xA;image = Image.open(&#39;xx.jpg&#39;).convert(&#39;RGB&#39;)&#xA;question = &#39;What is in the image?&#39;&#xA;msgs = [{&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: question}]&#xA;&#xA;res, context, _ = model.chat(&#xA;    image=image,&#xA;    msgs=msgs,&#xA;    context=None,&#xA;    tokenizer=tokenizer,&#xA;    sampling=True,&#xA;    temperature=0.7&#xA;)&#xA;print(res)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;vLLM 推理&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;安装&lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt;主分支版本: &lt;a href=&#34;https://docs.vllm.ai/en/latest/getting_started/installation.html#build-from-source&#34;&gt;从源码安装&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;测试样例&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python inference/inference_vllm.py --model_path &amp;lt;hf_repo_path&amp;gt; --prompt_path prompts/prompt_demo.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;期望输出&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;lt;用户&amp;gt;: Which city is the capital of China?&#xA;&amp;lt;AI&amp;gt;:&#xA; The capital city of China is Beijing. Beijing is a major political, cultural, and economic center in China, and it is known for its rich history, beautiful architecture, and vibrant nightlife. It is also home to many of China&#39;s most important cultural and historical sites, including the Forbidden City, the Great Wall of China, and the Temple of Heaven. Beijing is a popular destination for tourists from around the world, and it is an important hub for international business and trade.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;llama.cpp、Ollama、fastllm、mlx_lm推理&lt;/h4&gt; &#xA;&lt;p&gt;MiniCPM支持&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/&#34;&gt;llama.cpp&lt;/a&gt; 、&lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;ollama&lt;/a&gt;、&lt;a href=&#34;https://github.com/ztxz16/fastllm&#34;&gt;fastllm&lt;/a&gt;、&lt;a href=&#34;https://github.com/ml-explore/mlx-examples&#34;&gt;mlx_lm&lt;/a&gt;推理。感谢&lt;a href=&#34;https://github.com/runfuture&#34;&gt;@runfuture&lt;/a&gt;对llama.cpp和ollama的适配。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#build&#34;&gt;安装llama.cpp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;下载gguf形式的模型。&lt;a href=&#34;https://huggingface.co/runfuture/MiniCPM-2B-dpo-fp16-gguf&#34;&gt;下载链接-fp16格式&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/runfuture/MiniCPM-2B-dpo-q4km-gguf&#34;&gt;下载链接-q4km格式&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;在命令行运行示例代码:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;./main -m ../../model_ckpts/download_from_hf/MiniCPM-2B-dpo-fp16-gguf.gguf --prompt &#34;&amp;lt;用户&amp;gt;写藏头诗，藏头是龙年大吉&amp;lt;AI&amp;gt;&#34; --temp 0.3 --top-p 0.8 --repeat-penalty 1.05&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;更多参数调整&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/raw/master/examples/main/README.md&#34;&gt;详见&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ollama&lt;/strong&gt; 正在解决&lt;a href=&#34;https://github.com/ollama/ollama/issues/2383&#34;&gt;这个问题&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;fastllm&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ztxz16/fastllm&#34;&gt;编译安装fastllm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;模型推理&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoTokenizer, LlamaTokenizerFast, AutoModelForCausalLM&#xA;path = &#39;openbmb/MiniCPM-2B-dpo-fp16&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(path)&#xA;model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.float16, device_map=&#39;cuda&#39;, trust_remote_code=True)&#xA;from fastllm_pytools import llm&#xA;llm.set_device_map(&#34;cpu&#34;)&#xA;model = llm.from_hf(model, tokenizer, dtype = &#34;float16&#34;) # dtype支持 &#34;float16&#34;, &#34;int8&#34;, &#34;int4&#34;&#xA;print(model.response(&#34;&amp;lt;用户&amp;gt;山东省最高的山是哪座山, 它比黄山高还是矮？差距多少？&amp;lt;AI&amp;gt;&#34;, top_p=0.8, temperature=0.5, repeat_penalty=1.02))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;mlx_lm&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;安装mlx_lm库 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install mlx_lm&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;下载转换后的模型权重&lt;a href=&#34;https://huggingface.co/mlx-community/MiniCPM-2B-sft-bf16-llama-format-mlx&#34;&gt;MiniCPM-2B-sft-bf16-llama-format-mlx&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;模型推理 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m mlx_lm.generate --model mlx-community/MiniCPM-2B-sft-bf16-llama-format-mlx --prompt &#34;hello, tell me a joke.&#34; --trust-remote-code&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p id=&#34;community&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;开源社区&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/foldl/chatllm.cpp&#34;&gt;ChatLLM框架&lt;/a&gt;：&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-dpo-bf16/discussions/2#65c59c4f27b8c11e43fc8796&#34;&gt;在CPU上跑MiniCPM&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;3&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;评测结果&lt;/h2&gt; &#xA;&lt;h4&gt;评测设置&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;由于大模型评测难以统一，且大量评测也没有公开的prompt和测试代码，对于具体评测方式，我们只能尽量做到适合各类模型。&lt;/li&gt; &#xA; &lt;li&gt;整体而言，我们测试时采用统一的prompt输入，并按照各模型对应的模板进行输入调整。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;评测脚本及prompt已开源在我们的Github仓库中，也欢迎更多开发者来不断改进我们的评测方式。&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;文本评测部分，采用了我们的开源大模型能力评测框架&lt;a href=&#34;https://github.com/OpenBMB/UltraEval&#34;&gt;UltraEval&lt;/a&gt;。以下为开源模型复现流程： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;安装UltraEval &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/OpenBMB/UltraEval.git&#xA;cd UltraEval&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;     &lt;li&gt;下载相关数据并解压处理 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget -O RawData.zip &#34;https://cloud.tsinghua.edu.cn/f/71b5232264ae4833a4d0/?dl=1&#34;&#xA;unzip RawData.zip&#xA;python data_process.py&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;     &lt;li&gt;执行评测脚本(提供了模板，可自定义) &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bash run_eval.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;部署模式&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;因为MiniCPM采用Mup的结构，与现有模型在具体计算上有细微差别，我们是基于vllm=0.2.2版本进行了我们模型的实现。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;对于非MiniCPM模型，我们采用了vllm=0.2.7的最新版本进行推理。&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;评测度量&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;对于QA任务（选择题任务），我们选用两种方式进行测试： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;PPL：将选项作为题目生成的延续，并根据各个选项的PPL来进行答案选择；&lt;/li&gt; &#xA;   &lt;li&gt;第二种是直接生成答案选项。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;对于不同模型，这两种方式得到的结果差异较大。MiniCPM两种模式上的结果较为接近，而Mistral-7B-v0.1等模型在PPL上表现较好，直接生成上效果较差。&lt;/li&gt; &#xA; &lt;li&gt;在具体评测时，我们以两种评测方式得分的最高者为最终结果，以此保证对比的公平性(以下表格中*号表示采用PPL)。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;文本模型评测&lt;/h4&gt; &#xA;&lt;p&gt;&lt;strong&gt;越级比较:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;平均分&lt;/th&gt; &#xA;   &lt;th&gt;英文均分&lt;/th&gt; &#xA;   &lt;th&gt;中文均分&lt;/th&gt; &#xA;   &lt;th&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th&gt;CMMLU&lt;/th&gt; &#xA;   &lt;th&gt;MMLU&lt;/th&gt; &#xA;   &lt;th&gt;HumanEval&lt;/th&gt; &#xA;   &lt;th&gt;MBPP&lt;/th&gt; &#xA;   &lt;th&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th&gt;MATH&lt;/th&gt; &#xA;   &lt;th&gt;BBH&lt;/th&gt; &#xA;   &lt;th&gt;ARC-E&lt;/th&gt; &#xA;   &lt;th&gt;ARC-C&lt;/th&gt; &#xA;   &lt;th&gt;HellaSwag&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B&lt;/td&gt; &#xA;   &lt;td&gt;35.40&lt;/td&gt; &#xA;   &lt;td&gt;36.21&lt;/td&gt; &#xA;   &lt;td&gt;31.765&lt;/td&gt; &#xA;   &lt;td&gt;32.42&lt;/td&gt; &#xA;   &lt;td&gt;31.11&lt;/td&gt; &#xA;   &lt;td&gt;44.32&lt;/td&gt; &#xA;   &lt;td&gt;12.2&lt;/td&gt; &#xA;   &lt;td&gt;27.17&lt;/td&gt; &#xA;   &lt;td&gt;13.57&lt;/td&gt; &#xA;   &lt;td&gt;1.8&lt;/td&gt; &#xA;   &lt;td&gt;33.23&lt;/td&gt; &#xA;   &lt;td&gt;75.25&lt;/td&gt; &#xA;   &lt;td&gt;42.75&lt;/td&gt; &#xA;   &lt;td&gt;75.62*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen-7B&lt;/td&gt; &#xA;   &lt;td&gt;49.46&lt;/td&gt; &#xA;   &lt;td&gt;47.19&lt;/td&gt; &#xA;   &lt;td&gt;59.655&lt;/td&gt; &#xA;   &lt;td&gt;58.96&lt;/td&gt; &#xA;   &lt;td&gt;60.35&lt;/td&gt; &#xA;   &lt;td&gt;57.65&lt;/td&gt; &#xA;   &lt;td&gt;17.07&lt;/td&gt; &#xA;   &lt;td&gt;42.15&lt;/td&gt; &#xA;   &lt;td&gt;41.24&lt;/td&gt; &#xA;   &lt;td&gt;5.34&lt;/td&gt; &#xA;   &lt;td&gt;37.75&lt;/td&gt; &#xA;   &lt;td&gt;83.42&lt;/td&gt; &#xA;   &lt;td&gt;64.76&lt;/td&gt; &#xA;   &lt;td&gt;75.32*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Deepseek-7B&lt;/td&gt; &#xA;   &lt;td&gt;39.96&lt;/td&gt; &#xA;   &lt;td&gt;39.15&lt;/td&gt; &#xA;   &lt;td&gt;43.64&lt;/td&gt; &#xA;   &lt;td&gt;42.82&lt;/td&gt; &#xA;   &lt;td&gt;44.45&lt;/td&gt; &#xA;   &lt;td&gt;47.82&lt;/td&gt; &#xA;   &lt;td&gt;20.12&lt;/td&gt; &#xA;   &lt;td&gt;41.45&lt;/td&gt; &#xA;   &lt;td&gt;15.85&lt;/td&gt; &#xA;   &lt;td&gt;1.53&lt;/td&gt; &#xA;   &lt;td&gt;33.38&lt;/td&gt; &#xA;   &lt;td&gt;74.58*&lt;/td&gt; &#xA;   &lt;td&gt;42.15*&lt;/td&gt; &#xA;   &lt;td&gt;75.45*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B&lt;/td&gt; &#xA;   &lt;td&gt;48.97&lt;/td&gt; &#xA;   &lt;td&gt;49.96&lt;/td&gt; &#xA;   &lt;td&gt;44.54&lt;/td&gt; &#xA;   &lt;td&gt;46.12&lt;/td&gt; &#xA;   &lt;td&gt;42.96&lt;/td&gt; &#xA;   &lt;td&gt;62.69&lt;/td&gt; &#xA;   &lt;td&gt;27.44&lt;/td&gt; &#xA;   &lt;td&gt;45.2&lt;/td&gt; &#xA;   &lt;td&gt;33.13&lt;/td&gt; &#xA;   &lt;td&gt;5.0&lt;/td&gt; &#xA;   &lt;td&gt;41.06&lt;/td&gt; &#xA;   &lt;td&gt;83.92&lt;/td&gt; &#xA;   &lt;td&gt;70.73&lt;/td&gt; &#xA;   &lt;td&gt;80.43*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-13B&lt;/td&gt; &#xA;   &lt;td&gt;41.48&lt;/td&gt; &#xA;   &lt;td&gt;42.44&lt;/td&gt; &#xA;   &lt;td&gt;37.19&lt;/td&gt; &#xA;   &lt;td&gt;37.32&lt;/td&gt; &#xA;   &lt;td&gt;37.06&lt;/td&gt; &#xA;   &lt;td&gt;54.71&lt;/td&gt; &#xA;   &lt;td&gt;17.07&lt;/td&gt; &#xA;   &lt;td&gt;32.55&lt;/td&gt; &#xA;   &lt;td&gt;21.15&lt;/td&gt; &#xA;   &lt;td&gt;2.25&lt;/td&gt; &#xA;   &lt;td&gt;37.92&lt;/td&gt; &#xA;   &lt;td&gt;78.87*&lt;/td&gt; &#xA;   &lt;td&gt;58.19&lt;/td&gt; &#xA;   &lt;td&gt;79.23*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MPT-30B&lt;/td&gt; &#xA;   &lt;td&gt;38.17&lt;/td&gt; &#xA;   &lt;td&gt;39.82&lt;/td&gt; &#xA;   &lt;td&gt;30.72&lt;/td&gt; &#xA;   &lt;td&gt;29.34&lt;/td&gt; &#xA;   &lt;td&gt;32.09&lt;/td&gt; &#xA;   &lt;td&gt;46.56&lt;/td&gt; &#xA;   &lt;td&gt;21.95&lt;/td&gt; &#xA;   &lt;td&gt;35.36&lt;/td&gt; &#xA;   &lt;td&gt;10.31&lt;/td&gt; &#xA;   &lt;td&gt;1.56&lt;/td&gt; &#xA;   &lt;td&gt;38.22&lt;/td&gt; &#xA;   &lt;td&gt;78.66*&lt;/td&gt; &#xA;   &lt;td&gt;46.08*&lt;/td&gt; &#xA;   &lt;td&gt;79.72*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Falcon-40B&lt;/td&gt; &#xA;   &lt;td&gt;43.62&lt;/td&gt; &#xA;   &lt;td&gt;44.21&lt;/td&gt; &#xA;   &lt;td&gt;40.93&lt;/td&gt; &#xA;   &lt;td&gt;40.29&lt;/td&gt; &#xA;   &lt;td&gt;41.57&lt;/td&gt; &#xA;   &lt;td&gt;53.53&lt;/td&gt; &#xA;   &lt;td&gt;24.39&lt;/td&gt; &#xA;   &lt;td&gt;36.53&lt;/td&gt; &#xA;   &lt;td&gt;22.44&lt;/td&gt; &#xA;   &lt;td&gt;1.92&lt;/td&gt; &#xA;   &lt;td&gt;36.24&lt;/td&gt; &#xA;   &lt;td&gt;81.94*&lt;/td&gt; &#xA;   &lt;td&gt;57.68&lt;/td&gt; &#xA;   &lt;td&gt;83.26*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniCPM-2B&lt;/td&gt; &#xA;   &lt;td&gt;52.33&lt;/td&gt; &#xA;   &lt;td&gt;52.6&lt;/td&gt; &#xA;   &lt;td&gt;51.1&lt;/td&gt; &#xA;   &lt;td&gt;51.13&lt;/td&gt; &#xA;   &lt;td&gt;51.07&lt;/td&gt; &#xA;   &lt;td&gt;53.46&lt;/td&gt; &#xA;   &lt;td&gt;50.00&lt;/td&gt; &#xA;   &lt;td&gt;47.31&lt;/td&gt; &#xA;   &lt;td&gt;53.83&lt;/td&gt; &#xA;   &lt;td&gt;10.24&lt;/td&gt; &#xA;   &lt;td&gt;36.87&lt;/td&gt; &#xA;   &lt;td&gt;85.44&lt;/td&gt; &#xA;   &lt;td&gt;68.00&lt;/td&gt; &#xA;   &lt;td&gt;68.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;同级比较：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;平均分&lt;/th&gt; &#xA;   &lt;th&gt;英文均分&lt;/th&gt; &#xA;   &lt;th&gt;中文均分&lt;/th&gt; &#xA;   &lt;th&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th&gt;CMMLU&lt;/th&gt; &#xA;   &lt;th&gt;MMLU&lt;/th&gt; &#xA;   &lt;th&gt;HumanEval&lt;/th&gt; &#xA;   &lt;th&gt;MBPP&lt;/th&gt; &#xA;   &lt;th&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th&gt;MATH&lt;/th&gt; &#xA;   &lt;th&gt;BBH&lt;/th&gt; &#xA;   &lt;th&gt;ARC-E&lt;/th&gt; &#xA;   &lt;th&gt;ARC-C&lt;/th&gt; &#xA;   &lt;th&gt;HellaSwag&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TinyLlama-1.1B&lt;/td&gt; &#xA;   &lt;td&gt;25.36&lt;/td&gt; &#xA;   &lt;td&gt;25.55&lt;/td&gt; &#xA;   &lt;td&gt;24.525&lt;/td&gt; &#xA;   &lt;td&gt;25.02&lt;/td&gt; &#xA;   &lt;td&gt;24.03&lt;/td&gt; &#xA;   &lt;td&gt;24.3&lt;/td&gt; &#xA;   &lt;td&gt;6.71&lt;/td&gt; &#xA;   &lt;td&gt;19.91&lt;/td&gt; &#xA;   &lt;td&gt;2.27&lt;/td&gt; &#xA;   &lt;td&gt;0.74&lt;/td&gt; &#xA;   &lt;td&gt;28.78&lt;/td&gt; &#xA;   &lt;td&gt;60.77*&lt;/td&gt; &#xA;   &lt;td&gt;28.15*&lt;/td&gt; &#xA;   &lt;td&gt;58.33*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen-1.8B&lt;/td&gt; &#xA;   &lt;td&gt;34.72&lt;/td&gt; &#xA;   &lt;td&gt;31.87&lt;/td&gt; &#xA;   &lt;td&gt;47.57&lt;/td&gt; &#xA;   &lt;td&gt;49.81&lt;/td&gt; &#xA;   &lt;td&gt;45.32&lt;/td&gt; &#xA;   &lt;td&gt;43.37&lt;/td&gt; &#xA;   &lt;td&gt;7.93&lt;/td&gt; &#xA;   &lt;td&gt;17.80&lt;/td&gt; &#xA;   &lt;td&gt;19.26&lt;/td&gt; &#xA;   &lt;td&gt;2.42&lt;/td&gt; &#xA;   &lt;td&gt;29.07&lt;/td&gt; &#xA;   &lt;td&gt;63.97*&lt;/td&gt; &#xA;   &lt;td&gt;43.69&lt;/td&gt; &#xA;   &lt;td&gt;59.28*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemini Nano-3B&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;27.2(report)&lt;/td&gt; &#xA;   &lt;td&gt;22.8(report)&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;42.4(report)&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;StableLM-Zephyr-3B&lt;/td&gt; &#xA;   &lt;td&gt;43.46&lt;/td&gt; &#xA;   &lt;td&gt;46.31&lt;/td&gt; &#xA;   &lt;td&gt;30.62&lt;/td&gt; &#xA;   &lt;td&gt;30.34&lt;/td&gt; &#xA;   &lt;td&gt;30.89&lt;/td&gt; &#xA;   &lt;td&gt;45.9&lt;/td&gt; &#xA;   &lt;td&gt;35.37&lt;/td&gt; &#xA;   &lt;td&gt;31.85&lt;/td&gt; &#xA;   &lt;td&gt;52.54&lt;/td&gt; &#xA;   &lt;td&gt;12.49&lt;/td&gt; &#xA;   &lt;td&gt;37.68&lt;/td&gt; &#xA;   &lt;td&gt;73.78&lt;/td&gt; &#xA;   &lt;td&gt;55.38&lt;/td&gt; &#xA;   &lt;td&gt;71.87*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi-2-2B&lt;/td&gt; &#xA;   &lt;td&gt;48.84&lt;/td&gt; &#xA;   &lt;td&gt;54.41&lt;/td&gt; &#xA;   &lt;td&gt;23.78&lt;/td&gt; &#xA;   &lt;td&gt;23.37&lt;/td&gt; &#xA;   &lt;td&gt;24.18&lt;/td&gt; &#xA;   &lt;td&gt;52.66&lt;/td&gt; &#xA;   &lt;td&gt;47.56&lt;/td&gt; &#xA;   &lt;td&gt;55.04&lt;/td&gt; &#xA;   &lt;td&gt;57.16&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;   &lt;td&gt;43.39&lt;/td&gt; &#xA;   &lt;td&gt;86.11&lt;/td&gt; &#xA;   &lt;td&gt;71.25&lt;/td&gt; &#xA;   &lt;td&gt;73.07*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniCPM-2B&lt;/td&gt; &#xA;   &lt;td&gt;52.33&lt;/td&gt; &#xA;   &lt;td&gt;52.6&lt;/td&gt; &#xA;   &lt;td&gt;51.10&lt;/td&gt; &#xA;   &lt;td&gt;51.13&lt;/td&gt; &#xA;   &lt;td&gt;51.07&lt;/td&gt; &#xA;   &lt;td&gt;53.46&lt;/td&gt; &#xA;   &lt;td&gt;50.00&lt;/td&gt; &#xA;   &lt;td&gt;47.31&lt;/td&gt; &#xA;   &lt;td&gt;53.83&lt;/td&gt; &#xA;   &lt;td&gt;10.24&lt;/td&gt; &#xA;   &lt;td&gt;36.87&lt;/td&gt; &#xA;   &lt;td&gt;85.44&lt;/td&gt; &#xA;   &lt;td&gt;68.00&lt;/td&gt; &#xA;   &lt;td&gt;68.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Chat模型比较：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;平均分&lt;/th&gt; &#xA;   &lt;th&gt;英文均分&lt;/th&gt; &#xA;   &lt;th&gt;中文均分&lt;/th&gt; &#xA;   &lt;th&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th&gt;CMMLU&lt;/th&gt; &#xA;   &lt;th&gt;MMLU&lt;/th&gt; &#xA;   &lt;th&gt;HumanEval&lt;/th&gt; &#xA;   &lt;th&gt;MBPP&lt;/th&gt; &#xA;   &lt;th&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th&gt;MATH&lt;/th&gt; &#xA;   &lt;th&gt;BBH&lt;/th&gt; &#xA;   &lt;th&gt;ARC-E&lt;/th&gt; &#xA;   &lt;th&gt;ARC-C&lt;/th&gt; &#xA;   &lt;th&gt;HellaSwag&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;37.98&lt;/td&gt; &#xA;   &lt;td&gt;35.17&lt;/td&gt; &#xA;   &lt;td&gt;50.63&lt;/td&gt; &#xA;   &lt;td&gt;52.05&lt;/td&gt; &#xA;   &lt;td&gt;49.21&lt;/td&gt; &#xA;   &lt;td&gt;45.77&lt;/td&gt; &#xA;   &lt;td&gt;10.37&lt;/td&gt; &#xA;   &lt;td&gt;9.38&lt;/td&gt; &#xA;   &lt;td&gt;22.74&lt;/td&gt; &#xA;   &lt;td&gt;5.96&lt;/td&gt; &#xA;   &lt;td&gt;32.6&lt;/td&gt; &#xA;   &lt;td&gt;74.45&lt;/td&gt; &#xA;   &lt;td&gt;56.82&lt;/td&gt; &#xA;   &lt;td&gt;58.48*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B-Instruct-v0.1&lt;/td&gt; &#xA;   &lt;td&gt;44.36&lt;/td&gt; &#xA;   &lt;td&gt;45.89&lt;/td&gt; &#xA;   &lt;td&gt;37.51&lt;/td&gt; &#xA;   &lt;td&gt;38.06&lt;/td&gt; &#xA;   &lt;td&gt;36.96&lt;/td&gt; &#xA;   &lt;td&gt;53.56&lt;/td&gt; &#xA;   &lt;td&gt;29.27&lt;/td&gt; &#xA;   &lt;td&gt;39.34&lt;/td&gt; &#xA;   &lt;td&gt;28.73&lt;/td&gt; &#xA;   &lt;td&gt;3.48&lt;/td&gt; &#xA;   &lt;td&gt;39.52&lt;/td&gt; &#xA;   &lt;td&gt;81.61&lt;/td&gt; &#xA;   &lt;td&gt;63.99&lt;/td&gt; &#xA;   &lt;td&gt;73.47*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B-Instruct-v0.2&lt;/td&gt; &#xA;   &lt;td&gt;50.91&lt;/td&gt; &#xA;   &lt;td&gt;52.83&lt;/td&gt; &#xA;   &lt;td&gt;42.235&lt;/td&gt; &#xA;   &lt;td&gt;42.55&lt;/td&gt; &#xA;   &lt;td&gt;41.92&lt;/td&gt; &#xA;   &lt;td&gt;60.51&lt;/td&gt; &#xA;   &lt;td&gt;36.59&lt;/td&gt; &#xA;   &lt;td&gt;48.95&lt;/td&gt; &#xA;   &lt;td&gt;40.49&lt;/td&gt; &#xA;   &lt;td&gt;4.95&lt;/td&gt; &#xA;   &lt;td&gt;39.81&lt;/td&gt; &#xA;   &lt;td&gt;86.28&lt;/td&gt; &#xA;   &lt;td&gt;73.38&lt;/td&gt; &#xA;   &lt;td&gt;84.55*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;44.93&lt;/td&gt; &#xA;   &lt;td&gt;42.05&lt;/td&gt; &#xA;   &lt;td&gt;57.9&lt;/td&gt; &#xA;   &lt;td&gt;58.57&lt;/td&gt; &#xA;   &lt;td&gt;57.23&lt;/td&gt; &#xA;   &lt;td&gt;56.03&lt;/td&gt; &#xA;   &lt;td&gt;15.85&lt;/td&gt; &#xA;   &lt;td&gt;40.52&lt;/td&gt; &#xA;   &lt;td&gt;42.23&lt;/td&gt; &#xA;   &lt;td&gt;8.3&lt;/td&gt; &#xA;   &lt;td&gt;37.34&lt;/td&gt; &#xA;   &lt;td&gt;64.44*&lt;/td&gt; &#xA;   &lt;td&gt;39.25*&lt;/td&gt; &#xA;   &lt;td&gt;74.52*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Yi-6B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;50.46&lt;/td&gt; &#xA;   &lt;td&gt;45.89&lt;/td&gt; &#xA;   &lt;td&gt;70.995&lt;/td&gt; &#xA;   &lt;td&gt;70.88&lt;/td&gt; &#xA;   &lt;td&gt;71.11&lt;/td&gt; &#xA;   &lt;td&gt;62.95&lt;/td&gt; &#xA;   &lt;td&gt;14.02&lt;/td&gt; &#xA;   &lt;td&gt;28.34&lt;/td&gt; &#xA;   &lt;td&gt;36.54&lt;/td&gt; &#xA;   &lt;td&gt;3.88&lt;/td&gt; &#xA;   &lt;td&gt;37.43&lt;/td&gt; &#xA;   &lt;td&gt;84.89&lt;/td&gt; &#xA;   &lt;td&gt;70.39&lt;/td&gt; &#xA;   &lt;td&gt;74.6*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan2-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;44.68&lt;/td&gt; &#xA;   &lt;td&gt;42.74&lt;/td&gt; &#xA;   &lt;td&gt;53.39&lt;/td&gt; &#xA;   &lt;td&gt;53.28&lt;/td&gt; &#xA;   &lt;td&gt;53.5&lt;/td&gt; &#xA;   &lt;td&gt;53&lt;/td&gt; &#xA;   &lt;td&gt;21.34&lt;/td&gt; &#xA;   &lt;td&gt;32.32&lt;/td&gt; &#xA;   &lt;td&gt;25.25&lt;/td&gt; &#xA;   &lt;td&gt;6.32&lt;/td&gt; &#xA;   &lt;td&gt;37.46&lt;/td&gt; &#xA;   &lt;td&gt;79.63&lt;/td&gt; &#xA;   &lt;td&gt;60.15&lt;/td&gt; &#xA;   &lt;td&gt;69.23*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Deepseek-7B-chat&lt;/td&gt; &#xA;   &lt;td&gt;49.34&lt;/td&gt; &#xA;   &lt;td&gt;49.56&lt;/td&gt; &#xA;   &lt;td&gt;48.335&lt;/td&gt; &#xA;   &lt;td&gt;46.95&lt;/td&gt; &#xA;   &lt;td&gt;49.72&lt;/td&gt; &#xA;   &lt;td&gt;51.67&lt;/td&gt; &#xA;   &lt;td&gt;40.85&lt;/td&gt; &#xA;   &lt;td&gt;48.48&lt;/td&gt; &#xA;   &lt;td&gt;48.52&lt;/td&gt; &#xA;   &lt;td&gt;4.26&lt;/td&gt; &#xA;   &lt;td&gt;35.7&lt;/td&gt; &#xA;   &lt;td&gt;76.85&lt;/td&gt; &#xA;   &lt;td&gt;63.05&lt;/td&gt; &#xA;   &lt;td&gt;76.68*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;38.16&lt;/td&gt; &#xA;   &lt;td&gt;39.17&lt;/td&gt; &#xA;   &lt;td&gt;33.59&lt;/td&gt; &#xA;   &lt;td&gt;34.54&lt;/td&gt; &#xA;   &lt;td&gt;32.64&lt;/td&gt; &#xA;   &lt;td&gt;47.64&lt;/td&gt; &#xA;   &lt;td&gt;14.02&lt;/td&gt; &#xA;   &lt;td&gt;27.4&lt;/td&gt; &#xA;   &lt;td&gt;21.15&lt;/td&gt; &#xA;   &lt;td&gt;2.08&lt;/td&gt; &#xA;   &lt;td&gt;35.54&lt;/td&gt; &#xA;   &lt;td&gt;74.28&lt;/td&gt; &#xA;   &lt;td&gt;54.78&lt;/td&gt; &#xA;   &lt;td&gt;75.65*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniCPM-2B&lt;/td&gt; &#xA;   &lt;td&gt;52.33&lt;/td&gt; &#xA;   &lt;td&gt;52.6&lt;/td&gt; &#xA;   &lt;td&gt;51.10&lt;/td&gt; &#xA;   &lt;td&gt;51.13&lt;/td&gt; &#xA;   &lt;td&gt;51.07&lt;/td&gt; &#xA;   &lt;td&gt;53.46&lt;/td&gt; &#xA;   &lt;td&gt;50.00&lt;/td&gt; &#xA;   &lt;td&gt;47.31&lt;/td&gt; &#xA;   &lt;td&gt;53.83&lt;/td&gt; &#xA;   &lt;td&gt;10.24&lt;/td&gt; &#xA;   &lt;td&gt;36.87&lt;/td&gt; &#xA;   &lt;td&gt;85.44&lt;/td&gt; &#xA;   &lt;td&gt;68.00&lt;/td&gt; &#xA;   &lt;td&gt;68.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;DPO后模型比较：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;MT-bench&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-4-turbo&lt;/td&gt; &#xA;   &lt;td&gt;9.32&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-3.5-turbo&lt;/td&gt; &#xA;   &lt;td&gt;8.39&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-8*7b-Instruct-v0.1&lt;/td&gt; &#xA;   &lt;td&gt;8.30&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Claude-2.1&lt;/td&gt; &#xA;   &lt;td&gt;8.18&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Zephyr-7B-beta&lt;/td&gt; &#xA;   &lt;td&gt;7.34&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MiniCPM-2B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;7.25&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna-33B&lt;/td&gt; &#xA;   &lt;td&gt;7.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Zephyr-7B-alpha&lt;/td&gt; &#xA;   &lt;td&gt;6.88&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-2-70B-chat&lt;/td&gt; &#xA;   &lt;td&gt;6.86&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B-Instruct-v0.1&lt;/td&gt; &#xA;   &lt;td&gt;6.84&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MPT-34B-instruct&lt;/td&gt; &#xA;   &lt;td&gt;6.39&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;MiniCPM-2B-128k 模型评测&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;avg&lt;/th&gt; &#xA;   &lt;th&gt;avg w/o code&amp;amp;math&lt;/th&gt; &#xA;   &lt;th&gt;passkey&lt;/th&gt; &#xA;   &lt;th&gt;number_string&lt;/th&gt; &#xA;   &lt;th&gt;kv_retrieval&lt;/th&gt; &#xA;   &lt;th&gt;longbook_choice_eng&lt;/th&gt; &#xA;   &lt;th&gt;longbook_qa_chn&lt;/th&gt; &#xA;   &lt;th&gt;longbook_qa_eng&lt;/th&gt; &#xA;   &lt;th&gt;longbook_sum_eng&lt;/th&gt; &#xA;   &lt;th&gt;longdialogue_qa_eng&lt;/th&gt; &#xA;   &lt;th&gt;math_calc&lt;/th&gt; &#xA;   &lt;th&gt;math_find&lt;/th&gt; &#xA;   &lt;th&gt;code_debug&lt;/th&gt; &#xA;   &lt;th&gt;code_run&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-128k&lt;/td&gt; &#xA;   &lt;td&gt;24.45&lt;/td&gt; &#xA;   &lt;td&gt;33.62&lt;/td&gt; &#xA;   &lt;td&gt;100&lt;/td&gt; &#xA;   &lt;td&gt;97.8&lt;/td&gt; &#xA;   &lt;td&gt;0.6&lt;/td&gt; &#xA;   &lt;td&gt;28.82&lt;/td&gt; &#xA;   &lt;td&gt;15.93&lt;/td&gt; &#xA;   &lt;td&gt;14.31&lt;/td&gt; &#xA;   &lt;td&gt;9.99&lt;/td&gt; &#xA;   &lt;td&gt;1.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;3.43&lt;/td&gt; &#xA;   &lt;td&gt;20.05&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Yarn-Mistral-7b-128k&lt;/td&gt; &#xA;   &lt;td&gt;19.84&lt;/td&gt; &#xA;   &lt;td&gt;27.36&lt;/td&gt; &#xA;   &lt;td&gt;92.71&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;27.95&lt;/td&gt; &#xA;   &lt;td&gt;15.49&lt;/td&gt; &#xA;   &lt;td&gt;9.55&lt;/td&gt; &#xA;   &lt;td&gt;9.06&lt;/td&gt; &#xA;   &lt;td&gt;7.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;17.14&lt;/td&gt; &#xA;   &lt;td&gt;0.76&lt;/td&gt; &#xA;   &lt;td&gt;1.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B-Instruct-v0.2(ABF 1000w)&lt;/td&gt; &#xA;   &lt;td&gt;27.75&lt;/td&gt; &#xA;   &lt;td&gt;36.9&lt;/td&gt; &#xA;   &lt;td&gt;100&lt;/td&gt; &#xA;   &lt;td&gt;78.98&lt;/td&gt; &#xA;   &lt;td&gt;3.6&lt;/td&gt; &#xA;   &lt;td&gt;37.12&lt;/td&gt; &#xA;   &lt;td&gt;11.74&lt;/td&gt; &#xA;   &lt;td&gt;17.37&lt;/td&gt; &#xA;   &lt;td&gt;21.12&lt;/td&gt; &#xA;   &lt;td&gt;9.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;29.43&lt;/td&gt; &#xA;   &lt;td&gt;17.51&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Yi-6B-200k&lt;/td&gt; &#xA;   &lt;td&gt;22.15&lt;/td&gt; &#xA;   &lt;td&gt;32.54&lt;/td&gt; &#xA;   &lt;td&gt;100&lt;/td&gt; &#xA;   &lt;td&gt;94.92&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;36.68&lt;/td&gt; &#xA;   &lt;td&gt;15.07&lt;/td&gt; &#xA;   &lt;td&gt;9.2&lt;/td&gt; &#xA;   &lt;td&gt;0.92&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;4.29&lt;/td&gt; &#xA;   &lt;td&gt;0.51&lt;/td&gt; &#xA;   &lt;td&gt;0.75&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;chatglm3-6b-128k&lt;/td&gt; &#xA;   &lt;td&gt;25.58&lt;/td&gt; &#xA;   &lt;td&gt;36.57&lt;/td&gt; &#xA;   &lt;td&gt;89.93&lt;/td&gt; &#xA;   &lt;td&gt;99.66&lt;/td&gt; &#xA;   &lt;td&gt;5.2&lt;/td&gt; &#xA;   &lt;td&gt;46.29&lt;/td&gt; &#xA;   &lt;td&gt;10.7&lt;/td&gt; &#xA;   &lt;td&gt;8.38&lt;/td&gt; &#xA;   &lt;td&gt;25.91&lt;/td&gt; &#xA;   &lt;td&gt;6.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;5.33&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniCPM-2.4B-128k&lt;/td&gt; &#xA;   &lt;td&gt;27.32&lt;/td&gt; &#xA;   &lt;td&gt;37.68&lt;/td&gt; &#xA;   &lt;td&gt;98.31&lt;/td&gt; &#xA;   &lt;td&gt;99.83&lt;/td&gt; &#xA;   &lt;td&gt;9&lt;/td&gt; &#xA;   &lt;td&gt;29.69&lt;/td&gt; &#xA;   &lt;td&gt;23.06&lt;/td&gt; &#xA;   &lt;td&gt;16.33&lt;/td&gt; &#xA;   &lt;td&gt;15.73&lt;/td&gt; &#xA;   &lt;td&gt;9.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;4.29&lt;/td&gt; &#xA;   &lt;td&gt;22.08&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;MiniCPM-MoE-8x2B模型评测&lt;/h4&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;table style=&#34;margin: 0px auto;&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;    &lt;th nowrap&gt;BBH&lt;/th&gt; &#xA;    &lt;th nowrap&gt;MMLU&lt;/th&gt; &#xA;    &lt;th nowrap&gt;CEval&lt;/th&gt; &#xA;    &lt;th nowrap&gt;CMMLU&lt;/th&gt; &#xA;    &lt;th nowrap&gt;HumanEval&lt;/th&gt; &#xA;    &lt;th nowrap&gt;MBPP†&lt;/th&gt; &#xA;    &lt;th nowrap&gt;GSM8K&lt;/th&gt; &#xA;    &lt;th nowrap&gt;MATH&lt;/th&gt; &#xA;   &lt;/tr&gt;&#xA;  &lt;/thead&gt; &#xA;  &lt;tbody align=&#34;center&#34;&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Llama2-34B*&lt;/td&gt; &#xA;    &lt;td&gt;44.1&lt;/td&gt; &#xA;    &lt;td&gt;62.6&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;22.6&lt;/td&gt; &#xA;    &lt;td&gt;33.0&lt;/td&gt; &#xA;    &lt;td&gt;42.2&lt;/td&gt; &#xA;    &lt;td&gt;6.24&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Mistral-7B-Instruct-v0.2&lt;/td&gt; &#xA;    &lt;td&gt;39.81&lt;/td&gt; &#xA;    &lt;td&gt;60.51&lt;/td&gt; &#xA;    &lt;td&gt;42.55&lt;/td&gt; &#xA;    &lt;td&gt;41.92&lt;/td&gt; &#xA;    &lt;td&gt;36.59&lt;/td&gt; &#xA;    &lt;td&gt;39.63&lt;/td&gt; &#xA;    &lt;td&gt;40.49&lt;/td&gt; &#xA;    &lt;td&gt;4.95&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Gemma-7B*&lt;/td&gt; &#xA;    &lt;td&gt;55.1&lt;/td&gt; &#xA;    &lt;td&gt;64.3&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;32.3&lt;/td&gt; &#xA;    &lt;td&gt;44.4&lt;/td&gt; &#xA;    &lt;td&gt;46.4&lt;/td&gt; &#xA;    &lt;td&gt;24.3&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Qwen1.5-7B*&lt;/td&gt; &#xA;    &lt;td&gt;40.2&lt;/td&gt; &#xA;    &lt;td&gt;61&lt;/td&gt; &#xA;    &lt;td&gt;74.1&lt;/td&gt; &#xA;    &lt;td&gt;73.1&lt;/td&gt; &#xA;    &lt;td&gt;36&lt;/td&gt; &#xA;    &lt;td&gt;37.4&lt;/td&gt; &#xA;    &lt;td&gt;62.5&lt;/td&gt; &#xA;    &lt;td&gt;20.3&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Deepseek-MoE(16B)*&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;45.0&lt;/td&gt; &#xA;    &lt;td&gt;40.6&lt;/td&gt; &#xA;    &lt;td&gt;42.5&lt;/td&gt; &#xA;    &lt;td&gt;26.8&lt;/td&gt; &#xA;    &lt;td&gt;39.2&lt;/td&gt; &#xA;    &lt;td&gt;18.8&lt;/td&gt; &#xA;    &lt;td&gt;4.3&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;&lt;b&gt;MiniCPM-2.4B&lt;/b&gt;&lt;/td&gt; &#xA;    &lt;td&gt;36.87&lt;/td&gt; &#xA;    &lt;td&gt;53.46&lt;/td&gt; &#xA;    &lt;td&gt;51.13&lt;/td&gt; &#xA;    &lt;td&gt;51.07&lt;/td&gt; &#xA;    &lt;td&gt;50.00&lt;/td&gt; &#xA;    &lt;td&gt;35.93&lt;/td&gt; &#xA;    &lt;td&gt;53.83&lt;/td&gt; &#xA;    &lt;td&gt;10.24&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;&lt;b&gt;MiniCPM-MoE-8x2B&lt;/b&gt;&lt;/td&gt; &#xA;    &lt;td&gt;39.22&lt;/td&gt; &#xA;    &lt;td&gt;58.90&lt;/td&gt; &#xA;    &lt;td&gt;58.11&lt;/td&gt; &#xA;    &lt;td&gt;58.80&lt;/td&gt; &#xA;    &lt;td&gt;55.49&lt;/td&gt; &#xA;    &lt;td&gt;41.68&lt;/td&gt; &#xA;    &lt;td&gt;61.56&lt;/td&gt; &#xA;    &lt;td&gt;10.52&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;p id=&#34;4&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;注：* 表示结果取自技术报告。† 表示评测集为MBPP全集。&lt;/p&gt; &#xA;&lt;h4&gt;多模态模型评测&lt;/h4&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;margin: 0px auto;&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Size&lt;/th&gt; &#xA;    &lt;th&gt;TextVQA val&lt;/th&gt; &#xA;    &lt;th&gt;DocVQA test&lt;/th&gt; &#xA;    &lt;th&gt;OCRBench&lt;/th&gt; &#xA;    &lt;th&gt;OpenCompass&lt;/th&gt; &#xA;    &lt;th nowrap&gt;MME&lt;/th&gt; &#xA;    &lt;th&gt;MMB dev(en)&lt;/th&gt; &#xA;    &lt;th&gt;MMB dev(zh)&lt;/th&gt; &#xA;    &lt;th&gt;MMMU val&lt;/th&gt; &#xA;    &lt;th&gt;MathVista&lt;/th&gt; &#xA;    &lt;th&gt;LLaVA Bench&lt;/th&gt; &#xA;    &lt;th nowrap&gt;Object HalBench&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody align=&#34;center&#34;&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td colspan=&#34;12&#34; align=&#34;left&#34;&gt;&lt;strong&gt;Proprietary models&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Gemini Pro Vision&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;74.6&lt;/td&gt; &#xA;    &lt;td&gt;88.1&lt;/td&gt; &#xA;    &lt;td&gt;680&lt;/td&gt; &#xA;    &lt;td&gt;63.8&lt;/td&gt; &#xA;    &lt;td&gt;2148.9&lt;/td&gt; &#xA;    &lt;td&gt;75.2&lt;/td&gt; &#xA;    &lt;td&gt;74.0&lt;/td&gt; &#xA;    &lt;td&gt;48.9&lt;/td&gt; &#xA;    &lt;td&gt;45.8&lt;/td&gt; &#xA;    &lt;td&gt;79.9&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;GPT-4V&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;78.0&lt;/td&gt; &#xA;    &lt;td&gt;88.4&lt;/td&gt; &#xA;    &lt;td&gt;645&lt;/td&gt; &#xA;    &lt;td&gt;63.2&lt;/td&gt; &#xA;    &lt;td&gt;1771.5&lt;/td&gt; &#xA;    &lt;td&gt;75.1&lt;/td&gt; &#xA;    &lt;td&gt;75.0&lt;/td&gt; &#xA;    &lt;td&gt;53.8&lt;/td&gt; &#xA;    &lt;td&gt;47.8&lt;/td&gt; &#xA;    &lt;td&gt;93.1&lt;/td&gt; &#xA;    &lt;td&gt;86.4 / 92.7&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td colspan=&#34;12&#34; align=&#34;left&#34;&gt;&lt;strong&gt;Open-source models 6B~34B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Yi-VL-6B&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;6.7B&lt;/td&gt; &#xA;    &lt;td&gt;45.5*&lt;/td&gt; &#xA;    &lt;td&gt;17.1*&lt;/td&gt; &#xA;    &lt;td&gt;290&lt;/td&gt; &#xA;    &lt;td&gt;49.3&lt;/td&gt; &#xA;    &lt;td&gt;1915.1 &lt;/td&gt; &#xA;    &lt;td&gt;68.6 &lt;/td&gt; &#xA;    &lt;td&gt;68.3 &lt;/td&gt; &#xA;    &lt;td&gt;40.3 &lt;/td&gt; &#xA;    &lt;td&gt;28.8 &lt;/td&gt; &#xA;    &lt;td&gt;51.9 &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Qwen-VL-Chat&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;9.6B&lt;/td&gt; &#xA;    &lt;td&gt;61.5&lt;/td&gt; &#xA;    &lt;td&gt;62.6&lt;/td&gt; &#xA;    &lt;td&gt;488 &lt;/td&gt; &#xA;    &lt;td&gt;52.1 &lt;/td&gt; &#xA;    &lt;td&gt;1860.0 &lt;/td&gt; &#xA;    &lt;td&gt;60.6 &lt;/td&gt; &#xA;    &lt;td&gt;56.7 &lt;/td&gt; &#xA;    &lt;td&gt;37.0 &lt;/td&gt; &#xA;    &lt;td&gt;33.8 &lt;/td&gt; &#xA;    &lt;td&gt;67.7 &lt;/td&gt; &#xA;    &lt;td&gt;56.2 / 80.0&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Yi-VL-34B&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;34B&lt;/td&gt; &#xA;    &lt;td&gt;43.4*&lt;/td&gt; &#xA;    &lt;td&gt;16.9*&lt;/td&gt; &#xA;    &lt;td&gt;290&lt;/td&gt; &#xA;    &lt;td&gt;52.6 &lt;/td&gt; &#xA;    &lt;td&gt;2050.2&lt;/td&gt; &#xA;    &lt;td&gt;71.1&lt;/td&gt; &#xA;    &lt;td&gt;71.4&lt;/td&gt; &#xA;    &lt;td&gt;45.1&lt;/td&gt; &#xA;    &lt;td&gt;30.7&lt;/td&gt; &#xA;    &lt;td&gt;62.3&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;DeepSeek-VL-7B&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;7.3B&lt;/td&gt; &#xA;    &lt;td&gt;64.7*&lt;/td&gt; &#xA;    &lt;td&gt;47.0* &lt;/td&gt; &#xA;    &lt;td&gt;435&lt;/td&gt; &#xA;    &lt;td&gt;55.6 &lt;/td&gt; &#xA;    &lt;td&gt;1765.4 &lt;/td&gt; &#xA;    &lt;td&gt;74.1 &lt;/td&gt; &#xA;    &lt;td&gt;72.8 &lt;/td&gt; &#xA;    &lt;td&gt;38.3 &lt;/td&gt; &#xA;    &lt;td&gt;36.8&lt;/td&gt; &#xA;    &lt;td&gt;77.8 &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;TextMonkey&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;9.7B&lt;/td&gt; &#xA;    &lt;td&gt;64.3&lt;/td&gt; &#xA;    &lt;td&gt;66.7 &lt;/td&gt; &#xA;    &lt;td&gt;558&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;CogVLM-Chat&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;17.4B&lt;/td&gt; &#xA;    &lt;td&gt;70.4&lt;/td&gt; &#xA;    &lt;td&gt;33.3*&lt;/td&gt; &#xA;    &lt;td&gt;590 &lt;/td&gt; &#xA;    &lt;td&gt;52.5 &lt;/td&gt; &#xA;    &lt;td&gt;1736.6 &lt;/td&gt; &#xA;    &lt;td&gt;63.7 &lt;/td&gt; &#xA;    &lt;td&gt;53.8 &lt;/td&gt; &#xA;    &lt;td&gt;37.3 &lt;/td&gt; &#xA;    &lt;td&gt;34.7 &lt;/td&gt; &#xA;    &lt;td&gt;73.9 &lt;/td&gt; &#xA;    &lt;td&gt;73.6 / 87.4 &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td colspan=&#34;12&#34; align=&#34;left&#34;&gt;&lt;strong&gt;Open-source models 1B~3B &lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;DeepSeek-VL-1.3B&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;1.7B&lt;/td&gt; &#xA;    &lt;td&gt;58.4*&lt;/td&gt; &#xA;    &lt;td&gt;37.9*&lt;/td&gt; &#xA;    &lt;td&gt;413&lt;/td&gt; &#xA;    &lt;td&gt;46.0 &lt;/td&gt; &#xA;    &lt;td&gt;1531.6 &lt;/td&gt; &#xA;    &lt;td&gt;64.0 &lt;/td&gt; &#xA;    &lt;td&gt;61.2 &lt;/td&gt; &#xA;    &lt;td&gt;33.8 &lt;/td&gt; &#xA;    &lt;td&gt;29.4 &lt;/td&gt; &#xA;    &lt;td&gt;51.1 &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;MobileVLM V2&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;3.1B&lt;/td&gt; &#xA;    &lt;td&gt;57.5&lt;/td&gt; &#xA;    &lt;td&gt;19.4*&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;1440.5(P) &lt;/td&gt; &#xA;    &lt;td&gt;63.2 &lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Mini-Gemini&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;2.2B&lt;/td&gt; &#xA;    &lt;td&gt;56.2&lt;/td&gt; &#xA;    &lt;td&gt;34.2*&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;1653.0 &lt;/td&gt; &#xA;    &lt;td&gt;59.8 &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;31.7 &lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;MiniCPM-V&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;2.8B &lt;/td&gt; &#xA;    &lt;td&gt;60.6&lt;/td&gt; &#xA;    &lt;td&gt;38.2 &lt;/td&gt; &#xA;    &lt;td&gt;366&lt;/td&gt; &#xA;    &lt;td&gt;47.6&lt;/td&gt; &#xA;    &lt;td&gt;1650.2 &lt;/td&gt; &#xA;    &lt;td&gt;67.9 &lt;/td&gt; &#xA;    &lt;td&gt;65.3 &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;38.3&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;28.9&lt;/td&gt; &#xA;    &lt;td&gt;51.3 &lt;/td&gt; &#xA;    &lt;td&gt;78.4 / 88.5 &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;&lt;strong&gt;MiniCPM-V 2.0&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;2.8B &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;74.1&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;71.9&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;605&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;55.0&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;1808.6&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;69.6&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;68.1&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;38.2 &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;38.7&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;69.2&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;85.5 / 92.2 &lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; * 我们自己评测了正式开源的模型权重。 &#xA;&lt;p id=&#34;4&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;手机部署&lt;/h2&gt; &#xA;&lt;h4&gt;部署步骤&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;进行Int4量化后，MiniCPM只占2GB空间，具备在端侧手机进行模型部署的条件。&lt;/li&gt; &#xA; &lt;li&gt;对于不同的操作系统，我们进行了不同的适配。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;注意：当前开源框架对手机支持还在完善，并非所有芯片与操作系统版本均能成功运行MLC-LLM或LLMFarm。&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Android、HarmonyOS &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;使用开源框架MLC-LLM进行模型适配。&lt;/li&gt; &#xA;   &lt;li&gt;支持文本模型、多模态模型。&lt;/li&gt; &#xA;   &lt;li&gt;适用于MiniCPM-2B-SFT-INT4、MiniCPM-2B-DPO-INT4、MiniCPM-V。&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/OpenBMB/mlc-MiniCPM&#34;&gt;编译安装MiniCPM指南&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;iOS &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;使用开源框架LLMFarm进行模型适配。&lt;/li&gt; &#xA;   &lt;li&gt;支持文本模型。&lt;/li&gt; &#xA;   &lt;li&gt;适用于MiniCPM-2B-SFT-INT4、MiniCPM-2B-DPO-INT4。&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/OpenBMB/LLMFarm&#34;&gt;编译安装MiniCPM指南&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;部署性能&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;我们未针对手机推理模型进行深度优化和系统测试，仅验证MiniCPM使用手机芯片进行推理的可行性。&lt;strong&gt;我们也欢迎更多开发者进一步调优并更新下面的测试列表，不断提升端侧大模型在手机上的推理性能&lt;/strong&gt;。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;手机型号&lt;/th&gt; &#xA;   &lt;th&gt;操作系统&lt;/th&gt; &#xA;   &lt;th&gt;处理器&lt;/th&gt; &#xA;   &lt;th&gt;Memory（GB）&lt;/th&gt; &#xA;   &lt;th&gt;文本吞吐（token/s）&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OPPO Find N3&lt;/td&gt; &#xA;   &lt;td&gt;Android 13&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 8 Gen2&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;6.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Samsung S23 Ultra&lt;/td&gt; &#xA;   &lt;td&gt;Android 14&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 8 Gen2&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;6.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Meizu M182Q&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 888Plus&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi 12 Pro&lt;/td&gt; &#xA;   &lt;td&gt;Android 13&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 8 Gen1&lt;/td&gt; &#xA;   &lt;td&gt;8+3&lt;/td&gt; &#xA;   &lt;td&gt;3.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi Redmi K40&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 870&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus LE 2100&lt;/td&gt; &#xA;   &lt;td&gt;Android 13&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 870&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus HD1900&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 865&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus HD1900&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 855&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus HD1905&lt;/td&gt; &#xA;   &lt;td&gt;Android 10&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 855&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus HD1900&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 855&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi MI 8&lt;/td&gt; &#xA;   &lt;td&gt;Android 9&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 845&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;2.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Huawei Nova 11SE&lt;/td&gt; &#xA;   &lt;td&gt;HarmonyOS 4.0.0&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 778&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;1.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi MIX 2&lt;/td&gt; &#xA;   &lt;td&gt;Android 9&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 835&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;1.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 15 Pro&lt;/td&gt; &#xA;   &lt;td&gt;iOS 17.2.1&lt;/td&gt; &#xA;   &lt;td&gt;A17 pro&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;18.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 15&lt;/td&gt; &#xA;   &lt;td&gt;iOS 17.2.1&lt;/td&gt; &#xA;   &lt;td&gt;A16&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;15.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 12 Pro&lt;/td&gt; &#xA;   &lt;td&gt;iOS 16.5.1&lt;/td&gt; &#xA;   &lt;td&gt;A14&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;5.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 12&lt;/td&gt; &#xA;   &lt;td&gt;iOS 17.2.1&lt;/td&gt; &#xA;   &lt;td&gt;A14&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;5.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 11&lt;/td&gt; &#xA;   &lt;td&gt;iOS 16.6&lt;/td&gt; &#xA;   &lt;td&gt;A13&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;4.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi Redmi K50&lt;/td&gt; &#xA;   &lt;td&gt;HyperOS 1.0.2&lt;/td&gt; &#xA;   &lt;td&gt;MediaTek Dimensity 8100&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;我们也使用MLC-LLM验证了在手机上部署MiniCPM-V系列模型的可行性，能够正常输入输出，但也存在图片处理时间较长的问题，需要进一步优化，兼容性问题也需要进一步解决。下面的动图是使用小米14 Pro运行MiniCPM-V 2.0的屏幕录像，没有进行任何编辑。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/OpenBMB/MiniCPM-V/raw/main/assets/gif_cases/station.gif&#34; width=&#34;36%/&#34;&gt; &lt;img src=&#34;https://github.com/OpenBMB/MiniCPM-V/raw/main/assets/gif_cases/english_menu.gif&#34; width=&#34;36%/&#34;&gt; &lt;/p&gt;&#xA;&lt;table align=&#34;center&#34;&gt;  &#xA;&lt;/table&gt; &#xA;&lt;p id=&#34;5&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Demo &amp;amp; API 部署&lt;/h2&gt; &#xA;&lt;h4&gt;基于Gradio的网页版Demo&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;使用如下命令启动基于Gradio的网页版demo：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# generation powered by vllm&#xA;python demo/vllm_based_demo.py --model_path &amp;lt;vllmcpm_repo_path&amp;gt;&#xA;# generation powered by huggingface&#xA;python demo/hf_based_demo.py --model_path &amp;lt;hf_repo_path&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p id=&#34;6&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;二次开发&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;高效参数微调&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;一张1080/2080可实现高效参数微调&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/tree/main/finetune&#34;&gt;高效参数微调代码&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;全参数微调 or 持续训练&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;使用&lt;a href=&#34;https://github.com/OpenBMB/BMTrain&#34;&gt;BMTrain&lt;/a&gt;，借助重计算和ZeRO-3，一张3090/4090可实现全参数微调，一台机器可实现持续训练&lt;/li&gt; &#xA;   &lt;li&gt;相关代码也将陆续推出&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;mlx高效参数微调&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;环境准备 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -r finetune/requirements_mlx.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt;微调命令 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# train&#xA;python mlx_finetune.py --model MiniCPM-2B-sft-bf16-llama-format-mlx  --data data/AdvertiseGen  --train  --seed 2024 --iters 500&#xA;# test&#xA;python mlx_finetune.py --model MiniCPM-2B-sft-bf16-llama-format-mlx  --data data/AdvertiseGen  --test --seed 2024&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;9&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;典型示例&lt;/h2&gt; &#xA;&lt;h4&gt;文本生成&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/creation.case1.png&#34; alt=&#34;内容创作-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/creation.case2.png&#34; alt=&#34;内容创作-case2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/creation.case3.png&#34; alt=&#34;内容创作-case3&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;代码生成&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/code.case1.gif&#34; alt=&#34;代码生成-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/code.case2.gif&#34; alt=&#34;代码生成-case2&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;数理逻辑&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/math.case1.png&#34; alt=&#34;数理逻辑-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/math.case2.png&#34; alt=&#34;数理逻辑-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;文本翻译&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/translation.case1.png&#34; alt=&#34;文本翻译-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/translation.case2.png&#34; alt=&#34;文本翻译-case2&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;指令跟随&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/instruction_following.case1.png&#34; alt=&#34;指令跟随-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/instruction_following.case2.png&#34; alt=&#34;指令跟随-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;特殊字符&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/special_char.case1.png&#34; alt=&#34;特殊字符-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/special_char.case2.png&#34; alt=&#34;特殊字符-case2&#34;&gt;&lt;/p&gt; &#xA;&lt;p id=&#34;7&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;开源协议&lt;/h2&gt; &#xA;&lt;h4&gt;模型协议&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;本仓库中代码依照 &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/LICENSE&#34;&gt;Apache-2.0&lt;/a&gt; 协议开源&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM 模型权重的使用则需要遵循 &lt;a href=&#34;https://github.com/OpenBMB/General-Model-License/raw/main/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE-%E6%9D%A5%E6%BA%90%E8%AF%B4%E6%98%8E-%E5%AE%A3%E4%BC%A0%E9%99%90%E5%88%B6-%E5%95%86%E4%B8%9A%E6%8E%88%E6%9D%83.md&#34;&gt;“通用模型许可协议-来源说明-宣传限制-商业授权”&lt;/a&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM 模型权重对学术研究完全开放。&lt;/li&gt; &#xA; &lt;li&gt;如需将模型用于商业用途，请联系&lt;a href=&#34;mailto:cpm@modelbest.cn&#34;&gt;cpm@modelbest.cn&lt;/a&gt;来获取书面授权，在登记后亦允许免费商业使用。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;声明&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;作为一个语言模型，MiniCPM 通过学习大量的文本来生成内容，但它无法理解、表达个人观点或价值判断，它所输出的任何内容都不代表模型开发者的观点和立场。&lt;/li&gt; &#xA; &lt;li&gt;因此用户在使用 MiniCPM 生成的内容时，应自行负责对其进行评估和验证。&lt;/li&gt; &#xA; &lt;li&gt;如果由于使用 MiniCPM 开源模型而导致的任何问题，包括但不限于数据安全问题、公共舆论风险，或模型被误导、滥用、传播或不当利用所带来的任何风险和问题，我们将不承担任何责任。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;8&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;工作引用&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;如果觉得MiniCPM有助于您的工作，请引用我们的&lt;a href=&#34;https://arxiv.org/abs/2404.06395&#34;&gt;论文&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{hu2024minicpm,&#xA;  title={MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies},&#xA;  author={Hu, Shengding and Tu, Yuge and Han, Xu and He, Chaoqun and Cui, Ganqu and Long, Xiang and Zheng, Zhi and Fang, Yewei and Huang, Yuxiang and Zhao, Weilin and others},&#xA;  journal={arXiv preprint arXiv:2404.06395},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>arktrail/Dorothy-Ymir</title>
    <updated>2024-04-21T03:30:15Z</updated>
    <id>tag:github.com,2024-04-21:/arktrail/Dorothy-Ymir</id>
    <link href="https://github.com/arktrail/Dorothy-Ymir" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI solution for Patent Classification&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dorothy AI Patent Classifier&lt;/h1&gt; &#xA;&lt;p&gt;This github repository includes code for Dorothy AI Patent Classifier&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#data&#34;&gt;Data generation and preprocesss&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#data_loc&#34;&gt;Data location and summary&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#ml&#34;&gt;Machine learning model&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#fasttext&#34;&gt;FastText&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#tencent&#34;&gt;Tencent&#39;s NeuralClassifier&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#hftcnn&#34;&gt;HFT-CNN&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#eval&#34;&gt;Evaluation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#visual&#34;&gt;Visualization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#webapp&#34;&gt;Web app&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#other&#34;&gt;Other&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Data generation and preprocess &lt;a id=&#34;data&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Step 1: We generate our dataset from all granted patents up to September 2019, the total number of patents in the dataset is 4,363,544. To regenerate this dataset, such command could be used&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ sbatch /pylon5/sez3a3p/yyn1228/json_process_jobs/json_process_sin_*.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or mannuly sbatch from&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/json_process_jobs/json_process_sin_a.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/json_process_jobs/json_process_sin_h.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The extracted dataset is stored in the &lt;code&gt;/pylon5/sez3a3p/yyn1228/data/json_reparse&lt;/code&gt;, this path is defined in the file &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/data_preprocess/database_reparse.py&#34;&gt;database_reparse.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Step 2: We parse the cpc field into labels we need (section, classs, subclass, etc.), convert the text into a list of tokens, and split the data into train, valid, and test datasets by the ratio of 8:1:1. This step also removes all punctuations and convert all uppercase letters into lower case. This can be done by running the file &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/data_preprocess/text_preprocess.py&#34;&gt;data_preprocess/text_preprocess.py&lt;/a&gt;, for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ python3 -u data_preprocess/text_preprocess.py \&#xA;/pylon5/sez3a3p/yyn1228/data/json_reparse \&#xA;/pylon5/sez3a3p/yyn1228/data/all_data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Step 3: We further preprocess the data into a format that can be used by the machine learning libraries. This can be done by running the file &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/data_preprocess/create_training_data.py&#34;&gt;data_preprocess/create_training_data.py&lt;/a&gt;. Note that the file takes 6 arguments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;input directory&lt;/li&gt; &#xA; &lt;li&gt;output directory&lt;/li&gt; &#xA; &lt;li&gt;text field: &#39;title&#39;, &#39;abstraction&#39;, &#39;claims&#39;, &#39;brief_summary&#39; (&#39;description&#39; is too large to include)&lt;/li&gt; &#xA; &lt;li&gt;level name: &#39;section&#39;, &#39;class&#39;, &#39;subclass&#39;, &#39;main_group&#39;, &#39;subgroup&#39;&lt;/li&gt; &#xA; &lt;li&gt;whether to remove stop words: True means remove stop words&lt;/li&gt; &#xA; &lt;li&gt;whether to follow fasttext format: True means FastText format, False means Tecent format&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ python3 -u data_preprocess/create_training_data.py \&#xA;/pylon5/sez3a3p/yyn1228/data/all_data \&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_group \&#xA;brief_summary main_group false true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Data location and summary &lt;a id=&#34;data_loc&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Processed data after Step 1, which includes 91 files and most of which have 50,000 patents.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/json_reparse&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Processed data after Step 2, which includes three files: train.json, valid.json, and test.json.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/all_data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Smaller datasets for valid and test: created by shuffling valid.json and test.json above and taking the first 60,000 records. These data have the following fields:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;all_labels: all true labels at the lowest subgroup level&lt;/li&gt; &#xA; &lt;li&gt;title, abstraction, claims, brief_summary, description: text split into list of tokens for various cpc text fields&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/all_data_small&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Processed data after Step 3 for brief summary and subclass level, in Tecent&#39;s format. Note that these data do not have stop words.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/all_summary_nonstop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Processed data after Step 3 for brief summary and all levels, in FastText&#39;s format. Note that these data include stop words.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_section&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_class&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext (this is subclass)&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_group&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_subgroup&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Smaller datasets initially used for testing purposes. Note that these data were generated by legacy code and may not be easily reproduced.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/summary_only&#xA;/pylon5/sez3a3p/yyn1228/data/summary_only_fasttext&#xA;/pylon5/sez3a3p/yyn1228/data/summary_only_nonstop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Machine learning model &lt;a id=&#34;ml&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;This section introduces how we use various libraries to train machine learning models. All the models are trained using the brief summary text field.&lt;/p&gt; &#xA;&lt;h3&gt;FastText &lt;a id=&#34;fasttext&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/facebookresearch/fastText/tree/master/python&#34;&gt;Facebook&#39;s FastText library&lt;/a&gt; to train the well-known FastText model. This method first converts words into word embeddings and then average word embeddings to create the document embedding. Note that this does not consider the order of the words. To keep some information regarding the order, it includes 2-grams into the vocabulary. Because this model is relatively simple and Facebook uses a lot of tricks to speed up the training, the training can be done by using CPUs instead of GPUs in a couple of hours. To account for the hierarchical information, we borrow the idea from HFT-CNN: we first train the section level and pass the word embeddings into the next word as pretrained word embeddings.&lt;/p&gt; &#xA;&lt;p&gt;To train FastText on PSC, first run the training job to train the data on the section level&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ sbatch model/FastText/summary_all_section/train_fasttext.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then save the word embeddings by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ sbatch model/FastText/summary_all_section/bin_to_vec.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then do the same thing for the class, subclass, group, and subgroup levels. To change the hyperparameters, just edit the train.py file in the corresponding folder.&lt;/p&gt; &#xA;&lt;h3&gt;Tencent&#39;s NeuralClassifier &lt;a id=&#34;tencent&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/Tencent/NeuralNLP-NeuralClassifier&#34;&gt;Tencent&#39;s NeuralClassifier library&lt;/a&gt; to train the classic CNN/RNN/RCNN text classification models. This model accounts for the hierarchical structure by adding a loss that is calculated based on the label tree, which forces closer leaves in the tree to have closer losses. Note that the library supports many models but we also tried the classic CNN/RNN/RCNN models. We edit some code to allow for using existing vocabulary.&lt;/p&gt; &#xA;&lt;p&gt;A detailed README on how to train the model using NeuralClassifier is saved here: &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/model/NeuralClassifier/README.md&#34;&gt;README.md&lt;/a&gt;. All models are saved in the &#34;/pylon5/sez3a3p/yyn1228/Dorothy-Ymir/model/NeuralClassifier/output/xxx/checkpoint_dir_cpc&#34; folders on PSC.&lt;/p&gt; &#xA;&lt;p&gt;Because there are many hyperparameters to tune, we include a summary of all the models we trained with their corresponding hyperparameters: &lt;img src=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/tencent.png&#34; alt=&#34;tencent models&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;HFT-CNN &lt;a id=&#34;hftcnn&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;We also use &lt;a href=&#34;https://github.com/ShimShim46/HFT-CNN&#34;&gt;the HFT-CNN library&lt;/a&gt; to train another model. The idea is to train a CNN model on each level, which pass word embeddings and parameters in early layers to the CNN model on the next level. We add some code to support multi-GPU training. Follow the &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/model/HFT-CNN/README.md&#34;&gt;README.md&lt;/a&gt; here to train the model. Subclass level model is saved in the &#34;/pylon5/sez3a3p/yyn1228/Dorothy-Ymir/model/HFT-CNN/CNN/CNN/PARAMS/&#34; folders on PSC.&lt;/p&gt; &#xA;&lt;h2&gt;Evaluation &lt;a id=&#34;eval&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The detailed evaluation is saved in &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/prob_evaluate.ipynb&#34;&gt;notebooks/prob_evaluate.ipynb&lt;/a&gt;. It also includes methods to ensemble different models. See below a summary of the model results below. The best recall at n ≈ 5 is 91.6%. &lt;img src=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/eval.png&#34; alt=&#34;evaluation&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;To see how the model works on other text fields, we also evaluate the model using title, abstract, and claims, although the model is trained using brief summary. Note that we have not used description to evaluate the model because it would explode the storage, but it is worth trying to evaluate the model using the first 1,000 tokens of the description. Also note that these evaluations only use the FastText model.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Text Field&lt;/th&gt; &#xA;   &lt;th&gt;Precision @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Precision @ 5&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 5&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Title&lt;/td&gt; &#xA;   &lt;td&gt;0.107&lt;/td&gt; &#xA;   &lt;td&gt;0.568&lt;/td&gt; &#xA;   &lt;td&gt;0.098&lt;/td&gt; &#xA;   &lt;td&gt;0.603&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Abstract&lt;/td&gt; &#xA;   &lt;td&gt;0.675&lt;/td&gt; &#xA;   &lt;td&gt;0.401&lt;/td&gt; &#xA;   &lt;td&gt;0.190&lt;/td&gt; &#xA;   &lt;td&gt;0.709&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Claims&lt;/td&gt; &#xA;   &lt;td&gt;0.699&lt;/td&gt; &#xA;   &lt;td&gt;0.379&lt;/td&gt; &#xA;   &lt;td&gt;0.247&lt;/td&gt; &#xA;   &lt;td&gt;0.710&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Title + Abstract + Claims&lt;/td&gt; &#xA;   &lt;td&gt;0.749&lt;/td&gt; &#xA;   &lt;td&gt;0.403&lt;/td&gt; &#xA;   &lt;td&gt;0.251&lt;/td&gt; &#xA;   &lt;td&gt;0.755&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Brief Summary&lt;/td&gt; &#xA;   &lt;td&gt;0.851&lt;/td&gt; &#xA;   &lt;td&gt;0.453&lt;/td&gt; &#xA;   &lt;td&gt;0.216&lt;/td&gt; &#xA;   &lt;td&gt;0.856&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;We also train FastText models at all the 5 levels. Note that it is only plausible to use the FastText model to train for group and subgroup because there are too many labels. At the subclass level, there are 666 labels and it takes hours to train a non-FastText model; at the subgroup level, there are 200,000 labels, which means if we still use the same model, it would take weeks to finish the training. For group and subgroup, we use the &#34;hierarchical softmax loss&#34; in the FastText model, which is a trick developed by Facebook and significantly shortens training time but lowers the performance a little bit.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Level&lt;/th&gt; &#xA;   &lt;th&gt;Precision @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Precision @ 5&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 5&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Section&lt;/td&gt; &#xA;   &lt;td&gt;0.921&lt;/td&gt; &#xA;   &lt;td&gt;0.623&lt;/td&gt; &#xA;   &lt;td&gt;0.271&lt;/td&gt; &#xA;   &lt;td&gt;0.992&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Class&lt;/td&gt; &#xA;   &lt;td&gt;0.886&lt;/td&gt; &#xA;   &lt;td&gt;0.535&lt;/td&gt; &#xA;   &lt;td&gt;0.257&lt;/td&gt; &#xA;   &lt;td&gt;0.929&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Subclass&lt;/td&gt; &#xA;   &lt;td&gt;0.851&lt;/td&gt; &#xA;   &lt;td&gt;0.453&lt;/td&gt; &#xA;   &lt;td&gt;0.216&lt;/td&gt; &#xA;   &lt;td&gt;0.856&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;For the group:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Level&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 10&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 100&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Group&lt;/td&gt; &#xA;   &lt;td&gt;0.220&lt;/td&gt; &#xA;   &lt;td&gt;0.661&lt;/td&gt; &#xA;   &lt;td&gt;0.912&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;For subgroup:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Level&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 10&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 100&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1000&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Subgroup&lt;/td&gt; &#xA;   &lt;td&gt;0.054&lt;/td&gt; &#xA;   &lt;td&gt;0.208&lt;/td&gt; &#xA;   &lt;td&gt;0.468&lt;/td&gt; &#xA;   &lt;td&gt;0.750&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Visualization &lt;a id=&#34;visual&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;This notebook at &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/visualization.ipynb&#34;&gt;notebooks/visualization.ipynb&lt;/a&gt; includes visualizations of patent embeddings and word embeddings. The patent embedding figure is the one used in the presentation. The word embedding figure does not show very clear clusters, because the word lists and categories we choose are too general. The notebook includes all the code to generate the word embeddings and the word lists can be changed easily. If more representative word lists and categories are found, change the word lists and rerun the word embedding part in the notebook to get the word embedding visualization.&lt;/p&gt; &#xA;&lt;h2&gt;Web app &lt;a id=&#34;webapp&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Inorder to obtain an intuitive feeling of the result, we built an web app that could predict the corresponding CPC code given by any text in real time, and generate an tree plot. One thing to note is that the WebApp is under the &lt;code&gt;visualization&lt;/code&gt; branch, and the model impl is under &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; &#xA;&lt;p&gt;The backend for our Web app is Django, the frontend is built by React and the project is deployed on the AWS. The user could easily type in any text the describe one tech utility, and the predicted cpc codes will be render in the form of tree in secondes.&lt;/p&gt; &#xA;&lt;p&gt;For the backend, we load the model and make the prediction in &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/visualization/visualization/visualization-demo/backend/demo/models.py&#34;&gt;&lt;code&gt;models.py &lt;/code&gt;&lt;/a&gt; at the very first time of the prediction, so for the following predictions, we can get rid of loading the giant model file too much times. But the prediction also need to be structed and parsed into the format that could be used for frontend, and this part of work is done by &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/visualization/visualization/visualization-demo/backend/demo/treebuilder.py&#34;&gt;&lt;code&gt;treebuilders.py&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/visualization/visualization/visualization-demo/backend/demo/views.py&#34;&gt;&lt;code&gt;views.py&lt;/code&gt;&lt;/a&gt;. Also, in the backend, we need to rank the predcitions according to their confidence scores made by our model for the frontend render work, so the total data we return back to front is :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;res = {&#39;tree&#39;: tree, &#39;ordered_labels&#39;: ordered_labels}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;tree&lt;/code&gt; is the parsed predictions in tree structure format, and &lt;code&gt;ordered_labels&lt;/code&gt; is the prediction labels ranked by their confidence scores.&lt;/p&gt; &#xA;&lt;p&gt;In the front end, we use these two data to render a tree chart, and we also provide an adjust bar that could change the tree leafnode numbers for analyse.&lt;/p&gt; &#xA;&lt;p&gt;The implementation is well documented, so it is easy for further integration.&lt;/p&gt; &#xA;&lt;h2&gt;Other &lt;a id=&#34;other&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/CPC_Preliminary_Data_Analysis.ipynb&#34;&gt;notebooks/CPC_Preliminary_Data_Analysis.ipynb&lt;/a&gt;: this notebook includes some preliminary data analysis of the CPC MCF data (e.g. average number of labels, duplicate issues, number of labels at each level, etc.)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/CPC_Text_Data.ipynb&#34;&gt;notebooks/CPC_Text_Data.ipynb&lt;/a&gt;: this notebook has some preliminary data analysis of the CPC text data (e.g. average number of tokens of each text field)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/evaluate.ipynb&#34;&gt;notebooks/evaluate.ipynb&lt;/a&gt;: this notebook has some old evaluation methods (e.g. macro and micro F1, precision and recall at different percentiles, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>