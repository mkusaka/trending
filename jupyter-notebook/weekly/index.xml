<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-02T02:14:48Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>damienbenveniste/Intro-to-Data-Science</title>
    <updated>2022-06-02T02:14:48Z</updated>
    <id>tag:github.com,2022-06-02:/damienbenveniste/Intro-to-Data-Science</id>
    <link href="https://github.com/damienbenveniste/Intro-to-Data-Science" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>kwea123/nerf_pl</title>
    <updated>2022-06-02T02:14:48Z</updated>
    <id>tag:github.com,2022-06-02:/kwea123/nerf_pl</id>
    <link href="https://github.com/kwea123/nerf_pl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;NeRF (Neural Radiance Fields) and NeRF in the Wild using pytorch-lightning&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;nerf_pl&lt;/h1&gt; &#xA;&lt;h3&gt;Update: NVIDIA just open-sourced a lightning-fast version of NeRF: &lt;a href=&#34;https://github.com/NVlabs/instant-ngp&#34;&gt;NGP&lt;/a&gt;. If you just want to see how strong NeRF is, try out this one! Sadly, it allows very little customization due to many dependencies, unless you are super familiar with those libraries and cuda programming (I&#39;m not &lt;span&gt;ðŸ˜µðŸ’«&lt;/span&gt;).&lt;/h3&gt; &#xA;&lt;h3&gt;Update: an improved &lt;a href=&#34;https://www.cs.cornell.edu/~zl548/NSFF/&#34;&gt;NSFF&lt;/a&gt; implementation to handle dynamic scene is &lt;a href=&#34;https://github.com/kwea123/nsff_pl&#34;&gt;open&lt;/a&gt;!&lt;/h3&gt; &#xA;&lt;h3&gt;Update: &lt;a href=&#34;https://nerf-w.github.io/&#34;&gt;NeRF-W&lt;/a&gt; (NeRF in the Wild) implementation is added to &lt;a href=&#34;https://github.com/kwea123/nerf_pl/tree/nerfw&#34;&gt;nerfw&lt;/a&gt; branch!&lt;/h3&gt; &#xA;&lt;h3&gt;Update: The lastest code (using the latest libraries) will be updated to &lt;a href=&#34;https://github.com/kwea123/nerf_pl/tree/dev&#34;&gt;dev&lt;/a&gt; branch. The master branch remains to support the colab files. If you don&#39;t use colab, it is recommended to switch to dev branch.&lt;/h3&gt; &#xA;&lt;h3&gt;Only issues of the dev and nerfw branch will be considered currently.&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;span&gt;ðŸ’Ž&lt;/span&gt; &lt;a href=&#34;https://kwea123.github.io/nerf_pl/&#34;&gt;&lt;strong&gt;Project page&lt;/strong&gt;&lt;/a&gt; (live demo!)&lt;/h3&gt; &#xA;&lt;p&gt;Unofficial implementation of &lt;a href=&#34;https://arxiv.org/pdf/2003.08934.pdf&#34;&gt;NeRF&lt;/a&gt; (Neural Radiance Fields) using pytorch (&lt;a href=&#34;https://github.com/PyTorchLightning/pytorch-lightning&#34;&gt;pytorch-lightning&lt;/a&gt;). This repo doesn&#39;t aim at reproducibility, but aim at providing a simpler and faster training procedure (also simpler code with detailed comments to help to understand the work). Moreover, I try to extend much more opportunities by integrating this algorithm into game engine like Unity.&lt;/p&gt; &#xA;&lt;p&gt;Official implementation: &lt;a href=&#34;https://github.com/bmild/nerf&#34;&gt;nerf&lt;/a&gt; .. Reference pytorch implementation: &lt;a href=&#34;https://github.com/yenchenlin/nerf-pytorch&#34;&gt;nerf-pytorch&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Recommend to read: A detailed NeRF extension list: &lt;a href=&#34;https://github.com/yenchenlin/awesome-NeRF&#34;&gt;awesome-NeRF&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;&lt;span&gt;ðŸŒŒ&lt;/span&gt; Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Multi-gpu training: Training on 8 GPUs finishes within 1 hour for the synthetic dataset!&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/#mortar_board-colab&#34;&gt;Colab&lt;/a&gt; notebooks to allow easy usage!&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/#ribbon-mesh&#34;&gt;Reconstruct&lt;/a&gt; &lt;strong&gt;colored&lt;/strong&gt; mesh!&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/S5phWFTs2iM&#34;&gt;Mixed Reality&lt;/a&gt; in Unity!&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/w9qTbVzCdWk&#34;&gt;REAL TIME volume rendering&lt;/a&gt; in Unity!&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/#portable-scenes&#34;&gt;Portable Scenes&lt;/a&gt; to let you play with other people&#39;s scenes!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;You can find the Unity project including mesh, mixed reality and volume rendering &lt;a href=&#34;https://github.com/kwea123/nerf_Unity&#34;&gt;here&lt;/a&gt;! See &lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/README_Unity.md&#34;&gt;README_Unity&lt;/a&gt; for generating your own data for Unity rendering!&lt;/h3&gt; &#xA;&lt;h2&gt;&lt;span&gt;ðŸ”°&lt;/span&gt; Tutorial&lt;/h2&gt; &#xA;&lt;h3&gt;What can NeRF do?&lt;/h3&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/11364490/82124460-1ccbbb80-97da-11ea-88ad-25e22868a5c1.png&#34; style=&#34;max-width:100%&#34;&gt; &#xA;&lt;h3&gt;Tutorial videos&lt;/h3&gt; &#xA;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLDV2CyUo4q-K02pNEyDr7DYpTQuka3mbV&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/11364490/80913471-d5781080-8d7f-11ea-9f72-9d68402b8271.png&#34;&gt; &lt;/a&gt; &#xA;&lt;h1&gt;&lt;span&gt;ðŸ’»&lt;/span&gt; Installation&lt;/h1&gt; &#xA;&lt;h2&gt;Hardware&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;OS: Ubuntu 18.04&lt;/li&gt; &#xA; &lt;li&gt;NVIDIA GPU with &lt;strong&gt;CUDA&amp;gt;=10.1&lt;/strong&gt; (tested with 1 RTX2080Ti)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Software&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Clone this repo by &lt;code&gt;git clone --recursive https://github.com/kwea123/nerf_pl&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Python&amp;gt;=3.6 (installation via &lt;a href=&#34;https://www.anaconda.com/distribution/&#34;&gt;anaconda&lt;/a&gt; is recommended, use &lt;code&gt;conda create -n nerf_pl python=3.6&lt;/code&gt; to create a conda environment and activate it by &lt;code&gt;conda activate nerf_pl&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Python libraries &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Install core requirements by &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Install &lt;code&gt;torchsearchsorted&lt;/code&gt; by &lt;code&gt;cd torchsearchsorted&lt;/code&gt; then &lt;code&gt;pip install .&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;&lt;span&gt;ðŸ”‘&lt;/span&gt; Training&lt;/h1&gt; &#xA;&lt;p&gt;Please see each subsection for training on different datasets. Available training datasets:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/#blender&#34;&gt;Blender&lt;/a&gt; (Realistic Synthetic 360)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/#llff&#34;&gt;LLFF&lt;/a&gt; (Real Forward-Facing)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/#your-own-data&#34;&gt;Your own data&lt;/a&gt; (Forward-Facing/360 inward-facing)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Blender&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Steps&lt;/summary&gt; &#xA; &lt;h3&gt;Data download&lt;/h3&gt; &#xA; &lt;p&gt;Download &lt;code&gt;nerf_synthetic.zip&lt;/code&gt; from &lt;a href=&#34;https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Training model&lt;/h3&gt; &#xA; &lt;p&gt;Run (example)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;python train.py \&#xA;   --dataset_name blender \&#xA;   --root_dir $BLENDER_DIR \&#xA;   --N_importance 64 --img_wh 400 400 --noise_std 0 \&#xA;   --num_epochs 16 --batch_size 1024 \&#xA;   --optimizer adam --lr 5e-4 \&#xA;   --lr_scheduler steplr --decay_step 2 4 8 --decay_gamma 0.5 \&#xA;   --exp_name exp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;These parameters are chosen to best mimic the training settings in the original repo. See &lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/opt.py&#34;&gt;opt.py&lt;/a&gt; for all configurations.&lt;/p&gt; &#xA; &lt;p&gt;NOTE: the above configuration doesn&#39;t work for some scenes like &lt;code&gt;drums&lt;/code&gt;, &lt;code&gt;ship&lt;/code&gt;. In that case, consider increasing the &lt;code&gt;batch_size&lt;/code&gt; or change the &lt;code&gt;optimizer&lt;/code&gt; to &lt;code&gt;radam&lt;/code&gt;. I managed to train on all scenes with these modifications.&lt;/p&gt; &#xA; &lt;p&gt;You can monitor the training process by &lt;code&gt;tensorboard --logdir logs/&lt;/code&gt; and go to &lt;code&gt;localhost:6006&lt;/code&gt; in your browser.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;LLFF&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Steps&lt;/summary&gt; &#xA; &lt;h3&gt;Data download&lt;/h3&gt; &#xA; &lt;p&gt;Download &lt;code&gt;nerf_llff_data.zip&lt;/code&gt; from &lt;a href=&#34;https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Training model&lt;/h3&gt; &#xA; &lt;p&gt;Run (example)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;python train.py \&#xA;   --dataset_name llff \&#xA;   --root_dir $LLFF_DIR \&#xA;   --N_importance 64 --img_wh 504 378 \&#xA;   --num_epochs 30 --batch_size 1024 \&#xA;   --optimizer adam --lr 5e-4 \&#xA;   --lr_scheduler steplr --decay_step 10 20 --decay_gamma 0.5 \&#xA;   --exp_name exp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;These parameters are chosen to best mimic the training settings in the original repo. See &lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/opt.py&#34;&gt;opt.py&lt;/a&gt; for all configurations.&lt;/p&gt; &#xA; &lt;p&gt;You can monitor the training process by &lt;code&gt;tensorboard --logdir logs/&lt;/code&gt; and go to &lt;code&gt;localhost:6006&lt;/code&gt; in your browser.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Your own data&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Steps&lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Install &lt;a href=&#34;https://github.com/colmap/colmap&#34;&gt;COLMAP&lt;/a&gt; following &lt;a href=&#34;https://colmap.github.io/install.html&#34;&gt;installation guide&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Prepare your images in a folder (around 20 to 30 for forward facing, and 40 to 50 for 360 inward-facing)&lt;/li&gt; &#xA;  &lt;li&gt;Clone &lt;a href=&#34;https://github.com/Fyusion/LLFF&#34;&gt;LLFF&lt;/a&gt; and run &lt;code&gt;python img2poses.py $your-images-folder&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Train the model using the same command as in &lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/#llff&#34;&gt;LLFF&lt;/a&gt;. If the scene is captured in a 360 inward-facing manner, add &lt;code&gt;--spheric&lt;/code&gt; argument.&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;p&gt;For more details of training a good model, please see the video &lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/#colab&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Pretrained models and logs&lt;/h2&gt; &#xA;&lt;p&gt;Download the pretrained models and training logs in &lt;a href=&#34;https://github.com/kwea123/nerf_pl/releases&#34;&gt;release&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Comparison with other repos&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;training GPU memory in GB&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Speed (1 step)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bmild/nerf&#34;&gt;Original&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.177s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/yenchenlin/nerf-pytorch&#34;&gt;Ref pytorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.147s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;This repo&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.12s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The speed is measured on 1 RTX2080Ti. Detailed profile can be found in &lt;a href=&#34;https://github.com/kwea123/nerf_pl/releases&#34;&gt;release&lt;/a&gt;. Training memory is largely reduced, since the original repo loads the whole data to GPU at the beginning, while we only pass batches to GPU every step.&lt;/p&gt; &#xA;&lt;h1&gt;&lt;span&gt;ðŸ”Ž&lt;/span&gt; Testing&lt;/h1&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/test.ipynb&#34;&gt;test.ipynb&lt;/a&gt; for a simple view synthesis and depth prediction on 1 image.&lt;/p&gt; &#xA;&lt;p&gt;Use &lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/eval.py&#34;&gt;eval.py&lt;/a&gt; to create the whole sequence of moving views. E.g.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python eval.py \&#xA;   --root_dir $BLENDER \&#xA;   --dataset_name blender --scene_name lego \&#xA;   --img_wh 400 400 --N_importance 64 --ckpt_path $CKPT_PATH&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;IMPORTANT&lt;/strong&gt; : Don&#39;t forget to add &lt;code&gt;--spheric_poses&lt;/code&gt; if the model is trained under &lt;code&gt;--spheric&lt;/code&gt; setting!&lt;/p&gt; &#xA;&lt;p&gt;It will create folder &lt;code&gt;results/{dataset_name}/{scene_name}&lt;/code&gt; and run inference on all test data, finally create a gif out of them.&lt;/p&gt; &#xA;&lt;p&gt;Example of lego scene using pretrained model and the reconstructed &lt;strong&gt;colored&lt;/strong&gt; mesh: (PSNR=31.39, paper=32.54)&lt;/p&gt; &#xA;&lt;p&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/11364490/79932648-f8a1e680-8488-11ea-98fe-c11ec22fc8a1.gif&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/11364490/80813179-822d8300-8c04-11ea-84e6-142f04714c58.png&#34; width=&#34;200&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Example of fern scene using pretrained model:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/11364490/79932650-f9d31380-8488-11ea-8dad-b70a6a3daa6e.gif&#34; alt=&#34;fern&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Example of own scene (&lt;a href=&#34;https://www.youtube.com/watch?v=hVQIvEq_Av0&#34;&gt;Silica GGO figure&lt;/a&gt;) and the reconstructed &lt;strong&gt;colored&lt;/strong&gt; mesh. Click to link to youtube video.&lt;/p&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://youtu.be/yH1ZBcdNsUY&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/11364490/80279695-324d4880-873a-11ea-961a-d6350e149ece.gif&#34; height=&#34;252&#34;&gt; &lt;/a&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/11364490/80813184-83f74680-8c04-11ea-8606-40580f753355.png&#34; height=&#34;252&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Portable scenes&lt;/h2&gt; &#xA;&lt;p&gt;The concept of NeRF is that the whole scene is compressed into a NeRF model, then we can render from any pose we want. To render from plausible poses, we can leverage the training poses; therefore, you can generate video with &lt;strong&gt;only&lt;/strong&gt; the trained model and the poses (hence the name of portable scenes). I provided my silica model in &lt;a href=&#34;https://github.com/kwea123/nerf_pl/releases&#34;&gt;release&lt;/a&gt;, feel free to play around with it!&lt;/p&gt; &#xA;&lt;p&gt;If you trained some interesting scenes, you are also welcomed to share the model (and the &lt;code&gt;poses_bounds.npy&lt;/code&gt;) by sending me an email, or post in issues! After all, a model is just around &lt;strong&gt;5MB&lt;/strong&gt;! Please run &lt;code&gt;python utils/save_weights_only.py --ckpt_path $YOUR_MODEL_PATH&lt;/code&gt; to extract the final model.&lt;/p&gt; &#xA;&lt;h1&gt;&lt;span&gt;ðŸŽ€&lt;/span&gt; Mesh&lt;/h1&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/kwea123/nerf_pl/master/README_mesh.md&#34;&gt;README_mesh&lt;/a&gt; for reconstruction of &lt;strong&gt;colored&lt;/strong&gt; mesh. Only supported for blender dataset and 360 inward-facing data!&lt;/p&gt; &#xA;&lt;h1&gt;&lt;span&gt;âš &lt;/span&gt; Notes on differences with the original repo&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The learning rate decay in the original repo is &lt;strong&gt;by step&lt;/strong&gt;, which means it decreases every step, here I use learning rate decay &lt;strong&gt;by epoch&lt;/strong&gt;, which means it changes only at the end of 1 epoch.&lt;/li&gt; &#xA; &lt;li&gt;The validation image for LLFF dataset is chosen as the most centered image here, whereas the original repo chooses every 8th image.&lt;/li&gt; &#xA; &lt;li&gt;The rendering spiral path is slightly different from the original repo (I use approximate values to simplify the code).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;&lt;span&gt;ðŸŽ“&lt;/span&gt; COLAB&lt;/h1&gt; &#xA;&lt;p&gt;I also prepared colab notebooks that allow you to run the algorithm on any machine without GPU requirement.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gist.github.com/kwea123/f0e8f38ff2aa94495dbfe7ae9219f75c&#34;&gt;colmap&lt;/a&gt; to prepare camera poses for your own training data&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gist.github.com/kwea123/a3c541a325e895ef79ecbc0d2e6d7221&#34;&gt;nerf&lt;/a&gt; to train on your data&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gist.github.com/kwea123/77ed1640f9bc9550136dc13a6a419e88&#34;&gt;extract_mesh&lt;/a&gt; to extract colored mesh&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://www.youtube.com/playlist?list=PLDV2CyUo4q-K02pNEyDr7DYpTQuka3mbV&#34;&gt;this playlist&lt;/a&gt; for the detailed tutorials.&lt;/p&gt; &#xA;&lt;h1&gt;&lt;span&gt;ðŸŽƒ&lt;/span&gt; SHOWOFF&lt;/h1&gt; &#xA;&lt;p&gt;We can incorporate &lt;em&gt;ray tracing&lt;/em&gt; techniques into the volume rendering pipeline, and realize realistic scene editing (following is the &lt;code&gt;materials&lt;/code&gt; scene with an object removed, and a mesh is inserted and rendered with ray tracing). The code &lt;strong&gt;will not&lt;/strong&gt; be released.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/11364490/90312710-92face00-df41-11ea-9eea-10f24849b407.gif&#34; alt=&#34;add&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/11364490/90360796-92744b80-e097-11ea-859d-159aa2519375.gif&#34; alt=&#34;add2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;With my integration in Unity, I can realize realistic mixed reality photos (note my character casts shadow on the scene, &lt;strong&gt;zero&lt;/strong&gt; post- image editing required): &lt;img src=&#34;https://user-images.githubusercontent.com/11364490/140264589-295acebe-8ace-4d61-b871-26eb8ae10ab0.png&#34; alt=&#34;defer&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/11364490/140264596-59daebe5-b88d-48e7-82bd-5ccaaff2283f.png&#34; alt=&#34;defer2&#34;&gt; BTW, I would like to visit the museum one day...&lt;/p&gt; &#xA;&lt;h1&gt;&lt;span&gt;ðŸ“–&lt;/span&gt; Citation&lt;/h1&gt; &#xA;&lt;p&gt;If you use (part of) my code or find my work helpful, please consider citing&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{queianchen_nerf,&#xA;  author={Quei-An, Chen},&#xA;  title={Nerf_pl: a pytorch-lightning implementation of NeRF},&#xA;  url={https://github.com/kwea123/nerf_pl/},&#xA;  year={2020},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>huseinzol05/Stock-Prediction-Models</title>
    <updated>2022-06-02T02:14:48Z</updated>
    <id>tag:github.com,2022-06-02:/huseinzol05/Stock-Prediction-Models</id>
    <link href="https://github.com/huseinzol05/Stock-Prediction-Models" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Gathers machine learning and deep learning models for Stock forecasting including trading bots and simulations&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#readme&#34;&gt; &lt;img alt=&#34;logo&#34; width=&#34;50%&#34; src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/evolution-strategy.png&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/huseinzol05/Stock-Prediction-Models/raw/master/LICENSE&#34;&gt;&lt;img alt=&#34;MIT License&#34; src=&#34;https://img.shields.io/badge/License-Apache--License--2.0-yellow.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/deeplearning-30--models-success.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/agent-23--models-success.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;Stock-Prediction-Models&lt;/strong&gt;, Gathers machine learning and deep learning models for Stock forecasting, included trading bots and simulations.&lt;/p&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#models&#34;&gt;Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#agents&#34;&gt;Agents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/realtime-agent&#34;&gt;Realtime Agent&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#data-explorations&#34;&gt;Data Explorations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#simulations&#34;&gt;Simulations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#tensorflow-js&#34;&gt;Tensorflow-js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#misc&#34;&gt;Misc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#results&#34;&gt;Results&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#results-agent&#34;&gt;Results Agent&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#results-signal-prediction&#34;&gt;Results signal prediction&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#results-analysis&#34;&gt;Results analysis&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/#results-simulation&#34;&gt;Results simulation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;h3&gt;Models&lt;/h3&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/deep-learning&#34;&gt;Deep-learning models&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;LSTM&lt;/li&gt; &#xA; &lt;li&gt;LSTM Bidirectional&lt;/li&gt; &#xA; &lt;li&gt;LSTM 2-Path&lt;/li&gt; &#xA; &lt;li&gt;GRU&lt;/li&gt; &#xA; &lt;li&gt;GRU Bidirectional&lt;/li&gt; &#xA; &lt;li&gt;GRU 2-Path&lt;/li&gt; &#xA; &lt;li&gt;Vanilla&lt;/li&gt; &#xA; &lt;li&gt;Vanilla Bidirectional&lt;/li&gt; &#xA; &lt;li&gt;Vanilla 2-Path&lt;/li&gt; &#xA; &lt;li&gt;LSTM Seq2seq&lt;/li&gt; &#xA; &lt;li&gt;LSTM Bidirectional Seq2seq&lt;/li&gt; &#xA; &lt;li&gt;LSTM Seq2seq VAE&lt;/li&gt; &#xA; &lt;li&gt;GRU Seq2seq&lt;/li&gt; &#xA; &lt;li&gt;GRU Bidirectional Seq2seq&lt;/li&gt; &#xA; &lt;li&gt;GRU Seq2seq VAE&lt;/li&gt; &#xA; &lt;li&gt;Attention-is-all-you-Need&lt;/li&gt; &#xA; &lt;li&gt;CNN-Seq2seq&lt;/li&gt; &#xA; &lt;li&gt;Dilated-CNN-Seq2seq&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bonus&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;How to use one of the model to forecast &lt;code&gt;t + N&lt;/code&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/deep-learning/how-to-forecast.ipynb&#34;&gt;how-to-forecast.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Consensus, how to use sentiment data to forecast &lt;code&gt;t + N&lt;/code&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/deep-learning/sentiment-consensus.ipynb&#34;&gt;sentiment-consensus.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/stacking&#34;&gt;Stacking models&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Deep Feed-forward Auto-Encoder Neural Network to reduce dimension + Deep Recurrent Neural Network + ARIMA + Extreme Boosting Gradient Regressor&lt;/li&gt; &#xA; &lt;li&gt;Adaboost + Bagging + Extra Trees + Gradient Boosting + Random Forest + XGB&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent&#34;&gt;Agents&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Turtle-trading agent&lt;/li&gt; &#xA; &lt;li&gt;Moving-average agent&lt;/li&gt; &#xA; &lt;li&gt;Signal rolling agent&lt;/li&gt; &#xA; &lt;li&gt;Policy-gradient agent&lt;/li&gt; &#xA; &lt;li&gt;Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Evolution-strategy agent&lt;/li&gt; &#xA; &lt;li&gt;Double Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Recurrent Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Double Recurrent Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Duel Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Double Duel Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Duel Recurrent Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Double Duel Recurrent Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Actor-critic agent&lt;/li&gt; &#xA; &lt;li&gt;Actor-critic Duel agent&lt;/li&gt; &#xA; &lt;li&gt;Actor-critic Recurrent agent&lt;/li&gt; &#xA; &lt;li&gt;Actor-critic Duel Recurrent agent&lt;/li&gt; &#xA; &lt;li&gt;Curiosity Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Recurrent Curiosity Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Duel Curiosity Q-learning agent&lt;/li&gt; &#xA; &lt;li&gt;Neuro-evolution agent&lt;/li&gt; &#xA; &lt;li&gt;Neuro-evolution with Novelty search agent&lt;/li&gt; &#xA; &lt;li&gt;ABCD strategy agent&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc&#34;&gt;Data Explorations&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;stock market study on TESLA stock, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/tesla-study.ipynb&#34;&gt;tesla-study.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Outliers study using K-means, SVM, and Gaussian on TESLA stock, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/outliers.ipynb&#34;&gt;outliers.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Overbought-Oversold study on TESLA stock, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/overbought-oversold.ipynb&#34;&gt;overbought-oversold.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Which stock you need to buy? &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/which-stock.ipynb&#34;&gt;which-stock.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation&#34;&gt;Simulations&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Simple Monte Carlo, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/monte-carlo-drift.ipynb&#34;&gt;monte-carlo-drift.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Dynamic volatility Monte Carlo, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/monte-carlo-dynamic-volatility.ipynb&#34;&gt;monte-carlo-dynamic-volatility.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Drift Monte Carlo, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/monte-carlo-drift.ipynb&#34;&gt;monte-carlo-drift.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Multivariate Drift Monte Carlo BTC/USDT with Bitcurate sentiment, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/multivariate-drift-monte-carlo.ipynb&#34;&gt;multivariate-drift-monte-carlo.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Portfolio optimization, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/portfolio-optimization.ipynb&#34;&gt;portfolio-optimization.ipynb&lt;/a&gt;, inspired from &lt;a href=&#34;https://pythonforfinance.net/2017/01/21/investment-portfolio-optimisation-with-python/&#34;&gt;https://pythonforfinance.net/2017/01/21/investment-portfolio-optimisation-with-python/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/stock-forecasting-js&#34;&gt;Tensorflow-js&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;I code &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/deep-learning/1.lstm.ipynb&#34;&gt;LSTM Recurrent Neural Network&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/simple-agent.ipynb&#34;&gt;Simple signal rolling agent&lt;/a&gt; inside Tensorflow JS, you can try it here, &lt;a href=&#34;https://huseinhouse.com/stock-forecasting-js/&#34;&gt;huseinhouse.com/stock-forecasting-js&lt;/a&gt;, you can download any historical CSV and upload dynamically.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc&#34;&gt;Misc&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;fashion trending prediction with cross-validation, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/fashion-forecasting.ipynb&#34;&gt;fashion-forecasting.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Bitcoin analysis with LSTM prediction, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/bitcoin-analysis-lstm.ipynb&#34;&gt;bitcoin-analysis-lstm.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kijang Emas Bank Negara, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/kijang-emas-bank-negara.ipynb&#34;&gt;kijang-emas-bank-negara.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;h3&gt;Results Agent&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;This agent only able to buy or sell 1 unit per transaction.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Turtle-trading agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/1.turtle-agent.ipynb&#34;&gt;turtle-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/turtle-agent.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Moving-average agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/2.moving-average-agent.ipynb&#34;&gt;moving-average-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/moving-average-agent.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Signal rolling agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/3.signal-rolling-agent.ipynb&#34;&gt;signal-rolling-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/signal-rolling-agent.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Policy-gradient agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/4.policy-gradient-agent.ipynb&#34;&gt;policy-gradient-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/policy-gradient-agent.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/5.q-learning-agent.ipynb&#34;&gt;q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/q-learning-agent.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Evolution-strategy agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/6.evolution-strategy-agent.ipynb&#34;&gt;evolution-strategy-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/evolution-strategy-agent.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;7&#34;&gt; &#xA; &lt;li&gt;Double Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/7.double-q-learning-agent.ipynb&#34;&gt;double-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/double-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;8&#34;&gt; &#xA; &lt;li&gt;Recurrent Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/8.recurrent-q-learning-agent.ipynb&#34;&gt;recurrent-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/recurrent-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;9&#34;&gt; &#xA; &lt;li&gt;Double Recurrent Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/9.double-recurrent-q-learning-agent.ipynb&#34;&gt;double-recurrent-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/double-recurrent-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;10&#34;&gt; &#xA; &lt;li&gt;Duel Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/10.duel-q-learning-agent.ipynb&#34;&gt;duel-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/double-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;11&#34;&gt; &#xA; &lt;li&gt;Double Duel Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/11.double-duel-q-learning-agent.ipynb&#34;&gt;double-duel-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/double-duel-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;12&#34;&gt; &#xA; &lt;li&gt;Duel Recurrent Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/12.duel-recurrent-q-learning-agent.ipynb&#34;&gt;duel-recurrent-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/duel-recurrent-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;13&#34;&gt; &#xA; &lt;li&gt;Double Duel Recurrent Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/13.double-duel-recurrent-q-learning-agent.ipynb&#34;&gt;double-duel-recurrent-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/double-duel-recurrent-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;14&#34;&gt; &#xA; &lt;li&gt;Actor-critic agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/14.actor-critic-agent.ipynb&#34;&gt;actor-critic-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/actor-critic.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;15&#34;&gt; &#xA; &lt;li&gt;Actor-critic Duel agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/14.actor-critic-duel-agent.ipynb&#34;&gt;actor-critic-duel-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/actor-critic-duel.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;16&#34;&gt; &#xA; &lt;li&gt;Actor-critic Recurrent agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/16.actor-critic-recurrent-agent.ipynb&#34;&gt;actor-critic-recurrent-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/actor-critic-recurrent.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;17&#34;&gt; &#xA; &lt;li&gt;Actor-critic Duel Recurrent agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/17.actor-critic-duel-recurrent-agent.ipynb&#34;&gt;actor-critic-duel-recurrent-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/actor-critic-duel-recurrent.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;18&#34;&gt; &#xA; &lt;li&gt;Curiosity Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/18.curiosity-q-learning-agent.ipynb&#34;&gt;curiosity-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/curiosity-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;19&#34;&gt; &#xA; &lt;li&gt;Recurrent Curiosity Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/19.recurrent-curiosity-q-learning-agent.ipynb&#34;&gt;recurrent-curiosity-q-learning.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/recurrent-curiosity-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;20&#34;&gt; &#xA; &lt;li&gt;Duel Curiosity Q-learning agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/20.duel-curiosity-q-learning-agent.ipynb&#34;&gt;duel-curiosity-q-learning-agent.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/duel-curiosity-q-learning.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;21&#34;&gt; &#xA; &lt;li&gt;Neuro-evolution agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/21.neuro-evolution-agent.ipynb&#34;&gt;neuro-evolution.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/neuro-evolution.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;22&#34;&gt; &#xA; &lt;li&gt;Neuro-evolution with Novelty search agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/22.neuro-evolution-novelty-search-agent.ipynb&#34;&gt;neuro-evolution-novelty-search.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/neuro-evolution-novelty-search.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;23&#34;&gt; &#xA; &lt;li&gt;ABCD strategy agent, &lt;a href=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/agent/23.abcd-strategy-agent.ipynb&#34;&gt;abcd-strategy.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output-agent/abcd-strategy.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;h3&gt;Results signal prediction&lt;/h3&gt; &#xA;&lt;p&gt;I will cut the dataset to train and test datasets,&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Train dataset derived from starting timestamp until last 30 days&lt;/li&gt; &#xA; &lt;li&gt;Test dataset derived from last 30 days until end of the dataset&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;So we will let the model do forecasting based on last 30 days, and we will going to repeat the experiment for 10 times. You can increase it locally if you want, and tuning parameters will help you by a lot.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;LSTM, accuracy 95.693%, time taken for 1 epoch 01:09&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/lstm.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;LSTM Bidirectional, accuracy 93.8%, time taken for 1 epoch 01:40&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/bidirectional-lstm.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;LSTM 2-Path, accuracy 94.63%, time taken for 1 epoch 01:39&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/lstm-2path.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;GRU, accuracy 94.63%, time taken for 1 epoch 02:10&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/gru.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;GRU Bidirectional, accuracy 92.5673%, time taken for 1 epoch 01:40&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/bidirectional-gru.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;GRU 2-Path, accuracy 93.2117%, time taken for 1 epoch 01:39&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/gru-2path.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;7&#34;&gt; &#xA; &lt;li&gt;Vanilla, accuracy 91.4686%, time taken for 1 epoch 00:52&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/vanilla.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;8&#34;&gt; &#xA; &lt;li&gt;Vanilla Bidirectional, accuracy 88.9927%, time taken for 1 epoch 01:06&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/bidirectional-vanilla.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;9&#34;&gt; &#xA; &lt;li&gt;Vanilla 2-Path, accuracy 91.5406%, time taken for 1 epoch 01:08&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/vanilla-2path.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;10&#34;&gt; &#xA; &lt;li&gt;LSTM Seq2seq, accuracy 94.9817%, time taken for 1 epoch 01:36&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/lstm-seq2seq.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;11&#34;&gt; &#xA; &lt;li&gt;LSTM Bidirectional Seq2seq, accuracy 94.517%, time taken for 1 epoch 02:30&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/bidirectional-lstm-seq2seq.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;12&#34;&gt; &#xA; &lt;li&gt;LSTM Seq2seq VAE, accuracy 95.4190%, time taken for 1 epoch 01:48&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/lstm-seq2seq-vae.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;13&#34;&gt; &#xA; &lt;li&gt;GRU Seq2seq, accuracy 90.8854%, time taken for 1 epoch 01:34&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/gru-seq2seq.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;14&#34;&gt; &#xA; &lt;li&gt;GRU Bidirectional Seq2seq, accuracy 67.9915%, time taken for 1 epoch 02:30&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/bidirectional-gru-seq2seq.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;15&#34;&gt; &#xA; &lt;li&gt;GRU Seq2seq VAE, accuracy 89.1321%, time taken for 1 epoch 01:48&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/gru-seq2seq-vae.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;16&#34;&gt; &#xA; &lt;li&gt;Attention-is-all-you-Need, accuracy 94.2482%, time taken for 1 epoch 01:41&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/attention-is-all-you-need.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;17&#34;&gt; &#xA; &lt;li&gt;CNN-Seq2seq, accuracy 90.74%, time taken for 1 epoch 00:43&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/cnn-seq2seq.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;18&#34;&gt; &#xA; &lt;li&gt;Dilated-CNN-Seq2seq, accuracy 95.86%, time taken for 1 epoch 00:14&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/dilated-cnn-seq2seq.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bonus&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;How to forecast,&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/how-to-forecast.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Sentiment consensus,&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/output/sentiment-consensus.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;h3&gt;Results analysis&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Outliers study using K-means, SVM, and Gaussian on TESLA stock&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/outliers.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Overbought-Oversold study on TESLA stock&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/overbought-oversold.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Which stock you need to buy?&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/misc/which-stock.png&#34; width=&#34;40%&#34; align=&#34;&#34;&gt; &#xA;&lt;h3&gt;Results simulation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Simple Monte Carlo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/monte-carlo-simple.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Dynamic volatity Monte Carlo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/monte-carlo-dynamic-volatility.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Drift Monte Carlo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/monte-carlo-drift.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Multivariate Drift Monte Carlo BTC/USDT with Bitcurate sentiment&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/multivariate-drift-monte-carlo.png&#34; width=&#34;70%&#34; align=&#34;&#34;&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Portfolio optimization&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/simulation/portfolio-optimization.png&#34; width=&#34;40%&#34; align=&#34;&#34;&gt;</summary>
  </entry>
  <entry>
    <title>ageron/handson-ml2</title>
    <updated>2022-06-02T02:14:48Z</updated>
    <id>tag:github.com,2022-06-02:/ageron/handson-ml2</id>
    <link href="https://github.com/ageron/handson-ml2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Machine Learning Notebooks&lt;/h1&gt; &#xA;&lt;p&gt;This project aims at teaching you the fundamentals of Machine Learning in python. It contains the example code and solutions to the exercises in the second edition of my O&#39;Reilly book &lt;a href=&#34;https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/&#34;&gt;Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;img src=&#34;https://images-na.ssl-images-amazon.com/images/I/51aqYc1QyrL._SX379_BO1,204,203,200_.jpg&#34; title=&#34;book&#34; width=&#34;150&#34;&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you are looking for the first edition notebooks, check out &lt;a href=&#34;https://github.com/ageron/handson-ml&#34;&gt;ageron/handson-ml&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;Want to play with these notebooks online without having to install anything?&lt;/h3&gt; &#xA;&lt;p&gt;Use any of the following services (I recommended Colab or Kaggle, since they offer free GPUs and TPUs).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: &lt;em&gt;Please be aware that these services provide temporary environments: anything you do will be deleted after a while, so make sure you download any data you care about.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/ageron/handson-ml2/blob/master/&#34; target=&#34;_parent&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://homl.info/kaggle/&#34;&gt;&lt;img src=&#34;https://kaggle.com/static/images/open-in-kaggle.svg?sanitize=true&#34; alt=&#34;Open in Kaggle&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/ageron/handson-ml2/HEAD?filepath=%2Findex.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Launch binder&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://homl.info/deepnote/&#34;&gt;&lt;img src=&#34;https://deepnote.com/buttons/launch-in-deepnote-small.svg?sanitize=true&#34; alt=&#34;Launch in Deepnote&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Just want to quickly look at some notebooks, without executing any code?&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/ageron/handson-ml2/blob/master/index.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg?sanitize=true&#34; alt=&#34;Render nbviewer&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/ageron/handson-ml2/raw/master/index.ipynb&#34;&gt;github.com&#39;s notebook viewer&lt;/a&gt; also works but it&#39;s not ideal: it&#39;s slower, the math equations are not always displayed correctly, and large notebooks often fail to open.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Want to run this project using a Docker image?&lt;/h3&gt; &#xA;&lt;p&gt;Read the &lt;a href=&#34;https://github.com/ageron/handson-ml2/tree/master/docker&#34;&gt;Docker instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Want to install this project on your own machine?&lt;/h3&gt; &#xA;&lt;p&gt;Start by installing &lt;a href=&#34;https://www.anaconda.com/distribution/&#34;&gt;Anaconda&lt;/a&gt; (or &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;Miniconda&lt;/a&gt;), &lt;a href=&#34;https://git-scm.com/downloads&#34;&gt;git&lt;/a&gt;, and if you have a TensorFlow-compatible GPU, install the &lt;a href=&#34;https://www.nvidia.com/Download/index.aspx&#34;&gt;GPU driver&lt;/a&gt;, as well as the appropriate version of CUDA and cuDNN (see TensorFlow&#39;s documentation for more details).&lt;/p&gt; &#xA;&lt;p&gt;Next, clone this project by opening a terminal and typing the following commands (do not type the first &lt;code&gt;$&lt;/code&gt; signs on each line, they just indicate that these are terminal commands):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ageron/handson-ml2.git&#xA;$ cd handson-ml2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, run the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ conda env create -f environment.yml&#xA;$ conda activate tf2&#xA;$ python -m ipykernel install --user --name=python3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, start Jupyter:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ jupyter notebook&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you need further instructions, read the &lt;a href=&#34;https://raw.githubusercontent.com/ageron/handson-ml2/master/INSTALL.md&#34;&gt;detailed installation instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;FAQ&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Which Python version should I use?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;I recommend Python 3.8. If you follow the installation instructions above, that&#39;s the version you will get. Most code will work with other versions of Python 3, but some libraries do not support Python 3.9 or 3.10 yet, which is why I recommend Python 3.8.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;I&#39;m getting an error when I call &lt;code&gt;load_housing_data()&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Make sure you call &lt;code&gt;fetch_housing_data()&lt;/code&gt; &lt;em&gt;before&lt;/em&gt; you call &lt;code&gt;load_housing_data()&lt;/code&gt;. If you&#39;re getting an HTTP error, make sure you&#39;re running the exact same code as in the notebook (copy/paste it if needed). If the problem persists, please check your network configuration.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;I&#39;m getting an SSL error on MacOSX&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You probably need to install the SSL certificates (see this &lt;a href=&#34;https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error&#34;&gt;StackOverflow question&lt;/a&gt;). If you downloaded Python from the official website, then run &lt;code&gt;/Applications/Python\ 3.8/Install\ Certificates.command&lt;/code&gt; in a terminal (change &lt;code&gt;3.8&lt;/code&gt; to whatever version you installed). If you installed Python using MacPorts, run &lt;code&gt;sudo port install curl-ca-bundle&lt;/code&gt; in a terminal.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;I&#39;ve installed this project locally. How do I update it to the latest version?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/ageron/handson-ml2/master/INSTALL.md&#34;&gt;INSTALL.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How do I update my Python libraries to the latest versions, when using Anaconda?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/ageron/handson-ml2/master/INSTALL.md&#34;&gt;INSTALL.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;I would like to thank everyone &lt;a href=&#34;https://github.com/ageron/handson-ml2/graphs/contributors&#34;&gt;who contributed to this project&lt;/a&gt;, either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Haesun Park and Ian Beauregard who reviewed every notebook and submitted many PRs, including help on some of the exercise solutions. Thanks as well to Steven Bunkley and Ziembla who created the &lt;code&gt;docker&lt;/code&gt; directory, and to github user SuperYorio who helped on some exercise solutions.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>plotly/dash-sample-apps</title>
    <updated>2022-06-02T02:14:48Z</updated>
    <id>tag:github.com,2022-06-02:/plotly/dash-sample-apps</id>
    <link href="https://github.com/plotly/dash-sample-apps" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open-source demos hosted on Dash Gallery&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dash Sample Apps&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://circleci.com/gh/plotly/dash-sample-apps&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/plotly/dash-sample-apps.svg?style=svg&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository hosts the code for over 100 open-source Dash apps written in Python or R. They can serve as a starting point for your own Dash app, as a learning tool to better understand how Dash works, as a reusable templates, and much more.&lt;/p&gt; &#xA;&lt;p&gt;Most apps in this repository are hosted on &lt;a href=&#34;https://dash-gallery.plotly.host/&#34;&gt;Dash Gallery&lt;/a&gt;, which is our internal server running on &lt;a href=&#34;https://plotly.com/dash/kubernetes/&#34;&gt;Dash Enterprise Kubernetes&lt;/a&gt;. Note that you can find both open-sourced apps and demos for our &lt;a href=&#34;https://plotly.com/dash/&#34;&gt;licensed products&lt;/a&gt;, including &lt;a href=&#34;https://plotly.com/dash/design-kit/&#34;&gt;Design Kit&lt;/a&gt; and &lt;a href=&#34;https://plotly.com/dash/snapshot-engine/&#34;&gt;Snapshot Engine&lt;/a&gt;. If you are interested in learning more, don&#39;t hesitate to reach out to &lt;a href=&#34;https://plotly.com/get-demo/&#34;&gt;get a demo&lt;/a&gt;. If you want to only see the open-sourced apps, select the &lt;a href=&#34;https://dash-gallery.plotly.host/Portal/?search=%5BOpen%20Source%5D&#34;&gt;&#34;Open Source&#34; tag&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Downloading and running a single app&lt;/h2&gt; &#xA;&lt;p&gt;Visit the &lt;a href=&#34;https://github.com/plotly/dash-sample-apps/releases&#34;&gt;releases page&lt;/a&gt; and download and &lt;code&gt;unzip&lt;/code&gt; the app you want. Then &lt;code&gt;cd&lt;/code&gt; into the app directory and install its dependencies in a virtual environment in the following way:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m venv venv&#xA;source venv/bin/activate  # Windows: \venv\scripts\activate&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;then you can run the app:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Cloning this whole repository&lt;/h2&gt; &#xA;&lt;p&gt;To clone this repository, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/plotly/dash-sample-apps&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note this might take a long time since it copies over 100 apps available in the repo. If you just want to try one app, refer to the section above.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;To contribute to this repository, please see the &lt;a href=&#34;https://raw.githubusercontent.com/plotly/dash-sample-apps/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>bnsreenu/python_for_microscopists</title>
    <updated>2022-06-02T02:14:48Z</updated>
    <id>tag:github.com,2022-06-02:/bnsreenu/python_for_microscopists</id>
    <link href="https://github.com/bnsreenu/python_for_microscopists" rel="alternate"></link>
    <summary type="html">&lt;p&gt;https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w?sub_confirmation=1&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;b&gt; Author: Dr. Sreenivas Bhattiprolu &lt;/b&gt;&lt;br&gt; &lt;b&gt;Twitter: @digitalsreeni &lt;/b&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Python for Microscopists and other image processing enthusiasts&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w?sub_confirmation=1&#34;&gt;https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w?sub_confirmation=1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The YouTube channel associated with this code walks you through the entire process of learning to code in Python; all the way from basics to advanced machine learning and deep learning. The primary emphasis will be on image processing and other relevant functionality.&lt;/p&gt; &#xA;&lt;p&gt;Why did I create this channel? To help you (students and researchers) gain a new skill and succeed in your respective fields.&lt;/p&gt; &#xA;&lt;p&gt;You may think coding is hard and that it&#39;s not your cup of tea, but Python made it easy to code even advanced algorithms. In addition, coding will make you self sufficient, it will teach you how to think, it improves your collaborative skills and it can take your career to new heights. Therefore, if you want to stay ahead of your peers and relevant in your field, overcome your fears and start coding!&lt;/p&gt; &#xA;&lt;p&gt;Also, checkout WWW.APEER.COM if you want free image processing in the cloud! Free for non-profits / academics / personal use.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/AI-For-Beginners</title>
    <updated>2022-06-02T02:14:48Z</updated>
    <id>tag:github.com,2022-06-02:/microsoft/AI-For-Beginners</id>
    <link href="https://github.com/microsoft/AI-For-Beginners" rel="alternate"></link>
    <summary type="html">&lt;p&gt;12 Weeks, 24 Lessons, AI for All!&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/AI-For-Beginners/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/microsoft/AI-For-Beginners.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/AI-For-Beginners/graphs/contributors/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/microsoft/AI-For-Beginners.svg?sanitize=true&#34; alt=&#34;GitHub contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/AI-For-Beginners/issues/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/microsoft/AI-For-Beginners.svg?sanitize=true&#34; alt=&#34;GitHub issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/AI-For-Beginners/pulls/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/microsoft/AI-For-Beginners.svg?sanitize=true&#34; alt=&#34;GitHub pull-requests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://makeapullrequest.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://GitHub.com/microsoft/AI-For-Beginners/watchers/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/watchers/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Watch&#34; alt=&#34;GitHub watchers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/AI-For-Beginners/network/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Fork&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/AI-For-Beginners/stargazers/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Star&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mybinder.org/v2/gh/microsoft/ai-for-beginners/HEAD&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/Microsoft/ai-for-beginners?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/Microsoft/ai-for-beginners.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Artificial Intelligence for Beginners - A Curriculum&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/sketchnotes/ai-overview.png&#34; alt=&#34; Sketchnote by (@girlie_mac) &#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;AI For Beginners - &lt;em&gt;Sketchnote by &lt;a href=&#34;https://twitter.com/girlie_mac&#34;&gt;@girlie_mac&lt;/a&gt;&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Azure Cloud Advocates at Microsoft are pleased to offer a 12-week, 24-lesson curriculum all about &lt;strong&gt;Artificial Intelligence&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In this curriculum, you will learn:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Different approaches to Artificial Intelligence, including the &#34;good old&#34; symbolic approach with &lt;strong&gt;Knowledge Representation&lt;/strong&gt; and reasoning (&lt;a href=&#34;https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence&#34;&gt;GOFAI&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Neural Networks&lt;/strong&gt; and &lt;strong&gt;Deep Learning&lt;/strong&gt;, which are at the core of modern AI. We will illustrate the concepts behind these important topics using code in two of the most popular frameworks - &lt;a href=&#34;http://Tensorflow.org&#34;&gt;TensorFlow&lt;/a&gt; and &lt;a href=&#34;http://pytorch.org&#34;&gt;PyTorch&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Neural Architectures&lt;/strong&gt; for working with images and text. We will cover recent models but may lack a little bit on the state-of-the-art.&lt;/li&gt; &#xA; &lt;li&gt;Less popular AI approaches, such as &lt;strong&gt;Genetic Algorithms&lt;/strong&gt; and &lt;strong&gt;Multi-Agent Systems&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;What we will not cover in this curriculum:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Business cases of using &lt;strong&gt;AI in Business&lt;/strong&gt;. Consider taking &lt;a href=&#34;https://docs.microsoft.com/learn/paths/introduction-ai-for-business-users/?WT.mc_id=academic-57639-dmitryso&#34;&gt;Introduction to AI for business users&lt;/a&gt; learning path on Microsoft Learn, or &lt;a href=&#34;https://www.microsoft.com/ai/ai-business-school/?WT.mc_id=academic-57639-dmitryso&#34;&gt;AI Business School&lt;/a&gt;, developed in cooperation with &lt;a href=&#34;https://www.insead.edu/&#34;&gt;INSEAD&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Classic Machine Learning&lt;/strong&gt;, which is well described in our &lt;a href=&#34;http://github.com/Microsoft/ML-for-Beginners&#34;&gt;Machine Learning for Beginners Curriculum&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Practical AI applications built using &lt;strong&gt;&lt;a href=&#34;https://azure.microsoft.com/services/cognitive-services/?WT.mc_id=academic-57639-dmitryso&#34;&gt;Cognitive Services&lt;/a&gt;&lt;/strong&gt;. For this, we recommend that you start with modules Microsoft Learn for &lt;a href=&#34;https://docs.microsoft.com/learn/paths/create-computer-vision-solutions-azure-cognitive-services/?WT.mc_id=academic-57639-dmitryso&#34;&gt;vision&lt;/a&gt;, &lt;a href=&#34;https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-57639-dmitryso&#34;&gt;natural language processing&lt;/a&gt; and others.&lt;/li&gt; &#xA; &lt;li&gt;Specific ML &lt;strong&gt;Cloud Frameworks&lt;/strong&gt;, such as &lt;a href=&#34;https://azure.microsoft.com/services/machine-learning/?WT.mc_id=academic-57639-dmitryso&#34;&gt;Azure Machine Learning&lt;/a&gt; or &lt;a href=&#34;https://docs.microsoft.com/learn/paths/data-engineer-azure-databricks?WT.mc_id=academic-57639-dmitryso&#34;&gt;Azure Databricks&lt;/a&gt;. Consider using &lt;a href=&#34;https://docs.microsoft.com/learn/paths/build-ai-solutions-with-azure-ml-service/?WT.mc_id=academic-57639-dmitryso&#34;&gt;Build and operate machine learning solutions with Azure Machine Learning&lt;/a&gt; and &lt;a href=&#34;https://docs.microsoft.com/learn/paths/build-operate-machine-learning-solutions-azure-databricks/?WT.mc_id=academic-57639-dmitryso&#34;&gt;Build and Operate Machine Learning Solutions with Azure Databricks&lt;/a&gt; learning paths.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Conversational AI&lt;/strong&gt; and &lt;strong&gt;Chat Bots&lt;/strong&gt;. There is a separate &lt;a href=&#34;https://docs.microsoft.com/learn/paths/create-conversational-ai-solutions/?WT.mc_id=academic-57639-dmitryso&#34;&gt;Create conversational AI solutions&lt;/a&gt; learning path, and you can also refer to &lt;a href=&#34;https://soshnikov.com/azure/hello-bot-conversational-ai-on-microsoft-platform/&#34;&gt;this blog post&lt;/a&gt; for more detail.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Deep Mathematics&lt;/strong&gt; behind deep learning. For this, we would recommend &lt;a href=&#34;https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618&#34;&gt;Deep Learning&lt;/a&gt; by Ian Goodfellow, Yoshua Bengio and Aaron Courville, which is also available online at &lt;a href=&#34;https://www.deeplearningbook.org/&#34;&gt;https://www.deeplearningbook.org/&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For a gentle introduction to &lt;em&gt;AI in the Cloud&lt;/em&gt; topics you may consider taking the &lt;a href=&#34;https://docs.microsoft.com/learn/paths/get-started-with-artificial-intelligence-on-azure/?WT.mc_id=academic-57639-dmitryso&#34;&gt;Get started with artificial intelligence on Azure&lt;/a&gt; Learning Path.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Content&lt;/h1&gt; &#xA;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;th&gt;No&lt;/th&gt;&#xA;   &lt;th&gt;Lesson&lt;/th&gt;&#xA;   &lt;th&gt;Intro&lt;/th&gt;&#xA;   &lt;th&gt;PyTorch&lt;/th&gt;&#xA;   &lt;th&gt;Keras/TensorFlow&lt;/th&gt;&#xA;   &lt;th&gt;Lab&lt;/th&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;I&lt;/td&gt;&#xA;   &lt;td colspan=&#34;4&#34;&gt;&lt;b&gt;Introduction to AI&lt;/b&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;1&lt;/td&gt;&#xA;   &lt;td&gt;Introduction and History of AI&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/1-Intro/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;II&lt;/td&gt;&#xA;   &lt;td colspan=&#34;4&#34;&gt;&lt;b&gt;Symbolic AI&lt;/b&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;2 &lt;/td&gt;&#xA;   &lt;td&gt;Knowledge Representation and Expert Systems&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/Animals.ipynb&#34;&gt;Expert System&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/FamilyOntology.ipynb&#34;&gt;Ontology&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/MSConceptGraph.ipynb&#34;&gt;Concept Graph&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;III&lt;/td&gt;&#xA;   &lt;td colspan=&#34;4&#34;&gt;&lt;b&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/README.md&#34;&gt;Introduction to Neural Networks&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;3&lt;/td&gt;&#xA;   &lt;td&gt;Perceptron&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/README.md&#34;&gt;Text&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/Perceptron.ipynb&#34;&gt;Notebook&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;4 &lt;/td&gt;&#xA;   &lt;td&gt;Multi-Layered Perceptron and Creating our own Framework&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb&#34;&gt;Notebook&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;5&lt;/td&gt; &#xA;   &lt;td&gt;Intro to Frameworks (PyTorch/TensorFlow)&lt;br&gt;Overfitting&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/README.md&#34;&gt;Text&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/Overfitting.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb&#34;&gt;Keras&lt;/a&gt;&lt;/td&gt;/ &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;IV&lt;/td&gt;&#xA;   &lt;td&gt;&lt;b&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/README.md&#34;&gt;Computer Vision&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td colspan=&#34;3&#34;&gt;&lt;a href=&#34;https://docs.microsoft.com/learn/paths/explore-computer-vision-microsoft-azure/?WT.mc_id=academic-57639-dmitryso&#34;&gt;&lt;i&gt;AI Fundamentals: Explore Computer Vision&lt;/i&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt;&lt;i&gt;Microsoft Learn Module on Computer Vision&lt;/i&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.microsoft.com/learn/modules/intro-computer-vision-pytorch/?WT.mc_id=academic-57639-dmitryso&#34;&gt;&lt;i&gt;PyTorch&lt;/i&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.microsoft.com/learn/modules/intro-computer-vision-TensorFlow/?WT.mc_id=academic-57639-dmitryso&#34;&gt;&lt;i&gt;TensorFlow&lt;/i&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;6&lt;/td&gt;&#xA;   &lt;td&gt;Intro to Computer Vision. OpenCV&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/OpenCV.ipynb&#34;&gt;Notebook&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;7&lt;/td&gt;&#xA;   &lt;td&gt;Convolutional Neural Networks&lt;br&gt;CNN Architectures&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/README.md&#34;&gt;Text&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/ConvNetsPyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/ConvNetsTF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;8&lt;/td&gt;&#xA;   &lt;td&gt;Pre-trained Networks and Transfer Learning&lt;br&gt;Training Tricks&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/README.md&#34;&gt;Text&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/Dropout.ipynb&#34;&gt;Dropout sample&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;9&lt;/td&gt;&#xA;   &lt;td&gt;Autoencoders and VAEs&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;10&lt;/td&gt;&#xA;   &lt;td&gt;Generative Adversarial Networks&lt;br&gt;Artistic Style Transfer&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/GANTF.ipynb&#34;&gt;TensorFlow GAN&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb&#34;&gt;Style Transfer&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;11&lt;/td&gt;&#xA;   &lt;td&gt;Object Detection&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;PyTorch&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;12&lt;/td&gt;&#xA;   &lt;td&gt;Semantic Segmentation. U-Net&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationPytorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationTF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;V&lt;/td&gt;&#xA;   &lt;td&gt;&lt;b&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/README.md&#34;&gt;Natural Language Processing&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td colspan=&#34;3&#34;&gt;&lt;a href=&#34;https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-57639-dmitryso&#34;&gt;&lt;i&gt;AI Fundamentals: Explore Natural Language Processing&lt;/i&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt;&lt;i&gt;Microsoft Learn Module on Natural Language&lt;/i&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-57639-dmitryso&#34;&gt;&lt;i&gt;PyTorch&lt;/i&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.microsoft.com/learn/modules/intro-natural-language-processing-TensorFlow/?WT.mc_id=academic-57639-dmitryso&#34;&gt;&lt;i&gt;TensorFlow&lt;/i&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;13&lt;/td&gt;&#xA;   &lt;td&gt;Text Representation. Bow/TF-IDF&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/13-TextRep/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/13-TextRep/TextRepresentationPyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/13-TextRep/TextRepresentationTF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;14&lt;/td&gt;&#xA;   &lt;td&gt;Semantic word embeddings. Word2Vec and GloVe&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/14-Embeddings/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/14-Embeddings/EmbeddingsPyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/14-Embeddings/EmbeddingsTF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;15&lt;/td&gt;&#xA;   &lt;td&gt;Language Modeling. Training your own embeddings&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/CBoW-TF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;16&lt;/td&gt;&#xA;   &lt;td&gt;Recurrent Neural Networks&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/16-RNN/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/16-RNN/RNNPyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/16-RNN/RNNTF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;17&lt;/td&gt;&#xA;   &lt;td&gt;Generative Recurrent Networks&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/GenerativePyTorch.md&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/GenerativeTF.md&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;18&lt;/td&gt;&#xA;   &lt;td&gt;Transformers. BERT.&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/18-Transformers/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/18-Transformers/TransformersPyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/18-Transformers/TransformersTF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;19&lt;/td&gt;&#xA;   &lt;td&gt;Named Entity Recognition&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/NER-TF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;20&lt;/td&gt;&#xA;   &lt;td&gt;Large Language Models, Prompt Programming and Few-Shot Tasks&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/20-LangModels/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/20-LangModels/GPT-PyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;VI&lt;/td&gt;&#xA;   &lt;td colspan=&#34;4&#34;&gt;&lt;b&gt;Other AI Techniques&lt;/b&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;21&lt;/td&gt;&#xA;   &lt;td&gt;Genetic Algorithms&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/21-GeneticAlgorithms/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/21-GeneticAlgorithms/Genetic.ipynb&#34;&gt;Notebook&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;22&lt;/td&gt;&#xA;   &lt;td&gt;Deep Reinforcement Learning&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/CartPole-RL-TF.ipynb&#34;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/lab/README.md&#34;&gt;Lab&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;23&lt;/td&gt;&#xA;   &lt;td&gt;Multi-Agent Systems&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/23-MultiagentSystems/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;VII&lt;/td&gt;&#xA;   &lt;td colspan=&#34;4&#34;&gt;&lt;b&gt;AI Ethics&lt;/b&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;24&lt;/td&gt;&#xA;   &lt;td&gt;AI Ethics and Responsible AI&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/7-Ethics/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt;&lt;a href=&#34;https://docs.microsoft.com/learn/paths/responsible-ai-business-principles/?WT.mc_id=academic-57639-dmitryso&#34;&gt;&lt;i&gt;MS Learn: Responsible AI Principles&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;   &lt;td colspan=&#34;4&#34;&gt;&lt;b&gt;Extras&lt;/b&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;X1&lt;/td&gt;&#xA;   &lt;td&gt;Multi-Modal Networks, CLIP and VQGAN&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/X-Extras/X1-MultiModal/README.md&#34;&gt;Text&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/X-Extras/X1-MultiModal/Clip.ipynb&#34;&gt;Notebook&lt;/a&gt;&lt;/td&gt;&#xA;   &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://soshnikov.com/courses/ai-for-beginners/mindmap.html&#34;&gt;Mindmap of the Course&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Each lesson contains some pre-reading material (linked as &lt;strong&gt;Text&lt;/strong&gt; above), and some executable Jupyter Notebooks, which are often specific to the framework (&lt;strong&gt;PyTorch&lt;/strong&gt; or &lt;strong&gt;TensorFlow&lt;/strong&gt;). The executable notebook also contains a lot of theoretical material, so to understand the topic you need to go through at least one version of the notebooks (either PyTorch or TensorFlow). There are also &lt;strong&gt;Labs&lt;/strong&gt; available for some topics, which give you an opportunity to try applying the material you have learned to a specific problem.&lt;/p&gt; &#xA;&lt;p&gt;Some sections also contain links to &lt;strong&gt;MS Learn&lt;/strong&gt; modules that cover related topics. Microsoft Learn provides a convenient GPU-enabled learning environment, although in terms of content you can expect this curriculum to go a bit deeper.&lt;/p&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Students&lt;/strong&gt;, there are a couple of ways to use the curriculum. First of all, you can just read the text and look through the code directly on GitHub. If you want to run the code in any of the notebooks - &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/how-to-run.md&#34;&gt;read our instructions&lt;/a&gt;, and find more advice on how to do it &lt;a href=&#34;https://soshnikov.com/education/how-to-execute-notebooks-from-github/&#34;&gt;in this blog post&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/how-to-run.md&#34;&gt;Instructions on how to run the code in this curriculum&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;However, if you would like to take the course as a self-study project, we suggest that you fork the entire repo to your own GitHub account and complete the exercises on your own or with a group:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Start with a pre-lecture quiz&lt;/li&gt; &#xA; &lt;li&gt;Read the intro text for the lecture&lt;/li&gt; &#xA; &lt;li&gt;If the lecture has additional notebooks, go through them, reading and executing the code. If both TensorFlow and PyTorch notebooks are provided, you can focus on one of them - chose your favorite framework&lt;/li&gt; &#xA; &lt;li&gt;Notebooks often contain some of the challenges that require you to tweak the code a little bit to experiment&lt;/li&gt; &#xA; &lt;li&gt;Take the post-lecture quiz&lt;/li&gt; &#xA; &lt;li&gt;If there is a lab attached to the module - complete the assignment&lt;/li&gt; &#xA; &lt;li&gt;Visit the &lt;a href=&#34;https://github.com/microsoft/AI-For-Beginners/discussions&#34;&gt;Discussion board&lt;/a&gt; to &#34;learn out loud&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Chat with other learners &lt;a href=&#34;https://gitter.im/Microsoft/ai-for-beginners&#34;&gt;on Gitter&lt;/a&gt; or &lt;a href=&#34;http://t.me/ai_for_beginners&#34;&gt;in Telegram channel&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;For further study, we recommend following these &lt;a href=&#34;https://docs.microsoft.com/en-us/users/dmitrysoshnikov-9132/collections/31zgizg2p418yo/?WT.mc_id=academic-57639-dmitryso&#34;&gt;Microsoft Learn&lt;/a&gt; modules and learning paths.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;Teachers&lt;/strong&gt;, we have &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/for-teachers.md&#34;&gt;included some suggestions&lt;/a&gt; on how to use this curriculum.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;âœï¸ Primary Author:&lt;/strong&gt; &lt;a href=&#34;http://soshnikov.com&#34;&gt;Dmitry Soshnikov&lt;/a&gt;, PhD &lt;br&gt; &lt;strong&gt;ðŸ”¥ Editor:&lt;/strong&gt; &lt;a href=&#34;https://twitter.com/jenlooper&#34;&gt;Jen Looper&lt;/a&gt;, PhD &lt;br&gt; &lt;strong&gt;ðŸŽ¨ Sketchnote illustrator:&lt;/strong&gt; &lt;a href=&#34;https://twitter.com/girlie_mac&#34;&gt;Tomomi Imura&lt;/a&gt; &lt;br&gt; &lt;strong&gt;âœ… Quiz Creator:&lt;/strong&gt; &lt;a href=&#34;https://github.com/CinnamonXI&#34;&gt;Lateefah Bello&lt;/a&gt;, &lt;a href=&#34;https://studentambassadors.microsoft.com/&#34;&gt;MLSA&lt;/a&gt; &lt;br&gt; &lt;strong&gt;ðŸ™ Core Contributors:&lt;/strong&gt; &lt;a href=&#34;https://github.com/Pe4enIks&#34;&gt;Evgenii Pishchik&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Meet the Team&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/m2KrAk0cC1c&#34; title=&#34;Promo video&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/sketchnotes/ai-for-beginners.png&#34; alt=&#34;Promo video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ðŸŽ¥ Click the image above for a video about the project and the folks who created it!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Pedagogy&lt;/h2&gt; &#xA;&lt;p&gt;We have chosen two pedagogical tenets while building this curriculum: ensuring that it is hands-on &lt;strong&gt;project-based&lt;/strong&gt; and that it includes &lt;strong&gt;frequent quizzes&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;By ensuring that the content aligns with projects, the process is made more engaging for students and retention of concepts will be augmented. In addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 12 week cycle.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Find our &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/CODE_OF_CONDUCT.md&#34;&gt;Code of Conduct&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/TRANSLATIONS.md&#34;&gt;Translation&lt;/a&gt; guidelines. Find our &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/SUPPORT.md&#34;&gt;Support Documentation here&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/SECURITY.md&#34;&gt;security information here&lt;/a&gt;. We welcome your constructive feedback!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;A note about quizzes&lt;/strong&gt;: All quizzes are contained &lt;a href=&#34;https://black-ground-0cc93280f.1.azurestaticapps.net/&#34;&gt;in this app&lt;/a&gt;, for 50 total quizzes of three questions each. They are linked from within the lessons but the quiz app can be run locally; follow the instruction in the &lt;code&gt;etc/quiz-app&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Offline access&lt;/h2&gt; &#xA;&lt;p&gt;You can run this documentation offline by using &lt;a href=&#34;https://docsify.js.org/#/&#34;&gt;Docsify&lt;/a&gt;. Fork this repo, &lt;a href=&#34;https://docsify.js.org/#/quickstart&#34;&gt;install Docsify&lt;/a&gt; on your local machine, and then in the &lt;code&gt;etc/docsify&lt;/code&gt; folder of this repo, type &lt;code&gt;docsify serve&lt;/code&gt;. The website will be served on port 3000 on your localhost: &lt;code&gt;localhost:3000&lt;/code&gt;. A pdf of the curriculum is available &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/pdf/readme.pdf&#34;&gt;at this link&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Help Wanted!&lt;/h2&gt; &#xA;&lt;p&gt;Would you like to contribute a translation? Please read our &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/etc/TRANSLATIONS.md&#34;&gt;translation guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Other Curricula&lt;/h2&gt; &#xA;&lt;p&gt;Our team produces other curricula! Check out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/webdev-beginners&#34;&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/iot-beginners&#34;&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/ML-for-Beginners&#34;&gt;Machine Learning for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/datascience-beginners&#34;&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>